From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jan  1 10:09:58 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 1 Jan 2020 10:09:58 +0100
Subject: [R] Happy New Year
Message-ID: <CAC8ss311Uy5RLgLQQ9YZQRP8D9ywNDuDtQTS2V8382TMy9kbyg@mail.gmail.com>

Dear Friends,
Happy New Year.
Best regards
Ogbos

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Thu Jan  2 00:16:30 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Wed, 1 Jan 2020 23:16:30 +0000
Subject: [R] a simple question
Message-ID: <A86C6438FB909A409DDEF926277952B6113B7261@PPWEXCH2KX14.coh.org>

Hi R users,

in a Shiny test code, choices = list(1, 2, 3),  it generates three components in the choice list, my code works fine and generated tables and plots I want.

now I want to modify to  choices = list (1, 2, 3, ...., 5211).   list (seq(1, 5211,1) does not work, it generates one component (1, 2, 3, ....5211) in the choice list, not 5211-component list.

Can you help me?

Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Jan  2 00:29:34 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Jan 2020 12:29:34 +1300
Subject: [R] a simple question
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113B7261@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113B7261@PPWEXCH2KX14.coh.org>
Message-ID: <8684a34d-84a9-2626-6f9d-2179224807f6@auckland.ac.nz>


On 2/01/20 12:16 pm, Yuan Chun Ding wrote:

> Hi R users,
> 
> in a Shiny test code, choices = list(1, 2, 3),  it generates three
> components in the choice list, my code works fine and generated
> tables and plots I want.
> 
> now I want to modify to  choices = list (1, 2, 3, ...., 5211).   list
> (seq(1, 5211,1) does not work, it generates one component (1, 2, 3,
> ....5211) in the choice list, not 5211-component list.
> 
> Can you help me?

I don't use/have no idea about Shiny, so this may be a case of the blind 
leading the partially sighted, but perhaps you want

   choices = as.list(seq(1,5211,1))

cheers,

Rolf Turner


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ycd|ng @end|ng |rom coh@org  Thu Jan  2 00:55:17 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Wed, 1 Jan 2020 23:55:17 +0000
Subject: [R] a simple question
In-Reply-To: <8684a34d-84a9-2626-6f9d-2179224807f6@auckland.ac.nz>
References: <A86C6438FB909A409DDEF926277952B6113B7261@PPWEXCH2KX14.coh.org>,
 <8684a34d-84a9-2626-6f9d-2179224807f6@auckland.ac.nz>
Message-ID: <A86C6438FB909A409DDEF926277952B6113B7286@PPWEXCH2KX14.coh.org>

Hi Rolf,

Yes,

choices = as.list(seq(1,5211,1))

is what I want.

Thank you so much,

Ding
________________________________________
From: Rolf Turner [r.turner at auckland.ac.nz]
Sent: Wednesday, January 1, 2020 3:29 PM
To: Yuan Chun Ding; r-help at r-project.org
Subject: Re: [R] a simple question

[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]

----------------------------------------------------------------------

On 2/01/20 12:16 pm, Yuan Chun Ding wrote:

> Hi R users,
>
> in a Shiny test code, choices = list(1, 2, 3),  it generates three
> components in the choice list, my code works fine and generated
> tables and plots I want.
>
> now I want to modify to  choices = list (1, 2, 3, ...., 5211).   list
> (seq(1, 5211,1) does not work, it generates one component (1, 2, 3,
> ....5211) in the choice list, not 5211-component list.
>
> Can you help me?

I don't use/have no idea about Shiny, so this may be a case of the blind
leading the partially sighted, but perhaps you want

   choices = as.list(seq(1,5211,1))

cheers,

Rolf Turner


--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From er|cjberger @end|ng |rom gm@||@com  Thu Jan  2 12:12:50 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 2 Jan 2020 13:12:50 +0200
Subject: [R] outer join of xts's
Message-ID: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>

Hi,
I have a list L of about 2,600 xts's.
Each xts has a single numeric column. About 90% of the xts's have
approximately 500 rows, and the rest have fewer than 500 rows.
I create a single xts using the command

myXts <- Reduce( merge.xts, L )

By default, merge.xts() does an outer join (which is what I want).

The command takes about 80 seconds to complete.
I have plenty of RAM on my computer.

Are there faster ways to accomplish this task?

Thanks,
Eric

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Jan  2 12:49:26 2020
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Jan 2020 12:49:26 +0100
Subject: [R] outer join of xts's
In-Reply-To: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
Message-ID: <20200102124926.Horde.vJsV4ScUp09lAh2nasPrTA5@webmail.your-server.de>


Quoting Eric Berger <ericjberger at gmail.com>:

> Hi,
> I have a list L of about 2,600 xts's.
> Each xts has a single numeric column. About 90% of the xts's have
> approximately 500 rows, and the rest have fewer than 500 rows.
> I create a single xts using the command
>
> myXts <- Reduce( merge.xts, L )
>
> By default, merge.xts() does an outer join (which is what I want).
>
> The command takes about 80 seconds to complete.
> I have plenty of RAM on my computer.
>
> Are there faster ways to accomplish this task?
>
> Thanks,
> Eric
>

Since you already know the number of series and all possible timestamps,
you could preallocate a matrix (number of timestamps times number of series).
You could use the fastmatch package to match the timestamps against the rows.
This what 'pricetable' in the PMwR package does.  Calling

     library("PMwR")
     do.call(pricetable, L)

should give you matrix of the merged series, with an attribute 'timestamp',
from which you could create an xts object again.

I am not sure if it is the fastest way, but it's probably faster than calling
merge repeatedly.

kind regards
     Enrico  (the maintainer of PMwR)

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jan  2 14:22:25 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 2 Jan 2020 08:22:25 -0500
Subject: [R] outer join of xts's
In-Reply-To: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
Message-ID: <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>

You don't need Reduce as xts already supports mutliway merges.  This
perfroms one
multiway merge rather than  k-1 two way merges.

    do.call("merge", L)

On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi,
> I have a list L of about 2,600 xts's.
> Each xts has a single numeric column. About 90% of the xts's have
> approximately 500 rows, and the rest have fewer than 500 rows.
> I create a single xts using the command
>
> myXts <- Reduce( merge.xts, L )
>
> By default, merge.xts() does an outer join (which is what I want).
>
> The command takes about 80 seconds to complete.
> I have plenty of RAM on my computer.
>
> Are there faster ways to accomplish this task?
>
> Thanks,
> Eric
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From er|cjberger @end|ng |rom gm@||@com  Thu Jan  2 15:31:27 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 2 Jan 2020 16:31:27 +0200
Subject: [R] outer join of xts's
In-Reply-To: <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
Message-ID: <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>

Hi Gabor,
This is great, thanks. It brought the time down to about 4 seconds.
The command
do.call("merge.xts",L)
also works in this case.
Suppose that instead of the default "outer" join I wanted to use, say, a
"left" join.
Is that possible? I tried a few ways of adding the
join="left"
parameter to the do.call() command but I could not get the syntax to work
(assuming it's even possible).

Thanks,
Eric


On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
wrote:

> You don't need Reduce as xts already supports mutliway merges.  This
> perfroms one
> multiway merge rather than  k-1 two way merges.
>
>     do.call("merge", L)
>
> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> >
> > Hi,
> > I have a list L of about 2,600 xts's.
> > Each xts has a single numeric column. About 90% of the xts's have
> > approximately 500 rows, and the rest have fewer than 500 rows.
> > I create a single xts using the command
> >
> > myXts <- Reduce( merge.xts, L )
> >
> > By default, merge.xts() does an outer join (which is what I want).
> >
> > The command takes about 80 seconds to complete.
> > I have plenty of RAM on my computer.
> >
> > Are there faster ways to accomplish this task?
> >
> > Thanks,
> > Eric
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jan  2 16:38:11 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 2 Jan 2020 10:38:11 -0500
Subject: [R] outer join of xts's
In-Reply-To: <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
Message-ID: <CAP01uRkknHuBG_g75_Q02bJTFOXfJPwz8gfZJxWHi3jfd989Tg@mail.gmail.com>

It is not clear what multiway left join means but merge.zoo (though
not merge.xts) supports a generalized all= argument which is a logical
vector having the same length as L that can be TRUE or FALSE for each
object merged.  The objects corresponding to TRUE will have all their
times included in the result but the ones with FALSE will only be
included if they correspond to an already existing time. merge.zoo is
R based whereas merge.xts is C based so I would not expect it to be as
fast although it is more powerful.

If All is the logical vector having the same length as L then:

    Lzoo <- lapply(L, as.zoo)
    do.call("merge",  c(Lzoo, list(all = All))

On Thu, Jan 2, 2020 at 9:31 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi Gabor,
> This is great, thanks. It brought the time down to about 4 seconds.
> The command
> do.call("merge.xts",L)
> also works in this case.
> Suppose that instead of the default "outer" join I wanted to use, say, a "left" join.
> Is that possible? I tried a few ways of adding the
> join="left"
> parameter to the do.call() command but I could not get the syntax to work (assuming it's even possible).
>
> Thanks,
> Eric
>
>
> On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>
>> You don't need Reduce as xts already supports mutliway merges.  This
>> perfroms one
>> multiway merge rather than  k-1 two way merges.
>>
>>     do.call("merge", L)
>>
>> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
>> >
>> > Hi,
>> > I have a list L of about 2,600 xts's.
>> > Each xts has a single numeric column. About 90% of the xts's have
>> > approximately 500 rows, and the rest have fewer than 500 rows.
>> > I create a single xts using the command
>> >
>> > myXts <- Reduce( merge.xts, L )
>> >
>> > By default, merge.xts() does an outer join (which is what I want).
>> >
>> > The command takes about 80 seconds to complete.
>> > I have plenty of RAM on my computer.
>> >
>> > Are there faster ways to accomplish this task?
>> >
>> > Thanks,
>> > Eric
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jan  2 16:39:41 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 2 Jan 2020 10:39:41 -0500
Subject: [R] outer join of xts's
In-Reply-To: <CAP01uRkknHuBG_g75_Q02bJTFOXfJPwz8gfZJxWHi3jfd989Tg@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
 <CAP01uRkknHuBG_g75_Q02bJTFOXfJPwz8gfZJxWHi3jfd989Tg@mail.gmail.com>
Message-ID: <CAP01uR=VK=MDWsNS_ACV64n_+E9p_v-WEGYo2XpTGPQ7JQvXoQ@mail.gmail.com>

> It is not clear what multiway left join means but merge.zoo (though
> not merge.xts) supports a generalized all= argument which is a logical
> vector having the same length as L that can be TRUE or FALSE for each
> object merged.  The objects corresponding to TRUE will have all their
> times included in the result but the ones with FALSE will only be
> included if they correspond to an already existing time. merge.zoo is
> R based whereas merge.xts is C based so I would not expect it to be as
> fast although it is more powerful.
>
> If All is the logical vector having the same length as L then:
>
>     Lzoo <- lapply(L, as.zoo)
>     do.call("merge",  c(Lzoo, list(all = All))
>
> On Thu, Jan 2, 2020 at 9:31 AM Eric Berger <ericjberger at gmail.com> wrote:
> >
> > Hi Gabor,
> > This is great, thanks. It brought the time down to about 4 seconds.
> > The command
> > do.call("merge.xts",L)
> > also works in this case.
> > Suppose that instead of the default "outer" join I wanted to use, say, a "left" join.
> > Is that possible? I tried a few ways of adding the
> > join="left"
> > parameter to the do.call() command but I could not get the syntax to work (assuming it's even possible).
> >
> > Thanks,
> > Eric
> >
> >
> > On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >>
> >> You don't need Reduce as xts already supports mutliway merges.  This
> >> perfroms one
> >> multiway merge rather than  k-1 two way merges.
> >>
> >>     do.call("merge", L)
> >>
> >> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> >> >
> >> > Hi,
> >> > I have a list L of about 2,600 xts's.
> >> > Each xts has a single numeric column. About 90% of the xts's have
> >> > approximately 500 rows, and the rest have fewer than 500 rows.
> >> > I create a single xts using the command
> >> >
> >> > myXts <- Reduce( merge.xts, L )
> >> >
> >> > By default, merge.xts() does an outer join (which is what I want).
> >> >
> >> > The command takes about 80 seconds to complete.
> >> > I have plenty of RAM on my computer.
> >> >
> >> > Are there faster ways to accomplish this task?
> >> >
> >> > Thanks,
> >> > Eric
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Statistics & Software Consulting
> >> GKX Group, GKX Associates Inc.
> >> tel: 1-877-GKX-GROUP
> >> email: ggrothendieck at gmail.com
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan  2 19:29:20 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 2 Jan 2020 13:29:20 -0500
Subject: [R] outer join of xts's
In-Reply-To: <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
Message-ID: <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>

On 02/01/2020 9:31 a.m., Eric Berger wrote:
> Hi Gabor,
> This is great, thanks. It brought the time down to about 4 seconds.
> The command
> do.call("merge.xts",L)
> also works in this case.
> Suppose that instead of the default "outer" join I wanted to use, say, a
> "left" join.
> Is that possible? I tried a few ways of adding the
> join="left"
> parameter to the do.call() command but I could not get the syntax to work
> (assuming it's even possible).

This should work:

   do.call("merge", c(L, join = "left"))

The second argument to do.call is a list which becomes the arguments to 
the function being called.  Your time series should be unnamed entries 
in the list, while other arguments to merge() should be named.

Duncan Murdoch

> 
> Thanks,
> Eric
> 
> 
> On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
> 
>> You don't need Reduce as xts already supports mutliway merges.  This
>> perfroms one
>> multiway merge rather than  k-1 two way merges.
>>
>>      do.call("merge", L)
>>
>> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
>>>
>>> Hi,
>>> I have a list L of about 2,600 xts's.
>>> Each xts has a single numeric column. About 90% of the xts's have
>>> approximately 500 rows, and the rest have fewer than 500 rows.
>>> I create a single xts using the command
>>>
>>> myXts <- Reduce( merge.xts, L )
>>>
>>> By default, merge.xts() does an outer join (which is what I want).
>>>
>>> The command takes about 80 seconds to complete.
>>> I have plenty of RAM on my computer.
>>>
>>> Are there faster ways to accomplish this task?
>>>
>>> Thanks,
>>> Eric
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ycd|ng @end|ng |rom coh@org  Thu Jan  2 21:15:37 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 2 Jan 2020 20:15:37 +0000
Subject: [R] R package for genetic analysis of VNTR (variable number of
 tandem repeats) genotype data
Message-ID: <A86C6438FB909A409DDEF926277952B6113B75EB@PPWEXCH2KX14.coh.org>

Hi R users,
Does any one know a R package for genetic analysis of VNTR (variable number of tandem repeats) genotype data? For example, performing Hardy Weinberg equilibrium test, calculating heterozygosity and polymorphism information content etc.
I am sorry if this question is not relevant to this R platform.   I have searched for 3 hours.

Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jan  2 21:52:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 2 Jan 2020 12:52:26 -0800
Subject: [R] R package for genetic analysis of VNTR (variable number of
 tandem repeats) genotype data
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113B75EB@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113B75EB@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbSZpX-tW894xjrda6HsvJKmwv+4rnnPfu2ZuRz6+wC4EA@mail.gmail.com>

You may get a useful answer here, but you are much more likely to at the
Bioconductor website that specializes in this sort of thing.
https://bioconductor.org/help/

Cheers,
Bert



On Thu, Jan 2, 2020 at 12:16 PM Yuan Chun Ding <ycding at coh.org> wrote:

> Hi R users,
> Does any one know a R package for genetic analysis of VNTR (variable
> number of tandem repeats) genotype data? For example, performing Hardy
> Weinberg equilibrium test, calculating heterozygosity and polymorphism
> information content etc.
> I am sorry if this question is not relevant to this R platform.   I have
> searched for 3 hours.
>
> Thank you,
>
> Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to rec
>  eive further communications via e-mail, please reply to this message and
> inform the sender that you do not wish to receive further e-mail from the
> sender. (LCP301)
> ------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jan  2 22:38:49 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 2 Jan 2020 16:38:49 -0500
Subject: [R] outer join of xts's
In-Reply-To: <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
 <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>
Message-ID: <CAP01uRkOsr0Y5kob089omf2UDebGWECNixvNAE3pvvgDwt_bTw@mail.gmail.com>

join = "left" only applies with merge.xts if there are two objects.
If there are more it acts the same as join = TRUE..
See the Details section of ?merge.xts

On Thu, Jan 2, 2020 at 1:29 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 02/01/2020 9:31 a.m., Eric Berger wrote:
> > Hi Gabor,
> > This is great, thanks. It brought the time down to about 4 seconds.
> > The command
> > do.call("merge.xts",L)
> > also works in this case.
> > Suppose that instead of the default "outer" join I wanted to use, say, a
> > "left" join.
> > Is that possible? I tried a few ways of adding the
> > join="left"
> > parameter to the do.call() command but I could not get the syntax to work
> > (assuming it's even possible).
>
> This should work:
>
>    do.call("merge", c(L, join = "left"))
>
> The second argument to do.call is a list which becomes the arguments to
> the function being called.  Your time series should be unnamed entries
> in the list, while other arguments to merge() should be named.
>
> Duncan Murdoch
>
> >
> > Thanks,
> > Eric
> >
> >
> > On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
> > wrote:
> >
> >> You don't need Reduce as xts already supports mutliway merges.  This
> >> perfroms one
> >> multiway merge rather than  k-1 two way merges.
> >>
> >>      do.call("merge", L)
> >>
> >> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> >>>
> >>> Hi,
> >>> I have a list L of about 2,600 xts's.
> >>> Each xts has a single numeric column. About 90% of the xts's have
> >>> approximately 500 rows, and the rest have fewer than 500 rows.
> >>> I create a single xts using the command
> >>>
> >>> myXts <- Reduce( merge.xts, L )
> >>>
> >>> By default, merge.xts() does an outer join (which is what I want).
> >>>
> >>> The command takes about 80 seconds to complete.
> >>> I have plenty of RAM on my computer.
> >>>
> >>> Are there faster ways to accomplish this task?
> >>>
> >>> Thanks,
> >>> Eric
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Statistics & Software Consulting
> >> GKX Group, GKX Associates Inc.
> >> tel: 1-877-GKX-GROUP
> >> email: ggrothendieck at gmail.com
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Jan  2 23:54:47 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 3 Jan 2020 11:54:47 +1300
Subject: [R] [FORGED] Re:  rmgarch: source package installation problem
In-Reply-To: <e805b991-0ae2-e435-70e0-63d1f49da1e8@unisa.it>
References: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>
 <1a60a51b-18d9-df7e-cd99-3e0fa47184df@gmail.com>
 <5728d95b-782b-7518-57c0-ac845cea21be@unisa.it>
 <ceded949-2ecf-2db9-6737-4646a6f61244@auckland.ac.nz>
 <a35be053-c2a2-e8c3-981c-22283e82a2e9@unisa.it>
 <51f91d77-bca3-baa6-a8bb-3416d629731f@auckland.ac.nz>
 <e805b991-0ae2-e435-70e0-63d1f49da1e8@unisa.it>
Message-ID: <2495ba12-ccd4-c30b-b0a2-619f62841d12@auckland.ac.nz>


On 2/01/20 9:51 pm, Pietro Coretto wrote:

<SNIP>

> No problem Rolf. Thanks for you interest. But the problem is still 
> unsolved!

I experimented and found that I too could not install rmgarch.  However 
the string of error messages that I got was quite different from yours.

I did some scrounging around and after a bit of trial and error found 
that I needed to do:

sudo apt-get install libgmp3-dev
sudo apt-get install libmpfr-dev

Then the R command

    install.packages("rmgarch",lib="~/Rlib")

worked.  (Note that "~/Rlib" is where I keep my "contributed" packages.)

This is under Ubuntu 18.04.  I don't know if this will work for you 
since, as I said, the error messages that I initially got were different 
from those that you got.

*Don't* ask me about what to do under Mac OSX or (God save us!) under 
Windoze!!! :-)

cheers,

Rolf

P.S. I have taken the liberty of CC-ing this to the r-help list in case 
it is of interest to others or in case others may have useful 
contributions to add.

R.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pcoretto @end|ng |rom un|@@@|t  Fri Jan  3 07:56:54 2020
From: pcoretto @end|ng |rom un|@@@|t (Pietro Coretto)
Date: Fri, 3 Jan 2020 07:56:54 +0100
Subject: [R] [FORGED] Re:  rmgarch: source package installation problem
In-Reply-To: <2495ba12-ccd4-c30b-b0a2-619f62841d12@auckland.ac.nz>
References: <dceaea78-0b5d-79c6-1651-9c9315651916@unisa.it>
 <1a60a51b-18d9-df7e-cd99-3e0fa47184df@gmail.com>
 <5728d95b-782b-7518-57c0-ac845cea21be@unisa.it>
 <ceded949-2ecf-2db9-6737-4646a6f61244@auckland.ac.nz>
 <a35be053-c2a2-e8c3-981c-22283e82a2e9@unisa.it>
 <51f91d77-bca3-baa6-a8bb-3416d629731f@auckland.ac.nz>
 <e805b991-0ae2-e435-70e0-63d1f49da1e8@unisa.it>
 <2495ba12-ccd4-c30b-b0a2-619f62841d12@auckland.ac.nz>
Message-ID: <cd3a3a89-9ada-321d-7840-93c325ab8dc9@unisa.it>

Dear All

I could solve the problem: I removed my .Rprofile and I could install 
the package via the usual

install.packages("rmgarch")

My .Rprofile contains few settings, therefore, it was not too difficult 
to understand what was conflicting with the installation.  The issue in 
.Rprofile was the following

q <-  function (save="no", ...) {
    quit(save=save, ...)
}


Regards
Pietro Coretto





On 02/01/2020 23.54, Rolf Turner wrote:
> 
> On 2/01/20 9:51 pm, Pietro Coretto wrote:
> 
> <SNIP>
> 
>> No problem Rolf. Thanks for you interest. But the problem is still 
>> unsolved!
> 
> I experimented and found that I too could not install rmgarch.? However 
> the string of error messages that I got was quite different from yours.
> 
> I did some scrounging around and after a bit of trial and error found 
> that I needed to do:
> 
> sudo apt-get install libgmp3-dev
> sudo apt-get install libmpfr-dev
> 
> Then the R command
> 
>  ?? install.packages("rmgarch",lib="~/Rlib")
> 
> worked.? (Note that "~/Rlib" is where I keep my "contributed" packages.)
> 
> This is under Ubuntu 18.04.? I don't know if this will work for you 
> since, as I said, the error messages that I initially got were different 
> from those that you got.
> 
> *Don't* ask me about what to do under Mac OSX or (God save us!) under 
> Windoze!!! :-)
> 
> cheers,
> 
> Rolf
> 
> P.S. I have taken the liberty of CC-ing this to the r-help list in case 
> it is of interest to others or in case others may have useful 
> contributions to add.
> 
> R.
>


From er|cjberger @end|ng |rom gm@||@com  Fri Jan  3 08:13:20 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 3 Jan 2020 09:13:20 +0200
Subject: [R] outer join of xts's
In-Reply-To: <CAP01uRkOsr0Y5kob089omf2UDebGWECNixvNAE3pvvgDwt_bTw@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
 <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>
 <CAP01uRkOsr0Y5kob089omf2UDebGWECNixvNAE3pvvgDwt_bTw@mail.gmail.com>
Message-ID: <CAGgJW76vfZyD6LoWXtPS3574O3ExjxTEOPpSSHaB4Bvvt4Sjww@mail.gmail.com>

Hi Gabor and Duncan,
Thanks for your comments. As Gabor points out, Duncan's suggestion
does not work.
For those interested, here is some minimal reproducible example to illustrate

library(xts)
dtV <- as.Date("2019-01-01")+1:5
a <- xts(x=rnorm(5),order.by=dtV)
a1 <- a[1:3,]
a2 <- a[2:4,]
a3 <- a[3:5,]
colnames(a1) <- "a1"
colnames(a2) <- "a2"
colnames(a3) <- "a3"
L <- list(a1,a2,a3)
b.outer.1 <- Reduce(merge.xts,L)
b.outer.2 <- do.call(merge.xts,L)
identical(b.outer.1,b.outer.2)
# TRUE
dim(b.outer.1)
# [1] 5 3
b.left.1 <- merge.xts( merge.xts(a1,a2,join="left"), a3, join="left" )
f <- function(x,y) { merge.xts(x,y,join="left")}
b.left.2 <- Reduce(f,L)
identical(b.left.1,b.left.2)
# TRUE
dim(b.left.1)
# [1] 3 3
b.left.3 <- do.call("merge",c(L,join="left"))
# Warning message:
# In merge.xts(c(0.316095105296857, -1.69318390538755, -1.16430042971811 :
#  'join' only applicable to two object merges
dim(b.left.3)
# [1] 5 3
identical(b.outer.1,b.left.3)
# TRUE



On Thu, Jan 2, 2020 at 11:39 PM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> join = "left" only applies with merge.xts if there are two objects.
> If there are more it acts the same as join = TRUE..
> See the Details section of ?merge.xts
>
> On Thu, Jan 2, 2020 at 1:29 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On 02/01/2020 9:31 a.m., Eric Berger wrote:
> > > Hi Gabor,
> > > This is great, thanks. It brought the time down to about 4 seconds.
> > > The command
> > > do.call("merge.xts",L)
> > > also works in this case.
> > > Suppose that instead of the default "outer" join I wanted to use, say, a
> > > "left" join.
> > > Is that possible? I tried a few ways of adding the
> > > join="left"
> > > parameter to the do.call() command but I could not get the syntax to work
> > > (assuming it's even possible).
> >
> > This should work:
> >
> >    do.call("merge", c(L, join = "left"))
> >
> > The second argument to do.call is a list which becomes the arguments to
> > the function being called.  Your time series should be unnamed entries
> > in the list, while other arguments to merge() should be named.
> >
> > Duncan Murdoch
> >
> > >
> > > Thanks,
> > > Eric
> > >
> > >
> > > On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
> > > wrote:
> > >
> > >> You don't need Reduce as xts already supports mutliway merges.  This
> > >> perfroms one
> > >> multiway merge rather than  k-1 two way merges.
> > >>
> > >>      do.call("merge", L)
> > >>
> > >> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> > >>>
> > >>> Hi,
> > >>> I have a list L of about 2,600 xts's.
> > >>> Each xts has a single numeric column. About 90% of the xts's have
> > >>> approximately 500 rows, and the rest have fewer than 500 rows.
> > >>> I create a single xts using the command
> > >>>
> > >>> myXts <- Reduce( merge.xts, L )
> > >>>
> > >>> By default, merge.xts() does an outer join (which is what I want).
> > >>>
> > >>> The command takes about 80 seconds to complete.
> > >>> I have plenty of RAM on my computer.
> > >>>
> > >>> Are there faster ways to accomplish this task?
> > >>>
> > >>> Thanks,
> > >>> Eric
> > >>>
> > >>>          [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >>
> > >> --
> > >> Statistics & Software Consulting
> > >> GKX Group, GKX Associates Inc.
> > >> tel: 1-877-GKX-GROUP
> > >> email: ggrothendieck at gmail.com
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Fri Jan  3 14:44:54 2020
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Fri, 3 Jan 2020 07:44:54 -0600
Subject: [R] outer join of xts's
In-Reply-To: <CAGgJW76vfZyD6LoWXtPS3574O3ExjxTEOPpSSHaB4Bvvt4Sjww@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
 <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>
 <CAP01uRkOsr0Y5kob089omf2UDebGWECNixvNAE3pvvgDwt_bTw@mail.gmail.com>
 <CAGgJW76vfZyD6LoWXtPS3574O3ExjxTEOPpSSHaB4Bvvt4Sjww@mail.gmail.com>
Message-ID: <CAPPM_gR=hwLCSiP9KzsEE38-zC1ipuTAao5DWiJ18FVGXaqPWQ@mail.gmail.com>

On Fri, Jan 3, 2020 at 1:14 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi Gabor and Duncan,
> Thanks for your comments. As Gabor points out, Duncan's suggestion
> does not work.
> For those interested, here is some minimal reproducible example to illustrate
>
> library(xts)
> dtV <- as.Date("2019-01-01")+1:5
> a <- xts(x=rnorm(5),order.by=dtV)
> a1 <- a[1:3,]
> a2 <- a[2:4,]
> a3 <- a[3:5,]
> colnames(a1) <- "a1"
> colnames(a2) <- "a2"
> colnames(a3) <- "a3"
> L <- list(a1,a2,a3)
> b.outer.1 <- Reduce(merge.xts,L)
> b.outer.2 <- do.call(merge.xts,L)
> identical(b.outer.1,b.outer.2)
> # TRUE
> dim(b.outer.1)
> # [1] 5 3
> b.left.1 <- merge.xts( merge.xts(a1,a2,join="left"), a3, join="left" )
> f <- function(x,y) { merge.xts(x,y,join="left")}
> b.left.2 <- Reduce(f,L)
> identical(b.left.1,b.left.2)
> # TRUE
> dim(b.left.1)
> # [1] 3 3
> b.left.3 <- do.call("merge",c(L,join="left"))
> # Warning message:
> # In merge.xts(c(0.316095105296857, -1.69318390538755, -1.16430042971811 :
> #  'join' only applicable to two object merges
> dim(b.left.3)
> # [1] 5 3
> identical(b.outer.1,b.left.3)
> # TRUE
>
It's good practice to call generics and let dispatch determine what
method to call, instead of calling the method directly.  There's no
guarantee that merge.xts() will handle any objects you may
accidentally pass to it. So you should replace all your merge.xts()
calls with merge().

>
>
> On Thu, Jan 2, 2020 at 11:39 PM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > join = "left" only applies with merge.xts if there are two objects.
> > If there are more it acts the same as join = TRUE..
> > See the Details section of ?merge.xts
> >
> > On Thu, Jan 2, 2020 at 1:29 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> > >
> > > On 02/01/2020 9:31 a.m., Eric Berger wrote:
> > > > Hi Gabor,
> > > > This is great, thanks. It brought the time down to about 4 seconds.
> > > > The command
> > > > do.call("merge.xts",L)
> > > > also works in this case.
> > > > Suppose that instead of the default "outer" join I wanted to use, say, a
> > > > "left" join.
> > > > Is that possible? I tried a few ways of adding the
> > > > join="left"
> > > > parameter to the do.call() command but I could not get the syntax to work
> > > > (assuming it's even possible).
> > >
> > > This should work:
> > >
> > >    do.call("merge", c(L, join = "left"))
> > >
> > > The second argument to do.call is a list which becomes the arguments to
> > > the function being called.  Your time series should be unnamed entries
> > > in the list, while other arguments to merge() should be named.
> > >
> > > Duncan Murdoch
> > >
> > > >
> > > > Thanks,
> > > > Eric
> > > >
> > > >
> > > > On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
> > > > wrote:
> > > >
> > > >> You don't need Reduce as xts already supports mutliway merges.  This
> > > >> perfroms one
> > > >> multiway merge rather than  k-1 two way merges.
> > > >>
> > > >>      do.call("merge", L)
> > > >>
> > > >> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> > > >>>
> > > >>> Hi,
> > > >>> I have a list L of about 2,600 xts's.
> > > >>> Each xts has a single numeric column. About 90% of the xts's have
> > > >>> approximately 500 rows, and the rest have fewer than 500 rows.
> > > >>> I create a single xts using the command
> > > >>>
> > > >>> myXts <- Reduce( merge.xts, L )
> > > >>>
> > > >>> By default, merge.xts() does an outer join (which is what I want).
> > > >>>
> > > >>> The command takes about 80 seconds to complete.
> > > >>> I have plenty of RAM on my computer.
> > > >>>
> > > >>> Are there faster ways to accomplish this task?
> > > >>>
> > > >>> Thanks,
> > > >>> Eric
> > > >>>
> > > >>>          [[alternative HTML version deleted]]
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>> PLEASE do read the posting guide
> > > >> http://www.R-project.org/posting-guide.html
> > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > >>
> > > >>
> > > >>
> > > >> --
> > > >> Statistics & Software Consulting
> > > >> GKX Group, GKX Associates Inc.
> > > >> tel: 1-877-GKX-GROUP
> > > >> email: ggrothendieck at gmail.com
> > > >>
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From er|cjberger @end|ng |rom gm@||@com  Fri Jan  3 15:20:28 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 3 Jan 2020 16:20:28 +0200
Subject: [R] outer join of xts's
In-Reply-To: <CAPPM_gR=hwLCSiP9KzsEE38-zC1ipuTAao5DWiJ18FVGXaqPWQ@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
 <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>
 <CAP01uRkOsr0Y5kob089omf2UDebGWECNixvNAE3pvvgDwt_bTw@mail.gmail.com>
 <CAGgJW76vfZyD6LoWXtPS3574O3ExjxTEOPpSSHaB4Bvvt4Sjww@mail.gmail.com>
 <CAPPM_gR=hwLCSiP9KzsEE38-zC1ipuTAao5DWiJ18FVGXaqPWQ@mail.gmail.com>
Message-ID: <CAGgJW77zpEEcWyxuFXL3OgYACyfSPd2voD5QokyL6HJgkiFfTw@mail.gmail.com>

Hi Joshua,
Thanks for the comment but I guess I prefer a different behavior. If
merge.xts() cannot handle the objects I pass in, I want it to fail.
In fact, I typically adopt a naming convention where the variable name
indicates the type. In my normal coding style my example would look
like:
aXts <- xts(x=rnorm(5),order.by=dtV)
a1Xts <- aXts[1:3,]
a2Xts <- aXts[2:4,]
etc
Happy to hear your views on why other conventions might be better.

Regards,
Eric


On Fri, Jan 3, 2020 at 3:45 PM Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>
> On Fri, Jan 3, 2020 at 1:14 AM Eric Berger <ericjberger at gmail.com> wrote:
> >
> > Hi Gabor and Duncan,
> > Thanks for your comments. As Gabor points out, Duncan's suggestion
> > does not work.
> > For those interested, here is some minimal reproducible example to illustrate
> >
> > library(xts)
> > dtV <- as.Date("2019-01-01")+1:5
> > a <- xts(x=rnorm(5),order.by=dtV)
> > a1 <- a[1:3,]
> > a2 <- a[2:4,]
> > a3 <- a[3:5,]
> > colnames(a1) <- "a1"
> > colnames(a2) <- "a2"
> > colnames(a3) <- "a3"
> > L <- list(a1,a2,a3)
> > b.outer.1 <- Reduce(merge.xts,L)
> > b.outer.2 <- do.call(merge.xts,L)
> > identical(b.outer.1,b.outer.2)
> > # TRUE
> > dim(b.outer.1)
> > # [1] 5 3
> > b.left.1 <- merge.xts( merge.xts(a1,a2,join="left"), a3, join="left" )
> > f <- function(x,y) { merge.xts(x,y,join="left")}
> > b.left.2 <- Reduce(f,L)
> > identical(b.left.1,b.left.2)
> > # TRUE
> > dim(b.left.1)
> > # [1] 3 3
> > b.left.3 <- do.call("merge",c(L,join="left"))
> > # Warning message:
> > # In merge.xts(c(0.316095105296857, -1.69318390538755, -1.16430042971811 :
> > #  'join' only applicable to two object merges
> > dim(b.left.3)
> > # [1] 5 3
> > identical(b.outer.1,b.left.3)
> > # TRUE
> >
> It's good practice to call generics and let dispatch determine what
> method to call, instead of calling the method directly.  There's no
> guarantee that merge.xts() will handle any objects you may
> accidentally pass to it. So you should replace all your merge.xts()
> calls with merge().
>
> >
> >
> > On Thu, Jan 2, 2020 at 11:39 PM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > join = "left" only applies with merge.xts if there are two objects.
> > > If there are more it acts the same as join = TRUE..
> > > See the Details section of ?merge.xts
> > >
> > > On Thu, Jan 2, 2020 at 1:29 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> > > >
> > > > On 02/01/2020 9:31 a.m., Eric Berger wrote:
> > > > > Hi Gabor,
> > > > > This is great, thanks. It brought the time down to about 4 seconds.
> > > > > The command
> > > > > do.call("merge.xts",L)
> > > > > also works in this case.
> > > > > Suppose that instead of the default "outer" join I wanted to use, say, a
> > > > > "left" join.
> > > > > Is that possible? I tried a few ways of adding the
> > > > > join="left"
> > > > > parameter to the do.call() command but I could not get the syntax to work
> > > > > (assuming it's even possible).
> > > >
> > > > This should work:
> > > >
> > > >    do.call("merge", c(L, join = "left"))
> > > >
> > > > The second argument to do.call is a list which becomes the arguments to
> > > > the function being called.  Your time series should be unnamed entries
> > > > in the list, while other arguments to merge() should be named.
> > > >
> > > > Duncan Murdoch
> > > >
> > > > >
> > > > > Thanks,
> > > > > Eric
> > > > >
> > > > >
> > > > > On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
> > > > > wrote:
> > > > >
> > > > >> You don't need Reduce as xts already supports mutliway merges.  This
> > > > >> perfroms one
> > > > >> multiway merge rather than  k-1 two way merges.
> > > > >>
> > > > >>      do.call("merge", L)
> > > > >>
> > > > >> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> > > > >>>
> > > > >>> Hi,
> > > > >>> I have a list L of about 2,600 xts's.
> > > > >>> Each xts has a single numeric column. About 90% of the xts's have
> > > > >>> approximately 500 rows, and the rest have fewer than 500 rows.
> > > > >>> I create a single xts using the command
> > > > >>>
> > > > >>> myXts <- Reduce( merge.xts, L )
> > > > >>>
> > > > >>> By default, merge.xts() does an outer join (which is what I want).
> > > > >>>
> > > > >>> The command takes about 80 seconds to complete.
> > > > >>> I have plenty of RAM on my computer.
> > > > >>>
> > > > >>> Are there faster ways to accomplish this task?
> > > > >>>
> > > > >>> Thanks,
> > > > >>> Eric
> > > > >>>
> > > > >>>          [[alternative HTML version deleted]]
> > > > >>>
> > > > >>> ______________________________________________
> > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>> PLEASE do read the posting guide
> > > > >> http://www.R-project.org/posting-guide.html
> > > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > > >>
> > > > >>
> > > > >>
> > > > >> --
> > > > >> Statistics & Software Consulting
> > > > >> GKX Group, GKX Associates Inc.
> > > > >> tel: 1-877-GKX-GROUP
> > > > >> email: ggrothendieck at gmail.com
> > > > >>
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > >
> > > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


From SKHAN21 @end|ng |rom cr@nbrook@edu  Thu Jan  2 19:18:11 2020
From: SKHAN21 @end|ng |rom cr@nbrook@edu (Saaim Khan)
Date: Thu, 2 Jan 2020 18:18:11 +0000
Subject: [R] Extracting p value from bootstrap in R
Message-ID: <A77D5A7C-9458-4026-ABDA-B1961CA07C00@cranbrook.edu>

I've been trying to get the pvalue of my samples from a bootstrap rsquared test in R. I'm not very good with statistics so could someone please take a look at my below code and point me in the right direction with regards to how I can extract the p-values per sample (basically input a Descriptor_Score value and output a p-value based on the bootstrap model)? If my understanding is incorrect, please let me know. This code is mostly from API.

# Bootstrap 95% CI for R-Squared

library(boot)

# function to obtain R-Squared from the data

rsq <- function(formula, data, indices) {

d <- data[indices,] # allows boot to select sample

fit <- lm(formula, data=d)

return(summary(fit)$r.square)

}

###vdw beta bootstrap

`results[b]_vdw` = boot(data=rescored_beta, statistic=rsq,

R=10000, formula=Descriptor_Score~vdw)

# get 95% confidence interval

confb_vdw=boot.ci(`results[b]_vdw`)

cib_vdw = confb_vdw$bca[ , c(4, 5)]

Thanks!

	[[alternative HTML version deleted]]


From hwborcher@ @end|ng |rom gm@||@com  Fri Jan  3 18:26:15 2020
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Fri, 3 Jan 2020 18:26:15 +0100
Subject: [R] Which external functions are called in a package?
Message-ID: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>

How can I find out which functions of my package A are called within
another package B that depends on, imports, or suggests package A ?
And more specifically, which functions in B are calling functions in A ?

I tried to utilize the *pkgapi* package, but get error messages like

    > map_package("./R/x86_64-pc-linux-gnu-library/3.6/cranlogs")

    Error: <callr_status_error: callr subprocess failed:
        invalid first argument>
    -->
    <callr_remote_error in mget(targets, envir = env,
        mode = "function", inherits = TRUE,  ...:
     invalid first argument>
     in process 22909

(1) What do these error messages mean?

(2) Are there easier ways to get this information?

Thanks in advance. --HW


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jan  3 20:19:27 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 3 Jan 2020 14:19:27 -0500
Subject: [R] Which external functions are called in a package?
In-Reply-To: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
References: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
Message-ID: <a0239233-1efc-9a36-29d9-99e864d13541@gmail.com>

On 03/01/2020 12:26 p.m., Hans W Borchers wrote:
> How can I find out which functions of my package A are called within
> another package B that depends on, imports, or suggests package A ?
> And more specifically, which functions in B are calling functions in A ?
> 
> I tried to utilize the *pkgapi* package, but get error messages like
> 
>      > map_package("./R/x86_64-pc-linux-gnu-library/3.6/cranlogs")
> 
>      Error: <callr_status_error: callr subprocess failed:
>          invalid first argument>
>      -->
>      <callr_remote_error in mget(targets, envir = env,
>          mode = "function", inherits = TRUE,  ...:
>       invalid first argument>
>       in process 22909
> 
> (1) What do these error messages mean?
> 
> (2) Are there easier ways to get this information?

I'm not really familiar with pkgapi, but I believe the first argument is 
to the source directory for a package.  It looks as though you are 
pointing to the installed copy of it.

Duncan Murdoch


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan  3 20:52:09 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 3 Jan 2020 19:52:09 +0000
Subject: [R] Extracting p value from bootstrap in R
In-Reply-To: <A77D5A7C-9458-4026-ABDA-B1961CA07C00@cranbrook.edu>
References: <A77D5A7C-9458-4026-ABDA-B1961CA07C00@cranbrook.edu>
Message-ID: <45989a17-b6f5-5d85-d92f-864f0190cdc2@sapo.pt>

Hello,

Your code is correctly extracting the bootstrapped r-squared confidence 
intervals calculated using the adjusted bootstrap percentile (BCa) method.

If you want the p-values, do

summary(fit)$coefficients[, 4]

in the function.

Also, function boot calls a function statistic that expects data and 
indices as 1st and 2nd arguments. Argument formula should go after these 
ones. In your case that doesn't make any difference because you are 
passing *named* arguments but it's better to keep to the rules, you'll 
be avoiding potential/future problems. Rewrite the function as


rsq <- function(data, indices, formula) {
   d <- data[indices, ] # allows boot to select sample
   fit <- lm(formula, data = d)
   summary(fit)$r.square
}


Hope this helps,

Rui Barradas


?s 18:18 de 02/01/20, Saaim Khan escreveu:
> I've been trying to get the pvalue of my samples from a bootstrap rsquared test in R. I'm not very good with statistics so could someone please take a look at my below code and point me in the right direction with regards to how I can extract the p-values per sample (basically input a Descriptor_Score value and output a p-value based on the bootstrap model)? If my understanding is incorrect, please let me know. This code is mostly from API.
> 
> # Bootstrap 95% CI for R-Squared
> 
> library(boot)
> 
> # function to obtain R-Squared from the data
> 
> rsq <- function(formula, data, indices) {
> 
> d <- data[indices,] # allows boot to select sample
> 
> fit <- lm(formula, data=d)
> 
> return(summary(fit)$r.square)
> 
> }
> 
> ###vdw beta bootstrap
> 
> `results[b]_vdw` = boot(data=rescored_beta, statistic=rsq,
> 
> R=10000, formula=Descriptor_Score~vdw)
> 
> # get 95% confidence interval
> 
> confb_vdw=boot.ci(`results[b]_vdw`)
> 
> cib_vdw = confb_vdw$bca[ , c(4, 5)]
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Fri Jan  3 21:11:47 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Fri, 3 Jan 2020 15:11:47 -0500
Subject: [R] Extracting p value from bootstrap in R
In-Reply-To: <45989a17-b6f5-5d85-d92f-864f0190cdc2@sapo.pt>
References: <A77D5A7C-9458-4026-ABDA-B1961CA07C00@cranbrook.edu>
 <45989a17-b6f5-5d85-d92f-864f0190cdc2@sapo.pt>
Message-ID: <CAJc=yOEJsGJLUYSceLu+K4rqM=RSpyUmRC_GHzO3xg59_SVPhw@mail.gmail.com>

Also, note that the p-values will probably not exactly correspond to
conclusions drawn from the bootstrapped confidence limits. They are
two different approaches to the research question. Broadly speaking,
the bootstrapped limits avoid the assumption of a symmetric sampling
distribution that underlies the coefficient/standard error testing
strategy. Using the bootstrap gets you bootstrapped standard errors,
which have less stringent assumptions than normal-theory standard
errors, but the p-value will still reflect the symmetry assumption.
The BCa method allows asymmetric confidence intervals.


On Fri, Jan 3, 2020 at 2:52 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Your code is correctly extracting the bootstrapped r-squared confidence
> intervals calculated using the adjusted bootstrap percentile (BCa) method.
>
> If you want the p-values, do
>
> summary(fit)$coefficients[, 4]
>
> in the function.
>
> Also, function boot calls a function statistic that expects data and
> indices as 1st and 2nd arguments. Argument formula should go after these
> ones. In your case that doesn't make any difference because you are
> passing *named* arguments but it's better to keep to the rules, you'll
> be avoiding potential/future problems. Rewrite the function as
>
>
> rsq <- function(data, indices, formula) {
>    d <- data[indices, ] # allows boot to select sample
>    fit <- lm(formula, data = d)
>    summary(fit)$r.square
> }
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 18:18 de 02/01/20, Saaim Khan escreveu:
> > I've been trying to get the pvalue of my samples from a bootstrap rsquared test in R. I'm not very good with statistics so could someone please take a look at my below code and point me in the right direction with regards to how I can extract the p-values per sample (basically input a Descriptor_Score value and output a p-value based on the bootstrap model)? If my understanding is incorrect, please let me know. This code is mostly from API.
> >
> > # Bootstrap 95% CI for R-Squared
> >
> > library(boot)
> >
> > # function to obtain R-Squared from the data
> >
> > rsq <- function(formula, data, indices) {
> >
> > d <- data[indices,] # allows boot to select sample
> >
> > fit <- lm(formula, data=d)
> >
> > return(summary(fit)$r.square)
> >
> > }
> >
> > ###vdw beta bootstrap
> >
> > `results[b]_vdw` = boot(data=rescored_beta, statistic=rsq,
> >
> > R=10000, formula=Descriptor_Score~vdw)
> >
> > # get 95% confidence interval
> >
> > confb_vdw=boot.ci(`results[b]_vdw`)
> >
> > cib_vdw = confb_vdw$bca[ , c(4, 5)]
> >
> > Thanks!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: https://malonequantitative.com

He/Him/His


From hwborcher@ @end|ng |rom gm@||@com  Fri Jan  3 22:45:42 2020
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Fri, 3 Jan 2020 22:45:42 +0100
Subject: [R] Fwd:  Which external functions are called in a package?
In-Reply-To: <CAML4n3OA88HkmpJ12U_uNcBxQYhKEHtrqz4ejsJVhhGZHwMGiw@mail.gmail.com>
References: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
 <a0239233-1efc-9a36-29d9-99e864d13541@gmail.com>
 <CAML4n3OA88HkmpJ12U_uNcBxQYhKEHtrqz4ejsJVhhGZHwMGiw@mail.gmail.com>
Message-ID: <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>

You are absolutely right. I forgot that there is a difference between
the unpacked and the installed directory of a package. The
documentation of the *pkgapi* package in development is quite scarce
and does not mention the details. Thanks for the tip.

--HW

PS: Still I would like to learn about other approaches for listing
external calls of a package. This must be a general problem for
package developers whose packages are depended on by many other CRAN
packages.


On Fri, 3 Jan 2020 at 20:19, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> I'm not really familiar with pkgapi, but I believe the first argument is
> to the source directory for a package.  It looks as though you are
> pointing to the installed copy of it.
>
> Duncan Murdoch


From hwborcher@ @end|ng |rom gm@||@com  Fri Jan  3 22:52:51 2020
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Fri, 3 Jan 2020 22:52:51 +0100
Subject: [R] Fwd: Which external functions are called in a package?
In-Reply-To: <36451ACC-7A7F-4228-A117-B1CC70E9FA00@dcn.davis.ca.us>
References: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
 <a0239233-1efc-9a36-29d9-99e864d13541@gmail.com>
 <CAML4n3OA88HkmpJ12U_uNcBxQYhKEHtrqz4ejsJVhhGZHwMGiw@mail.gmail.com>
 <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>
 <36451ACC-7A7F-4228-A117-B1CC70E9FA00@dcn.davis.ca.us>
Message-ID: <CAML4n3PnG0TpUfp+JJVRbKsgcx5PD4iYpg-FRAtUprtSDLKMVg@mail.gmail.com>

Jeff, the problem is:
There I see the packages that depend on mine, but not which functions are used
Or maybe I misunderstood your comment.

On Fri, 3 Jan 2020 at 22:49, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> If you are so lucky as to have this problem, perhaps you could take a look at the reverse dependencies on your packages' CRAN web page.
>
> On January 3, 2020 1:45:42 PM PST, Hans W Borchers <hwborchers at gmail.com> wrote:
> >You are absolutely right. I forgot that there is a difference between
> >the unpacked and the installed directory of a package. The
> >documentation of the *pkgapi* package in development is quite scarce
> >and does not mention the details. Thanks for the tip.
> >
> >--HW
> >
> >PS: Still I would like to learn about other approaches for listing
> >external calls of a package. This must be a general problem for
> >package developers whose packages are depended on by many other CRAN
> >packages.
> >
> >
> >On Fri, 3 Jan 2020 at 20:19, Duncan Murdoch <murdoch.duncan at gmail.com>
> >wrote:
> >>
> >> I'm not really familiar with pkgapi, but I believe the first argument
> >is
> >> to the source directory for a package.  It looks as though you are
> >> pointing to the installed copy of it.
> >>
> >> Duncan Murdoch
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jan  3 22:49:49 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 03 Jan 2020 13:49:49 -0800
Subject: [R] Fwd:  Which external functions are called in a package?
In-Reply-To: <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>
References: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
 <a0239233-1efc-9a36-29d9-99e864d13541@gmail.com>
 <CAML4n3OA88HkmpJ12U_uNcBxQYhKEHtrqz4ejsJVhhGZHwMGiw@mail.gmail.com>
 <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>
Message-ID: <36451ACC-7A7F-4228-A117-B1CC70E9FA00@dcn.davis.ca.us>

If you are so lucky as to have this problem, perhaps you could take a look at the reverse dependencies on your packages' CRAN web page.

On January 3, 2020 1:45:42 PM PST, Hans W Borchers <hwborchers at gmail.com> wrote:
>You are absolutely right. I forgot that there is a difference between
>the unpacked and the installed directory of a package. The
>documentation of the *pkgapi* package in development is quite scarce
>and does not mention the details. Thanks for the tip.
>
>--HW
>
>PS: Still I would like to learn about other approaches for listing
>external calls of a package. This must be a general problem for
>package developers whose packages are depended on by many other CRAN
>packages.
>
>
>On Fri, 3 Jan 2020 at 20:19, Duncan Murdoch <murdoch.duncan at gmail.com>
>wrote:
>>
>> I'm not really familiar with pkgapi, but I believe the first argument
>is
>> to the source directory for a package.  It looks as though you are
>> pointing to the installed copy of it.
>>
>> Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jan  4 00:05:08 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 3 Jan 2020 18:05:08 -0500
Subject: [R] Fwd: Which external functions are called in a package?
In-Reply-To: <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>
References: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
 <a0239233-1efc-9a36-29d9-99e864d13541@gmail.com>
 <CAML4n3OA88HkmpJ12U_uNcBxQYhKEHtrqz4ejsJVhhGZHwMGiw@mail.gmail.com>
 <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>
Message-ID: <bc868486-02b6-42b8-3abd-35889885daa3@gmail.com>

On 03/01/2020 4:45 p.m., Hans W Borchers wrote:
> You are absolutely right. I forgot that there is a difference between
> the unpacked and the installed directory of a package. The
> documentation of the *pkgapi* package in development is quite scarce
> and does not mention the details. Thanks for the tip.
> 
> --HW
> 
> PS: Still I would like to learn about other approaches for listing
> external calls of a package. This must be a general problem for
> package developers whose packages are depended on by many other CRAN
> packages.
>

I've never worried too much about that for my packages.  What matters is 
whether the changes I make cause trouble for other packages.  Knowing 
the reverse dependencies lets me test all the other packages after 
making changes, and if new problems come up, it's usually pretty obvious 
which of my functions were being used.

(I use some code I wrote for myself to run the tests with the old and 
new version of my package, but I believe there is similar code out there 
nowadays to do the comparison.  I'd look in devtools if I was looking 
for that.)

Duncan Murdoch


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jan  4 01:49:46 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 03 Jan 2020 16:49:46 -0800
Subject: [R] Fwd: Which external functions are called in a package?
In-Reply-To: <CAML4n3PnG0TpUfp+JJVRbKsgcx5PD4iYpg-FRAtUprtSDLKMVg@mail.gmail.com>
References: <CAML4n3PtWKiVF=9H-0eWunue+BzTwPoOiF58HMqf2ZeV+SPVzg@mail.gmail.com>
 <a0239233-1efc-9a36-29d9-99e864d13541@gmail.com>
 <CAML4n3OA88HkmpJ12U_uNcBxQYhKEHtrqz4ejsJVhhGZHwMGiw@mail.gmail.com>
 <CAML4n3OgZWDTQHypD3tk4Z5+bMJE3bo2LBMm27HONhjZ5MAY4g@mail.gmail.com>
 <36451ACC-7A7F-4228-A117-B1CC70E9FA00@dcn.davis.ca.us>
 <CAML4n3PnG0TpUfp+JJVRbKsgcx5PD4iYpg-FRAtUprtSDLKMVg@mail.gmail.com>
Message-ID: <BB2579D3-10C3-4AD0-B60D-08C3E957E520@dcn.davis.ca.us>

No, sorry, I misunderstood your question.

a) Read the NAMESPACE file of package B? If they use importFrom that would be specific enough.

b) "Suggests" can refer to usage that does not even appear in the loaded package at all.

c) Try asking in the r-package-devel mailing list?

On January 3, 2020 1:52:51 PM PST, Hans W Borchers <hwborchers at gmail.com> wrote:
>Jeff, the problem is:
>There I see the packages that depend on mine, but not which functions
>are used
>Or maybe I misunderstood your comment.
>
>On Fri, 3 Jan 2020 at 22:49, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>>
>> If you are so lucky as to have this problem, perhaps you could take a
>look at the reverse dependencies on your packages' CRAN web page.
>>
>> On January 3, 2020 1:45:42 PM PST, Hans W Borchers
><hwborchers at gmail.com> wrote:
>> >You are absolutely right. I forgot that there is a difference
>between
>> >the unpacked and the installed directory of a package. The
>> >documentation of the *pkgapi* package in development is quite scarce
>> >and does not mention the details. Thanks for the tip.
>> >
>> >--HW
>> >
>> >PS: Still I would like to learn about other approaches for listing
>> >external calls of a package. This must be a general problem for
>> >package developers whose packages are depended on by many other CRAN
>> >packages.
>> >
>> >
>> >On Fri, 3 Jan 2020 at 20:19, Duncan Murdoch
><murdoch.duncan at gmail.com>
>> >wrote:
>> >>
>> >> I'm not really familiar with pkgapi, but I believe the first
>argument
>> >is
>> >> to the source directory for a package.  It looks as though you are
>> >> pointing to the installed copy of it.
>> >>
>> >> Duncan Murdoch
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Sat Jan  4 17:36:24 2020
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Sat, 4 Jan 2020 10:36:24 -0600
Subject: [R] outer join of xts's
In-Reply-To: <CAGgJW77zpEEcWyxuFXL3OgYACyfSPd2voD5QokyL6HJgkiFfTw@mail.gmail.com>
References: <CAGgJW77j9rwjuJEZmr3qhFQNp8tEZuKE1RmnE0pn-fYr-6TBXw@mail.gmail.com>
 <CAP01uRnzOWezcLyDfhAa2hUvoLWyax=D=zrjJYKH+B83KmVewQ@mail.gmail.com>
 <CAGgJW75oMpzaQtXrz8kqGFDEpG4DEe7EzsBJsOJsDxuGJW_X-w@mail.gmail.com>
 <af2fa199-4899-2139-fcac-48ecee8a8df4@gmail.com>
 <CAP01uRkOsr0Y5kob089omf2UDebGWECNixvNAE3pvvgDwt_bTw@mail.gmail.com>
 <CAGgJW76vfZyD6LoWXtPS3574O3ExjxTEOPpSSHaB4Bvvt4Sjww@mail.gmail.com>
 <CAPPM_gR=hwLCSiP9KzsEE38-zC1ipuTAao5DWiJ18FVGXaqPWQ@mail.gmail.com>
 <CAGgJW77zpEEcWyxuFXL3OgYACyfSPd2voD5QokyL6HJgkiFfTw@mail.gmail.com>
Message-ID: <CAPPM_gSr75eVsZi0Gm5KD59CfLfHRsjwVpXBRCJxA1e2wZPD4g@mail.gmail.com>

On Fri, Jan 3, 2020 at 8:20 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi Joshua,
> Thanks for the comment but I guess I prefer a different behavior. If
> merge.xts() cannot handle the objects I pass in, I want it to fail.
> In fact, I typically adopt a naming convention where the variable name
> indicates the type. In my normal coding style my example would look
> like:
> aXts <- xts(x=rnorm(5),order.by=dtV)
> a1Xts <- aXts[1:3,]
> a2Xts <- aXts[2:4,]
> etc
> Happy to hear your views on why other conventions might be better.
>
What you describe above works for merge.xts(), but my point is more
general. You don't have a guarantee that every method for every class
in every package will behave that way if you pass objects they don't
expect.

For example, you could call merge.xts() on objects that are some new
class that inherits from xts.  That would "work".  But the new class
may have its own merge() method that does something different than
merge.xts(). In that case, the result of merge.xts() could be
malformed in an unexpected way.

Also, methods don't need to be exported.  I would  prefer that
merge.xts(), lag.xts(), etc were not exported.  I have considered
un-exporting them.  The reason I don't is because it would break code
like yours.

I hope that helps you understand my rationale.

Best,
Josh


> Regards,
> Eric
>
>
> On Fri, Jan 3, 2020 at 3:45 PM Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> >
> > On Fri, Jan 3, 2020 at 1:14 AM Eric Berger <ericjberger at gmail.com> wrote:
> > >
> > > Hi Gabor and Duncan,
> > > Thanks for your comments. As Gabor points out, Duncan's suggestion
> > > does not work.
> > > For those interested, here is some minimal reproducible example to illustrate
> > >
> > > library(xts)
> > > dtV <- as.Date("2019-01-01")+1:5
> > > a <- xts(x=rnorm(5),order.by=dtV)
> > > a1 <- a[1:3,]
> > > a2 <- a[2:4,]
> > > a3 <- a[3:5,]
> > > colnames(a1) <- "a1"
> > > colnames(a2) <- "a2"
> > > colnames(a3) <- "a3"
> > > L <- list(a1,a2,a3)
> > > b.outer.1 <- Reduce(merge.xts,L)
> > > b.outer.2 <- do.call(merge.xts,L)
> > > identical(b.outer.1,b.outer.2)
> > > # TRUE
> > > dim(b.outer.1)
> > > # [1] 5 3
> > > b.left.1 <- merge.xts( merge.xts(a1,a2,join="left"), a3, join="left" )
> > > f <- function(x,y) { merge.xts(x,y,join="left")}
> > > b.left.2 <- Reduce(f,L)
> > > identical(b.left.1,b.left.2)
> > > # TRUE
> > > dim(b.left.1)
> > > # [1] 3 3
> > > b.left.3 <- do.call("merge",c(L,join="left"))
> > > # Warning message:
> > > # In merge.xts(c(0.316095105296857, -1.69318390538755, -1.16430042971811 :
> > > #  'join' only applicable to two object merges
> > > dim(b.left.3)
> > > # [1] 5 3
> > > identical(b.outer.1,b.left.3)
> > > # TRUE
> > >
> > It's good practice to call generics and let dispatch determine what
> > method to call, instead of calling the method directly.  There's no
> > guarantee that merge.xts() will handle any objects you may
> > accidentally pass to it. So you should replace all your merge.xts()
> > calls with merge().
> >
> > >
> > >
> > > On Thu, Jan 2, 2020 at 11:39 PM Gabor Grothendieck
> > > <ggrothendieck at gmail.com> wrote:
> > > >
> > > > join = "left" only applies with merge.xts if there are two objects.
> > > > If there are more it acts the same as join = TRUE..
> > > > See the Details section of ?merge.xts
> > > >
> > > > On Thu, Jan 2, 2020 at 1:29 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> > > > >
> > > > > On 02/01/2020 9:31 a.m., Eric Berger wrote:
> > > > > > Hi Gabor,
> > > > > > This is great, thanks. It brought the time down to about 4 seconds.
> > > > > > The command
> > > > > > do.call("merge.xts",L)
> > > > > > also works in this case.
> > > > > > Suppose that instead of the default "outer" join I wanted to use, say, a
> > > > > > "left" join.
> > > > > > Is that possible? I tried a few ways of adding the
> > > > > > join="left"
> > > > > > parameter to the do.call() command but I could not get the syntax to work
> > > > > > (assuming it's even possible).
> > > > >
> > > > > This should work:
> > > > >
> > > > >    do.call("merge", c(L, join = "left"))
> > > > >
> > > > > The second argument to do.call is a list which becomes the arguments to
> > > > > the function being called.  Your time series should be unnamed entries
> > > > > in the list, while other arguments to merge() should be named.
> > > > >
> > > > > Duncan Murdoch
> > > > >
> > > > > >
> > > > > > Thanks,
> > > > > > Eric
> > > > > >
> > > > > >
> > > > > > On Thu, Jan 2, 2020 at 3:23 PM Gabor Grothendieck <ggrothendieck at gmail.com>
> > > > > > wrote:
> > > > > >
> > > > > >> You don't need Reduce as xts already supports mutliway merges.  This
> > > > > >> perfroms one
> > > > > >> multiway merge rather than  k-1 two way merges.
> > > > > >>
> > > > > >>      do.call("merge", L)
> > > > > >>
> > > > > >> On Thu, Jan 2, 2020 at 6:13 AM Eric Berger <ericjberger at gmail.com> wrote:
> > > > > >>>
> > > > > >>> Hi,
> > > > > >>> I have a list L of about 2,600 xts's.
> > > > > >>> Each xts has a single numeric column. About 90% of the xts's have
> > > > > >>> approximately 500 rows, and the rest have fewer than 500 rows.
> > > > > >>> I create a single xts using the command
> > > > > >>>
> > > > > >>> myXts <- Reduce( merge.xts, L )
> > > > > >>>
> > > > > >>> By default, merge.xts() does an outer join (which is what I want).
> > > > > >>>
> > > > > >>> The command takes about 80 seconds to complete.
> > > > > >>> I have plenty of RAM on my computer.
> > > > > >>>
> > > > > >>> Are there faster ways to accomplish this task?
> > > > > >>>
> > > > > >>> Thanks,
> > > > > >>> Eric
> > > > > >>>
> > > > > >>>          [[alternative HTML version deleted]]
> > > > > >>>
> > > > > >>> ______________________________________________
> > > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > >>> PLEASE do read the posting guide
> > > > > >> http://www.R-project.org/posting-guide.html
> > > > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > > > >>
> > > > > >>
> > > > > >>
> > > > > >> --
> > > > > >> Statistics & Software Consulting
> > > > > >> GKX Group, GKX Associates Inc.
> > > > > >> tel: 1-877-GKX-GROUP
> > > > > >> email: ggrothendieck at gmail.com
> > > > > >>
> > > > > >
> > > > > >       [[alternative HTML version deleted]]
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > > >
> > > > >
> > > >
> > > >
> > > > --
> > > > Statistics & Software Consulting
> > > > GKX Group, GKX Associates Inc.
> > > > tel: 1-877-GKX-GROUP
> > > > email: ggrothendieck at gmail.com
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Joshua Ulrich  |  about.me/joshuaulrich
> > FOSS Trading  |  www.fosstrading.com



--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From Tou||k@Z@h@| @end|ng |rom u|b@@c@be  Mon Jan  6 14:16:08 2020
From: Tou||k@Z@h@| @end|ng |rom u|b@@c@be (tzahaf)
Date: Mon, 06 Jan 2020 14:16:08 +0100
Subject: [R] issue with Rcmdr
Message-ID: <3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>

Dear

I have a problem when trying to use Rcmdr.  This is the msg I receive:


package ?Rcmdr? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
         
C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
> local({pkg <- select.list(sort(.packages(all.available = 
> TRUE)),graphics=TRUE)
+ if(nchar(pkg)) library(pkg, character.only=TRUE)})
Loading required package: RcmdrMisc
Error: package or namespace load failed for ?RcmdrMisc? in rbind(info, 
getNamespaceInfo(env, "S3methods")):
  number of columns of matrices must match (see arg 2)
Error: package ?RcmdrMisc? could not be loaded
> 

I am running R 3.5.3 on WIN 10

thanks for your help

Best

Toufik


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jan  6 17:31:17 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 6 Jan 2020 08:31:17 -0800
Subject: [R] issue with Rcmdr
In-Reply-To: <3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
References: <3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
Message-ID: <2a1191ad-dcb5-5a19-26a6-dc90bbeb43cc@comcast.net>


On 1/6/20 5:16 AM, tzahaf wrote:
> Dear
>
> I have a problem when trying to use Rcmdr.? This is the msg I receive:
>
>
> package ?Rcmdr? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
>> local({pkg <- select.list(sort(.packages(all.available = 
>> TRUE)),graphics=TRUE)
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Loading required package: RcmdrMisc
> Error: package or namespace load failed for ?RcmdrMisc? in rbind(info, 
> getNamespaceInfo(env, "S3methods")):
> ?number of columns of matrices must match (see arg 2)
> Error: package ?RcmdrMisc? could not be loaded
>>

Do you have RcmdrMisc installed? You can answer that question by running 
this in your R console window:


grep("RcmdrMisc", installed.packages()[,1])


If you get, as I did since I do not use Rcmdr,? this result: integer(0), 
then it means you have not yet installed the package and you should now run:


install.packages("RcmdrMisc", dependencies=TRUE)


Best;

David.

>
> I am running R 3.5.3 on WIN 10
>
> thanks for your help
>
> Best
>
> Toufik
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jan  6 19:20:04 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 6 Jan 2020 18:20:04 +0000
Subject: [R] issue with Rcmdr
In-Reply-To: <6028_1578324705_006FV6G6022534_3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
References: <6028_1578324705_006FV6G6022534_3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC88CC650A8@FHSDB4H16-2.csu.mcmaster.ca>

Dear Toufik,

You've already had a suggestion to check whether RcmdrMisc is installed. It should have been installed automatically when you installed the Rcmdr package. 

If RcmdrMisc is installed, see whether you can load it directly via the command library(RcmdrMisc). If that too fails, you could try reinstalling RcmdrMisc via install.packages("RcmdrMisc"). 

Finally, you're using an old version of R. You might try installing the current version, which is 3.6.2. Then install the Rcmdr package by install.packages("Rcmdr").

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of tzahaf
> Sent: Monday, January 6, 2020 8:16 AM
> To: r-help at r-project.org
> Subject: [R] issue with Rcmdr
> 
> Dear
> 
> I have a problem when trying to use Rcmdr.  This is the msg I receive:
> 
> 
> package ?Rcmdr? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
> 
> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
> > local({pkg <- select.list(sort(.packages(all.available =
> > TRUE)),graphics=TRUE)
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Loading required package: RcmdrMisc
> Error: package or namespace load failed for ?RcmdrMisc? in rbind(info,
> getNamespaceInfo(env, "S3methods")):
>   number of columns of matrices must match (see arg 2)
> Error: package ?RcmdrMisc? could not be loaded
> >
> 
> I am running R 3.5.3 on WIN 10
> 
> thanks for your help
> 
> Best
> 
> Toufik
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan  6 20:37:10 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 06 Jan 2020 11:37:10 -0800
Subject: [R] issue with Rcmdr
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC88CC650A8@FHSDB4H16-2.csu.mcmaster.ca>
References: <6028_1578324705_006FV6G6022534_3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
 <ACD1644AA6C67E4FBD0C350625508EC88CC650A8@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <719726AD-2856-473A-91BE-FB5FD72F77D3@dcn.davis.ca.us>

That version of R happens to be "current" if using MRAN... which has some benefits (MKL comes pre-configured) and some... ah... "philosophical" ideas about stability (uses checkpoint package out of the box... which freezes packages at 2019-04-15 UTC unless actions are taken to use a different snapshot [1]). The OP may be "stuck in time" at Rcmdr 2.5-2 if they have not invoked checkpoint or adjusted the "repos" option... and if the latter then they may be encountering package incompatibilities with R 3.5.3 that should have been caught with a minimum R-version spec in the Rcmdr package.

[1] https://mran.microsoft.com/documents/rro/reproducibility

On January 6, 2020 10:20:04 AM PST, "Fox, John" <jfox at mcmaster.ca> wrote:
>Dear Toufik,
>
>You've already had a suggestion to check whether RcmdrMisc is
>installed. It should have been installed automatically when you
>installed the Rcmdr package. 
>
>If RcmdrMisc is installed, see whether you can load it directly via the
>command library(RcmdrMisc). If that too fails, you could try
>reinstalling RcmdrMisc via install.packages("RcmdrMisc"). 
>
>Finally, you're using an old version of R. You might try installing the
>current version, which is 3.6.2. Then install the Rcmdr package by
>install.packages("Rcmdr").
>
>I hope this helps,
> John
>
>-----------------------------------------------------------------
>John Fox
>Professor Emeritus
>McMaster University
>Hamilton, Ontario, Canada
>Web: https://socialsciences.mcmaster.ca/jfox/
>
>
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of tzahaf
>> Sent: Monday, January 6, 2020 8:16 AM
>> To: r-help at r-project.org
>> Subject: [R] issue with Rcmdr
>> 
>> Dear
>> 
>> I have a problem when trying to use Rcmdr.  This is the msg I
>receive:
>> 
>> 
>> package ?Rcmdr? successfully unpacked and MD5 sums checked
>> 
>> The downloaded binary packages are in
>> 
>> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
>> > local({pkg <- select.list(sort(.packages(all.available =
>> > TRUE)),graphics=TRUE)
>> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>> Loading required package: RcmdrMisc
>> Error: package or namespace load failed for ?RcmdrMisc? in
>rbind(info,
>> getNamespaceInfo(env, "S3methods")):
>>   number of columns of matrices must match (see arg 2)
>> Error: package ?RcmdrMisc? could not be loaded
>> >
>> 
>> I am running R 3.5.3 on WIN 10
>> 
>> thanks for your help
>> 
>> Best
>> 
>> Toufik
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jan  6 23:59:10 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 6 Jan 2020 22:59:10 +0000
Subject: [R] issue with Rcmdr
In-Reply-To: <6309CC14-39FF-47E4-96F9-CDDE30BC14C9@ulb.ac.be>
References: <6028_1578324705_006FV6G6022534_3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
 <ACD1644AA6C67E4FBD0C350625508EC88CC650A8@FHSDB4H16-2.csu.mcmaster.ca>
 <719726AD-2856-473A-91BE-FB5FD72F77D3@dcn.davis.ca.us>
 <6309CC14-39FF-47E4-96F9-CDDE30BC14C9@ulb.ac.be>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC88CC6568F@FHSDB4H16-2.csu.mcmaster.ca>

Dear Toufik,

> -----Original Message-----
> From: Toufik Zahaf <tzahaf at ulb.ac.be>
> Sent: Monday, January 6, 2020 4:07 PM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help at r-project.org; Fox, John <jfox at mcmaster.ca>; tzahaf
> <Toufik.Zahaf at ulb.ac.be>
> Subject: Re: [R] issue with Rcmdr
> 
> Dears
> 
> Thanks a lot , I understand that may be Rcmdr is not ?adapted? to run with R
> 3.5.3 so I will try to update R version to 3.6.2 or use the oldest version of R I
> used in the past.

The Rcmdr worked perfectly fine with R 3.5.3 about a year ago but it's possible that you've installed incompatible versions of some packages. As a general matter, keeping R up-to-date isn't a bad idea.

Best,
 John

> 
> I will let you know the outcome
> 
> Best regards
> Toufik
> 
> > Le 6 janv. 2020 ? 20:37, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit :
> >
> > That version of R happens to be "current" if using MRAN... which has some
> benefits (MKL comes pre-configured) and some... ah... "philosophical" ideas
> about stability (uses checkpoint package out of the box... which freezes
> packages at 2019-04-15 UTC unless actions are taken to use a different
> snapshot [1]). The OP may be "stuck in time" at Rcmdr 2.5-2 if they have not
> invoked checkpoint or adjusted the "repos" option... and if the latter then they
> may be encountering package incompatibilities with R 3.5.3 that should have
> been caught with a minimum R-version spec in the Rcmdr package.
> >
> > [1] https://mran.microsoft.com/documents/rro/reproducibility
> >
> >> On January 6, 2020 10:20:04 AM PST, "Fox, John" <jfox at mcmaster.ca>
> wrote:
> >> Dear Toufik,
> >>
> >> You've already had a suggestion to check whether RcmdrMisc is
> >> installed. It should have been installed automatically when you
> >> installed the Rcmdr package.
> >>
> >> If RcmdrMisc is installed, see whether you can load it directly via
> >> the command library(RcmdrMisc). If that too fails, you could try
> >> reinstalling RcmdrMisc via install.packages("RcmdrMisc").
> >>
> >> Finally, you're using an old version of R. You might try installing
> >> the current version, which is 3.6.2. Then install the Rcmdr package
> >> by install.packages("Rcmdr").
> >>
> >> I hope this helps,
> >> John
> >>
> >> -----------------------------------------------------------------
> >> John Fox
> >> Professor Emeritus
> >> McMaster University
> >> Hamilton, Ontario, Canada
> >> Web: https://socialsciences.mcmaster.ca/jfox/
> >>
> >>
> >>
> >>> -----Original Message-----
> >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of tzahaf
> >>> Sent: Monday, January 6, 2020 8:16 AM
> >>> To: r-help at r-project.org
> >>> Subject: [R] issue with Rcmdr
> >>>
> >>> Dear
> >>>
> >>> I have a problem when trying to use Rcmdr.  This is the msg I
> >> receive:
> >>>
> >>>
> >>> package ?Rcmdr? successfully unpacked and MD5 sums checked
> >>>
> >>> The downloaded binary packages are in
> >>>
> >>>
> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
> >>>> local({pkg <- select.list(sort(.packages(all.available =
> >>>> TRUE)),graphics=TRUE)
> >>> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> >>> Loading required package: RcmdrMisc
> >>> Error: package or namespace load failed for ?RcmdrMisc? in
> >> rbind(info,
> >>> getNamespaceInfo(env, "S3methods")):
> >>>  number of columns of matrices must match (see arg 2)
> >>> Error: package ?RcmdrMisc? could not be loaded
> >>>>
> >>>
> >>> I am running R 3.5.3 on WIN 10
> >>>
> >>> thanks for your help
> >>>
> >>> Best
> >>>
> >>> Toufik
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html and provide commented, minimal, self-contained,
> >>> reproducible code.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.


From tz@h@| @end|ng |rom u|b@@c@be  Mon Jan  6 22:07:03 2020
From: tz@h@| @end|ng |rom u|b@@c@be (Toufik Zahaf)
Date: Mon, 6 Jan 2020 22:07:03 +0100
Subject: [R] issue with Rcmdr
In-Reply-To: <719726AD-2856-473A-91BE-FB5FD72F77D3@dcn.davis.ca.us>
References: <6028_1578324705_006FV6G6022534_3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
 <ACD1644AA6C67E4FBD0C350625508EC88CC650A8@FHSDB4H16-2.csu.mcmaster.ca>
 <719726AD-2856-473A-91BE-FB5FD72F77D3@dcn.davis.ca.us>
Message-ID: <6309CC14-39FF-47E4-96F9-CDDE30BC14C9@ulb.ac.be>

Dears 

Thanks a lot , I understand that may be Rcmdr is not ?adapted? to run with R 3.5.3 so I will try to update R version to 3.6.2 or use the oldest version of R I used in the past.

I will let you know the outcome

Best regards 
Toufik

> Le 6 janv. 2020 ? 20:37, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit :
> 
> That version of R happens to be "current" if using MRAN... which has some benefits (MKL comes pre-configured) and some... ah... "philosophical" ideas about stability (uses checkpoint package out of the box... which freezes packages at 2019-04-15 UTC unless actions are taken to use a different snapshot [1]). The OP may be "stuck in time" at Rcmdr 2.5-2 if they have not invoked checkpoint or adjusted the "repos" option... and if the latter then they may be encountering package incompatibilities with R 3.5.3 that should have been caught with a minimum R-version spec in the Rcmdr package.
> 
> [1] https://mran.microsoft.com/documents/rro/reproducibility
> 
>> On January 6, 2020 10:20:04 AM PST, "Fox, John" <jfox at mcmaster.ca> wrote:
>> Dear Toufik,
>> 
>> You've already had a suggestion to check whether RcmdrMisc is
>> installed. It should have been installed automatically when you
>> installed the Rcmdr package. 
>> 
>> If RcmdrMisc is installed, see whether you can load it directly via the
>> command library(RcmdrMisc). If that too fails, you could try
>> reinstalling RcmdrMisc via install.packages("RcmdrMisc"). 
>> 
>> Finally, you're using an old version of R. You might try installing the
>> current version, which is 3.6.2. Then install the Rcmdr package by
>> install.packages("Rcmdr").
>> 
>> I hope this helps,
>> John
>> 
>> -----------------------------------------------------------------
>> John Fox
>> Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: https://socialsciences.mcmaster.ca/jfox/
>> 
>> 
>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of tzahaf
>>> Sent: Monday, January 6, 2020 8:16 AM
>>> To: r-help at r-project.org
>>> Subject: [R] issue with Rcmdr
>>> 
>>> Dear
>>> 
>>> I have a problem when trying to use Rcmdr.  This is the msg I
>> receive:
>>> 
>>> 
>>> package ?Rcmdr? successfully unpacked and MD5 sums checked
>>> 
>>> The downloaded binary packages are in
>>> 
>>> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
>>>> local({pkg <- select.list(sort(.packages(all.available =
>>>> TRUE)),graphics=TRUE)
>>> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>>> Loading required package: RcmdrMisc
>>> Error: package or namespace load failed for ?RcmdrMisc? in
>> rbind(info,
>>> getNamespaceInfo(env, "S3methods")):
>>>  number of columns of matrices must match (see arg 2)
>>> Error: package ?RcmdrMisc? could not be loaded
>>>> 
>>> 
>>> I am running R 3.5.3 on WIN 10
>>> 
>>> thanks for your help
>>> 
>>> Best
>>> 
>>> Toufik
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


From @@@t@rke @end|ng |rom hzdr@de  Tue Jan  7 08:14:12 2020
From: @@@t@rke @end|ng |rom hzdr@de (Sebastian Starke)
Date: Tue, 7 Jan 2020 08:14:12 +0100
Subject: [R] Computation of r.squared for weighted least squares linear
 models
Message-ID: <99b2f80f-b292-9ba9-3f89-3b30bcb14f90@hzdr.de>

Hi,

recently I posted a question about how R computes the value for the 
"r.squared" statistic internally for weighted least squares linear 
models on crossvalidated.com (see: 
https://stats.stackexchange.com/questions/439590/how-does-r-compute-r-squared-for-weighted-least-squares) 
including a minimal code example but unfortunately did not get an answer.

I would greatly appreciate if any of you who know the answer could reply 
either here or directly on my post on crossvalidated.

Thanks a lot in advance!

-- 
Sebastian Starke

Computational Science Group (FWCC)
Department of Information Services and Computing (FWC)
Building 312, Room 9
Phone: +49 - 351 - 260 3693

Helmholtz-Zentrum Dresden-Rossendorf e.V.
http://www.hzdr.de

Vorstand: Prof. Dr. Dr. h. c. Roland Sauerbrey, Dr. Ulrich Breuer
Vereinsregister: VR 1693 beim Amtsgericht Dresden


From Tou||k@Z@h@| @end|ng |rom u|b@@c@be  Tue Jan  7 09:28:16 2020
From: Tou||k@Z@h@| @end|ng |rom u|b@@c@be (tzahaf)
Date: Tue, 07 Jan 2020 09:28:16 +0100
Subject: [R] issue with Rcmdr
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC88CC6568F@FHSDB4H16-2.csu.mcmaster.ca>
References: <6028_1578324705_006FV6G6022534_3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
 <ACD1644AA6C67E4FBD0C350625508EC88CC650A8@FHSDB4H16-2.csu.mcmaster.ca>
 <719726AD-2856-473A-91BE-FB5FD72F77D3@dcn.davis.ca.us>
 <6309CC14-39FF-47E4-96F9-CDDE30BC14C9@ulb.ac.be>
 <ACD1644AA6C67E4FBD0C350625508EC88CC6568F@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <ca631242dbea97dc49c931df5099dc11@imapproxy.vub.ac.be>

Dear John, Jeff

I have updated R version (3.6.2) as suggested and now Rcmdr works :-)

Thanks again for your time et great help

Best regards

Toufik


On 06.01.2020 23:59, Fox, John wrote:
> Dear Toufik,
> 
>> -----Original Message-----
>> From: Toufik Zahaf <tzahaf at ulb.ac.be>
>> Sent: Monday, January 6, 2020 4:07 PM
>> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> Cc: r-help at r-project.org; Fox, John <jfox at mcmaster.ca>; tzahaf
>> <Toufik.Zahaf at ulb.ac.be>
>> Subject: Re: [R] issue with Rcmdr
>> 
>> Dears
>> 
>> Thanks a lot , I understand that may be Rcmdr is not ?adapted? to run 
>> with R
>> 3.5.3 so I will try to update R version to 3.6.2 or use the oldest 
>> version of R I
>> used in the past.
> 
> The Rcmdr worked perfectly fine with R 3.5.3 about a year ago but it's
> possible that you've installed incompatible versions of some packages.
> As a general matter, keeping R up-to-date isn't a bad idea.
> 
> Best,
>  John
> 
>> 
>> I will let you know the outcome
>> 
>> Best regards
>> Toufik
>> 
>> > Le 6 janv. 2020 ? 20:37, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit :
>> >
>> > That version of R happens to be "current" if using MRAN... which has some
>> benefits (MKL comes pre-configured) and some... ah... "philosophical" 
>> ideas
>> about stability (uses checkpoint package out of the box... which 
>> freezes
>> packages at 2019-04-15 UTC unless actions are taken to use a different
>> snapshot [1]). The OP may be "stuck in time" at Rcmdr 2.5-2 if they 
>> have not
>> invoked checkpoint or adjusted the "repos" option... and if the latter 
>> then they
>> may be encountering package incompatibilities with R 3.5.3 that should 
>> have
>> been caught with a minimum R-version spec in the Rcmdr package.
>> >
>> > [1] https://mran.microsoft.com/documents/rro/reproducibility
>> >
>> >> On January 6, 2020 10:20:04 AM PST, "Fox, John" <jfox at mcmaster.ca>
>> wrote:
>> >> Dear Toufik,
>> >>
>> >> You've already had a suggestion to check whether RcmdrMisc is
>> >> installed. It should have been installed automatically when you
>> >> installed the Rcmdr package.
>> >>
>> >> If RcmdrMisc is installed, see whether you can load it directly via
>> >> the command library(RcmdrMisc). If that too fails, you could try
>> >> reinstalling RcmdrMisc via install.packages("RcmdrMisc").
>> >>
>> >> Finally, you're using an old version of R. You might try installing
>> >> the current version, which is 3.6.2. Then install the Rcmdr package
>> >> by install.packages("Rcmdr").
>> >>
>> >> I hope this helps,
>> >> John
>> >>
>> >> -----------------------------------------------------------------
>> >> John Fox
>> >> Professor Emeritus
>> >> McMaster University
>> >> Hamilton, Ontario, Canada
>> >> Web: https://socialsciences.mcmaster.ca/jfox/
>> >>
>> >>
>> >>
>> >>> -----Original Message-----
>> >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of tzahaf
>> >>> Sent: Monday, January 6, 2020 8:16 AM
>> >>> To: r-help at r-project.org
>> >>> Subject: [R] issue with Rcmdr
>> >>>
>> >>> Dear
>> >>>
>> >>> I have a problem when trying to use Rcmdr.  This is the msg I
>> >> receive:
>> >>>
>> >>>
>> >>> package ?Rcmdr? successfully unpacked and MD5 sums checked
>> >>>
>> >>> The downloaded binary packages are in
>> >>>
>> >>>
>> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
>> >>>> local({pkg <- select.list(sort(.packages(all.available =
>> >>>> TRUE)),graphics=TRUE)
>> >>> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>> >>> Loading required package: RcmdrMisc
>> >>> Error: package or namespace load failed for ?RcmdrMisc? in
>> >> rbind(info,
>> >>> getNamespaceInfo(env, "S3methods")):
>> >>>  number of columns of matrices must match (see arg 2)
>> >>> Error: package ?RcmdrMisc? could not be loaded
>> >>>>
>> >>>
>> >>> I am running R 3.5.3 on WIN 10
>> >>>
>> >>> thanks for your help
>> >>>
>> >>> Best
>> >>>
>> >>> Toufik
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> >>> guide.html and provide commented, minimal, self-contained,
>> >>> reproducible code.
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Sent from my phone. Please excuse my brevity.


From Tou||k@Z@h@| @end|ng |rom u|b@@c@be  Tue Jan  7 09:31:00 2020
From: Tou||k@Z@h@| @end|ng |rom u|b@@c@be (tzahaf)
Date: Tue, 07 Jan 2020 09:31:00 +0100
Subject: [R] issue with Rcmdr
In-Reply-To: <2a1191ad-dcb5-5a19-26a6-dc90bbeb43cc@comcast.net>
References: <3e037ee3aa7c0eb8ab710df72c004f15@imapproxy.vub.ac.be>
 <2a1191ad-dcb5-5a19-26a6-dc90bbeb43cc@comcast.net>
Message-ID: <80090ae31e9606911fb03ff73b72afee@imapproxy.vub.ac.be>

Dear David

I have updated R version (3.6.2) as suggested by John and now Rcmdr 
works :-)

Thanks again for your time and great help

Best regards

Toufik
On 06.01.2020 17:31, David Winsemius wrote:
> On 1/6/20 5:16 AM, tzahaf wrote:
>> Dear
>> 
>> I have a problem when trying to use Rcmdr.? This is the msg I receive:
>> 
>> 
>> package ?Rcmdr? successfully unpacked and MD5 sums checked
>> 
>> The downloaded binary packages are in
>> C:\Users\toufiz00\AppData\Local\Temp\RtmpgXuxDP\downloaded_packages
>>> local({pkg <- select.list(sort(.packages(all.available = 
>>> TRUE)),graphics=TRUE)
>> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
>> Loading required package: RcmdrMisc
>> Error: package or namespace load failed for ?RcmdrMisc? in rbind(info, 
>> getNamespaceInfo(env, "S3methods")):
>> ?number of columns of matrices must match (see arg 2)
>> Error: package ?RcmdrMisc? could not be loaded
>>> 
> 
> Do you have RcmdrMisc installed? You can answer that question by
> running this in your R console window:
> 
> 
> grep("RcmdrMisc", installed.packages()[,1])
> 
> 
> If you get, as I did since I do not use Rcmdr,? this result:
> integer(0), then it means you have not yet installed the package and
> you should now run:
> 
> 
> install.packages("RcmdrMisc", dependencies=TRUE)
> 
> 
> Best;
> 
> David.
> 
>> 
>> I am running R 3.5.3 on WIN 10
>> 
>> thanks for your help
>> 
>> Best
>> 
>> Toufik
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r@dmuzom @end|ng |rom out|ook@com  Tue Jan  7 15:54:28 2020
From: r@dmuzom @end|ng |rom out|ook@com (Anindya Mozumdar)
Date: Tue, 7 Jan 2020 14:54:28 +0000
Subject: [R] Computation of r.squared for weighted least squares linear
 models
In-Reply-To: <99b2f80f-b292-9ba9-3f89-3b30bcb14f90@hzdr.de>
References: <99b2f80f-b292-9ba9-3f89-3b30bcb14f90@hzdr.de>
Message-ID: <PN1PR0101MB19340A2B80348385B67AF9EDCB3F0@PN1PR0101MB1934.INDPRD01.PROD.OUTLOOK.COM>

Dear Sebastian,

I was able to replicate the R^2 value of 0.993019 using the function provided as the second answer (by Julien Massardier) to the following question - https://stats.stackexchange.com/questions/83826/is-a-weighted-r2-in-robust-linear-model-meaningful-for-goodness-of-fit-analys

Thank you.
Regards,
Anindya
?


Hi,



recently I posted a question about how R computes the value for the 

"r.squared" statistic internally for weighted least squares linear 

models on crossvalidated.com (see: 

https://stats.stackexchange.com/questions/439590/how-does-r-compute-r-squared-for-weighted-least-squares)


including a minimal code example but unfortunately did not get an answer.



I would greatly appreciate if any of you who know the answer could reply 

either here or directly on my post on crossvalidated.



Thanks a lot in advance!



-- 

Sebastian Starke



Computational Science Group (FWCC)

Department of Information Services and Computing (FWC)

Building 312, Room 9

Phone: +49 - 351 - 260 3693



Helmholtz-Zentrum Dresden-Rossendorf e.V.

http://www.hzdr.de



Vorstand: Prof. Dr. Dr. h. c. Roland Sauerbrey, Dr. Ulrich Breuer

Vereinsregister: VR 1693 beim Amtsgericht Dresden



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.



From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jan  7 23:18:10 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 7 Jan 2020 16:18:10 -0600
Subject: [R] adjusted p value, fdr
Message-ID: <CAF9-5jO4v-ScVB-ATd3hLRP52QHp7sszocbXyWrT2BJR+-6Jbg@mail.gmail.com>

Hello,

I have a data set which has 15568 entries

I am trying to calculate adjusted p values using p value via:

head(x1g)

                                                   t      P.Value
      adj.P.Val          B       fdr
3TXADqtSkhV1IXRHlg  4.468671 3.072189e-05 0.4782784  1.5253151 0.4782784
34lG83aZ6.WLFnge6s  4.217037 7.518696e-05 0.5852553  0.8660534 0.5852553
oS67lguv5HpU4i6Pvg -3.939182 1.959413e-04 0.9994637  0.1600655 0.9994637
Qpc2sX7gp.W5E2rRS4  3.732914 3.900822e-04 0.9994637 -0.3471331 0.9994637
NqsVOy_yos30cOQRSE -3.673551 4.737810e-04 0.9994637 -0.4902001 0.9994637
B3SDpegGjpdxnvU0S0 -3.665765 4.859528e-04 0.9994637 -0.5088638 0.9994637

x1g$fdr=p.adjust(x1g$P.Value,method="BH")

the fdr values seem unusually high

if I just do it for the first few p values from my x1g data frame:
>pval=c(3.072189e-05,7.518696e-05,1.959413e-04,3.900822e-04)
> p.adjust(pval,method="BH")
[1] 0.0001228876 0.0001503739 0.0002612551 0.0003900822

Can someone please explain what might be the issue.

Thanks
Ana


From drj|m|emon @end|ng |rom gm@||@com  Tue Jan  7 23:36:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 8 Jan 2020 09:36:45 +1100
Subject: [R] adjusted p value, fdr
In-Reply-To: <CAF9-5jO4v-ScVB-ATd3hLRP52QHp7sszocbXyWrT2BJR+-6Jbg@mail.gmail.com>
References: <CAF9-5jO4v-ScVB-ATd3hLRP52QHp7sszocbXyWrT2BJR+-6Jbg@mail.gmail.com>
Message-ID: <CA+8X3fUpZX7n=-gQrD3gW8WVOv_5CfViGWceToSeapT0R-FUfw@mail.gmail.com>

Hi Anamarija,
In the first calculation you are implicity using n=15568 as the
default as the number of p values tested.

> p.adjust(pval,method="BH",n=15568)
[1] 0.4782784 0.5852553 1.0000000 1.0000000

If all of your t-tests are related, say by testing the location values
for each row against a fixed value like zero, then this is an
appropriate way to discover whether any differ significantly from your
reference value. In general if you only want to test a subset of the
rows rather than all, you should have a good reason for doing so.

Jim

On Wed, Jan 8, 2020 at 9:15 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a data set which has 15568 entries
>
> I am trying to calculate adjusted p values using p value via:
>
> head(x1g)
>
>                                                    t      P.Value
>       adj.P.Val          B       fdr
> 3TXADqtSkhV1IXRHlg  4.468671 3.072189e-05 0.4782784  1.5253151 0.4782784
> 34lG83aZ6.WLFnge6s  4.217037 7.518696e-05 0.5852553  0.8660534 0.5852553
> oS67lguv5HpU4i6Pvg -3.939182 1.959413e-04 0.9994637  0.1600655 0.9994637
> Qpc2sX7gp.W5E2rRS4  3.732914 3.900822e-04 0.9994637 -0.3471331 0.9994637
> NqsVOy_yos30cOQRSE -3.673551 4.737810e-04 0.9994637 -0.4902001 0.9994637
> B3SDpegGjpdxnvU0S0 -3.665765 4.859528e-04 0.9994637 -0.5088638 0.9994637
>
> x1g$fdr=p.adjust(x1g$P.Value,method="BH")
>
> the fdr values seem unusually high
>
> if I just do it for the first few p values from my x1g data frame:
> >pval=c(3.072189e-05,7.518696e-05,1.959413e-04,3.900822e-04)
> > p.adjust(pval,method="BH")
> [1] 0.0001228876 0.0001503739 0.0002612551 0.0003900822
>
> Can someone please explain what might be the issue.
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Tue Jan  7 23:37:34 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Tue, 7 Jan 2020 22:37:34 +0000
Subject: [R] adjusted p value, fdr
In-Reply-To: <CAF9-5jO4v-ScVB-ATd3hLRP52QHp7sszocbXyWrT2BJR+-6Jbg@mail.gmail.com>
References: <CAF9-5jO4v-ScVB-ATd3hLRP52QHp7sszocbXyWrT2BJR+-6Jbg@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113B81F8@PPWEXCH2KX14.coh.org>

When you do x1g$fdr, you adjusted for  a total of 15568  tests, so FDR is high for those first four entries. When you do p.adjust(pval,method="BH"), you assumed there were only a total of 4 multiple tests in your experiment, so FDR is low.

Ding

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ana Marija
Sent: Tuesday, January 07, 2020 2:18 PM
To: r-help
Subject: [R] adjusted p value, fdr

[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]

----------------------------------------------------------------------
Hello,



I have a data set which has 15568 entries



I am trying to calculate adjusted p values using p value via:



head(x1g)



                                                   t      P.Value

      adj.P.Val          B       fdr

3TXADqtSkhV1IXRHlg  4.468671 3.072189e-05 0.4782784  1.5253151 0.4782784

34lG83aZ6.WLFnge6s  4.217037 7.518696e-05 0.5852553  0.8660534 0.5852553

oS67lguv5HpU4i6Pvg -3.939182 1.959413e-04 0.9994637  0.1600655 0.9994637

Qpc2sX7gp.W5E2rRS4  3.732914 3.900822e-04 0.9994637 -0.3471331 0.9994637

NqsVOy_yos30cOQRSE -3.673551 4.737810e-04 0.9994637 -0.4902001 0.9994637

B3SDpegGjpdxnvU0S0 -3.665765 4.859528e-04 0.9994637 -0.5088638 0.9994637



x1g$fdr=p.adjust(x1g$P.Value,method="BH")



the fdr values seem unusually high



if I just do it for the first few p values from my x1g data frame:

>pval=c(3.072189e-05,7.518696e-05,1.959413e-04,3.900822e-04)

> p.adjust(pval,method="BH")

[1] 0.0001228876 0.0001503739 0.0002612551 0.0003900822



Can someone please explain what might be the issue.



Thanks

Ana



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!4bosaaipAoQGBWeAiIEWMDxU4RRjSCsN0DmyN4DzNZK1NSLhh5pdAGPEy5zh$

PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!4bosaaipAoQGBWeAiIEWMDxU4RRjSCsN0DmyN4DzNZK1NSLhh5pdADDOUx9a$ 

and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jan  8 10:37:23 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 8 Jan 2020 10:37:23 +0100
Subject: [R] Incorrect Conversion of Datetime
Message-ID: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>

Dear Friends,
A sample of my data is:
98 05 01 02    8541
98 05 01 03    8548
98 05 01 04    8512
98 05 01 05    8541
98 05 01 06    8509
98 05 01 07    8472
98 05 01 08    8454
98 05 01 09    8461
98 05 01 10    8462
98 05 01 11    8475
98 05 01 12    8433
98 05 01 13    8479
98 05 01 14    8417
98 05 01 15    8463
98 05 01 16    8473
98 05 01 17    8450
98 05 01 18    8433
98 05 01 19    8437
98 05 01 20    8437
98 05 01 21    8438
98 05 01 22    8421
98 05 01 23    8420
98 05 02 00    8371
98 05 02 01    8338
98 05 02 02    8251
98 05 02 03    8204
98 05 02 04    8183
98 05 02 05    8231
98 05 02 06    8242
Columns 1, 2, 3, 4 and 5 stands for year, month, day , hour and count.

Using:
Sys.setenv( TZ="GMT" )


dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
"hour", "counts"))
dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
dta$datetime <- with( dta, as.POSIXct(ISOdatetime(year, month,day,hour,0,0)))
a =  dta$datetime
I converted the datetime and plotted the graph of count vs a. The plot
was great but I have issues with the date.

The raw data is for some hours for Ist and second day of may 1998 as
is evident from the sample data. But the result of date stored in "a"
above shows:
> a
 [1] "1998-01-05 02:00:00 GMT" "1998-01-05 03:00:00 GMT"
 [3] "1998-01-05 04:00:00 GMT" "1998-01-05 05:00:00 GMT"
 [5] "1998-01-05 06:00:00 GMT" "1998-01-05 07:00:00 GMT"
 [7] "1998-01-05 08:00:00 GMT" "1998-01-05 09:00:00 GMT"
 [9] "1998-01-05 10:00:00 GMT" "1998-01-05 11:00:00 GMT"
[11] "1998-01-05 12:00:00 GMT" "1998-01-05 13:00:00 GMT"
[13] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
[15] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
[17] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
[19] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
[21] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
[23] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
[25] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
[27] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
[29] "1998-01-06 06:00:00 GMT"
This seems to suggest day 5 and 6 in January 1998 instead of day 1 and
2 in May of 1998.

I have spent some time trying to resolve this but I have not been successful.

I would be thankful if you could help me to check where I went astray.

Thank you.
Best wishes
Ogbos


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan  8 11:03:24 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 8 Jan 2020 21:03:24 +1100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
Message-ID: <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>

Hi Ogbos,
I get the correct result using strptime:

dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
 "%y %m %d %H"
)
> dta$date
[1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
[3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
[5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
[7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
[9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
[11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
[13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
[15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
[17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
[19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
[21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
[23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
[25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
[27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
[29] "1998-05-02 06:00:00 AEST"

Same result with

ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))

As it should be as the lower two call strptime. I can't see from your
code why the month and day are transcribed.

Jim


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jan  8 11:02:53 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 8 Jan 2020 13:02:53 +0300
Subject: [R] spurious locking of packages
In-Reply-To: <b43c72ad-c214-47f8-9539-33870cd2c996@www.fastmail.com>
References: <mailman.357243.1.1577444401.20251.r-help@r-project.org>
 <b43c72ad-c214-47f8-9539-33870cd2c996@www.fastmail.com>
Message-ID: <20200108130253.3e916db7@Tarkus>

On Fri, 27 Dec 2019 15:27:01 -0500
"Jan Galkowski" <bayesianlogic.1 at gmail.com> wrote:

> *emoa* is a stand-in for whatever package faulted during the load. (I
> also have no idea why *EMD* is locked in the above.)

Both packages mentioned have NeedsCompilation: yes. Could it be the case
that some anti-virus software is scanning the DLLs as they are opened
and, having an open HANDLE to them, prevents the files from being
replaced?

-- 
Best regards,
Ivan


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan  8 11:05:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 8 Jan 2020 21:05:13 +1100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
Message-ID: <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>

Hi again,
Small typo, should be

dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
 "%Y %m %d %H"

as I tried it both with and without the century just to check and
copied the wrong line.

On Wed, Jan 8, 2020 at 9:03 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ogbos,
> I get the correct result using strptime:
>
> dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>  "%y %m %d %H"
> )
> > dta$date
> [1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
> [3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
> [5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
> [7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
> [9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
> [11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
> [13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
> [15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
> [17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
> [19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
> [21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
> [23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
> [25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
> [27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
> [29] "1998-05-02 06:00:00 AEST"
>
> Same result with
>
> ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
> as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))
>
> As it should be as the lower two call strptime. I can't see from your
> code why the month and day are transcribed.
>
> Jim


From hwborcher@ @end|ng |rom gm@||@com  Wed Jan  8 12:09:55 2020
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Wed, 8 Jan 2020 12:09:55 +0100
Subject: [R] Which external functions are called in a package? [Solved]
Message-ID: <CAML4n3Mf35rP_LbnN-j8U9HjNuUJ7Pw-Kwx6ST43jk=XLL0mxg@mail.gmail.com>

By using the *pkgapi* package and with quite a bit of manual work I
was able to (almost) automatically find all function calls to my
package in 150 depending on, importing, or suggesting packages. It
took two days to overcome all the obstacles during the process -- and
was a very rewarding experience. And one where I learned a lot about R
again.

I also found two bugs in *pkgapi* that I will report. I will write up
a short notice on R-pubs for those interested in doing the same for
their packages. (By the way, I like the somewhat stricter rules for
package dependencies and vignettes on BioConductor.) NB: `trapz`, ie.
the trapezoidal integration formula, seems to be the numerical
function to be missed the most in R base.

Thanks for all the help. --HW


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jan  8 12:55:10 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 8 Jan 2020 12:55:10 +0100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
 <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>
Message-ID: <CAC8ss33_cF4rYP7p686p3ZzMKWQRjYO1b_u97BXPWmGAjYSeNA@mail.gmail.com>

Dear Jim,
Thank you for coming my assist me.
I have tried all you suggested but the same result keep coming.
I tried, for example:
dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
"hour", "counts"))

dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
 "%Y %m %d %H")
a =  dta$date
and obtained:
> a
 [1] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
 [3] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
 [5] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
 [7] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
 [9] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
[11] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
[13] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
[15] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
[17] "1998-01-06 06:00:00 GMT"

Instead of getting AEST as in your own result, mine remains GMT.

I think the problem is coming from my system or location, I am not sure.

Please have a look again and advise further.

Thank you.

On Wed, Jan 8, 2020 at 11:05 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi again,
> Small typo, should be
>
> dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>  "%Y %m %d %H"
>
> as I tried it both with and without the century just to check and
> copied the wrong line.
>
> On Wed, Jan 8, 2020 at 9:03 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Ogbos,
> > I get the correct result using strptime:
> >
> > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
> >  "%y %m %d %H"
> > )
> > > dta$date
> > [1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
> > [3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
> > [5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
> > [7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
> > [9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
> > [11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
> > [13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
> > [15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
> > [17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
> > [19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
> > [21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
> > [23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
> > [25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
> > [27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
> > [29] "1998-05-02 06:00:00 AEST"
> >
> > Same result with
> >
> > ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
> > as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))
> >
> > As it should be as the lower two call strptime. I can't see from your
> > code why the month and day are transcribed.
> >
> > Jim


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Jan  8 13:07:53 2020
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 08 Jan 2020 13:07:53 +0100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
Message-ID: <20200108130753.Horde.RHAvO4E8QS_x6tjm3m7NeiS@webmail.your-server.de>


Quoting Ogbos Okike <giftedlife2014 at gmail.com>:

> Dear Friends,
> A sample of my data is:
> 98 05 01 02    8541
> 98 05 01 03    8548
> 98 05 01 04    8512
> 98 05 01 05    8541
> 98 05 01 06    8509
> 98 05 01 07    8472
> 98 05 01 08    8454
> 98 05 01 09    8461
> 98 05 01 10    8462
> 98 05 01 11    8475
> 98 05 01 12    8433
> 98 05 01 13    8479
> 98 05 01 14    8417
> 98 05 01 15    8463
> 98 05 01 16    8473
> 98 05 01 17    8450
> 98 05 01 18    8433
> 98 05 01 19    8437
> 98 05 01 20    8437
> 98 05 01 21    8438
> 98 05 01 22    8421
> 98 05 01 23    8420
> 98 05 02 00    8371
> 98 05 02 01    8338
> 98 05 02 02    8251
> 98 05 02 03    8204
> 98 05 02 04    8183
> 98 05 02 05    8231
> 98 05 02 06    8242
> Columns 1, 2, 3, 4 and 5 stands for year, month, day , hour and count.
>
> Using:
> Sys.setenv( TZ="GMT" )
>
>
> dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
> "hour", "counts"))
> dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
> dta$datetime <- with( dta, as.POSIXct(ISOdatetime(year, month,day,hour,0,0)))
> a =  dta$datetime
> I converted the datetime and plotted the graph of count vs a. The plot
> was great but I have issues with the date.
>
> The raw data is for some hours for Ist and second day of may 1998 as
> is evident from the sample data. But the result of date stored in "a"
> above shows:
>> a
>  [1] "1998-01-05 02:00:00 GMT" "1998-01-05 03:00:00 GMT"
>  [3] "1998-01-05 04:00:00 GMT" "1998-01-05 05:00:00 GMT"
>  [5] "1998-01-05 06:00:00 GMT" "1998-01-05 07:00:00 GMT"
>  [7] "1998-01-05 08:00:00 GMT" "1998-01-05 09:00:00 GMT"
>  [9] "1998-01-05 10:00:00 GMT" "1998-01-05 11:00:00 GMT"
> [11] "1998-01-05 12:00:00 GMT" "1998-01-05 13:00:00 GMT"
> [13] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
> [15] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
> [17] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
> [19] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
> [21] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
> [23] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
> [25] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
> [27] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
> [29] "1998-01-06 06:00:00 GMT"
> This seems to suggest day 5 and 6 in January 1998 instead of day 1 and
> 2 in May of 1998.
>
> I have spent some time trying to resolve this but I have not been successful.
>
> I would be thankful if you could help me to check where I went astray.
>
> Thank you.
> Best wishes
> Ogbos
>

I cannot reproduce these results. Could you please provide a fully
reproducible example, by providing a small example dataset via 'dput(dta)'?


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jan  8 13:09:01 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 8 Jan 2020 13:09:01 +0100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CAC8ss33_cF4rYP7p686p3ZzMKWQRjYO1b_u97BXPWmGAjYSeNA@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
 <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>
 <CAC8ss33_cF4rYP7p686p3ZzMKWQRjYO1b_u97BXPWmGAjYSeNA@mail.gmail.com>
Message-ID: <CAC8ss30CwZTkxkjCZOeLBDKu7F34vKMrjhmgdDaRwUb9tisSXg@mail.gmail.com>

Dear Jim,
In order to check whether I have a correct time on my system, I run:
$ timedatectl

 and it gives:
Local time: Wed 2020-01-08 13:03:44 WAT
                  Universal time: Wed 2020-01-08 12:03:44 UTC
                        RTC time: Wed 2020-01-08 12:03:44
                       Time zone: Africa/Lagos (WAT, +0100)
       System clock synchronized: yes
systemd-timesyncd.service active: yes
                 RTC in local TZ: no.

The time is correct as it agrees with the system time.

I don't know if there are other things I need to change.

Thank you for any suggestions.
Ogbos

On Wed, Jan 8, 2020 at 12:55 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Jim,
> Thank you for coming my assist me.
> I have tried all you suggested but the same result keep coming.
> I tried, for example:
> dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
> "hour", "counts"))
>
> dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
> dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>  "%Y %m %d %H")
> a =  dta$date
> and obtained:
> > a
>  [1] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
>  [3] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
>  [5] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
>  [7] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
>  [9] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
> [11] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
> [13] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
> [15] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
> [17] "1998-01-06 06:00:00 GMT"
>
> Instead of getting AEST as in your own result, mine remains GMT.
>
> I think the problem is coming from my system or location, I am not sure.
>
> Please have a look again and advise further.
>
> Thank you.
>
> On Wed, Jan 8, 2020 at 11:05 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi again,
> > Small typo, should be
> >
> > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
> >  "%Y %m %d %H"
> >
> > as I tried it both with and without the century just to check and
> > copied the wrong line.
> >
> > On Wed, Jan 8, 2020 at 9:03 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Ogbos,
> > > I get the correct result using strptime:
> > >
> > > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
> > >  "%y %m %d %H"
> > > )
> > > > dta$date
> > > [1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
> > > [3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
> > > [5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
> > > [7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
> > > [9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
> > > [11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
> > > [13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
> > > [15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
> > > [17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
> > > [19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
> > > [21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
> > > [23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
> > > [25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
> > > [27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
> > > [29] "1998-05-02 06:00:00 AEST"
> > >
> > > Same result with
> > >
> > > ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
> > > as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))
> > >
> > > As it should be as the lower two call strptime. I can't see from your
> > > code why the month and day are transcribed.
> > >
> > > Jim


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jan  8 13:22:58 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 8 Jan 2020 06:22:58 -0600
Subject: [R] adjusted p value, fdr
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113B81F8@PPWEXCH2KX14.coh.org>
References: <CAF9-5jO4v-ScVB-ATd3hLRP52QHp7sszocbXyWrT2BJR+-6Jbg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6113B81F8@PPWEXCH2KX14.coh.org>
Message-ID: <CAF9-5jOZRA3w7zuXW5mm7VemidR0ydHj0EG0m=UJ-z9QMQpcyQ@mail.gmail.com>

Thank you so much for this explanation!

On Tue, Jan 7, 2020 at 4:37 PM Yuan Chun Ding <ycding at coh.org> wrote:
>
> When you do x1g$fdr, you adjusted for  a total of 15568  tests, so FDR is high for those first four entries. When you do p.adjust(pval,method="BH"), you assumed there were only a total of 4 multiple tests in your experiment, so FDR is low.
>
> Ding
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ana Marija
> Sent: Tuesday, January 07, 2020 2:18 PM
> To: r-help
> Subject: [R] adjusted p value, fdr
>
> [Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
>
> ----------------------------------------------------------------------
> Hello,
>
>
>
> I have a data set which has 15568 entries
>
>
>
> I am trying to calculate adjusted p values using p value via:
>
>
>
> head(x1g)
>
>
>
>                                                    t      P.Value
>
>       adj.P.Val          B       fdr
>
> 3TXADqtSkhV1IXRHlg  4.468671 3.072189e-05 0.4782784  1.5253151 0.4782784
>
> 34lG83aZ6.WLFnge6s  4.217037 7.518696e-05 0.5852553  0.8660534 0.5852553
>
> oS67lguv5HpU4i6Pvg -3.939182 1.959413e-04 0.9994637  0.1600655 0.9994637
>
> Qpc2sX7gp.W5E2rRS4  3.732914 3.900822e-04 0.9994637 -0.3471331 0.9994637
>
> NqsVOy_yos30cOQRSE -3.673551 4.737810e-04 0.9994637 -0.4902001 0.9994637
>
> B3SDpegGjpdxnvU0S0 -3.665765 4.859528e-04 0.9994637 -0.5088638 0.9994637
>
>
>
> x1g$fdr=p.adjust(x1g$P.Value,method="BH")
>
>
>
> the fdr values seem unusually high
>
>
>
> if I just do it for the first few p values from my x1g data frame:
>
> >pval=c(3.072189e-05,7.518696e-05,1.959413e-04,3.900822e-04)
>
> > p.adjust(pval,method="BH")
>
> [1] 0.0001228876 0.0001503739 0.0002612551 0.0003900822
>
>
>
> Can someone please explain what might be the issue.
>
>
>
> Thanks
>
> Ana
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!4bosaaipAoQGBWeAiIEWMDxU4RRjSCsN0DmyN4DzNZK1NSLhh5pdAGPEy5zh$
>
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!4bosaaipAoQGBWeAiIEWMDxU4RRjSCsN0DmyN4DzNZK1NSLhh5pdADDOUx9a$
>
> and provide commented, minimal, self-contained, reproducible code.
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> ------------------------------------------------------------


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Wed Jan  8 15:52:18 2020
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Wed, 8 Jan 2020 14:52:18 +0000
Subject: [R] Dataframe by Serial ID
Message-ID: <CH2PR17MB37494099472C2136250B6BECB83E0@CH2PR17MB3749.namprd17.prod.outlook.com>

Colleagues,

I have two data frames which look like this.

Data frame 1

  	Serial 	Pre.Hole 	Pre.flow  	Pre.Date
1   	3036        1     		0.24 		19-Nov-19
2   	3036        2    		0.212 		19-Nov-19
3   	3036        3    		1.292 		19-Nov-19
4   	3036        4    		0.262 		19-Nov-19
5   	3036        5    		1.291 		19-Nov-19
6   	3036        6     		0.26 		19-Nov-19

Data frame 2

      	Serial	 Post.Hole 	Post.flow 	Post.Date
62323  11024        44    		-0.678 		11-Dec-19
62324  11024        45    		-0.659 		11-Dec-19
62325  11024        46   		 -0.654 		11-Dec-19
62326  11024        47    		-0.699 		11-Dec-19
62327  11024        48   		 -0.671 		11-Dec-19
62328  11024        49    		-0.687 		11-Dec-19

What I want is to create a data frame whose serials numbers are common to data frames 1 and 2.
The resulting data frame 1st row would look like this.

Serial 	Post.Hole 	Post.flow 	Post.Date	Pre.Hole 	Pre.flow 	Pre.Date

Any ideas on how to do this would be appreciated.

Thomas Subia 
Statistician / Senior Quality Engineer

IMG Companies?
225 Mountain Vista Parkway
Livermore, CA 94551
T.?(925) 273-1106
F.?(925) 273-1111
E. tsubia at imgprecision.com


Precision Manufacturing for Emerging Technologies
imgprecision.com?

The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan  8 16:04:59 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Jan 2020 07:04:59 -0800
Subject: [R] Dataframe by Serial ID
In-Reply-To: <CH2PR17MB37494099472C2136250B6BECB83E0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB37494099472C2136250B6BECB83E0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <870E84E1-E909-4537-8504-4A82D7CE6474@dcn.davis.ca.us>

"merge" is generally the base R answer to this question, and there are equivalent functions in various contributed packages.

However, it is necessary to identify which columns in each table uniquely identify each row ("primary key"). If your Serial 3036 shows up 10 times in the first table and 10 times in the second table then you will end up with all combinations of those rows (100 rows) in a merge that uses only Serial to match rows. Is that what you want?


On January 8, 2020 6:52:18 AM PST, Thomas Subia <tsubia at imgprecision.com> wrote:
>Colleagues,
>
>I have two data frames which look like this.
>
>Data frame 1
>
>  	Serial 	Pre.Hole 	Pre.flow  	Pre.Date
>1   	3036        1     		0.24 		19-Nov-19
>2   	3036        2    		0.212 		19-Nov-19
>3   	3036        3    		1.292 		19-Nov-19
>4   	3036        4    		0.262 		19-Nov-19
>5   	3036        5    		1.291 		19-Nov-19
>6   	3036        6     		0.26 		19-Nov-19
>
>Data frame 2
>
>      	Serial	 Post.Hole 	Post.flow 	Post.Date
>62323  11024        44    		-0.678 		11-Dec-19
>62324  11024        45    		-0.659 		11-Dec-19
>62325  11024        46   		 -0.654 		11-Dec-19
>62326  11024        47    		-0.699 		11-Dec-19
>62327  11024        48   		 -0.671 		11-Dec-19
>62328  11024        49    		-0.687 		11-Dec-19
>
>What I want is to create a data frame whose serials numbers are common
>to data frames 1 and 2.
>The resulting data frame 1st row would look like this.
>
>Serial 	Post.Hole 	Post.flow 	Post.Date	Pre.Hole 	Pre.flow 	Pre.Date
>
>Any ideas on how to do this would be appreciated.
>
>Thomas Subia 
>Statistician / Senior Quality Engineer
>
>IMG Companies?
>225 Mountain Vista Parkway
>Livermore, CA 94551
>T.?(925) 273-1106
>F.?(925) 273-1111
>E. tsubia at imgprecision.com
>
>
>Precision Manufacturing for Emerging Technologies
>imgprecision.com?
>
>The contents of this message, together with any attachments, are
>intended only for the use of the individual or entity to which they are
>addressed and may contain information that is legally privileged,
>confidential and exempt from disclosure. If you are not the intended
>recipient, you are hereby notified that any dissemination,
>distribution, or copying of this message, or any attachment, is
>strictly prohibited. If you have received this message in error, please
>notify the original sender or IMG Companies, LLC at Tel: 925-273-1100
>immediately by telephone or by return E-mail and delete this message,
>along with any attachments, from your computer. Thank you.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jan  8 16:09:51 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 8 Jan 2020 07:09:51 -0800
Subject: [R] Dataframe by Serial ID
In-Reply-To: <CH2PR17MB37494099472C2136250B6BECB83E0@CH2PR17MB3749.namprd17.prod.outlook.com>
References: <CH2PR17MB37494099472C2136250B6BECB83E0@CH2PR17MB3749.namprd17.prod.outlook.com>
Message-ID: <B92FCB57-1B30-445E-A058-BB276EEDB2FA@comcast.net>



> On Jan 8, 2020, at 6:52 AM, Thomas Subia <tsubia at imgprecision.com> wrote:
> 
> Colleagues,
> 
> I have two data frames which look like this.
> 
> Data frame 1
> 
>  	Serial 	Pre.Hole 	Pre.flow  	Pre.Date
> 1   	3036        1     		0.24 		19-Nov-19
> 2   	3036        2    		0.212 		19-Nov-19
> 3   	3036        3    		1.292 		19-Nov-19
> 4   	3036        4    		0.262 		19-Nov-19
> 5   	3036        5    		1.291 		19-Nov-19
> 6   	3036        6     		0.26 		19-Nov-19
> 
> Data frame 2
> 
>      	Serial	 Post.Hole 	Post.flow 	Post.Date
> 62323  11024        44    		-0.678 		11-Dec-19
> 62324  11024        45    		-0.659 		11-Dec-19
> 62325  11024        46   		 -0.654 		11-Dec-19
> 62326  11024        47    		-0.699 		11-Dec-19
> 62327  11024        48   		 -0.671 		11-Dec-19
> 62328  11024        49    		-0.687 		11-Dec-19
> 
> What I want is to create a data frame whose serials numbers are common to data frames 1 and 2.
> The resulting data frame 1st row would look like this.
> 
> Serial 	Post.Hole 	Post.flow 	Post.Date	Pre.Hole 	Pre.flow 	Pre.Date

Simply try:

new.df <- merge(df1,df2)

You should be aware that those columns with dates are actually factor or character values. R does have a Date class and you will likely want to look at using as.Date to make them more useful.


-- 
David.
> 
> Any ideas on how to do this would be appreciated.
> 
> Thomas Subia 
> Statistician / Senior Quality Engineer
> 
> IMG Companies 
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T. (925) 273-1106
> F. (925) 273-1111
> E. tsubia at imgprecision.com
> 
> 
> Precision Manufacturing for Emerging Technologies
> imgprecision.com 
> 
> The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan  8 16:22:29 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Jan 2020 07:22:29 -0800
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CAC8ss30CwZTkxkjCZOeLBDKu7F34vKMrjhmgdDaRwUb9tisSXg@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
 <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>
 <CAC8ss33_cF4rYP7p686p3ZzMKWQRjYO1b_u97BXPWmGAjYSeNA@mail.gmail.com>
 <CAC8ss30CwZTkxkjCZOeLBDKu7F34vKMrjhmgdDaRwUb9tisSXg@mail.gmail.com>
Message-ID: <A9ECD28D-7257-47AC-8068-4A7BEB8D2C4C@dcn.davis.ca.us>

In your first email you said you were using

Sys.setenv( TZ="GMT" )

in your code, which defines the default assumption for time conversion timezone (at least until you change it). Keep in mind that you may be dealing with data from other timezones than your local one that the operating system uses, so the OS timezone only gets used if TZ is blank (and even that behavior can be OS-dependent I think).

Read

?OlsonNames

because AEST may not be a valid specification for TZ.

On January 8, 2020 4:09:01 AM PST, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jim,
>In order to check whether I have a correct time on my system, I run:
>$ timedatectl
>
> and it gives:
>Local time: Wed 2020-01-08 13:03:44 WAT
>                  Universal time: Wed 2020-01-08 12:03:44 UTC
>                        RTC time: Wed 2020-01-08 12:03:44
>                       Time zone: Africa/Lagos (WAT, +0100)
>       System clock synchronized: yes
>systemd-timesyncd.service active: yes
>                 RTC in local TZ: no.
>
>The time is correct as it agrees with the system time.
>
>I don't know if there are other things I need to change.
>
>Thank you for any suggestions.
>Ogbos
>
>On Wed, Jan 8, 2020 at 12:55 PM Ogbos Okike <giftedlife2014 at gmail.com>
>wrote:
>>
>> Dear Jim,
>> Thank you for coming my assist me.
>> I have tried all you suggested but the same result keep coming.
>> I tried, for example:
>> dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
>> "hour", "counts"))
>>
>> dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
>> dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>>  "%Y %m %d %H")
>> a =  dta$date
>> and obtained:
>> > a
>>  [1] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
>>  [3] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
>>  [5] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
>>  [7] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
>>  [9] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
>> [11] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
>> [13] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
>> [15] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
>> [17] "1998-01-06 06:00:00 GMT"
>>
>> Instead of getting AEST as in your own result, mine remains GMT.
>>
>> I think the problem is coming from my system or location, I am not
>sure.
>>
>> Please have a look again and advise further.
>>
>> Thank you.
>>
>> On Wed, Jan 8, 2020 at 11:05 AM Jim Lemon <drjimlemon at gmail.com>
>wrote:
>> >
>> > Hi again,
>> > Small typo, should be
>> >
>> > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>> >  "%Y %m %d %H"
>> >
>> > as I tried it both with and without the century just to check and
>> > copied the wrong line.
>> >
>> > On Wed, Jan 8, 2020 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
>wrote:
>> > >
>> > > Hi Ogbos,
>> > > I get the correct result using strptime:
>> > >
>> > > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>> > >  "%y %m %d %H"
>> > > )
>> > > > dta$date
>> > > [1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
>> > > [3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
>> > > [5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
>> > > [7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
>> > > [9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
>> > > [11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
>> > > [13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
>> > > [15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
>> > > [17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
>> > > [19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
>> > > [21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
>> > > [23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
>> > > [25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
>> > > [27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
>> > > [29] "1998-05-02 06:00:00 AEST"
>> > >
>> > > Same result with
>> > >
>> > > ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
>> > >
>as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))
>> > >
>> > > As it should be as the lower two call strptime. I can't see from
>your
>> > > code why the month and day are transcribed.
>> > >
>> > > Jim
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From er|cjberger @end|ng |rom gm@||@com  Wed Jan  8 16:25:18 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 8 Jan 2020 17:25:18 +0200
Subject: [R] Dataframe by Serial ID
In-Reply-To: <870E84E1-E909-4537-8504-4A82D7CE6474@dcn.davis.ca.us>
References: <CH2PR17MB37494099472C2136250B6BECB83E0@CH2PR17MB3749.namprd17.prod.outlook.com>
 <870E84E1-E909-4537-8504-4A82D7CE6474@dcn.davis.ca.us>
Message-ID: <CAGgJW757sZZbD-2OWYFWwd_QPcqgzPTjJq89b8=0tJssOc8c2Q@mail.gmail.com>

Hi Thomas,
Jeff is correct that this can be handled via merge, e.g.
df3 <- merge( df2, df1, by="Serial", all=FALSE )

This operation is called an "inner join", and you could use other tools,
such as the dplyr package to accomplish the same thing

df3 <- dplyr::inner_join( df2, df1, by="Serial" )

HTH,
Eric


On Wed, Jan 8, 2020 at 5:05 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> "merge" is generally the base R answer to this question, and there are
> equivalent functions in various contributed packages.
>
> However, it is necessary to identify which columns in each table uniquely
> identify each row ("primary key"). If your Serial 3036 shows up 10 times in
> the first table and 10 times in the second table then you will end up with
> all combinations of those rows (100 rows) in a merge that uses only Serial
> to match rows. Is that what you want?
>
>
> On January 8, 2020 6:52:18 AM PST, Thomas Subia <tsubia at imgprecision.com>
> wrote:
> >Colleagues,
> >
> >I have two data frames which look like this.
> >
> >Data frame 1
> >
> >       Serial  Pre.Hole        Pre.flow        Pre.Date
> >1      3036        1                   0.24            19-Nov-19
> >2      3036        2                   0.212           19-Nov-19
> >3      3036        3                   1.292           19-Nov-19
> >4      3036        4                   0.262           19-Nov-19
> >5      3036        5                   1.291           19-Nov-19
> >6      3036        6                   0.26            19-Nov-19
> >
> >Data frame 2
> >
> >       Serial   Post.Hole      Post.flow       Post.Date
> >62323  11024        44                 -0.678          11-Dec-19
> >62324  11024        45                 -0.659          11-Dec-19
> >62325  11024        46                  -0.654                 11-Dec-19
> >62326  11024        47                 -0.699          11-Dec-19
> >62327  11024        48                  -0.671                 11-Dec-19
> >62328  11024        49                 -0.687          11-Dec-19
> >
> >What I want is to create a data frame whose serials numbers are common
> >to data frames 1 and 2.
> >The resulting data frame 1st row would look like this.
> >
> >Serial         Post.Hole       Post.flow       Post.Date       Pre.Hole
>       Pre.flow        Pre.Date
> >
> >Any ideas on how to do this would be appreciated.
> >
> >Thomas Subia
> >Statistician / Senior Quality Engineer
> >
> >IMG Companies
> >225 Mountain Vista Parkway
> >Livermore, CA 94551
> >T. (925) 273-1106
> >F. (925) 273-1111
> >E. tsubia at imgprecision.com
> >
> >
> >Precision Manufacturing for Emerging Technologies
> >imgprecision.com
> >
> >The contents of this message, together with any attachments, are
> >intended only for the use of the individual or entity to which they are
> >addressed and may contain information that is legally privileged,
> >confidential and exempt from disclosure. If you are not the intended
> >recipient, you are hereby notified that any dissemination,
> >distribution, or copying of this message, or any attachment, is
> >strictly prohibited. If you have received this message in error, please
> >notify the original sender or IMG Companies, LLC at Tel: 925-273-1100
> >immediately by telephone or by return E-mail and delete this message,
> >along with any attachments, from your computer. Thank you.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jan  8 17:43:29 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 8 Jan 2020 17:43:29 +0100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <20200108130753.Horde.RHAvO4E8QS_x6tjm3m7NeiS@webmail.your-server.de>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <20200108130753.Horde.RHAvO4E8QS_x6tjm3m7NeiS@webmail.your-server.de>
Message-ID: <CAC8ss33G4dUYCt+8P4BjvwMq8_2uNRu7mftXb69FEPq=ZKUqCQ@mail.gmail.com>

Dear Enrico,
Thanks for your time.
I have tried to learn how to use dput in R. I have not yet made much progress.

I have succeeded in using dput to store my data frame. I first
converted my data into a data frame and then used:
dput(dd,file="Ogbos2",control = c("keepNA", "keepInteger",
"showAttributes")) to output the dput file. dd is my data frame.

When I opened the file, I didn't like its content as it differs very
much from my data frame. But I don't know whether that makes sense to
you. I am attaching the file.
I am thanking you in advance for additional suggestions.
Best wishes
Ogbos

On Wed, Jan 8, 2020 at 1:07 PM Enrico Schumann <es at enricoschumann.net> wrote:
>
>
> Quoting Ogbos Okike <giftedlife2014 at gmail.com>:
>
> > Dear Friends,
> > A sample of my data is:
> > 98 05 01 02    8541
> > 98 05 01 03    8548
> > 98 05 01 04    8512
> > 98 05 01 05    8541
> > 98 05 01 06    8509
> > 98 05 01 07    8472
> > 98 05 01 08    8454
> > 98 05 01 09    8461
> > 98 05 01 10    8462
> > 98 05 01 11    8475
> > 98 05 01 12    8433
> > 98 05 01 13    8479
> > 98 05 01 14    8417
> > 98 05 01 15    8463
> > 98 05 01 16    8473
> > 98 05 01 17    8450
> > 98 05 01 18    8433
> > 98 05 01 19    8437
> > 98 05 01 20    8437
> > 98 05 01 21    8438
> > 98 05 01 22    8421
> > 98 05 01 23    8420
> > 98 05 02 00    8371
> > 98 05 02 01    8338
> > 98 05 02 02    8251
> > 98 05 02 03    8204
> > 98 05 02 04    8183
> > 98 05 02 05    8231
> > 98 05 02 06    8242
> > Columns 1, 2, 3, 4 and 5 stands for year, month, day , hour and count.
> >
> > Using:
> > Sys.setenv( TZ="GMT" )
> >
> >
> > dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
> > "hour", "counts"))
> > dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
> > dta$datetime <- with( dta, as.POSIXct(ISOdatetime(year, month,day,hour,0,0)))
> > a =  dta$datetime
> > I converted the datetime and plotted the graph of count vs a. The plot
> > was great but I have issues with the date.
> >
> > The raw data is for some hours for Ist and second day of may 1998 as
> > is evident from the sample data. But the result of date stored in "a"
> > above shows:
> >> a
> >  [1] "1998-01-05 02:00:00 GMT" "1998-01-05 03:00:00 GMT"
> >  [3] "1998-01-05 04:00:00 GMT" "1998-01-05 05:00:00 GMT"
> >  [5] "1998-01-05 06:00:00 GMT" "1998-01-05 07:00:00 GMT"
> >  [7] "1998-01-05 08:00:00 GMT" "1998-01-05 09:00:00 GMT"
> >  [9] "1998-01-05 10:00:00 GMT" "1998-01-05 11:00:00 GMT"
> > [11] "1998-01-05 12:00:00 GMT" "1998-01-05 13:00:00 GMT"
> > [13] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
> > [15] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
> > [17] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
> > [19] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
> > [21] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
> > [23] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
> > [25] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
> > [27] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
> > [29] "1998-01-06 06:00:00 GMT"
> > This seems to suggest day 5 and 6 in January 1998 instead of day 1 and
> > 2 in May of 1998.
> >
> > I have spent some time trying to resolve this but I have not been successful.
> >
> > I would be thankful if you could help me to check where I went astray.
> >
> > Thank you.
> > Best wishes
> > Ogbos
> >
>
> I cannot reproduce these results. Could you please provide a fully
> reproducible example, by providing a small example dataset via 'dput(dta)'?
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>

From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jan  8 17:55:19 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 8 Jan 2020 17:55:19 +0100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <A9ECD28D-7257-47AC-8068-4A7BEB8D2C4C@dcn.davis.ca.us>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
 <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>
 <CAC8ss33_cF4rYP7p686p3ZzMKWQRjYO1b_u97BXPWmGAjYSeNA@mail.gmail.com>
 <CAC8ss30CwZTkxkjCZOeLBDKu7F34vKMrjhmgdDaRwUb9tisSXg@mail.gmail.com>
 <A9ECD28D-7257-47AC-8068-4A7BEB8D2C4C@dcn.davis.ca.us>
Message-ID: <CAC8ss32OWbNawzLjBHW7SF1JthVuqzjME5KWro-aTopc+45mVA@mail.gmail.com>

Dear Jeff,
Thank you very much for looking into this.

I have made some search on ?OlsonNames.
System time zones indicates Africa/Lagos whereas the data I am trying
to convert are Cosmic ray data prepared at different time zones
including Oulu station (Russia), Climax station (America), many parts
of Europe, etc.

Including:
 Sys.timezone()
str(OlsonNames())

in my code gives:
[1] "1998-01-05 02:00:00 WAT" "1998-01-05 03:00:00 WAT"
 [3] "1998-01-05 04:00:00 WAT" "1998-01-05 05:00:00 WAT"
 [5] "1998-01-05 06:00:00 WAT" "1998-01-05 07:00:00 WAT"
 [7] "1998-01-05 08:00:00 WAT" "1998-01-05 09:00:00 WAT"
 [9] "1998-01-05 10:00:00 WAT" "1998-01-05 11:00:00 WAT"
[11] "1998-01-05 12:00:00 WAT" "1998-01-05 13:00:00 WAT"
[13] "1998-01-05 14:00:00 WAT" "1998-01-05 15:00:00 WAT"
[15] "1998-01-05 16:00:00 WAT" "1998-01-05 17:00:00 WAT"
[17] "1998-01-05 18:00:00 WAT" "1998-01-05 19:00:00 WAT"
[19] "1998-01-05 20:00:00 WAT" "1998-01-05 21:00:00 WAT"
[21] "1998-01-05 22:00:00 WAT" "1998-01-05 23:00:00 WAT"
[23] "1998-01-06 00:00:00 WAT" "1998-01-06 01:00:00 WAT"
[25] "1998-01-06 02:00:00 WAT" "1998-01-06 03:00:00 WAT"
[27] "1998-01-06 04:00:00 WAT" "1998-01-06 05:00:00 WAT"
[29] "1998-01-06 06:00:00 WAT"

Replacing the two lines above with:
Sys.setenv( TZ="" )
gives:
[1] "1998-01-05 02:00:00 UTC" "1998-01-05 03:00:00 UTC"
 [3] "1998-01-05 04:00:00 UTC" "1998-01-05 05:00:00 UTC"
 [5] "1998-01-05 06:00:00 UTC" "1998-01-05 07:00:00 UTC"
 [7] "1998-01-05 08:00:00 UTC" "1998-01-05 09:00:00 UTC"
 [9] "1998-01-05 10:00:00 UTC" "1998-01-05 11:00:00 UTC"
[11] "1998-01-05 12:00:00 UTC" "1998-01-05 13:00:00 UTC"
[13] "1998-01-05 14:00:00 UTC" "1998-01-05 15:00:00 UTC"
[15] "1998-01-05 16:00:00 UTC" "1998-01-05 17:00:00 UTC"
[17] "1998-01-05 18:00:00 UTC" "1998-01-05 19:00:00 UTC"
[19] "1998-01-05 20:00:00 UTC" "1998-01-05 21:00:00 UTC"
[21] "1998-01-05 22:00:00 UTC" "1998-01-05 23:00:00 UTC"
[23] "1998-01-06 00:00:00 UTC" "1998-01-06 01:00:00 UTC"
[25] "1998-01-06 02:00:00 UTC" "1998-01-06 03:00:00 UTC"
[27] "1998-01-06 04:00:00 UTC" "1998-01-06 05:00:00 UTC"
[29] "1998-01-06 06:00:00 UTC"

All these are still not correct and I am yet longing for further help.

Best regards
Ogbos

On Wed, Jan 8, 2020 at 4:22 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> In your first email you said you were using
>
> Sys.setenv( TZ="GMT" )
>
> in your code, which defines the default assumption for time conversion timezone (at least until you change it). Keep in mind that you may be dealing with data from other timezones than your local one that the operating system uses, so the OS timezone only gets used if TZ is blank (and even that behavior can be OS-dependent I think).
>
> Read
>
> ?OlsonNames
>
> because AEST may not be a valid specification for TZ.
>
> On January 8, 2020 4:09:01 AM PST, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> >Dear Jim,
> >In order to check whether I have a correct time on my system, I run:
> >$ timedatectl
> >
> > and it gives:
> >Local time: Wed 2020-01-08 13:03:44 WAT
> >                  Universal time: Wed 2020-01-08 12:03:44 UTC
> >                        RTC time: Wed 2020-01-08 12:03:44
> >                       Time zone: Africa/Lagos (WAT, +0100)
> >       System clock synchronized: yes
> >systemd-timesyncd.service active: yes
> >                 RTC in local TZ: no.
> >
> >The time is correct as it agrees with the system time.
> >
> >I don't know if there are other things I need to change.
> >
> >Thank you for any suggestions.
> >Ogbos
> >
> >On Wed, Jan 8, 2020 at 12:55 PM Ogbos Okike <giftedlife2014 at gmail.com>
> >wrote:
> >>
> >> Dear Jim,
> >> Thank you for coming my assist me.
> >> I have tried all you suggested but the same result keep coming.
> >> I tried, for example:
> >> dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
> >> "hour", "counts"))
> >>
> >> dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
> >> dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
> >>  "%Y %m %d %H")
> >> a =  dta$date
> >> and obtained:
> >> > a
> >>  [1] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
> >>  [3] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
> >>  [5] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
> >>  [7] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
> >>  [9] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
> >> [11] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
> >> [13] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
> >> [15] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
> >> [17] "1998-01-06 06:00:00 GMT"
> >>
> >> Instead of getting AEST as in your own result, mine remains GMT.
> >>
> >> I think the problem is coming from my system or location, I am not
> >sure.
> >>
> >> Please have a look again and advise further.
> >>
> >> Thank you.
> >>
> >> On Wed, Jan 8, 2020 at 11:05 AM Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >> >
> >> > Hi again,
> >> > Small typo, should be
> >> >
> >> > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
> >> >  "%Y %m %d %H"
> >> >
> >> > as I tried it both with and without the century just to check and
> >> > copied the wrong line.
> >> >
> >> > On Wed, Jan 8, 2020 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >> > >
> >> > > Hi Ogbos,
> >> > > I get the correct result using strptime:
> >> > >
> >> > > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
> >> > >  "%y %m %d %H"
> >> > > )
> >> > > > dta$date
> >> > > [1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
> >> > > [3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
> >> > > [5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
> >> > > [7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
> >> > > [9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
> >> > > [11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
> >> > > [13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
> >> > > [15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
> >> > > [17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
> >> > > [19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
> >> > > [21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
> >> > > [23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
> >> > > [25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
> >> > > [27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
> >> > > [29] "1998-05-02 06:00:00 AEST"
> >> > >
> >> > > Same result with
> >> > >
> >> > > ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
> >> > >
> >as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))
> >> > >
> >> > > As it should be as the lower two call strptime. I can't see from
> >your
> >> > > code why the month and day are transcribed.
> >> > >
> >> > > Jim
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From n@m@t|o|| @end|ng |rom ucd@v|@@edu  Wed Jan  8 18:37:17 2020
From: n@m@t|o|| @end|ng |rom ucd@v|@@edu (Norm Matloff)
Date: Wed, 8 Jan 2020 09:37:17 -0800
Subject: [R] issue with Rcmdr
In-Reply-To: <mailman.357314.1.1578481201.57125.r-help@r-project.org>
References: <mailman.357314.1.1578481201.57125.r-help@r-project.org>
Message-ID: <20200108173717.GF12965@laura>

Glad to hear it now works for you.  But speaking more generally, note that R-squared is the squared correlation between the predicted Y and actual Y values.  E.g.

lmout <- lm(y ~ x)
print(cor(lmout$fitted.values,y)^2)

One can use this in any regression setting, even machine learning methods.

Norm


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan  8 18:59:56 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Jan 2020 09:59:56 -0800
Subject: [R] issue with Rcmdr
In-Reply-To: <20200108173717.GF12965@laura>
References: <mailman.357314.1.1578481201.57125.r-help@r-project.org>
 <20200108173717.GF12965@laura>
Message-ID: <CAGxFJbTsAtvG3g-rr_g4u5T8ttPOEP3gGjAZhrRXUF-6qz3r8g@mail.gmail.com>

... and even more generally, is generally misleading. ;-)

(search "problems with R^2" or similar for why).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 8, 2020 at 9:37 AM Norm Matloff <nsmatloff at ucdavis.edu> wrote:

> Glad to hear it now works for you.  But speaking more generally, note that
> R-squared is the squared correlation between the predicted Y and actual Y
> values.  E.g.
>
> lmout <- lm(y ~ x)
> print(cor(lmout$fitted.values,y)^2)
>
> One can use this in any regression setting, even machine learning methods.
>
> Norm
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jan  8 19:27:39 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Jan 2020 10:27:39 -0800
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CAC8ss32OWbNawzLjBHW7SF1JthVuqzjME5KWro-aTopc+45mVA@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <CA+8X3fWu0pZ7MR+mxNtbr+a_OKdvCMab8MiF=-TFB60PeHg5gA@mail.gmail.com>
 <CA+8X3fWu-ykQ77npgo9rA05OXPg6B4azx6agrci5U0uR88E=5w@mail.gmail.com>
 <CAC8ss33_cF4rYP7p686p3ZzMKWQRjYO1b_u97BXPWmGAjYSeNA@mail.gmail.com>
 <CAC8ss30CwZTkxkjCZOeLBDKu7F34vKMrjhmgdDaRwUb9tisSXg@mail.gmail.com>
 <A9ECD28D-7257-47AC-8068-4A7BEB8D2C4C@dcn.davis.ca.us>
 <CAC8ss32OWbNawzLjBHW7SF1JthVuqzjME5KWro-aTopc+45mVA@mail.gmail.com>
Message-ID: <067B350F-4D81-48B4-BB23-82EF4ACAAE51@dcn.davis.ca.us>

a) R cannot deal with POSIXt vectors having more than one timezone in one vector. Won't happen. You need to separate the data into different data frames if you need to deal with importing data with different timezones.

b) You say you included the  lines

Sys.timezone()
str(OlsonNames())

in your R code... but these are both used for you to extract information that could be useful to you in understanding how things are set up... they do NOT alter how R will do anything. To do that you would need to do something like

Sys.setenv( TZ="Africa/Lagos" )

and then convert some character data to POSIXct like

dta$timestamp <- as.POSIXct( dta$timestring, format=...


On January 8, 2020 8:55:19 AM PST, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>Thank you very much for looking into this.
>
>I have made some search on ?OlsonNames.
>System time zones indicates Africa/Lagos whereas the data I am trying
>to convert are Cosmic ray data prepared at different time zones
>including Oulu station (Russia), Climax station (America), many parts
>of Europe, etc.
>
>Including:
> Sys.timezone()
>str(OlsonNames())
>
>in my code gives:
>[1] "1998-01-05 02:00:00 WAT" "1998-01-05 03:00:00 WAT"
> [3] "1998-01-05 04:00:00 WAT" "1998-01-05 05:00:00 WAT"
> [5] "1998-01-05 06:00:00 WAT" "1998-01-05 07:00:00 WAT"
> [7] "1998-01-05 08:00:00 WAT" "1998-01-05 09:00:00 WAT"
> [9] "1998-01-05 10:00:00 WAT" "1998-01-05 11:00:00 WAT"
>[11] "1998-01-05 12:00:00 WAT" "1998-01-05 13:00:00 WAT"
>[13] "1998-01-05 14:00:00 WAT" "1998-01-05 15:00:00 WAT"
>[15] "1998-01-05 16:00:00 WAT" "1998-01-05 17:00:00 WAT"
>[17] "1998-01-05 18:00:00 WAT" "1998-01-05 19:00:00 WAT"
>[19] "1998-01-05 20:00:00 WAT" "1998-01-05 21:00:00 WAT"
>[21] "1998-01-05 22:00:00 WAT" "1998-01-05 23:00:00 WAT"
>[23] "1998-01-06 00:00:00 WAT" "1998-01-06 01:00:00 WAT"
>[25] "1998-01-06 02:00:00 WAT" "1998-01-06 03:00:00 WAT"
>[27] "1998-01-06 04:00:00 WAT" "1998-01-06 05:00:00 WAT"
>[29] "1998-01-06 06:00:00 WAT"
>
>Replacing the two lines above with:
>Sys.setenv( TZ="" )
>gives:
>[1] "1998-01-05 02:00:00 UTC" "1998-01-05 03:00:00 UTC"
> [3] "1998-01-05 04:00:00 UTC" "1998-01-05 05:00:00 UTC"
> [5] "1998-01-05 06:00:00 UTC" "1998-01-05 07:00:00 UTC"
> [7] "1998-01-05 08:00:00 UTC" "1998-01-05 09:00:00 UTC"
> [9] "1998-01-05 10:00:00 UTC" "1998-01-05 11:00:00 UTC"
>[11] "1998-01-05 12:00:00 UTC" "1998-01-05 13:00:00 UTC"
>[13] "1998-01-05 14:00:00 UTC" "1998-01-05 15:00:00 UTC"
>[15] "1998-01-05 16:00:00 UTC" "1998-01-05 17:00:00 UTC"
>[17] "1998-01-05 18:00:00 UTC" "1998-01-05 19:00:00 UTC"
>[19] "1998-01-05 20:00:00 UTC" "1998-01-05 21:00:00 UTC"
>[21] "1998-01-05 22:00:00 UTC" "1998-01-05 23:00:00 UTC"
>[23] "1998-01-06 00:00:00 UTC" "1998-01-06 01:00:00 UTC"
>[25] "1998-01-06 02:00:00 UTC" "1998-01-06 03:00:00 UTC"
>[27] "1998-01-06 04:00:00 UTC" "1998-01-06 05:00:00 UTC"
>[29] "1998-01-06 06:00:00 UTC"
>
>All these are still not correct and I am yet longing for further help.
>
>Best regards
>Ogbos
>
>On Wed, Jan 8, 2020 at 4:22 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>
>> In your first email you said you were using
>>
>> Sys.setenv( TZ="GMT" )
>>
>> in your code, which defines the default assumption for time
>conversion timezone (at least until you change it). Keep in mind that
>you may be dealing with data from other timezones than your local one
>that the operating system uses, so the OS timezone only gets used if TZ
>is blank (and even that behavior can be OS-dependent I think).
>>
>> Read
>>
>> ?OlsonNames
>>
>> because AEST may not be a valid specification for TZ.
>>
>> On January 8, 2020 4:09:01 AM PST, Ogbos Okike
><giftedlife2014 at gmail.com> wrote:
>> >Dear Jim,
>> >In order to check whether I have a correct time on my system, I run:
>> >$ timedatectl
>> >
>> > and it gives:
>> >Local time: Wed 2020-01-08 13:03:44 WAT
>> >                  Universal time: Wed 2020-01-08 12:03:44 UTC
>> >                        RTC time: Wed 2020-01-08 12:03:44
>> >                       Time zone: Africa/Lagos (WAT, +0100)
>> >       System clock synchronized: yes
>> >systemd-timesyncd.service active: yes
>> >                 RTC in local TZ: no.
>> >
>> >The time is correct as it agrees with the system time.
>> >
>> >I don't know if there are other things I need to change.
>> >
>> >Thank you for any suggestions.
>> >Ogbos
>> >
>> >On Wed, Jan 8, 2020 at 12:55 PM Ogbos Okike
><giftedlife2014 at gmail.com>
>> >wrote:
>> >>
>> >> Dear Jim,
>> >> Thank you for coming my assist me.
>> >> I have tried all you suggested but the same result keep coming.
>> >> I tried, for example:
>> >> dta <- read.table("Ohr1may98", col.names = c("year", "month",
>"day",
>> >> "hour", "counts"))
>> >>
>> >> dta$year <- with( dta, ifelse(year < 50, year + 2000, year +
>1900))
>> >> dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>> >>  "%Y %m %d %H")
>> >> a =  dta$date
>> >> and obtained:
>> >> > a
>> >>  [1] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
>> >>  [3] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
>> >>  [5] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
>> >>  [7] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
>> >>  [9] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
>> >> [11] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
>> >> [13] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
>> >> [15] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
>> >> [17] "1998-01-06 06:00:00 GMT"
>> >>
>> >> Instead of getting AEST as in your own result, mine remains GMT.
>> >>
>> >> I think the problem is coming from my system or location, I am not
>> >sure.
>> >>
>> >> Please have a look again and advise further.
>> >>
>> >> Thank you.
>> >>
>> >> On Wed, Jan 8, 2020 at 11:05 AM Jim Lemon <drjimlemon at gmail.com>
>> >wrote:
>> >> >
>> >> > Hi again,
>> >> > Small typo, should be
>> >> >
>> >> > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>> >> >  "%Y %m %d %H"
>> >> >
>> >> > as I tried it both with and without the century just to check
>and
>> >> > copied the wrong line.
>> >> >
>> >> > On Wed, Jan 8, 2020 at 9:03 PM Jim Lemon <drjimlemon at gmail.com>
>> >wrote:
>> >> > >
>> >> > > Hi Ogbos,
>> >> > > I get the correct result using strptime:
>> >> > >
>> >> > > dta$date<-strptime(paste(dta$year,dta$month,dta$day,dta$hour),
>> >> > >  "%y %m %d %H"
>> >> > > )
>> >> > > > dta$date
>> >> > > [1] "1998-05-01 02:00:00 AEST" "1998-05-01 03:00:00 AEST"
>> >> > > [3] "1998-05-01 04:00:00 AEST" "1998-05-01 05:00:00 AEST"
>> >> > > [5] "1998-05-01 06:00:00 AEST" "1998-05-01 07:00:00 AEST"
>> >> > > [7] "1998-05-01 08:00:00 AEST" "1998-05-01 09:00:00 AEST"
>> >> > > [9] "1998-05-01 10:00:00 AEST" "1998-05-01 11:00:00 AEST"
>> >> > > [11] "1998-05-01 12:00:00 AEST" "1998-05-01 13:00:00 AEST"
>> >> > > [13] "1998-05-01 14:00:00 AEST" "1998-05-01 15:00:00 AEST"
>> >> > > [15] "1998-05-01 16:00:00 AEST" "1998-05-01 17:00:00 AEST"
>> >> > > [17] "1998-05-01 18:00:00 AEST" "1998-05-01 19:00:00 AEST"
>> >> > > [19] "1998-05-01 20:00:00 AEST" "1998-05-01 21:00:00 AEST"
>> >> > > [21] "1998-05-01 22:00:00 AEST" "1998-05-01 23:00:00 AEST"
>> >> > > [23] "1998-05-02 00:00:00 AEST" "1998-05-02 01:00:00 AEST"
>> >> > > [25] "1998-05-02 02:00:00 AEST" "1998-05-02 03:00:00 AEST"
>> >> > > [27] "1998-05-02 04:00:00 AEST" "1998-05-02 05:00:00 AEST"
>> >> > > [29] "1998-05-02 06:00:00 AEST"
>> >> > >
>> >> > > Same result with
>> >> > >
>> >> > > ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT")
>> >> > >
>>
>>as.POSIXct(ISOdatetime(dta$year,dta$month,dta$day,dta$hour,0,0,tz="GMT"))
>> >> > >
>> >> > > As it should be as the lower two call strptime. I can't see
>from
>> >your
>> >> > > code why the month and day are transcribed.
>> >> > >
>> >> > > Jim
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jan  8 19:52:00 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 8 Jan 2020 12:52:00 -0600
Subject: [R] editing plot
Message-ID: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>

Hello,

I have this plot in attach. I was wondering how can I change my
plotting code in order to remove these gray horizontal background
lines but keep these two vertical lines? These two vertical lines
don't need to be gray, can be any other type of lines but they must be
at the same place. Also how can I make these two bars narrower?

library("ggplot2")
p<-ggplot(data=toplot, aes(x=cat, y=props)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
                position=position_dodge(.9))  +

  geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
                               c("All SNPs", "eQTL from 103 genes")),
              y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
= 0.0012", "p = 0.0023")) +
  scale_y_continuous(breaks=seq(0,.06,by=.01)) +
  xlab("") + ylab("Proportion p-values < 0.05") +
  theme_minimal()
p

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-01-08 at 12.51.34 PM.png
Type: image/png
Size: 66461 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200108/a744e6e0/attachment.png>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jan  8 20:14:01 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 8 Jan 2020 13:14:01 -0600
Subject: [R] editing plot
In-Reply-To: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
References: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
Message-ID: <CAF9-5jNSJ9w0PTW6i9bjhHaw6fkWVYO4pQWxy0O2aO8-vWGw=g@mail.gmail.com>

I used width=0.5, to reduce bar widths and aspect.ratio = 2/1 to
reduce white spaces between bars but now text on my x axis is
overlapping and my plot is too elongated, and I don't have those 3
vertical lines trough bars.

Please advise

p<-ggplot(data=toplot, aes(x=cat, y=props)) +
  geom_bar(stat="identity",width=0.5, fill="steelblue")+
  geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
                position=position_dodge(.9))  +

  geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
                               c("All SNPs", "eQTL from 103 genes")),
              y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
= 0.0012", "p = 0.0023")) +
  scale_y_continuous(breaks=seq(0,.06,by=.01)) +
  xlab("") + ylab("Proportion p-values < 0.05") +
  theme(aspect.ratio = 2/1,axis.title.x=element_text(size=1,face="bold"))
p

On Wed, Jan 8, 2020 at 12:52 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have this plot in attach. I was wondering how can I change my
> plotting code in order to remove these gray horizontal background
> lines but keep these two vertical lines? These two vertical lines
> don't need to be gray, can be any other type of lines but they must be
> at the same place. Also how can I make these two bars narrower?
>
> library("ggplot2")
> p<-ggplot(data=toplot, aes(x=cat, y=props)) +
>   geom_bar(stat="identity", fill="steelblue")+
>   geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
>                 position=position_dodge(.9))  +
>
>   geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
>                                c("All SNPs", "eQTL from 103 genes")),
>               y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> = 0.0012", "p = 0.0023")) +
>   scale_y_continuous(breaks=seq(0,.06,by=.01)) +
>   xlab("") + ylab("Proportion p-values < 0.05") +
>   theme_minimal()
> p


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jan  8 20:38:54 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 8 Jan 2020 13:38:54 -0600
Subject: [R] editing plot
In-Reply-To: <CAF9-5jNSJ9w0PTW6i9bjhHaw6fkWVYO4pQWxy0O2aO8-vWGw=g@mail.gmail.com>
References: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
 <CAF9-5jNSJ9w0PTW6i9bjhHaw6fkWVYO4pQWxy0O2aO8-vWGw=g@mail.gmail.com>
Message-ID: <CAF9-5jOYRRwd7gQtrCi=-XGVf9h+3+yTbj+onF7DnoZjm-vvuw@mail.gmail.com>

I made some progress with this:
ax.11.text <- element_text(size = 10)
ay.11.text <- element_text(size = 10)
p<-ggplot(data=toplot, aes(x=cat, y=props)) +
  geom_bar(stat="identity",width=0.5, fill="steelblue")+
  geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
                position=position_dodge(.9))  +

  geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
                               c("All SNPs", "eQTL from 103 genes")),
              y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
= 0.0012", "p = 0.0023")) +
  scale_y_continuous(breaks=seq(0,.06,by=.01)) +
  xlab("") + ylab("Proportion p-values < 0.05") +
  theme_classic()+
  theme(aspect.ratio = 2/1,axis.text.x = ax.11.text,axis.text.y=ay.11.text)
p

But the spaces between ticks on y axis are too big and the plot is
very elongated. Any advice on how to shrink this vertically?



On Wed, Jan 8, 2020 at 1:14 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> I used width=0.5, to reduce bar widths and aspect.ratio = 2/1 to
> reduce white spaces between bars but now text on my x axis is
> overlapping and my plot is too elongated, and I don't have those 3
> vertical lines trough bars.
>
> Please advise
>
> p<-ggplot(data=toplot, aes(x=cat, y=props)) +
>   geom_bar(stat="identity",width=0.5, fill="steelblue")+
>   geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
>                 position=position_dodge(.9))  +
>
>   geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
>                                c("All SNPs", "eQTL from 103 genes")),
>               y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> = 0.0012", "p = 0.0023")) +
>   scale_y_continuous(breaks=seq(0,.06,by=.01)) +
>   xlab("") + ylab("Proportion p-values < 0.05") +
>   theme(aspect.ratio = 2/1,axis.title.x=element_text(size=1,face="bold"))
> p
>
> On Wed, Jan 8, 2020 at 12:52 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have this plot in attach. I was wondering how can I change my
> > plotting code in order to remove these gray horizontal background
> > lines but keep these two vertical lines? These two vertical lines
> > don't need to be gray, can be any other type of lines but they must be
> > at the same place. Also how can I make these two bars narrower?
> >
> > library("ggplot2")
> > p<-ggplot(data=toplot, aes(x=cat, y=props)) +
> >   geom_bar(stat="identity", fill="steelblue")+
> >   geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
> >                 position=position_dodge(.9))  +
> >
> >   geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
> >                                c("All SNPs", "eQTL from 103 genes")),
> >               y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> > = 0.0012", "p = 0.0023")) +
> >   scale_y_continuous(breaks=seq(0,.06,by=.01)) +
> >   xlab("") + ylab("Proportion p-values < 0.05") +
> >   theme_minimal()
> > p

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-01-08 at 1.36.25 PM.png
Type: image/png
Size: 107228 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200108/9b3ce359/attachment.png>

From e@ @end|ng |rom enr|co@chum@nn@net  Wed Jan  8 21:50:25 2020
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 08 Jan 2020 21:50:25 +0100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <CAC8ss33G4dUYCt+8P4BjvwMq8_2uNRu7mftXb69FEPq=ZKUqCQ@mail.gmail.com>
 (Ogbos Okike's message of "Wed, 8 Jan 2020 17:43:29 +0100")
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <20200108130753.Horde.RHAvO4E8QS_x6tjm3m7NeiS@webmail.your-server.de>
 <CAC8ss33G4dUYCt+8P4BjvwMq8_2uNRu7mftXb69FEPq=ZKUqCQ@mail.gmail.com>
Message-ID: <87a76xbrla.fsf@enricoschumann.net>

>>>>> On Wed, 8 Jan 2020 17:43:29 +0100, Ogbos Okike <giftedlife2014 at gmail.com> writes:

  Ogbos> Dear Enrico,
  Ogbos> Thanks for your time.
  Ogbos> I have tried to learn how to use dput in R. I have not yet made much progress.

  Ogbos> I have succeeded in using dput to store my data frame. I first
  Ogbos> converted my data into a data frame and then used:
  Ogbos> dput(dd,file="Ogbos2",control = c("keepNA", "keepInteger",
  Ogbos> "showAttributes")) to output the dput file. dd is my data frame.

  Ogbos> When I opened the file, I didn't like its content as it differs very
  Ogbos> much from my data frame. But I don't know whether that makes sense to
  Ogbos> you. I am attaching the file.
  Ogbos> I am thanking you in advance for additional suggestions.
  Ogbos> Best wishes
  Ogbos> Ogbos

Hello Ogbos

your attempt worked fine: this is the data you sent


    dta <- structure(list(dta.year = c(98L, 98L, 98L, 98L, 98L, 98L, 98L, 
      98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 
      98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L), dta.month = c(1L, 
      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), dta.day = c(5L, 
      5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
      5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), dta.hour = c(2L, 
      3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
      17L, 18L, 19L, 20L, 21L, 22L, 23L, 0L, 1L, 2L, 3L, 4L, 5L, 6L
      ), dta.counts = c(6462L, 6450L, 6423L, 6467L, 6480L, 6457L, 6417L, 
      6467L, 6467L, 6468L, 6500L, 6482L, 6465L, 6465L, 6475L, 6452L, 
      6440L, 6478L, 6470L, 6422L, 6448L, 6462L, 6485L, 6462L, 6485L, 
      6470L, 6487L, 6515L, 6488L)), .Names = c("dta.year", "dta.month", 
      "dta.day", "dta.hour", "dta.counts"), row.names = c(NA, -29L),
      class = "data.frame")

But then:

  head(dta)
  ##   dta.year dta.month dta.day dta.hour dta.counts
  ## 1       98         1       5        2       6462
  ## 2       98         1       5        3       6450
  ## 3       98         1       5        4       6423
  ## 4       98         1       5        5       6467
  ## 5       98         1       5        6       6480
  ## 6       98         1       5        7       6457

The data that you read in has January (1) as month.
So whatever goes wrong, seems to go wrong when you read
the data.  Are you quite sure you read the file you
read is the file you have shown?


kind regards
    Enrico

  Ogbos> On Wed, Jan 8, 2020 at 1:07 PM Enrico Schumann <es at enricoschumann.net> wrote:
  >> 
  >> 
  >> Quoting Ogbos Okike <giftedlife2014 at gmail.com>:
  >> 
  >> > Dear Friends,
  >> > A sample of my data is:
  >> > 98 05 01 02    8541
  >> > 98 05 01 03    8548
  >> > 98 05 01 04    8512
  >> > 98 05 01 05    8541
  >> > 98 05 01 06    8509
  >> > 98 05 01 07    8472
  >> > 98 05 01 08    8454
  >> > 98 05 01 09    8461
  >> > 98 05 01 10    8462
  >> > 98 05 01 11    8475
  >> > 98 05 01 12    8433
  >> > 98 05 01 13    8479
  >> > 98 05 01 14    8417
  >> > 98 05 01 15    8463
  >> > 98 05 01 16    8473
  >> > 98 05 01 17    8450
  >> > 98 05 01 18    8433
  >> > 98 05 01 19    8437
  >> > 98 05 01 20    8437
  >> > 98 05 01 21    8438
  >> > 98 05 01 22    8421
  >> > 98 05 01 23    8420
  >> > 98 05 02 00    8371
  >> > 98 05 02 01    8338
  >> > 98 05 02 02    8251
  >> > 98 05 02 03    8204
  >> > 98 05 02 04    8183
  >> > 98 05 02 05    8231
  >> > 98 05 02 06    8242
  >> > Columns 1, 2, 3, 4 and 5 stands for year, month, day , hour and count.
  >> >
  >> > Using:
  >> > Sys.setenv( TZ="GMT" )
  >> >
  >> >
  >> > dta <- read.table("Ohr1may98", col.names = c("year", "month", "day",
  >> > "hour", "counts"))
  >> > dta$year <- with( dta, ifelse(year < 50, year + 2000, year + 1900))
  >> > dta$datetime <- with( dta, as.POSIXct(ISOdatetime(year, month,day,hour,0,0)))
  >> > a =  dta$datetime
  >> > I converted the datetime and plotted the graph of count vs a. The plot
  >> > was great but I have issues with the date.
  >> >
  >> > The raw data is for some hours for Ist and second day of may 1998 as
  >> > is evident from the sample data. But the result of date stored in "a"
  >> > above shows:
  >> >> a
  >> >  [1] "1998-01-05 02:00:00 GMT" "1998-01-05 03:00:00 GMT"
  >> >  [3] "1998-01-05 04:00:00 GMT" "1998-01-05 05:00:00 GMT"
  >> >  [5] "1998-01-05 06:00:00 GMT" "1998-01-05 07:00:00 GMT"
  >> >  [7] "1998-01-05 08:00:00 GMT" "1998-01-05 09:00:00 GMT"
  >> >  [9] "1998-01-05 10:00:00 GMT" "1998-01-05 11:00:00 GMT"
  >> > [11] "1998-01-05 12:00:00 GMT" "1998-01-05 13:00:00 GMT"
  >> > [13] "1998-01-05 14:00:00 GMT" "1998-01-05 15:00:00 GMT"
  >> > [15] "1998-01-05 16:00:00 GMT" "1998-01-05 17:00:00 GMT"
  >> > [17] "1998-01-05 18:00:00 GMT" "1998-01-05 19:00:00 GMT"
  >> > [19] "1998-01-05 20:00:00 GMT" "1998-01-05 21:00:00 GMT"
  >> > [21] "1998-01-05 22:00:00 GMT" "1998-01-05 23:00:00 GMT"
  >> > [23] "1998-01-06 00:00:00 GMT" "1998-01-06 01:00:00 GMT"
  >> > [25] "1998-01-06 02:00:00 GMT" "1998-01-06 03:00:00 GMT"
  >> > [27] "1998-01-06 04:00:00 GMT" "1998-01-06 05:00:00 GMT"
  >> > [29] "1998-01-06 06:00:00 GMT"
  >> > This seems to suggest day 5 and 6 in January 1998 instead of day 1 and
  >> > 2 in May of 1998.
  >> >
  >> > I have spent some time trying to resolve this but I have not been successful.
  >> >
  >> > I would be thankful if you could help me to check where I went astray.
  >> >
  >> > Thank you.
  >> > Best wishes
  >> > Ogbos
  >> >
  >> 
  >> I cannot reproduce these results. Could you please provide a fully
  >> reproducible example, by providing a small example dataset via 'dput(dta)'?
  >> 
  >> 
  >> --
  >> Enrico Schumann
  >> Lucerne, Switzerland
  >> http://enricoschumann.net
  >> 

  Ogbos> structure(list(dta.year = c(98L, 98L, 98L, 98L, 98L, 98L, 98L, 
  Ogbos> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 
  Ogbos> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L), dta.month = c(1L, 
  Ogbos> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
  Ogbos> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), dta.day = c(5L, 
  Ogbos> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
  Ogbos> 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), dta.hour = c(2L, 
  Ogbos> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
  Ogbos> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 0L, 1L, 2L, 3L, 4L, 5L, 6L
  Ogbos> ), dta.counts = c(6462L, 6450L, 6423L, 6467L, 6480L, 6457L, 6417L, 
  Ogbos> 6467L, 6467L, 6468L, 6500L, 6482L, 6465L, 6465L, 6475L, 6452L, 
  Ogbos> 6440L, 6478L, 6470L, 6422L, 6448L, 6462L, 6485L, 6462L, 6485L, 
  Ogbos> 6470L, 6487L, 6515L, 6488L)), .Names = c("dta.year", "dta.month", 
  Ogbos> "dta.day", "dta.hour", "dta.counts"), row.names = c(NA, -29L), class = "data.frame")


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jan  8 21:58:07 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 8 Jan 2020 20:58:07 +0000
Subject: [R] editing plot
In-Reply-To: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
References: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
Message-ID: <134d3ec4-8c52-1cf2-fbc2-bbc662a2db9b@sapo.pt>

Hello,

Maybe


theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
         panel.grid.major.y = element_blank(),
         panel.grid.minor = element_blank()
   )



Note that if you remove the y axis grid you must set the x axis grid 
explicitly.

Hope this helps,

Rui Barradas

?s 18:52 de 08/01/20, Ana Marija escreveu:
> Hello,
> 
> I have this plot in attach. I was wondering how can I change my
> plotting code in order to remove these gray horizontal background
> lines but keep these two vertical lines? These two vertical lines
> don't need to be gray, can be any other type of lines but they must be
> at the same place. Also how can I make these two bars narrower?
> 
> library("ggplot2")
> p<-ggplot(data=toplot, aes(x=cat, y=props)) +
>    geom_bar(stat="identity", fill="steelblue")+
>    geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
>                  position=position_dodge(.9))  +
> 
>    geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
>                                 c("All SNPs", "eQTL from 103 genes")),
>                y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> = 0.0012", "p = 0.0023")) +
>    scale_y_continuous(breaks=seq(0,.06,by=.01)) +
>    xlab("") + ylab("Proportion p-values < 0.05") +
>    theme_minimal()
> p
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan  8 22:17:23 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 9 Jan 2020 08:17:23 +1100
Subject: [R] Incorrect Conversion of Datetime
In-Reply-To: <87a76xbrla.fsf@enricoschumann.net>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <20200108130753.Horde.RHAvO4E8QS_x6tjm3m7NeiS@webmail.your-server.de>
 <CAC8ss33G4dUYCt+8P4BjvwMq8_2uNRu7mftXb69FEPq=ZKUqCQ@mail.gmail.com>
 <87a76xbrla.fsf@enricoschumann.net>
Message-ID: <CA+8X3fWCDNiTcSTwCcvnWcbX__B6+k5bJxF4of8iA1C4_2Cg_g@mail.gmail.com>

Enrico seems to have found the problem - you can't change dates much
by changing the time zone, but transposing month and day will do the
trick nicely. The mm/dd/yyyy format and others like it are so common
that you always have to be on the lookout for it. Is the sample data
you included in your first email taken from the file you are reading
in? When I read in that sample data the correct result was returned. I
would open the original file in a text editor, read the data in using
your commands and then:

head(dta)

and compare what appears with the original file. You may see the
problem straightaway.

Jim


On Thu, Jan 9, 2020 at 7:50 AM Enrico Schumann <es at enricoschumann.net> wrote:
> ...
> The data that you read in has January (1) as month.
> So whatever goes wrong, seems to go wrong when you read
> the data.  Are you quite sure you read the file you
> read is the file you have shown?
>


From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jan  9 03:20:07 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 9 Jan 2020 03:20:07 +0100
Subject: [R] Incorrect Conversion of Datetime: Fixed
In-Reply-To: <CA+8X3fWCDNiTcSTwCcvnWcbX__B6+k5bJxF4of8iA1C4_2Cg_g@mail.gmail.com>
References: <CAC8ss32gjr1LRh=LbyPiLkuOZ0SNGMWvqEfb3Sei=Li288y4eQ@mail.gmail.com>
 <20200108130753.Horde.RHAvO4E8QS_x6tjm3m7NeiS@webmail.your-server.de>
 <CAC8ss33G4dUYCt+8P4BjvwMq8_2uNRu7mftXb69FEPq=ZKUqCQ@mail.gmail.com>
 <87a76xbrla.fsf@enricoschumann.net>
 <CA+8X3fWCDNiTcSTwCcvnWcbX__B6+k5bJxF4of8iA1C4_2Cg_g@mail.gmail.com>
Message-ID: <CAC8ss32Q7CTpkOf=KQEOVfjzjaA+X9uysq+sDHb_ZP7eK0kPoQ@mail.gmail.com>

Dear ALL,
I am really happy. Erinco has pointed out the error.

Out of the the 5 stations'  Cosmic ray data I am staking together to
show some similar effects, I wrongly (and I am sorry for taking your
time) copied one of the dates, including January 1, 1998 instead of
May.
Others were correct and it will never occur to me, except for the keen
eye of Erinco, that the problem is from any of the data.

This singular correction has also changed my plot and all the
attendant analysis.
Thank you all for your kind suggestions.
Warmest regards
Ogbos
On Wed, Jan 8, 2020 at 10:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Enrico seems to have found the problem - you can't change dates much
> by changing the time zone, but transposing month and day will do the
> trick nicely. The mm/dd/yyyy format and others like it are so common
> that you always have to be on the lookout for it. Is the sample data
> you included in your first email taken from the file you are reading
> in? When I read in that sample data the correct result was returned. I
> would open the original file in a text editor, read the data in using
> your commands and then:
>
> head(dta)
>
> and compare what appears with the original file. You may see the
> problem straightaway.
>
> Jim
>
>
> On Thu, Jan 9, 2020 at 7:50 AM Enrico Schumann <es at enricoschumann.net> wrote:
> > ...
> > The data that you read in has January (1) as month.
> > So whatever goes wrong, seems to go wrong when you read
> > the data.  Are you quite sure you read the file you
> > read is the file you have shown?
> >


From |uc@@p@@@@|@cqu@ @end|ng |rom un|rom@1@|t  Thu Jan  9 10:18:01 2020
From: |uc@@p@@@@|@cqu@ @end|ng |rom un|rom@1@|t (Luca Passalacqua)
Date: Thu, 9 Jan 2020 10:18:01 +0100
Subject: [R] .Random.seed for the Mersenne Twister
Message-ID: <CAGHVBE6Yk+EAMCcOPYd5_TmwtOTMjAszrMVuxN1mt87+o27C1Q@mail.gmail.com>

Dear R users,

 inspecting  .Random.seed for the Mersenne Twister (MT) I find (many)
negative values for the
624 values of the initial state of the generator.
It seems to me that this is a bug (an unsigned integer mapped to a signed
integer ?),
since, to my understanding, the R version of MT should be working with
32-bits unsigned long.
Moreover, this prevents starting the generator by setting .Random.seed to
user provided
values.
Could someone please provide some insight to this issue ?
Many thanks,

Luca Passalacqua


> RNGkind('default')> RNGkind()[1] "Mersenne-Twister" "Inversion"       > set.seed(1)> .Random.seed  [1]         403         624  -169270483  -442010614  -603558397  ...



-- 
Luca Passalacqua
Department of Statistics
University of Rome "La Sapienza"
Viale Regina Elena, 295
00161 Rome (Italy)
luca.passalacqua at uniroma1.it

-- 
________________________________________________________
Le informazioni 
contenute in questo messaggio di posta elettronica sono strettamente 
riservate e indirizzate esclusivamente al destinatario. Si prega di non 
leggere, fare copia, inoltrare a terzi o conservare tale messaggio se non 
si ? il legittimo destinatario dello stesso. Qualora tale messaggio sia 
stato ricevuto per errore, si prega di restituirlo al mittente e di 
cancellarlo permanentemente dal proprio computer.

The information 
contained in this e mail message is strictly confidential and intended for
the use of the addressee only.? If you are not the intended recipient,
please do not read, copy, forward or store it on your computer. If you have
received the message in error, please forward it back to the sender and 
delete it permanently from your computer system.

	[[alternative HTML version deleted]]


From he|mut@@chuetz @end|ng |rom beb@c@@t  Thu Jan  9 12:20:52 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Thu, 9 Jan 2020 12:20:52 +0100
Subject: [R] R-help Digest, Vol 203, Issue 8
In-Reply-To: <mailman.357336.1.1578567601.49117.r-help@r-project.org>
References: <mailman.357336.1.1578567601.49117.r-help@r-project.org>
Message-ID: <c50cad39-419f-38ae-7daf-ba738f15822f@bebac.at>

Dear Hans,

r-help-request at r-project.org wrote on 2020-01-09 12:00:
> Date: Wed, 8 Jan 2020 12:09:55 +0100
> From: Hans W Borchers <hwborchers at gmail.com>
> To: R help project <r-help at r-project.org>
> Subject: [R] Which external functions are called in a package?
> 	[Solved]
>
> NB: `trapz`, ie.
> the trapezoidal integration formula, seems to be the numerical
> function to be missed the most in R base.

In R base indeed. However available in Frank Harrels Hmisc as the 
function trap.rule(x, y) for sorted values.
In plain R: function(x, y) sum(diff(x) * (y[-1] + y[-length(y)]))/2

Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
W https://bebac.at/
F https://forum.bebac.at/


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan  9 16:40:09 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Jan 2020 07:40:09 -0800
Subject: [R] .Random.seed for the Mersenne Twister
In-Reply-To: <CAGHVBE6Yk+EAMCcOPYd5_TmwtOTMjAszrMVuxN1mt87+o27C1Q@mail.gmail.com>
References: <CAGHVBE6Yk+EAMCcOPYd5_TmwtOTMjAszrMVuxN1mt87+o27C1Q@mail.gmail.com>
Message-ID: <47BC7988-9E4B-4AF5-8153-7AB08B6DEB34@dcn.davis.ca.us>

I am no expert on this specific algorithm, but there is no "32-bit unsigned integer" type in R. Presumably the interpretation of those negative numbers in the C code is as if they were unsigned while R presents them as if they were signed because it cannot do otherwise.

AFAIK you need to use set.seed to configure .Random.seed, and you can retrieve and later restore the vectors created this way in the future. As I understand it there exist invalid vectors that cannot arbitrarily be used by this algorithm so generating them yourself is at the very least hard, and possibly could break in future versions of R.

On January 9, 2020 1:18:01 AM PST, Luca Passalacqua via R-help <r-help at r-project.org> wrote:
>Dear R users,
>
> inspecting  .Random.seed for the Mersenne Twister (MT) I find (many)
>negative values for the
>624 values of the initial state of the generator.
>It seems to me that this is a bug (an unsigned integer mapped to a
>signed
>integer ?),
>since, to my understanding, the R version of MT should be working with
>32-bits unsigned long.
>Moreover, this prevents starting the generator by setting .Random.seed
>to
>user provided
>values.
>Could someone please provide some insight to this issue ?
>Many thanks,
>
>Luca Passalacqua
>
>
>> RNGkind('default')> RNGkind()[1] "Mersenne-Twister" "Inversion"      
>> set.seed(1)> .Random.seed  [1]         403         624  -169270483 
>-442010614  -603558397  ...

-- 
Sent from my phone. Please excuse my brevity.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan  9 17:43:20 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 9 Jan 2020 10:43:20 -0600
Subject: [R] editing plot
In-Reply-To: <CAF9-5jMODczsdhWLFsaAgMwvbe4h3OT2=P0F4hOX67g1ueRSuA@mail.gmail.com>
References: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
 <134d3ec4-8c52-1cf2-fbc2-bbc662a2db9b@sapo.pt>
 <CAF9-5jMODczsdhWLFsaAgMwvbe4h3OT2=P0F4hOX67g1ueRSuA@mail.gmail.com>
Message-ID: <CAF9-5jOkD4qM39Cc5Cv7P2wJNFRHg50ib=ZmL503zp1RfUaq5w@mail.gmail.com>

HI Rui,

Thank you so much for getting back to me!
I did implement your idea (see attach):

ax.11.text <- element_text(size = 10)
ay.11.text <- element_text(size = 10)
p<-ggplot(data=toplot, aes(x=cat, y=props)) +
  geom_bar(stat="identity",width=0.5, fill="steelblue")+
  geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
                position=position_dodge(.9))  +

  geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
                               c("All SNPs", "eQTL from 103 genes")),
              y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
= 0.0012", "p = 0.0023")) +
  scale_y_continuous(breaks=seq(0,.06,by=.01)) +
  xlab("") + ylab("Proportion p-values < 0.05") +
  theme_classic()+
  theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank(),axis.text.x =
ax.11.text,axis.text.y=ay.11.text
  )
p

I was wondering is there is any way to decrease the amount of white
spaces around the bars?

Thanks
Ana

On Thu, Jan 9, 2020 at 10:41 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> HI Rui,
>
> Thank you so much for getting back to me!
> I did implement your idea (see attach):
>
> ax.11.text <- element_text(size = 10)
> ay.11.text <- element_text(size = 10)
> p<-ggplot(data=toplot, aes(x=cat, y=props)) +
>   geom_bar(stat="identity",width=0.5, fill="steelblue")+
>   geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
>                 position=position_dodge(.9))  +
>
>   geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
>                                c("All SNPs", "eQTL from 103 genes")),
>               y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> = 0.0012", "p = 0.0023")) +
>   scale_y_continuous(breaks=seq(0,.06,by=.01)) +
>   xlab("") + ylab("Proportion p-values < 0.05") +
>   theme_classic()+
>   theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
>         panel.grid.major.y = element_blank(),
>         panel.grid.minor = element_blank(),axis.text.x =
> ax.11.text,axis.text.y=ay.11.text
>   )
> p
>
> I was wondering is there is any way to decrease the amount of white
> spaces around the bars?
>
> Thanks
> Ana
>
> On Wed, Jan 8, 2020 at 2:58 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Maybe
> >
> >
> > theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
> >          panel.grid.major.y = element_blank(),
> >          panel.grid.minor = element_blank()
> >    )
> >
> >
> >
> > Note that if you remove the y axis grid you must set the x axis grid
> > explicitly.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 18:52 de 08/01/20, Ana Marija escreveu:
> > > Hello,
> > >
> > > I have this plot in attach. I was wondering how can I change my
> > > plotting code in order to remove these gray horizontal background
> > > lines but keep these two vertical lines? These two vertical lines
> > > don't need to be gray, can be any other type of lines but they must be
> > > at the same place. Also how can I make these two bars narrower?
> > >
> > > library("ggplot2")
> > > p<-ggplot(data=toplot, aes(x=cat, y=props)) +
> > >    geom_bar(stat="identity", fill="steelblue")+
> > >    geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
> > >                  position=position_dodge(.9))  +
> > >
> > >    geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
> > >                                 c("All SNPs", "eQTL from 103 genes")),
> > >                y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> > > = 0.0012", "p = 0.0023")) +
> > >    scale_y_continuous(breaks=seq(0,.06,by=.01)) +
> > >    xlab("") + ylab("Proportion p-values < 0.05") +
> > >    theme_minimal()
> > > p
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-01-09 at 10.42.17 AM.png
Type: image/png
Size: 67901 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200109/3cf8b31d/attachment.png>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan  9 17:41:16 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 9 Jan 2020 10:41:16 -0600
Subject: [R] editing plot
In-Reply-To: <134d3ec4-8c52-1cf2-fbc2-bbc662a2db9b@sapo.pt>
References: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
 <134d3ec4-8c52-1cf2-fbc2-bbc662a2db9b@sapo.pt>
Message-ID: <CAF9-5jMODczsdhWLFsaAgMwvbe4h3OT2=P0F4hOX67g1ueRSuA@mail.gmail.com>

HI Rui,

Thank you so much for getting back to me!
I did implement your idea (see attach):

ax.11.text <- element_text(size = 10)
ay.11.text <- element_text(size = 10)
p<-ggplot(data=toplot, aes(x=cat, y=props)) +
  geom_bar(stat="identity",width=0.5, fill="steelblue")+
  geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
                position=position_dodge(.9))  +

  geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
                               c("All SNPs", "eQTL from 103 genes")),
              y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
= 0.0012", "p = 0.0023")) +
  scale_y_continuous(breaks=seq(0,.06,by=.01)) +
  xlab("") + ylab("Proportion p-values < 0.05") +
  theme_classic()+
  theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank(),axis.text.x =
ax.11.text,axis.text.y=ay.11.text
  )
p

I was wondering is there is any way to decrease the amount of white
spaces around the bars?

Thanks
Ana

On Wed, Jan 8, 2020 at 2:58 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Maybe
>
>
> theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
>          panel.grid.major.y = element_blank(),
>          panel.grid.minor = element_blank()
>    )
>
>
>
> Note that if you remove the y axis grid you must set the x axis grid
> explicitly.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 18:52 de 08/01/20, Ana Marija escreveu:
> > Hello,
> >
> > I have this plot in attach. I was wondering how can I change my
> > plotting code in order to remove these gray horizontal background
> > lines but keep these two vertical lines? These two vertical lines
> > don't need to be gray, can be any other type of lines but they must be
> > at the same place. Also how can I make these two bars narrower?
> >
> > library("ggplot2")
> > p<-ggplot(data=toplot, aes(x=cat, y=props)) +
> >    geom_bar(stat="identity", fill="steelblue")+
> >    geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
> >                  position=position_dodge(.9))  +
> >
> >    geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
> >                                 c("All SNPs", "eQTL from 103 genes")),
> >                y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> > = 0.0012", "p = 0.0023")) +
> >    scale_y_continuous(breaks=seq(0,.06,by=.01)) +
> >    xlab("") + ylab("Proportion p-values < 0.05") +
> >    theme_minimal()
> > p
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-01-09 at 10.38.42 AM.png
Type: image/png
Size: 123326 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200109/bf069bd7/attachment.png>

From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Thu Jan  9 18:17:48 2020
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Thu, 9 Jan 2020 18:17:48 +0100
Subject: [R] .Random.seed for the Mersenne Twister
In-Reply-To: <47BC7988-9E4B-4AF5-8153-7AB08B6DEB34@dcn.davis.ca.us>
References: <CAGHVBE6Yk+EAMCcOPYd5_TmwtOTMjAszrMVuxN1mt87+o27C1Q@mail.gmail.com>
 <47BC7988-9E4B-4AF5-8153-7AB08B6DEB34@dcn.davis.ca.us>
Message-ID: <0abc192c-d5e6-2e81-ba50-3c43a259fe42@statistik.tu-dortmund.de>

Exactly, from ?.Random.seed:

"In the underlying C, .Random.seed[-1] is unsigned; therefore in R 
.Random.seed[-1] can be negative, due to the representation of an 
unsigned integer by a signed integer. "

and

"It can be saved and restored, but should not be altered by the user. "

Best,
Uwe Ligges


On 09.01.2020 16:40, Jeff Newmiller wrote:
> I am no expert on this specific algorithm, but there is no "32-bit unsigned integer" type in R. Presumably the interpretation of those negative numbers in the C code is as if they were unsigned while R presents them as if they were signed because it cannot do otherwise.
> 
> AFAIK you need to use set.seed to configure .Random.seed, and you can retrieve and later restore the vectors created this way in the future. As I understand it there exist invalid vectors that cannot arbitrarily be used by this algorithm so generating them yourself is at the very least hard, and possibly could break in future versions of R.
> 
> On January 9, 2020 1:18:01 AM PST, Luca Passalacqua via R-help <r-help at r-project.org> wrote:
>> Dear R users,
>>
>> inspecting  .Random.seed for the Mersenne Twister (MT) I find (many)
>> negative values for the
>> 624 values of the initial state of the generator.
>> It seems to me that this is a bug (an unsigned integer mapped to a
>> signed
>> integer ?),
>> since, to my understanding, the R version of MT should be working with
>> 32-bits unsigned long.
>> Moreover, this prevents starting the generator by setting .Random.seed
>> to
>> user provided
>> values.
>> Could someone please provide some insight to this issue ?
>> Many thanks,
>>
>> Luca Passalacqua
>>
>>
>>> RNGkind('default')> RNGkind()[1] "Mersenne-Twister" "Inversion"
>>> set.seed(1)> .Random.seed  [1]         403         624  -169270483
>> -442010614  -603558397  ...
>


From n@m@t|o|| @end|ng |rom ucd@v|@@edu  Thu Jan  9 19:53:04 2020
From: n@m@t|o|| @end|ng |rom ucd@v|@@edu (Norm Matloff)
Date: Thu, 9 Jan 2020 10:53:04 -0800
Subject: [R] issue with Rcmdr
In-Reply-To: <mailman.357336.1.1578567601.49117.r-help@r-project.org>
References: <mailman.357336.1.1578567601.49117.r-help@r-project.org>
Message-ID: <20200109185304.GC3369@laura>


> Message: 14
> Date: Wed, 8 Jan 2020 09:59:56 -0800
> From: Bert Gunter <bgunter.4567 at gmail.com>
> To: Norm Matloff <nsmatloff at ucdavis.edu>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] issue with Rcmdr
 
> ... and even more generally, is generally misleading. ;-)
 
> (search "problems with R^2" or similar for why).
 
> Bert Gunter

I was addressing the OP's issue of computing R^2.  Its value in analysis
is a separate question.  If one's goal is prediction, it arguably is
fairly good providing we avoid overfitting.  If our goal is inference,
R^2 still is informative, but limited.

Norm


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jan 10 02:57:37 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Jan 2020 17:57:37 -0800
Subject: [R] Fwd: Re:  .Random.seed for the Mersenne Twister
In-Reply-To: <A146FB46-5A7B-429C-B571-3F1B6E084D67@dcn.davis.ca.us>
References: <A146FB46-5A7B-429C-B571-3F1B6E084D67@dcn.davis.ca.us>
Message-ID: <AE5B06EE-D217-4A7F-8ADA-7C9C64787907@dcn.davis.ca.us>

Forgot to cc list.


-------- Original Message --------
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: January 9, 2020 2:10:00 PM PST
To: Luca Passalacqua <luca.passalacqua at uniroma1.it>
Subject: Re: [R] .Random.seed for the Mersenne Twister

No information is lost. Thirty-two "one" bits is equally valid when viewed as a -1L in R or as 4294967295 as a uint32 in C. If you need to enter unsigned int 4294967295 into memory using R code for the benefit of some C code, use -1L instead.

If you read the help file recommended by Uwe you will see that the seed vector is the RNG kind value followed by the current position followed by 624 values ("MT").

Be warned that other stochastc functions in R (like rnorm) can add their own algorithms on top of the basic RNG... reproducing others' calculations may require that you re-implement some functionality the way the original authors did it to get the same results.

RNGkind('default')
RNGkind()
#[1] "Mersenne-Twister" "Inversion"      
set.seed(1)
x <- .Random.seed
before <- runif(5)
head(x)
m1 <- 2^31-1
m2 <- 2^32
dput(x[1:2])
index <- x[2]
MT <- as.double( x[-(1:2)] )
MTu <- MT
neg <- MT < 0
MTu[neg] <- MTu[neg] + m2
MT[1:20]
MTu[1:20]
MTs <- MTu
neg2 <- m1 < MTu
MTs[neg2] <- MTs[neg2] - m2
x2 <- c(403L,index,as.integer(MTs))
head(x2)
.Random.seed <- x2
after <- runif(5)
before==after

On January 9, 2020 9:43:22 AM PST, Luca Passalacqua <luca.passalacqua at uniroma1.it> wrote:
>Dear Jeff and Uwe,
>
>  thanks for your kind answers. Restoring works (see below),
>but I do not understand how, since in mapping from unsigned
>to signed, information is lost, and you cannot go back from
>signed to unsigned.
>
>The reason I would like to alter the initial state is that R is
>initialing
>the seed
>with an algorithm different from that used by the MT authors, but I
>would like to use the "original" seed to reproduce their results.
>
>> set.seed(1)
>> s0 = .Random.seed
>> s0[1:10]
> [1]        403        624 -169270483 -442010614 -603558397 -222347416
>1489374793  865871222 1734802815   98005428
>
>> runif(5)
>[1] 0.2655087 0.3721239 0.5728534 0.9082078 0.2016819
>
>> runif(5)
>[1] 0.89838968 0.94467527 0.66079779 0.62911404 0.06178627
>
>> .Random.seed = s0
>> runif(5)
>[1] 0.2655087 0.3721239 0.5728534 0.9082078 0.2016819
>
>Luca
>
>Il giorno gio 9 gen 2020 alle ore 16:44 Jeff Newmiller <
>jdnewmil at dcn.davis.ca.us> ha scritto:
>
>> I am no expert on this specific algorithm, but there is no "32-bit
>> unsigned integer" type in R. Presumably the interpretation of those
>> negative numbers in the C code is as if they were unsigned while R
>presents
>> them as if they were signed because it cannot do otherwise.
>>
>> AFAIK you need to use set.seed to configure .Random.seed, and you can
>> retrieve and later restore the vectors created this way in the
>future. As I
>> understand it there exist invalid vectors that cannot arbitrarily be
>used
>> by this algorithm so generating them yourself is at the very least
>hard,
>> and possibly could break in future versions of R.
>>
>> On January 9, 2020 1:18:01 AM PST, Luca Passalacqua via R-help <
>> r-help at r-project.org> wrote:
>> >Dear R users,
>> >
>> > inspecting  .Random.seed for the Mersenne Twister (MT) I find
>(many)
>> >negative values for the
>> >624 values of the initial state of the generator.
>> >It seems to me that this is a bug (an unsigned integer mapped to a
>> >signed
>> >integer ?),
>> >since, to my understanding, the R version of MT should be working
>with
>> >32-bits unsigned long.
>> >Moreover, this prevents starting the generator by setting
>.Random.seed
>> >to
>> >user provided
>> >values.
>> >Could someone please provide some insight to this issue ?
>> >Many thanks,
>> >
>> >Luca Passalacqua
>> >
>> >
>> >> RNGkind('default')> RNGkind()[1] "Mersenne-Twister" "Inversion"
>> >> set.seed(1)> .Random.seed  [1]         403         624  -169270483
>> >-442010614  -603558397  ...
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.
-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan 10 06:22:13 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 10 Jan 2020 05:22:13 +0000
Subject: [R] R-help Digest, Vol 203, Issue 8
In-Reply-To: <c50cad39-419f-38ae-7daf-ba738f15822f@bebac.at>
References: <mailman.357336.1.1578567601.49117.r-help@r-project.org>
 <c50cad39-419f-38ae-7daf-ba738f15822f@bebac.at>
Message-ID: <6e21d9be-1fc1-0fef-5934-6bd21b96a5c9@sapo.pt>

Hello,

And there's also


#
# library(caTools)
# Author(s)
# Jarek Tuszynski <jaroslaw.w.tuszynski at saic.com>
#
# Original
trapz <- function(x, y){
     idx = 2:length(x)
     return(as.double( (x[idx] - x[idx-1]) %*% (y[idx] + y[idx-1]) ) / 2)
}

# Modified by me, input is x, f(x)
trapzf <- function(x, FUN) trapz(x, FUN(x))
# Call like 'integrate'
trapzf2 <- function(f, lower, upper, subdivisions = 100){
     trapzf(seq(lower, upper, length.out = subdivisions), match.fun(f))
}



So I guess it's not missing, just missing in base R, like the OP said.

Hope this helps,

Rui Barradas

?s 11:20 de 09/01/20, Helmut Sch?tz escreveu:
> Dear Hans,
> 
> r-help-request at r-project.org wrote on 2020-01-09 12:00:
>> Date: Wed, 8 Jan 2020 12:09:55 +0100
>> From: Hans W Borchers <hwborchers at gmail.com>
>> To: R help project <r-help at r-project.org>
>> Subject: [R] Which external functions are called in a package?
>> ????[Solved]
>>
>> NB: `trapz`, ie.
>> the trapezoidal integration formula, seems to be the numerical
>> function to be missed the most in R base.
> 
> In R base indeed. However available in Frank Harrels Hmisc as the 
> function trap.rule(x, y) for sorted values.
> In plain R: function(x, y) sum(diff(x) * (y[-1] + y[-length(y)]))/2
> 
> Helmut
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan 10 13:58:51 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 10 Jan 2020 12:58:51 +0000
Subject: [R] editing plot
In-Reply-To: <CAF9-5jMODczsdhWLFsaAgMwvbe4h3OT2=P0F4hOX67g1ueRSuA@mail.gmail.com>
References: <CAF9-5jNOqZg8paLLcJgeYzCnuk4uHuqfC=vzhknOrbvZgscFjQ@mail.gmail.com>
 <134d3ec4-8c52-1cf2-fbc2-bbc662a2db9b@sapo.pt>
 <CAF9-5jMODczsdhWLFsaAgMwvbe4h3OT2=P0F4hOX67g1ueRSuA@mail.gmail.com>
Message-ID: <a3b21b77-f424-032b-216e-2963d9f0242d@sapo.pt>

Hello,

There are ways of reducing the white space between the bars but they are 
not obvious. Here are the two ways that I know.

First a data example.

library(ggplot2)
library(gridExtra)

df1 <- data.frame(x = LETTERS[1:5],
                   y = c(40, 15, 30, 15, 20))


1. The examples that follow set argument width in two places. What is 
important is the relative magnitudes of width and position_dodge(width).

If width is bigger than position_dodge(width) then the bar sizes and the 
space between them do not change. They only change if the second width 
is bigger. In this case the first argument makes a difference. Run the 
examples to see what I mean.


g1 <- ggplot(df1, aes(x, y)) +
   geom_bar(stat = "identity",
            width = 0.8,
            position = position_dodge(width = 0.5))

g2 <- ggplot(df1, aes(x, y)) +
   geom_bar(stat = "identity",
            width = 0.8,
            position = position_dodge(width = 0.25))

g3 <- ggplot(df1, aes(x, y)) +
   geom_bar(stat = "identity",
            width = 0.5,
            position = position_dodge(width = 0.8))

g4 <- ggplot(df1, aes(x, y)) +
   geom_bar(stat = "identity",
            width = 0.25,
            position = position_dodge(width = 0.8))

grid.arrange(g31, g2, g3, g4)


2. The other way is to shrink the plot by changing its aspect ratio.

g3 + theme(aspect.ratio = 2/1)

grid.arrange(g3, g3 + theme(aspect.ratio = 2/1), nrow = 1)


Run the examples and try to do something out of this.


Hope this helps,

Rui Barradas


?s 16:41 de 09/01/20, Ana Marija escreveu:
> HI Rui,
> 
> Thank you so much for getting back to me!
> I did implement your idea (see attach):
> 
> ax.11.text <- element_text(size = 10)
> ay.11.text <- element_text(size = 10)
> p<-ggplot(data=toplot, aes(x=cat, y=props)) +
>    geom_bar(stat="identity",width=0.5, fill="steelblue")+
>    geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.1,
>                  position=position_dodge(.9))  +
> 
>    geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
>                                 c("All SNPs", "eQTL from 103 genes")),
>                y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
> = 0.0012", "p = 0.0023")) +
>    scale_y_continuous(breaks=seq(0,.06,by=.01)) +
>    xlab("") + ylab("Proportion p-values < 0.05") +
>    theme_classic()+
>    theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
>          panel.grid.major.y = element_blank(),
>          panel.grid.minor = element_blank(),axis.text.x =
> ax.11.text,axis.text.y=ay.11.text
>    )
> p
> 
> I was wondering is there is any way to decrease the amount of white
> spaces around the bars?
> 
> Thanks
> Ana
> 
> On Wed, Jan 8, 2020 at 2:58 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Maybe
>>
>>
>> theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
>>           panel.grid.major.y = element_blank(),
>>           panel.grid.minor = element_blank()
>>     )
>>
>>
>>
>> Note that if you remove the y axis grid you must set the x axis grid
>> explicitly.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 18:52 de 08/01/20, Ana Marija escreveu:
>>> Hello,
>>>
>>> I have this plot in attach. I was wondering how can I change my
>>> plotting code in order to remove these gray horizontal background
>>> lines but keep these two vertical lines? These two vertical lines
>>> don't need to be gray, can be any other type of lines but they must be
>>> at the same place. Also how can I make these two bars narrower?
>>>
>>> library("ggplot2")
>>> p<-ggplot(data=toplot, aes(x=cat, y=props)) +
>>>     geom_bar(stat="identity", fill="steelblue")+
>>>     geom_errorbar(aes(ymin=props-1.96*ses, ymax=props+1.96*ses), width=.2,
>>>                   position=position_dodge(.9))  +
>>>
>>>     geom_signif(comparisons=list( c("All eQTL", "eQTL from 103 genes"),
>>>                                  c("All SNPs", "eQTL from 103 genes")),
>>>                 y_position=c(0.065, 0.07), tip_length=0, annotation=c("p
>>> = 0.0012", "p = 0.0023")) +
>>>     scale_y_continuous(breaks=seq(0,.06,by=.01)) +
>>>     xlab("") + ylab("Proportion p-values < 0.05") +
>>>     theme_minimal()
>>> p
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From herd_dog @end|ng |rom cox@net  Fri Jan 10 19:31:58 2020
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Fri, 10 Jan 2020 11:31:58 -0700
Subject: [R] Data Carpentry - Creating a New SQLite Database
Message-ID: <98708B7EAC63468A8C75E46108693E91@OWNERPC>

Working my way through a tutorial named Data Carpentry (https://datacarpentry.org/R-ecology-lesson/).  for the most part it is excellent but I?m stuck on the very last section (https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html).

First, below are the packages I have loaded:
[1] "forcats"   "stringr"   "purrr"     "readr"     "tidyr"     "tibble"    "ggplot2"   "tidyverse" "dbplyr"    "RMySQL"    "DBI"      
[12] "dplyr"     "RSQLite"   "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
 
     
            >  
     

Second,
Second, is the text of the last section of the last chapter titled ?Creating a New SQLite Database?.
Second, below is the text from the tutorial.  The black type is from the tutorial.  The green and blue is the suggested R code.  My comments are in red.
Creating a new SQLite database
So far, we have used a previously prepared SQLite database. But we can also use R to create a new database, e.g. from existing csv files. Let?s recreate the mammals database that we?ve been working with, in R. First let?s download and read in the csv files. We?ll import tidyverse to gain access to the read_csv() function.

download.file("https://ndownloader.figshare.com/files/3299483",
              "data_raw/species.csv")
download.file("https://ndownloader.figshare.com/files/10717177",
              "data_raw/surveys.csv")
download.file("https://ndownloader.figshare.com/files/3299474",
              "data_raw/plots.csv")
library(tidyverse)
species <- read_csv("data_raw/species.csv")No problem here.  I?m pulling three databases from the Web and saving them to a folder on my hard drive. (...data_raw/species.csv) etc.surveys <- read_csv("data_raw/surveys.csv") plots <- read_csv("data_raw/plots.csv")Again no problem.  I?m just creating an R data files.  But here is where I loose it.  I?m creating something named my_db_file from another file named portal-database-output with an sqlite extension and then creating my_db from the My_db_file.  Not sure where the sqlite extension file came from. Creating a new SQLite database with dplyr is easy. You can re-use the same command we used above to open an existing .sqlite file. The create = TRUE argument instructs R to create a new, empty database instead.

Caution: When create = TRUE is added, any existing database at the same location is overwritten without warning.

my_db_file <- "data/portal-database-output.sqlite"
my_db <- src_sqlite(my_db_file, create = TRUE)Currently, our new database is empty, it doesn?t contain any tables:

my_db#> src:  sqlite 3.29.0 [data/portal-database-output.sqlite]
#> tbls:To add tables, we copy the existing data.frames into the database one by one:

copy_to(my_db, surveys)
copy_to(my_db, plots)
my_dbI can follow the directions to fill in my_db but I have no idea how to access the tables.  The text from the tutorial below says to check the location of our database.  Huh!  Can someone give me some direction.  Thanks.





If you check the location of our database you?ll see that data is automatically being written to disk. R and dplyr not only provide easy ways to query existing databases, they also allows you to easily create your own databases from flat files!



Here is where I loose it.  

    
	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Jan 10 21:44:16 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 10 Jan 2020 23:44:16 +0300
Subject: [R] Data Carpentry - Creating a New SQLite Database
In-Reply-To: <98708B7EAC63468A8C75E46108693E91@OWNERPC>
References: <98708B7EAC63468A8C75E46108693E91@OWNERPC>
Message-ID: <20200110234416.59f75bab@Tarkus>

On Fri, 10 Jan 2020 11:31:58 -0700
"Phillip Heinrich" <herd_dog at cox.net> wrote:

> below is the text from the tutorial.  The black type is from the
> tutorial.  The green and blue is the suggested R code.  My comments
> are in red

R-help is a plain text mailing list, so the markup has been stripped
off (and since HTML-enabled mail clients don't quite care how the plain
text version of the e-mail looks, some paragraph breaks had to go, too).

> etc.surveys <- read_csv("data_raw/surveys.csv")
> plots <- read_csv("data_raw/plots.csv")

> Again no problem.  I?m just creating an R data files.

Note that it is not files that you are creating by running read_csv(),
but variables (of type "tibble", which is like "data.frame", either of
which should have been covered in earlier chapters in a good tutorial)
in the R environment. The files you downloaded previously are opened
in read only mode and are never changed.

> my_db_file <- "data/portal-database-output.sqlite"

> I?m creating something named my_db_file from another file named
> portal-database-output with an sqlite extension and then creating
> my_db from the My_db_file.

This something is just a text string that happens to contain a *path*
to a file. Just like the variable `greeting` in the following snippet:

greeting <- "Hello world"
print(greeting)

See [1] for more info on character vectors in R.

> Not sure where the sqlite extension file came from.

The authors of the tutorial decided that the file to be created should
be named like this. Feel free to change the extension (or the path) to
anything else: neither R, nor SQLite cares about it much (but the file
manager you use may display a different icon for it or become confused
if you name it .txt or .pdf).

> I can follow the directions to fill in my_db but I have no idea
> how to access the tables.

What exactly do you mean by "access"? At this point my_db should be a
dplyr "src" object, so the tools described in dplyr vignettes [2] should
be applicable. Try calling tbl() on it and passing the name of one of
the tables you have just created. Also try running:

example("src_sqlite")

> The text from the tutorial below says to check the location of our
> database.  Huh!  Can someone give me some direction.

The variable my_db_file contains the location of the file where the
database is stored. This is the same variable that you passed to the
src_sqlite() function.

-- 
Best regards,
Ivan

[1]
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Character-vectors

[2]
https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html
https://cran.r-project.org/web/packages/dplyr/vignettes/programming.html
https://cran.r-project.org/web/packages/dplyr/vignettes/two-table.html
https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan 10 22:23:48 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 10 Jan 2020 13:23:48 -0800
Subject: [R] Data Carpentry - Creating a New SQLite Database
In-Reply-To: <98708B7EAC63468A8C75E46108693E91@OWNERPC>
References: <98708B7EAC63468A8C75E46108693E91@OWNERPC>
Message-ID: <CAGxFJbQvnAWvU7D+iG65vNhPBR8bU+gUE1LwQbiLxfA2G5-9Jw@mail.gmail.com>

Please note that tidyverse packages have their own support resources at
RStudio, whence they came; e.g. here:
https://education.rstudio.com/learn/beginner/
You may also do better asking about issues that concern them at their
support site:  https://support.rstudio.com/hc/en-us
 though, as you already found out, there are folks here who may help also.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 10, 2020 at 10:32 AM Phillip Heinrich <herd_dog at cox.net> wrote:

> Working my way through a tutorial named Data Carpentry (
> https://datacarpentry.org/R-ecology-lesson/).  for the most part it is
> excellent but I?m stuck on the very last section (
> https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html).
>
> First, below are the packages I have loaded:
> [1] "forcats"   "stringr"   "purrr"     "readr"     "tidyr"     "tibble"
>   "ggplot2"   "tidyverse" "dbplyr"    "RMySQL"    "DBI"
> [12] "dplyr"     "RSQLite"   "stats"     "graphics"  "grDevices" "utils"
>    "datasets"  "methods"   "base"
>
>
>             >
>
>
> Second,
> Second, is the text of the last section of the last chapter titled
> ?Creating a New SQLite Database?.
> Second, below is the text from the tutorial.  The black type is from the
> tutorial.  The green and blue is the suggested R code.  My comments are in
> red.
> Creating a new SQLite database
> So far, we have used a previously prepared SQLite database. But we can
> also use R to create a new database, e.g. from existing csv files. Let?s
> recreate the mammals database that we?ve been working with, in R. First
> let?s download and read in the csv files. We?ll import tidyverse to gain
> access to the read_csv() function.
>
> download.file("https://ndownloader.figshare.com/files/3299483",
>               "data_raw/species.csv")
> download.file("https://ndownloader.figshare.com/files/10717177",
>               "data_raw/surveys.csv")
> download.file("https://ndownloader.figshare.com/files/3299474",
>               "data_raw/plots.csv")
> library(tidyverse)
> species <- read_csv("data_raw/species.csv")No problem here.  I?m pulling
> three databases from the Web and saving them to a folder on my hard drive.
> (...data_raw/species.csv) etc.surveys <- read_csv("data_raw/surveys.csv")
> plots <- read_csv("data_raw/plots.csv")Again no problem.  I?m just creating
> an R data files.  But here is where I loose it.  I?m creating something
> named my_db_file from another file named portal-database-output with an
> sqlite extension and then creating my_db from the My_db_file.  Not sure
> where the sqlite extension file came from. Creating a new SQLite database
> with dplyr is easy. You can re-use the same command we used above to open
> an existing .sqlite file. The create = TRUE argument instructs R to create
> a new, empty database instead.
>
> Caution: When create = TRUE is added, any existing database at the same
> location is overwritten without warning.
>
> my_db_file <- "data/portal-database-output.sqlite"
> my_db <- src_sqlite(my_db_file, create = TRUE)Currently, our new database
> is empty, it doesn?t contain any tables:
>
> my_db#> src:  sqlite 3.29.0 [data/portal-database-output.sqlite]
> #> tbls:To add tables, we copy the existing data.frames into the database
> one by one:
>
> copy_to(my_db, surveys)
> copy_to(my_db, plots)
> my_dbI can follow the directions to fill in my_db but I have no idea how
> to access the tables.  The text from the tutorial below says to check the
> location of our database.  Huh!  Can someone give me some direction.
> Thanks.
>
>
>
>
>
> If you check the location of our database you?ll see that data is
> automatically being written to disk. R and dplyr not only provide easy ways
> to query existing databases, they also allows you to easily create your own
> databases from flat files!
>
>
>
> Here is where I loose it.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Sat Jan 11 04:19:54 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Fri, 10 Jan 2020 19:19:54 -0800
Subject: [R] Data Carpentry - Creating a New SQLite Database
In-Reply-To: <98708B7EAC63468A8C75E46108693E91@OWNERPC>
References: <98708B7EAC63468A8C75E46108693E91@OWNERPC>
Message-ID: <CAA99HCwGb=odcjv1RozcrvZK5xp=EgFwpn739mq_xRpgaTCNRg@mail.gmail.com>

Hi Phillip,

Skipping to the last few lines of your email, did you download a
program to look at Sqlite databases (independent of R) as listed
below? Maybe that program ("DB Browser for SQLite") and/or the
instructions below can help you locate your database directory:

https://datacarpentry.org/semester-biology/computer-setup/
https://datacarpentry.org/semester-biology/materials/sql-for-dplyr-users/

If you do have that program, and you're still seeing an error, you
might consider looking for similar issues at the appropriate
'datacarpentry' repository on Github (or posting a new issue
yourself):

https://github.com/datacarpentry/R-ecology-lesson/issues

Finally, I really feel you'll benefit from reading over the documents
pertaining to "R Data Import/Export" on the www.r-project.org website.
No disrespect to the people at 'datacarpentry', but you'll find
similar (and possibly, easier) R code to follow at section 4.3.1
'Packages using DBI' :

https://cran.r-project.org/doc/manuals/r-release/R-data.html

HTH, Bill.

W. Michels, Ph.D.




On Fri, Jan 10, 2020 at 10:32 AM Phillip Heinrich <herd_dog at cox.net> wrote:
>
> Working my way through a tutorial named Data Carpentry (https://datacarpentry.org/R-ecology-lesson/).  for the most part it is excellent but I?m stuck on the very last section (https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html).
>
> First, below are the packages I have loaded:
> [1] "forcats"   "stringr"   "purrr"     "readr"     "tidyr"     "tibble"    "ggplot2"   "tidyverse" "dbplyr"    "RMySQL"    "DBI"
> [12] "dplyr"     "RSQLite"   "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"
>
>
>             >
>
>
> Second,
> Second, is the text of the last section of the last chapter titled ?Creating a New SQLite Database?.
> Second, below is the text from the tutorial.  The black type is from the tutorial.  The green and blue is the suggested R code.  My comments are in red.
> Creating a new SQLite database
> So far, we have used a previously prepared SQLite database. But we can also use R to create a new database, e.g. from existing csv files. Let?s recreate the mammals database that we?ve been working with, in R. First let?s download and read in the csv files. We?ll import tidyverse to gain access to the read_csv() function.
>
> download.file("https://ndownloader.figshare.com/files/3299483",
>               "data_raw/species.csv")
> download.file("https://ndownloader.figshare.com/files/10717177",
>               "data_raw/surveys.csv")
> download.file("https://ndownloader.figshare.com/files/3299474",
>               "data_raw/plots.csv")
> library(tidyverse)
> species <- read_csv("data_raw/species.csv")No problem here.  I?m pulling three databases from the Web and saving them to a folder on my hard drive. (...data_raw/species.csv) etc.surveys <- read_csv("data_raw/surveys.csv") plots <- read_csv("data_raw/plots.csv")Again no problem.  I?m just creating an R data files.  But here is where I loose it.  I?m creating something named my_db_file from another file named portal-database-output with an sqlite extension and then creating my_db from the My_db_file.  Not sure where the sqlite extension file came from. Creating a new SQLite database with dplyr is easy. You can re-use the same command we used above to open an existing .sqlite file. The create = TRUE argument instructs R to create a new, empty database instead.
>
> Caution: When create = TRUE is added, any existing database at the same location is overwritten without warning.
>
> my_db_file <- "data/portal-database-output.sqlite"
> my_db <- src_sqlite(my_db_file, create = TRUE)Currently, our new database is empty, it doesn?t contain any tables:
>
> my_db#> src:  sqlite 3.29.0 [data/portal-database-output.sqlite]
> #> tbls:To add tables, we copy the existing data.frames into the database one by one:
>
> copy_to(my_db, surveys)
> copy_to(my_db, plots)
> my_dbI can follow the directions to fill in my_db but I have no idea how to access the tables.  The text from the tutorial below says to check the location of our database.  Huh!  Can someone give me some direction.  Thanks.
>
>
>
>
>
> If you check the location of our database you?ll see that data is automatically being written to disk. R and dplyr not only provide easy ways to query existing databases, they also allows you to easily create your own databases from flat files!
>
>
>
> Here is where I loose it.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom @end|ng |rom d|@no|go@com  Mon Jan 13 09:03:19 2020
From: tom @end|ng |rom d|@no|go@com (Thomas Farrar)
Date: Mon, 13 Jan 2020 10:03:19 +0200
Subject: [R] [R-pkgs] Introducing skedastic: Heteroskedasticity Diagnostics
 for Linear Regression Models
Message-ID: <CAG25rBLnG23LFt_m2KP5d5TAEonZBJZZM16Ai5Qz5Br8G6rAZw@mail.gmail.com>

Dear All,

I would like to introduce the above-named new package that is now available
on CRAN: https://cran.r-project.org/web/packages/skedastic/index.html The
package features numerous 'classical' heteroskedasticity tests (some not
previously available in any published R package) as well as one very new
test that appeared in the literature only in 2019.

Feedback on bugs/issues is most welcome at
https://github.com/tjfarrar/skedastic and reviews are welcome at
crantastic: https://crantastic.org/packages/skedastic

Sincerely,
Thomas Farrar
Cape Peninsula University of Technology; University of the Western Cape

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From g@@@uu| @end|ng |rom gm@||@com  Tue Jan 14 05:53:38 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 14 Jan 2020 13:53:38 +0900
Subject: [R] Subset a data frame with specific date
Message-ID: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>

Good morning R-Help,

I have a dataframe with 7 columns and 10000+ rows. I want to subset/extract
those data frame with specific date (not in order). Here the head of my
data frame:

head(mjo30)  year month date      rmm1     rmm2 phase     amp
1 1986     1    1 -0.326480 -1.55895     2 1.59277
2 1986     1    2 -0.417700 -1.82689     2 1.87403
3 1986     1    3  0.032915 -2.40150     3 2.40172
4 1986     1    4  0.492743 -2.49216     3 2.54041
5 1986     1    5  0.585106 -2.76866     3 2.82981
6 1986     1    6  0.665013 -3.13883     3 3.20851

and here my specific date:
> date [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05" "1990-10-26" "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
[10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-16"
"2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
[19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-24"
"2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
[28] "2013-04-07" "2014-05-07" "2015-07-26"

And also I was confused when I dput my date, it show like this:
> dput(date)structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358, 8423, 9103,
9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
16197, 16642), class = "Date")

what is that mean? I mean why it is not recall the dates but some
values (5958,6369,7217,..)?

Any comment and recommendation is appreciate.  Thank you.

Best,

Ani

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 14 07:20:52 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 13 Jan 2020 22:20:52 -0800
Subject: [R] Subset a data frame with specific date
In-Reply-To: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
Message-ID: <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>

The dput function is for re-creating an R object in another R workspace, so it uses fundamental base types to define objects. A Date is really the number of days since a specific date (typically 1970-01-01) that get converted to look like dates whenever you display or print them, so what you are seiing are those numbers. If we enter the R code returned by dput into our R session we will be able to see the dates.

Your mjo30 table seems to call the day of the month the "date"... which is confusing. I would combine those three columns into one like

mjo30$Dt <- as.Date( ISOdate( mjo30$year, mjo30$month, mjo30$date ) )

You could then use indexing

mjo30[ date[1] == mjo30$Dt, ]

or

mjo30[ mjo30$Dt %in% date, ]

but the subset function would not work in this case because you have two different objects (a column in mjo30 and a vector in your global environment) both referred to as 'date'.

On January 13, 2020 8:53:38 PM PST, ani jaya <gaaauul at gmail.com> wrote:
>Good morning R-Help,
>
>I have a dataframe with 7 columns and 10000+ rows. I want to
>subset/extract
>those data frame with specific date (not in order). Here the head of my
>data frame:
>
>head(mjo30)  year month date      rmm1     rmm2 phase     amp
>1 1986     1    1 -0.326480 -1.55895     2 1.59277
>2 1986     1    2 -0.417700 -1.82689     2 1.87403
>3 1986     1    3  0.032915 -2.40150     3 2.40172
>4 1986     1    4  0.492743 -2.49216     3 2.54041
>5 1986     1    5  0.585106 -2.76866     3 2.82981
>6 1986     1    6  0.665013 -3.13883     3 3.20851
>
>and here my specific date:
>> date [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05"
>"1990-10-26" "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
>[10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-16"
>"2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
>[19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-24"
>"2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
>[28] "2013-04-07" "2014-05-07" "2015-07-26"
>
>And also I was confused when I dput my date, it show like this:
>> dput(date)structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358, 8423,
>9103,
>9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
>13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
>16197, 16642), class = "Date")
>
>what is that mean? I mean why it is not recall the dates but some
>values (5958,6369,7217,..)?
>
>Any comment and recommendation is appreciate.  Thank you.
>
>Best,
>
>Ani
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 14 07:42:22 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Jan 2020 22:42:22 -0800
Subject: [R] Subset a data frame with specific date
In-Reply-To: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
Message-ID: <CAGxFJbTvG+UuNK7Exj=uJULo9HHgcTAoAgjZkEvM6gUFXGrBpQ@mail.gmail.com>

Inline.

Bert Gunter




On Mon, Jan 13, 2020 at 8:54 PM ani jaya <gaaauul at gmail.com> wrote:

> Good morning R-Help,
>
> I have a dataframe with 7 columns and 10000+ rows. I want to subset/extract
> those data frame with specific date (not in order). Here the head of my
> data frame:
>
> head(mjo30)



> year month date      rmm1     rmm2 phase     amp
> 1 1986     1    1 -0.326480 -1.55895     2 1.59277
> 2 1986     1    2 -0.417700 -1.82689     2 1.87403
> 3 1986     1    3  0.032915 -2.40150     3 2.40172
> 4 1986     1    4  0.492743 -2.49216     3 2.54041
> 5 1986     1    5  0.585106 -2.76866     3 2.82981
> 6 1986     1    6  0.665013 -3.13883     3 3.20851
>

These are columns of numeric values. That you label them as year, month,
date is irrelevant,.

>
> and here my specific date:
> > date



> [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05" "1990-10-26"
> "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
> [10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-16"
> "2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
> [19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-24"
> "2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
> [28] "2013-04-07" "2014-05-07" "2015-07-26"
>
> This is how the print method for Date objects prints the dates. See ?Dates

And also I was confused when I dput my date, it show like this:
> > dput(date)



> structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358, 8423, 9103,
> 9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
> 13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
> 16197, 16642), class = "Date")
>

These are how objects of class date are represented internally, as
integers. See ?Dates.
Use ?str to see the structure of an object, not dput()
I think you need to go through a tutorial or two on dates in R. And
probably also on S3 methods in R.


> what is that mean? I mean why it is not recall the dates but some
> values (5958,6369,7217,..)?
>
> Any comment and recommendation is appreciate.  Thank you.
>
> Extended tutorials on these topics are inappropriate here. There are many
places they can be found on the web.
But here's an example for one simple way to do it:

> d <- as.Date("2004-10-5") ## create object of class "Date"
## This is what you want to subset with
> d  ## how they are printed
[1] "2004-10-05"
> str(d)
 Date[1:1], format: "2004-10-05"
> class(d)
[1] "Date"
> dput(d) ## the internal representation of Date objects
structure(12696, class = "Date")
>
>
> ## Now create a data frame that you want to subset with d
> df <- data.frame (year = c(2004,2005),
+       month = c(10,2),
+       date = c(5,15))
> df
  year month date
1 2004    10    5
2 2005     2   15
> ## convert to a formatted character column of dates
> alldates <- with(df,paste(year,month,date, sep ="-"))
> alldates ## vector of formatted character strings.
[1] "2004-10-5" "2005-2-15"
> class(alldates)
[1] "character"
> ## convert it to "Date" class
> alldates <- as.Date(alldates)
> class(alldates)
[1] "Date"
> ## Now use this to subset the data frame
> df[alldates %in% d, ]
  year month date
1 2004    10    5


## And please post in **plain text** not HTML in future.

Cheers,
Bert




Best,
>
> Ani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Tue Jan 14 07:56:18 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 14 Jan 2020 15:56:18 +0900
Subject: [R] Subset a data frame with specific date
In-Reply-To: <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
 <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>
Message-ID: <CAHXS41x05iN0Hk_A+Xm3pYU=bs3pCukiOJmLgsF3EYWYFSJ_Cw@mail.gmail.com>

Dear Jeff and Bert,

Thank you very much for your correction and explanation.
And yes, I need to study about date format more.
Sorry for HTML mail, don't realize.

I was able to subset the data that I want.

mjo30<-read.table("rmm.txt", header=FALSE, skip=4234, nrows=10957)
mjo30$V8<-NULL
names(mjo30)<-c("year","month","day", "rmm1","rmm2","phase","amp")
mjo3<-as.Date(with(mjo30,paste(year,month, day, sep="-")),"%Y-%m-%d")
mjo<-mjo30[which(mjo3%in%date),]

head(mjo)
     year month day      rmm1      rmm2 phase      amp
115  1986     4  25 -0.319090 -0.363030     2 0.483332
526  1987     6  10  1.662870  0.291632     5 1.688250
977  1988     9   3 -0.604950 -0.299850     1 0.675181
1374 1989    10   5  0.972298 -0.461030     4 1.076060
1760 1990    10  26 -1.183110 -1.589810     2 1.981730
1953 1991     5   7 -0.317180  0.953061     7 1.004450


Best,
Ani


On Tue, Jan 14, 2020 at 3:20 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> The dput function is for re-creating an R object in another R workspace, so it uses fundamental base types to define objects. A Date is really the number of days since a specific date (typically 1970-01-01) that get converted to look like dates whenever you display or print them, so what you are seiing are those numbers. If we enter the R code returned by dput into our R session we will be able to see the dates.
>
> Your mjo30 table seems to call the day of the month the "date"... which is confusing. I would combine those three columns into one like
>
> mjo30$Dt <- as.Date( ISOdate( mjo30$year, mjo30$month, mjo30$date ) )
>
> You could then use indexing
>
> mjo30[ date[1] == mjo30$Dt, ]
>
> or
>
> mjo30[ mjo30$Dt %in% date, ]
>
> but the subset function would not work in this case because you have two different objects (a column in mjo30 and a vector in your global environment) both referred to as 'date'.
>
> On January 13, 2020 8:53:38 PM PST, ani jaya <gaaauul at gmail.com> wrote:
> >Good morning R-Help,
> >
> >I have a dataframe with 7 columns and 10000+ rows. I want to
> >subset/extract
> >those data frame with specific date (not in order). Here the head of my
> >data frame:
> >
> >head(mjo30)  year month date      rmm1     rmm2 phase     amp
> >1 1986     1    1 -0.326480 -1.55895     2 1.59277
> >2 1986     1    2 -0.417700 -1.82689     2 1.87403
> >3 1986     1    3  0.032915 -2.40150     3 2.40172
> >4 1986     1    4  0.492743 -2.49216     3 2.54041
> >5 1986     1    5  0.585106 -2.76866     3 2.82981
> >6 1986     1    6  0.665013 -3.13883     3 3.20851
> >
> >and here my specific date:
> >> date [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05"
> >"1990-10-26" "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
> >[10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-16"
> >"2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
> >[19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-24"
> >"2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
> >[28] "2013-04-07" "2014-05-07" "2015-07-26"
> >
> >And also I was confused when I dput my date, it show like this:
> >> dput(date)structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358, 8423,
> >9103,
> >9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
> >13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
> >16197, 16642), class = "Date")
> >
> >what is that mean? I mean why it is not recall the dates but some
> >values (5958,6369,7217,..)?
> >
> >Any comment and recommendation is appreciate.  Thank you.
> >
> >Best,
> >
> >Ani
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From g@@@uu| @end|ng |rom gm@||@com  Tue Jan 14 08:00:45 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 14 Jan 2020 16:00:45 +0900
Subject: [R] Subset a data frame with specific date
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
 <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>
 <CAHXS41x05iN0Hk_A+Xm3pYU=bs3pCukiOJmLgsF3EYWYFSJ_Cw@mail.gmail.com>
Message-ID: <CAHXS41yA_OoiH2g-1ihD32XrCh-AyCjmLcswMQkzOf5uQxgOoQ@mail.gmail.com>

Dear Jeff and Bert,

Thank you for your correction and explanation.
Yes, I need more study regarding date format and
sorry for HTML mail.

I was able to subset data that I want.

mjo30<-read.table("rmm.txt", header=FALSE, skip=4234, nrows=10957)
mjo30$V8<-NULL
names(mjo30)<-c("year","month","day", "rmm1","rmm2","phase","amp")
mjo3<-as.Date(with(mjo30,paste(year,month, day, sep="-")),"%Y-%m-%d")
mjo<-mjo30[which(mjo3%in%date),]

head(mjo)
     year month day      rmm1      rmm2 phase      amp
115  1986     4  25 -0.319090 -0.363030     2 0.483332
526  1987     6  10  1.662870  0.291632     5 1.688250
977  1988     9   3 -0.604950 -0.299850     1 0.675181
1374 1989    10   5  0.972298 -0.461030     4 1.076060
1760 1990    10  26 -1.183110 -1.589810     2 1.981730
1953 1991     5   7 -0.317180  0.953061     7 1.004450

Best,
Ani

On Tue, Jan 14, 2020 at 3:56 PM ani jaya <gaaauul at gmail.com> wrote:
>
>


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 14 08:10:27 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Jan 2020 23:10:27 -0800
Subject: [R] Subset a data frame with specific date
In-Reply-To: <CAHXS41x05iN0Hk_A+Xm3pYU=bs3pCukiOJmLgsF3EYWYFSJ_Cw@mail.gmail.com>
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
 <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>
 <CAHXS41x05iN0Hk_A+Xm3pYU=bs3pCukiOJmLgsF3EYWYFSJ_Cw@mail.gmail.com>
Message-ID: <CAGxFJbRJ+8AJp2Cuu4z+hS8vP6KJ8oCWC8jgebk5PbkN+JwuGw@mail.gmail.com>

That's fine, but do note that the which() function is wholly unnecessary in
your last line as R allows logical indexing. Perhaps another topic you need
to study.

-- Bert



On Mon, Jan 13, 2020 at 10:56 PM ani jaya <gaaauul at gmail.com> wrote:

> Dear Jeff and Bert,
>
> Thank you very much for your correction and explanation.
> And yes, I need to study about date format more.
> Sorry for HTML mail, don't realize.
>
> I was able to subset the data that I want.
>
> mjo30<-read.table("rmm.txt", header=FALSE, skip=4234, nrows=10957)
> mjo30$V8<-NULL
> names(mjo30)<-c("year","month","day", "rmm1","rmm2","phase","amp")
> mjo3<-as.Date(with(mjo30,paste(year,month, day, sep="-")),"%Y-%m-%d")
> mjo<-mjo30[which(mjo3%in%date),]
>
> head(mjo)
>      year month day      rmm1      rmm2 phase      amp
> 115  1986     4  25 -0.319090 -0.363030     2 0.483332
> 526  1987     6  10  1.662870  0.291632     5 1.688250
> 977  1988     9   3 -0.604950 -0.299850     1 0.675181
> 1374 1989    10   5  0.972298 -0.461030     4 1.076060
> 1760 1990    10  26 -1.183110 -1.589810     2 1.981730
> 1953 1991     5   7 -0.317180  0.953061     7 1.004450
>
>
> Best,
> Ani
>
>
> On Tue, Jan 14, 2020 at 3:20 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > The dput function is for re-creating an R object in another R workspace,
> so it uses fundamental base types to define objects. A Date is really the
> number of days since a specific date (typically 1970-01-01) that get
> converted to look like dates whenever you display or print them, so what
> you are seiing are those numbers. If we enter the R code returned by dput
> into our R session we will be able to see the dates.
> >
> > Your mjo30 table seems to call the day of the month the "date"... which
> is confusing. I would combine those three columns into one like
> >
> > mjo30$Dt <- as.Date( ISOdate( mjo30$year, mjo30$month, mjo30$date ) )
> >
> > You could then use indexing
> >
> > mjo30[ date[1] == mjo30$Dt, ]
> >
> > or
> >
> > mjo30[ mjo30$Dt %in% date, ]
> >
> > but the subset function would not work in this case because you have two
> different objects (a column in mjo30 and a vector in your global
> environment) both referred to as 'date'.
> >
> > On January 13, 2020 8:53:38 PM PST, ani jaya <gaaauul at gmail.com> wrote:
> > >Good morning R-Help,
> > >
> > >I have a dataframe with 7 columns and 10000+ rows. I want to
> > >subset/extract
> > >those data frame with specific date (not in order). Here the head of my
> > >data frame:
> > >
> > >head(mjo30)  year month date      rmm1     rmm2 phase     amp
> > >1 1986     1    1 -0.326480 -1.55895     2 1.59277
> > >2 1986     1    2 -0.417700 -1.82689     2 1.87403
> > >3 1986     1    3  0.032915 -2.40150     3 2.40172
> > >4 1986     1    4  0.492743 -2.49216     3 2.54041
> > >5 1986     1    5  0.585106 -2.76866     3 2.82981
> > >6 1986     1    6  0.665013 -3.13883     3 3.20851
> > >
> > >and here my specific date:
> > >> date [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05"
> > >"1990-10-26" "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
> > >[10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-16"
> > >"2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
> > >[19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-24"
> > >"2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
> > >[28] "2013-04-07" "2014-05-07" "2015-07-26"
> > >
> > >And also I was confused when I dput my date, it show like this:
> > >> dput(date)structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358, 8423,
> > >9103,
> > >9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
> > >13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
> > >16197, 16642), class = "Date")
> > >
> > >what is that mean? I mean why it is not recall the dates but some
> > >values (5958,6369,7217,..)?
> > >
> > >Any comment and recommendation is appreciate.  Thank you.
> > >
> > >Best,
> > >
> > >Ani
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Tue Jan 14 08:47:23 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 14 Jan 2020 16:47:23 +0900
Subject: [R] Subset a data frame with specific date
In-Reply-To: <CAGxFJbRJ+8AJp2Cuu4z+hS8vP6KJ8oCWC8jgebk5PbkN+JwuGw@mail.gmail.com>
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
 <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>
 <CAHXS41x05iN0Hk_A+Xm3pYU=bs3pCukiOJmLgsF3EYWYFSJ_Cw@mail.gmail.com>
 <CAGxFJbRJ+8AJp2Cuu4z+hS8vP6KJ8oCWC8jgebk5PbkN+JwuGw@mail.gmail.com>
Message-ID: <CAHXS41x2p=imT0oaEp-Gce+biQCtjP-s5wOMugxXCZ1M7VaOpw@mail.gmail.com>

Thank you Bert.
And yes another topic to study.

On Tue, Jan 14, 2020 at 4:10 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> That's fine, but do note that the which() function is wholly unnecessary in your last line as R allows logical indexing. Perhaps another topic you need to study.
>
> -- Bert
>
>
>
> On Mon, Jan 13, 2020 at 10:56 PM ani jaya <gaaauul at gmail.com> wrote:
>>
>> Dear Jeff and Bert,
>>
>> Thank you very much for your correction and explanation.
>> And yes, I need to study about date format more.
>> Sorry for HTML mail, don't realize.
>>
>> I was able to subset the data that I want.
>>
>> mjo30<-read.table("rmm.txt", header=FALSE, skip=4234, nrows=10957)
>> mjo30$V8<-NULL
>> names(mjo30)<-c("year","month","day", "rmm1","rmm2","phase","amp")
>> mjo3<-as.Date(with(mjo30,paste(year,month, day, sep="-")),"%Y-%m-%d")
>> mjo<-mjo30[which(mjo3%in%date),]
>>
>> head(mjo)
>>      year month day      rmm1      rmm2 phase      amp
>> 115  1986     4  25 -0.319090 -0.363030     2 0.483332
>> 526  1987     6  10  1.662870  0.291632     5 1.688250
>> 977  1988     9   3 -0.604950 -0.299850     1 0.675181
>> 1374 1989    10   5  0.972298 -0.461030     4 1.076060
>> 1760 1990    10  26 -1.183110 -1.589810     2 1.981730
>> 1953 1991     5   7 -0.317180  0.953061     7 1.004450
>>
>>
>> Best,
>> Ani
>>
>>
>> On Tue, Jan 14, 2020 at 3:20 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> >
>> > The dput function is for re-creating an R object in another R workspace, so it uses fundamental base types to define objects. A Date is really the number of days since a specific date (typically 1970-01-01) that get converted to look like dates whenever you display or print them, so what you are seiing are those numbers. If we enter the R code returned by dput into our R session we will be able to see the dates.
>> >
>> > Your mjo30 table seems to call the day of the month the "date"... which is confusing. I would combine those three columns into one like
>> >
>> > mjo30$Dt <- as.Date( ISOdate( mjo30$year, mjo30$month, mjo30$date ) )
>> >
>> > You could then use indexing
>> >
>> > mjo30[ date[1] == mjo30$Dt, ]
>> >
>> > or
>> >
>> > mjo30[ mjo30$Dt %in% date, ]
>> >
>> > but the subset function would not work in this case because you have two different objects (a column in mjo30 and a vector in your global environment) both referred to as 'date'.
>> >
>> > On January 13, 2020 8:53:38 PM PST, ani jaya <gaaauul at gmail.com> wrote:
>> > >Good morning R-Help,
>> > >
>> > >I have a dataframe with 7 columns and 10000+ rows. I want to
>> > >subset/extract
>> > >those data frame with specific date (not in order). Here the head of my
>> > >data frame:
>> > >
>> > >head(mjo30)  year month date      rmm1     rmm2 phase     amp
>> > >1 1986     1    1 -0.326480 -1.55895     2 1.59277
>> > >2 1986     1    2 -0.417700 -1.82689     2 1.87403
>> > >3 1986     1    3  0.032915 -2.40150     3 2.40172
>> > >4 1986     1    4  0.492743 -2.49216     3 2.54041
>> > >5 1986     1    5  0.585106 -2.76866     3 2.82981
>> > >6 1986     1    6  0.665013 -3.13883     3 3.20851
>> > >
>> > >and here my specific date:
>> > >> date [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05"
>> > >"1990-10-26" "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
>> > >[10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-16"
>> > >"2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
>> > >[19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-24"
>> > >"2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
>> > >[28] "2013-04-07" "2014-05-07" "2015-07-26"
>> > >
>> > >And also I was confused when I dput my date, it show like this:
>> > >> dput(date)structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358, 8423,
>> > >9103,
>> > >9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
>> > >13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
>> > >16197, 16642), class = "Date")
>> > >
>> > >what is that mean? I mean why it is not recall the dates but some
>> > >values (5958,6369,7217,..)?
>> > >
>> > >Any comment and recommendation is appreciate.  Thank you.
>> > >
>> > >Best,
>> > >
>> > >Ani
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jan 14 12:52:04 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 14 Jan 2020 11:52:04 +0000
Subject: [R] Subset a data frame with specific date
In-Reply-To: <CAGxFJbRJ+8AJp2Cuu4z+hS8vP6KJ8oCWC8jgebk5PbkN+JwuGw@mail.gmail.com>
References: <CAHXS41xq8G-bbyW+0d+D7JxPo2i+vRGe4_5C+_KF+us=uzDs9A@mail.gmail.com>
 <19E9B3DC-DA55-41A7-9B1D-34220873CFD3@dcn.davis.ca.us>
 <CAHXS41x05iN0Hk_A+Xm3pYU=bs3pCukiOJmLgsF3EYWYFSJ_Cw@mail.gmail.com>
 <CAGxFJbRJ+8AJp2Cuu4z+hS8vP6KJ8oCWC8jgebk5PbkN+JwuGw@mail.gmail.com>
Message-ID: <88cf7b97a1184fd3856580a361b5b109@SRVEXCHCM1302.precheza.cz>

Hi Bert

I sometimes use indexing with  "which" too, depends on desired result,
especially with data frames.

x <- 1:10
x[5:6] <- NA
> xd <- data.frame(x, y=rnorm(10))

> xd[xd$x>3,]
      x          y
4     4 -1.5086790
NA   NA         NA
NA.1 NA         NA
7     7 -0.2302614
8     8 -0.1660547
9     9  1.3197811
10   10 -0.3234029
> xd[which(xd$x>3),]
    x          y
4   4 -1.5086790
7   7 -0.2302614
8   8 -0.1660547
9   9  1.3197811
10 10 -0.3234029

The variant without which retains NA values, which may be sometimes
undesirable.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
> Sent: Tuesday, January 14, 2020 8:10 AM
> To: ani jaya <gaaauul at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Subset a data frame with specific date
> 
> That's fine, but do note that the which() function is wholly unnecessary
in
> your last line as R allows logical indexing. Perhaps another topic you
need to
> study.
> 
> -- Bert
> 
> 
> 
> On Mon, Jan 13, 2020 at 10:56 PM ani jaya <gaaauul at gmail.com> wrote:
> 
> > Dear Jeff and Bert,
> >
> > Thank you very much for your correction and explanation.
> > And yes, I need to study about date format more.
> > Sorry for HTML mail, don't realize.
> >
> > I was able to subset the data that I want.
> >
> > mjo30<-read.table("rmm.txt", header=FALSE, skip=4234, nrows=10957)
> > mjo30$V8<-NULL names(mjo30)<-c("year","month","day",
> > "rmm1","rmm2","phase","amp")
> > mjo3<-as.Date(with(mjo30,paste(year,month, day, sep="-")),"%Y-%m-%d")
> > mjo<-mjo30[which(mjo3%in%date),]
> >
> > head(mjo)
> >      year month day      rmm1      rmm2 phase      amp
> > 115  1986     4  25 -0.319090 -0.363030     2 0.483332
> > 526  1987     6  10  1.662870  0.291632     5 1.688250
> > 977  1988     9   3 -0.604950 -0.299850     1 0.675181
> > 1374 1989    10   5  0.972298 -0.461030     4 1.076060
> > 1760 1990    10  26 -1.183110 -1.589810     2 1.981730
> > 1953 1991     5   7 -0.317180  0.953061     7 1.004450
> >
> >
> > Best,
> > Ani
> >
> >
> > On Tue, Jan 14, 2020 at 3:20 PM Jeff Newmiller
> > <jdnewmil at dcn.davis.ca.us>
> > wrote:
> > >
> > > The dput function is for re-creating an R object in another R
> > > workspace,
> > so it uses fundamental base types to define objects. A Date is really
> > the number of days since a specific date (typically 1970-01-01) that
> > get converted to look like dates whenever you display or print them,
> > so what you are seiing are those numbers. If we enter the R code
> > returned by dput into our R session we will be able to see the dates.
> > >
> > > Your mjo30 table seems to call the day of the month the "date"...
> > > which
> > is confusing. I would combine those three columns into one like
> > >
> > > mjo30$Dt <- as.Date( ISOdate( mjo30$year, mjo30$month, mjo30$date )
> > > )
> > >
> > > You could then use indexing
> > >
> > > mjo30[ date[1] == mjo30$Dt, ]
> > >
> > > or
> > >
> > > mjo30[ mjo30$Dt %in% date, ]
> > >
> > > but the subset function would not work in this case because you have
> > > two
> > different objects (a column in mjo30 and a vector in your global
> > environment) both referred to as 'date'.
> > >
> > > On January 13, 2020 8:53:38 PM PST, ani jaya <gaaauul at gmail.com>
> wrote:
> > > >Good morning R-Help,
> > > >
> > > >I have a dataframe with 7 columns and 10000+ rows. I want to
> > > >subset/extract those data frame with specific date (not in order).
> > > >Here the head of my data frame:
> > > >
> > > >head(mjo30)  year month date      rmm1     rmm2 phase     amp
> > > >1 1986     1    1 -0.326480 -1.55895     2 1.59277
> > > >2 1986     1    2 -0.417700 -1.82689     2 1.87403
> > > >3 1986     1    3  0.032915 -2.40150     3 2.40172
> > > >4 1986     1    4  0.492743 -2.49216     3 2.54041
> > > >5 1986     1    5  0.585106 -2.76866     3 2.82981
> > > >6 1986     1    6  0.665013 -3.13883     3 3.20851
> > > >
> > > >and here my specific date:
> > > >> date [1] "1986-04-25" "1987-06-10" "1988-09-03" "1989-10-05"
> > > >"1990-10-26" "1991-05-07" "1992-11-19" "1993-01-23" "1994-12-04"
> > > >[10] "1995-05-11" "1996-10-04" "1997-04-29" "1998-04-08" "1999-01-
> 16"
> > > >"2000-08-01" "2001-10-02" "2002-05-08" "2003-04-01"
> > > >[19] "2004-05-07" "2005-09-02" "2006-12-30" "2007-09-03" "2008-10-
> 24"
> > > >"2009-11-14" "2010-07-05" "2011-04-30" "2012-05-21"
> > > >[28] "2013-04-07" "2014-05-07" "2015-07-26"
> > > >
> > > >And also I was confused when I dput my date, it show like this:
> > > >> dput(date)structure(c(5958, 6369, 6820, 7217, 7603, 7796, 8358,
> > > >> 8423,
> > > >9103,
> > > >9261, 9773, 9980, 10324, 10607, 11170, 11597, 11815, 12143, 12545,
> > > >13028, 13512, 13759, 14176, 14562, 14795, 15094, 15481, 15802,
> > > >16197, 16642), class = "Date")
> > > >
> > > >what is that mean? I mean why it is not recall the dates but some
> > > >values (5958,6369,7217,..)?
> > > >
> > > >Any comment and recommendation is appreciate.  Thank you.
> > > >
> > > >Best,
> > > >
> > > >Ani
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ESWRIGHT @end|ng |rom p|tt@edu  Tue Jan 14 00:33:57 2020
From: ESWRIGHT @end|ng |rom p|tt@edu (Wright, Erik Scott)
Date: Mon, 13 Jan 2020 23:33:57 +0000
Subject: [R] choose(n, k) as n approaches k
Message-ID: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>

This struck me as incorrect:

> choose(3.999999, 4)
[1] 0.9999979
> choose(3.9999999, 4)
[1] 0
> choose(4, 4)
[1] 1
> choose(4.0000001, 4)
[1] 4
> choose(4.000001, 4)
[1] 1.000002

Should base::choose(n, k) check whether n is within machine precision of k and return 1?

Thanks,
Erik

***
sessionInfo()
R version 3.6.0 beta (2019-04-15 r76395)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS High Sierra 10.13.6

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jan 14 16:03:51 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 14 Jan 2020 10:03:51 -0500
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
Message-ID: <efded920-c8d4-9bf9-53ae-3632612843ba@gmail.com>

On 13/01/2020 6:33 p.m., Wright, Erik Scott wrote:
> This struck me as incorrect:
> 
>> choose(3.999999, 4)
> [1] 0.9999979
>> choose(3.9999999, 4)
> [1] 0
>> choose(4, 4)
> [1] 1
>> choose(4.0000001, 4)
> [1] 4
>> choose(4.000001, 4)
> [1] 1.000002
> 
> Should base::choose(n, k) check whether n is within machine precision of k and return 1?

I don't think that's the solution.  The current code checks whether n is 
within 1e-7 of an integer; if it is and n-k is smaller than k, it 
computes choose(n, n-k) instead.  The problem in your second example is 
that n-k < 0 which implies the answer should be zero.  In the 4th 
example n-k > 0 but it is not an integer; the code rounds k to an 
integer, but the transformation to n-k happens after that, so the code 
ends up working with a non-integer.

I think a solution would be to force n to be an integer if it is very 
close to one.

I note that the source to lchoose() seems to already do this:  it 
handles your examples nicely.

Duncan Murdoch


From pd@|gd @end|ng |rom gm@||@com  Tue Jan 14 16:07:44 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 14 Jan 2020 16:07:44 +0100
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
Message-ID: <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>

Yep, that looks wrong (probably want to continue discussion over on R-devel)

I think the culprit is here (in src/nmath/choose.c)
 
   if (k < k_small_max) {
        int j;
        if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
        if (k <  0) return 0.;
        if (k == 0) return 1.;
        /* else: k >= 1 */

if n is a near-integer, then k can become non-integer and negative. In your case, 

n == 4 - 1e-7
k == 4
n - k == -1e-7 < 4
n >= 0 
R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)

so k gets set to

n - k == -1e-7

which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.

> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
[1] -9.289025e-11

I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.

-pd



> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
> 
> This struck me as incorrect:
> 
>> choose(3.999999, 4)
> [1] 0.9999979
>> choose(3.9999999, 4)
> [1] 0
>> choose(4, 4)
> [1] 1
>> choose(4.0000001, 4)
> [1] 4
>> choose(4.000001, 4)
> [1] 1.000002
> 
> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
> 
> Thanks,
> Erik
> 
> ***
> sessionInfo()
> R version 3.6.0 beta (2019-04-15 r76395)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS High Sierra 10.13.6
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jan 14 16:21:13 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 14 Jan 2020 10:21:13 -0500
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
 <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
Message-ID: <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>

On 14/01/2020 10:07 a.m., peter dalgaard wrote:
> Yep, that looks wrong (probably want to continue discussion over on R-devel)
> 
> I think the culprit is here (in src/nmath/choose.c)
>   
>     if (k < k_small_max) {
>          int j;
>          if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
>          if (k <  0) return 0.;
>          if (k == 0) return 1.;
>          /* else: k >= 1 */
> 
> if n is a near-integer, then k can become non-integer and negative. In your case,
> 
> n == 4 - 1e-7
> k == 4
> n - k == -1e-7 < 4
> n >= 0
> R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)
> 
> so k gets set to
> 
> n - k == -1e-7
> 
> which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.
> 
>> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
> [1] -9.289025e-11
> 
> I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.

I think that would break symmetry:  you want choose(n, k) to equal 
choose(n, n-k) when n is very close to an integer.  So I'd suggest the 
replacement whenever R_IS_INT(n) is true.

Duncan Murdoch

> 
> -pd
> 
> 
> 
>> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
>>
>> This struck me as incorrect:
>>
>>> choose(3.999999, 4)
>> [1] 0.9999979
>>> choose(3.9999999, 4)
>> [1] 0
>>> choose(4, 4)
>> [1] 1
>>> choose(4.0000001, 4)
>> [1] 4
>>> choose(4.000001, 4)
>> [1] 1.000002
>>
>> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
>>
>> Thanks,
>> Erik
>>
>> ***
>> sessionInfo()
>> R version 3.6.0 beta (2019-04-15 r76395)
>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> Running under: macOS High Sierra 10.13.6
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From pd@|gd @end|ng |rom gm@||@com  Tue Jan 14 16:50:52 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 14 Jan 2020 16:50:52 +0100
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
 <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
 <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>
Message-ID: <6B40064A-8B62-4FC3-967D-3695F2E46EFA@gmail.com>



> On 14 Jan 2020, at 16:21 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 14/01/2020 10:07 a.m., peter dalgaard wrote:
>> Yep, that looks wrong (probably want to continue discussion over on R-devel)
>> I think the culprit is here (in src/nmath/choose.c)
>>      if (k < k_small_max) {
>>         int j;
>>         if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
>>         if (k <  0) return 0.;
>>         if (k == 0) return 1.;
>>         /* else: k >= 1 */
>> if n is a near-integer, then k can become non-integer and negative. In your case,
>> n == 4 - 1e-7
>> k == 4
>> n - k == -1e-7 < 4
>> n >= 0
>> R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)
>> so k gets set to
>> n - k == -1e-7
>> which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.
>>> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
>> [1] -9.289025e-11
>> I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.
> 
> I think that would break symmetry:  you want choose(n, k) to equal choose(n, n-k) when n is very close to an integer.  So I'd suggest the replacement whenever R_IS_INT(n) is true.
> 

But choose() very deliberately ensures that k is integer, so choose(n, n-k) is ill-defined for non-integer n.

    double r, k0 = k;
    k = R_forceint(k);
...
    if (fabs(k - k0) > 1e-7)
        MATHLIB_WARNING2(_("'k' (%.2f) must be integer, rounded to %.0f"), k0, k);
  

> Duncan Murdoch
> 
>> -pd
>>> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
>>> 
>>> This struck me as incorrect:
>>> 
>>>> choose(3.999999, 4)
>>> [1] 0.9999979
>>>> choose(3.9999999, 4)
>>> [1] 0
>>>> choose(4, 4)
>>> [1] 1
>>>> choose(4.0000001, 4)
>>> [1] 4
>>>> choose(4.000001, 4)
>>> [1] 1.000002
>>> 
>>> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
>>> 
>>> Thanks,
>>> Erik
>>> 
>>> ***
>>> sessionInfo()
>>> R version 3.6.0 beta (2019-04-15 r76395)
>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>> Running under: macOS High Sierra 10.13.6
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jan 14 17:02:20 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 14 Jan 2020 11:02:20 -0500
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <6B40064A-8B62-4FC3-967D-3695F2E46EFA@gmail.com>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
 <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
 <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>
 <6B40064A-8B62-4FC3-967D-3695F2E46EFA@gmail.com>
Message-ID: <7cf77331-6ee2-a980-e781-8ee2a6e8dad6@gmail.com>

On 14/01/2020 10:50 a.m., peter dalgaard wrote:
> 
> 
>> On 14 Jan 2020, at 16:21 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 14/01/2020 10:07 a.m., peter dalgaard wrote:
>>> Yep, that looks wrong (probably want to continue discussion over on R-devel)
>>> I think the culprit is here (in src/nmath/choose.c)
>>>       if (k < k_small_max) {
>>>          int j;
>>>          if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
>>>          if (k <  0) return 0.;
>>>          if (k == 0) return 1.;
>>>          /* else: k >= 1 */
>>> if n is a near-integer, then k can become non-integer and negative. In your case,
>>> n == 4 - 1e-7
>>> k == 4
>>> n - k == -1e-7 < 4
>>> n >= 0
>>> R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)
>>> so k gets set to
>>> n - k == -1e-7
>>> which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.
>>>> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
>>> [1] -9.289025e-11
>>> I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.
>>
>> I think that would break symmetry:  you want choose(n, k) to equal choose(n, n-k) when n is very close to an integer.  So I'd suggest the replacement whenever R_IS_INT(n) is true.
>>
> 
> But choose() very deliberately ensures that k is integer, so choose(n, n-k) is ill-defined for non-integer n.

That's only true if there's a big difference.  I'd be worried about 
cases where n and k are close to integers (within 1e-7).  In those 
cases, k is silently rounded to integer.  As I read your suggestion, n 
would only be rounded to integer if k > n-k.  I think both n and k 
should be rounded to integer in this near-integer situation, regardless 
of the value of k.

I believe that lchoose(n, k) already does this.

Duncan Murdoch

> 
>      double r, k0 = k;
>      k = R_forceint(k);
> ...
>      if (fabs(k - k0) > 1e-7)
>          MATHLIB_WARNING2(_("'k' (%.2f) must be integer, rounded to %.0f"), k0, k);
>    
> 
>> Duncan Murdoch
>>
>>> -pd
>>>> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
>>>>
>>>> This struck me as incorrect:
>>>>
>>>>> choose(3.999999, 4)
>>>> [1] 0.9999979
>>>>> choose(3.9999999, 4)
>>>> [1] 0
>>>>> choose(4, 4)
>>>> [1] 1
>>>>> choose(4.0000001, 4)
>>>> [1] 4
>>>>> choose(4.000001, 4)
>>>> [1] 1.000002
>>>>
>>>> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
>>>>
>>>> Thanks,
>>>> Erik
>>>>
>>>> ***
>>>> sessionInfo()
>>>> R version 3.6.0 beta (2019-04-15 r76395)
>>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>>> Running under: macOS High Sierra 10.13.6
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>


From pd@|gd @end|ng |rom gm@||@com  Tue Jan 14 19:20:22 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 14 Jan 2020 19:20:22 +0100
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <7cf77331-6ee2-a980-e781-8ee2a6e8dad6@gmail.com>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
 <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
 <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>
 <6B40064A-8B62-4FC3-967D-3695F2E46EFA@gmail.com>
 <7cf77331-6ee2-a980-e781-8ee2a6e8dad6@gmail.com>
Message-ID: <0E56B63E-E9C5-4C92-B9ED-F73CEAF9C053@gmail.com>

OK, I see what you mean. But in those cases, we don't get the catastrophic failures from the 

        if (k <  0) return 0.;
        if (k == 0) return 1.;
        /* else: k >= 1 */

part, because at that point k is sure to be integer, possibly after rounding. 

It is when n-k is approximately but not exactly zero and we should return 1, that we either return 0 (negative case) or n (positive case; because the n(n-1)(n-2)... product has at least one factor). In the other cases, we get 1 or n(n-1)(n-2)...(n-k+1) which if n is near-integer gets rounded to produce an integer, due to the

        return R_IS_INT(n) ? R_forceint(r) : r;

part.

-pd



> On 14 Jan 2020, at 17:02 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 14/01/2020 10:50 a.m., peter dalgaard wrote:
>>> On 14 Jan 2020, at 16:21 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> 
>>> On 14/01/2020 10:07 a.m., peter dalgaard wrote:
>>>> Yep, that looks wrong (probably want to continue discussion over on R-devel)
>>>> I think the culprit is here (in src/nmath/choose.c)
>>>>      if (k < k_small_max) {
>>>>         int j;
>>>>         if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
>>>>         if (k <  0) return 0.;
>>>>         if (k == 0) return 1.;
>>>>         /* else: k >= 1 */
>>>> if n is a near-integer, then k can become non-integer and negative. In your case,
>>>> n == 4 - 1e-7
>>>> k == 4
>>>> n - k == -1e-7 < 4
>>>> n >= 0
>>>> R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)
>>>> so k gets set to
>>>> n - k == -1e-7
>>>> which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.
>>>>> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
>>>> [1] -9.289025e-11
>>>> I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.
>>> 
>>> I think that would break symmetry:  you want choose(n, k) to equal choose(n, n-k) when n is very close to an integer.  So I'd suggest the replacement whenever R_IS_INT(n) is true.
>>> 
>> But choose() very deliberately ensures that k is integer, so choose(n, n-k) is ill-defined for non-integer n.
> 
> That's only true if there's a big difference.  I'd be worried about cases where n and k are close to integers (within 1e-7).  In those cases, k is silently rounded to integer.  As I read your suggestion, n would only be rounded to integer if k > n-k.  I think both n and k should be rounded to integer in this near-integer situation, regardless of the value of k.
> 
> I believe that lchoose(n, k) already does this.
> 
> Duncan Murdoch
> 
>>     double r, k0 = k;
>>     k = R_forceint(k);
>> ...
>>     if (fabs(k - k0) > 1e-7)
>>         MATHLIB_WARNING2(_("'k' (%.2f) must be integer, rounded to %.0f"), k0, k);
>>   
>>> Duncan Murdoch
>>> 
>>>> -pd
>>>>> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
>>>>> 
>>>>> This struck me as incorrect:
>>>>> 
>>>>>> choose(3.999999, 4)
>>>>> [1] 0.9999979
>>>>>> choose(3.9999999, 4)
>>>>> [1] 0
>>>>>> choose(4, 4)
>>>>> [1] 1
>>>>>> choose(4.0000001, 4)
>>>>> [1] 4
>>>>>> choose(4.000001, 4)
>>>>> [1] 1.000002
>>>>> 
>>>>> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
>>>>> 
>>>>> Thanks,
>>>>> Erik
>>>>> 
>>>>> ***
>>>>> sessionInfo()
>>>>> R version 3.6.0 beta (2019-04-15 r76395)
>>>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>>>> Running under: macOS High Sierra 10.13.6
>>>>> 
>>>>> 	[[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jmount @end|ng |rom w|n-vector@com  Tue Jan 14 19:36:15 2020
From: jmount @end|ng |rom w|n-vector@com (John Mount)
Date: Tue, 14 Jan 2020 10:36:15 -0800
Subject: [R] [Rd]  choose(n, k) as n approaches k
In-Reply-To: <0E56B63E-E9C5-4C92-B9ED-F73CEAF9C053@gmail.com>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
 <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
 <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>
 <6B40064A-8B62-4FC3-967D-3695F2E46EFA@gmail.com>
 <7cf77331-6ee2-a980-e781-8ee2a6e8dad6@gmail.com>
 <0E56B63E-E9C5-4C92-B9ED-F73CEAF9C053@gmail.com>
Message-ID: <DA3BC314-5415-47A3-AA73-4FA3A36CAECA@win-vector.com>


At the risk of throwing oil on a fire.  If we are talking about fractional values of choose() doesn't it make sense to look to the gamma function for the correct analytic continuation?  In particular k<0 may not imply the function should evaluate to zero until we get k<=-1.

Example:

``` r
choose(5, 4)
#> [1] 5

gchoose <- function(n, k) { 
  gamma(n+1)/(gamma(n+1-k) * gamma(k+1))
}

gchoose(5, 4)
#> [1] 5
gchoose(5, 0)
#> [1] 1
gchoose(5, -0.5)
#> [1] 0.2351727
```

> On Jan 14, 2020, at 10:20 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> OK, I see what you mean. But in those cases, we don't get the catastrophic failures from the 
> 
>        if (k <  0) return 0.;
>        if (k == 0) return 1.;
>        /* else: k >= 1 */
> 
> part, because at that point k is sure to be integer, possibly after rounding. 
> 
> It is when n-k is approximately but not exactly zero and we should return 1, that we either return 0 (negative case) or n (positive case; because the n(n-1)(n-2)... product has at least one factor). In the other cases, we get 1 or n(n-1)(n-2)...(n-k+1) which if n is near-integer gets rounded to produce an integer, due to the
> 
>        return R_IS_INT(n) ? R_forceint(r) : r;
> 
> part.
> 
> -pd
> 
> 
> 
>> On 14 Jan 2020, at 17:02 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 14/01/2020 10:50 a.m., peter dalgaard wrote:
>>>> On 14 Jan 2020, at 16:21 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>> 
>>>> On 14/01/2020 10:07 a.m., peter dalgaard wrote:
>>>>> Yep, that looks wrong (probably want to continue discussion over on R-devel)
>>>>> I think the culprit is here (in src/nmath/choose.c)
>>>>>     if (k < k_small_max) {
>>>>>        int j;
>>>>>        if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
>>>>>        if (k <  0) return 0.;
>>>>>        if (k == 0) return 1.;
>>>>>        /* else: k >= 1 */
>>>>> if n is a near-integer, then k can become non-integer and negative. In your case,
>>>>> n == 4 - 1e-7
>>>>> k == 4
>>>>> n - k == -1e-7 < 4
>>>>> n >= 0
>>>>> R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)
>>>>> so k gets set to
>>>>> n - k == -1e-7
>>>>> which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.
>>>>>> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
>>>>> [1] -9.289025e-11
>>>>> I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.
>>>> 
>>>> I think that would break symmetry:  you want choose(n, k) to equal choose(n, n-k) when n is very close to an integer.  So I'd suggest the replacement whenever R_IS_INT(n) is true.
>>>> 
>>> But choose() very deliberately ensures that k is integer, so choose(n, n-k) is ill-defined for non-integer n.
>> 
>> That's only true if there's a big difference.  I'd be worried about cases where n and k are close to integers (within 1e-7).  In those cases, k is silently rounded to integer.  As I read your suggestion, n would only be rounded to integer if k > n-k.  I think both n and k should be rounded to integer in this near-integer situation, regardless of the value of k.
>> 
>> I believe that lchoose(n, k) already does this.
>> 
>> Duncan Murdoch
>> 
>>>    double r, k0 = k;
>>>    k = R_forceint(k);
>>> ...
>>>    if (fabs(k - k0) > 1e-7)
>>>        MATHLIB_WARNING2(_("'k' (%.2f) must be integer, rounded to %.0f"), k0, k);
>>> 
>>>> Duncan Murdoch
>>>> 
>>>>> -pd
>>>>>> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
>>>>>> 
>>>>>> This struck me as incorrect:
>>>>>> 
>>>>>>> choose(3.999999, 4)
>>>>>> [1] 0.9999979
>>>>>>> choose(3.9999999, 4)
>>>>>> [1] 0
>>>>>>> choose(4, 4)
>>>>>> [1] 1
>>>>>>> choose(4.0000001, 4)
>>>>>> [1] 4
>>>>>>> choose(4.000001, 4)
>>>>>> [1] 1.000002
>>>>>> 
>>>>>> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
>>>>>> 
>>>>>> Thanks,
>>>>>> Erik
>>>>>> 
>>>>>> ***
>>>>>> sessionInfo()
>>>>>> R version 3.6.0 beta (2019-04-15 r76395)
>>>>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>>>>> Running under: macOS High Sierra 10.13.6
>>>>>> 
>>>>>> 	[[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---------------
John Mount
http://www.win-vector.com/ <http://www.win-vector.com/> 
Our book: Practical Data Science with R
http://practicaldatascience.com <http://practicaldatascience.com/> 






	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Jan 15 01:45:59 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 15 Jan 2020 01:45:59 +0100
Subject: [R] choose(n, k) as n approaches k
In-Reply-To: <0E56B63E-E9C5-4C92-B9ED-F73CEAF9C053@gmail.com>
References: <A3522327-CF54-4960-A09F-D334C408BB84@pitt.edu>
 <65C7647D-9E6C-4D4A-B8F7-63EBA0320E09@gmail.com>
 <ae3139e1-c728-83e5-0aa7-a17135b31df6@gmail.com>
 <6B40064A-8B62-4FC3-967D-3695F2E46EFA@gmail.com>
 <7cf77331-6ee2-a980-e781-8ee2a6e8dad6@gmail.com>
 <0E56B63E-E9C5-4C92-B9ED-F73CEAF9C053@gmail.com>
Message-ID: <44999E7A-4D41-4E54-AA9D-532AA5771A18@gmail.com>

Um, n(n-1)(n-2)...(n-k+1)/factorial(k), of course, but I think the argument still holds. 

Also, note that there are overflow conditions involved with computing 

n(n-1)(n-2)...(n-k+1)/factorial(k)
 
as written, so it is computed in a loop with alternating multiply and divide steps. This introduces FP errors even if it is known that the result should be integer. I.e., we cannot remove the final "R_IS_INT(n) ? R_forceint(r) : r" if we want choose(n, k) to return an integer if n and k are integers.

-pd

> On 14 Jan 2020, at 19:20 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> OK, I see what you mean. But in those cases, we don't get the catastrophic failures from the 
> 
>        if (k <  0) return 0.;
>        if (k == 0) return 1.;
>        /* else: k >= 1 */
> 
> part, because at that point k is sure to be integer, possibly after rounding. 
> 
> It is when n-k is approximately but not exactly zero and we should return 1, that we either return 0 (negative case) or n (positive case; because the n(n-1)(n-2)... product has at least one factor). In the other cases, we get 1 or n(n-1)(n-2)...(n-k+1) which if n is near-integer gets rounded to produce an integer, due to the
> 
>        return R_IS_INT(n) ? R_forceint(r) : r;
> 
> part.
> 
> -pd
> 
> 
> 
>> On 14 Jan 2020, at 17:02 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 14/01/2020 10:50 a.m., peter dalgaard wrote:
>>>> On 14 Jan 2020, at 16:21 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>> 
>>>> On 14/01/2020 10:07 a.m., peter dalgaard wrote:
>>>>> Yep, that looks wrong (probably want to continue discussion over on R-devel)
>>>>> I think the culprit is here (in src/nmath/choose.c)
>>>>>     if (k < k_small_max) {
>>>>>        int j;
>>>>>        if(n-k < k && n >= 0 && R_IS_INT(n)) k = n-k; /* <- Symmetry */
>>>>>        if (k <  0) return 0.;
>>>>>        if (k == 0) return 1.;
>>>>>        /* else: k >= 1 */
>>>>> if n is a near-integer, then k can become non-integer and negative. In your case,
>>>>> n == 4 - 1e-7
>>>>> k == 4
>>>>> n - k == -1e-7 < 4
>>>>> n >= 0
>>>>> R_IS_INT(n) = TRUE (relative diff < 1e-7 is allowed)
>>>>> so k gets set to
>>>>> n - k == -1e-7
>>>>> which is less than 0, so we return 0. However, as you point out, 1 would be more reasonable and in accordance with the limit as n -> 4, e.g.
>>>>>> factorial(4 - 1e-10)/factorial(1e-10)/factorial(4) -1
>>>>> [1] -9.289025e-11
>>>>> I guess that the fix could be as simple as replacing n by R_forceint(n) in the k = n - k step.
>>>> 
>>>> I think that would break symmetry:  you want choose(n, k) to equal choose(n, n-k) when n is very close to an integer.  So I'd suggest the replacement whenever R_IS_INT(n) is true.
>>>> 
>>> But choose() very deliberately ensures that k is integer, so choose(n, n-k) is ill-defined for non-integer n.
>> 
>> That's only true if there's a big difference.  I'd be worried about cases where n and k are close to integers (within 1e-7).  In those cases, k is silently rounded to integer.  As I read your suggestion, n would only be rounded to integer if k > n-k.  I think both n and k should be rounded to integer in this near-integer situation, regardless of the value of k.
>> 
>> I believe that lchoose(n, k) already does this.
>> 
>> Duncan Murdoch
>> 
>>>    double r, k0 = k;
>>>    k = R_forceint(k);
>>> ...
>>>    if (fabs(k - k0) > 1e-7)
>>>        MATHLIB_WARNING2(_("'k' (%.2f) must be integer, rounded to %.0f"), k0, k);
>>> 
>>>> Duncan Murdoch
>>>> 
>>>>> -pd
>>>>>> On 14 Jan 2020, at 00:33 , Wright, Erik Scott <ESWRIGHT at pitt.edu> wrote:
>>>>>> 
>>>>>> This struck me as incorrect:
>>>>>> 
>>>>>>> choose(3.999999, 4)
>>>>>> [1] 0.9999979
>>>>>>> choose(3.9999999, 4)
>>>>>> [1] 0
>>>>>>> choose(4, 4)
>>>>>> [1] 1
>>>>>>> choose(4.0000001, 4)
>>>>>> [1] 4
>>>>>>> choose(4.000001, 4)
>>>>>> [1] 1.000002
>>>>>> 
>>>>>> Should base::choose(n, k) check whether n is within machine precision of k and return 1?
>>>>>> 
>>>>>> Thanks,
>>>>>> Erik
>>>>>> 
>>>>>> ***
>>>>>> sessionInfo()
>>>>>> R version 3.6.0 beta (2019-04-15 r76395)
>>>>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>>>>> Running under: macOS High Sierra 10.13.6
>>>>>> 
>>>>>> 	[[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From yue||7 @end|ng |rom 126@com  Wed Jan 15 05:26:16 2020
From: yue||7 @end|ng |rom 126@com (yueli)
Date: Wed, 15 Jan 2020 12:26:16 +0800 (CST)
Subject: [R] Error in (function (cl, name, valueClass)  :
Message-ID: <2a79ab88.9c6b.16fa773b74d.Coremail.yueli7@126.com>

Hello??

I have error in running the program:

Any hint or help will be appreciated!

Thanks in advance!

Yue

Error in (function (cl, name, valueClass)  :
  assignment of an object of class ??numeric?? is not valid for @??Dim?? in an object of class ??dgTMatrix??; is(value, "integer") is not TRUE
Calls: convert2countM -> .makewide -> <Anonymous> -> <Anonymous>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Jan 15 22:28:04 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 15 Jan 2020 15:28:04 -0600
Subject: [R] Reporting missing dates
References: <002701d5cbea$aca09ad0$05e1d070$.ref@sbcglobal.net>
Message-ID: <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>

R-help Forum

I have a 20 year data set and I am looking for a way to find missing dates.
I wrote this and its works, but am wounding if there is a better way?

d <- c('2020-01-01', '2020-01-02', '2020-01-04', '2020-01-05')
d <- as.Date(d)
date_range <- seq(min(d), max(d), by = 1) 
date_range[!date_range %in% d] 
 

Sincerely

Jeff Reichman


	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Thu Jan 16 10:46:16 2020
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Thu, 16 Jan 2020 09:46:16 +0000
Subject: [R] Course: Zero-inflated GAMs and GAMMs for the analysis of
 spatial and spatial-temporal correlated data using R-INLA
Message-ID: <217b4521-b6df-db49-ab61-b85acd81cbda@highstat.com>


We would like to announce the following statistics course.

Course: Zero-inflated GAMs and GAMMs for the analysis of spatial and 
spatial-temporal correlated data using R-INLA

Where and when: NIOZ, Texel, The Netherlands. 20 - 24 April 2020

Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2020/Flyer2020_05NIOZ_GAMZISPatTemp.pdf

Kind regards,


Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jan 16 11:35:47 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 16 Jan 2020 10:35:47 +0000
Subject: [R] Reporting missing dates
In-Reply-To: <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
References: <002701d5cbea$aca09ad0$05e1d070$.ref@sbcglobal.net>
 <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
Message-ID: <782eae9af6634696aaceead832a517e3@SRVEXCHCM1302.precheza.cz>

Your approach is quite simple and works well

Another option is
as.Date(setdiff(date_range, d), origin="1970-01-01")
but I do not believe that it has some advantage above yours.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
> Sent: Wednesday, January 15, 2020 10:28 PM
> To: R-help at r-project.org
> Subject: [R] Reporting missing dates
> 
> R-help Forum
> 
> I have a 20 year data set and I am looking for a way to find missing
dates.
> I wrote this and its works, but am wounding if there is a better way?
> 
> d <- c('2020-01-01', '2020-01-02', '2020-01-04', '2020-01-05')
> d <- as.Date(d)
> date_range <- seq(min(d), max(d), by = 1)
> date_range[!date_range %in% d]
> 
> 
> Sincerely
> 
> Jeff Reichman
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan 16 11:46:19 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 16 Jan 2020 05:46:19 -0500
Subject: [R] Reporting missing dates
In-Reply-To: <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
References: <002701d5cbea$aca09ad0$05e1d070$.ref@sbcglobal.net>
 <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
Message-ID: <a1c4214a-35f4-101e-e4b8-505b836766f1@gmail.com>

On 15/01/2020 4:28 p.m., Jeff Reichman wrote:
> R-help Forum
> 
> I have a 20 year data set and I am looking for a way to find missing dates.
> I wrote this and its works, but am wounding if there is a better way?
> 
> d <- c('2020-01-01', '2020-01-02', '2020-01-04', '2020-01-05')
> d <- as.Date(d)
> date_range <- seq(min(d), max(d), by = 1)
> date_range[!date_range %in% d]

Another approach would be based on diff(d) - 1.  That will count the 
number of missing dates between any pair of dates that are present:

diff(d) - 1
# Time differences in days
# [1] 0 1 0

That shows that the second date is followed by one missing day.

Duncan Murdoch


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Jan 16 12:02:02 2020
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 16 Jan 2020 12:02:02 +0100
Subject: [R] Reporting missing dates
In-Reply-To: <a1c4214a-35f4-101e-e4b8-505b836766f1@gmail.com>
References: <002701d5cbea$aca09ad0$05e1d070$.ref@sbcglobal.net>
 <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
 <a1c4214a-35f4-101e-e4b8-505b836766f1@gmail.com>
Message-ID: <20200116120202.Horde.n-5BNbqHCdqm34SkoTaCfAy@webmail.your-server.de>


Quoting Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 15/01/2020 4:28 p.m., Jeff Reichman wrote:
>> R-help Forum
>>
>> I have a 20 year data set and I am looking for a way to find missing dates.
>> I wrote this and its works, but am wounding if there is a better way?
>>
>> d <- c('2020-01-01', '2020-01-02', '2020-01-04', '2020-01-05')
>> d <- as.Date(d)
>> date_range <- seq(min(d), max(d), by = 1)
>> date_range[!date_range %in% d]
>
> Another approach would be based on diff(d) - 1.  That will count the  
> number of missing dates between any pair of dates that are present:
>
> diff(d) - 1
> # Time differences in days
> # [1] 0 1 0
>
> That shows that the second date is followed by one missing day.
>
> Duncan Murdoch

But you might want to check if the dates in 'd' are really sorted.

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From |@heemj@n93 @end|ng |rom y@hoo@com  Thu Jan 16 12:02:59 2020
From: |@heemj@n93 @end|ng |rom y@hoo@com (Faheem Jan)
Date: Thu, 16 Jan 2020 11:02:59 +0000 (UTC)
Subject: [R] Extracting a particular column from list
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
Message-ID: <47617339.8228196.1579172579216@mail.yahoo.com>

Hi. How to extract a column from the list.. I will be thanks full..?

Sent from Yahoo Mail on Android
	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jan 16 13:03:17 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 16 Jan 2020 19:03:17 +0700
Subject: [R] Reporting missing dates
In-Reply-To: <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
References: <002701d5cbea$aca09ad0$05e1d070$.ref@sbcglobal.net>
 <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
Message-ID: <B41EB900-9D7D-407D-92C7-BF866C6B770E@comcast.net>

Looks reasonable and efficient. There is a seq.Date function that would be implicitly selected by the S3 class dispatch rules  

David

Sent from my iPhone

> On Jan 16, 2020, at 4:28 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> 
> R-help Forum
> 
> I have a 20 year data set and I am looking for a way to find missing dates.
> I wrote this and its works, but am wounding if there is a better way?
> 
> d <- c('2020-01-01', '2020-01-02', '2020-01-04', '2020-01-05')
> d <- as.Date(d)
> date_range <- seq(min(d), max(d), by = 1) 
> date_range[!date_range %in% d] 
> 
> 
> Sincerely
> 
> Jeff Reichman
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jan 16 13:55:56 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 16 Jan 2020 12:55:56 +0000
Subject: [R] Extracting a particular column from list
In-Reply-To: <47617339.8228196.1579172579216@mail.yahoo.com>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
Message-ID: <82a3950f-b329-a5b4-487b-0dc0449b5ae1@sapo.pt>

Hello,

What column and what list?
Please post a reproducible example, see the link at the bottom of this 
mail and  [1], [2], [3].

[1] https://cran.r-project.org/web/packages/reprex/index.html
[2] 
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
[3] https://stackoverflow.com/help/mcve

Hope this helps,

Rui Barradas


?s 11:02 de 16/01/20, Faheem Jan via R-help escreveu:
> Hi. How to extract a column from the list.. I will be thanks full..
> 
> Sent from Yahoo Mail on Android
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ||54250 @end|ng |rom m@n@com  Thu Jan 16 15:21:23 2020
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Thu, 16 Jan 2020 14:21:23 +0000
Subject: [R] How to save  multiple values of a variable in a json file in R
Message-ID: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>

hello everyone,

and happy new year!

I have this problem: I want to save the name of the 'countries', the 'taxonomy_gem' and the 'minimum_im' and 'maximum_im' . The problem is that there are several names of countries.  How can i transfer the information from the json file to an R data.frame? See below for the json file.

Best,
ioanna



{
    "pk": 670,
    "model": "vulnerability.generalinformation",
    "fields": {
        "category": "Structure class",
        "article_title": "A GLOBAL DATABASE OF VULNERABILITY MODELS FOR SEISMIC RISK ASSESSMENT",
        "name": "CR/LFINF/DUL/H:2",
        "publication_conference_name": "16EECE",
        "llrs": null,
        "material": null,
        "web_link": "",
        "owner": {
            "pk": 1900,
            "model": "people.profile",
            "fields": {
                "username": "lmartins",
                "first_name": "",
                "last_name": "",
                "email": "luis.martins at globalquakemodel.org"
            }
        },
        "general_comments": "",
        "geo_applicability": {
            "pk": 669,
            "model": "vulnerability.geoapplicability",
            "fields": {
                "general_information": 670,
                "area": "",
                "countries": [
                    {
                        "pk": "CIV",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Cte d'Ivoire"
                        }
                    },
                    {
                        "pk": "CMR",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Cameroon"
                        }
                    },
                    {
                        "pk": "SDN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Sudan"
                        }
                    },
                    {
                        "pk": "SSD",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "South Sudan"
                        }
                    },
                    {
                        "pk": "TUN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Tunisia"
                        }
                    },
                    {
                        "pk": "TGO",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Togo"
                        }
                    },
                    {
                        "pk": "ZAF",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "South Africa"
                        }
                    },
                    {
                        "pk": "NER",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Niger"
                        }
                    },
                    {
                        "pk": "MAR",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Morocco"
                        }
                    },
                    {
                        "pk": "KEN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Kenya"
                        }
                    },
                    {
                        "pk": "SYC",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Seychelles"
                        }
                    },
                    {
                        "pk": "ESH",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Western Sahara"
                        }
                    },
                    {
                        "pk": "SHN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Saint Helena"
                        }
                    },
                    {
                        "pk": "REU",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Reunion"
                        }
                    },
                    {
                        "pk": "SLE",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Sierra Leone"
                        }
                    },
                    {
                        "pk": "DJI",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Djibouti"
                        }
                    },
                    {
                        "pk": "STP",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Sao Tome and Principe"
                        }
                    },
                    {
                        "pk": "BDI",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Burundi"
                        }
                    },
                    {
                        "pk": "MLI",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Mali"
                        }
                    },
                    {
                        "pk": "GMB",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Gambia"
                        }
                    },
                    {
                        "pk": "ZMB",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Zambia"
                        }
                    },
                    {
                        "pk": "RWA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Rwanda"
                        }
                    },
                    {
                        "pk": "MWI",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Malawi"
                        }
                    },
                    {
                        "pk": "BFA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Burkina Faso"
                        }
                    },
                    {
                        "pk": "GAB",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Gabon"
                        }
                    },
                    {
                        "pk": "TCD",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Chad"
                        }
                    },
                    {
                        "pk": "SEN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Senegal"
                        }
                    },
                    {
                        "pk": "NAM",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Namibia"
                        }
                    },
                    {
                        "pk": "ATF",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "French Southern Territories"
                        }
                    },
                    {
                        "pk": "BWA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Botswana"
                        }
                    },
                    {
                        "pk": "TZA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Tanzania"
                        }
                    },
                    {
                        "pk": "ERI",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Eritrea"
                        }
                    },
                    {
                        "pk": "MYT",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Mayotte"
                        }
                    },
                    {
                        "pk": "SOM",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Somalia"
                        }
                    },
                    {
                        "pk": "UGA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Uganda"
                        }
                    },
                    {
                        "pk": "LSO",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Lesotho"
                        }
                    },
                    {
                        "pk": "LBY",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Libya"
                        }
                    },
                    {
                        "pk": "LBR",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Liberia"
                        }
                    },
                    {
                        "pk": "COD",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Democratic Republic of the Congo"
                        }
                    },
                    {
                        "pk": "CPV",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Cape Verde"
                        }
                    },
                    {
                        "pk": "CAF",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Central African Republic"
                        }
                    },
                    {
                        "pk": "COM",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Comoros"
                        }
                    },
                    {
                        "pk": "ETH",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Ethiopia"
                        }
                    },
                    {
                        "pk": "GIN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Guinea"
                        }
                    },
                    {
                        "pk": "COG",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Republic of Congo"
                        }
                    },
                    {
                        "pk": "GHA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Ghana"
                        }
                    },
                    {
                        "pk": "SWZ",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Swaziland"
                        }
                    },
                    {
                        "pk": "GNB",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Guinea-Bissau"
                        }
                    },
                    {
                        "pk": "MDG",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Madagascar"
                        }
                    },
                    {
                        "pk": "ZWE",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Zimbabwe"
                        }
                    },
                    {
                        "pk": "MOZ",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Mozambique"
                        }
                    },
                    {
                        "pk": "MRT",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Mauritania"
                        }
                    },
                    {
                        "pk": "MUS",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Mauritius"
                        }
                    },
                    {
                        "pk": "NGA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Nigeria"
                        }
                    },
                    {
                        "pk": "BEN",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Benin"
                        }
                    },
                    {
                        "pk": "GNQ",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Equatorial Guinea"
                        }
                    },
                    {
                        "pk": "EGY",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Egypt"
                        }
                    },
                    {
                        "pk": "AGO",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Angola"
                        }
                    },
                    {
                        "pk": "DZA",
                        "model": "vulnerability.country",
                        "fields": {
                            "is_visible": true,
                            "region": 2,
                            "name": "Algeria"
                        }
                    }
                ],
                "lon": null,
                "address": "",
                "lat": null
            }
        },
        "authors": "Martins and Silva",
        "use_case_information": "",
        "structure_type": "Building",
        "taxonomy_gem": "DX+D99/MAT99/L99/DY+D99/MAT99/L99/H99/Y99/OC99/BP99/PLF99/IR99/EW99/RSH99+RMT99+R99+RWC99/F99+FWC99/FOS99",
        "year": 2018,
        "type_of_assessment": "Vulnerability",
        "taxonomy_type": {
            "pk": 1,
            "model": "vulnerability.taxonomytype",
            "fields": {
                "user_def": false,
                "name": "GEM"
            }
        },
        "taxonomy_text": "",
        "vulnerability_func": {
            "pk": 30,
            "model": "vulnerability.vulnerabilityfunc",
            "fields": {
                "general_information": 670,
                "predictor_var": {
                    "pk": 602,
                    "model": "vulnerability.predictorvar",
                    "fields": {
                        "type_of_period": "Telastic (s)",
                        "minimum_im": 0.05,
                        "intensity_measure_type": "Sa(T)",
                        "fragility_func": null,
                        "period": 0.3,
                        "vulnerability_func": 30,
                        "maximum_im": 8,
                        "intensity_measure_unit": "g"
                    }
                },
                "func_distr_vuln_discr": {
                    "pk": 23,
                    "model": "vulnerability.funcdistrvulndiscr",
                    "fields": {
                        "resp_var_mean_val": "0.000025;0.000033;0.000045;0.000059;0.000078;0.000101;0.000131;0.00017;0.000217;0.000277;0.00035;0.00044;0.000551;0.000684;0.000844;0.001036;0.001264;0.001532;0.001846;0.002212;0.002635;0.003121;0.003676;0.004306;0.005016;0.005812;0.006701;0.007685;0.008772;0.009966;0.01127;0.012691;0.014233;0.0159;0.0177;0.019639;0.021726;0.023972;0.026388;0.028991;0.0318;0.034838;0.038132;0.041714;0.04562;0.049893;0.05458;0.059733;0.065409;0.07167;0.078582;0.086213;0.094633;0.103913;0.114125;0.125335;0.13761;0.151007;0.165578;0.181366;0.1984;0.216699;0.236266;0.257091;0.279144;0.302379;0.326733;0.352124;0.378455;0.40561;0.433459;0.461862;0.490663;0.519703;0.548813;0.577824;0.606566;0.634874;0.662589;0.68956;0.715649;0.740732;0.764702;0.787467;0.808956;0.829114;0.847907;0.865317;0.881347;0.896012;0.909344;0.921388;0.932199;0.941842;0.950388;0.957913;0.964497;0.97022;0.975163;0.979405",
                        "resp_var_val_coeff": "",
                        "predictor_var_im_val": "0.05;0.05263;0.055398;0.058312;0.06138;0.064608;0.068007;0.071584;0.07535;0.079313;0.083485;0.087876;0.092499;0.097364;0.102486;0.107877;0.113551;0.119524;0.125811;0.132429;0.139395;0.146727;0.154445;0.162569;0.171121;0.180122;0.189596;0.199569;0.210067;0.221117;0.232748;0.24499;0.257877;0.271442;0.28572;0.300749;0.316569;0.333221;0.350749;0.369198;0.388619;0.40906;0.430577;0.453226;0.477066;0.502161;0.528575;0.556379;0.585645;0.61645;0.648876;0.683008;0.718935;0.756752;0.796558;0.838458;0.882561;0.928985;0.977851;1.029287;1.083429;1.140418;1.200405;1.263548;1.330012;1.399972;1.473613;1.551126;1.632717;1.7186;1.809;1.904156;2.004317;2.109746;2.220721;2.337534;2.460491;2.589915;2.726148;2.869546;3.020488;3.179369;3.346607;3.522643;3.707938;3.902979;4.108281;4.324381;4.551848;4.791281;5.043307;5.308591;5.587829;5.881755;6.191142;6.516804;6.859595;7.220418;7.60022;8",
                        "vulnerability_func": 30,
                        "func_distr_shape": null,
                        "data_pts_num": 100
                    }
                },
                "method_of_estimation": "Analytical",
                "func_distr_type": "Discrete",
                "resp_var": "Damage factor"
            }
        }
    }
}

	[[alternative HTML version deleted]]


From ||54250 @end|ng |rom m@n@com  Thu Jan 16 16:01:58 2020
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Thu, 16 Jan 2020 15:01:58 +0000
Subject: [R] 
 How to save  multiple values of a variable in a json file in R
In-Reply-To: <B4D78F92-CB0E-42C8-99A7-E115DE725714@krugs.de>
References: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <17F90DC5-D0FD-4A2D-A6FA-0A22861A78CF@krugs.de>
 <DBBPR05MB6570B84F540BE7F511103A70F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>,
 <B4D78F92-CB0E-42C8-99A7-E115DE725714@krugs.de>
Message-ID: <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>

ok, my problem is the follwoing
a<- read_json(json_file)
a$fields$geo_applicability$fields$countries[[1]]$fields$name

this was i can see the name of a single country reported first in the json. HOwever, i  need to save all 59. My worry is that i have multiple files that i need to read and in some cases there will be one country reported and in some others multiple. How can i optimise the code?

Best,

________________________________
From: Rainer M Krug <Rainer at krugs.de>
Sent: 16 January 2020 14:47
To: Ioanna Ioannou <ii54250 at msn.com>
Subject: Re: [R] How to save multiple values of a variable in a json file in R

Check the hep of the read_json() function and please keep the conversation on the list

On 16 Jan 2020, at 15:42, Ioanna Ioannou <ii54250 at msn.com<mailto:ii54250 at msn.com>> wrote:

I will try the package but i could do with a worked example.

________________________________
From: Rainer M Krug <Rainer at krugs.de<mailto:Rainer at krugs.de>>
Sent: 16 January 2020 14:29
To: Ioanna Ioannou <ii54250 at msn.com<mailto:ii54250 at msn.com>>
Subject: Re: [R] How to save multiple values of a variable in a json file in R

Have you looked at the jsonlite package?

Rainer


On 16 Jan 2020, at 15:21, Ioanna Ioannou <ii54250 at msn.com<mailto:ii54250 at msn.com>> wrote:

hello everyone,

and happy new year!

I have this problem: I want to save the name of the 'countries', the 'taxonomy_gem' and the 'minimum_im' and 'maximum_im' . The problem is that there are several names of countries.  How can i transfer the information from the json file to an R data.frame? See below for the json file.

Best,
ioanna



json_file<- {
   "pk": 670,
   "model": "vulnerability.generalinformation",
   "fields": {
       "category": "Structure class",
       "article_title": "A GLOBAL DATABASE OF VULNERABILITY MODELS FOR SEISMIC RISK ASSESSMENT",
       "name": "CR/LFINF/DUL/H:2",
       "publication_conference_name": "16EECE",
       "llrs": null,
       "material": null,
       "web_link": "",
       "owner": {
           "pk": 1900,
           "model": "people.profile",
           "fields": {
               "username": "lmartins",
               "first_name": "",
               "last_name": "",
               "email": "luis.martins at globalquakemodel.org<mailto:luis.martins at globalquakemodel.org>"
           }
       },
       "general_comments": "",
       "geo_applicability": {
           "pk": 669,
           "model": "vulnerability.geoapplicability",
           "fields": {
               "general_information": 670,
               "area": "",
               "countries": [
                   {
                       "pk": "CIV",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Cte d'Ivoire"
                       }
                   },
                   {
                       "pk": "CMR",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Cameroon"
                       }
                   },
                   {
                       "pk": "SDN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Sudan"
                       }
                   },
                   {
                       "pk": "SSD",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "South Sudan"
                       }
                   },
                   {
                       "pk": "TUN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Tunisia"
                       }
                   },
                   {
                       "pk": "TGO",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Togo"
                       }
                   },
                   {
                       "pk": "ZAF",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "South Africa"
                       }
                   },
                   {
                       "pk": "NER",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Niger"
                       }
                   },
                   {
                       "pk": "MAR",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Morocco"
                       }
                   },
                   {
                       "pk": "KEN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Kenya"
                       }
                   },
                   {
                       "pk": "SYC",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Seychelles"
                       }
                   },
                   {
                       "pk": "ESH",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Western Sahara"
                       }
                   },
                   {
                       "pk": "SHN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Saint Helena"
                       }
                   },
                   {
                       "pk": "REU",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Reunion"
                       }
                   },
                   {
                       "pk": "SLE",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Sierra Leone"
                       }
                   },
                   {
                       "pk": "DJI",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Djibouti"
                       }
                   },
                   {
                       "pk": "STP",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Sao Tome and Principe"
                       }
                   },
                   {
                       "pk": "BDI",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Burundi"
                       }
                   },
                   {
                       "pk": "MLI",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Mali"
                       }
                   },
                   {
                       "pk": "GMB",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Gambia"
                       }
                   },
                   {
                       "pk": "ZMB",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Zambia"
                       }
                   },
                   {
                       "pk": "RWA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Rwanda"
                       }
                   },
                   {
                       "pk": "MWI",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Malawi"
                       }
                   },
                   {
                       "pk": "BFA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Burkina Faso"
                       }
                   },
                   {
                       "pk": "GAB",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Gabon"
                       }
                   },
                   {
                       "pk": "TCD",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Chad"
                       }
                   },
                   {
                       "pk": "SEN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Senegal"
                       }
                   },
                   {
                       "pk": "NAM",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Namibia"
                       }
                   },
                   {
                       "pk": "ATF",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "French Southern Territories"
                       }
                   },
                   {
                       "pk": "BWA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Botswana"
                       }
                   },
                   {
                       "pk": "TZA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Tanzania"
                       }
                   },
                   {
                       "pk": "ERI",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Eritrea"
                       }
                   },
                   {
                       "pk": "MYT",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Mayotte"
                       }
                   },
                   {
                       "pk": "SOM",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Somalia"
                       }
                   },
                   {
                       "pk": "UGA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Uganda"
                       }
                   },
                   {
                       "pk": "LSO",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Lesotho"
                       }
                   },
                   {
                       "pk": "LBY",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Libya"
                       }
                   },
                   {
                       "pk": "LBR",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Liberia"
                       }
                   },
                   {
                       "pk": "COD",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Democratic Republic of the Congo"
                       }
                   },
                   {
                       "pk": "CPV",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Cape Verde"
                       }
                   },
                   {
                       "pk": "CAF",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Central African Republic"
                       }
                   },
                   {
                       "pk": "COM",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Comoros"
                       }
                   },
                   {
                       "pk": "ETH",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Ethiopia"
                       }
                   },
                   {
                       "pk": "GIN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Guinea"
                       }
                   },
                   {
                       "pk": "COG",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Republic of Congo"
                       }
                   },
                   {
                       "pk": "GHA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Ghana"
                       }
                   },
                   {
                       "pk": "SWZ",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Swaziland"
                       }
                   },
                   {
                       "pk": "GNB",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Guinea-Bissau"
                       }
                   },
                   {
                       "pk": "MDG",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Madagascar"
                       }
                   },
                   {
                       "pk": "ZWE",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Zimbabwe"
                       }
                   },
                   {
                       "pk": "MOZ",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Mozambique"
                       }
                   },
                   {
                       "pk": "MRT",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Mauritania"
                       }
                   },
                   {
                       "pk": "MUS",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Mauritius"
                       }
                   },
                   {
                       "pk": "NGA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Nigeria"
                       }
                   },
                   {
                       "pk": "BEN",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Benin"
                       }
                   },
                   {
                       "pk": "GNQ",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Equatorial Guinea"
                       }
                   },
                   {
                       "pk": "EGY",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Egypt"
                       }
                   },
                   {
                       "pk": "AGO",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Angola"
                       }
                   },
                   {
                       "pk": "DZA",
                       "model": "vulnerability.country",
                       "fields": {
                           "is_visible": true,
                           "region": 2,
                           "name": "Algeria"
                       }
                   }
               ],
               "lon": null,
               "address": "",
               "lat": null
           }
       },
       "authors": "Martins and Silva",
       "use_case_information": "",
       "structure_type": "Building",
       "taxonomy_gem": "DX+D99/MAT99/L99/DY+D99/MAT99/L99/H99/Y99/OC99/BP99/PLF99/IR99/EW99/RSH99+RMT99+R99+RWC99/F99+FWC99/FOS99",
       "year": 2018,
       "type_of_assessment": "Vulnerability",
       "taxonomy_type": {
           "pk": 1,
           "model": "vulnerability.taxonomytype",
           "fields": {
               "user_def": false,
               "name": "GEM"
           }
       },
       "taxonomy_text": "",
       "vulnerability_func": {
           "pk": 30,
           "model": "vulnerability.vulnerabilityfunc",
           "fields": {
               "general_information": 670,
               "predictor_var": {
                   "pk": 602,
                   "model": "vulnerability.predictorvar",
                   "fields": {
                       "type_of_period": "Telastic (s)",
                       "minimum_im": 0.05,
                       "intensity_measure_type": "Sa(T)",
                       "fragility_func": null,
                       "period": 0.3,
                       "vulnerability_func": 30,
                       "maximum_im": 8,
                       "intensity_measure_unit": "g"
                   }
               },
               "func_distr_vuln_discr": {
                   "pk": 23,
                   "model": "vulnerability.funcdistrvulndiscr",
                   "fields": {
                       "resp_var_mean_val": "0.000025;0.000033;0.000045;0.000059;0.000078;0.000101;0.000131;0.00017;0.000217;0.000277;0.00035;0.00044;0.000551;0.000684;0.000844;0.001036;0.001264;0.001532;0.001846;0.002212;0.002635;0.003121;0.003676;0.004306;0.005016;0.005812;0.006701;0.007685;0.008772;0.009966;0.01127;0.012691;0.014233;0.0159;0.0177;0.019639;0.021726;0.023972;0.026388;0.028991;0.0318;0.034838;0.038132;0.041714;0.04562;0.049893;0.05458;0.059733;0.065409;0.07167;0.078582;0.086213;0.094633;0.103913;0.114125;0.125335;0.13761;0.151007;0.165578;0.181366;0.1984;0.216699;0.236266;0.257091;0.279144;0.302379;0.326733;0.352124;0.378455;0.40561;0.433459;0.461862;0.490663;0.519703;0.548813;0.577824;0.606566;0.634874;0.662589;0.68956;0.715649;0.740732;0.764702;0.787467;0.808956;0.829114;0.847907;0.865317;0.881347;0.896012;0.909344;0.921388;0.932199;0.941842;0.950388;0.957913;0.964497;0.97022;0.975163;0.979405",
                       "resp_var_val_coeff": "",
                       "predictor_var_im_val": "0.05;0.05263;0.055398;0.058312;0.06138;0.064608;0.068007;0.071584;0.07535;0.079313;0.083485;0.087876;0.092499;0.097364;0.102486;0.107877;0.113551;0.119524;0.125811;0.132429;0.139395;0.146727;0.154445;0.162569;0.171121;0.180122;0.189596;0.199569;0.210067;0.221117;0.232748;0.24499;0.257877;0.271442;0.28572;0.300749;0.316569;0.333221;0.350749;0.369198;0.388619;0.40906;0.430577;0.453226;0.477066;0.502161;0.528575;0.556379;0.585645;0.61645;0.648876;0.683008;0.718935;0.756752;0.796558;0.838458;0.882561;0.928985;0.977851;1.029287;1.083429;1.140418;1.200405;1.263548;1.330012;1.399972;1.473613;1.551126;1.632717;1.7186;1.809;1.904156;2.004317;2.109746;2.220721;2.337534;2.460491;2.589915;2.726148;2.869546;3.020488;3.179369;3.346607;3.522643;3.707938;3.902979;4.108281;4.324381;4.551848;4.791281;5.043307;5.308591;5.587829;5.881755;6.191142;6.516804;6.859595;7.220418;7.60022;8",
                       "vulnerability_func": 30,
                       "func_distr_shape": null,
                       "data_pts_num": 100
                   }
               },
               "method_of_estimation": "Analytical",
               "func_distr_type": "Discrete",
               "resp_var": "Damage factor"
           }
       }
   }
}

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office: +41 (0)44 635 47 64
Cell:        +41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch<mailto:Rainer.Krug at uzh.ch>
Rainer at krugs.de<mailto:Rainer at krugs.de>
Skype:     RMkrug

PGP: 0x0F52F982

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office: +41 (0)44 635 47 64
Cell:        +41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch<mailto:Rainer.Krug at uzh.ch>
Rainer at krugs.de<mailto:Rainer at krugs.de>
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Jan 16 18:03:55 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 16 Jan 2020 18:03:55 +0100
Subject: [R] citing old(er) versions of packages
Message-ID: <957faa8d-9f0e-0ec5-5801-5a7c860e9b15@rgzm.de>

Dear useRs,

I want to cite the packages I have used in my analyses for a paper. I
have recorded through sessionInfo() which packages and which versions I
used for a given analysis.

I know how to cite a package using the citation() function, but the
problem is that in the meantime, I have updated these packages.
citation() returns the citation for the actual installed version. And
citations change over time (e.g. with more people getting involved in
the development and maintenance of a package).

Now the question is how do I find out how to cite a given, not actual
version of a package?

Thank you in advance.
Best regards,
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From m@rc_@chw@rtz @end|ng |rom me@com  Thu Jan 16 18:31:35 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 16 Jan 2020 12:31:35 -0500
Subject: [R] citing old(er) versions of packages
In-Reply-To: <957faa8d-9f0e-0ec5-5801-5a7c860e9b15@rgzm.de>
References: <957faa8d-9f0e-0ec5-5801-5a7c860e9b15@rgzm.de>
Message-ID: <5D399ECA-950B-45DD-8DBD-3C5F51BA9F0A@me.com>


> On Jan 16, 2020, at 12:03 PM, Ivan Calandra <calandra at rgzm.de> wrote:
> 
> Dear useRs,
> 
> I want to cite the packages I have used in my analyses for a paper. I
> have recorded through sessionInfo() which packages and which versions I
> used for a given analysis.
> 
> I know how to cite a package using the citation() function, but the
> problem is that in the meantime, I have updated these packages.
> citation() returns the citation for the actual installed version. And
> citations change over time (e.g. with more people getting involved in
> the development and maintenance of a package).
> 
> Now the question is how do I find out how to cite a given, not actual
> version of a package?
> 
> Thank you in advance.
> Best regards,
> Ivan


Hi,

If you know the package versions that you wish to cite and they are no longer installed locally, you can use the content of either the CITATION file for the package, if included, or the content of the DESCRIPTION file, for the relevant version of the package. 

The easiest way to do this may be to download the source tarball for the package from the CRAN archive for the package or wherever the package is located, if not on CRAN.

An alternative, if the package is stored in an online VC system (e.g. Github), is that you may be able to read the relevant file from that system for the version of the file that is tagged appropriately.

Regards,

Marc Schwartz


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Jan 16 21:47:38 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 17 Jan 2020 09:47:38 +1300
Subject: [R] Extracting a particular column from list
In-Reply-To: <82a3950f-b329-a5b4-487b-0dc0449b5ae1@sapo.pt>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <82a3950f-b329-a5b4-487b-0dc0449b5ae1@sapo.pt>
Message-ID: <a3821e18-7d24-901f-6010-f6a27f1bf098@auckland.ac.nz>


On 17/01/20 1:55 am, Rui Barradas wrote:

> Hello,
> 
> What column and what list?
> Please post a reproducible example, see the link at the bottom of this 
> mail and? [1], [2], [3].
> 
> [1] https://cran.r-project.org/web/packages/reprex/index.html
> [2] 
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 
> 
> [3] https://stackoverflow.com/help/mcve
> 
> Hope this helps,

The OP should note that lists in general *do not have* columns.  Data 
frames (which are a special case of lists) do have columns.

Lists have "*entries*" or "components".  It is important to get your 
terminology right and to understand the concepts that you are dealing 
with.  Slap-dash hammer and hope is a recipe for disaster, especially
in R.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jan 17 08:09:05 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 17 Jan 2020 07:09:05 +0000
Subject: [R] Extracting a particular column from list
In-Reply-To: <CAHz+bWZHHMYL7eTJeP2u_5cD9_RmAWRkGY_H_2YGpjinJep57A@mail.gmail.com>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <82a3950f-b329-a5b4-487b-0dc0449b5ae1@sapo.pt>
 <a3821e18-7d24-901f-6010-f6a27f1bf098@auckland.ac.nz>
 <CAHz+bWZHHMYL7eTJeP2u_5cD9_RmAWRkGY_H_2YGpjinJep57A@mail.gmail.com>
Message-ID: <e443304a-34b0-57b6-1d9d-caddd9347b59@sapo.pt>

Hello,

Inline.


?s 22:03 de 16/01/20, Mark Leeds escreveu:
> I nominate the last sentence of Rolf's comment as a fortune.

Second.


Rui Barradas

> 
> 
> On Thu, Jan 16, 2020 at 3:48 PM Rolf Turner <r.turner at auckland.ac.nz 
> <mailto:r.turner at auckland.ac.nz>> wrote:
> 
> 
>     On 17/01/20 1:55 am, Rui Barradas wrote:
> 
>      > Hello,
>      >
>      > What column and what list?
>      > Please post a reproducible example, see the link at the bottom of
>     this
>      > mail and? [1], [2], [3].
>      >
>      > [1] https://cran.r-project.org/web/packages/reprex/index.html
>      > [2]
>      >
>     https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
>      >
>      > [3] https://stackoverflow.com/help/mcve
>      >
>      > Hope this helps,
> 
>     The OP should note that lists in general *do not have* columns.? Data
>     frames (which are a special case of lists) do have columns.
> 
>     Lists have "*entries*" or "components".? It is important to get your
>     terminology right and to understand the concepts that you are dealing
>     with.? Slap-dash hammer and hope is a recipe for disaster, especially
>     in R.
> 
>     cheers,
> 
>     Rolf Turner
> 
>     -- 
>     Honorary Research Fellow
>     Department of Statistics
>     University of Auckland
>     Phone: +64-9-373-7599 ext. 88276
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Fri Jan 17 08:33:37 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Fri, 17 Jan 2020 08:33:37 +0100
Subject: [R] Strange behaviour of R?
Message-ID: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>

Hi,

I wrote a function like

test <- function(FUN, args) {
   print(FUN)
   FUN(args)
}

When I call it lieke this

test(mean, 1:10)
test(NULL, 1:10)

then the second call still uses mean, although I set FUN to NULL. Is 
that ok?

Actually, I used something like

test(mean, list(x=1:10, na.rm=TRUE))

which actually crashed R, but I can not reproduce it. Of course, when I 
replaced FUN(args) with do.call(FUN, args) then everything works fine.

Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From R@|ner @end|ng |rom krug@@de  Fri Jan 17 08:42:10 2020
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Fri, 17 Jan 2020 08:42:10 +0100
Subject: [R] Strange behaviour of R?
In-Reply-To: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
Message-ID: <0CE0E863-C94A-4456-A2AB-AABDD198F59B@krugs.de>

Hi

> On 17 Jan 2020, at 08:33, Sigbert Klinke <sigbert at wiwi.hu-berlin.de <mailto:sigbert at wiwi.hu-berlin.de>> wrote:
> 
> Hi,
> 
> I wrote a function like
> 
> test <- function(FUN, args) {
>  print(FUN)
>  FUN(args)
> }
> 
> When I call it lieke this
> 
> test(mean, 1:10)
> test(NULL, 1:10)
> 
> then the second call still uses mean, although I set FUN to NULL. Is that ok?

Not for me - macOS, R 3.6.2


> 
> Actually, I used something like
> 
> test(mean, list(x=1:10, na.rm=TRUE))

Fails as expected,

Rainer

> 
> which actually crashed R, but I can not reproduce it. Of course, when I replaced FUN(args) with do.call(FUN, args) then everything works fine.
> 
> Sigbert
> 
> -- 
> https://hu.berlin/sk <https://hu.berlin/sk>
> https://hu.berlin/mmstat3
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email: ? ? ?Rainer.Krug at uzh.ch <mailto:Rainer.Krug at uzh.ch>
		Rainer at krugs.de <mailto:Rainer at krugs.de>
Skype:     RMkrug

PGP: 0x0F52F982





--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Jan 17 09:06:09 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Jan 2020 19:06:09 +1100
Subject: [R] Extracting a particular column from list
In-Reply-To: <e443304a-34b0-57b6-1d9d-caddd9347b59@sapo.pt>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <82a3950f-b329-a5b4-487b-0dc0449b5ae1@sapo.pt>
 <a3821e18-7d24-901f-6010-f6a27f1bf098@auckland.ac.nz>
 <CAHz+bWZHHMYL7eTJeP2u_5cD9_RmAWRkGY_H_2YGpjinJep57A@mail.gmail.com>
 <e443304a-34b0-57b6-1d9d-caddd9347b59@sapo.pt>
Message-ID: <CA+8X3fUqrGc+P4XZ5kC7x71XVcb1Fti41A+sAFRfoCpd1LqZAg@mail.gmail.com>

Good one. When I saw this thread beginning to lengthen, I thought:

"Ask an unanswerable question and you get philosophy."

Jim

On Fri, Jan 17, 2020 at 6:10 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Inline.
>
>
> ?s 22:03 de 16/01/20, Mark Leeds escreveu:
> > I nominate the last sentence of Rolf's comment as a fortune.
>
> Second.
>
>
> Rui Barradas
>
> >
> >
> > On Thu, Jan 16, 2020 at 3:48 PM Rolf Turner <r.turner at auckland.ac.nz
> > <mailto:r.turner at auckland.ac.nz>> wrote:
> >
> >
> >     On 17/01/20 1:55 am, Rui Barradas wrote:
> >
> >      > Hello,
> >      >
> >      > What column and what list?
> >      > Please post a reproducible example, see the link at the bottom of
> >     this
> >      > mail and  [1], [2], [3].
> >      >
> >      > [1] https://cran.r-project.org/web/packages/reprex/index.html
> >      > [2]
> >      >
> >     https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >
> >      >
> >      > [3] https://stackoverflow.com/help/mcve
> >      >
> >      > Hope this helps,
> >
> >     The OP should note that lists in general *do not have* columns.  Data
> >     frames (which are a special case of lists) do have columns.
> >
> >     Lists have "*entries*" or "components".  It is important to get your
> >     terminology right and to understand the concepts that you are dealing
> >     with.  Slap-dash hammer and hope is a recipe for disaster, especially
> >     in R.
> >
> >     cheers,
> >
> >     Rolf Turner
> >
> >     --
> >     Honorary Research Fellow
> >     Department of Statistics
> >     University of Auckland
> >     Phone: +64-9-373-7599 ext. 88276
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Fri Jan 17 09:21:59 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Fri, 17 Jan 2020 09:21:59 +0100
Subject: [R] Strange behaviour of R?
In-Reply-To: <0CE0E863-C94A-4456-A2AB-AABDD198F59B@krugs.de>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
 <0CE0E863-C94A-4456-A2AB-AABDD198F59B@krugs.de>
Message-ID: <6dd50b1f-7ea4-36dd-9fe0-5c31d19939ea@wiwi.hu-berlin.de>

Hi,

Am 17.01.20 um 08:42 schrieb Rainer M Krug:
 > Not for me - macOS, R 3.6.2

Sorry, I forgot to add: Ubuntu 18.04.3 LTS, R 3.6.2

Best Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From m@||||@t@ @end|ng |rom pp@|net@||  Fri Jan 17 09:33:28 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Fri, 17 Jan 2020 10:33:28 +0200
Subject: [R] Strange behaviour of R?
In-Reply-To: <6dd50b1f-7ea4-36dd-9fe0-5c31d19939ea@wiwi.hu-berlin.de>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
 <0CE0E863-C94A-4456-A2AB-AABDD198F59B@krugs.de>
 <6dd50b1f-7ea4-36dd-9fe0-5c31d19939ea@wiwi.hu-berlin.de>
Message-ID: <1bfa225bb514d01c6e6a681c2b13f5f72b11e233.camel@pp.inet.fi>

Hi,

cannot reproduce, either, on my Linuxmint 19.3 + R 3.6.2.

Here the outputs:

--- snip ---

> test(mean, 1:10)
[1] 5.5
> test(NULL, 1:10)
NULL
Error in FUN(args) : could not find function "FUN"
> test(mean, list(x=1:10, na.rm=TRUE))
[1] NA
Warning message:
In mean.default(args) : argument is not numeric or logical: returning
NA

--- snip ---

Best,
Kimmo

pe, 2020-01-17 kello 09:21 +0100, Sigbert Klinke kirjoitti:
> Hi,
> 
> Am 17.01.20 um 08:42 schrieb Rainer M Krug:
>  > Not for me - macOS, R 3.6.2
> 
> Sorry, I forgot to add: Ubuntu 18.04.3 LTS, R 3.6.2
> 
> Best Sigbert
>


From c@|@ndr@ @end|ng |rom rgzm@de  Fri Jan 17 09:37:20 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Fri, 17 Jan 2020 09:37:20 +0100
Subject: [R] citing old(er) versions of packages
In-Reply-To: <5D399ECA-950B-45DD-8DBD-3C5F51BA9F0A@me.com>
References: <957faa8d-9f0e-0ec5-5801-5a7c860e9b15@rgzm.de>
 <5D399ECA-950B-45DD-8DBD-3C5F51BA9F0A@me.com>
Message-ID: <736805d9-8578-2b39-6ca0-2f51ee6a6ebe@rgzm.de>

Dear Marc,

Thank you, exactly what I needed!

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 16/01/2020 18:31, Marc Schwartz wrote:
>> On Jan 16, 2020, at 12:03 PM, Ivan Calandra <calandra at rgzm.de> wrote:
>>
>> Dear useRs,
>>
>> I want to cite the packages I have used in my analyses for a paper. I
>> have recorded through sessionInfo() which packages and which versions I
>> used for a given analysis.
>>
>> I know how to cite a package using the citation() function, but the
>> problem is that in the meantime, I have updated these packages.
>> citation() returns the citation for the actual installed version. And
>> citations change over time (e.g. with more people getting involved in
>> the development and maintenance of a package).
>>
>> Now the question is how do I find out how to cite a given, not actual
>> version of a package?
>>
>> Thank you in advance.
>> Best regards,
>> Ivan
>
> Hi,
>
> If you know the package versions that you wish to cite and they are no longer installed locally, you can use the content of either the CITATION file for the package, if included, or the content of the DESCRIPTION file, for the relevant version of the package. 
>
> The easiest way to do this may be to download the source tarball for the package from the CRAN archive for the package or wherever the package is located, if not on CRAN.
>
> An alternative, if the package is stored in an online VC system (e.g. Github), is that you may be able to read the relevant file from that system for the version of the file that is tagged appropriately.
>
> Regards,
>
> Marc Schwartz
>
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jan 17 09:49:29 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 17 Jan 2020 09:49:29 +0100
Subject: [R] Strange behaviour of R?
In-Reply-To: <6dd50b1f-7ea4-36dd-9fe0-5c31d19939ea@wiwi.hu-berlin.de>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
 <0CE0E863-C94A-4456-A2AB-AABDD198F59B@krugs.de>
 <6dd50b1f-7ea4-36dd-9fe0-5c31d19939ea@wiwi.hu-berlin.de>
Message-ID: <24097.29977.430108.767708@stat.math.ethz.ch>

>>>>> Sigbert Klinke 
>>>>>     on Fri, 17 Jan 2020 09:21:59 +0100 writes:

    > Hi,
    > Am 17.01.20 um 08:42 schrieb Rainer M Krug:
    >> Not for me - macOS, R 3.6.2

    > Sorry, I forgot to add: Ubuntu 18.04.3 LTS, R 3.6.2

Sorry but that's very hard to believe, i.e.,
that such fundamental R behavior would depend on the exact OS
version ... unless you did compile (and link) R yourself *and*
are using somewhat peculiar compiler / linker / ... settings ?


Context : 

	> I wrote a function like

	> test <- function(FUN, args) {
	>    print(FUN)
	>    FUN(args)
	> }

	> When I call it lieke this

	> test(mean, 1:10)
	> test(NULL, 1:10)

	> then the second call still uses mean, although I set FUN to NULL. Is 
	> that ok?

definitely not ok, and also not reproducible for me.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jan 17 11:40:07 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 17 Jan 2020 05:40:07 -0500
Subject: [R] Strange behaviour of R?
In-Reply-To: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
Message-ID: <f60e8926-8e35-e920-4142-832f61b87aed@gmail.com>

On 17/01/2020 2:33 a.m., Sigbert Klinke wrote:
> Hi,
> 
> I wrote a function like
> 
> test <- function(FUN, args) {
>     print(FUN)
>     FUN(args)
> }
> 
> When I call it lieke this
> 
> test(mean, 1:10)
> test(NULL, 1:10)
> 
> then the second call still uses mean, although I set FUN to NULL. Is
> that ok?

You probably have a function defined in your global environment that is 
named FUN and acts like mean.

The general rule in R is that it only looks for objects of mode function 
when trying to find something used as a function.  So in your second 
case, when trying to evaluate FUN(args), R will look for a function 
named FUN in the local evaluation frame, and won't find one:  FUN is 
NULL there.  Then it will go to the environment of test, which is likely 
the global environment, and look there.  That's where it probably found 
the function.

For example, try this:

FUN <- function(...) print('FUN was called')


test <- function(FUN, args) {
    print(FUN)
    FUN(args)
}

test(NULL, 1:10)

Duncan Murdoch

> 
> Actually, I used something like
> 
> test(mean, list(x=1:10, na.rm=TRUE))
> 
> which actually crashed R, but I can not reproduce it. Of course, when I
> replaced FUN(args) with do.call(FUN, args) then everything works fine.
> 
> Sigbert
>


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Fri Jan 17 13:14:31 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Fri, 17 Jan 2020 13:14:31 +0100
Subject: [R] Strange behaviour of R?
In-Reply-To: <f60e8926-8e35-e920-4142-832f61b87aed@gmail.com>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
 <f60e8926-8e35-e920-4142-832f61b87aed@gmail.com>
Message-ID: <be566cae-8c81-8f90-ce16-af4491ace54e@wiwi.hu-berlin.de>

Hi,

> You probably have a function defined in your global environment that is 
> named FUN and acts like mean.

You are right.

Thanks Sigbert


-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From m@rk|eed@2 @end|ng |rom gm@||@com  Thu Jan 16 23:03:06 2020
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Thu, 16 Jan 2020 17:03:06 -0500
Subject: [R] Extracting a particular column from list
In-Reply-To: <a3821e18-7d24-901f-6010-f6a27f1bf098@auckland.ac.nz>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <82a3950f-b329-a5b4-487b-0dc0449b5ae1@sapo.pt>
 <a3821e18-7d24-901f-6010-f6a27f1bf098@auckland.ac.nz>
Message-ID: <CAHz+bWZHHMYL7eTJeP2u_5cD9_RmAWRkGY_H_2YGpjinJep57A-6091@mail.gmail.com>

I nominate the last sentence of Rolf's comment as a fortune.


On Thu, Jan 16, 2020 at 3:48 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On 17/01/20 1:55 am, Rui Barradas wrote:
>
> > Hello,
> >
> > What column and what list?
> > Please post a reproducible example, see the link at the bottom of this
> > mail and  [1], [2], [3].
> >
> > [1] https://cran.r-project.org/web/packages/reprex/index.html
> > [2]
> >
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >
> > [3] https://stackoverflow.com/help/mcve
> >
> > Hope this helps,
>
> The OP should note that lists in general *do not have* columns.  Data
> frames (which are a special case of lists) do have columns.
>
> Lists have "*entries*" or "components".  It is important to get your
> terminology right and to understand the concepts that you are dealing
> with.  Slap-dash hammer and hope is a recipe for disaster, especially
> in R.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Jan 16 13:36:19 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 16 Jan 2020 14:36:19 +0200
Subject: [R] Fwd:  Extracting a particular column from list
In-Reply-To: <393206509.8239350.1579174278504@mail.yahoo.com>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <CAGgJW765wm1m94y013Us+Mb0bsnrXnOS=ViBbUMUkcu1WVpSfA@mail.gmail.com>
 <393206509.8239350.1579174278504@mail.yahoo.com>
Message-ID: <CAGgJW754TWP7eb0u5hepAbQH=igJfeUEP+9GHeXhyrEsOiKUAA-9106@mail.gmail.com>

[Putting back onto r-help]

You could try sapply() and lapply().

> e <- sapply( 1:length(u), function(i) u[[i]][1] )
> e
# [1] "1" "a"    (note that the integer 1 became a character string "1")

> f <- lapply( 1:length(u), function(i) u[[i]][1] )
> f
[[1]]
[1] 1

[[2]]
[1] "a"

In this case sapply will try to create a vector, and all its elements will
need to be of the same type, so you end up with a character vector.
The second method returns a list, which may or may not be of use to you,
but each element of the list retains its type.



---------- Forwarded message ---------
From: Faheem Jan <faheemjan93 at yahoo.com>
Date: Thu, Jan 16, 2020 at 1:31 PM
Subject: Re: [R] Extracting a particular column from list
To: ericjberger at gmail.com <ericjberger at gmail.com>


In my problem i want to extract the first value of a and b and so on... So
using such data for further analysis

Sent from Yahoo Mail on Android
<https://go.onelink.me/107872968?pid=InProduct&c=Global_Internal_YGrowth_AndroidEmailSig__AndroidUsers&af_wl=ym&af_sub1=Internal&af_sub2=Global_YGrowth&af_sub3=EmailSignature>

On Thu, 16 Jan 2020 at 4:24 PM, Eric Berger
<ericjberger at gmail.com> wrote:
> u <- list(a=1:5, b=letters[1:3])
> u
# $a
# [1] 1 2 3 4 5
#
# $b
# [1] "a" "b" "c"
> u[["a"]]
[1] 1 2 3 4 5





On Thu, Jan 16, 2020 at 1:04 PM Faheem Jan via R-help <r-help at r-project.org>
wrote:

Hi. How to extract a column from the list.. I will be thanks full..

Sent from Yahoo Mail on Android
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Jan 15 22:45:44 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 16 Jan 2020 08:45:44 +1100
Subject: [R] Reporting missing dates
In-Reply-To: <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
References: <002701d5cbea$aca09ad0$05e1d070$.ref@sbcglobal.net>
 <002701d5cbea$aca09ad0$05e1d070$@sbcglobal.net>
Message-ID: <CA+8X3fW2WbO9pKFZDJFuR3jDNeYrLawVwgx2O=goBhDJasf1OA-5347@mail.gmail.com>


Hi Jeff,
As I'm sure you realize, that only tells you whether a date is within
the range that you have specified. Do you only want to find dates
within a certain range:

new_date<-as.Date("2020-01-10")
new_date < min(d) | new_date > max(d)

or maybe whether the text string specifying the date is NA or cannot
be converted to a date?

Jim

On Thu, Jan 16, 2020 at 8:28 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> R-help Forum
>
> I have a 20 year data set and I am looking for a way to find missing dates.
> I wrote this and its works, but am wounding if there is a better way?
>
> d <- c('2020-01-01', '2020-01-02', '2020-01-04', '2020-01-05')
> d <- as.Date(d)
> date_range <- seq(min(d), max(d), by = 1)
> date_range[!date_range %in% d]
>
>
> Sincerely
>
> Jeff Reichman
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Jan 20 08:03:29 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 20 Jan 2020 07:03:29 +0000
Subject: [R] Fwd:  Extracting a particular column from list
In-Reply-To: <CAGgJW754TWP7eb0u5hepAbQH=igJfeUEP+9GHeXhyrEsOiKUAA-9106@mail.gmail.com>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <CAGgJW765wm1m94y013Us+Mb0bsnrXnOS=ViBbUMUkcu1WVpSfA@mail.gmail.com>
 <393206509.8239350.1579174278504@mail.yahoo.com>
 <CAGgJW754TWP7eb0u5hepAbQH=igJfeUEP+9GHeXhyrEsOiKUAA-9106@mail.gmail.com>
Message-ID: <cf652c25cf81471ca143de41d97d4303@SRVEXCHCM1302.precheza.cz>

Or simply

lapply(u, "[", 1)
$a
[1] 1

$b
[1] "a"

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Eric Berger
> Sent: Thursday, January 16, 2020 1:36 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] Fwd: Extracting a particular column from list
> 
> [Putting back onto r-help]
> 
> You could try sapply() and lapply().
> 
> > e <- sapply( 1:length(u), function(i) u[[i]][1] ) e
> # [1] "1" "a"    (note that the integer 1 became a character string "1")
> 
> > f <- lapply( 1:length(u), function(i) u[[i]][1] ) f
> [[1]]
> [1] 1
> 
> [[2]]
> [1] "a"
> 
> In this case sapply will try to create a vector, and all its elements will
need to
> be of the same type, so you end up with a character vector.
> The second method returns a list, which may or may not be of use to you,
> but each element of the list retains its type.
> 
> 
> 
> ---------- Forwarded message ---------
> From: Faheem Jan <faheemjan93 at yahoo.com>
> Date: Thu, Jan 16, 2020 at 1:31 PM
> Subject: Re: [R] Extracting a particular column from list
> To: ericjberger at gmail.com <ericjberger at gmail.com>
> 
> 
> In my problem i want to extract the first value of a and b and so on... So
> using such data for further analysis
> 
> Sent from Yahoo Mail on Android
> <https://go.onelink.me/107872968?pid=InProduct&c=Global_Internal_YGro
> wth_AndroidEmailSig__AndroidUsers&af_wl=ym&af_sub1=Internal&af_sub
> 2=Global_YGrowth&af_sub3=EmailSignature>
> 
> On Thu, 16 Jan 2020 at 4:24 PM, Eric Berger <ericjberger at gmail.com> wrote:
> > u <- list(a=1:5, b=letters[1:3])
> > u
> # $a
> # [1] 1 2 3 4 5
> #
> # $b
> # [1] "a" "b" "c"
> > u[["a"]]
> [1] 1 2 3 4 5
> 
> 
> 
> 
> 
> On Thu, Jan 16, 2020 at 1:04 PM Faheem Jan via R-help <r-help at r-
> project.org>
> wrote:
> 
> Hi. How to extract a column from the list.. I will be thanks full..
> 
> Sent from Yahoo Mail on Android
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@oknz @end|ng |rom gm@||@com  Sat Jan 18 12:17:33 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 19 Jan 2020 00:17:33 +1300
Subject: [R] 
 How to save multiple values of a variable in a json file in R
In-Reply-To: <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <17F90DC5-D0FD-4A2D-A6FA-0A22861A78CF@krugs.de>
 <DBBPR05MB6570B84F540BE7F511103A70F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <B4D78F92-CB0E-42C8-99A7-E115DE725714@krugs.de>
 <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <CABcYAdLvFyYDS+rFD3fboAy15Ydhks=ng82AsUZqBU9ZDU_j_A-3622@mail.gmail.com>


In your example, these keys occur
   1  countries
   1  maximum_im
   1  minimum_im
 61  name
 66  pk           -- many of these pertain to countries, some do not
   1  taxonomy_gem
It is not clear what you mean by 'the name of the countries'.
There appear to be 61 countries each with two 'names'.
I am guessing that you want the 'name' slots, not the locale-
independent 3-letter ISO codes.
So 'name' occurs once per country.
'maximum_im' and 'minimum_im' occur once per predictor_var?
And 'taxonomy_gem' appears to occur once per dataset.
Now in a data frame, every variable occurs the same number of times
(once per row = observation = case = thingy).
So, leaving aside the issue of parsing JSON, suppose someone
gave you
 - a vector of N country Names
 - a vector of P maximum_im values for Predictors
 - a vector of P minimum_im values for Predictors
 - a vector of T taxonomy_gems
How do you intend to fit these into a data frame?

On Fri, 17 Jan 2020 at 04:03, Ioanna Ioannou <ii54250 at msn.com> wrote:
>
> ok, my problem is the follwoing
> a<- read_json(json_file)
> a$fields$geo_applicability$fields$countries[[1]]$fields$name
>
> this was i can see the name of a single country reported first in the json. HOwever, i  need to save all 59. My worry is that i have multiple files that i need to read and in some cases there will be one country reported and in some others multiple. How can i optimise the code?
>
> Best,
>
> ________________________________
> From: Rainer M Krug <Rainer at krugs.de>
> Sent: 16 January 2020 14:47
> To: Ioanna Ioannou <ii54250 at msn.com>
> Subject: Re: [R] How to save multiple values of a variable in a json file in R
>
> Check the hep of the read_json() function and please keep the conversation on the list
>
> On 16 Jan 2020, at 15:42, Ioanna Ioannou <ii54250 at msn.com<mailto:ii54250 at msn.com>> wrote:
>
> I will try the package but i could do with a worked example.
>
> ________________________________
> From: Rainer M Krug <Rainer at krugs.de<mailto:Rainer at krugs.de>>
> Sent: 16 January 2020 14:29
> To: Ioanna Ioannou <ii54250 at msn.com<mailto:ii54250 at msn.com>>
> Subject: Re: [R] How to save multiple values of a variable in a json file in R
>
> Have you looked at the jsonlite package?
>
> Rainer
>
>
> On 16 Jan 2020, at 15:21, Ioanna Ioannou <ii54250 at msn.com<mailto:ii54250 at msn.com>> wrote:
>
> hello everyone,
>
> and happy new year!
>
> I have this problem: I want to save the name of the 'countries', the 'taxonomy_gem' and the 'minimum_im' and 'maximum_im' . The problem is that there are several names of countries.  How can i transfer the information from the json file to an R data.frame? See below for the json file.
>
> Best,
> ioanna
>
>
>
> json_file<- {
>    "pk": 670,
>    "model": "vulnerability.generalinformation",
>    "fields": {
>        "category": "Structure class",
>        "article_title": "A GLOBAL DATABASE OF VULNERABILITY MODELS FOR SEISMIC RISK ASSESSMENT",
>        "name": "CR/LFINF/DUL/H:2",
>        "publication_conference_name": "16EECE",
>        "llrs": null,
>        "material": null,
>        "web_link": "",
>        "owner": {
>            "pk": 1900,
>            "model": "people.profile",
>            "fields": {
>                "username": "lmartins",
>                "first_name": "",
>                "last_name": "",
>                "email": "luis.martins at globalquakemodel.org<mailto:luis.martins at globalquakemodel.org>"
>            }
>        },
>        "general_comments": "",
>        "geo_applicability": {
>            "pk": 669,
>            "model": "vulnerability.geoapplicability",
>            "fields": {
>                "general_information": 670,
>                "area": "",
>                "countries": [
>                    {
>                        "pk": "CIV",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Cte d'Ivoire"
>                        }
>                    },
>                    {
>                        "pk": "CMR",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Cameroon"
>                        }
>                    },
>                    {
>                        "pk": "SDN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Sudan"
>                        }
>                    },
>                    {
>                        "pk": "SSD",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "South Sudan"
>                        }
>                    },
>                    {
>                        "pk": "TUN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Tunisia"
>                        }
>                    },
>                    {
>                        "pk": "TGO",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Togo"
>                        }
>                    },
>                    {
>                        "pk": "ZAF",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "South Africa"
>                        }
>                    },
>                    {
>                        "pk": "NER",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Niger"
>                        }
>                    },
>                    {
>                        "pk": "MAR",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Morocco"
>                        }
>                    },
>                    {
>                        "pk": "KEN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Kenya"
>                        }
>                    },
>                    {
>                        "pk": "SYC",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Seychelles"
>                        }
>                    },
>                    {
>                        "pk": "ESH",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Western Sahara"
>                        }
>                    },
>                    {
>                        "pk": "SHN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Saint Helena"
>                        }
>                    },
>                    {
>                        "pk": "REU",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Reunion"
>                        }
>                    },
>                    {
>                        "pk": "SLE",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Sierra Leone"
>                        }
>                    },
>                    {
>                        "pk": "DJI",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Djibouti"
>                        }
>                    },
>                    {
>                        "pk": "STP",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Sao Tome and Principe"
>                        }
>                    },
>                    {
>                        "pk": "BDI",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Burundi"
>                        }
>                    },
>                    {
>                        "pk": "MLI",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Mali"
>                        }
>                    },
>                    {
>                        "pk": "GMB",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Gambia"
>                        }
>                    },
>                    {
>                        "pk": "ZMB",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Zambia"
>                        }
>                    },
>                    {
>                        "pk": "RWA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Rwanda"
>                        }
>                    },
>                    {
>                        "pk": "MWI",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Malawi"
>                        }
>                    },
>                    {
>                        "pk": "BFA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Burkina Faso"
>                        }
>                    },
>                    {
>                        "pk": "GAB",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Gabon"
>                        }
>                    },
>                    {
>                        "pk": "TCD",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Chad"
>                        }
>                    },
>                    {
>                        "pk": "SEN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Senegal"
>                        }
>                    },
>                    {
>                        "pk": "NAM",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Namibia"
>                        }
>                    },
>                    {
>                        "pk": "ATF",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "French Southern Territories"
>                        }
>                    },
>                    {
>                        "pk": "BWA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Botswana"
>                        }
>                    },
>                    {
>                        "pk": "TZA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Tanzania"
>                        }
>                    },
>                    {
>                        "pk": "ERI",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Eritrea"
>                        }
>                    },
>                    {
>                        "pk": "MYT",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Mayotte"
>                        }
>                    },
>                    {
>                        "pk": "SOM",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Somalia"
>                        }
>                    },
>                    {
>                        "pk": "UGA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Uganda"
>                        }
>                    },
>                    {
>                        "pk": "LSO",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Lesotho"
>                        }
>                    },
>                    {
>                        "pk": "LBY",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Libya"
>                        }
>                    },
>                    {
>                        "pk": "LBR",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Liberia"
>                        }
>                    },
>                    {
>                        "pk": "COD",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Democratic Republic of the Congo"
>                        }
>                    },
>                    {
>                        "pk": "CPV",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Cape Verde"
>                        }
>                    },
>                    {
>                        "pk": "CAF",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Central African Republic"
>                        }
>                    },
>                    {
>                        "pk": "COM",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Comoros"
>                        }
>                    },
>                    {
>                        "pk": "ETH",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Ethiopia"
>                        }
>                    },
>                    {
>                        "pk": "GIN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Guinea"
>                        }
>                    },
>                    {
>                        "pk": "COG",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Republic of Congo"
>                        }
>                    },
>                    {
>                        "pk": "GHA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Ghana"
>                        }
>                    },
>                    {
>                        "pk": "SWZ",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Swaziland"
>                        }
>                    },
>                    {
>                        "pk": "GNB",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Guinea-Bissau"
>                        }
>                    },
>                    {
>                        "pk": "MDG",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Madagascar"
>                        }
>                    },
>                    {
>                        "pk": "ZWE",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Zimbabwe"
>                        }
>                    },
>                    {
>                        "pk": "MOZ",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Mozambique"
>                        }
>                    },
>                    {
>                        "pk": "MRT",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Mauritania"
>                        }
>                    },
>                    {
>                        "pk": "MUS",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Mauritius"
>                        }
>                    },
>                    {
>                        "pk": "NGA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Nigeria"
>                        }
>                    },
>                    {
>                        "pk": "BEN",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Benin"
>                        }
>                    },
>                    {
>                        "pk": "GNQ",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Equatorial Guinea"
>                        }
>                    },
>                    {
>                        "pk": "EGY",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Egypt"
>                        }
>                    },
>                    {
>                        "pk": "AGO",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Angola"
>                        }
>                    },
>                    {
>                        "pk": "DZA",
>                        "model": "vulnerability.country",
>                        "fields": {
>                            "is_visible": true,
>                            "region": 2,
>                            "name": "Algeria"
>                        }
>                    }
>                ],
>                "lon": null,
>                "address": "",
>                "lat": null
>            }
>        },
>        "authors": "Martins and Silva",
>        "use_case_information": "",
>        "structure_type": "Building",
>        "taxonomy_gem": "DX+D99/MAT99/L99/DY+D99/MAT99/L99/H99/Y99/OC99/BP99/PLF99/IR99/EW99/RSH99+RMT99+R99+RWC99/F99+FWC99/FOS99",
>        "year": 2018,
>        "type_of_assessment": "Vulnerability",
>        "taxonomy_type": {
>            "pk": 1,
>            "model": "vulnerability.taxonomytype",
>            "fields": {
>                "user_def": false,
>                "name": "GEM"
>            }
>        },
>        "taxonomy_text": "",
>        "vulnerability_func": {
>            "pk": 30,
>            "model": "vulnerability.vulnerabilityfunc",
>            "fields": {
>                "general_information": 670,
>                "predictor_var": {
>                    "pk": 602,
>                    "model": "vulnerability.predictorvar",
>                    "fields": {
>                        "type_of_period": "Telastic (s)",
>                        "minimum_im": 0.05,
>                        "intensity_measure_type": "Sa(T)",
>                        "fragility_func": null,
>                        "period": 0.3,
>                        "vulnerability_func": 30,
>                        "maximum_im": 8,
>                        "intensity_measure_unit": "g"
>                    }
>                },
>                "func_distr_vuln_discr": {
>                    "pk": 23,
>                    "model": "vulnerability.funcdistrvulndiscr",
>                    "fields": {
>                        "resp_var_mean_val": "0.000025;0.000033;0.000045;0.000059;0.000078;0.000101;0.000131;0.00017;0.000217;0.000277;0.00035;0.00044;0.000551;0.000684;0.000844;0.001036;0.001264;0.001532;0.001846;0.002212;0.002635;0.003121;0.003676;0.004306;0.005016;0.005812;0.006701;0.007685;0.008772;0.009966;0.01127;0.012691;0.014233;0.0159;0.0177;0.019639;0.021726;0.023972;0.026388;0.028991;0.0318;0.034838;0.038132;0.041714;0.04562;0.049893;0.05458;0.059733;0.065409;0.07167;0.078582;0.086213;0.094633;0.103913;0.114125;0.125335;0.13761;0.151007;0.165578;0.181366;0.1984;0.216699;0.236266;0.257091;0.279144;0.302379;0.326733;0.352124;0.378455;0.40561;0.433459;0.461862;0.490663;0.519703;0.548813;0.577824;0.606566;0.634874;0.662589;0.68956;0.715649;0.740732;0.764702;0.787467;0.808956;0.829114;0.847907;0.865317;0.881347;0.896012;0.909344;0.921388;0.932199;0.941842;0.950388;0.957913;0.964497;0.97022;0.975163;0.979405",
>                        "resp_var_val_coeff": "",
>                        "predictor_var_im_val": "0.05;0.05263;0.055398;0.058312;0.06138;0.064608;0.068007;0.071584;0.07535;0.079313;0.083485;0.087876;0.092499;0.097364;0.102486;0.107877;0.113551;0.119524;0.125811;0.132429;0.139395;0.146727;0.154445;0.162569;0.171121;0.180122;0.189596;0.199569;0.210067;0.221117;0.232748;0.24499;0.257877;0.271442;0.28572;0.300749;0.316569;0.333221;0.350749;0.369198;0.388619;0.40906;0.430577;0.453226;0.477066;0.502161;0.528575;0.556379;0.585645;0.61645;0.648876;0.683008;0.718935;0.756752;0.796558;0.838458;0.882561;0.928985;0.977851;1.029287;1.083429;1.140418;1.200405;1.263548;1.330012;1.399972;1.473613;1.551126;1.632717;1.7186;1.809;1.904156;2.004317;2.109746;2.220721;2.337534;2.460491;2.589915;2.726148;2.869546;3.020488;3.179369;3.346607;3.522643;3.707938;3.902979;4.108281;4.324381;4.551848;4.791281;5.043307;5.308591;5.587829;5.881755;6.191142;6.516804;6.859595;7.220418;7.60022;8",
>                        "vulnerability_func": 30,
>                        "func_distr_shape": null,
>                        "data_pts_num": 100
>                    }
>                },
>                "method_of_estimation": "Analytical",
>                "func_distr_type": "Discrete",
>                "resp_var": "Damage factor"
>            }
>        }
>    }
> }
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
> Orcid ID: 0000-0002-7490-0066
>
> Department of Evolutionary Biology and Environmental Studies
> University of Z?rich
> Office Y34-J-74
> Winterthurerstrasse 190
> 8075 Z?rich
> Switzerland
>
> Office: +41 (0)44 635 47 64
> Cell:        +41 (0)78 630 66 57
> email:      Rainer.Krug at uzh.ch<mailto:Rainer.Krug at uzh.ch>
> Rainer at krugs.de<mailto:Rainer at krugs.de>
> Skype:     RMkrug
>
> PGP: 0x0F52F982
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
> Orcid ID: 0000-0002-7490-0066
>
> Department of Evolutionary Biology and Environmental Studies
> University of Z?rich
> Office Y34-J-74
> Winterthurerstrasse 190
> 8075 Z?rich
> Switzerland
>
> Office: +41 (0)44 635 47 64
> Cell:        +41 (0)78 630 66 57
> email:      Rainer.Krug at uzh.ch<mailto:Rainer.Krug at uzh.ch>
> Rainer at krugs.de<mailto:Rainer at krugs.de>
> Skype:     RMkrug
>
> PGP: 0x0F52F982
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jan 18 07:22:23 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 17 Jan 2020 22:22:23 -0800
Subject: [R] Fwd: Extracting a particular column from list
In-Reply-To: <CAGgJW754TWP7eb0u5hepAbQH=igJfeUEP+9GHeXhyrEsOiKUAA-9106@mail.gmail.com>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
 <CAGgJW765wm1m94y013Us+Mb0bsnrXnOS=ViBbUMUkcu1WVpSfA@mail.gmail.com>
 <393206509.8239350.1579174278504@mail.yahoo.com>
 <CAGgJW754TWP7eb0u5hepAbQH=igJfeUEP+9GHeXhyrEsOiKUAA-9106@mail.gmail.com>
Message-ID: <CAGxFJbQZCvNV6MyFbojo0dYDNbUeq7=1Up7dfvWrLY7QVxqHDw-4718@mail.gmail.com>

Trickier, but shorter:

> lapply(u,'[',1)
$a
[1] 1

$b
[1] "a"

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 17, 2020 at 10:04 PM Eric Berger <ericjberger at gmail.com> wrote:

> [Putting back onto r-help]
>
> You could try sapply() and lapply().
>
> > e <- sapply( 1:length(u), function(i) u[[i]][1] )
> > e
> # [1] "1" "a"    (note that the integer 1 became a character string "1")
>
> > f <- lapply( 1:length(u), function(i) u[[i]][1] )
> > f
> [[1]]
> [1] 1
>
> [[2]]
> [1] "a"
>
> In this case sapply will try to create a vector, and all its elements will
> need to be of the same type, so you end up with a character vector.
> The second method returns a list, which may or may not be of use to you,
> but each element of the list retains its type.
>
>
>
> ---------- Forwarded message ---------
> From: Faheem Jan <faheemjan93 at yahoo.com>
> Date: Thu, Jan 16, 2020 at 1:31 PM
> Subject: Re: [R] Extracting a particular column from list
> To: ericjberger at gmail.com <ericjberger at gmail.com>
>
>
> In my problem i want to extract the first value of a and b and so on... So
> using such data for further analysis
>
> Sent from Yahoo Mail on Android
> <
> https://go.onelink.me/107872968?pid=InProduct&c=Global_Internal_YGrowth_AndroidEmailSig__AndroidUsers&af_wl=ym&af_sub1=Internal&af_sub2=Global_YGrowth&af_sub3=EmailSignature
> >
>
> On Thu, 16 Jan 2020 at 4:24 PM, Eric Berger
> <ericjberger at gmail.com> wrote:
> > u <- list(a=1:5, b=letters[1:3])
> > u
> # $a
> # [1] 1 2 3 4 5
> #
> # $b
> # [1] "a" "b" "c"
> > u[["a"]]
> [1] 1 2 3 4 5
>
>
>
>
>
> On Thu, Jan 16, 2020 at 1:04 PM Faheem Jan via R-help <
> r-help at r-project.org>
> wrote:
>
> Hi. How to extract a column from the list.. I will be thanks full..
>
> Sent from Yahoo Mail on Android
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Fri Jan 17 14:25:28 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Fri, 17 Jan 2020 08:25:28 -0500
Subject: [R] Strange behaviour of R?
In-Reply-To: <f60e8926-8e35-e920-4142-832f61b87aed@gmail.com>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
 <f60e8926-8e35-e920-4142-832f61b87aed@gmail.com>
Message-ID: <CAP01uR=SKF0Ytir4ByO-b+u48pj-oJu8b1K_cjx3r-0MFgYgLg-4624@mail.gmail.com>


Normally one uses match.fun to avoid such problems.
This will give the error shown even if FUN is defined in the global environment.

  test <- function(FUN, args) {
     FUN <- match.fun(FUN)
     print(FUN)
     FUN(args)
  }
  test(NULL, 1:10)
  ## Error in match.fun(FUN) : 'NULL' is not a function, character or symbol

On Fri, Jan 17, 2020 at 5:41 AM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 17/01/2020 2:33 a.m., Sigbert Klinke wrote:
> > Hi,
> >
> > I wrote a function like
> >
> > test <- function(FUN, args) {
> >     print(FUN)
> >     FUN(args)
> > }
> >
> > When I call it lieke this
> >
> > test(mean, 1:10)
> > test(NULL, 1:10)
> >
> > then the second call still uses mean, although I set FUN to NULL. Is
> > that ok?
>
> You probably have a function defined in your global environment that is
> named FUN and acts like mean.
>
> The general rule in R is that it only looks for objects of mode function
> when trying to find something used as a function.  So in your second
> case, when trying to evaluate FUN(args), R will look for a function
> named FUN in the local evaluation frame, and won't find one:  FUN is
> NULL there.  Then it will go to the environment of test, which is likely
> the global environment, and look there.  That's where it probably found
> the function.
>
> For example, try this:
>
> FUN <- function(...) print('FUN was called')
>
>
> test <- function(FUN, args) {
>     print(FUN)
>     FUN(args)
> }
>
> test(NULL, 1:10)
>
> Duncan Murdoch
>
> >
> > Actually, I used something like
> >
> > test(mean, list(x=1:10, na.rm=TRUE))
> >
> > which actually crashed R, but I can not reproduce it. Of course, when I
> > replaced FUN(args) with do.call(FUN, args) then everything works fine.
> >
> > Sigbert
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan 16 22:18:59 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 16 Jan 2020 15:18:59 -0600
Subject: [R] 
 how to add annotate horizontal line between bars and decrease
 size and space between bars?
In-Reply-To: <CAF9-5jPWgQbnUfrmRZc=Uzds2iTwe=nVmEo17kJDqgtnHX7CGQ@mail.gmail.com>
References: <CAF9-5jPWgQbnUfrmRZc=Uzds2iTwe=nVmEo17kJDqgtnHX7CGQ@mail.gmail.com>
Message-ID: <CAF9-5jMTv1aa8Tzj3KrUm2q+9mXJPXvSF6GawqeaKtHzPY6-8Q-974@mail.gmail.com>


I tried doing this but it didn't help

p <- ggplot(data = df, aes(x = Name, y = prop, fill = Name)) +
  geom_bar(stat = "identity") +
  labs(x = "", y = "EQTL / gene") +
  scale_fill_brewer(palette="Greens",name = "Number of cis EQTL") +
  theme_classic()+
  theme(panel.grid.major.x = element_line(size = 0.1, color = "grey"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank()
  )

p+geom_path(x=c(1,1,2,2),y=c(0.85,0.86,0.86,0.85))+
  annotate("text",x=1.5,y=1.2,label="p = 2e-16")

I am getting:
Error in annotate("text", x = 1.5, y = 1.2, label = "p = 2e-16") :
  unused arguments (x = 1.5, y = 1.2, label = "p = 2e-16")

On Thu, Jan 16, 2020 at 2:51 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a code like this:
>
> p <- ggplot(data = df, aes(x = Name, y = prop, fill = Name)) +
>   geom_bar(stat = "identity") +
>   labs(x = "", y = "EQTL / gene") +
>   scale_fill_brewer(palette="Greens",name = "Number of cis EQTL") +
>   theme(legend.position = "none")
> p
> which produces the attached plot.
> How do I add a horizontal lines in between middle points of two bars
> above which I would have written: p = 2e-16
>
> I tried adding this:
>
> > p+ annotate("text", x = 1.5, y = 1.2, label = "p = 2e-16", size = 3.5) +
> +   annotate("rect", xmin = 1, xmax = 2, ymin = 1, ymax =1,
> alpha=0.3,colour = "black")
> Error in annotate("text", x = 1.5, y = 1.2, label = "p = 2e-16", size = 3.5) :
>   unused arguments (x = 1.5, y = 1.2, label = "p = 2e-16", size = 3.5)
>
> Also how do I decrease size of these two bars?
>
> Thanks
> Ana


From drj|m|emon @end|ng |rom gm@||@com  Thu Jan 16 21:10:21 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Jan 2020 07:10:21 +1100
Subject: [R] 
 How to save multiple values of a variable in a json file in R
In-Reply-To: <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <17F90DC5-D0FD-4A2D-A6FA-0A22861A78CF@krugs.de>
 <DBBPR05MB6570B84F540BE7F511103A70F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <B4D78F92-CB0E-42C8-99A7-E115DE725714@krugs.de>
 <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <CA+8X3fXMS1GukuWdbbbx3XOOJA22Uu3oGtaoeLtJmeb-O0nBpA-7807@mail.gmail.com>


Hi Ioanna,
Assuming your input file is named "ii.json" and contains the text in
your original post:

library(jsonlite)
a2<-fromJSON("ii.json",flatten=TRUE)
a2$fields$geo_applicability$fields$countries[,"fields.name"]

You can find this yourself by progressively checking names and
extracting until you reach the data frame that contains the
information you want. Note that the format of your files must be the
same for this to work on more than one JSON file.

Jim


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan 16 21:51:12 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 16 Jan 2020 14:51:12 -0600
Subject: [R] how to add annotate horizontal line between bars and decrease
 size and space between bars?
Message-ID: <CAF9-5jPWgQbnUfrmRZc=Uzds2iTwe=nVmEo17kJDqgtnHX7CGQ-617@mail.gmail.com>

Hello,

I have a code like this:

p <- ggplot(data = df, aes(x = Name, y = prop, fill = Name)) +
  geom_bar(stat = "identity") +
  labs(x = "", y = "EQTL / gene") +
  scale_fill_brewer(palette="Greens",name = "Number of cis EQTL") +
  theme(legend.position = "none")
p
which produces the attached plot.
How do I add a horizontal lines in between middle points of two bars
above which I would have written: p = 2e-16

I tried adding this:

> p+ annotate("text", x = 1.5, y = 1.2, label = "p = 2e-16", size = 3.5) +
+   annotate("rect", xmin = 1, xmax = 2, ymin = 1, ymax =1,
alpha=0.3,colour = "black")
Error in annotate("text", x = 1.5, y = 1.2, label = "p = 2e-16", size = 3.5) :
  unused arguments (x = 1.5, y = 1.2, label = "p = 2e-16", size = 3.5)

Also how do I decrease size of these two bars?

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-01-16 at 2.50.42 PM.png
Type: image/png
Size: 50677 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200116/1b2a0e76/attachment.png>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan 16 19:01:45 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 16 Jan 2020 12:01:45 -0600
Subject: [R] Error in annotate
Message-ID: <CAF9-5jPT-n0GnzZtQz3o2MWwU5dTxM_wsKjyfjckP22cPmqT5g-6573@mail.gmail.com>


Hello,

my code used to work and now I am getting this error which does not
display my annotation

df <- data.frame("prop" = c(102.73,260.65), "Name" = c("All Genes \n
31385","Glucose Response Genes \n 103"))

p <- ggplot(data = df, aes(x = Name, y = prop, fill = Name)) +
  geom_bar(stat = "identity") +
  labs(x = "", y = "EQTL / gene") +
  scale_fill_brewer(palette="Greens",name = "Number of cis EQTL",
labels = c("3124345", "26846")) +
  theme_minimal() +
  theme(legend.position = "right",
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.line = element_line(),
        axis.ticks = element_line())

p + annotate("text", x = 1.5, y = 280, label = "p = 0.008", size = 3.5) +
  annotate("rect", xmin = 1, xmax = 2, ymin = 270, ymax =270,
alpha=0.3,colour = "black")

I am getting this error:

> p + annotate("text", x = 1.5, y = 280, label = "p = 0.008", size = 3.5) +
+   annotate("rect", xmin = 1, xmax = 2, ymin = 270, ymax =270,
alpha=0.3,colour = "black")
Error in annotate("text", x = 1.5, y = 280, label = "p = 0.008", size = 3.5) :
  unused arguments (x = 1.5, y = 280, label = "p = 0.008", size = 3.5)

Please advice,
Ana


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Jan 16 17:31:51 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 16 Jan 2020 11:31:51 -0500
Subject: [R] =?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
Message-ID: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>

Dear friends,

How can I convert the following binary number in two?s complement
representation in R?

10110010

Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Jan 16 15:58:15 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 16 Jan 2020 16:58:15 +0200
Subject: [R] 
 How to save multiple values of a variable in a json file in R
In-Reply-To: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <CAGgJW7718qTLRTeehQtzCCkj8s6REqS=2ULeOMHGyim1kvVdfQ-9160@mail.gmail.com>

I have had success using the fromJSON() function in the rjson package.

On Thu, Jan 16, 2020 at 4:22 PM Ioanna Ioannou <ii54250 at msn.com> wrote:

> hello everyone,
>
> and happy new year!
>
> I have this problem: I want to save the name of the 'countries', the
> 'taxonomy_gem' and the 'minimum_im' and 'maximum_im' . The problem is that
> there are several names of countries.  How can i transfer the information
> from the json file to an R data.frame? See below for the json file.
>
> Best,
> ioanna
>
>
>
> {
>     "pk": 670,
>     "model": "vulnerability.generalinformation",
>     "fields": {
>         "category": "Structure class",
>         "article_title": "A GLOBAL DATABASE OF VULNERABILITY MODELS FOR
> SEISMIC RISK ASSESSMENT",
>         "name": "CR/LFINF/DUL/H:2",
>         "publication_conference_name": "16EECE",
>         "llrs": null,
>         "material": null,
>         "web_link": "",
>         "owner": {
>             "pk": 1900,
>             "model": "people.profile",
>             "fields": {
>                 "username": "lmartins",
>                 "first_name": "",
>                 "last_name": "",
>                 "email": "luis.martins at globalquakemodel.org"
>             }
>         },
>         "general_comments": "",
>         "geo_applicability": {
>             "pk": 669,
>             "model": "vulnerability.geoapplicability",
>             "fields": {
>                 "general_information": 670,
>                 "area": "",
>                 "countries": [
>                     {
>                         "pk": "CIV",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Cte d'Ivoire"
>                         }
>                     },
>                     {
>                         "pk": "CMR",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Cameroon"
>                         }
>                     },
>                     {
>                         "pk": "SDN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Sudan"
>                         }
>                     },
>                     {
>                         "pk": "SSD",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "South Sudan"
>                         }
>                     },
>                     {
>                         "pk": "TUN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Tunisia"
>                         }
>                     },
>                     {
>                         "pk": "TGO",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Togo"
>                         }
>                     },
>                     {
>                         "pk": "ZAF",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "South Africa"
>                         }
>                     },
>                     {
>                         "pk": "NER",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Niger"
>                         }
>                     },
>                     {
>                         "pk": "MAR",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Morocco"
>                         }
>                     },
>                     {
>                         "pk": "KEN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Kenya"
>                         }
>                     },
>                     {
>                         "pk": "SYC",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Seychelles"
>                         }
>                     },
>                     {
>                         "pk": "ESH",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Western Sahara"
>                         }
>                     },
>                     {
>                         "pk": "SHN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Saint Helena"
>                         }
>                     },
>                     {
>                         "pk": "REU",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Reunion"
>                         }
>                     },
>                     {
>                         "pk": "SLE",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Sierra Leone"
>                         }
>                     },
>                     {
>                         "pk": "DJI",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Djibouti"
>                         }
>                     },
>                     {
>                         "pk": "STP",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Sao Tome and Principe"
>                         }
>                     },
>                     {
>                         "pk": "BDI",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Burundi"
>                         }
>                     },
>                     {
>                         "pk": "MLI",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Mali"
>                         }
>                     },
>                     {
>                         "pk": "GMB",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Gambia"
>                         }
>                     },
>                     {
>                         "pk": "ZMB",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Zambia"
>                         }
>                     },
>                     {
>                         "pk": "RWA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Rwanda"
>                         }
>                     },
>                     {
>                         "pk": "MWI",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Malawi"
>                         }
>                     },
>                     {
>                         "pk": "BFA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Burkina Faso"
>                         }
>                     },
>                     {
>                         "pk": "GAB",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Gabon"
>                         }
>                     },
>                     {
>                         "pk": "TCD",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Chad"
>                         }
>                     },
>                     {
>                         "pk": "SEN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Senegal"
>                         }
>                     },
>                     {
>                         "pk": "NAM",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Namibia"
>                         }
>                     },
>                     {
>                         "pk": "ATF",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "French Southern Territories"
>                         }
>                     },
>                     {
>                         "pk": "BWA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Botswana"
>                         }
>                     },
>                     {
>                         "pk": "TZA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Tanzania"
>                         }
>                     },
>                     {
>                         "pk": "ERI",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Eritrea"
>                         }
>                     },
>                     {
>                         "pk": "MYT",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Mayotte"
>                         }
>                     },
>                     {
>                         "pk": "SOM",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Somalia"
>                         }
>                     },
>                     {
>                         "pk": "UGA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Uganda"
>                         }
>                     },
>                     {
>                         "pk": "LSO",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Lesotho"
>                         }
>                     },
>                     {
>                         "pk": "LBY",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Libya"
>                         }
>                     },
>                     {
>                         "pk": "LBR",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Liberia"
>                         }
>                     },
>                     {
>                         "pk": "COD",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Democratic Republic of the Congo"
>                         }
>                     },
>                     {
>                         "pk": "CPV",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Cape Verde"
>                         }
>                     },
>                     {
>                         "pk": "CAF",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Central African Republic"
>                         }
>                     },
>                     {
>                         "pk": "COM",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Comoros"
>                         }
>                     },
>                     {
>                         "pk": "ETH",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Ethiopia"
>                         }
>                     },
>                     {
>                         "pk": "GIN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Guinea"
>                         }
>                     },
>                     {
>                         "pk": "COG",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Republic of Congo"
>                         }
>                     },
>                     {
>                         "pk": "GHA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Ghana"
>                         }
>                     },
>                     {
>                         "pk": "SWZ",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Swaziland"
>                         }
>                     },
>                     {
>                         "pk": "GNB",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Guinea-Bissau"
>                         }
>                     },
>                     {
>                         "pk": "MDG",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Madagascar"
>                         }
>                     },
>                     {
>                         "pk": "ZWE",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Zimbabwe"
>                         }
>                     },
>                     {
>                         "pk": "MOZ",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Mozambique"
>                         }
>                     },
>                     {
>                         "pk": "MRT",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Mauritania"
>                         }
>                     },
>                     {
>                         "pk": "MUS",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Mauritius"
>                         }
>                     },
>                     {
>                         "pk": "NGA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Nigeria"
>                         }
>                     },
>                     {
>                         "pk": "BEN",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Benin"
>                         }
>                     },
>                     {
>                         "pk": "GNQ",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Equatorial Guinea"
>                         }
>                     },
>                     {
>                         "pk": "EGY",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Egypt"
>                         }
>                     },
>                     {
>                         "pk": "AGO",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Angola"
>                         }
>                     },
>                     {
>                         "pk": "DZA",
>                         "model": "vulnerability.country",
>                         "fields": {
>                             "is_visible": true,
>                             "region": 2,
>                             "name": "Algeria"
>                         }
>                     }
>                 ],
>                 "lon": null,
>                 "address": "",
>                 "lat": null
>             }
>         },
>         "authors": "Martins and Silva",
>         "use_case_information": "",
>         "structure_type": "Building",
>         "taxonomy_gem":
> "DX+D99/MAT99/L99/DY+D99/MAT99/L99/H99/Y99/OC99/BP99/PLF99/IR99/EW99/RSH99+RMT99+R99+RWC99/F99+FWC99/FOS99",
>         "year": 2018,
>         "type_of_assessment": "Vulnerability",
>         "taxonomy_type": {
>             "pk": 1,
>             "model": "vulnerability.taxonomytype",
>             "fields": {
>                 "user_def": false,
>                 "name": "GEM"
>             }
>         },
>         "taxonomy_text": "",
>         "vulnerability_func": {
>             "pk": 30,
>             "model": "vulnerability.vulnerabilityfunc",
>             "fields": {
>                 "general_information": 670,
>                 "predictor_var": {
>                     "pk": 602,
>                     "model": "vulnerability.predictorvar",
>                     "fields": {
>                         "type_of_period": "Telastic (s)",
>                         "minimum_im": 0.05,
>                         "intensity_measure_type": "Sa(T)",
>                         "fragility_func": null,
>                         "period": 0.3,
>                         "vulnerability_func": 30,
>                         "maximum_im": 8,
>                         "intensity_measure_unit": "g"
>                     }
>                 },
>                 "func_distr_vuln_discr": {
>                     "pk": 23,
>                     "model": "vulnerability.funcdistrvulndiscr",
>                     "fields": {
>                         "resp_var_mean_val":
> "0.000025;0.000033;0.000045;0.000059;0.000078;0.000101;0.000131;0.00017;0.000217;0.000277;0.00035;0.00044;0.000551;0.000684;0.000844;0.001036;0.001264;0.001532;0.001846;0.002212;0.002635;0.003121;0.003676;0.004306;0.005016;0.005812;0.006701;0.007685;0.008772;0.009966;0.01127;0.012691;0.014233;0.0159;0.0177;0.019639;0.021726;0.023972;0.026388;0.028991;0.0318;0.034838;0.038132;0.041714;0.04562;0.049893;0.05458;0.059733;0.065409;0.07167;0.078582;0.086213;0.094633;0.103913;0.114125;0.125335;0.13761;0.151007;0.165578;0.181366;0.1984;0.216699;0.236266;0.257091;0.279144;0.302379;0.326733;0.352124;0.378455;0.40561;0.433459;0.461862;0.490663;0.519703;0.548813;0.577824;0.606566;0.634874;0.662589;0.68956;0.715649;0.740732;0.764702;0.787467;0.808956;0.829114;0.847907;0.865317;0.881347;0.896012;0.909344;0.921388;0.932199;0.941842;0.950388;0.957913;0.964497;0.97022;0.975163;0.979405",
>                         "resp_var_val_coeff": "",
>                         "predictor_var_im_val":
> "0.05;0.05263;0.055398;0.058312;0.06138;0.064608;0.068007;0.071584;0.07535;0.079313;0.083485;0.087876;0.092499;0.097364;0.102486;0.107877;0.113551;0.119524;0.125811;0.132429;0.139395;0.146727;0.154445;0.162569;0.171121;0.180122;0.189596;0.199569;0.210067;0.221117;0.232748;0.24499;0.257877;0.271442;0.28572;0.300749;0.316569;0.333221;0.350749;0.369198;0.388619;0.40906;0.430577;0.453226;0.477066;0.502161;0.528575;0.556379;0.585645;0.61645;0.648876;0.683008;0.718935;0.756752;0.796558;0.838458;0.882561;0.928985;0.977851;1.029287;1.083429;1.140418;1.200405;1.263548;1.330012;1.399972;1.473613;1.551126;1.632717;1.7186;1.809;1.904156;2.004317;2.109746;2.220721;2.337534;2.460491;2.589915;2.726148;2.869546;3.020488;3.179369;3.346607;3.522643;3.707938;3.902979;4.108281;4.324381;4.551848;4.791281;5.043307;5.308591;5.587829;5.881755;6.191142;6.516804;6.859595;7.220418;7.60022;8",
>                         "vulnerability_func": 30,
>                         "func_distr_shape": null,
>                         "data_pts_num": 100
>                     }
>                 },
>                 "method_of_estimation": "Analytical",
>                 "func_distr_type": "Discrete",
>                 "resp_var": "Damage factor"
>             }
>         }
>     }
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Jan 16 12:23:47 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 16 Jan 2020 13:23:47 +0200
Subject: [R] Extracting a particular column from list
In-Reply-To: <47617339.8228196.1579172579216@mail.yahoo.com>
References: <47617339.8228196.1579172579216.ref@mail.yahoo.com>
 <47617339.8228196.1579172579216@mail.yahoo.com>
Message-ID: <CAGgJW765wm1m94y013Us+Mb0bsnrXnOS=ViBbUMUkcu1WVpSfA-8545@mail.gmail.com>

> u <- list(a=1:5, b=letters[1:3])
> u
# $a
# [1] 1 2 3 4 5
#
# $b
# [1] "a" "b" "c"
> u[["a"]]
[1] 1 2 3 4 5





On Thu, Jan 16, 2020 at 1:04 PM Faheem Jan via R-help <r-help at r-project.org>
wrote:

> Hi. How to extract a column from the list.. I will be thanks full..
>
> Sent from Yahoo Mail on Android
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 20 12:38:59 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Jan 2020 11:38:59 +0000
Subject: [R] 
 =?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
 =?utf-8?q?nt_representation?=
In-Reply-To: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
Message-ID: <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>

Hello,

Is this what you want?


x <- "10110010"
strtoi(x, base = 2)
#[1] 178


Hope this helps,

Rui Barradas

?s 16:31 de 16/01/20, Paul Bernal escreveu:
> Dear friends,
> 
> How can I convert the following binary number in two?s complement
> representation in R?
> 
> 10110010
> 
> Any help and/or guidance will be greatly appreciated,
> 
> Best regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 20 13:22:15 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Jan 2020 12:22:15 +0000
Subject: [R] 
 =?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
 =?utf-8?q?nt_representation?=
In-Reply-To: <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
Message-ID: <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>

Sorry, missunderstood the problem.
Here it goes:

fun <- function(x){
   res <- sapply(x, function(y){
     if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
       strtoi(y, base = 2)
     }else{
       y <- unlist(strsplit(y, ""))
       -sum((y != "1")*2^((length(y) - 1):0)) - 1
     }
   })
   unname(res)
}

fun("10110010")
fun("10000000")
fun(c("01000000", "01111111", "10110010", "10000000"))


Hope this helps,

Rui Barradas

?s 11:38 de 20/01/20, Rui Barradas escreveu:
> Hello,
> 
> Is this what you want?
> 
> 
> x <- "10110010"
> strtoi(x, base = 2)
> #[1] 178
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 16:31 de 16/01/20, Paul Bernal escreveu:
>> Dear friends,
>>
>> How can I convert the following binary number in two?s complement
>> representation in R?
>>
>> 10110010
>>
>> Any help and/or guidance will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @c|@bo|@zz@ @end|ng |rom gm@||@com  Sun Jan 19 18:19:18 2020
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Sun, 19 Jan 2020 18:19:18 +0100
Subject: [R] survival::clogit - how to construct data and use sampling
 weights
Message-ID: <CABZtLWzH9JdCQrM2WeH197iF-TUGKawt9wUyWaoHyp5BrYz-kw@mail.gmail.com>

Dear list users,
I need some guidelines to run a conditional logistic regression with
fixed effects.

Let me give you some background.

I have a survey where each respondent is asked the same question once
a year for three consecutive years. There is no apriori on the extent
to which choice at time t is affected by the choice at t-1.

There are 4 possible answer to the question, say a, b, c, d.
I want to know to what extent some time-varying characteristics of the
respondent,say x1 and x2, affect her decision to choose one answer
(e.g., a).

I want to take into account some unobserved heterogeneous factor which
might affect the choice of the respondent, by including individual and
time fixed effects.

In addition, I want to take into account the sampling weight
associated to each respondent, which changes over time.

Following, I provide some code to show how I would do this with
survival::clogit.

My questions are: i) am I properly constructing the dataset and using
the field weights?, ii) is it necessary to include the variable "alt"
in the formula?

Can anyone provide any useful guidelines?
Regards,
Valerio Leone Sciabolazza, Ph.D.


set.seed(123)
# number of observations
n <- 99
# number of possible choice
possible_choice <- letters[1:4]
# number of years
years <- 3
# individual (time-varying) characteristics
x1 <- runif(n, 5.0, 70.5)
x2 <- sample(1:n^2, n, replace = F)
# sampling (time-varying) weights
wgt <- runif(n, 0, 1)
# actual choice at time t
actual_choice_year_1 <- possible_choice[sample(1:4, n/3, replace = T,
prob = rep(1/4, 4))]
actual_choice_year_2 <- possible_choice[sample(1:4, n/3, replace = T,
prob = c(0.4, 0.3, 0.2, 0.1))]
actual_choice_year_3 <- possible_choice[sample(1:4, n/3, replace = T,
prob = c(0.2, 0.5, 0.2, 0.1))]
# create dataset
df <- data.frame(choice = c(actual_choice_year_1,
actual_choice_year_2, actual_choice_year_3),
                 x1 = x1, x2 = x2, wgt = wgt,
                 individual_fixed_effect = as.character(rep(1:(n/3), years)),
                 time_fixed_effect = as.character(rep(1:years, each = n/3)),
                 stringsAsFactors = F)
# prepare data for clogit
df <- df[rep(seq_len(nrow(df)), 4), ]
df$alt <- letters[1:4]
df$mode <- df$choice == df$alt
df <- df[order(as.numeric(df$time_fixed_effect), df$alt,
df$individual_fixed_effect), ]

# run regression
my.reg <- clogit(formula(mode ~ alt + x1 + x2 + time_fixed_effect +
                             strata(individual_fixed_effect)),
                 data = df, method="approximate", weights = df$wgt)

summary(my.reg)


From @tu|@@|n|m@|| @end|ng |rom gm@||@com  Sun Jan 19 09:25:25 2020
From: @tu|@@|n|m@|| @end|ng |rom gm@||@com (Atul Saini)
Date: Sun, 19 Jan 2020 13:55:25 +0530
Subject: [R] "In sqrt(VS) : NaNs produced"
Message-ID: <CACqmUaqtSaoGKXTNqXfY8JKGOd8UXXQm9mT5_UObBVCm=G7MCA-987@mail.gmail.com>

Hello R,
             I am attaching the script and data please help me to solve the
problem of

"In sqrt(VS) : NaNs produced"  with the p value of dumy$Mar

Regards,

From r@|ner_krug @end|ng |rom |c|oud@com  Fri Jan 17 08:41:12 2020
From: r@|ner_krug @end|ng |rom |c|oud@com (Rainer Krug)
Date: Fri, 17 Jan 2020 08:41:12 +0100
Subject: [R] Strange behaviour of R?
In-Reply-To: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
References: <aad6da00-352e-4dc7-0f32-ab03f76839a9@wiwi.hu-berlin.de>
Message-ID: <5DFC70E4-F263-4083-B5A5-80045C002343@icloud.com>

Hi

> On 17 Jan 2020, at 08:33, Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
> 
> Hi,
> 
> I wrote a function like
> 
> test <- function(FUN, args) {
>  print(FUN)
>  FUN(args)
> }
> 
> When I call it lieke this
> 
> test(mean, 1:10)
> test(NULL, 1:10)
> 
> then the second call still uses mean, although I set FUN to NULL. Is that ok?

Not for me - macOS, R 3.6.2


> 
> Actually, I used something like
> 
> test(mean, list(x=1:10, na.rm=TRUE))

Fails as expected,

Rainer

> 
> which actually crashed R, but I can not reproduce it. Of course, when I replaced FUN(args) with do.call(FUN, args) then everything works fine.
> 
> Sigbert
> 
> -- 
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From j@me@power@|d @end|ng |rom gm@||@com  Thu Jan 16 14:10:27 2020
From: j@me@power@|d @end|ng |rom gm@||@com (james poweraid)
Date: Thu, 16 Jan 2020 14:10:27 +0100
Subject: [R] R package for meta-analysis from z scores
Message-ID: <CAEnduPpYyg-Cz_nzD9UCpZAXEgzV+=npDQGBAQYXmutN5prYqA-7699@mail.gmail.com>

Hello,

I have a set of Z scores from an N=2 studies and I need to run a
meta-analysis across the two Z scores for many N variables. I do not have
effect sizes and SEs. I realize there are many different meta analysis
packages in R, but I only have Z scores and it seems to me this is
limiting. I am using the metap package because this very conveniently
accepts directly p values which I can get from my Z scores. I have applied
what is called in metap package the sumlog Fisher?s method Chi square (2
df).

I have three questions:

   1. Is this the same as a fixed effect meta-analysis without weights?
   2. Is there any way to do a random effects meta-analysis starting only
   with Z scores?
   3. Is there a way to get the I2 heterogeneity across studies from this
   or from other packages? It looks like I need the estimates for this. Is
   there another package that can easily get this using as input Z scores or P
   values?

Data

    library(metap)

    zscores = cbind(c(4, 2, 0.1),c(5, 2.5, 0.1))

    pvalues = apply(zscores, 1:2, function(x)  2*(pnorm( abs(x) ,
lower.tail=F)))

    meta = apply(pvalues, MARGIN=1, FUN=sumlog)



Thank you much

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jan 20 14:46:47 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 20 Jan 2020 13:46:47 +0000
Subject: [R] "In sqrt(VS) : NaNs produced"
In-Reply-To: <CACqmUaqtSaoGKXTNqXfY8JKGOd8UXXQm9mT5_UObBVCm=G7MCA-987@mail.gmail.com>
References: <CACqmUaqtSaoGKXTNqXfY8JKGOd8UXXQm9mT5_UObBVCm=G7MCA-987@mail.gmail.com>
Message-ID: <237a676d-4af9-f2cf-b09a-e4f36655184a@dewey.myzen.co.uk>

Your script and data were stripped so we are none the wiser I am afraid. 
You need to embed the script in your post and give a minimal data-set 
which exhibits the problem using dput() and embed that in the post too.

Michael

On 19/01/2020 08:25, Atul Saini wrote:
> Hello R,
>               I am attaching the script and data please help me to solve the
> problem of
> 
> "In sqrt(VS) : NaNs produced"  with the p value of dumy$Mar
> 
> Regards,
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jan 20 14:51:48 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 20 Jan 2020 13:51:48 +0000
Subject: [R] R package for meta-analysis from z scores
In-Reply-To: <CAEnduPpYyg-Cz_nzD9UCpZAXEgzV+=npDQGBAQYXmutN5prYqA-7699@mail.gmail.com>
References: <CAEnduPpYyg-Cz_nzD9UCpZAXEgzV+=npDQGBAQYXmutN5prYqA-7699@mail.gmail.com>
Message-ID: <ef98027b-f1cd-6a72-2f61-026053a91ec6@dewey.myzen.co.uk>

Dear James

Your question really boil down to whether you can estimate tau^2, the 
between study variance of the effect sizes, if you only have p-values. 
As far as I can see the answer has to be no.

Michael

On 16/01/2020 13:10, james poweraid wrote:
> Hello,
> 
> I have a set of Z scores from an N=2 studies and I need to run a
> meta-analysis across the two Z scores for many N variables. I do not have
> effect sizes and SEs. I realize there are many different meta analysis
> packages in R, but I only have Z scores and it seems to me this is
> limiting. I am using the metap package because this very conveniently
> accepts directly p values which I can get from my Z scores. I have applied
> what is called in metap package the sumlog Fisher?s method Chi square (2
> df).
> 
> I have three questions:
> 
>     1. Is this the same as a fixed effect meta-analysis without weights?
>     2. Is there any way to do a random effects meta-analysis starting only
>     with Z scores?
>     3. Is there a way to get the I2 heterogeneity across studies from this
>     or from other packages? It looks like I need the estimates for this. Is
>     there another package that can easily get this using as input Z scores or P
>     values?
> 
> Data
> 
>      library(metap)
> 
>      zscores = cbind(c(4, 2, 0.1),c(5, 2.5, 0.1))
> 
>      pvalues = apply(zscores, 1:2, function(x)  2*(pnorm( abs(x) ,
> lower.tail=F)))
> 
>      meta = apply(pvalues, MARGIN=1, FUN=sumlog)
> 
> 
> 
> Thank you much
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jan 20 15:36:20 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 20 Jan 2020 09:36:20 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
Message-ID: <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>

Dear friend Rui,

Hope you are doing great, thanks for your kind feedback. The challenge I
currently have at hand is to decode AIS messages and obtain latitude and
longitude values from those.

So basically, I want to accomplish something like in the example below. I
want to convert this binary number (10110010) into the two?s complement
representation, there is the logic they are using for that. Since longitude
ranges from
Example of conversion to decimal of a signed binary number in two's
complement representation

Let's convert to decimal the following signed binary number: 10110010
10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 = -128 +
32 + 16 + 2 = -78.

El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<ruipbarradas at sapo.pt>)
escribi?:

> Sorry, missunderstood the problem.
> Here it goes:
>
> fun <- function(x){
>    res <- sapply(x, function(y){
>      if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>        strtoi(y, base = 2)
>      }else{
>        y <- unlist(strsplit(y, ""))
>        -sum((y != "1")*2^((length(y) - 1):0)) - 1
>      }
>    })
>    unname(res)
> }
>
> fun("10110010")
> fun("10000000")
> fun(c("01000000", "01111111", "10110010", "10000000"))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:38 de 20/01/20, Rui Barradas escreveu:
> > Hello,
> >
> > Is this what you want?
> >
> >
> > x <- "10110010"
> > strtoi(x, base = 2)
> > #[1] 178
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
> >> Dear friends,
> >>
> >> How can I convert the following binary number in two?s complement
> >> representation in R?
> >>
> >> 10110010
> >>
> >> Any help and/or guidance will be greatly appreciated,
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jan 20 15:40:43 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 20 Jan 2020 09:40:43 -0500
Subject: [R] (no subject)
Message-ID: <CAMOcQfNWFbojsZMr80cWv0vnyykuo7aQwgn=b2kw1xB2UYbAeg@mail.gmail.com>

Example of conversion to decimal of a signed binary number in two's
complement representation

Let's convert to decimal the following signed binary number: 10110010
10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 = -128 +
32 + 16 + 2 = -78.

that operation ilvoves base 2 raised to the 7th, 6th, 5th, .... and 0th
power. Only the first one has a minus one multiplying. The  first one is
multiplied by a 2 raised to the seventh power because powers goe from right
to left, starting from zero, all the way to the leftmost integer.

Thank you so much for your valuable help,

Cheers,

Paul

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jan 20 15:57:56 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 20 Jan 2020 09:57:56 -0500
Subject: [R] =?utf-8?q?Binary_Number_To_Two=C2=B4s_Complement_Representat?=
 =?utf-8?q?ion?=
Message-ID: <CAMOcQfPg0ETa1ysysVxPoC4=Fn45kKJAhVw_YxRyHaPSnSi_ew@mail.gmail.com>

Dear Rui,

Based on the rules given in the link below, I want to transform the binary
numbers into latitude and longitude coordinates (in degrees and minutes),
so that is basically what I am trying to accomplish. The first integer
gives the sign (positive or negative) of the number, and the rest n-1
digits, give the magnitude of the number.

So for example: 01111001, the first integer indicates that the decimal is
positive, and, in the case of 1001011. the first integer starts with "1",
so that means the number is negative, then the rest of the integers give
the actual number, while the first integer (from left to right) give the
sign, with 0 meaning it?s a positive integer, and 1 meaning is a negative
integer.

Best regards!

https://www.electronics-tutorials.ws/binary/signed-binary-numbers.html

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jan 20 16:28:14 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Jan 2020 15:28:14 +0000
Subject: [R] 
 =?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
 =?utf-8?q?nt_representation?=
In-Reply-To: <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
Message-ID: <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>

Hello,

The function I included converts signed binary numbers into their 
decimal representation. They are negative if a) they are multiples of 8 
bits and b) the most significant bit is a "1". If not just convert to 
integer.

As for a) above, I assume that you will have 8 bit numbers. And the 
conversion is done as follows:

input: 10110010

splitting, to make it more clear:

1 0 1 1 0 0 1 0 - input
0 1 0 0 1 1 0 1 - reversed
               1 - add 1 to the number with reversed bits
0 1 0 0 1 1 1 0 - result is the two's complement

c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78

But the msb is "1" so it's -78


This is what the function does, but instead of %*% it uses

sum(two's compl * powers of two)


Hope this helps,

Rui Barradas

The input must be a character string or character vector.

?s 14:36 de 20/01/20, Paul Bernal escreveu:
> Dear friend Rui,
> 
> Hope you are doing great, thanks for your kind feedback. The challenge I 
> currently have at hand is to decode AIS messages and obtain latitude and 
> longitude values from those.
> 
> So basically, I want to accomplish something like in the example below. 
> I want to convert this binary number (10110010) into the two?s 
> complement representation, there is the logic they are using for that. 
> Since longitude ranges from
> 
> 
>       Example of conversion to decimal of a signed binary number in
>       two's complement representation
> 
> Let's convert to decimal the following signed binary number: 10110010
> 
> 10110010 = -1?27?+ 0?26?+ 1?25?+ 1?24?+ 0?23?+ 0?22?+ 1?21?+ 0?20?= -128 
> + 32 + 16 + 2 = -78.
> 
> El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>>) escribi?:
> 
>     Sorry, missunderstood the problem.
>     Here it goes:
> 
>     fun <- function(x){
>      ? ?res <- sapply(x, function(y){
>      ? ? ?if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>      ? ? ? ?strtoi(y, base = 2)
>      ? ? ?}else{
>      ? ? ? ?y <- unlist(strsplit(y, ""))
>      ? ? ? ?-sum((y != "1")*2^((length(y) - 1):0)) - 1
>      ? ? ?}
>      ? ?})
>      ? ?unname(res)
>     }
> 
>     fun("10110010")
>     fun("10000000")
>     fun(c("01000000", "01111111", "10110010", "10000000"))
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
>      > Hello,
>      >
>      > Is this what you want?
>      >
>      >
>      > x <- "10110010"
>      > strtoi(x, base = 2)
>      > #[1] 178
>      >
>      >
>      > Hope this helps,
>      >
>      > Rui Barradas
>      >
>      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
>      >> Dear friends,
>      >>
>      >> How can I convert the following binary number in two?s complement
>      >> representation in R?
>      >>
>      >> 10110010
>      >>
>      >> Any help and/or guidance will be greatly appreciated,
>      >>
>      >> Best regards,
>      >>
>      >> Paul
>      >>
>      >> ????[[alternative HTML version deleted]]
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>      >> PLEASE do read the posting guide
>      >> http://www.R-project.org/posting-guide.html
>      >> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>      > http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan 20 16:35:36 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 20 Jan 2020 07:35:36 -0800
Subject: [R] (no subject)
In-Reply-To: <CAMOcQfNWFbojsZMr80cWv0vnyykuo7aQwgn=b2kw1xB2UYbAeg@mail.gmail.com>
References: <CAMOcQfNWFbojsZMr80cWv0vnyykuo7aQwgn=b2kw1xB2UYbAeg@mail.gmail.com>
Message-ID: <D7DB7859-1ABF-438A-BC6E-0436B97F546C@dcn.davis.ca.us>

Per the Posting Guide... stop sending HTML-formatted email to this mailing list. The formatting gets stripped out anyway and introduces confusion. Gmail _has_ this option, but you must specify it before you send the email.

Also, try to use Reply-all when discussing the same topic to keep related emails together.

On January 20, 2020 6:40:43 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Example of conversion to decimal of a signed binary number in two's
>complement representation
>
>Let's convert to decimal the following signed binary number: 10110010
>10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 =
>-128 +
>32 + 16 + 2 = -78.
>
>that operation ilvoves base 2 raised to the 7th, 6th, 5th, .... and 0th
>power. Only the first one has a minus one multiplying. The  first one
>is
>multiplied by a 2 raised to the seventh power because powers goe from
>right
>to left, starting from zero, all the way to the leftmost integer.
>
>Thank you so much for your valuable help,
>
>Cheers,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jan 20 16:35:36 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 20 Jan 2020 07:35:36 -0800
Subject: [R] (no subject)
In-Reply-To: <CAMOcQfNWFbojsZMr80cWv0vnyykuo7aQwgn=b2kw1xB2UYbAeg@mail.gmail.com>
References: <CAMOcQfNWFbojsZMr80cWv0vnyykuo7aQwgn=b2kw1xB2UYbAeg@mail.gmail.com>
Message-ID: <9B5FFDD9-2A45-4455-8161-D604FA9749E0@dcn.davis.ca.us>

Per the Posting Guide... stop sending HTML-formatted email to this mailing list. The formatting gets stripped out anyway and introduces confusion. Gmail _has_ this option, but you must specify it before you send the email.

Also, try to use Reply-all when discussing the same topic to keep related emails together.

On January 20, 2020 6:40:43 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Example of conversion to decimal of a signed binary number in two's
>complement representation
>
>Let's convert to decimal the following signed binary number: 10110010
>10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 =
>-128 +
>32 + 16 + 2 = -78.
>
>that operation ilvoves base 2 raised to the 7th, 6th, 5th, .... and 0th
>power. Only the first one has a minus one multiplying. The  first one
>is
>multiplied by a 2 raised to the seventh power because powers goe from
>right
>to left, starting from zero, all the way to the leftmost integer.
>
>Thank you so much for your valuable help,
>
>Cheers,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jrkr|de@u @end|ng |rom gm@||@com  Mon Jan 20 17:01:10 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 20 Jan 2020 11:01:10 -0500
Subject: [R] "In sqrt(VS) : NaNs produced"
In-Reply-To: <237a676d-4af9-f2cf-b09a-e4f36655184a@dewey.myzen.co.uk>
References: <CACqmUaqtSaoGKXTNqXfY8JKGOd8UXXQm9mT5_UObBVCm=G7MCA-987@mail.gmail.com>
 <237a676d-4af9-f2cf-b09a-e4f36655184a@dewey.myzen.co.uk>
Message-ID: <CAKZQJMDevz4LYodgqKvwF5vhpoVuPqe-xkSHOsEZdR0y=F5fcA@mail.gmail.com>

As a follow-up to Michael's post, here is a link to some advice on how
create the example.
/<a href=" http://adv-r.had.co.nz/Reproducibility.html "> How to write a
reproducible example </a>


On Mon, 20 Jan 2020 at 08:49, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Your script and data were stripped so we are none the wiser I am afraid.
> You need to embed the script in your post and give a minimal data-set
> which exhibits the problem using dput() and embed that in the post too.
>
> Michael
>
> On 19/01/2020 08:25, Atul Saini wrote:
> > Hello R,
> >               I am attaching the script and data please help me to solve
> the
> > problem of
> >
> > "In sqrt(VS) : NaNs produced"  with the p value of dumy$Mar
> >
> > Regards,
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From v@|kremk @end|ng |rom gm@||@com  Mon Jan 20 23:58:39 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Mon, 20 Jan 2020 16:58:39 -0600
Subject: [R] Mixed format
Message-ID: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>

Hi All,

I have a data frame where one column is  a mixed date format,
a date in the form "%m-%d-%y"  and "%m/%d/%Y", also some are not in date format.

Is there a way to delete the rows that contain non-dates  and
standardize the dates in one date format like  %m-%d-%Y?
Please see my  sample data and desired output

DFX<-read.table(text="name ddate
  A  19-10-02
  B  22-11-20
  C  19-01-15
  D  11/19/2006
  F  9/9/2011
  G  12/29/2010
  H  DEX",header=TRUE)

Desired output
name ddate
A  19-10-2002
B  22-11-2020
C  19-01-2015
D  11-19-2006
F  09-09-2011
G  12-29-2010

Thank you


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jan 21 00:40:29 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Jan 2020 23:40:29 +0000
Subject: [R] Mixed format
In-Reply-To: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
References: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
Message-ID: <02b23128-eaf2-9745-d601-81208a270894@sapo.pt>

Hello,

The following strategy works with your data.
It uses the fact that most dates are in one of 3 formats, dmy, mdy, ymd.
It tries those formats one by one, after each try looks for NA's in the 
new column.


# first round, format is dmy
DFX$dnew <- lubridate::dmy(DFX$ddate)
na <- is.na(DFX$dnew)

# second round, format is mdy
DFX$dnew[na] <- lubridate::mdy(DFX$ddate[na])
na <- is.na(DFX$dnew)

# last round, format is ymd
DFX$dnew[na] <- lubridate::ymd(DFX$ddate[na])

# remove what didn't fit any format
DFX <- DFX[!is.na(DFX$dnew), ]
DFX


Hope this helps,

Rui Barradas

?s 22:58 de 20/01/20, Val escreveu:
> Hi All,
> 
> I have a data frame where one column is  a mixed date format,
> a date in the form "%m-%d-%y"  and "%m/%d/%Y", also some are not in date format.
> 
> Is there a way to delete the rows that contain non-dates  and
> standardize the dates in one date format like  %m-%d-%Y?
> Please see my  sample data and desired output
> 
> DFX<-read.table(text="name ddate
>    A  19-10-02
>    B  22-11-20
>    C  19-01-15
>    D  11/19/2006
>    F  9/9/2011
>    G  12/29/2010
>    H  DEX",header=TRUE)
> 
> Desired output
> name ddate
> A  19-10-2002
> B  22-11-2020
> C  19-01-2015
> D  11-19-2006
> F  09-09-2011
> G  12-29-2010
> 
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Jan 21 10:22:24 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Tue, 21 Jan 2020 09:22:24 +0000 (GMT)
Subject: [R] Mixed format
In-Reply-To: <02b23128-eaf2-9745-d601-81208a270894@sapo.pt>
References: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
 <02b23128-eaf2-9745-d601-81208a270894@sapo.pt>
Message-ID: <1255043385.4404444.1579598544376.JavaMail.zimbra@psyctc.org>

I think that might risk giving the wrong date for a date like 1/3/1990 which I think in Val's data is mdy data not dmy.  

As I read the data, where the separator is "/" the format is mdy and where the separator is "-" it's dmy.  So I would
go for:

library(lubridate)
DFX$dnew[grep("-", DFX$ddate, fixed = TRUE)] <- dmy(DFX$ddate[grep("-", DFX$ddate, fixed = TRUE)])
DFX$dnew[grep("/", DFX$ddate, fixed = TRUE)] <- mdy(DFX$ddate[grep("/", DFX$ddate, fixed = TRUE)])
DFX <- DFX[!is.na(DFX$dnew),]
DFX

  name      ddate       dnew
1    A   19-10-02 2002-10-19
2    B   22-11-20 2020-11-22
3    C   19-01-15 2015-01-19
4    D 11/19/2006 2006-11-19
5    F   9/9/2011 2011-09-09
6    G 12/29/2010 2010-12-29

But I am so much in awe of Rui's skills with R, and that of most of the regular commentators here, that I submit
this a little nervously!

Many thanks to all who teach me so much here, lovely, if I am correct, to contribute for a change!

Chris


----- Original Message -----
> From: "Rui Barradas" <ruipbarradas at sapo.pt>
> To: "Val" <valkremk at gmail.com>, "r-help at R-project.org (r-help at r-project.org)" <r-help at r-project.org>
> Sent: Tuesday, 21 January, 2020 00:40:29
> Subject: Re: [R] Mixed format

> Hello,
> 
> The following strategy works with your data.
> It uses the fact that most dates are in one of 3 formats, dmy, mdy, ymd.
> It tries those formats one by one, after each try looks for NA's in the
> new column.
> 
> 
> # first round, format is dmy
> DFX$dnew <- lubridate::dmy(DFX$ddate)
> na <- is.na(DFX$dnew)
> 
> # second round, format is mdy
> DFX$dnew[na] <- lubridate::mdy(DFX$ddate[na])
> na <- is.na(DFX$dnew)
> 
> # last round, format is ymd
> DFX$dnew[na] <- lubridate::ymd(DFX$ddate[na])
> 
> # remove what didn't fit any format
> DFX <- DFX[!is.na(DFX$dnew), ]
> DFX
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 22:58 de 20/01/20, Val escreveu:
>> Hi All,
>> 
>> I have a data frame where one column is  a mixed date format,
>> a date in the form "%m-%d-%y"  and "%m/%d/%Y", also some are not in date format.
>> 
>> Is there a way to delete the rows that contain non-dates  and
>> standardize the dates in one date format like  %m-%d-%Y?
>> Please see my  sample data and desired output
>> 
>> DFX<-read.table(text="name ddate
>>    A  19-10-02
>>    B  22-11-20u
>>    C  19-01-15
>>    D  11/19/2006
>>    F  9/9/2011
>>    G  12/29/2010
>>    H  DEX",header=TRUE)
>> 
>> Desired output
>> name ddate
>> A  19-10-2002
>> B  22-11-2020
>> C  19-01-2015
>> D  11-19-2006
>> F  09-09-2011
>> G  12-29-2010
>> 
>> Thank you
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From pd@|gd @end|ng |rom gm@||@com  Tue Jan 21 11:49:49 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 21 Jan 2020 11:49:49 +0100
Subject: [R] Mixed format
In-Reply-To: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
References: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
Message-ID: <21E3E32A-9C50-47B7-B62F-36D29CB16856@gmail.com>

Perhaps flogging a dead horse here, but notice that your desired output has lines C and D in conflicting formats, since you can't have 19 in both 1st and 2nd position. Also, it is not clear that A-C are not yy-mm-dd, with B being November 20 2022. 

If you can ensure that formats are at least consistent within xx-yy-zz and xx/yy/zzzz, then you can do as Rui suggests (possibly safeguarded by comparing results for several formats), otherwise you are a bit "up the roof without a paddle".

-pd

> On 20 Jan 2020, at 23:58 , Val <valkremk at gmail.com> wrote:
> 
> Hi All,
> 
> I have a data frame where one column is  a mixed date format,
> a date in the form "%m-%d-%y"  and "%m/%d/%Y", also some are not in date format.
> 
> Is there a way to delete the rows that contain non-dates  and
> standardize the dates in one date format like  %m-%d-%Y?
> Please see my  sample data and desired output
> 
> DFX<-read.table(text="name ddate
>  A  19-10-02
>  B  22-11-20
>  C  19-01-15
>  D  11/19/2006
>  F  9/9/2011
>  G  12/29/2010
>  H  DEX",header=TRUE)
> 
> Desired output
> name ddate
> A  19-10-2002
> B  22-11-2020
> C  19-01-2015
> D  11-19-2006
> F  09-09-2011
> G  12-29-2010
> 
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jan 21 12:28:29 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 21 Jan 2020 11:28:29 +0000
Subject: [R] Mixed format
In-Reply-To: <1255043385.4404444.1579598544376.JavaMail.zimbra@psyctc.org>
References: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
 <02b23128-eaf2-9745-d601-81208a270894@sapo.pt>
 <1255043385.4404444.1579598544376.JavaMail.zimbra@psyctc.org>
Message-ID: <8c480a90-3b57-709a-a836-6f271426cc09@sapo.pt>

Hello,

Inline.

?s 09:22 de 21/01/20, Chris Evans escreveu:
> I think that might risk giving the wrong date for a date like 1/3/1990 which I think in Val's data is mdy data not dmy.
> 
> As I read the data, where the separator is "/" the format is mdy and where the separator is "-" it's dmy.  

Maybe you're right. But I really don't know, in my country (Portugal) we 
use "/" and dmy. Anyway, what's important is that the OP must have a 
much better understanding of the data, the way it is posted is likely to 
cause errors. See, for instance, the expected output with numbers 
greater than 12 in the 1st and 2nd places, depending on the row.


So I would
> go for:
> 
> library(lubridate)
> DFX$dnew[grep("-", DFX$ddate, fixed = TRUE)] <- dmy(DFX$ddate[grep("-", DFX$ddate, fixed = TRUE)])
> DFX$dnew[grep("/", DFX$ddate, fixed = TRUE)] <- mdy(DFX$ddate[grep("/", DFX$ddate, fixed = TRUE)])
> DFX <- DFX[!is.na(DFX$dnew),]
> DFX
> 
>    name      ddate       dnew
> 1    A   19-10-02 2002-10-19
> 2    B   22-11-20 2020-11-22
> 3    C   19-01-15 2015-01-19
> 4    D 11/19/2006 2006-11-19
> 5    F   9/9/2011 2011-09-09
> 6    G 12/29/2010 2010-12-29
> 
> But I am so much in awe of Rui's skills with R, and that of most of the regular commentators here, that I submit
> this a little nervously!

Thanks!

Rui Barradas
> 
> Many thanks to all who teach me so much here, lovely, if I am correct, to contribute for a change!
> 
> Chris
> 
> 
> ----- Original Message -----
>> From: "Rui Barradas" <ruipbarradas at sapo.pt>
>> To: "Val" <valkremk at gmail.com>, "r-help at R-project.org (r-help at r-project.org)" <r-help at r-project.org>
>> Sent: Tuesday, 21 January, 2020 00:40:29
>> Subject: Re: [R] Mixed format
> 
>> Hello,
>>
>> The following strategy works with your data.
>> It uses the fact that most dates are in one of 3 formats, dmy, mdy, ymd.
>> It tries those formats one by one, after each try looks for NA's in the
>> new column.
>>
>>
>> # first round, format is dmy
>> DFX$dnew <- lubridate::dmy(DFX$ddate)
>> na <- is.na(DFX$dnew)
>>
>> # second round, format is mdy
>> DFX$dnew[na] <- lubridate::mdy(DFX$ddate[na])
>> na <- is.na(DFX$dnew)
>>
>> # last round, format is ymd
>> DFX$dnew[na] <- lubridate::ymd(DFX$ddate[na])
>>
>> # remove what didn't fit any format
>> DFX <- DFX[!is.na(DFX$dnew), ]
>> DFX
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 22:58 de 20/01/20, Val escreveu:
>>> Hi All,
>>>
>>> I have a data frame where one column is  a mixed date format,
>>> a date in the form "%m-%d-%y"  and "%m/%d/%Y", also some are not in date format.
>>>
>>> Is there a way to delete the rows that contain non-dates  and
>>> standardize the dates in one date format like  %m-%d-%Y?
>>> Please see my  sample data and desired output
>>>
>>> DFX<-read.table(text="name ddate
>>>     A  19-10-02
>>>     B  22-11-20u
>>>     C  19-01-15
>>>     D  11/19/2006
>>>     F  9/9/2011
>>>     G  12/29/2010
>>>     H  DEX",header=TRUE)
>>>
>>> Desired output
>>> name ddate
>>> A  19-10-2002
>>> B  22-11-2020
>>> C  19-01-2015
>>> D  11-19-2006
>>> F  09-09-2011
>>> G  12-29-2010
>>>
>>> Thank you
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From b@|u @end|ng |rom berke|ey@edu  Mon Jan 20 19:10:00 2020
From: b@|u @end|ng |rom berke|ey@edu (Benjamin Lu)
Date: Mon, 20 Jan 2020 10:10:00 -0800
Subject: [R] [R-pkgs] forestError 0.1.0: Random forest conditional
 prediction intervals, squared errors, and biases
Message-ID: <CAFbfGPa1mNBzw40kui_pD=CWSkFMeRiZ4551kg8ZcbKzdhfDvg@mail.gmail.com>

Hi all,

I?m writing to introduce a new package, forestError. This package estimates
conditional response quantiles (prediction intervals), conditional mean
squared prediction errors, conditional biases, and conditional prediction
error distribution functions for random forests using new methods proposed
in Lu and Hardin (2019+) <arXiv:1912.07435>.

The package does not grow specially designed random forests, but rather
sits on top of the standard random forest algorithm. In particular, the
package can estimate the above quantities for regression random forests
built using the randomForest, randomForestSRC, ranger, and quantregForest
packages.

I hope that you find this useful. Please feel free to reach out with
feedback or questions.

CRAN: https://cran.r-project.org/package=forestError
Github: https://github.com/benjilu/forestError
Reference: https://arxiv.org/abs/1912.07435

Best,
Benji Lu

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @ng@d|ub @end|ng |rom gm@||@com  Tue Jan 21 12:44:51 2020
From: @ng@d|ub @end|ng |rom gm@||@com (Ulavappa Angadi)
Date: Tue, 21 Jan 2020 17:14:51 +0530
Subject: [R] How my r package convert into higher r version
Message-ID: <CAJ4Qip-TNMLMGfK9Onj4XBm8F0Fbs18+PM2dfqWiUvHYGq5VmA@mail.gmail.com>

Dear all
please help me to how my r package (version 3.0.) convert into higher r
version  (3.6)

while installing in higher version R it showing
package mbFerns_1.0.1.zip is not available (for R version 3.6.0)

With regards

Angadi U B
Principal. Scientist
CABin, IASRI, Pusa, New Delhi

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jan 21 16:56:03 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 21 Jan 2020 07:56:03 -0800
Subject: [R] How my r package convert into higher r version
In-Reply-To: <CAJ4Qip-TNMLMGfK9Onj4XBm8F0Fbs18+PM2dfqWiUvHYGq5VmA@mail.gmail.com>
References: <CAJ4Qip-TNMLMGfK9Onj4XBm8F0Fbs18+PM2dfqWiUvHYGq5VmA@mail.gmail.com>
Message-ID: <CEDF2959-E11F-4569-BAD6-A142205DFB81@dcn.davis.ca.us>

a) Wrong mailing list... Per the Posting Guide you probably need [1].

b) In the absence of a specific question, you should probably demonstrate that you have read and followed [2].

c) These mailing lists use plain text only... sumbitting questions with HTML formatting is strongly frowned on because the recipients will only see some mangled version of what you sent. Review your email client settings.

[1] https://stat.ethz.ch/mailman/listinfo/r-package-devel

[2] https://cran.r-project.org/web/packages/submission_checklist.html

On January 21, 2020 3:44:51 AM PST, Ulavappa Angadi <angadiub at gmail.com> wrote:
>Dear all
>please help me to how my r package (version 3.0.) convert into higher r
>version  (3.6)
>
>while installing in higher version R it showing
>package mbFerns_1.0.1.zip is not available (for R version 3.6.0)
>
>With regards
>
>Angadi U B
>Principal. Scientist
>CABin, IASRI, Pusa, New Delhi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p@rkhur@ @end|ng |rom |nd|@n@@edu  Tue Jan 21 18:20:14 2020
From: p@rkhur@ @end|ng |rom |nd|@n@@edu (David)
Date: Tue, 21 Jan 2020 12:20:14 -0500
Subject: [R] File names for mac newby
Message-ID: <6a6df995-9029-ac4b-cbd0-cc53e12be5dc@indiana.edu>

I moved to a mac a few months ago after years in windows, and I'm still 
learning basics.? I'm wanting to create a data frame based on a text 
file called HouseTemps.txt.? That's a file within one called house which 
is within one called ah.? That may further be in one called? Documents.? 
I tried various lines like:

temps <- 
read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)

based on my windows DOS experience, but nothing I try works.? So my 
question is, what do complete file names look like in a mac?

I tried Apple support, but they couldn't help me with R.


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Tue Jan 21 19:13:07 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Tue, 21 Jan 2020 10:13:07 -0800
Subject: [R] File names for mac newby
In-Reply-To: <6a6df995-9029-ac4b-cbd0-cc53e12be5dc@indiana.edu>
References: <6a6df995-9029-ac4b-cbd0-cc53e12be5dc@indiana.edu>
Message-ID: <CAA99HCw=Gj_0L5za9jUj2O4xPDxwxG9SrjCM-3wo_NLEvzxdsA@mail.gmail.com>

Hi David,

Often on a Mac you can "right click" (or on a laptop--press down with
two fingers), and a pop-up will give you the option to "Copy File
Path". (You can also find this option in a Finder window under the
"Finder -> Services" menu bar) .This is the path you should use to
import your file into R.

There's also a R-Help mailing list for Mac users (R-SIG-Mac):
https://stat.ethz.ch/mailman/listinfo/r-sig-mac

HTH, Bill.

W. Michels, Ph.D.

On Tue, Jan 21, 2020 at 9:38 AM David <parkhurs at indiana.edu> wrote:
>
> I moved to a mac a few months ago after years in windows, and I'm still
> learning basics.  I'm wanting to create a data frame based on a text
> file called HouseTemps.txt.  That's a file within one called house which
> is within one called ah.  That may further be in one called  Documents.
> I tried various lines like:
>
> temps <-
> read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)
>
> based on my windows DOS experience, but nothing I try works.  So my
> question is, what do complete file names look like in a mac?
>
> I tried Apple support, but they couldn't help me with R.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@me@ @end|ng |rom j@@@oc@com  Tue Jan 21 18:53:57 2020
From: j@me@ @end|ng |rom j@@@oc@com (James Spottiswoode)
Date: Tue, 21 Jan 2020 09:53:57 -0800
Subject: [R] File names for mac newby
In-Reply-To: <6a6df995-9029-ac4b-cbd0-cc53e12be5dc@indiana.edu>
References: <6a6df995-9029-ac4b-cbd0-cc53e12be5dc@indiana.edu>
Message-ID: <F98D80D1-84B2-40A9-B0FA-F0BAB3264171@jsasoc.com>

OSX is based on BSD UNIX so paths use the forward slash as separator, e.g.

temps <- read.table("c:/Users/DFP/Documents/ah/house/HouseTemps.txt",header=T,row.names=1)

Best James

> On Jan 21, 2020, at 9:20 AM, David <parkhurs at indiana.edu> wrote:
> 
> I moved to a mac a few months ago after years in windows, and I'm still learning basics.  I'm wanting to create a data frame based on a text file called HouseTemps.txt.  That's a file within one called house which is within one called ah.  That may further be in one called  Documents.  I tried various lines like:
> 
> temps <- read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)
> 
> based on my windows DOS experience, but nothing I try works.  So my question is, what do complete file names look like in a mac?
> 
> I tried Apple support, but they couldn't help me with R.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



	[[alternative HTML version deleted]]


From HDor@n @end|ng |rom @|r@org  Tue Jan 21 20:56:05 2020
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Tue, 21 Jan 2020 19:56:05 +0000
Subject: [R] N Sizes between Pairs of Columns using cor(, , ,
 use = 'pairwise')
Message-ID: <BL0PR05MB48188CF4E5CF763445DC4E51CA0D0@BL0PR05MB4818.namprd05.prod.outlook.com>

I'm trying to find an efficient way to find the N size on correlations produced when using the pairwise option in cor(). 

Here is a sample to illustrate:

### Create a sample data frame
tmp <- data.frame(v1 = rnorm(10), v2 = rnorm(10), v3 = rnorm(10), v4 = rnorm(10))

### Create some random missingness
for(i in 1:4) tmp[sample(1:10, 2, replace = FALSE), i] <- NA

### Correlate
cor(tmp, use = 'pairwise')

Now, a REALLY bad idea would be this (but conceptually it illustrates what I want)

### Identify all column pairs
pairs <- combn(4,2)

### Now, write code to loop over each pair of columns and identify where both rows are TRUE
!is.na(tmp[, pairs[,1]])

Of course doing this when the number of pairwise combinations is silly. So, hmmm, I don't see as a by-product of the cor() function N sizes, and certainly looping over pairs of columns would be doable, but not efficient, but any suggestions on this?

Thanks,
Harold


From wdun|@p @end|ng |rom t|bco@com  Tue Jan 21 21:00:08 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 21 Jan 2020 12:00:08 -0800
Subject: [R] N Sizes between Pairs of Columns using cor(, , ,
 use = 'pairwise')
In-Reply-To: <BL0PR05MB48188CF4E5CF763445DC4E51CA0D0@BL0PR05MB4818.namprd05.prod.outlook.com>
References: <BL0PR05MB48188CF4E5CF763445DC4E51CA0D0@BL0PR05MB4818.namprd05.prod.outlook.com>
Message-ID: <CAF8bMcacd56moxTXF5ipCDv5-TMLk9DhNry-R21uLzh=0zR6bg@mail.gmail.com>

crossprod(!is.na(tmp))

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Jan 21, 2020 at 11:56 AM Doran, Harold <HDoran at air.org> wrote:

> I'm trying to find an efficient way to find the N size on correlations
> produced when using the pairwise option in cor().
>
> Here is a sample to illustrate:
>
> ### Create a sample data frame
> tmp <- data.frame(v1 = rnorm(10), v2 = rnorm(10), v3 = rnorm(10), v4 =
> rnorm(10))
>
> ### Create some random missingness
> for(i in 1:4) tmp[sample(1:10, 2, replace = FALSE), i] <- NA
>
> ### Correlate
> cor(tmp, use = 'pairwise')
>
> Now, a REALLY bad idea would be this (but conceptually it illustrates what
> I want)
>
> ### Identify all column pairs
> pairs <- combn(4,2)
>
> ### Now, write code to loop over each pair of columns and identify where
> both rows are TRUE
> !is.na(tmp[, pairs[,1]])
>
> Of course doing this when the number of pairwise combinations is silly.
> So, hmmm, I don't see as a by-product of the cor() function N sizes, and
> certainly looping over pairs of columns would be doable, but not efficient,
> but any suggestions on this?
>
> Thanks,
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Tue Jan 21 21:01:58 2020
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Tue, 21 Jan 2020 20:01:58 +0000
Subject: [R] File names for mac newby
In-Reply-To: <F98D80D1-84B2-40A9-B0FA-F0BAB3264171@jsasoc.com>
References: <6a6df995-9029-ac4b-cbd0-cc53e12be5dc@indiana.edu>
 <F98D80D1-84B2-40A9-B0FA-F0BAB3264171@jsasoc.com>
Message-ID: <D2E9FB89-054E-4DA0-83FD-037730380160@utoronto.ca>

You would also need to drop the c: as that is a DOS/Windows thing.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
 

?On 2020-01-21, 1:26 PM, "R-help on behalf of James Spottiswoode" <r-help-bounces at r-project.org on behalf of james at jsasoc.com> wrote:

    OSX is based on BSD UNIX so paths use the forward slash as separator, e.g.
    
    temps <- read.table("c:/Users/DFP/Documents/ah/house/HouseTemps.txt",header=T,row.names=1)
    
    Best James
    
    > On Jan 21, 2020, at 9:20 AM, David <parkhurs at indiana.edu> wrote:
    > 
    > I moved to a mac a few months ago after years in windows, and I'm still learning basics.  I'm wanting to create a data frame based on a text file called HouseTemps.txt.  That's a file within one called house which is within one called ah.  That may further be in one called  Documents.  I tried various lines like:
    > 
    > temps <- read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)
    > 
    > based on my windows DOS experience, but nothing I try works.  So my question is, what do complete file names look like in a mac?
    > 
    > I tried Apple support, but they couldn't help me with R.
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    > 
    
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From HDor@n @end|ng |rom @|r@org  Tue Jan 21 21:06:31 2020
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Tue, 21 Jan 2020 20:06:31 +0000
Subject: [R] N Sizes between Pairs of Columns using cor(, , ,
 use = 'pairwise')
In-Reply-To: <CAF8bMcacd56moxTXF5ipCDv5-TMLk9DhNry-R21uLzh=0zR6bg@mail.gmail.com>
References: <BL0PR05MB48188CF4E5CF763445DC4E51CA0D0@BL0PR05MB4818.namprd05.prod.outlook.com>
 <CAF8bMcacd56moxTXF5ipCDv5-TMLk9DhNry-R21uLzh=0zR6bg@mail.gmail.com>
Message-ID: <BL0PR05MB481827E49E05663C2697EE9FCA0D0@BL0PR05MB4818.namprd05.prod.outlook.com>

Now that?s brilliant! And to get a vector of counts I could extend it to

rr <- crossprod(!is.na(tmp))

rr[lower.tri(rr),]

Thanks, Bill!

From: William Dunlap <wdunlap at tibco.com>
Sent: Tuesday, January 21, 2020 3:00 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] N Sizes between Pairs of Columns using cor(, , , use = 'pairwise')

External email alert: Be wary of links & attachments.
crossprod(!is.na<https://nam01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fis.na%2F&data=02%7C01%7CHDoran%40air.org%7C8fd9799ec01c4a7550e008d79eac8b57%7C9ea45dbc7b724abfa77cc770a0a8b962%7C0%7C0%7C637152336221357438&sdata=k2OoWHLJts1VNYOBVSn%2Fwv85LLjdpAcH93o7k6HWnJ0%3D&reserved=0>(tmp))

Bill Dunlap
TIBCO Software
wdunlap tibco.com<https://nam01.safelinks.protection.outlook.com/?url=http%3A%2F%2Ftibco.com%2F&data=02%7C01%7CHDoran%40air.org%7C8fd9799ec01c4a7550e008d79eac8b57%7C9ea45dbc7b724abfa77cc770a0a8b962%7C0%7C0%7C637152336221367435&sdata=aonp2ClFToaETLQMSZ7ie629zzGBDxtOWRf3XjHMGMQ%3D&reserved=0>


On Tue, Jan 21, 2020 at 11:56 AM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
I'm trying to find an efficient way to find the N size on correlations produced when using the pairwise option in cor().

Here is a sample to illustrate:

### Create a sample data frame
tmp <- data.frame(v1 = rnorm(10), v2 = rnorm(10), v3 = rnorm(10), v4 = rnorm(10))

### Create some random missingness
for(i in 1:4) tmp[sample(1:10, 2, replace = FALSE), i] <- NA

### Correlate
cor(tmp, use = 'pairwise')

Now, a REALLY bad idea would be this (but conceptually it illustrates what I want)

### Identify all column pairs
pairs <- combn(4,2)

### Now, write code to loop over each pair of columns and identify where both rows are TRUE
!is.na<https://nam01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fis.na%2F&data=02%7C01%7CHDoran%40air.org%7C8fd9799ec01c4a7550e008d79eac8b57%7C9ea45dbc7b724abfa77cc770a0a8b962%7C0%7C0%7C637152336221377429&sdata=LwSEn2KSTjjhT8BhnEvNwSKgt%2BFCj8WIgc8%2FOEsWXJY%3D&reserved=0>(tmp[, pairs[,1]])

Of course doing this when the number of pairwise combinations is silly. So, hmmm, I don't see as a by-product of the cor() function N sizes, and certainly looping over pairs of columns would be doable, but not efficient, but any suggestions on this?

Thanks,
Harold

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=02%7C01%7CHDoran%40air.org%7C8fd9799ec01c4a7550e008d79eac8b57%7C9ea45dbc7b724abfa77cc770a0a8b962%7C0%7C0%7C637152336221377429&sdata=sRZ8evNYBw9MdgChOLWiNFxJ5KJcPnHNT1tUHMrPvEM%3D&reserved=0>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://nam01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=02%7C01%7CHDoran%40air.org%7C8fd9799ec01c4a7550e008d79eac8b57%7C9ea45dbc7b724abfa77cc770a0a8b962%7C0%7C0%7C637152336221387423&sdata=%2F%2FvHb0sfGXF1F9ZaLBdcI6Hw3UVwY2rEYPcvBSuTga4%3D&reserved=0>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Jan 21 23:43:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 22 Jan 2020 09:43:07 +1100
Subject: [R] How my r package convert into higher r version
In-Reply-To: <CAJ4Qip-TNMLMGfK9Onj4XBm8F0Fbs18+PM2dfqWiUvHYGq5VmA@mail.gmail.com>
References: <CAJ4Qip-TNMLMGfK9Onj4XBm8F0Fbs18+PM2dfqWiUvHYGq5VmA@mail.gmail.com>
Message-ID: <CA+8X3fVAE+LBo0v8qXjNvuy3BZEHyNFx1x2eT_O3hYg6DF_g2w@mail.gmail.com>

Hi Ulavappa,
This is only a guess, but there was recently a change in the "barplot"
function that broke a lot of packages. If any functions in your
package call the "barplot" function, it may have been dropped from the
repositories for newer versions of R.

Jim

On Wed, Jan 22, 2020 at 12:56 AM Ulavappa Angadi <angadiub at gmail.com> wrote:
>
> Dear all
> please help me to how my r package (version 3.0.) convert into higher r
> version  (3.6)
>
> while installing in higher version R it showing
> package mbFerns_1.0.1.zip is not available (for R version 3.6.0)
>
> With regards
>
> Angadi U B
> Principal. Scientist
> CABin, IASRI, Pusa, New Delhi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dj|uckett @end|ng |rom gm@||@com  Wed Jan 22 05:36:54 2020
From: dj|uckett @end|ng |rom gm@||@com (David Luckett)
Date: Wed, 22 Jan 2020 15:36:54 +1100
Subject: [R] Mixed format
Message-ID: <CAM4LFTLCe_XDatTZpbYwrUhhToBWJkWJE2CoAOCPG9DhFjfHsw@mail.gmail.com>

Bearing Peter's warning in mind, the {anytime} package can be useful in this
example:

library(anytime)
DFX$dnew <- anydate(DFX$ddate)
DFX
# First three strings are ambiguous
# Also, string 5 is only OK if its assumed to be the same format as
strings 4 & 6.

# Can add a specific format to those anytime() uses:
getFormats()
addFormats(c("%d-%m-%y"))

DFX$dnew <- anydate(DFX$ddate)
DFX

Cheers
David Luckett
djluckett at gmail.com
0408 750 703


From rm@h@rp @end|ng |rom me@com  Wed Jan 22 08:52:54 2020
From: rm@h@rp @end|ng |rom me@com (R. Mark Sharp)
Date: Wed, 22 Jan 2020 01:52:54 -0600
Subject: [R] File names for mac newby
In-Reply-To: <D2E9FB89-054E-4DA0-83FD-037730380160@utoronto.ca>
References: <D2E9FB89-054E-4DA0-83FD-037730380160@utoronto.ca>
Message-ID: <2596ED33-A213-45BA-945C-29E7A6AB3616@me.com>

Open the terminal application in the Utilities folder. Select the file you want to use in R in a Finder window and drag it to the terminal applications command line prompt and then release the file. The absolute path of the file will be entered in the command line of the terminal?s window. Though this absolute path will work, relative paths are often preferred. 


Mark

R. Mark Sharp, Ph.D.
rmsharp at me.com

> On Jan 21, 2020, at 2:02 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
> 
> ?You would also need to drop the c: as that is a DOS/Windows thing.
> 
> -- 
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> 
> ?On 2020-01-21, 1:26 PM, "R-help on behalf of James Spottiswoode" <r-help-bounces at r-project.org on behalf of james at jsasoc.com> wrote:
> 
>    OSX is based on BSD UNIX so paths use the forward slash as separator, e.g.
> 
>    temps <- read.table("c:/Users/DFP/Documents/ah/house/HouseTemps.txt",header=T,row.names=1)
> 
>    Best James
> 
>> On Jan 21, 2020, at 9:20 AM, David <parkhurs at indiana.edu> wrote:
>> 
>> I moved to a mac a few months ago after years in windows, and I'm still learning basics.  I'm wanting to create a data frame based on a text file called HouseTemps.txt.  That's a file within one called house which is within one called ah.  That may further be in one called  Documents.  I tried various lines like:
>> 
>> temps <- read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)
>> 
>> based on my windows DOS experience, but nothing I try works.  So my question is, what do complete file names look like in a mac?
>> 
>> I tried Apple support, but they couldn't help me with R.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Wed Jan 22 11:15:08 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 22 Jan 2020 23:15:08 +1300
Subject: [R] "In sqrt(VS) : NaNs produced"
In-Reply-To: <CACqmUaqtSaoGKXTNqXfY8JKGOd8UXXQm9mT5_UObBVCm=G7MCA-987@mail.gmail.com>
References: <CACqmUaqtSaoGKXTNqXfY8JKGOd8UXXQm9mT5_UObBVCm=G7MCA-987@mail.gmail.com>
Message-ID: <CABcYAd+D5Q6jXxPzXmU-QWtmaCv+myuQSGf6V5PjrAoQJwHDNg@mail.gmail.com>

> sqrt(c(1,-2,3))
[1] 1.000000      NaN 1.732051
Warning message:
In sqrt(c(1, -2, 3)) : NaNs produced
You might want to put
if (any(VS < 0)) stop("some VS are negative")
just after the definition of VS.

On Tue, 21 Jan 2020 at 02:01, Atul Saini <atulsainimail at gmail.com> wrote:
>
> Hello R,
>              I am attaching the script and data please help me to solve the
> problem of
>
> "In sqrt(VS) : NaNs produced"  with the p value of dumy$Mar
>
> Regards,
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From th@nhtungm||@n @end|ng |rom gm@||@com  Wed Jan 22 16:00:39 2020
From: th@nhtungm||@n @end|ng |rom gm@||@com (Tung Nguyen)
Date: Wed, 22 Jan 2020 07:00:39 -0800
Subject: [R] Error with constrained curve fitting through specific points
Message-ID: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>

Hello R-Help,

I'm trying to find the best fitting curve through a given set of points.
The fitted curve must also pass through these points. I found an answer on
Cross Validated which suggested to use the `cobs: Constrained B-Splines
(Sparse Matrix Based)` package. However, I got an error while testing it
with my sample data:

Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)

*My question*: what caused this error and how can I fix it? Any suggestion
is greatly appreciated. Thanks!

library(cobs)

dat <- data.frame(
  x = c(1e-06,0.25,0.5,0.75,1,2,3,4,5,6),
  y = c(1e-07,1.925,2.9625,3.469375,
        3.875,4.5315,4.89,5.09375,5.216,5.46))
dat
#>          x         y#> 1  1.0e-06 0.0000001#> 2  2.5e-01
1.9250000#> 3  5.0e-01 2.9625000#> 4  7.5e-01 3.4693750#> 5  1.0e+00
3.8750000#> 6  2.0e+00 4.5315000#> 7  3.0e+00 4.8900000#> 8  4.0e+00
5.0937500#> 9  5.0e+00 5.2160000#> 10 6.0e+00 5.4600000
# visual inspection
plot(dat); lines(dat)

# define constrained points
con <- matrix(
  cbind(c(0,0,0,0,0,0,0,0,0,0),
        c(1e-06,0.25,0.5,0.75,1,2,3, 4,5,6),
        c(1e-07,1.925,2.9625,3.469375,
          3.875,4.5315,4.89,5.09375,5.216, 5.46)),
  ncol = 3, nrow = 10)
# curve fitting
fit_result <- cobs(dat$x, dat$y, pointwise = con)*#> qbsks2():
#>  Performing general knot selection ...
#> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)*


Best regards,

-- Tung

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan 22 16:17:23 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Jan 2020 07:17:23 -0800
Subject: [R] File names for mac newby
In-Reply-To: <2596ED33-A213-45BA-945C-29E7A6AB3616@me.com>
References: <D2E9FB89-054E-4DA0-83FD-037730380160@utoronto.ca>
 <2596ED33-A213-45BA-945C-29E7A6AB3616@me.com>
Message-ID: <CAGxFJbSUxNK8SRD1s57pVG5y=S4dQBAycKYkifVxzXbwSBt44g@mail.gmail.com>

Use ?file.choose to choose a file interactively and avoid typing paths:

read.table(file.choose(), header = TRUE, etc....)

will open a finder window to navigate to and click on the file you want.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 21, 2020 at 11:53 PM R. Mark Sharp via R-help <
r-help at r-project.org> wrote:

> Open the terminal application in the Utilities folder. Select the file you
> want to use in R in a Finder window and drag it to the terminal
> applications command line prompt and then release the file. The absolute
> path of the file will be entered in the command line of the terminal?s
> window. Though this absolute path will work, relative paths are often
> preferred.
>
>
> Mark
>
> R. Mark Sharp, Ph.D.
> rmsharp at me.com
>
> > On Jan 21, 2020, at 2:02 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
> wrote:
> >
> > ?You would also need to drop the c: as that is a DOS/Windows thing.
> >
> > --
> > Kevin E. Thorpe
> > Head of Biostatistics,  Applied Health Research Centre (AHRC)
> > Li Ka Shing Knowledge Institute of St. Michael's
> > Assistant Professor, Dalla Lana School of Public Health
> > University of Toronto
> > email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> >
> >
> > ?On 2020-01-21, 1:26 PM, "R-help on behalf of James Spottiswoode" <
> r-help-bounces at r-project.org on behalf of james at jsasoc.com> wrote:
> >
> >    OSX is based on BSD UNIX so paths use the forward slash as separator,
> e.g.
> >
> >    temps <-
> read.table("c:/Users/DFP/Documents/ah/house/HouseTemps.txt",header=T,row.names=1)
> >
> >    Best James
> >
> >> On Jan 21, 2020, at 9:20 AM, David <parkhurs at indiana.edu> wrote:
> >>
> >> I moved to a mac a few months ago after years in windows, and I'm still
> learning basics.  I'm wanting to create a data frame based on a text file
> called HouseTemps.txt.  That's a file within one called house which is
> within one called ah.  That may further be in one called  Documents.  I
> tried various lines like:
> >>
> >> temps <-
> read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)
> >>
> >> based on my windows DOS experience, but nothing I try works.  So my
> question is, what do complete file names look like in a mac?
> >>
> >> I tried Apple support, but they couldn't help me with R.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> >        [[alternative HTML version deleted]]
> >
> >    ______________________________________________
> >    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >    https://stat.ethz.ch/mailman/listinfo/r-help
> >    PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >    and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jan 22 16:22:55 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Jan 2020 07:22:55 -0800
Subject: [R] 
 Error with constrained curve fitting through specific points
In-Reply-To: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
References: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
Message-ID: <CAGxFJbR_OzCdehivva0wfEu+KnbQY47fHs6n1DgN0DxMGX0nGw@mail.gmail.com>

Just a note: There is no such thing as "a best fitting curve" that must
pass through all the points.

You may wish to consult a statistician or spend time with references to
clarify your intent.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 22, 2020 at 7:01 AM Tung Nguyen <thanhtungmilan at gmail.com>
wrote:

> Hello R-Help,
>
> I'm trying to find the best fitting curve through a given set of points.
> The fitted curve must also pass through these points. I found an answer on
> Cross Validated which suggested to use the `cobs: Constrained B-Splines
> (Sparse Matrix Based)` package. However, I got an error while testing it
> with my sample data:
>
> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)
>
> *My question*: what caused this error and how can I fix it? Any suggestion
> is greatly appreciated. Thanks!
>
> library(cobs)
>
> dat <- data.frame(
>   x = c(1e-06,0.25,0.5,0.75,1,2,3,4,5,6),
>   y = c(1e-07,1.925,2.9625,3.469375,
>         3.875,4.5315,4.89,5.09375,5.216,5.46))
> dat
> #>          x         y#> 1  1.0e-06 0.0000001#> 2  2.5e-01
> 1.9250000#> 3  5.0e-01 2.9625000#> 4  7.5e-01 3.4693750#> 5  1.0e+00
> 3.8750000#> 6  2.0e+00 4.5315000#> 7  3.0e+00 4.8900000#> 8  4.0e+00
> 5.0937500#> 9  5.0e+00 5.2160000#> 10 6.0e+00 5.4600000
> # visual inspection
> plot(dat); lines(dat)
>
> # define constrained points
> con <- matrix(
>   cbind(c(0,0,0,0,0,0,0,0,0,0),
>         c(1e-06,0.25,0.5,0.75,1,2,3, 4,5,6),
>         c(1e-07,1.925,2.9625,3.469375,
>           3.875,4.5315,4.89,5.09375,5.216, 5.46)),
>   ncol = 3, nrow = 10)
> # curve fitting
> fit_result <- cobs(dat$x, dat$y, pointwise = con)*#> qbsks2():
> #>  Performing general knot selection ...
> #> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg
> 2)*
>
>
> Best regards,
>
> -- Tung
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jan 22 16:32:44 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 22 Jan 2020 15:32:44 +0000
Subject: [R] 
 Error with constrained curve fitting through specific points
In-Reply-To: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
References: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
Message-ID: <6f2d3d13f78f4395b4a2cd062a5a375f@SRVEXCHCM1302.precheza.cz>

Hi

You probably has to use less points in con.

With just three points
> con1 <- con[c(1, 5, 10),]
> fit_result <- cobs(dat$x, dat$y, pointwise = con1)
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...

function seems to work without error.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tung Nguyen
> Sent: Wednesday, January 22, 2020 4:01 PM
> To: r-help at r-project.org
> Subject: [R] Error with constrained curve fitting through specific points
> 
> Hello R-Help,
> 
> I'm trying to find the best fitting curve through a given set of points.
> The fitted curve must also pass through these points. I found an answer on
> Cross Validated which suggested to use the `cobs: Constrained B-Splines
> (Sparse Matrix Based)` package. However, I got an error while testing it
> with my sample data:
> 
> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)
> 
> *My question*: what caused this error and how can I fix it? Any suggestion
> is greatly appreciated. Thanks!
> 
> library(cobs)
> 
> dat <- data.frame(
>   x = c(1e-06,0.25,0.5,0.75,1,2,3,4,5,6),
>   y = c(1e-07,1.925,2.9625,3.469375,
>         3.875,4.5315,4.89,5.09375,5.216,5.46))
> dat
> #>          x         y#> 1  1.0e-06 0.0000001#> 2  2.5e-01
> 1.9250000#> 3  5.0e-01 2.9625000#> 4  7.5e-01 3.4693750#> 5  1.0e+00
> 3.8750000#> 6  2.0e+00 4.5315000#> 7  3.0e+00 4.8900000#> 8  4.0e+00
> 5.0937500#> 9  5.0e+00 5.2160000#> 10 6.0e+00 5.4600000
> # visual inspection
> plot(dat); lines(dat)
> 
> # define constrained points
> con <- matrix(
>   cbind(c(0,0,0,0,0,0,0,0,0,0),
>         c(1e-06,0.25,0.5,0.75,1,2,3, 4,5,6),
>         c(1e-07,1.925,2.9625,3.469375,
>           3.875,4.5315,4.89,5.09375,5.216, 5.46)),
>   ncol = 3, nrow = 10)
> # curve fitting
> fit_result <- cobs(dat$x, dat$y, pointwise = con)*#> qbsks2():
> #>  Performing general knot selection ...
> #> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg
2)*
> 
> 
> Best regards,
> 
> -- Tung
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From p@rkhur@ @end|ng |rom |nd|@n@@edu  Wed Jan 22 17:05:29 2020
From: p@rkhur@ @end|ng |rom |nd|@n@@edu (David)
Date: Wed, 22 Jan 2020 11:05:29 -0500
Subject: [R] File names for mac newby
In-Reply-To: <CAGxFJbSUxNK8SRD1s57pVG5y=S4dQBAycKYkifVxzXbwSBt44g@mail.gmail.com>
References: <D2E9FB89-054E-4DA0-83FD-037730380160@utoronto.ca>
 <2596ED33-A213-45BA-945C-29E7A6AB3616@me.com>
 <CAGxFJbSUxNK8SRD1s57pVG5y=S4dQBAycKYkifVxzXbwSBt44g@mail.gmail.com>
Message-ID: <1b780df8-1c44-1589-2970-c4692942b1d3@indiana.edu>

Neat.? Thanks.

On 1/22/20 10:17 AM, Bert Gunter wrote:
>
> Use ?file.choose to choose a file interactively and avoid typing paths:
>
> read.table(file.choose(), header = TRUE, etc....)
>
> will open a finder window to navigate to and click on the file you want.
>
> -- Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Jan 21, 2020 at 11:53 PM R. Mark Sharp via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     Open the terminal application in the Utilities folder. Select the
>     file you want to use in R in a Finder window and drag it to the
>     terminal applications command line prompt and then release the
>     file. The absolute path of the file will be entered in the command
>     line of the terminal?s window. Though this absolute path will
>     work, relative paths are often preferred.
>
>
>     Mark
>
>     R. Mark Sharp, Ph.D.
>     rmsharp at me.com <mailto:rmsharp at me.com>
>
>     > On Jan 21, 2020, at 2:02 PM, Kevin Thorpe
>     <kevin.thorpe at utoronto.ca <mailto:kevin.thorpe at utoronto.ca>> wrote:
>     >
>     > ?You would also need to drop the c: as that is a DOS/Windows thing.
>     >
>     > --
>     > Kevin E. Thorpe
>     > Head of Biostatistics,? Applied Health Research Centre (AHRC)
>     > Li Ka Shing Knowledge Institute of St. Michael's
>     > Assistant Professor, Dalla Lana School of Public Health
>     > University of Toronto
>     > email: kevin.thorpe at utoronto.ca
>     <mailto:kevin.thorpe at utoronto.ca> Tel: 416.864.5776? Fax: 416.864.3016
>     >
>     >
>     > ?On 2020-01-21, 1:26 PM, "R-help on behalf of James
>     Spottiswoode" <r-help-bounces at r-project.org
>     <mailto:r-help-bounces at r-project.org> on behalf of
>     james at jsasoc.com <mailto:james at jsasoc.com>> wrote:
>     >
>     >? ? OSX is based on BSD UNIX so paths use the forward slash as
>     separator, e.g.
>     >
>     >? ? temps <-
>     read.table("c:/Users/DFP/Documents/ah/house/HouseTemps.txt",header=T,row.names=1)
>     >
>     >? ? Best James
>     >
>     >> On Jan 21, 2020, at 9:20 AM, David <parkhurs at indiana.edu
>     <mailto:parkhurs at indiana.edu>> wrote:
>     >>
>     >> I moved to a mac a few months ago after years in windows, and
>     I'm still learning basics.? I'm wanting to create a data frame
>     based on a text file called HouseTemps.txt. That's a file within
>     one called house which is within one called ah.? That may further
>     be in one called? Documents.? I tried various lines like:
>     >>
>     >> temps <-
>     read.table("c:\\Users\\DFP\\Documents\\ah\\house\\HouseTemps.txt",header=T,row.names=1)
>     >>
>     >> based on my windows DOS experience, but nothing I try works.?
>     So my question is, what do complete file names look like in a mac?
>     >>
>     >> I tried Apple support, but they couldn't help me with R.
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >>
>     >
>     >
>     >
>     >? ? ? ? [[alternative HTML version deleted]]
>     >
>     >? ? ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     >? ? PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     >? ? and provide commented, minimal, self-contained, reproducible
>     code.
>     >
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jan 22 18:19:25 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 22 Jan 2020 11:19:25 -0600
Subject: [R] how to save Rdata into .csv file
Message-ID: <CAF9-5jPT=zpiVi=gy6DSSZmwx_CWSG2+UmFCY_rQn8e=emSHuQ@mail.gmail.com>

Hello,

I have my normalized data matrix in file:normalizedDataMatrix_filtered.RData

how do I have that in .csv format?

Thanks
Ana


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jan 22 18:39:38 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 22 Jan 2020 17:39:38 +0000
Subject: [R] 
 Error with constrained curve fitting through specific points
In-Reply-To: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
References: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
Message-ID: <ea977a6d-da68-fb5e-0e66-6b5dcc587f04@sapo.pt>

Hello,

This seems to "work". It doesn't give errors nor warnings and the fitted 
line passes through the given points.


fit_result <- cobs(dat$x, dat$y,
                    constraint = "increase",
                    lambda = 0.1,
                    pointwise = con)

plot(y~x, dat)
pred <- predict(fit_result)
lines(pred[,1], pred[,2], col = "red")


Hope this helps,

Rui Barradas

?s 15:00 de 22/01/20, Tung Nguyen escreveu:
> Hello R-Help,
> 
> I'm trying to find the best fitting curve through a given set of points.
> The fitted curve must also pass through these points. I found an answer on
> Cross Validated which suggested to use the `cobs: Constrained B-Splines
> (Sparse Matrix Based)` package. However, I got an error while testing it
> with my sample data:
> 
> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)
> 
> *My question*: what caused this error and how can I fix it? Any suggestion
> is greatly appreciated. Thanks!
> 
> library(cobs)
> 
> dat <- data.frame(
>    x = c(1e-06,0.25,0.5,0.75,1,2,3,4,5,6),
>    y = c(1e-07,1.925,2.9625,3.469375,
>          3.875,4.5315,4.89,5.09375,5.216,5.46))
> dat
> #>          x         y#> 1  1.0e-06 0.0000001#> 2  2.5e-01
> 1.9250000#> 3  5.0e-01 2.9625000#> 4  7.5e-01 3.4693750#> 5  1.0e+00
> 3.8750000#> 6  2.0e+00 4.5315000#> 7  3.0e+00 4.8900000#> 8  4.0e+00
> 5.0937500#> 9  5.0e+00 5.2160000#> 10 6.0e+00 5.4600000
> # visual inspection
> plot(dat); lines(dat)
> 
> # define constrained points
> con <- matrix(
>    cbind(c(0,0,0,0,0,0,0,0,0,0),
>          c(1e-06,0.25,0.5,0.75,1,2,3, 4,5,6),
>          c(1e-07,1.925,2.9625,3.469375,
>            3.875,4.5315,4.89,5.09375,5.216, 5.46)),
>    ncol = 3, nrow = 10)
> # curve fitting
> fit_result <- cobs(dat$x, dat$y, pointwise = con)*#> qbsks2():
> #>  Performing general knot selection ...
> #> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)*
> 
> 
> Best regards,
> 
> -- Tung
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jan 22 20:16:38 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 22 Jan 2020 22:16:38 +0300
Subject: [R] how to save Rdata into .csv file
In-Reply-To: <CAF9-5jPT=zpiVi=gy6DSSZmwx_CWSG2+UmFCY_rQn8e=emSHuQ@mail.gmail.com>
References: <CAF9-5jPT=zpiVi=gy6DSSZmwx_CWSG2+UmFCY_rQn8e=emSHuQ@mail.gmail.com>
Message-ID: <20200122221638.601c6f54@Tarkus>

On Wed, 22 Jan 2020 11:19:25 -0600
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> I have my normalized data matrix in
> file:normalizedDataMatrix_filtered.RData
> 
> how do I have that in .csv format?

Have you tried using the function load() to load the saved data, then
write.csv() or write.csv2() to create the CSV file? What happened
instead? See also:
https://cran.r-project.org/doc/manuals/r-release/R-data.html#Export-to-text-files

-- 
Best regards,
Ivan


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jan 22 22:01:53 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 23 Jan 2020 10:01:53 +1300
Subject: [R] 
 Error with constrained curve fitting through specific points
In-Reply-To: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
References: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
Message-ID: <CAB8pepyhnV1MEmqP8uz-rNsA9aMg6d=JaHTZN=Xr0ZxUjNgX-A@mail.gmail.com>

This is probably the *simplest* approach:

> f = splinefun (dat$x, dat$y)

> #simple plot
> x = seq (0, 6,, 200)
> plot (dat)
> lines (x, f (x) )

If that's not what you want, perhaps you could expand on "constraints"
or "best fitting"...

Expanding on what Bert said, spline fitting and (regression style)
curve fitting are different.
While it is possible to constrain a regression curve to pass through
one or more points, there aren't many situations where one would want
to do that (constraining yhat=0 given x=0, perhaps?), and your example
suggests that you're wanting a spline...

B.


On Thu, Jan 23, 2020 at 4:01 AM Tung Nguyen <thanhtungmilan at gmail.com> wrote:
>
> Hello R-Help,
>
> I'm trying to find the best fitting curve through a given set of points.
> The fitted curve must also pass through these points. I found an answer on
> Cross Validated which suggested to use the `cobs: Constrained B-Splines
> (Sparse Matrix Based)` package. However, I got an error while testing it
> with my sample data:
>
> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)
>
> *My question*: what caused this error and how can I fix it? Any suggestion
> is greatly appreciated. Thanks!
>
> library(cobs)
>
> dat <- data.frame(
>   x = c(1e-06,0.25,0.5,0.75,1,2,3,4,5,6),
>   y = c(1e-07,1.925,2.9625,3.469375,
>         3.875,4.5315,4.89,5.09375,5.216,5.46))
> dat
> #>          x         y#> 1  1.0e-06 0.0000001#> 2  2.5e-01
> 1.9250000#> 3  5.0e-01 2.9625000#> 4  7.5e-01 3.4693750#> 5  1.0e+00
> 3.8750000#> 6  2.0e+00 4.5315000#> 7  3.0e+00 4.8900000#> 8  4.0e+00
> 5.0937500#> 9  5.0e+00 5.2160000#> 10 6.0e+00 5.4600000
> # visual inspection
> plot(dat); lines(dat)
>
> # define constrained points
> con <- matrix(
>   cbind(c(0,0,0,0,0,0,0,0,0,0),
>         c(1e-06,0.25,0.5,0.75,1,2,3, 4,5,6),
>         c(1e-07,1.925,2.9625,3.469375,
>           3.875,4.5315,4.89,5.09375,5.216, 5.46)),
>   ncol = 3, nrow = 10)
> # curve fitting
> fit_result <- cobs(dat$x, dat$y, pointwise = con)*#> qbsks2():
> #>  Performing general knot selection ...
> #> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)*
>
>
> Best regards,
>
> -- Tung
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jan 22 22:07:04 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 23 Jan 2020 10:07:04 +1300
Subject: [R] 
 Error with constrained curve fitting through specific points
In-Reply-To: <CAB8pepyhnV1MEmqP8uz-rNsA9aMg6d=JaHTZN=Xr0ZxUjNgX-A@mail.gmail.com>
References: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
 <CAB8pepyhnV1MEmqP8uz-rNsA9aMg6d=JaHTZN=Xr0ZxUjNgX-A@mail.gmail.com>
Message-ID: <CAB8pepyCh2ophqv3SacSLSb1sEpH2wH8E1oZoBdkUuaGt41dsg@mail.gmail.com>

Sorry, I should have said "Spline Interpolation" (not spline fitting).


From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jan 23 10:24:11 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 23 Jan 2020 10:24:11 +0100
Subject: [R] Convert Long DOY time format to yyyymmdd hh format
Message-ID: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>

Dear Experts,
I have a data spanning 56 years from 1963 to 2018.
The datetime format is in DOY hour:
1963 335 0
1963 335 1
1963 335 2
1963 335 3
1963 335 4
1963 335 5
1963 335 6
1963 335 7
1963 335 8
1963 335 9
1996 202 20
1996 202 21
1996 202 22
1996 202 23
1996 203 0
1996 203 1
1996 203 2
1996 203 3
2018 365 20
2018 365 21
2018 365 22
2018 365 23
When I used:
as.Date(335,origin="1963-01-01"), for the first row, I got:
[1] "1963-12-02"
This is the format I want, though it is not yet complete. Time is missing.

Again, I can't be doing this one after the other. I guess you have a
better way of handling this. I have spent some time trying to get it
right but I am really stuck. I would be most glad if you could spare
your busy time to help me again.

Thank you very much for your usual kind assistance.

Best regards
Ogbos


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Jan 23 10:35:18 2020
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 23 Jan 2020 10:35:18 +0100
Subject: [R] Convert Long DOY time format to yyyymmdd hh format
In-Reply-To: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
Message-ID: <20200123103518.Horde.WAMpFx1dOsFnqj7HFTKLLfq@webmail.your-server.de>


Quoting Ogbos Okike <giftedlife2014 at gmail.com>:

> Dear Experts,
> I have a data spanning 56 years from 1963 to 2018.
> The datetime format is in DOY hour:
> 1963 335 0
> 1963 335 1
> 1963 335 2
> 1963 335 3
> 1963 335 4
> 1963 335 5
> 1963 335 6
> 1963 335 7
> 1963 335 8
> 1963 335 9
> 1996 202 20
> 1996 202 21
> 1996 202 22
> 1996 202 23
> 1996 203 0
> 1996 203 1
> 1996 203 2
> 1996 203 3
> 2018 365 20
> 2018 365 21
> 2018 365 22
> 2018 365 23
> When I used:
> as.Date(335,origin="1963-01-01"), for the first row, I got:
> [1] "1963-12-02"
> This is the format I want, though it is not yet complete. Time is missing.
>
> Again, I can't be doing this one after the other. I guess you have a
> better way of handling this. I have spent some time trying to get it
> right but I am really stuck. I would be most glad if you could spare
> your busy time to help me again.
>
> Thank you very much for your usual kind assistance.
>
> Best regards
> Ogbos
>

Perhaps something like this:

read.table(text="
1963 335 0
1963 335 1
1963 335 2
1963 335 3
1963 335 4
1963 335 5
1963 335 6
1963 335 7
1963 335 8
1963 335 9
1996 202 20
1996 202 21
1996 202 22
1996 202 23
1996 203 0
1996 203 1
1996 203 2
1996 203 3
2018 365 20
2018 365 21
2018 365 22
2018 365 23
", header = FALSE, sep = " ") -> data

as.POSIXct(paste(as.Date(paste0(data[[1]], "-1-1")) + data[[2]] - 1,  
data[[3]]),
            format = "%Y-%m-%d %H")

You might want to specify a different timezone, and also check for  
"off-by-one" error
when it comes to day of year.

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From drj|m|emon @end|ng |rom gm@||@com  Thu Jan 23 10:42:37 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 23 Jan 2020 20:42:37 +1100
Subject: [R] Convert Long DOY time format to yyyymmdd hh format
In-Reply-To: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
References: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
Message-ID: <CA+8X3fW43JPDHBX6jA4kDA0k5THXgHQ+6QtHrTV11Bo52krdhw@mail.gmail.com>

Hi Ogbos,
Try this:

oodates<-read.table(text="1963 335 0
1963 335 1
1963 335 2
1963 335 3
1963 335 4
1963 335 5
1963 335 6
1963 335 7
1963 335 8
1963 335 9
1996 202 20
1996 202 21
1996 202 22
1996 202 23
1996 203 0
1996 203 1
1996 203 2
1996 203 3
2018 365 20
2018 365 21
2018 365 22
2018 365 23")
oodates$Pdate<-strptime(paste(oodates[,1],oodates[,2],oodates[,3]),
 format="%Y %j %H")

Jim

On Thu, Jan 23, 2020 at 8:24 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Experts,
> I have a data spanning 56 years from 1963 to 2018.
> The datetime format is in DOY hour:
> 1963 335 0
> 1963 335 1
> 1963 335 2
> 1963 335 3
> 1963 335 4
> 1963 335 5
> 1963 335 6
> 1963 335 7
> 1963 335 8
> 1963 335 9
> 1996 202 20
> 1996 202 21
> 1996 202 22
> 1996 202 23
> 1996 203 0
> 1996 203 1
> 1996 203 2
> 1996 203 3
> 2018 365 20
> 2018 365 21
> 2018 365 22
> 2018 365 23
> When I used:
> as.Date(335,origin="1963-01-01"), for the first row, I got:
> [1] "1963-12-02"
> This is the format I want, though it is not yet complete. Time is missing.
>
> Again, I can't be doing this one after the other. I guess you have a
> better way of handling this. I have spent some time trying to get it
> right but I am really stuck. I would be most glad if you could spare
> your busy time to help me again.
>
> Thank you very much for your usual kind assistance.
>
> Best regards
> Ogbos
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jan 23 10:47:15 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 23 Jan 2020 09:47:15 +0000
Subject: [R] Convert Long DOY time format to yyyymmdd hh format
In-Reply-To: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
References: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
Message-ID: <331c18f4977b483da461e83a05d9126e@SRVEXCHCM1302.precheza.cz>

Hi

as.Date converts to dates (without hours), which is clearly stated in the
first line of documentation.

If you want include hour you should use ?strptime
Something like

> strptime("1963 335 1", format="%Y %j %H")
[1] "1963-12-01 01:00:00 CET"

You definitely does not need to do it one by one, but exact way depends on
how does the object look like in R.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> Sent: Thursday, January 23, 2020 10:24 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] Convert Long DOY time format to yyyymmdd hh format
> 
> Dear Experts,
> I have a data spanning 56 years from 1963 to 2018.
> The datetime format is in DOY hour:
> 1963 335 0"
> 1963 335 1
> 1963 335 2
> 1963 335 3
> 1963 335 4
> 1963 335 5
> 1963 335 6
> 1963 335 7
> 1963 335 8
> 1963 335 9
> 1996 202 20
> 1996 202 21
> 1996 202 22
> 1996 202 23
> 1996 203 0
> 1996 203 1
> 1996 203 2
> 1996 203 3
> 2018 365 20
> 2018 365 21
> 2018 365 22
> 2018 365 23
> When I used:
> as.Date(335,origin="1963-01-01"), for the first row, I got:
> [1] "1963-12-02"
> This is the format I want, though it is not yet complete. Time is missing.
> 
> Again, I can't be doing this one after the other. I guess you have a
better way
> of handling this. I have spent some time trying to get it right but I am
really
> stuck. I would be most glad if you could spare your busy time to help me
> again.
> 
> Thank you very much for your usual kind assistance.
> 
> Best regards
> Ogbos
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pd@|gd @end|ng |rom gm@||@com  Thu Jan 23 10:56:57 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 23 Jan 2020 10:56:57 +0100
Subject: [R] Convert Long DOY time format to yyyymmdd hh format
In-Reply-To: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
References: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
Message-ID: <6B58FEA3-6D68-40C9-B52C-DD4563BE859D@gmail.com>

Here's an idea:

> as.POSIXct(paste0("1963","-1-1"))+as.difftime(335,units="days") + as.difftime(3, units="hours")
[1] "1963-12-02 03:00:00 CET"

However, 2 caveats

(a) I think you need to subtract 1 from the DOY (1 should be Jan 1, right?)
(b) Beware Daylight Savings time:

> as.POSIXct(paste0("2019","-1-1"))+as.difftime(160,units="days") + as.difftime(3, units="hours")
[1] "2019-06-10 04:00:00 CEST"

This can be worked around as follows:

> tt <- as.POSIXct(paste0("2019","-1-1"))+as.difftime(160,units="days")
> ttl <- as.POSIXlt(tt)
> ttl$hour=0
> ttl + as.difftime(3, units="hours")
[1] "2019-06-10 03:00:00 CEST"

ISOdate() and ISOdatetime() can also be used, again beware of time zones and DST. Also, ISOdate gives 12:00 GMT, whereas the POSIX stuff gives 0:00.

-pd

> On 23 Jan 2020, at 10:24 , Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear Experts,
> I have a data spanning 56 years from 1963 to 2018.
> The datetime format is in DOY hour:
> 1963 335 0
> 1963 335 1
> 1963 335 2
> 1963 335 3
> 1963 335 4
> 1963 335 5
> 1963 335 6
> 1963 335 7
> 1963 335 8
> 1963 335 9
> 1996 202 20
> 1996 202 21
> 1996 202 22
> 1996 202 23
> 1996 203 0
> 1996 203 1
> 1996 203 2
> 1996 203 3
> 2018 365 20
> 2018 365 21
> 2018 365 22
> 2018 365 23
> When I used:
> as.Date(335,origin="1963-01-01"), for the first row, I got:
> [1] "1963-12-02"
> This is the format I want, though it is not yet complete. Time is missing.
> 
> Again, I can't be doing this one after the other. I guess you have a
> better way of handling this. I have spent some time trying to get it
> right but I am really stuck. I would be most glad if you could spare
> your busy time to help me again.
> 
> Thank you very much for your usual kind assistance.
> 
> Best regards
> Ogbos
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Thu Jan 23 11:01:13 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 23 Jan 2020 11:01:13 +0100
Subject: [R] Convert Long DOY time format to yyyymmdd hh format
In-Reply-To: <6B58FEA3-6D68-40C9-B52C-DD4563BE859D@gmail.com>
References: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
 <6B58FEA3-6D68-40C9-B52C-DD4563BE859D@gmail.com>
Message-ID: <8789DA7E-A093-46DA-B65A-B616B9AC5B6E@gmail.com>

Jim's (and Petr's) solution wins....

-pd

> On 23 Jan 2020, at 10:56 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Here's an idea:
> 
>> as.POSIXct(paste0("1963","-1-1"))+as.difftime(335,units="days") + as.difftime(3, units="hours")
> [1] "1963-12-02 03:00:00 CET"
> 
> However, 2 caveats
> 
> (a) I think you need to subtract 1 from the DOY (1 should be Jan 1, right?)
> (b) Beware Daylight Savings time:
> 
>> as.POSIXct(paste0("2019","-1-1"))+as.difftime(160,units="days") + as.difftime(3, units="hours")
> [1] "2019-06-10 04:00:00 CEST"
> 
> This can be worked around as follows:
> 
>> tt <- as.POSIXct(paste0("2019","-1-1"))+as.difftime(160,units="days")
>> ttl <- as.POSIXlt(tt)
>> ttl$hour=0
>> ttl + as.difftime(3, units="hours")
> [1] "2019-06-10 03:00:00 CEST"
> 
> ISOdate() and ISOdatetime() can also be used, again beware of time zones and DST. Also, ISOdate gives 12:00 GMT, whereas the POSIX stuff gives 0:00.
> 
> -pd
> 
>> On 23 Jan 2020, at 10:24 , Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>> 
>> Dear Experts,
>> I have a data spanning 56 years from 1963 to 2018.
>> The datetime format is in DOY hour:
>> 1963 335 0
>> 1963 335 1
>> 1963 335 2
>> 1963 335 3
>> 1963 335 4
>> 1963 335 5
>> 1963 335 6
>> 1963 335 7
>> 1963 335 8
>> 1963 335 9
>> 1996 202 20
>> 1996 202 21
>> 1996 202 22
>> 1996 202 23
>> 1996 203 0
>> 1996 203 1
>> 1996 203 2
>> 1996 203 3
>> 2018 365 20
>> 2018 365 21
>> 2018 365 22
>> 2018 365 23
>> When I used:
>> as.Date(335,origin="1963-01-01"), for the first row, I got:
>> [1] "1963-12-02"
>> This is the format I want, though it is not yet complete. Time is missing.
>> 
>> Again, I can't be doing this one after the other. I guess you have a
>> better way of handling this. I have spent some time trying to get it
>> right but I am really stuck. I would be most glad if you could spare
>> your busy time to help me again.
>> 
>> Thank you very much for your usual kind assistance.
>> 
>> Best regards
>> Ogbos
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jan 23 11:14:55 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 23 Jan 2020 11:14:55 +0100
Subject: [R] Convert Long DOY time format to yyyymmdd hh format: Problem
 Fixed
In-Reply-To: <CA+8X3fW43JPDHBX6jA4kDA0k5THXgHQ+6QtHrTV11Bo52krdhw@mail.gmail.com>
References: <CAC8ss32uS52adh+yfyGex_vV1VMX-GazSoKw-CmVZNzZM3SnBw@mail.gmail.com>
 <CA+8X3fW43JPDHBX6jA4kDA0k5THXgHQ+6QtHrTV11Bo52krdhw@mail.gmail.com>
Message-ID: <CAC8ss31JtCJPdkEVRA7kRLO7JDWcHuSueDESTmCJz8kkPs5V-g@mail.gmail.com>

Dear Gurus,
I am so happy to thank you all for your great help!!!
Jim's code first did it.
Thanks again to everyone.
Warmest regards
Ogbos
On Thu, Jan 23, 2020 at 10:42 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ogbos,
> Try this:
>
> oodates<-read.table(text="1963 335 0
> 1963 335 1
> 1963 335 2
> 1963 335 3
> 1963 335 4
> 1963 335 5
> 1963 335 6
> 1963 335 7
> 1963 335 8
> 1963 335 9
> 1996 202 20
> 1996 202 21
> 1996 202 22
> 1996 202 23
> 1996 203 0
> 1996 203 1
> 1996 203 2
> 1996 203 3
> 2018 365 20
> 2018 365 21
> 2018 365 22
> 2018 365 23")
> oodates$Pdate<-strptime(paste(oodates[,1],oodates[,2],oodates[,3]),
>  format="%Y %j %H")
>
> Jim
>
> On Thu, Jan 23, 2020 at 8:24 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> >
> > Dear Experts,
> > I have a data spanning 56 years from 1963 to 2018.
> > The datetime format is in DOY hour:
> > 1963 335 0
> > 1963 335 1
> > 1963 335 2
> > 1963 335 3
> > 1963 335 4
> > 1963 335 5
> > 1963 335 6
> > 1963 335 7
> > 1963 335 8
> > 1963 335 9
> > 1996 202 20
> > 1996 202 21
> > 1996 202 22
> > 1996 202 23
> > 1996 203 0
> > 1996 203 1
> > 1996 203 2
> > 1996 203 3
> > 2018 365 20
> > 2018 365 21
> > 2018 365 22
> > 2018 365 23
> > When I used:
> > as.Date(335,origin="1963-01-01"), for the first row, I got:
> > [1] "1963-12-02"
> > This is the format I want, though it is not yet complete. Time is missing.
> >
> > Again, I can't be doing this one after the other. I guess you have a
> > better way of handling this. I have spent some time trying to get it
> > right but I am really stuck. I would be most glad if you could spare
> > your busy time to help me again.
> >
> > Thank you very much for your usual kind assistance.
> >
> > Best regards
> > Ogbos
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From th@nhtungm||@n @end|ng |rom gm@||@com  Thu Jan 23 15:35:55 2020
From: th@nhtungm||@n @end|ng |rom gm@||@com (Tung Nguyen)
Date: Thu, 23 Jan 2020 06:35:55 -0800
Subject: [R] 
 Error with constrained curve fitting through specific points
In-Reply-To: <ea977a6d-da68-fb5e-0e66-6b5dcc587f04@sapo.pt>
References: <CAE0B8CK_m1QBoe2-MkpJToFE5tn2Ue3BZhLkb26MU0oqtaox3Q@mail.gmail.com>
 <ea977a6d-da68-fb5e-0e66-6b5dcc587f04@sapo.pt>
Message-ID: <CAE0B8CJuLnDgYfBqhm1WOwJmNKtEemX22gi_xrGXXQQM5UBdMw@mail.gmail.com>

Thanks Rui and everyone for your help!

Using ` constraint = "increase"` and `lambda = 0.1` did it.
If we ignore the first point, `lambda = -1` option is also possible. `cobs`
will automatically choose a lambda value

	plot(fit_result)
	summary(fit_result)
	# COBS smoothing spline (degree = 2) from call:
	#   cobs(x = dat$x, y = dat$y, constraint = "increase", lambda = -1,
   pointwise = con)
	# {tau=0.5}-quantile;  dimensionality of fit: 29 from {29}
	# x$knots[1:9]: -6.0e-06,  2.5e-01,  5.0e-01, ... ,  6.0e+00
	# lambda = 1.4494, selected via SIC, out of 25 ones.
	# with 10 pointwise constraints
	# coef[1:11]: -6.1866e-05,  1.1065e+00,  2.7435e+00,  3.1815e+00,
3.7572e+00, ... ,  1.9183e+01
	# R^2 = 100% ;  empirical tau (over all): 5/10 = 0.5 (target tau= 0.5)


Best,

-- Tung



On Wed, Jan 22, 2020 at 9:39 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> This seems to "work". It doesn't give errors nor warnings and the fitted
> line passes through the given points.
>
>
> fit_result <- cobs(dat$x, dat$y,
>                     constraint = "increase",
>                     lambda = 0.1,
>                     pointwise = con)
>
> plot(y~x, dat)
> pred <- predict(fit_result)
> lines(pred[,1], pred[,2], col = "red")
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 15:00 de 22/01/20, Tung Nguyen escreveu:
> > Hello R-Help,
> >
> > I'm trying to find the best fitting curve through a given set of points.
> > The fitted curve must also pass through these points. I found an answer
> on
> > Cross Validated which suggested to use the `cobs: Constrained B-Splines
> > (Sparse Matrix Based)` package. However, I got an error while testing it
> > with my sample data:
> >
> > Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg 2)
> >
> > *My question*: what caused this error and how can I fix it? Any
> suggestion
> > is greatly appreciated. Thanks!
> >
> > library(cobs)
> >
> > dat <- data.frame(
> >    x = c(1e-06,0.25,0.5,0.75,1,2,3,4,5,6),
> >    y = c(1e-07,1.925,2.9625,3.469375,
> >          3.875,4.5315,4.89,5.09375,5.216,5.46))
> > dat
> > #>          x         y#> 1  1.0e-06 0.0000001#> 2  2.5e-01
> > 1.9250000#> 3  5.0e-01 2.9625000#> 4  7.5e-01 3.4693750#> 5  1.0e+00
> > 3.8750000#> 6  2.0e+00 4.5315000#> 7  3.0e+00 4.8900000#> 8  4.0e+00
> > 5.0937500#> 9  5.0e+00 5.2160000#> 10 6.0e+00 5.4600000
> > # visual inspection
> > plot(dat); lines(dat)
> >
> > # define constrained points
> > con <- matrix(
> >    cbind(c(0,0,0,0,0,0,0,0,0,0),
> >          c(1e-06,0.25,0.5,0.75,1,2,3, 4,5,6),
> >          c(1e-07,1.925,2.9625,3.469375,
> >            3.875,4.5315,4.89,5.09375,5.216, 5.46)),
> >    ncol = 3, nrow = 10)
> > # curve fitting
> > fit_result <- cobs(dat$x, dat$y, pointwise = con)*#> qbsks2():
> > #>  Performing general knot selection ...
> > #> Error in x %*% coefficients: NA/NaN/Inf in foreign function call (arg
> 2)*
> >
> >
> > Best regards,
> >
> > -- Tung
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan 23 21:12:38 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 23 Jan 2020 14:12:38 -0600
Subject: [R] how to create a plot of permutation of 30 random values and
 show proportion of values
Message-ID: <CAF9-5jPH7Mw203KYQS2Vuqko4XyVa9yorMsoVf=bG+uGTTL4MA@mail.gmail.com>

Hello,

I have a data frame which looks like this:

> head(a,20)
             rs   pvalue
 1: rs185642176 0.267407
 2: rs184120752 0.787681
 3:  rs10904045 0.508162
 4:  rs35849539 0.875910
 5: rs141633513 0.787759
 6:   rs4468273 0.542171
 7:   rs4567378 0.539484
 8:   rs7084251 0.126445
 9: rs181605000 0.787838
10:  rs12255619 0.192719
11: rs140367257 0.788008
12:  rs10904178 0.969814
13:   rs7918960 0.436341
14:  rs61688896 0.526256
15: rs151283848 0.787284
16: rs140174295 0.989107
17: rs145945079 0.787015
18:   rs4881370 0.455089
19: rs183895035 0.787015
20: rs181749526 0.787015
> dim(a)
[1] 3859763       2

What I would like to do is to take random subsets of 30 of those rs
throughout the dataframe and find out which subsets of those generated
have FDR value <0.05

FDR I would calculate I guess with:
a$fdr=p.adjust(a$pvalue,method="BH")

but I also guess I would be calculating only FDR for a particular
subset of 30 randomly chosen rs, not for the whole data set.

The result I would like to present like in the attached plot. The
x-axis say proportion of SNPs and in my case SNP is equivalent to rs

Can you please help with this, I really don't have idea how to go about this.

Thanks

From drj|m|emon @end|ng |rom gm@||@com  Fri Jan 24 03:06:38 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 24 Jan 2020 13:06:38 +1100
Subject: [R] how to create a plot of permutation of 30 random values and
 show proportion of values
In-Reply-To: <CAF9-5jPH7Mw203KYQS2Vuqko4XyVa9yorMsoVf=bG+uGTTL4MA@mail.gmail.com>
References: <CAF9-5jPH7Mw203KYQS2Vuqko4XyVa9yorMsoVf=bG+uGTTL4MA@mail.gmail.com>
Message-ID: <CA+8X3fVNRN8t+4rH2a6Ye9N-2g3iNfiyTHOKF0J_SJufL1axTw@mail.gmail.com>

Hi Ana,
You seem to be working on an identification or classification problem.
Your sample plot didn't come through, perhaps try converting it to a
PDF or PNG.
I may be missing something, but I can't see how randomly selecting 30
values from almost 4 million is going to mean anything in terms of
statistical significance. I hope you will pardon me for saying that it
looks like a "p-trawl". It is easy to select cases where the p-value
is less than 0.05:

a[a$pvalue < 0.05,]

Maybe what you want to do is display this subset of your data as
candidates for a match among the very large number of non-matches.
Let's do a bit of damage to your sample data and add the proportions:

a<-read.table(text="rs pvalue pSNP
 rs185642176 0.0267407 0.6
 rs184120752 0.0787681 0.3
 rs10904045 0.0508162 0.4
 rs35849539 0.0875910 0.2
 rs141633513 0.0787759 0.2
 rs4468273 0.0542171 0.4
 rs4567378 0.0539484 0.4
 rs7084251 0.0126445 0.7
 rs181605000 0.0787838 0.35
 rs12255619 0.0192719 0.61
 rs140367257 0.0788008 0.25
 rs10904178 0.0969814 0.16
 rs7918960 0.0436341 0.45
 rs61688896 0.0526256 0.39
 rs151283848 0.0787284 0.34
 rs140174295 0.0989107 0.11
 rs145945079 0.0787015 0.23
 rs4881370 0.0455089 0.51
 rs183895035 0.0787015 0.22
 rs181749526 0.0787015 0.22",
 header=TRUE,stringsAsFactors=FALSE)
alt05<-a[a$pvalue < 0.05,]
library(plotrix)
segmat<-matrix(c(alt05$pSNP,alt05$pSNP-0.1,alt05$pSNP+0.1,rep(1,5)),
 nrow=4,byrow=TRUE)
rownames(segmat)<-c("prop","lower","upper","N")
centipede.plot(segmat,mar=c(4,6,3,4),
 main="Proportion of SNPs",
 left.labels=alt05$rs,right.labels=rep("",5))

This is probably not what you want, but it is a start.

Jim

On Fri, Jan 24, 2020 at 7:08 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a data frame which looks like this:
>
> > head(a,20)
>              rs   pvalue
>  1: rs185642176 0.267407
>  2: rs184120752 0.787681
>  3:  rs10904045 0.508162
>  4:  rs35849539 0.875910
>  5: rs141633513 0.787759
>  6:   rs4468273 0.542171
>  7:   rs4567378 0.539484
>  8:   rs7084251 0.126445
>  9: rs181605000 0.787838
> 10:  rs12255619 0.192719
> 11: rs140367257 0.788008
> 12:  rs10904178 0.969814
> 13:   rs7918960 0.436341
> 14:  rs61688896 0.526256
> 15: rs151283848 0.787284
> 16: rs140174295 0.989107
> 17: rs145945079 0.787015
> 18:   rs4881370 0.455089
> 19: rs183895035 0.787015
> 20: rs181749526 0.787015
> > dim(a)
> [1] 3859763       2
>
> What I would like to do is to take random subsets of 30 of those rs
> throughout the dataframe and find out which subsets of those generated
> have FDR value <0.05
>
> FDR I would calculate I guess with:
> a$fdr=p.adjust(a$pvalue,method="BH")
>
> but I also guess I would be calculating only FDR for a particular
> subset of 30 randomly chosen rs, not for the whole data set.
>
> The result I would like to present like in the attached plot. The
> x-axis say proportion of SNPs and in my case SNP is equivalent to rs
>
> Can you please help with this, I really don't have idea how to go about this.
>
> Thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Jan 24 05:05:12 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 23 Jan 2020 22:05:12 -0600
Subject: [R] how to create a plot of permutation of 30 random values and
 show proportion of values
In-Reply-To: <CA+8X3fVNRN8t+4rH2a6Ye9N-2g3iNfiyTHOKF0J_SJufL1axTw@mail.gmail.com>
References: <CAF9-5jPH7Mw203KYQS2Vuqko4XyVa9yorMsoVf=bG+uGTTL4MA@mail.gmail.com>
 <CA+8X3fVNRN8t+4rH2a6Ye9N-2g3iNfiyTHOKF0J_SJufL1axTw@mail.gmail.com>
Message-ID: <CAF9-5jNd3aQg1RZcm6=Rw-6zoJHm5MOY9AJrpV94zBAhD4rtpw@mail.gmail.com>

Hi Jim,

thanks for getting back to me.
Can you please confirm if you can see this plot in attach?


Thanks
Ana

On Thu, Jan 23, 2020 at 8:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> You seem to be working on an identification or classification problem.
> Your sample plot didn't come through, perhaps try converting it to a
> PDF or PNG.
> I may be missing something, but I can't see how randomly selecting 30
> values from almost 4 million is going to mean anything in terms of
> statistical significance. I hope you will pardon me for saying that it
> looks like a "p-trawl". It is easy to select cases where the p-value
> is less than 0.05:
>
> a[a$pvalue < 0.05,]
>
> Maybe what you want to do is display this subset of your data as
> candidates for a match among the very large number of non-matches.
> Let's do a bit of damage to your sample data and add the proportions:
>
> a<-read.table(text="rs pvalue pSNP
>  rs185642176 0.0267407 0.6
>  rs184120752 0.0787681 0.3
>  rs10904045 0.0508162 0.4
>  rs35849539 0.0875910 0.2
>  rs141633513 0.0787759 0.2
>  rs4468273 0.0542171 0.4
>  rs4567378 0.0539484 0.4
>  rs7084251 0.0126445 0.7
>  rs181605000 0.0787838 0.35
>  rs12255619 0.0192719 0.61
>  rs140367257 0.0788008 0.25
>  rs10904178 0.0969814 0.16
>  rs7918960 0.0436341 0.45
>  rs61688896 0.0526256 0.39
>  rs151283848 0.0787284 0.34
>  rs140174295 0.0989107 0.11
>  rs145945079 0.0787015 0.23
>  rs4881370 0.0455089 0.51
>  rs183895035 0.0787015 0.22
>  rs181749526 0.0787015 0.22",
>  header=TRUE,stringsAsFactors=FALSE)
> alt05<-a[a$pvalue < 0.05,]
> library(plotrix)
> segmat<-matrix(c(alt05$pSNP,alt05$pSNP-0.1,alt05$pSNP+0.1,rep(1,5)),
>  nrow=4,byrow=TRUE)
> rownames(segmat)<-c("prop","lower","upper","N")
> centipede.plot(segmat,mar=c(4,6,3,4),
>  main="Proportion of SNPs",
>  left.labels=alt05$rs,right.labels=rep("",5))
>
> This is probably not what you want, but it is a start.
>
> Jim
>
> On Fri, Jan 24, 2020 at 7:08 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have a data frame which looks like this:
> >
> > > head(a,20)
> >              rs   pvalue
> >  1: rs185642176 0.267407
> >  2: rs184120752 0.787681
> >  3:  rs10904045 0.508162
> >  4:  rs35849539 0.875910
> >  5: rs141633513 0.787759
> >  6:   rs4468273 0.542171
> >  7:   rs4567378 0.539484
> >  8:   rs7084251 0.126445
> >  9: rs181605000 0.787838
> > 10:  rs12255619 0.192719
> > 11: rs140367257 0.788008
> > 12:  rs10904178 0.969814
> > 13:   rs7918960 0.436341
> > 14:  rs61688896 0.526256
> > 15: rs151283848 0.787284
> > 16: rs140174295 0.989107
> > 17: rs145945079 0.787015
> > 18:   rs4881370 0.455089
> > 19: rs183895035 0.787015
> > 20: rs181749526 0.787015
> > > dim(a)
> > [1] 3859763       2
> >
> > What I would like to do is to take random subsets of 30 of those rs
> > throughout the dataframe and find out which subsets of those generated
> > have FDR value <0.05
> >
> > FDR I would calculate I guess with:
> > a$fdr=p.adjust(a$pvalue,method="BH")
> >
> > but I also guess I would be calculating only FDR for a particular
> > subset of 30 randomly chosen rs, not for the whole data set.
> >
> > The result I would like to present like in the attached plot. The
> > x-axis say proportion of SNPs and in my case SNP is equivalent to rs
> >
> > Can you please help with this, I really don't have idea how to go about this.
> >
> > Thanks
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: rsz_screen_shot_2020-01-23_at_100147_pm.png
Type: image/png
Size: 74890 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200123/57224a4e/attachment.png>

From drj|m|emon @end|ng |rom gm@||@com  Fri Jan 24 05:29:28 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 24 Jan 2020 15:29:28 +1100
Subject: [R] how to create a plot of permutation of 30 random values and
 show proportion of values
In-Reply-To: <CAF9-5jNd3aQg1RZcm6=Rw-6zoJHm5MOY9AJrpV94zBAhD4rtpw@mail.gmail.com>
References: <CAF9-5jPH7Mw203KYQS2Vuqko4XyVa9yorMsoVf=bG+uGTTL4MA@mail.gmail.com>
 <CA+8X3fVNRN8t+4rH2a6Ye9N-2g3iNfiyTHOKF0J_SJufL1axTw@mail.gmail.com>
 <CAF9-5jNd3aQg1RZcm6=Rw-6zoJHm5MOY9AJrpV94zBAhD4rtpw@mail.gmail.com>
Message-ID: <CA+8X3fV9iAmYnbSOCNKxSYrHogiLvA8dqAmBPdaWsOgF6JRo4g@mail.gmail.com>

Hi Ana,
Yes, this makes more sense. A bar plot of the number of simulations
performed by the proportion of SNPs with q-value < 0.05. I would
expect the axes to be swapped, but my notion that you would want to
know the proportion (DV) for a given number of simulations (IV) may
well be wrong.

Jim

On Fri, Jan 24, 2020 at 3:00 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim,
>
> thanks for getting back to me.
> Can you please confirm if you can see this plot in attach?
>
>
> Thanks
> Ana
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jan 23 21:10:12 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 23 Jan 2020 14:10:12 -0600
Subject: [R] how to create a plot of permutation of 30 random values and
 show proportion of values
Message-ID: <CAF9-5jNNCnwYRp2LW+zK-D+3wiQ-ZRUJzS+ms6HJH884QZFRMw@mail.gmail.com>

Hello,

I have a data frame which looks like this:

> head(a,20)
             rs   pvalue
 1: rs185642176 0.267407
 2: rs184120752 0.787681
 3:  rs10904045 0.508162
 4:  rs35849539 0.875910
 5: rs141633513 0.787759
 6:   rs4468273 0.542171
 7:   rs4567378 0.539484
 8:   rs7084251 0.126445
 9: rs181605000 0.787838
10:  rs12255619 0.192719
11: rs140367257 0.788008
12:  rs10904178 0.969814
13:   rs7918960 0.436341
14:  rs61688896 0.526256
15: rs151283848 0.787284
16: rs140174295 0.989107
17: rs145945079 0.787015
18:   rs4881370 0.455089
19: rs183895035 0.787015
20: rs181749526 0.787015
> dim(a)
[1] 3859763       2

What I would like to do is to take random subsets of 30 of those rs
throughout the dataframe and find out which subsets of those generated
have FDR value <0.05

FDR I would calculate I guess with:
a$fdr=p.adjust(a$pvalue,method="BH")

but I also guess I would be calculating only FDR for a particular
subset of 30 randomly chosen rs, not for the whole data set.

The result I would like to present like in the attached plot. The
x-axis say proportion of SNPs and in my case SNP is equivalent to rs

Can you please help with this, I really don't have idea how to go about this.

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-01-23 at 2.09.26 PM.png
Type: image/png
Size: 352485 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200123/9648e05d/attachment.png>

From chr|@@@te|nm@n @end|ng |rom jhu@edu  Thu Jan 23 21:19:56 2020
From: chr|@@@te|nm@n @end|ng |rom jhu@edu (Christopher Steinman)
Date: Thu, 23 Jan 2020 20:19:56 +0000
Subject: [R] RSA package adjust alpha for a1-a4 confidence intervals
Message-ID: <MN2PR01MB5359A80CFD12A909D45B207F9D0F0@MN2PR01MB5359.prod.exchangelabs.com>

Hi, I'm not experienced with R at all.  I'm using some canned code to produce RSA models in the RSA package.  I'd like to be able to adjust the alpha for the a1-a4 confidence intervals.

This doesn't appear to be a native option for the RSA package, unless I'm missing something because I'm a novice.  Is there an easy way to do this?

Any advice would be appreciated, thanks for your time in advance!

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jan 24 12:12:35 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 24 Jan 2020 19:12:35 +0800
Subject: [R] how to create a plot of permutation of 30 random values and
 show proportion of values
In-Reply-To: <CAF9-5jNNCnwYRp2LW+zK-D+3wiQ-ZRUJzS+ms6HJH884QZFRMw@mail.gmail.com>
References: <CAF9-5jNNCnwYRp2LW+zK-D+3wiQ-ZRUJzS+ms6HJH884QZFRMw@mail.gmail.com>
Message-ID: <94492DD7-ED12-4BF8-8DD2-F8FED2F253DD@comcast.net>

It appears you are not trying to do this within individual SNPs. If I?m wrong then this would need to be done within a grouping procedure. And I?m not at all confident that you can estimate FDRs in this manner, but if your strategy is valid, then some variant of this untested code:

replicate ( 50, my.50.vals = { p.adjust(dfrm[ sample(1:3859763, 30), 2], method =?BH?)})

It would be better in the future to make a small example that supports testing. 

David. 
Sent from my iPhone

> On Jan 24, 2020, at 4:10 AM, Ana Marija <sokovic.anamarija at gmail.com> wrote:
> 
> Hello,
> 
> I have a data frame which looks like this:
> 
>> head(a,20)
>             rs   pvalue
> 1: rs185642176 0.267407
> 2: rs184120752 0.787681
> 3:  rs10904045 0.508162
> 4:  rs35849539 0.875910
> 5: rs141633513 0.787759
> 6:   rs4468273 0.542171
> 7:   rs4567378 0.539484
> 8:   rs7084251 0.126445
> 9: rs181605000 0.787838
> 10:  rs12255619 0.192719
> 11: rs140367257 0.788008
> 12:  rs10904178 0.969814
> 13:   rs7918960 0.436341
> 14:  rs61688896 0.526256
> 15: rs151283848 0.787284
> 16: rs140174295 0.989107
> 17: rs145945079 0.787015
> 18:   rs4881370 0.455089
> 19: rs183895035 0.787015
> 20: rs181749526 0.787015
>> dim(a)
> [1] 3859763       2
> 
> What I would like to do is to take random subsets of 30 of those rs
> throughout the dataframe and find out which subsets of those generated
> have FDR value <0.05
> 
> FDR I would calculate I guess with:
> a$fdr=p.adjust(a$pvalue,method="BH")
> 
> but I also guess I would be calculating only FDR for a particular
> subset of 30 randomly chosen rs, not for the whole data set.
> 
> The result I would like to present like in the attached plot. The
> x-axis say proportion of SNPs and in my case SNP is equivalent to rs
> 
> Can you please help with this, I really don't have idea how to go about this.
> 
> Thanks
> Ana
> <Screen Shot 2020-01-23 at 2.09.26 PM.png>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Jan 24 17:33:29 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 24 Jan 2020 11:33:29 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
Message-ID: <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>

Dear friend Rui,

Hope you are doing great. Firstly, I want to thank you for your super
valuable and kind support of always. As I mentioned in earlier e-mails, I
am trying to decode AIS type messages, and the only ones I am having a real
hard time with, is with latitude and longitude.

I tried the function you provided me in one of your replies, and it works
well with the examples  you provided, but in other cases it doesn?t.

The messages I am trying to decode are in the 6th column of the data. I
will provide you with a small sample first, and then the complete dataset
(which has 100 rows). This is the small sample:

> head(dat)
    ...1 ...2 ...3 ...4 ...5                         ...6 ...7       ...8
...9 ...10 ...11 ...12 ...13
1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54 1485907200
<NA>    NA    NA    NA  <NA>
2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39 1485907200
<NA>    NA    NA    NA  <NA>
3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D 1485907200
<NA>    NA    NA    NA  <NA>
4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43 1485907200
<NA>    NA    NA    NA  <NA>
5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29 1485907200
<NA>    NA    NA    NA  <NA>
6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D 1485907200
<NA>    NA    NA    NA  <NA>

It is worth mentioning that each row of the 6th column provides several
information about maritime vessels, like speed over ground, latitude,
longitude, vessel ID, etc. I am only concerned with latitude and longitude
since those are the only two fields I have not been able to decode
successfully. Also, I am working on R version 3.6.2 for windows 64-bit OS.

The messages to decode are of the following format:
15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.

Now, here is the complete dataset:

> dput(dat)
structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
"!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
"!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
"1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
"1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
"1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
"1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
"2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
"1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
"1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
"1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
"A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
"B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
"B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
"A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
"B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
"B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
"A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
"B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
"1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
"D03Iu6QGLN01MdN01StN000",
"B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
"1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
"15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
"403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
"H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
"15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
"13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
"403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
"403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
"15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
"A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00>TtPF1Asll03wPUwP06",
"15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
"15>uP00P00rC`U:59im;H?v22 at 1D",
"54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
"3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h", "15BkV00P00rCQBf5:Q5JQOv42D1o",
"35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
"34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
"15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
"15U?B00000rCgb>58DFJfRl620RT", "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
@W9K4Oi0D at PC0ShK40C",
"PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
"15De7F?P00JCr5r5517v4?v80h2P",
"15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
"15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
"55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
"88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
"15E:BR0P00rCgaT58DdJUwv82H34",
"15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
"1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
"15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
"A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
"1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
"7933.8835099999997",
"18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
"15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
"13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
"A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
"1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
"B;s at N9h00>TtPG1Asm403wSUwP06",

"15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
"10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
"19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
"15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
"15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
"803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
"HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
"15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
"15ATk20000rCnrv53N6;gPr>085R",
"55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",

"88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
"15BW=20P00JCrvH54t=an?vB00Sg",
"13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
"85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "1349B:3000rCtrn553aR at JHD2d4O",

"7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
"15B3Sj0000rC9RD5=mOh40jB20SU",
"15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
"2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
"0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
"0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
"W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
"0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
"0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
"0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
"0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
"0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
"0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
"0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 = c(1485907200,
1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
1485907203, 1485907203, 1485907204, 1485907204, 1485907204, 1485907204,
1485907204, 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
1485907204, 1485907205, 1485907205, 1485907205, 1485907205, 1485907205,
1485907205, 1485907205, 1485907206, 1485907206, 1485907206, 1485907206,
1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
1485907206, 1485907206, 1485907206, 1485907208, 1485907208, 1485907208,
1485907208, 1485907208, 1485907209, 1485907209, 1485907209, 1485907209,
1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
    NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1485907209,
    NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")

To tested your function I took the first message, which is located in the
6th column and the 1st row, and did the following:

library(stringi)
library(dplyr)
library(R.utils)
library(RANN)
library(NISTunits)
library(pracma)
library(celestial)
library(stringr)

dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE, na="",
+   sheet="RawSampleData", stringsAsFactors=FALSE)

testmessage1 <- dat[1,6]

ascii_datformat <- utf8ToInt(testmessage1)

Base <- ascii_datformat - 48

decy <- ifelse(Base > 40, Base - 8, Base)

biny <- intToBin(decy)

binyframe <- data.frame(biny)

tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I have
the complete first message, all in binary format

#according to the literature of AIS message decoding, longitude goes from
position 62 to position 89
#and latitude goes from position 90 to position 116

longitude <- substr(tbinyframe, 62, 89)
latitude    <- substr(tbinyframe, 90, 116)

#now I apply the function you provided me with:

 fun <- function(x){
         res <- sapply(x, function(y){
            if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
             strtoi(y, base = 2)
            }else{
              y <- unlist(strsplit(y, ""))
              -sum((y != "1")*2^((length(y) - 1):0)) - 1
            }
          })
          unname(res)
      }

> fun(longitude)
[1] 220663102
>
> fun(latitude)
[1] 5414823
>
> fun("1101001001110000110100111110")
[1] 220663102
>
> fun("000010100101001111110100111")
[1] 5414823
>
> fun("10110010")
[1] -78

as you can see, the function only worked or showed expected result on the
last case with a -78, but in the other cases, it the results were not as
expected, maybe I am missing something here?

Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<ruipbarradas at sapo.pt>)
escribi?:

> Hello,
>
> The function I included converts signed binary numbers into their
> decimal representation. They are negative if a) they are multiples of 8
> bits and b) the most significant bit is a "1". If not just convert to
> integer.
>
> As for a) above, I assume that you will have 8 bit numbers. And the
> conversion is done as follows:
>
> input: 10110010
>
> splitting, to make it more clear:
>
> 1 0 1 1 0 0 1 0 - input
> 0 1 0 0 1 1 0 1 - reversed
>                1 - add 1 to the number with reversed bits
> 0 1 0 0 1 1 1 0 - result is the two's complement
>
> c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
>
> But the msb is "1" so it's -78
>
>
> This is what the function does, but instead of %*% it uses
>
> sum(two's compl * powers of two)
>
>
> Hope this helps,
>
> Rui Barradas
>
> The input must be a character string or character vector.
>
> ?s 14:36 de 20/01/20, Paul Bernal escreveu:
> > Dear friend Rui,
> >
> > Hope you are doing great, thanks for your kind feedback. The challenge I
> > currently have at hand is to decode AIS messages and obtain latitude and
> > longitude values from those.
> >
> > So basically, I want to accomplish something like in the example below.
> > I want to convert this binary number (10110010) into the two?s
> > complement representation, there is the logic they are using for that.
> > Since longitude ranges from
> >
> >
> >       Example of conversion to decimal of a signed binary number in
> >       two's complement representation
> >
> > Let's convert to decimal the following signed binary number: 10110010
> >
> > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 = -128
> > + 32 + 16 + 2 = -78.
> >
> > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> >
> >     Sorry, missunderstood the problem.
> >     Here it goes:
> >
> >     fun <- function(x){
> >         res <- sapply(x, function(y){
> >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> >             strtoi(y, base = 2)
> >           }else{
> >             y <- unlist(strsplit(y, ""))
> >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
> >           }
> >         })
> >         unname(res)
> >     }
> >
> >     fun("10110010")
> >     fun("10000000")
> >     fun(c("01000000", "01111111", "10110010", "10000000"))
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
> >      > Hello,
> >      >
> >      > Is this what you want?
> >      >
> >      >
> >      > x <- "10110010"
> >      > strtoi(x, base = 2)
> >      > #[1] 178
> >      >
> >      >
> >      > Hope this helps,
> >      >
> >      > Rui Barradas
> >      >
> >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
> >      >> Dear friends,
> >      >>
> >      >> How can I convert the following binary number in two?s complement
> >      >> representation in R?
> >      >>
> >      >> 10110010
> >      >>
> >      >> Any help and/or guidance will be greatly appreciated,
> >      >>
> >      >> Best regards,
> >      >>
> >      >> Paul
> >      >>
> >      >>     [[alternative HTML version deleted]]
> >      >>
> >      >> ______________________________________________
> >      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      >> https://stat.ethz.ch/mailman/listinfo/r-help
> >      >> PLEASE do read the posting guide
> >      >> http://www.R-project.org/posting-guide.html
> >      >> and provide commented, minimal, self-contained, reproducible
> code.
> >      >>
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >      > http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Jan 24 18:23:31 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 24 Jan 2020 12:23:31 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
Message-ID: <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>

You show the example

> fun("10110010")
[1] -78

as satisfactory.  Where in your posted data set do you find the input
string "10110010"?

Please post a set of relevant input strings, and the answers you want from them.
The rest of the columns are not helpful for this specific exercise.

On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friend Rui,
>
> Hope you are doing great. Firstly, I want to thank you for your super
> valuable and kind support of always. As I mentioned in earlier e-mails, I
> am trying to decode AIS type messages, and the only ones I am having a real
> hard time with, is with latitude and longitude.
>
> I tried the function you provided me in one of your replies, and it works
> well with the examples  you provided, but in other cases it doesn?t.
>
> The messages I am trying to decode are in the 6th column of the data. I
> will provide you with a small sample first, and then the complete dataset
> (which has 100 rows). This is the small sample:
>
> > head(dat)
>     ...1 ...2 ...3 ...4 ...5                         ...6 ...7       ...8
> ...9 ...10 ...11 ...12 ...13
> 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54 1485907200
> <NA>    NA    NA    NA  <NA>
> 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39 1485907200
> <NA>    NA    NA    NA  <NA>
> 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D 1485907200
> <NA>    NA    NA    NA  <NA>
> 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43 1485907200
> <NA>    NA    NA    NA  <NA>
> 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29 1485907200
> <NA>    NA    NA    NA  <NA>
> 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D 1485907200
> <NA>    NA    NA    NA  <NA>
>
> It is worth mentioning that each row of the 6th column provides several
> information about maritime vessels, like speed over ground, latitude,
> longitude, vessel ID, etc. I am only concerned with latitude and longitude
> since those are the only two fields I have not been able to decode
> successfully. Also, I am working on R version 3.6.2 for windows 64-bit OS.
>
> The messages to decode are of the following format:
> 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
>
> Now, here is the complete dataset:
>
> > dput(dat)
> structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
> 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
> 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
> "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
> "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
> "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
> "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
> "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
> NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
> 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
> 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
> NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
> "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
> "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
> "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
> "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
> "B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
> "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
> "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
> "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
> "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
> "D03Iu6QGLN01MdN01StN000",
> "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
> "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
> "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
> "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
> "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
> "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
> "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
> "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
> "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
> "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
> "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00>TtPF1Asll03wPUwP06",
> "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
> "15>uP00P00rC`U:59im;H?v22 at 1D",
> "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
> "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h", "15BkV00P00rCQBf5:Q5JQOv42D1o",
> "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
> "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
> "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
> "15U?B00000rCgb>58DFJfRl620RT", "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
> @W9K4Oi0D at PC0ShK40C",
> "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
> "15De7F?P00JCr5r5517v4?v80h2P",
> "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
> "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
> "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
> "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
> "15E:BR0P00rCgaT58DdJUwv82H34",
> "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
> "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
> "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
> "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
> "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
> "7933.8835099999997",
> "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
> "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
> "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
> "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
> "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
> "B;s at N9h00>TtPG1Asm403wSUwP06",
>
> "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
> "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
> "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
> "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
> "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
> "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
> "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
> "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
> "15ATk20000rCnrv53N6;gPr>085R",
> "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>
> "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
> "15BW=20P00JCrvH54t=an?vB00Sg",
> "13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
> "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "1349B:3000rCtrn553aR at JHD2d4O",
>
> "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
> "15B3Sj0000rC9RD5=mOh40jB20SU",
> "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
> "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
> "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
> "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
> "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
> "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
> "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
> "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
> "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
> NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
> "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
> "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
> "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 = c(1485907200,
> 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
> NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
> 1485907203, 1485907203, 1485907204, 1485907204, 1485907204, 1485907204,
> 1485907204, 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
> 1485907204, 1485907205, 1485907205, 1485907205, 1485907205, 1485907205,
> 1485907205, 1485907205, 1485907206, 1485907206, 1485907206, 1485907206,
> 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
> 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
> 1485907206, 1485907206, 1485907206, 1485907208, 1485907208, 1485907208,
> 1485907208, 1485907208, 1485907209, 1485907209, 1485907209, 1485907209,
> 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
> 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
> 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
> ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
>     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
>     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1485907209,
>     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
>
> To tested your function I took the first message, which is located in the
> 6th column and the 1st row, and did the following:
>
> library(stringi)
> library(dplyr)
> library(R.utils)
> library(RANN)
> library(NISTunits)
> library(pracma)
> library(celestial)
> library(stringr)
>
> dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE, na="",
> +   sheet="RawSampleData", stringsAsFactors=FALSE)
>
> testmessage1 <- dat[1,6]
>
> ascii_datformat <- utf8ToInt(testmessage1)
>
> Base <- ascii_datformat - 48
>
> decy <- ifelse(Base > 40, Base - 8, Base)
>
> biny <- intToBin(decy)
>
> binyframe <- data.frame(biny)
>
> tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I have
> the complete first message, all in binary format
>
> #according to the literature of AIS message decoding, longitude goes from
> position 62 to position 89
> #and latitude goes from position 90 to position 116
>
> longitude <- substr(tbinyframe, 62, 89)
> latitude    <- substr(tbinyframe, 90, 116)
>
> #now I apply the function you provided me with:
>
>  fun <- function(x){
>          res <- sapply(x, function(y){
>             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>              strtoi(y, base = 2)
>             }else{
>               y <- unlist(strsplit(y, ""))
>               -sum((y != "1")*2^((length(y) - 1):0)) - 1
>             }
>           })
>           unname(res)
>       }
>
> > fun(longitude)
> [1] 220663102
> >
> > fun(latitude)
> [1] 5414823
> >
> > fun("1101001001110000110100111110")
> [1] 220663102
> >
> > fun("000010100101001111110100111")
> [1] 5414823
> >
> > fun("10110010")
> [1] -78
>
> as you can see, the function only worked or showed expected result on the
> last case with a -78, but in the other cases, it the results were not as
> expected, maybe I am missing something here?
>
> Any help and/or guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
> El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<ruipbarradas at sapo.pt>)
> escribi?:
>
> > Hello,
> >
> > The function I included converts signed binary numbers into their
> > decimal representation. They are negative if a) they are multiples of 8
> > bits and b) the most significant bit is a "1". If not just convert to
> > integer.
> >
> > As for a) above, I assume that you will have 8 bit numbers. And the
> > conversion is done as follows:
> >
> > input: 10110010
> >
> > splitting, to make it more clear:
> >
> > 1 0 1 1 0 0 1 0 - input
> > 0 1 0 0 1 1 0 1 - reversed
> >                1 - add 1 to the number with reversed bits
> > 0 1 0 0 1 1 1 0 - result is the two's complement
> >
> > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
> >
> > But the msb is "1" so it's -78
> >
> >
> > This is what the function does, but instead of %*% it uses
> >
> > sum(two's compl * powers of two)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > The input must be a character string or character vector.
> >
> > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
> > > Dear friend Rui,
> > >
> > > Hope you are doing great, thanks for your kind feedback. The challenge I
> > > currently have at hand is to decode AIS messages and obtain latitude and
> > > longitude values from those.
> > >
> > > So basically, I want to accomplish something like in the example below.
> > > I want to convert this binary number (10110010) into the two?s
> > > complement representation, there is the logic they are using for that.
> > > Since longitude ranges from
> > >
> > >
> > >       Example of conversion to decimal of a signed binary number in
> > >       two's complement representation
> > >
> > > Let's convert to decimal the following signed binary number: 10110010
> > >
> > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 = -128
> > > + 32 + 16 + 2 = -78.
> > >
> > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<ruipbarradas at sapo.pt
> > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> > >
> > >     Sorry, missunderstood the problem.
> > >     Here it goes:
> > >
> > >     fun <- function(x){
> > >         res <- sapply(x, function(y){
> > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> > >             strtoi(y, base = 2)
> > >           }else{
> > >             y <- unlist(strsplit(y, ""))
> > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
> > >           }
> > >         })
> > >         unname(res)
> > >     }
> > >
> > >     fun("10110010")
> > >     fun("10000000")
> > >     fun(c("01000000", "01111111", "10110010", "10000000"))
> > >
> > >
> > >     Hope this helps,
> > >
> > >     Rui Barradas
> > >
> > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
> > >      > Hello,
> > >      >
> > >      > Is this what you want?
> > >      >
> > >      >
> > >      > x <- "10110010"
> > >      > strtoi(x, base = 2)
> > >      > #[1] 178
> > >      >
> > >      >
> > >      > Hope this helps,
> > >      >
> > >      > Rui Barradas
> > >      >
> > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
> > >      >> Dear friends,
> > >      >>
> > >      >> How can I convert the following binary number in two?s complement
> > >      >> representation in R?
> > >      >>
> > >      >> 10110010
> > >      >>
> > >      >> Any help and/or guidance will be greatly appreciated,
> > >      >>
> > >      >> Best regards,
> > >      >>
> > >      >> Paul
> > >      >>
> > >      >>     [[alternative HTML version deleted]]
> > >      >>
> > >      >> ______________________________________________
> > >      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >      >> PLEASE do read the posting guide
> > >      >> http://www.R-project.org/posting-guide.html
> > >      >> and provide commented, minimal, self-contained, reproducible
> > code.
> > >      >>
> > >      >
> > >      > ______________________________________________
> > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > >      > PLEASE do read the posting guide
> > >      > http://www.R-project.org/posting-guide.html
> > >      > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Jan 24 19:45:44 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 24 Jan 2020 13:45:44 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
Message-ID: <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>

Hi Richard,

That was just an example, to show that, for that particular string of
binary numbers, the code works as expected. That is absolutely no related
to the dataset I provided. If I try the function on the dataset, I get
values well over the latitude and longitude boundaries (which should range
from -90 to + 90, and -180 to +180).

Regards,

Paul

El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<rmh at temple.edu>)
escribi?:

> You show the example
>
> > fun("10110010")
> [1] -78
>
> as satisfactory.  Where in your posted data set do you find the input
> string "10110010"?
>
> Please post a set of relevant input strings, and the answers you want from
> them.
> The rest of the columns are not helpful for this specific exercise.
>
> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >
> > Dear friend Rui,
> >
> > Hope you are doing great. Firstly, I want to thank you for your super
> > valuable and kind support of always. As I mentioned in earlier e-mails, I
> > am trying to decode AIS type messages, and the only ones I am having a
> real
> > hard time with, is with latitude and longitude.
> >
> > I tried the function you provided me in one of your replies, and it works
> > well with the examples  you provided, but in other cases it doesn?t.
> >
> > The messages I am trying to decode are in the 6th column of the data. I
> > will provide you with a small sample first, and then the complete dataset
> > (which has 100 rows). This is the small sample:
> >
> > > head(dat)
> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7       ...8
> > ...9 ...10 ...11 ...12 ...13
> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54
> 1485907200
> > <NA>    NA    NA    NA  <NA>
> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39
> 1485907200
> > <NA>    NA    NA    NA  <NA>
> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D 1485907200
> > <NA>    NA    NA    NA  <NA>
> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43 1485907200
> > <NA>    NA    NA    NA  <NA>
> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29
> 1485907200
> > <NA>    NA    NA    NA  <NA>
> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D
> 1485907200
> > <NA>    NA    NA    NA  <NA>
> >
> > It is worth mentioning that each row of the 6th column provides several
> > information about maritime vessels, like speed over ground, latitude,
> > longitude, vessel ID, etc. I am only concerned with latitude and
> longitude
> > since those are the only two fields I have not been able to decode
> > successfully. Also, I am working on R version 3.6.2 for windows 64-bit
> OS.
> >
> > The messages to decode are of the following format:
> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
> >
> > Now, here is the complete dataset:
> >
> > > dput(dat)
> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
> > "D03Iu6QGLN01MdN01StN000",
> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00>TtPF1Asll03wPUwP06",
> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
> > "15>uP00P00rC`U:59im;H?v22 at 1D",
> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h", "15BkV00P00rCQBf5:Q5JQOv42D1o",
> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
> > "15U?B00000rCgb>58DFJfRl620RT",
> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
> > @W9K4Oi0D at PC0ShK40C",
> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
> > "15De7F?P00JCr5r5517v4?v80h2P",
> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
> > "15E:BR0P00rCgaT58DdJUwv82H34",
> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
> > "7933.8835099999997",
> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
> > "B;s at N9h00>TtPG1Asm403wSUwP06",
> >
> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
> > "15ATk20000rCnrv53N6;gPr>085R",
> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
> >
> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
> > "15BW=20P00JCrvH54t=an?vB00Sg",
> > "13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0",
> "1349B:3000rCtrn553aR at JHD2d4O",
> >
> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
> > "15B3Sj0000rC9RD5=mOh40jB20SU",
> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 =
> c(1485907200,
> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204, 1485907204,
> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205, 1485907205,
> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206, 1485907206,
> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208, 1485907208,
> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209, 1485907209,
> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1485907209,
> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
> >
> > To tested your function I took the first message, which is located in the
> > 6th column and the 1st row, and did the following:
> >
> > library(stringi)
> > library(dplyr)
> > library(R.utils)
> > library(RANN)
> > library(NISTunits)
> > library(pracma)
> > library(celestial)
> > library(stringr)
> >
> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE,
> na="",
> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
> >
> > testmessage1 <- dat[1,6]
> >
> > ascii_datformat <- utf8ToInt(testmessage1)
> >
> > Base <- ascii_datformat - 48
> >
> > decy <- ifelse(Base > 40, Base - 8, Base)
> >
> > biny <- intToBin(decy)
> >
> > binyframe <- data.frame(biny)
> >
> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I
> have
> > the complete first message, all in binary format
> >
> > #according to the literature of AIS message decoding, longitude goes from
> > position 62 to position 89
> > #and latitude goes from position 90 to position 116
> >
> > longitude <- substr(tbinyframe, 62, 89)
> > latitude    <- substr(tbinyframe, 90, 116)
> >
> > #now I apply the function you provided me with:
> >
> >  fun <- function(x){
> >          res <- sapply(x, function(y){
> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> >              strtoi(y, base = 2)
> >             }else{
> >               y <- unlist(strsplit(y, ""))
> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
> >             }
> >           })
> >           unname(res)
> >       }
> >
> > > fun(longitude)
> > [1] 220663102
> > >
> > > fun(latitude)
> > [1] 5414823
> > >
> > > fun("1101001001110000110100111110")
> > [1] 220663102
> > >
> > > fun("000010100101001111110100111")
> > [1] 5414823
> > >
> > > fun("10110010")
> > [1] -78
> >
> > as you can see, the function only worked or showed expected result on the
> > last case with a -78, but in the other cases, it the results were not as
> > expected, maybe I am missing something here?
> >
> > Any help and/or guidance will be greatly appreciated,
> >
> > Best regards,
> >
> > Paul
> >
> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<ruipbarradas at sapo.pt>)
> > escribi?:
> >
> > > Hello,
> > >
> > > The function I included converts signed binary numbers into their
> > > decimal representation. They are negative if a) they are multiples of 8
> > > bits and b) the most significant bit is a "1". If not just convert to
> > > integer.
> > >
> > > As for a) above, I assume that you will have 8 bit numbers. And the
> > > conversion is done as follows:
> > >
> > > input: 10110010
> > >
> > > splitting, to make it more clear:
> > >
> > > 1 0 1 1 0 0 1 0 - input
> > > 0 1 0 0 1 1 0 1 - reversed
> > >                1 - add 1 to the number with reversed bits
> > > 0 1 0 0 1 1 1 0 - result is the two's complement
> > >
> > > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
> > >
> > > But the msb is "1" so it's -78
> > >
> > >
> > > This is what the function does, but instead of %*% it uses
> > >
> > > sum(two's compl * powers of two)
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > The input must be a character string or character vector.
> > >
> > > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
> > > > Dear friend Rui,
> > > >
> > > > Hope you are doing great, thanks for your kind feedback. The
> challenge I
> > > > currently have at hand is to decode AIS messages and obtain latitude
> and
> > > > longitude values from those.
> > > >
> > > > So basically, I want to accomplish something like in the example
> below.
> > > > I want to convert this binary number (10110010) into the two?s
> > > > complement representation, there is the logic they are using for
> that.
> > > > Since longitude ranges from
> > > >
> > > >
> > > >       Example of conversion to decimal of a signed binary number in
> > > >       two's complement representation
> > > >
> > > > Let's convert to decimal the following signed binary number: 10110010
> > > >
> > > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 =
> -128
> > > > + 32 + 16 + 2 = -78.
> > > >
> > > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<
> ruipbarradas at sapo.pt
> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> > > >
> > > >     Sorry, missunderstood the problem.
> > > >     Here it goes:
> > > >
> > > >     fun <- function(x){
> > > >         res <- sapply(x, function(y){
> > > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> > > >             strtoi(y, base = 2)
> > > >           }else{
> > > >             y <- unlist(strsplit(y, ""))
> > > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
> > > >           }
> > > >         })
> > > >         unname(res)
> > > >     }
> > > >
> > > >     fun("10110010")
> > > >     fun("10000000")
> > > >     fun(c("01000000", "01111111", "10110010", "10000000"))
> > > >
> > > >
> > > >     Hope this helps,
> > > >
> > > >     Rui Barradas
> > > >
> > > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
> > > >      > Hello,
> > > >      >
> > > >      > Is this what you want?
> > > >      >
> > > >      >
> > > >      > x <- "10110010"
> > > >      > strtoi(x, base = 2)
> > > >      > #[1] 178
> > > >      >
> > > >      >
> > > >      > Hope this helps,
> > > >      >
> > > >      > Rui Barradas
> > > >      >
> > > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
> > > >      >> Dear friends,
> > > >      >>
> > > >      >> How can I convert the following binary number in two?s
> complement
> > > >      >> representation in R?
> > > >      >>
> > > >      >> 10110010
> > > >      >>
> > > >      >> Any help and/or guidance will be greatly appreciated,
> > > >      >>
> > > >      >> Best regards,
> > > >      >>
> > > >      >> Paul
> > > >      >>
> > > >      >>     [[alternative HTML version deleted]]
> > > >      >>
> > > >      >> ______________________________________________
> > > >      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing
> list
> > > >     -- To UNSUBSCRIBE and more, see
> > > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >      >> PLEASE do read the posting guide
> > > >      >> http://www.R-project.org/posting-guide.html
> > > >      >> and provide commented, minimal, self-contained, reproducible
> > > code.
> > > >      >>
> > > >      >
> > > >      > ______________________________________________
> > > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> list
> > > >     -- To UNSUBSCRIBE and more, see
> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >      > PLEASE do read the posting guide
> > > >      > http://www.R-project.org/posting-guide.html
> > > >      > and provide commented, minimal, self-contained, reproducible
> code.
> > > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Jan 24 20:09:43 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 24 Jan 2020 14:09:43 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
Message-ID: <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>

now I am even more puzzled.

please complete the following two data.frames and send it to the list.

latDegrees lat2Comp
-90 xxxxxxxx
-89 xxxxxxxx
...
-1 xxxxxxxx
0 xxxxxxxx
1 xxxxxxxx
...
89 xxxxxxxx
90 xxxxxxxx

lonDegrees lon2Comp
-180 xxxxxxxx
-179 xxxxxxxx
...
-91 xxxxxxxx
-90 xxxxxxxx
-89 xxxxxxxx
...
-1 xxxxxxxx
0 xxxxxxxx
1 xxxxxxxx
...
89 xxxxxxxx
90 xxxxxxxx
91 xxxxxxxx
...
179 xxxxxxxx
180 xxxxxxxx

Your 8 bit 2C example has 7 digits of precision plus sign which gives
a range of (-127,127).  That suffices for latitude (-90,90).
For longitude you will need 9 bits of twos complement for 8 bits of
precision plus sign to cover (-255,255), thus more than enough for
(-180,180).
This assumes that precision to the degree is sufficient.  If you need
precision to minutes and seconds, or to meters, then you
will need even more bits in 2C.

Since it looks like you need a different number of bits for each
variable, I am asking for two data.frames.

Rich

On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Hi Richard,
>
> That was just an example, to show that, for that particular string of binary numbers, the code works as expected. That is absolutely no related to the dataset I provided. If I try the function on the dataset, I get values well over the latitude and longitude boundaries (which should range from -90 to + 90, and -180 to +180).
>
> Regards,
>
> Paul
>
> El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<rmh at temple.edu>) escribi?:
>>
>> You show the example
>>
>> > fun("10110010")
>> [1] -78
>>
>> as satisfactory.  Where in your posted data set do you find the input
>> string "10110010"?
>>
>> Please post a set of relevant input strings, and the answers you want from them.
>> The rest of the columns are not helpful for this specific exercise.
>>
>> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >
>> > Dear friend Rui,
>> >
>> > Hope you are doing great. Firstly, I want to thank you for your super
>> > valuable and kind support of always. As I mentioned in earlier e-mails, I
>> > am trying to decode AIS type messages, and the only ones I am having a real
>> > hard time with, is with latitude and longitude.
>> >
>> > I tried the function you provided me in one of your replies, and it works
>> > well with the examples  you provided, but in other cases it doesn?t.
>> >
>> > The messages I am trying to decode are in the 6th column of the data. I
>> > will provide you with a small sample first, and then the complete dataset
>> > (which has 100 rows). This is the small sample:
>> >
>> > > head(dat)
>> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7       ...8
>> > ...9 ...10 ...11 ...12 ...13
>> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54 1485907200
>> > <NA>    NA    NA    NA  <NA>
>> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39 1485907200
>> > <NA>    NA    NA    NA  <NA>
>> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D 1485907200
>> > <NA>    NA    NA    NA  <NA>
>> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43 1485907200
>> > <NA>    NA    NA    NA  <NA>
>> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29 1485907200
>> > <NA>    NA    NA    NA  <NA>
>> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D 1485907200
>> > <NA>    NA    NA    NA  <NA>
>> >
>> > It is worth mentioning that each row of the 6th column provides several
>> > information about maritime vessels, like speed over ground, latitude,
>> > longitude, vessel ID, etc. I am only concerned with latitude and longitude
>> > since those are the only two fields I have not been able to decode
>> > successfully. Also, I am working on R version 3.6.2 for windows 64-bit OS.
>> >
>> > The messages to decode are of the following format:
>> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
>> >
>> > Now, here is the complete dataset:
>> >
>> > > dput(dat)
>> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
>> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
>> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
>> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
>> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
>> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
>> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
>> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
>> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
>> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
>> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
>> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
>> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
>> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
>> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
>> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
>> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
>> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
>> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
>> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
>> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
>> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
>> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
>> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
>> > "D03Iu6QGLN01MdN01StN000",
>> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
>> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
>> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
>> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
>> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
>> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
>> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
>> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
>> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
>> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00>TtPF1Asll03wPUwP06",
>> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
>> > "15>uP00P00rC`U:59im;H?v22 at 1D",
>> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h", "15BkV00P00rCQBf5:Q5JQOv42D1o",
>> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
>> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
>> > "15U?B00000rCgb>58DFJfRl620RT", "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
>> > @W9K4Oi0D at PC0ShK40C",
>> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
>> > "15De7F?P00JCr5r5517v4?v80h2P",
>> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
>> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
>> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
>> > "15E:BR0P00rCgaT58DdJUwv82H34",
>> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
>> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
>> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
>> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
>> > "7933.8835099999997",
>> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
>> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
>> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>> > "B;s at N9h00>TtPG1Asm403wSUwP06",
>> >
>> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
>> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
>> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
>> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
>> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
>> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
>> > "15ATk20000rCnrv53N6;gPr>085R",
>> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>> >
>> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
>> > "15BW=20P00JCrvH54t=an?vB00Sg",
>> > "13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "1349B:3000rCtrn553aR at JHD2d4O",
>> >
>> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
>> > "15B3Sj0000rC9RD5=mOh40jB20SU",
>> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
>> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
>> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
>> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
>> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
>> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
>> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
>> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
>> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
>> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
>> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
>> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
>> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 = c(1485907200,
>> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
>> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
>> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204, 1485907204,
>> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
>> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205, 1485907205,
>> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206, 1485907206,
>> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
>> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
>> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208, 1485907208,
>> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209, 1485907209,
>> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
>> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
>> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
>> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
>> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
>> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1485907209,
>> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
>> >
>> > To tested your function I took the first message, which is located in the
>> > 6th column and the 1st row, and did the following:
>> >
>> > library(stringi)
>> > library(dplyr)
>> > library(R.utils)
>> > library(RANN)
>> > library(NISTunits)
>> > library(pracma)
>> > library(celestial)
>> > library(stringr)
>> >
>> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE, na="",
>> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
>> >
>> > testmessage1 <- dat[1,6]
>> >
>> > ascii_datformat <- utf8ToInt(testmessage1)
>> >
>> > Base <- ascii_datformat - 48
>> >
>> > decy <- ifelse(Base > 40, Base - 8, Base)
>> >
>> > biny <- intToBin(decy)
>> >
>> > binyframe <- data.frame(biny)
>> >
>> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I have
>> > the complete first message, all in binary format
>> >
>> > #according to the literature of AIS message decoding, longitude goes from
>> > position 62 to position 89
>> > #and latitude goes from position 90 to position 116
>> >
>> > longitude <- substr(tbinyframe, 62, 89)
>> > latitude    <- substr(tbinyframe, 90, 116)
>> >
>> > #now I apply the function you provided me with:
>> >
>> >  fun <- function(x){
>> >          res <- sapply(x, function(y){
>> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>> >              strtoi(y, base = 2)
>> >             }else{
>> >               y <- unlist(strsplit(y, ""))
>> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
>> >             }
>> >           })
>> >           unname(res)
>> >       }
>> >
>> > > fun(longitude)
>> > [1] 220663102
>> > >
>> > > fun(latitude)
>> > [1] 5414823
>> > >
>> > > fun("1101001001110000110100111110")
>> > [1] 220663102
>> > >
>> > > fun("000010100101001111110100111")
>> > [1] 5414823
>> > >
>> > > fun("10110010")
>> > [1] -78
>> >
>> > as you can see, the function only worked or showed expected result on the
>> > last case with a -78, but in the other cases, it the results were not as
>> > expected, maybe I am missing something here?
>> >
>> > Any help and/or guidance will be greatly appreciated,
>> >
>> > Best regards,
>> >
>> > Paul
>> >
>> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<ruipbarradas at sapo.pt>)
>> > escribi?:
>> >
>> > > Hello,
>> > >
>> > > The function I included converts signed binary numbers into their
>> > > decimal representation. They are negative if a) they are multiples of 8
>> > > bits and b) the most significant bit is a "1". If not just convert to
>> > > integer.
>> > >
>> > > As for a) above, I assume that you will have 8 bit numbers. And the
>> > > conversion is done as follows:
>> > >
>> > > input: 10110010
>> > >
>> > > splitting, to make it more clear:
>> > >
>> > > 1 0 1 1 0 0 1 0 - input
>> > > 0 1 0 0 1 1 0 1 - reversed
>> > >                1 - add 1 to the number with reversed bits
>> > > 0 1 0 0 1 1 1 0 - result is the two's complement
>> > >
>> > > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
>> > >
>> > > But the msb is "1" so it's -78
>> > >
>> > >
>> > > This is what the function does, but instead of %*% it uses
>> > >
>> > > sum(two's compl * powers of two)
>> > >
>> > >
>> > > Hope this helps,
>> > >
>> > > Rui Barradas
>> > >
>> > > The input must be a character string or character vector.
>> > >
>> > > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
>> > > > Dear friend Rui,
>> > > >
>> > > > Hope you are doing great, thanks for your kind feedback. The challenge I
>> > > > currently have at hand is to decode AIS messages and obtain latitude and
>> > > > longitude values from those.
>> > > >
>> > > > So basically, I want to accomplish something like in the example below.
>> > > > I want to convert this binary number (10110010) into the two?s
>> > > > complement representation, there is the logic they are using for that.
>> > > > Since longitude ranges from
>> > > >
>> > > >
>> > > >       Example of conversion to decimal of a signed binary number in
>> > > >       two's complement representation
>> > > >
>> > > > Let's convert to decimal the following signed binary number: 10110010
>> > > >
>> > > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 = -128
>> > > > + 32 + 16 + 2 = -78.
>> > > >
>> > > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<ruipbarradas at sapo.pt
>> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
>> > > >
>> > > >     Sorry, missunderstood the problem.
>> > > >     Here it goes:
>> > > >
>> > > >     fun <- function(x){
>> > > >         res <- sapply(x, function(y){
>> > > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>> > > >             strtoi(y, base = 2)
>> > > >           }else{
>> > > >             y <- unlist(strsplit(y, ""))
>> > > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
>> > > >           }
>> > > >         })
>> > > >         unname(res)
>> > > >     }
>> > > >
>> > > >     fun("10110010")
>> > > >     fun("10000000")
>> > > >     fun(c("01000000", "01111111", "10110010", "10000000"))
>> > > >
>> > > >
>> > > >     Hope this helps,
>> > > >
>> > > >     Rui Barradas
>> > > >
>> > > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
>> > > >      > Hello,
>> > > >      >
>> > > >      > Is this what you want?
>> > > >      >
>> > > >      >
>> > > >      > x <- "10110010"
>> > > >      > strtoi(x, base = 2)
>> > > >      > #[1] 178
>> > > >      >
>> > > >      >
>> > > >      > Hope this helps,
>> > > >      >
>> > > >      > Rui Barradas
>> > > >      >
>> > > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
>> > > >      >> Dear friends,
>> > > >      >>
>> > > >      >> How can I convert the following binary number in two?s complement
>> > > >      >> representation in R?
>> > > >      >>
>> > > >      >> 10110010
>> > > >      >>
>> > > >      >> Any help and/or guidance will be greatly appreciated,
>> > > >      >>
>> > > >      >> Best regards,
>> > > >      >>
>> > > >      >> Paul
>> > > >      >>
>> > > >      >>     [[alternative HTML version deleted]]
>> > > >      >>
>> > > >      >> ______________________________________________
>> > > >      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>> > > >     -- To UNSUBSCRIBE and more, see
>> > > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >      >> PLEASE do read the posting guide
>> > > >      >> http://www.R-project.org/posting-guide.html
>> > > >      >> and provide commented, minimal, self-contained, reproducible
>> > > code.
>> > > >      >>
>> > > >      >
>> > > >      > ______________________________________________
>> > > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>> > > >     -- To UNSUBSCRIBE and more, see
>> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >      > PLEASE do read the posting guide
>> > > >      > http://www.R-project.org/posting-guide.html
>> > > >      > and provide commented, minimal, self-contained, reproducible code.
>> > > >
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Jan 24 21:01:44 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 24 Jan 2020 15:01:44 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
 <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
Message-ID: <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>

Dear friend Richard,

Thank you for your interest in helping me through this challenge. As
requested, I am providing the two lat and long frames you suggested, plus
the one single column I am trying to decode:

LatitudeFrame:

> dput(LatitudeFrame)
structure(list(Latitude = structure(c(90L, 88L, 87L, 86L, 85L,
84L, 83L, 82L, 81L, 80L, 79L, 77L, 76L, 75L, 74L, 73L, 72L, 71L,
70L, 69L, 68L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L, 57L,
55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 46L, 44L, 43L, 42L,
41L, 40L, 39L, 38L, 37L, 36L, 35L, 33L, 32L, 31L, 30L, 29L, 28L,
27L, 26L, 25L, 24L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L, 14L,
13L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 89L, 78L, 67L,
56L, 45L, 34L, 23L, 12L, 1L, 91L, 92L, 103L, 114L, 125L, 136L,
147L, 158L, 169L, 180L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
101L, 102L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
113L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 137L,
138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 148L, 149L,
150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 159L, 160L, 161L,
162L, 163L, 164L, 165L, 166L, 167L, 168L, 170L, 171L, 172L, 173L,
174L, 175L, 176L, 177L, 178L, 179L, 181L), .Label = c("-1", "-10",
"-11", "-12", "-13", "-14", "-15", "-16", "-17", "-18", "-19",
"-2", "-20", "-21", "-22", "-23", "-24", "-25", "-26", "-27",
"-28", "-29", "-3", "-30", "-31", "-32", "-33", "-34", "-35",
"-36", "-37", "-38", "-39", "-4", "-40", "-41", "-42", "-43",
"-44", "-45", "-46", "-47", "-48", "-49", "-5", "-50", "-51",
"-52", "-53", "-54", "-55", "-56", "-57", "-58", "-59", "-6",
"-60", "-61", "-62", "-63", "-64", "-65", "-66", "-67", "-68",
"-69", "-7", "-70", "-71", "-72", "-73", "-74", "-75", "-76",
"-77", "-78", "-79", "-8", "-80", "-81", "-82", "-83", "-84",
"-85", "-86", "-87", "-88", "-89", "-9", "-90", "0", "1", "10",
"11", "12", "13", "14", "15", "16", "17", "18", "19", "2", "20",
"21", "22", "23", "24", "25", "26", "27", "28", "29", "3", "30",
"31", "32", "33", "34", "35", "36", "37", "38", "39", "4", "40",
"41", "42", "43", "44", "45", "46", "47", "48", "49", "5", "50",
"51", "52", "53", "54", "55", "56", "57", "58", "59", "6", "60",
"61", "62", "63", "64", "65", "66", "67", "68", "69", "7", "70",
"71", "72", "73", "74", "75", "76", "77", "78", "79", "8", "80",
"81", "82", "83", "84", "85", "86", "87", "88", "89", "9", "90"
), class = "factor"), LatitudeBinRep = structure(c(92L, 93L,
94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L,
106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L,
117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L,
128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L,
139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L,
172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 1L,
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L,
55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L,
68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L), .Label =
c("0000000000000000000000000000000",
"0000000000000000000000000000001", "0000000000000000000000000000010",
"0000000000000000000000000000011", "0000000000000000000000000000100",
"0000000000000000000000000000101", "0000000000000000000000000000110",
"0000000000000000000000000000111", "0000000000000000000000000001000",
"0000000000000000000000000001001", "0000000000000000000000000001010",
"0000000000000000000000000001011", "0000000000000000000000000001100",
"0000000000000000000000000001101", "0000000000000000000000000001110",
"0000000000000000000000000001111", "0000000000000000000000000010000",
"0000000000000000000000000010001", "0000000000000000000000000010010",
"0000000000000000000000000010011", "0000000000000000000000000010100",
"0000000000000000000000000010101", "0000000000000000000000000010110",
"0000000000000000000000000010111", "0000000000000000000000000011000",
"0000000000000000000000000011001", "0000000000000000000000000011010",
"0000000000000000000000000011011", "0000000000000000000000000011100",
"0000000000000000000000000011101", "0000000000000000000000000011110",
"0000000000000000000000000011111", "0000000000000000000000000100000",
"0000000000000000000000000100001", "0000000000000000000000000100010",
"0000000000000000000000000100011", "0000000000000000000000000100100",
"0000000000000000000000000100101", "0000000000000000000000000100110",
"0000000000000000000000000100111", "0000000000000000000000000101000",
"0000000000000000000000000101001", "0000000000000000000000000101010",
"0000000000000000000000000101011", "0000000000000000000000000101100",
"0000000000000000000000000101101", "0000000000000000000000000101110",
"0000000000000000000000000101111", "0000000000000000000000000110000",
"0000000000000000000000000110001", "0000000000000000000000000110010",
"0000000000000000000000000110011", "0000000000000000000000000110100",
"0000000000000000000000000110101", "0000000000000000000000000110110",
"0000000000000000000000000110111", "0000000000000000000000000111000",
"0000000000000000000000000111001", "0000000000000000000000000111010",
"0000000000000000000000000111011", "0000000000000000000000000111100",
"0000000000000000000000000111101", "0000000000000000000000000111110",
"0000000000000000000000000111111", "0000000000000000000000001000000",
"0000000000000000000000001000001", "0000000000000000000000001000010",
"0000000000000000000000001000011", "0000000000000000000000001000100",
"0000000000000000000000001000101", "0000000000000000000000001000110",
"0000000000000000000000001000111", "0000000000000000000000001001000",
"0000000000000000000000001001001", "0000000000000000000000001001010",
"0000000000000000000000001001011", "0000000000000000000000001001100",
"0000000000000000000000001001101", "0000000000000000000000001001110",
"0000000000000000000000001001111", "0000000000000000000000001010000",
"0000000000000000000000001010001", "0000000000000000000000001010010",
"0000000000000000000000001010011", "0000000000000000000000001010100",
"0000000000000000000000001010101", "0000000000000000000000001010110",
"0000000000000000000000001010111", "0000000000000000000000001011000",
"0000000000000000000000001011001", "0000000000000000000000001011010",
"1111111111111111111111110100110", "1111111111111111111111110100111",
"1111111111111111111111110101000", "1111111111111111111111110101001",
"1111111111111111111111110101010", "1111111111111111111111110101011",
"1111111111111111111111110101100", "1111111111111111111111110101101",
"1111111111111111111111110101110", "1111111111111111111111110101111",
"1111111111111111111111110110000", "1111111111111111111111110110001",
"1111111111111111111111110110010", "1111111111111111111111110110011",
"1111111111111111111111110110100", "1111111111111111111111110110101",
"1111111111111111111111110110110", "1111111111111111111111110110111",
"1111111111111111111111110111000", "1111111111111111111111110111001",
"1111111111111111111111110111010", "1111111111111111111111110111011",
"1111111111111111111111110111100", "1111111111111111111111110111101",
"1111111111111111111111110111110", "1111111111111111111111110111111",
"1111111111111111111111111000000", "1111111111111111111111111000001",
"1111111111111111111111111000010", "1111111111111111111111111000011",
"1111111111111111111111111000100", "1111111111111111111111111000101",
"1111111111111111111111111000110", "1111111111111111111111111000111",
"1111111111111111111111111001000", "1111111111111111111111111001001",
"1111111111111111111111111001010", "1111111111111111111111111001011",
"1111111111111111111111111001100", "1111111111111111111111111001101",
"1111111111111111111111111001110", "1111111111111111111111111001111",
"1111111111111111111111111010000", "1111111111111111111111111010001",
"1111111111111111111111111010010", "1111111111111111111111111010011",
"1111111111111111111111111010100", "1111111111111111111111111010101",
"1111111111111111111111111010110", "1111111111111111111111111010111",
"1111111111111111111111111011000", "1111111111111111111111111011001",
"1111111111111111111111111011010", "1111111111111111111111111011011",
"1111111111111111111111111011100", "1111111111111111111111111011101",
"1111111111111111111111111011110", "1111111111111111111111111011111",
"1111111111111111111111111100000", "1111111111111111111111111100001",
"1111111111111111111111111100010", "1111111111111111111111111100011",
"1111111111111111111111111100100", "1111111111111111111111111100101",
"1111111111111111111111111100110", "1111111111111111111111111100111",
"1111111111111111111111111101000", "1111111111111111111111111101001",
"1111111111111111111111111101010", "1111111111111111111111111101011",
"1111111111111111111111111101100", "1111111111111111111111111101101",
"1111111111111111111111111101110", "1111111111111111111111111101111",
"1111111111111111111111111110000", "1111111111111111111111111110001",
"1111111111111111111111111110010", "1111111111111111111111111110011",
"1111111111111111111111111110100", "1111111111111111111111111110101",
"1111111111111111111111111110110", "1111111111111111111111111110111",
"1111111111111111111111111111000", "1111111111111111111111111111001",
"1111111111111111111111111111010", "1111111111111111111111111111011",
"1111111111111111111111111111100", "1111111111111111111111111111101",
"1111111111111111111111111111110", "1111111111111111111111111111111"
), class = "factor")), class = "data.frame", row.names = c(NA,
-181L))

LongitudeFrame:

> dput(LongitudeFrame)
structure(list(Longitude = structure(c(91L, 89L, 88L, 87L, 86L,
85L, 84L, 83L, 82L, 81L, 80L, 78L, 77L, 76L, 75L, 74L, 73L, 72L,
71L, 70L, 69L, 67L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L,
56L, 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 45L, 44L, 43L,
42L, 41L, 40L, 39L, 38L, 37L, 36L, 34L, 33L, 32L, 31L, 30L, 29L,
28L, 27L, 26L, 25L, 23L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L,
14L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 180L, 179L, 178L,
177L, 176L, 175L, 174L, 173L, 172L, 171L, 169L, 168L, 167L, 166L,
165L, 164L, 163L, 162L, 161L, 160L, 158L, 157L, 156L, 155L, 154L,
153L, 152L, 151L, 150L, 149L, 147L, 146L, 145L, 144L, 143L, 142L,
141L, 140L, 139L, 138L, 136L, 135L, 134L, 133L, 132L, 131L, 130L,
129L, 128L, 127L, 125L, 124L, 123L, 122L, 121L, 120L, 119L, 118L,
117L, 116L, 114L, 113L, 112L, 111L, 110L, 109L, 108L, 107L, 106L,
105L, 103L, 102L, 101L, 100L, 99L, 98L, 97L, 96L, 95L, 94L, 92L,
90L, 79L, 68L, 57L, 46L, 35L, 24L, 13L, 2L, 170L, 159L, 148L,
137L, 126L, 115L, 104L, 93L, 1L, 181L, 182L, 274L, 285L, 296L,
307L, 318L, 329L, 340L, 351L, 183L, 194L, 205L, 216L, 227L, 238L,
249L, 260L, 271L, 273L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
282L, 283L, 284L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L,
294L, 295L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 305L,
306L, 308L, 309L, 310L, 311L, 312L, 313L, 314L, 315L, 316L, 317L,
319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 330L,
331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 341L, 342L,
343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L,
355L, 356L, 357L, 358L, 359L, 360L, 361L, 184L, 185L, 186L, 187L,
188L, 189L, 190L, 191L, 192L, 193L, 195L, 196L, 197L, 198L, 199L,
200L, 201L, 202L, 203L, 204L, 206L, 207L, 208L, 209L, 210L, 211L,
212L, 213L, 214L, 215L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
224L, 225L, 226L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
236L, 237L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
248L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L, 272L
), .Label = c("-1", "-10", "-100", "-101", "-102", "-103", "-104",
"-105", "-106", "-107", "-108", "-109", "-11", "-110", "-111",
"-112", "-113", "-114", "-115", "-116", "-117", "-118", "-119",
"-12", "-120", "-121", "-122", "-123", "-124", "-125", "-126",
"-127", "-128", "-129", "-13", "-130", "-131", "-132", "-133",
"-134", "-135", "-136", "-137", "-138", "-139", "-14", "-140",
"-141", "-142", "-143", "-144", "-145", "-146", "-147", "-148",
"-149", "-15", "-150", "-151", "-152", "-153", "-154", "-155",
"-156", "-157", "-158", "-159", "-16", "-160", "-161", "-162",
"-163", "-164", "-165", "-166", "-167", "-168", "-169", "-17",
"-170", "-171", "-172", "-173", "-174", "-175", "-176", "-177",
"-178", "-179", "-18", "-180", "-19", "-2", "-20", "-21", "-22",
"-23", "-24", "-25", "-26", "-27", "-28", "-29", "-3", "-30",
"-31", "-32", "-33", "-34", "-35", "-36", "-37", "-38", "-39",
"-4", "-40", "-41", "-42", "-43", "-44", "-45", "-46", "-47",
"-48", "-49", "-5", "-50", "-51", "-52", "-53", "-54", "-55",
"-56", "-57", "-58", "-59", "-6", "-60", "-61", "-62", "-63",
"-64", "-65", "-66", "-67", "-68", "-69", "-7", "-70", "-71",
"-72", "-73", "-74", "-75", "-76", "-77", "-78", "-79", "-8",
"-80", "-81", "-82", "-83", "-84", "-85", "-86", "-87", "-88",
"-89", "-9", "-90", "-91", "-92", "-93", "-94", "-95", "-96",
"-97", "-98", "-99", "0", "1", "10", "100", "101", "102", "103",
"104", "105", "106", "107", "108", "109", "11", "110", "111",
"112", "113", "114", "115", "116", "117", "118", "119", "12",
"120", "121", "122", "123", "124", "125", "126", "127", "128",
"129", "13", "130", "131", "132", "133", "134", "135", "136",
"137", "138", "139", "14", "140", "141", "142", "143", "144",
"145", "146", "147", "148", "149", "15", "150", "151", "152",
"153", "154", "155", "156", "157", "158", "159", "16", "160",
"161", "162", "163", "164", "165", "166", "167", "168", "169",
"17", "170", "171", "172", "173", "174", "175", "176", "177",
"178", "179", "18", "180", "19", "2", "20", "21", "22", "23",
"24", "25", "26", "27", "28", "29", "3", "30", "31", "32", "33",
"34", "35", "36", "37", "38", "39", "4", "40", "41", "42", "43",
"44", "45", "46", "47", "48", "49", "5", "50", "51", "52", "53",
"54", "55", "56", "57", "58", "59", "6", "60", "61", "62", "63",
"64", "65", "66", "67", "68", "69", "7", "70", "71", "72", "73",
"74", "75", "76", "77", "78", "79", "8", "80", "81", "82", "83",
"84", "85", "86", "87", "88", "89", "9", "90", "91", "92", "93",
"94", "95", "96", "97", "98", "99"), class = "factor"), LongitudeBinRep =
structure(c(182L,
183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 193L,
194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L,
205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L,
227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L, 236L, 237L,
238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L, 248L,
249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L,
271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L,
293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L,
304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,
315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L,
326L, 327L, 328L, 329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L,
337L, 338L, 339L, 340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L,
348L, 349L, 350L, 351L, 352L, 353L, 354L, 355L, 356L, 357L, 358L,
359L, 360L, 361L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L,
51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L,
64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L,
102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L,
124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L,
135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L,
157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L,
168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
179L, 180L, 181L), .Label = c("0000000000000000000000000000000",
"0000000000000000000000000000001", "0000000000000000000000000000010",
"0000000000000000000000000000011", "0000000000000000000000000000100",
"0000000000000000000000000000101", "0000000000000000000000000000110",
"0000000000000000000000000000111", "0000000000000000000000000001000",
"0000000000000000000000000001001", "0000000000000000000000000001010",
"0000000000000000000000000001011", "0000000000000000000000000001100",
"0000000000000000000000000001101", "0000000000000000000000000001110",
"0000000000000000000000000001111", "0000000000000000000000000010000",
"0000000000000000000000000010001", "0000000000000000000000000010010",
"0000000000000000000000000010011", "0000000000000000000000000010100",
"0000000000000000000000000010101", "0000000000000000000000000010110",
"0000000000000000000000000010111", "0000000000000000000000000011000",
"0000000000000000000000000011001", "0000000000000000000000000011010",
"0000000000000000000000000011011", "0000000000000000000000000011100",
"0000000000000000000000000011101", "0000000000000000000000000011110",
"0000000000000000000000000011111", "0000000000000000000000000100000",
"0000000000000000000000000100001", "0000000000000000000000000100010",
"0000000000000000000000000100011", "0000000000000000000000000100100",
"0000000000000000000000000100101", "0000000000000000000000000100110",
"0000000000000000000000000100111", "0000000000000000000000000101000",
"0000000000000000000000000101001", "0000000000000000000000000101010",
"0000000000000000000000000101011", "0000000000000000000000000101100",
"0000000000000000000000000101101", "0000000000000000000000000101110",
"0000000000000000000000000101111", "0000000000000000000000000110000",
"0000000000000000000000000110001", "0000000000000000000000000110010",
"0000000000000000000000000110011", "0000000000000000000000000110100",
"0000000000000000000000000110101", "0000000000000000000000000110110",
"0000000000000000000000000110111", "0000000000000000000000000111000",
"0000000000000000000000000111001", "0000000000000000000000000111010",
"0000000000000000000000000111011", "0000000000000000000000000111100",
"0000000000000000000000000111101", "0000000000000000000000000111110",
"0000000000000000000000000111111", "0000000000000000000000001000000",
"0000000000000000000000001000001", "0000000000000000000000001000010",
"0000000000000000000000001000011", "0000000000000000000000001000100",
"0000000000000000000000001000101", "0000000000000000000000001000110",
"0000000000000000000000001000111", "0000000000000000000000001001000",
"0000000000000000000000001001001", "0000000000000000000000001001010",
"0000000000000000000000001001011", "0000000000000000000000001001100",
"0000000000000000000000001001101", "0000000000000000000000001001110",
"0000000000000000000000001001111", "0000000000000000000000001010000",
"0000000000000000000000001010001", "0000000000000000000000001010010",
"0000000000000000000000001010011", "0000000000000000000000001010100",
"0000000000000000000000001010101", "0000000000000000000000001010110",
"0000000000000000000000001010111", "0000000000000000000000001011000",
"0000000000000000000000001011001", "0000000000000000000000001011010",
"0000000000000000000000001011011", "0000000000000000000000001011100",
"0000000000000000000000001011101", "0000000000000000000000001011110",
"0000000000000000000000001011111", "0000000000000000000000001100000",
"0000000000000000000000001100001", "0000000000000000000000001100010",
"0000000000000000000000001100011", "0000000000000000000000001100100",
"0000000000000000000000001100101", "0000000000000000000000001100110",
"0000000000000000000000001100111", "0000000000000000000000001101000",
"0000000000000000000000001101001", "0000000000000000000000001101010",
"0000000000000000000000001101011", "0000000000000000000000001101100",
"0000000000000000000000001101101", "0000000000000000000000001101110",
"0000000000000000000000001101111", "0000000000000000000000001110000",
"0000000000000000000000001110001", "0000000000000000000000001110010",
"0000000000000000000000001110011", "0000000000000000000000001110100",
"0000000000000000000000001110101", "0000000000000000000000001110110",
"0000000000000000000000001110111", "0000000000000000000000001111000",
"0000000000000000000000001111001", "0000000000000000000000001111010",
"0000000000000000000000001111011", "0000000000000000000000001111100",
"0000000000000000000000001111101", "0000000000000000000000001111110",
"0000000000000000000000001111111", "0000000000000000000000010000000",
"0000000000000000000000010000001", "0000000000000000000000010000010",
"0000000000000000000000010000011", "0000000000000000000000010000100",
"0000000000000000000000010000101", "0000000000000000000000010000110",
"0000000000000000000000010000111", "0000000000000000000000010001000",
"0000000000000000000000010001001", "0000000000000000000000010001010",
"0000000000000000000000010001011", "0000000000000000000000010001100",
"0000000000000000000000010001101", "0000000000000000000000010001110",
"0000000000000000000000010001111", "0000000000000000000000010010000",
"0000000000000000000000010010001", "0000000000000000000000010010010",
"0000000000000000000000010010011", "0000000000000000000000010010100",
"0000000000000000000000010010101", "0000000000000000000000010010110",
"0000000000000000000000010010111", "0000000000000000000000010011000",
"0000000000000000000000010011001", "0000000000000000000000010011010",
"0000000000000000000000010011011", "0000000000000000000000010011100",
"0000000000000000000000010011101", "0000000000000000000000010011110",
"0000000000000000000000010011111", "0000000000000000000000010100000",
"0000000000000000000000010100001", "0000000000000000000000010100010",
"0000000000000000000000010100011", "0000000000000000000000010100100",
"0000000000000000000000010100101", "0000000000000000000000010100110",
"0000000000000000000000010100111", "0000000000000000000000010101000",
"0000000000000000000000010101001", "0000000000000000000000010101010",
"0000000000000000000000010101011", "0000000000000000000000010101100",
"0000000000000000000000010101101", "0000000000000000000000010101110",
"0000000000000000000000010101111", "0000000000000000000000010110000",
"0000000000000000000000010110001", "0000000000000000000000010110010",
"0000000000000000000000010110011", "0000000000000000000000010110100",
"1111111111111111111111101001100", "1111111111111111111111101001101",
"1111111111111111111111101001110", "1111111111111111111111101001111",
"1111111111111111111111101010000", "1111111111111111111111101010001",
"1111111111111111111111101010010", "1111111111111111111111101010011",
"1111111111111111111111101010100", "1111111111111111111111101010101",
"1111111111111111111111101010110", "1111111111111111111111101010111",
"1111111111111111111111101011000", "1111111111111111111111101011001",
"1111111111111111111111101011010", "1111111111111111111111101011011",
"1111111111111111111111101011100", "1111111111111111111111101011101",
"1111111111111111111111101011110", "1111111111111111111111101011111",
"1111111111111111111111101100000", "1111111111111111111111101100001",
"1111111111111111111111101100010", "1111111111111111111111101100011",
"1111111111111111111111101100100", "1111111111111111111111101100101",
"1111111111111111111111101100110", "1111111111111111111111101100111",
"1111111111111111111111101101000", "1111111111111111111111101101001",
"1111111111111111111111101101010", "1111111111111111111111101101011",
"1111111111111111111111101101100", "1111111111111111111111101101101",
"1111111111111111111111101101110", "1111111111111111111111101101111",
"1111111111111111111111101110000", "1111111111111111111111101110001",
"1111111111111111111111101110010", "1111111111111111111111101110011",
"1111111111111111111111101110100", "1111111111111111111111101110101",
"1111111111111111111111101110110", "1111111111111111111111101110111",
"1111111111111111111111101111000", "1111111111111111111111101111001",
"1111111111111111111111101111010", "1111111111111111111111101111011",
"1111111111111111111111101111100", "1111111111111111111111101111101",
"1111111111111111111111101111110", "1111111111111111111111101111111",
"1111111111111111111111110000000", "1111111111111111111111110000001",
"1111111111111111111111110000010", "1111111111111111111111110000011",
"1111111111111111111111110000100", "1111111111111111111111110000101",
"1111111111111111111111110000110", "1111111111111111111111110000111",
"1111111111111111111111110001000", "1111111111111111111111110001001",
"1111111111111111111111110001010", "1111111111111111111111110001011",
"1111111111111111111111110001100", "1111111111111111111111110001101",
"1111111111111111111111110001110", "1111111111111111111111110001111",
"1111111111111111111111110010000", "1111111111111111111111110010001",
"1111111111111111111111110010010", "1111111111111111111111110010011",
"1111111111111111111111110010100", "1111111111111111111111110010101",
"1111111111111111111111110010110", "1111111111111111111111110010111",
"1111111111111111111111110011000", "1111111111111111111111110011001",
"1111111111111111111111110011010", "1111111111111111111111110011011",
"1111111111111111111111110011100", "1111111111111111111111110011101",
"1111111111111111111111110011110", "1111111111111111111111110011111",
"1111111111111111111111110100000", "1111111111111111111111110100001",
"1111111111111111111111110100010", "1111111111111111111111110100011",
"1111111111111111111111110100100", "1111111111111111111111110100101",
"1111111111111111111111110100110", "1111111111111111111111110100111",
"1111111111111111111111110101000", "1111111111111111111111110101001",
"1111111111111111111111110101010", "1111111111111111111111110101011",
"1111111111111111111111110101100", "1111111111111111111111110101101",
"1111111111111111111111110101110", "1111111111111111111111110101111",
"1111111111111111111111110110000", "1111111111111111111111110110001",
"1111111111111111111111110110010", "1111111111111111111111110110011",
"1111111111111111111111110110100", "1111111111111111111111110110101",
"1111111111111111111111110110110", "1111111111111111111111110110111",
"1111111111111111111111110111000", "1111111111111111111111110111001",
"1111111111111111111111110111010", "1111111111111111111111110111011",
"1111111111111111111111110111100", "1111111111111111111111110111101",
"1111111111111111111111110111110", "1111111111111111111111110111111",
"1111111111111111111111111000000", "1111111111111111111111111000001",
"1111111111111111111111111000010", "1111111111111111111111111000011",
"1111111111111111111111111000100", "1111111111111111111111111000101",
"1111111111111111111111111000110", "1111111111111111111111111000111",
"1111111111111111111111111001000", "1111111111111111111111111001001",
"1111111111111111111111111001010", "1111111111111111111111111001011",
"1111111111111111111111111001100", "1111111111111111111111111001101",
"1111111111111111111111111001110", "1111111111111111111111111001111",
"1111111111111111111111111010000", "1111111111111111111111111010001",
"1111111111111111111111111010010", "1111111111111111111111111010011",
"1111111111111111111111111010100", "1111111111111111111111111010101",
"1111111111111111111111111010110", "1111111111111111111111111010111",
"1111111111111111111111111011000", "1111111111111111111111111011001",
"1111111111111111111111111011010", "1111111111111111111111111011011",
"1111111111111111111111111011100", "1111111111111111111111111011101",
"1111111111111111111111111011110", "1111111111111111111111111011111",
"1111111111111111111111111100000", "1111111111111111111111111100001",
"1111111111111111111111111100010", "1111111111111111111111111100011",
"1111111111111111111111111100100", "1111111111111111111111111100101",
"1111111111111111111111111100110", "1111111111111111111111111100111",
"1111111111111111111111111101000", "1111111111111111111111111101001",
"1111111111111111111111111101010", "1111111111111111111111111101011",
"1111111111111111111111111101100", "1111111111111111111111111101101",
"1111111111111111111111111101110", "1111111111111111111111111101111",
"1111111111111111111111111110000", "1111111111111111111111111110001",
"1111111111111111111111111110010", "1111111111111111111111111110011",
"1111111111111111111111111110100", "1111111111111111111111111110101",
"1111111111111111111111111110110", "1111111111111111111111111110111",
"1111111111111111111111111111000", "1111111111111111111111111111001",
"1111111111111111111111111111010", "1111111111111111111111111111011",
"1111111111111111111111111111100", "1111111111111111111111111111101",
"1111111111111111111111111111110", "1111111111111111111111111111111"
), class = "factor")), class = "data.frame", row.names = c(NA,
-361L))

AISMessageFrame (Raw Messages as they come from the AIS device):

> dput(AISMessageFrame)
structure(list(MessgeCode = structure(c(17L, 6L, 93L, 92L, 81L,
24L, 4L, 44L, 21L, 43L, 66L, 64L, 94L, 46L, 26L, 82L, 12L, 9L,
67L, 63L, 65L, 39L, 48L, 38L, 79L, 83L, 37L, 73L, 23L, 68L, 59L,
NA, 5L, 30L, 62L, 84L, 60L, 22L, 52L, 61L, 50L, 70L, 96L, 85L,
33L, 51L, 8L, 16L, 19L, 71L, 76L, 86L, 34L, 25L, 14L, 53L, 10L,
29L, 2L, 77L, 57L, 87L, 72L, 54L, 55L, 36L, 1L, 13L, NA, 78L,
58L, 15L, 89L, 35L, 20L, 3L, 49L, 56L, 90L, 40L, 45L, 41L, 42L,
74L, 95L, 32L, 91L, 27L, 69L, 76L, 18L, 31L, 11L, 80L, 75L, 7L,
72L, 88L, 28L, 47L), .Label = c("1:u0KOh001rCq5P529qqubqh2 at 3n",
"100000?P00JCkt:583J=r?v:283Q", "10007NgP00rCQGV5:Pa=?gv>2<1H",
"1000Fo at P01rCuG<56bnkN?v004`0", "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
"1349B:3000rCtrn553aR at JH02PRp", "1349B:3000rCtrn553aR at JHD2d4O",
"137g`F8007rCaIj59Tc5Dl at 800SN", "139NL4000LrCc8j59FEED4 at 000S<",
"13M at Hk00jSJD@RD4s=qG1mT80 at 3J", "13P;K8 at 001rCfgr58=f;QbFD2D4G",
"13P;K8 at Oh1rCfgp58=ec1bD22<4J", "13P>4mhw1CrCi5H57aK5WlN>0<4F",
"14aMBf000wrCKKN5:sdU0Sv<083C", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
"15?7P`0P00rD1S453KSlj?v824`0", "15?f5H?P00rCQat5:Oah0?wn2 at S6",
"15?lSL?P00JCQWD5:OpP0?vB24`0", "15?mqH?P00rCek458rkEN?v:00S4",
"15 at EA<0P01JCo8l53=BFgwv at 0D47", "15 at eD@8000rC`bl59kW`mFn004`0",
"15>nNj0000rCT<@5::qUpkt604`0", "15>uP00P00rC`U:59im;H?v22 at 1D",
"15A at av3P00rClHn53<I8M?v02<2B", "15AIw`0P0GrCcO859DO5Ogv:0T`0",
"15Aq00?P00rC`a`59mFeogv004`0", "15ATk20000rCnrv53N6;gPr>085R",
"15B3Sj0000rC9RD5=mOh40jB20SU", "15BI>P0001rCgUD58DRalRj:00S5",
"15BkV00P00rCQBf5:Q5JQOv42D1o", "15BW=20P00JCrvH54t=an?vB00Sg",
"15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "15De7F?P00JCr5r5517v4?v80h2P",
"15E:BR0P00rCgaT58DdJUwv82H34", "15E:N at 0000rCgOd57p45bW><0<2H",
"15E=m60000rC`W459k28Wnd:083h", "15E=q08P00JCrnR52cb>4?v200Sw",
"15PoOh0001rCgbt58CwUaBD004`0", "15PvE at 0002rCi7R57pokCT:424`0",
"15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:",
"15QDCP0P?w<tSF0l4Q@>4?wp0D1G", "15QIK`0P00rC`Sb59jFUUgv02<1g",
"15QK900001JCq=d54l?5J0op0l4e", "15QtF00000rCafD59P?VJ9p<0H52",
"15TGcJ0002rD<>p55FgmI at Ul0H0S", "15TgVb0000rCgVb57oFc;ARF2 at 67",
"15TgVb0000rCgVd57oFc31R42L46", "15TILd?P00JCm4l53`D>4?v>0L1m",
"15U?B00000rCgb>58DFJfRl620RT", "15U at cn0000rCgU>57oPLGiT:2D4D",
"15UHOn9P00rCQ`D5:OcTkgv80<4:", "1819?@H001rC9TB5=bppM9<82D0T",
"18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
"19NSG<h003rCi@:57pmUkAB<0<1v", "1gu00CLLwfh2 at Asw9@1<", "1gu103LLwfl1 at Asw9P1<",

"3", "34`odN1000rD1V2537=dfPJ60000", "35A=Rh1001rD;s454vSTuP`40000",
"35QN<D1000rCr5l53esbgPR20000", "39NS at m11@1rCrb:53:E<v0j3R000",
"403Iu6Qv4PU00rCk0d57rwW00<2g", "403Iu6Qv4PU01rCk0d57rwW00<2g",
"403Iupiv4PU00rC9065>=fW00H0I", "403Iupiv4PU00rC9065>=fW00H0j",
"54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
"55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
"55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G@W9K4Oi0D at PC0ShK40C",
"55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
"7933.8835099999997", "7933.8836099999999",
"803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
"85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "88888888880",
"A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
"A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
"A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T",
"A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
"B;s at N9h00>TtPEQAslh03wuUwP06", "B;s at N9h00>TtPF1Asll03wP5wP06",
"B;s at N9h00>TtPF1Asll03wPUwP06", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
"B;s at N9h00>TtPFQAslt03wQUwP06", "B;s at N9h00>TtPFQAslt03wR5wP06",
"B;s at N9h00>TtPFQAsm003wRUwP06", "B;s at N9h00>TtPFQAsm803wU5wP06",
"B;s at N9h00>TtPG1Asm403wSUwP06", "B;s at N9h00>TtPG1Asm403wT5wP06",
"B;s at N9h00>TtPG1Asm803wTUwP06", "D03Iu6QGLN01MdN01StN000",
"D03Iuph1TNfp4dv9J<`N000",
"H5?AU:4U653hhhi8 at lkihP000000",
"HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
"PC at H8888880"), class = "factor")), class = "data.frame", row.names = c(NA,
-100L))

Each one of those weird codes given in the AISMessageFrame correspond to an
AIS message, there is a lot of information provided here, but I am only
concerned with the Latitude and Longitude values (degrees with minutes). In
order to accomplish this, each one of those wierd codes need to be
converted to binary strings, once converted to binary strings. As I
mentioned before, the information regarding latitude and longitude can be
extracted from the following positions (again, after converting code to
binary strings):
Latitude = positions 90 to 116 inclusive (assuming you count the bits from
left to right, with the first one having position number 1)
Longitude = positions 62 to 89 inclusive (assuming you count the bits from
left to right withe the first one having position number 1)

In the sample code I provided in previous emails, I used the following to
obtain the Latitude and Longitude:

library(stringi)
library(dplyr)
library(R.utils)
library(RANN)
library(NISTunits)
library(pracma)
library(celestial)
library(stringr)

#here I show the sample to decode a single record, though that needs to be
done for all AIS messages, so obviously a loop will be needed for that:

ascii_datformat <- utf8ToInt(dataset1[1,6]) #turning the first AIS message
as it comes to ascii number
Base <- ascii_datformat - 48    #transformation from ascii to decimal
decy <- ifelse(Base > 40, Base-8, Base) #transformation from ascii to
decimal continued
biny <- intToBin(decy)  #transformation from decimal to binary
representation
binyframe <- data.frame(biny)
tbinyframe <- paste(t(binyframe[,1]), collapse="") #simply transposing the
results

tbinyframe will give you something like this (for each row having an AIS
message)
> tbinyframe
[1]
"000001000101001111101110000101011000001111100000000000000000111010010011100001101001111100000101001010011111101001110000000000001111111111110110000010010000100011000110"

Latitude <- substr(tbinyframe, 90, 116)
Longitude <- substr(tbinyframe, 62, 89)

What I need is to decode thos latitude and longitude values , to get
results in a -90 to +90 range for latitude, and in the -180 to +180 range
for longitude.

Hopefully I?ve made myself sufficiently clear this time and/or hopefully I
understood your point correctly and provided you what you need.

Again, thank you so much for your time and valuable support brother!

Best regards,

Paul

El vie., 24 ene. 2020 a las 14:09, Richard M. Heiberger (<rmh at temple.edu>)
escribi?:

> now I am even more puzzled.
>
> please complete the following two data.frames and send it to the list.
>
> latDegrees lat2Comp
> -90 xxxxxxxx
> -89 xxxxxxxx
> ...
> -1 xxxxxxxx
> 0 xxxxxxxx
> 1 xxxxxxxx
> ...
> 89 xxxxxxxx
> 90 xxxxxxxx
>
> lonDegrees lon2Comp
> -180 xxxxxxxx
> -179 xxxxxxxx
> ...
> -91 xxxxxxxx
> -90 xxxxxxxx
> -89 xxxxxxxx
> ...
> -1 xxxxxxxx
> 0 xxxxxxxx
> 1 xxxxxxxx
> ...
> 89 xxxxxxxx
> 90 xxxxxxxx
> 91 xxxxxxxx
> ...
> 179 xxxxxxxx
> 180 xxxxxxxx
>
> Your 8 bit 2C example has 7 digits of precision plus sign which gives
> a range of (-127,127).  That suffices for latitude (-90,90).
> For longitude you will need 9 bits of twos complement for 8 bits of
> precision plus sign to cover (-255,255), thus more than enough for
> (-180,180).
> This assumes that precision to the degree is sufficient.  If you need
> precision to minutes and seconds, or to meters, then you
> will need even more bits in 2C.
>
> Since it looks like you need a different number of bits for each
> variable, I am asking for two data.frames.
>
> Rich
>
> On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >
> > Hi Richard,
> >
> > That was just an example, to show that, for that particular string of
> binary numbers, the code works as expected. That is absolutely no related
> to the dataset I provided. If I try the function on the dataset, I get
> values well over the latitude and longitude boundaries (which should range
> from -90 to + 90, and -180 to +180).
> >
> > Regards,
> >
> > Paul
> >
> > El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<rmh at temple.edu>)
> escribi?:
> >>
> >> You show the example
> >>
> >> > fun("10110010")
> >> [1] -78
> >>
> >> as satisfactory.  Where in your posted data set do you find the input
> >> string "10110010"?
> >>
> >> Please post a set of relevant input strings, and the answers you want
> from them.
> >> The rest of the columns are not helpful for this specific exercise.
> >>
> >> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >> >
> >> > Dear friend Rui,
> >> >
> >> > Hope you are doing great. Firstly, I want to thank you for your super
> >> > valuable and kind support of always. As I mentioned in earlier
> e-mails, I
> >> > am trying to decode AIS type messages, and the only ones I am having
> a real
> >> > hard time with, is with latitude and longitude.
> >> >
> >> > I tried the function you provided me in one of your replies, and it
> works
> >> > well with the examples  you provided, but in other cases it doesn?t.
> >> >
> >> > The messages I am trying to decode are in the 6th column of the data.
> I
> >> > will provide you with a small sample first, and then the complete
> dataset
> >> > (which has 100 rows). This is the small sample:
> >> >
> >> > > head(dat)
> >> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7
>  ...8
> >> > ...9 ...10 ...11 ...12 ...13
> >> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54
> 1485907200
> >> > <NA>    NA    NA    NA  <NA>
> >> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39
> 1485907200
> >> > <NA>    NA    NA    NA  <NA>
> >> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D
> 1485907200
> >> > <NA>    NA    NA    NA  <NA>
> >> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43
> 1485907200
> >> > <NA>    NA    NA    NA  <NA>
> >> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29
> 1485907200
> >> > <NA>    NA    NA    NA  <NA>
> >> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D
> 1485907200
> >> > <NA>    NA    NA    NA  <NA>
> >> >
> >> > It is worth mentioning that each row of the 6th column provides
> several
> >> > information about maritime vessels, like speed over ground, latitude,
> >> > longitude, vessel ID, etc. I am only concerned with latitude and
> longitude
> >> > since those are the only two fields I have not been able to decode
> >> > successfully. Also, I am working on R version 3.6.2 for windows
> 64-bit OS.
> >> >
> >> > The messages to decode are of the following format:
> >> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
> >> >
> >> > Now, here is the complete dataset:
> >> >
> >> > > dput(dat)
> >> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
> >> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
> >> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
> >> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
> >> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
> >> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
> >> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> >> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
> >> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
> >> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> >> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
> >> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> >> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
> >> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
> >> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
> >> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
> >> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
> >> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
> >> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
> >> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
> >> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
> >> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
> >> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
> >> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
> >> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
> >> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
> >> > "D03Iu6QGLN01MdN01StN000",
> >> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
> >> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
> >> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
> >> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
> >> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
> >> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
> >> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
> >> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
> >> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
> >> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
> >> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00
> >TtPF1Asll03wPUwP06",
> >> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
> >> > "15>uP00P00rC`U:59im;H?v22 at 1D",
> >> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
> >> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
> "15BkV00P00rCQBf5:Q5JQOv42D1o",
> >> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
> >> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
> >> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
> >> > "15U?B00000rCgb>58DFJfRl620RT",
> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
> >> > @W9K4Oi0D at PC0ShK40C",
> >> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
> >> > "15De7F?P00JCr5r5517v4?v80h2P",
> >> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
> >> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
> >> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
> >> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
> >> > "15E:BR0P00rCgaT58DdJUwv82H34",
> >> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
> >> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
> >> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
> >> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
> >> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
> >> > "7933.8835099999997",
> >> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
> >> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
> >> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
> >> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
> >> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
> >> > "B;s at N9h00>TtPG1Asm403wSUwP06",
> >> >
> >> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
> >> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
> >> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
> >> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
> >> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
> >> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
> >> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
> >> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
> >> > "15ATk20000rCnrv53N6;gPr>085R",
> >> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
> >> >
> >> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
> >> > "15BW=20P00JCrvH54t=an?vB00Sg",
> >> > "13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T
> ",
> >> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0",
> "1349B:3000rCtrn553aR at JHD2d4O",
> >> >
> >> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
> >> > "15B3Sj0000rC9RD5=mOh40jB20SU",
> >> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
> >> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
> >> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
> >> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
> >> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
> >> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
> >> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
> >> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
> >> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
> >> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
> >> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
> >> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
> >> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 =
> c(1485907200,
> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> 1485907200,
> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> 1485907200,
> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> 1485907201,
> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> 1485907201,
> >> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
> >> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
> >> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204,
> 1485907204,
> >> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
> 1485907204,
> >> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205,
> 1485907205,
> >> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206,
> 1485907206,
> >> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
> >> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
> >> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208,
> 1485907208,
> >> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209,
> 1485907209,
> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
> 1485907209,
> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
> >> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
> >> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
> >> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
> >> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> 1485907209,
> >> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
> >> >
> >> > To tested your function I took the first message, which is located in
> the
> >> > 6th column and the 1st row, and did the following:
> >> >
> >> > library(stringi)
> >> > library(dplyr)
> >> > library(R.utils)
> >> > library(RANN)
> >> > library(NISTunits)
> >> > library(pracma)
> >> > library(celestial)
> >> > library(stringr)
> >> >
> >> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE,
> na="",
> >> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
> >> >
> >> > testmessage1 <- dat[1,6]
> >> >
> >> > ascii_datformat <- utf8ToInt(testmessage1)
> >> >
> >> > Base <- ascii_datformat - 48
> >> >
> >> > decy <- ifelse(Base > 40, Base - 8, Base)
> >> >
> >> > biny <- intToBin(decy)
> >> >
> >> > binyframe <- data.frame(biny)
> >> >
> >> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I
> have
> >> > the complete first message, all in binary format
> >> >
> >> > #according to the literature of AIS message decoding, longitude goes
> from
> >> > position 62 to position 89
> >> > #and latitude goes from position 90 to position 116
> >> >
> >> > longitude <- substr(tbinyframe, 62, 89)
> >> > latitude    <- substr(tbinyframe, 90, 116)
> >> >
> >> > #now I apply the function you provided me with:
> >> >
> >> >  fun <- function(x){
> >> >          res <- sapply(x, function(y){
> >> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> >> >              strtoi(y, base = 2)
> >> >             }else{
> >> >               y <- unlist(strsplit(y, ""))
> >> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
> >> >             }
> >> >           })
> >> >           unname(res)
> >> >       }
> >> >
> >> > > fun(longitude)
> >> > [1] 220663102
> >> > >
> >> > > fun(latitude)
> >> > [1] 5414823
> >> > >
> >> > > fun("1101001001110000110100111110")
> >> > [1] 220663102
> >> > >
> >> > > fun("000010100101001111110100111")
> >> > [1] 5414823
> >> > >
> >> > > fun("10110010")
> >> > [1] -78
> >> >
> >> > as you can see, the function only worked or showed expected result on
> the
> >> > last case with a -78, but in the other cases, it the results were not
> as
> >> > expected, maybe I am missing something here?
> >> >
> >> > Any help and/or guidance will be greatly appreciated,
> >> >
> >> > Best regards,
> >> >
> >> > Paul
> >> >
> >> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<
> ruipbarradas at sapo.pt>)
> >> > escribi?:
> >> >
> >> > > Hello,
> >> > >
> >> > > The function I included converts signed binary numbers into their
> >> > > decimal representation. They are negative if a) they are multiples
> of 8
> >> > > bits and b) the most significant bit is a "1". If not just convert
> to
> >> > > integer.
> >> > >
> >> > > As for a) above, I assume that you will have 8 bit numbers. And the
> >> > > conversion is done as follows:
> >> > >
> >> > > input: 10110010
> >> > >
> >> > > splitting, to make it more clear:
> >> > >
> >> > > 1 0 1 1 0 0 1 0 - input
> >> > > 0 1 0 0 1 1 0 1 - reversed
> >> > >                1 - add 1 to the number with reversed bits
> >> > > 0 1 0 0 1 1 1 0 - result is the two's complement
> >> > >
> >> > > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
> >> > >
> >> > > But the msb is "1" so it's -78
> >> > >
> >> > >
> >> > > This is what the function does, but instead of %*% it uses
> >> > >
> >> > > sum(two's compl * powers of two)
> >> > >
> >> > >
> >> > > Hope this helps,
> >> > >
> >> > > Rui Barradas
> >> > >
> >> > > The input must be a character string or character vector.
> >> > >
> >> > > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
> >> > > > Dear friend Rui,
> >> > > >
> >> > > > Hope you are doing great, thanks for your kind feedback. The
> challenge I
> >> > > > currently have at hand is to decode AIS messages and obtain
> latitude and
> >> > > > longitude values from those.
> >> > > >
> >> > > > So basically, I want to accomplish something like in the example
> below.
> >> > > > I want to convert this binary number (10110010) into the two?s
> >> > > > complement representation, there is the logic they are using for
> that.
> >> > > > Since longitude ranges from
> >> > > >
> >> > > >
> >> > > >       Example of conversion to decimal of a signed binary number
> in
> >> > > >       two's complement representation
> >> > > >
> >> > > > Let's convert to decimal the following signed binary number:
> 10110010
> >> > > >
> >> > > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20
> = -128
> >> > > > + 32 + 16 + 2 = -78.
> >> > > >
> >> > > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<
> ruipbarradas at sapo.pt
> >> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> >> > > >
> >> > > >     Sorry, missunderstood the problem.
> >> > > >     Here it goes:
> >> > > >
> >> > > >     fun <- function(x){
> >> > > >         res <- sapply(x, function(y){
> >> > > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> >> > > >             strtoi(y, base = 2)
> >> > > >           }else{
> >> > > >             y <- unlist(strsplit(y, ""))
> >> > > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
> >> > > >           }
> >> > > >         })
> >> > > >         unname(res)
> >> > > >     }
> >> > > >
> >> > > >     fun("10110010")
> >> > > >     fun("10000000")
> >> > > >     fun(c("01000000", "01111111", "10110010", "10000000"))
> >> > > >
> >> > > >
> >> > > >     Hope this helps,
> >> > > >
> >> > > >     Rui Barradas
> >> > > >
> >> > > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
> >> > > >      > Hello,
> >> > > >      >
> >> > > >      > Is this what you want?
> >> > > >      >
> >> > > >      >
> >> > > >      > x <- "10110010"
> >> > > >      > strtoi(x, base = 2)
> >> > > >      > #[1] 178
> >> > > >      >
> >> > > >      >
> >> > > >      > Hope this helps,
> >> > > >      >
> >> > > >      > Rui Barradas
> >> > > >      >
> >> > > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
> >> > > >      >> Dear friends,
> >> > > >      >>
> >> > > >      >> How can I convert the following binary number in two?s
> complement
> >> > > >      >> representation in R?
> >> > > >      >>
> >> > > >      >> 10110010
> >> > > >      >>
> >> > > >      >> Any help and/or guidance will be greatly appreciated,
> >> > > >      >>
> >> > > >      >> Best regards,
> >> > > >      >>
> >> > > >      >> Paul
> >> > > >      >>
> >> > > >      >>     [[alternative HTML version deleted]]
> >> > > >      >>
> >> > > >      >> ______________________________________________
> >> > > >      >> R-help at r-project.org <mailto:R-help at r-project.org>
> mailing list
> >> > > >     -- To UNSUBSCRIBE and more, see
> >> > > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > >      >> PLEASE do read the posting guide
> >> > > >      >> http://www.R-project.org/posting-guide.html
> >> > > >      >> and provide commented, minimal, self-contained,
> reproducible
> >> > > code.
> >> > > >      >>
> >> > > >      >
> >> > > >      > ______________________________________________
> >> > > >      > R-help at r-project.org <mailto:R-help at r-project.org>
> mailing list
> >> > > >     -- To UNSUBSCRIBE and more, see
> >> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > >      > PLEASE do read the posting guide
> >> > > >      > http://www.R-project.org/posting-guide.html
> >> > > >      > and provide commented, minimal, self-contained,
> reproducible code.
> >> > > >
> >> > >
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@her @end|ng |rom p|e@@th@n@com  Fri Jan 24 22:27:53 2020
From: ||@her @end|ng |rom p|e@@th@n@com (Dennis Fisher)
Date: Fri, 24 Jan 2020 13:27:53 -0800
Subject: [R] Did the output from summary(lm(...)) change
Message-ID: <7943CAC1-4463-4E1E-BF20-3674BD798FC4@plessthan.com>

R 3.6.1
OS X

Colleagues

My recollection (possibly wrong) is that:
	summary(lm(YVAR ~ XVAR))$p.value
used to return the P value for a linear regression.  It does not appear to do so now.  
Of note:
	summary(lm(YVAR ~ XVAR))
does report the P value.

I realize that I can access the P value from:
	summary(lm(YVAR ~ XVAR))$coeff
but I am curious as to whether my memory is flawed.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com <http://www.plessthan.com/>





	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Jan 24 23:39:41 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 24 Jan 2020 17:39:41 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
 <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
 <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>
Message-ID: <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>

I don't have my computer with me, so I am commenting right now on the
visual impression of the email.

The latitude shows 90, 88, ... 2, 89, ...
The labels are lexicographically ordered
-1, -10, -11,...

The latitude binrep look in correct order, and the labels looks like binary
in order.

These things are identified as factors, not as character.

Please ensure that character values are not misinterpreted as factor when
you construct your data frames.

The four columns do not look to be in consistent order with each other.
This in itself could cause trouble.

I will look more when I have my computer running R so I can follow the rest
of what you wrote.

Rich

On Fri, Jan 24, 2020 at 15:02 Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friend Richard,
>
> Thank you for your interest in helping me through this challenge. As
> requested, I am providing the two lat and long frames you suggested, plus
> the one single column I am trying to decode:
>
> LatitudeFrame:
>
> > dput(LatitudeFrame)
> structure(list(Latitude = structure(c(90L, 88L, 87L, 86L, 85L,
> 84L, 83L, 82L, 81L, 80L, 79L, 77L, 76L, 75L, 74L, 73L, 72L, 71L,
> 70L, 69L, 68L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L, 57L,
> 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 46L, 44L, 43L, 42L,
> 41L, 40L, 39L, 38L, 37L, 36L, 35L, 33L, 32L, 31L, 30L, 29L, 28L,
> 27L, 26L, 25L, 24L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L, 14L,
> 13L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 89L, 78L, 67L,
> 56L, 45L, 34L, 23L, 12L, 1L, 91L, 92L, 103L, 114L, 125L, 136L,
> 147L, 158L, 169L, 180L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
> 101L, 102L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
> 113L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
> 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 137L,
> 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 148L, 149L,
> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 159L, 160L, 161L,
> 162L, 163L, 164L, 165L, 166L, 167L, 168L, 170L, 171L, 172L, 173L,
> 174L, 175L, 176L, 177L, 178L, 179L, 181L), .Label = c("-1", "-10",
> "-11", "-12", "-13", "-14", "-15", "-16", "-17", "-18", "-19",
> "-2", "-20", "-21", "-22", "-23", "-24", "-25", "-26", "-27",
> "-28", "-29", "-3", "-30", "-31", "-32", "-33", "-34", "-35",
> "-36", "-37", "-38", "-39", "-4", "-40", "-41", "-42", "-43",
> "-44", "-45", "-46", "-47", "-48", "-49", "-5", "-50", "-51",
> "-52", "-53", "-54", "-55", "-56", "-57", "-58", "-59", "-6",
> "-60", "-61", "-62", "-63", "-64", "-65", "-66", "-67", "-68",
> "-69", "-7", "-70", "-71", "-72", "-73", "-74", "-75", "-76",
> "-77", "-78", "-79", "-8", "-80", "-81", "-82", "-83", "-84",
> "-85", "-86", "-87", "-88", "-89", "-9", "-90", "0", "1", "10",
> "11", "12", "13", "14", "15", "16", "17", "18", "19", "2", "20",
> "21", "22", "23", "24", "25", "26", "27", "28", "29", "3", "30",
> "31", "32", "33", "34", "35", "36", "37", "38", "39", "4", "40",
> "41", "42", "43", "44", "45", "46", "47", "48", "49", "5", "50",
> "51", "52", "53", "54", "55", "56", "57", "58", "59", "6", "60",
> "61", "62", "63", "64", "65", "66", "67", "68", "69", "7", "70",
> "71", "72", "73", "74", "75", "76", "77", "78", "79", "8", "80",
> "81", "82", "83", "84", "85", "86", "87", "88", "89", "9", "90"
> ), class = "factor"), LatitudeBinRep = structure(c(92L, 93L,
> 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L,
> 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L,
> 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L,
> 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L,
> 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
> 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L,
> 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
> 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L,
> 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L,
> 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
> 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L), .Label =
> c("0000000000000000000000000000000",
> "0000000000000000000000000000001", "0000000000000000000000000000010",
> "0000000000000000000000000000011", "0000000000000000000000000000100",
> "0000000000000000000000000000101", "0000000000000000000000000000110",
> "0000000000000000000000000000111", "0000000000000000000000000001000",
> "0000000000000000000000000001001", "0000000000000000000000000001010",
> "0000000000000000000000000001011", "0000000000000000000000000001100",
> "0000000000000000000000000001101", "0000000000000000000000000001110",
> "0000000000000000000000000001111", "0000000000000000000000000010000",
> "0000000000000000000000000010001", "0000000000000000000000000010010",
> "0000000000000000000000000010011", "0000000000000000000000000010100",
> "0000000000000000000000000010101", "0000000000000000000000000010110",
> "0000000000000000000000000010111", "0000000000000000000000000011000",
> "0000000000000000000000000011001", "0000000000000000000000000011010",
> "0000000000000000000000000011011", "0000000000000000000000000011100",
> "0000000000000000000000000011101", "0000000000000000000000000011110",
> "0000000000000000000000000011111", "0000000000000000000000000100000",
> "0000000000000000000000000100001", "0000000000000000000000000100010",
> "0000000000000000000000000100011", "0000000000000000000000000100100",
> "0000000000000000000000000100101", "0000000000000000000000000100110",
> "0000000000000000000000000100111", "0000000000000000000000000101000",
> "0000000000000000000000000101001", "0000000000000000000000000101010",
> "0000000000000000000000000101011", "0000000000000000000000000101100",
> "0000000000000000000000000101101", "0000000000000000000000000101110",
> "0000000000000000000000000101111", "0000000000000000000000000110000",
> "0000000000000000000000000110001", "0000000000000000000000000110010",
> "0000000000000000000000000110011", "0000000000000000000000000110100",
> "0000000000000000000000000110101", "0000000000000000000000000110110",
> "0000000000000000000000000110111", "0000000000000000000000000111000",
> "0000000000000000000000000111001", "0000000000000000000000000111010",
> "0000000000000000000000000111011", "0000000000000000000000000111100",
> "0000000000000000000000000111101", "0000000000000000000000000111110",
> "0000000000000000000000000111111", "0000000000000000000000001000000",
> "0000000000000000000000001000001", "0000000000000000000000001000010",
> "0000000000000000000000001000011", "0000000000000000000000001000100",
> "0000000000000000000000001000101", "0000000000000000000000001000110",
> "0000000000000000000000001000111", "0000000000000000000000001001000",
> "0000000000000000000000001001001", "0000000000000000000000001001010",
> "0000000000000000000000001001011", "0000000000000000000000001001100",
> "0000000000000000000000001001101", "0000000000000000000000001001110",
> "0000000000000000000000001001111", "0000000000000000000000001010000",
> "0000000000000000000000001010001", "0000000000000000000000001010010",
> "0000000000000000000000001010011", "0000000000000000000000001010100",
> "0000000000000000000000001010101", "0000000000000000000000001010110",
> "0000000000000000000000001010111", "0000000000000000000000001011000",
> "0000000000000000000000001011001", "0000000000000000000000001011010",
> "1111111111111111111111110100110", "1111111111111111111111110100111",
> "1111111111111111111111110101000", "1111111111111111111111110101001",
> "1111111111111111111111110101010", "1111111111111111111111110101011",
> "1111111111111111111111110101100", "1111111111111111111111110101101",
> "1111111111111111111111110101110", "1111111111111111111111110101111",
> "1111111111111111111111110110000", "1111111111111111111111110110001",
> "1111111111111111111111110110010", "1111111111111111111111110110011",
> "1111111111111111111111110110100", "1111111111111111111111110110101",
> "1111111111111111111111110110110", "1111111111111111111111110110111",
> "1111111111111111111111110111000", "1111111111111111111111110111001",
> "1111111111111111111111110111010", "1111111111111111111111110111011",
> "1111111111111111111111110111100", "1111111111111111111111110111101",
> "1111111111111111111111110111110", "1111111111111111111111110111111",
> "1111111111111111111111111000000", "1111111111111111111111111000001",
> "1111111111111111111111111000010", "1111111111111111111111111000011",
> "1111111111111111111111111000100", "1111111111111111111111111000101",
> "1111111111111111111111111000110", "1111111111111111111111111000111",
> "1111111111111111111111111001000", "1111111111111111111111111001001",
> "1111111111111111111111111001010", "1111111111111111111111111001011",
> "1111111111111111111111111001100", "1111111111111111111111111001101",
> "1111111111111111111111111001110", "1111111111111111111111111001111",
> "1111111111111111111111111010000", "1111111111111111111111111010001",
> "1111111111111111111111111010010", "1111111111111111111111111010011",
> "1111111111111111111111111010100", "1111111111111111111111111010101",
> "1111111111111111111111111010110", "1111111111111111111111111010111",
> "1111111111111111111111111011000", "1111111111111111111111111011001",
> "1111111111111111111111111011010", "1111111111111111111111111011011",
> "1111111111111111111111111011100", "1111111111111111111111111011101",
> "1111111111111111111111111011110", "1111111111111111111111111011111",
> "1111111111111111111111111100000", "1111111111111111111111111100001",
> "1111111111111111111111111100010", "1111111111111111111111111100011",
> "1111111111111111111111111100100", "1111111111111111111111111100101",
> "1111111111111111111111111100110", "1111111111111111111111111100111",
> "1111111111111111111111111101000", "1111111111111111111111111101001",
> "1111111111111111111111111101010", "1111111111111111111111111101011",
> "1111111111111111111111111101100", "1111111111111111111111111101101",
> "1111111111111111111111111101110", "1111111111111111111111111101111",
> "1111111111111111111111111110000", "1111111111111111111111111110001",
> "1111111111111111111111111110010", "1111111111111111111111111110011",
> "1111111111111111111111111110100", "1111111111111111111111111110101",
> "1111111111111111111111111110110", "1111111111111111111111111110111",
> "1111111111111111111111111111000", "1111111111111111111111111111001",
> "1111111111111111111111111111010", "1111111111111111111111111111011",
> "1111111111111111111111111111100", "1111111111111111111111111111101",
> "1111111111111111111111111111110", "1111111111111111111111111111111"
> ), class = "factor")), class = "data.frame", row.names = c(NA,
> -181L))
>
> LongitudeFrame:
>
> > dput(LongitudeFrame)
> structure(list(Longitude = structure(c(91L, 89L, 88L, 87L, 86L,
> 85L, 84L, 83L, 82L, 81L, 80L, 78L, 77L, 76L, 75L, 74L, 73L, 72L,
> 71L, 70L, 69L, 67L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L,
> 56L, 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 45L, 44L, 43L,
> 42L, 41L, 40L, 39L, 38L, 37L, 36L, 34L, 33L, 32L, 31L, 30L, 29L,
> 28L, 27L, 26L, 25L, 23L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L,
> 14L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 180L, 179L, 178L,
> 177L, 176L, 175L, 174L, 173L, 172L, 171L, 169L, 168L, 167L, 166L,
> 165L, 164L, 163L, 162L, 161L, 160L, 158L, 157L, 156L, 155L, 154L,
> 153L, 152L, 151L, 150L, 149L, 147L, 146L, 145L, 144L, 143L, 142L,
> 141L, 140L, 139L, 138L, 136L, 135L, 134L, 133L, 132L, 131L, 130L,
> 129L, 128L, 127L, 125L, 124L, 123L, 122L, 121L, 120L, 119L, 118L,
> 117L, 116L, 114L, 113L, 112L, 111L, 110L, 109L, 108L, 107L, 106L,
> 105L, 103L, 102L, 101L, 100L, 99L, 98L, 97L, 96L, 95L, 94L, 92L,
> 90L, 79L, 68L, 57L, 46L, 35L, 24L, 13L, 2L, 170L, 159L, 148L,
> 137L, 126L, 115L, 104L, 93L, 1L, 181L, 182L, 274L, 285L, 296L,
> 307L, 318L, 329L, 340L, 351L, 183L, 194L, 205L, 216L, 227L, 238L,
> 249L, 260L, 271L, 273L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
> 282L, 283L, 284L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L,
> 294L, 295L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 305L,
> 306L, 308L, 309L, 310L, 311L, 312L, 313L, 314L, 315L, 316L, 317L,
> 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 330L,
> 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 341L, 342L,
> 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L,
> 355L, 356L, 357L, 358L, 359L, 360L, 361L, 184L, 185L, 186L, 187L,
> 188L, 189L, 190L, 191L, 192L, 193L, 195L, 196L, 197L, 198L, 199L,
> 200L, 201L, 202L, 203L, 204L, 206L, 207L, 208L, 209L, 210L, 211L,
> 212L, 213L, 214L, 215L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
> 224L, 225L, 226L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
> 236L, 237L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
> 248L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
> 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L, 272L
> ), .Label = c("-1", "-10", "-100", "-101", "-102", "-103", "-104",
> "-105", "-106", "-107", "-108", "-109", "-11", "-110", "-111",
> "-112", "-113", "-114", "-115", "-116", "-117", "-118", "-119",
> "-12", "-120", "-121", "-122", "-123", "-124", "-125", "-126",
> "-127", "-128", "-129", "-13", "-130", "-131", "-132", "-133",
> "-134", "-135", "-136", "-137", "-138", "-139", "-14", "-140",
> "-141", "-142", "-143", "-144", "-145", "-146", "-147", "-148",
> "-149", "-15", "-150", "-151", "-152", "-153", "-154", "-155",
> "-156", "-157", "-158", "-159", "-16", "-160", "-161", "-162",
> "-163", "-164", "-165", "-166", "-167", "-168", "-169", "-17",
> "-170", "-171", "-172", "-173", "-174", "-175", "-176", "-177",
> "-178", "-179", "-18", "-180", "-19", "-2", "-20", "-21", "-22",
> "-23", "-24", "-25", "-26", "-27", "-28", "-29", "-3", "-30",
> "-31", "-32", "-33", "-34", "-35", "-36", "-37", "-38", "-39",
> "-4", "-40", "-41", "-42", "-43", "-44", "-45", "-46", "-47",
> "-48", "-49", "-5", "-50", "-51", "-52", "-53", "-54", "-55",
> "-56", "-57", "-58", "-59", "-6", "-60", "-61", "-62", "-63",
> "-64", "-65", "-66", "-67", "-68", "-69", "-7", "-70", "-71",
> "-72", "-73", "-74", "-75", "-76", "-77", "-78", "-79", "-8",
> "-80", "-81", "-82", "-83", "-84", "-85", "-86", "-87", "-88",
> "-89", "-9", "-90", "-91", "-92", "-93", "-94", "-95", "-96",
> "-97", "-98", "-99", "0", "1", "10", "100", "101", "102", "103",
> "104", "105", "106", "107", "108", "109", "11", "110", "111",
> "112", "113", "114", "115", "116", "117", "118", "119", "12",
> "120", "121", "122", "123", "124", "125", "126", "127", "128",
> "129", "13", "130", "131", "132", "133", "134", "135", "136",
> "137", "138", "139", "14", "140", "141", "142", "143", "144",
> "145", "146", "147", "148", "149", "15", "150", "151", "152",
> "153", "154", "155", "156", "157", "158", "159", "16", "160",
> "161", "162", "163", "164", "165", "166", "167", "168", "169",
> "17", "170", "171", "172", "173", "174", "175", "176", "177",
> "178", "179", "18", "180", "19", "2", "20", "21", "22", "23",
> "24", "25", "26", "27", "28", "29", "3", "30", "31", "32", "33",
> "34", "35", "36", "37", "38", "39", "4", "40", "41", "42", "43",
> "44", "45", "46", "47", "48", "49", "5", "50", "51", "52", "53",
> "54", "55", "56", "57", "58", "59", "6", "60", "61", "62", "63",
> "64", "65", "66", "67", "68", "69", "7", "70", "71", "72", "73",
> "74", "75", "76", "77", "78", "79", "8", "80", "81", "82", "83",
> "84", "85", "86", "87", "88", "89", "9", "90", "91", "92", "93",
> "94", "95", "96", "97", "98", "99"), class = "factor"), LongitudeBinRep =
> structure(c(182L,
> 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 193L,
> 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L,
> 205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
> 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L,
> 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L, 236L, 237L,
> 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L, 248L,
> 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
> 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L,
> 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
> 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L,
> 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L,
> 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,
> 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L,
> 326L, 327L, 328L, 329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L,
> 337L, 338L, 339L, 340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L,
> 348L, 349L, 350L, 351L, 352L, 353L, 354L, 355L, 356L, 357L, 358L,
> 359L, 360L, 361L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
> 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L,
> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L,
> 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
> 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
> 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L,
> 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
> 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L,
> 124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L,
> 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
> 146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L,
> 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L,
> 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
> 179L, 180L, 181L), .Label = c("0000000000000000000000000000000",
> "0000000000000000000000000000001", "0000000000000000000000000000010",
> "0000000000000000000000000000011", "0000000000000000000000000000100",
> "0000000000000000000000000000101", "0000000000000000000000000000110",
> "0000000000000000000000000000111", "0000000000000000000000000001000",
> "0000000000000000000000000001001", "0000000000000000000000000001010",
> "0000000000000000000000000001011", "0000000000000000000000000001100",
> "0000000000000000000000000001101", "0000000000000000000000000001110",
> "0000000000000000000000000001111", "0000000000000000000000000010000",
> "0000000000000000000000000010001", "0000000000000000000000000010010",
> "0000000000000000000000000010011", "0000000000000000000000000010100",
> "0000000000000000000000000010101", "0000000000000000000000000010110",
> "0000000000000000000000000010111", "0000000000000000000000000011000",
> "0000000000000000000000000011001", "0000000000000000000000000011010",
> "0000000000000000000000000011011", "0000000000000000000000000011100",
> "0000000000000000000000000011101", "0000000000000000000000000011110",
> "0000000000000000000000000011111", "0000000000000000000000000100000",
> "0000000000000000000000000100001", "0000000000000000000000000100010",
> "0000000000000000000000000100011", "0000000000000000000000000100100",
> "0000000000000000000000000100101", "0000000000000000000000000100110",
> "0000000000000000000000000100111", "0000000000000000000000000101000",
> "0000000000000000000000000101001", "0000000000000000000000000101010",
> "0000000000000000000000000101011", "0000000000000000000000000101100",
> "0000000000000000000000000101101", "0000000000000000000000000101110",
> "0000000000000000000000000101111", "0000000000000000000000000110000",
> "0000000000000000000000000110001", "0000000000000000000000000110010",
> "0000000000000000000000000110011", "0000000000000000000000000110100",
> "0000000000000000000000000110101", "0000000000000000000000000110110",
> "0000000000000000000000000110111", "0000000000000000000000000111000",
> "0000000000000000000000000111001", "0000000000000000000000000111010",
> "0000000000000000000000000111011", "0000000000000000000000000111100",
> "0000000000000000000000000111101", "0000000000000000000000000111110",
> "0000000000000000000000000111111", "0000000000000000000000001000000",
> "0000000000000000000000001000001", "0000000000000000000000001000010",
> "0000000000000000000000001000011", "0000000000000000000000001000100",
> "0000000000000000000000001000101", "0000000000000000000000001000110",
> "0000000000000000000000001000111", "0000000000000000000000001001000",
> "0000000000000000000000001001001", "0000000000000000000000001001010",
> "0000000000000000000000001001011", "0000000000000000000000001001100",
> "0000000000000000000000001001101", "0000000000000000000000001001110",
> "0000000000000000000000001001111", "0000000000000000000000001010000",
> "0000000000000000000000001010001", "0000000000000000000000001010010",
> "0000000000000000000000001010011", "0000000000000000000000001010100",
> "0000000000000000000000001010101", "0000000000000000000000001010110",
> "0000000000000000000000001010111", "0000000000000000000000001011000",
> "0000000000000000000000001011001", "0000000000000000000000001011010",
> "0000000000000000000000001011011", "0000000000000000000000001011100",
> "0000000000000000000000001011101", "0000000000000000000000001011110",
> "0000000000000000000000001011111", "0000000000000000000000001100000",
> "0000000000000000000000001100001", "0000000000000000000000001100010",
> "0000000000000000000000001100011", "0000000000000000000000001100100",
> "0000000000000000000000001100101", "0000000000000000000000001100110",
> "0000000000000000000000001100111", "0000000000000000000000001101000",
> "0000000000000000000000001101001", "0000000000000000000000001101010",
> "0000000000000000000000001101011", "0000000000000000000000001101100",
> "0000000000000000000000001101101", "0000000000000000000000001101110",
> "0000000000000000000000001101111", "0000000000000000000000001110000",
> "0000000000000000000000001110001", "0000000000000000000000001110010",
> "0000000000000000000000001110011", "0000000000000000000000001110100",
> "0000000000000000000000001110101", "0000000000000000000000001110110",
> "0000000000000000000000001110111", "0000000000000000000000001111000",
> "0000000000000000000000001111001", "0000000000000000000000001111010",
> "0000000000000000000000001111011", "0000000000000000000000001111100",
> "0000000000000000000000001111101", "0000000000000000000000001111110",
> "0000000000000000000000001111111", "0000000000000000000000010000000",
> "0000000000000000000000010000001", "0000000000000000000000010000010",
> "0000000000000000000000010000011", "0000000000000000000000010000100",
> "0000000000000000000000010000101", "0000000000000000000000010000110",
> "0000000000000000000000010000111", "0000000000000000000000010001000",
> "0000000000000000000000010001001", "0000000000000000000000010001010",
> "0000000000000000000000010001011", "0000000000000000000000010001100",
> "0000000000000000000000010001101", "0000000000000000000000010001110",
> "0000000000000000000000010001111", "0000000000000000000000010010000",
> "0000000000000000000000010010001", "0000000000000000000000010010010",
> "0000000000000000000000010010011", "0000000000000000000000010010100",
> "0000000000000000000000010010101", "0000000000000000000000010010110",
> "0000000000000000000000010010111", "0000000000000000000000010011000",
> "0000000000000000000000010011001", "0000000000000000000000010011010",
> "0000000000000000000000010011011", "0000000000000000000000010011100",
> "0000000000000000000000010011101", "0000000000000000000000010011110",
> "0000000000000000000000010011111", "0000000000000000000000010100000",
> "0000000000000000000000010100001", "0000000000000000000000010100010",
> "0000000000000000000000010100011", "0000000000000000000000010100100",
> "0000000000000000000000010100101", "0000000000000000000000010100110",
> "0000000000000000000000010100111", "0000000000000000000000010101000",
> "0000000000000000000000010101001", "0000000000000000000000010101010",
> "0000000000000000000000010101011", "0000000000000000000000010101100",
> "0000000000000000000000010101101", "0000000000000000000000010101110",
> "0000000000000000000000010101111", "0000000000000000000000010110000",
> "0000000000000000000000010110001", "0000000000000000000000010110010",
> "0000000000000000000000010110011", "0000000000000000000000010110100",
> "1111111111111111111111101001100", "1111111111111111111111101001101",
> "1111111111111111111111101001110", "1111111111111111111111101001111",
> "1111111111111111111111101010000", "1111111111111111111111101010001",
> "1111111111111111111111101010010", "1111111111111111111111101010011",
> "1111111111111111111111101010100", "1111111111111111111111101010101",
> "1111111111111111111111101010110", "1111111111111111111111101010111",
> "1111111111111111111111101011000", "1111111111111111111111101011001",
> "1111111111111111111111101011010", "1111111111111111111111101011011",
> "1111111111111111111111101011100", "1111111111111111111111101011101",
> "1111111111111111111111101011110", "1111111111111111111111101011111",
> "1111111111111111111111101100000", "1111111111111111111111101100001",
> "1111111111111111111111101100010", "1111111111111111111111101100011",
> "1111111111111111111111101100100", "1111111111111111111111101100101",
> "1111111111111111111111101100110", "1111111111111111111111101100111",
> "1111111111111111111111101101000", "1111111111111111111111101101001",
> "1111111111111111111111101101010", "1111111111111111111111101101011",
> "1111111111111111111111101101100", "1111111111111111111111101101101",
> "1111111111111111111111101101110", "1111111111111111111111101101111",
> "1111111111111111111111101110000", "1111111111111111111111101110001",
> "1111111111111111111111101110010", "1111111111111111111111101110011",
> "1111111111111111111111101110100", "1111111111111111111111101110101",
> "1111111111111111111111101110110", "1111111111111111111111101110111",
> "1111111111111111111111101111000", "1111111111111111111111101111001",
> "1111111111111111111111101111010", "1111111111111111111111101111011",
> "1111111111111111111111101111100", "1111111111111111111111101111101",
> "1111111111111111111111101111110", "1111111111111111111111101111111",
> "1111111111111111111111110000000", "1111111111111111111111110000001",
> "1111111111111111111111110000010", "1111111111111111111111110000011",
> "1111111111111111111111110000100", "1111111111111111111111110000101",
> "1111111111111111111111110000110", "1111111111111111111111110000111",
> "1111111111111111111111110001000", "1111111111111111111111110001001",
> "1111111111111111111111110001010", "1111111111111111111111110001011",
> "1111111111111111111111110001100", "1111111111111111111111110001101",
> "1111111111111111111111110001110", "1111111111111111111111110001111",
> "1111111111111111111111110010000", "1111111111111111111111110010001",
> "1111111111111111111111110010010", "1111111111111111111111110010011",
> "1111111111111111111111110010100", "1111111111111111111111110010101",
> "1111111111111111111111110010110", "1111111111111111111111110010111",
> "1111111111111111111111110011000", "1111111111111111111111110011001",
> "1111111111111111111111110011010", "1111111111111111111111110011011",
> "1111111111111111111111110011100", "1111111111111111111111110011101",
> "1111111111111111111111110011110", "1111111111111111111111110011111",
> "1111111111111111111111110100000", "1111111111111111111111110100001",
> "1111111111111111111111110100010", "1111111111111111111111110100011",
> "1111111111111111111111110100100", "1111111111111111111111110100101",
> "1111111111111111111111110100110", "1111111111111111111111110100111",
> "1111111111111111111111110101000", "1111111111111111111111110101001",
> "1111111111111111111111110101010", "1111111111111111111111110101011",
> "1111111111111111111111110101100", "1111111111111111111111110101101",
> "1111111111111111111111110101110", "1111111111111111111111110101111",
> "1111111111111111111111110110000", "1111111111111111111111110110001",
> "1111111111111111111111110110010", "1111111111111111111111110110011",
> "1111111111111111111111110110100", "1111111111111111111111110110101",
> "1111111111111111111111110110110", "1111111111111111111111110110111",
> "1111111111111111111111110111000", "1111111111111111111111110111001",
> "1111111111111111111111110111010", "1111111111111111111111110111011",
> "1111111111111111111111110111100", "1111111111111111111111110111101",
> "1111111111111111111111110111110", "1111111111111111111111110111111",
> "1111111111111111111111111000000", "1111111111111111111111111000001",
> "1111111111111111111111111000010", "1111111111111111111111111000011",
> "1111111111111111111111111000100", "1111111111111111111111111000101",
> "1111111111111111111111111000110", "1111111111111111111111111000111",
> "1111111111111111111111111001000", "1111111111111111111111111001001",
> "1111111111111111111111111001010", "1111111111111111111111111001011",
> "1111111111111111111111111001100", "1111111111111111111111111001101",
> "1111111111111111111111111001110", "1111111111111111111111111001111",
> "1111111111111111111111111010000", "1111111111111111111111111010001",
> "1111111111111111111111111010010", "1111111111111111111111111010011",
> "1111111111111111111111111010100", "1111111111111111111111111010101",
> "1111111111111111111111111010110", "1111111111111111111111111010111",
> "1111111111111111111111111011000", "1111111111111111111111111011001",
> "1111111111111111111111111011010", "1111111111111111111111111011011",
> "1111111111111111111111111011100", "1111111111111111111111111011101",
> "1111111111111111111111111011110", "1111111111111111111111111011111",
> "1111111111111111111111111100000", "1111111111111111111111111100001",
> "1111111111111111111111111100010", "1111111111111111111111111100011",
> "1111111111111111111111111100100", "1111111111111111111111111100101",
> "1111111111111111111111111100110", "1111111111111111111111111100111",
> "1111111111111111111111111101000", "1111111111111111111111111101001",
> "1111111111111111111111111101010", "1111111111111111111111111101011",
> "1111111111111111111111111101100", "1111111111111111111111111101101",
> "1111111111111111111111111101110", "1111111111111111111111111101111",
> "1111111111111111111111111110000", "1111111111111111111111111110001",
> "1111111111111111111111111110010", "1111111111111111111111111110011",
> "1111111111111111111111111110100", "1111111111111111111111111110101",
> "1111111111111111111111111110110", "1111111111111111111111111110111",
> "1111111111111111111111111111000", "1111111111111111111111111111001",
> "1111111111111111111111111111010", "1111111111111111111111111111011",
> "1111111111111111111111111111100", "1111111111111111111111111111101",
> "1111111111111111111111111111110", "1111111111111111111111111111111"
> ), class = "factor")), class = "data.frame", row.names = c(NA,
> -361L))
>
> AISMessageFrame (Raw Messages as they come from the AIS device):
>
> > dput(AISMessageFrame)
> structure(list(MessgeCode = structure(c(17L, 6L, 93L, 92L, 81L,
> 24L, 4L, 44L, 21L, 43L, 66L, 64L, 94L, 46L, 26L, 82L, 12L, 9L,
> 67L, 63L, 65L, 39L, 48L, 38L, 79L, 83L, 37L, 73L, 23L, 68L, 59L,
> NA, 5L, 30L, 62L, 84L, 60L, 22L, 52L, 61L, 50L, 70L, 96L, 85L,
> 33L, 51L, 8L, 16L, 19L, 71L, 76L, 86L, 34L, 25L, 14L, 53L, 10L,
> 29L, 2L, 77L, 57L, 87L, 72L, 54L, 55L, 36L, 1L, 13L, NA, 78L,
> 58L, 15L, 89L, 35L, 20L, 3L, 49L, 56L, 90L, 40L, 45L, 41L, 42L,
> 74L, 95L, 32L, 91L, 27L, 69L, 76L, 18L, 31L, 11L, 80L, 75L, 7L,
> 72L, 88L, 28L, 47L), .Label = c("1:u0KOh001rCq5P529qqubqh2 at 3n",
> "100000?P00JCkt:583J=r?v:283Q", "10007NgP00rCQGV5:Pa=?gv>2<1H",
> "1000Fo at P01rCuG<56bnkN?v004`0", "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
> "1349B:3000rCtrn553aR at JH02PRp", "1349B:3000rCtrn553aR at JHD2d4O",
> "137g`F8007rCaIj59Tc5Dl at 800SN", "139NL4000LrCc8j59FEED4 at 000S<",
> "13M at Hk00jSJD@RD4s=qG1mT80 at 3J", "13P;K8 at 001rCfgr58=f;QbFD2D4G",
> "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "13P>4mhw1CrCi5H57aK5WlN>0<4F",
> "14aMBf000wrCKKN5:sdU0Sv<083C", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
> "15?7P`0P00rD1S453KSlj?v824`0", "15?f5H?P00rCQat5:Oah0?wn2 at S6",
> "15?lSL?P00JCQWD5:OpP0?vB24`0", "15?mqH?P00rCek458rkEN?v:00S4",
> "15 at EA<0P01JCo8l53=BFgwv at 0D47", "15 at eD@8000rC`bl59kW`mFn004`0",
> "15>nNj0000rCT<@5::qUpkt604`0", "15>uP00P00rC`U:59im;H?v22 at 1D",
> "15A at av3P00rClHn53<I8M?v02<2B", "15AIw`0P0GrCcO859DO5Ogv:0T`0",
> "15Aq00?P00rC`a`59mFeogv004`0", "15ATk20000rCnrv53N6;gPr>085R",
> "15B3Sj0000rC9RD5=mOh40jB20SU", "15BI>P0001rCgUD58DRalRj:00S5",
> "15BkV00P00rCQBf5:Q5JQOv42D1o", "15BW=20P00JCrvH54t=an?vB00Sg",
> "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "15De7F?P00JCr5r5517v4?v80h2P",
> "15E:BR0P00rCgaT58DdJUwv82H34", "15E:N at 0000rCgOd57p45bW><0<2H",
> "15E=m60000rC`W459k28Wnd:083h", "15E=q08P00JCrnR52cb>4?v200Sw",
> "15PoOh0001rCgbt58CwUaBD004`0", "15PvE at 0002rCi7R57pokCT:424`0",
> "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:",
> "15QDCP0P?w<tSF0l4Q@>4?wp0D1G", "15QIK`0P00rC`Sb59jFUUgv02<1g",
> "15QK900001JCq=d54l?5J0op0l4e", "15QtF00000rCafD59P?VJ9p<0H52",
> "15TGcJ0002rD<>p55FgmI at Ul0H0S", "15TgVb0000rCgVb57oFc;ARF2 at 67",
> "15TgVb0000rCgVd57oFc31R42L46", "15TILd?P00JCm4l53`D>4?v>0L1m",
> "15U?B00000rCgb>58DFJfRl620RT", "15U at cn0000rCgU>57oPLGiT:2D4D",
> "15UHOn9P00rCQ`D5:OcTkgv80<4:", "1819?@H001rC9TB5=bppM9<82D0T",
> "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
> "19NSG<h003rCi@:57pmUkAB<0<1v", "1gu00CLLwfh2 at Asw9@1<",
> "1gu103LLwfl1 at Asw9P1<",
> "3", "34`odN1000rD1V2537=dfPJ60000", "35A=Rh1001rD;s454vSTuP`40000",
> "35QN<D1000rCr5l53esbgPR20000", "39NS at m11@1rCrb:53:E<v0j3R000",
> "403Iu6Qv4PU00rCk0d57rwW00<2g", "403Iu6Qv4PU01rCk0d57rwW00<2g",
> "403Iupiv4PU00rC9065>=fW00H0I", "403Iupiv4PU00rC9065>=fW00H0j",
> "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
> "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G@W9K4Oi0D at PC0ShK40C",
> "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
> "7933.8835099999997", "7933.8836099999999",
> "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
> "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "88888888880",
> "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
> "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
> "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T",
> "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
> "B;s at N9h00>TtPEQAslh03wuUwP06", "B;s at N9h00>TtPF1Asll03wP5wP06",
> "B;s at N9h00>TtPF1Asll03wPUwP06", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
> "B;s at N9h00>TtPFQAslt03wQUwP06", "B;s at N9h00>TtPFQAslt03wR5wP06",
> "B;s at N9h00>TtPFQAsm003wRUwP06", "B;s at N9h00>TtPFQAsm803wU5wP06",
> "B;s at N9h00>TtPG1Asm403wSUwP06", "B;s at N9h00>TtPG1Asm403wT5wP06",
> "B;s at N9h00>TtPG1Asm803wTUwP06", "D03Iu6QGLN01MdN01StN000",
> "D03Iuph1TNfp4dv9J<`N000",
> "H5?AU:4U653hhhi8 at lkihP000000",
> "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
> "PC at H8888880"), class = "factor")), class = "data.frame", row.names =
> c(NA,
> -100L))
>
> Each one of those weird codes given in the AISMessageFrame correspond to
> an AIS message, there is a lot of information provided here, but I am only
> concerned with the Latitude and Longitude values (degrees with minutes). In
> order to accomplish this, each one of those wierd codes need to be
> converted to binary strings, once converted to binary strings. As I
> mentioned before, the information regarding latitude and longitude can be
> extracted from the following positions (again, after converting code to
> binary strings):
> Latitude = positions 90 to 116 inclusive (assuming you count the bits from
> left to right, with the first one having position number 1)
> Longitude = positions 62 to 89 inclusive (assuming you count the bits from
> left to right withe the first one having position number 1)
>
> In the sample code I provided in previous emails, I used the following to
> obtain the Latitude and Longitude:
>
> library(stringi)
> library(dplyr)
> library(R.utils)
> library(RANN)
> library(NISTunits)
> library(pracma)
> library(celestial)
> library(stringr)
>
> #here I show the sample to decode a single record, though that needs to be
> done for all AIS messages, so obviously a loop will be needed for that:
>
> ascii_datformat <- utf8ToInt(dataset1[1,6]) #turning the first AIS message
> as it comes to ascii number
> Base <- ascii_datformat - 48    #transformation from ascii to decimal
> decy <- ifelse(Base > 40, Base-8, Base) #transformation from ascii to
> decimal continued
> biny <- intToBin(decy)  #transformation from decimal to binary
> representation
> binyframe <- data.frame(biny)
> tbinyframe <- paste(t(binyframe[,1]), collapse="") #simply transposing the
> results
>
> tbinyframe will give you something like this (for each row having an AIS
> message)
> > tbinyframe
> [1]
> "000001000101001111101110000101011000001111100000000000000000111010010011100001101001111100000101001010011111101001110000000000001111111111110110000010010000100011000110"
>
> Latitude <- substr(tbinyframe, 90, 116)
> Longitude <- substr(tbinyframe, 62, 89)
>
> What I need is to decode thos latitude and longitude values , to get
> results in a -90 to +90 range for latitude, and in the -180 to +180 range
> for longitude.
>
> Hopefully I?ve made myself sufficiently clear this time and/or hopefully I
> understood your point correctly and provided you what you need.
>
> Again, thank you so much for your time and valuable support brother!
>
> Best regards,
>
> Paul
>
> El vie., 24 ene. 2020 a las 14:09, Richard M. Heiberger (<rmh at temple.edu>)
> escribi?:
>
>> now I am even more puzzled.
>>
>> please complete the following two data.frames and send it to the list.
>>
>> latDegrees lat2Comp
>> -90 xxxxxxxx
>> -89 xxxxxxxx
>> ...
>> -1 xxxxxxxx
>> 0 xxxxxxxx
>> 1 xxxxxxxx
>> ...
>> 89 xxxxxxxx
>> 90 xxxxxxxx
>>
>> lonDegrees lon2Comp
>> -180 xxxxxxxx
>> -179 xxxxxxxx
>> ...
>> -91 xxxxxxxx
>> -90 xxxxxxxx
>> -89 xxxxxxxx
>> ...
>> -1 xxxxxxxx
>> 0 xxxxxxxx
>> 1 xxxxxxxx
>> ...
>> 89 xxxxxxxx
>> 90 xxxxxxxx
>> 91 xxxxxxxx
>> ...
>> 179 xxxxxxxx
>> 180 xxxxxxxx
>>
>> Your 8 bit 2C example has 7 digits of precision plus sign which gives
>> a range of (-127,127).  That suffices for latitude (-90,90).
>> For longitude you will need 9 bits of twos complement for 8 bits of
>> precision plus sign to cover (-255,255), thus more than enough for
>> (-180,180).
>> This assumes that precision to the degree is sufficient.  If you need
>> precision to minutes and seconds, or to meters, then you
>> will need even more bits in 2C.
>>
>> Since it looks like you need a different number of bits for each
>> variable, I am asking for two data.frames.
>>
>> Rich
>>
>> On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> >
>> > Hi Richard,
>> >
>> > That was just an example, to show that, for that particular string of
>> binary numbers, the code works as expected. That is absolutely no related
>> to the dataset I provided. If I try the function on the dataset, I get
>> values well over the latitude and longitude boundaries (which should range
>> from -90 to + 90, and -180 to +180).
>> >
>> > Regards,
>> >
>> > Paul
>> >
>> > El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<
>> rmh at temple.edu>) escribi?:
>> >>
>> >> You show the example
>> >>
>> >> > fun("10110010")
>> >> [1] -78
>> >>
>> >> as satisfactory.  Where in your posted data set do you find the input
>> >> string "10110010"?
>> >>
>> >> Please post a set of relevant input strings, and the answers you want
>> from them.
>> >> The rest of the columns are not helpful for this specific exercise.
>> >>
>> >> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> >> >
>> >> > Dear friend Rui,
>> >> >
>> >> > Hope you are doing great. Firstly, I want to thank you for your super
>> >> > valuable and kind support of always. As I mentioned in earlier
>> e-mails, I
>> >> > am trying to decode AIS type messages, and the only ones I am having
>> a real
>> >> > hard time with, is with latitude and longitude.
>> >> >
>> >> > I tried the function you provided me in one of your replies, and it
>> works
>> >> > well with the examples  you provided, but in other cases it doesn?t.
>> >> >
>> >> > The messages I am trying to decode are in the 6th column of the
>> data. I
>> >> > will provide you with a small sample first, and then the complete
>> dataset
>> >> > (which has 100 rows). This is the small sample:
>> >> >
>> >> > > head(dat)
>> >> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7
>>  ...8
>> >> > ...9 ...10 ...11 ...12 ...13
>> >> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54
>> 1485907200
>> >> > <NA>    NA    NA    NA  <NA>
>> >> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39
>> 1485907200
>> >> > <NA>    NA    NA    NA  <NA>
>> >> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D
>> 1485907200
>> >> > <NA>    NA    NA    NA  <NA>
>> >> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43
>> 1485907200
>> >> > <NA>    NA    NA    NA  <NA>
>> >> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29
>> 1485907200
>> >> > <NA>    NA    NA    NA  <NA>
>> >> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D
>> 1485907200
>> >> > <NA>    NA    NA    NA  <NA>
>> >> >
>> >> > It is worth mentioning that each row of the 6th column provides
>> several
>> >> > information about maritime vessels, like speed over ground, latitude,
>> >> > longitude, vessel ID, etc. I am only concerned with latitude and
>> longitude
>> >> > since those are the only two fields I have not been able to decode
>> >> > successfully. Also, I am working on R version 3.6.2 for windows
>> 64-bit OS.
>> >> >
>> >> > The messages to decode are of the following format:
>> >> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
>> >> >
>> >> > Now, here is the complete dataset:
>> >> >
>> >> > > dput(dat)
>> >> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
>> >> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> >> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
>> >> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
>> >> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
>> >> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
>> >> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
>> >> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
>> >> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
>> >> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
>> >> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
>> >> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
>> >> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
>> >> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
>> >> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
>> >> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
>> >> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
>> >> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B",
>> "3.2999999999999998",
>> >> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
>> >> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
>> >> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
>> >> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
>> >> > "D03Iu6QGLN01MdN01StN000",
>> >> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
>> >> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
>> >> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>> >> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
>> >> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
>> >> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
>> >> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
>> >> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
>> >> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
>> >> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
>> >> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00
>> >TtPF1Asll03wPUwP06",
>> >> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
>> >> > "15>uP00P00rC`U:59im;H?v22 at 1D",
>> >> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>> >> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
>> "15BkV00P00rCQBf5:Q5JQOv42D1o",
>> >> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>> >> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
>> >> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
>> >> > "15U?B00000rCgb>58DFJfRl620RT",
>> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
>> >> > @W9K4Oi0D at PC0ShK40C",
>> >> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
>> >> > "15De7F?P00JCr5r5517v4?v80h2P",
>> >> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
>> >> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
>> >> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>> >> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
>> >> > "15E:BR0P00rCgaT58DdJUwv82H34",
>> >> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
>> >> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
>> >> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
>> >> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>> >> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
>> >> > "7933.8835099999997",
>> >> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>> >> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
>> >> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
>> >> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>> >> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>> >> > "B;s at N9h00>TtPG1Asm403wSUwP06",
>> >> >
>> >> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
>> >> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
>> >> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
>> >> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
>> >> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
>> >> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>> >> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>> >> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
>> >> > "15ATk20000rCnrv53N6;gPr>085R",
>> >> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>> >> >
>> >> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
>> >> > "15BW=20P00JCrvH54t=an?vB00Sg",
>> >> > "13P;K8 at 001rCfgr58=f;QbFD2D4G",
>> "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>> >> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0",
>> "1349B:3000rCtrn553aR at JHD2d4O",
>> >> >
>> >> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
>> >> > "15B3Sj0000rC9RD5=mOh40jB20SU",
>> >> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
>> >> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
>> >> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
>> >> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
>> >> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
>> >> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
>> >> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
>> >> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
>> >> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
>> >> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
>> >> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
>> >> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
>> >> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 =
>> c(1485907200,
>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>> 1485907200,
>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>> 1485907200,
>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>> 1485907201,
>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>> 1485907201,
>> >> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
>> >> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
>> >> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204,
>> 1485907204,
>> >> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
>> 1485907204,
>> >> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205,
>> 1485907205,
>> >> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206,
>> 1485907206,
>> >> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
>> >> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
>> >> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208,
>> 1485907208,
>> >> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209,
>> 1485907209,
>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
>> 1485907209,
>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
>> >> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
>> >> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
>> >> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
>> >> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> 1485907209,
>> >> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
>> >> >
>> >> > To tested your function I took the first message, which is located
>> in the
>> >> > 6th column and the 1st row, and did the following:
>> >> >
>> >> > library(stringi)
>> >> > library(dplyr)
>> >> > library(R.utils)
>> >> > library(RANN)
>> >> > library(NISTunits)
>> >> > library(pracma)
>> >> > library(celestial)
>> >> > library(stringr)
>> >> >
>> >> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE,
>> na="",
>> >> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
>> >> >
>> >> > testmessage1 <- dat[1,6]
>> >> >
>> >> > ascii_datformat <- utf8ToInt(testmessage1)
>> >> >
>> >> > Base <- ascii_datformat - 48
>> >> >
>> >> > decy <- ifelse(Base > 40, Base - 8, Base)
>> >> >
>> >> > biny <- intToBin(decy)
>> >> >
>> >> > binyframe <- data.frame(biny)
>> >> >
>> >> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point,
>> I have
>> >> > the complete first message, all in binary format
>> >> >
>> >> > #according to the literature of AIS message decoding, longitude goes
>> from
>> >> > position 62 to position 89
>> >> > #and latitude goes from position 90 to position 116
>> >> >
>> >> > longitude <- substr(tbinyframe, 62, 89)
>> >> > latitude    <- substr(tbinyframe, 90, 116)
>> >> >
>> >> > #now I apply the function you provided me with:
>> >> >
>> >> >  fun <- function(x){
>> >> >          res <- sapply(x, function(y){
>> >> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>> >> >              strtoi(y, base = 2)
>> >> >             }else{
>> >> >               y <- unlist(strsplit(y, ""))
>> >> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
>> >> >             }
>> >> >           })
>> >> >           unname(res)
>> >> >       }
>> >> >
>> >> > > fun(longitude)
>> >> > [1] 220663102
>> >> > >
>> >> > > fun(latitude)
>> >> > [1] 5414823
>> >> > >
>> >> > > fun("1101001001110000110100111110")
>> >> > [1] 220663102
>> >> > >
>> >> > > fun("000010100101001111110100111")
>> >> > [1] 5414823
>> >> > >
>> >> > > fun("10110010")
>> >> > [1] -78
>> >> >
>> >> > as you can see, the function only worked or showed expected result
>> on the
>> >> > last case with a -78, but in the other cases, it the results were
>> not as
>> >> > expected, maybe I am missing something here?
>> >> >
>> >> > Any help and/or guidance will be greatly appreciated,
>> >> >
>> >> > Best regards,
>> >> >
>> >> > Paul
>> >> >
>> >> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<
>> ruipbarradas at sapo.pt>)
>> >> > escribi?:
>> >> >
>> >> > > Hello,
>> >> > >
>> >> > > The function I included converts signed binary numbers into their
>> >> > > decimal representation. They are negative if a) they are multiples
>> of 8
>> >> > > bits and b) the most significant bit is a "1". If not just convert
>> to
>> >> > > integer.
>> >> > >
>> >> > > As for a) above, I assume that you will have 8 bit numbers. And the
>> >> > > conversion is done as follows:
>> >> > >
>> >> > > input: 10110010
>> >> > >
>> >> > > splitting, to make it more clear:
>> >> > >
>> >> > > 1 0 1 1 0 0 1 0 - input
>> >> > > 0 1 0 0 1 1 0 1 - reversed
>> >> > >                1 - add 1 to the number with reversed bits
>> >> > > 0 1 0 0 1 1 1 0 - result is the two's complement
>> >> > >
>> >> > > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
>> >> > >
>> >> > > But the msb is "1" so it's -78
>> >> > >
>> >> > >
>> >> > > This is what the function does, but instead of %*% it uses
>> >> > >
>> >> > > sum(two's compl * powers of two)
>> >> > >
>> >> > >
>> >> > > Hope this helps,
>> >> > >
>> >> > > Rui Barradas
>> >> > >
>> >> > > The input must be a character string or character vector.
>> >> > >
>> >> > > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
>> >> > > > Dear friend Rui,
>> >> > > >
>> >> > > > Hope you are doing great, thanks for your kind feedback. The
>> challenge I
>> >> > > > currently have at hand is to decode AIS messages and obtain
>> latitude and
>> >> > > > longitude values from those.
>> >> > > >
>> >> > > > So basically, I want to accomplish something like in the example
>> below.
>> >> > > > I want to convert this binary number (10110010) into the two?s
>> >> > > > complement representation, there is the logic they are using for
>> that.
>> >> > > > Since longitude ranges from
>> >> > > >
>> >> > > >
>> >> > > >       Example of conversion to decimal of a signed binary number
>> in
>> >> > > >       two's complement representation
>> >> > > >
>> >> > > > Let's convert to decimal the following signed binary number:
>> 10110010
>> >> > > >
>> >> > > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 +
>> 0?20 = -128
>> >> > > > + 32 + 16 + 2 = -78.
>> >> > > >
>> >> > > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<
>> ruipbarradas at sapo.pt
>> >> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
>> >> > > >
>> >> > > >     Sorry, missunderstood the problem.
>> >> > > >     Here it goes:
>> >> > > >
>> >> > > >     fun <- function(x){
>> >> > > >         res <- sapply(x, function(y){
>> >> > > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>> >> > > >             strtoi(y, base = 2)
>> >> > > >           }else{
>> >> > > >             y <- unlist(strsplit(y, ""))
>> >> > > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
>> >> > > >           }
>> >> > > >         })
>> >> > > >         unname(res)
>> >> > > >     }
>> >> > > >
>> >> > > >     fun("10110010")
>> >> > > >     fun("10000000")
>> >> > > >     fun(c("01000000", "01111111", "10110010", "10000000"))
>> >> > > >
>> >> > > >
>> >> > > >     Hope this helps,
>> >> > > >
>> >> > > >     Rui Barradas
>> >> > > >
>> >> > > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
>> >> > > >      > Hello,
>> >> > > >      >
>> >> > > >      > Is this what you want?
>> >> > > >      >
>> >> > > >      >
>> >> > > >      > x <- "10110010"
>> >> > > >      > strtoi(x, base = 2)
>> >> > > >      > #[1] 178
>> >> > > >      >
>> >> > > >      >
>> >> > > >      > Hope this helps,
>> >> > > >      >
>> >> > > >      > Rui Barradas
>> >> > > >      >
>> >> > > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
>> >> > > >      >> Dear friends,
>> >> > > >      >>
>> >> > > >      >> How can I convert the following binary number in two?s
>> complement
>> >> > > >      >> representation in R?
>> >> > > >      >>
>> >> > > >      >> 10110010
>> >> > > >      >>
>> >> > > >      >> Any help and/or guidance will be greatly appreciated,
>> >> > > >      >>
>> >> > > >      >> Best regards,
>> >> > > >      >>
>> >> > > >      >> Paul
>> >> > > >      >>
>> >> > > >      >>     [[alternative HTML version deleted]]
>> >> > > >      >>
>> >> > > >      >> ______________________________________________
>> >> > > >      >> R-help at r-project.org <mailto:R-help at r-project.org>
>> mailing list
>> >> > > >     -- To UNSUBSCRIBE and more, see
>> >> > > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > >      >> PLEASE do read the posting guide
>> >> > > >      >> http://www.R-project.org/posting-guide.html
>> >> > > >      >> and provide commented, minimal, self-contained,
>> reproducible
>> >> > > code.
>> >> > > >      >>
>> >> > > >      >
>> >> > > >      > ______________________________________________
>> >> > > >      > R-help at r-project.org <mailto:R-help at r-project.org>
>> mailing list
>> >> > > >     -- To UNSUBSCRIBE and more, see
>> >> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > >      > PLEASE do read the posting guide
>> >> > > >      > http://www.R-project.org/posting-guide.html
>> >> > > >      > and provide commented, minimal, self-contained,
>> reproducible code.
>> >> > > >
>> >> > >
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Jan 24 23:47:01 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 24 Jan 2020 17:47:01 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
 <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
 <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>
 <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>
Message-ID: <CAMOcQfPKJq4Zvcqt=Kop7jdjmddUbZb-YHeTp=UEEUF8qbrhKg@mail.gmail.com>

Thanks brother, I really appreciate your help.

Have an awesome weekend!

El vie., 24 de enero de 2020 5:39 p. m., Richard M. Heiberger <
rmh at temple.edu> escribi?:

> I don't have my computer with me, so I am commenting right now on the
> visual impression of the email.
>
> The latitude shows 90, 88, ... 2, 89, ...
> The labels are lexicographically ordered
> -1, -10, -11,...
>
> The latitude binrep look in correct order, and the labels looks like
> binary in order.
>
> These things are identified as factors, not as character.
>
> Please ensure that character values are not misinterpreted as factor when
> you construct your data frames.
>
> The four columns do not look to be in consistent order with each other.
> This in itself could cause trouble.
>
> I will look more when I have my computer running R so I can follow the
> rest of what you wrote.
>
> Rich
>
> On Fri, Jan 24, 2020 at 15:02 Paul Bernal <paulbernal07 at gmail.com> wrote:
>
>> Dear friend Richard,
>>
>> Thank you for your interest in helping me through this challenge. As
>> requested, I am providing the two lat and long frames you suggested, plus
>> the one single column I am trying to decode:
>>
>> LatitudeFrame:
>>
>> > dput(LatitudeFrame)
>> structure(list(Latitude = structure(c(90L, 88L, 87L, 86L, 85L,
>> 84L, 83L, 82L, 81L, 80L, 79L, 77L, 76L, 75L, 74L, 73L, 72L, 71L,
>> 70L, 69L, 68L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L, 57L,
>> 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 46L, 44L, 43L, 42L,
>> 41L, 40L, 39L, 38L, 37L, 36L, 35L, 33L, 32L, 31L, 30L, 29L, 28L,
>> 27L, 26L, 25L, 24L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L, 14L,
>> 13L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 89L, 78L, 67L,
>> 56L, 45L, 34L, 23L, 12L, 1L, 91L, 92L, 103L, 114L, 125L, 136L,
>> 147L, 158L, 169L, 180L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
>> 101L, 102L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
>> 113L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
>> 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 137L,
>> 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 148L, 149L,
>> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 159L, 160L, 161L,
>> 162L, 163L, 164L, 165L, 166L, 167L, 168L, 170L, 171L, 172L, 173L,
>> 174L, 175L, 176L, 177L, 178L, 179L, 181L), .Label = c("-1", "-10",
>> "-11", "-12", "-13", "-14", "-15", "-16", "-17", "-18", "-19",
>> "-2", "-20", "-21", "-22", "-23", "-24", "-25", "-26", "-27",
>> "-28", "-29", "-3", "-30", "-31", "-32", "-33", "-34", "-35",
>> "-36", "-37", "-38", "-39", "-4", "-40", "-41", "-42", "-43",
>> "-44", "-45", "-46", "-47", "-48", "-49", "-5", "-50", "-51",
>> "-52", "-53", "-54", "-55", "-56", "-57", "-58", "-59", "-6",
>> "-60", "-61", "-62", "-63", "-64", "-65", "-66", "-67", "-68",
>> "-69", "-7", "-70", "-71", "-72", "-73", "-74", "-75", "-76",
>> "-77", "-78", "-79", "-8", "-80", "-81", "-82", "-83", "-84",
>> "-85", "-86", "-87", "-88", "-89", "-9", "-90", "0", "1", "10",
>> "11", "12", "13", "14", "15", "16", "17", "18", "19", "2", "20",
>> "21", "22", "23", "24", "25", "26", "27", "28", "29", "3", "30",
>> "31", "32", "33", "34", "35", "36", "37", "38", "39", "4", "40",
>> "41", "42", "43", "44", "45", "46", "47", "48", "49", "5", "50",
>> "51", "52", "53", "54", "55", "56", "57", "58", "59", "6", "60",
>> "61", "62", "63", "64", "65", "66", "67", "68", "69", "7", "70",
>> "71", "72", "73", "74", "75", "76", "77", "78", "79", "8", "80",
>> "81", "82", "83", "84", "85", "86", "87", "88", "89", "9", "90"
>> ), class = "factor"), LatitudeBinRep = structure(c(92L, 93L,
>> 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L,
>> 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L,
>> 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L,
>> 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L,
>> 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
>> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
>> 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L,
>> 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 1L,
>> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
>> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
>> 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
>> 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L,
>> 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L,
>> 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
>> 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L), .Label =
>> c("0000000000000000000000000000000",
>> "0000000000000000000000000000001", "0000000000000000000000000000010",
>> "0000000000000000000000000000011", "0000000000000000000000000000100",
>> "0000000000000000000000000000101", "0000000000000000000000000000110",
>> "0000000000000000000000000000111", "0000000000000000000000000001000",
>> "0000000000000000000000000001001", "0000000000000000000000000001010",
>> "0000000000000000000000000001011", "0000000000000000000000000001100",
>> "0000000000000000000000000001101", "0000000000000000000000000001110",
>> "0000000000000000000000000001111", "0000000000000000000000000010000",
>> "0000000000000000000000000010001", "0000000000000000000000000010010",
>> "0000000000000000000000000010011", "0000000000000000000000000010100",
>> "0000000000000000000000000010101", "0000000000000000000000000010110",
>> "0000000000000000000000000010111", "0000000000000000000000000011000",
>> "0000000000000000000000000011001", "0000000000000000000000000011010",
>> "0000000000000000000000000011011", "0000000000000000000000000011100",
>> "0000000000000000000000000011101", "0000000000000000000000000011110",
>> "0000000000000000000000000011111", "0000000000000000000000000100000",
>> "0000000000000000000000000100001", "0000000000000000000000000100010",
>> "0000000000000000000000000100011", "0000000000000000000000000100100",
>> "0000000000000000000000000100101", "0000000000000000000000000100110",
>> "0000000000000000000000000100111", "0000000000000000000000000101000",
>> "0000000000000000000000000101001", "0000000000000000000000000101010",
>> "0000000000000000000000000101011", "0000000000000000000000000101100",
>> "0000000000000000000000000101101", "0000000000000000000000000101110",
>> "0000000000000000000000000101111", "0000000000000000000000000110000",
>> "0000000000000000000000000110001", "0000000000000000000000000110010",
>> "0000000000000000000000000110011", "0000000000000000000000000110100",
>> "0000000000000000000000000110101", "0000000000000000000000000110110",
>> "0000000000000000000000000110111", "0000000000000000000000000111000",
>> "0000000000000000000000000111001", "0000000000000000000000000111010",
>> "0000000000000000000000000111011", "0000000000000000000000000111100",
>> "0000000000000000000000000111101", "0000000000000000000000000111110",
>> "0000000000000000000000000111111", "0000000000000000000000001000000",
>> "0000000000000000000000001000001", "0000000000000000000000001000010",
>> "0000000000000000000000001000011", "0000000000000000000000001000100",
>> "0000000000000000000000001000101", "0000000000000000000000001000110",
>> "0000000000000000000000001000111", "0000000000000000000000001001000",
>> "0000000000000000000000001001001", "0000000000000000000000001001010",
>> "0000000000000000000000001001011", "0000000000000000000000001001100",
>> "0000000000000000000000001001101", "0000000000000000000000001001110",
>> "0000000000000000000000001001111", "0000000000000000000000001010000",
>> "0000000000000000000000001010001", "0000000000000000000000001010010",
>> "0000000000000000000000001010011", "0000000000000000000000001010100",
>> "0000000000000000000000001010101", "0000000000000000000000001010110",
>> "0000000000000000000000001010111", "0000000000000000000000001011000",
>> "0000000000000000000000001011001", "0000000000000000000000001011010",
>> "1111111111111111111111110100110", "1111111111111111111111110100111",
>> "1111111111111111111111110101000", "1111111111111111111111110101001",
>> "1111111111111111111111110101010", "1111111111111111111111110101011",
>> "1111111111111111111111110101100", "1111111111111111111111110101101",
>> "1111111111111111111111110101110", "1111111111111111111111110101111",
>> "1111111111111111111111110110000", "1111111111111111111111110110001",
>> "1111111111111111111111110110010", "1111111111111111111111110110011",
>> "1111111111111111111111110110100", "1111111111111111111111110110101",
>> "1111111111111111111111110110110", "1111111111111111111111110110111",
>> "1111111111111111111111110111000", "1111111111111111111111110111001",
>> "1111111111111111111111110111010", "1111111111111111111111110111011",
>> "1111111111111111111111110111100", "1111111111111111111111110111101",
>> "1111111111111111111111110111110", "1111111111111111111111110111111",
>> "1111111111111111111111111000000", "1111111111111111111111111000001",
>> "1111111111111111111111111000010", "1111111111111111111111111000011",
>> "1111111111111111111111111000100", "1111111111111111111111111000101",
>> "1111111111111111111111111000110", "1111111111111111111111111000111",
>> "1111111111111111111111111001000", "1111111111111111111111111001001",
>> "1111111111111111111111111001010", "1111111111111111111111111001011",
>> "1111111111111111111111111001100", "1111111111111111111111111001101",
>> "1111111111111111111111111001110", "1111111111111111111111111001111",
>> "1111111111111111111111111010000", "1111111111111111111111111010001",
>> "1111111111111111111111111010010", "1111111111111111111111111010011",
>> "1111111111111111111111111010100", "1111111111111111111111111010101",
>> "1111111111111111111111111010110", "1111111111111111111111111010111",
>> "1111111111111111111111111011000", "1111111111111111111111111011001",
>> "1111111111111111111111111011010", "1111111111111111111111111011011",
>> "1111111111111111111111111011100", "1111111111111111111111111011101",
>> "1111111111111111111111111011110", "1111111111111111111111111011111",
>> "1111111111111111111111111100000", "1111111111111111111111111100001",
>> "1111111111111111111111111100010", "1111111111111111111111111100011",
>> "1111111111111111111111111100100", "1111111111111111111111111100101",
>> "1111111111111111111111111100110", "1111111111111111111111111100111",
>> "1111111111111111111111111101000", "1111111111111111111111111101001",
>> "1111111111111111111111111101010", "1111111111111111111111111101011",
>> "1111111111111111111111111101100", "1111111111111111111111111101101",
>> "1111111111111111111111111101110", "1111111111111111111111111101111",
>> "1111111111111111111111111110000", "1111111111111111111111111110001",
>> "1111111111111111111111111110010", "1111111111111111111111111110011",
>> "1111111111111111111111111110100", "1111111111111111111111111110101",
>> "1111111111111111111111111110110", "1111111111111111111111111110111",
>> "1111111111111111111111111111000", "1111111111111111111111111111001",
>> "1111111111111111111111111111010", "1111111111111111111111111111011",
>> "1111111111111111111111111111100", "1111111111111111111111111111101",
>> "1111111111111111111111111111110", "1111111111111111111111111111111"
>> ), class = "factor")), class = "data.frame", row.names = c(NA,
>> -181L))
>>
>> LongitudeFrame:
>>
>> > dput(LongitudeFrame)
>> structure(list(Longitude = structure(c(91L, 89L, 88L, 87L, 86L,
>> 85L, 84L, 83L, 82L, 81L, 80L, 78L, 77L, 76L, 75L, 74L, 73L, 72L,
>> 71L, 70L, 69L, 67L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L,
>> 56L, 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 45L, 44L, 43L,
>> 42L, 41L, 40L, 39L, 38L, 37L, 36L, 34L, 33L, 32L, 31L, 30L, 29L,
>> 28L, 27L, 26L, 25L, 23L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L,
>> 14L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 180L, 179L, 178L,
>> 177L, 176L, 175L, 174L, 173L, 172L, 171L, 169L, 168L, 167L, 166L,
>> 165L, 164L, 163L, 162L, 161L, 160L, 158L, 157L, 156L, 155L, 154L,
>> 153L, 152L, 151L, 150L, 149L, 147L, 146L, 145L, 144L, 143L, 142L,
>> 141L, 140L, 139L, 138L, 136L, 135L, 134L, 133L, 132L, 131L, 130L,
>> 129L, 128L, 127L, 125L, 124L, 123L, 122L, 121L, 120L, 119L, 118L,
>> 117L, 116L, 114L, 113L, 112L, 111L, 110L, 109L, 108L, 107L, 106L,
>> 105L, 103L, 102L, 101L, 100L, 99L, 98L, 97L, 96L, 95L, 94L, 92L,
>> 90L, 79L, 68L, 57L, 46L, 35L, 24L, 13L, 2L, 170L, 159L, 148L,
>> 137L, 126L, 115L, 104L, 93L, 1L, 181L, 182L, 274L, 285L, 296L,
>> 307L, 318L, 329L, 340L, 351L, 183L, 194L, 205L, 216L, 227L, 238L,
>> 249L, 260L, 271L, 273L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
>> 282L, 283L, 284L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L,
>> 294L, 295L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 305L,
>> 306L, 308L, 309L, 310L, 311L, 312L, 313L, 314L, 315L, 316L, 317L,
>> 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 330L,
>> 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 341L, 342L,
>> 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L,
>> 355L, 356L, 357L, 358L, 359L, 360L, 361L, 184L, 185L, 186L, 187L,
>> 188L, 189L, 190L, 191L, 192L, 193L, 195L, 196L, 197L, 198L, 199L,
>> 200L, 201L, 202L, 203L, 204L, 206L, 207L, 208L, 209L, 210L, 211L,
>> 212L, 213L, 214L, 215L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
>> 224L, 225L, 226L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
>> 236L, 237L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
>> 248L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
>> 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L, 272L
>> ), .Label = c("-1", "-10", "-100", "-101", "-102", "-103", "-104",
>> "-105", "-106", "-107", "-108", "-109", "-11", "-110", "-111",
>> "-112", "-113", "-114", "-115", "-116", "-117", "-118", "-119",
>> "-12", "-120", "-121", "-122", "-123", "-124", "-125", "-126",
>> "-127", "-128", "-129", "-13", "-130", "-131", "-132", "-133",
>> "-134", "-135", "-136", "-137", "-138", "-139", "-14", "-140",
>> "-141", "-142", "-143", "-144", "-145", "-146", "-147", "-148",
>> "-149", "-15", "-150", "-151", "-152", "-153", "-154", "-155",
>> "-156", "-157", "-158", "-159", "-16", "-160", "-161", "-162",
>> "-163", "-164", "-165", "-166", "-167", "-168", "-169", "-17",
>> "-170", "-171", "-172", "-173", "-174", "-175", "-176", "-177",
>> "-178", "-179", "-18", "-180", "-19", "-2", "-20", "-21", "-22",
>> "-23", "-24", "-25", "-26", "-27", "-28", "-29", "-3", "-30",
>> "-31", "-32", "-33", "-34", "-35", "-36", "-37", "-38", "-39",
>> "-4", "-40", "-41", "-42", "-43", "-44", "-45", "-46", "-47",
>> "-48", "-49", "-5", "-50", "-51", "-52", "-53", "-54", "-55",
>> "-56", "-57", "-58", "-59", "-6", "-60", "-61", "-62", "-63",
>> "-64", "-65", "-66", "-67", "-68", "-69", "-7", "-70", "-71",
>> "-72", "-73", "-74", "-75", "-76", "-77", "-78", "-79", "-8",
>> "-80", "-81", "-82", "-83", "-84", "-85", "-86", "-87", "-88",
>> "-89", "-9", "-90", "-91", "-92", "-93", "-94", "-95", "-96",
>> "-97", "-98", "-99", "0", "1", "10", "100", "101", "102", "103",
>> "104", "105", "106", "107", "108", "109", "11", "110", "111",
>> "112", "113", "114", "115", "116", "117", "118", "119", "12",
>> "120", "121", "122", "123", "124", "125", "126", "127", "128",
>> "129", "13", "130", "131", "132", "133", "134", "135", "136",
>> "137", "138", "139", "14", "140", "141", "142", "143", "144",
>> "145", "146", "147", "148", "149", "15", "150", "151", "152",
>> "153", "154", "155", "156", "157", "158", "159", "16", "160",
>> "161", "162", "163", "164", "165", "166", "167", "168", "169",
>> "17", "170", "171", "172", "173", "174", "175", "176", "177",
>> "178", "179", "18", "180", "19", "2", "20", "21", "22", "23",
>> "24", "25", "26", "27", "28", "29", "3", "30", "31", "32", "33",
>> "34", "35", "36", "37", "38", "39", "4", "40", "41", "42", "43",
>> "44", "45", "46", "47", "48", "49", "5", "50", "51", "52", "53",
>> "54", "55", "56", "57", "58", "59", "6", "60", "61", "62", "63",
>> "64", "65", "66", "67", "68", "69", "7", "70", "71", "72", "73",
>> "74", "75", "76", "77", "78", "79", "8", "80", "81", "82", "83",
>> "84", "85", "86", "87", "88", "89", "9", "90", "91", "92", "93",
>> "94", "95", "96", "97", "98", "99"), class = "factor"), LongitudeBinRep =
>> structure(c(182L,
>> 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 193L,
>> 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L,
>> 205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
>> 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L,
>> 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L, 236L, 237L,
>> 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L, 248L,
>> 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
>> 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L,
>> 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
>> 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L,
>> 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L,
>> 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,
>> 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L,
>> 326L, 327L, 328L, 329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L,
>> 337L, 338L, 339L, 340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L,
>> 348L, 349L, 350L, 351L, 352L, 353L, 354L, 355L, 356L, 357L, 358L,
>> 359L, 360L, 361L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
>> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
>> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
>> 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L,
>> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L,
>> 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
>> 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
>> 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L,
>> 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
>> 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L,
>> 124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L,
>> 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
>> 146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L,
>> 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L,
>> 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
>> 179L, 180L, 181L), .Label = c("0000000000000000000000000000000",
>> "0000000000000000000000000000001", "0000000000000000000000000000010",
>> "0000000000000000000000000000011", "0000000000000000000000000000100",
>> "0000000000000000000000000000101", "0000000000000000000000000000110",
>> "0000000000000000000000000000111", "0000000000000000000000000001000",
>> "0000000000000000000000000001001", "0000000000000000000000000001010",
>> "0000000000000000000000000001011", "0000000000000000000000000001100",
>> "0000000000000000000000000001101", "0000000000000000000000000001110",
>> "0000000000000000000000000001111", "0000000000000000000000000010000",
>> "0000000000000000000000000010001", "0000000000000000000000000010010",
>> "0000000000000000000000000010011", "0000000000000000000000000010100",
>> "0000000000000000000000000010101", "0000000000000000000000000010110",
>> "0000000000000000000000000010111", "0000000000000000000000000011000",
>> "0000000000000000000000000011001", "0000000000000000000000000011010",
>> "0000000000000000000000000011011", "0000000000000000000000000011100",
>> "0000000000000000000000000011101", "0000000000000000000000000011110",
>> "0000000000000000000000000011111", "0000000000000000000000000100000",
>> "0000000000000000000000000100001", "0000000000000000000000000100010",
>> "0000000000000000000000000100011", "0000000000000000000000000100100",
>> "0000000000000000000000000100101", "0000000000000000000000000100110",
>> "0000000000000000000000000100111", "0000000000000000000000000101000",
>> "0000000000000000000000000101001", "0000000000000000000000000101010",
>> "0000000000000000000000000101011", "0000000000000000000000000101100",
>> "0000000000000000000000000101101", "0000000000000000000000000101110",
>> "0000000000000000000000000101111", "0000000000000000000000000110000",
>> "0000000000000000000000000110001", "0000000000000000000000000110010",
>> "0000000000000000000000000110011", "0000000000000000000000000110100",
>> "0000000000000000000000000110101", "0000000000000000000000000110110",
>> "0000000000000000000000000110111", "0000000000000000000000000111000",
>> "0000000000000000000000000111001", "0000000000000000000000000111010",
>> "0000000000000000000000000111011", "0000000000000000000000000111100",
>> "0000000000000000000000000111101", "0000000000000000000000000111110",
>> "0000000000000000000000000111111", "0000000000000000000000001000000",
>> "0000000000000000000000001000001", "0000000000000000000000001000010",
>> "0000000000000000000000001000011", "0000000000000000000000001000100",
>> "0000000000000000000000001000101", "0000000000000000000000001000110",
>> "0000000000000000000000001000111", "0000000000000000000000001001000",
>> "0000000000000000000000001001001", "0000000000000000000000001001010",
>> "0000000000000000000000001001011", "0000000000000000000000001001100",
>> "0000000000000000000000001001101", "0000000000000000000000001001110",
>> "0000000000000000000000001001111", "0000000000000000000000001010000",
>> "0000000000000000000000001010001", "0000000000000000000000001010010",
>> "0000000000000000000000001010011", "0000000000000000000000001010100",
>> "0000000000000000000000001010101", "0000000000000000000000001010110",
>> "0000000000000000000000001010111", "0000000000000000000000001011000",
>> "0000000000000000000000001011001", "0000000000000000000000001011010",
>> "0000000000000000000000001011011", "0000000000000000000000001011100",
>> "0000000000000000000000001011101", "0000000000000000000000001011110",
>> "0000000000000000000000001011111", "0000000000000000000000001100000",
>> "0000000000000000000000001100001", "0000000000000000000000001100010",
>> "0000000000000000000000001100011", "0000000000000000000000001100100",
>> "0000000000000000000000001100101", "0000000000000000000000001100110",
>> "0000000000000000000000001100111", "0000000000000000000000001101000",
>> "0000000000000000000000001101001", "0000000000000000000000001101010",
>> "0000000000000000000000001101011", "0000000000000000000000001101100",
>> "0000000000000000000000001101101", "0000000000000000000000001101110",
>> "0000000000000000000000001101111", "0000000000000000000000001110000",
>> "0000000000000000000000001110001", "0000000000000000000000001110010",
>> "0000000000000000000000001110011", "0000000000000000000000001110100",
>> "0000000000000000000000001110101", "0000000000000000000000001110110",
>> "0000000000000000000000001110111", "0000000000000000000000001111000",
>> "0000000000000000000000001111001", "0000000000000000000000001111010",
>> "0000000000000000000000001111011", "0000000000000000000000001111100",
>> "0000000000000000000000001111101", "0000000000000000000000001111110",
>> "0000000000000000000000001111111", "0000000000000000000000010000000",
>> "0000000000000000000000010000001", "0000000000000000000000010000010",
>> "0000000000000000000000010000011", "0000000000000000000000010000100",
>> "0000000000000000000000010000101", "0000000000000000000000010000110",
>> "0000000000000000000000010000111", "0000000000000000000000010001000",
>> "0000000000000000000000010001001", "0000000000000000000000010001010",
>> "0000000000000000000000010001011", "0000000000000000000000010001100",
>> "0000000000000000000000010001101", "0000000000000000000000010001110",
>> "0000000000000000000000010001111", "0000000000000000000000010010000",
>> "0000000000000000000000010010001", "0000000000000000000000010010010",
>> "0000000000000000000000010010011", "0000000000000000000000010010100",
>> "0000000000000000000000010010101", "0000000000000000000000010010110",
>> "0000000000000000000000010010111", "0000000000000000000000010011000",
>> "0000000000000000000000010011001", "0000000000000000000000010011010",
>> "0000000000000000000000010011011", "0000000000000000000000010011100",
>> "0000000000000000000000010011101", "0000000000000000000000010011110",
>> "0000000000000000000000010011111", "0000000000000000000000010100000",
>> "0000000000000000000000010100001", "0000000000000000000000010100010",
>> "0000000000000000000000010100011", "0000000000000000000000010100100",
>> "0000000000000000000000010100101", "0000000000000000000000010100110",
>> "0000000000000000000000010100111", "0000000000000000000000010101000",
>> "0000000000000000000000010101001", "0000000000000000000000010101010",
>> "0000000000000000000000010101011", "0000000000000000000000010101100",
>> "0000000000000000000000010101101", "0000000000000000000000010101110",
>> "0000000000000000000000010101111", "0000000000000000000000010110000",
>> "0000000000000000000000010110001", "0000000000000000000000010110010",
>> "0000000000000000000000010110011", "0000000000000000000000010110100",
>> "1111111111111111111111101001100", "1111111111111111111111101001101",
>> "1111111111111111111111101001110", "1111111111111111111111101001111",
>> "1111111111111111111111101010000", "1111111111111111111111101010001",
>> "1111111111111111111111101010010", "1111111111111111111111101010011",
>> "1111111111111111111111101010100", "1111111111111111111111101010101",
>> "1111111111111111111111101010110", "1111111111111111111111101010111",
>> "1111111111111111111111101011000", "1111111111111111111111101011001",
>> "1111111111111111111111101011010", "1111111111111111111111101011011",
>> "1111111111111111111111101011100", "1111111111111111111111101011101",
>> "1111111111111111111111101011110", "1111111111111111111111101011111",
>> "1111111111111111111111101100000", "1111111111111111111111101100001",
>> "1111111111111111111111101100010", "1111111111111111111111101100011",
>> "1111111111111111111111101100100", "1111111111111111111111101100101",
>> "1111111111111111111111101100110", "1111111111111111111111101100111",
>> "1111111111111111111111101101000", "1111111111111111111111101101001",
>> "1111111111111111111111101101010", "1111111111111111111111101101011",
>> "1111111111111111111111101101100", "1111111111111111111111101101101",
>> "1111111111111111111111101101110", "1111111111111111111111101101111",
>> "1111111111111111111111101110000", "1111111111111111111111101110001",
>> "1111111111111111111111101110010", "1111111111111111111111101110011",
>> "1111111111111111111111101110100", "1111111111111111111111101110101",
>> "1111111111111111111111101110110", "1111111111111111111111101110111",
>> "1111111111111111111111101111000", "1111111111111111111111101111001",
>> "1111111111111111111111101111010", "1111111111111111111111101111011",
>> "1111111111111111111111101111100", "1111111111111111111111101111101",
>> "1111111111111111111111101111110", "1111111111111111111111101111111",
>> "1111111111111111111111110000000", "1111111111111111111111110000001",
>> "1111111111111111111111110000010", "1111111111111111111111110000011",
>> "1111111111111111111111110000100", "1111111111111111111111110000101",
>> "1111111111111111111111110000110", "1111111111111111111111110000111",
>> "1111111111111111111111110001000", "1111111111111111111111110001001",
>> "1111111111111111111111110001010", "1111111111111111111111110001011",
>> "1111111111111111111111110001100", "1111111111111111111111110001101",
>> "1111111111111111111111110001110", "1111111111111111111111110001111",
>> "1111111111111111111111110010000", "1111111111111111111111110010001",
>> "1111111111111111111111110010010", "1111111111111111111111110010011",
>> "1111111111111111111111110010100", "1111111111111111111111110010101",
>> "1111111111111111111111110010110", "1111111111111111111111110010111",
>> "1111111111111111111111110011000", "1111111111111111111111110011001",
>> "1111111111111111111111110011010", "1111111111111111111111110011011",
>> "1111111111111111111111110011100", "1111111111111111111111110011101",
>> "1111111111111111111111110011110", "1111111111111111111111110011111",
>> "1111111111111111111111110100000", "1111111111111111111111110100001",
>> "1111111111111111111111110100010", "1111111111111111111111110100011",
>> "1111111111111111111111110100100", "1111111111111111111111110100101",
>> "1111111111111111111111110100110", "1111111111111111111111110100111",
>> "1111111111111111111111110101000", "1111111111111111111111110101001",
>> "1111111111111111111111110101010", "1111111111111111111111110101011",
>> "1111111111111111111111110101100", "1111111111111111111111110101101",
>> "1111111111111111111111110101110", "1111111111111111111111110101111",
>> "1111111111111111111111110110000", "1111111111111111111111110110001",
>> "1111111111111111111111110110010", "1111111111111111111111110110011",
>> "1111111111111111111111110110100", "1111111111111111111111110110101",
>> "1111111111111111111111110110110", "1111111111111111111111110110111",
>> "1111111111111111111111110111000", "1111111111111111111111110111001",
>> "1111111111111111111111110111010", "1111111111111111111111110111011",
>> "1111111111111111111111110111100", "1111111111111111111111110111101",
>> "1111111111111111111111110111110", "1111111111111111111111110111111",
>> "1111111111111111111111111000000", "1111111111111111111111111000001",
>> "1111111111111111111111111000010", "1111111111111111111111111000011",
>> "1111111111111111111111111000100", "1111111111111111111111111000101",
>> "1111111111111111111111111000110", "1111111111111111111111111000111",
>> "1111111111111111111111111001000", "1111111111111111111111111001001",
>> "1111111111111111111111111001010", "1111111111111111111111111001011",
>> "1111111111111111111111111001100", "1111111111111111111111111001101",
>> "1111111111111111111111111001110", "1111111111111111111111111001111",
>> "1111111111111111111111111010000", "1111111111111111111111111010001",
>> "1111111111111111111111111010010", "1111111111111111111111111010011",
>> "1111111111111111111111111010100", "1111111111111111111111111010101",
>> "1111111111111111111111111010110", "1111111111111111111111111010111",
>> "1111111111111111111111111011000", "1111111111111111111111111011001",
>> "1111111111111111111111111011010", "1111111111111111111111111011011",
>> "1111111111111111111111111011100", "1111111111111111111111111011101",
>> "1111111111111111111111111011110", "1111111111111111111111111011111",
>> "1111111111111111111111111100000", "1111111111111111111111111100001",
>> "1111111111111111111111111100010", "1111111111111111111111111100011",
>> "1111111111111111111111111100100", "1111111111111111111111111100101",
>> "1111111111111111111111111100110", "1111111111111111111111111100111",
>> "1111111111111111111111111101000", "1111111111111111111111111101001",
>> "1111111111111111111111111101010", "1111111111111111111111111101011",
>> "1111111111111111111111111101100", "1111111111111111111111111101101",
>> "1111111111111111111111111101110", "1111111111111111111111111101111",
>> "1111111111111111111111111110000", "1111111111111111111111111110001",
>> "1111111111111111111111111110010", "1111111111111111111111111110011",
>> "1111111111111111111111111110100", "1111111111111111111111111110101",
>> "1111111111111111111111111110110", "1111111111111111111111111110111",
>> "1111111111111111111111111111000", "1111111111111111111111111111001",
>> "1111111111111111111111111111010", "1111111111111111111111111111011",
>> "1111111111111111111111111111100", "1111111111111111111111111111101",
>> "1111111111111111111111111111110", "1111111111111111111111111111111"
>> ), class = "factor")), class = "data.frame", row.names = c(NA,
>> -361L))
>>
>> AISMessageFrame (Raw Messages as they come from the AIS device):
>>
>> > dput(AISMessageFrame)
>> structure(list(MessgeCode = structure(c(17L, 6L, 93L, 92L, 81L,
>> 24L, 4L, 44L, 21L, 43L, 66L, 64L, 94L, 46L, 26L, 82L, 12L, 9L,
>> 67L, 63L, 65L, 39L, 48L, 38L, 79L, 83L, 37L, 73L, 23L, 68L, 59L,
>> NA, 5L, 30L, 62L, 84L, 60L, 22L, 52L, 61L, 50L, 70L, 96L, 85L,
>> 33L, 51L, 8L, 16L, 19L, 71L, 76L, 86L, 34L, 25L, 14L, 53L, 10L,
>> 29L, 2L, 77L, 57L, 87L, 72L, 54L, 55L, 36L, 1L, 13L, NA, 78L,
>> 58L, 15L, 89L, 35L, 20L, 3L, 49L, 56L, 90L, 40L, 45L, 41L, 42L,
>> 74L, 95L, 32L, 91L, 27L, 69L, 76L, 18L, 31L, 11L, 80L, 75L, 7L,
>> 72L, 88L, 28L, 47L), .Label = c("1:u0KOh001rCq5P529qqubqh2 at 3n",
>> "100000?P00JCkt:583J=r?v:283Q", "10007NgP00rCQGV5:Pa=?gv>2<1H",
>> "1000Fo at P01rCuG<56bnkN?v004`0", "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
>> "1349B:3000rCtrn553aR at JH02PRp", "1349B:3000rCtrn553aR at JHD2d4O",
>> "137g`F8007rCaIj59Tc5Dl at 800SN", "139NL4000LrCc8j59FEED4 at 000S<",
>> "13M at Hk00jSJD@RD4s=qG1mT80 at 3J", "13P;K8 at 001rCfgr58=f;QbFD2D4G",
>> "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "13P>4mhw1CrCi5H57aK5WlN>0<4F",
>> "14aMBf000wrCKKN5:sdU0Sv<083C", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>> "15?7P`0P00rD1S453KSlj?v824`0", "15?f5H?P00rCQat5:Oah0?wn2 at S6",
>> "15?lSL?P00JCQWD5:OpP0?vB24`0", "15?mqH?P00rCek458rkEN?v:00S4",
>> "15 at EA<0P01JCo8l53=BFgwv at 0D47", "15 at eD@8000rC`bl59kW`mFn004`0",
>> "15>nNj0000rCT<@5::qUpkt604`0", "15>uP00P00rC`U:59im;H?v22 at 1D",
>> "15A at av3P00rClHn53<I8M?v02<2B", "15AIw`0P0GrCcO859DO5Ogv:0T`0",
>> "15Aq00?P00rC`a`59mFeogv004`0", "15ATk20000rCnrv53N6;gPr>085R",
>> "15B3Sj0000rC9RD5=mOh40jB20SU", "15BI>P0001rCgUD58DRalRj:00S5",
>> "15BkV00P00rCQBf5:Q5JQOv42D1o", "15BW=20P00JCrvH54t=an?vB00Sg",
>> "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "15De7F?P00JCr5r5517v4?v80h2P",
>> "15E:BR0P00rCgaT58DdJUwv82H34", "15E:N at 0000rCgOd57p45bW><0<2H",
>> "15E=m60000rC`W459k28Wnd:083h", "15E=q08P00JCrnR52cb>4?v200Sw",
>> "15PoOh0001rCgbt58CwUaBD004`0", "15PvE at 0002rCi7R57pokCT:424`0",
>> "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:",
>> "15QDCP0P?w<tSF0l4Q@>4?wp0D1G", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>> "15QK900001JCq=d54l?5J0op0l4e", "15QtF00000rCafD59P?VJ9p<0H52",
>> "15TGcJ0002rD<>p55FgmI at Ul0H0S", "15TgVb0000rCgVb57oFc;ARF2 at 67",
>> "15TgVb0000rCgVd57oFc31R42L46", "15TILd?P00JCm4l53`D>4?v>0L1m",
>> "15U?B00000rCgb>58DFJfRl620RT", "15U at cn0000rCgU>57oPLGiT:2D4D",
>> "15UHOn9P00rCQ`D5:OcTkgv80<4:", "1819?@H001rC9TB5=bppM9<82D0T",
>> "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>> "19NSG<h003rCi@:57pmUkAB<0<1v", "1gu00CLLwfh2 at Asw9@1<",
>> "1gu103LLwfl1 at Asw9P1<",
>> "3", "34`odN1000rD1V2537=dfPJ60000", "35A=Rh1001rD;s454vSTuP`40000",
>> "35QN<D1000rCr5l53esbgPR20000", "39NS at m11@1rCrb:53:E<v0j3R000",
>> "403Iu6Qv4PU00rCk0d57rwW00<2g", "403Iu6Qv4PU01rCk0d57rwW00<2g",
>> "403Iupiv4PU00rC9065>=fW00H0I", "403Iupiv4PU00rC9065>=fW00H0j",
>> "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>> "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G@W9K4Oi0D at PC0ShK40C",
>> "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>> "7933.8835099999997", "7933.8836099999999",
>> "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>> "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "88888888880",
>> "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>> "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>> "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T",
>> "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>> "B;s at N9h00>TtPEQAslh03wuUwP06", "B;s at N9h00>TtPF1Asll03wP5wP06",
>> "B;s at N9h00>TtPF1Asll03wPUwP06", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>> "B;s at N9h00>TtPFQAslt03wQUwP06", "B;s at N9h00>TtPFQAslt03wR5wP06",
>> "B;s at N9h00>TtPFQAsm003wRUwP06", "B;s at N9h00>TtPFQAsm803wU5wP06",
>> "B;s at N9h00>TtPG1Asm403wSUwP06", "B;s at N9h00>TtPG1Asm403wT5wP06",
>> "B;s at N9h00>TtPG1Asm803wTUwP06", "D03Iu6QGLN01MdN01StN000",
>> "D03Iuph1TNfp4dv9J<`N000",
>> "H5?AU:4U653hhhi8 at lkihP000000",
>> "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>> "PC at H8888880"), class = "factor")), class = "data.frame", row.names =
>> c(NA,
>> -100L))
>>
>> Each one of those weird codes given in the AISMessageFrame correspond to
>> an AIS message, there is a lot of information provided here, but I am only
>> concerned with the Latitude and Longitude values (degrees with minutes). In
>> order to accomplish this, each one of those wierd codes need to be
>> converted to binary strings, once converted to binary strings. As I
>> mentioned before, the information regarding latitude and longitude can be
>> extracted from the following positions (again, after converting code to
>> binary strings):
>> Latitude = positions 90 to 116 inclusive (assuming you count the bits
>> from left to right, with the first one having position number 1)
>> Longitude = positions 62 to 89 inclusive (assuming you count the bits
>> from left to right withe the first one having position number 1)
>>
>> In the sample code I provided in previous emails, I used the following to
>> obtain the Latitude and Longitude:
>>
>> library(stringi)
>> library(dplyr)
>> library(R.utils)
>> library(RANN)
>> library(NISTunits)
>> library(pracma)
>> library(celestial)
>> library(stringr)
>>
>> #here I show the sample to decode a single record, though that needs to
>> be done for all AIS messages, so obviously a loop will be needed for that:
>>
>> ascii_datformat <- utf8ToInt(dataset1[1,6]) #turning the first AIS
>> message as it comes to ascii number
>> Base <- ascii_datformat - 48    #transformation from ascii to decimal
>> decy <- ifelse(Base > 40, Base-8, Base) #transformation from ascii to
>> decimal continued
>> biny <- intToBin(decy)  #transformation from decimal to binary
>> representation
>> binyframe <- data.frame(biny)
>> tbinyframe <- paste(t(binyframe[,1]), collapse="") #simply transposing
>> the results
>>
>> tbinyframe will give you something like this (for each row having an AIS
>> message)
>> > tbinyframe
>> [1]
>> "000001000101001111101110000101011000001111100000000000000000111010010011100001101001111100000101001010011111101001110000000000001111111111110110000010010000100011000110"
>>
>> Latitude <- substr(tbinyframe, 90, 116)
>> Longitude <- substr(tbinyframe, 62, 89)
>>
>> What I need is to decode thos latitude and longitude values , to get
>> results in a -90 to +90 range for latitude, and in the -180 to +180 range
>> for longitude.
>>
>> Hopefully I?ve made myself sufficiently clear this time and/or hopefully
>> I understood your point correctly and provided you what you need.
>>
>> Again, thank you so much for your time and valuable support brother!
>>
>> Best regards,
>>
>> Paul
>>
>> El vie., 24 ene. 2020 a las 14:09, Richard M. Heiberger (<rmh at temple.edu>)
>> escribi?:
>>
>>> now I am even more puzzled.
>>>
>>> please complete the following two data.frames and send it to the list.
>>>
>>> latDegrees lat2Comp
>>> -90 xxxxxxxx
>>> -89 xxxxxxxx
>>> ...
>>> -1 xxxxxxxx
>>> 0 xxxxxxxx
>>> 1 xxxxxxxx
>>> ...
>>> 89 xxxxxxxx
>>> 90 xxxxxxxx
>>>
>>> lonDegrees lon2Comp
>>> -180 xxxxxxxx
>>> -179 xxxxxxxx
>>> ...
>>> -91 xxxxxxxx
>>> -90 xxxxxxxx
>>> -89 xxxxxxxx
>>> ...
>>> -1 xxxxxxxx
>>> 0 xxxxxxxx
>>> 1 xxxxxxxx
>>> ...
>>> 89 xxxxxxxx
>>> 90 xxxxxxxx
>>> 91 xxxxxxxx
>>> ...
>>> 179 xxxxxxxx
>>> 180 xxxxxxxx
>>>
>>> Your 8 bit 2C example has 7 digits of precision plus sign which gives
>>> a range of (-127,127).  That suffices for latitude (-90,90).
>>> For longitude you will need 9 bits of twos complement for 8 bits of
>>> precision plus sign to cover (-255,255), thus more than enough for
>>> (-180,180).
>>> This assumes that precision to the degree is sufficient.  If you need
>>> precision to minutes and seconds, or to meters, then you
>>> will need even more bits in 2C.
>>>
>>> Since it looks like you need a different number of bits for each
>>> variable, I am asking for two data.frames.
>>>
>>> Rich
>>>
>>> On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>> >
>>> > Hi Richard,
>>> >
>>> > That was just an example, to show that, for that particular string of
>>> binary numbers, the code works as expected. That is absolutely no related
>>> to the dataset I provided. If I try the function on the dataset, I get
>>> values well over the latitude and longitude boundaries (which should range
>>> from -90 to + 90, and -180 to +180).
>>> >
>>> > Regards,
>>> >
>>> > Paul
>>> >
>>> > El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<
>>> rmh at temple.edu>) escribi?:
>>> >>
>>> >> You show the example
>>> >>
>>> >> > fun("10110010")
>>> >> [1] -78
>>> >>
>>> >> as satisfactory.  Where in your posted data set do you find the input
>>> >> string "10110010"?
>>> >>
>>> >> Please post a set of relevant input strings, and the answers you want
>>> from them.
>>> >> The rest of the columns are not helpful for this specific exercise.
>>> >>
>>> >> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>> >> >
>>> >> > Dear friend Rui,
>>> >> >
>>> >> > Hope you are doing great. Firstly, I want to thank you for your
>>> super
>>> >> > valuable and kind support of always. As I mentioned in earlier
>>> e-mails, I
>>> >> > am trying to decode AIS type messages, and the only ones I am
>>> having a real
>>> >> > hard time with, is with latitude and longitude.
>>> >> >
>>> >> > I tried the function you provided me in one of your replies, and it
>>> works
>>> >> > well with the examples  you provided, but in other cases it doesn?t.
>>> >> >
>>> >> > The messages I am trying to decode are in the 6th column of the
>>> data. I
>>> >> > will provide you with a small sample first, and then the complete
>>> dataset
>>> >> > (which has 100 rows). This is the small sample:
>>> >> >
>>> >> > > head(dat)
>>> >> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7
>>>  ...8
>>> >> > ...9 ...10 ...11 ...12 ...13
>>> >> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54
>>> 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39
>>> 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D
>>> 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43
>>> 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29
>>> 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D
>>> 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> >
>>> >> > It is worth mentioning that each row of the 6th column provides
>>> several
>>> >> > information about maritime vessels, like speed over ground,
>>> latitude,
>>> >> > longitude, vessel ID, etc. I am only concerned with latitude and
>>> longitude
>>> >> > since those are the only two fields I have not been able to decode
>>> >> > successfully. Also, I am working on R version 3.6.2 for windows
>>> 64-bit OS.
>>> >> >
>>> >> > The messages to decode are of the following format:
>>> >> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
>>> >> >
>>> >> > Now, here is the complete dataset:
>>> >> >
>>> >> > > dput(dat)
>>> >> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM",
>>> "$GPGBS",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO",
>>> "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> "!AIVDM",
>>> >> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
>>> >> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> >> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
>>> >> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
>>> >> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
>>> >> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
>>> >> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
>>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
>>> >> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
>>> >> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
>>> >> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
>>> >> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
>>> >> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
>>> >> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
>>> >> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
>>> >> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
>>> >> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
>>> >> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
>>> >> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B",
>>> "3.2999999999999998",
>>> >> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
>>> >> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
>>> >> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
>>> >> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
>>> >> > "D03Iu6QGLN01MdN01StN000",
>>> >> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
>>> >> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
>>> >> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>>> >> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
>>> >> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
>>> >> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
>>> >> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
>>> >> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
>>> >> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
>>> >> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
>>> >> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00
>>> >TtPF1Asll03wPUwP06",
>>> >> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
>>> >> > "15>uP00P00rC`U:59im;H?v22 at 1D",
>>> >> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>>> >> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
>>> "15BkV00P00rCQBf5:Q5JQOv42D1o",
>>> >> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>>> >> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
>>> >> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
>>> >> > "15U?B00000rCgb>58DFJfRl620RT",
>>> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
>>> >> > @W9K4Oi0D at PC0ShK40C",
>>> >> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
>>> >> > "15De7F?P00JCr5r5517v4?v80h2P",
>>> >> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
>>> >> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
>>> >> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>>> >> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
>>> >> > "15E:BR0P00rCgaT58DdJUwv82H34",
>>> >> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
>>> >> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
>>> >> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
>>> >> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>>> >> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
>>> >> > "7933.8835099999997",
>>> >> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>>> >> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
>>> >> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
>>> >> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>>> >> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>>> >> > "B;s at N9h00>TtPG1Asm403wSUwP06",
>>> >> >
>>> >> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
>>> >> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
>>> >> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
>>> >> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
>>> >> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
>>> >> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>>> >> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>>> >> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
>>> >> > "15ATk20000rCnrv53N6;gPr>085R",
>>> >> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>>> >> >
>>> >> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
>>> >> > "15BW=20P00JCrvH54t=an?vB00Sg",
>>> >> > "13P;K8 at 001rCfgr58=f;QbFD2D4G",
>>> "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>>> >> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0",
>>> "1349B:3000rCtrn553aR at JHD2d4O",
>>> >> >
>>> >> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
>>> >> > "15B3Sj0000rC9RD5=mOh40jB20SU",
>>> >> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
>>> >> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
>>> >> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
>>> >> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
>>> >> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
>>> >> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
>>> >> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
>>> >> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
>>> >> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
>>> >> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
>>> >> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
>>> >> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
>>> >> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 =
>>> c(1485907200,
>>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>>> 1485907200,
>>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>>> 1485907200,
>>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>>> 1485907201,
>>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>>> 1485907201,
>>> >> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
>>> >> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
>>> >> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204,
>>> 1485907204,
>>> >> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
>>> 1485907204,
>>> >> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205,
>>> 1485907205,
>>> >> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206,
>>> 1485907206,
>>> >> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
>>> >> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
>>> >> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208,
>>> 1485907208,
>>> >> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209,
>>> 1485907209,
>>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
>>> 1485907209,
>>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
>>> >> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
>>> >> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
>>> >> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
>>> >> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> 1485907209,
>>> >> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
>>> >> >
>>> >> > To tested your function I took the first message, which is located
>>> in the
>>> >> > 6th column and the 1st row, and did the following:
>>> >> >
>>> >> > library(stringi)
>>> >> > library(dplyr)
>>> >> > library(R.utils)
>>> >> > library(RANN)
>>> >> > library(NISTunits)
>>> >> > library(pracma)
>>> >> > library(celestial)
>>> >> > library(stringr)
>>> >> >
>>> >> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE,
>>> na="",
>>> >> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
>>> >> >
>>> >> > testmessage1 <- dat[1,6]
>>> >> >
>>> >> > ascii_datformat <- utf8ToInt(testmessage1)
>>> >> >
>>> >> > Base <- ascii_datformat - 48
>>> >> >
>>> >> > decy <- ifelse(Base > 40, Base - 8, Base)
>>> >> >
>>> >> > biny <- intToBin(decy)
>>> >> >
>>> >> > binyframe <- data.frame(biny)
>>> >> >
>>> >> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point,
>>> I have
>>> >> > the complete first message, all in binary format
>>> >> >
>>> >> > #according to the literature of AIS message decoding, longitude
>>> goes from
>>> >> > position 62 to position 89
>>> >> > #and latitude goes from position 90 to position 116
>>> >> >
>>> >> > longitude <- substr(tbinyframe, 62, 89)
>>> >> > latitude    <- substr(tbinyframe, 90, 116)
>>> >> >
>>> >> > #now I apply the function you provided me with:
>>> >> >
>>> >> >  fun <- function(x){
>>> >> >          res <- sapply(x, function(y){
>>> >> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>>> >> >              strtoi(y, base = 2)
>>> >> >             }else{
>>> >> >               y <- unlist(strsplit(y, ""))
>>> >> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
>>> >> >             }
>>> >> >           })
>>> >> >           unname(res)
>>> >> >       }
>>> >> >
>>> >> > > fun(longitude)
>>> >> > [1] 220663102
>>> >> > >
>>> >> > > fun(latitude)
>>> >> > [1] 5414823
>>> >> > >
>>> >> > > fun("1101001001110000110100111110")
>>> >> > [1] 220663102
>>> >> > >
>>> >> > > fun("000010100101001111110100111")
>>> >> > [1] 5414823
>>> >> > >
>>> >> > > fun("10110010")
>>> >> > [1] -78
>>> >> >
>>> >> > as you can see, the function only worked or showed expected result
>>> on the
>>> >> > last case with a -78, but in the other cases, it the results were
>>> not as
>>> >> > expected, maybe I am missing something here?
>>> >> >
>>> >> > Any help and/or guidance will be greatly appreciated,
>>> >> >
>>> >> > Best regards,
>>> >> >
>>> >> > Paul
>>> >> >
>>> >> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<
>>> ruipbarradas at sapo.pt>)
>>> >> > escribi?:
>>> >> >
>>> >> > > Hello,
>>> >> > >
>>> >> > > The function I included converts signed binary numbers into their
>>> >> > > decimal representation. They are negative if a) they are
>>> multiples of 8
>>> >> > > bits and b) the most significant bit is a "1". If not just
>>> convert to
>>> >> > > integer.
>>> >> > >
>>> >> > > As for a) above, I assume that you will have 8 bit numbers. And
>>> the
>>> >> > > conversion is done as follows:
>>> >> > >
>>> >> > > input: 10110010
>>> >> > >
>>> >> > > splitting, to make it more clear:
>>> >> > >
>>> >> > > 1 0 1 1 0 0 1 0 - input
>>> >> > > 0 1 0 0 1 1 0 1 - reversed
>>> >> > >                1 - add 1 to the number with reversed bits
>>> >> > > 0 1 0 0 1 1 1 0 - result is the two's complement
>>> >> > >
>>> >> > > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
>>> >> > >
>>> >> > > But the msb is "1" so it's -78
>>> >> > >
>>> >> > >
>>> >> > > This is what the function does, but instead of %*% it uses
>>> >> > >
>>> >> > > sum(two's compl * powers of two)
>>> >> > >
>>> >> > >
>>> >> > > Hope this helps,
>>> >> > >
>>> >> > > Rui Barradas
>>> >> > >
>>> >> > > The input must be a character string or character vector.
>>> >> > >
>>> >> > > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
>>> >> > > > Dear friend Rui,
>>> >> > > >
>>> >> > > > Hope you are doing great, thanks for your kind feedback. The
>>> challenge I
>>> >> > > > currently have at hand is to decode AIS messages and obtain
>>> latitude and
>>> >> > > > longitude values from those.
>>> >> > > >
>>> >> > > > So basically, I want to accomplish something like in the
>>> example below.
>>> >> > > > I want to convert this binary number (10110010) into the two?s
>>> >> > > > complement representation, there is the logic they are using
>>> for that.
>>> >> > > > Since longitude ranges from
>>> >> > > >
>>> >> > > >
>>> >> > > >       Example of conversion to decimal of a signed binary
>>> number in
>>> >> > > >       two's complement representation
>>> >> > > >
>>> >> > > > Let's convert to decimal the following signed binary number:
>>> 10110010
>>> >> > > >
>>> >> > > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 +
>>> 0?20 = -128
>>> >> > > > + 32 + 16 + 2 = -78.
>>> >> > > >
>>> >> > > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<
>>> ruipbarradas at sapo.pt
>>> >> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
>>> >> > > >
>>> >> > > >     Sorry, missunderstood the problem.
>>> >> > > >     Here it goes:
>>> >> > > >
>>> >> > > >     fun <- function(x){
>>> >> > > >         res <- sapply(x, function(y){
>>> >> > > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>>> >> > > >             strtoi(y, base = 2)
>>> >> > > >           }else{
>>> >> > > >             y <- unlist(strsplit(y, ""))
>>> >> > > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
>>> >> > > >           }
>>> >> > > >         })
>>> >> > > >         unname(res)
>>> >> > > >     }
>>> >> > > >
>>> >> > > >     fun("10110010")
>>> >> > > >     fun("10000000")
>>> >> > > >     fun(c("01000000", "01111111", "10110010", "10000000"))
>>> >> > > >
>>> >> > > >
>>> >> > > >     Hope this helps,
>>> >> > > >
>>> >> > > >     Rui Barradas
>>> >> > > >
>>> >> > > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
>>> >> > > >      > Hello,
>>> >> > > >      >
>>> >> > > >      > Is this what you want?
>>> >> > > >      >
>>> >> > > >      >
>>> >> > > >      > x <- "10110010"
>>> >> > > >      > strtoi(x, base = 2)
>>> >> > > >      > #[1] 178
>>> >> > > >      >
>>> >> > > >      >
>>> >> > > >      > Hope this helps,
>>> >> > > >      >
>>> >> > > >      > Rui Barradas
>>> >> > > >      >
>>> >> > > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
>>> >> > > >      >> Dear friends,
>>> >> > > >      >>
>>> >> > > >      >> How can I convert the following binary number in two?s
>>> complement
>>> >> > > >      >> representation in R?
>>> >> > > >      >>
>>> >> > > >      >> 10110010
>>> >> > > >      >>
>>> >> > > >      >> Any help and/or guidance will be greatly appreciated,
>>> >> > > >      >>
>>> >> > > >      >> Best regards,
>>> >> > > >      >>
>>> >> > > >      >> Paul
>>> >> > > >      >>
>>> >> > > >      >>     [[alternative HTML version deleted]]
>>> >> > > >      >>
>>> >> > > >      >> ______________________________________________
>>> >> > > >      >> R-help at r-project.org <mailto:R-help at r-project.org>
>>> mailing list
>>> >> > > >     -- To UNSUBSCRIBE and more, see
>>> >> > > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > > >      >> PLEASE do read the posting guide
>>> >> > > >      >> http://www.R-project.org/posting-guide.html
>>> >> > > >      >> and provide commented, minimal, self-contained,
>>> reproducible
>>> >> > > code.
>>> >> > > >      >>
>>> >> > > >      >
>>> >> > > >      > ______________________________________________
>>> >> > > >      > R-help at r-project.org <mailto:R-help at r-project.org>
>>> mailing list
>>> >> > > >     -- To UNSUBSCRIBE and more, see
>>> >> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > > >      > PLEASE do read the posting guide
>>> >> > > >      > http://www.R-project.org/posting-guide.html
>>> >> > > >      > and provide commented, minimal, self-contained,
>>> reproducible code.
>>> >> > > >
>>> >> > >
>>> >> >
>>> >> >         [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jan 25 00:09:07 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Jan 2020 23:09:07 +0000
Subject: [R] Did the output from summary(lm(...)) change
In-Reply-To: <7943CAC1-4463-4E1E-BF20-3674BD798FC4@plessthan.com>
References: <7943CAC1-4463-4E1E-BF20-3674BD798FC4@plessthan.com>
Message-ID: <6c23704a-5229-4ddc-ca14-19b940f23e98@sapo.pt>

Hello,

No, your memory is wrong, like you say.

summary(lm(.)) returns a matrix with the 4th column named "Pr(>|t|)", 
not "p.value". And this hasn't changed. If you want the p-values, the 
(old) way to do it still is

summary(lm(.))$coefficients[, 4]

or, more complicated,

summary(lm(.))$coefficients[, "Pr(>|t|)"]


Hope this helps,

Rui Barradas


?s 21:27 de 24/01/20, Dennis Fisher escreveu:
> R 3.6.1
> OS X
> 
> Colleagues
> 
> My recollection (possibly wrong) is that:
> 	summary(lm(YVAR ~ XVAR))$p.value
> used to return the P value for a linear regression.  It does not appear to do so now.
> Of note:
> 	summary(lm(YVAR ~ XVAR))
> does report the P value.
> 
> I realize that I can access the P value from:
> 	summary(lm(YVAR ~ XVAR))$coeff
> but I am curious as to whether my memory is flawed.
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com <http://www.plessthan.com/>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From v@|kremk @end|ng |rom gm@||@com  Sat Jan 25 04:09:34 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 24 Jan 2020 21:09:34 -0600
Subject: [R] Mixed format
In-Reply-To: <8c480a90-3b57-709a-a836-6f271426cc09@sapo.pt>
References: <CAJOiR6aWLuB=sSFmxOsqAA4ModEokdt51AWHGvoqGXvb7qk_mw@mail.gmail.com>
 <02b23128-eaf2-9745-d601-81208a270894@sapo.pt>
 <1255043385.4404444.1579598544376.JavaMail.zimbra@psyctc.org>
 <8c480a90-3b57-709a-a836-6f271426cc09@sapo.pt>
Message-ID: <CAJOiR6aWa8c2LsDCyXs9xvxrkftxGCSPONGoYZhL_XMTTyZKMQ@mail.gmail.com>

Thank you all for your help.
My data has  mixed  format such as
%m/%d/%y,%d/%m/%y,%m-%d-%y,%d-%m-%y etc. and
the library (anytime) handles it very well!!

Thank you again.


On Tue, Jan 21, 2020 at 5:28 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Inline.
>
> ?s 09:22 de 21/01/20, Chris Evans escreveu:
> > I think that might risk giving the wrong date for a date like 1/3/1990 which I think in Val's data is mdy data not dmy.
> >
> > As I read the data, where the separator is "/" the format is mdy and where the separator is "-" it's dmy.
>
> Maybe you're right. But I really don't know, in my country (Portugal) we
> use "/" and dmy. Anyway, what's important is that the OP must have a
> much better understanding of the data, the way it is posted is likely to
> cause errors. See, for instance, the expected output with numbers
> greater than 12 in the 1st and 2nd places, depending on the row.
>
>
> So I would
> > go for:
> >
> > library(lubridate)
> > DFX$dnew[grep("-", DFX$ddate, fixed = TRUE)] <- dmy(DFX$ddate[grep("-", DFX$ddate, fixed = TRUE)])
> > DFX$dnew[grep("/", DFX$ddate, fixed = TRUE)] <- mdy(DFX$ddate[grep("/", DFX$ddate, fixed = TRUE)])
> > DFX <- DFX[!is.na(DFX$dnew),]
> > DFX
> >
> >    name      ddate       dnew
> > 1    A   19-10-02 2002-10-19
> > 2    B   22-11-20 2020-11-22
> > 3    C   19-01-15 2015-01-19
> > 4    D 11/19/2006 2006-11-19
> > 5    F   9/9/2011 2011-09-09
> > 6    G 12/29/2010 2010-12-29
> >
> > But I am so much in awe of Rui's skills with R, and that of most of the regular commentators here, that I submit
> > this a little nervously!
>
> Thanks!
>
> Rui Barradas
> >
> > Many thanks to all who teach me so much here, lovely, if I am correct, to contribute for a change!
> >
> > Chris
> >
> >
> > ----- Original Message -----
> >> From: "Rui Barradas" <ruipbarradas at sapo.pt>
> >> To: "Val" <valkremk at gmail.com>, "r-help at R-project.org (r-help at r-project.org)" <r-help at r-project.org>
> >> Sent: Tuesday, 21 January, 2020 00:40:29
> >> Subject: Re: [R] Mixed format
> >
> >> Hello,
> >>
> >> The following strategy works with your data.
> >> It uses the fact that most dates are in one of 3 formats, dmy, mdy, ymd.
> >> It tries those formats one by one, after each try looks for NA's in the
> >> new column.
> >>
> >>
> >> # first round, format is dmy
> >> DFX$dnew <- lubridate::dmy(DFX$ddate)
> >> na <- is.na(DFX$dnew)
> >>
> >> # second round, format is mdy
> >> DFX$dnew[na] <- lubridate::mdy(DFX$ddate[na])
> >> na <- is.na(DFX$dnew)
> >>
> >> # last round, format is ymd
> >> DFX$dnew[na] <- lubridate::ymd(DFX$ddate[na])
> >>
> >> # remove what didn't fit any format
> >> DFX <- DFX[!is.na(DFX$dnew), ]
> >> DFX
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >> ?s 22:58 de 20/01/20, Val escreveu:
> >>> Hi All,
> >>>
> >>> I have a data frame where one column is  a mixed date format,
> >>> a date in the form "%m-%d-%y"  and "%m/%d/%Y", also some are not in date format.
> >>>
> >>> Is there a way to delete the rows that contain non-dates  and
> >>> standardize the dates in one date format like  %m-%d-%Y?
> >>> Please see my  sample data and desired output
> >>>
> >>> DFX<-read.table(text="name ddate
> >>>     A  19-10-02
> >>>     B  22-11-20u
> >>>     C  19-01-15
> >>>     D  11/19/2006
> >>>     F  9/9/2011
> >>>     G  12/29/2010
> >>>     H  DEX",header=TRUE)
> >>>
> >>> Desired output
> >>> name ddate
> >>> A  19-10-2002
> >>> B  22-11-2020
> >>> C  19-01-2015
> >>> D  11-19-2006
> >>> F  09-09-2011
> >>> G  12-29-2010
> >>>
> >>> Thank you
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >


From rmh @end|ng |rom temp|e@edu  Sat Jan 25 22:03:03 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sat, 25 Jan 2020 16:03:03 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
 <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
 <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>
 <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>
Message-ID: <CAGx1TMAz=9KMuLPJGNk2Mdt-=7R40OCi87TfvgwnB4-7f4qAgg@mail.gmail.com>

## from2Comp uses base R functions only
from2Comp <- function(x, binDigits=8) {
  ## binDigits=8 means 8 significant digits plus a sign bit, thus nchar(x) == 9
  tmp <- strtoi(x, base=2)
  Neg <- (tmp > (2^binDigits - 1))
  tmp[Neg] <- tmp[Neg] - (2^(binDigits + 1))
  tmp
}

from2Comp(substr(as.character(LatitudeFrame[,2]), 24, 31), 7)

from2Comp(substr(as.character(LatitudeFrame[,2]), 23, 31), 8)
from2Comp(substr(as.character(LongitudeFrame[,2]), 23, 31), 8)

from2Comp(as.character(LatitudeFrame[,2]), 30)
from2Comp(as.character(LongitudeFrame[,2]), 30)


## I don't see any system in AISMessageFrame
tail(AISMessageFrame)
##                                      MessgeCode
## 95  85E:BR0F0P0000000000032jS2P000000DE7P3A00h0
## 96                 1349B:3000rCtrn553aR at JHD2d4O
## 97                           7933.8835099999997
## 98                 B;s at N9h00>TtPFQAsm803wU5wP06
## 99                 15B3Sj0000rC9RD5=mOh40jB20SU
## 100                15TgVb0000rCgVb57oFc;ARF2 at 67


## 180Long = -180Long, thus there is duplication.  How do you handle this?
## 90Lat  != -90Lat, so there is no duplication.
## How are minutes and seconds stored?

On Fri, Jan 24, 2020 at 5:39 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> I don't have my computer with me, so I am commenting right now on the visual impression of the email.
>
> The latitude shows 90, 88, ... 2, 89, ...
> The labels are lexicographically ordered
> -1, -10, -11,...
>
> The latitude binrep look in correct order, and the labels looks like binary in order.
>
> These things are identified as factors, not as character.
>
> Please ensure that character values are not misinterpreted as factor when you construct your data frames.
>
> The four columns do not look to be in consistent order with each other. This in itself could cause trouble.
>
> I will look more when I have my computer running R so I can follow the rest of what you wrote.
>
> Rich
>
> On Fri, Jan 24, 2020 at 15:02 Paul Bernal <paulbernal07 at gmail.com> wrote:
>>
>> Dear friend Richard,
>>
>> Thank you for your interest in helping me through this challenge. As requested, I am providing the two lat and long frames you suggested, plus the one single column I am trying to decode:
>>
>> LatitudeFrame:
>>
>> > dput(LatitudeFrame)
>> structure(list(Latitude = structure(c(90L, 88L, 87L, 86L, 85L,
>> 84L, 83L, 82L, 81L, 80L, 79L, 77L, 76L, 75L, 74L, 73L, 72L, 71L,
>> 70L, 69L, 68L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L, 57L,
>> 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 46L, 44L, 43L, 42L,
>> 41L, 40L, 39L, 38L, 37L, 36L, 35L, 33L, 32L, 31L, 30L, 29L, 28L,
>> 27L, 26L, 25L, 24L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L, 14L,
>> 13L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 89L, 78L, 67L,
>> 56L, 45L, 34L, 23L, 12L, 1L, 91L, 92L, 103L, 114L, 125L, 136L,
>> 147L, 158L, 169L, 180L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
>> 101L, 102L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
>> 113L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
>> 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 137L,
>> 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 148L, 149L,
>> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 159L, 160L, 161L,
>> 162L, 163L, 164L, 165L, 166L, 167L, 168L, 170L, 171L, 172L, 173L,
>> 174L, 175L, 176L, 177L, 178L, 179L, 181L), .Label = c("-1", "-10",
>> "-11", "-12", "-13", "-14", "-15", "-16", "-17", "-18", "-19",
>> "-2", "-20", "-21", "-22", "-23", "-24", "-25", "-26", "-27",
>> "-28", "-29", "-3", "-30", "-31", "-32", "-33", "-34", "-35",
>> "-36", "-37", "-38", "-39", "-4", "-40", "-41", "-42", "-43",
>> "-44", "-45", "-46", "-47", "-48", "-49", "-5", "-50", "-51",
>> "-52", "-53", "-54", "-55", "-56", "-57", "-58", "-59", "-6",
>> "-60", "-61", "-62", "-63", "-64", "-65", "-66", "-67", "-68",
>> "-69", "-7", "-70", "-71", "-72", "-73", "-74", "-75", "-76",
>> "-77", "-78", "-79", "-8", "-80", "-81", "-82", "-83", "-84",
>> "-85", "-86", "-87", "-88", "-89", "-9", "-90", "0", "1", "10",
>> "11", "12", "13", "14", "15", "16", "17", "18", "19", "2", "20",
>> "21", "22", "23", "24", "25", "26", "27", "28", "29", "3", "30",
>> "31", "32", "33", "34", "35", "36", "37", "38", "39", "4", "40",
>> "41", "42", "43", "44", "45", "46", "47", "48", "49", "5", "50",
>> "51", "52", "53", "54", "55", "56", "57", "58", "59", "6", "60",
>> "61", "62", "63", "64", "65", "66", "67", "68", "69", "7", "70",
>> "71", "72", "73", "74", "75", "76", "77", "78", "79", "8", "80",
>> "81", "82", "83", "84", "85", "86", "87", "88", "89", "9", "90"
>> ), class = "factor"), LatitudeBinRep = structure(c(92L, 93L,
>> 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L,
>> 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L,
>> 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L,
>> 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L,
>> 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
>> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
>> 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L,
>> 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 1L,
>> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
>> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
>> 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
>> 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L,
>> 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L,
>> 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
>> 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L), .Label = c("0000000000000000000000000000000",
>> "0000000000000000000000000000001", "0000000000000000000000000000010",
>> "0000000000000000000000000000011", "0000000000000000000000000000100",
>> "0000000000000000000000000000101", "0000000000000000000000000000110",
>> "0000000000000000000000000000111", "0000000000000000000000000001000",
>> "0000000000000000000000000001001", "0000000000000000000000000001010",
>> "0000000000000000000000000001011", "0000000000000000000000000001100",
>> "0000000000000000000000000001101", "0000000000000000000000000001110",
>> "0000000000000000000000000001111", "0000000000000000000000000010000",
>> "0000000000000000000000000010001", "0000000000000000000000000010010",
>> "0000000000000000000000000010011", "0000000000000000000000000010100",
>> "0000000000000000000000000010101", "0000000000000000000000000010110",
>> "0000000000000000000000000010111", "0000000000000000000000000011000",
>> "0000000000000000000000000011001", "0000000000000000000000000011010",
>> "0000000000000000000000000011011", "0000000000000000000000000011100",
>> "0000000000000000000000000011101", "0000000000000000000000000011110",
>> "0000000000000000000000000011111", "0000000000000000000000000100000",
>> "0000000000000000000000000100001", "0000000000000000000000000100010",
>> "0000000000000000000000000100011", "0000000000000000000000000100100",
>> "0000000000000000000000000100101", "0000000000000000000000000100110",
>> "0000000000000000000000000100111", "0000000000000000000000000101000",
>> "0000000000000000000000000101001", "0000000000000000000000000101010",
>> "0000000000000000000000000101011", "0000000000000000000000000101100",
>> "0000000000000000000000000101101", "0000000000000000000000000101110",
>> "0000000000000000000000000101111", "0000000000000000000000000110000",
>> "0000000000000000000000000110001", "0000000000000000000000000110010",
>> "0000000000000000000000000110011", "0000000000000000000000000110100",
>> "0000000000000000000000000110101", "0000000000000000000000000110110",
>> "0000000000000000000000000110111", "0000000000000000000000000111000",
>> "0000000000000000000000000111001", "0000000000000000000000000111010",
>> "0000000000000000000000000111011", "0000000000000000000000000111100",
>> "0000000000000000000000000111101", "0000000000000000000000000111110",
>> "0000000000000000000000000111111", "0000000000000000000000001000000",
>> "0000000000000000000000001000001", "0000000000000000000000001000010",
>> "0000000000000000000000001000011", "0000000000000000000000001000100",
>> "0000000000000000000000001000101", "0000000000000000000000001000110",
>> "0000000000000000000000001000111", "0000000000000000000000001001000",
>> "0000000000000000000000001001001", "0000000000000000000000001001010",
>> "0000000000000000000000001001011", "0000000000000000000000001001100",
>> "0000000000000000000000001001101", "0000000000000000000000001001110",
>> "0000000000000000000000001001111", "0000000000000000000000001010000",
>> "0000000000000000000000001010001", "0000000000000000000000001010010",
>> "0000000000000000000000001010011", "0000000000000000000000001010100",
>> "0000000000000000000000001010101", "0000000000000000000000001010110",
>> "0000000000000000000000001010111", "0000000000000000000000001011000",
>> "0000000000000000000000001011001", "0000000000000000000000001011010",
>> "1111111111111111111111110100110", "1111111111111111111111110100111",
>> "1111111111111111111111110101000", "1111111111111111111111110101001",
>> "1111111111111111111111110101010", "1111111111111111111111110101011",
>> "1111111111111111111111110101100", "1111111111111111111111110101101",
>> "1111111111111111111111110101110", "1111111111111111111111110101111",
>> "1111111111111111111111110110000", "1111111111111111111111110110001",
>> "1111111111111111111111110110010", "1111111111111111111111110110011",
>> "1111111111111111111111110110100", "1111111111111111111111110110101",
>> "1111111111111111111111110110110", "1111111111111111111111110110111",
>> "1111111111111111111111110111000", "1111111111111111111111110111001",
>> "1111111111111111111111110111010", "1111111111111111111111110111011",
>> "1111111111111111111111110111100", "1111111111111111111111110111101",
>> "1111111111111111111111110111110", "1111111111111111111111110111111",
>> "1111111111111111111111111000000", "1111111111111111111111111000001",
>> "1111111111111111111111111000010", "1111111111111111111111111000011",
>> "1111111111111111111111111000100", "1111111111111111111111111000101",
>> "1111111111111111111111111000110", "1111111111111111111111111000111",
>> "1111111111111111111111111001000", "1111111111111111111111111001001",
>> "1111111111111111111111111001010", "1111111111111111111111111001011",
>> "1111111111111111111111111001100", "1111111111111111111111111001101",
>> "1111111111111111111111111001110", "1111111111111111111111111001111",
>> "1111111111111111111111111010000", "1111111111111111111111111010001",
>> "1111111111111111111111111010010", "1111111111111111111111111010011",
>> "1111111111111111111111111010100", "1111111111111111111111111010101",
>> "1111111111111111111111111010110", "1111111111111111111111111010111",
>> "1111111111111111111111111011000", "1111111111111111111111111011001",
>> "1111111111111111111111111011010", "1111111111111111111111111011011",
>> "1111111111111111111111111011100", "1111111111111111111111111011101",
>> "1111111111111111111111111011110", "1111111111111111111111111011111",
>> "1111111111111111111111111100000", "1111111111111111111111111100001",
>> "1111111111111111111111111100010", "1111111111111111111111111100011",
>> "1111111111111111111111111100100", "1111111111111111111111111100101",
>> "1111111111111111111111111100110", "1111111111111111111111111100111",
>> "1111111111111111111111111101000", "1111111111111111111111111101001",
>> "1111111111111111111111111101010", "1111111111111111111111111101011",
>> "1111111111111111111111111101100", "1111111111111111111111111101101",
>> "1111111111111111111111111101110", "1111111111111111111111111101111",
>> "1111111111111111111111111110000", "1111111111111111111111111110001",
>> "1111111111111111111111111110010", "1111111111111111111111111110011",
>> "1111111111111111111111111110100", "1111111111111111111111111110101",
>> "1111111111111111111111111110110", "1111111111111111111111111110111",
>> "1111111111111111111111111111000", "1111111111111111111111111111001",
>> "1111111111111111111111111111010", "1111111111111111111111111111011",
>> "1111111111111111111111111111100", "1111111111111111111111111111101",
>> "1111111111111111111111111111110", "1111111111111111111111111111111"
>> ), class = "factor")), class = "data.frame", row.names = c(NA,
>> -181L))
>>
>> LongitudeFrame:
>>
>> > dput(LongitudeFrame)
>> structure(list(Longitude = structure(c(91L, 89L, 88L, 87L, 86L,
>> 85L, 84L, 83L, 82L, 81L, 80L, 78L, 77L, 76L, 75L, 74L, 73L, 72L,
>> 71L, 70L, 69L, 67L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L,
>> 56L, 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 45L, 44L, 43L,
>> 42L, 41L, 40L, 39L, 38L, 37L, 36L, 34L, 33L, 32L, 31L, 30L, 29L,
>> 28L, 27L, 26L, 25L, 23L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L,
>> 14L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 180L, 179L, 178L,
>> 177L, 176L, 175L, 174L, 173L, 172L, 171L, 169L, 168L, 167L, 166L,
>> 165L, 164L, 163L, 162L, 161L, 160L, 158L, 157L, 156L, 155L, 154L,
>> 153L, 152L, 151L, 150L, 149L, 147L, 146L, 145L, 144L, 143L, 142L,
>> 141L, 140L, 139L, 138L, 136L, 135L, 134L, 133L, 132L, 131L, 130L,
>> 129L, 128L, 127L, 125L, 124L, 123L, 122L, 121L, 120L, 119L, 118L,
>> 117L, 116L, 114L, 113L, 112L, 111L, 110L, 109L, 108L, 107L, 106L,
>> 105L, 103L, 102L, 101L, 100L, 99L, 98L, 97L, 96L, 95L, 94L, 92L,
>> 90L, 79L, 68L, 57L, 46L, 35L, 24L, 13L, 2L, 170L, 159L, 148L,
>> 137L, 126L, 115L, 104L, 93L, 1L, 181L, 182L, 274L, 285L, 296L,
>> 307L, 318L, 329L, 340L, 351L, 183L, 194L, 205L, 216L, 227L, 238L,
>> 249L, 260L, 271L, 273L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
>> 282L, 283L, 284L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L,
>> 294L, 295L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 305L,
>> 306L, 308L, 309L, 310L, 311L, 312L, 313L, 314L, 315L, 316L, 317L,
>> 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 330L,
>> 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 341L, 342L,
>> 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L,
>> 355L, 356L, 357L, 358L, 359L, 360L, 361L, 184L, 185L, 186L, 187L,
>> 188L, 189L, 190L, 191L, 192L, 193L, 195L, 196L, 197L, 198L, 199L,
>> 200L, 201L, 202L, 203L, 204L, 206L, 207L, 208L, 209L, 210L, 211L,
>> 212L, 213L, 214L, 215L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
>> 224L, 225L, 226L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
>> 236L, 237L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
>> 248L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
>> 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L, 272L
>> ), .Label = c("-1", "-10", "-100", "-101", "-102", "-103", "-104",
>> "-105", "-106", "-107", "-108", "-109", "-11", "-110", "-111",
>> "-112", "-113", "-114", "-115", "-116", "-117", "-118", "-119",
>> "-12", "-120", "-121", "-122", "-123", "-124", "-125", "-126",
>> "-127", "-128", "-129", "-13", "-130", "-131", "-132", "-133",
>> "-134", "-135", "-136", "-137", "-138", "-139", "-14", "-140",
>> "-141", "-142", "-143", "-144", "-145", "-146", "-147", "-148",
>> "-149", "-15", "-150", "-151", "-152", "-153", "-154", "-155",
>> "-156", "-157", "-158", "-159", "-16", "-160", "-161", "-162",
>> "-163", "-164", "-165", "-166", "-167", "-168", "-169", "-17",
>> "-170", "-171", "-172", "-173", "-174", "-175", "-176", "-177",
>> "-178", "-179", "-18", "-180", "-19", "-2", "-20", "-21", "-22",
>> "-23", "-24", "-25", "-26", "-27", "-28", "-29", "-3", "-30",
>> "-31", "-32", "-33", "-34", "-35", "-36", "-37", "-38", "-39",
>> "-4", "-40", "-41", "-42", "-43", "-44", "-45", "-46", "-47",
>> "-48", "-49", "-5", "-50", "-51", "-52", "-53", "-54", "-55",
>> "-56", "-57", "-58", "-59", "-6", "-60", "-61", "-62", "-63",
>> "-64", "-65", "-66", "-67", "-68", "-69", "-7", "-70", "-71",
>> "-72", "-73", "-74", "-75", "-76", "-77", "-78", "-79", "-8",
>> "-80", "-81", "-82", "-83", "-84", "-85", "-86", "-87", "-88",
>> "-89", "-9", "-90", "-91", "-92", "-93", "-94", "-95", "-96",
>> "-97", "-98", "-99", "0", "1", "10", "100", "101", "102", "103",
>> "104", "105", "106", "107", "108", "109", "11", "110", "111",
>> "112", "113", "114", "115", "116", "117", "118", "119", "12",
>> "120", "121", "122", "123", "124", "125", "126", "127", "128",
>> "129", "13", "130", "131", "132", "133", "134", "135", "136",
>> "137", "138", "139", "14", "140", "141", "142", "143", "144",
>> "145", "146", "147", "148", "149", "15", "150", "151", "152",
>> "153", "154", "155", "156", "157", "158", "159", "16", "160",
>> "161", "162", "163", "164", "165", "166", "167", "168", "169",
>> "17", "170", "171", "172", "173", "174", "175", "176", "177",
>> "178", "179", "18", "180", "19", "2", "20", "21", "22", "23",
>> "24", "25", "26", "27", "28", "29", "3", "30", "31", "32", "33",
>> "34", "35", "36", "37", "38", "39", "4", "40", "41", "42", "43",
>> "44", "45", "46", "47", "48", "49", "5", "50", "51", "52", "53",
>> "54", "55", "56", "57", "58", "59", "6", "60", "61", "62", "63",
>> "64", "65", "66", "67", "68", "69", "7", "70", "71", "72", "73",
>> "74", "75", "76", "77", "78", "79", "8", "80", "81", "82", "83",
>> "84", "85", "86", "87", "88", "89", "9", "90", "91", "92", "93",
>> "94", "95", "96", "97", "98", "99"), class = "factor"), LongitudeBinRep = structure(c(182L,
>> 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 193L,
>> 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L,
>> 205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
>> 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L,
>> 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L, 236L, 237L,
>> 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L, 248L,
>> 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
>> 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L,
>> 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
>> 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L,
>> 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L,
>> 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,
>> 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L,
>> 326L, 327L, 328L, 329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L,
>> 337L, 338L, 339L, 340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L,
>> 348L, 349L, 350L, 351L, 352L, 353L, 354L, 355L, 356L, 357L, 358L,
>> 359L, 360L, 361L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
>> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
>> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
>> 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L,
>> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L,
>> 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
>> 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
>> 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L,
>> 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
>> 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L,
>> 124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L,
>> 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
>> 146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L,
>> 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L,
>> 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
>> 179L, 180L, 181L), .Label = c("0000000000000000000000000000000",
>> "0000000000000000000000000000001", "0000000000000000000000000000010",
>> "0000000000000000000000000000011", "0000000000000000000000000000100",
>> "0000000000000000000000000000101", "0000000000000000000000000000110",
>> "0000000000000000000000000000111", "0000000000000000000000000001000",
>> "0000000000000000000000000001001", "0000000000000000000000000001010",
>> "0000000000000000000000000001011", "0000000000000000000000000001100",
>> "0000000000000000000000000001101", "0000000000000000000000000001110",
>> "0000000000000000000000000001111", "0000000000000000000000000010000",
>> "0000000000000000000000000010001", "0000000000000000000000000010010",
>> "0000000000000000000000000010011", "0000000000000000000000000010100",
>> "0000000000000000000000000010101", "0000000000000000000000000010110",
>> "0000000000000000000000000010111", "0000000000000000000000000011000",
>> "0000000000000000000000000011001", "0000000000000000000000000011010",
>> "0000000000000000000000000011011", "0000000000000000000000000011100",
>> "0000000000000000000000000011101", "0000000000000000000000000011110",
>> "0000000000000000000000000011111", "0000000000000000000000000100000",
>> "0000000000000000000000000100001", "0000000000000000000000000100010",
>> "0000000000000000000000000100011", "0000000000000000000000000100100",
>> "0000000000000000000000000100101", "0000000000000000000000000100110",
>> "0000000000000000000000000100111", "0000000000000000000000000101000",
>> "0000000000000000000000000101001", "0000000000000000000000000101010",
>> "0000000000000000000000000101011", "0000000000000000000000000101100",
>> "0000000000000000000000000101101", "0000000000000000000000000101110",
>> "0000000000000000000000000101111", "0000000000000000000000000110000",
>> "0000000000000000000000000110001", "0000000000000000000000000110010",
>> "0000000000000000000000000110011", "0000000000000000000000000110100",
>> "0000000000000000000000000110101", "0000000000000000000000000110110",
>> "0000000000000000000000000110111", "0000000000000000000000000111000",
>> "0000000000000000000000000111001", "0000000000000000000000000111010",
>> "0000000000000000000000000111011", "0000000000000000000000000111100",
>> "0000000000000000000000000111101", "0000000000000000000000000111110",
>> "0000000000000000000000000111111", "0000000000000000000000001000000",
>> "0000000000000000000000001000001", "0000000000000000000000001000010",
>> "0000000000000000000000001000011", "0000000000000000000000001000100",
>> "0000000000000000000000001000101", "0000000000000000000000001000110",
>> "0000000000000000000000001000111", "0000000000000000000000001001000",
>> "0000000000000000000000001001001", "0000000000000000000000001001010",
>> "0000000000000000000000001001011", "0000000000000000000000001001100",
>> "0000000000000000000000001001101", "0000000000000000000000001001110",
>> "0000000000000000000000001001111", "0000000000000000000000001010000",
>> "0000000000000000000000001010001", "0000000000000000000000001010010",
>> "0000000000000000000000001010011", "0000000000000000000000001010100",
>> "0000000000000000000000001010101", "0000000000000000000000001010110",
>> "0000000000000000000000001010111", "0000000000000000000000001011000",
>> "0000000000000000000000001011001", "0000000000000000000000001011010",
>> "0000000000000000000000001011011", "0000000000000000000000001011100",
>> "0000000000000000000000001011101", "0000000000000000000000001011110",
>> "0000000000000000000000001011111", "0000000000000000000000001100000",
>> "0000000000000000000000001100001", "0000000000000000000000001100010",
>> "0000000000000000000000001100011", "0000000000000000000000001100100",
>> "0000000000000000000000001100101", "0000000000000000000000001100110",
>> "0000000000000000000000001100111", "0000000000000000000000001101000",
>> "0000000000000000000000001101001", "0000000000000000000000001101010",
>> "0000000000000000000000001101011", "0000000000000000000000001101100",
>> "0000000000000000000000001101101", "0000000000000000000000001101110",
>> "0000000000000000000000001101111", "0000000000000000000000001110000",
>> "0000000000000000000000001110001", "0000000000000000000000001110010",
>> "0000000000000000000000001110011", "0000000000000000000000001110100",
>> "0000000000000000000000001110101", "0000000000000000000000001110110",
>> "0000000000000000000000001110111", "0000000000000000000000001111000",
>> "0000000000000000000000001111001", "0000000000000000000000001111010",
>> "0000000000000000000000001111011", "0000000000000000000000001111100",
>> "0000000000000000000000001111101", "0000000000000000000000001111110",
>> "0000000000000000000000001111111", "0000000000000000000000010000000",
>> "0000000000000000000000010000001", "0000000000000000000000010000010",
>> "0000000000000000000000010000011", "0000000000000000000000010000100",
>> "0000000000000000000000010000101", "0000000000000000000000010000110",
>> "0000000000000000000000010000111", "0000000000000000000000010001000",
>> "0000000000000000000000010001001", "0000000000000000000000010001010",
>> "0000000000000000000000010001011", "0000000000000000000000010001100",
>> "0000000000000000000000010001101", "0000000000000000000000010001110",
>> "0000000000000000000000010001111", "0000000000000000000000010010000",
>> "0000000000000000000000010010001", "0000000000000000000000010010010",
>> "0000000000000000000000010010011", "0000000000000000000000010010100",
>> "0000000000000000000000010010101", "0000000000000000000000010010110",
>> "0000000000000000000000010010111", "0000000000000000000000010011000",
>> "0000000000000000000000010011001", "0000000000000000000000010011010",
>> "0000000000000000000000010011011", "0000000000000000000000010011100",
>> "0000000000000000000000010011101", "0000000000000000000000010011110",
>> "0000000000000000000000010011111", "0000000000000000000000010100000",
>> "0000000000000000000000010100001", "0000000000000000000000010100010",
>> "0000000000000000000000010100011", "0000000000000000000000010100100",
>> "0000000000000000000000010100101", "0000000000000000000000010100110",
>> "0000000000000000000000010100111", "0000000000000000000000010101000",
>> "0000000000000000000000010101001", "0000000000000000000000010101010",
>> "0000000000000000000000010101011", "0000000000000000000000010101100",
>> "0000000000000000000000010101101", "0000000000000000000000010101110",
>> "0000000000000000000000010101111", "0000000000000000000000010110000",
>> "0000000000000000000000010110001", "0000000000000000000000010110010",
>> "0000000000000000000000010110011", "0000000000000000000000010110100",
>> "1111111111111111111111101001100", "1111111111111111111111101001101",
>> "1111111111111111111111101001110", "1111111111111111111111101001111",
>> "1111111111111111111111101010000", "1111111111111111111111101010001",
>> "1111111111111111111111101010010", "1111111111111111111111101010011",
>> "1111111111111111111111101010100", "1111111111111111111111101010101",
>> "1111111111111111111111101010110", "1111111111111111111111101010111",
>> "1111111111111111111111101011000", "1111111111111111111111101011001",
>> "1111111111111111111111101011010", "1111111111111111111111101011011",
>> "1111111111111111111111101011100", "1111111111111111111111101011101",
>> "1111111111111111111111101011110", "1111111111111111111111101011111",
>> "1111111111111111111111101100000", "1111111111111111111111101100001",
>> "1111111111111111111111101100010", "1111111111111111111111101100011",
>> "1111111111111111111111101100100", "1111111111111111111111101100101",
>> "1111111111111111111111101100110", "1111111111111111111111101100111",
>> "1111111111111111111111101101000", "1111111111111111111111101101001",
>> "1111111111111111111111101101010", "1111111111111111111111101101011",
>> "1111111111111111111111101101100", "1111111111111111111111101101101",
>> "1111111111111111111111101101110", "1111111111111111111111101101111",
>> "1111111111111111111111101110000", "1111111111111111111111101110001",
>> "1111111111111111111111101110010", "1111111111111111111111101110011",
>> "1111111111111111111111101110100", "1111111111111111111111101110101",
>> "1111111111111111111111101110110", "1111111111111111111111101110111",
>> "1111111111111111111111101111000", "1111111111111111111111101111001",
>> "1111111111111111111111101111010", "1111111111111111111111101111011",
>> "1111111111111111111111101111100", "1111111111111111111111101111101",
>> "1111111111111111111111101111110", "1111111111111111111111101111111",
>> "1111111111111111111111110000000", "1111111111111111111111110000001",
>> "1111111111111111111111110000010", "1111111111111111111111110000011",
>> "1111111111111111111111110000100", "1111111111111111111111110000101",
>> "1111111111111111111111110000110", "1111111111111111111111110000111",
>> "1111111111111111111111110001000", "1111111111111111111111110001001",
>> "1111111111111111111111110001010", "1111111111111111111111110001011",
>> "1111111111111111111111110001100", "1111111111111111111111110001101",
>> "1111111111111111111111110001110", "1111111111111111111111110001111",
>> "1111111111111111111111110010000", "1111111111111111111111110010001",
>> "1111111111111111111111110010010", "1111111111111111111111110010011",
>> "1111111111111111111111110010100", "1111111111111111111111110010101",
>> "1111111111111111111111110010110", "1111111111111111111111110010111",
>> "1111111111111111111111110011000", "1111111111111111111111110011001",
>> "1111111111111111111111110011010", "1111111111111111111111110011011",
>> "1111111111111111111111110011100", "1111111111111111111111110011101",
>> "1111111111111111111111110011110", "1111111111111111111111110011111",
>> "1111111111111111111111110100000", "1111111111111111111111110100001",
>> "1111111111111111111111110100010", "1111111111111111111111110100011",
>> "1111111111111111111111110100100", "1111111111111111111111110100101",
>> "1111111111111111111111110100110", "1111111111111111111111110100111",
>> "1111111111111111111111110101000", "1111111111111111111111110101001",
>> "1111111111111111111111110101010", "1111111111111111111111110101011",
>> "1111111111111111111111110101100", "1111111111111111111111110101101",
>> "1111111111111111111111110101110", "1111111111111111111111110101111",
>> "1111111111111111111111110110000", "1111111111111111111111110110001",
>> "1111111111111111111111110110010", "1111111111111111111111110110011",
>> "1111111111111111111111110110100", "1111111111111111111111110110101",
>> "1111111111111111111111110110110", "1111111111111111111111110110111",
>> "1111111111111111111111110111000", "1111111111111111111111110111001",
>> "1111111111111111111111110111010", "1111111111111111111111110111011",
>> "1111111111111111111111110111100", "1111111111111111111111110111101",
>> "1111111111111111111111110111110", "1111111111111111111111110111111",
>> "1111111111111111111111111000000", "1111111111111111111111111000001",
>> "1111111111111111111111111000010", "1111111111111111111111111000011",
>> "1111111111111111111111111000100", "1111111111111111111111111000101",
>> "1111111111111111111111111000110", "1111111111111111111111111000111",
>> "1111111111111111111111111001000", "1111111111111111111111111001001",
>> "1111111111111111111111111001010", "1111111111111111111111111001011",
>> "1111111111111111111111111001100", "1111111111111111111111111001101",
>> "1111111111111111111111111001110", "1111111111111111111111111001111",
>> "1111111111111111111111111010000", "1111111111111111111111111010001",
>> "1111111111111111111111111010010", "1111111111111111111111111010011",
>> "1111111111111111111111111010100", "1111111111111111111111111010101",
>> "1111111111111111111111111010110", "1111111111111111111111111010111",
>> "1111111111111111111111111011000", "1111111111111111111111111011001",
>> "1111111111111111111111111011010", "1111111111111111111111111011011",
>> "1111111111111111111111111011100", "1111111111111111111111111011101",
>> "1111111111111111111111111011110", "1111111111111111111111111011111",
>> "1111111111111111111111111100000", "1111111111111111111111111100001",
>> "1111111111111111111111111100010", "1111111111111111111111111100011",
>> "1111111111111111111111111100100", "1111111111111111111111111100101",
>> "1111111111111111111111111100110", "1111111111111111111111111100111",
>> "1111111111111111111111111101000", "1111111111111111111111111101001",
>> "1111111111111111111111111101010", "1111111111111111111111111101011",
>> "1111111111111111111111111101100", "1111111111111111111111111101101",
>> "1111111111111111111111111101110", "1111111111111111111111111101111",
>> "1111111111111111111111111110000", "1111111111111111111111111110001",
>> "1111111111111111111111111110010", "1111111111111111111111111110011",
>> "1111111111111111111111111110100", "1111111111111111111111111110101",
>> "1111111111111111111111111110110", "1111111111111111111111111110111",
>> "1111111111111111111111111111000", "1111111111111111111111111111001",
>> "1111111111111111111111111111010", "1111111111111111111111111111011",
>> "1111111111111111111111111111100", "1111111111111111111111111111101",
>> "1111111111111111111111111111110", "1111111111111111111111111111111"
>> ), class = "factor")), class = "data.frame", row.names = c(NA,
>> -361L))
>>
>> AISMessageFrame (Raw Messages as they come from the AIS device):
>>
>> > dput(AISMessageFrame)
>> structure(list(MessgeCode = structure(c(17L, 6L, 93L, 92L, 81L,
>> 24L, 4L, 44L, 21L, 43L, 66L, 64L, 94L, 46L, 26L, 82L, 12L, 9L,
>> 67L, 63L, 65L, 39L, 48L, 38L, 79L, 83L, 37L, 73L, 23L, 68L, 59L,
>> NA, 5L, 30L, 62L, 84L, 60L, 22L, 52L, 61L, 50L, 70L, 96L, 85L,
>> 33L, 51L, 8L, 16L, 19L, 71L, 76L, 86L, 34L, 25L, 14L, 53L, 10L,
>> 29L, 2L, 77L, 57L, 87L, 72L, 54L, 55L, 36L, 1L, 13L, NA, 78L,
>> 58L, 15L, 89L, 35L, 20L, 3L, 49L, 56L, 90L, 40L, 45L, 41L, 42L,
>> 74L, 95L, 32L, 91L, 27L, 69L, 76L, 18L, 31L, 11L, 80L, 75L, 7L,
>> 72L, 88L, 28L, 47L), .Label = c("1:u0KOh001rCq5P529qqubqh2 at 3n",
>> "100000?P00JCkt:583J=r?v:283Q", "10007NgP00rCQGV5:Pa=?gv>2<1H",
>> "1000Fo at P01rCuG<56bnkN?v004`0", "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
>> "1349B:3000rCtrn553aR at JH02PRp", "1349B:3000rCtrn553aR at JHD2d4O",
>> "137g`F8007rCaIj59Tc5Dl at 800SN", "139NL4000LrCc8j59FEED4 at 000S<",
>> "13M at Hk00jSJD@RD4s=qG1mT80 at 3J", "13P;K8 at 001rCfgr58=f;QbFD2D4G",
>> "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "13P>4mhw1CrCi5H57aK5WlN>0<4F",
>> "14aMBf000wrCKKN5:sdU0Sv<083C", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>> "15?7P`0P00rD1S453KSlj?v824`0", "15?f5H?P00rCQat5:Oah0?wn2 at S6",
>> "15?lSL?P00JCQWD5:OpP0?vB24`0", "15?mqH?P00rCek458rkEN?v:00S4",
>> "15 at EA<0P01JCo8l53=BFgwv at 0D47", "15 at eD@8000rC`bl59kW`mFn004`0",
>> "15>nNj0000rCT<@5::qUpkt604`0", "15>uP00P00rC`U:59im;H?v22 at 1D",
>> "15A at av3P00rClHn53<I8M?v02<2B", "15AIw`0P0GrCcO859DO5Ogv:0T`0",
>> "15Aq00?P00rC`a`59mFeogv004`0", "15ATk20000rCnrv53N6;gPr>085R",
>> "15B3Sj0000rC9RD5=mOh40jB20SU", "15BI>P0001rCgUD58DRalRj:00S5",
>> "15BkV00P00rCQBf5:Q5JQOv42D1o", "15BW=20P00JCrvH54t=an?vB00Sg",
>> "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "15De7F?P00JCr5r5517v4?v80h2P",
>> "15E:BR0P00rCgaT58DdJUwv82H34", "15E:N at 0000rCgOd57p45bW><0<2H",
>> "15E=m60000rC`W459k28Wnd:083h", "15E=q08P00JCrnR52cb>4?v200Sw",
>> "15PoOh0001rCgbt58CwUaBD004`0", "15PvE at 0002rCi7R57pokCT:424`0",
>> "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:",
>> "15QDCP0P?w<tSF0l4Q@>4?wp0D1G", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>> "15QK900001JCq=d54l?5J0op0l4e", "15QtF00000rCafD59P?VJ9p<0H52",
>> "15TGcJ0002rD<>p55FgmI at Ul0H0S", "15TgVb0000rCgVb57oFc;ARF2 at 67",
>> "15TgVb0000rCgVd57oFc31R42L46", "15TILd?P00JCm4l53`D>4?v>0L1m",
>> "15U?B00000rCgb>58DFJfRl620RT", "15U at cn0000rCgU>57oPLGiT:2D4D",
>> "15UHOn9P00rCQ`D5:OcTkgv80<4:", "1819?@H001rC9TB5=bppM9<82D0T",
>> "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>> "19NSG<h003rCi@:57pmUkAB<0<1v", "1gu00CLLwfh2 at Asw9@1<", "1gu103LLwfl1 at Asw9P1<",
>> "3", "34`odN1000rD1V2537=dfPJ60000", "35A=Rh1001rD;s454vSTuP`40000",
>> "35QN<D1000rCr5l53esbgPR20000", "39NS at m11@1rCrb:53:E<v0j3R000",
>> "403Iu6Qv4PU00rCk0d57rwW00<2g", "403Iu6Qv4PU01rCk0d57rwW00<2g",
>> "403Iupiv4PU00rC9065>=fW00H0I", "403Iupiv4PU00rC9065>=fW00H0j",
>> "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>> "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G@W9K4Oi0D at PC0ShK40C",
>> "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>> "7933.8835099999997", "7933.8836099999999", "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>> "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "88888888880",
>> "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>> "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>> "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>> "B;s at N9h00>TtPEQAslh03wuUwP06", "B;s at N9h00>TtPF1Asll03wP5wP06",
>> "B;s at N9h00>TtPF1Asll03wPUwP06", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>> "B;s at N9h00>TtPFQAslt03wQUwP06", "B;s at N9h00>TtPFQAslt03wR5wP06",
>> "B;s at N9h00>TtPFQAsm003wRUwP06", "B;s at N9h00>TtPFQAsm803wU5wP06",
>> "B;s at N9h00>TtPG1Asm403wSUwP06", "B;s at N9h00>TtPG1Asm403wT5wP06",
>> "B;s at N9h00>TtPG1Asm803wTUwP06", "D03Iu6QGLN01MdN01StN000", "D03Iuph1TNfp4dv9J<`N000",
>> "H5?AU:4U653hhhi8 at lkihP000000", "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>> "PC at H8888880"), class = "factor")), class = "data.frame", row.names = c(NA,
>> -100L))
>>
>> Each one of those weird codes given in the AISMessageFrame correspond to an AIS message, there is a lot of information provided here, but I am only concerned with the Latitude and Longitude values (degrees with minutes). In order to accomplish this, each one of those wierd codes need to be converted to binary strings, once converted to binary strings. As I mentioned before, the information regarding latitude and longitude can be extracted from the following positions (again, after converting code to binary strings):
>> Latitude = positions 90 to 116 inclusive (assuming you count the bits from left to right, with the first one having position number 1)
>> Longitude = positions 62 to 89 inclusive (assuming you count the bits from left to right withe the first one having position number 1)
>>
>> In the sample code I provided in previous emails, I used the following to obtain the Latitude and Longitude:
>>
>> library(stringi)
>> library(dplyr)
>> library(R.utils)
>> library(RANN)
>> library(NISTunits)
>> library(pracma)
>> library(celestial)
>> library(stringr)
>>
>> #here I show the sample to decode a single record, though that needs to be done for all AIS messages, so obviously a loop will be needed for that:
>>
>> ascii_datformat <- utf8ToInt(dataset1[1,6]) #turning the first AIS message as it comes to ascii number
>> Base <- ascii_datformat - 48    #transformation from ascii to decimal
>> decy <- ifelse(Base > 40, Base-8, Base) #transformation from ascii to decimal continued
>> biny <- intToBin(decy)  #transformation from decimal to binary representation
>> binyframe <- data.frame(biny)
>> tbinyframe <- paste(t(binyframe[,1]), collapse="") #simply transposing the results
>>
>> tbinyframe will give you something like this (for each row having an AIS message)
>> > tbinyframe
>> [1] "000001000101001111101110000101011000001111100000000000000000111010010011100001101001111100000101001010011111101001110000000000001111111111110110000010010000100011000110"
>>
>> Latitude <- substr(tbinyframe, 90, 116)
>> Longitude <- substr(tbinyframe, 62, 89)
>>
>> What I need is to decode thos latitude and longitude values , to get results in a -90 to +90 range for latitude, and in the -180 to +180 range for longitude.
>>
>> Hopefully I?ve made myself sufficiently clear this time and/or hopefully I understood your point correctly and provided you what you need.
>>
>> Again, thank you so much for your time and valuable support brother!
>>
>> Best regards,
>>
>> Paul
>>
>> El vie., 24 ene. 2020 a las 14:09, Richard M. Heiberger (<rmh at temple.edu>) escribi?:
>>>
>>> now I am even more puzzled.
>>>
>>> please complete the following two data.frames and send it to the list.
>>>
>>> latDegrees lat2Comp
>>> -90 xxxxxxxx
>>> -89 xxxxxxxx
>>> ...
>>> -1 xxxxxxxx
>>> 0 xxxxxxxx
>>> 1 xxxxxxxx
>>> ...
>>> 89 xxxxxxxx
>>> 90 xxxxxxxx
>>>
>>> lonDegrees lon2Comp
>>> -180 xxxxxxxx
>>> -179 xxxxxxxx
>>> ...
>>> -91 xxxxxxxx
>>> -90 xxxxxxxx
>>> -89 xxxxxxxx
>>> ...
>>> -1 xxxxxxxx
>>> 0 xxxxxxxx
>>> 1 xxxxxxxx
>>> ...
>>> 89 xxxxxxxx
>>> 90 xxxxxxxx
>>> 91 xxxxxxxx
>>> ...
>>> 179 xxxxxxxx
>>> 180 xxxxxxxx
>>>
>>> Your 8 bit 2C example has 7 digits of precision plus sign which gives
>>> a range of (-127,127).  That suffices for latitude (-90,90).
>>> For longitude you will need 9 bits of twos complement for 8 bits of
>>> precision plus sign to cover (-255,255), thus more than enough for
>>> (-180,180).
>>> This assumes that precision to the degree is sufficient.  If you need
>>> precision to minutes and seconds, or to meters, then you
>>> will need even more bits in 2C.
>>>
>>> Since it looks like you need a different number of bits for each
>>> variable, I am asking for two data.frames.
>>>
>>> Rich
>>>
>>> On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>>> >
>>> > Hi Richard,
>>> >
>>> > That was just an example, to show that, for that particular string of binary numbers, the code works as expected. That is absolutely no related to the dataset I provided. If I try the function on the dataset, I get values well over the latitude and longitude boundaries (which should range from -90 to + 90, and -180 to +180).
>>> >
>>> > Regards,
>>> >
>>> > Paul
>>> >
>>> > El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<rmh at temple.edu>) escribi?:
>>> >>
>>> >> You show the example
>>> >>
>>> >> > fun("10110010")
>>> >> [1] -78
>>> >>
>>> >> as satisfactory.  Where in your posted data set do you find the input
>>> >> string "10110010"?
>>> >>
>>> >> Please post a set of relevant input strings, and the answers you want from them.
>>> >> The rest of the columns are not helpful for this specific exercise.
>>> >>
>>> >> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>>> >> >
>>> >> > Dear friend Rui,
>>> >> >
>>> >> > Hope you are doing great. Firstly, I want to thank you for your super
>>> >> > valuable and kind support of always. As I mentioned in earlier e-mails, I
>>> >> > am trying to decode AIS type messages, and the only ones I am having a real
>>> >> > hard time with, is with latitude and longitude.
>>> >> >
>>> >> > I tried the function you provided me in one of your replies, and it works
>>> >> > well with the examples  you provided, but in other cases it doesn?t.
>>> >> >
>>> >> > The messages I am trying to decode are in the 6th column of the data. I
>>> >> > will provide you with a small sample first, and then the complete dataset
>>> >> > (which has 100 rows). This is the small sample:
>>> >> >
>>> >> > > head(dat)
>>> >> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7       ...8
>>> >> > ...9 ...10 ...11 ...12 ...13
>>> >> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D 1485907200
>>> >> > <NA>    NA    NA    NA  <NA>
>>> >> >
>>> >> > It is worth mentioning that each row of the 6th column provides several
>>> >> > information about maritime vessels, like speed over ground, latitude,
>>> >> > longitude, vessel ID, etc. I am only concerned with latitude and longitude
>>> >> > since those are the only two fields I have not been able to decode
>>> >> > successfully. Also, I am working on R version 3.6.2 for windows 64-bit OS.
>>> >> >
>>> >> > The messages to decode are of the following format:
>>> >> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
>>> >> >
>>> >> > Now, here is the complete dataset:
>>> >> >
>>> >> > > dput(dat)
>>> >> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>>> >> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
>>> >> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> >> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
>>> >> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
>>> >> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
>>> >> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
>>> >> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
>>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
>>> >> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
>>> >> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>>> >> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
>>> >> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
>>> >> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
>>> >> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
>>> >> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
>>> >> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
>>> >> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
>>> >> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
>>> >> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
>>> >> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
>>> >> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
>>> >> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
>>> >> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
>>> >> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
>>> >> > "D03Iu6QGLN01MdN01StN000",
>>> >> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
>>> >> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
>>> >> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>>> >> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
>>> >> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
>>> >> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
>>> >> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
>>> >> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
>>> >> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
>>> >> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
>>> >> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00>TtPF1Asll03wPUwP06",
>>> >> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
>>> >> > "15>uP00P00rC`U:59im;H?v22 at 1D",
>>> >> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>>> >> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h", "15BkV00P00rCQBf5:Q5JQOv42D1o",
>>> >> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>>> >> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
>>> >> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
>>> >> > "15U?B00000rCgb>58DFJfRl620RT", "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
>>> >> > @W9K4Oi0D at PC0ShK40C",
>>> >> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
>>> >> > "15De7F?P00JCr5r5517v4?v80h2P",
>>> >> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
>>> >> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
>>> >> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>>> >> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
>>> >> > "15E:BR0P00rCgaT58DdJUwv82H34",
>>> >> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
>>> >> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
>>> >> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
>>> >> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>>> >> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
>>> >> > "7933.8835099999997",
>>> >> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>>> >> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
>>> >> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
>>> >> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>>> >> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>>> >> > "B;s at N9h00>TtPG1Asm403wSUwP06",
>>> >> >
>>> >> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
>>> >> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
>>> >> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
>>> >> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
>>> >> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
>>> >> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>>> >> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>>> >> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
>>> >> > "15ATk20000rCnrv53N6;gPr>085R",
>>> >> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>>> >> >
>>> >> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
>>> >> > "15BW=20P00JCrvH54t=an?vB00Sg",
>>> >> > "13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>>> >> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "1349B:3000rCtrn553aR at JHD2d4O",
>>> >> >
>>> >> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
>>> >> > "15B3Sj0000rC9RD5=mOh40jB20SU",
>>> >> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
>>> >> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
>>> >> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
>>> >> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
>>> >> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
>>> >> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
>>> >> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
>>> >> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
>>> >> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
>>> >> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
>>> >> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
>>> >> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
>>> >> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 = c(1485907200,
>>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>>> >> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
>>> >> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
>>> >> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204, 1485907204,
>>> >> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
>>> >> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205, 1485907205,
>>> >> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206, 1485907206,
>>> >> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
>>> >> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
>>> >> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208, 1485907208,
>>> >> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209, 1485907209,
>>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
>>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
>>> >> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
>>> >> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
>>> >> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
>>> >> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1485907209,
>>> >> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
>>> >> >
>>> >> > To tested your function I took the first message, which is located in the
>>> >> > 6th column and the 1st row, and did the following:
>>> >> >
>>> >> > library(stringi)
>>> >> > library(dplyr)
>>> >> > library(R.utils)
>>> >> > library(RANN)
>>> >> > library(NISTunits)
>>> >> > library(pracma)
>>> >> > library(celestial)
>>> >> > library(stringr)
>>> >> >
>>> >> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE, na="",
>>> >> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
>>> >> >
>>> >> > testmessage1 <- dat[1,6]
>>> >> >
>>> >> > ascii_datformat <- utf8ToInt(testmessage1)
>>> >> >
>>> >> > Base <- ascii_datformat - 48
>>> >> >
>>> >> > decy <- ifelse(Base > 40, Base - 8, Base)
>>> >> >
>>> >> > biny <- intToBin(decy)
>>> >> >
>>> >> > binyframe <- data.frame(biny)
>>> >> >
>>> >> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I have
>>> >> > the complete first message, all in binary format
>>> >> >
>>> >> > #according to the literature of AIS message decoding, longitude goes from
>>> >> > position 62 to position 89
>>> >> > #and latitude goes from position 90 to position 116
>>> >> >
>>> >> > longitude <- substr(tbinyframe, 62, 89)
>>> >> > latitude    <- substr(tbinyframe, 90, 116)
>>> >> >
>>> >> > #now I apply the function you provided me with:
>>> >> >
>>> >> >  fun <- function(x){
>>> >> >          res <- sapply(x, function(y){
>>> >> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>>> >> >              strtoi(y, base = 2)
>>> >> >             }else{
>>> >> >               y <- unlist(strsplit(y, ""))
>>> >> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
>>> >> >             }
>>> >> >           })
>>> >> >           unname(res)
>>> >> >       }
>>> >> >
>>> >> > > fun(longitude)
>>> >> > [1] 220663102
>>> >> > >
>>> >> > > fun(latitude)
>>> >> > [1] 5414823
>>> >> > >
>>> >> > > fun("1101001001110000110100111110")
>>> >> > [1] 220663102
>>> >> > >
>>> >> > > fun("000010100101001111110100111")
>>> >> > [1] 5414823
>>> >> > >
>>> >> > > fun("10110010")
>>> >> > [1] -78
>>> >> >
>>> >> > as you can see, the function only worked or showed expected result on the
>>> >> > last case with a -78, but in the other cases, it the results were not as
>>> >> > expected, maybe I am missing something here?
>>> >> >
>>> >> > Any help and/or guidance will be greatly appreciated,
>>> >> >
>>> >> > Best regards,
>>> >> >
>>> >> > Paul
>>> >> >
>>> >> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<ruipbarradas at sapo.pt>)
>>> >> > escribi?:
>>> >> >
>>> >> > > Hello,
>>> >> > >
>>> >> > > The function I included converts signed binary numbers into their
>>> >> > > decimal representation. They are negative if a) they are multiples of 8
>>> >> > > bits and b) the most significant bit is a "1". If not just convert to
>>> >> > > integer.
>>> >> > >
>>> >> > > As for a) above, I assume that you will have 8 bit numbers. And the
>>> >> > > conversion is done as follows:
>>> >> > >
>>> >> > > input: 10110010
>>> >> > >
>>> >> > > splitting, to make it more clear:
>>> >> > >
>>> >> > > 1 0 1 1 0 0 1 0 - input
>>> >> > > 0 1 0 0 1 1 0 1 - reversed
>>> >> > >                1 - add 1 to the number with reversed bits
>>> >> > > 0 1 0 0 1 1 1 0 - result is the two's complement
>>> >> > >
>>> >> > > c(0, 1, 0, 0, 1, 1, 1, 0) %*% 2^(7:0) is 78
>>> >> > >
>>> >> > > But the msb is "1" so it's -78
>>> >> > >
>>> >> > >
>>> >> > > This is what the function does, but instead of %*% it uses
>>> >> > >
>>> >> > > sum(two's compl * powers of two)
>>> >> > >
>>> >> > >
>>> >> > > Hope this helps,
>>> >> > >
>>> >> > > Rui Barradas
>>> >> > >
>>> >> > > The input must be a character string or character vector.
>>> >> > >
>>> >> > > ?s 14:36 de 20/01/20, Paul Bernal escreveu:
>>> >> > > > Dear friend Rui,
>>> >> > > >
>>> >> > > > Hope you are doing great, thanks for your kind feedback. The challenge I
>>> >> > > > currently have at hand is to decode AIS messages and obtain latitude and
>>> >> > > > longitude values from those.
>>> >> > > >
>>> >> > > > So basically, I want to accomplish something like in the example below.
>>> >> > > > I want to convert this binary number (10110010) into the two?s
>>> >> > > > complement representation, there is the logic they are using for that.
>>> >> > > > Since longitude ranges from
>>> >> > > >
>>> >> > > >
>>> >> > > >       Example of conversion to decimal of a signed binary number in
>>> >> > > >       two's complement representation
>>> >> > > >
>>> >> > > > Let's convert to decimal the following signed binary number: 10110010
>>> >> > > >
>>> >> > > > 10110010 = -1?27 + 0?26 + 1?25 + 1?24 + 0?23 + 0?22 + 1?21 + 0?20 = -128
>>> >> > > > + 32 + 16 + 2 = -78.
>>> >> > > >
>>> >> > > > El lun., 20 ene. 2020 a las 7:22, Rui Barradas (<ruipbarradas at sapo.pt
>>> >> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
>>> >> > > >
>>> >> > > >     Sorry, missunderstood the problem.
>>> >> > > >     Here it goes:
>>> >> > > >
>>> >> > > >     fun <- function(x){
>>> >> > > >         res <- sapply(x, function(y){
>>> >> > > >           if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>>> >> > > >             strtoi(y, base = 2)
>>> >> > > >           }else{
>>> >> > > >             y <- unlist(strsplit(y, ""))
>>> >> > > >             -sum((y != "1")*2^((length(y) - 1):0)) - 1
>>> >> > > >           }
>>> >> > > >         })
>>> >> > > >         unname(res)
>>> >> > > >     }
>>> >> > > >
>>> >> > > >     fun("10110010")
>>> >> > > >     fun("10000000")
>>> >> > > >     fun(c("01000000", "01111111", "10110010", "10000000"))
>>> >> > > >
>>> >> > > >
>>> >> > > >     Hope this helps,
>>> >> > > >
>>> >> > > >     Rui Barradas
>>> >> > > >
>>> >> > > >     ?s 11:38 de 20/01/20, Rui Barradas escreveu:
>>> >> > > >      > Hello,
>>> >> > > >      >
>>> >> > > >      > Is this what you want?
>>> >> > > >      >
>>> >> > > >      >
>>> >> > > >      > x <- "10110010"
>>> >> > > >      > strtoi(x, base = 2)
>>> >> > > >      > #[1] 178
>>> >> > > >      >
>>> >> > > >      >
>>> >> > > >      > Hope this helps,
>>> >> > > >      >
>>> >> > > >      > Rui Barradas
>>> >> > > >      >
>>> >> > > >      > ?s 16:31 de 16/01/20, Paul Bernal escreveu:
>>> >> > > >      >> Dear friends,
>>> >> > > >      >>
>>> >> > > >      >> How can I convert the following binary number in two?s complement
>>> >> > > >      >> representation in R?
>>> >> > > >      >>
>>> >> > > >      >> 10110010
>>> >> > > >      >>
>>> >> > > >      >> Any help and/or guidance will be greatly appreciated,
>>> >> > > >      >>
>>> >> > > >      >> Best regards,
>>> >> > > >      >>
>>> >> > > >      >> Paul
>>> >> > > >      >>
>>> >> > > >      >>     [[alternative HTML version deleted]]
>>> >> > > >      >>
>>> >> > > >      >> ______________________________________________
>>> >> > > >      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> >> > > >     -- To UNSUBSCRIBE and more, see
>>> >> > > >      >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > > >      >> PLEASE do read the posting guide
>>> >> > > >      >> http://www.R-project.org/posting-guide.html
>>> >> > > >      >> and provide commented, minimal, self-contained, reproducible
>>> >> > > code.
>>> >> > > >      >>
>>> >> > > >      >
>>> >> > > >      > ______________________________________________
>>> >> > > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> >> > > >     -- To UNSUBSCRIBE and more, see
>>> >> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > > >      > PLEASE do read the posting guide
>>> >> > > >      > http://www.R-project.org/posting-guide.html
>>> >> > > >      > and provide commented, minimal, self-contained, reproducible code.
>>> >> > > >
>>> >> > >
>>> >> >
>>> >> >         [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Jan 25 22:14:13 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 25 Jan 2020 16:14:13 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAGx1TMAz=9KMuLPJGNk2Mdt-=7R40OCi87TfvgwnB4-7f4qAgg@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
 <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
 <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>
 <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>
 <CAGx1TMAz=9KMuLPJGNk2Mdt-=7R40OCi87TfvgwnB4-7f4qAgg@mail.gmail.com>
Message-ID: <CAMOcQfN3ay6sFFC0KkG2x_cQec1BF1Kjq1Wsg-2N-xq2g-9RQw@mail.gmail.com>

Dear friend Richard,

Were you able to obtain the latitude and longitude values with that script?

Thank you so much brother,

Paul

El s?b., 25 de enero de 2020 4:03 p. m., Richard M. Heiberger <
rmh at temple.edu> escribi?:

> ## from2Comp uses base R functions only
> from2Comp <- function(x, binDigits=8) {
>   ## binDigits=8 means 8 significant digits plus a sign bit, thus nchar(x)
> == 9
>   tmp <- strtoi(x, base=2)
>   Neg <- (tmp > (2^binDigits - 1))
>   tmp[Neg] <- tmp[Neg] - (2^(binDigits + 1))
>   tmp
> }
>
> from2Comp(substr(as.character(LatitudeFrame[,2]), 24, 31), 7)
>
> from2Comp(substr(as.character(LatitudeFrame[,2]), 23, 31), 8)
> from2Comp(substr(as.character(LongitudeFrame[,2]), 23, 31), 8)
>
> from2Comp(as.character(LatitudeFrame[,2]), 30)
> from2Comp(as.character(LongitudeFrame[,2]), 30)
>
>
> ## I don't see any system in AISMessageFrame
> tail(AISMessageFrame)
> ##                                      MessgeCode
> ## 95  85E:BR0F0P0000000000032jS2P000000DE7P3A00h0
> ## 96                 1349B:3000rCtrn553aR at JHD2d4O
> ## 97                           7933.8835099999997
> ## 98                 B;s at N9h00>TtPFQAsm803wU5wP06
> ## 99                 15B3Sj0000rC9RD5=mOh40jB20SU
> ## 100                15TgVb0000rCgVb57oFc;ARF2 at 67
>
>
> ## 180Long = -180Long, thus there is duplication.  How do you handle this?
> ## 90Lat  != -90Lat, so there is no duplication.
> ## How are minutes and seconds stored?
>
> On Fri, Jan 24, 2020 at 5:39 PM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >
> > I don't have my computer with me, so I am commenting right now on the
> visual impression of the email.
> >
> > The latitude shows 90, 88, ... 2, 89, ...
> > The labels are lexicographically ordered
> > -1, -10, -11,...
> >
> > The latitude binrep look in correct order, and the labels looks like
> binary in order.
> >
> > These things are identified as factors, not as character.
> >
> > Please ensure that character values are not misinterpreted as factor
> when you construct your data frames.
> >
> > The four columns do not look to be in consistent order with each other.
> This in itself could cause trouble.
> >
> > I will look more when I have my computer running R so I can follow the
> rest of what you wrote.
> >
> > Rich
> >
> > On Fri, Jan 24, 2020 at 15:02 Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>
> >> Dear friend Richard,
> >>
> >> Thank you for your interest in helping me through this challenge. As
> requested, I am providing the two lat and long frames you suggested, plus
> the one single column I am trying to decode:
> >>
> >> LatitudeFrame:
> >>
> >> > dput(LatitudeFrame)
> >> structure(list(Latitude = structure(c(90L, 88L, 87L, 86L, 85L,
> >> 84L, 83L, 82L, 81L, 80L, 79L, 77L, 76L, 75L, 74L, 73L, 72L, 71L,
> >> 70L, 69L, 68L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L, 57L,
> >> 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 46L, 44L, 43L, 42L,
> >> 41L, 40L, 39L, 38L, 37L, 36L, 35L, 33L, 32L, 31L, 30L, 29L, 28L,
> >> 27L, 26L, 25L, 24L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L, 14L,
> >> 13L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 89L, 78L, 67L,
> >> 56L, 45L, 34L, 23L, 12L, 1L, 91L, 92L, 103L, 114L, 125L, 136L,
> >> 147L, 158L, 169L, 180L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
> >> 101L, 102L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
> >> 113L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
> >> 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 137L,
> >> 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 148L, 149L,
> >> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 159L, 160L, 161L,
> >> 162L, 163L, 164L, 165L, 166L, 167L, 168L, 170L, 171L, 172L, 173L,
> >> 174L, 175L, 176L, 177L, 178L, 179L, 181L), .Label = c("-1", "-10",
> >> "-11", "-12", "-13", "-14", "-15", "-16", "-17", "-18", "-19",
> >> "-2", "-20", "-21", "-22", "-23", "-24", "-25", "-26", "-27",
> >> "-28", "-29", "-3", "-30", "-31", "-32", "-33", "-34", "-35",
> >> "-36", "-37", "-38", "-39", "-4", "-40", "-41", "-42", "-43",
> >> "-44", "-45", "-46", "-47", "-48", "-49", "-5", "-50", "-51",
> >> "-52", "-53", "-54", "-55", "-56", "-57", "-58", "-59", "-6",
> >> "-60", "-61", "-62", "-63", "-64", "-65", "-66", "-67", "-68",
> >> "-69", "-7", "-70", "-71", "-72", "-73", "-74", "-75", "-76",
> >> "-77", "-78", "-79", "-8", "-80", "-81", "-82", "-83", "-84",
> >> "-85", "-86", "-87", "-88", "-89", "-9", "-90", "0", "1", "10",
> >> "11", "12", "13", "14", "15", "16", "17", "18", "19", "2", "20",
> >> "21", "22", "23", "24", "25", "26", "27", "28", "29", "3", "30",
> >> "31", "32", "33", "34", "35", "36", "37", "38", "39", "4", "40",
> >> "41", "42", "43", "44", "45", "46", "47", "48", "49", "5", "50",
> >> "51", "52", "53", "54", "55", "56", "57", "58", "59", "6", "60",
> >> "61", "62", "63", "64", "65", "66", "67", "68", "69", "7", "70",
> >> "71", "72", "73", "74", "75", "76", "77", "78", "79", "8", "80",
> >> "81", "82", "83", "84", "85", "86", "87", "88", "89", "9", "90"
> >> ), class = "factor"), LatitudeBinRep = structure(c(92L, 93L,
> >> 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L,
> >> 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L,
> >> 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L,
> >> 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L,
> >> 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
> >> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
> >> 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L,
> >> 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 1L,
> >> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> >> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> >> 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
> >> 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L,
> >> 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L,
> >> 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
> >> 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L), .Label =
> c("0000000000000000000000000000000",
> >> "0000000000000000000000000000001", "0000000000000000000000000000010",
> >> "0000000000000000000000000000011", "0000000000000000000000000000100",
> >> "0000000000000000000000000000101", "0000000000000000000000000000110",
> >> "0000000000000000000000000000111", "0000000000000000000000000001000",
> >> "0000000000000000000000000001001", "0000000000000000000000000001010",
> >> "0000000000000000000000000001011", "0000000000000000000000000001100",
> >> "0000000000000000000000000001101", "0000000000000000000000000001110",
> >> "0000000000000000000000000001111", "0000000000000000000000000010000",
> >> "0000000000000000000000000010001", "0000000000000000000000000010010",
> >> "0000000000000000000000000010011", "0000000000000000000000000010100",
> >> "0000000000000000000000000010101", "0000000000000000000000000010110",
> >> "0000000000000000000000000010111", "0000000000000000000000000011000",
> >> "0000000000000000000000000011001", "0000000000000000000000000011010",
> >> "0000000000000000000000000011011", "0000000000000000000000000011100",
> >> "0000000000000000000000000011101", "0000000000000000000000000011110",
> >> "0000000000000000000000000011111", "0000000000000000000000000100000",
> >> "0000000000000000000000000100001", "0000000000000000000000000100010",
> >> "0000000000000000000000000100011", "0000000000000000000000000100100",
> >> "0000000000000000000000000100101", "0000000000000000000000000100110",
> >> "0000000000000000000000000100111", "0000000000000000000000000101000",
> >> "0000000000000000000000000101001", "0000000000000000000000000101010",
> >> "0000000000000000000000000101011", "0000000000000000000000000101100",
> >> "0000000000000000000000000101101", "0000000000000000000000000101110",
> >> "0000000000000000000000000101111", "0000000000000000000000000110000",
> >> "0000000000000000000000000110001", "0000000000000000000000000110010",
> >> "0000000000000000000000000110011", "0000000000000000000000000110100",
> >> "0000000000000000000000000110101", "0000000000000000000000000110110",
> >> "0000000000000000000000000110111", "0000000000000000000000000111000",
> >> "0000000000000000000000000111001", "0000000000000000000000000111010",
> >> "0000000000000000000000000111011", "0000000000000000000000000111100",
> >> "0000000000000000000000000111101", "0000000000000000000000000111110",
> >> "0000000000000000000000000111111", "0000000000000000000000001000000",
> >> "0000000000000000000000001000001", "0000000000000000000000001000010",
> >> "0000000000000000000000001000011", "0000000000000000000000001000100",
> >> "0000000000000000000000001000101", "0000000000000000000000001000110",
> >> "0000000000000000000000001000111", "0000000000000000000000001001000",
> >> "0000000000000000000000001001001", "0000000000000000000000001001010",
> >> "0000000000000000000000001001011", "0000000000000000000000001001100",
> >> "0000000000000000000000001001101", "0000000000000000000000001001110",
> >> "0000000000000000000000001001111", "0000000000000000000000001010000",
> >> "0000000000000000000000001010001", "0000000000000000000000001010010",
> >> "0000000000000000000000001010011", "0000000000000000000000001010100",
> >> "0000000000000000000000001010101", "0000000000000000000000001010110",
> >> "0000000000000000000000001010111", "0000000000000000000000001011000",
> >> "0000000000000000000000001011001", "0000000000000000000000001011010",
> >> "1111111111111111111111110100110", "1111111111111111111111110100111",
> >> "1111111111111111111111110101000", "1111111111111111111111110101001",
> >> "1111111111111111111111110101010", "1111111111111111111111110101011",
> >> "1111111111111111111111110101100", "1111111111111111111111110101101",
> >> "1111111111111111111111110101110", "1111111111111111111111110101111",
> >> "1111111111111111111111110110000", "1111111111111111111111110110001",
> >> "1111111111111111111111110110010", "1111111111111111111111110110011",
> >> "1111111111111111111111110110100", "1111111111111111111111110110101",
> >> "1111111111111111111111110110110", "1111111111111111111111110110111",
> >> "1111111111111111111111110111000", "1111111111111111111111110111001",
> >> "1111111111111111111111110111010", "1111111111111111111111110111011",
> >> "1111111111111111111111110111100", "1111111111111111111111110111101",
> >> "1111111111111111111111110111110", "1111111111111111111111110111111",
> >> "1111111111111111111111111000000", "1111111111111111111111111000001",
> >> "1111111111111111111111111000010", "1111111111111111111111111000011",
> >> "1111111111111111111111111000100", "1111111111111111111111111000101",
> >> "1111111111111111111111111000110", "1111111111111111111111111000111",
> >> "1111111111111111111111111001000", "1111111111111111111111111001001",
> >> "1111111111111111111111111001010", "1111111111111111111111111001011",
> >> "1111111111111111111111111001100", "1111111111111111111111111001101",
> >> "1111111111111111111111111001110", "1111111111111111111111111001111",
> >> "1111111111111111111111111010000", "1111111111111111111111111010001",
> >> "1111111111111111111111111010010", "1111111111111111111111111010011",
> >> "1111111111111111111111111010100", "1111111111111111111111111010101",
> >> "1111111111111111111111111010110", "1111111111111111111111111010111",
> >> "1111111111111111111111111011000", "1111111111111111111111111011001",
> >> "1111111111111111111111111011010", "1111111111111111111111111011011",
> >> "1111111111111111111111111011100", "1111111111111111111111111011101",
> >> "1111111111111111111111111011110", "1111111111111111111111111011111",
> >> "1111111111111111111111111100000", "1111111111111111111111111100001",
> >> "1111111111111111111111111100010", "1111111111111111111111111100011",
> >> "1111111111111111111111111100100", "1111111111111111111111111100101",
> >> "1111111111111111111111111100110", "1111111111111111111111111100111",
> >> "1111111111111111111111111101000", "1111111111111111111111111101001",
> >> "1111111111111111111111111101010", "1111111111111111111111111101011",
> >> "1111111111111111111111111101100", "1111111111111111111111111101101",
> >> "1111111111111111111111111101110", "1111111111111111111111111101111",
> >> "1111111111111111111111111110000", "1111111111111111111111111110001",
> >> "1111111111111111111111111110010", "1111111111111111111111111110011",
> >> "1111111111111111111111111110100", "1111111111111111111111111110101",
> >> "1111111111111111111111111110110", "1111111111111111111111111110111",
> >> "1111111111111111111111111111000", "1111111111111111111111111111001",
> >> "1111111111111111111111111111010", "1111111111111111111111111111011",
> >> "1111111111111111111111111111100", "1111111111111111111111111111101",
> >> "1111111111111111111111111111110", "1111111111111111111111111111111"
> >> ), class = "factor")), class = "data.frame", row.names = c(NA,
> >> -181L))
> >>
> >> LongitudeFrame:
> >>
> >> > dput(LongitudeFrame)
> >> structure(list(Longitude = structure(c(91L, 89L, 88L, 87L, 86L,
> >> 85L, 84L, 83L, 82L, 81L, 80L, 78L, 77L, 76L, 75L, 74L, 73L, 72L,
> >> 71L, 70L, 69L, 67L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L,
> >> 56L, 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 45L, 44L, 43L,
> >> 42L, 41L, 40L, 39L, 38L, 37L, 36L, 34L, 33L, 32L, 31L, 30L, 29L,
> >> 28L, 27L, 26L, 25L, 23L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L,
> >> 14L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 180L, 179L, 178L,
> >> 177L, 176L, 175L, 174L, 173L, 172L, 171L, 169L, 168L, 167L, 166L,
> >> 165L, 164L, 163L, 162L, 161L, 160L, 158L, 157L, 156L, 155L, 154L,
> >> 153L, 152L, 151L, 150L, 149L, 147L, 146L, 145L, 144L, 143L, 142L,
> >> 141L, 140L, 139L, 138L, 136L, 135L, 134L, 133L, 132L, 131L, 130L,
> >> 129L, 128L, 127L, 125L, 124L, 123L, 122L, 121L, 120L, 119L, 118L,
> >> 117L, 116L, 114L, 113L, 112L, 111L, 110L, 109L, 108L, 107L, 106L,
> >> 105L, 103L, 102L, 101L, 100L, 99L, 98L, 97L, 96L, 95L, 94L, 92L,
> >> 90L, 79L, 68L, 57L, 46L, 35L, 24L, 13L, 2L, 170L, 159L, 148L,
> >> 137L, 126L, 115L, 104L, 93L, 1L, 181L, 182L, 274L, 285L, 296L,
> >> 307L, 318L, 329L, 340L, 351L, 183L, 194L, 205L, 216L, 227L, 238L,
> >> 249L, 260L, 271L, 273L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
> >> 282L, 283L, 284L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L,
> >> 294L, 295L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 305L,
> >> 306L, 308L, 309L, 310L, 311L, 312L, 313L, 314L, 315L, 316L, 317L,
> >> 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 330L,
> >> 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 341L, 342L,
> >> 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L,
> >> 355L, 356L, 357L, 358L, 359L, 360L, 361L, 184L, 185L, 186L, 187L,
> >> 188L, 189L, 190L, 191L, 192L, 193L, 195L, 196L, 197L, 198L, 199L,
> >> 200L, 201L, 202L, 203L, 204L, 206L, 207L, 208L, 209L, 210L, 211L,
> >> 212L, 213L, 214L, 215L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
> >> 224L, 225L, 226L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
> >> 236L, 237L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
> >> 248L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
> >> 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L, 272L
> >> ), .Label = c("-1", "-10", "-100", "-101", "-102", "-103", "-104",
> >> "-105", "-106", "-107", "-108", "-109", "-11", "-110", "-111",
> >> "-112", "-113", "-114", "-115", "-116", "-117", "-118", "-119",
> >> "-12", "-120", "-121", "-122", "-123", "-124", "-125", "-126",
> >> "-127", "-128", "-129", "-13", "-130", "-131", "-132", "-133",
> >> "-134", "-135", "-136", "-137", "-138", "-139", "-14", "-140",
> >> "-141", "-142", "-143", "-144", "-145", "-146", "-147", "-148",
> >> "-149", "-15", "-150", "-151", "-152", "-153", "-154", "-155",
> >> "-156", "-157", "-158", "-159", "-16", "-160", "-161", "-162",
> >> "-163", "-164", "-165", "-166", "-167", "-168", "-169", "-17",
> >> "-170", "-171", "-172", "-173", "-174", "-175", "-176", "-177",
> >> "-178", "-179", "-18", "-180", "-19", "-2", "-20", "-21", "-22",
> >> "-23", "-24", "-25", "-26", "-27", "-28", "-29", "-3", "-30",
> >> "-31", "-32", "-33", "-34", "-35", "-36", "-37", "-38", "-39",
> >> "-4", "-40", "-41", "-42", "-43", "-44", "-45", "-46", "-47",
> >> "-48", "-49", "-5", "-50", "-51", "-52", "-53", "-54", "-55",
> >> "-56", "-57", "-58", "-59", "-6", "-60", "-61", "-62", "-63",
> >> "-64", "-65", "-66", "-67", "-68", "-69", "-7", "-70", "-71",
> >> "-72", "-73", "-74", "-75", "-76", "-77", "-78", "-79", "-8",
> >> "-80", "-81", "-82", "-83", "-84", "-85", "-86", "-87", "-88",
> >> "-89", "-9", "-90", "-91", "-92", "-93", "-94", "-95", "-96",
> >> "-97", "-98", "-99", "0", "1", "10", "100", "101", "102", "103",
> >> "104", "105", "106", "107", "108", "109", "11", "110", "111",
> >> "112", "113", "114", "115", "116", "117", "118", "119", "12",
> >> "120", "121", "122", "123", "124", "125", "126", "127", "128",
> >> "129", "13", "130", "131", "132", "133", "134", "135", "136",
> >> "137", "138", "139", "14", "140", "141", "142", "143", "144",
> >> "145", "146", "147", "148", "149", "15", "150", "151", "152",
> >> "153", "154", "155", "156", "157", "158", "159", "16", "160",
> >> "161", "162", "163", "164", "165", "166", "167", "168", "169",
> >> "17", "170", "171", "172", "173", "174", "175", "176", "177",
> >> "178", "179", "18", "180", "19", "2", "20", "21", "22", "23",
> >> "24", "25", "26", "27", "28", "29", "3", "30", "31", "32", "33",
> >> "34", "35", "36", "37", "38", "39", "4", "40", "41", "42", "43",
> >> "44", "45", "46", "47", "48", "49", "5", "50", "51", "52", "53",
> >> "54", "55", "56", "57", "58", "59", "6", "60", "61", "62", "63",
> >> "64", "65", "66", "67", "68", "69", "7", "70", "71", "72", "73",
> >> "74", "75", "76", "77", "78", "79", "8", "80", "81", "82", "83",
> >> "84", "85", "86", "87", "88", "89", "9", "90", "91", "92", "93",
> >> "94", "95", "96", "97", "98", "99"), class = "factor"), LongitudeBinRep
> = structure(c(182L,
> >> 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 193L,
> >> 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L,
> >> 205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
> >> 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L,
> >> 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L, 236L, 237L,
> >> 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L, 248L,
> >> 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
> >> 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L,
> >> 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
> >> 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L,
> >> 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L,
> >> 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,
> >> 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L,
> >> 326L, 327L, 328L, 329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L,
> >> 337L, 338L, 339L, 340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L,
> >> 348L, 349L, 350L, 351L, 352L, 353L, 354L, 355L, 356L, 357L, 358L,
> >> 359L, 360L, 361L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> >> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> >> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
> >> 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L,
> >> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L,
> >> 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
> >> 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
> >> 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L,
> >> 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
> >> 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L,
> >> 124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L,
> >> 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
> >> 146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L,
> >> 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L,
> >> 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
> >> 179L, 180L, 181L), .Label = c("0000000000000000000000000000000",
> >> "0000000000000000000000000000001", "0000000000000000000000000000010",
> >> "0000000000000000000000000000011", "0000000000000000000000000000100",
> >> "0000000000000000000000000000101", "0000000000000000000000000000110",
> >> "0000000000000000000000000000111", "0000000000000000000000000001000",
> >> "0000000000000000000000000001001", "0000000000000000000000000001010",
> >> "0000000000000000000000000001011", "0000000000000000000000000001100",
> >> "0000000000000000000000000001101", "0000000000000000000000000001110",
> >> "0000000000000000000000000001111", "0000000000000000000000000010000",
> >> "0000000000000000000000000010001", "0000000000000000000000000010010",
> >> "0000000000000000000000000010011", "0000000000000000000000000010100",
> >> "0000000000000000000000000010101", "0000000000000000000000000010110",
> >> "0000000000000000000000000010111", "0000000000000000000000000011000",
> >> "0000000000000000000000000011001", "0000000000000000000000000011010",
> >> "0000000000000000000000000011011", "0000000000000000000000000011100",
> >> "0000000000000000000000000011101", "0000000000000000000000000011110",
> >> "0000000000000000000000000011111", "0000000000000000000000000100000",
> >> "0000000000000000000000000100001", "0000000000000000000000000100010",
> >> "0000000000000000000000000100011", "0000000000000000000000000100100",
> >> "0000000000000000000000000100101", "0000000000000000000000000100110",
> >> "0000000000000000000000000100111", "0000000000000000000000000101000",
> >> "0000000000000000000000000101001", "0000000000000000000000000101010",
> >> "0000000000000000000000000101011", "0000000000000000000000000101100",
> >> "0000000000000000000000000101101", "0000000000000000000000000101110",
> >> "0000000000000000000000000101111", "0000000000000000000000000110000",
> >> "0000000000000000000000000110001", "0000000000000000000000000110010",
> >> "0000000000000000000000000110011", "0000000000000000000000000110100",
> >> "0000000000000000000000000110101", "0000000000000000000000000110110",
> >> "0000000000000000000000000110111", "0000000000000000000000000111000",
> >> "0000000000000000000000000111001", "0000000000000000000000000111010",
> >> "0000000000000000000000000111011", "0000000000000000000000000111100",
> >> "0000000000000000000000000111101", "0000000000000000000000000111110",
> >> "0000000000000000000000000111111", "0000000000000000000000001000000",
> >> "0000000000000000000000001000001", "0000000000000000000000001000010",
> >> "0000000000000000000000001000011", "0000000000000000000000001000100",
> >> "0000000000000000000000001000101", "0000000000000000000000001000110",
> >> "0000000000000000000000001000111", "0000000000000000000000001001000",
> >> "0000000000000000000000001001001", "0000000000000000000000001001010",
> >> "0000000000000000000000001001011", "0000000000000000000000001001100",
> >> "0000000000000000000000001001101", "0000000000000000000000001001110",
> >> "0000000000000000000000001001111", "0000000000000000000000001010000",
> >> "0000000000000000000000001010001", "0000000000000000000000001010010",
> >> "0000000000000000000000001010011", "0000000000000000000000001010100",
> >> "0000000000000000000000001010101", "0000000000000000000000001010110",
> >> "0000000000000000000000001010111", "0000000000000000000000001011000",
> >> "0000000000000000000000001011001", "0000000000000000000000001011010",
> >> "0000000000000000000000001011011", "0000000000000000000000001011100",
> >> "0000000000000000000000001011101", "0000000000000000000000001011110",
> >> "0000000000000000000000001011111", "0000000000000000000000001100000",
> >> "0000000000000000000000001100001", "0000000000000000000000001100010",
> >> "0000000000000000000000001100011", "0000000000000000000000001100100",
> >> "0000000000000000000000001100101", "0000000000000000000000001100110",
> >> "0000000000000000000000001100111", "0000000000000000000000001101000",
> >> "0000000000000000000000001101001", "0000000000000000000000001101010",
> >> "0000000000000000000000001101011", "0000000000000000000000001101100",
> >> "0000000000000000000000001101101", "0000000000000000000000001101110",
> >> "0000000000000000000000001101111", "0000000000000000000000001110000",
> >> "0000000000000000000000001110001", "0000000000000000000000001110010",
> >> "0000000000000000000000001110011", "0000000000000000000000001110100",
> >> "0000000000000000000000001110101", "0000000000000000000000001110110",
> >> "0000000000000000000000001110111", "0000000000000000000000001111000",
> >> "0000000000000000000000001111001", "0000000000000000000000001111010",
> >> "0000000000000000000000001111011", "0000000000000000000000001111100",
> >> "0000000000000000000000001111101", "0000000000000000000000001111110",
> >> "0000000000000000000000001111111", "0000000000000000000000010000000",
> >> "0000000000000000000000010000001", "0000000000000000000000010000010",
> >> "0000000000000000000000010000011", "0000000000000000000000010000100",
> >> "0000000000000000000000010000101", "0000000000000000000000010000110",
> >> "0000000000000000000000010000111", "0000000000000000000000010001000",
> >> "0000000000000000000000010001001", "0000000000000000000000010001010",
> >> "0000000000000000000000010001011", "0000000000000000000000010001100",
> >> "0000000000000000000000010001101", "0000000000000000000000010001110",
> >> "0000000000000000000000010001111", "0000000000000000000000010010000",
> >> "0000000000000000000000010010001", "0000000000000000000000010010010",
> >> "0000000000000000000000010010011", "0000000000000000000000010010100",
> >> "0000000000000000000000010010101", "0000000000000000000000010010110",
> >> "0000000000000000000000010010111", "0000000000000000000000010011000",
> >> "0000000000000000000000010011001", "0000000000000000000000010011010",
> >> "0000000000000000000000010011011", "0000000000000000000000010011100",
> >> "0000000000000000000000010011101", "0000000000000000000000010011110",
> >> "0000000000000000000000010011111", "0000000000000000000000010100000",
> >> "0000000000000000000000010100001", "0000000000000000000000010100010",
> >> "0000000000000000000000010100011", "0000000000000000000000010100100",
> >> "0000000000000000000000010100101", "0000000000000000000000010100110",
> >> "0000000000000000000000010100111", "0000000000000000000000010101000",
> >> "0000000000000000000000010101001", "0000000000000000000000010101010",
> >> "0000000000000000000000010101011", "0000000000000000000000010101100",
> >> "0000000000000000000000010101101", "0000000000000000000000010101110",
> >> "0000000000000000000000010101111", "0000000000000000000000010110000",
> >> "0000000000000000000000010110001", "0000000000000000000000010110010",
> >> "0000000000000000000000010110011", "0000000000000000000000010110100",
> >> "1111111111111111111111101001100", "1111111111111111111111101001101",
> >> "1111111111111111111111101001110", "1111111111111111111111101001111",
> >> "1111111111111111111111101010000", "1111111111111111111111101010001",
> >> "1111111111111111111111101010010", "1111111111111111111111101010011",
> >> "1111111111111111111111101010100", "1111111111111111111111101010101",
> >> "1111111111111111111111101010110", "1111111111111111111111101010111",
> >> "1111111111111111111111101011000", "1111111111111111111111101011001",
> >> "1111111111111111111111101011010", "1111111111111111111111101011011",
> >> "1111111111111111111111101011100", "1111111111111111111111101011101",
> >> "1111111111111111111111101011110", "1111111111111111111111101011111",
> >> "1111111111111111111111101100000", "1111111111111111111111101100001",
> >> "1111111111111111111111101100010", "1111111111111111111111101100011",
> >> "1111111111111111111111101100100", "1111111111111111111111101100101",
> >> "1111111111111111111111101100110", "1111111111111111111111101100111",
> >> "1111111111111111111111101101000", "1111111111111111111111101101001",
> >> "1111111111111111111111101101010", "1111111111111111111111101101011",
> >> "1111111111111111111111101101100", "1111111111111111111111101101101",
> >> "1111111111111111111111101101110", "1111111111111111111111101101111",
> >> "1111111111111111111111101110000", "1111111111111111111111101110001",
> >> "1111111111111111111111101110010", "1111111111111111111111101110011",
> >> "1111111111111111111111101110100", "1111111111111111111111101110101",
> >> "1111111111111111111111101110110", "1111111111111111111111101110111",
> >> "1111111111111111111111101111000", "1111111111111111111111101111001",
> >> "1111111111111111111111101111010", "1111111111111111111111101111011",
> >> "1111111111111111111111101111100", "1111111111111111111111101111101",
> >> "1111111111111111111111101111110", "1111111111111111111111101111111",
> >> "1111111111111111111111110000000", "1111111111111111111111110000001",
> >> "1111111111111111111111110000010", "1111111111111111111111110000011",
> >> "1111111111111111111111110000100", "1111111111111111111111110000101",
> >> "1111111111111111111111110000110", "1111111111111111111111110000111",
> >> "1111111111111111111111110001000", "1111111111111111111111110001001",
> >> "1111111111111111111111110001010", "1111111111111111111111110001011",
> >> "1111111111111111111111110001100", "1111111111111111111111110001101",
> >> "1111111111111111111111110001110", "1111111111111111111111110001111",
> >> "1111111111111111111111110010000", "1111111111111111111111110010001",
> >> "1111111111111111111111110010010", "1111111111111111111111110010011",
> >> "1111111111111111111111110010100", "1111111111111111111111110010101",
> >> "1111111111111111111111110010110", "1111111111111111111111110010111",
> >> "1111111111111111111111110011000", "1111111111111111111111110011001",
> >> "1111111111111111111111110011010", "1111111111111111111111110011011",
> >> "1111111111111111111111110011100", "1111111111111111111111110011101",
> >> "1111111111111111111111110011110", "1111111111111111111111110011111",
> >> "1111111111111111111111110100000", "1111111111111111111111110100001",
> >> "1111111111111111111111110100010", "1111111111111111111111110100011",
> >> "1111111111111111111111110100100", "1111111111111111111111110100101",
> >> "1111111111111111111111110100110", "1111111111111111111111110100111",
> >> "1111111111111111111111110101000", "1111111111111111111111110101001",
> >> "1111111111111111111111110101010", "1111111111111111111111110101011",
> >> "1111111111111111111111110101100", "1111111111111111111111110101101",
> >> "1111111111111111111111110101110", "1111111111111111111111110101111",
> >> "1111111111111111111111110110000", "1111111111111111111111110110001",
> >> "1111111111111111111111110110010", "1111111111111111111111110110011",
> >> "1111111111111111111111110110100", "1111111111111111111111110110101",
> >> "1111111111111111111111110110110", "1111111111111111111111110110111",
> >> "1111111111111111111111110111000", "1111111111111111111111110111001",
> >> "1111111111111111111111110111010", "1111111111111111111111110111011",
> >> "1111111111111111111111110111100", "1111111111111111111111110111101",
> >> "1111111111111111111111110111110", "1111111111111111111111110111111",
> >> "1111111111111111111111111000000", "1111111111111111111111111000001",
> >> "1111111111111111111111111000010", "1111111111111111111111111000011",
> >> "1111111111111111111111111000100", "1111111111111111111111111000101",
> >> "1111111111111111111111111000110", "1111111111111111111111111000111",
> >> "1111111111111111111111111001000", "1111111111111111111111111001001",
> >> "1111111111111111111111111001010", "1111111111111111111111111001011",
> >> "1111111111111111111111111001100", "1111111111111111111111111001101",
> >> "1111111111111111111111111001110", "1111111111111111111111111001111",
> >> "1111111111111111111111111010000", "1111111111111111111111111010001",
> >> "1111111111111111111111111010010", "1111111111111111111111111010011",
> >> "1111111111111111111111111010100", "1111111111111111111111111010101",
> >> "1111111111111111111111111010110", "1111111111111111111111111010111",
> >> "1111111111111111111111111011000", "1111111111111111111111111011001",
> >> "1111111111111111111111111011010", "1111111111111111111111111011011",
> >> "1111111111111111111111111011100", "1111111111111111111111111011101",
> >> "1111111111111111111111111011110", "1111111111111111111111111011111",
> >> "1111111111111111111111111100000", "1111111111111111111111111100001",
> >> "1111111111111111111111111100010", "1111111111111111111111111100011",
> >> "1111111111111111111111111100100", "1111111111111111111111111100101",
> >> "1111111111111111111111111100110", "1111111111111111111111111100111",
> >> "1111111111111111111111111101000", "1111111111111111111111111101001",
> >> "1111111111111111111111111101010", "1111111111111111111111111101011",
> >> "1111111111111111111111111101100", "1111111111111111111111111101101",
> >> "1111111111111111111111111101110", "1111111111111111111111111101111",
> >> "1111111111111111111111111110000", "1111111111111111111111111110001",
> >> "1111111111111111111111111110010", "1111111111111111111111111110011",
> >> "1111111111111111111111111110100", "1111111111111111111111111110101",
> >> "1111111111111111111111111110110", "1111111111111111111111111110111",
> >> "1111111111111111111111111111000", "1111111111111111111111111111001",
> >> "1111111111111111111111111111010", "1111111111111111111111111111011",
> >> "1111111111111111111111111111100", "1111111111111111111111111111101",
> >> "1111111111111111111111111111110", "1111111111111111111111111111111"
> >> ), class = "factor")), class = "data.frame", row.names = c(NA,
> >> -361L))
> >>
> >> AISMessageFrame (Raw Messages as they come from the AIS device):
> >>
> >> > dput(AISMessageFrame)
> >> structure(list(MessgeCode = structure(c(17L, 6L, 93L, 92L, 81L,
> >> 24L, 4L, 44L, 21L, 43L, 66L, 64L, 94L, 46L, 26L, 82L, 12L, 9L,
> >> 67L, 63L, 65L, 39L, 48L, 38L, 79L, 83L, 37L, 73L, 23L, 68L, 59L,
> >> NA, 5L, 30L, 62L, 84L, 60L, 22L, 52L, 61L, 50L, 70L, 96L, 85L,
> >> 33L, 51L, 8L, 16L, 19L, 71L, 76L, 86L, 34L, 25L, 14L, 53L, 10L,
> >> 29L, 2L, 77L, 57L, 87L, 72L, 54L, 55L, 36L, 1L, 13L, NA, 78L,
> >> 58L, 15L, 89L, 35L, 20L, 3L, 49L, 56L, 90L, 40L, 45L, 41L, 42L,
> >> 74L, 95L, 32L, 91L, 27L, 69L, 76L, 18L, 31L, 11L, 80L, 75L, 7L,
> >> 72L, 88L, 28L, 47L), .Label = c("1:u0KOh001rCq5P529qqubqh2 at 3n",
> >> "100000?P00JCkt:583J=r?v:283Q", "10007NgP00rCQGV5:Pa=?gv>2<1H",
> >> "1000Fo at P01rCuG<56bnkN?v004`0", "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
> >> "1349B:3000rCtrn553aR at JH02PRp", "1349B:3000rCtrn553aR at JHD2d4O",
> >> "137g`F8007rCaIj59Tc5Dl at 800SN", "139NL4000LrCc8j59FEED4 at 000S<",
> >> "13M at Hk00jSJD@RD4s=qG1mT80 at 3J", "13P;K8 at 001rCfgr58=f;QbFD2D4G",
> >> "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "13P>4mhw1CrCi5H57aK5WlN>0<4F",
> >> "14aMBf000wrCKKN5:sdU0Sv<083C", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
> >> "15?7P`0P00rD1S453KSlj?v824`0", "15?f5H?P00rCQat5:Oah0?wn2 at S6",
> >> "15?lSL?P00JCQWD5:OpP0?vB24`0", "15?mqH?P00rCek458rkEN?v:00S4",
> >> "15 at EA<0P01JCo8l53=BFgwv at 0D47", "15 at eD@8000rC`bl59kW`mFn004`0",
> >> "15>nNj0000rCT<@5::qUpkt604`0", "15>uP00P00rC`U:59im;H?v22 at 1D",
> >> "15A at av3P00rClHn53<I8M?v02<2B", "15AIw`0P0GrCcO859DO5Ogv:0T`0",
> >> "15Aq00?P00rC`a`59mFeogv004`0", "15ATk20000rCnrv53N6;gPr>085R",
> >> "15B3Sj0000rC9RD5=mOh40jB20SU", "15BI>P0001rCgUD58DRalRj:00S5",
> >> "15BkV00P00rCQBf5:Q5JQOv42D1o", "15BW=20P00JCrvH54t=an?vB00Sg",
> >> "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "15De7F?P00JCr5r5517v4?v80h2P",
> >> "15E:BR0P00rCgaT58DdJUwv82H34", "15E:N at 0000rCgOd57p45bW><0<2H",
> >> "15E=m60000rC`W459k28Wnd:083h", "15E=q08P00JCrnR52cb>4?v200Sw",
> >> "15PoOh0001rCgbt58CwUaBD004`0", "15PvE at 0002rCi7R57pokCT:424`0",
> >> "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:",
> >> "15QDCP0P?w<tSF0l4Q@>4?wp0D1G", "15QIK`0P00rC`Sb59jFUUgv02<1g",
> >> "15QK900001JCq=d54l?5J0op0l4e", "15QtF00000rCafD59P?VJ9p<0H52",
> >> "15TGcJ0002rD<>p55FgmI at Ul0H0S", "15TgVb0000rCgVb57oFc;ARF2 at 67",
> >> "15TgVb0000rCgVd57oFc31R42L46", "15TILd?P00JCm4l53`D>4?v>0L1m",
> >> "15U?B00000rCgb>58DFJfRl620RT", "15U at cn0000rCgU>57oPLGiT:2D4D",
> >> "15UHOn9P00rCQ`D5:OcTkgv80<4:", "1819?@H001rC9TB5=bppM9<82D0T",
> >> "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
> >> "19NSG<h003rCi@:57pmUkAB<0<1v", "1gu00CLLwfh2 at Asw9@1<",
> "1gu103LLwfl1 at Asw9P1<",
> >> "3", "34`odN1000rD1V2537=dfPJ60000", "35A=Rh1001rD;s454vSTuP`40000",
> >> "35QN<D1000rCr5l53esbgPR20000", "39NS at m11@1rCrb:53:E<v0j3R000",
> >> "403Iu6Qv4PU00rCk0d57rwW00<2g", "403Iu6Qv4PU01rCk0d57rwW00<2g",
> >> "403Iupiv4PU00rC9065>=fW00H0I", "403Iupiv4PU00rC9065>=fW00H0j",
> >> "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
> >> "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
> >> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G@W9K4Oi0D at PC0ShK40C",
> >> "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
> >> "7933.8835099999997", "7933.8836099999999",
> "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
> >> "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "88888888880",
> >> "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
> >> "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
> >> "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T",
> "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
> >> "B;s at N9h00>TtPEQAslh03wuUwP06", "B;s at N9h00>TtPF1Asll03wP5wP06",
> >> "B;s at N9h00>TtPF1Asll03wPUwP06", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
> >> "B;s at N9h00>TtPFQAslt03wQUwP06", "B;s at N9h00>TtPFQAslt03wR5wP06",
> >> "B;s at N9h00>TtPFQAsm003wRUwP06", "B;s at N9h00>TtPFQAsm803wU5wP06",
> >> "B;s at N9h00>TtPG1Asm403wSUwP06", "B;s at N9h00>TtPG1Asm403wT5wP06",
> >> "B;s at N9h00>TtPG1Asm803wTUwP06", "D03Iu6QGLN01MdN01StN000",
> "D03Iuph1TNfp4dv9J<`N000",
> >> "H5?AU:4U653hhhi8 at lkihP000000",
> "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
> >> "PC at H8888880"), class = "factor")), class = "data.frame", row.names =
> c(NA,
> >> -100L))
> >>
> >> Each one of those weird codes given in the AISMessageFrame correspond
> to an AIS message, there is a lot of information provided here, but I am
> only concerned with the Latitude and Longitude values (degrees with
> minutes). In order to accomplish this, each one of those wierd codes need
> to be converted to binary strings, once converted to binary strings. As I
> mentioned before, the information regarding latitude and longitude can be
> extracted from the following positions (again, after converting code to
> binary strings):
> >> Latitude = positions 90 to 116 inclusive (assuming you count the bits
> from left to right, with the first one having position number 1)
> >> Longitude = positions 62 to 89 inclusive (assuming you count the bits
> from left to right withe the first one having position number 1)
> >>
> >> In the sample code I provided in previous emails, I used the following
> to obtain the Latitude and Longitude:
> >>
> >> library(stringi)
> >> library(dplyr)
> >> library(R.utils)
> >> library(RANN)
> >> library(NISTunits)
> >> library(pracma)
> >> library(celestial)
> >> library(stringr)
> >>
> >> #here I show the sample to decode a single record, though that needs to
> be done for all AIS messages, so obviously a loop will be needed for that:
> >>
> >> ascii_datformat <- utf8ToInt(dataset1[1,6]) #turning the first AIS
> message as it comes to ascii number
> >> Base <- ascii_datformat - 48    #transformation from ascii to decimal
> >> decy <- ifelse(Base > 40, Base-8, Base) #transformation from ascii to
> decimal continued
> >> biny <- intToBin(decy)  #transformation from decimal to binary
> representation
> >> binyframe <- data.frame(biny)
> >> tbinyframe <- paste(t(binyframe[,1]), collapse="") #simply transposing
> the results
> >>
> >> tbinyframe will give you something like this (for each row having an
> AIS message)
> >> > tbinyframe
> >> [1]
> "000001000101001111101110000101011000001111100000000000000000111010010011100001101001111100000101001010011111101001110000000000001111111111110110000010010000100011000110"
> >>
> >> Latitude <- substr(tbinyframe, 90, 116)
> >> Longitude <- substr(tbinyframe, 62, 89)
> >>
> >> What I need is to decode thos latitude and longitude values , to get
> results in a -90 to +90 range for latitude, and in the -180 to +180 range
> for longitude.
> >>
> >> Hopefully I?ve made myself sufficiently clear this time and/or
> hopefully I understood your point correctly and provided you what you need.
> >>
> >> Again, thank you so much for your time and valuable support brother!
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >> El vie., 24 ene. 2020 a las 14:09, Richard M. Heiberger (<
> rmh at temple.edu>) escribi?:
> >>>
> >>> now I am even more puzzled.
> >>>
> >>> please complete the following two data.frames and send it to the list.
> >>>
> >>> latDegrees lat2Comp
> >>> -90 xxxxxxxx
> >>> -89 xxxxxxxx
> >>> ...
> >>> -1 xxxxxxxx
> >>> 0 xxxxxxxx
> >>> 1 xxxxxxxx
> >>> ...
> >>> 89 xxxxxxxx
> >>> 90 xxxxxxxx
> >>>
> >>> lonDegrees lon2Comp
> >>> -180 xxxxxxxx
> >>> -179 xxxxxxxx
> >>> ...
> >>> -91 xxxxxxxx
> >>> -90 xxxxxxxx
> >>> -89 xxxxxxxx
> >>> ...
> >>> -1 xxxxxxxx
> >>> 0 xxxxxxxx
> >>> 1 xxxxxxxx
> >>> ...
> >>> 89 xxxxxxxx
> >>> 90 xxxxxxxx
> >>> 91 xxxxxxxx
> >>> ...
> >>> 179 xxxxxxxx
> >>> 180 xxxxxxxx
> >>>
> >>> Your 8 bit 2C example has 7 digits of precision plus sign which gives
> >>> a range of (-127,127).  That suffices for latitude (-90,90).
> >>> For longitude you will need 9 bits of twos complement for 8 bits of
> >>> precision plus sign to cover (-255,255), thus more than enough for
> >>> (-180,180).
> >>> This assumes that precision to the degree is sufficient.  If you need
> >>> precision to minutes and seconds, or to meters, then you
> >>> will need even more bits in 2C.
> >>>
> >>> Since it looks like you need a different number of bits for each
> >>> variable, I am asking for two data.frames.
> >>>
> >>> Rich
> >>>
> >>> On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>> >
> >>> > Hi Richard,
> >>> >
> >>> > That was just an example, to show that, for that particular string
> of binary numbers, the code works as expected. That is absolutely no
> related to the dataset I provided. If I try the function on the dataset, I
> get values well over the latitude and longitude boundaries (which should
> range from -90 to + 90, and -180 to +180).
> >>> >
> >>> > Regards,
> >>> >
> >>> > Paul
> >>> >
> >>> > El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<
> rmh at temple.edu>) escribi?:
> >>> >>
> >>> >> You show the example
> >>> >>
> >>> >> > fun("10110010")
> >>> >> [1] -78
> >>> >>
> >>> >> as satisfactory.  Where in your posted data set do you find the
> input
> >>> >> string "10110010"?
> >>> >>
> >>> >> Please post a set of relevant input strings, and the answers you
> want from them.
> >>> >> The rest of the columns are not helpful for this specific exercise.
> >>> >>
> >>> >> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <
> paulbernal07 at gmail.com> wrote:
> >>> >> >
> >>> >> > Dear friend Rui,
> >>> >> >
> >>> >> > Hope you are doing great. Firstly, I want to thank you for your
> super
> >>> >> > valuable and kind support of always. As I mentioned in earlier
> e-mails, I
> >>> >> > am trying to decode AIS type messages, and the only ones I am
> having a real
> >>> >> > hard time with, is with latitude and longitude.
> >>> >> >
> >>> >> > I tried the function you provided me in one of your replies, and
> it works
> >>> >> > well with the examples  you provided, but in other cases it
> doesn?t.
> >>> >> >
> >>> >> > The messages I am trying to decode are in the 6th column of the
> data. I
> >>> >> > will provide you with a small sample first, and then the complete
> dataset
> >>> >> > (which has 100 rows). This is the small sample:
> >>> >> >
> >>> >> > > head(dat)
> >>> >> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7
>    ...8
> >>> >> > ...9 ...10 ...11 ...12 ...13
> >>> >> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54
> 1485907200
> >>> >> > <NA>    NA    NA    NA  <NA>
> >>> >> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39
> 1485907200
> >>> >> > <NA>    NA    NA    NA  <NA>
> >>> >> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D
> 1485907200
> >>> >> > <NA>    NA    NA    NA  <NA>
> >>> >> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43
> 1485907200
> >>> >> > <NA>    NA    NA    NA  <NA>
> >>> >> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29
> 1485907200
> >>> >> > <NA>    NA    NA    NA  <NA>
> >>> >> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D
> 1485907200
> >>> >> > <NA>    NA    NA    NA  <NA>
> >>> >> >
> >>> >> > It is worth mentioning that each row of the 6th column provides
> several
> >>> >> > information about maritime vessels, like speed over ground,
> latitude,
> >>> >> > longitude, vessel ID, etc. I am only concerned with latitude and
> longitude
> >>> >> > since those are the only two fields I have not been able to decode
> >>> >> > successfully. Also, I am working on R version 3.6.2 for windows
> 64-bit OS.
> >>> >> >
> >>> >> > The messages to decode are of the following format:
> >>> >> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
> >>> >> >
> >>> >> > Now, here is the complete dataset:
> >>> >> >
> >>> >> > > dput(dat)
> >>> >> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> >>> >> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM",
> "$GPGBS",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO",
> "!AIVDM",
> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
> "!AIVDM",
> >>> >> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
> >>> >> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>> >> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
> >>> >> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
> >>> >> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
> >>> >> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
> >>> >> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
> >>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> >>> >> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
> >>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
> >>> >> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> >>> >> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
> >>> >> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
> >>> >> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
> >>> >> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
> >>> >> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
> >>> >> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
> >>> >> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
> >>> >> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
> >>> >> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
> >>> >> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
> >>> >> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
> >>> >> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B",
> "3.2999999999999998",
> >>> >> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
> >>> >> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
> >>> >> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
> >>> >> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
> >>> >> > "D03Iu6QGLN01MdN01StN000",
> >>> >> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
> >>> >> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
> >>> >> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
> >>> >> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
> >>> >> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
> >>> >> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
> >>> >> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
> >>> >> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
> >>> >> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
> >>> >> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
> >>> >> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00
> >TtPF1Asll03wPUwP06",
> >>> >> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
> >>> >> > "15>uP00P00rC`U:59im;H?v22 at 1D",
> >>> >> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
> >>> >> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
> "15BkV00P00rCQBf5:Q5JQOv42D1o",
> >>> >> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
> >>> >> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
> >>> >> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
> >>> >> > "15U?B00000rCgb>58DFJfRl620RT",
> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
> >>> >> > @W9K4Oi0D at PC0ShK40C",
> >>> >> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
> >>> >> > "15De7F?P00JCr5r5517v4?v80h2P",
> >>> >> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
> >>> >> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
> >>> >> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
> >>> >> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
> >>> >> > "15E:BR0P00rCgaT58DdJUwv82H34",
> >>> >> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
> >>> >> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
> >>> >> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
> >>> >> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
> >>> >> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
> >>> >> > "7933.8835099999997",
> >>> >> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
> >>> >> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
> >>> >> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
> >>> >> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
> >>> >> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
> >>> >> > "B;s at N9h00>TtPG1Asm403wSUwP06",
> >>> >> >
> >>> >> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
> >>> >> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
> >>> >> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
> >>> >> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
> >>> >> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
> >>> >> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
> >>> >> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
> >>> >> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
> >>> >> > "15ATk20000rCnrv53N6;gPr>085R",
> >>> >> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
> >>> >> >
> >>> >> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
> >>> >> > "15BW=20P00JCrvH54t=an?vB00Sg",
> >>> >> > "13P;K8 at 001rCfgr58=f;QbFD2D4G",
> "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
> >>> >> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0",
> "1349B:3000rCtrn553aR at JHD2d4O",
> >>> >> >
> >>> >> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
> >>> >> > "15B3Sj0000rC9RD5=mOh40jB20SU",
> >>> >> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
> >>> >> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
> >>> >> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
> >>> >> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
> >>> >> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
> >>> >> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
> >>> >> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
> >>> >> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
> >>> >> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
> >>> >> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C",
> "0*38",
> >>> >> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
> >>> >> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
> >>> >> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 =
> c(1485907200,
> >>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> 1485907200,
> >>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
> 1485907200,
> >>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> 1485907201,
> >>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
> 1485907201,
> >>> >> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
> >>> >> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
> >>> >> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204,
> 1485907204,
> >>> >> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
> 1485907204,
> >>> >> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205,
> 1485907205,
> >>> >> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206,
> 1485907206,
> >>> >> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
> >>> >> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
> >>> >> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208,
> 1485907208,
> >>> >> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209,
> 1485907209,
> >>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
> 1485907209,
> >>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
> >>> >> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
> >>> >> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
> >>> >> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
> >>> >> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> 1485907209,
> >>> >> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
> >>> >> >
> >>> >> > To tested your function I took the first message, which is
> located in the
> >>> >> > 6th column and the 1st row, and did the following:
> >>> >> >
> >>> >> > library(stringi)
> >>> >> > library(dplyr)
> >>> >> > library(R.utils)
> >>> >> > library(RANN)
> >>> >> > library(NISTunits)
> >>> >> > library(pracma)
> >>> >> > library(celestial)
> >>> >> > library(stringr)
> >>> >> >
> >>> >> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE,
> header=FALSE, na="",
> >>> >> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
> >>> >> >
> >>> >> > testmessage1 <- dat[1,6]
> >>> >> >
> >>> >> > ascii_datformat <- utf8ToInt(testmessage1)
> >>> >> >
> >>> >> > Base <- ascii_datformat - 48
> >>> >> >
> >>> >> > decy <- ifelse(Base > 40, Base - 8, Base)
> >>> >> >
> >>> >> > biny <- intToBin(decy)
> >>> >> >
> >>> >> > binyframe <- data.frame(biny)
> >>> >> >
> >>> >> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this
> point, I have
> >>> >> > the complete first message, all in binary format
> >>> >> >
> >>> >> > #according to the literature of AIS message decoding, longitude
> goes from
> >>> >> > position 62 to position 89
> >>> >> > #and latitude goes from position 90 to position 116
> >>> >> >
> >>> >> > longitude <- substr(tbinyframe, 62, 89)
> >>> >> > latitude    <- substr(tbinyframe, 90, 116)
> >>> >> >
> >>> >> > #now I apply the function you provided me with:
> >>> >> >
> >>> >> >  fun <- function(x){
> >>> >> >          res <- sapply(x, function(y){
> >>> >> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
> >>> >> >              strtoi(y, base = 2)
> >>> >> >             }else{
> >>> >> >               y <- unlist(strsplit(y, ""))
> >>> >> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
> >>> >> >             }
> >>> >> >           })
> >>> >> >           unname(res)
> >>> >> >       }
> >>> >> >
> >>> >> > > fun(longitude)
> >>> >> > [1] 220663102
> >>> >> > >
> >>> >> > > fun(latitude)
> >>> >> > [1] 5414823
> >>> >> > >
> >>> >> > > fun("1101001001110000110100111110")
> >>> >> > [1] 220663102
> >>> >> > >
> >>> >> > > fun("000010100101001111110100111")
> >>> >> > [1] 5414823
> >>> >> > >
> >>> >> > > fun("10110010")
> >>> >> > [1] -78
> >>> >> >
> >>> >> > as you can see, the function only worked or showed expected
> result on the
> >>> >> > last case with a -78, but in the other cases, it the results were
> not as
> >>> >> > expected, maybe I am missing something here?
> >>> >> >
> >>> >> > Any help and/or guidance will be greatly appreciated,
> >>> >> >
> >>> >> > Best regards,
> >>> >> >
> >>> >> > Paul
> >>> >> >
> >>> >> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<
> ruipbarradas at sapo.pt>)
> >>> >> > escribi?:
> >>> >> >
> >>> >> > > Hello,
> >>> >> > >
> >>> >> > > The function I included converts signed binary numbers into
> their
> >>> >> > > decimal representation. They are negative if a) they are
> multiples of 8
> >>> >> > > bits and b) the most significant bit is a "1". If not just
> convert to
> >>> >> > > integer.
> >>> >> > >
> >>> >> > > As for a) above, I assume that you will have 8 bit numbers. And
> the
> >>> >> > > conversion is done as follows:
> >>> >> > >
> >>> >> > > input: 10110010
> >>> >

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Sat Jan 25 23:21:38 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sat, 25 Jan 2020 17:21:38 -0500
Subject: [R] 
	=?utf-8?q?Converting_binary_number_to_in_Two=C2=B4s_compleme?=
	=?utf-8?q?nt_representation?=
In-Reply-To: <CAMOcQfN3ay6sFFC0KkG2x_cQec1BF1Kjq1Wsg-2N-xq2g-9RQw@mail.gmail.com>
References: <CAMOcQfM-KHmuChu=8Y0k9n8fvcu7HPn=PV+X_9R7TTD65yOrfg-6542@mail.gmail.com>
 <c888a6a0-d5d1-808e-c4ad-10b4650dc0dd@sapo.pt>
 <7eda7f63-44e1-1ac3-5b00-72c7fd34cf1c@sapo.pt>
 <CAMOcQfPrjpXv4fbT1dhzaMwQufri+2c_HN306rdJw7vVtHgfMg@mail.gmail.com>
 <92fa06c4-fbc6-7a98-406e-21ca39ac8ea1@sapo.pt>
 <CAMOcQfO20DiPHUkor3gRMVysbgJcCQ0xNJhNi-Sq+v=GyF5Zsw@mail.gmail.com>
 <CAGx1TMBZtQ9E+8aywhSaxEHc=70XW4o+Vh6c82cJhPjhYu4fJg@mail.gmail.com>
 <CAMOcQfP1S8ANLuBw26HSqx0r4KSO=q3DvqrcOuAcKQyr578jQg@mail.gmail.com>
 <CAGx1TMA-pZUmu+nfmPAnnVYRhyJthU0=PK0k=rQEp1a8KpzC=g@mail.gmail.com>
 <CAMOcQfOk7ahgYmQz_pX7sNu_X-SRjc=8USbGjs+QbOVwHKoSyw@mail.gmail.com>
 <CAGx1TMDVBksR47xNdJetSvvuZ_yfA8yvq9Bhhyqx2xg1k0zdkA@mail.gmail.com>
 <CAGx1TMAz=9KMuLPJGNk2Mdt-=7R40OCi87TfvgwnB4-7f4qAgg@mail.gmail.com>
 <CAMOcQfN3ay6sFFC0KkG2x_cQec1BF1Kjq1Wsg-2N-xq2g-9RQw@mail.gmail.com>
Message-ID: <CAGx1TMDJBb7AuggST28a-UVdf11ScAR1Jx+ryO7YTXnBgeOsZw@mail.gmail.com>

no,

## I don't see any system in AISMessageFrame
tail(AISMessageFrame)
##                                      MessgeCode
## 95  85E:BR0F0P0000000000032jS2P000000DE7P3A00h0
## 96                 1349B:3000rCtrn553aR at JHD2d4O
## 97                           7933.8835099999997
## 98                 B;s at N9h00>TtPFQAsm803wU5wP06
## 99                 15B3Sj0000rC9RD5=mOh40jB20SU
## 100                15TgVb0000rCgVb57oFc;ARF2 at 67

at a minimum, collect this as character values, not factors.

On Sat, Jan 25, 2020 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friend Richard,
>
> Were you able to obtain the latitude and longitude values with that script?
>
> Thank you so much brother,
>
> Paul
>
> El s?b., 25 de enero de 2020 4:03 p. m., Richard M. Heiberger <rmh at temple.edu> escribi?:
>>
>> ## from2Comp uses base R functions only
>> from2Comp <- function(x, binDigits=8) {
>>   ## binDigits=8 means 8 significant digits plus a sign bit, thus nchar(x) == 9
>>   tmp <- strtoi(x, base=2)
>>   Neg <- (tmp > (2^binDigits - 1))
>>   tmp[Neg] <- tmp[Neg] - (2^(binDigits + 1))
>>   tmp
>> }
>>
>> from2Comp(substr(as.character(LatitudeFrame[,2]), 24, 31), 7)
>>
>> from2Comp(substr(as.character(LatitudeFrame[,2]), 23, 31), 8)
>> from2Comp(substr(as.character(LongitudeFrame[,2]), 23, 31), 8)
>>
>> from2Comp(as.character(LatitudeFrame[,2]), 30)
>> from2Comp(as.character(LongitudeFrame[,2]), 30)
>>
>>
>> ## I don't see any system in AISMessageFrame
>> tail(AISMessageFrame)
>> ##                                      MessgeCode
>> ## 95  85E:BR0F0P0000000000032jS2P000000DE7P3A00h0
>> ## 96                 1349B:3000rCtrn553aR at JHD2d4O
>> ## 97                           7933.8835099999997
>> ## 98                 B;s at N9h00>TtPFQAsm803wU5wP06
>> ## 99                 15B3Sj0000rC9RD5=mOh40jB20SU
>> ## 100                15TgVb0000rCgVb57oFc;ARF2 at 67
>>
>>
>> ## 180Long = -180Long, thus there is duplication.  How do you handle this?
>> ## 90Lat  != -90Lat, so there is no duplication.
>> ## How are minutes and seconds stored?
>>
>> On Fri, Jan 24, 2020 at 5:39 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>> >
>> > I don't have my computer with me, so I am commenting right now on the visual impression of the email.
>> >
>> > The latitude shows 90, 88, ... 2, 89, ...
>> > The labels are lexicographically ordered
>> > -1, -10, -11,...
>> >
>> > The latitude binrep look in correct order, and the labels looks like binary in order.
>> >
>> > These things are identified as factors, not as character.
>> >
>> > Please ensure that character values are not misinterpreted as factor when you construct your data frames.
>> >
>> > The four columns do not look to be in consistent order with each other. This in itself could cause trouble.
>> >
>> > I will look more when I have my computer running R so I can follow the rest of what you wrote.
>> >
>> > Rich
>> >
>> > On Fri, Jan 24, 2020 at 15:02 Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >>
>> >> Dear friend Richard,
>> >>
>> >> Thank you for your interest in helping me through this challenge. As requested, I am providing the two lat and long frames you suggested, plus the one single column I am trying to decode:
>> >>
>> >> LatitudeFrame:
>> >>
>> >> > dput(LatitudeFrame)
>> >> structure(list(Latitude = structure(c(90L, 88L, 87L, 86L, 85L,
>> >> 84L, 83L, 82L, 81L, 80L, 79L, 77L, 76L, 75L, 74L, 73L, 72L, 71L,
>> >> 70L, 69L, 68L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L, 57L,
>> >> 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 46L, 44L, 43L, 42L,
>> >> 41L, 40L, 39L, 38L, 37L, 36L, 35L, 33L, 32L, 31L, 30L, 29L, 28L,
>> >> 27L, 26L, 25L, 24L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L, 14L,
>> >> 13L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 89L, 78L, 67L,
>> >> 56L, 45L, 34L, 23L, 12L, 1L, 91L, 92L, 103L, 114L, 125L, 136L,
>> >> 147L, 158L, 169L, 180L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
>> >> 101L, 102L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
>> >> 113L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
>> >> 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 137L,
>> >> 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 148L, 149L,
>> >> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 159L, 160L, 161L,
>> >> 162L, 163L, 164L, 165L, 166L, 167L, 168L, 170L, 171L, 172L, 173L,
>> >> 174L, 175L, 176L, 177L, 178L, 179L, 181L), .Label = c("-1", "-10",
>> >> "-11", "-12", "-13", "-14", "-15", "-16", "-17", "-18", "-19",
>> >> "-2", "-20", "-21", "-22", "-23", "-24", "-25", "-26", "-27",
>> >> "-28", "-29", "-3", "-30", "-31", "-32", "-33", "-34", "-35",
>> >> "-36", "-37", "-38", "-39", "-4", "-40", "-41", "-42", "-43",
>> >> "-44", "-45", "-46", "-47", "-48", "-49", "-5", "-50", "-51",
>> >> "-52", "-53", "-54", "-55", "-56", "-57", "-58", "-59", "-6",
>> >> "-60", "-61", "-62", "-63", "-64", "-65", "-66", "-67", "-68",
>> >> "-69", "-7", "-70", "-71", "-72", "-73", "-74", "-75", "-76",
>> >> "-77", "-78", "-79", "-8", "-80", "-81", "-82", "-83", "-84",
>> >> "-85", "-86", "-87", "-88", "-89", "-9", "-90", "0", "1", "10",
>> >> "11", "12", "13", "14", "15", "16", "17", "18", "19", "2", "20",
>> >> "21", "22", "23", "24", "25", "26", "27", "28", "29", "3", "30",
>> >> "31", "32", "33", "34", "35", "36", "37", "38", "39", "4", "40",
>> >> "41", "42", "43", "44", "45", "46", "47", "48", "49", "5", "50",
>> >> "51", "52", "53", "54", "55", "56", "57", "58", "59", "6", "60",
>> >> "61", "62", "63", "64", "65", "66", "67", "68", "69", "7", "70",
>> >> "71", "72", "73", "74", "75", "76", "77", "78", "79", "8", "80",
>> >> "81", "82", "83", "84", "85", "86", "87", "88", "89", "9", "90"
>> >> ), class = "factor"), LatitudeBinRep = structure(c(92L, 93L,
>> >> 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L, 102L, 103L, 104L, 105L,
>> >> 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L,
>> >> 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L,
>> >> 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L,
>> >> 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
>> >> 150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L,
>> >> 161L, 162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L,
>> >> 172L, 173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 1L,
>> >> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
>> >> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
>> >> 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L,
>> >> 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L,
>> >> 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L,
>> >> 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
>> >> 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L), .Label = c("0000000000000000000000000000000",
>> >> "0000000000000000000000000000001", "0000000000000000000000000000010",
>> >> "0000000000000000000000000000011", "0000000000000000000000000000100",
>> >> "0000000000000000000000000000101", "0000000000000000000000000000110",
>> >> "0000000000000000000000000000111", "0000000000000000000000000001000",
>> >> "0000000000000000000000000001001", "0000000000000000000000000001010",
>> >> "0000000000000000000000000001011", "0000000000000000000000000001100",
>> >> "0000000000000000000000000001101", "0000000000000000000000000001110",
>> >> "0000000000000000000000000001111", "0000000000000000000000000010000",
>> >> "0000000000000000000000000010001", "0000000000000000000000000010010",
>> >> "0000000000000000000000000010011", "0000000000000000000000000010100",
>> >> "0000000000000000000000000010101", "0000000000000000000000000010110",
>> >> "0000000000000000000000000010111", "0000000000000000000000000011000",
>> >> "0000000000000000000000000011001", "0000000000000000000000000011010",
>> >> "0000000000000000000000000011011", "0000000000000000000000000011100",
>> >> "0000000000000000000000000011101", "0000000000000000000000000011110",
>> >> "0000000000000000000000000011111", "0000000000000000000000000100000",
>> >> "0000000000000000000000000100001", "0000000000000000000000000100010",
>> >> "0000000000000000000000000100011", "0000000000000000000000000100100",
>> >> "0000000000000000000000000100101", "0000000000000000000000000100110",
>> >> "0000000000000000000000000100111", "0000000000000000000000000101000",
>> >> "0000000000000000000000000101001", "0000000000000000000000000101010",
>> >> "0000000000000000000000000101011", "0000000000000000000000000101100",
>> >> "0000000000000000000000000101101", "0000000000000000000000000101110",
>> >> "0000000000000000000000000101111", "0000000000000000000000000110000",
>> >> "0000000000000000000000000110001", "0000000000000000000000000110010",
>> >> "0000000000000000000000000110011", "0000000000000000000000000110100",
>> >> "0000000000000000000000000110101", "0000000000000000000000000110110",
>> >> "0000000000000000000000000110111", "0000000000000000000000000111000",
>> >> "0000000000000000000000000111001", "0000000000000000000000000111010",
>> >> "0000000000000000000000000111011", "0000000000000000000000000111100",
>> >> "0000000000000000000000000111101", "0000000000000000000000000111110",
>> >> "0000000000000000000000000111111", "0000000000000000000000001000000",
>> >> "0000000000000000000000001000001", "0000000000000000000000001000010",
>> >> "0000000000000000000000001000011", "0000000000000000000000001000100",
>> >> "0000000000000000000000001000101", "0000000000000000000000001000110",
>> >> "0000000000000000000000001000111", "0000000000000000000000001001000",
>> >> "0000000000000000000000001001001", "0000000000000000000000001001010",
>> >> "0000000000000000000000001001011", "0000000000000000000000001001100",
>> >> "0000000000000000000000001001101", "0000000000000000000000001001110",
>> >> "0000000000000000000000001001111", "0000000000000000000000001010000",
>> >> "0000000000000000000000001010001", "0000000000000000000000001010010",
>> >> "0000000000000000000000001010011", "0000000000000000000000001010100",
>> >> "0000000000000000000000001010101", "0000000000000000000000001010110",
>> >> "0000000000000000000000001010111", "0000000000000000000000001011000",
>> >> "0000000000000000000000001011001", "0000000000000000000000001011010",
>> >> "1111111111111111111111110100110", "1111111111111111111111110100111",
>> >> "1111111111111111111111110101000", "1111111111111111111111110101001",
>> >> "1111111111111111111111110101010", "1111111111111111111111110101011",
>> >> "1111111111111111111111110101100", "1111111111111111111111110101101",
>> >> "1111111111111111111111110101110", "1111111111111111111111110101111",
>> >> "1111111111111111111111110110000", "1111111111111111111111110110001",
>> >> "1111111111111111111111110110010", "1111111111111111111111110110011",
>> >> "1111111111111111111111110110100", "1111111111111111111111110110101",
>> >> "1111111111111111111111110110110", "1111111111111111111111110110111",
>> >> "1111111111111111111111110111000", "1111111111111111111111110111001",
>> >> "1111111111111111111111110111010", "1111111111111111111111110111011",
>> >> "1111111111111111111111110111100", "1111111111111111111111110111101",
>> >> "1111111111111111111111110111110", "1111111111111111111111110111111",
>> >> "1111111111111111111111111000000", "1111111111111111111111111000001",
>> >> "1111111111111111111111111000010", "1111111111111111111111111000011",
>> >> "1111111111111111111111111000100", "1111111111111111111111111000101",
>> >> "1111111111111111111111111000110", "1111111111111111111111111000111",
>> >> "1111111111111111111111111001000", "1111111111111111111111111001001",
>> >> "1111111111111111111111111001010", "1111111111111111111111111001011",
>> >> "1111111111111111111111111001100", "1111111111111111111111111001101",
>> >> "1111111111111111111111111001110", "1111111111111111111111111001111",
>> >> "1111111111111111111111111010000", "1111111111111111111111111010001",
>> >> "1111111111111111111111111010010", "1111111111111111111111111010011",
>> >> "1111111111111111111111111010100", "1111111111111111111111111010101",
>> >> "1111111111111111111111111010110", "1111111111111111111111111010111",
>> >> "1111111111111111111111111011000", "1111111111111111111111111011001",
>> >> "1111111111111111111111111011010", "1111111111111111111111111011011",
>> >> "1111111111111111111111111011100", "1111111111111111111111111011101",
>> >> "1111111111111111111111111011110", "1111111111111111111111111011111",
>> >> "1111111111111111111111111100000", "1111111111111111111111111100001",
>> >> "1111111111111111111111111100010", "1111111111111111111111111100011",
>> >> "1111111111111111111111111100100", "1111111111111111111111111100101",
>> >> "1111111111111111111111111100110", "1111111111111111111111111100111",
>> >> "1111111111111111111111111101000", "1111111111111111111111111101001",
>> >> "1111111111111111111111111101010", "1111111111111111111111111101011",
>> >> "1111111111111111111111111101100", "1111111111111111111111111101101",
>> >> "1111111111111111111111111101110", "1111111111111111111111111101111",
>> >> "1111111111111111111111111110000", "1111111111111111111111111110001",
>> >> "1111111111111111111111111110010", "1111111111111111111111111110011",
>> >> "1111111111111111111111111110100", "1111111111111111111111111110101",
>> >> "1111111111111111111111111110110", "1111111111111111111111111110111",
>> >> "1111111111111111111111111111000", "1111111111111111111111111111001",
>> >> "1111111111111111111111111111010", "1111111111111111111111111111011",
>> >> "1111111111111111111111111111100", "1111111111111111111111111111101",
>> >> "1111111111111111111111111111110", "1111111111111111111111111111111"
>> >> ), class = "factor")), class = "data.frame", row.names = c(NA,
>> >> -181L))
>> >>
>> >> LongitudeFrame:
>> >>
>> >> > dput(LongitudeFrame)
>> >> structure(list(Longitude = structure(c(91L, 89L, 88L, 87L, 86L,
>> >> 85L, 84L, 83L, 82L, 81L, 80L, 78L, 77L, 76L, 75L, 74L, 73L, 72L,
>> >> 71L, 70L, 69L, 67L, 66L, 65L, 64L, 63L, 62L, 61L, 60L, 59L, 58L,
>> >> 56L, 55L, 54L, 53L, 52L, 51L, 50L, 49L, 48L, 47L, 45L, 44L, 43L,
>> >> 42L, 41L, 40L, 39L, 38L, 37L, 36L, 34L, 33L, 32L, 31L, 30L, 29L,
>> >> 28L, 27L, 26L, 25L, 23L, 22L, 21L, 20L, 19L, 18L, 17L, 16L, 15L,
>> >> 14L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 180L, 179L, 178L,
>> >> 177L, 176L, 175L, 174L, 173L, 172L, 171L, 169L, 168L, 167L, 166L,
>> >> 165L, 164L, 163L, 162L, 161L, 160L, 158L, 157L, 156L, 155L, 154L,
>> >> 153L, 152L, 151L, 150L, 149L, 147L, 146L, 145L, 144L, 143L, 142L,
>> >> 141L, 140L, 139L, 138L, 136L, 135L, 134L, 133L, 132L, 131L, 130L,
>> >> 129L, 128L, 127L, 125L, 124L, 123L, 122L, 121L, 120L, 119L, 118L,
>> >> 117L, 116L, 114L, 113L, 112L, 111L, 110L, 109L, 108L, 107L, 106L,
>> >> 105L, 103L, 102L, 101L, 100L, 99L, 98L, 97L, 96L, 95L, 94L, 92L,
>> >> 90L, 79L, 68L, 57L, 46L, 35L, 24L, 13L, 2L, 170L, 159L, 148L,
>> >> 137L, 126L, 115L, 104L, 93L, 1L, 181L, 182L, 274L, 285L, 296L,
>> >> 307L, 318L, 329L, 340L, 351L, 183L, 194L, 205L, 216L, 227L, 238L,
>> >> 249L, 260L, 271L, 273L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
>> >> 282L, 283L, 284L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L,
>> >> 294L, 295L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 305L,
>> >> 306L, 308L, 309L, 310L, 311L, 312L, 313L, 314L, 315L, 316L, 317L,
>> >> 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 330L,
>> >> 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 341L, 342L,
>> >> 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L,
>> >> 355L, 356L, 357L, 358L, 359L, 360L, 361L, 184L, 185L, 186L, 187L,
>> >> 188L, 189L, 190L, 191L, 192L, 193L, 195L, 196L, 197L, 198L, 199L,
>> >> 200L, 201L, 202L, 203L, 204L, 206L, 207L, 208L, 209L, 210L, 211L,
>> >> 212L, 213L, 214L, 215L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
>> >> 224L, 225L, 226L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
>> >> 236L, 237L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
>> >> 248L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
>> >> 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L, 272L
>> >> ), .Label = c("-1", "-10", "-100", "-101", "-102", "-103", "-104",
>> >> "-105", "-106", "-107", "-108", "-109", "-11", "-110", "-111",
>> >> "-112", "-113", "-114", "-115", "-116", "-117", "-118", "-119",
>> >> "-12", "-120", "-121", "-122", "-123", "-124", "-125", "-126",
>> >> "-127", "-128", "-129", "-13", "-130", "-131", "-132", "-133",
>> >> "-134", "-135", "-136", "-137", "-138", "-139", "-14", "-140",
>> >> "-141", "-142", "-143", "-144", "-145", "-146", "-147", "-148",
>> >> "-149", "-15", "-150", "-151", "-152", "-153", "-154", "-155",
>> >> "-156", "-157", "-158", "-159", "-16", "-160", "-161", "-162",
>> >> "-163", "-164", "-165", "-166", "-167", "-168", "-169", "-17",
>> >> "-170", "-171", "-172", "-173", "-174", "-175", "-176", "-177",
>> >> "-178", "-179", "-18", "-180", "-19", "-2", "-20", "-21", "-22",
>> >> "-23", "-24", "-25", "-26", "-27", "-28", "-29", "-3", "-30",
>> >> "-31", "-32", "-33", "-34", "-35", "-36", "-37", "-38", "-39",
>> >> "-4", "-40", "-41", "-42", "-43", "-44", "-45", "-46", "-47",
>> >> "-48", "-49", "-5", "-50", "-51", "-52", "-53", "-54", "-55",
>> >> "-56", "-57", "-58", "-59", "-6", "-60", "-61", "-62", "-63",
>> >> "-64", "-65", "-66", "-67", "-68", "-69", "-7", "-70", "-71",
>> >> "-72", "-73", "-74", "-75", "-76", "-77", "-78", "-79", "-8",
>> >> "-80", "-81", "-82", "-83", "-84", "-85", "-86", "-87", "-88",
>> >> "-89", "-9", "-90", "-91", "-92", "-93", "-94", "-95", "-96",
>> >> "-97", "-98", "-99", "0", "1", "10", "100", "101", "102", "103",
>> >> "104", "105", "106", "107", "108", "109", "11", "110", "111",
>> >> "112", "113", "114", "115", "116", "117", "118", "119", "12",
>> >> "120", "121", "122", "123", "124", "125", "126", "127", "128",
>> >> "129", "13", "130", "131", "132", "133", "134", "135", "136",
>> >> "137", "138", "139", "14", "140", "141", "142", "143", "144",
>> >> "145", "146", "147", "148", "149", "15", "150", "151", "152",
>> >> "153", "154", "155", "156", "157", "158", "159", "16", "160",
>> >> "161", "162", "163", "164", "165", "166", "167", "168", "169",
>> >> "17", "170", "171", "172", "173", "174", "175", "176", "177",
>> >> "178", "179", "18", "180", "19", "2", "20", "21", "22", "23",
>> >> "24", "25", "26", "27", "28", "29", "3", "30", "31", "32", "33",
>> >> "34", "35", "36", "37", "38", "39", "4", "40", "41", "42", "43",
>> >> "44", "45", "46", "47", "48", "49", "5", "50", "51", "52", "53",
>> >> "54", "55", "56", "57", "58", "59", "6", "60", "61", "62", "63",
>> >> "64", "65", "66", "67", "68", "69", "7", "70", "71", "72", "73",
>> >> "74", "75", "76", "77", "78", "79", "8", "80", "81", "82", "83",
>> >> "84", "85", "86", "87", "88", "89", "9", "90", "91", "92", "93",
>> >> "94", "95", "96", "97", "98", "99"), class = "factor"), LongitudeBinRep = structure(c(182L,
>> >> 183L, 184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 192L, 193L,
>> >> 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L,
>> >> 205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
>> >> 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L,
>> >> 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L, 236L, 237L,
>> >> 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L, 248L,
>> >> 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L, 259L,
>> >> 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L, 270L,
>> >> 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L,
>> >> 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L,
>> >> 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L,
>> >> 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,
>> >> 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L,
>> >> 326L, 327L, 328L, 329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L,
>> >> 337L, 338L, 339L, 340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L,
>> >> 348L, 349L, 350L, 351L, 352L, 353L, 354L, 355L, 356L, 357L, 358L,
>> >> 359L, 360L, 361L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
>> >> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
>> >> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
>> >> 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L,
>> >> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L,
>> >> 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
>> >> 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
>> >> 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 101L,
>> >> 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L,
>> >> 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L,
>> >> 124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L,
>> >> 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L,
>> >> 146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L, 156L,
>> >> 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L, 166L, 167L,
>> >> 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
>> >> 179L, 180L, 181L), .Label = c("0000000000000000000000000000000",
>> >> "0000000000000000000000000000001", "0000000000000000000000000000010",
>> >> "0000000000000000000000000000011", "0000000000000000000000000000100",
>> >> "0000000000000000000000000000101", "0000000000000000000000000000110",
>> >> "0000000000000000000000000000111", "0000000000000000000000000001000",
>> >> "0000000000000000000000000001001", "0000000000000000000000000001010",
>> >> "0000000000000000000000000001011", "0000000000000000000000000001100",
>> >> "0000000000000000000000000001101", "0000000000000000000000000001110",
>> >> "0000000000000000000000000001111", "0000000000000000000000000010000",
>> >> "0000000000000000000000000010001", "0000000000000000000000000010010",
>> >> "0000000000000000000000000010011", "0000000000000000000000000010100",
>> >> "0000000000000000000000000010101", "0000000000000000000000000010110",
>> >> "0000000000000000000000000010111", "0000000000000000000000000011000",
>> >> "0000000000000000000000000011001", "0000000000000000000000000011010",
>> >> "0000000000000000000000000011011", "0000000000000000000000000011100",
>> >> "0000000000000000000000000011101", "0000000000000000000000000011110",
>> >> "0000000000000000000000000011111", "0000000000000000000000000100000",
>> >> "0000000000000000000000000100001", "0000000000000000000000000100010",
>> >> "0000000000000000000000000100011", "0000000000000000000000000100100",
>> >> "0000000000000000000000000100101", "0000000000000000000000000100110",
>> >> "0000000000000000000000000100111", "0000000000000000000000000101000",
>> >> "0000000000000000000000000101001", "0000000000000000000000000101010",
>> >> "0000000000000000000000000101011", "0000000000000000000000000101100",
>> >> "0000000000000000000000000101101", "0000000000000000000000000101110",
>> >> "0000000000000000000000000101111", "0000000000000000000000000110000",
>> >> "0000000000000000000000000110001", "0000000000000000000000000110010",
>> >> "0000000000000000000000000110011", "0000000000000000000000000110100",
>> >> "0000000000000000000000000110101", "0000000000000000000000000110110",
>> >> "0000000000000000000000000110111", "0000000000000000000000000111000",
>> >> "0000000000000000000000000111001", "0000000000000000000000000111010",
>> >> "0000000000000000000000000111011", "0000000000000000000000000111100",
>> >> "0000000000000000000000000111101", "0000000000000000000000000111110",
>> >> "0000000000000000000000000111111", "0000000000000000000000001000000",
>> >> "0000000000000000000000001000001", "0000000000000000000000001000010",
>> >> "0000000000000000000000001000011", "0000000000000000000000001000100",
>> >> "0000000000000000000000001000101", "0000000000000000000000001000110",
>> >> "0000000000000000000000001000111", "0000000000000000000000001001000",
>> >> "0000000000000000000000001001001", "0000000000000000000000001001010",
>> >> "0000000000000000000000001001011", "0000000000000000000000001001100",
>> >> "0000000000000000000000001001101", "0000000000000000000000001001110",
>> >> "0000000000000000000000001001111", "0000000000000000000000001010000",
>> >> "0000000000000000000000001010001", "0000000000000000000000001010010",
>> >> "0000000000000000000000001010011", "0000000000000000000000001010100",
>> >> "0000000000000000000000001010101", "0000000000000000000000001010110",
>> >> "0000000000000000000000001010111", "0000000000000000000000001011000",
>> >> "0000000000000000000000001011001", "0000000000000000000000001011010",
>> >> "0000000000000000000000001011011", "0000000000000000000000001011100",
>> >> "0000000000000000000000001011101", "0000000000000000000000001011110",
>> >> "0000000000000000000000001011111", "0000000000000000000000001100000",
>> >> "0000000000000000000000001100001", "0000000000000000000000001100010",
>> >> "0000000000000000000000001100011", "0000000000000000000000001100100",
>> >> "0000000000000000000000001100101", "0000000000000000000000001100110",
>> >> "0000000000000000000000001100111", "0000000000000000000000001101000",
>> >> "0000000000000000000000001101001", "0000000000000000000000001101010",
>> >> "0000000000000000000000001101011", "0000000000000000000000001101100",
>> >> "0000000000000000000000001101101", "0000000000000000000000001101110",
>> >> "0000000000000000000000001101111", "0000000000000000000000001110000",
>> >> "0000000000000000000000001110001", "0000000000000000000000001110010",
>> >> "0000000000000000000000001110011", "0000000000000000000000001110100",
>> >> "0000000000000000000000001110101", "0000000000000000000000001110110",
>> >> "0000000000000000000000001110111", "0000000000000000000000001111000",
>> >> "0000000000000000000000001111001", "0000000000000000000000001111010",
>> >> "0000000000000000000000001111011", "0000000000000000000000001111100",
>> >> "0000000000000000000000001111101", "0000000000000000000000001111110",
>> >> "0000000000000000000000001111111", "0000000000000000000000010000000",
>> >> "0000000000000000000000010000001", "0000000000000000000000010000010",
>> >> "0000000000000000000000010000011", "0000000000000000000000010000100",
>> >> "0000000000000000000000010000101", "0000000000000000000000010000110",
>> >> "0000000000000000000000010000111", "0000000000000000000000010001000",
>> >> "0000000000000000000000010001001", "0000000000000000000000010001010",
>> >> "0000000000000000000000010001011", "0000000000000000000000010001100",
>> >> "0000000000000000000000010001101", "0000000000000000000000010001110",
>> >> "0000000000000000000000010001111", "0000000000000000000000010010000",
>> >> "0000000000000000000000010010001", "0000000000000000000000010010010",
>> >> "0000000000000000000000010010011", "0000000000000000000000010010100",
>> >> "0000000000000000000000010010101", "0000000000000000000000010010110",
>> >> "0000000000000000000000010010111", "0000000000000000000000010011000",
>> >> "0000000000000000000000010011001", "0000000000000000000000010011010",
>> >> "0000000000000000000000010011011", "0000000000000000000000010011100",
>> >> "0000000000000000000000010011101", "0000000000000000000000010011110",
>> >> "0000000000000000000000010011111", "0000000000000000000000010100000",
>> >> "0000000000000000000000010100001", "0000000000000000000000010100010",
>> >> "0000000000000000000000010100011", "0000000000000000000000010100100",
>> >> "0000000000000000000000010100101", "0000000000000000000000010100110",
>> >> "0000000000000000000000010100111", "0000000000000000000000010101000",
>> >> "0000000000000000000000010101001", "0000000000000000000000010101010",
>> >> "0000000000000000000000010101011", "0000000000000000000000010101100",
>> >> "0000000000000000000000010101101", "0000000000000000000000010101110",
>> >> "0000000000000000000000010101111", "0000000000000000000000010110000",
>> >> "0000000000000000000000010110001", "0000000000000000000000010110010",
>> >> "0000000000000000000000010110011", "0000000000000000000000010110100",
>> >> "1111111111111111111111101001100", "1111111111111111111111101001101",
>> >> "1111111111111111111111101001110", "1111111111111111111111101001111",
>> >> "1111111111111111111111101010000", "1111111111111111111111101010001",
>> >> "1111111111111111111111101010010", "1111111111111111111111101010011",
>> >> "1111111111111111111111101010100", "1111111111111111111111101010101",
>> >> "1111111111111111111111101010110", "1111111111111111111111101010111",
>> >> "1111111111111111111111101011000", "1111111111111111111111101011001",
>> >> "1111111111111111111111101011010", "1111111111111111111111101011011",
>> >> "1111111111111111111111101011100", "1111111111111111111111101011101",
>> >> "1111111111111111111111101011110", "1111111111111111111111101011111",
>> >> "1111111111111111111111101100000", "1111111111111111111111101100001",
>> >> "1111111111111111111111101100010", "1111111111111111111111101100011",
>> >> "1111111111111111111111101100100", "1111111111111111111111101100101",
>> >> "1111111111111111111111101100110", "1111111111111111111111101100111",
>> >> "1111111111111111111111101101000", "1111111111111111111111101101001",
>> >> "1111111111111111111111101101010", "1111111111111111111111101101011",
>> >> "1111111111111111111111101101100", "1111111111111111111111101101101",
>> >> "1111111111111111111111101101110", "1111111111111111111111101101111",
>> >> "1111111111111111111111101110000", "1111111111111111111111101110001",
>> >> "1111111111111111111111101110010", "1111111111111111111111101110011",
>> >> "1111111111111111111111101110100", "1111111111111111111111101110101",
>> >> "1111111111111111111111101110110", "1111111111111111111111101110111",
>> >> "1111111111111111111111101111000", "1111111111111111111111101111001",
>> >> "1111111111111111111111101111010", "1111111111111111111111101111011",
>> >> "1111111111111111111111101111100", "1111111111111111111111101111101",
>> >> "1111111111111111111111101111110", "1111111111111111111111101111111",
>> >> "1111111111111111111111110000000", "1111111111111111111111110000001",
>> >> "1111111111111111111111110000010", "1111111111111111111111110000011",
>> >> "1111111111111111111111110000100", "1111111111111111111111110000101",
>> >> "1111111111111111111111110000110", "1111111111111111111111110000111",
>> >> "1111111111111111111111110001000", "1111111111111111111111110001001",
>> >> "1111111111111111111111110001010", "1111111111111111111111110001011",
>> >> "1111111111111111111111110001100", "1111111111111111111111110001101",
>> >> "1111111111111111111111110001110", "1111111111111111111111110001111",
>> >> "1111111111111111111111110010000", "1111111111111111111111110010001",
>> >> "1111111111111111111111110010010", "1111111111111111111111110010011",
>> >> "1111111111111111111111110010100", "1111111111111111111111110010101",
>> >> "1111111111111111111111110010110", "1111111111111111111111110010111",
>> >> "1111111111111111111111110011000", "1111111111111111111111110011001",
>> >> "1111111111111111111111110011010", "1111111111111111111111110011011",
>> >> "1111111111111111111111110011100", "1111111111111111111111110011101",
>> >> "1111111111111111111111110011110", "1111111111111111111111110011111",
>> >> "1111111111111111111111110100000", "1111111111111111111111110100001",
>> >> "1111111111111111111111110100010", "1111111111111111111111110100011",
>> >> "1111111111111111111111110100100", "1111111111111111111111110100101",
>> >> "1111111111111111111111110100110", "1111111111111111111111110100111",
>> >> "1111111111111111111111110101000", "1111111111111111111111110101001",
>> >> "1111111111111111111111110101010", "1111111111111111111111110101011",
>> >> "1111111111111111111111110101100", "1111111111111111111111110101101",
>> >> "1111111111111111111111110101110", "1111111111111111111111110101111",
>> >> "1111111111111111111111110110000", "1111111111111111111111110110001",
>> >> "1111111111111111111111110110010", "1111111111111111111111110110011",
>> >> "1111111111111111111111110110100", "1111111111111111111111110110101",
>> >> "1111111111111111111111110110110", "1111111111111111111111110110111",
>> >> "1111111111111111111111110111000", "1111111111111111111111110111001",
>> >> "1111111111111111111111110111010", "1111111111111111111111110111011",
>> >> "1111111111111111111111110111100", "1111111111111111111111110111101",
>> >> "1111111111111111111111110111110", "1111111111111111111111110111111",
>> >> "1111111111111111111111111000000", "1111111111111111111111111000001",
>> >> "1111111111111111111111111000010", "1111111111111111111111111000011",
>> >> "1111111111111111111111111000100", "1111111111111111111111111000101",
>> >> "1111111111111111111111111000110", "1111111111111111111111111000111",
>> >> "1111111111111111111111111001000", "1111111111111111111111111001001",
>> >> "1111111111111111111111111001010", "1111111111111111111111111001011",
>> >> "1111111111111111111111111001100", "1111111111111111111111111001101",
>> >> "1111111111111111111111111001110", "1111111111111111111111111001111",
>> >> "1111111111111111111111111010000", "1111111111111111111111111010001",
>> >> "1111111111111111111111111010010", "1111111111111111111111111010011",
>> >> "1111111111111111111111111010100", "1111111111111111111111111010101",
>> >> "1111111111111111111111111010110", "1111111111111111111111111010111",
>> >> "1111111111111111111111111011000", "1111111111111111111111111011001",
>> >> "1111111111111111111111111011010", "1111111111111111111111111011011",
>> >> "1111111111111111111111111011100", "1111111111111111111111111011101",
>> >> "1111111111111111111111111011110", "1111111111111111111111111011111",
>> >> "1111111111111111111111111100000", "1111111111111111111111111100001",
>> >> "1111111111111111111111111100010", "1111111111111111111111111100011",
>> >> "1111111111111111111111111100100", "1111111111111111111111111100101",
>> >> "1111111111111111111111111100110", "1111111111111111111111111100111",
>> >> "1111111111111111111111111101000", "1111111111111111111111111101001",
>> >> "1111111111111111111111111101010", "1111111111111111111111111101011",
>> >> "1111111111111111111111111101100", "1111111111111111111111111101101",
>> >> "1111111111111111111111111101110", "1111111111111111111111111101111",
>> >> "1111111111111111111111111110000", "1111111111111111111111111110001",
>> >> "1111111111111111111111111110010", "1111111111111111111111111110011",
>> >> "1111111111111111111111111110100", "1111111111111111111111111110101",
>> >> "1111111111111111111111111110110", "1111111111111111111111111110111",
>> >> "1111111111111111111111111111000", "1111111111111111111111111111001",
>> >> "1111111111111111111111111111010", "1111111111111111111111111111011",
>> >> "1111111111111111111111111111100", "1111111111111111111111111111101",
>> >> "1111111111111111111111111111110", "1111111111111111111111111111111"
>> >> ), class = "factor")), class = "data.frame", row.names = c(NA,
>> >> -361L))
>> >>
>> >> AISMessageFrame (Raw Messages as they come from the AIS device):
>> >>
>> >> > dput(AISMessageFrame)
>> >> structure(list(MessgeCode = structure(c(17L, 6L, 93L, 92L, 81L,
>> >> 24L, 4L, 44L, 21L, 43L, 66L, 64L, 94L, 46L, 26L, 82L, 12L, 9L,
>> >> 67L, 63L, 65L, 39L, 48L, 38L, 79L, 83L, 37L, 73L, 23L, 68L, 59L,
>> >> NA, 5L, 30L, 62L, 84L, 60L, 22L, 52L, 61L, 50L, 70L, 96L, 85L,
>> >> 33L, 51L, 8L, 16L, 19L, 71L, 76L, 86L, 34L, 25L, 14L, 53L, 10L,
>> >> 29L, 2L, 77L, 57L, 87L, 72L, 54L, 55L, 36L, 1L, 13L, NA, 78L,
>> >> 58L, 15L, 89L, 35L, 20L, 3L, 49L, 56L, 90L, 40L, 45L, 41L, 42L,
>> >> 74L, 95L, 32L, 91L, 27L, 69L, 76L, 18L, 31L, 11L, 80L, 75L, 7L,
>> >> 72L, 88L, 28L, 47L), .Label = c("1:u0KOh001rCq5P529qqubqh2 at 3n",
>> >> "100000?P00JCkt:583J=r?v:283Q", "10007NgP00rCQGV5:Pa=?gv>2<1H",
>> >> "1000Fo at P01rCuG<56bnkN?v004`0", "1018lEWP?w<tSF0l4Q@>4?wp0W3h",
>> >> "1349B:3000rCtrn553aR at JH02PRp", "1349B:3000rCtrn553aR at JHD2d4O",
>> >> "137g`F8007rCaIj59Tc5Dl at 800SN", "139NL4000LrCc8j59FEED4 at 000S<",
>> >> "13M at Hk00jSJD@RD4s=qG1mT80 at 3J", "13P;K8 at 001rCfgr58=f;QbFD2D4G",
>> >> "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "13P>4mhw1CrCi5H57aK5WlN>0<4F",
>> >> "14aMBf000wrCKKN5:sdU0Sv<083C", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>> >> "15?7P`0P00rD1S453KSlj?v824`0", "15?f5H?P00rCQat5:Oah0?wn2 at S6",
>> >> "15?lSL?P00JCQWD5:OpP0?vB24`0", "15?mqH?P00rCek458rkEN?v:00S4",
>> >> "15 at EA<0P01JCo8l53=BFgwv at 0D47", "15 at eD@8000rC`bl59kW`mFn004`0",
>> >> "15>nNj0000rCT<@5::qUpkt604`0", "15>uP00P00rC`U:59im;H?v22 at 1D",
>> >> "15A at av3P00rClHn53<I8M?v02<2B", "15AIw`0P0GrCcO859DO5Ogv:0T`0",
>> >> "15Aq00?P00rC`a`59mFeogv004`0", "15ATk20000rCnrv53N6;gPr>085R",
>> >> "15B3Sj0000rC9RD5=mOh40jB20SU", "15BI>P0001rCgUD58DRalRj:00S5",
>> >> "15BkV00P00rCQBf5:Q5JQOv42D1o", "15BW=20P00JCrvH54t=an?vB00Sg",
>> >> "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "15De7F?P00JCr5r5517v4?v80h2P",
>> >> "15E:BR0P00rCgaT58DdJUwv82H34", "15E:N at 0000rCgOd57p45bW><0<2H",
>> >> "15E=m60000rC`W459k28Wnd:083h", "15E=q08P00JCrnR52cb>4?v200Sw",
>> >> "15PoOh0001rCgbt58CwUaBD004`0", "15PvE at 0002rCi7R57pokCT:424`0",
>> >> "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:",
>> >> "15QDCP0P?w<tSF0l4Q@>4?wp0D1G", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>> >> "15QK900001JCq=d54l?5J0op0l4e", "15QtF00000rCafD59P?VJ9p<0H52",
>> >> "15TGcJ0002rD<>p55FgmI at Ul0H0S", "15TgVb0000rCgVb57oFc;ARF2 at 67",
>> >> "15TgVb0000rCgVd57oFc31R42L46", "15TILd?P00JCm4l53`D>4?v>0L1m",
>> >> "15U?B00000rCgb>58DFJfRl620RT", "15U at cn0000rCgU>57oPLGiT:2D4D",
>> >> "15UHOn9P00rCQ`D5:OcTkgv80<4:", "1819?@H001rC9TB5=bppM9<82D0T",
>> >> "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>> >> "19NSG<h003rCi@:57pmUkAB<0<1v", "1gu00CLLwfh2 at Asw9@1<", "1gu103LLwfl1 at Asw9P1<",
>> >> "3", "34`odN1000rD1V2537=dfPJ60000", "35A=Rh1001rD;s454vSTuP`40000",
>> >> "35QN<D1000rCr5l53esbgPR20000", "39NS at m11@1rCrb:53:E<v0j3R000",
>> >> "403Iu6Qv4PU00rCk0d57rwW00<2g", "403Iu6Qv4PU01rCk0d57rwW00<2g",
>> >> "403Iupiv4PU00rC9065>=fW00H0I", "403Iupiv4PU00rC9065>=fW00H0j",
>> >> "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>> >> "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>> >> "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G@W9K4Oi0D at PC0ShK40C",
>> >> "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>> >> "7933.8835099999997", "7933.8836099999999", "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>> >> "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "88888888880",
>> >> "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>> >> "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>> >> "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>> >> "B;s at N9h00>TtPEQAslh03wuUwP06", "B;s at N9h00>TtPF1Asll03wP5wP06",
>> >> "B;s at N9h00>TtPF1Asll03wPUwP06", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>> >> "B;s at N9h00>TtPFQAslt03wQUwP06", "B;s at N9h00>TtPFQAslt03wR5wP06",
>> >> "B;s at N9h00>TtPFQAsm003wRUwP06", "B;s at N9h00>TtPFQAsm803wU5wP06",
>> >> "B;s at N9h00>TtPG1Asm403wSUwP06", "B;s at N9h00>TtPG1Asm403wT5wP06",
>> >> "B;s at N9h00>TtPG1Asm803wTUwP06", "D03Iu6QGLN01MdN01StN000", "D03Iuph1TNfp4dv9J<`N000",
>> >> "H5?AU:4U653hhhi8 at lkihP000000", "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>> >> "PC at H8888880"), class = "factor")), class = "data.frame", row.names = c(NA,
>> >> -100L))
>> >>
>> >> Each one of those weird codes given in the AISMessageFrame correspond to an AIS message, there is a lot of information provided here, but I am only concerned with the Latitude and Longitude values (degrees with minutes). In order to accomplish this, each one of those wierd codes need to be converted to binary strings, once converted to binary strings. As I mentioned before, the information regarding latitude and longitude can be extracted from the following positions (again, after converting code to binary strings):
>> >> Latitude = positions 90 to 116 inclusive (assuming you count the bits from left to right, with the first one having position number 1)
>> >> Longitude = positions 62 to 89 inclusive (assuming you count the bits from left to right withe the first one having position number 1)
>> >>
>> >> In the sample code I provided in previous emails, I used the following to obtain the Latitude and Longitude:
>> >>
>> >> library(stringi)
>> >> library(dplyr)
>> >> library(R.utils)
>> >> library(RANN)
>> >> library(NISTunits)
>> >> library(pracma)
>> >> library(celestial)
>> >> library(stringr)
>> >>
>> >> #here I show the sample to decode a single record, though that needs to be done for all AIS messages, so obviously a loop will be needed for that:
>> >>
>> >> ascii_datformat <- utf8ToInt(dataset1[1,6]) #turning the first AIS message as it comes to ascii number
>> >> Base <- ascii_datformat - 48    #transformation from ascii to decimal
>> >> decy <- ifelse(Base > 40, Base-8, Base) #transformation from ascii to decimal continued
>> >> biny <- intToBin(decy)  #transformation from decimal to binary representation
>> >> binyframe <- data.frame(biny)
>> >> tbinyframe <- paste(t(binyframe[,1]), collapse="") #simply transposing the results
>> >>
>> >> tbinyframe will give you something like this (for each row having an AIS message)
>> >> > tbinyframe
>> >> [1] "000001000101001111101110000101011000001111100000000000000000111010010011100001101001111100000101001010011111101001110000000000001111111111110110000010010000100011000110"
>> >>
>> >> Latitude <- substr(tbinyframe, 90, 116)
>> >> Longitude <- substr(tbinyframe, 62, 89)
>> >>
>> >> What I need is to decode thos latitude and longitude values , to get results in a -90 to +90 range for latitude, and in the -180 to +180 range for longitude.
>> >>
>> >> Hopefully I?ve made myself sufficiently clear this time and/or hopefully I understood your point correctly and provided you what you need.
>> >>
>> >> Again, thank you so much for your time and valuable support brother!
>> >>
>> >> Best regards,
>> >>
>> >> Paul
>> >>
>> >> El vie., 24 ene. 2020 a las 14:09, Richard M. Heiberger (<rmh at temple.edu>) escribi?:
>> >>>
>> >>> now I am even more puzzled.
>> >>>
>> >>> please complete the following two data.frames and send it to the list.
>> >>>
>> >>> latDegrees lat2Comp
>> >>> -90 xxxxxxxx
>> >>> -89 xxxxxxxx
>> >>> ...
>> >>> -1 xxxxxxxx
>> >>> 0 xxxxxxxx
>> >>> 1 xxxxxxxx
>> >>> ...
>> >>> 89 xxxxxxxx
>> >>> 90 xxxxxxxx
>> >>>
>> >>> lonDegrees lon2Comp
>> >>> -180 xxxxxxxx
>> >>> -179 xxxxxxxx
>> >>> ...
>> >>> -91 xxxxxxxx
>> >>> -90 xxxxxxxx
>> >>> -89 xxxxxxxx
>> >>> ...
>> >>> -1 xxxxxxxx
>> >>> 0 xxxxxxxx
>> >>> 1 xxxxxxxx
>> >>> ...
>> >>> 89 xxxxxxxx
>> >>> 90 xxxxxxxx
>> >>> 91 xxxxxxxx
>> >>> ...
>> >>> 179 xxxxxxxx
>> >>> 180 xxxxxxxx
>> >>>
>> >>> Your 8 bit 2C example has 7 digits of precision plus sign which gives
>> >>> a range of (-127,127).  That suffices for latitude (-90,90).
>> >>> For longitude you will need 9 bits of twos complement for 8 bits of
>> >>> precision plus sign to cover (-255,255), thus more than enough for
>> >>> (-180,180).
>> >>> This assumes that precision to the degree is sufficient.  If you need
>> >>> precision to minutes and seconds, or to meters, then you
>> >>> will need even more bits in 2C.
>> >>>
>> >>> Since it looks like you need a different number of bits for each
>> >>> variable, I am asking for two data.frames.
>> >>>
>> >>> Rich
>> >>>
>> >>> On Fri, Jan 24, 2020 at 1:46 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >>> >
>> >>> > Hi Richard,
>> >>> >
>> >>> > That was just an example, to show that, for that particular string of binary numbers, the code works as expected. That is absolutely no related to the dataset I provided. If I try the function on the dataset, I get values well over the latitude and longitude boundaries (which should range from -90 to + 90, and -180 to +180).
>> >>> >
>> >>> > Regards,
>> >>> >
>> >>> > Paul
>> >>> >
>> >>> > El vie., 24 ene. 2020 a las 12:23, Richard M. Heiberger (<rmh at temple.edu>) escribi?:
>> >>> >>
>> >>> >> You show the example
>> >>> >>
>> >>> >> > fun("10110010")
>> >>> >> [1] -78
>> >>> >>
>> >>> >> as satisfactory.  Where in your posted data set do you find the input
>> >>> >> string "10110010"?
>> >>> >>
>> >>> >> Please post a set of relevant input strings, and the answers you want from them.
>> >>> >> The rest of the columns are not helpful for this specific exercise.
>> >>> >>
>> >>> >> On Fri, Jan 24, 2020 at 11:34 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >>> >> >
>> >>> >> > Dear friend Rui,
>> >>> >> >
>> >>> >> > Hope you are doing great. Firstly, I want to thank you for your super
>> >>> >> > valuable and kind support of always. As I mentioned in earlier e-mails, I
>> >>> >> > am trying to decode AIS type messages, and the only ones I am having a real
>> >>> >> > hard time with, is with latitude and longitude.
>> >>> >> >
>> >>> >> > I tried the function you provided me in one of your replies, and it works
>> >>> >> > well with the examples  you provided, but in other cases it doesn?t.
>> >>> >> >
>> >>> >> > The messages I am trying to decode are in the 6th column of the data. I
>> >>> >> > will provide you with a small sample first, and then the complete dataset
>> >>> >> > (which has 100 rows). This is the small sample:
>> >>> >> >
>> >>> >> > > head(dat)
>> >>> >> >     ...1 ...2 ...3 ...4 ...5                         ...6 ...7       ...8
>> >>> >> > ...9 ...10 ...11 ...12 ...13
>> >>> >> > 1 !AIVDM    1    1   NA    A 15?f5H?P00rCQat5:Oah0?wn2 at S6 0*54 1485907200
>> >>> >> > <NA>    NA    NA    NA  <NA>
>> >>> >> > 2 !AIVDM    1    1   NA    A 1349B:3000rCtrn553aR at JH02PRp 0*39 1485907200
>> >>> >> > <NA>    NA    NA    NA  <NA>
>> >>> >> > 3 !AIVDM    1    1   NA    A      D03Iuph1TNfp4dv9J<`N000 2*0D 1485907200
>> >>> >> > <NA>    NA    NA    NA  <NA>
>> >>> >> > 4 !AIVDM    1    1   NA    A      D03Iu6QGLN01MdN01StN000 2*43 1485907200
>> >>> >> > <NA>    NA    NA    NA  <NA>
>> >>> >> > 5 !AIVDO    1    1   NA <NA> B;s at N9h00>TtPEQAslh03wuUwP06 0*29 1485907200
>> >>> >> > <NA>    NA    NA    NA  <NA>
>> >>> >> > 6 !AIVDM    1    1   NA    A 15A at av3P00rClHn53<I8M?v02<2B 0*2D 1485907200
>> >>> >> > <NA>    NA    NA    NA  <NA>
>> >>> >> >
>> >>> >> > It is worth mentioning that each row of the 6th column provides several
>> >>> >> > information about maritime vessels, like speed over ground, latitude,
>> >>> >> > longitude, vessel ID, etc. I am only concerned with latitude and longitude
>> >>> >> > since those are the only two fields I have not been able to decode
>> >>> >> > successfully. Also, I am working on R version 3.6.2 for windows 64-bit OS.
>> >>> >> >
>> >>> >> > The messages to decode are of the following format:
>> >>> >> > 15?f5H?P00rCQat5:Oah0?wn2 at S6,  1349B:3000rCtrn553aR at JH02PRp, etc.
>> >>> >> >
>> >>> >> > Now, here is the complete dataset:
>> >>> >> >
>> >>> >> > > dput(dat)
>> >>> >> > structure(list(...1 = c("!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDO", "!AIVDM", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "$GPGBS",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDO", "$GPRMC", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "$GPGBS", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDO", "!AIVDM",
>> >>> >> > "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM", "!AIVDM",
>> >>> >> > "!AIVDM", "$GPRMC", "!AIVDO", "!AIVDM", "!AIVDM"), ...2 = c(1,
>> >>> >> > 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> >>> >> > 1, 1, 1, 1, 1, 50002, 1, 2, 2, 50002, 1, 1, 1, 1, 1, 1, 1, 1,
>> >>> >> > 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
>> >>> >> > 1, 50006, 1, 1, 1, 1, 1, 50006, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,
>> >>> >> > 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 50010, 1,
>> >>> >> > 1, 1), ...3 = c("1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >>> >> > "1", "1", "1", "1", "1", "A", "1", "1", "2", "1.3", "1", "1",
>> >>> >> > "1", "1", "1", "1", "1", "1", "1", "1", "2", "1", "1", "1", "1",
>> >>> >> > "1", "1", "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >>> >> > "2", "1", "A", "1", "1", "1", "1", "1", "1.3999999999999999",
>> >>> >> > "1", "2", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>> >>> >> > "1", "1", "2", "1", "1", "1", "1", "2", "1", "1", "1", "1", "1",
>> >>> >> > "1", "A", "1", "1", "1"), ...4 = c(NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, 856.96783, NA, 7, 7, 1.5, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, 8, 8, NA, NA, NA, NA, NA, NA, 9, 9, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, 0, 0, NA, 856.96805, NA, NA, NA, NA, NA,
>> >>> >> > 1.5, 1, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
>> >>> >> > 2, NA, NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 856.96827, NA, NA,
>> >>> >> > NA), ...5 = c("A", "A", "A", "A", NA, "A", "A", "B", "B", "A",
>> >>> >> > "A", "A", "A", "B", "B", NA, "B", "A", "B", "A", "B", "B", "A",
>> >>> >> > "B", "A", NA, "B", "N", "B", "A", "A", "3.2000000000000002",
>> >>> >> > "B", "A", "A", NA, "A", "A", "A", "A", "B", "A", "A", NA, "B",
>> >>> >> > "A", "A", "A", "A", "A", "A", NA, "A", "A", "A", "B", "B", "B",
>> >>> >> > "B", "A", "A", NA, "N", "A", "A", "B", "B", "B", "3.2999999999999998",
>> >>> >> > "B", "B", "B", NA, "B", "B", "A", "B", "B", NA, "B", "B", "A",
>> >>> >> > "A", "B", "B", "A", NA, "B", "B", "B", "A", "A", "A", "A", "A",
>> >>> >> > "B", "N", NA, "B", "B"), ...6 = c("15?f5H?P00rCQat5:Oah0?wn2 at S6",
>> >>> >> > "1349B:3000rCtrn553aR at JH02PRp", "D03Iuph1TNfp4dv9J<`N000",
>> >>> >> > "D03Iu6QGLN01MdN01StN000",
>> >>> >> > "B;s at N9h00>TtPEQAslh03wuUwP06", "15A at av3P00rClHn53<I8M?v02<2B",
>> >>> >> > "1000Fo at P01rCuG<56bnkN?v004`0", "15QK900001JCq=d54l?5J0op0l4e",
>> >>> >> > "15 at eD@8000rC`bl59kW`mFn004`0", "15QIK`0P00rC`Sb59jFUUgv02<1g",
>> >>> >> > "403Iupiv4PU00rC9065>=fW00H0I", "403Iu6Qv4PU00rCk0d57rwW00<2g",
>> >>> >> > "H5?AU:4U653hhhi8 at lkihP000000", "15TGcJ0002rD<>p55FgmI at Ul0H0S",
>> >>> >> > "15Aq00?P00rC`a`59mFeogv004`0", "B;s at N9h00>TtPF1Asll03wP5wP06",
>> >>> >> > "13P;K8 at Oh1rCfgp58=ec1bD22<4J", "139NL4000LrCc8j59FEED4 at 000S<",
>> >>> >> > "403Iupiv4PU00rC9065>=fW00H0j", "39NS at m11@1rCrb:53:E<v0j3R000",
>> >>> >> > "403Iu6Qv4PU01rCk0d57rwW00<2g", "15PvE at 0002rCi7R57pokCT:424`0",
>> >>> >> > "15TgVb0000rCgVd57oFc31R42L46", "15PoOh0001rCgbt58CwUaBD004`0",
>> >>> >> > "A03IupkAC4:dH0v90>@P1cF6nud at NrP5wH5T", "B;s at N9h00>TtPF1Asll03wPUwP06",
>> >>> >> > "15E=q08P00JCrnR52cb>4?v200Sw", "7933.8836099999999",
>> >>> >> > "15>uP00P00rC`U:59im;H?v22 at 1D",
>> >>> >> > "54aMBf02:9M`?IDOH018DL4j085T000000000016>`Q8>4Oc0?@lRDm3hPC0",
>> >>> >> > "3", NA, "1018lEWP?w<tSF0l4Q@>4?wp0W3h", "15BkV00P00rCQBf5:Q5JQOv42D1o",
>> >>> >> > "35QN<D1000rCr5l53esbgPR20000", "B;s at N9h00>TtPF1Aslp03wQ5wP06",
>> >>> >> > "34`odN1000rD1V2537=dfPJ60000", "15>nNj0000rCT<@5::qUpkt604`0",
>> >>> >> > "15UHOn9P00rCQ`D5:OcTkgv80<4:", "35A=Rh1001rD;s454vSTuP`40000",
>> >>> >> > "15U?B00000rCgb>58DFJfRl620RT", "55B7iD42CSGC<H`WF20L5>1=@5:222222222221 at G
>> >>> >> > @W9K4Oi0D at PC0ShK40C",
>> >>> >> > "PC at H8888880", "B;s at N9h00>TtPFQAslt03wQUwP06",
>> >>> >> > "15De7F?P00JCr5r5517v4?v80h2P",
>> >>> >> > "15U at cn0000rCgU>57oPLGiT:2D4D", "137g`F8007rCaIj59Tc5Dl at 800SN",
>> >>> >> > "15?7P`0P00rD1S453KSlj?v824`0", "15?mqH?P00rCek458rkEN?v:00S4",
>> >>> >> > "55R4:002?H<`Q3S7GR1<lUB0 at 4pF22222222220l000004p60;0E7kBE8888",
>> >>> >> > "88888888880", "B;s at N9h00>TtPFQAslt03wR5wP06",
>> >>> >> > "15E:BR0P00rCgaT58DdJUwv82H34",
>> >>> >> > "15AIw`0P0GrCcO859DO5Ogv:0T`0", "14aMBf000wrCKKN5:sdU0Sv<083C",
>> >>> >> > "1819?@H001rC9TB5=bppM9<82D0T", "13M at Hk00jSJD@RD4s=qG1mT80 at 3J",
>> >>> >> > "15BI>P0001rCgUD58DRalRj:00S5", "100000?P00JCkt:583J=r?v:283Q",
>> >>> >> > "A03IupkAC4:dH0N90C9p0goOwj<Cw`P05A7vnh081wqU05DFwAKw<0?va at 1>",
>> >>> >> > "1gu00CLLwfh2 at Asw9@1<", "B;s at N9h00>TtPFQAsm003wRUwP06",
>> >>> >> > "7933.8835099999997",
>> >>> >> > "18K1kH000FrCSMt5:@;m>l8>0<4J", "19NSFKh000JCTeH5:7g1LT8:0`3g",
>> >>> >> > "15E=m60000rC`W459k28Wnd:083h", "1:u0KOh001rCq5P529qqubqh2 at 3n",
>> >>> >> > "13P>4mhw1CrCi5H57aK5WlN>0<4F", NA,
>> >>> >> > "A03IupkAC4:dH0N90D=p0goP02<Cw``05A7vnwt81wqVwUDFwAOt<0?vah1>",
>> >>> >> > "1gu103LLwfl1 at Asw9P1<", "14S8 at n001LrD?bH53iGe1rN>0 at 49",
>> >>> >> > "B;s at N9h00>TtPG1Asm403wSUwP06",
>> >>> >> >
>> >>> >> > "15E:N at 0000rCgOd57p45bW><0<2H", "15 at EA<0P01JCo8l53=BFgwv at 0D47",
>> >>> >> > "10007NgP00rCQGV5:Pa=?gv>2<1H", "15TILd?P00JCm4l53`D>4?v>0L1m",
>> >>> >> > "19NSG<h003rCi@:57pmUkAB<0<1v", "B;s at N9h00>TtPG1Asm403wT5wP06",
>> >>> >> > "15Q69 at 8000rCiDr57n`bp at tB2<4R", "15QtF00000rCafD59P?VJ9p<0H52",
>> >>> >> > "15QCl@?P?w<tSF0l4Q@>4?wp0 at 5:", "15QDCP0P?w<tSF0l4Q@>4?wp0D1G",
>> >>> >> > "803Iu6PF15REPH3 at Dh000000000002c88I2P0002IrbQ0@40TW`800000000",
>> >>> >> > "HGp0772K07N4d1;0Pf71r0aj19RVmR19RVuR19RW5R19RW;t91Cjp31000C4",
>> >>> >> > "15D8Gj0P00rCThP5:6T=2Ov>0 at 5H", "B;s at N9h00>TtPG1Asm803wTUwP06",
>> >>> >> > "15ATk20000rCnrv53N6;gPr>085R",
>> >>> >> > "55AP::02 at VAlQ3G;7:1<lUB0MD4 at DhuE0F22220l0`G465k90<PlRDm3hPC8",
>> >>> >> >
>> >>> >> > "88888888880", "15?lSL?P00JCQWD5:OpP0?vB24`0",
>> >>> >> > "15BW=20P00JCrvH54t=an?vB00Sg",
>> >>> >> > "13P;K8 at 001rCfgr58=f;QbFD2D4G", "A03IupkAC4:dH0v90FtP1cF6nud at NrP5wH5T",
>> >>> >> > "85E:BR0F0P0000000000032jS2P000000DE7P3A00h0", "1349B:3000rCtrn553aR at JHD2d4O",
>> >>> >> >
>> >>> >> > "7933.8835099999997", "B;s at N9h00>TtPFQAsm803wU5wP06",
>> >>> >> > "15B3Sj0000rC9RD5=mOh40jB20SU",
>> >>> >> > "15TgVb0000rCgVb57oFc;ARF2 at 67"), ...7 = c("0*54", "0*39", "2*0D",
>> >>> >> > "2*43", "0*29", "0*2D", "0*27", "0*1D", "0*26", "0*48", "0*4B",
>> >>> >> > "0*3A", "0*34", "0*3A", "0*76", "0*0B", "0*4A", "0*72", "0*6B",
>> >>> >> > "0*4E", "0*38", "0*04", "0*11", "0*17", "0*18", "0*6B", "0*64",
>> >>> >> > "W", "0*53", "0*32", "2*20", NA, "0*61", "0*1C", "0*79", "0*16",
>> >>> >> > "0*44", "0*53", "0*04", "0*2D", "0*1C", "0*07", "2*37", "0*12",
>> >>> >> > "0*2D", "0*30", "0*6D", "0*25", "0*26", "0*75", "2*2D", "0*71",
>> >>> >> > "0*38", "0*6D", "0*0F", "0*34", "0*1D", "0*70", "0*47", "0*70",
>> >>> >> > "0*4C", "0*54", "W", "0*64", "0*66", "0*69", "0*0C", "0*70",
>> >>> >> > NA, "0*11", "0*28", "0*38", "0*30", "0*1F", "0*64", "0*7C", "0*38",
>> >>> >> > "0*67", "0*57", "0*59", "0*75", "0*52", "0*18", "0*08", "0*5F",
>> >>> >> > "0*26", "0*3B", "0*67", "0*6A", "2*24", "0*47", "0*65", "0*56",
>> >>> >> > "0*54", "2*76", "0*23", "W", "0*3B", "0*1D", "0*11"), ...8 = c(1485907200,
>> >>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>> >>> >> > 1485907200, 1485907200, 1485907200, 1485907200, 1485907200, 1485907200,
>> >>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>> >>> >> > 1485907201, 1485907201, 1485907201, 1485907201, 1485907201, 1485907201,
>> >>> >> > 1485907201, 1485907201, 0.008, 1485907201, 1485907201, 1485907201,
>> >>> >> > NA, 1485907203, 1485907203, 1485907203, 1485907203, 1485907203,
>> >>> >> > 1485907203, 1485907203, 1485907204, 1485907204, 1485907204, 1485907204,
>> >>> >> > 1485907204, 1485907204, 1485907204, 1485907204, 1485907204, 1485907204,
>> >>> >> > 1485907204, 1485907205, 1485907205, 1485907205, 1485907205, 1485907205,
>> >>> >> > 1485907205, 1485907205, 1485907206, 1485907206, 1485907206, 1485907206,
>> >>> >> > 1485907206, 0.01, 1485907206, 1485907206, 1485907206, 1485907206,
>> >>> >> > 1485907206, NA, 1485907206, 1485907206, 1485907206, 1485907206,
>> >>> >> > 1485907206, 1485907206, 1485907206, 1485907208, 1485907208, 1485907208,
>> >>> >> > 1485907208, 1485907208, 1485907209, 1485907209, 1485907209, 1485907209,
>> >>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 1485907209,
>> >>> >> > 1485907209, 1485907209, 1485907209, 1485907209, 1485907209, 0.005,
>> >>> >> > 1485907209, 1485907209, 1485907209), ...9 = c(NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "*41", NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, "*43", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA), ...10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > 10217, NA, NA, NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA, NA, NA, 1485907206,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10217, NA, NA, NA
>> >>> >> > ), ...11 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA), ...12 = c(NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
>> >>> >> >     ...13 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     "D*6F", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, "D*60", NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "D*63", NA, NA,
>> >>> >> >     NA), ...14 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, 1485907201, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, 1485907206, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >>> >> >     NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1485907209,
>> >>> >> >     NA, NA, NA)), row.names = c(NA, -100L), class = "data.frame")
>> >>> >> >
>> >>> >> > To tested your function I took the first message, which is located in the
>> >>> >> > 6th column and the 1st row, and did the following:
>> >>> >> >
>> >>> >> > library(stringi)
>> >>> >> > library(dplyr)
>> >>> >> > library(R.utils)
>> >>> >> > library(RANN)
>> >>> >> > library(NISTunits)
>> >>> >> > library(pracma)
>> >>> >> > library(celestial)
>> >>> >> > library(stringr)
>> >>> >> >
>> >>> >> > dat <- readXL("U:/RawSampleData.xls", rownames=FALSE, header=FALSE, na="",
>> >>> >> > +   sheet="RawSampleData", stringsAsFactors=FALSE)
>> >>> >> >
>> >>> >> > testmessage1 <- dat[1,6]
>> >>> >> >
>> >>> >> > ascii_datformat <- utf8ToInt(testmessage1)
>> >>> >> >
>> >>> >> > Base <- ascii_datformat - 48
>> >>> >> >
>> >>> >> > decy <- ifelse(Base > 40, Base - 8, Base)
>> >>> >> >
>> >>> >> > biny <- intToBin(decy)
>> >>> >> >
>> >>> >> > binyframe <- data.frame(biny)
>> >>> >> >
>> >>> >> > tbinyframe <- paste(t(binyframe[,1]), collapse="")  #at this point, I have
>> >>> >> > the complete first message, all in binary format
>> >>> >> >
>> >>> >> > #according to the literature of AIS message decoding, longitude goes from
>> >>> >> > position 62 to position 89
>> >>> >> > #and latitude goes from position 90 to position 116
>> >>> >> >
>> >>> >> > longitude <- substr(tbinyframe, 62, 89)
>> >>> >> > latitude    <- substr(tbinyframe, 90, 116)
>> >>> >> >
>> >>> >> > #now I apply the function you provided me with:
>> >>> >> >
>> >>> >> >  fun <- function(x){
>> >>> >> >          res <- sapply(x, function(y){
>> >>> >> >             if(nchar(y) %% 8 != 0 || substr(y, 1, 1) == "0"){
>> >>> >> >              strtoi(y, base = 2)
>> >>> >> >             }else{
>> >>> >> >               y <- unlist(strsplit(y, ""))
>> >>> >> >               -sum((y != "1")*2^((length(y) - 1):0)) - 1
>> >>> >> >             }
>> >>> >> >           })
>> >>> >> >           unname(res)
>> >>> >> >       }
>> >>> >> >
>> >>> >> > > fun(longitude)
>> >>> >> > [1] 220663102
>> >>> >> > >
>> >>> >> > > fun(latitude)
>> >>> >> > [1] 5414823
>> >>> >> > >
>> >>> >> > > fun("1101001001110000110100111110")
>> >>> >> > [1] 220663102
>> >>> >> > >
>> >>> >> > > fun("000010100101001111110100111")
>> >>> >> > [1] 5414823
>> >>> >> > >
>> >>> >> > > fun("10110010")
>> >>> >> > [1] -78
>> >>> >> >
>> >>> >> > as you can see, the function only worked or showed expected result on the
>> >>> >> > last case with a -78, but in the other cases, it the results were not as
>> >>> >> > expected, maybe I am missing something here?
>> >>> >> >
>> >>> >> > Any help and/or guidance will be greatly appreciated,
>> >>> >> >
>> >>> >> > Best regards,
>> >>> >> >
>> >>> >> > Paul
>> >>> >> >
>> >>> >> > El lun., 20 ene. 2020 a las 10:28, Rui Barradas (<ruipbarradas at sapo.pt>)
>> >>> >> > escribi?:
>> >>> >> >
>> >>> >> > > Hello,
>> >>> >> > >
>> >>> >> > > The function I included converts signed binary numbers into their
>> >>> >> > > decimal representation. They are negative if a) they are multiples of 8
>> >>> >> > > bits and b) the most significant bit is a "1". If not just convert to
>> >>> >> > > integer.
>> >>> >> > >
>> >>> >> > > As for a) above, I assume that you will have 8 bit numbers. And the
>> >>> >> > > conversion is done as follows:
>> >>> >> > >
>> >>> >> > > input: 10110010
>> >>> >


From @ew@@hm @end|ng |rom gm@||@com  Sun Jan 26 00:22:06 2020
From: @ew@@hm @end|ng |rom gm@||@com (Ashta)
Date: Sat, 25 Jan 2020 17:22:06 -0600
Subject: [R] Text search
Message-ID: <CADDFq301awsKpnoE5GKb+vqnCv75hx6kFnFjsMU71OYvO_uS=w@mail.gmail.com>

Hi all,
>From  one of the columns of the data frame I want to search and
extract  a text that contains Tall or   Short  and create new column
that should contain these texts in a corresponding row.
My example data and the desired output are shown below

dat<-read.table(text="obs Year char
1  2001 Tall156
2  2002 12565Tall
3  2003 all54
4  2004 Short
5  2005 54all
6  2006 7Short12 ",header=TRUE,stringsAsFactors=F)
dat$new <- "      "

Desired out put
obs Year     char        new
   1 2001   Tall156      Tall
   2 2002 12565Tall    Tall
   3 2003     all54
   5 2004     Short      Short
   6 2005     Shall54
   7 2006  7Short12   Short

How do I get my desired output?
Thank you.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sun Jan 26 00:37:48 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sat, 25 Jan 2020 18:37:48 -0500
Subject: [R] Text search
In-Reply-To: <CADDFq301awsKpnoE5GKb+vqnCv75hx6kFnFjsMU71OYvO_uS=w@mail.gmail.com>
References: <CADDFq301awsKpnoE5GKb+vqnCv75hx6kFnFjsMU71OYvO_uS=w@mail.gmail.com>
Message-ID: <CAM_vju=kOLZPWvi99Hb+CC+9iUV1sXd6o42CJT3U-cHo3eY+7g@mail.gmail.com>

Hi,

> dat$new[grep("Tall", dat$char)] <- "Tall"
> dat$new[grep("Short", dat$char)] <- "Short"
> dat
  obs Year      char    new
1   1 2001   Tall156   Tall
2   2 2002 12565Tall   Tall
3   3 2003     all54
4   4 2004     Short  Short
5   5 2005     54all
6   6 2006  7Short12  Short

Assuming that no entries contain both Tall and Short.

Sarah

On Sat, Jan 25, 2020 at 6:23 PM Ashta <sewashm at gmail.com> wrote:
>
> Hi all,
> From  one of the columns of the data frame I want to search and
> extract  a text that contains Tall or   Short  and create new column
> that should contain these texts in a corresponding row.
> My example data and the desired output are shown below
>
> dat<-read.table(text="obs Year char
> 1  2001 Tall156
> 2  2002 12565Tall
> 3  2003 all54
> 4  2004 Short
> 5  2005 54all
> 6  2006 7Short12 ",header=TRUE,stringsAsFactors=F)
> dat$new <- "      "
>
> Desired out put
> obs Year     char        new
>    1 2001   Tall156      Tall
>    2 2002 12565Tall    Tall
>    3 2003     all54
>    5 2004     Short      Short
>    6 2005     Shall54
>    7 2006  7Short12   Short
>
> How do I get my desired output?
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From jwd @end|ng |rom @urewe@t@net  Sun Jan 26 02:55:13 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Sat, 25 Jan 2020 17:55:13 -0800
Subject: [R] CRAN UC Berkeley link
Message-ID: <20200125175513.24a254e4@Draco.localdomain>

This link

https://cran.cnr.berkeley.edu/

 on the "mirrors" page no longer points to a CRAN mirror.  It seems to
 be generic to UCB.

JWDougherty


From @w|mp@ck@ge @end|ng |rom gm@||@com  Thu Jan 23 14:27:29 2020
From: @w|mp@ck@ge @end|ng |rom gm@||@com (Silvana Pesenti)
Date: Thu, 23 Jan 2020 08:27:29 -0500
Subject: [R] [R-pkgs] SWIM: vignette and new version on CRAN
Message-ID: <CAAGSCf3tD+wSVJC59z=Uj-Yz6k1K45AE3UTzsOMyorNF3Ytw1w@mail.gmail.com>

Hi all,


We?re happy to announce that the new version of *SWIM* is available on
CRAN. *SWIM* is an efficient sensitivity analysis tool for stochastic
models based on Monte Carlo samples. It provides weights on simulated
scenarios from a stochastic model, such that stressed random variables
fulfil given probabilistic constraints (e.g. specified values for risk
measures), under the new scenario weights. Scenario weights are selected by
constrained minimisation of the relative entropy to the baseline model.

 The new version includes additional functionalities which are illustrated
in the Vignette on a credit risk model:
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3515274.
<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3515274>


CRAN: https://CRAN.R-project.org/package=SWIM

GitHuB: https://github.com/spesenti/SWIM

Vignette: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3515274




Best regards,

Silvana Pesenti

Maintainer and co-author.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From proccontent@ @end|ng |rom gm@||@com  Fri Jan 24 16:25:08 2020
From: proccontent@ @end|ng |rom gm@||@com (SAS_learner)
Date: Fri, 24 Jan 2020 09:25:08 -0600
Subject: [R] R Dplyr hands on project
Message-ID: <CAPo+ggt2Oe5r-x_V_AvieQP7MVkQtzfqKVnV-6ZZGnXZHJ4Srw@mail.gmail.com>

Hello All ,

I am trying to learn R and started with R Dplyr for data management
.Can anyone point out  to a  book or place or GitHub location which
has a project that I can use to replicate , to improve my skills would
be of great help.

thanks
Kumar


From pj@|nh@07 @end|ng |rom gm@||@com  Fri Jan 24 21:06:15 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 24 Jan 2020 15:06:15 -0500
Subject: [R] Problem in plotting Circos plot with the attached dataset
Message-ID: <CAGjf1cMY+1nBht=jXUM=fu6SqoJ1TPLFQBMgP20=Oe9UnxwAJA@mail.gmail.com>

 YOUNGCONTROL.csv
<https://drive.google.com/file/d/1arQqlzkRJybclikAByB9w9TCnvmD_Y46/view?usp=drive_web>
 YOUNGTREATED.csv
<https://drive.google.com/file/d/1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO/view?usp=drive_web>
Hi I have attached the three different datasets for Rn6 genome and I needed
to use circos plot by circlize package in R. Please help me in writing the
code and making plot. Any help will be highly appreciated.

The outermost ring contain Rn6 ideogram followed by YOUNGCONTROL,
YOUNGTREATED & last circle will be of
YOUNGTREATED.vs.YOUNGCONTROL.sig

Thanks,
Puja

From huynguyen96@dnu @end|ng |rom gm@||@com  Sat Jan 25 14:58:04 2020
From: huynguyen96@dnu @end|ng |rom gm@||@com (Huy Nguyen)
Date: Sat, 25 Jan 2020 20:58:04 +0700
Subject: [R] [cph] Error in [.default (y, , 3) : subscript out of bounds
Message-ID: <CAPPT=HkDDiBbRgUNObqq8+NEQyWEmN-GiHLyY_ngAjKGwwg2Ag@mail.gmail.com>

Dear CRAN support team,

I have been facing with an error when using the package *cph* to construct
nomogram! Let me clarify what exactly I have been encountered.

Firstly, this is a summary of my data:

 > str(train)

 'data.frame': 1323 obs. of  25 variables:

  $ LYMPH_NODES_EXAMINED_POSITIVE: Factor w/ 3 levels "<=3","<=9",">10": 3
NA 1 2 NA 1 NA 1 3 1 ...

  $ CELLULARITY                  : Factor w/ 3 levels
"High","Low","Moderate": NA 1 3 1 3 3 1 3 NA 1 ...

 $ MENOPAUSAL_STATE             : Factor w/ 2 levels "Post","Pre": 1 2 2 1
1 1 1 1 NA 2 ...

  $ ER_STATUS                    : Factor w/ 2 levels
 "Negative","Positive": 2 2 2 2 2 2 1 2 2 1 ...

 $ OS_MONTHS                    : num  718 425 822 186 16 816 77 514 NA
 821 ...

 $ OS_STATUS                    : Factor w/ 2 levels "DECEASED","LIVING": 2
2 2 1 1 2 1 1 NA 2 ...

 $ LATERALITY                   : Factor w/ 2 levels "Left","Right": 2 2 2
2 1 2 1 1 NA 2 ...


and this is my code:


> attach(train);d <- datadist(CELLULARITY, MENOPAUSAL_STATE, ER_STATUS,

     LATERALITY, LYMPH_NODES_EXAMINED_POSITIVE)

>  options(datadist = 'd')

>      mod.cox <- cph(formula(Surv(OS_MONTHS, OS_STATUS) ~ CELLULARITY +
MENOPAUSAL_STATE + ER_STATUS + LATERALITY +LYMPH_NODES_EXAMINED_POSITIVE),
data=train, x= TRUE, y= TRUE, surv = TRUE)


Right there, I got the error when running mod.cox:

*Error in  [.default (y, , 3) : subscript out of bounds*


I did some researches and found this previous issue
<https://github.com/harrelfe/rms/issues/31> and this
<https://github.com/harrelfe/rms/issues/25> related, which solved by
Prof.Harrelfe. But, It seems not working to me.

Any helps would be appreciated.

The example data that produces the same error:
https://drive.google.com/open?id=1Bi9nfg34eByc5H1Bmmq43dz6O8lEaj5O


Best regards,

Huy Nguyen

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Sun Jan 26 07:02:18 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sat, 25 Jan 2020 23:02:18 -0700
Subject: [R] R Dplyr hands on project
In-Reply-To: <CAPo+ggt2Oe5r-x_V_AvieQP7MVkQtzfqKVnV-6ZZGnXZHJ4Srw@mail.gmail.com>
References: <CAPo+ggt2Oe5r-x_V_AvieQP7MVkQtzfqKVnV-6ZZGnXZHJ4Srw@mail.gmail.com>
Message-ID: <CACxE24m31KF8yGAwrjOxcE8-aFr6zAXgYmXu0uauFLuo9f=Dyw@mail.gmail.com>

Hello!

?R for Data Science? is an excellent reference.

Thanks,
Erin


On Sat, Jan 25, 2020 at 11:00 PM SAS_learner <proccontents at gmail.com> wrote:

> Hello All ,
>
> I am trying to learn R and started with R Dplyr for data management
> .Can anyone point out  to a  book or place or GitHub location which
> has a project that I can use to replicate , to improve my skills would
> be of great help.
>
> thanks
> Kumar
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From |e||xb||nd @end|ng |rom gm@||@com  Fri Jan 24 17:32:44 2020
From: |e||xb||nd @end|ng |rom gm@||@com (Felix Blind)
Date: Fri, 24 Jan 2020 17:32:44 +0100
Subject: [R] Executing an R script and show the plots.
Message-ID: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>

Dear R users,

i am a python user trying to get my statistical knowledge up to speed
and R is the language for that.
I would like to run R scripts like that: R -f script.r and still get the
plots that pop up.

When I type the following code in the R REPL I get a nice plot:

library(ggplot2)??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

data("midwest",
package="ggplot2")????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()

But when I put the same code in a file script.r and run it with R -f
script.r or if I source it in the REPL with source("script.r") I do not
get any plots shown.

Can you guys tell me what I do wrong. (Apart from either using RStudio
or the REPL exclusively)

Kind regards,
Felix


From pj@|nh@07 @end|ng |rom gm@||@com  Sun Jan 26 14:45:34 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Sun, 26 Jan 2020 08:45:34 -0500
Subject: [R] Fwd: Problem in plotting Circos plot with the attached dataset
In-Reply-To: <CAGjf1cMY+1nBht=jXUM=fu6SqoJ1TPLFQBMgP20=Oe9UnxwAJA@mail.gmail.com>
References: <CAGjf1cMY+1nBht=jXUM=fu6SqoJ1TPLFQBMgP20=Oe9UnxwAJA@mail.gmail.com>
Message-ID: <CAGjf1cM+WJesRuFfNRwPfj0J_D3nXJ-33V66b-Sh8QQCxsv=_g@mail.gmail.com>

---------- Forwarded message ---------
From: pooja sinha <pjsinha07 at gmail.com>
Date: Fri 24 Jan, 2020, 15:06
Subject: Problem in plotting Circos plot with the attached dataset
To: <r-help at r-project.org>


 YOUNGCONTROL.csv
<https://drive.google.com/file/d/1arQqlzkRJybclikAByB9w9TCnvmD_Y46/view?usp=drive_web>
 YOUNGTREATED.csv
<https://drive.google.com/file/d/1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO/view?usp=drive_web>
Hi I have attached the three different datasets for Rn6 genome and I needed
to use circos plot by circlize package in R. Please help me in writing the
code and making plot. Any help will be highly appreciated.

The outermost ring contain Rn6 ideogram followed by YOUNGCONTROL,
YOUNGTREATED & last circle will be of
YOUNGTREATED.vs.YOUNGCONTROL.sig

Thanks,
Puja

From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 26 17:06:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 26 Jan 2020 08:06:24 -0800
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
Message-ID: <CAGxFJbT1n8_jmSQF9e38EO1sRaM=poVTmv9CD28fhfS-3Uhpsw@mail.gmail.com>

Google is your friend!

https://stackoverflow.com/questions/26643852/ggplot-plots-in-scripts-do-not-display-in-rstudio

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 26, 2020 at 7:30 AM Felix Blind <felixblind at gmail.com> wrote:

> Dear R users,
>
> i am a python user trying to get my statistical knowledge up to speed
> and R is the language for that.
> I would like to run R scripts like that: R -f script.r and still get the
> plots that pop up.
>
> When I type the following code in the R REPL I get a nice plot:
>
>
> library(ggplot2)
>
> data("midwest",
>
> package="ggplot2")
>
> ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()
>
> But when I put the same code in a file script.r and run it with R -f
> script.r or if I source it in the REPL with source("script.r") I do not
> get any plots shown.
>
> Can you guys tell me what I do wrong. (Apart from either using RStudio
> or the REPL exclusively)
>
> Kind regards,
> Felix
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 26 17:15:13 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 26 Jan 2020 08:15:13 -0800
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <CAGxFJbT1n8_jmSQF9e38EO1sRaM=poVTmv9CD28fhfS-3Uhpsw@mail.gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <CAGxFJbT1n8_jmSQF9e38EO1sRaM=poVTmv9CD28fhfS-3Uhpsw@mail.gmail.com>
Message-ID: <6954AD21-6838-49A9-AC6C-92AF6F6DCC7D@dcn.davis.ca.us>

OP does not want to depend on RStudio. Bert.

Need to open a graphics device. Which one you use is highly dependent on your needs and OS configuration. https://stat.ethz.ch/R-manual/R-devel/library/grDevices/html/Devices.html

On January 26, 2020 8:06:24 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Google is your friend!
>
>https://stackoverflow.com/questions/26643852/ggplot-plots-in-scripts-do-not-display-in-rstudio
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Jan 26, 2020 at 7:30 AM Felix Blind <felixblind at gmail.com>
>wrote:
>
>> Dear R users,
>>
>> i am a python user trying to get my statistical knowledge up to speed
>> and R is the language for that.
>> I would like to run R scripts like that: R -f script.r and still get
>the
>> plots that pop up.
>>
>> When I type the following code in the R REPL I get a nice plot:
>>
>>
>> library(ggplot2)
>>
>> data("midwest",
>>
>> package="ggplot2")
>>
>> ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()
>>
>> But when I put the same code in a file script.r and run it with R -f
>> script.r or if I source it in the REPL with source("script.r") I do
>not
>> get any plots shown.
>>
>> Can you guys tell me what I do wrong. (Apart from either using
>RStudio
>> or the REPL exclusively)
>>
>> Kind regards,
>> Felix
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jan 26 17:18:15 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 26 Jan 2020 08:18:15 -0800
Subject: [R] Problem in plotting Circos plot with the attached dataset
In-Reply-To: <CAGjf1cMY+1nBht=jXUM=fu6SqoJ1TPLFQBMgP20=Oe9UnxwAJA@mail.gmail.com>
References: <CAGjf1cMY+1nBht=jXUM=fu6SqoJ1TPLFQBMgP20=Oe9UnxwAJA@mail.gmail.com>
Message-ID: <39EDCA29-A317-4428-98AA-FDFC25E0905F@dcn.davis.ca.us>

a) your request is inappropriate for this forum. Read the Posting Guide.

b) Your attachments did not come through. Read the Posting Guide.

On January 24, 2020 12:06:15 PM PST, pooja sinha <pjsinha07 at gmail.com> wrote:
> YOUNGCONTROL.csv
><https://drive.google.com/file/d/1arQqlzkRJybclikAByB9w9TCnvmD_Y46/view?usp=drive_web>
> YOUNGTREATED.csv
><https://drive.google.com/file/d/1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO/view?usp=drive_web>
>Hi I have attached the three different datasets for Rn6 genome and I
>needed
>to use circos plot by circlize package in R. Please help me in writing
>the
>code and making plot. Any help will be highly appreciated.
>
>The outermost ring contain Rn6 ideogram followed by YOUNGCONTROL,
>YOUNGTREATED & last circle will be of
>YOUNGTREATED.vs.YOUNGCONTROL.sig
>
>Thanks,
>Puja
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jan 26 17:27:07 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 26 Jan 2020 16:27:07 +0000
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
Message-ID: <cd7fca1d-44bd-f994-c992-41806fca2131@sapo.pt>

Hello,

Have you tried

source("script.r", print.eval = TRUE)

?

Also, you should print() the graph explicitly:


library(ggplot2)
data(midwest, package = "ggplot2")

g <- ggplot(midwest, aes(area, poptotal)) + geom_point()
print(g)


Hope this helps,

Rui Barradas

?s 16:32 de 24/01/20, Felix Blind escreveu:
> Dear R users,
> 
> i am a python user trying to get my statistical knowledge up to speed
> and R is the language for that.
> I would like to run R scripts like that: R -f script.r and still get the
> plots that pop up.
> 
> When I type the following code in the R REPL I get a nice plot:
> 
> library(ggplot2)
> 
> data("midwest",
> package="ggplot2")
> 
> ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()
> 
> But when I put the same code in a file script.r and run it with R -f
> script.r or if I source it in the REPL with source("script.r") I do not
> get any plots shown.
> 
> Can you guys tell me what I do wrong. (Apart from either using RStudio
> or the REPL exclusively)
> 
> Kind regards,
> Felix
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@dmuzom @end|ng |rom out|ook@com  Sun Jan 26 17:30:41 2020
From: r@dmuzom @end|ng |rom out|ook@com (Anindya Mozumdar)
Date: Sun, 26 Jan 2020 16:30:41 +0000
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
Message-ID: <MAXPR01MB40934D59279E20B4EB4564A7CB080@MAXPR01MB4093.INDPRD01.PROD.OUTLOOK.COM>

Dear Felix,

> I would like to run R scripts like that: R -f script.r and still get the
> plots that pop up.

Since you are using ggplot2, you can use the ggsave function from the package to save the plot to a location of your choice. I tested the following script from the command line and it worked.

library(ggplot2)                                                                                                                                                                          
data("midwest",
     package="ggplot2")                                                                                                                                                        
ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()
ggsave(paste0(getwd(), "/midwest.png"), device = "png")

Regards,
Anindya



From r@dmuzom @end|ng |rom out|ook@com  Sun Jan 26 17:38:23 2020
From: r@dmuzom @end|ng |rom out|ook@com (Anindya Mozumdar)
Date: Sun, 26 Jan 2020 16:38:23 +0000
Subject: [R] CRAN UC Berkeley link
In-Reply-To: <20200125175513.24a254e4@Draco.localdomain>
References: <20200125175513.24a254e4@Draco.localdomain>
Message-ID: <MAXPR01MB4093E3863A4E33F65B515EC6CB080@MAXPR01MB4093.INDPRD01.PROD.OUTLOOK.COM>

Hi John,

> This link
> https://cran.cnr.berkeley.edu/
>?on the "mirrors" page no longer points to a CRAN mirror.? It seems to
> be generic to UCB.

I suggest you email cran at r-project.org reporting them of the broken mirror.

Regards,
Anindya

From pj@|nh@07 @end|ng |rom gm@||@com  Sun Jan 26 17:53:27 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Sun, 26 Jan 2020 11:53:27 -0500
Subject: [R] Problems in writing code for circos plot
Message-ID: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>

Hi All,

I have attached the three different datasets for Rn6 genome (rat) and I
needed to use circos plot by *circlize package in R*. Please anyone help me
in writing the code and making the plot. Any help will be highly
appreciated.
The three file links are below:

File 1: YOUNGCONTROL.csv (
https://drive.google.com/open?id=1arQqlzkRJybclikAByB9w9TCnvmD_Y46 )
File 2:  YOUNGTREATED.csv (
https://drive.google.com/open?id=1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO )
File 3:  YOUNGTREATED.vs.YOUNGCONTROL.sig.csv (
https://drive.google.com/open?id=0B33BGsdd5x_dOGF0X3BuaWRoMmdSYklOZnJoX09uaWdnNEdN
 )

The circos plot having the outermost ring contain Rn6 ideogram followed by
YOUNGCONTROL, YOUNGTREATED & last innermost circle will be of
YOUNGTREATED.vs.YOUNGCONTROL.sig

Thanks,
Puja

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jan 26 21:20:03 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 26 Jan 2020 12:20:03 -0800
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
Message-ID: <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>

You need to understand that the R interpreter does not have an 
interactive plot device when run as a script from an OS command line. 
You need to open an output device, `print` the output of the ggplot 
call, and then? _after_ closing the device appropriately, open the 
output in an appropriate viewer supplied by your unstated OS.


?Devices # brings up a list of possible devices and has a "See Also" 
section that says:

===========================

The individual help files for further information on any of the devices 
listed here;

on Windows:
windows.options,

on a Unix-alike:
X11.options, quartz.options,

ps.options and pdf.options for how to customize devices.

dev.interactive, dev.cur, dev.print, graphics.off, image, dev2bitmap.

On Unix-alikes only:
capabilities to see if X11, jpeg, png, tiff, quartz and the cairo-based 
devices are available.
==============================


So do some further reading to educate yourself.


-- 

David.

On 1/24/20 8:32 AM, Felix Blind wrote:
> Dear R users,
>
> i am a python user trying to get my statistical knowledge up to speed
> and R is the language for that.
> I would like to run R scripts like that: R -f script.r and still get the
> plots that pop up.
>
> When I type the following code in the R REPL I get a nice plot:
>
> library(ggplot2)
>
> data("midwest",
> package="ggplot2")
>
> ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()
>
> But when I put the same code in a file script.r and run it with R -f
> script.r or if I source it in the REPL with source("script.r") I do not
> get any plots shown.
>
> Can you guys tell me what I do wrong. (Apart from either using RStudio
> or the REPL exclusively)
>
> Kind regards,
> Felix
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sun Jan 26 21:47:58 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sun, 26 Jan 2020 20:47:58 +0000
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>,
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
Message-ID: <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>

Felix,
I suggest you consider using an IDE such as RStudio as you develop and run R code. An integrated development environment will allow you to concentrate on learning R
rather on the mechanics of running R in a
non-standard environment.
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street<x-apple-data-detectors://12>
GRECC<x-apple-data-detectors://12> (BT/18/GR)
Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
(Phone) 410-605-711<tel:410-605-7119>9
(Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above prior to faxing)

On Jan 26, 2020, at 3:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:

?You need to understand that the R interpreter does not have an interactive plot device when run as a script from an OS command line. You need to open an output device, `print` the output of the ggplot call, and then  _after_ closing the device appropriately, open the output in an appropriate viewer supplied by your unstated OS.


?Devices # brings up a list of possible devices and has a "See Also" section that says:

===========================

The individual help files for further information on any of the devices listed here;

on Windows:
windows.options,

on a Unix-alike:
X11.options, quartz.options,

ps.options and pdf.options for how to customize devices.

dev.interactive, dev.cur, dev.print, graphics.off, image, dev2bitmap.

On Unix-alikes only:
capabilities to see if X11, jpeg, png, tiff, quartz and the cairo-based devices are available.
==============================


So do some further reading to educate yourself.


--

David.

On 1/24/20 8:32 AM, Felix Blind wrote:
Dear R users,

i am a python user trying to get my statistical knowledge up to speed
and R is the language for that.
I would like to run R scripts like that: R -f script.r and still get the
plots that pop up.

When I type the following code in the R REPL I get a nice plot:

library(ggplot2)

data("midwest",
package="ggplot2")

ggplot(midwest, aes(x=area, y=poptotal)) + geom_point()

But when I put the same code in a file script.r and run it with R -f
script.r or if I source it in the REPL with source("script.r") I do not
get any plots shown.

Can you guys tell me what I do wrong. (Apart from either using RStudio
or the REPL exclusively)

Kind regards,
Felix

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7CJSorkin%40som.umaryland.edu%7Cff399da2c92c46d8dbef08d7a29d28e1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637156668200832250&amp;sdata=%2F4npPPdmZiflpvoByexxwJKfkSQmGASQimaxnnDyOj0%3D&amp;reserved=0
PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=02%7C01%7CJSorkin%40som.umaryland.edu%7Cff399da2c92c46d8dbef08d7a29d28e1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637156668200832250&amp;sdata=Z%2FbUl0zEHpfVuQsvFysOAFps0VjeAtA7NdcL3VYJcus%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7CJSorkin%40som.umaryland.edu%7Cff399da2c92c46d8dbef08d7a29d28e1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637156668200842231&amp;sdata=VMdvcvmZ6Cn8kZ%2Buta44UT08Q5T%2FEf3X8ufWmYz9avE%3D&amp;reserved=0
PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=02%7C01%7CJSorkin%40som.umaryland.edu%7Cff399da2c92c46d8dbef08d7a29d28e1%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637156668200842231&amp;sdata=0%2BBjKhdtQ7cMP6wuDm36%2BJmLLWAMLHCDHtJ8ugl2oag%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Jan 26 22:22:27 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 27 Jan 2020 10:22:27 +1300
Subject: [R] [FORGED] Re:  Executing an R script and show the plots.
In-Reply-To: <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
Message-ID: <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>


On 27/01/20 9:47 am, Sorkin, John wrote:

> Felix, I suggest you consider using an IDE such as RStudio as you
> develop and run R code. An integrated development environment will
> allow you to concentrate on learning R rather on the mechanics of
> running R in a non-standard environment.

I disagree.  Or rather, I would say that this is a matter of personal 
taste.  And personally I find that RStudio and its like just present 
another "learning curve" to climb.  I would much rather just write R 
code and get on with it.

I have never liked GUIs:

> GUIs normally make it simple to accomplish simple actions and
> impossible to accomplish complex actions.
> 
>         --- Doug Gwyn
>             (22/Jun/91 in `comp.unix.wizards')

But as I say it's a matter of taste and inclination.  It is likely that 
Felix is among the overwhelming majority of users who prefer GUIs.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drj|m|emon @end|ng |rom gm@||@com  Sun Jan 26 23:06:48 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 27 Jan 2020 09:06:48 +1100
Subject: [R] Problems in writing code for circos plot
In-Reply-To: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>
References: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>
Message-ID: <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>

Hi Puja,
Three things:
1) Your data files are very large. If you do manage to get circular
plots out of them with the circlize library they will probably be very
dense.
2) The structure of your data includes too many levels in "Chrom" to
get the circlize functions to work. I had to pare them back to the
non-random levels.
3) You should probably change the subject line of your message to
"Would anyone care to do my work for me?"

Jim

On Mon, Jan 27, 2020 at 6:47 AM pooja sinha <pjsinha07 at gmail.com> wrote:
>
> Hi All,
>
> I have attached the three different datasets for Rn6 genome (rat) and I
> needed to use circos plot by *circlize package in R*. Please anyone help me
> in writing the code and making the plot. Any help will be highly
> appreciated.
> The three file links are below:
>
> File 1: YOUNGCONTROL.csv (
> https://drive.google.com/open?id=1arQqlzkRJybclikAByB9w9TCnvmD_Y46 )
> File 2:  YOUNGTREATED.csv (
> https://drive.google.com/open?id=1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO )
> File 3:  YOUNGTREATED.vs.YOUNGCONTROL.sig.csv (
> https://drive.google.com/open?id=0B33BGsdd5x_dOGF0X3BuaWRoMmdSYklOZnJoX09uaWdnNEdN
>  )
>
> The circos plot having the outermost ring contain Rn6 ideogram followed by
> YOUNGCONTROL, YOUNGTREATED & last innermost circle will be of
> YOUNGTREATED.vs.YOUNGCONTROL.sig
>
> Thanks,
> Puja
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Jan 26 23:20:05 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 27 Jan 2020 11:20:05 +1300
Subject: [R] [FORGED] Re:  Problems in writing code for circos plot
In-Reply-To: <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>
References: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>
 <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>
Message-ID: <0cafbd27-f8e5-5b08-4a96-7a66e25f3a0b@auckland.ac.nz>


On 27/01/20 11:06 am, Jim Lemon wrote:

> Hi Puja,
> Three things:

<SNIP>

> 3) You should probably change the subject line of your message to
> "Would anyone care to do my work for me?"

Fortune nomination!!! :-)

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jan 26 23:53:56 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 26 Jan 2020 14:53:56 -0800
Subject: [R] [FORGED] Re: Problems in writing code for circos plot
In-Reply-To: <0cafbd27-f8e5-5b08-4a96-7a66e25f3a0b@auckland.ac.nz>
References: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>
 <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>
 <0cafbd27-f8e5-5b08-4a96-7a66e25f3a0b@auckland.ac.nz>
Message-ID: <CAGxFJbR-90c9NLpsetSNcsZFq2Ra6LZcbaYfRYzJL0g68_mkSw@mail.gmail.com>

Second.

Bert


On Sun, Jan 26, 2020 at 2:20 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On 27/01/20 11:06 am, Jim Lemon wrote:
>
> > Hi Puja,
> > Three things:
>
> <SNIP>
>
> > 3) You should probably change the subject line of your message to
> > "Would anyone care to do my work for me?"
>
> Fortune nomination!!! :-)
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Mon Jan 27 01:32:53 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 27 Jan 2020 01:32:53 +0100
Subject: [R] How to store something not simple in a vector?
Message-ID: <CAGAA5befGSA_LBTw_zUCauawg2+-AjNrB0iG8puhtqPoF=iEuQ@mail.gmail.com>

Hi,

  Sorry for the HTML version in the buttom of this email.
I don't think it is possible to post using gmail without a
html-version in the end.

Anyway to my problem:

I am trying to create a vector to store objects create with gmp::as.bigq().

My first attempt:
library(gmp)
V <- vector("bigq", 100)

My second attempt after understand that I probably need to
examine a bigq with typeof()

library(gmp)
V <- vector(typeof(as.bigq(1)), 100) # typeof(as.bigq(1)) is raw
V[[100]] <- as.bigq(1,2)

With the error message:
Error in V[[100]] <- as.bigq(1, 2) :
  more elements supplied than there are to replace

And now I understand that bigq is stored as raw-bytes and it
is has a length more than 1. Actually:
length(as.raw(as.bitq(1,2))
[1] 16

Please advise.
Thanks a lot.

/Martin M. S. Pedersen


From tr@xp|@yer @end|ng |rom gm@||@com  Mon Jan 27 02:25:15 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 27 Jan 2020 02:25:15 +0100
Subject: [R] How to store something not simple in a vector?
In-Reply-To: <CAGAA5befGSA_LBTw_zUCauawg2+-AjNrB0iG8puhtqPoF=iEuQ@mail.gmail.com>
References: <CAGAA5befGSA_LBTw_zUCauawg2+-AjNrB0iG8puhtqPoF=iEuQ@mail.gmail.com>
Message-ID: <CAGAA5bf4QLLfd70y1NeWe-SwEpbxSx1B3My0Xj_wD0QK0qrWxA@mail.gmail.com>

> I am trying to create a vector to store objects create with gmp::as.bigq().
[...]

> library(gmp)
> V <- vector(typeof(as.bigq(1)), 100) # typeof(as.bigq(1)) is raw
> V[[100]] <- as.bigq(1,2)

I got a solution now. If I use a list instead then everything works.

Regards
Martin M. S. Pedersen


From h@@@n@d|w@n @end|ng |rom gm@||@com  Mon Jan 27 07:45:38 2020
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Sun, 26 Jan 2020 22:45:38 -0800
Subject: [R] CRAN UC Berkeley link
In-Reply-To: <20200125175513.24a254e4@Draco.localdomain>
References: <20200125175513.24a254e4@Draco.localdomain>
Message-ID: <CAP+bYWCK81Dj6n=800o9EGeN7PWKZF3yEN_8TNwg8HMM6jSk1A@mail.gmail.com>

https://cran.r-project.org/mirmon_report.html
Let them know what's going on.

	[[alternative HTML version deleted]]


From |e||xb||nd @end|ng |rom gm@||@com  Mon Jan 27 10:16:53 2020
From: |e||xb||nd @end|ng |rom gm@||@com (Felix Blind)
Date: Mon, 27 Jan 2020 10:16:53 +0100
Subject: [R] [FORGED] Re:  Executing an R script and show the plots.
In-Reply-To: <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
Message-ID: <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>

Thanks? a lot you guys,

you all were right; I used most of your suggestions as part of the solution.
It is a considerable effort to get persistent plots when running an R
script.
The problem is even when I open an interface with X11() it closes
immediately afterwards, when the script is done executing.

My workaround now is:
g <- ggplot(...)
X11()
print(g)
invisible(readLines("stdin", n=1))

But frankly I do not think that is feasible for a steady development
environment.

As to the suggestions to use Rstudio. I tried it before in university. I
did not like it, too much mouse, too crowded interface. Actually the
difficulty to just use scripts in R was one big reason that I now write
python code. (But that now borders on a discussion post, and that is not
my intention)

Kind regards,
Felix

On 1/26/20 10:22 PM, Rolf Turner wrote:
>
> On 27/01/20 9:47 am, Sorkin, John wrote:
>
>> Felix, I suggest you consider using an IDE such as RStudio as you
>> develop and run R code. An integrated development environment will
>> allow you to concentrate on learning R rather on the mechanics of
>> running R in a non-standard environment.
>
> I disagree.? Or rather, I would say that this is a matter of personal
> taste.? And personally I find that RStudio and its like just present
> another "learning curve" to climb.? I would much rather just write R
> code and get on with it.
>
> I have never liked GUIs:
>
>> GUIs normally make it simple to accomplish simple actions and
>> impossible to accomplish complex actions.
>>
>> ??????? --- Doug Gwyn
>> ??????????? (22/Jun/91 in `comp.unix.wizards')
>
> But as I say it's a matter of taste and inclination.? It is likely
> that Felix is among the overwhelming majority of users who prefer GUIs.
>
> cheers,
>
> Rolf Turner
>


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jan 27 21:32:05 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Jan 2020 09:32:05 +1300
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
Message-ID: <CAB8pepzJnfxoQ0dJKXqUsQbwhf85sQ2J82Uq+DrYp4gnrcyPHA@mail.gmail.com>

> An integrated development environment will allow you to concentrate on learning R
> rather on the mechanics of running R in a
> non-standard environment.

Oh my gosh...
The terminal emulator is not a non-standard environment.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jan 27 21:46:41 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Jan 2020 09:46:41 +1300
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
Message-ID: <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>

It is possible to produce interactive-style plots, while running
scripts from the terminal.
(Or at least, it was, because I've done before).

Can I verify, ***which OS*** are you using...???

I'm offsite now.
If you're using Windows or Linux, I can check later.
(If no one else posts the answer, that is).


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jan 28 01:27:55 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Jan 2020 13:27:55 +1300
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
 <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
Message-ID: <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>

Here's a solution for Windows, for use with graphics::plot.
Using, Linux and grid or ggplot2, may require some modification.
(However, I assuming the modifications would be easy to make).

You can create a file, say quasi_interactive.r

----quasi_interactive.r----
#for use with windows only
options (device = windows)

.initialize = function ()
{   n = length (dev.list () )
    if (n == 0)
        windows ()
    else
        locator (1)
}

.finalize = function ()
{   n = length (dev.list () )
    if (n > 0)
        invisible (locator (1) )
}

#assumes plots called with graphics::plot function
plot = function (x, ...)
{   .initialize ()
    graphics::plot (x, ...)
}

args = commandArgs (TRUE)
source (args [1])

.finalize ()
----end-of-file----

Then at the terminal, use either of:
> Rscript quasi_interactive.r my_script_file.r
> R -f quasi_interactive.r --args test.r

The first option is probably better.

Also, instead of locator (1) you could test for text input (say by
pressing enter), or wait (say 10 seconds per plot).
Another option is to open one graphics device for each plot.

B.


From |e||xb||nd @end|ng |rom gm@||@com  Tue Jan 28 13:02:51 2020
From: |e||xb||nd @end|ng |rom gm@||@com (Felix Blind)
Date: Tue, 28 Jan 2020 13:02:51 +0100
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
 <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
 <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>
Message-ID: <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>

Thanks Abby,

I am using Linux and device X11 worked for me in the past. I will check
your script later and tell you if it works.

On 1/28/20 1:27 AM, Abby Spurdle wrote:
> Here's a solution for Windows, for use with graphics::plot.
> Using, Linux and grid or ggplot2, may require some modification.
> (However, I assuming the modifications would be easy to make).
>
> You can create a file, say quasi_interactive.r
>
> ----quasi_interactive.r----
> #for use with windows only
> options (device = windows)
>
> .initialize = function ()
> {   n = length (dev.list () )
>     if (n == 0)
>         windows ()
>     else
>         locator (1)
> }
>
> .finalize = function ()
> {   n = length (dev.list () )
>     if (n > 0)
>         invisible (locator (1) )
> }
>
> #assumes plots called with graphics::plot function
> plot = function (x, ...)
> {   .initialize ()
>     graphics::plot (x, ...)
> }
>
> args = commandArgs (TRUE)
> source (args [1])
>
> .finalize ()
> ----end-of-file----
>
> Then at the terminal, use either of:
>> Rscript quasi_interactive.r my_script_file.r
>> R -f quasi_interactive.r --args test.r
> The first option is probably better.
>
> Also, instead of locator (1) you could test for text input (say by
> pressing enter), or wait (say 10 seconds per plot).
> Another option is to open one graphics device for each plot.
>
> B.


From p|erre@r@t|n@ud @end|ng |rom un|v-t|@e2@|r  Tue Jan 28 15:57:15 2020
From: p|erre@r@t|n@ud @end|ng |rom un|v-t|@e2@|r (Pierre Ratinaud)
Date: Tue, 28 Jan 2020 15:57:15 +0100 (CET)
Subject: [R] problems with greek language on windows
Message-ID: <308dab93-19a7-c362-6d96-0158cda037a1@univ-tlse2.fr>

Hello,

I've seen two computers in Greece which have the following problem. They 
are both windows 10 computers with R 3.6.2. These both windows are asked 
to use english or french as main language. In this context, if users 
switch their keyboard to write greek, they cannot use greek input in the 
command line of the interface of R or print graphics with greek 
letters/words coming from an input file : every characters are replaced 
with a latin letter with an accent. Greek letters are ok in options box 
of the preferences of the interface.

Does anybody know how it's possible to use greek language in R in this 
context ?

Best regards

Pierre Ratinaud

-- 
Pierre Ratinaud
Ma?tre de conf?rences
D?partement des Sciences de l'Education et de la Formation
Laboratoire LERASS : http://www.lerass.com/
Universit? Toulouse - Jean Jaur?s : http://www.univ-tlse2.fr/
tel : 05 61 50 42 28


From |o@nn|@@d|m@ko@ @end|ng |rom gm@||@com  Tue Jan 28 17:52:05 2020
From: |o@nn|@@d|m@ko@ @end|ng |rom gm@||@com (Ioannis Dimakos)
Date: Tue, 28 Jan 2020 18:52:05 +0200
Subject: [R] problems with greek language on windows
In-Reply-To: <308dab93-19a7-c362-6d96-0158cda037a1@univ-tlse2.fr>
References: <308dab93-19a7-c362-6d96-0158cda037a1@univ-tlse2.fr>
Message-ID: <CAJuoTkVF3r2fBCY+cNwuzej6tzE9wqvgT5Phoax+NA6k-7D5UQ@mail.gmail.com>

You could try

> Sys.setlocale("LC_CTYPE", "Greek")
and it should work.

Best,

Ioannis

On Tue, Jan 28, 2020 at 5:59 PM Pierre Ratinaud <
pierre.ratinaud at univ-tlse2.fr> wrote:

> Hello,
>
> I've seen two computers in Greece which have the following problem. They
> are both windows 10 computers with R 3.6.2. These both windows are asked
> to use english or french as main language. In this context, if users
> switch their keyboard to write greek, they cannot use greek input in the
> command line of the interface of R or print graphics with greek
> letters/words coming from an input file : every characters are replaced
> with a latin letter with an accent. Greek letters are ok in options box
> of the preferences of the interface.
>
> Does anybody know how it's possible to use greek language in R in this
> context ?
>
> Best regards
>
> Pierre Ratinaud
>
> --
> Pierre Ratinaud
> Ma?tre de conf?rences
> D?partement des Sciences de l'Education et de la Formation
> Laboratoire LERASS : http://www.lerass.com/
> Universit? Toulouse - Jean Jaur?s : http://www.univ-tlse2.fr/
> tel : 05 61 50 42 28
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Ioannis Dimakos, PhD
University of Patras
Dept. of Educational Sciences & Social Work
Patras, GR-26500 Greece
T: +30-2610-969740, F: +30-2610-969780, M: +30-6977-646059
Email: idimakos at upatras.gr
http://www.elemedu.upatras.gr/info/dimakos
http://about.me/idimakos

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jan 28 18:34:15 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 28 Jan 2020 11:34:15 -0600
Subject: [R] how to import/read .vcf files in R
Message-ID: <CAF9-5jNoVwUepw_Vb-u=bJQHJ9Rt_KXnDh68GHEBNfjBMYSq_g@mail.gmail.com>

Hello,

I tried doing:
> library(vcfR)
> vcf <- read.vcfR("ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf", verbose = FALSE )

but this takes forever to load and I am not sure it is even working.

Any other suggestion on how I can read in .vcf file in R?

Thanks
Ana


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jan 28 18:36:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 28 Jan 2020 09:36:13 -0800
Subject: [R] how to import/read .vcf files in R
In-Reply-To: <CAF9-5jNoVwUepw_Vb-u=bJQHJ9Rt_KXnDh68GHEBNfjBMYSq_g@mail.gmail.com>
References: <CAF9-5jNoVwUepw_Vb-u=bJQHJ9Rt_KXnDh68GHEBNfjBMYSq_g@mail.gmail.com>
Message-ID: <CAGxFJbT8HjtR9Okvo-aDzCmSxLsmYwrAwNxs879cYhCuGWS5HA@mail.gmail.com>

As this apparently involves genomic data, I would suggest that you ask this
on the BioConductor site:
https://www.bioconductor.org/help/
especially if you don't get effective help here.

Bert Gunter




On Tue, Jan 28, 2020 at 9:29 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I tried doing:
> > library(vcfR)
> > vcf <-
> read.vcfR("ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf",
> verbose = FALSE )
>
> but this takes forever to load and I am not sure it is even working.
>
> Any other suggestion on how I can read in .vcf file in R?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jan 28 18:46:04 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 28 Jan 2020 11:46:04 -0600
Subject: [R] how to import/read .vcf files in R
In-Reply-To: <CAGxFJbT8HjtR9Okvo-aDzCmSxLsmYwrAwNxs879cYhCuGWS5HA@mail.gmail.com>
References: <CAF9-5jNoVwUepw_Vb-u=bJQHJ9Rt_KXnDh68GHEBNfjBMYSq_g@mail.gmail.com>
 <CAGxFJbT8HjtR9Okvo-aDzCmSxLsmYwrAwNxs879cYhCuGWS5HA@mail.gmail.com>
Message-ID: <CAF9-5jMpCNNLu0BgT==Dp9b7JJ4P_o4YZ18eD-ttdagnFe+bJQ@mail.gmail.com>

Thanks for the tip!

On Tue, Jan 28, 2020 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> As this apparently involves genomic data, I would suggest that you ask this on the BioConductor site:
> https://www.bioconductor.org/help/
> especially if you don't get effective help here.
>
> Bert Gunter
>
>
>
>
> On Tue, Jan 28, 2020 at 9:29 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hello,
>>
>> I tried doing:
>> > library(vcfR)
>> > vcf <- read.vcfR("ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf", verbose = FALSE )
>>
>> but this takes forever to load and I am not sure it is even working.
>>
>> Any other suggestion on how I can read in .vcf file in R?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Jan 29 12:07:01 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 29 Jan 2020 12:07:01 +0100
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
 <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
 <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>
 <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>
Message-ID: <CAGAA5bd1F8D5Utk2NrY9LwWwrJhED_Lx-5i=X-wKoCOWrX59GA@mail.gmail.com>

On Tue, 28 Jan 2020 at 13:03, Felix Blind <felixblind at gmail.com> wrote:
>
> I am using Linux and device X11 worked for me in the past. I will check
> your script later and tell you if it works.

[...]

I am using R version 3.6.2 on ubuntu 18.04.3 LTS and the X11-device
when I make plot in the terminal works without problems.



Regards
Martin


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Jan 29 12:07:05 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 29 Jan 2020 16:37:05 +0530
Subject: [R] Correct place to put an import directive
Message-ID: <CAC8=1eo8pS3y6CmaZufDYhq6H1uVjFnPNxdh3LJ+F3JGkKuptA@mail.gmail.com>

Dear All,

This is a cross post of the following query:-

https://stackoverflow.com/questions/59946803/import-directive-in-r-which-file-and-where-in-that-file-should-we-put-this

Since no one answered this query, so I am posting this here.

Can someone please help  me ?

Thank you,
Ashim

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Jan 29 12:11:17 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 29 Jan 2020 12:11:17 +0100
Subject: [R] Executing an R script and show the plots.
In-Reply-To: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
Message-ID: <CAGAA5bfFqwRAWT0e7V-e9kfDe41WMz8EeKtPJRtZrsnQmmb+VQ@mail.gmail.com>

On Sun, 26 Jan 2020 at 16:30, Felix Blind <felixblind at gmail.com> wrote:
>

> But when I put the same code in a file script.r and run it with R -f
> script.r or if I source it in the REPL with source("script.r") I do not
> get any plots shown.
>
> Can you guys tell me what I do wrong. (Apart from either using RStudio
> or the REPL exclusively)

Add Sys.sleep(Inf) to the end of your script.r and run it with

R --interactive < script.r

It works for me.

Regards
Martin


From er|cjberger @end|ng |rom gm@||@com  Wed Jan 29 12:17:06 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 29 Jan 2020 13:17:06 +0200
Subject: [R] Correct place to put an import directive
In-Reply-To: <CAC8=1eo8pS3y6CmaZufDYhq6H1uVjFnPNxdh3LJ+F3JGkKuptA@mail.gmail.com>
References: <CAC8=1eo8pS3y6CmaZufDYhq6H1uVjFnPNxdh3LJ+F3JGkKuptA@mail.gmail.com>
Message-ID: <CAGgJW74vMh=XK==TTPg8D_XVKtVUnDT3GtPn9GNi=7amE-d99w@mail.gmail.com>

I think a better place to post this question would be
 r-package-devel



On Wed, Jan 29, 2020 at 1:07 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> This is a cross post of the following query:-
>
>
> https://stackoverflow.com/questions/59946803/import-directive-in-r-which-file-and-where-in-that-file-should-we-put-this
>
> Since no one answered this query, so I am posting this here.
>
> Can someone please help  me ?
>
> Thank you,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pr||ett|ngton @end|ng |rom gm@||@com  Thu Jan 30 06:05:00 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Thu, 30 Jan 2020 18:05:00 +1300
Subject: [R] Biostrings: how to add annotations to aligned sequences
Message-ID: <CAE9tUWfQ5ngNMQxdxR5iF3GP=te4B9fSaYK=HdsnW4PpC1u7sg@mail.gmail.com>

I want to annotate a domain that the sequences in my alignment share, how
can I do this using Biostrings?

Thank you,
April

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jan 30 06:16:17 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 29 Jan 2020 21:16:17 -0800
Subject: [R] Biostrings: how to add annotations to aligned sequences
In-Reply-To: <CAE9tUWfQ5ngNMQxdxR5iF3GP=te4B9fSaYK=HdsnW4PpC1u7sg@mail.gmail.com>
References: <CAE9tUWfQ5ngNMQxdxR5iF3GP=te4B9fSaYK=HdsnW4PpC1u7sg@mail.gmail.com>
Message-ID: <A8271599-6DD7-4CAD-BD47-6298008A7C7F@dcn.davis.ca.us>

Wrong mailing list. Search for bioconductor support.

On January 29, 2020 9:05:00 PM PST, April Ettington <aprilettington at gmail.com> wrote:
>I want to annotate a domain that the sequences in my alignment share,
>how
>can I do this using Biostrings?
>
>Thank you,
>April
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Thu Jan 30 07:05:49 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 30 Jan 2020 19:05:49 +1300
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
 <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
 <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>
 <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>
Message-ID: <CAB8pepy3i5_+042r_8VXDwcpmSpJY6BWePk=52Z_FLEXpreytg@mail.gmail.com>

> I am using Linux and device X11 worked for me in the past. I will check
> your script later and tell you if it works.

The previous script isn't very good.
I've improved it.
The new version has been tested on Linux and Windows, and with lattice
and ggplot2.

I note that the script is more complex that originally intended.
And I suspect that there maybe (mostly small) problems, that would
require further maintenance.

Running R (by itself) non-REPL with partial interactivity, while it
has merit, may be problematic, in the long run.
(Unless, of course, one were to hack the graphics device(s), but that
would probably be a lot of work).

But in saying that, you're welcome to run R, however, you like.

----------------page.r----------------
os = tolower (Sys.info ()[1])
if (os == "windows")
    options (device = windows)
if (os == "linux")
    options (device = X11)

.initialize = function ()
{   n = length (dev.list () )
    if (n > 0)
        locator (1)
}

.finalize = function ()
{   n = length (dev.list () )
    if (n > 0)
        invisible (locator (1) )
}

"+" = function (a, b)
{   object = base::`+` (a, b)
    if (inherits (object, "gg") )
        print (object)
    object
}

.prompt = function (pkg, fun)
{   fbody = character (1)
    fbody [1] = paste (fun, "=", 'function (...) {')
    fbody [2] = '.initialize ()'
    fbody [3] = paste ('print (', pkg, '::', fun, '(...) )', sep="")
    fbody [4] = "}"
    eval (str2lang (paste (fbody, collapse="\n") ), -2)
}

####################################################
#add other top-level plotting functions, if required
####################################################
.prompt ("graphics", "plot")
.prompt ("lattice", "xyplot")
.prompt ("ggplot2", "ggplot")
####################################################

args = commandArgs (TRUE)
source (args [1])

.finalize ()
----------------EOF----------------

Usage is similar to before:
> Rscript page.r myfile.r

The file <myfile.r> shouldn't require any modification, can have multiple plots.

Click on the plot, to move to next one...


From @purd|e@@ @end|ng |rom gm@||@com  Thu Jan 30 07:15:28 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 30 Jan 2020 19:15:28 +1300
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <CAB8pepy3i5_+042r_8VXDwcpmSpJY6BWePk=52Z_FLEXpreytg@mail.gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
 <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
 <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>
 <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>
 <CAB8pepy3i5_+042r_8VXDwcpmSpJY6BWePk=52Z_FLEXpreytg@mail.gmail.com>
Message-ID: <CAB8pepyXPhHwfogXVKHhDg9Gv5xWtoX_tcDqh_7G53-HYX5iDA@mail.gmail.com>

> .prompt = function (pkg, fun)
> {   fbody = character (1)

And I've already noticed a bug.
This isn't going too well...


From gb@rc@ro|| @end|ng |rom gm@||@com  Tue Jan 28 11:28:36 2020
From: gb@rc@ro|| @end|ng |rom gm@||@com (Giulio Barcaroli)
Date: Tue, 28 Jan 2020 11:28:36 +0100
Subject: [R] [R-pkgs] SamplingStrata: new version on CRAN
Message-ID: <649f9b7a-8cec-661d-453b-af6a6a151e8d@gmail.com>

Dear all,

this is to announce that a new version of*SamplingStrata*  
       is available on CRAN.*SamplingStrata*  is a package for the
       optimization of stratified sample design. This new version (the
       1.5) contains a lot of news. In particular:

- there is now the possibility to cover also*spatial sampling*,
       whenever the units in sampling frame are geo-referenced (method =
       "spatial" in*optimStrata *function);

- the use of the function*optimStrata *(a wrapper that call different
	optimization functions) greatly simplifies the handling of*takeall *
	strata;

- when models are used in order to take into account the*anticipated variance*  of target variables, a new function (computeGamma)
       permits to evaluate*heteroscedasticity*  in order to
       correctly calculate the overall variance in strata.

A*cheatsheet*  is available in the /docs/inst directory.

You can find the whole documentation at

https://barcaroli.github.io/SamplingStrata/

Best regards,

Giulio Barcaroli


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From proccontent@ @end|ng |rom gm@||@com  Wed Jan 29 22:42:13 2020
From: proccontent@ @end|ng |rom gm@||@com (SAS_learner)
Date: Wed, 29 Jan 2020 15:42:13 -0600
Subject: [R] R Dplyr hands on project
In-Reply-To: <CACxE24m31KF8yGAwrjOxcE8-aFr6zAXgYmXu0uauFLuo9f=Dyw@mail.gmail.com>
References: <CAPo+ggt2Oe5r-x_V_AvieQP7MVkQtzfqKVnV-6ZZGnXZHJ4Srw@mail.gmail.com>
 <CACxE24m31KF8yGAwrjOxcE8-aFr6zAXgYmXu0uauFLuo9f=Dyw@mail.gmail.com>
Message-ID: <CAPo+ggtm7z0n3yJGFjw4Mtqnrb1nsNTOwCP32TYmzJbCAyUyQw@mail.gmail.com>

Thanks for the tip!

On Sun, Jan 26, 2020 at 12:02 AM Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> Hello!
>
> ?R for Data Science? is an excellent reference.
>
> Thanks,
> Erin
>
>
> On Sat, Jan 25, 2020 at 11:00 PM SAS_learner <proccontents at gmail.com> wrote:
>>
>> Hello All ,
>>
>> I am trying to learn R and started with R Dplyr for data management
>> .Can anyone point out  to a  book or place or GitHub location which
>> has a project that I can use to replicate , to improve my skills would
>> be of great help.
>>
>> thanks
>> Kumar
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Thu Jan 30 16:44:59 2020
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Thu, 30 Jan 2020 15:44:59 +0000
Subject: [R] R Dplyr hands on project
Message-ID: <BY5PR17MB3956CD3BB3898B78DB907EEBB8040@BY5PR17MB3956.namprd17.prod.outlook.com>

> On Sat, Jan 25, 2020 at 11:00 PM SAS_learner <proccontents at gmail.com> wrote:
>>
>> Hello All ,
>>
>> I am trying to learn R and started with R Dplyr for data management
>> .Can anyone point out  to a  book or place or GitHub location which
>> has a project that I can use to replicate , to improve my skills would
>> be of great help.
>>
>> thanks
>> Kumar

Kumar,

If you need to learn how to use R for statistical analyses, you might want to consider getting a copy of Andy Fields's book, Discovering Statistics using R.
It will show you how to write scripts for basic statistical analyses like t-tests, ANOVA, correlation and regression. It will also give you the necessary
statistical background you will need to use them properly.

While this is great book for statistical analyses, its coverage of basic graphing is not as extensive.
For that I recommend getting Winston Chang's book, The R Graphics Cookbook.

Speaking of graphics, try installing an R Studio add in called equisse.
This add in allows you to interactively explore your data by visualizing it with the ggplot2 package.
It's a great tool which allows a user to create your choice graphs with whatever variables you choose without having to write any code.
Parenthetically, after creating the graph, the add in will display the code which created your graph.
Pairing equisse with Chang's book will enable you to learn how to create graphs using R more easily.

Hope this helps!

Thomas Subia 
ASQ CQE

Statistician / Sr. Quality Engineer
IMG Companies?
225 Mountain Vista Parkway
Livermore, CA 94551
T.?(925) 273-1106
F.?(925) 273-1111
E. tsubia at imgprecision.com


Precision Manufacturing for Emerging Technologies
imgprecision.com?

The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.


From t@n@@@ @end|ng |rom gm@||@com  Thu Jan 30 19:38:04 2020
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 30 Jan 2020 10:38:04 -0800
Subject: [R] about .function
Message-ID: <CA+JEM00vHVMs2rAvAnc9qL5WM6ZsK73vQ0_bpjELpg2SLsvjzg@mail.gmail.com>

Dear all,

if I may ask please a very simple question :

what does "." mean in front of  function name : an example below . thank
you very much !

.set_pbmc_color_11<-function() {
  myColors <- c( "dodgerblue2",
                 "green4",
                 "#6A3D9A", # purple
                 "grey",
                 "tan4",
                 "yellow",
                 "#FF7F00", # orange
                 "black",
                 "#FB9A99", # pink
                 "orchid",
                 "red")

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jan 30 20:18:15 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 30 Jan 2020 14:18:15 -0500
Subject: [R] about .function
In-Reply-To: <CA+JEM00vHVMs2rAvAnc9qL5WM6ZsK73vQ0_bpjELpg2SLsvjzg@mail.gmail.com>
References: <CA+JEM00vHVMs2rAvAnc9qL5WM6ZsK73vQ0_bpjELpg2SLsvjzg@mail.gmail.com>
Message-ID: <52a6b977-be89-5a2a-a2cd-9f81191f0ad4@gmail.com>

On 30/01/2020 1:38 p.m., Bogdan Tanasa wrote:
> Dear all,
> 
> if I may ask please a very simple question :
> 
> what does "." mean in front of  function name : an example below . thank
> you very much !
> 
> .set_pbmc_color_11<-function() {
>    myColors <- c( "dodgerblue2",
>                   "green4",
>                   "#6A3D9A", # purple
>                   "grey",
>                   "tan4",
>                   "yellow",
>                   "#FF7F00", # orange
>                   "black",
>                   "#FB9A99", # pink
>                   "orchid",
>                   "red")
> 

It means that the default ls() won't list the function, you'd need 
ls(all.names = TRUE).  By convention such functions are usually meant 
for internal use, but there are lots of exceptions to that convention.
The same convention is used in Unix-alike file systems.

Duncan Murdoch


From t@n@@@ @end|ng |rom gm@||@com  Thu Jan 30 20:22:23 2020
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 30 Jan 2020 11:22:23 -0800
Subject: [R] about .function
In-Reply-To: <52a6b977-be89-5a2a-a2cd-9f81191f0ad4@gmail.com>
References: <CA+JEM00vHVMs2rAvAnc9qL5WM6ZsK73vQ0_bpjELpg2SLsvjzg@mail.gmail.com>
 <52a6b977-be89-5a2a-a2cd-9f81191f0ad4@gmail.com>
Message-ID: <CA+JEM00xu_tEnqrZeRUh_N_A=ANFxc1RUbsmuV7Rv=e4kxs+dg@mail.gmail.com>

appreciate it ! thank you Duncan !

On Thu, Jan 30, 2020 at 11:18 AM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/01/2020 1:38 p.m., Bogdan Tanasa wrote:
> > Dear all,
> >
> > if I may ask please a very simple question :
> >
> > what does "." mean in front of  function name : an example below . thank
> > you very much !
> >
> > .set_pbmc_color_11<-function() {
> >    myColors <- c( "dodgerblue2",
> >                   "green4",
> >                   "#6A3D9A", # purple
> >                   "grey",
> >                   "tan4",
> >                   "yellow",
> >                   "#FF7F00", # orange
> >                   "black",
> >                   "#FB9A99", # pink
> >                   "orchid",
> >                   "red")
> >
>
> It means that the default ls() won't list the function, you'd need
> ls(all.names = TRUE).  By convention such functions are usually meant
> for internal use, but there are lots of exceptions to that convention.
> The same convention is used in Unix-alike file systems.
>
> Duncan Murdoch
>
>
>

	[[alternative HTML version deleted]]


From emm@nue|@|evy @end|ng |rom gm@||@com  Fri Jan 31 10:04:19 2020
From: emm@nue|@|evy @end|ng |rom gm@||@com (Emmanuel Levy)
Date: Fri, 31 Jan 2020 11:04:19 +0200
Subject: [R] How to read a file containing two types of rows - (for the
 Netflix challenge data format)
Message-ID: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>

Hi,

I'd like to use the Netflix challenge data and just can't figure out how to
efficiently "scan" the files.
https://www.kaggle.com/netflix-inc/netflix-prize-data

The files have two types of row, either an *ID* e.g., "1:" , "2:", etc. or
3 values associated to each ID:

The format is as follows:
*1:*
value1,value2, value3
value1,value2, value3
value1,value2, value3
value1,value2, value3
*2:*
value1,value2, value3
value1,value2, value3
*3:*
value1,value2, value3
value1,value2, value3
value1,value2, value3
*4:*
etc ...

And I want to create a matrix where each line is of the form:

ID value1, value2, value3

Si "ID" needs to be duplicated - I could write a Perl script to convert
this format to CSV, but I'm sure there's a simple R trick.

Thanks for suggestions!

Emmanuel

	[[alternative HTML version deleted]]


From R@|ner @end|ng |rom krug@@de  Fri Jan 31 10:55:46 2020
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Fri, 31 Jan 2020 10:55:46 +0100
Subject: [R] How to read a file containing two types of rows - (for the
 Netflix challenge data format)
In-Reply-To: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>
References: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>
Message-ID: <CA6BF6AC-5233-4CAE-BDF9-F6826FA13877@krugs.de>

I did something similar yesterday?

Use readLine() to read at in and identify the ?*1:*, ? with a regex. Than you have your dividers. In a second step, use read.csv(skip = ?, Ncollumns = ?)  to read the enclosed blocks, and last, combine them accordingly.

This is written without an R installation, so the argument names are likely wrong.

Rainer


> On 31 Jan 2020, at 10:04, Emmanuel Levy <emmanuel.levy at gmail.com> wrote:
> 
> Hi,
> 
> I'd like to use the Netflix challenge data and just can't figure out how to
> efficiently "scan" the files.
> https://www.kaggle.com/netflix-inc/netflix-prize-data
> 
> The files have two types of row, either an *ID* e.g., "1:" , "2:", etc. or
> 3 values associated to each ID:
> 
> The format is as follows:
> *1:*
> value1,value2, value3
> value1,value2, value3
> value1,value2, value3
> value1,value2, value3
> *2:*
> value1,value2, value3
> value1,value2, value3
> *3:*
> value1,value2, value3
> value1,value2, value3
> value1,value2, value3
> *4:*
> etc ...
> 
> And I want to create a matrix where each line is of the form:
> 
> ID value1, value2, value3
> 
> Si "ID" needs to be duplicated - I could write a Perl script to convert
> this format to CSV, but I'm sure there's a simple R trick.
> 
> Thanks for suggestions!
> 
> Emmanuel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From chr|@ho|d @end|ng |rom p@yctc@org  Fri Jan 31 11:39:48 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Fri, 31 Jan 2020 10:39:48 +0000 (GMT)
Subject: [R] How to read a file containing two types of rows - (for the
 Netflix challenge data format)
In-Reply-To: <CA6BF6AC-5233-4CAE-BDF9-F6826FA13877@krugs.de>
References: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>
 <CA6BF6AC-5233-4CAE-BDF9-F6826FA13877@krugs.de>
Message-ID: <1878818242.2076491.1580467188561.JavaMail.zimbra@psyctc.org>

I am sure Rainer's approach is good and I know my R programming is truly terrible but here's a crude script in base R that does what you want

# rawDat <- readLines(con = "netflix.dat")
fil <- tempfile(fileext = ".dat")
cat("*1:*
value1,value2, value3
value1,value2, value3
value1,value2, value3
value1,value2, value3
*2:*
value1,value2, value3
value1,value2, value3
*3:*
value1,value2, value3
value1,value2, value3
value1,value2, value3
*4:*", 
    file = fil,
    sep = "\n")
rawDat <- readLines(fil, n = -1)
unlink(fil) # tidy up data input

### create a data frame for output
### this first line will be overwritten by the actual data
outDF <- as.data.frame(list(id = 1,
                            value1 = "",
                            value2 = "",
                            value3 = ""),
                       stringsAsFactors = FALSE) # necessary to avoid mess with character to factor conversion

j <- 0 # counter for entries
for (i in 1:length(rawDat)) {
  rawDat[i] <- trimws(rawDat[i])
  if (nchar(rawDat[i]) == 0) next # skip empty lines
  if (grepl(":*", rawDat[i], fixed = TRUE)) {
    ### got an ID line
    id <- sub("\\*([0123456789]*):\\*", "\\1", rawDat[i])
  } else {
    ### not an ID line so one of the one or more following lines of data
    ### I have assumed these are all of the same form
    j <- j + 1
    rawDat[i] <- gsub(" ", "", rawDat[i], fixed = TRUE)
    tmpDat <- unlist(strsplit(rawDat[i], ","))
    outDF[j,1] <- id
    outDF[j,2:4] <- tmpDat
  }
}
outDF

I am slowly adapting to the tidyverse but this is something I still find easier to do in very crude for loop, base R.

Plea: my formal programming training is one week of "Introduction to FORTRAN" on teletypes in 1975, but I confess it's 
both lack of formal training _and_ lack of native ability that means my coding is so bad.

If any gurus have a moment, show us really elegant and tidyverse ways to do this!

Very best all,

Chris

----- Original Message -----
> From: "Rainer M Krug" <Rainer at krugs.de>
> To: "Emmanuel Levy" <emmanuel.levy at gmail.com>
> Cc: "R-help Mailing List" <r-help at r-project.org>
> Sent: Friday, 31 January, 2020 10:55:46
> Subject: Re: [R] How to read a file containing two types of rows - (for the Netflix challenge data format)

> I did something similar yesterday?
> 
> Use readLine() to read at in and identify the ?*1:*, ? with a regex. Than you
> have your dividers. In a second step, use read.csv(skip = ?, Ncollumns = ?)  to
> read the enclosed blocks, and last, combine them accordingly.
> 
> This is written without an R installation, so the argument names are likely
> wrong.
> 
> Rainer
> 
> 
>> On 31 Jan 2020, at 10:04, Emmanuel Levy <emmanuel.levy at gmail.com> wrote:
>> 
>> Hi,
>> 
>> I'd like to use the Netflix challenge data and just can't figure out how to
>> efficiently "scan" the files.
>> https://www.kaggle.com/netflix-inc/netflix-prize-data
>> 
>> The files have two types of row, either an *ID* e.g., "1:" , "2:", etc. or
>> 3 values associated to each ID:
>> 
>> The format is as follows:
>> *1:*
>> value1,value2, value3
>> value1,value2, value3
>> value1,value2, value3
>> value1,value2, value3
>> *2:*
>> value1,value2, value3
>> value1,value2, value3
>> *3:*
>> value1,value2, value3
>> value1,value2, value3
>> value1,value2, value3
>> *4:*
>> etc ...
>> 
>> And I want to create a matrix where each line is of the form:
>> 
>> ID value1, value2, value3
>> 
>> Si "ID" needs to be duplicated - I could write a Perl script to convert
>> this format to CSV, but I'm sure there's a simple R trick.
>> 
>> Thanks for suggestions!
>> 
>> Emmanuel
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology,
> UCT), Dipl. Phys. (Germany)
> 
> Orcid ID: 0000-0002-7490-0066
> 
> Department of Evolutionary Biology and Environmental Studies
> University of Z?rich
> Office Y34-J-74
> Winterthurerstrasse 190
> 8075 Z?rich
> Switzerland
> 
> Office:	+41 (0)44 635 47 64
> Cell:       	+41 (0)78 630 66 57
> email:      Rainer.Krug at uzh.ch
>		Rainer at krugs.de
> Skype:     RMkrug
> 
> PGP: 0x0F52F982
> 
> 
> 
> 
>	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From pj@|nh@07 @end|ng |rom gm@||@com  Fri Jan 31 15:21:20 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 31 Jan 2020 09:21:20 -0500
Subject: [R] How to extract or sort values from one column
Message-ID: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>

Hi All,

I have a .csv file with four columns (Chrom, Start_pos, End_pos & Value).
The value column range from 0 to 1.0 having more than 2.8 million rows. I
need to write a code from which I can extract the values from 0.2-0.4 &
0.7-1.0. Could anyone help me in writing the code because I am new to R and
it takes lot of time manually to sort based on values.

The only part I know is I can read the .csv file and after that I don?t
know how to proceed further.


Thanks,

Puja

	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Fri Jan 31 15:52:14 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Fri, 31 Jan 2020 09:52:14 -0500
Subject: [R] How to extract or sort values from one column
In-Reply-To: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
Message-ID: <CALrbzg0zxcRL8PzqHWomwX_QMEXCRpZEze9Q6kBbZHuPgANyuQ@mail.gmail.com>

Welcome to R!

You could try using findInterval() which will quickly determine into
which interval your values belong.

# your break points define the intervals
brks <- c( 0.2, 0.4, 0.7)

# make an example data frame
n <- 100
x <- data.frame(
  x = seq_len(n),
  y = runif(n, min = 0, max = 1))

# compute the interval associations and add it to the
# data frame
x$group <- findInterval(x$y, brks)

# show the groupings
plot(x$x, x$y, pch = 1 + x$group)

Cheers,
Ben


On Fri, Jan 31, 2020 at 9:21 AM pooja sinha <pjsinha07 at gmail.com> wrote:
>
> Hi All,
>
> I have a .csv file with four columns (Chrom, Start_pos, End_pos & Value).
> The value column range from 0 to 1.0 having more than 2.8 million rows. I
> need to write a code from which I can extract the values from 0.2-0.4 &
> 0.7-1.0. Could anyone help me in writing the code because I am new to R and
> it takes lot of time manually to sort based on values.
>
> The only part I know is I can read the .csv file and after that I don?t
> know how to proceed further.
>
>
> Thanks,
>
> Puja
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
West Boothbay Harbor, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From m@||||@t@ @end|ng |rom pp@|net@||  Fri Jan 31 16:12:53 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Fri, 31 Jan 2020 17:12:53 +0200
Subject: [R] How to extract or sort values from one column
In-Reply-To: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
Message-ID: <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>

Hi!

Let's assume your data is stored in a data frame called 'df'. So this
code should do the job:

df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]

Best,
Kimmo



pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
> Hi All,
> 
> I have a .csv file with four columns (Chrom, Start_pos, End_pos &
> Value).
> The value column range from 0 to 1.0 having more than 2.8 million
> rows. I
> need to write a code from which I can extract the values from 0.2-0.4 
> &
> 0.7-1.0. Could anyone help me in writing the code because I am new to
> R and
> it takes lot of time manually to sort based on values.
> 
> The only part I know is I can read the .csv file and after that I
> don?t
> know how to proceed further.
> 
> 
> Thanks,
> 
> Puja
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@||||@t@ @end|ng |rom pp@|net@||  Fri Jan 31 16:14:57 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Fri, 31 Jan 2020 17:14:57 +0200
Subject: [R] How to extract or sort values from one column
In-Reply-To: <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
 <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
Message-ID: <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>

Hi!

Oh, sorry, one "s" too much in my code. Here the correct one:

df$Value[ (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ]

Best,
Kimmo

pe, 2020-01-31 kello 17:12 +0200, K. Elo kirjoitti:
> Hi!
> 
> Let's assume your data is stored in a data frame called 'df'. So this
> code should do the job:
> 
> df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]
> 
> Best,
> Kimmo
> 
> 
> 
> pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
> > Hi All,
> > 
> > I have a .csv file with four columns (Chrom, Start_pos, End_pos &
> > Value).
> > The value column range from 0 to 1.0 having more than 2.8 million
> > rows. I
> > need to write a code from which I can extract the values from 0.2-
> > 0.4 
> > &
> > 0.7-1.0. Could anyone help me in writing the code because I am new
> > to
> > R and
> > it takes lot of time manually to sort based on values.
> > 
> > The only part I know is I can read the .csv file and after that I
> > don?t
> > know how to proceed further.
> > 
> > 
> > Thanks,
> > 
> > Puja
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pj@|nh@07 @end|ng |rom gm@||@com  Fri Jan 31 16:50:16 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 31 Jan 2020 10:50:16 -0500
Subject: [R] How to extract or sort values from one column
In-Reply-To: <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
 <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
 <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>
Message-ID: <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>

Thanks for providing the code but I also needed the output sheet in
.csv format with all the four columns corresponding to the value (Chrom,
Start_pos, End_pos & Value ranging from what I specified earlier).

Puja

On Fri, Jan 31, 2020 at 10:23 AM K. Elo <maillists at pp.inet.fi> wrote:

> Hi!
>
> Oh, sorry, one "s" too much in my code. Here the correct one:
>
> df$Value[ (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ]
>
> Best,
> Kimmo
>
> pe, 2020-01-31 kello 17:12 +0200, K. Elo kirjoitti:
> > Hi!
> >
> > Let's assume your data is stored in a data frame called 'df'. So this
> > code should do the job:
> >
> > df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]
> >
> > Best,
> > Kimmo
> >
> >
> >
> > pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
> > > Hi All,
> > >
> > > I have a .csv file with four columns (Chrom, Start_pos, End_pos &
> > > Value).
> > > The value column range from 0 to 1.0 having more than 2.8 million
> > > rows. I
> > > need to write a code from which I can extract the values from 0.2-
> > > 0.4
> > > &
> > > 0.7-1.0. Could anyone help me in writing the code because I am new
> > > to
> > > R and
> > > it takes lot of time manually to sort based on values.
> > >
> > > The only part I know is I can read the .csv file and after that I
> > > don?t
> > > know how to proceed further.
> > >
> > >
> > > Thanks,
> > >
> > > Puja
> > >
> > >     [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b@ye@|@n|og|c@1 @end|ng |rom gm@||@com  Fri Jan 31 17:05:45 2020
From: b@ye@|@n|og|c@1 @end|ng |rom gm@||@com (Jan Galkowski)
Date: Fri, 31 Jan 2020 11:05:45 -0500
Subject: [R] 
 =?utf-8?q?How_to_read_a_file_containing_two_types_of_rows_-_?=
 =?utf-8?q?=28for_the_Netflix_challenge_data_format=29?=
Message-ID: <f058af33-e7f3-4c74-8b40-cd370f7865af@www.fastmail.com>

With the *data.table* package, *R* can use *fread* as follows:

> grab<- function(file)
> {
>  fin<- fread(file=file,
>  sep=NULL,
>  dec=".",
>  quote="", nrows=Inf, header=FALSE,
>  stringsAsFactors=FALSE, verbose=FALSE,
>  col.names=c("record"),
>  check.names=FALSE, fill=FALSE, blank.lines.skip=FALSE,
>  showProgress=TRUE,
>  data.table=FALSE, skip=0,
>  nThread=2, logical01=FALSE, keepLeadingZeros=FALSE)
>  cat(sprintf("Read '%s'.\n", file))
>  #
>  substance<- apply(X=fin, MARGIN=1, FUN=function(r) chartr(",", "\t", r[1]))
>  cat(sprintf("Translated '%s'.\n", file))
>  D<- fread(text=substance,
>  sep="\t",
>  dec=".",
>  quote="", nrows=Inf, header=FALSE,
>  stringsAsFactors=FALSE, verbose=FALSE,
>  col.names=c("ip", "valid.hits", "err.hits", "megabytes"),
>  check.names=FALSE, fill=FALSE, blank.lines.skip=FALSE,
>  showProgress=TRUE,
>  data.table=FALSE, skip=0,
>  nThread=2, logical01=FALSE, keepLeadingZeros=FALSE)
>  cat(sprintf("Parsed '%s'.\n", file))
>  ip<- D$ip
>  withinBlock<- sapply(X=ip, FUN=function(s) as.integer((strsplit(x=s, split=".", fixed=TRUE)[[1]])[4]))
>  D$within.block<- withinBlock
>  return(D)
> }
> 

In short, one pass pulls in all the records into an internal structure, which can be edited or manipulated at will, and then a second call to *fread* parses it properly. 

*fread *is fast, even for big datasets.


--
Jan Galkowski 

https://www.linkedin.com/in/deepdevelopment

member,

... American Statistical Association
... International Society for Bayesian Analysis
... Ecological Society of America
... International Association of Survey Statisticians
... American Association for the Advancement of Science
... TeX Users Group

(pronouns: *he, him, his*)

*Keep your energy local*. --John Farrell, *ILSR <http://ilsr.org/>*


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jan 31 17:26:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 31 Jan 2020 08:26:21 -0800
Subject: [R] How to extract or sort values from one column
In-Reply-To: <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
 <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
 <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>
 <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>
Message-ID: <CAGxFJbTEE4TMpcKQGyOCJCO1KgAdQLBx_1de4vZ7cBRDVysONw@mail.gmail.com>

Time to study some tutorials and do your own work, don't you think? There
are many good tutorials on the web.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 31, 2020 at 7:50 AM pooja sinha <pjsinha07 at gmail.com> wrote:

> Thanks for providing the code but I also needed the output sheet in
> .csv format with all the four columns corresponding to the value (Chrom,
> Start_pos, End_pos & Value ranging from what I specified earlier).
>
> Puja
>
> On Fri, Jan 31, 2020 at 10:23 AM K. Elo <maillists at pp.inet.fi> wrote:
>
> > Hi!
> >
> > Oh, sorry, one "s" too much in my code. Here the correct one:
> >
> > df$Value[ (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ]
> >
> > Best,
> > Kimmo
> >
> > pe, 2020-01-31 kello 17:12 +0200, K. Elo kirjoitti:
> > > Hi!
> > >
> > > Let's assume your data is stored in a data frame called 'df'. So this
> > > code should do the job:
> > >
> > > df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]
> > >
> > > Best,
> > > Kimmo
> > >
> > >
> > >
> > > pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
> > > > Hi All,
> > > >
> > > > I have a .csv file with four columns (Chrom, Start_pos, End_pos &
> > > > Value).
> > > > The value column range from 0 to 1.0 having more than 2.8 million
> > > > rows. I
> > > > need to write a code from which I can extract the values from 0.2-
> > > > 0.4
> > > > &
> > > > 0.7-1.0. Could anyone help me in writing the code because I am new
> > > > to
> > > > R and
> > > > it takes lot of time manually to sort based on values.
> > > >
> > > > The only part I know is I can read the .csv file and after that I
> > > > don?t
> > > > know how to proceed further.
> > > >
> > > >
> > > > Thanks,
> > > >
> > > > Puja
> > > >
> > > >     [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@||||@t@ @end|ng |rom pp@|net@||  Fri Jan 31 17:31:02 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Fri, 31 Jan 2020 18:31:02 +0200
Subject: [R] How to extract or sort values from one column
In-Reply-To: <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
 <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
 <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>
 <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>
Message-ID: <a393bdcb5ca409fe33b7b39a84513963a7827f8e.camel@pp.inet.fi>

Hi!

To extract full rows, use:

df[ ( (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ), ]


But it is also a good idea to start reading some introductory
tutorials. These are basic things you can find in all tutorials :-)

Best,
Kimmo

pe, 2020-01-31 kello 10:50 -0500, pooja sinha kirjoitti:
> Thanks for providing the code but I also needed the output sheet in
> .csv format with all the four columns corresponding to the value
> (Chrom,
> Start_pos, End_pos & Value ranging from what I specified earlier).
> 
> Puja
> 
> On Fri, Jan 31, 2020 at 10:23 AM K. Elo <maillists at pp.inet.fi> wrote:
> 
> > Hi!
> > 
> > Oh, sorry, one "s" too much in my code. Here the correct one:
> > 
> > df$Value[ (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ]
> > 
> > Best,
> > Kimmo
> > 
> > pe, 2020-01-31 kello 17:12 +0200, K. Elo kirjoitti:
> > > Hi!
> > > 
> > > Let's assume your data is stored in a data frame called 'df'. So
> > > this
> > > code should do the job:
> > > 
> > > df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]
> > > 
> > > Best,
> > > Kimmo
> > > 
> > > 
> > > 
> > > pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
> > > > Hi All,
> > > > 
> > > > I have a .csv file with four columns (Chrom, Start_pos, End_pos
> > > > &
> > > > Value).
> > > > The value column range from 0 to 1.0 having more than 2.8
> > > > million
> > > > rows. I
> > > > need to write a code from which I can extract the values from
> > > > 0.2-
> > > > 0.4
> > > > &
> > > > 0.7-1.0. Could anyone help me in writing the code because I am
> > > > new
> > > > to
> > > > R and
> > > > it takes lot of time manually to sort based on values.
> > > > 
> > > > The only part I know is I can read the .csv file and after that
> > > > I
> > > > don?t
> > > > know how to proceed further.
> > > > 
> > > > 
> > > > Thanks,
> > > > 
> > > > Puja
> > > > 
> > > >     [[alternative HTML version deleted]]
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible
> > > > code.
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible
> > > code.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ||54250 @end|ng |rom m@n@com  Fri Jan 31 19:06:00 2020
From: ||54250 @end|ng |rom m@n@com (Ioanna Ioannou)
Date: Fri, 31 Jan 2020 18:06:00 +0000
Subject: [R] How to create a vector by searching information in multiple
 data.tables in r?
In-Reply-To: <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <17F90DC5-D0FD-4A2D-A6FA-0A22861A78CF@krugs.de>
 <DBBPR05MB6570B84F540BE7F511103A70F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>,
 <B4D78F92-CB0E-42C8-99A7-E115DE725714@krugs.de>,
 <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <DBBPR05MB6570420EA0AB59D8B2E203CEF3070@DBBPR05MB6570.eurprd05.prod.outlook.com>

Hello everyone,

Once again i am a bit stack. I have over 200 json files with information. I managed to manipulate them and their format is rather difficult as shown below. Unfortunately, not all these files contain the same fields. I want to extract e.g., the country from all these files. How can i add NA for the files for which the country is not mentioned?

Here is a reproducible example. Lets say i have two files, three files, two provide the country and the one does not.  essentially i want a vector called country which will look like this:

Country <- c('Colombia', 'Greece', NA)

Any help much appreciated!

Best,
ioanna


A<- data.frame( name1 = c('fields', 'fields', 'fields'),
                              name2= c('category', 'asset', 'country'),
                              value  = c('Structure Class', 'Building', 'Colombia')



B<- data.frame( name1 = c('fields', 'fields', 'fields'),
                              name2= c('category', 'asset', 'country'),
                              value  = c('Structure Class', 'Building', 'Greece')



C<- data.frame( name1 = c('fields', 'fields', 'fields'),
                              name2= c('category', 'asset', 'assessment'),
                              value  = c('Structure Class', 'Building', 'Fragility')



	[[alternative HTML version deleted]]


From pj@|nh@07 @end|ng |rom gm@||@com  Fri Jan 31 19:06:16 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 31 Jan 2020 13:06:16 -0500
Subject: [R] How to extract or sort values from one column
In-Reply-To: <a393bdcb5ca409fe33b7b39a84513963a7827f8e.camel@pp.inet.fi>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
 <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
 <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>
 <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>
 <a393bdcb5ca409fe33b7b39a84513963a7827f8e.camel@pp.inet.fi>
Message-ID: <CAGjf1cN=wBJcZONcYtYgBa4kHgSnpbhC05wBmQ__Kgnu04j=Kw@mail.gmail.com>

Thanks but it gives error "incorrect number of dimensions".


Best,
Puja

On Fri, Jan 31, 2020 at 11:37 AM K. Elo <maillists at pp.inet.fi> wrote:

> Hi!
>
> To extract full rows, use:
>
> df[ ( (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ), ]
>
>
> But it is also a good idea to start reading some introductory
> tutorials. These are basic things you can find in all tutorials :-)
>
> Best,
> Kimmo
>
> pe, 2020-01-31 kello 10:50 -0500, pooja sinha kirjoitti:
> > Thanks for providing the code but I also needed the output sheet in
> > .csv format with all the four columns corresponding to the value
> > (Chrom,
> > Start_pos, End_pos & Value ranging from what I specified earlier).
> >
> > Puja
> >
> > On Fri, Jan 31, 2020 at 10:23 AM K. Elo <maillists at pp.inet.fi> wrote:
> >
> > > Hi!
> > >
> > > Oh, sorry, one "s" too much in my code. Here the correct one:
> > >
> > > df$Value[ (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ]
> > >
> > > Best,
> > > Kimmo
> > >
> > > pe, 2020-01-31 kello 17:12 +0200, K. Elo kirjoitti:
> > > > Hi!
> > > >
> > > > Let's assume your data is stored in a data frame called 'df'. So
> > > > this
> > > > code should do the job:
> > > >
> > > > df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]
> > > >
> > > > Best,
> > > > Kimmo
> > > >
> > > >
> > > >
> > > > pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
> > > > > Hi All,
> > > > >
> > > > > I have a .csv file with four columns (Chrom, Start_pos, End_pos
> > > > > &
> > > > > Value).
> > > > > The value column range from 0 to 1.0 having more than 2.8
> > > > > million
> > > > > rows. I
> > > > > need to write a code from which I can extract the values from
> > > > > 0.2-
> > > > > 0.4
> > > > > &
> > > > > 0.7-1.0. Could anyone help me in writing the code because I am
> > > > > new
> > > > > to
> > > > > R and
> > > > > it takes lot of time manually to sort based on values.
> > > > >
> > > > > The only part I know is I can read the .csv file and after that
> > > > > I
> > > > > don?t
> > > > > know how to proceed further.
> > > > >
> > > > >
> > > > > Thanks,
> > > > >
> > > > > Puja
> > > > >
> > > > >     [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible
> > > > > code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible
> > > > code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pj@|nh@07 @end|ng |rom gm@||@com  Fri Jan 31 20:05:21 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 31 Jan 2020 14:05:21 -0500
Subject: [R] How to extract or sort values from one column
In-Reply-To: <CAGjf1cN=wBJcZONcYtYgBa4kHgSnpbhC05wBmQ__Kgnu04j=Kw@mail.gmail.com>
References: <CAGjf1cPfVK5J3CAsoXHxxJ1TwLT77zmqJp2snsVYExrU1OZVPA@mail.gmail.com>
 <e13fb5186ca4d096987608b0b42db32087cfc265.camel@pp.inet.fi>
 <21e3942ad9ee8c0cfc88e8544e4eeeb47a3d3c05.camel@pp.inet.fi>
 <CAGjf1cMGoDzynFv-p3YBcpqRQhEy9bXtL05KSCuTu8KTiQbZaw@mail.gmail.com>
 <a393bdcb5ca409fe33b7b39a84513963a7827f8e.camel@pp.inet.fi>
 <CAGjf1cN=wBJcZONcYtYgBa4kHgSnpbhC05wBmQ__Kgnu04j=Kw@mail.gmail.com>
Message-ID: <CAGjf1cMgNzV=LMQ+qg7A5jO2KS7xYWvtTdhDC8hHAzJgc8wpuw@mail.gmail.com>

It worked, initially I made some mistake.


Thanks a lot. Trying to read basics of R.

Puja

On Fri, Jan 31, 2020 at 1:06 PM pooja sinha <pjsinha07 at gmail.com> wrote:

> Thanks but it gives error "incorrect number of dimensions".
>
>
> Best,
> Puja
>
> On Fri, Jan 31, 2020 at 11:37 AM K. Elo <maillists at pp.inet.fi> wrote:
>
>> Hi!
>>
>> To extract full rows, use:
>>
>> df[ ( (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ), ]
>>
>>
>> But it is also a good idea to start reading some introductory
>> tutorials. These are basic things you can find in all tutorials :-)
>>
>> Best,
>> Kimmo
>>
>> pe, 2020-01-31 kello 10:50 -0500, pooja sinha kirjoitti:
>> > Thanks for providing the code but I also needed the output sheet in
>> > .csv format with all the four columns corresponding to the value
>> > (Chrom,
>> > Start_pos, End_pos & Value ranging from what I specified earlier).
>> >
>> > Puja
>> >
>> > On Fri, Jan 31, 2020 at 10:23 AM K. Elo <maillists at pp.inet.fi> wrote:
>> >
>> > > Hi!
>> > >
>> > > Oh, sorry, one "s" too much in my code. Here the correct one:
>> > >
>> > > df$Value[ (df$Value>=0.2 & df$Value<=0.4) | df$Value>=0.7 ]
>> > >
>> > > Best,
>> > > Kimmo
>> > >
>> > > pe, 2020-01-31 kello 17:12 +0200, K. Elo kirjoitti:
>> > > > Hi!
>> > > >
>> > > > Let's assume your data is stored in a data frame called 'df'. So
>> > > > this
>> > > > code should do the job:
>> > > >
>> > > > df$Value[ (df$Value>=0.2 & df$Values<=0.4) | df$Value>=0.7 ]
>> > > >
>> > > > Best,
>> > > > Kimmo
>> > > >
>> > > >
>> > > >
>> > > > pe, 2020-01-31 kello 09:21 -0500, pooja sinha kirjoitti:
>> > > > > Hi All,
>> > > > >
>> > > > > I have a .csv file with four columns (Chrom, Start_pos, End_pos
>> > > > > &
>> > > > > Value).
>> > > > > The value column range from 0 to 1.0 having more than 2.8
>> > > > > million
>> > > > > rows. I
>> > > > > need to write a code from which I can extract the values from
>> > > > > 0.2-
>> > > > > 0.4
>> > > > > &
>> > > > > 0.7-1.0. Could anyone help me in writing the code because I am
>> > > > > new
>> > > > > to
>> > > > > R and
>> > > > > it takes lot of time manually to sort based on values.
>> > > > >
>> > > > > The only part I know is I can read the .csv file and after that
>> > > > > I
>> > > > > don?t
>> > > > > know how to proceed further.
>> > > > >
>> > > > >
>> > > > > Thanks,
>> > > > >
>> > > > > Puja
>> > > > >
>> > > > >     [[alternative HTML version deleted]]
>> > > > >
>> > > > > ______________________________________________
>> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> > > > > see
>> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > > PLEASE do read the posting guide
>> > > > > http://www.R-project.org/posting-guide.html
>> > > > > and provide commented, minimal, self-contained, reproducible
>> > > > > code.
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide
>> > > > http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible
>> > > > code.
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Jan 31 21:01:29 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 31 Jan 2020 23:01:29 +0300
Subject: [R] How to create a vector by searching information in multiple
 data.tables in r?
In-Reply-To: <DBBPR05MB6570420EA0AB59D8B2E203CEF3070@DBBPR05MB6570.eurprd05.prod.outlook.com>
References: <DBBPR05MB657042CF5BA5D3BE1592166BF3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <17F90DC5-D0FD-4A2D-A6FA-0A22861A78CF@krugs.de>
 <DBBPR05MB6570B84F540BE7F511103A70F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <B4D78F92-CB0E-42C8-99A7-E115DE725714@krugs.de>
 <DBBPR05MB65705DE2605FFC8D9F02E2C8F3360@DBBPR05MB6570.eurprd05.prod.outlook.com>
 <DBBPR05MB6570420EA0AB59D8B2E203CEF3070@DBBPR05MB6570.eurprd05.prod.outlook.com>
Message-ID: <20200131230129.3a98e331@Tarkus>

On Fri, 31 Jan 2020 18:06:00 +0000
Ioanna Ioannou <ii54250 at msn.com> wrote:

> I want to extract e.g., the country from all these files. How can i
> add NA for the files for which the country is not mentioned?

I am starting from the beginning, since I don't know what you have
tried and where exactly you are stuck.

> A<- data.frame( name1 = c('fields', 'fields', 'fields'),
>                               name2= c('category', 'asset',
> 'country'), value  = c('Structure Class', 'Building', 'Colombia')

Given one such data frame, we can use logical vector subscripts to
extract the 'country' field. The following command returns a logical
vector:

A[, 'name2'] == 'country'
# [1] FALSE FALSE  TRUE

If we pass it to the subscript operator (type ?'[' in the R prompt for
more info), we can get the matching rows of the data frame:

subs <- A[, 'name2'] == 'country'
A[subs, ]
#    name1   name2    value
# 3 fields country Colombia

Okay, now we just need to choose the correct column:

A[subs, 'value']
# [1] Colombia
# Levels: Building Colombia Structure Class

What happens if there is no "country" row?

C[C[, 'name2'] == 'country', 'value']
# factor(0)
# Levels: Building Fragility Structure Class

We get a 0-length vector instead of the NA we want. The length()
function and the `if` control-flow construct should let us test for
0-length vectors (see ?length and ?'if'):

x <- C[C[,'name2'] == 'country','value']
if (length(x) == 1) x else NA
# [1] NA

Bonus question: what happens if there is more than one "country" line
in the data frame? What should happen instead?

See also:
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors

Note that the "value" column is a factor (that's why we are getting
these "Levels:" when we print the vectors; see ?factor). You want a
character vector, so we will coerce the value to the desired type using
the as.character() function.

> essentially i want a vector called country which will look like this:
> 
> Country <- c('Colombia', 'Greece', NA)

Once we have a procedure to deal with one data frame, we can apply it
to multiple data frames by putting the procedure into a function and
calling it on a list of data frames using one of the *apply functions
(see ?vapply):

# TODO: produce the list programmatically by calling the JSON reading
# function on a vector of filenames
dataframes <- list(A, B, C)
# perform an anonymous function on each of the data frames,
# return the result as a vector
sapply(dataframes, function(x) {
 country <- x[x[,'name2'] == 'country','value'] # look for "country" row
 # return the country as a string if found one row, NA otherwise
 if (length(country) == 1) as.character(country) else NA
})

I am pretty sure there are other ways to perform this operation, but I
find this one the easiest to explain.

-- 
Best regards,
Ivan

P.S.

> 	[[alternative HTML version deleted]]

Please post e-mails in plain text, not HTML. See
<http://www.R-project.org/posting-guide.html> for more info.


From emm@nue|@|evy @end|ng |rom gm@||@com  Fri Jan 31 22:36:10 2020
From: emm@nue|@|evy @end|ng |rom gm@||@com (Emmanuel Levy)
Date: Fri, 31 Jan 2020 23:36:10 +0200
Subject: [R] How to read a file containing two types of rows - (for the
 Netflix challenge data format)
In-Reply-To: <10131E8D-DDFC-41A2-A5BB-31D1EAF1A761@ucsd.edu>
References: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>
 <10131E8D-DDFC-41A2-A5BB-31D1EAF1A761@ucsd.edu>
Message-ID: <CAMUS-Mu+tzakX8A5A3aizJdsrWfJGptpckUMAOfuFTOaHp883g@mail.gmail.com>

Hi All,

Thanks so much for your inputs, it's so nice to have such a helpful
community -- I wrote some kind of mix between the different replies, I copy
my final code below.

All the best,

Emmanuel

mat = read.csv("~/format_test.csv", fill=TRUE, header=FALSE, as.is=TRUE)

first.col.idx = grep(":",mat[,1])

first.col.val = grep(":",mat[,1],value=TRUE)

first.col.val = gsub(pattern=":", replacement="", first.col.val)

mat.clean = mat[-first.col.idx,]

reps = diff(c(first.col.idx,length(mat1[,1])))

reps[1] = reps[1]+1

mat.final = cbind( rep(first.col.val, reps-1), mat.clean)








On Fri, 31 Jan 2020 at 20:31, Berry, Charles <ccberry at health.ucsd.edu>
wrote:

>
>
> > On Jan 31, 2020, at 1:04 AM, Emmanuel Levy <emmanuel.levy at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I'd like to use the Netflix challenge data and just can't figure out how
> to
> > efficiently "scan" the files.
> > https://www.kaggle.com/netflix-inc/netflix-prize-data
> >
> > The files have two types of row, either an *ID* e.g., "1:" , "2:", etc.
> or
> > 3 values associated to each ID:
> >
> > The format is as follows:
> > *1:*
> > value1,value2, value3
> > value1,value2, value3
> > value1,value2, value3
> > value1,value2, value3
> > *2:*
> > value1,value2, value3
> > value1,value2, value3
> > *3:*
> > value1,value2, value3
> > value1,value2, value3
> > value1,value2, value3
> > *4:*
> > etc ...
> >
> > And I want to create a matrix where each line is of the form:
> >
> > ID value1, value2, value3
> >
> > Si "ID" needs to be duplicated - I could write a Perl script to convert
> > this format to CSV, but I'm sure there's a simple R trick.
> >
>
> I'd be tempted to use pipe() to separately read the ID lines and the value
> lines, but in R you can do this:
>
> fc <- count.fields( "yourfile.txt", sep = ",")
> rlines <- split( readLines( "yourfile.txt" ), fc)
> mat <-
>   cbind( rlines[[1]],
>         do.call( rbind, strsplit( rlines[[2]], ",")))
>
>
> This assumes that there are exactly 1 or 3 fields in each row of
> "yourfile.txt", if not, some incantation of grepl() applied to the text of
> readLines() should suffice.
>
> HTH,
>
> Chuck
>
>
>
>

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom he@|th@uc@d@edu  Fri Jan 31 19:30:50 2020
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Fri, 31 Jan 2020 18:30:50 +0000
Subject: [R] How to read a file containing two types of rows - (for the
 Netflix challenge data format)
In-Reply-To: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>
References: <CAMUS-Mu5K7ZTQcP_yzgtfnJq5hvJ5H_3ANYStS1PX3nD+LD0PA@mail.gmail.com>
Message-ID: <10131E8D-DDFC-41A2-A5BB-31D1EAF1A761@ucsd.edu>



> On Jan 31, 2020, at 1:04 AM, Emmanuel Levy <emmanuel.levy at gmail.com> wrote:
> 
> Hi,
> 
> I'd like to use the Netflix challenge data and just can't figure out how to
> efficiently "scan" the files.
> https://www.kaggle.com/netflix-inc/netflix-prize-data
> 
> The files have two types of row, either an *ID* e.g., "1:" , "2:", etc. or
> 3 values associated to each ID:
> 
> The format is as follows:
> *1:*
> value1,value2, value3
> value1,value2, value3
> value1,value2, value3
> value1,value2, value3
> *2:*
> value1,value2, value3
> value1,value2, value3
> *3:*
> value1,value2, value3
> value1,value2, value3
> value1,value2, value3
> *4:*
> etc ...
> 
> And I want to create a matrix where each line is of the form:
> 
> ID value1, value2, value3
> 
> Si "ID" needs to be duplicated - I could write a Perl script to convert
> this format to CSV, but I'm sure there's a simple R trick.
> 

I'd be tempted to use pipe() to separately read the ID lines and the value lines, but in R you can do this:

fc <- count.fields( "yourfile.txt", sep = ",")
rlines <- split( readLines( "yourfile.txt" ), fc)
mat <-
  cbind( rlines[[1]],
        do.call( rbind, strsplit( rlines[[2]], ",")))


This assumes that there are exactly 1 or 3 fields in each row of "yourfile.txt", if not, some incantation of grepl() applied to the text of readLines() should suffice.

HTH,

Chuck 


