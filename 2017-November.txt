From drjimlemon at gmail.com  Wed Nov  1 03:33:02 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 1 Nov 2017 13:33:02 +1100
Subject: [R] Scatterplot3d :: Rotating x tick labels by x degrees
In-Reply-To: <727ca822-a190-f7a3-c006-f8538513969a@statistik.tu-dortmund.de>
References: <BLUPR0301MB2052BB1D513419274FB69EB6FA590@BLUPR0301MB2052.namprd03.prod.outlook.com>
 <727ca822-a190-f7a3-c006-f8538513969a@statistik.tu-dortmund.de>
Message-ID: <CA+8X3fX5adRgyt-_Y+eKj=-eRZO-ux5cMT0BNXuDB5O3EfBPxQ@mail.gmail.com>

Well, scatterplot3d might not allow it, but have a look at the second
example for staxlab in the plotrix package.

Jim

On Wed, Nov 1, 2017 at 7:30 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 31.10.2017 00:56, Alex Restrepo wrote:
> ...
> 45 degree rotation is not supported in base R graphics and scatterplot3d
> uses that.
>


From alex.restrepo at outlook.com  Wed Nov  1 03:48:41 2017
From: alex.restrepo at outlook.com (Alex Restrepo)
Date: Wed, 1 Nov 2017 02:48:41 +0000
Subject: [R] Scatterplot3d :: Rotating x tick labels by x degrees
In-Reply-To: <06AA0B5E-E51A-4D21-A2F3-6C58E54F1A30@comcast.net>
References: <BLUPR0301MB2052BB1D513419274FB69EB6FA590@BLUPR0301MB2052.namprd03.prod.outlook.com>
 <20171031165523.d36d8499bcadc8c33b654470@univ-nantes.fr>,
 <06AA0B5E-E51A-4D21-A2F3-6C58E54F1A30@comcast.net>
Message-ID: <BLUPR0301MB20523B974BC2C04FAE9F8099FA5F0@BLUPR0301MB2052.namprd03.prod.outlook.com>

Hello,

David, don?t worry about answering this question or any of my inquiries in the future.  Not looking for code servants. Definitely not an expert at using the scatter plot 3D  library.  That being said, I plan on researching rgl as was recommended so kindly on a previous response to my question.

Regards, Alex

On Oct 31, 2017, at 4:13 PM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:


On Oct 31, 2017, at 8:55 AM, Olivier Crouzet <olivier.crouzet at univ-nantes.fr<mailto:olivier.crouzet at univ-nantes.fr>> wrote:

Hi Alex,

this should be related to the "las" argument of "par()" but
actually it does not seem to be parametered in scatterplot3d.
Searching the net for "scatterplot3d las" provides a link to:

https://stackoverflow.com/questions/25458652/specifying-the-orientation-of-the-axes-labels-in-scatterplot3d

You may try the solution that is provided in this link or consider using
alternate packages (like rgl or the plotly packages which one may be
more powerfull as far as I can judge). However I can't help more. It
seems ggplot does not produce 3d plots (but it looks like it can
interact with plotly when using 3d plots).

Olivier;

The cited SO solutions (mine being the first one)  were addressing the request for rotated "axis"-labels rather than rotated "axtick"-labels, although the general strategy of looking at the code and using the `text`-function with xpd=TRUE (rather than the `mtext`-function where needed in the definitions of mytext and mytext2) should apply.

Alex;

I'd encourage you to demonstrate more initiative rather than expecting us to be on-call code servants.  I've decided to limit my gratis coding time to 15 minutes daily. I think this might take me an hour or more. I'm still available for on-list code review on this effort.

As a start, I'd suggest downloading the scatterplot3d package code and then open up scatterplot3d.R. Find the comment

## label tick marks

... and perhaps decide whether you need to use `text` rather than `mtext`. (`text` can rotate by any amount,
but may need "xpd" to be set TRUE. `mtext` is limited to 90 degree increments.) I've used up my time, so the next move is yours.
--
David.



Olivier.

On Mon, 30 Oct 2017
23:56:02 +0000 Alex Restrepo <alex.restrepo at outlook.com<mailto:alex.restrepo at outlook.com>> wrote:

Hi,

I would like to rotate the x axis tick labels by 45 degrees.   Using
the code below, could someone please provide an example?   Many
Thanks In Advance, Alex

library("scatterplot3d")
mydf=data.frame(rate=seq(158, 314)
              ,age=seq(1, 157)
              ,market_date=seq(as.Date("2000/1/1"), as.Date
("2003/1/1"), by="7 days"))

mydf$market_date=as.Date(mydf$market_date, format="%Y-%m-%d")

scatterplot3d(mydf$market_date
            ,mydf$rate
            ,mydf$age
            ,x.ticklabs = seq(as.Date("2000/1/1"), as.Date
("2003/1/1"), by="330 days"))


   [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html and provide commented,
minimal, self-contained, reproducible code.


--
Olivier Crouzet, PhD
/Assistant Professor/
@LLING - Laboratoire de Linguistique de Nantes
  UMR6310 CNRS / Universit? de Nantes
/Guest Researcher/
@UMCG (University Medical Center Groningen)
  ENT department
  Rijksuniversiteit Groningen

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From alex.restrepo at outlook.com  Wed Nov  1 03:49:22 2017
From: alex.restrepo at outlook.com (Alex Restrepo)
Date: Wed, 1 Nov 2017 02:49:22 +0000
Subject: [R] Scatterplot3d :: Rotating x tick labels by x degrees
In-Reply-To: <CA+8X3fX5adRgyt-_Y+eKj=-eRZO-ux5cMT0BNXuDB5O3EfBPxQ@mail.gmail.com>
References: <BLUPR0301MB2052BB1D513419274FB69EB6FA590@BLUPR0301MB2052.namprd03.prod.outlook.com>
 <727ca822-a190-f7a3-c006-f8538513969a@statistik.tu-dortmund.de>,
 <CA+8X3fX5adRgyt-_Y+eKj=-eRZO-ux5cMT0BNXuDB5O3EfBPxQ@mail.gmail.com>
Message-ID: <BLUPR0301MB2052AD561E5C9FFEEFBFBC0AFA5F0@BLUPR0301MB2052.namprd03.prod.outlook.com>

Thanks Jim, I will research.  I appreciate the response.

On Oct 31, 2017, at 9:33 PM, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:

Well, scatterplot3d might not allow it, but have a look at the second
example for staxlab in the plotrix package.

Jim

On Wed, Nov 1, 2017 at 7:30 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de<mailto:ligges at statistik.tu-dortmund.de>> wrote:


On 31.10.2017 00:56, Alex Restrepo wrote:
...
45 degree rotation is not supported in base R graphics and scatterplot3d
uses that.


	[[alternative HTML version deleted]]


From ABDELKARIM2 at msn.com  Wed Nov  1 04:12:57 2017
From: ABDELKARIM2 at msn.com (Amany Abdel-Karim)
Date: Wed, 1 Nov 2017 03:12:57 +0000
Subject: [R] beta binomial  distribution installation
Message-ID: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>

Hello,

I  tried to install package ?TailRank? using the command install.packages (RankTail) and library (TailRank) but I got the following errors. So, how can I install TaiRank in Rstudio to have se beta-binomial distribution, CDF and inverse CDG of  beta-binomal?

The commands I used are:

> install.packages("TailRank")

Installing package into ?C:/Users/stator-guest/Documents/R/win-library/3.4?

(as ?lib? is unspecified)

Warning in install.packages :

  dependency ?Biobase? is not available

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/TailRank_3.1.3.zip'

Content type 'application/zip' length 331270 bytes (323 KB)

downloaded 323 KB



package ?TailRank? successfully unpacked and MD5 sums checked



The downloaded binary packages are in

            C:\Users\stator-guest\AppData\Local\Temp\RtmpoVx40V\downloaded_packages

> library(TailRank)

Error: package or namespace load failed for ?TailRank? in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):

 there is no package called ?Biobase?

In addition: Warning message:

package ?TailRank? was built under R version 3.4.2




	[[alternative HTML version deleted]]


From rmcgu at doh.health.nsw.gov.au  Wed Nov  1 06:50:06 2017
From: rmcgu at doh.health.nsw.gov.au (MCGUIRE, Rhydwyn)
Date: Wed, 1 Nov 2017 05:50:06 +0000
Subject: [R] beta binomial  distribution installation
In-Reply-To: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
References: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
Message-ID: <AF36C32BE015CB48883C4A9F73CC8C3201BB979E86@DOHNSMXDB03.doh.health.nsw.gov.au>

Hi there, 

It looks like you also need the bioconductor package biobase, I found instructions for downloading that package here: www.bioconductor.org/install

Good luck.

Cheers,
Rhydwyn 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Amany Abdel-Karim
Sent: Wednesday, 1 November 2017 2:13 PM
To: R-help at stat.math.ethz.ch
Subject: [R] beta binomial distribution installation

Hello,

I  tried to install package TailRank using the command install.packages (RankTail) and library (TailRank) but I got the following errors. So, how can I install TaiRank in Rstudio to have se beta-binomial distribution, CDF and inverse CDG of  beta-binomal?

The commands I used are:

> install.packages("TailRank")

Installing package into C:/Users/stator-guest/Documents/R/win-library/3.4

(as lib is unspecified)

Warning in install.packages :

  dependency Biobase is not available

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/TailRank_3.1.3.zip'

Content type 'application/zip' length 331270 bytes (323 KB)

downloaded 323 KB



package TailRank successfully unpacked and MD5 sums checked



The downloaded binary packages are in

            C:\Users\stator-guest\AppData\Local\Temp\RtmpoVx40V\downloaded_packages

> library(TailRank)

Error: package or namespace load failed for TailRank in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):

 there is no package called Biobase

In addition: Warning message:

package TailRank was built under R version 3.4.2




	[[alternative HTML version deleted]]

__________________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of health's Electronic Messaging Policy.
__________________________________________________________________________________________________________
_______________________________________________________________________________________________________
Disclaimer: This message is intended for the addressee named and may contain confidential information.
If you are not the intended recipient, please delete it and notify the sender.
Views expressed in this message are those of the individual sender, and are not necessarily the views of the NSW Ministry of Health.
_______________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
_______________________________________________________________________________________________________

From hemantsain55 at gmail.com  Wed Nov  1 07:03:17 2017
From: hemantsain55 at gmail.com (Hemant Sain)
Date: Wed, 1 Nov 2017 11:33:17 +0530
Subject: [R] Creating Tag
Message-ID: <CAJL6Qs_-rUjnbAmxrPYAd41K=E2uGi1F9kUZu_0c08g6duF_kg@mail.gmail.com>

i want to tag categories to its menuname.
i have a csv containing menu item name and in other csv i have a column
containing some strings,
i want to pick that strings from categories and look into  menu items if
any menu item containing that string i want to create a new column next to
menu item name flagged as 1 otherwise 0
and the only condition is once a menu item flagged as 1 i don't need to
consider that menu item again to tag further in case of redundant strings
in categories only i want to search which are flagged as 0.
please help me with the R script.

*Menu Name*
9\ bobbie"
9\ chz steak"
9\ tuna"
provolone
20\ bobbie"
bottled soda 20oz
cran-slam ww
american
small chips
medium drink
9\ meatball"
capriotti's water
20'' chicken cheese steak
9\ veg turkey"
medium chips
9\ capastrami"
12\ bobbie"
12'' chicken cheese steak
cookie
12\ chz steak"
9\ cole turkey"
kid grilled cheese white
12\ italian"
12\ meatball"
12\ capastrami"
turkey sand w
20\ slaw be jo"
swiss
12\ cole turkey"
large drink
9\ ham&chz"
9'' chicken cheese steak
9\ slaw be jo"
turkey sand ww
stuffing
12\ turkey"
9\ italian"
12\ slaw be jo"
9\ grld italian"
12\ veg burger w/chz"
extra american
black&bleu salad
9\ turkey"
20\ turkey"
20\ capastrami"
ham sand w
12\ mushroom"
12\ grld italia"
italian salad
tuna sand ww
9\ roast beef"
20\ chz steak"
20\ mushroom"
9\ veg chzstk"
ham
genoa
12\ veg turkey"
12\ veggie cole turkey"
9\ mushroom"
cap's creation
mushrooms
salad chicken
20\ cole turkey"
1 pack chicken
kr  veg burger w/chz
12\ roast beef"
kid turkey n cheese white
20\ italian"
12\ ham&chz"
9\ employee sub"
roast beef kr
9\ veggie cole turkey"
12\ sausage"
tea
turkey sand kr
salad turkey
tuna sand kr
brownie
slice american cheese
1 oz pastrami
9\ cheese"
12\ italian up"
12\ capastrami up"
1 pack steak
delaware's finest small
the sampler sm
side ranch dressing
12\ veg turkey up"
20\ roast beef"
roast beef w
1oz turkey
12\ tuna"
20\ veg turkey"
12\ veg chzstk"
9\ sausage"
kid ham n cheese white
side italian dressing
salad provolone
20\ grld italia"
sample item 6
sample item 9
turkey
12\ slaw be jo up"
12\ meatball up"
1 oz roast beef
ham sand ww
delaware's finest large
side cole slaw large
large chips
20\ meatball"
12'' chick cheese stk up
12\ chz steak up"
12\ grld italia up"
cran-slam w
12\ bobbie up"
20\ cheese"
slice provolone
the sampler lg
meatball bar
slice ham
wise large chips
small side
sm soup
12\ tuna up"
12\ cole turkey up"
prosciutini
20\ veggie cole turkey"
soup
roast beef
20\ italian up"
20'' chick cheese stk up
20\ chz steak up"
20\ bobbie up"
20\ veg turkey up"
slice swiss
20\ capastrami up"
sample item 7
12\ ham&chz up"
salad swiss
12\ veggie cheese stk up"
california omelet
orange juice
exteme bac boy
dinner salad
chef salad
12\ turkey up"
the big cheese
combo it
fries cmb
sm pepsi
km cheese burger
#NAME?
#NAME?
kid grilled cheese wheat
kids ham cheese white box
calif. blt
bacon turkey melt
coffee
1-pc pancake
fries
tuna sand
biscuits & gravy
s-1/3 patty
x avocado
x chez
s-bacon
#NAME?
xtra egg
lg bev upcharge
sm ice tea
small soup
roast beef ww
salad tuna
med pepsi
20\ veg chzstk up"
day nm egg san
s-chkn brest
bell pepper
fruit
1 slice veggie turkey
s-toast
x sausage
1 pack sausage
chicken salad
lg pepsi
x dressing
large side
9\ firecracker turkey"
20\ sausage up"
20\ turkey up"
20\ veg chzstk"
lg ice tea
12\ roast beef up"
sample item 8
catering cap creation sal
the turkey lover sm
little italy sm
cookie tray
sd chk avo san
sm fry / 2 pc zucch
kid turkey n cheese wheat
junior chz burger
extra italian meat
chili chz fries
sm fry / 2 pc o ring
extra turkey








*CATEGORIES*
non-veg
chix
salmon
ch
chkn
brisket
brskt
bacon
bcn
chse
mahi
dog
shk
clam
parmesan
asiago
prosciutto
prosciutti
salami
Angus
hicken
chk
chick
wings
prk
pork
ham
bacon
ribs
fish
shrimp
tuna
beef
steak
stk
meatball
-------------- next part --------------
non-veg
chix
salmon
ch
chkn
brisket
brskt
bacon
bcn
chse
mahi
dog
shk
clam
parmesan 
asiago 
prosciutto 
prosciutti 
salami 
Angus
hicken 
chk 
chick 
wings
prk 
pork 
ham 
bacon 
ribs
fish 
shrimp
tuna
beef 
steak 
stk
meatball



























-------------- next part --------------
i want to tag categories to its menuname.
i have a csv containing menu item name and in other csv i have a colunmn containing some strings,
i want to pick that strings from categories and look into  menu items if any menu item containing that string i want to create a new column next to menu item name flagged as 1 otherwise 0
and the only condition is once a menu item flagged as 1 i dont need to consider that menu item again to tag further in case of redudant strings in categories only i want to search which are flagged as 0.
please help me with the r script.


Menu Name
9\ bobbie"
9\ chz steak"
9\ tuna"
provolone
20\ bobbie"
bottled soda 20oz
cran-slam ww
american
small chips
medium drink
9\ meatball"
capriotti's water
20'' chicken cheese steak
9\ veg turkey"
medium chips
9\ capastrami"
12\ bobbie"
12'' chicken cheese steak
cookie
12\ chz steak"
9\ cole turkey"
kid grilled cheese white
12\ italian"
12\ meatball"
12\ capastrami"
turkey sand w
20\ slaw be jo"
swiss
12\ cole turkey"
large drink
9\ ham&chz"
9'' chicken cheese steak
9\ slaw be jo"
turkey sand ww
stuffing
12\ turkey"
9\ italian"
12\ slaw be jo"
9\ grld italian"
12\ veg burger w/chz"
extra american
black&bleu salad
9\ turkey"
20\ turkey"
20\ capastrami"
ham sand w
12\ mushroom"
12\ grld italia"
italian salad
tuna sand ww
9\ roast beef"
20\ chz steak"
20\ mushroom"
9\ veg chzstk"
ham
genoa
12\ veg turkey"
12\ veggie cole turkey"
9\ mushroom"
cap's creation
mushrooms
salad chicken
20\ cole turkey"
1 pack chicken
kr  veg burger w/chz
12\ roast beef"
kid turkey n cheese white
20\ italian"
12\ ham&chz"
9\ employee sub"
roast beef kr
9\ veggie cole turkey"
12\ sausage"
tea
turkey sand kr
salad turkey
tuna sand kr
brownie
slice american cheese
1 oz pastrami
9\ cheese"
12\ italian up"
12\ capastrami up"
1 pack steak
delaware's finest small
the sampler sm
side ranch dressing
12\ veg turkey up"
20\ roast beef"
roast beef w
1oz turkey
12\ tuna"
20\ veg turkey"
12\ veg chzstk"
9\ sausage"
kid ham n cheese white
side italian dressing
salad provolone
20\ grld italia"
sample item 6
sample item 9
turkey
12\ slaw be jo up"
12\ meatball up"
1 oz roast beef
ham sand ww
delaware's finest large
side cole slaw large
large chips
20\ meatball"
12'' chick cheese stk up
12\ chz steak up"
12\ grld italia up"
cran-slam w
12\ bobbie up"
20\ cheese"
slice provolone
the sampler lg
meatball bar
slice ham
wise large chips
small side
sm soup
12\ tuna up"
12\ cole turkey up"
prosciutini
20\ veggie cole turkey"
soup
roast beef
20\ italian up"
20'' chick cheese stk up
20\ chz steak up"
20\ bobbie up"
20\ veg turkey up"
slice swiss
20\ capastrami up"
sample item 7
12\ ham&chz up"
salad swiss
12\ veggie cheese stk up"
california omelet
orange juice
exteme bac boy
dinner salad
chef salad
12\ turkey up"
the big cheese
combo it
fries cmb
sm pepsi
km cheese burger
#NAME?
#NAME?
kid grilled cheese wheat
kids ham cheese white box
calif. blt
bacon turkey melt
coffee
1-pc pancake
fries
tuna sand
biscuits & gravy
s-1/3 patty
x avocado
x chez
s-bacon
#NAME?
xtra egg
lg bev upcharge
sm ice tea
small soup
roast beef ww
salad tuna
med pepsi
20\ veg chzstk up"
day nm egg san
s-chkn brest
bell pepper
fruit
1 slice veggie turkey
s-toast
x sausage
1 pack sausage
chicken salad
lg pepsi
x dressing
large side
9\ firecracker turkey"
20\ sausage up"
20\ turkey up"
20\ veg chzstk"
lg ice tea
12\ roast beef up"
sample item 8
catering cap creation sal
the turkey lover sm
little italy sm
cookie tray
sd chk avo san
sm fry / 2 pc zucch
kid turkey n cheese wheat
junior chz burger
extra italian meat
chili chz fries
sm fry / 2 pc o ring
extra turkey

From maechler at stat.math.ethz.ch  Wed Nov  1 09:05:00 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Nov 2017 09:05:00 +0100
Subject: [R] run r script in r-fiddle
In-Reply-To: <CAPtbhHzLZ54YZm-me_xjQP+hF-KB-fZ5uPE_r1hYWPzK4fskag@mail.gmail.com>
References: <CAF0J_MviTcFMLEyygkPfDhsSyxgA-qoQrfTB932yuEq1e1t7+Q@mail.gmail.com>
 <CAPtbhHyDh9jOgEmai8XENCX=0RA8YVQUfjwZkEyPCv-3skcCzQ@mail.gmail.com>
 <23031.15488.515464.855674@stat.math.ethz.ch>
 <CAPtbhHxOFy2-OBeuZnNt9WOV1A8qyCAoerQYGywA_c0f2OY7JA@mail.gmail.com>
 <23032.25011.679300.970659@stat.math.ethz.ch>
 <CAPtbhHz=TXEh6dz+ERtNxp5b0e7J-39x-qEUEXd5hp5v-ZxAsw@mail.gmail.com>
 <CAPtbhHzLZ54YZm-me_xjQP+hF-KB-fZ5uPE_r1hYWPzK4fskag@mail.gmail.com>
Message-ID: <23033.32812.32970.270786@stat.math.ethz.ch>

>>>>> Suzen, Mehmet <msuzen at gmail.com>
>>>>>     on Tue, 31 Oct 2017 19:27:30 +0100 writes:

    > Dear List, According to datacamp support team,
    > r-fiddle.org is not supported. We asked them to put it
    > down as Professor Maechler suggested it is a waste of time
    > for the R-help to respond to questions on something not
    > maintained and severely outdated. If you would like to use
    > R from your browser, you can embed the following into a
    > web page:

    > <script
    > src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>
    > <div data-datacamp-exercise data-lang="r"></div>

    > Currently, it supports R 3.4.0. See the code base, which
    > is open source, here
    > https://github.com/datacamp/datacamp-light

    > Hope it helps.
    > Best, Mehmet

Yes, it does!
Thank you very much, Mehmet, for reaching out to get these
clarifications and reporting back here.

I'm glad to be notified that datacamp seems to adhere to an open source
philosophy also in the tools they write: For datacamp-light they
_do_ adhere (*) to the much more strict 
GNU Public Licence (GPL) Free Software standard which emphasizes not
only the free availability of source code, but also other
freedoms, e.g., to *modify* and re-distribute under the GPL, see
https://en.wikipedia.org/wiki/GPL for much more.

An open Github repos alone is _no_ guarantee for that, and
unfortunately I think there's much software there where authors
don't care (or don't want) to use a "truly" free software
licence such as
(*) https://github.com/datacamp/datacamp-light/blob/master/LICENSE.md

Best,
Martin Maechler


    > On 31 October 2017 at 15:09, Suzen, Mehmet
    > <msuzen at gmail.com> wrote:
    >> On 31 October 2017 at 12:42, Martin Maechler
    >> <maechler at stat.math.ethz.ch> wrote:
    >>> Notably as I think it's been provided by a company that
    >>> no longer exists under that name, and even if that'd be
    >>> wrong, R-Fiddle does not seem free software (apart from
    >>> the R parts, I hope !).
    >> 
    >> For the record, r-fiddle is maintained by datacamp:
    >> https://www.datacamp.com/community/blog/r-fiddle-an-online-playground-for-r-code-2


From ericjberger at gmail.com  Wed Nov  1 09:42:36 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 10:42:36 +0200
Subject: [R] beta binomial distribution installation
In-Reply-To: <AF36C32BE015CB48883C4A9F73CC8C3201BB979E86@DOHNSMXDB03.doh.health.nsw.gov.au>
References: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
 <AF36C32BE015CB48883C4A9F73CC8C3201BB979E86@DOHNSMXDB03.doh.health.nsw.gov.au>
Message-ID: <CAGgJW7521xe7dwvUhhaHYgP3YH6FrwcJ+sz3keSPdS6y4vEOcQ@mail.gmail.com>

Hi,
I did a quick search for other packages that provide the beta binomial
distribution and found "rmutil".

> install.packages("rmutil")

The package has the CDF (pbetabinom) and inverse CDF (qbetabinom) among
other functions.

HTH,
Eric



On Wed, Nov 1, 2017 at 7:50 AM, MCGUIRE, Rhydwyn <
rmcgu at doh.health.nsw.gov.au> wrote:

> Hi there,
>
> It looks like you also need the bioconductor package biobase, I found
> instructions for downloading that package here:
> www.bioconductor.org/install
>
> Good luck.
>
> Cheers,
> Rhydwyn
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Amany
> Abdel-Karim
> Sent: Wednesday, 1 November 2017 2:13 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] beta binomial distribution installation
>
> Hello,
>
> I  tried to install package TailRank using the command install.packages
> (RankTail) and library (TailRank) but I got the following errors. So, how
> can I install TaiRank in Rstudio to have se beta-binomial distribution, CDF
> and inverse CDG of  beta-binomal?
>
> The commands I used are:
>
> > install.packages("TailRank")
>
> Installing package into C:/Users/stator-guest/Documents/R/win-library/3.4
>
> (as lib is unspecified)
>
> Warning in install.packages :
>
>   dependency Biobase is not available
>
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/TailRank_
> 3.1.3.zip'
>
> Content type 'application/zip' length 331270 bytes (323 KB)
>
> downloaded 323 KB
>
>
>
> package TailRank successfully unpacked and MD5 sums checked
>
>
>
> The downloaded binary packages are in
>
>             C:\Users\stator-guest\AppData\Local\Temp\RtmpoVx40V\
> downloaded_packages
>
> > library(TailRank)
>
> Error: package or namespace load failed for TailRank in loadNamespace(i,
> c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>
>  there is no package called Biobase
>
> In addition: Warning message:
>
> package TailRank was built under R version 3.4.2
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ____________________________________________________________
> ______________________________________________
> This email has been scanned for the NSW Ministry of Health by the Websense
> Hosted Email Security System.
> Emails and attachments are monitored to ensure compliance with the NSW
> Ministry of health's Electronic Messaging Policy.
> ____________________________________________________________
> ______________________________________________
> ____________________________________________________________
> ___________________________________________
> Disclaimer: This message is intended for the addressee named and may
> contain confidential information.
> If you are not the intended recipient, please delete it and notify the
> sender.
> Views expressed in this message are those of the individual sender, and
> are not necessarily the views of the NSW Ministry of Health.
> ____________________________________________________________
> ___________________________________________
> This email has been scanned for the NSW Ministry of Health by the Websense
> Hosted Email Security System.
> Emails and attachments are monitored to ensure compliance with the NSW
> Ministry of Health's Electronic Messaging Policy.
> ____________________________________________________________
> ___________________________________________
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alkauffm at fastmail.fm  Wed Nov  1 13:11:49 2017
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Wed, 01 Nov 2017 13:11:49 +0100
Subject: [R] R-3.4.2: make check stops at line 698 of tests/reg-tests-1d.R
Message-ID: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>

Hi all,

after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
R-3.4.1 I never had a problem with these tests. No, the programm stops
at the following line of tests/reg-tests-1d.R:

> ## available.packages() (not) caching in case of errors
> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar")) 
    error in assertCondition(expr, "warning",
   .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
   available.packages(repo  ...: wanted warning

The error message is a result of:      ap2 <- available.packages(repos =
"http://foo.bar"),
not of the following condition in the test script:   stopifnot(nrow(ap1)
== 0, identical(ap1, ap2))  .

ap1 <- available.packages(repos = "http://foo.bar") works well, but the
following line stops the program.

After replacing "http://foo.bar" by "http://foo.poi" (every phrase
different from "bar" works well), reg-test-1d.R passed without error
message the interpreter.

Has someone an idea why the original program code stops (only) at line
698: 
tools::assertWarning(ap2 <- available.packages(repos =
"http://foo.bar"))?

With many thanks for every hint,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm


From Eric.Pueyo at avivainvestors.com  Wed Nov  1 13:31:08 2017
From: Eric.Pueyo at avivainvestors.com (Eric.Pueyo at avivainvestors.com)
Date: Wed, 1 Nov 2017 12:31:08 +0000
Subject: [R]  repeat a function
Message-ID: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>

I want to populate the matrix prb through the function HWMProb <- function (a,j,dt) that encapsulates different functions (please see code below), using j= 0:2 for each j.

It only populates prb if I specify each function independently in the global environment and then run the loop with the iF statement, as per below.
for (j in 0:2) {
  if (j==0) {
    prb["0","1"] <- ProbUP(a,j,dt)
    prb["0","0"] <- ProbMID(a,j,dt)
    prb["0","-1"] <- ProbDWN(a,j,dt)
  }
  else {
    if (j==jmax) {
      prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
      prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
      prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
      prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
      prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
      prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
    }
    else {
      prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
      prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
      prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
      prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
      prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
      prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
    } # Close 2nd IF
  } # Close 1st IF
}

Many thanks in advance.
Kind regards,

Eric Pueyo
Investment Risk Analyst
Email:  Eric.Pueyo at avivainvestors.com<mailto:Eric.Pueyo at avivainvestors.com>
D: +44 (0)20 7809 8070
No. 1 Undershaft, London EC3P 3DQ
Web: www.avivainvestors.com<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.avivainvestors.com_&d=CwMFAg&c=zUO0BtkCe66yJvAZ4cAvZg&r=-34SVFvqwmZvbxD0ShuYglbuijP84lygitjFgiP1fxI&m=kRg3I7ESFxV-KaNbYHN6DPupgyEmFCiThNO6oDnpAFs&s=tQa1EuXKNfzRgiR2HgG0H_tW_X-BCpgebe5AL9A_GC8&e=>

jmax<-2
prb <-matrix(0L,nrow=5, ncol=3)
rownames(prb) <- c(seq(-2,2, by = 1))
colnames(prb) <- c(-1,0,1)
a<- 0.1
dt<-1

ExpX <-function(x,a,dt) {                              ######Defines the Expectation of X on t+1 | t
ExpX <- x*exp(-a*dt)
ExpX
}
Mfactor<-function(a,dt)  {                           #######Factor multiplicative
  Mfactor<- exp(-a*dt)-1
  Mfactor
}
VarX <-function(sigma,a,dt) {                         #######Defubes the Variance of X on t+1 | t
  VarX <- (sigma^2/(2*a))*(1-exp(-2*a*dt))
  VarX
}
DeltaX <-function(sigma,a,dt) {                       ######Defines the change of X
  DeltaX<- sqrt(3*VarX(sigma,a,dt))
  DeltaX<-value(DeltaX)
}

Mfactor<-function(a,dt)  {                           #######Factor multiplicative
  Mfactor<- exp(-a*dt)-1
  Mfactor
}

KNode<-function(sigma,x,a,j,dt) {                    ######Central Node
  KNode<- round(ExpX(x,a,dt)/DeltaX(sigma,a,dt))
  KNode
}

####### Probability Calculations taking into account different branches
HWMProb <- function (a,j,dt) {
  ######################### DESCRIPTION #####################################
  ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a, dt)) / 2)                     ######### Probability X going up
  ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)                             ######## Probability X going middle
  ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a, dt)) / 2)                  #######  Probability X going down
  TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j * Mfactor(a, dt)) / 2                 ####### Top branch probability going up
  TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j * Mfactor(a, dt)              ####### Top branch probability going MID
  TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a, dt)) / 2               ####### Top branch probability going DOWN
  BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a, dt)) / 2           ####### Bottom branch probability going u
  BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j * Mfactor(a, dt)               ####### Bottom branch probability going MID
  BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j * Mfactor(a, dt)) / 2              ####### Bottom branch probability going DOWN

  if (j==0) {
    prb["0","1"] <- ProbUP(a,j,dt)
    prb["0","0"] <- ProbMID(a,j,dt)
    prb["0","-1"] <- ProbDWN(a,j,dt)
  }
  else {
    if (j==jmax) {
      prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
      prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
      prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
      prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
      prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
      prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
    }
    else {
      prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
      prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
      prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
      prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
     prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
      prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
    } # Close 2nd IF
  } # Close 1st IF
} #Close Formula

for (j in 0:2) {
  HWMProb(a,j,dt)

}


	[[alternative HTML version deleted]]


From galaxie2485 at yahoo.co.in  Wed Nov  1 12:32:46 2017
From: galaxie2485 at yahoo.co.in (Priya Arasu)
Date: Wed, 1 Nov 2017 11:32:46 +0000 (UTC)
Subject: [R] Function to save results
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
Message-ID: <1192929665.582943.1509535966471@mail.yahoo.com>

Hi,I want the results to be saved automatically in a output text file after the script has finished running.

I used the sink function in the following example, but the results file (output.txt) was empty.

net <- loadNetwork("C://Users//Priya//Desktop//Attractor analysis_all genes//synaptogenesis//regulationof_dopamine_signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors
attr <- sink("C://Users//Priya//Desktop//Attractor analysis_all genes//synaptogenesis//output.txt")# used the sink function to save the results from attr function

attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors
Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?

Thank youPriya



	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  1 14:24:26 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 15:24:26 +0200
Subject: [R] Function to save results
In-Reply-To: <1192929665.582943.1509535966471@mail.yahoo.com>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
Message-ID: <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>

Some comments:
1. sink() does not return a value. There is on point to set attr <-
sink(...). Just give the command sink("C://....etc")
2. to complete the saving to the file you must give a second sink command
with no argument:  sink()
So your code would be (pseudo-code, not actual code)

sink( "filename" )
do something that prints output which will be captured by sink
sink()

HTH,
Eric



On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org
> wrote:

> Hi,I want the results to be saved automatically in a output text file
> after the script has finished running.
>
> I used the sink function in the following example, but the results file
> (output.txt) was empty.
>
> net <- loadNetwork("C://Users//Priya//Desktop//Attractor analysis_all
> genes//synaptogenesis//regulationof_dopamine_signaling_submodule3.txt")#
> First I loaded theinput file for which I want to identify attractors
> attr <- sink("C://Users//Priya//Desktop//Attractor analysis_all
> genes//synaptogenesis//output.txt")# used the sink function to save the
> results from attr function
>
> attr <- getAttractors(net, type="asynchronous")# then ran the script for
> identifying attractors
> Is there any function to save the results before setting the script to
> run, so that results are automatically saved in a text file after the
> script has finished running?
>
> Thank youPriya
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  1 15:23:22 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 16:23:22 +0200
Subject: [R] Function to save results
In-Reply-To: <691851277.669264.1509545458197@mail.yahoo.com>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
 <691851277.669264.1509545458197@mail.yahoo.com>
Message-ID: <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>

Hi Priya,

You did not follow the logic of the pseudo-code.
The sink("filename"), sink() pair captures whatever output is generated
between the first sink statement and the second sink statement.
You need (possibly) to do:

sink("C://Users//Priya//Desktop//Attractor analysis_all
genes//synaptogenesis//attr.txt")


net <- loadNetwork("C://Users//Priya//Desktop//Attractor analysis_all
genes//synaptogenesis//regulationof_dopamine_signaling_submodule3.txt")

attr <- getAttractors(net, type="asynchronous")


sink()


HTH,

Eric






On Wed, Nov 1, 2017 at 4:10 PM, Priya Arasu <galaxie2485 at yahoo.co.in> wrote:

> Hi Eric,
> I tried as you suggested but I could not find the output in the text file
> I created (attr.txt)
>
> net <- loadNetwork("C://Users//Priya//Desktop//Attractor analysis_all genes//synaptogenesis//regulationof_dopamine_signaling_submodule3.txt")
>
> sink("C://Users//Priya//Desktop//Attractor analysis_all genes//synaptogenesis//attr.txt")
>
>
> sink()
>
> attr <- getAttractors(net, type="asynchronous")
>
>
> Priya
>
>
> On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com>
> wrote:
>
>
> Some comments:
> 1. sink() does not return a value. There is on point to set attr <-
> sink(...). Just give the command sink("C://....etc")
> 2. to complete the saving to the file you must give a second sink command
> with no argument:  sink()
> So your code would be (pseudo-code, not actual code)
>
> sink( "filename" )
> do something that prints output which will be captured by sink
> sink()
>
> HTH,
> Eric
>
>
>
> On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <
> r-help at r-project.org> wrote:
>
> Hi,I want the results to be saved automatically in a output text file
> after the script has finished running.
>
> I used the sink function in the following example, but the results file
> (output.txt) was empty.
>
> net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all
> genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")#
> First I loaded theinput file for which I want to identify attractors
> attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all
> genes//synaptogenesis//output. txt")# used the sink function to save the
> results from attr function
>
> attr <- getAttractors(net, type="asynchronous")# then ran the script for
> identifying attractors
> Is there any function to save the results before setting the script to
> run, so that results are automatically saved in a text file after the
> script has finished running?
>
> Thank youPriya
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Wed Nov  1 15:30:03 2017
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Wed, 1 Nov 2017 14:30:03 +0000 (GMT)
Subject: [R] Data invisible to read.csv
Message-ID: <1339376573.270777.1509546603977.JavaMail.open-xchange@oxbe8.tb.ukmail.iss.as9143.net>

Hello   This relates to trying to upload csv files to R.  Essentially I have
some v large csv files, but in the column where the dates are appears the column
entry "00:00.0" for every line.  But in the formula bar appears a date as well,
for example "01/04/09 00:00.0", and this never appears in the main body of the
document

It's the dates I need but they seem to be invisible to the read.csv function by
which I'm uploading - that works, but simply gives "00:00.0" and not the date
bit.  I've never seen this before.  Does anyone know what's going on and how I
can get to the date string?

Thanks, Nick Wray
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Nov  1 15:50:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 01 Nov 2017 07:50:03 -0700
Subject: [R] Data invisible to read.csv
In-Reply-To: <1339376573.270777.1509546603977.JavaMail.open-xchange@oxbe8.tb.ukmail.iss.as9143.net>
References: <1339376573.270777.1509546603977.JavaMail.open-xchange@oxbe8.tb.ukmail.iss.as9143.net>
Message-ID: <C9F640B8-D19F-4861-8D5D-3A74AB0C8784@dcn.davis.ca.us>

You are using terms and concepts that apply to spreadsheets, but do not apply to R or CSV files. Please conform to the Posting Guide and make a reproducible example [1][2][3] using R code to demonstrate your problem. I suspect you will find that your problem begins in your spreadsheet and not in R or the CSV file, but if not then the example will help us help you. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

-- 
Sent from my phone. Please excuse my brevity.

On November 1, 2017 7:30:03 AM PDT, WRAY NICHOLAS via R-help <r-help at r-project.org> wrote:
>Hello   This relates to trying to upload csv files to R.  Essentially I
>have
>some v large csv files, but in the column where the dates are appears
>the column
>entry "00:00.0" for every line.  But in the formula bar appears a date
>as well,
>for example "01/04/09 00:00.0", and this never appears in the main body
>of the
>document
>
>It's the dates I need but they seem to be invisible to the read.csv
>function by
>which I'm uploading - that works, but simply gives "00:00.0" and not
>the date
>bit.  I've never seen this before.  Does anyone know what's going on
>and how I
>can get to the date string?
>
>Thanks, Nick Wray
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ebs15242 at gmail.com  Wed Nov  1 15:54:30 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Wed, 1 Nov 2017 09:54:30 -0500
Subject: [R] googlesheets gs_reshape_cellfeed()
Message-ID: <CALRb-ofpPU8YtYC97r90gSeFUGoq_pu9M9qsGcT2mFbtKtqO2w@mail.gmail.com>

I have a google spreadsheet with a column of hyperlinks I want the URL from.
The googlesheets package can return this information with gs_read_cellfeed(),
but it needs to be reshaped with gs_reshape_cellfeed().  Problem is,
gs_reshape_cellfeed() returns the 'value' of the cells, not the
'input_value' making
it exactly like gs_read().

How do I extract input_value from a cell feed in a convenient format? I want a
data frame that looks exactly like the output of gs_read(), except returning
'input_value' instead of 'value'.


From murdoch.duncan at gmail.com  Wed Nov  1 16:17:51 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 1 Nov 2017 11:17:51 -0400
Subject: [R] R-3.4.2: make check stops at line 698 of
	tests/reg-tests-1d.R
In-Reply-To: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
Message-ID: <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>

On 01/11/2017 8:11 AM, Albrecht Kauffmann wrote:
> Hi all,
> 
> after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
> R-3.4.1 I never had a problem with these tests. No, the programm stops
> at the following line of tests/reg-tests-1d.R:
> 
>> ## available.packages() (not) caching in case of errors
>> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
>> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
>      error in assertCondition(expr, "warning",
>     .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
>     available.packages(repo  ...: wanted warning
> 
> The error message is a result of:      ap2 <- available.packages(repos =
> "http://foo.bar"),
> not of the following condition in the test script:   stopifnot(nrow(ap1)
> == 0, identical(ap1, ap2))  .

What error message did you see?

> 
> ap1 <- available.packages(repos = "http://foo.bar") works well, but the
> following line stops the program.
> 
> After replacing "http://foo.bar" by "http://foo.poi" (every phrase
> different from "bar" works well), reg-test-1d.R passed without error
> message the interpreter.
> 
> Has someone an idea why the original program code stops (only) at line
> 698:
> tools::assertWarning(ap2 <- available.packages(repos =
> "http://foo.bar"))?
> 


Perhaps your system is resolving foo.bar to a web address.  If I use a 
URL for a web page that doesn't have a repository, I still get a 
warning, but the text of the error may explain why you don't.

Duncan Murdoch


From galaxie2485 at yahoo.co.in  Wed Nov  1 15:10:58 2017
From: galaxie2485 at yahoo.co.in (Priya Arasu)
Date: Wed, 1 Nov 2017 14:10:58 +0000 (UTC)
Subject: [R] Function to save results
In-Reply-To: <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
Message-ID: <691851277.669264.1509545458197@mail.yahoo.com>

Hi Eric,I tried as you suggested but I could not find the output in the text file I created (attr.txt)

net <- loadNetwork("C://Users//Priya//Desktop//Attractor analysis_all genes//synaptogenesis//regulationof_dopamine_signaling_submodule3.txt")sink("C://Users//Priya//Desktop//Attractor analysis_all genes//synaptogenesis//attr.txt")


sink()

attr <- getAttractors(net, type="asynchronous")
?Priya
 

    On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com> wrote:
 

 Some comments:1. sink() does not return a value. There is on point to set attr <- sink(...). Just give the command sink("C://....etc")2. to complete the saving to the file you must give a second sink command with no argument:? sink()So your code would be (pseudo-code, not actual code)
sink( "filename" )do something that prints output which will be captured by sinksink()
HTH,Eric


On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org> wrote:

Hi,I want the results to be saved automatically in a output text file after the script has finished running.

I used the sink function in the following example, but the results file (output.txt) was empty.

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors
attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//output. txt")# used the sink function to save the results from attr function

attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors
Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?

Thank youPriya



? ? ? ? [[alternative HTML version deleted]]

______________________________ ________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/ listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




   
	[[alternative HTML version deleted]]


From galaxie2485 at yahoo.co.in  Wed Nov  1 15:56:40 2017
From: galaxie2485 at yahoo.co.in (Priya Arasu)
Date: Wed, 1 Nov 2017 14:56:40 +0000 (UTC)
Subject: [R] Function to save results
In-Reply-To: <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
 <691851277.669264.1509545458197@mail.yahoo.com>
 <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>
Message-ID: <924053227.693026.1509548200479@mail.yahoo.com>

Hi Eric,Thanks for the explanation. Is there a way to save the results automatically after the analysis gets over?. As I recently lost the results, because I didn't save the results. I don't want to run the sink or save command after the analysis is over rather run the command for saving the file before starting to run the analysis, so the file gets saved automatically after the script has finished running
Priya
?


    On Wednesday, 1 November 2017 7:53 PM, Eric Berger <ericjberger at gmail.com> wrote:
 

 Hi Priya,
You did not follow the logic of the pseudo-code.?The sink("filename"), sink() pair captures whatever output is generated between the first sink statement and the second sink statement.You need (possibly) to do:
sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")
net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")attr <- getAttractors(net, type="asynchronous")
sink()
HTH,Eric


?
On Wed, Nov 1, 2017 at 4:10 PM, Priya Arasu <galaxie2485 at yahoo.co.in> wrote:

Hi Eric,I tried as you suggested but I could not find the output in the text file I created (attr.txt)

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")


sink()

attr <- getAttractors(net, type="asynchronous")
?Priya
 

    On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com> wrote:
 

 Some comments:1. sink() does not return a value. There is on point to set attr <- sink(...). Just give the command sink("C://....etc")2. to complete the saving to the file you must give a second sink command with no argument:? sink()So your code would be (pseudo-code, not actual code)
sink( "filename" )do something that prints output which will be captured by sinksink()
HTH,Eric


On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org> wrote:

Hi,I want the results to be saved automatically in a output text file after the script has finished running.

I used the sink function in the following example, but the results file (output.txt) was empty.

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors
attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//output. txt")# used the sink function to save the results from attr function

attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors
Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?

Thank youPriya



? ? ? ? [[alternative HTML version deleted]]

______________________________ ________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/ listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




   



   
	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Nov  1 16:45:56 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 01 Nov 2017 15:45:56 +0000
Subject: [R] Creating Tag
In-Reply-To: <CAJL6Qs_-rUjnbAmxrPYAd41K=E2uGi1F9kUZu_0c08g6duF_kg@mail.gmail.com>
References: <CAJL6Qs_-rUjnbAmxrPYAd41K=E2uGi1F9kUZu_0c08g6duF_kg@mail.gmail.com>
Message-ID: <CAKVAULM_+yZTKndJ5b_iki-t99s1wRyyTn92xMwrNzSjiVjOgw@mail.gmail.com>

Hi Hermant,

It sounds lile grep from base or str_detect from the Stringr package is
what you want.

Best,
Ulrik

Hemant Sain <hemantsain55 at gmail.com> schrieb am Mi., 1. Nov. 2017, 08:31:

> i want to tag categories to its menuname.
> i have a csv containing menu item name and in other csv i have a column
> containing some strings,
> i want to pick that strings from categories and look into  menu items if
> any menu item containing that string i want to create a new column next to
> menu item name flagged as 1 otherwise 0
> and the only condition is once a menu item flagged as 1 i don't need to
> consider that menu item again to tag further in case of redundant strings
> in categories only i want to search which are flagged as 0.
> please help me with the R script.
>
> *Menu Name*
> 9\ bobbie"
> 9\ chz steak"
> 9\ tuna"
> provolone
> 20\ bobbie"
> bottled soda 20oz
> cran-slam ww
> american
> small chips
> medium drink
> 9\ meatball"
> capriotti's water
> 20'' chicken cheese steak
> 9\ veg turkey"
> medium chips
> 9\ capastrami"
> 12\ bobbie"
> 12'' chicken cheese steak
> cookie
> 12\ chz steak"
> 9\ cole turkey"
> kid grilled cheese white
> 12\ italian"
> 12\ meatball"
> 12\ capastrami"
> turkey sand w
> 20\ slaw be jo"
> swiss
> 12\ cole turkey"
> large drink
> 9\ ham&chz"
> 9'' chicken cheese steak
> 9\ slaw be jo"
> turkey sand ww
> stuffing
> 12\ turkey"
> 9\ italian"
> 12\ slaw be jo"
> 9\ grld italian"
> 12\ veg burger w/chz"
> extra american
> black&bleu salad
> 9\ turkey"
> 20\ turkey"
> 20\ capastrami"
> ham sand w
> 12\ mushroom"
> 12\ grld italia"
> italian salad
> tuna sand ww
> 9\ roast beef"
> 20\ chz steak"
> 20\ mushroom"
> 9\ veg chzstk"
> ham
> genoa
> 12\ veg turkey"
> 12\ veggie cole turkey"
> 9\ mushroom"
> cap's creation
> mushrooms
> salad chicken
> 20\ cole turkey"
> 1 pack chicken
> kr  veg burger w/chz
> 12\ roast beef"
> kid turkey n cheese white
> 20\ italian"
> 12\ ham&chz"
> 9\ employee sub"
> roast beef kr
> 9\ veggie cole turkey"
> 12\ sausage"
> tea
> turkey sand kr
> salad turkey
> tuna sand kr
> brownie
> slice american cheese
> 1 oz pastrami
> 9\ cheese"
> 12\ italian up"
> 12\ capastrami up"
> 1 pack steak
> delaware's finest small
> the sampler sm
> side ranch dressing
> 12\ veg turkey up"
> 20\ roast beef"
> roast beef w
> 1oz turkey
> 12\ tuna"
> 20\ veg turkey"
> 12\ veg chzstk"
> 9\ sausage"
> kid ham n cheese white
> side italian dressing
> salad provolone
> 20\ grld italia"
> sample item 6
> sample item 9
> turkey
> 12\ slaw be jo up"
> 12\ meatball up"
> 1 oz roast beef
> ham sand ww
> delaware's finest large
> side cole slaw large
> large chips
> 20\ meatball"
> 12'' chick cheese stk up
> 12\ chz steak up"
> 12\ grld italia up"
> cran-slam w
> 12\ bobbie up"
> 20\ cheese"
> slice provolone
> the sampler lg
> meatball bar
> slice ham
> wise large chips
> small side
> sm soup
> 12\ tuna up"
> 12\ cole turkey up"
> prosciutini
> 20\ veggie cole turkey"
> soup
> roast beef
> 20\ italian up"
> 20'' chick cheese stk up
> 20\ chz steak up"
> 20\ bobbie up"
> 20\ veg turkey up"
> slice swiss
> 20\ capastrami up"
> sample item 7
> 12\ ham&chz up"
> salad swiss
> 12\ veggie cheese stk up"
> california omelet
> orange juice
> exteme bac boy
> dinner salad
> chef salad
> 12\ turkey up"
> the big cheese
> combo it
> fries cmb
> sm pepsi
> km cheese burger
> #NAME?
> #NAME?
> kid grilled cheese wheat
> kids ham cheese white box
> calif. blt
> bacon turkey melt
> coffee
> 1-pc pancake
> fries
> tuna sand
> biscuits & gravy
> s-1/3 patty
> x avocado
> x chez
> s-bacon
> #NAME?
> xtra egg
> lg bev upcharge
> sm ice tea
> small soup
> roast beef ww
> salad tuna
> med pepsi
> 20\ veg chzstk up"
> day nm egg san
> s-chkn brest
> bell pepper
> fruit
> 1 slice veggie turkey
> s-toast
> x sausage
> 1 pack sausage
> chicken salad
> lg pepsi
> x dressing
> large side
> 9\ firecracker turkey"
> 20\ sausage up"
> 20\ turkey up"
> 20\ veg chzstk"
> lg ice tea
> 12\ roast beef up"
> sample item 8
> catering cap creation sal
> the turkey lover sm
> little italy sm
> cookie tray
> sd chk avo san
> sm fry / 2 pc zucch
> kid turkey n cheese wheat
> junior chz burger
> extra italian meat
> chili chz fries
> sm fry / 2 pc o ring
> extra turkey
>
>
>
>
>
>
>
>
> *CATEGORIES*
> non-veg
> chix
> salmon
> ch
> chkn
> brisket
> brskt
> bacon
> bcn
> chse
> mahi
> dog
> shk
> clam
> parmesan
> asiago
> prosciutto
> prosciutti
> salami
> Angus
> hicken
> chk
> chick
> wings
> prk
> pork
> ham
> bacon
> ribs
> fish
> shrimp
> tuna
> beef
> steak
> stk
> meatball
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Nov  1 17:02:07 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 1 Nov 2017 16:02:07 +0000
Subject: [R] Function to save results
In-Reply-To: <924053227.693026.1509548200479@mail.yahoo.com>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
 <691851277.669264.1509545458197@mail.yahoo.com>
 <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>
 <924053227.693026.1509548200479@mail.yahoo.com>
Message-ID: <692b7f8e75db4df4aba8bfb0fbba84d4@exch-2p-mbx-w2.ads.tamu.edu>

Let's try a simple example. 

> # Create a script file of commands
> # Note we must print the results of quantile explicitly
> cat("x <- rnorm(50)\nprint(quantile(x))\nstem(x)\n", file="Test.R")
> 
> # Test it by running it to the console
> source("Test.R")
        0%        25%        50%        75%       100% 
-2.4736219 -0.7915433 -0.1178056  0.7023577  2.9158617 

  The decimal point is at the |

  -2 | 510
  -1 | 7631110
  -0 | 9988777333333211
   0 | 01124455557777889
   1 | 00045
   2 | 19

> 
> # Now run it and save the file
> sink("Testout.txt")
> source("Test.R")
> sink()
> 
> # What is located in "Testout.txt"?
> cat(readLines("Testout.txt"), sep="\n")
         0%         25%         50%         75%        100% 
-2.47511893 -0.47919111  0.05761628  0.67403447  1.79825459 

  The decimal point is at the |

  -2 | 5
  -2 | 4
  -1 | 
  -1 | 432000
  -0 | 87755
  -0 | 4433332110
   0 | 001244
   0 | 55666667777789
   1 | 113
   1 | 5788

> # Success

Depending on your operating system, you may also be able to save the output with File | Save to File.

---------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Priya Arasu via R-help
Sent: Wednesday, November 1, 2017 9:57 AM
To: Eric Berger <ericjberger at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Function to save results

Hi Eric,Thanks for the explanation. Is there a way to save the results automatically after the analysis gets over?. As I recently lost the results, because I didn't save the results. I don't want to run the sink or save command after the analysis is over rather run the command for saving the file before starting to run the analysis, so the file gets saved automatically after the script has finished running Priya
?


    On Wednesday, 1 November 2017 7:53 PM, Eric Berger <ericjberger at gmail.com> wrote:
 

 Hi Priya,
You did not follow the logic of the pseudo-code.?The sink("filename"), sink() pair captures whatever output is generated between the first sink statement and the second sink statement.You need (possibly) to do:
sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt") net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")attr <- getAttractors(net, type="asynchronous")
sink()
HTH,Eric


?
On Wed, Nov 1, 2017 at 4:10 PM, Priya Arasu <galaxie2485 at yahoo.co.in> wrote:

Hi Eric,I tried as you suggested but I could not find the output in the text file I created (attr.txt)

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")


sink()

attr <- getAttractors(net, type="asynchronous")
?Priya
 

    On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com> wrote:
 

 Some comments:1. sink() does not return a value. There is on point to set attr <- sink(...). Just give the command sink("C://....etc")2. to complete the saving to the file you must give a second sink command with no argument:? sink()So your code would be (pseudo-code, not actual code) sink( "filename" )do something that prints output which will be captured by sinksink() HTH,Eric


On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org> wrote:

Hi,I want the results to be saved automatically in a output text file after the script has finished running.

I used the sink function in the following example, but the results file (output.txt) was empty.

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//output. txt")# used the sink function to save the results from attr function

attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?

Thank youPriya



? ? ? ? [[alternative HTML version deleted]]

______________________________ ________________ R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/ listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html and provide commented, minimal, self-contained, reproducible code.




   



   
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From alkauffm at fastmail.fm  Wed Nov  1 17:02:53 2017
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Wed, 01 Nov 2017 17:02:53 +0100
Subject: [R] R-3.4.2: make check stops at line 698 of
	tests/reg-tests-1d.R
In-Reply-To: <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
 <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
Message-ID: <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>

Dear Duncan,

Many thanks!

Am Mi, 1. Nov 2017, um 16:17, schrieb Duncan Murdoch:
> On 01/11/2017 8:11 AM, Albrecht Kauffmann wrote:
> > Hi all,
> > 
> > after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
> > R-3.4.1 I never had a problem with these tests. No, the programm stops
> > at the following line of tests/reg-tests-1d.R:
> > 
> >> ## available.packages() (not) caching in case of errors
> >> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
> >> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
> >      error in assertCondition(expr, "warning",
> >     .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
> >     available.packages(repo  ...: wanted warning
> > 
> > The error message is a result of:      ap2 <- available.packages(repos =
> > "http://foo.bar"),
> > not of the following condition in the test script:   stopifnot(nrow(ap1)
> > == 0, identical(ap1, ap2))  .
> 
> What error message did you see?

after: R --vanilla <../R-3.4.2/tests/reg-tests-1d.R

I get 

...
> ## available.packages() (not) caching in case of errors
> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
   Error in assertCondition(expr, "warning", .exprString = d.expr) : 
     Got simpleError during evaluating of ap2 <- available.packages(repo
      ...: wanted warning
     Calls: <Anonymous> -> assertCondition
     Evaluation stopped


> 
> > 
> > ap1 <- available.packages(repos = "http://foo.bar") works well, but the
> > following line stops the program.
> > 
> > After replacing "http://foo.bar" by "http://foo.poi" (every phrase
> > different from "bar" works well), reg-test-1d.R passed without error
> > message the interpreter.
> > 
> > Has someone an idea why the original program code stops (only) at line
> > 698:
> > tools::assertWarning(ap2 <- available.packages(repos =
> > "http://foo.bar"))?
> > 
> 
> 
> Perhaps your system is resolving foo.bar to a web address.  If I use a 
> URL for a web page that doesn't have a repository, I still get a 
> warning, but the text of the error may explain why you don't.

There was a message, maybe a warning, but I don't understand it. Now I
installed R-3.4.2 also on another PC; there it works fine. Do you have
an idea, what went wrong here?

Albrecht Kauffmann

> 
> Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Nov  1 17:40:48 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 1 Nov 2017 12:40:48 -0400
Subject: [R] R-3.4.2: make check stops at line 698 of
	tests/reg-tests-1d.R
In-Reply-To: <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
 <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
 <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>
Message-ID: <471d1fe1-f176-ad30-877a-8d59916c50ef@gmail.com>

On 01/11/2017 12:02 PM, Albrecht Kauffmann wrote:
> Dear Duncan,
> 
> Many thanks!
> 
> Am Mi, 1. Nov 2017, um 16:17, schrieb Duncan Murdoch:
>> On 01/11/2017 8:11 AM, Albrecht Kauffmann wrote:
>>> Hi all,
>>>
>>> after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
>>> R-3.4.1 I never had a problem with these tests. No, the programm stops
>>> at the following line of tests/reg-tests-1d.R:
>>>
>>>> ## available.packages() (not) caching in case of errors
>>>> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
>>>> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
>>>       error in assertCondition(expr, "warning",
>>>      .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
>>>      available.packages(repo  ...: wanted warning
>>>
>>> The error message is a result of:      ap2 <- available.packages(repos =
>>> "http://foo.bar"),
>>> not of the following condition in the test script:   stopifnot(nrow(ap1)
>>> == 0, identical(ap1, ap2))  .
>>
>> What error message did you see?
> 
> after: R --vanilla <../R-3.4.2/tests/reg-tests-1d.R

Sorry, I wasn't clear.  I meant to ask what error message you get if you 
run the command that's supposed to generate a warning, i.e. run the code

ap1 <- available.packages(repos = "http://foo.bar")
ap2 <- available.packages(repos = "http://foo.bar")

and you'll likely see a warning on the first line, and an error on the 
second.  The text of that error may be informative.

Duncan Murdoch

> 
> I get
> 
> ...
>> ## available.packages() (not) caching in case of errors
>> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
>> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
>     Error in assertCondition(expr, "warning", .exprString = d.expr) :
>       Got simpleError during evaluating of ap2 <- available.packages(repo
>        ...: wanted warning
>       Calls: <Anonymous> -> assertCondition
>       Evaluation stopped
> 
> 
>>
>>>
>>> ap1 <- available.packages(repos = "http://foo.bar") works well, but the
>>> following line stops the program.
>>>
>>> After replacing "http://foo.bar" by "http://foo.poi" (every phrase
>>> different from "bar" works well), reg-test-1d.R passed without error
>>> message the interpreter.
>>>
>>> Has someone an idea why the original program code stops (only) at line
>>> 698:
>>> tools::assertWarning(ap2 <- available.packages(repos =
>>> "http://foo.bar"))?
>>>
>>
>>
>> Perhaps your system is resolving foo.bar to a web address.  If I use a
>> URL for a web page that doesn't have a repository, I still get a
>> warning, but the text of the error may explain why you don't.
> 
> There was a message, maybe a warning, but I don't understand it. Now I
> installed R-3.4.2 also on another PC; there it works fine. Do you have
> an idea, what went wrong here?
> 
> Albrecht Kauffmann
> 
>>
>> Duncan Murdoch


From ABDELKARIM2 at msn.com  Wed Nov  1 17:09:31 2017
From: ABDELKARIM2 at msn.com (Amany Abdel-Karim)
Date: Wed, 1 Nov 2017 16:09:31 +0000
Subject: [R] beta binomial distribution installation
In-Reply-To: <CAGgJW7521xe7dwvUhhaHYgP3YH6FrwcJ+sz3keSPdS6y4vEOcQ@mail.gmail.com>
References: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
 <AF36C32BE015CB48883C4A9F73CC8C3201BB979E86@DOHNSMXDB03.doh.health.nsw.gov.au>,
 <CAGgJW7521xe7dwvUhhaHYgP3YH6FrwcJ+sz3keSPdS6y4vEOcQ@mail.gmail.com>
Message-ID: <SN1PR0101MB16141709F932542AACE7CC50E55F0@SN1PR0101MB1614.prod.exchangelabs.com>

Hello,

Thank you for your response. I need to install RankTail package since it contains the beta binomial distribution, CDF and inverse CDF in the usual form which I need to use. However rmutil package contain unusual forms for these functions. So it is easier for me to deal with the forms are contained in RankTail.

I tried to install  bioconductor package, using the following commands but I still got the following errors:


 (1) I tried biocLite() and then library ("TailRank"), I got the following errors.

> biocLite()
Error in biocLite() : could not find function "biocLite"
> library("TailRank")
Loading required package: oompaBase
Error: package or namespace load failed for ?TailRank? in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 there is no package called ?Biobase?
In addition: Warning messages:
1: package ?TailRank? was built under R version 3.4.2
2: package ?oompaBase? was built under R version 3.4.2



(2) I tried to write the command biocLite(), then biocLite("TailRank"), I got the following errors:

> biocLite()
Error in biocLite() : could not find function "biocLite"
> biocLite("ilRank")
Error in biocLite("ilRank") : could not find function "biocLite"
> biocLite()
Error in biocLite() : could not find function "biocLite"
> biocLite("TailRank")
Error in biocLite("TailRank") : could not find function "biocLite"




>




Also, I checked under packages on the right side of the R window and I found TailRank , Description is Tail-Rank statistic, and version is 3.1.3. So, I tried to write the following code in the console window to check if the package works:

> N<-20
> u<-3
> v<-10
> p<-u/u+v
> x<-0:N

> yy<-dbb(x,N,u,v)


I got the following error:
Error in dbb(x, N, u, v) : could not find function "dbb"




>



I am confused because if the package TailRank is already there, why the pervious code does not work to calculate dbb (x,N,u,v) and I got error? If I do not have the package, would you please let me know the right commands I should write in the script window to install TaiRank because the commands I used (which I mentioned at the beginning of the email did not work and gave errors). I appreciate your help since I am a new user of R.


Amany



________________________________

From: Eric Berger <ericjberger at gmail.com>
Sent: Wednesday, November 1, 2017 2:42 AM
To: MCGUIRE, Rhydwyn
Cc: Amany Abdel-Karim; R-help at stat.math.ethz.ch
Subject: Re: [R] beta binomial distribution installation

Hi,
I did a quick search for other packages that provide the beta binomial distribution and found "rmutil".

> install.packages("rmutil")

The package has the CDF (pbetabinom) and inverse CDF (qbetabinom) among other functions.

HTH,
Eric



On Wed, Nov 1, 2017 at 7:50 AM, MCGUIRE, Rhydwyn <rmcgu at doh.health.nsw.gov.au<mailto:rmcgu at doh.health.nsw.gov.au>> wrote:
Hi there,

It looks like you also need the bioconductor package biobase, I found instructions for downloading that package here: www.bioconductor.org/install<http://www.bioconductor.org/install>

Good luck.

Cheers,
Rhydwyn

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Amany Abdel-Karim
Sent: Wednesday, 1 November 2017 2:13 PM
To: R-help at stat.math.ethz.ch<mailto:R-help at stat.math.ethz.ch>
Subject: [R] beta binomial distribution installation

Hello,

I  tried to install package TailRank using the command install.packages (RankTail) and library (TailRank) but I got the following errors. So, how can I install TaiRank in Rstudio to have se beta-binomial distribution, CDF and inverse CDG of  beta-binomal?

The commands I used are:

> install.packages("TailRank")

Installing package into C:/Users/stator-guest/Documents/R/win-library/3.4

(as lib is unspecified)

Warning in install.packages :

  dependency Biobase is not available

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/TailRank_3.1.3.zip'

Content type 'application/zip' length 331270 bytes (323 KB)

downloaded 323 KB



package TailRank successfully unpacked and MD5 sums checked



The downloaded binary packages are in

            C:\Users\stator-guest\AppData\Local\Temp\RtmpoVx40V\downloaded_packages

> library(TailRank)

Error: package or namespace load failed for TailRank in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):

 there is no package called Biobase

In addition: Warning message:

package TailRank was built under R version 3.4.2




        [[alternative HTML version deleted]]

__________________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of health's Electronic Messaging Policy.
__________________________________________________________________________________________________________
_______________________________________________________________________________________________________
Disclaimer: This message is intended for the addressee named and may contain confidential information.
If you are not the intended recipient, please delete it and notify the sender.
Views expressed in this message are those of the individual sender, and are not necessarily the views of the NSW Ministry of Health.
_______________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
_______________________________________________________________________________________________________
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Wed Nov  1 17:13:42 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Wed, 1 Nov 2017 16:13:42 +0000 (UTC)
Subject: [R] Correct subsetting in R
References: <1626314739.772830.1509552822802.ref@mail.yahoo.com>
Message-ID: <1626314739.772830.1509552822802@mail.yahoo.com>

Hi all,
I have two data frames that one of them does not have the column ID:

    > str(data)
    'data.frame':	499 obs. of  608 variables:
    $ ID           : int  1 2 3 4 5 6 7 8 9 10 ...
    $ alright      : int  1 0 0 0 0 0 0 1 2 1 ...
    $ bad          : int  1 0 0 0 0 0 0 0 0 0 ...
    $ boy          : int  1 2 1 1 0 2 2 4 2 1 ...
    $ cooki        : int  1 2 2 1 0 1 1 4 2 3 ...
    $ curtain      : int  1 0 0 0 0 2 0 2 0 0 ...
    $ dish         : int  2 1 0 1 0 0 1 2 2 2 ...
    $ doesnt       : int  1 0 0 0 0 0 0 0 1 0 ...
    $ dont         : int  2 1 4 2 0 0 2 1 2 0 ...
    $ fall         : int  3 1 0 0 1 0 1 2 3 2 ...
    $ fell         : int  1 0 0 0 0 0 0 0 0 0 ...

and the other one is:

    > str(training)
    'data.frame':	375 obs. of  607 variables:
    $ alright      : num  1 0 0 0 1 2 1 0 0 0 ...
    $ bad          : num  1 0 0 0 0 0 0 0 0 0 ...
    $ boy          : num  1 1 2 2 4 2 1 0 1 0 ...
    $ cooki        : num  1 1 1 1 4 2 3 1 2 2 ...
    $ curtain      : num  1 0 2 0 2 0 0 0 0 0 ...
    $ dish         : num  2 1 0 1 2 2 2 1 4 1 ...
    $ doesnt       : num  1 0 0 0 0 1 0 0 0 0 ...
    $ dont         : num  2 2 0 2 1 2 0 0 1 0 ...
    $ fall         : num  3 0 0 1 2 3 2 0 2 0 ...
    $ fell         : num  1 0 0 0 0 0 0 0 0 0 ...
Does anyone know how should I get the IDs of training from data?
thanks for any help!
Elahe


From alkauffm at fastmail.fm  Wed Nov  1 18:08:26 2017
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Wed, 01 Nov 2017 18:08:26 +0100
Subject: [R] R-3.4.2: make check stops at line 698 of
	tests/reg-tests-1d.R
In-Reply-To: <471d1fe1-f176-ad30-877a-8d59916c50ef@gmail.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
 <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
 <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>
 <471d1fe1-f176-ad30-877a-8d59916c50ef@gmail.com>
Message-ID: <1509556106.1495684.1158298960.54AEA5CF@webmail.messagingengine.com>

Am Mi, 1. Nov 2017, um 17:40, schrieb Duncan Murdoch:
> On 01/11/2017 12:02 PM, Albrecht Kauffmann wrote:
> > Dear Duncan,
> > 
> > Many thanks!
> > 
> > Am Mi, 1. Nov 2017, um 16:17, schrieb Duncan Murdoch:
> >> On 01/11/2017 8:11 AM, Albrecht Kauffmann wrote:
> >>> Hi all,
> >>>
> >>> after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
> >>> R-3.4.1 I never had a problem with these tests. No, the programm stops
> >>> at the following line of tests/reg-tests-1d.R:
> >>>
> >>>> ## available.packages() (not) caching in case of errors
> >>>> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
> >>>> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
> >>>       error in assertCondition(expr, "warning",
> >>>      .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
> >>>      available.packages(repo  ...: wanted warning
> >>>
> >>> The error message is a result of:      ap2 <- available.packages(repos =
> >>> "http://foo.bar"),
> >>> not of the following condition in the test script:   stopifnot(nrow(ap1)
> >>> == 0, identical(ap1, ap2))  .
> >>
> >> What error message did you see?
> > 
> > after: R --vanilla <../R-3.4.2/tests/reg-tests-1d.R
> 
> Sorry, I wasn't clear.  I meant to ask what error message you get if you 
> run the command that's supposed to generate a warning, i.e. run the code
> 
Oops! Here are the resulting error messages, which are not the same:
> ap1 <- available.packages(repos = "http://foo.bar")
Warning: Cannot access to the index of the repository
http://foo.bar/src/contrib:
  line beginning with '<!DOCTYPE html PUBLI ...' is incorrect formatted

> ap2 <- available.packages(repos = "http://foo.bar")
Error in readRDS(dest) : unknown input format

On my other PC, the same lines give 2 times the same error message:
"Warning: Cannot access to the index of the repository
http://foo.bar/src/contrib: Cannot open URL
'http://foo.bar/src/contrib/PACKAGES' "

Indeed, the second error message on the present PC is different. What
may be the cause?

Many thanks 
Albrecht

> 
> and you'll likely see a warning on the first line, and an error on the 
> second.  The text of that error may be informative.
> 
> Duncan Murdoch
> 
> > 
> > I get
> > 
> > ...
> >> ## available.packages() (not) caching in case of errors
> >> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
> >> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
> >     Error in assertCondition(expr, "warning", .exprString = d.expr) :
> >       Got simpleError during evaluating of ap2 <- available.packages(repo
> >        ...: wanted warning
> >       Calls: <Anonymous> -> assertCondition
> >       Evaluation stopped
> > 
> > 
> >>
> >>>
> >>> ap1 <- available.packages(repos = "http://foo.bar") works well, but the
> >>> following line stops the program.
> >>>
> >>> After replacing "http://foo.bar" by "http://foo.poi" (every phrase
> >>> different from "bar" works well), reg-test-1d.R passed without error
> >>> message the interpreter.
> >>>
> >>> Has someone an idea why the original program code stops (only) at line
> >>> 698:
> >>> tools::assertWarning(ap2 <- available.packages(repos =
> >>> "http://foo.bar"))?
> >>>
> >>
> >>
> >> Perhaps your system is resolving foo.bar to a web address.  If I use a
> >> URL for a web page that doesn't have a repository, I still get a
> >> warning, but the text of the error may explain why you don't.
> > 
> > There was a message, maybe a warning, but I don't understand it. Now I
> > installed R-3.4.2 also on another PC; there it works fine. Do you have
> > an idea, what went wrong here?
> > 
> > Albrecht Kauffmann
> > 
> >>
> >> Duncan Murdoch
>


From ericjberger at gmail.com  Wed Nov  1 18:09:24 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 19:09:24 +0200
Subject: [R] beta binomial distribution installation
In-Reply-To: <SN1PR0101MB16141709F932542AACE7CC50E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
References: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
 <AF36C32BE015CB48883C4A9F73CC8C3201BB979E86@DOHNSMXDB03.doh.health.nsw.gov.au>
 <CAGgJW7521xe7dwvUhhaHYgP3YH6FrwcJ+sz3keSPdS6y4vEOcQ@mail.gmail.com>
 <SN1PR0101MB16141709F932542AACE7CC50E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
Message-ID: <CAGgJW74Cr6=G4yHDt2aFP2cjhWXE-ApxGv9Hf83sshynXa3Weg@mail.gmail.com>

Hi Amany,
I had no trouble installing TailRank and bioconductor using the link Rhydwyn
 provided.
I was curious about your statement that TailRank uses a different
parameterization for the betabinomial distribution than rmutil.
I looked at the documentation for the two packages and the transformation
to go from one to the other is straightforward.
If you want, you can do the following.
Let (N,u,v) be the parameters used in TailRank and (N,m,s) the parameters
used in rmutil. The correspondence is:

N = N, m  = u/(u+v), s = u+v.

This means you can define functions such as:

mypbb <- function(x,N,u,v) { rmutil::pbetabinom(x,N,u/(u+v),u+v) }   # CDF
myqbb <- function(x,N,u,v) { rmutil:qbetabinom{x,N,u/(u+v),u+v) }  #
inverse CDF

HTH,
Eric





On Wed, Nov 1, 2017 at 6:09 PM, Amany Abdel-Karim <ABDELKARIM2 at msn.com>
wrote:

> Hello,
>
> Thank you for your response. I need to install RankTail package since it
> contains the beta binomial distribution, CDF and inverse CDF in the usual
> form which I need to use. However rmutil package contain unusual forms for
> these functions. So it is easier for me to deal with the forms are
> contained in RankTail.
>
> I tried to install  bioconductor package, using the following commands
> but I still got the following errors:
>
>
>  (1) I tried biocLite() and then library ("TailRank"), I got the following
> errors.
>
> > biocLite()Error in biocLite() : could not find function "biocLite"> library("TailRank")Loading required package: oompaBaseError: package or namespace load failed for ?TailRank? in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>  there is no package called ?Biobase?In addition: Warning messages:1: package ?TailRank? was built under R version 3.4.2 2: package ?oompaBase? was built under R version 3.4.2
>
>
> (2) I tried to write the command biocLite(), then biocLite("TailRank"), I got the following errors:
>
> > biocLite()Error in biocLite() : could not find function "biocLite"> biocLite("ilRank")Error in biocLite("ilRank") : could not find function "biocLite"> biocLite()Error in biocLite() : could not find function "biocLite"> biocLite("TailRank")Error in biocLite("TailRank") : could not find function "biocLite"
>
> >
>
>
> Also, I checked under packages on the right side of the R window and I
> found TailRank , Description is Tail-Rank statistic, and version is 3.1.3.
> So, I tried to write the following code in the console window to check if
> the package works:
>
> > N<-20> u<-3> v<-10> p<-u/u+v> x<-0:N
>
> > yy<-dbb(x,N,u,v)
>
>
> I got the following error:Error in dbb(x, N, u, v) : could not find function "dbb"
>
> >
>
> I am confused because if the package TailRank is already there, why the
> pervious code does not work to calculate dbb (x,N,u,v) and I got error? If
> I do not have the package, would you please let me know the right commands
> I should write in the script window to install TaiRank because the commands
> I used (which I mentioned at the beginning of the email did not work and
> gave errors). I appreciate your help since I am a new user of R.
>
>
> Amany
>
>
>
> ------------------------------
>
> *From:* Eric Berger <ericjberger at gmail.com>
> *Sent:* Wednesday, November 1, 2017 2:42 AM
> *To:* MCGUIRE, Rhydwyn
> *Cc:* Amany Abdel-Karim; R-help at stat.math.ethz.ch
> *Subject:* Re: [R] beta binomial distribution installation
>
> Hi,
> I did a quick search for other packages that provide the beta binomial
> distribution and found "rmutil".
>
> > install.packages("rmutil")
>
> The package has the CDF (pbetabinom) and inverse CDF (qbetabinom) among
> other functions.
>
> HTH,
> Eric
>
>
>
> On Wed, Nov 1, 2017 at 7:50 AM, MCGUIRE, Rhydwyn <
> rmcgu at doh.health.nsw.gov.au> wrote:
>
>> Hi there,
>>
>> It looks like you also need the bioconductor package biobase, I found
>> instructions for downloading that package here:
>> www.bioconductor.org/install
>>
>> Good luck.
>>
>> Cheers,
>> Rhydwyn
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Amany
>> Abdel-Karim
>> Sent: Wednesday, 1 November 2017 2:13 PM
>> To: R-help at stat.math.ethz.ch
>> Subject: [R] beta binomial distribution installation
>>
>> Hello,
>>
>> I  tried to install package TailRank using the command install.packages
>> (RankTail) and library (TailRank) but I got the following errors. So, how
>> can I install TaiRank in Rstudio to have se beta-binomial distribution, CDF
>> and inverse CDG of  beta-binomal?
>>
>> The commands I used are:
>>
>> > install.packages("TailRank")
>>
>> Installing package into C:/Users/stator-guest/Documents/R/win-library/3.4
>>
>> (as lib is unspecified)
>>
>> Warning in install.packages :
>>
>>   dependency Biobase is not available
>>
>> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/TailRank_3
>> .1.3.zip'
>>
>> Content type 'application/zip' length 331270 bytes (323 KB)
>>
>> downloaded 323 KB
>>
>>
>>
>> package TailRank successfully unpacked and MD5 sums checked
>>
>>
>>
>> The downloaded binary packages are in
>>
>>             C:\Users\stator-guest\AppData\Local\Temp\RtmpoVx40V\download
>> ed_packages
>>
>> > library(TailRank)
>>
>> Error: package or namespace load failed for TailRank in loadNamespace(i,
>> c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>>
>>  there is no package called Biobase
>>
>> In addition: Warning message:
>>
>> package TailRank was built under R version 3.4.2
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ____________________________________________________________
>> ______________________________________________
>> This email has been scanned for the NSW Ministry of Health by the
>> Websense Hosted Email Security System.
>> Emails and attachments are monitored to ensure compliance with the NSW
>> Ministry of health's Electronic Messaging Policy.
>> ____________________________________________________________
>> ______________________________________________
>> ____________________________________________________________
>> ___________________________________________
>> Disclaimer: This message is intended for the addressee named and may
>> contain confidential information.
>> If you are not the intended recipient, please delete it and notify the
>> sender.
>> Views expressed in this message are those of the individual sender, and
>> are not necessarily the views of the NSW Ministry of Health.
>> ____________________________________________________________
>> ___________________________________________
>> This email has been scanned for the NSW Ministry of Health by the
>> Websense Hosted Email Security System.
>> Emails and attachments are monitored to ensure compliance with the NSW
>> Ministry of Health's Electronic Messaging Policy.
>> ____________________________________________________________
>> ___________________________________________
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  1 18:18:19 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 19:18:19 +0200
Subject: [R] Correct subsetting in R
In-Reply-To: <1626314739.772830.1509552822802@mail.yahoo.com>
References: <1626314739.772830.1509552822802.ref@mail.yahoo.com>
 <1626314739.772830.1509552822802@mail.yahoo.com>
Message-ID: <CAGgJW76uKWq+RdO-xXvn9CpXvW5GC5esuiygCm5pPx+8nYy-ow@mail.gmail.com>

matches <- merge(training,data,by=intersect(names(training),names(data)))

HTH,
Eric


On Wed, Nov 1, 2017 at 6:13 PM, Elahe chalabi via R-help <
r-help at r-project.org> wrote:

> Hi all,
> I have two data frames that one of them does not have the column ID:
>
>     > str(data)
>     'data.frame':       499 obs. of  608 variables:
>     $ ID           : int  1 2 3 4 5 6 7 8 9 10 ...
>     $ alright      : int  1 0 0 0 0 0 0 1 2 1 ...
>     $ bad          : int  1 0 0 0 0 0 0 0 0 0 ...
>     $ boy          : int  1 2 1 1 0 2 2 4 2 1 ...
>     $ cooki        : int  1 2 2 1 0 1 1 4 2 3 ...
>     $ curtain      : int  1 0 0 0 0 2 0 2 0 0 ...
>     $ dish         : int  2 1 0 1 0 0 1 2 2 2 ...
>     $ doesnt       : int  1 0 0 0 0 0 0 0 1 0 ...
>     $ dont         : int  2 1 4 2 0 0 2 1 2 0 ...
>     $ fall         : int  3 1 0 0 1 0 1 2 3 2 ...
>     $ fell         : int  1 0 0 0 0 0 0 0 0 0 ...
>
> and the other one is:
>
>     > str(training)
>     'data.frame':       375 obs. of  607 variables:
>     $ alright      : num  1 0 0 0 1 2 1 0 0 0 ...
>     $ bad          : num  1 0 0 0 0 0 0 0 0 0 ...
>     $ boy          : num  1 1 2 2 4 2 1 0 1 0 ...
>     $ cooki        : num  1 1 1 1 4 2 3 1 2 2 ...
>     $ curtain      : num  1 0 2 0 2 0 0 0 0 0 ...
>     $ dish         : num  2 1 0 1 2 2 2 1 4 1 ...
>     $ doesnt       : num  1 0 0 0 0 1 0 0 0 0 ...
>     $ dont         : num  2 2 0 2 1 2 0 0 1 0 ...
>     $ fall         : num  3 0 0 1 2 3 2 0 2 0 ...
>     $ fell         : num  1 0 0 0 0 0 0 0 0 0 ...
> Does anyone know how should I get the IDs of training from data?
> thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  1 18:24:09 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 19:24:09 +0200
Subject: [R] Function to save results
In-Reply-To: <692b7f8e75db4df4aba8bfb0fbba84d4@exch-2p-mbx-w2.ads.tamu.edu>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
 <691851277.669264.1509545458197@mail.yahoo.com>
 <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>
 <924053227.693026.1509548200479@mail.yahoo.com>
 <692b7f8e75db4df4aba8bfb0fbba84d4@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAGgJW74TQRMDEzfzHKv8WpgNOoa9Vo2PWan1=jyDSw7gDbMXxg@mail.gmail.com>

Hi Priya,
I think your original question may have been phrased in a way that caused
David and me some confusion.
I think sink() may not be the function that is appropriate in your case.
Sink() is used to capture output to the console (so to speak).
You are trying to save the results of calculations returned, in this case
in the variable 'attr'.
You need to do something like:

attr <- getAttractors( ... )
saveRDS( attr, "filename.RDS")

and then later you can read the results back in another R session:

savedAttr <- readRDS("filename.RDS")

Look at the documentation ?saveRDS and ?readRDS

HTH,
Eric

On Wed, Nov 1, 2017 at 6:02 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Let's try a simple example.
>
> > # Create a script file of commands
> > # Note we must print the results of quantile explicitly
> > cat("x <- rnorm(50)\nprint(quantile(x))\nstem(x)\n", file="Test.R")
> >
> > # Test it by running it to the console
> > source("Test.R")
>         0%        25%        50%        75%       100%
> -2.4736219 -0.7915433 -0.1178056  0.7023577  2.9158617
>
>   The decimal point is at the |
>
>   -2 | 510
>   -1 | 7631110
>   -0 | 9988777333333211
>    0 | 01124455557777889
>    1 | 00045
>    2 | 19
>
> >
> > # Now run it and save the file
> > sink("Testout.txt")
> > source("Test.R")
> > sink()
> >
> > # What is located in "Testout.txt"?
> > cat(readLines("Testout.txt"), sep="\n")
>          0%         25%         50%         75%        100%
> -2.47511893 -0.47919111  0.05761628  0.67403447  1.79825459
>
>   The decimal point is at the |
>
>   -2 | 5
>   -2 | 4
>   -1 |
>   -1 | 432000
>   -0 | 87755
>   -0 | 4433332110
>    0 | 001244
>    0 | 55666667777789
>    1 | 113
>    1 | 5788
>
> > # Success
>
> Depending on your operating system, you may also be able to save the
> output with File | Save to File.
>
> ---------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Priya
> Arasu via R-help
> Sent: Wednesday, November 1, 2017 9:57 AM
> To: Eric Berger <ericjberger at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Function to save results
>
> Hi Eric,Thanks for the explanation. Is there a way to save the results
> automatically after the analysis gets over?. As I recently lost the
> results, because I didn't save the results. I don't want to run the sink or
> save command after the analysis is over rather run the command for saving
> the file before starting to run the analysis, so the file gets saved
> automatically after the script has finished running Priya
>
>
>
>     On Wednesday, 1 November 2017 7:53 PM, Eric Berger <
> ericjberger at gmail.com> wrote:
>
>
>  Hi Priya,
> You did not follow the logic of the pseudo-code. The sink("filename"),
> sink() pair captures whatever output is generated between the first sink
> statement and the second sink statement.You need (possibly) to do:
> sink("C://Users//Priya// Desktop//Attractor analysis_all
> genes//synaptogenesis//attr. txt") net <- loadNetwork("C://Users//Priya/
> /Desktop//Attractor analysis_all genes//synaptogenesis//
> regulationof_dopamine_ signaling_submodule3.txt")attr <- getAttractors(net,
> type="asynchronous")
> sink()
> HTH,Eric
>
>
>
> On Wed, Nov 1, 2017 at 4:10 PM, Priya Arasu <galaxie2485 at yahoo.co.in>
> wrote:
>
> Hi Eric,I tried as you suggested but I could not find the output in the
> text file I created (attr.txt)
>
> net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all
> genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")sink("C://Users//Priya//
> Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")
>
>
> sink()
>
> attr <- getAttractors(net, type="asynchronous")
>  Priya
>
>
>     On Wednesday, 1 November 2017 6:54 PM, Eric Berger <
> ericjberger at gmail.com> wrote:
>
>
>  Some comments:1. sink() does not return a value. There is on point to set
> attr <- sink(...). Just give the command sink("C://....etc")2. to complete
> the saving to the file you must give a second sink command with no
> argument:  sink()So your code would be (pseudo-code, not actual code) sink(
> "filename" )do something that prints output which will be captured by
> sinksink() HTH,Eric
>
>
> On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <
> r-help at r-project.org> wrote:
>
> Hi,I want the results to be saved automatically in a output text file
> after the script has finished running.
>
> I used the sink function in the following example, but the results file
> (output.txt) was empty.
>
> net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all
> genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")#
> First I loaded theinput file for which I want to identify attractors attr
> <- sink("C://Users//Priya// Desktop//Attractor analysis_all
> genes//synaptogenesis//output. txt")# used the sink function to save the
> results from attr function
>
> attr <- getAttractors(net, type="asynchronous")# then ran the script for
> identifying attractors Is there any function to save the results before
> setting the script to run, so that results are automatically saved in a
> text file after the script has finished running?
>
> Thank youPriya
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________ ________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/
> listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html and provide commented, minimal, self-contained,
> reproducible code.
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Nov  1 18:27:21 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 1 Nov 2017 17:27:21 +0000
Subject: [R] Function to save results
Message-ID: <b3c0719c-89ae-481c-8665-74816fa2e056@email.android.com>

No. You have not used it correctly. It was an example. Put your commands between the two sink functions. That will save any printed out put that results from those commands. It will not save attr, but you did not ask how to do that.

David C

On Nov 1, 2017 12:21 PM, Priya Arasu <galaxie2485 at yahoo.co.in> wrote:
Hi David,
Thank you for the example.
When I try to use the cat function, I get an error


cat(attr<-getAttractors(net, type="asynchronous"))

Error in cat(attr <- getAttractors(net, type = "asynchronous")) :
  argument 1 (type 'pairlist') cannot be handled by 'cat'

Please let me know, if I have used the function in right way?.
Thank you
Priya











On Wednesday, 1 November 2017 9:32 PM, David L Carlson <dcarlson at tamu.edu> wrote:


Let's try a simple example.

> # Create a script file of commands
> # Note we must print the results of quantile explicitly
> cat("x <- rnorm(50)\nprint(quantile(x))\nstem(x)\n", file="Test.R")
>
> # Test it by running it to the console
> source("Test.R")
        0%        25%        50%        75%      100%
-2.4736219 -0.7915433 -0.1178056  0.7023577  2.9158617

  The decimal point is at the |

  -2 | 510
  -1 | 7631110
  -0 | 9988777333333211
  0 | 01124455557777889
  1 | 00045
  2 | 19

>
> # Now run it and save the file
> sink("Testout.txt")
> source("Test.R")
> sink()
>
> # What is located in "Testout.txt"?
> cat(readLines("Testout.txt"), sep="\n")
        0%        25%        50%        75%        100%
-2.47511893 -0.47919111  0.05761628  0.67403447  1.79825459

  The decimal point is at the |

  -2 | 5
  -2 | 4
  -1 |
  -1 | 432000
  -0 | 87755
  -0 | 4433332110
  0 | 001244
  0 | 55666667777789
  1 | 113
  1 | 5788

> # Success

Depending on your operating system, you may also be able to save the output with File | Save to File.

---------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Priya Arasu via R-help
Sent: Wednesday, November 1, 2017 9:57 AM
To: Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>>
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Function to save results

Hi Eric,Thanks for the explanation. Is there a way to save the results automatically after the analysis gets over?. As I recently lost the results, because I didn't save the results. I don't want to run the sink or save command after the analysis is over rather run the command for saving the file before starting to run the analysis, so the file gets saved automatically after the script has finished running Priya



    On Wednesday, 1 November 2017 7:53 PM, Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>> wrote:


Hi Priya,
You did not follow the logic of the pseudo-code. The sink("filename"), sink() pair captures whatever output is generated between the first sink statement and the second sink statement.You need (possibly) to do:
sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt") net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")attr <- getAttractors(net, type="asynchronous")
sink()
HTH,Eric



On Wed, Nov 1, 2017 at 4:10 PM, Priya Arasu <galaxie2485 at yahoo.co.in<mailto:galaxie2485 at yahoo.co.in>> wrote:

Hi Eric,I tried as you suggested but I could not find the output in the text file I created (attr.txt)

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")


sink()

attr <- getAttractors(net, type="asynchronous")
 Priya


    On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>> wrote:


Some comments:1. sink() does not return a value. There is on point to set attr <- sink(...). Just give the command sink("C://....etc")2. to complete the saving to the file you must give a second sink command with no argument:  sink()So your code would be (pseudo-code, not actual code) sink( "filename" )do something that prints output which will be captured by sinksink() HTH,Eric


On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:

Hi,I want the results to be saved automatically in a output text file after the script has finished running.

I used the sink function in the following example, but the results file (output.txt) was empty.

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//output. txt")# used the sink function to save the results from attr function

attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?

Thank youPriya



        [[alternative HTML version deleted]]

______________________________ ________________ R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/ <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=0lwqkbol4cK6IWihnScmuGPoCwJqLAUtPYFjA8-ZvcE&s=CFc0GZ3acaXstJwZ-4_sa6VyWMYBAefLT8bl5XF5VtY&e=> listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/ <https://urldefense.proofpoint.com/v2/url?u=http-3A__www.r-2Dproject.org_&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=0lwqkbol4cK6IWihnScmuGPoCwJqLAUtPYFjA8-ZvcE&s=wcRmk52RCDGqEMXMWwXPSmoZZCePwhACPhEVr3JkZtc&e=> posting-guide.html and provide commented, minimal, self-contained, reproducible code.










    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=0lwqkbol4cK6IWihnScmuGPoCwJqLAUtPYFjA8-ZvcE&s=pFgUol7cBhhv83zYVjM7DgjhrD3_QSjy-FUEB4ZUH8E&e=>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.r-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=0lwqkbol4cK6IWihnScmuGPoCwJqLAUtPYFjA8-ZvcE&s=_tTiMicLMGdHIKg3A9nPOpCYxcm_zGZecdMMAxTu7i0&e=>
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Wed Nov  1 18:03:51 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Wed, 1 Nov 2017 17:03:51 +0000 (UTC)
Subject: [R] Correct subsetting in R
References: <1132433779.794722.1509555831950.ref@mail.yahoo.com>
Message-ID: <1132433779.794722.1509555831950@mail.yahoo.com>

But they row.names() cannot give me the IDs






On Wednesday, November 1, 2017 9:45 AM, David Wolfskill <r at catwhisker.org> wrote:



On Wed, Nov 01, 2017 at 04:13:42PM +0000, Elahe chalabi via R-help wrote:

> Hi all,
> I have two data frames that one of them does not have the column ID:
> 
>     > str(data)
>     'data.frame':    499 obs. of  608 variables:
>     $ ID           : int  1 2 3 4 5 6 7 8 9 10 ...
>     $ alright      : int  1 0 0 0 0 0 0 1 2 1 ...
>     $ bad          : int  1 0 0 0 0 0 0 0 0 0 ...
>     $ boy          : int  1 2 1 1 0 2 2 4 2 1 ...
>     $ cooki        : int  1 2 2 1 0 1 1 4 2 3 ...
>     $ curtain      : int  1 0 0 0 0 2 0 2 0 0 ...
>     $ dish         : int  2 1 0 1 0 0 1 2 2 2 ...
>     $ doesnt       : int  1 0 0 0 0 0 0 0 1 0 ...
>     $ dont         : int  2 1 4 2 0 0 2 1 2 0 ...
>     $ fall         : int  3 1 0 0 1 0 1 2 3 2 ...
>     $ fell         : int  1 0 0 0 0 0 0 0 0 0 ...
> 
> and the other one is:
> 
>     > str(training)
>     'data.frame':    375 obs. of  607 variables:
>     $ alright      : num  1 0 0 0 1 2 1 0 0 0 ...
>     $ bad          : num  1 0 0 0 0 0 0 0 0 0 ...
>     $ boy          : num  1 1 2 2 4 2 1 0 1 0 ...
>     $ cooki        : num  1 1 1 1 4 2 3 1 2 2 ...
>     $ curtain      : num  1 0 2 0 2 0 0 0 0 0 ...
>     $ dish         : num  2 1 0 1 2 2 2 1 4 1 ...
>     $ doesnt       : num  1 0 0 0 0 1 0 0 0 0 ...
>     $ dont         : num  2 2 0 2 1 2 0 0 1 0 ...
>     $ fall         : num  3 0 0 1 2 3 2 0 2 0 ...
>     $ fell         : num  1 0 0 0 0 0 0 0 0 0 ...
> Does anyone know how should I get the IDs of training from data?
> thanks for any help!
> Elahe
> ....

row.names() appears to be what is wanted.

Peace,
david
-- 
David H. Wolfskill                r at catwhisker.org
Unsubstantiated claims of "Fake News" are evidence that the claimant lies again.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.


From galaxie2485 at yahoo.co.in  Wed Nov  1 18:21:30 2017
From: galaxie2485 at yahoo.co.in (Priya Arasu)
Date: Wed, 1 Nov 2017 17:21:30 +0000 (UTC)
Subject: [R] Function to save results
In-Reply-To: <692b7f8e75db4df4aba8bfb0fbba84d4@exch-2p-mbx-w2.ads.tamu.edu>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
 <691851277.669264.1509545458197@mail.yahoo.com>
 <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>
 <924053227.693026.1509548200479@mail.yahoo.com>
 <692b7f8e75db4df4aba8bfb0fbba84d4@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <35871757.742005.1509556890862@mail.yahoo.com>

Hi David,Thank you for the example.When I try to use the cat function, I get an error

cat(attr<-getAttractors(net, type="asynchronous"))Error in cat(attr <- getAttractors(net, type = "asynchronous")) : 
  argument 1 (type 'pairlist') cannot be handled by 'cat'

Please let me know, if I have used the function in right way?. 
Thank you
Priya






?
 

    On Wednesday, 1 November 2017 9:32 PM, David L Carlson <dcarlson at tamu.edu> wrote:
 

 Let's try a simple example. 

> # Create a script file of commands
> # Note we must print the results of quantile explicitly
> cat("x <- rnorm(50)\nprint(quantile(x))\nstem(x)\n", file="Test.R")
> 
> # Test it by running it to the console
> source("Test.R")
? ? ? ? 0%? ? ? ? 25%? ? ? ? 50%? ? ? ? 75%? ? ? 100% 
-2.4736219 -0.7915433 -0.1178056? 0.7023577? 2.9158617 

? The decimal point is at the |

? -2 | 510
? -1 | 7631110
? -0 | 9988777333333211
? 0 | 01124455557777889
? 1 | 00045
? 2 | 19

> 
> # Now run it and save the file
> sink("Testout.txt")
> source("Test.R")
> sink()
> 
> # What is located in "Testout.txt"?
> cat(readLines("Testout.txt"), sep="\n")
? ? ? ? 0%? ? ? ? 25%? ? ? ? 50%? ? ? ? 75%? ? ? ? 100% 
-2.47511893 -0.47919111? 0.05761628? 0.67403447? 1.79825459 

? The decimal point is at the |

? -2 | 5
? -2 | 4
? -1 | 
? -1 | 432000
? -0 | 87755
? -0 | 4433332110
? 0 | 001244
? 0 | 55666667777789
? 1 | 113
? 1 | 5788

> # Success

Depending on your operating system, you may also be able to save the output with File | Save to File.

---------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Priya Arasu via R-help
Sent: Wednesday, November 1, 2017 9:57 AM
To: Eric Berger <ericjberger at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Function to save results

Hi Eric,Thanks for the explanation. Is there a way to save the results automatically after the analysis gets over?. As I recently lost the results, because I didn't save the results. I don't want to run the sink or save command after the analysis is over rather run the command for saving the file before starting to run the analysis, so the file gets saved automatically after the script has finished running Priya
?


? ? On Wednesday, 1 November 2017 7:53 PM, Eric Berger <ericjberger at gmail.com> wrote:


 Hi Priya,
You did not follow the logic of the pseudo-code.?The sink("filename"), sink() pair captures whatever output is generated between the first sink statement and the second sink statement.You need (possibly) to do:
sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt") net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")attr <- getAttractors(net, type="asynchronous")
sink()
HTH,Eric


?


Hi Eric,I tried as you suggested but I could not find the output in the text file I created (attr.txt)

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")


sink()

attr <- getAttractors(net, type="asynchronous")
?Priya


? ? On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com> wrote:


 Some comments:1. sink() does not return a value. There is on point to set attr <- sink(...). Just give the command sink("C://....etc")2. to complete the saving to the file you must give a second sink command with no argument:? sink()So your code would be (pseudo-code, not actual code) sink( "filename" )do something that prints output which will be captured by sinksink() HTH,Eric


On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org> wrote:

Hi,I want the results to be saved automatically in a output text file after the script has finished running.

I used the sink function in the following example, but the results file (output.txt) was empty.

net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//output. txt")# used the sink function to save the results from attr function

attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?

Thank youPriya



? ? ? ? [[alternative HTML version deleted]]

______________________________ ________________ R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/ listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html and provide commented, minimal, self-contained, reproducible code.




? 



? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Nov  1 19:24:13 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 1 Nov 2017 14:24:13 -0400
Subject: [R] R-3.4.2: make check stops at line 698 of
	tests/reg-tests-1d.R
In-Reply-To: <1509556106.1495684.1158298960.54AEA5CF@webmail.messagingengine.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
 <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
 <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>
 <471d1fe1-f176-ad30-877a-8d59916c50ef@gmail.com>
 <1509556106.1495684.1158298960.54AEA5CF@webmail.messagingengine.com>
Message-ID: <52d3fed4-2a7e-90ac-9663-10b828469d0b@gmail.com>


On 01/11/2017 1:08 PM, Albrecht Kauffmann wrote:
> Am Mi, 1. Nov 2017, um 17:40, schrieb Duncan Murdoch:
>> On 01/11/2017 12:02 PM, Albrecht Kauffmann wrote:
>>> Dear Duncan,
>>>
>>> Many thanks!
>>>
>>> Am Mi, 1. Nov 2017, um 16:17, schrieb Duncan Murdoch:
>>>> On 01/11/2017 8:11 AM, Albrecht Kauffmann wrote:
>>>>> Hi all,
>>>>>
>>>>> after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
>>>>> R-3.4.1 I never had a problem with these tests. No, the programm stops
>>>>> at the following line of tests/reg-tests-1d.R:
>>>>>
>>>>>> ## available.packages() (not) caching in case of errors
>>>>>> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
>>>>>> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
>>>>>        error in assertCondition(expr, "warning",
>>>>>       .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
>>>>>       available.packages(repo  ...: wanted warning
>>>>>
>>>>> The error message is a result of:      ap2 <- available.packages(repos =
>>>>> "http://foo.bar"),
>>>>> not of the following condition in the test script:   stopifnot(nrow(ap1)
>>>>> == 0, identical(ap1, ap2))  .
>>>>
>>>> What error message did you see?
>>>
>>> after: R --vanilla <../R-3.4.2/tests/reg-tests-1d.R
>>
>> Sorry, I wasn't clear.  I meant to ask what error message you get if you
>> run the command that's supposed to generate a warning, i.e. run the code
>>
> Oops! Here are the resulting error messages, which are not the same:
>> ap1 <- available.packages(repos = "http://foo.bar")
> Warning: Cannot access to the index of the repository
> http://foo.bar/src/contrib:
>    line beginning with '<!DOCTYPE html PUBLI ...' is incorrect formatted
> 
>> ap2 <- available.packages(repos = "http://foo.bar")
> Error in readRDS(dest) : unknown input format
> 
> On my other PC, the same lines give 2 times the same error message:
> "Warning: Cannot access to the index of the repository
> http://foo.bar/src/contrib: Cannot open URL
> 'http://foo.bar/src/contrib/PACKAGES' "
> 
> Indeed, the second error message on the present PC is different. What
> may be the cause?

It looks as though one of your PCs is returning a file in response to 
the request, rather than signalling that the URL is not found.

If you go into a browser like Firefox and try to open the URL

http://foo.bar/src/contrib/PACKAGES

what do you see on the two systems?  I get a message from Firefox that 
the server is not found.

Some ISPs respond to requests for nonexistent URLs with a message, 
basically an ad for something or other.  Maybe that's what you're getting.

In any case, this looks like a bug in R:  the first request failed, but 
something got cached, and then the second request got an error reading 
the cached value.

Duncan Murdoch


From ruipbarradas at sapo.pt  Wed Nov  1 19:12:21 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 01 Nov 2017 18:12:21 +0000
Subject: [R] Function to save results
In-Reply-To: <35871757.742005.1509556890862@mail.yahoo.com>
References: <1192929665.582943.1509535966471.ref@mail.yahoo.com>
 <1192929665.582943.1509535966471@mail.yahoo.com>
 <CAGgJW74oBWj28Lz5vbTmV5g1qvQeSbArCGUjWn8DAp19QRSXng@mail.gmail.com>
 <691851277.669264.1509545458197@mail.yahoo.com>
 <CAGgJW752zQ8-Hp3CHzy5tcy2-Vivc2ynbbqz-zo52wmXtDKzhQ@mail.gmail.com>
 <924053227.693026.1509548200479@mail.yahoo.com>
 <692b7f8e75db4df4aba8bfb0fbba84d4@exch-2p-mbx-w2.ads.tamu.edu>
 <35871757.742005.1509556890862@mail.yahoo.com>
Message-ID: <59FA0E85.9060102@sapo.pt>

Hello,

If cat is giving you an error try print(attr <- ...etc...)

Hope this helps,

Rui Barradas

Em 01-11-2017 17:21, Priya Arasu via R-help escreveu:
> Hi David,Thank you for the example.When I try to use the cat function, I get an error
>
> cat(attr<-getAttractors(net, type="asynchronous"))Error in cat(attr <- getAttractors(net, type = "asynchronous")) :
>    argument 1 (type 'pairlist') cannot be handled by 'cat'
>
> Please let me know, if I have used the function in right way?.
> Thank you
> Priya
>
>
>
>
>
>
>
>
>
>      On Wednesday, 1 November 2017 9:32 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
>
>   Let's try a simple example.
>
>> # Create a script file of commands
>> # Note we must print the results of quantile explicitly
>> cat("x <- rnorm(50)\nprint(quantile(x))\nstem(x)\n", file="Test.R")
>>
>> # Test it by running it to the console
>> source("Test.R")
>          0%        25%        50%        75%      100%
> -2.4736219 -0.7915433 -0.1178056  0.7023577  2.9158617
>
>    The decimal point is at the |
>
>    -2 | 510
>    -1 | 7631110
>    -0 | 9988777333333211
>    0 | 01124455557777889
>    1 | 00045
>    2 | 19
>
>>
>> # Now run it and save the file
>> sink("Testout.txt")
>> source("Test.R")
>> sink()
>>
>> # What is located in "Testout.txt"?
>> cat(readLines("Testout.txt"), sep="\n")
>          0%        25%        50%        75%        100%
> -2.47511893 -0.47919111  0.05761628  0.67403447  1.79825459
>
>    The decimal point is at the |
>
>    -2 | 5
>    -2 | 4
>    -1 |
>    -1 | 432000
>    -0 | 87755
>    -0 | 4433332110
>    0 | 001244
>    0 | 55666667777789
>    1 | 113
>    1 | 5788
>
>> # Success
>
> Depending on your operating system, you may also be able to save the output with File | Save to File.
>
> ---------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Priya Arasu via R-help
> Sent: Wednesday, November 1, 2017 9:57 AM
> To: Eric Berger <ericjberger at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Function to save results
>
> Hi Eric,Thanks for the explanation. Is there a way to save the results automatically after the analysis gets over?. As I recently lost the results, because I didn't save the results. I don't want to run the sink or save command after the analysis is over rather run the command for saving the file before starting to run the analysis, so the file gets saved automatically after the script has finished running Priya
>
>
>
>      On Wednesday, 1 November 2017 7:53 PM, Eric Berger <ericjberger at gmail.com> wrote:
>
>
>   Hi Priya,
> You did not follow the logic of the pseudo-code. The sink("filename"), sink() pair captures whatever output is generated between the first sink statement and the second sink statement.You need (possibly) to do:
> sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt") net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")attr <- getAttractors(net, type="asynchronous")
> sink()
> HTH,Eric
>
>
>
>
>
> Hi Eric,I tried as you suggested but I could not find the output in the text file I created (attr.txt)
>
> net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//attr. txt")
>
>
> sink()
>
> attr <- getAttractors(net, type="asynchronous")
>   Priya
>
>
>      On Wednesday, 1 November 2017 6:54 PM, Eric Berger <ericjberger at gmail.com> wrote:
>
>
>   Some comments:1. sink() does not return a value. There is on point to set attr <- sink(...). Just give the command sink("C://....etc")2. to complete the saving to the file you must give a second sink command with no argument:  sink()So your code would be (pseudo-code, not actual code) sink( "filename" )do something that prints output which will be captured by sinksink() HTH,Eric
>
>
> On Wed, Nov 1, 2017 at 1:32 PM, Priya Arasu via R-help <r-help at r-project.org> wrote:
>
> Hi,I want the results to be saved automatically in a output text file after the script has finished running.
>
> I used the sink function in the following example, but the results file (output.txt) was empty.
>
> net <- loadNetwork("C://Users//Priya/ /Desktop//Attractor analysis_all genes//synaptogenesis// regulationof_dopamine_ signaling_submodule3.txt")# First I loaded theinput file for which I want to identify attractors attr <- sink("C://Users//Priya// Desktop//Attractor analysis_all genes//synaptogenesis//output. txt")# used the sink function to save the results from attr function
>
> attr <- getAttractors(net, type="asynchronous")# then ran the script for identifying attractors Is there any function to save the results before setting the script to run, so that results are automatically saved in a text file after the script has finished running?
>
> Thank youPriya
>
>
>
>          [[alternative HTML version deleted]]
>
> ______________________________ ________________ R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/ listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
>
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Nov  1 20:17:09 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Nov 2017 12:17:09 -0700
Subject: [R] beta binomial distribution installation
In-Reply-To: <SN1PR0101MB16141709F932542AACE7CC50E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
References: <SN1PR0101MB1614E504A9C3A4851D9D80C5E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
 <AF36C32BE015CB48883C4A9F73CC8C3201BB979E86@DOHNSMXDB03.doh.health.nsw.gov.au>
 <CAGgJW7521xe7dwvUhhaHYgP3YH6FrwcJ+sz3keSPdS6y4vEOcQ@mail.gmail.com>
 <SN1PR0101MB16141709F932542AACE7CC50E55F0@SN1PR0101MB1614.prod.exchangelabs.com>
Message-ID: <2FACBB54-193A-448F-AEC0-BFEEB4C5A2C9@comcast.net>


> On Nov 1, 2017, at 9:09 AM, Amany Abdel-Karim <ABDELKARIM2 at msn.com> wrote:
> 
> Hello,
> 
> Thank you for your response. I need to install RankTail package since it contains the beta binomial distribution, CDF and inverse CDF in the usual form which I need to use. However rmutil package contain unusual forms for these functions. So it is easier for me to deal with the forms are contained in RankTail.
> 
> I tried to install  bioconductor package, using the following commands but I still got the following errors:
> 
> 
> (1) I tried biocLite() and then library ("TailRank"), I got the following errors.

It appears you failed to follow the full instructions which were to execute:

source("https://bioconductor.org/biocLite.R")
biocLite()

The first line creates the biocLite function within your workspace.

-- 
David.


> 
>> biocLite()
> Error in biocLite() : could not find function "biocLite"
>> library("TailRank")
> Loading required package: oompaBase
> Error: package or namespace load failed for ?TailRank? in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> there is no package called ?Biobase?
> In addition: Warning messages:
> 1: package ?TailRank? was built under R version 3.4.2
> 2: package ?oompaBase? was built under R version 3.4.2
> 
> 
> 
> (2) I tried to write the command biocLite(), then biocLite("TailRank"), I got the following errors:
> 
>> biocLite()
> Error in biocLite() : could not find function "biocLite"
>> biocLite("ilRank")
> Error in biocLite("ilRank") : could not find function "biocLite"
>> biocLite()
> Error in biocLite() : could not find function "biocLite"
>> biocLite("TailRank")
> Error in biocLite("TailRank") : could not find function "biocLite"
> 
> 
> 
> 
>> 
> 
> 
> 
> 
> Also, I checked under packages on the right side of the R window and I found TailRank , Description is Tail-Rank statistic, and version is 3.1.3. So, I tried to write the following code in the console window to check if the package works:
> 
>> N<-20
>> u<-3
>> v<-10
>> p<-u/u+v
>> x<-0:N
> 
>> yy<-dbb(x,N,u,v)
> 
> 
> I got the following error:
> Error in dbb(x, N, u, v) : could not find function "dbb"
> 
> 
> 
> 
>> 
> 
> 
> 
> I am confused because if the package TailRank is already there, why the pervious code does not work to calculate dbb (x,N,u,v) and I got error? If I do not have the package, would you please let me know the right commands I should write in the script window to install TaiRank because the commands I used (which I mentioned at the beginning of the email did not work and gave errors). I appreciate your help since I am a new user of R.
> 
> 
> Amany
> 
> 
> 
> ________________________________
> 
> From: Eric Berger <ericjberger at gmail.com>
> Sent: Wednesday, November 1, 2017 2:42 AM
> To: MCGUIRE, Rhydwyn
> Cc: Amany Abdel-Karim; R-help at stat.math.ethz.ch
> Subject: Re: [R] beta binomial distribution installation
> 
> Hi,
> I did a quick search for other packages that provide the beta binomial distribution and found "rmutil".
> 
>> install.packages("rmutil")
> 
> The package has the CDF (pbetabinom) and inverse CDF (qbetabinom) among other functions.
> 
> HTH,
> Eric
> 
> 
> 
> On Wed, Nov 1, 2017 at 7:50 AM, MCGUIRE, Rhydwyn <rmcgu at doh.health.nsw.gov.au<mailto:rmcgu at doh.health.nsw.gov.au>> wrote:
> Hi there,
> 
> It looks like you also need the bioconductor package biobase, I found instructions for downloading that package here: www.bioconductor.org/install<http://www.bioconductor.org/install>
> 
> Good luck.
> 
> Cheers,
> Rhydwyn
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Amany Abdel-Karim
> Sent: Wednesday, 1 November 2017 2:13 PM
> To: R-help at stat.math.ethz.ch<mailto:R-help at stat.math.ethz.ch>
> Subject: [R] beta binomial distribution installation
> 
> Hello,
> 
> I  tried to install package TailRank using the command install.packages (RankTail) and library (TailRank) but I got the following errors. So, how can I install TaiRank in Rstudio to have se beta-binomial distribution, CDF and inverse CDG of  beta-binomal?
> 
> The commands I used are:
> 
>> install.packages("TailRank")
> 
> Installing package into C:/Users/stator-guest/Documents/R/win-library/3.4
> 
> (as lib is unspecified)
> 
> Warning in install.packages :
> 
>  dependency Biobase is not available
> 
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/TailRank_3.1.3.zip'
> 
> Content type 'application/zip' length 331270 bytes (323 KB)
> 
> downloaded 323 KB
> 
> 
> 
> package TailRank successfully unpacked and MD5 sums checked
> 
> 
> 
> The downloaded binary packages are in
> 
>            C:\Users\stator-guest\AppData\Local\Temp\RtmpoVx40V\downloaded_packages
> 
>> library(TailRank)
> 
> Error: package or namespace load failed for TailRank in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> 
> there is no package called Biobase
> 
> In addition: Warning message:
> 
> package TailRank was built under R version 3.4.2
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> __________________________________________________________________________________________________________
> This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
> Emails and attachments are monitored to ensure compliance with the NSW Ministry of health's Electronic Messaging Policy.
> __________________________________________________________________________________________________________
> _______________________________________________________________________________________________________
> Disclaimer: This message is intended for the addressee named and may contain confidential information.
> If you are not the intended recipient, please delete it and notify the sender.
> Views expressed in this message are those of the individual sender, and are not necessarily the views of the NSW Ministry of Health.
> _______________________________________________________________________________________________________
> This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
> Emails and attachments are monitored to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
> _______________________________________________________________________________________________________
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From chalabi.elahe at yahoo.de  Wed Nov  1 20:29:56 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Wed, 1 Nov 2017 19:29:56 +0000 (UTC)
Subject: [R] Correct subsetting in R
References: <1606248669.947141.1509564596450.ref@mail.yahoo.com>
Message-ID: <1606248669.947141.1509564596450@mail.yahoo.com>


It's not what I want, the first data frame has 499 observations and the second data frame is a subset of the first one but with 375 observations. I want something that returns the ID for training data frame  


On Wednesday, November 1, 2017 10:18 AM, Eric Berger <ericjberger at gmail.com> wrote:



matches <- merge(training,data,by=intersect(names(training),names(data)))

HTH,
Eric



On Wed, Nov 1, 2017 at 6:13 PM, Elahe chalabi via R-help <r-help at r-project.org> wrote:

Hi all,
>I have two data frames that one of them does not have the column ID:
>
>    > str(data)
>    'data.frame':       499 obs. of  608 variables:
>    $ ID           : int  1 2 3 4 5 6 7 8 9 10 ...
>    $ alright      : int  1 0 0 0 0 0 0 1 2 1 ...
>    $ bad          : int  1 0 0 0 0 0 0 0 0 0 ...
>    $ boy          : int  1 2 1 1 0 2 2 4 2 1 ...
>    $ cooki        : int  1 2 2 1 0 1 1 4 2 3 ...
>    $ curtain      : int  1 0 0 0 0 2 0 2 0 0 ...
>    $ dish         : int  2 1 0 1 0 0 1 2 2 2 ...
>    $ doesnt       : int  1 0 0 0 0 0 0 0 1 0 ...
>    $ dont         : int  2 1 4 2 0 0 2 1 2 0 ...
>    $ fall         : int  3 1 0 0 1 0 1 2 3 2 ...
>    $ fell         : int  1 0 0 0 0 0 0 0 0 0 ...
>
>and the other one is:
>
>    > str(training)
>    'data.frame':       375 obs. of  607 variables:
>    $ alright      : num  1 0 0 0 1 2 1 0 0 0 ...
>    $ bad          : num  1 0 0 0 0 0 0 0 0 0 ...
>    $ boy          : num  1 1 2 2 4 2 1 0 1 0 ...
>    $ cooki        : num  1 1 1 1 4 2 3 1 2 2 ...
>    $ curtain      : num  1 0 2 0 2 0 0 0 0 0 ...
>    $ dish         : num  2 1 0 1 2 2 2 1 4 1 ...
>    $ doesnt       : num  1 0 0 0 0 1 0 0 0 0 ...
>    $ dont         : num  2 2 0 2 1 2 0 0 1 0 ...
>    $ fall         : num  3 0 0 1 2 3 2 0 2 0 ...
>    $ fell         : num  1 0 0 0 0 0 0 0 0 0 ...
>Does anyone know how should I get the IDs of training from data?
>thanks for any help!
>Elahe
>
>______________________________ ________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/ listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From paulbernal07 at gmail.com  Wed Nov  1 20:45:54 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 1 Nov 2017 14:45:54 -0500
Subject: [R] Adding Records to a Table in R
Message-ID: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>

Dear R friends,

I am currently working with time series data, and I have a table(as data
frame) that has looks like this (TransitDate are in format = "%e-%B-%Y") :

TransitDate       Transits      CargoTons
1985-04-01        100            2500
1985-05-01        135            4500
1985-06-01        120            1750
1985-07-01        100            3750
1985-08-01        200            1250

The problem is, that there are several periods that don?t exist in the
table, so it has the following behavior:

TransitDate        Transits      CargoTons
1985-04-01        100             1000
1985-07-01        100             1080
1985-12-01        500             3785
1986-04-01        325             4200
.
.
2017-09-01        400             2350 (*this is the last observation)

You can see in the last table fragment that the series jumps from
1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01 making the
time series quite irregular (non-constant chronologically speaking).

What I want to do is create a dummy table that has the sequence from the
first observation (1985-04-01) up to the last one (2017-09-01) and then
develop a code that checks if the dates contained in the dummy table exist
in the original table, if they don?t exist then add those dates and put
zeroes on the fields.

How can I achieve this?

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  1 21:05:00 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 22:05:00 +0200
Subject: [R] Correct subsetting in R
In-Reply-To: <1606248669.947141.1509564596450@mail.yahoo.com>
References: <1606248669.947141.1509564596450.ref@mail.yahoo.com>
 <1606248669.947141.1509564596450@mail.yahoo.com>
Message-ID: <CAGgJW77uZoU3kyD=zSfMXoN2Gp9cm=DXikW6rb_wrvxrOOkU4w@mail.gmail.com>

training$TrainingRownum <- 1:nrow(training)
data$DataRownum <- 1:nrow(data)
matches <- merge(training,data,by=intersect(names(training),names(data)))

The data frame 'matches' now has additional columns telling you the row in
each data frame corresponding to the matched items.

Regards,
Eric

On Wed, Nov 1, 2017 at 9:29 PM, Elahe chalabi <chalabi.elahe at yahoo.de>
wrote:

>
> It's not what I want, the first data frame has 499 observations and the
> second data frame is a subset of the first one but with 375 observations. I
> want something that returns the ID for training data frame
>
>
> On Wednesday, November 1, 2017 10:18 AM, Eric Berger <
> ericjberger at gmail.com> wrote:
>
>
>
> matches <- merge(training,data,by=intersect(names(training),names(data)))
>
> HTH,
> Eric
>
>
>
> On Wed, Nov 1, 2017 at 6:13 PM, Elahe chalabi via R-help <
> r-help at r-project.org> wrote:
>
> Hi all,
> >I have two data frames that one of them does not have the column ID:
> >
> >    > str(data)
> >    'data.frame':       499 obs. of  608 variables:
> >    $ ID           : int  1 2 3 4 5 6 7 8 9 10 ...
> >    $ alright      : int  1 0 0 0 0 0 0 1 2 1 ...
> >    $ bad          : int  1 0 0 0 0 0 0 0 0 0 ...
> >    $ boy          : int  1 2 1 1 0 2 2 4 2 1 ...
> >    $ cooki        : int  1 2 2 1 0 1 1 4 2 3 ...
> >    $ curtain      : int  1 0 0 0 0 2 0 2 0 0 ...
> >    $ dish         : int  2 1 0 1 0 0 1 2 2 2 ...
> >    $ doesnt       : int  1 0 0 0 0 0 0 0 1 0 ...
> >    $ dont         : int  2 1 4 2 0 0 2 1 2 0 ...
> >    $ fall         : int  3 1 0 0 1 0 1 2 3 2 ...
> >    $ fell         : int  1 0 0 0 0 0 0 0 0 0 ...
> >
> >and the other one is:
> >
> >    > str(training)
> >    'data.frame':       375 obs. of  607 variables:
> >    $ alright      : num  1 0 0 0 1 2 1 0 0 0 ...
> >    $ bad          : num  1 0 0 0 0 0 0 0 0 0 ...
> >    $ boy          : num  1 1 2 2 4 2 1 0 1 0 ...
> >    $ cooki        : num  1 1 1 1 4 2 3 1 2 2 ...
> >    $ curtain      : num  1 0 2 0 2 0 0 0 0 0 ...
> >    $ dish         : num  2 1 0 1 2 2 2 1 4 1 ...
> >    $ doesnt       : num  1 0 0 0 0 1 0 0 0 0 ...
> >    $ dont         : num  2 2 0 2 1 2 0 0 1 0 ...
> >    $ fall         : num  3 0 0 1 2 3 2 0 2 0 ...
> >    $ fell         : num  1 0 0 0 0 0 0 0 0 0 ...
> >Does anyone know how should I get the IDs of training from data?
> >thanks for any help!
> >Elahe
> >
> >______________________________ ________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/ listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  1 21:21:05 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 1 Nov 2017 22:21:05 +0200
Subject: [R] Adding Records to a Table in R
In-Reply-To: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
References: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
Message-ID: <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>

Hi Paul,

#First I set up some sample data since I don't have a copy of your data
dtOrig <- as.Date( c("1985-04-01","1985-07-01","1985-12-01","1986-04-01"))
dfOrig <- data.frame( TransitDate=dtOrig, Transits=c(100,100,500,325),
CargoTons=c(1000,1080,3785,4200) )

#Generate the complete set of dates as a data frame
dfDates<- data.frame( TransitDate=seq(from=as.Date("1985-04-01"),by="1
month",length=13) )

# do the merge adding the "missing" rows (where NA will appear)
dfNew  <- merge(dfDates, dfOrig, by="TransitDate", all.x=TRUE )

# replace the NA's by zero
dfNew[is.na(dfNew)] <- 0

HTH,
Eric


On Wed, Nov 1, 2017 at 9:45 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear R friends,
>
> I am currently working with time series data, and I have a table(as data
> frame) that has looks like this (TransitDate are in format = "%e-%B-%Y") :
>
> TransitDate       Transits      CargoTons
> 1985-04-01        100            2500
> 1985-05-01        135            4500
> 1985-06-01        120            1750
> 1985-07-01        100            3750
> 1985-08-01        200            1250
>
> The problem is, that there are several periods that don?t exist in the
> table, so it has the following behavior:
>
> TransitDate        Transits      CargoTons
> 1985-04-01        100             1000
> 1985-07-01        100             1080
> 1985-12-01        500             3785
> 1986-04-01        325             4200
> .
> .
> 2017-09-01        400             2350 (*this is the last observation)
>
> You can see in the last table fragment that the series jumps from
> 1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01 making the
> time series quite irregular (non-constant chronologically speaking).
>
> What I want to do is create a dummy table that has the sequence from the
> first observation (1985-04-01) up to the last one (2017-09-01) and then
> develop a code that checks if the dates contained in the dummy table exist
> in the original table, if they don?t exist then add those dates and put
> zeroes on the fields.
>
> How can I achieve this?
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From alkauffm at fastmail.fm  Wed Nov  1 21:52:16 2017
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Wed, 01 Nov 2017 21:52:16 +0100
Subject: [R] R-3.4.2: make check stops at line 698 of
	tests/reg-tests-1d.R
In-Reply-To: <52d3fed4-2a7e-90ac-9663-10b828469d0b@gmail.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
 <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
 <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>
 <471d1fe1-f176-ad30-877a-8d59916c50ef@gmail.com>
 <1509556106.1495684.1158298960.54AEA5CF@webmail.messagingengine.com>
 <52d3fed4-2a7e-90ac-9663-10b828469d0b@gmail.com>
Message-ID: <1509569536.3043313.1158549240.3752290B@webmail.messagingengine.com>

Dear Duncan,

thank you very much, that is it! Indeed, there was activated in my
internet router the "telekom navigation help". When I am (or the system
is) looking for an not existent url, this "help" opens its own website.
After deactivation of telekom navigation help, the normal message
(server not found) comes. I never gave attention to this "help",
although it is bothering sometimes; now it is switched off in my
residence. However, in Germany this problem probably frequently arises,
therefor, it should be considered in the respective code for testing R
after compilation.  

All the best,
Albrecht
-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mi, 1. Nov 2017, um 19:24, schrieb Duncan Murdoch:
> 
> On 01/11/2017 1:08 PM, Albrecht Kauffmann wrote:
> > Am Mi, 1. Nov 2017, um 17:40, schrieb Duncan Murdoch:
> >> On 01/11/2017 12:02 PM, Albrecht Kauffmann wrote:
> >>> Dear Duncan,
> >>>
> >>> Many thanks!
> >>>
> >>> Am Mi, 1. Nov 2017, um 16:17, schrieb Duncan Murdoch:
> >>>> On 01/11/2017 8:11 AM, Albrecht Kauffmann wrote:
> >>>>> Hi all,
> >>>>>
> >>>>> after compiling R-3.4.2 on opensuse leap 42.3, make check failed. Until
> >>>>> R-3.4.1 I never had a problem with these tests. No, the programm stops
> >>>>> at the following line of tests/reg-tests-1d.R:
> >>>>>
> >>>>>> ## available.packages() (not) caching in case of errors
> >>>>>> tools::assertWarning(ap1 <- available.packages(repos = "http://foo.bar"))
> >>>>>> tools::assertWarning(ap2 <- available.packages(repos = "http://foo.bar"))
> >>>>>        error in assertCondition(expr, "warning",
> >>>>>       .exprString = d.expr) :  Got simpleError evaluating of ap2 <-
> >>>>>       available.packages(repo  ...: wanted warning
> >>>>>
> >>>>> The error message is a result of:      ap2 <- available.packages(repos =
> >>>>> "http://foo.bar"),
> >>>>> not of the following condition in the test script:   stopifnot(nrow(ap1)
> >>>>> == 0, identical(ap1, ap2))  .
> >>>>
> >>>> What error message did you see?
> >>>
> >>> after: R --vanilla <../R-3.4.2/tests/reg-tests-1d.R
> >>
> >> Sorry, I wasn't clear.  I meant to ask what error message you get if you
> >> run the command that's supposed to generate a warning, i.e. run the code
> >>
> > Oops! Here are the resulting error messages, which are not the same:
> >> ap1 <- available.packages(repos = "http://foo.bar")
> > Warning: Cannot access to the index of the repository
> > http://foo.bar/src/contrib:
> >    line beginning with '<!DOCTYPE html PUBLI ...' is incorrect formatted
> > 
> >> ap2 <- available.packages(repos = "http://foo.bar")
> > Error in readRDS(dest) : unknown input format
> > 
> > On my other PC, the same lines give 2 times the same error message:
> > "Warning: Cannot access to the index of the repository
> > http://foo.bar/src/contrib: Cannot open URL
> > 'http://foo.bar/src/contrib/PACKAGES' "
> > 
> > Indeed, the second error message on the present PC is different. What
> > may be the cause?
> 
> It looks as though one of your PCs is returning a file in response to 
> the request, rather than signalling that the URL is not found.
> 
> If you go into a browser like Firefox and try to open the URL
> 
> http://foo.bar/src/contrib/PACKAGES
> 
> what do you see on the two systems?  I get a message from Firefox that 
> the server is not found.
> 
> Some ISPs respond to requests for nonexistent URLs with a message, 
> basically an ad for something or other.  Maybe that's what you're
> getting.
> 
> In any case, this looks like a bug in R:  the first request failed, but 
> something got cached, and then the second request got an error reading 
> the cached value.
> 
> Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Wed Nov  1 22:32:00 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 01 Nov 2017 14:32:00 -0700
Subject: [R] R-3.4.2: make check stops at line 698
	of	tests/reg-tests-1d.R
In-Reply-To: <1509569536.3043313.1158549240.3752290B@webmail.messagingengine.com>
References: <1509538309.2207418.1157977864.7FD64B02@webmail.messagingengine.com>
 <63d74102-df81-9e6e-2c1d-8554d83d1c59@gmail.com>
 <1509552173.800849.1158227096.6093A93E@webmail.messagingengine.com>
 <471d1fe1-f176-ad30-877a-8d59916c50ef@gmail.com>
 <1509556106.1495684.1158298960.54AEA5CF@webmail.messagingengine.com>
 <52d3fed4-2a7e-90ac-9663-10b828469d0b@gmail.com>
 <1509569536.3043313.1158549240.3752290B@webmail.messagingengine.com>
Message-ID: <E62174BA-C957-461D-8F8A-6918E8A44117@dcn.davis.ca.us>

This idea of hijacking failed connections has been tried before and it breaks many things beyond R software and most ISPs have given up on doing this. If you, who have this "feature" at hand can figure out a reliable way to detect this then it might be "considered". However, it seems unlikely that a general solution can be found after all this time, so the better option is probably for you to disable this "feature".
-- 
Sent from my phone. Please excuse my brevity.

On November 1, 2017 1:52:16 PM PDT, Albrecht Kauffmann <alkauffm at fastmail.fm> wrote:
>Dear Duncan,
>
>thank you very much, that is it! Indeed, there was activated in my
>internet router the "telekom navigation help". When I am (or the system
>is) looking for an not existent url, this "help" opens its own website.
>After deactivation of telekom navigation help, the normal message
>(server not found) comes. I never gave attention to this "help",
>although it is bothering sometimes; now it is switched off in my
>residence. However, in Germany this problem probably frequently arises,
>therefor, it should be considered in the respective code for testing R
>after compilation.  
>
>All the best,
>Albrecht


From tlkantro at gmail.com  Wed Nov  1 20:51:40 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Wed, 1 Nov 2017 15:51:40 -0400
Subject: [R] "prob" package alternative
Message-ID: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>

The prob package has been archived because it depends upon some other
packages which have issues.

However, such projects as Introduction to Probability and Statistics in R
depend upon it for learning. There are a few other resources that also use
it.

Does anyone know of any workarounds?

Someone at stack exchange mentioned using R 2.9. However, that broke my
RStudio (WSOD) and the dependent packages still wouldn't install, anyway.

Suggestions?

Thanks!

Best -

Tiby

	[[alternative HTML version deleted]]


From kosmirnov at gmail.com  Wed Nov  1 21:12:09 2017
From: kosmirnov at gmail.com (Kosta S.)
Date: Wed, 1 Nov 2017 21:12:09 +0100
Subject: [R] Cox Regression : Spline Coefficient Interpretation?
Message-ID: <CALgq08bCmMKuZioj3uPby+XoLROzk2QsJ_hKweFJBOTLsmUh5Q@mail.gmail.com>

Hi,

I'm using a Cox-Regression to estimate hazard rates on prepayments.

I'm using the "pspline" function to face non-linearity, but I have no clue
how to interpret the result.
Unfortunately I did not find enough information on the "pspline" function
wether in the survival package nor using google..

I got following output:

* library(survival)*


>
>
>
>
>
>
>
>
>
>
>
>
>
> *> Option.test2<-coxph(Surv(START,STOP,ZEROBAL==1)~pspline(OPTION),
> data=FNMA)coxph(formula = Surv(START, STOP, ZEROBAL == 1) ~
> pspline(OPTION),     data = FNMA)> > Option.test2> Call:> coxph(formula =
> Surv(START, STOP, ZEROBAL == 1) ~ pspline(OPTION), >     data = FNMA)>
>                          coef  se(coef)       se2     Chisq   DF
>         p> pspline(OPTION), linear   -0.1334    0.0131    0.0131  104.4325
> 1.00 <0.0000000000000002> pspline(OPTION), nonlin
>     1747.1295 3.05 <0.0000000000000002> Iterations: 8 outer, 19
> Newton-Raphson>      Theta= 0.991 > Degrees of freedom for terms= 4 >
> Likelihood ratio test=2136  on 4.05 df, p=0  n= 3390429 >  *


Thanks,

KS

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Nov  1 23:11:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 1 Nov 2017 15:11:08 -0700
Subject: [R] Cox Regression : Spline Coefficient Interpretation?
In-Reply-To: <CALgq08bCmMKuZioj3uPby+XoLROzk2QsJ_hKweFJBOTLsmUh5Q@mail.gmail.com>
References: <CALgq08bCmMKuZioj3uPby+XoLROzk2QsJ_hKweFJBOTLsmUh5Q@mail.gmail.com>
Message-ID: <CAGxFJbT-JqxBztBViniqBpLFMP93javh1TCOMUdFobOeGDVfCw@mail.gmail.com>

??

It is unclear to me what "How to interpret the result" means. Note that the
survival package is very well documented and there is a vignette
specifically on the topic of the use of "Spline terms in a Cox model." Have
you studied it?

If you want to discuss the statistical issues, e.g. of survival modeling
or the technical details of penalized smoothing splines, that is mostly OT
here: stats.stackexchange.com would probably be a better place to post for
that. This list is mostly about R programming rather than statistics,
although they do sometimes intersect.

If I have misunderstood your question, you might wish to clarify exactly
what it is that you are seeking in another post.

Finally, as you can see from the below, post in PLAIN TEXT ONLY, as html
can get mangled by the server on this plain text mailing list.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 1, 2017 at 1:12 PM, Kosta S. <kosmirnov at gmail.com> wrote:

> Hi,
>
> I'm using a Cox-Regression to estimate hazard rates on prepayments.
>
> I'm using the "pspline" function to face non-linearity, but I have no clue
> how to interpret the result.
> Unfortunately I did not find enough information on the "pspline" function
> wether in the survival package nor using google..
>
> I got following output:
>
> * library(survival)*
>
>
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *> Option.test2<-coxph(Surv(START,STOP,ZEROBAL==1)~pspline(OPTION),
> > data=FNMA)coxph(formula = Surv(START, STOP, ZEROBAL == 1) ~
> > pspline(OPTION),     data = FNMA)> > Option.test2> Call:> coxph(formula =
> > Surv(START, STOP, ZEROBAL == 1) ~ pspline(OPTION), >     data = FNMA)>
> >                          coef  se(coef)       se2     Chisq   DF
> >         p> pspline(OPTION), linear   -0.1334    0.0131    0.0131
> 104.4325
> > 1.00 <0.0000000000000002> pspline(OPTION), nonlin
> >     1747.1295 3.05 <0.0000000000000002> Iterations: 8 outer, 19
> > Newton-Raphson>      Theta= 0.991 > Degrees of freedom for terms= 4 >
> > Likelihood ratio test=2136  on 4.05 df, p=0  n= 3390429 >  *
>
>
> Thanks,
>
> KS
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov  1 23:17:10 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Nov 2017 15:17:10 -0700
Subject: [R] "prob" package alternative
In-Reply-To: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
Message-ID: <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>


> On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> 
> The prob package has been archived because it depends upon some other
> packages which have issues.
> 
> However, such projects as Introduction to Probability and Statistics in R
> depend upon it for learning. There are a few other resources that also use
> it.
> 
> Does anyone know of any workarounds?
> 
> Someone at stack exchange mentioned using R 2.9.

I'm not sure I would trust that person. They seem a bit uninformed.

> However, that broke my
> RStudio (WSOD) and the dependent packages still wouldn't install, anyway.

The latest version of pkg-prob at the Archive directory of CRAN indicates that it was last updated within this year. The DESCRIPTION file indicates that it does not need compilation, but:

Depends: combinat, fAsianOptions

So there should be code in text files in its ../R directory which can be sourced from that directory.

~myuser_name$ ls /Users/../Downloads/prob/R 
characteristicfunctions.r	simulation.r			utils-spaces.r
genData.R			spaces-examples.r		utils-subsets.r
misc.r				spaces-prob.r
prob.r				utils-events.r


Or you can install from source after downloading:

install.packages("~/Downloads/prob", repo=NULL,type="source")

# Success


>  library(prob)   # So does require having several other packages
Loading required package: combinat

Attaching package: ?combinat?

The following object is masked from ?package:utils?:

    combn

Loading required package: fAsianOptions
Loading required package: timeDate

Attaching package: ?timeDate?

The following object is masked from ?package:cairoDevice?:

    Cairo

The following objects are masked from ?package:PerformanceAnalytics?:

    kurtosis, skewness

Loading required package: timeSeries

Attaching package: ?timeSeries?

The following object is masked from ?package:zoo?:

    time<-

Loading required package: fBasics


Rmetrics Package fBasics
Analysing Markets and calculating Basic Statistics
Copyright (C) 2005-2014 Rmetrics Association Zurich
Educational Software for Financial Engineering and Computational Science
Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
https://www.rmetrics.org --- Mail to: info at rmetrics.org
Loading required package: fOptions


Rmetrics Package fOptions
Pricing and Evaluating Basic Options
Copyright (C) 2005-2014 Rmetrics Association Zurich
Educational Software for Financial Engineering and Computational Science
Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
https://www.rmetrics.org --- Mail to: info at rmetrics.org

Attaching package: ?prob?

The following objects are masked from ?package:dplyr?:

    intersect, setdiff, union

The following objects are masked from ?package:base?:

    intersect, setdiff, union

> 
> 
> 
> Tiby
> 
> 	[[alternative HTML version deleted]]

A specific suggestion would be that you read the listinfo and the Posting Guide and learn to post in plain text.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From pdalgd at gmail.com  Thu Nov  2 12:08:31 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Nov 2017 12:08:31 +0100
Subject: [R] Correct subsetting in R
In-Reply-To: <1132433779.794722.1509555831950@mail.yahoo.com>
References: <1132433779.794722.1509555831950.ref@mail.yahoo.com>
 <1132433779.794722.1509555831950@mail.yahoo.com>
Message-ID: <2784F3C4-9DE1-47AB-A96C-F4BB80A43248@gmail.com>


> On 1 Nov 2017, at 18:03 , Elahe chalabi via R-help <r-help at r-project.org> wrote:
> 
> But they row.names() cannot give me the IDs
> 

Is "training" extracted from "data" using standard data frame indexing? If so, data[row.names(training), "ID"] should give you the relevant values. 

If not, then you are in trouble because you cannot tell the difference between two IDs that have identical responses in columns 2:608. You might proceed with something like 

signature1 <- do.call("paste", data)
any(duplicated(signature1)) # if TRUE you're not quite happy because two or more IDs are indistinguishable.

signature2 <- do.call("paste", data)
m <- match(signature2, signature1)

any(duplicated(m)) # ouch if TRUE... will require more thought

any(is.na(m)) # even more ouch, if TRUE...

data$ID[m]


-pd

> 
> 
> 
> 
> 
> On Wednesday, November 1, 2017 9:45 AM, David Wolfskill <r at catwhisker.org> wrote:
> 
> 
> 
> On Wed, Nov 01, 2017 at 04:13:42PM +0000, Elahe chalabi via R-help wrote:
> 
>> Hi all,
>> I have two data frames that one of them does not have the column ID:
>> 
>>> str(data)
>>    'data.frame':    499 obs. of  608 variables:
>>    $ ID           : int  1 2 3 4 5 6 7 8 9 10 ...
>>    $ alright      : int  1 0 0 0 0 0 0 1 2 1 ...
>>    $ bad          : int  1 0 0 0 0 0 0 0 0 0 ...
>>    $ boy          : int  1 2 1 1 0 2 2 4 2 1 ...
>>    $ cooki        : int  1 2 2 1 0 1 1 4 2 3 ...
>>    $ curtain      : int  1 0 0 0 0 2 0 2 0 0 ...
>>    $ dish         : int  2 1 0 1 0 0 1 2 2 2 ...
>>    $ doesnt       : int  1 0 0 0 0 0 0 0 1 0 ...
>>    $ dont         : int  2 1 4 2 0 0 2 1 2 0 ...
>>    $ fall         : int  3 1 0 0 1 0 1 2 3 2 ...
>>    $ fell         : int  1 0 0 0 0 0 0 0 0 0 ...
>> 
>> and the other one is:
>> 
>>> str(training)
>>    'data.frame':    375 obs. of  607 variables:
>>    $ alright      : num  1 0 0 0 1 2 1 0 0 0 ...
>>    $ bad          : num  1 0 0 0 0 0 0 0 0 0 ...
>>    $ boy          : num  1 1 2 2 4 2 1 0 1 0 ...
>>    $ cooki        : num  1 1 1 1 4 2 3 1 2 2 ...
>>    $ curtain      : num  1 0 2 0 2 0 0 0 0 0 ...
>>    $ dish         : num  2 1 0 1 2 2 2 1 4 1 ...
>>    $ doesnt       : num  1 0 0 0 0 1 0 0 0 0 ...
>>    $ dont         : num  2 2 0 2 1 2 0 0 1 0 ...
>>    $ fall         : num  3 0 0 1 2 3 2 0 2 0 ...
>>    $ fell         : num  1 0 0 0 0 0 0 0 0 0 ...
>> Does anyone know how should I get the IDs of training from data?
>> thanks for any help!
>> Elahe
>> ....
> 
> row.names() appears to be what is wanted.
> 
> Peace,
> david
> -- 
> David H. Wolfskill                r at catwhisker.org
> Unsubstantiated claims of "Fake News" are evidence that the claimant lies again.
> 
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From cjsilwood at gmail.com  Thu Nov  2 14:00:13 2017
From: cjsilwood at gmail.com (Chris S)
Date: Thu, 2 Nov 2017 13:00:13 +0000
Subject: [R] SamplingStrata R package
Message-ID: <CAHBtsTvvVkfAgUbpHPwTMvSw=Q33SS+=cw2gWBgGGM+LTo+8Sg@mail.gmail.com>

Hi all

I am hoping to use the SamplingStrata R package for a dataset describing a
population of businesses wherein I have information on the type of
business, as well as, for designated employment number bands, number of
employees and business turnover information. So ideally the stratification
will be business type X business size. I am not 100% sure what "domains"
(in the vernacular of the package) would be referring to in this case? Also
can I employ both number of employees and business turnover information to
optimise the stratification sampling procedure?

thank you in advance

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Nov  2 14:53:34 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Nov 2017 06:53:34 -0700
Subject: [R] Cox Regression : Spline Coefficient Interpretation?
In-Reply-To: <CALgq08Z0UdT7fXT1sfc4-eqqVcbL0wRXjJv-1UkuQAyNzS5_7Q@mail.gmail.com>
References: <CALgq08bCmMKuZioj3uPby+XoLROzk2QsJ_hKweFJBOTLsmUh5Q@mail.gmail.com>
 <CAGxFJbT-JqxBztBViniqBpLFMP93javh1TCOMUdFobOeGDVfCw@mail.gmail.com>
 <CALgq08Z0UdT7fXT1sfc4-eqqVcbL0wRXjJv-1UkuQAyNzS5_7Q@mail.gmail.com>
Message-ID: <CAGxFJbRYJEZKBFgkWps+_coTa9Gupa9K391anmXqXST+iGOF0A@mail.gmail.com>

Always reply to the list. I do not do private consulting.
(I have cc'ed this to the list).

I still think this belongs on stackexchange, not r-help. I think you need
to read up on the mathematics of spline bases.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 2, 2017 at 3:43 AM, Kosta S. <kosmirnov at gmail.com> wrote:

> Hi Bert,
>
> Maybe I should make this more clear.
> I get following output when I use the pspline function inside the coxph
> statement:
>
> * library(survival)*
>
>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *> Option.test2<-coxph(Surv(START,STOP,ZEROBAL==1)~pspline(OPTION),
>> data=FNMA)coxph(formula = Surv(START, STOP, ZEROBAL == 1) ~
>> pspline(OPTION),    data = FNMA)> > Option.test2> Call:> coxph(formula =
>> Surv(START, STOP, ZEROBAL == 1) ~ pspline(OPTION),>     data = FNMA)>
>>                        coef  se(coef)       se2     Chisq   DF
>>       p> pspline(OPTION), linear   -0.1334    0.0131    0.0131  104.4325
>> 1.00 <0.0000000000000002> pspline(OPTION), nonlin
>>     1747.1295 3.05 <0.0000000000000002> Iterations: 8 outer, 19
>> Newton-Raphson>      Theta= 0.991> Degrees of freedom for terms= 4>
>> Likelihood ratio test=2136  on 4.05 df, p=0  n= 3390429*
>
>
>
> What I do not understand, and what I have not found either in the package
> documentation nor somewhere else is how to  interpret the output result:
>
>
>
>
>
>
>
> *>                              coef  se(coef)       se2     Chisq   DF
>                 p> pspline(OPTION), linear   -0.1334    0.0131    0.0131
>  104.4325 1.00 <0.0000000000000002> pspline(OPTION), nonlin
>               1747.1295 3.05 <0.0000000000000002> Iterations: 8 outer, 19
> Newton-Raphson>      Theta= 0.991> Degrees of freedom for terms= 4>
> Likelihood ratio test=2136  on 4.05 df, p=0  n= 3390429*
>
>
> What does it actually tell me? What does the "linear" and "nonlinear"
> mean? It differs from the usual coxph output. Is this a proof of
> non-linearity?
>
> This topic was also alreday asked on the cross validated board, but
> unfortunately without any answer, see https://stats.
> stackexchange.com/questions/280168/interpretation-of-coxph-pspline-terms
>
>
> Thanks,
>
> KS
>
>
>
>
>
>
>
>
> 2017-11-01 23:11 GMT+01:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
>> ??
>>
>> It is unclear to me what "How to interpret the result" means. Note that
>> the survival package is very well documented and there is a vignette
>> specifically on the topic of the use of "Spline terms in a Cox model." Have
>> you studied it?
>>
>> If you want to discuss the statistical issues, e.g. of survival modeling
>> or the technical details of penalized smoothing splines, that is mostly OT
>> here: stats.stackexchange.com would probably be a better place to post
>> for that. This list is mostly about R programming rather than statistics,
>> although they do sometimes intersect.
>>
>> If I have misunderstood your question, you might wish to clarify exactly
>> what it is that you are seeking in another post.
>>
>> Finally, as you can see from the below, post in PLAIN TEXT ONLY, as html
>> can get mangled by the server on this plain text mailing list.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Nov 1, 2017 at 1:12 PM, Kosta S. <kosmirnov at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I'm using a Cox-Regression to estimate hazard rates on prepayments.
>>>
>>> I'm using the "pspline" function to face non-linearity, but I have no
>>> clue
>>> how to interpret the result.
>>> Unfortunately I did not find enough information on the "pspline" function
>>> wether in the survival package nor using google..
>>>
>>> I got following output:
>>>
>>> * library(survival)*
>>>
>>>
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > *> Option.test2<-coxph(Surv(START,STOP,ZEROBAL==1)~pspline(OPTION),
>>> > data=FNMA)coxph(formula = Surv(START, STOP, ZEROBAL == 1) ~
>>> > pspline(OPTION),     data = FNMA)> > Option.test2> Call:>
>>> coxph(formula =
>>> > Surv(START, STOP, ZEROBAL == 1) ~ pspline(OPTION), >     data = FNMA)>
>>> >                          coef  se(coef)       se2     Chisq   DF
>>> >         p> pspline(OPTION), linear   -0.1334    0.0131    0.0131
>>> 104.4325
>>> > 1.00 <0.0000000000000002> pspline(OPTION), nonlin
>>> >     1747.1295 3.05 <0.0000000000000002> Iterations: 8 outer, 19
>>> > Newton-Raphson>      Theta= 0.991 > Degrees of freedom for terms= 4 >
>>> > Likelihood ratio test=2136  on 4.05 df, p=0  n= 3390429 >  *
>>>
>>>
>>> Thanks,
>>>
>>> KS
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Nov  2 16:56:05 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Nov 2017 15:56:05 +0000
Subject: [R] repeat a function
In-Reply-To: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>
References: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>

Hi Eric

I did not see any answer and frankly speaking I cannot provide you with canned help.

AFAIK if a function is defined within another function (which is your case) it cannot be called directly so it is necessary to define it in global environment.

>  fff <- function(x) {
+  myf <- function(a) a+2
+  myf(x)^2}
>
> fff(5)
[1] 49
> myf(5)
Error in myf(5) : could not find function "myf"
>

Your function set is quite complicated but I wonder why would it be necessary to use for cycle for what seems to be simple table. Everything seems quite deterministic.

Basically you have combination of rows (-2,-1,0,1,2) and columns -1,-,1.
expand.grid(u=-2:2, v=-1:1)
for each row you can than use one function with parameters u, v and a and dt.
After you calculate vector of results, you can easily transform it to matrix by setting dim argument to it.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Eric.Pueyo at avivainvestors.com
> Sent: Wednesday, November 1, 2017 1:31 PM
> To: r-help at r-project.org
> Subject: [R] repeat a function
>
> I want to populate the matrix prb through the function HWMProb <- function
> (a,j,dt) that encapsulates different functions (please see code below), using j=
> 0:2 for each j.
>
> It only populates prb if I specify each function independently in the global
> environment and then run the loop with the iF statement, as per below.
> for (j in 0:2) {
>   if (j==0) {
>     prb["0","1"] <- ProbUP(a,j,dt)
>     prb["0","0"] <- ProbMID(a,j,dt)
>     prb["0","-1"] <- ProbDWN(a,j,dt)
>   }
>   else {
>     if (j==jmax) {
>       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
>     }
>     else {
>       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
>     } # Close 2nd IF
>   } # Close 1st IF
> }
>
> Many thanks in advance.
> Kind regards,
>
> Eric Pueyo
> Investment Risk Analyst
> Email:
> Eric.Pueyo at avivainvestors.com<mailto:Eric.Pueyo at avivainvestors.com>
> D: +44 (0)20 7809 8070
> No. 1 Undershaft, London EC3P 3DQ
> Web:
> www.avivainvestors.com<https://urldefense.proofpoint.com/v2/url?u=http-
> 3A__www.avivainvestors.com_&d=CwMFAg&c=zUO0BtkCe66yJvAZ4cAvZg&r=-
> 34SVFvqwmZvbxD0ShuYglbuijP84lygitjFgiP1fxI&m=kRg3I7ESFxV-
> KaNbYHN6DPupgyEmFCiThNO6oDnpAFs&s=tQa1EuXKNfzRgiR2HgG0H_tW_X-
> BCpgebe5AL9A_GC8&e=>
>
> jmax<-2
> prb <-matrix(0L,nrow=5, ncol=3)
> rownames(prb) <- c(seq(-2,2, by = 1))
> colnames(prb) <- c(-1,0,1)
> a<- 0.1
> dt<-1
>
> ExpX <-function(x,a,dt) {                              ######Defines the Expectation of X
> on t+1 | t
> ExpX <- x*exp(-a*dt)
> ExpX
> }
> Mfactor<-function(a,dt)  {                           #######Factor multiplicative
>   Mfactor<- exp(-a*dt)-1
>   Mfactor
> }
> VarX <-function(sigma,a,dt) {                         #######Defubes the Variance of X
> on t+1 | t
>   VarX <- (sigma^2/(2*a))*(1-exp(-2*a*dt))
>   VarX
> }
> DeltaX <-function(sigma,a,dt) {                       ######Defines the change of X
>   DeltaX<- sqrt(3*VarX(sigma,a,dt))
>   DeltaX<-value(DeltaX)
> }
>
> Mfactor<-function(a,dt)  {                           #######Factor multiplicative
>   Mfactor<- exp(-a*dt)-1
>   Mfactor
> }
>
> KNode<-function(sigma,x,a,j,dt) {                    ######Central Node
>   KNode<- round(ExpX(x,a,dt)/DeltaX(sigma,a,dt))
>   KNode
> }
>
> ####### Probability Calculations taking into account different branches
> HWMProb <- function (a,j,dt) {
>   ######################### DESCRIPTION
> #####################################
>   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> dt)) / 2)                     ######### Probability X going up
>   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)
> ######## Probability X going middle
>   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a,
> dt)) / 2)                  #######  Probability X going down
>   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j *
> Mfactor(a, dt)) / 2                 ####### Top branch probability going up
>   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j *
> Mfactor(a, dt)              ####### Top branch probability going MID
>   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j *
> Mfactor(a, dt)) / 2               ####### Top branch probability going DOWN
>   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> Mfactor(a, dt)) / 2           ####### Bottom branch probability going u
>   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j *
> Mfactor(a, dt)               ####### Bottom branch probability going MID
>   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j *
> Mfactor(a, dt)) / 2              ####### Bottom branch probability going DOWN
>
>   if (j==0) {
>     prb["0","1"] <- ProbUP(a,j,dt)
>     prb["0","0"] <- ProbMID(a,j,dt)
>     prb["0","-1"] <- ProbDWN(a,j,dt)
>   }
>   else {
>     if (j==jmax) {
>       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
>     }
>     else {
>       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
>      prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
>     } # Close 2nd IF
>   } # Close 1st IF
> } #Close Formula
>
> for (j in 0:2) {
>   HWMProb(a,j,dt)
>
> }
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ebs15242 at gmail.com  Thu Nov  2 17:27:29 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 2 Nov 2017 11:27:29 -0500
Subject: [R] ggplot inside function doesn't plot
Message-ID: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>

I have a function:

myplot <- function (X) {
    d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
    png(paste("img/", X, ".png", sep=""))
    ggplot(d, aes(x=condition, y=count, color=condition)) +
        geom_point(position=position_jitter(w=0.1,h=0)) +
        scale_y_log10(breaks=c(25,100,400)) +
        ggtitle(X) +
        theme(plot.title = element_text(hjust = 0.5))

    dev.off()
    }

'd' is a dataframe

                             count      condition
E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO

If I set X="Etv5" and paste the contents of the function into R, I get
'img/Etv5.png'
If I run myplot(X), I get nothing.


> X
[1] "Etv5"
> list.files("img")
character(0)
> myplot(X)
null device
          1
> list.files("img")
character(0)
> d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
> png(paste("img/", X, ".png", sep=""))
> ggplot(d, aes(x=condition, y=count, color=condition)) +
+ geom_point(position=position_jitter(w=0.1,h=0)) +
+ scale_y_log10(breaks=c(25,100,400)) +
+ ggtitle(X) +
+ theme(plot.title = element_text(hjust = 0.5))
> dev.off()
null device
          1
> list.files("img")
[1] "Etv5.png"

Why doesn't my function work?


From petr.pikal at precheza.cz  Thu Nov  2 17:49:28 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Nov 2017 16:49:28 +0000
Subject: [R] ggplot inside function doesn't plot
In-Reply-To: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
References: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8260@SRVEXCHCM301.precheza.cz>

Hi

You have to print it.

just add

print(all ggplot stuff)

inside the function.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ed Siefker
> Sent: Thursday, November 2, 2017 5:27 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] ggplot inside function doesn't plot
>
> I have a function:
>
> myplot <- function (X) {
>     d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>     png(paste("img/", X, ".png", sep=""))
>     ggplot(d, aes(x=condition, y=count, color=condition)) +
>         geom_point(position=position_jitter(w=0.1,h=0)) +
>         scale_y_log10(breaks=c(25,100,400)) +
>         ggtitle(X) +
>         theme(plot.title = element_text(hjust = 0.5))
>
>     dev.off()
>     }
>
> 'd' is a dataframe
>
>                              count      condition
> E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
> E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
> E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
> E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
> E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
> E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO
>
> If I set X="Etv5" and paste the contents of the function into R, I get
> 'img/Etv5.png'
> If I run myplot(X), I get nothing.
>
>
> > X
> [1] "Etv5"
> > list.files("img")
> character(0)
> > myplot(X)
> null device
>           1
> > list.files("img")
> character(0)
> > d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
> > png(paste("img/", X, ".png", sep="")) ggplot(d, aes(x=condition,
> > y=count, color=condition)) +
> + geom_point(position=position_jitter(w=0.1,h=0)) +
> + scale_y_log10(breaks=c(25,100,400)) +
> + ggtitle(X) +
> + theme(plot.title = element_text(hjust = 0.5))
> > dev.off()
> null device
>           1
> > list.files("img")
> [1] "Etv5.png"
>
> Why doesn't my function work?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dwinsemius at comcast.net  Thu Nov  2 17:54:48 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 09:54:48 -0700
Subject: [R] ggplot inside function doesn't plot
In-Reply-To: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
References: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
Message-ID: <98E6544A-F660-446F-8F5F-432D84FDDA89@comcast.net>


> On Nov 2, 2017, at 9:27 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
> 
> I have a function:
> 
> myplot <- function (X) {
>    d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>    png(paste("img/", X, ".png", sep=""))
>    ggplot(d, aes(x=condition, y=count, color=condition)) +
>        geom_point(position=position_jitter(w=0.1,h=0)) +
>        scale_y_log10(breaks=c(25,100,400)) +
>        ggtitle(X) +
>        theme(plot.title = element_text(hjust = 0.5))
> 
>    dev.off()
>    }
> 
> 'd' is a dataframe
> 
>                             count      condition
> E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
> E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
> E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
> E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
> E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
> E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO
> 
> If I set X="Etv5" and paste the contents of the function into R, I get
> 'img/Etv5.png'
> If I run myplot(X), I get nothing.
> 
> 
>> X
> [1] "Etv5"
>> list.files("img")
> character(0)
>> myplot(X)
> null device
>          1
>> list.files("img")
> character(0)
>> d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>> png(paste("img/", X, ".png", sep=""))
>> ggplot(d, aes(x=condition, y=count, color=condition)) +
> + geom_point(position=position_jitter(w=0.1,h=0)) +
> + scale_y_log10(breaks=c(25,100,400)) +
> + ggtitle(X) +
> + theme(plot.title = element_text(hjust = 0.5))
>> dev.off()
> null device
>          1
>> list.files("img")
> [1] "Etv5.png"
> 
> Why doesn't my function work?

`ggplot` creates an object. You need to print it when used inside a function. Inside a function (in a more restricted environment) there is no parse-eval-print-loop.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ebs15242 at gmail.com  Thu Nov  2 18:03:24 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 2 Nov 2017 12:03:24 -0500
Subject: [R] ggplot inside function doesn't plot
In-Reply-To: <98E6544A-F660-446F-8F5F-432D84FDDA89@comcast.net>
References: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
 <98E6544A-F660-446F-8F5F-432D84FDDA89@comcast.net>
Message-ID: <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>

I don't really understand. I mean, I understand the solution is
print(ggplot(...)).  But why is that required in a function and not at
the console?

Shouldn't I be able to rely on what I do at the console working in a
script?  Is this inconsistent behavior by design?



On Thu, Nov 2, 2017 at 11:54 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Nov 2, 2017, at 9:27 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
>>
>> I have a function:
>>
>> myplot <- function (X) {
>>    d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>    png(paste("img/", X, ".png", sep=""))
>>    ggplot(d, aes(x=condition, y=count, color=condition)) +
>>        geom_point(position=position_jitter(w=0.1,h=0)) +
>>        scale_y_log10(breaks=c(25,100,400)) +
>>        ggtitle(X) +
>>        theme(plot.title = element_text(hjust = 0.5))
>>
>>    dev.off()
>>    }
>>
>> 'd' is a dataframe
>>
>>                             count      condition
>> E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
>> E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
>> E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
>> E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
>> E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
>> E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO
>>
>> If I set X="Etv5" and paste the contents of the function into R, I get
>> 'img/Etv5.png'
>> If I run myplot(X), I get nothing.
>>
>>
>>> X
>> [1] "Etv5"
>>> list.files("img")
>> character(0)
>>> myplot(X)
>> null device
>>          1
>>> list.files("img")
>> character(0)
>>> d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>> png(paste("img/", X, ".png", sep=""))
>>> ggplot(d, aes(x=condition, y=count, color=condition)) +
>> + geom_point(position=position_jitter(w=0.1,h=0)) +
>> + scale_y_log10(breaks=c(25,100,400)) +
>> + ggtitle(X) +
>> + theme(plot.title = element_text(hjust = 0.5))
>>> dev.off()
>> null device
>>          1
>>> list.files("img")
>> [1] "Etv5.png"
>>
>> Why doesn't my function work?
>
> `ggplot` creates an object. You need to print it when used inside a function. Inside a function (in a more restricted environment) there is no parse-eval-print-loop.
>
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>


From bgunter.4567 at gmail.com  Thu Nov  2 18:08:56 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Nov 2017 10:08:56 -0700
Subject: [R] repeat a function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>
References: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>
Message-ID: <CAGxFJbRbKRPGjNPLgiPDsKR_T5AR50g0Pjfmi48MoFM678Xjqg@mail.gmail.com>

Petr et al. :

I only wish to comment on Petr's remark; I have nothing useful to say about
the subject of this thread.

"AFAIK if a function is defined within another function (which is your
case) it cannot be called directly so it is necessary to define it in
global environment."

Right, a deliberate consequence of R's (lexical) scoping semantics.
However, as you are probably aware, a function can *return* a function that
is then visible and can be called in the caller's scope. e.g. , using your
example:

> fff <- function(a){
    function(x) x^2 + a
 }

> fff(2)(3) ## note syntax: 3^2 + 2
[1] 11

> fff(3)(2) ## 2^2 + 3
[1] 7

## or you can assign the function to a symbol and call it directly

> myf <- fff(2)

> myf(3) ## 3^2 + 2
[1] 11


You all can decide whether or not this is useful in the current context.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 2, 2017 at 8:56 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi Eric
>
> I did not see any answer and frankly speaking I cannot provide you with
> canned help.
>
> AFAIK if a function is defined within another function (which is your
> case) it cannot be called directly so it is necessary to define it in
> global environment.
>
> >  fff <- function(x) {
> +  myf <- function(a) a+2
> +  myf(x)^2}
> >
> > fff(5)
> [1] 49
> > myf(5)
> Error in myf(5) : could not find function "myf"
> >
>
> Your function set is quite complicated but I wonder why would it be
> necessary to use for cycle for what seems to be simple table. Everything
> seems quite deterministic.
>
> Basically you have combination of rows (-2,-1,0,1,2) and columns -1,-,1.
> expand.grid(u=-2:2, v=-1:1)
> for each row you can than use one function with parameters u, v and a and
> dt.
> After you calculate vector of results, you can easily transform it to
> matrix by setting dim argument to it.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Eric.Pueyo at avivainvestors.com
> > Sent: Wednesday, November 1, 2017 1:31 PM
> > To: r-help at r-project.org
> > Subject: [R] repeat a function
> >
> > I want to populate the matrix prb through the function HWMProb <-
> function
> > (a,j,dt) that encapsulates different functions (please see code below),
> using j=
> > 0:2 for each j.
> >
> > It only populates prb if I specify each function independently in the
> global
> > environment and then run the loop with the iF statement, as per below.
> > for (j in 0:2) {
> >   if (j==0) {
> >     prb["0","1"] <- ProbUP(a,j,dt)
> >     prb["0","0"] <- ProbMID(a,j,dt)
> >     prb["0","-1"] <- ProbDWN(a,j,dt)
> >   }
> >   else {
> >     if (j==jmax) {
> >       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
> >     }
> >     else {
> >       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
> >     } # Close 2nd IF
> >   } # Close 1st IF
> > }
> >
> > Many thanks in advance.
> > Kind regards,
> >
> > Eric Pueyo
> > Investment Risk Analyst
> > Email:
> > Eric.Pueyo at avivainvestors.com<mailto:Eric.Pueyo at avivainvestors.com>
> > D: +44 (0)20 7809 8070
> > No. 1 Undershaft, London EC3P 3DQ
> > Web:
> > www.avivainvestors.com<https://urldefense.proofpoint.com/v2/url?u=http-
> > 3A__www.avivainvestors.com_&d=CwMFAg&c=zUO0BtkCe66yJvAZ4cAvZg&r=-
> > 34SVFvqwmZvbxD0ShuYglbuijP84lygitjFgiP1fxI&m=kRg3I7ESFxV-
> > KaNbYHN6DPupgyEmFCiThNO6oDnpAFs&s=tQa1EuXKNfzRgiR2HgG0H_tW_X-
> > BCpgebe5AL9A_GC8&e=>
> >
> > jmax<-2
> > prb <-matrix(0L,nrow=5, ncol=3)
> > rownames(prb) <- c(seq(-2,2, by = 1))
> > colnames(prb) <- c(-1,0,1)
> > a<- 0.1
> > dt<-1
> >
> > ExpX <-function(x,a,dt) {                              ######Defines the
> Expectation of X
> > on t+1 | t
> > ExpX <- x*exp(-a*dt)
> > ExpX
> > }
> > Mfactor<-function(a,dt)  {                           #######Factor
> multiplicative
> >   Mfactor<- exp(-a*dt)-1
> >   Mfactor
> > }
> > VarX <-function(sigma,a,dt) {                         #######Defubes the
> Variance of X
> > on t+1 | t
> >   VarX <- (sigma^2/(2*a))*(1-exp(-2*a*dt))
> >   VarX
> > }
> > DeltaX <-function(sigma,a,dt) {                       ######Defines the
> change of X
> >   DeltaX<- sqrt(3*VarX(sigma,a,dt))
> >   DeltaX<-value(DeltaX)
> > }
> >
> > Mfactor<-function(a,dt)  {                           #######Factor
> multiplicative
> >   Mfactor<- exp(-a*dt)-1
> >   Mfactor
> > }
> >
> > KNode<-function(sigma,x,a,j,dt) {                    ######Central Node
> >   KNode<- round(ExpX(x,a,dt)/DeltaX(sigma,a,dt))
> >   KNode
> > }
> >
> > ####### Probability Calculations taking into account different branches
> > HWMProb <- function (a,j,dt) {
> >   ######################### DESCRIPTION
> > #####################################
> >   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j
> * Mfactor(a,
> > dt)) / 2)                     ######### Probability X going up
> >   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)
> > ######## Probability X going middle
> >   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j
> * Mfactor(a,
> > dt)) / 2)                  #######  Probability X going down
> >   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 +
> 3 * j *
> > Mfactor(a, dt)) / 2                 ####### Top branch probability going
> up
> >   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 -
> 2 * j *
> > Mfactor(a, dt)              ####### Top branch probability going MID
> >   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 +
> j *
> > Mfactor(a, dt)) / 2               ####### Top branch probability going
> DOWN
> >   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 -
> j *
> > Mfactor(a, dt)) / 2           ####### Bottom branch probability going u
> >   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2
> + 2 * j *
> > Mfactor(a, dt)               ####### Bottom branch probability going MID
> >   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2
> - 3 * j *
> > Mfactor(a, dt)) / 2              ####### Bottom branch probability going
> DOWN
> >
> >   if (j==0) {
> >     prb["0","1"] <- ProbUP(a,j,dt)
> >     prb["0","0"] <- ProbMID(a,j,dt)
> >     prb["0","-1"] <- ProbDWN(a,j,dt)
> >   }
> >   else {
> >     if (j==jmax) {
> >       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
> >     }
> >     else {
> >       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
> >      prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
> >     } # Close 2nd IF
> >   } # Close 1st IF
> > } #Close Formula
> >
> > for (j in 0:2) {
> >   HWMProb(a,j,dt)
> >
> > }
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Thu Nov  2 18:15:45 2017
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 2 Nov 2017 13:15:45 -0400
Subject: [R] Cox Regression : Spline Coefficient Interpretation?
In-Reply-To: <CALgq08bCmMKuZioj3uPby+XoLROzk2QsJ_hKweFJBOTLsmUh5Q@mail.gmail.com>
References: <CALgq08bCmMKuZioj3uPby+XoLROzk2QsJ_hKweFJBOTLsmUh5Q@mail.gmail.com>
Message-ID: <d8bccfa7-4a8a-ca49-dbe2-3985ff816383@utoronto.ca>

Your output is mangled beyond interpretation.

However, when it comes to interpreting splines in general, you cannot 
easily convert the individual beta coefficients into, say HR by 
exponenitating them. The collection of beta coefficients describe the 
relationship between the continuous variable and the outcome.

Consider a simple case. Suppose you fit a model with x and x^2. You 
cannot really interpret the x^2 coefficient in isolation from the x 
coefficient. It is the same with splines only worse.

Graphical displays of the spline are often more informative.

Kevin

On 11/01/2017 04:12 PM, Kosta S. wrote:
> Hi,
> 
> I'm using a Cox-Regression to estimate hazard rates on prepayments.
> 
> I'm using the "pspline" function to face non-linearity, but I have no clue
> how to interpret the result.
> Unfortunately I did not find enough information on the "pspline" function
> wether in the survival package nor using google..
> 
> I got following output:
> 
> * library(survival)*
> 
> 
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *> Option.test2<-coxph(Surv(START,STOP,ZEROBAL==1)~pspline(OPTION),
>> data=FNMA)coxph(formula = Surv(START, STOP, ZEROBAL == 1) ~
>> pspline(OPTION),     data = FNMA)> > Option.test2> Call:> coxph(formula =
>> Surv(START, STOP, ZEROBAL == 1) ~ pspline(OPTION), >     data = FNMA)>
>>                           coef  se(coef)       se2     Chisq   DF
>>          p> pspline(OPTION), linear   -0.1334    0.0131    0.0131  104.4325
>> 1.00 <0.0000000000000002> pspline(OPTION), nonlin
>>      1747.1295 3.05 <0.0000000000000002> Iterations: 8 outer, 19
>> Newton-Raphson>      Theta= 0.991 > Degrees of freedom for terms= 4 >
>> Likelihood ratio test=2136  on 4.05 df, p=0  n= 3390429 >  *
> 
> 
> Thanks,
> 
> KS
> 


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From rmh at temple.edu  Thu Nov  2 18:19:30 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 2 Nov 2017 13:19:30 -0400
Subject: [R] ggplot inside function doesn't plot
In-Reply-To: <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>
References: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
 <98E6544A-F660-446F-8F5F-432D84FDDA89@comcast.net>
 <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>
Message-ID: <CAGx1TMCrgjoZGjFuy24RsUJ0Bw34khPqrtMOWcYh7AGLwmqw0w@mail.gmail.com>

FAQ 7.22

Open the file indicated by
system.file("../../doc/FAQ")
and scroll down to 7.22



On Thu, Nov 2, 2017 at 1:03 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I don't really understand. I mean, I understand the solution is
> print(ggplot(...)).  But why is that required in a function and not at
> the console?
>
> Shouldn't I be able to rely on what I do at the console working in a
> script?  Is this inconsistent behavior by design?
>
>
>
> On Thu, Nov 2, 2017 at 11:54 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Nov 2, 2017, at 9:27 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
>>>
>>> I have a function:
>>>
>>> myplot <- function (X) {
>>>    d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>>    png(paste("img/", X, ".png", sep=""))
>>>    ggplot(d, aes(x=condition, y=count, color=condition)) +
>>>        geom_point(position=position_jitter(w=0.1,h=0)) +
>>>        scale_y_log10(breaks=c(25,100,400)) +
>>>        ggtitle(X) +
>>>        theme(plot.title = element_text(hjust = 0.5))
>>>
>>>    dev.off()
>>>    }
>>>
>>> 'd' is a dataframe
>>>
>>>                             count      condition
>>> E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
>>> E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
>>> E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
>>> E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
>>> E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
>>> E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO
>>>
>>> If I set X="Etv5" and paste the contents of the function into R, I get
>>> 'img/Etv5.png'
>>> If I run myplot(X), I get nothing.
>>>
>>>
>>>> X
>>> [1] "Etv5"
>>>> list.files("img")
>>> character(0)
>>>> myplot(X)
>>> null device
>>>          1
>>>> list.files("img")
>>> character(0)
>>>> d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>>> png(paste("img/", X, ".png", sep=""))
>>>> ggplot(d, aes(x=condition, y=count, color=condition)) +
>>> + geom_point(position=position_jitter(w=0.1,h=0)) +
>>> + scale_y_log10(breaks=c(25,100,400)) +
>>> + ggtitle(X) +
>>> + theme(plot.title = element_text(hjust = 0.5))
>>>> dev.off()
>>> null device
>>>          1
>>>> list.files("img")
>>> [1] "Etv5.png"
>>>
>>> Why doesn't my function work?
>>
>> `ggplot` creates an object. You need to print it when used inside a function. Inside a function (in a more restricted environment) there is no parse-eval-print-loop.
>>
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Nov  2 18:39:05 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 2 Nov 2017 13:39:05 -0400
Subject: [R] ggplot inside function doesn't plot
In-Reply-To: <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>
References: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
 <98E6544A-F660-446F-8F5F-432D84FDDA89@comcast.net>
 <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>
Message-ID: <bd584a8d-ce78-6a06-ae0b-2e121a0da1e3@gmail.com>

On 02/11/2017 1:03 PM, Ed Siefker wrote:
> I don't really understand. I mean, I understand the solution is
> print(ggplot(...)).  But why is that required in a function and not at
> the console?
> 
> Shouldn't I be able to rely on what I do at the console working in a
> script?  Is this inconsistent behavior by design?

Yes, it's by design.  At top level, values are normally printed after 
being computed (but this can be turned off).  So

x <- 5
x + 1

will print 6 after the second line.  If you have the line "x + 1" in a 
function, nothing will print.  So you can have a function

addOne <- function(x) {
   x + 1
}

and you can call it lots of times from other functions without printing 
a line each time.

Duncan Murdoch

> 
> 
> 
> On Thu, Nov 2, 2017 at 11:54 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Nov 2, 2017, at 9:27 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
>>>
>>> I have a function:
>>>
>>> myplot <- function (X) {
>>>     d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>>     png(paste("img/", X, ".png", sep=""))
>>>     ggplot(d, aes(x=condition, y=count, color=condition)) +
>>>         geom_point(position=position_jitter(w=0.1,h=0)) +
>>>         scale_y_log10(breaks=c(25,100,400)) +
>>>         ggtitle(X) +
>>>         theme(plot.title = element_text(hjust = 0.5))
>>>
>>>     dev.off()
>>>     }
>>>
>>> 'd' is a dataframe
>>>
>>>                              count      condition
>>> E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
>>> E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
>>> E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
>>> E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
>>> E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
>>> E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO
>>>
>>> If I set X="Etv5" and paste the contents of the function into R, I get
>>> 'img/Etv5.png'
>>> If I run myplot(X), I get nothing.
>>>
>>>
>>>> X
>>> [1] "Etv5"
>>>> list.files("img")
>>> character(0)
>>>> myplot(X)
>>> null device
>>>           1
>>>> list.files("img")
>>> character(0)
>>>> d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>>> png(paste("img/", X, ".png", sep=""))
>>>> ggplot(d, aes(x=condition, y=count, color=condition)) +
>>> + geom_point(position=position_jitter(w=0.1,h=0)) +
>>> + scale_y_log10(breaks=c(25,100,400)) +
>>> + ggtitle(X) +
>>> + theme(plot.title = element_text(hjust = 0.5))
>>>> dev.off()
>>> null device
>>>           1
>>>> list.files("img")
>>> [1] "Etv5.png"
>>>
>>> Why doesn't my function work?
>>
>> `ggplot` creates an object. You need to print it when used inside a function. Inside a function (in a more restricted environment) there is no parse-eval-print-loop.
>>
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Nov  2 18:48:50 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 10:48:50 -0700
Subject: [R] ggplot inside function doesn't plot
In-Reply-To: <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>
References: <CALRb-ofqSXQFcq8XXq6arb6paFEfLqaukbYiv7ETCUHC8CqLgg@mail.gmail.com>
 <98E6544A-F660-446F-8F5F-432D84FDDA89@comcast.net>
 <CALRb-odGG7EquE1SND=d41jEqmJf++V_MpzhbeB=J_=W1cZS2Q@mail.gmail.com>
Message-ID: <31211EE1-8AC0-4C1D-B30D-2C4D9A943E6C@comcast.net>


> On Nov 2, 2017, at 10:03 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
> 
> I don't really understand. I mean, I understand the solution is
> print(ggplot(...)).  But why is that required in a function and not at
> the console?

The REPL design of the interactive console is offered the user as a convenience, but I agree it's somewhat at odds with pure functional principles. 

> 
> Shouldn't I be able to rely on what I do at the console working in a
> script?  Is this inconsistent behavior by design?

By design? Yes. Completely by design. Functions are a method of encapsulating intermediate results in a manner that does not interact with the objects that exist outside the function. There are three plotting paradigms: base-graphics, lattice, and ggplot. The latter two are built with grid graphics and a both more functional and object oriented (loosely spoken since they return objects) than base graphics. Base graphics behaves the way you expect. Execution of `lines` or `points` will give you "pen-on-ink" output, actually pixel on device output.


> 
> 
> 
> On Thu, Nov 2, 2017 at 11:54 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Nov 2, 2017, at 9:27 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
>>> 
>>> I have a function:
>>> 
>>> myplot <- function (X) {
>>>   d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>>   png(paste("img/", X, ".png", sep=""))
>>>   ggplot(d, aes(x=condition, y=count, color=condition)) +
>>>       geom_point(position=position_jitter(w=0.1,h=0)) +
>>>       scale_y_log10(breaks=c(25,100,400)) +
>>>       ggtitle(X) +
>>>       theme(plot.title = element_text(hjust = 0.5))
>>> 
>>>   dev.off()
>>>   }
>>> 
>>> 'd' is a dataframe
>>> 
>>>                            count      condition
>>> E11.5 F20HET BA40_quant   955.9788   E11.5 F20HET
>>> E11.5 F20HET BA45_quant   796.2863   E11.5 F20HET
>>> E11.5 F20HET BB84_quant   745.0340   E11.5 F20HET
>>> E11.5 F9.20DKO YEH3_quant 334.2994 E11.5 F9.20DKO
>>> E11.5 F9.20DKO fkm1_quant 313.7307 E11.5 F9.20DKO
>>> E11.5 F9.20DKO zzE2_quant 349.3313 E11.5 F9.20DKO
>>> 
>>> If I set X="Etv5" and paste the contents of the function into R, I get
>>> 'img/Etv5.png'
>>> If I run myplot(X), I get nothing.
>>> 
>>> 
>>>> X
>>> [1] "Etv5"
>>>> list.files("img")
>>> character(0)
>>>> myplot(X)
>>> null device
>>>         1
>>>> list.files("img")
>>> character(0)
>>>> d <- plotCounts(dds2, gene=X, intgroup="condition", returnData=TRUE)
>>>> png(paste("img/", X, ".png", sep=""))
>>>> ggplot(d, aes(x=condition, y=count, color=condition)) +
>>> + geom_point(position=position_jitter(w=0.1,h=0)) +
>>> + scale_y_log10(breaks=c(25,100,400)) +
>>> + ggtitle(X) +
>>> + theme(plot.title = element_text(hjust = 0.5))
>>>> dev.off()
>>> null device
>>>         1
>>>> list.files("img")
>>> [1] "Etv5.png"
>>> 
>>> Why doesn't my function work?
>> 
>> `ggplot` creates an object. You need to print it when used inside a function. Inside a function (in a more restricted environment) there is no parse-eval-print-loop.
>> 
>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>> 
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tlkantro at gmail.com  Thu Nov  2 19:15:10 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Thu, 2 Nov 2017 14:15:10 -0400
Subject: [R] "prob" package alternative
In-Reply-To: <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
Message-ID: <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>

The issue is fAsianOptions. Is there a version that works with the latest
version of R? If not, which version of it works with which version of R and
where can it be found? I tried several at the archive already.

Alternatively, is there another package that behaves similarly to prob?



On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > The prob package has been archived because it depends upon some other
> > packages which have issues.
> >
> > However, such projects as Introduction to Probability and Statistics in R
> > depend upon it for learning. There are a few other resources that also
> use
> > it.
> >
> > Does anyone know of any workarounds?
> >
> > Someone at stack exchange mentioned using R 2.9.
>
> I'm not sure I would trust that person. They seem a bit uninformed.
>
> > However, that broke my
> > RStudio (WSOD) and the dependent packages still wouldn't install, anyway.
>
> The latest version of pkg-prob at the Archive directory of CRAN indicates
> that it was last updated within this year. The DESCRIPTION file indicates
> that it does not need compilation, but:
>
> Depends: combinat, fAsianOptions
>
> So there should be code in text files in its ../R directory which can be
> sourced from that directory.
>
> ~myuser_name$ ls /Users/../Downloads/prob/R
> characteristicfunctions.r       simulation.r
> utils-spaces.r
> genData.R                       spaces-examples.r
>  utils-subsets.r
> misc.r                          spaces-prob.r
> prob.r                          utils-events.r
>
>
> Or you can install from source after downloading:
>
> install.packages("~/Downloads/prob", repo=NULL,type="source")
>
> # Success
>
>
> >  library(prob)   # So does require having several other packages
> Loading required package: combinat
>
> Attaching package: ?combinat?
>
> The following object is masked from ?package:utils?:
>
>     combn
>
> Loading required package: fAsianOptions
> Loading required package: timeDate
>
> Attaching package: ?timeDate?
>
> The following object is masked from ?package:cairoDevice?:
>
>     Cairo
>
> The following objects are masked from ?package:PerformanceAnalytics?:
>
>     kurtosis, skewness
>
> Loading required package: timeSeries
>
> Attaching package: ?timeSeries?
>
> The following object is masked from ?package:zoo?:
>
>     time<-
>
> Loading required package: fBasics
>
>
> Rmetrics Package fBasics
> Analysing Markets and calculating Basic Statistics
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
> Loading required package: fOptions
>
>
> Rmetrics Package fOptions
> Pricing and Evaluating Basic Options
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
>
> Attaching package: ?prob?
>
> The following objects are masked from ?package:dplyr?:
>
>     intersect, setdiff, union
>
> The following objects are masked from ?package:base?:
>
>     intersect, setdiff, union
>
> >
> >
> >
> > Tiby
> >
> >       [[alternative HTML version deleted]]
>
> A specific suggestion would be that you read the listinfo and the Posting
> Guide and learn to post in plain text.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Nov  2 19:29:13 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 11:29:13 -0700
Subject: [R] "prob" package alternative
In-Reply-To: <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
Message-ID: <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>


> On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> 
> The issue is fAsianOptions. Is there a version that works with the latest version of R? If not, which version of it works with which version of R and where can it be found? I tried several at the archive already.

sessionInfo()
R version 3.4.2 Patched (2017-10-04 r73465)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

> 


packageDescription("fAsianOptions")
Package: fAsianOptions
Version: 3010.79
Revision: 5522
Date: 2013-06-23
Title: EBM and Asian Option Valuation
Author: Diethelm Wuertz and many others, see the SOURCE file
Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
Suggests: RUnit
Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
Description: Environment for teaching "Financial Engineering and Computational Finance"
Note: Several parts are still preliminary and may be changed in the future. this
          typically includes function and argument names, as well as defaults for
          arguments and return values.
LazyData: yes
License: GPL (>= 2)
URL: http://www.rmetrics.org
Packaged: 2013-06-23 18:22:14 UTC; yohan
NeedsCompilation: yes
Repository: CRAN
Date/Publication: 2013-06-24 01:53:27
Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix



> Alternatively, is there another package that behaves similarly to prob?
> 
> 
> 
> On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > The prob package has been archived because it depends upon some other
> > packages which have issues.
> >
> > However, such projects as Introduction to Probability and Statistics in R
> > depend upon it for learning. There are a few other resources that also use
> > it.
> >
> > Does anyone know of any workarounds?
> >
> > Someone at stack exchange mentioned using R 2.9.
> 
> I'm not sure I would trust that person. They seem a bit uninformed.
> 
> > However, that broke my
> > RStudio (WSOD) and the dependent packages still wouldn't install, anyway.
> 
> The latest version of pkg-prob at the Archive directory of CRAN indicates that it was last updated within this year. The DESCRIPTION file indicates that it does not need compilation, but:
> 
> Depends: combinat, fAsianOptions
> 
> So there should be code in text files in its ../R directory which can be sourced from that directory.
> 
> ~myuser_name$ ls /Users/../Downloads/prob/R
> characteristicfunctions.r       simulation.r                    utils-spaces.r
> genData.R                       spaces-examples.r               utils-subsets.r
> misc.r                          spaces-prob.r
> prob.r                          utils-events.r
> 
> 
> Or you can install from source after downloading:
> 
> install.packages("~/Downloads/prob", repo=NULL,type="source")
> 
> # Success
> 
> 
> >  library(prob)   # So does require having several other packages
> Loading required package: combinat
> 
> Attaching package: ?combinat?
> 
> The following object is masked from ?package:utils?:
> 
>     combn
> 
> Loading required package: fAsianOptions
> Loading required package: timeDate
> 
> Attaching package: ?timeDate?
> 
> The following object is masked from ?package:cairoDevice?:
> 
>     Cairo
> 
> The following objects are masked from ?package:PerformanceAnalytics?:
> 
>     kurtosis, skewness
> 
> Loading required package: timeSeries
> 
> Attaching package: ?timeSeries?
> 
> The following object is masked from ?package:zoo?:
> 
>     time<-
> 
> Loading required package: fBasics
> 
> 
> Rmetrics Package fBasics
> Analysing Markets and calculating Basic Statistics
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
> Loading required package: fOptions
> 
> 
> Rmetrics Package fOptions
> Pricing and Evaluating Basic Options
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
> 
> Attaching package: ?prob?
> 
> The following objects are masked from ?package:dplyr?:
> 
>     intersect, setdiff, union
> 
> The following objects are masked from ?package:base?:
> 
>     intersect, setdiff, union
> 
> >
> >
> >
> > Tiby
> >
> >       [[alternative HTML version deleted]]
> 
> A specific suggestion would be that you read the listinfo and the Posting Guide and learn to post in plain text.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tlkantro at gmail.com  Thu Nov  2 20:07:50 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Thu, 2 Nov 2017 15:07:50 -0400
Subject: [R] "prob" package alternative
In-Reply-To: <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
Message-ID: <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>

Yes. That's the version I've been discussing that has non-zero exit status.
That situation is why CRAN retired the prob package. It's possible you
installed that library earlier in development and it's been "carried"
along. It no longer installs, now.

The problems with all of this seem to have started this month according to
the conversations. However, no one has mentioned any solutions or
workarounds except the one mentioned in passing (2.9).

Is there some other package that does something similar to prob that can be
used instead?

On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > The issue is fAsianOptions. Is there a version that works with the
> latest version of R? If not, which version of it works with which version
> of R and where can it be found? I tried several at the archive already.
>
> sessionInfo()
> R version 3.4.2 Patched (2017-10-04 r73465)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: OS X El Capitan 10.11.6
>
> >
>
>
> packageDescription("fAsianOptions")
> Package: fAsianOptions
> Version: 3010.79
> Revision: 5522
> Date: 2013-06-23
> Title: EBM and Asian Option Valuation
> Author: Diethelm Wuertz and many others, see the SOURCE file
> Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> Suggests: RUnit
> Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> Description: Environment for teaching "Financial Engineering and
> Computational Finance"
> Note: Several parts are still preliminary and may be changed in the
> future. this
>           typically includes function and argument names, as well as
> defaults for
>           arguments and return values.
> LazyData: yes
> License: GPL (>= 2)
> URL: http://www.rmetrics.org
> Packaged: 2013-06-23 18:22:14 UTC; yohan
> NeedsCompilation: yes
> Repository: CRAN
> Date/Publication: 2013-06-24 01:53:27
> Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix
>
>
>
> > Alternatively, is there another package that behaves similarly to prob?
> >
> >
> >
> > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > >
> > > The prob package has been archived because it depends upon some other
> > > packages which have issues.
> > >
> > > However, such projects as Introduction to Probability and Statistics
> in R
> > > depend upon it for learning. There are a few other resources that also
> use
> > > it.
> > >
> > > Does anyone know of any workarounds?
> > >
> > > Someone at stack exchange mentioned using R 2.9.
> >
> > I'm not sure I would trust that person. They seem a bit uninformed.
> >
> > > However, that broke my
> > > RStudio (WSOD) and the dependent packages still wouldn't install,
> anyway.
> >
> > The latest version of pkg-prob at the Archive directory of CRAN
> indicates that it was last updated within this year. The DESCRIPTION file
> indicates that it does not need compilation, but:
> >
> > Depends: combinat, fAsianOptions
> >
> > So there should be code in text files in its ../R directory which can be
> sourced from that directory.
> >
> > ~myuser_name$ ls /Users/../Downloads/prob/R
> > characteristicfunctions.r       simulation.r
> utils-spaces.r
> > genData.R                       spaces-examples.r
>  utils-subsets.r
> > misc.r                          spaces-prob.r
> > prob.r                          utils-events.r
> >
> >
> > Or you can install from source after downloading:
> >
> > install.packages("~/Downloads/prob", repo=NULL,type="source")
> >
> > # Success
> >
> >
> > >  library(prob)   # So does require having several other packages
> > Loading required package: combinat
> >
> > Attaching package: ?combinat?
> >
> > The following object is masked from ?package:utils?:
> >
> >     combn
> >
> > Loading required package: fAsianOptions
> > Loading required package: timeDate
> >
> > Attaching package: ?timeDate?
> >
> > The following object is masked from ?package:cairoDevice?:
> >
> >     Cairo
> >
> > The following objects are masked from ?package:PerformanceAnalytics?:
> >
> >     kurtosis, skewness
> >
> > Loading required package: timeSeries
> >
> > Attaching package: ?timeSeries?
> >
> > The following object is masked from ?package:zoo?:
> >
> >     time<-
> >
> > Loading required package: fBasics
> >
> >
> > Rmetrics Package fBasics
> > Analysing Markets and calculating Basic Statistics
> > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > Educational Software for Financial Engineering and Computational Science
> > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > Loading required package: fOptions
> >
> >
> > Rmetrics Package fOptions
> > Pricing and Evaluating Basic Options
> > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > Educational Software for Financial Engineering and Computational Science
> > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> >
> > Attaching package: ?prob?
> >
> > The following objects are masked from ?package:dplyr?:
> >
> >     intersect, setdiff, union
> >
> > The following objects are masked from ?package:base?:
> >
> >     intersect, setdiff, union
> >
> > >
> > >
> > >
> > > Tiby
> > >
> > >       [[alternative HTML version deleted]]
> >
> > A specific suggestion would be that you read the listinfo and the
> Posting Guide and learn to post in plain text.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Nov  2 20:44:39 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 12:44:39 -0700
Subject: [R] "prob" package alternative
In-Reply-To: <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
Message-ID: <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>


> On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> 
> Yes. That's the version I've been discussing that has non-zero exit status. That situation is why CRAN retired the prob package. It's possible you installed that library earlier in development and it's been "carried" along. It no longer installs, now.
> 
> The problems with all of this seem to have started this month according to the conversations. However, no one has mentioned any solutions or workarounds except the one mentioned in passing (2.9).

Not true. Not even close to being true. I explained it all on the SO question page that you posted 2 days ago.

-- 

David.
> 
> Is there some other package that does something similar to prob that can be used instead?
> 
> On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > The issue is fAsianOptions. Is there a version that works with the latest version of R? If not, which version of it works with which version of R and where can it be found? I tried several at the archive already.
> 
> sessionInfo()
> R version 3.4.2 Patched (2017-10-04 r73465)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: OS X El Capitan 10.11.6
> 
> >
> 
> 
> packageDescription("fAsianOptions")
> Package: fAsianOptions
> Version: 3010.79
> Revision: 5522
> Date: 2013-06-23
> Title: EBM and Asian Option Valuation
> Author: Diethelm Wuertz and many others, see the SOURCE file
> Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> Suggests: RUnit
> Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> Description: Environment for teaching "Financial Engineering and Computational Finance"
> Note: Several parts are still preliminary and may be changed in the future. this
>           typically includes function and argument names, as well as defaults for
>           arguments and return values.
> LazyData: yes
> License: GPL (>= 2)
> URL: http://www.rmetrics.org
> Packaged: 2013-06-23 18:22:14 UTC; yohan
> NeedsCompilation: yes
> Repository: CRAN
> Date/Publication: 2013-06-24 01:53:27
> Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix
> 
> 
> 
> > Alternatively, is there another package that behaves similarly to prob?
> >
> >
> >
> > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > >
> > > The prob package has been archived because it depends upon some other
> > > packages which have issues.
> > >
> > > However, such projects as Introduction to Probability and Statistics in R
> > > depend upon it for learning. There are a few other resources that also use
> > > it.
> > >
> > > Does anyone know of any workarounds?
> > >
> > > Someone at stack exchange mentioned using R 2.9.
> >
> > I'm not sure I would trust that person. They seem a bit uninformed.
> >
> > > However, that broke my
> > > RStudio (WSOD) and the dependent packages still wouldn't install, anyway.
> >
> > The latest version of pkg-prob at the Archive directory of CRAN indicates that it was last updated within this year. The DESCRIPTION file indicates that it does not need compilation, but:
> >
> > Depends: combinat, fAsianOptions
> >
> > So there should be code in text files in its ../R directory which can be sourced from that directory.
> >
> > ~myuser_name$ ls /Users/../Downloads/prob/R
> > characteristicfunctions.r       simulation.r                    utils-spaces.r
> > genData.R                       spaces-examples.r               utils-subsets.r
> > misc.r                          spaces-prob.r
> > prob.r                          utils-events.r
> >
> >
> > Or you can install from source after downloading:
> >
> > install.packages("~/Downloads/prob", repo=NULL,type="source")
> >
> > # Success
> >
> >
> > >  library(prob)   # So does require having several other packages
> > Loading required package: combinat
> >
> > Attaching package: ?combinat?
> >
> > The following object is masked from ?package:utils?:
> >
> >     combn
> >
> > Loading required package: fAsianOptions
> > Loading required package: timeDate
> >
> > Attaching package: ?timeDate?
> >
> > The following object is masked from ?package:cairoDevice?:
> >
> >     Cairo
> >
> > The following objects are masked from ?package:PerformanceAnalytics?:
> >
> >     kurtosis, skewness
> >
> > Loading required package: timeSeries
> >
> > Attaching package: ?timeSeries?
> >
> > The following object is masked from ?package:zoo?:
> >
> >     time<-
> >
> > Loading required package: fBasics
> >
> >
> > Rmetrics Package fBasics
> > Analysing Markets and calculating Basic Statistics
> > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > Educational Software for Financial Engineering and Computational Science
> > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > Loading required package: fOptions
> >
> >
> > Rmetrics Package fOptions
> > Pricing and Evaluating Basic Options
> > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > Educational Software for Financial Engineering and Computational Science
> > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> >
> > Attaching package: ?prob?
> >
> > The following objects are masked from ?package:dplyr?:
> >
> >     intersect, setdiff, union
> >
> > The following objects are masked from ?package:base?:
> >
> >     intersect, setdiff, union
> >
> > >
> > >
> > >
> > > Tiby
> > >
> > >       [[alternative HTML version deleted]]
> >
> > A specific suggestion would be that you read the listinfo and the Posting Guide and learn to post in plain text.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tlkantro at gmail.com  Thu Nov  2 21:09:04 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Thu, 2 Nov 2017 16:09:04 -0400
Subject: [R] "prob" package alternative
In-Reply-To: <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
Message-ID: <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>

Yes, that is exactly what I was doing two days ago.

Warning in install.packages :
  installation of package ?fAsianOptions_3010.79.tar.gz? had non-zero exit
status

Which is what a reading of the explanation for why "prob" was retired leads
one to expect. Do you have some other suggestion about how to get it to
work? I notice you're not using Windows which might have a relationship to
why it is working for you.

Otherwise, do you know of some other package that could be used instead of
prob?

On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Yes. That's the version I've been discussing that has non-zero exit
> status. That situation is why CRAN retired the prob package. It's possible
> you installed that library earlier in development and it's been "carried"
> along. It no longer installs, now.
> >
> > The problems with all of this seem to have started this month according
> to the conversations. However, no one has mentioned any solutions or
> workarounds except the one mentioned in passing (2.9).
>
> Not true. Not even close to being true. I explained it all on the SO
> question page that you posted 2 days ago.
>
> --
>
> David.
> >
> > Is there some other package that does something similar to prob that can
> be used instead?
> >
> > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > >
> > > The issue is fAsianOptions. Is there a version that works with the
> latest version of R? If not, which version of it works with which version
> of R and where can it be found? I tried several at the archive already.
> >
> > sessionInfo()
> > R version 3.4.2 Patched (2017-10-04 r73465)
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > Running under: OS X El Capitan 10.11.6
> >
> > >
> >
> >
> > packageDescription("fAsianOptions")
> > Package: fAsianOptions
> > Version: 3010.79
> > Revision: 5522
> > Date: 2013-06-23
> > Title: EBM and Asian Option Valuation
> > Author: Diethelm Wuertz and many others, see the SOURCE file
> > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > Suggests: RUnit
> > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > Description: Environment for teaching "Financial Engineering and
> Computational Finance"
> > Note: Several parts are still preliminary and may be changed in the
> future. this
> >           typically includes function and argument names, as well as
> defaults for
> >           arguments and return values.
> > LazyData: yes
> > License: GPL (>= 2)
> > URL: http://www.rmetrics.org
> > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > NeedsCompilation: yes
> > Repository: CRAN
> > Date/Publication: 2013-06-24 01:53:27
> > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix
> >
> >
> >
> > > Alternatively, is there another package that behaves similarly to prob?
> > >
> > >
> > >
> > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > >
> > > > The prob package has been archived because it depends upon some other
> > > > packages which have issues.
> > > >
> > > > However, such projects as Introduction to Probability and Statistics
> in R
> > > > depend upon it for learning. There are a few other resources that
> also use
> > > > it.
> > > >
> > > > Does anyone know of any workarounds?
> > > >
> > > > Someone at stack exchange mentioned using R 2.9.
> > >
> > > I'm not sure I would trust that person. They seem a bit uninformed.
> > >
> > > > However, that broke my
> > > > RStudio (WSOD) and the dependent packages still wouldn't install,
> anyway.
> > >
> > > The latest version of pkg-prob at the Archive directory of CRAN
> indicates that it was last updated within this year. The DESCRIPTION file
> indicates that it does not need compilation, but:
> > >
> > > Depends: combinat, fAsianOptions
> > >
> > > So there should be code in text files in its ../R directory which can
> be sourced from that directory.
> > >
> > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > characteristicfunctions.r       simulation.r
> utils-spaces.r
> > > genData.R                       spaces-examples.r
>  utils-subsets.r
> > > misc.r                          spaces-prob.r
> > > prob.r                          utils-events.r
> > >
> > >
> > > Or you can install from source after downloading:
> > >
> > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > >
> > > # Success
> > >
> > >
> > > >  library(prob)   # So does require having several other packages
> > > Loading required package: combinat
> > >
> > > Attaching package: ?combinat?
> > >
> > > The following object is masked from ?package:utils?:
> > >
> > >     combn
> > >
> > > Loading required package: fAsianOptions
> > > Loading required package: timeDate
> > >
> > > Attaching package: ?timeDate?
> > >
> > > The following object is masked from ?package:cairoDevice?:
> > >
> > >     Cairo
> > >
> > > The following objects are masked from ?package:PerformanceAnalytics?:
> > >
> > >     kurtosis, skewness
> > >
> > > Loading required package: timeSeries
> > >
> > > Attaching package: ?timeSeries?
> > >
> > > The following object is masked from ?package:zoo?:
> > >
> > >     time<-
> > >
> > > Loading required package: fBasics
> > >
> > >
> > > Rmetrics Package fBasics
> > > Analysing Markets and calculating Basic Statistics
> > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > Educational Software for Financial Engineering and Computational
> Science
> > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > Loading required package: fOptions
> > >
> > >
> > > Rmetrics Package fOptions
> > > Pricing and Evaluating Basic Options
> > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > Educational Software for Financial Engineering and Computational
> Science
> > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > >
> > > Attaching package: ?prob?
> > >
> > > The following objects are masked from ?package:dplyr?:
> > >
> > >     intersect, setdiff, union
> > >
> > > The following objects are masked from ?package:base?:
> > >
> > >     intersect, setdiff, union
> > >
> > > >
> > > >
> > > >
> > > > Tiby
> > > >
> > > >       [[alternative HTML version deleted]]
> > >
> > > A specific suggestion would be that you read the listinfo and the
> Posting Guide and learn to post in plain text.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Nov  2 21:25:50 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 13:25:50 -0700
Subject: [R] "prob" package alternative
In-Reply-To: <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
 <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
Message-ID: <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>


> On Nov 2, 2017, at 1:09 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> 
> Yes, that is exactly what I was doing two days ago.
> 
> Warning in install.packages :
>   installation of package ?fAsianOptions_3010.79.tar.gz? had non-zero exit status
> 
> Which is what a reading of the explanation for why "prob" was retired leads one to expect. Do you have some other suggestion about how to get it to work? I notice you're not using Windows which might have a relationship to why it is working for you.


I explained what you needed to do if you were on Windows. You do need to read the explanation more closely, identify the parts you don't understand (in all likelihood the point I made about needing the proper development tools for Windows) _and_ read:

https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installing-packages

If you have trouble understanding or getting success after thoroughly reading these directions, you need to explain what you have done (preserving the order of all operations) and post a complete transcript of all commands and complete error messages.



-- 
David.
> Otherwise, do you know of some other package that could be used instead of prob?
> 
> On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Yes. That's the version I've been discussing that has non-zero exit status. That situation is why CRAN retired the prob package. It's possible you installed that library earlier in development and it's been "carried" along. It no longer installs, now.
> >
> > The problems with all of this seem to have started this month according to the conversations. However, no one has mentioned any solutions or workarounds except the one mentioned in passing (2.9).
> 
> Not true. Not even close to being true. I explained it all on the SO question page that you posted 2 days ago.
> 
> --
> 
> David.
> >
> > Is there some other package that does something similar to prob that can be used instead?
> >
> > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > >
> > > The issue is fAsianOptions. Is there a version that works with the latest version of R? If not, which version of it works with which version of R and where can it be found? I tried several at the archive already.
> >
> > sessionInfo()
> > R version 3.4.2 Patched (2017-10-04 r73465)
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > Running under: OS X El Capitan 10.11.6
> >
> > >
> >
> >
> > packageDescription("fAsianOptions")
> > Package: fAsianOptions
> > Version: 3010.79
> > Revision: 5522
> > Date: 2013-06-23
> > Title: EBM and Asian Option Valuation
> > Author: Diethelm Wuertz and many others, see the SOURCE file
> > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > Suggests: RUnit
> > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > Description: Environment for teaching "Financial Engineering and Computational Finance"
> > Note: Several parts are still preliminary and may be changed in the future. this
> >           typically includes function and argument names, as well as defaults for
> >           arguments and return values.
> > LazyData: yes
> > License: GPL (>= 2)
> > URL: http://www.rmetrics.org
> > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > NeedsCompilation: yes
> > Repository: CRAN
> > Date/Publication: 2013-06-24 01:53:27
> > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix
> >
> >
> >
> > > Alternatively, is there another package that behaves similarly to prob?
> > >
> > >
> > >
> > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > > >
> > > > The prob package has been archived because it depends upon some other
> > > > packages which have issues.
> > > >
> > > > However, such projects as Introduction to Probability and Statistics in R
> > > > depend upon it for learning. There are a few other resources that also use
> > > > it.
> > > >
> > > > Does anyone know of any workarounds?
> > > >
> > > > Someone at stack exchange mentioned using R 2.9.
> > >
> > > I'm not sure I would trust that person. They seem a bit uninformed.
> > >
> > > > However, that broke my
> > > > RStudio (WSOD) and the dependent packages still wouldn't install, anyway.
> > >
> > > The latest version of pkg-prob at the Archive directory of CRAN indicates that it was last updated within this year. The DESCRIPTION file indicates that it does not need compilation, but:
> > >
> > > Depends: combinat, fAsianOptions
> > >
> > > So there should be code in text files in its ../R directory which can be sourced from that directory.
> > >
> > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > characteristicfunctions.r       simulation.r                    utils-spaces.r
> > > genData.R                       spaces-examples.r               utils-subsets.r
> > > misc.r                          spaces-prob.r
> > > prob.r                          utils-events.r
> > >
> > >
> > > Or you can install from source after downloading:
> > >
> > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > >
> > > # Success
> > >
> > >
> > > >  library(prob)   # So does require having several other packages
> > > Loading required package: combinat
> > >
> > > Attaching package: ?combinat?
> > >
> > > The following object is masked from ?package:utils?:
> > >
> > >     combn
> > >
> > > Loading required package: fAsianOptions
> > > Loading required package: timeDate
> > >
> > > Attaching package: ?timeDate?
> > >
> > > The following object is masked from ?package:cairoDevice?:
> > >
> > >     Cairo
> > >
> > > The following objects are masked from ?package:PerformanceAnalytics?:
> > >
> > >     kurtosis, skewness
> > >
> > > Loading required package: timeSeries
> > >
> > > Attaching package: ?timeSeries?
> > >
> > > The following object is masked from ?package:zoo?:
> > >
> > >     time<-
> > >
> > > Loading required package: fBasics
> > >
> > >
> > > Rmetrics Package fBasics
> > > Analysing Markets and calculating Basic Statistics
> > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > Educational Software for Financial Engineering and Computational Science
> > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > Loading required package: fOptions
> > >
> > >
> > > Rmetrics Package fOptions
> > > Pricing and Evaluating Basic Options
> > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > Educational Software for Financial Engineering and Computational Science
> > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > >
> > > Attaching package: ?prob?
> > >
> > > The following objects are masked from ?package:dplyr?:
> > >
> > >     intersect, setdiff, union
> > >
> > > The following objects are masked from ?package:base?:
> > >
> > >     intersect, setdiff, union
> > >
> > > >
> > > >
> > > >
> > > > Tiby
> > > >
> > > >       [[alternative HTML version deleted]]
> > >
> > > A specific suggestion would be that you read the listinfo and the Posting Guide and learn to post in plain text.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From Eric.Pueyo at avivainvestors.com  Thu Nov  2 17:54:29 2017
From: Eric.Pueyo at avivainvestors.com (Eric.Pueyo at avivainvestors.com)
Date: Thu, 2 Nov 2017 16:54:29 +0000
Subject: [R] repeat a function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>
References: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>
Message-ID: <a8a78eb5324b46ed97f050ace3a021e3@DB4PR7001MB0030.015d.mgd.msft.net>

Hi Petr, 

Many thanks for your response.

Basically I want to create a probability matrix to be used in a trinomial tree going forward. This is the reason why I thought to build the matrix around 0 would be much more efficient. I need to loop through because the probabilities will depend on my node and is not always the same per row (e.g. if N> jmax, jmax being defined in another function)
I found a workaround. Please see below. 
Thereafter I want to optimize this function. Hopefully it works.

Many thanks,
Eric

HWMProb <- function(N) {
  ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a, dt)) / 2)          ######### Probability X going up
  ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)                                     ######## Probability X going middle
  ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a, dt)) / 2)          #######  Probability X going down
  TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j * Mfactor(a, dt)) / 2     ####### Top branch probability going up
  TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j * Mfactor(a, dt)          ####### Top branch probability going MID
  TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a, dt)) / 2        ####### Top branch probability going DOWN
  BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a, dt)) / 2        ####### Bottom branch probability going u
  BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j * Mfactor(a, dt)        ####### Bottom branch probability going MID
  BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j * Mfactor(a, dt)) / 2   ####### Bottom branch probability going DOWN

if (N>jmax) N=jmax

for (j in 0:N) {    
  if (j==0) {
    prb["0","1"] <<- ProbUP(a,j,dt)
    prb["0","0"] <<- ProbMID(a,j,dt)
    prb["0","-1"] <<- ProbDWN(a,j,dt)
  }
  else {
    if (j==jmax) {
      prb[paste(j,sep = ""),"1"] <<- TOPProbUP(a,j,dt)
      prb[paste(j,sep = ""),"0"] <<- TOPProbMID(a,j,dt)
      prb[paste(j,sep = ""),"-1"] <<- TOPProbDWN(a,j,dt)
      prb[paste(-j,sep = ""),"1"] <<- BTTMProbUP(a,-j,dt)
      prb[paste(-j,sep = ""),"0"] <<- BTTMProbMID(a,-j,dt)
      prb[paste(-j,sep = ""),"-1"] <<- BTTMProbDWN(a,-j,dt)
    }
    else {
      prb[paste(j,sep = ""),"1"] <<- ProbUP(a,j,dt)
      prb[paste(j,sep = ""),"0"] <<- ProbMID(a,j,dt)
      prb[paste(j,sep = ""),"-1"] <<- ProbDWN(a,j,dt)
      prb[paste(-j,sep = ""),"1"] <<- ProbUP(a,-j,dt)
      prb[paste(-j,sep = ""),"0"] <<- ProbMID(a,-j,dt)
      prb[paste(-j,sep = ""),"-1"] <<- ProbDWN(a,-j,dt)
    } # Close 2nd IF
  } # Close 1st IF
} #end for
}


-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: 02 November 2017 15:56
To: Eric Pueyo; r-help at r-project.org
Subject: RE: [R] repeat a function

Hi Eric

I did not see any answer and frankly speaking I cannot provide you with canned help.

AFAIK if a function is defined within another function (which is your case) it cannot be called directly so it is necessary to define it in global environment.

>  fff <- function(x) {
+  myf <- function(a) a+2
+  myf(x)^2}
>
> fff(5)
[1] 49
> myf(5)
Error in myf(5) : could not find function "myf"
>

Your function set is quite complicated but I wonder why would it be necessary to use for cycle for what seems to be simple table. Everything seems quite deterministic.

Basically you have combination of rows (-2,-1,0,1,2) and columns -1,-,1.
expand.grid(u=-2:2, v=-1:1)
for each row you can than use one function with parameters u, v and a and dt.
After you calculate vector of results, you can easily transform it to matrix by setting dim argument to it.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> Eric.Pueyo at avivainvestors.com
> Sent: Wednesday, November 1, 2017 1:31 PM
> To: r-help at r-project.org
> Subject: [R] repeat a function
>
> I want to populate the matrix prb through the function HWMProb <- 
> function
> (a,j,dt) that encapsulates different functions (please see code 
> below), using j=
> 0:2 for each j.
>
> It only populates prb if I specify each function independently in the 
> global environment and then run the loop with the iF statement, as per below.
> for (j in 0:2) {
>   if (j==0) {
>     prb["0","1"] <- ProbUP(a,j,dt)
>     prb["0","0"] <- ProbMID(a,j,dt)
>     prb["0","-1"] <- ProbDWN(a,j,dt)
>   }
>   else {
>     if (j==jmax) {
>       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
>     }
>     else {
>       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
>     } # Close 2nd IF
>   } # Close 1st IF
> }
>
> Many thanks in advance.
> Kind regards,
>
> Eric Pueyo
> Investment Risk Analyst
> Email:
> Eric.Pueyo at avivainvestors.com<mailto:Eric.Pueyo at avivainvestors.com>
> D: +44 (0)20 7809 8070
> No. 1 Undershaft, London EC3P 3DQ
> Web:
> www.avivainvestors.com<https://urldefense.proofpoint.com/v2/url?u=http
> -
> 3A__www.avivainvestors.com_&d=CwMFAg&c=zUO0BtkCe66yJvAZ4cAvZg&r=-
> 34SVFvqwmZvbxD0ShuYglbuijP84lygitjFgiP1fxI&m=kRg3I7ESFxV-
> KaNbYHN6DPupgyEmFCiThNO6oDnpAFs&s=tQa1EuXKNfzRgiR2HgG0H_tW_X-
> BCpgebe5AL9A_GC8&e=>
>
> jmax<-2
> prb <-matrix(0L,nrow=5, ncol=3)
> rownames(prb) <- c(seq(-2,2, by = 1))
> colnames(prb) <- c(-1,0,1)
> a<- 0.1
> dt<-1
>
> ExpX <-function(x,a,dt) {                              ######Defines the Expectation of X
> on t+1 | t
> ExpX <- x*exp(-a*dt)
> ExpX
> }
> Mfactor<-function(a,dt)  {                           #######Factor multiplicative
>   Mfactor<- exp(-a*dt)-1
>   Mfactor
> }
> VarX <-function(sigma,a,dt) {                         #######Defubes the Variance of X
> on t+1 | t
>   VarX <- (sigma^2/(2*a))*(1-exp(-2*a*dt))
>   VarX
> }
> DeltaX <-function(sigma,a,dt) {                       ######Defines the change of X
>   DeltaX<- sqrt(3*VarX(sigma,a,dt))
>   DeltaX<-value(DeltaX)
> }
>
> Mfactor<-function(a,dt)  {                           #######Factor multiplicative
>   Mfactor<- exp(-a*dt)-1
>   Mfactor
> }
>
> KNode<-function(sigma,x,a,j,dt) {                    ######Central Node
>   KNode<- round(ExpX(x,a,dt)/DeltaX(sigma,a,dt))
>   KNode
> }
>
> ####### Probability Calculations taking into account different 
> branches HWMProb <- function (a,j,dt) {
>   ######################### DESCRIPTION 
> #####################################
>   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> dt)) / 2)                     ######### Probability X going up
>   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2) 
> ######## Probability X going middle
>   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a,
> dt)) / 2)                  #######  Probability X going down
>   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j *
> Mfactor(a, dt)) / 2                 ####### Top branch probability going up
>   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j *
> Mfactor(a, dt)              ####### Top branch probability going MID
>   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j *
> Mfactor(a, dt)) / 2               ####### Top branch probability going DOWN
>   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> Mfactor(a, dt)) / 2           ####### Bottom branch probability going u
>   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j *
> Mfactor(a, dt)               ####### Bottom branch probability going MID
>   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j *
> Mfactor(a, dt)) / 2              ####### Bottom branch probability going DOWN
>
>   if (j==0) {
>     prb["0","1"] <- ProbUP(a,j,dt)
>     prb["0","0"] <- ProbMID(a,j,dt)
>     prb["0","-1"] <- ProbDWN(a,j,dt)
>   }
>   else {
>     if (j==jmax) {
>       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
>     }
>     else {
>       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
>      prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
>     } # Close 2nd IF
>   } # Close 1st IF
> } #Close Formula
>
> for (j in 0:2) {
>   HWMProb(a,j,dt)
>
> }
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

This email transmission and any attachments may contain confidential or legally privileged information that is intended for the addressee(s) only. Any views or opinions presented are solely those of the author and do not necessarily represent those of Aviva Investors. If you are not the intended recipient or person responsible for delivering this information to the intended recipient you are hereby notified that any disclosure, copying, distribution or reliance upon the contents of this email is strictly prohibited. If you have received this email transmission in error please notify the sender immediately so that we may arrange for its proper delivery and delete the message from your inbox.

Aviva Investors Global Services Limited, registered in England No. 1151805. Entered on the Financial Services Register, No: 119178. Authorised and regulated by the Financial Conduct Authority.

Aviva Investors Pensions Limited, registered in England No. 1059606. Entered on the Financial Services Register, No: 110410. Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.

Aviva Investors UK Fund Services Limited, registered in England No. 1973412. Entered on the Financial Services Register, No. 119310. Authorised and regulated by the Financial Conduct Authority. 

Aviva Investors UK Funds Limited, registered in England No. 2503054. Entered on the Financial Services Register, No. 147088. Authorised and regulated by the Financial Conduct Authority. 

Registered Office for all companies: St Helen?s, 1 Undershaft, London EC3P 3DQ. VAT number: 105 4373 00.

Telephone calls to Aviva Investors may be recorded for training or monitoring purposes. We may monitor traffic data of both business and personal emails. By replying to this email, you consent to us monitoring the content of any emails you send to or receive from Aviva Investors.

From tlkantro at gmail.com  Thu Nov  2 22:14:16 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Thu, 2 Nov 2017 17:14:16 -0400
Subject: [R] "prob" package alternative
In-Reply-To: <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
 <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
 <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>
Message-ID: <CALwT-rDo69eTk8PrycgRpyvU44S33s4-uO26gGuD3FY9xpzVdg@mail.gmail.com>

Rtools is not available for the current version of R.

What I'm looking for is an alternative package or how others have managed
to create workarounds.

On Thu, Nov 2, 2017 at 4:25 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 2, 2017, at 1:09 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Yes, that is exactly what I was doing two days ago.
> >
> > Warning in install.packages :
> >   installation of package ?fAsianOptions_3010.79.tar.gz? had non-zero
> exit status
> >
> > Which is what a reading of the explanation for why "prob" was retired
> leads one to expect. Do you have some other suggestion about how to get it
> to work? I notice you're not using Windows which might have a relationship
> to why it is working for you.
>
>
> I explained what you needed to do if you were on Windows. You do need to
> read the explanation more closely, identify the parts you don't understand
> (in all likelihood the point I made about needing the proper development
> tools for Windows) _and_ read:
>
> https://cran.r-project.org/doc/manuals/r-release/R-admin.
> html#Installing-packages
>
> If you have trouble understanding or getting success after thoroughly
> reading these directions, you need to explain what you have done
> (preserving the order of all operations) and post a complete transcript of
> all commands and complete error messages.
>
>
>
> --
> David.
> > Otherwise, do you know of some other package that could be used instead
> of prob?
> >
> > On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > >
> > > Yes. That's the version I've been discussing that has non-zero exit
> status. That situation is why CRAN retired the prob package. It's possible
> you installed that library earlier in development and it's been "carried"
> along. It no longer installs, now.
> > >
> > > The problems with all of this seem to have started this month
> according to the conversations. However, no one has mentioned any solutions
> or workarounds except the one mentioned in passing (2.9).
> >
> > Not true. Not even close to being true. I explained it all on the SO
> question page that you posted 2 days ago.
> >
> > --
> >
> > David.
> > >
> > > Is there some other package that does something similar to prob that
> can be used instead?
> > >
> > > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > >
> > > > The issue is fAsianOptions. Is there a version that works with the
> latest version of R? If not, which version of it works with which version
> of R and where can it be found? I tried several at the archive already.
> > >
> > > sessionInfo()
> > > R version 3.4.2 Patched (2017-10-04 r73465)
> > > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > > Running under: OS X El Capitan 10.11.6
> > >
> > > >
> > >
> > >
> > > packageDescription("fAsianOptions")
> > > Package: fAsianOptions
> > > Version: 3010.79
> > > Revision: 5522
> > > Date: 2013-06-23
> > > Title: EBM and Asian Option Valuation
> > > Author: Diethelm Wuertz and many others, see the SOURCE file
> > > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > > Suggests: RUnit
> > > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > > Description: Environment for teaching "Financial Engineering and
> Computational Finance"
> > > Note: Several parts are still preliminary and may be changed in the
> future. this
> > >           typically includes function and argument names, as well as
> defaults for
> > >           arguments and return values.
> > > LazyData: yes
> > > License: GPL (>= 2)
> > > URL: http://www.rmetrics.org
> > > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > > NeedsCompilation: yes
> > > Repository: CRAN
> > > Date/Publication: 2013-06-24 01:53:27
> > > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC;
> unix
> > >
> > >
> > >
> > > > Alternatively, is there another package that behaves similarly to
> prob?
> > > >
> > > >
> > > >
> > > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > >
> > > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > > >
> > > > > The prob package has been archived because it depends upon some
> other
> > > > > packages which have issues.
> > > > >
> > > > > However, such projects as Introduction to Probability and
> Statistics in R
> > > > > depend upon it for learning. There are a few other resources that
> also use
> > > > > it.
> > > > >
> > > > > Does anyone know of any workarounds?
> > > > >
> > > > > Someone at stack exchange mentioned using R 2.9.
> > > >
> > > > I'm not sure I would trust that person. They seem a bit uninformed.
> > > >
> > > > > However, that broke my
> > > > > RStudio (WSOD) and the dependent packages still wouldn't install,
> anyway.
> > > >
> > > > The latest version of pkg-prob at the Archive directory of CRAN
> indicates that it was last updated within this year. The DESCRIPTION file
> indicates that it does not need compilation, but:
> > > >
> > > > Depends: combinat, fAsianOptions
> > > >
> > > > So there should be code in text files in its ../R directory which
> can be sourced from that directory.
> > > >
> > > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > > characteristicfunctions.r       simulation.r
> utils-spaces.r
> > > > genData.R                       spaces-examples.r
>  utils-subsets.r
> > > > misc.r                          spaces-prob.r
> > > > prob.r                          utils-events.r
> > > >
> > > >
> > > > Or you can install from source after downloading:
> > > >
> > > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > > >
> > > > # Success
> > > >
> > > >
> > > > >  library(prob)   # So does require having several other packages
> > > > Loading required package: combinat
> > > >
> > > > Attaching package: ?combinat?
> > > >
> > > > The following object is masked from ?package:utils?:
> > > >
> > > >     combn
> > > >
> > > > Loading required package: fAsianOptions
> > > > Loading required package: timeDate
> > > >
> > > > Attaching package: ?timeDate?
> > > >
> > > > The following object is masked from ?package:cairoDevice?:
> > > >
> > > >     Cairo
> > > >
> > > > The following objects are masked from ?package:PerformanceAnalytics?
> :
> > > >
> > > >     kurtosis, skewness
> > > >
> > > > Loading required package: timeSeries
> > > >
> > > > Attaching package: ?timeSeries?
> > > >
> > > > The following object is masked from ?package:zoo?:
> > > >
> > > >     time<-
> > > >
> > > > Loading required package: fBasics
> > > >
> > > >
> > > > Rmetrics Package fBasics
> > > > Analysing Markets and calculating Basic Statistics
> > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > Educational Software for Financial Engineering and Computational
> Science
> > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > Loading required package: fOptions
> > > >
> > > >
> > > > Rmetrics Package fOptions
> > > > Pricing and Evaluating Basic Options
> > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > Educational Software for Financial Engineering and Computational
> Science
> > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > >
> > > > Attaching package: ?prob?
> > > >
> > > > The following objects are masked from ?package:dplyr?:
> > > >
> > > >     intersect, setdiff, union
> > > >
> > > > The following objects are masked from ?package:base?:
> > > >
> > > >     intersect, setdiff, union
> > > >
> > > > >
> > > > >
> > > > >
> > > > > Tiby
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > >
> > > > A specific suggestion would be that you read the listinfo and the
> Posting Guide and learn to post in plain text.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Nov  2 23:06:56 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 15:06:56 -0700
Subject: [R] "prob" package alternative
In-Reply-To: <CALwT-rDo69eTk8PrycgRpyvU44S33s4-uO26gGuD3FY9xpzVdg@mail.gmail.com>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
 <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
 <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>
 <CALwT-rDo69eTk8PrycgRpyvU44S33s4-uO26gGuD3FY9xpzVdg@mail.gmail.com>
Message-ID: <CE8FCDEA-706E-4B0B-91B6-C6DA42798F27@comcast.net>


> On Nov 2, 2017, at 2:14 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> 
> Rtools is not available for the current version of R.

Really? If true, I'm surprised and not able to help. I do see an Rtools34.exe at https://cran.r-project.org/bin/windows/Rtools/
-- 
David.

> 
> What I'm looking for is an alternative package or how others have managed to create workarounds.
> 
> On Thu, Nov 2, 2017 at 4:25 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Nov 2, 2017, at 1:09 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Yes, that is exactly what I was doing two days ago.
> >
> > Warning in install.packages :
> >   installation of package ?fAsianOptions_3010.79.tar.gz? had non-zero exit status
> >
> > Which is what a reading of the explanation for why "prob" was retired leads one to expect. Do you have some other suggestion about how to get it to work? I notice you're not using Windows which might have a relationship to why it is working for you.
> 
> 
> I explained what you needed to do if you were on Windows. You do need to read the explanation more closely, identify the parts you don't understand (in all likelihood the point I made about needing the proper development tools for Windows) _and_ read:
> 
> https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installing-packages
> 
> If you have trouble understanding or getting success after thoroughly reading these directions, you need to explain what you have done (preserving the order of all operations) and post a complete transcript of all commands and complete error messages.
> 
> 
> 
> --
> David.
> > Otherwise, do you know of some other package that could be used instead of prob?
> >
> > On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > >
> > > Yes. That's the version I've been discussing that has non-zero exit status. That situation is why CRAN retired the prob package. It's possible you installed that library earlier in development and it's been "carried" along. It no longer installs, now.
> > >
> > > The problems with all of this seem to have started this month according to the conversations. However, no one has mentioned any solutions or workarounds except the one mentioned in passing (2.9).
> >
> > Not true. Not even close to being true. I explained it all on the SO question page that you posted 2 days ago.
> >
> > --
> >
> > David.
> > >
> > > Is there some other package that does something similar to prob that can be used instead?
> > >
> > > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > > >
> > > > The issue is fAsianOptions. Is there a version that works with the latest version of R? If not, which version of it works with which version of R and where can it be found? I tried several at the archive already.
> > >
> > > sessionInfo()
> > > R version 3.4.2 Patched (2017-10-04 r73465)
> > > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > > Running under: OS X El Capitan 10.11.6
> > >
> > > >
> > >
> > >
> > > packageDescription("fAsianOptions")
> > > Package: fAsianOptions
> > > Version: 3010.79
> > > Revision: 5522
> > > Date: 2013-06-23
> > > Title: EBM and Asian Option Valuation
> > > Author: Diethelm Wuertz and many others, see the SOURCE file
> > > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > > Suggests: RUnit
> > > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > > Description: Environment for teaching "Financial Engineering and Computational Finance"
> > > Note: Several parts are still preliminary and may be changed in the future. this
> > >           typically includes function and argument names, as well as defaults for
> > >           arguments and return values.
> > > LazyData: yes
> > > License: GPL (>= 2)
> > > URL: http://www.rmetrics.org
> > > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > > NeedsCompilation: yes
> > > Repository: CRAN
> > > Date/Publication: 2013-06-24 01:53:27
> > > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix
> > >
> > >
> > >
> > > > Alternatively, is there another package that behaves similarly to prob?
> > > >
> > > >
> > > >
> > > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > > >
> > > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > > > >
> > > > > The prob package has been archived because it depends upon some other
> > > > > packages which have issues.
> > > > >
> > > > > However, such projects as Introduction to Probability and Statistics in R
> > > > > depend upon it for learning. There are a few other resources that also use
> > > > > it.
> > > > >
> > > > > Does anyone know of any workarounds?
> > > > >
> > > > > Someone at stack exchange mentioned using R 2.9.
> > > >
> > > > I'm not sure I would trust that person. They seem a bit uninformed.
> > > >
> > > > > However, that broke my
> > > > > RStudio (WSOD) and the dependent packages still wouldn't install, anyway.
> > > >
> > > > The latest version of pkg-prob at the Archive directory of CRAN indicates that it was last updated within this year. The DESCRIPTION file indicates that it does not need compilation, but:
> > > >
> > > > Depends: combinat, fAsianOptions
> > > >
> > > > So there should be code in text files in its ../R directory which can be sourced from that directory.
> > > >
> > > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > > characteristicfunctions.r       simulation.r                    utils-spaces.r
> > > > genData.R                       spaces-examples.r               utils-subsets.r
> > > > misc.r                          spaces-prob.r
> > > > prob.r                          utils-events.r
> > > >
> > > >
> > > > Or you can install from source after downloading:
> > > >
> > > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > > >
> > > > # Success
> > > >
> > > >
> > > > >  library(prob)   # So does require having several other packages
> > > > Loading required package: combinat
> > > >
> > > > Attaching package: ?combinat?
> > > >
> > > > The following object is masked from ?package:utils?:
> > > >
> > > >     combn
> > > >
> > > > Loading required package: fAsianOptions
> > > > Loading required package: timeDate
> > > >
> > > > Attaching package: ?timeDate?
> > > >
> > > > The following object is masked from ?package:cairoDevice?:
> > > >
> > > >     Cairo
> > > >
> > > > The following objects are masked from ?package:PerformanceAnalytics?:
> > > >
> > > >     kurtosis, skewness
> > > >
> > > > Loading required package: timeSeries
> > > >
> > > > Attaching package: ?timeSeries?
> > > >
> > > > The following object is masked from ?package:zoo?:
> > > >
> > > >     time<-
> > > >
> > > > Loading required package: fBasics
> > > >
> > > >
> > > > Rmetrics Package fBasics
> > > > Analysing Markets and calculating Basic Statistics
> > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > Educational Software for Financial Engineering and Computational Science
> > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > Loading required package: fOptions
> > > >
> > > >
> > > > Rmetrics Package fOptions
> > > > Pricing and Evaluating Basic Options
> > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > Educational Software for Financial Engineering and Computational Science
> > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > >
> > > > Attaching package: ?prob?
> > > >
> > > > The following objects are masked from ?package:dplyr?:
> > > >
> > > >     intersect, setdiff, union
> > > >
> > > > The following objects are masked from ?package:base?:
> > > >
> > > >     intersect, setdiff, union
> > > >
> > > > >
> > > > >
> > > > >
> > > > > Tiby
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > >
> > > > A specific suggestion would be that you read the listinfo and the Posting Guide and learn to post in plain text.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > > > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tlkantro at gmail.com  Thu Nov  2 23:46:28 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Thu, 2 Nov 2017 18:46:28 -0400
Subject: [R] "prob" package alternative
In-Reply-To: <CE8FCDEA-706E-4B0B-91B6-C6DA42798F27@comcast.net>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
 <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
 <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>
 <CALwT-rDo69eTk8PrycgRpyvU44S33s4-uO26gGuD3FY9xpzVdg@mail.gmail.com>
 <CE8FCDEA-706E-4B0B-91B6-C6DA42798F27@comcast.net>
Message-ID: <CALwT-rD-ZTY2qD85CajGoS6NHN+jpuC23PCQRu+68MLS5aNPLQ@mail.gmail.com>

Thanks. I found that, and installed it and got the same message. Here:

RTools version 3.4

install.packages("fAsianOptions_3010.tar.gz", dependencies=TRUE,
repos=NULL, type = "source")
Installing package into ?C:/Users/Tlk7/Documents/R/win-library/3.4? (as
?lib? is unspecified) Warning: invalid package 'fAsianOptions_3010.tar.gz'
Error: ERROR: no packages specified Warning in install.packages : running
command '"C:/PROGRA~1/R/R-34~1.2/bin/x64/R" CMD INSTALL -l
"C:\Users\Tlk7\Documents\R\win-library\3.4" "fAsianOptions_3010.tar.gz"'
had status 1 Warning in install.packages : installation of package
?fAsianOptions_3010.tar.gz? had non-zero exit status

On Thu, Nov 2, 2017 at 6:06 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 2, 2017, at 2:14 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Rtools is not available for the current version of R.
>
> Really? If true, I'm surprised and not able to help. I do see an
> Rtools34.exe at https://cran.r-project.org/bin/windows/Rtools/
> --
> David.
>
> >
> > What I'm looking for is an alternative package or how others have
> managed to create workarounds.
> >
> > On Thu, Nov 2, 2017 at 4:25 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Nov 2, 2017, at 1:09 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > >
> > > Yes, that is exactly what I was doing two days ago.
> > >
> > > Warning in install.packages :
> > >   installation of package ?fAsianOptions_3010.79.tar.gz? had non-zero
> exit status
> > >
> > > Which is what a reading of the explanation for why "prob" was retired
> leads one to expect. Do you have some other suggestion about how to get it
> to work? I notice you're not using Windows which might have a relationship
> to why it is working for you.
> >
> >
> > I explained what you needed to do if you were on Windows. You do need to
> read the explanation more closely, identify the parts you don't understand
> (in all likelihood the point I made about needing the proper development
> tools for Windows) _and_ read:
> >
> > https://cran.r-project.org/doc/manuals/r-release/R-admin.
> html#Installing-packages
> >
> > If you have trouble understanding or getting success after thoroughly
> reading these directions, you need to explain what you have done
> (preserving the order of all operations) and post a complete transcript of
> all commands and complete error messages.
> >
> >
> >
> > --
> > David.
> > > Otherwise, do you know of some other package that could be used
> instead of prob?
> > >
> > > On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > >
> > > > Yes. That's the version I've been discussing that has non-zero exit
> status. That situation is why CRAN retired the prob package. It's possible
> you installed that library earlier in development and it's been "carried"
> along. It no longer installs, now.
> > > >
> > > > The problems with all of this seem to have started this month
> according to the conversations. However, no one has mentioned any solutions
> or workarounds except the one mentioned in passing (2.9).
> > >
> > > Not true. Not even close to being true. I explained it all on the SO
> question page that you posted 2 days ago.
> > >
> > > --
> > >
> > > David.
> > > >
> > > > Is there some other package that does something similar to prob that
> can be used instead?
> > > >
> > > > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > >
> > > > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > > >
> > > > > The issue is fAsianOptions. Is there a version that works with the
> latest version of R? If not, which version of it works with which version
> of R and where can it be found? I tried several at the archive already.
> > > >
> > > > sessionInfo()
> > > > R version 3.4.2 Patched (2017-10-04 r73465)
> > > > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > > > Running under: OS X El Capitan 10.11.6
> > > >
> > > > >
> > > >
> > > >
> > > > packageDescription("fAsianOptions")
> > > > Package: fAsianOptions
> > > > Version: 3010.79
> > > > Revision: 5522
> > > > Date: 2013-06-23
> > > > Title: EBM and Asian Option Valuation
> > > > Author: Diethelm Wuertz and many others, see the SOURCE file
> > > > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > > > Suggests: RUnit
> > > > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > > > Description: Environment for teaching "Financial Engineering and
> Computational Finance"
> > > > Note: Several parts are still preliminary and may be changed in the
> future. this
> > > >           typically includes function and argument names, as well as
> defaults for
> > > >           arguments and return values.
> > > > LazyData: yes
> > > > License: GPL (>= 2)
> > > > URL: http://www.rmetrics.org
> > > > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > > > NeedsCompilation: yes
> > > > Repository: CRAN
> > > > Date/Publication: 2013-06-24 01:53:27
> > > > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC;
> unix
> > > >
> > > >
> > > >
> > > > > Alternatively, is there another package that behaves similarly to
> prob?
> > > > >
> > > > >
> > > > >
> > > > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > > >
> > > > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > > > >
> > > > > > The prob package has been archived because it depends upon some
> other
> > > > > > packages which have issues.
> > > > > >
> > > > > > However, such projects as Introduction to Probability and
> Statistics in R
> > > > > > depend upon it for learning. There are a few other resources
> that also use
> > > > > > it.
> > > > > >
> > > > > > Does anyone know of any workarounds?
> > > > > >
> > > > > > Someone at stack exchange mentioned using R 2.9.
> > > > >
> > > > > I'm not sure I would trust that person. They seem a bit uninformed.
> > > > >
> > > > > > However, that broke my
> > > > > > RStudio (WSOD) and the dependent packages still wouldn't
> install, anyway.
> > > > >
> > > > > The latest version of pkg-prob at the Archive directory of CRAN
> indicates that it was last updated within this year. The DESCRIPTION file
> indicates that it does not need compilation, but:
> > > > >
> > > > > Depends: combinat, fAsianOptions
> > > > >
> > > > > So there should be code in text files in its ../R directory which
> can be sourced from that directory.
> > > > >
> > > > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > > > characteristicfunctions.r       simulation.r
> utils-spaces.r
> > > > > genData.R                       spaces-examples.r
>  utils-subsets.r
> > > > > misc.r                          spaces-prob.r
> > > > > prob.r                          utils-events.r
> > > > >
> > > > >
> > > > > Or you can install from source after downloading:
> > > > >
> > > > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > > > >
> > > > > # Success
> > > > >
> > > > >
> > > > > >  library(prob)   # So does require having several other packages
> > > > > Loading required package: combinat
> > > > >
> > > > > Attaching package: ?combinat?
> > > > >
> > > > > The following object is masked from ?package:utils?:
> > > > >
> > > > >     combn
> > > > >
> > > > > Loading required package: fAsianOptions
> > > > > Loading required package: timeDate
> > > > >
> > > > > Attaching package: ?timeDate?
> > > > >
> > > > > The following object is masked from ?package:cairoDevice?:
> > > > >
> > > > >     Cairo
> > > > >
> > > > > The following objects are masked from
> ?package:PerformanceAnalytics?:
> > > > >
> > > > >     kurtosis, skewness
> > > > >
> > > > > Loading required package: timeSeries
> > > > >
> > > > > Attaching package: ?timeSeries?
> > > > >
> > > > > The following object is masked from ?package:zoo?:
> > > > >
> > > > >     time<-
> > > > >
> > > > > Loading required package: fBasics
> > > > >
> > > > >
> > > > > Rmetrics Package fBasics
> > > > > Analysing Markets and calculating Basic Statistics
> > > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > > Educational Software for Financial Engineering and Computational
> Science
> > > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > > Loading required package: fOptions
> > > > >
> > > > >
> > > > > Rmetrics Package fOptions
> > > > > Pricing and Evaluating Basic Options
> > > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > > Educational Software for Financial Engineering and Computational
> Science
> > > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > >
> > > > > Attaching package: ?prob?
> > > > >
> > > > > The following objects are masked from ?package:dplyr?:
> > > > >
> > > > >     intersect, setdiff, union
> > > > >
> > > > > The following objects are masked from ?package:base?:
> > > > >
> > > > >     intersect, setdiff, union
> > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > Tiby
> > > > > >
> > > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > A specific suggestion would be that you read the listinfo and the
> Posting Guide and learn to post in plain text.
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible
> code.
> > > > >
> > > > > David Winsemius
> > > > > Alameda, CA, USA
> > > > >
> > > > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > >
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Nov  3 00:02:53 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 2 Nov 2017 16:02:53 -0700
Subject: [R] "prob" package alternative
In-Reply-To: <CALwT-rD-ZTY2qD85CajGoS6NHN+jpuC23PCQRu+68MLS5aNPLQ@mail.gmail.com>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
 <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
 <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>
 <CALwT-rDo69eTk8PrycgRpyvU44S33s4-uO26gGuD3FY9xpzVdg@mail.gmail.com>
 <CE8FCDEA-706E-4B0B-91B6-C6DA42798F27@comcast.net>
 <CALwT-rD-ZTY2qD85CajGoS6NHN+jpuC23PCQRu+68MLS5aNPLQ@mail.gmail.com>
Message-ID: <08E4D0FE-6EB9-45AD-A1B7-A5AA60F66760@comcast.net>


> On Nov 2, 2017, at 3:46 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> 
> Thanks. I found that, and installed it and got the same message. Here:
> 
> RTools version 3.4 
> 
> install.packages("fAsianOptions_3010.tar.gz",

I don't see a path to that file's location.

The expansion from pkg_version.tar.gz might be automatic, but I do generally expand such file into its own directory and then drag that directory icon into the console so my command would look like:

install.packages("~/Downloads/fAsianOptions", dependencies=TRUE, repos=NULL, type = "source") 


I suggest you learn to post in plain text since your HTML postings are loosing their carriage returns.

-- 
David




> dependencies=TRUE, repos=NULL, type = "source") 
> Installing package into ?C:/Users/Tlk7/Documents/R/win-library/3.4? (as ?lib? is unspecified) Warning: invalid package 'fAsianOptions_3010.tar.gz' Error: ERROR: no packages specified Warning in install.packages : running command '"C:/PROGRA~1/R/R-34~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Tlk7\Documents\R\win-library\3.4" "fAsianOptions_3010.tar.gz"' had status 1 Warning in install.packages : installation of package ?fAsianOptions_3010.tar.gz? had non-zero exit status
> 
> On Thu, Nov 2, 2017 at 6:06 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Nov 2, 2017, at 2:14 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Rtools is not available for the current version of R.
> 
> Really? If true, I'm surprised and not able to help. I do see an Rtools34.exe at https://cran.r-project.org/bin/windows/Rtools/
> --
> David.
> 
> >
> > What I'm looking for is an alternative package or how others have managed to create workarounds.
> >
> > On Thu, Nov 2, 2017 at 4:25 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Nov 2, 2017, at 1:09 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > >
> > > Yes, that is exactly what I was doing two days ago.
> > >
> > > Warning in install.packages :
> > >   installation of package ?fAsianOptions_3010.79.tar.gz? had non-zero exit status
> > >
> > > Which is what a reading of the explanation for why "prob" was retired leads one to expect. Do you have some other suggestion about how to get it to work? I notice you're not using Windows which might have a relationship to why it is working for you.
> >
> >
> > I explained what you needed to do if you were on Windows. You do need to read the explanation more closely, identify the parts you don't understand (in all likelihood the point I made about needing the proper development tools for Windows) _and_ read:
> >
> > https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installing-packages
> >
> > If you have trouble understanding or getting success after thoroughly reading these directions, you need to explain what you have done (preserving the order of all operations) and post a complete transcript of all commands and complete error messages.
> >
> >
> >
> > --
> > David.
> > > Otherwise, do you know of some other package that could be used instead of prob?
> > >
> > > On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > > >
> > > > Yes. That's the version I've been discussing that has non-zero exit status. That situation is why CRAN retired the prob package. It's possible you installed that library earlier in development and it's been "carried" along. It no longer installs, now.
> > > >
> > > > The problems with all of this seem to have started this month according to the conversations. However, no one has mentioned any solutions or workarounds except the one mentioned in passing (2.9).
> > >
> > > Not true. Not even close to being true. I explained it all on the SO question page that you posted 2 days ago.
> > >
> > > --
> > >
> > > David.
> > > >
> > > > Is there some other package that does something similar to prob that can be used instead?
> > > >
> > > > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > > >
> > > > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > > > >
> > > > > The issue is fAsianOptions. Is there a version that works with the latest version of R? If not, which version of it works with which version of R and where can it be found? I tried several at the archive already.
> > > >
> > > > sessionInfo()
> > > > R version 3.4.2 Patched (2017-10-04 r73465)
> > > > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > > > Running under: OS X El Capitan 10.11.6
> > > >
> > > > >
> > > >
> > > >
> > > > packageDescription("fAsianOptions")
> > > > Package: fAsianOptions
> > > > Version: 3010.79
> > > > Revision: 5522
> > > > Date: 2013-06-23
> > > > Title: EBM and Asian Option Valuation
> > > > Author: Diethelm Wuertz and many others, see the SOURCE file
> > > > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > > > Suggests: RUnit
> > > > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > > > Description: Environment for teaching "Financial Engineering and Computational Finance"
> > > > Note: Several parts are still preliminary and may be changed in the future. this
> > > >           typically includes function and argument names, as well as defaults for
> > > >           arguments and return values.
> > > > LazyData: yes
> > > > License: GPL (>= 2)
> > > > URL: http://www.rmetrics.org
> > > > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > > > NeedsCompilation: yes
> > > > Repository: CRAN
> > > > Date/Publication: 2013-06-24 01:53:27
> > > > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02 UTC; unix
> > > >
> > > >
> > > >
> > > > > Alternatively, is there another package that behaves similarly to prob?
> > > > >
> > > > >
> > > > >
> > > > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > > > >
> > > > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> > > > > >
> > > > > > The prob package has been archived because it depends upon some other
> > > > > > packages which have issues.
> > > > > >
> > > > > > However, such projects as Introduction to Probability and Statistics in R
> > > > > > depend upon it for learning. There are a few other resources that also use
> > > > > > it.
> > > > > >
> > > > > > Does anyone know of any workarounds?
> > > > > >
> > > > > > Someone at stack exchange mentioned using R 2.9.
> > > > >
> > > > > I'm not sure I would trust that person. They seem a bit uninformed.
> > > > >
> > > > > > However, that broke my
> > > > > > RStudio (WSOD) and the dependent packages still wouldn't install, anyway.
> > > > >
> > > > > The latest version of pkg-prob at the Archive directory of CRAN indicates that it was last updated within this year. The DESCRIPTION file indicates that it does not need compilation, but:
> > > > >
> > > > > Depends: combinat, fAsianOptions
> > > > >
> > > > > So there should be code in text files in its ../R directory which can be sourced from that directory.
> > > > >
> > > > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > > > characteristicfunctions.r       simulation.r                    utils-spaces.r
> > > > > genData.R                       spaces-examples.r               utils-subsets.r
> > > > > misc.r                          spaces-prob.r
> > > > > prob.r                          utils-events.r
> > > > >
> > > > >
> > > > > Or you can install from source after downloading:
> > > > >
> > > > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > > > >
> > > > > # Success
> > > > >
> > > > >
> > > > > >  library(prob)   # So does require having several other packages
> > > > > Loading required package: combinat
> > > > >
> > > > > Attaching package: ?combinat?
> > > > >
> > > > > The following object is masked from ?package:utils?:
> > > > >
> > > > >     combn
> > > > >
> > > > > Loading required package: fAsianOptions
> > > > > Loading required package: timeDate
> > > > >
> > > > > Attaching package: ?timeDate?
> > > > >
> > > > > The following object is masked from ?package:cairoDevice?:
> > > > >
> > > > >     Cairo
> > > > >
> > > > > The following objects are masked from ?package:PerformanceAnalytics?:
> > > > >
> > > > >     kurtosis, skewness
> > > > >
> > > > > Loading required package: timeSeries
> > > > >
> > > > > Attaching package: ?timeSeries?
> > > > >
> > > > > The following object is masked from ?package:zoo?:
> > > > >
> > > > >     time<-
> > > > >
> > > > > Loading required package: fBasics
> > > > >
> > > > >
> > > > > Rmetrics Package fBasics
> > > > > Analysing Markets and calculating Basic Statistics
> > > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > > Educational Software for Financial Engineering and Computational Science
> > > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > > Loading required package: fOptions
> > > > >
> > > > >
> > > > > Rmetrics Package fOptions
> > > > > Pricing and Evaluating Basic Options
> > > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > > Educational Software for Financial Engineering and Computational Science
> > > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > >
> > > > > Attaching package: ?prob?
> > > > >
> > > > > The following objects are masked from ?package:dplyr?:
> > > > >
> > > > >     intersect, setdiff, union
> > > > >
> > > > > The following objects are masked from ?package:base?:
> > > > >
> > > > >     intersect, setdiff, union
> > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > Tiby
> > > > > >
> > > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > A specific suggestion would be that you read the listinfo and the Posting Guide and learn to post in plain text.
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > >
> > > > > David Winsemius
> > > > > Alameda, CA, USA
> > > > >
> > > > > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > >
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > > > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tlkantro at gmail.com  Fri Nov  3 00:25:35 2017
From: tlkantro at gmail.com (Tiby Kantrowitz)
Date: Thu, 2 Nov 2017 19:25:35 -0400
Subject: [R] "prob" package alternative
In-Reply-To: <08E4D0FE-6EB9-45AD-A1B7-A5AA60F66760@comcast.net>
References: <CALwT-rA6wfqk3qNmr4Q9WY39iLiy-yLmBN5N78EF3kOCrLUR0Q@mail.gmail.com>
 <D72D8367-483C-4E3C-AD38-D2E4C20B4D34@comcast.net>
 <CALwT-rDHwzCeOdRkRnOvei14CZq3ZMZiAbd=Zs-z9SrqaH_zNg@mail.gmail.com>
 <B00A34DC-4E62-4700-AE34-D836273C43B4@comcast.net>
 <CALwT-rCGn9+ksQGE3Ny4m_fWas9TCGoZOo9uzobGyGr8VJD1zQ@mail.gmail.com>
 <8D8BBB3B-C695-45DB-A4DD-5C03334CE4C2@comcast.net>
 <CALwT-rB7JWnrZuvtDBofd0uNryRoYSzBkNdanabi=1y1uoJa9Q@mail.gmail.com>
 <CA91DED3-8238-4862-B14A-88AB29CD66B5@comcast.net>
 <CALwT-rDo69eTk8PrycgRpyvU44S33s4-uO26gGuD3FY9xpzVdg@mail.gmail.com>
 <CE8FCDEA-706E-4B0B-91B6-C6DA42798F27@comcast.net>
 <CALwT-rD-ZTY2qD85CajGoS6NHN+jpuC23PCQRu+68MLS5aNPLQ@mail.gmail.com>
 <08E4D0FE-6EB9-45AD-A1B7-A5AA60F66760@comcast.net>
Message-ID: <CALwT-rDq-buim7U_pHB24Ce+ZDUj7td3Gd1WxQjWHcpo9-rAQw@mail.gmail.com>

That worked. Thank you, especially for that last one!

So, for others who might encounter this same situation:

1. Install RTools from here:
https://cran.r-project.org/bin/windows/Rtools/Rtools34.exe
Trying to install Rtools from inside RStudio will result in an "it's not
available for 3.4.2"  message.

2. Install the following dependencies: timeDate, timeSeries, fBasics,
fOptions

3. Download fAsianOptions from here:
https://cran.r-project.org/src/contrib/Archive/fAsianOptions/fAsianOptions_3010.79.tar.gz
and prob from here:
https://cran.r-project.org/src/contrib/Archive/prob/prob_1.0-0.tar.gz

4. Unzip each into its own directory.

5. Use this to install each, as appropriate:
install.packages("~/Downloads/fAsianOptions",
dependencies=TRUE, repos=NULL, type = "source")





On Thu, Nov 2, 2017 at 7:02 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 2, 2017, at 3:46 PM, Tiby Kantrowitz <tlkantro at gmail.com> wrote:
> >
> > Thanks. I found that, and installed it and got the same message. Here:
> >
> > RTools version 3.4
> >
> > install.packages("fAsianOptions_3010.tar.gz",
>
> I don't see a path to that file's location.
>
> The expansion from pkg_version.tar.gz might be automatic, but I do
> generally expand such file into its own directory and then drag that
> directory icon into the console so my command would look like:
>
> install.packages("~/Downloads/fAsianOptions", dependencies=TRUE,
> repos=NULL, type = "source")
>
>
> I suggest you learn to post in plain text since your HTML postings are
> loosing their carriage returns.
>
> --
> David
>
>
>
>
> > dependencies=TRUE, repos=NULL, type = "source")
> > Installing package into ?C:/Users/Tlk7/Documents/R/win-library/3.4? (as
> ?lib? is unspecified) Warning: invalid package 'fAsianOptions_3010.tar.gz'
> Error: ERROR: no packages specified Warning in install.packages : running
> command '"C:/PROGRA~1/R/R-34~1.2/bin/x64/R" CMD INSTALL -l
> "C:\Users\Tlk7\Documents\R\win-library\3.4" "fAsianOptions_3010.tar.gz"'
> had status 1 Warning in install.packages : installation of package
> ?fAsianOptions_3010.tar.gz? had non-zero exit status
> >
> > On Thu, Nov 2, 2017 at 6:06 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Nov 2, 2017, at 2:14 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > >
> > > Rtools is not available for the current version of R.
> >
> > Really? If true, I'm surprised and not able to help. I do see an
> Rtools34.exe at https://cran.r-project.org/bin/windows/Rtools/
> > --
> > David.
> >
> > >
> > > What I'm looking for is an alternative package or how others have
> managed to create workarounds.
> > >
> > > On Thu, Nov 2, 2017 at 4:25 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >
> > > > On Nov 2, 2017, at 1:09 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > >
> > > > Yes, that is exactly what I was doing two days ago.
> > > >
> > > > Warning in install.packages :
> > > >   installation of package ?fAsianOptions_3010.79.tar.gz? had
> non-zero exit status
> > > >
> > > > Which is what a reading of the explanation for why "prob" was
> retired leads one to expect. Do you have some other suggestion about how to
> get it to work? I notice you're not using Windows which might have a
> relationship to why it is working for you.
> > >
> > >
> > > I explained what you needed to do if you were on Windows. You do need
> to read the explanation more closely, identify the parts you don't
> understand (in all likelihood the point I made about needing the proper
> development tools for Windows) _and_ read:
> > >
> > > https://cran.r-project.org/doc/manuals/r-release/R-admin.
> html#Installing-packages
> > >
> > > If you have trouble understanding or getting success after thoroughly
> reading these directions, you need to explain what you have done
> (preserving the order of all operations) and post a complete transcript of
> all commands and complete error messages.
> > >
> > >
> > >
> > > --
> > > David.
> > > > Otherwise, do you know of some other package that could be used
> instead of prob?
> > > >
> > > > On Thu, Nov 2, 2017 at 3:44 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > >
> > > > > On Nov 2, 2017, at 12:07 PM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > > >
> > > > > Yes. That's the version I've been discussing that has non-zero
> exit status. That situation is why CRAN retired the prob package. It's
> possible you installed that library earlier in development and it's been
> "carried" along. It no longer installs, now.
> > > > >
> > > > > The problems with all of this seem to have started this month
> according to the conversations. However, no one has mentioned any solutions
> or workarounds except the one mentioned in passing (2.9).
> > > >
> > > > Not true. Not even close to being true. I explained it all on the SO
> question page that you posted 2 days ago.
> > > >
> > > > --
> > > >
> > > > David.
> > > > >
> > > > > Is there some other package that does something similar to prob
> that can be used instead?
> > > > >
> > > > > On Thu, Nov 2, 2017 at 2:29 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > > >
> > > > > > On Nov 2, 2017, at 11:15 AM, Tiby Kantrowitz <tlkantro at gmail.com>
> wrote:
> > > > > >
> > > > > > The issue is fAsianOptions. Is there a version that works with
> the latest version of R? If not, which version of it works with which
> version of R and where can it be found? I tried several at the archive
> already.
> > > > >
> > > > > sessionInfo()
> > > > > R version 3.4.2 Patched (2017-10-04 r73465)
> > > > > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> > > > > Running under: OS X El Capitan 10.11.6
> > > > >
> > > > > >
> > > > >
> > > > >
> > > > > packageDescription("fAsianOptions")
> > > > > Package: fAsianOptions
> > > > > Version: 3010.79
> > > > > Revision: 5522
> > > > > Date: 2013-06-23
> > > > > Title: EBM and Asian Option Valuation
> > > > > Author: Diethelm Wuertz and many others, see the SOURCE file
> > > > > Depends: R (>= 2.4.0), timeDate, timeSeries, fBasics, fOptions
> > > > > Suggests: RUnit
> > > > > Maintainer: Yohan Chalabi <yohan.chalabi at rmetrics.org>
> > > > > Description: Environment for teaching "Financial Engineering and
> Computational Finance"
> > > > > Note: Several parts are still preliminary and may be changed in
> the future. this
> > > > >           typically includes function and argument names, as well
> as defaults for
> > > > >           arguments and return values.
> > > > > LazyData: yes
> > > > > License: GPL (>= 2)
> > > > > URL: http://www.rmetrics.org
> > > > > Packaged: 2013-06-23 18:22:14 UTC; yohan
> > > > > NeedsCompilation: yes
> > > > > Repository: CRAN
> > > > > Date/Publication: 2013-06-24 01:53:27
> > > > > Built: R 3.4.2; x86_64-apple-darwin15.6.0; 2017-11-01 22:45:02
> UTC; unix
> > > > >
> > > > >
> > > > >
> > > > > > Alternatively, is there another package that behaves similarly
> to prob?
> > > > > >
> > > > > >
> > > > > >
> > > > > > On Wed, Nov 1, 2017 at 6:17 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > > > >
> > > > > > > On Nov 1, 2017, at 12:51 PM, Tiby Kantrowitz <
> tlkantro at gmail.com> wrote:
> > > > > > >
> > > > > > > The prob package has been archived because it depends upon
> some other
> > > > > > > packages which have issues.
> > > > > > >
> > > > > > > However, such projects as Introduction to Probability and
> Statistics in R
> > > > > > > depend upon it for learning. There are a few other resources
> that also use
> > > > > > > it.
> > > > > > >
> > > > > > > Does anyone know of any workarounds?
> > > > > > >
> > > > > > > Someone at stack exchange mentioned using R 2.9.
> > > > > >
> > > > > > I'm not sure I would trust that person. They seem a bit
> uninformed.
> > > > > >
> > > > > > > However, that broke my
> > > > > > > RStudio (WSOD) and the dependent packages still wouldn't
> install, anyway.
> > > > > >
> > > > > > The latest version of pkg-prob at the Archive directory of CRAN
> indicates that it was last updated within this year. The DESCRIPTION file
> indicates that it does not need compilation, but:
> > > > > >
> > > > > > Depends: combinat, fAsianOptions
> > > > > >
> > > > > > So there should be code in text files in its ../R directory
> which can be sourced from that directory.
> > > > > >
> > > > > > ~myuser_name$ ls /Users/../Downloads/prob/R
> > > > > > characteristicfunctions.r       simulation.r
> utils-spaces.r
> > > > > > genData.R                       spaces-examples.r
>  utils-subsets.r
> > > > > > misc.r                          spaces-prob.r
> > > > > > prob.r                          utils-events.r
> > > > > >
> > > > > >
> > > > > > Or you can install from source after downloading:
> > > > > >
> > > > > > install.packages("~/Downloads/prob", repo=NULL,type="source")
> > > > > >
> > > > > > # Success
> > > > > >
> > > > > >
> > > > > > >  library(prob)   # So does require having several other
> packages
> > > > > > Loading required package: combinat
> > > > > >
> > > > > > Attaching package: ?combinat?
> > > > > >
> > > > > > The following object is masked from ?package:utils?:
> > > > > >
> > > > > >     combn
> > > > > >
> > > > > > Loading required package: fAsianOptions
> > > > > > Loading required package: timeDate
> > > > > >
> > > > > > Attaching package: ?timeDate?
> > > > > >
> > > > > > The following object is masked from ?package:cairoDevice?:
> > > > > >
> > > > > >     Cairo
> > > > > >
> > > > > > The following objects are masked from
> ?package:PerformanceAnalytics?:
> > > > > >
> > > > > >     kurtosis, skewness
> > > > > >
> > > > > > Loading required package: timeSeries
> > > > > >
> > > > > > Attaching package: ?timeSeries?
> > > > > >
> > > > > > The following object is masked from ?package:zoo?:
> > > > > >
> > > > > >     time<-
> > > > > >
> > > > > > Loading required package: fBasics
> > > > > >
> > > > > >
> > > > > > Rmetrics Package fBasics
> > > > > > Analysing Markets and calculating Basic Statistics
> > > > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > > > Educational Software for Financial Engineering and Computational
> Science
> > > > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > > > Loading required package: fOptions
> > > > > >
> > > > > >
> > > > > > Rmetrics Package fOptions
> > > > > > Pricing and Evaluating Basic Options
> > > > > > Copyright (C) 2005-2014 Rmetrics Association Zurich
> > > > > > Educational Software for Financial Engineering and Computational
> Science
> > > > > > Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> > > > > > https://www.rmetrics.org --- Mail to: info at rmetrics.org
> > > > > >
> > > > > > Attaching package: ?prob?
> > > > > >
> > > > > > The following objects are masked from ?package:dplyr?:
> > > > > >
> > > > > >     intersect, setdiff, union
> > > > > >
> > > > > > The following objects are masked from ?package:base?:
> > > > > >
> > > > > >     intersect, setdiff, union
> > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > Tiby
> > > > > > >
> > > > > > >       [[alternative HTML version deleted]]
> > > > > >
> > > > > > A specific suggestion would be that you read the listinfo and
> the Posting Guide and learn to post in plain text.
> > > > > > >
> > > > > > > ______________________________________________
> > > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > > > > > and provide commented, minimal, self-contained, reproducible
> code.
> > > > > >
> > > > > > David Winsemius
> > > > > > Alameda, CA, USA
> > > > > >
> > > > > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > >
> > > > > David Winsemius
> > > > > Alameda, CA, USA
> > > > >
> > > > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > >
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently
> advanced.'   -Gehm's Corollary to Clarke's Third Law
> > >
> > >
> > >
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Nov  3 08:54:17 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Nov 2017 07:54:17 +0000
Subject: [R] repeat a function
In-Reply-To: <a8a78eb5324b46ed97f050ace3a021e3@DB4PR7001MB0030.015d.mgd.msft.net>
References: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>
 <a8a78eb5324b46ed97f050ace3a021e3@DB4PR7001MB0030.015d.mgd.msft.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB834A@SRVEXCHCM301.precheza.cz>

Hi

Well, I am not an expert in this field so I cannot comment your approach. I wanted only to point out that building matrix your way is like scratching your left ear with right hand, especially in R. What if you want increase size of your matrix?

E.g. you use function ProbUP once for row "0" and than for rows different from jmax (if I correctly understand your code). Use of any function depends on two parameters (row and column, let them call u and v)

>   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> dt)) / 2)          ######### Probability X going up
>   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)
> ######## Probability X going middle
>   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a,
> dt)) / 2)

Functions are quite similar, you basically need to find how combination of row and column number results in desired j value. However it could be quite tricky and if your approach works and you do not want to extend it or to make it more general, you could stay with it.

Cheers
Petr


> -----Original Message-----
> From: Eric.Pueyo at avivainvestors.com [mailto:Eric.Pueyo at avivainvestors.com]
> Sent: Thursday, November 2, 2017 5:54 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
> Subject: RE: [R] repeat a function
>
> Hi Petr,
>
> Many thanks for your response.
>
> Basically I want to create a probability matrix to be used in a trinomial tree
> going forward. This is the reason why I thought to build the matrix around 0
> would be much more efficient. I need to loop through because the probabilities
> will depend on my node and is not always the same per row (e.g. if N> jmax,
> jmax being defined in another function) I found a workaround. Please see
> below.
> Thereafter I want to optimize this function. Hopefully it works.
>
> Many thanks,
> Eric
>
> HWMProb <- function(N) {
>   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> dt)) / 2)          ######### Probability X going up
>   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)
> ######## Probability X going middle
>   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a,
> dt)) / 2)          #######  Probability X going down
>   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j *
> Mfactor(a, dt)) / 2     ####### Top branch probability going up
>   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j *
> Mfactor(a, dt)          ####### Top branch probability going MID
>   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j *
> Mfactor(a, dt)) / 2        ####### Top branch probability going DOWN
>   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> Mfactor(a, dt)) / 2        ####### Bottom branch probability going u
>   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j *
> Mfactor(a, dt)        ####### Bottom branch probability going MID
>   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j *
> Mfactor(a, dt)) / 2   ####### Bottom branch probability going DOWN
>
> if (N>jmax) N=jmax
>
> for (j in 0:N) {
>   if (j==0) {
>     prb["0","1"] <<- ProbUP(a,j,dt)
>     prb["0","0"] <<- ProbMID(a,j,dt)
>     prb["0","-1"] <<- ProbDWN(a,j,dt)
>   }
>   else {
>     if (j==jmax) {
>       prb[paste(j,sep = ""),"1"] <<- TOPProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <<- TOPProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <<- TOPProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <<- BTTMProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <<- BTTMProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <<- BTTMProbDWN(a,-j,dt)
>     }
>     else {
>       prb[paste(j,sep = ""),"1"] <<- ProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <<- ProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <<- ProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <<- ProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <<- ProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <<- ProbDWN(a,-j,dt)
>     } # Close 2nd IF
>   } # Close 1st IF
> } #end for
> }
>
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: 02 November 2017 15:56
> To: Eric Pueyo; r-help at r-project.org
> Subject: RE: [R] repeat a function
>
> Hi Eric
>
> I did not see any answer and frankly speaking I cannot provide you with canned
> help.
>
> AFAIK if a function is defined within another function (which is your case) it
> cannot be called directly so it is necessary to define it in global environment.
>
> >  fff <- function(x) {
> +  myf <- function(a) a+2
> +  myf(x)^2}
> >
> > fff(5)
> [1] 49
> > myf(5)
> Error in myf(5) : could not find function "myf"
> >
>
> Your function set is quite complicated but I wonder why would it be necessary
> to use for cycle for what seems to be simple table. Everything seems quite
> deterministic.
>
> Basically you have combination of rows (-2,-1,0,1,2) and columns -1,-,1.
> expand.grid(u=-2:2, v=-1:1)
> for each row you can than use one function with parameters u, v and a and dt.
> After you calculate vector of results, you can easily transform it to matrix by
> setting dim argument to it.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Eric.Pueyo at avivainvestors.com
> > Sent: Wednesday, November 1, 2017 1:31 PM
> > To: r-help at r-project.org
> > Subject: [R] repeat a function
> >
> > I want to populate the matrix prb through the function HWMProb <-
> > function
> > (a,j,dt) that encapsulates different functions (please see code
> > below), using j=
> > 0:2 for each j.
> >
> > It only populates prb if I specify each function independently in the
> > global environment and then run the loop with the iF statement, as per
> below.
> > for (j in 0:2) {
> >   if (j==0) {
> >     prb["0","1"] <- ProbUP(a,j,dt)
> >     prb["0","0"] <- ProbMID(a,j,dt)
> >     prb["0","-1"] <- ProbDWN(a,j,dt)
> >   }
> >   else {
> >     if (j==jmax) {
> >       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
> >     }
> >     else {
> >       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
> >     } # Close 2nd IF
> >   } # Close 1st IF
> > }
> >
> > Many thanks in advance.
> > Kind regards,
> >
> > Eric Pueyo
> > Investment Risk Analyst
> > Email:
> > Eric.Pueyo at avivainvestors.com<mailto:Eric.Pueyo at avivainvestors.com>
> > D: +44 (0)20 7809 8070
> > No. 1 Undershaft, London EC3P 3DQ
> > Web:
> > www.avivainvestors.com<https://urldefense.proofpoint.com/v2/url?u=http
> > -
> >
> 3A__www.avivainvestors.com_&d=CwMFAg&c=zUO0BtkCe66yJvAZ4cAvZg&r=-
> > 34SVFvqwmZvbxD0ShuYglbuijP84lygitjFgiP1fxI&m=kRg3I7ESFxV-
> > KaNbYHN6DPupgyEmFCiThNO6oDnpAFs&s=tQa1EuXKNfzRgiR2HgG0H_tW_X-
> > BCpgebe5AL9A_GC8&e=>
> >
> > jmax<-2
> > prb <-matrix(0L,nrow=5, ncol=3)
> > rownames(prb) <- c(seq(-2,2, by = 1))
> > colnames(prb) <- c(-1,0,1)
> > a<- 0.1
> > dt<-1
> >
> > ExpX <-function(x,a,dt) {                              ######Defines the Expectation of X
> > on t+1 | t
> > ExpX <- x*exp(-a*dt)
> > ExpX
> > }
> > Mfactor<-function(a,dt)  {                           #######Factor multiplicative
> >   Mfactor<- exp(-a*dt)-1
> >   Mfactor
> > }
> > VarX <-function(sigma,a,dt) {                         #######Defubes the Variance of X
> > on t+1 | t
> >   VarX <- (sigma^2/(2*a))*(1-exp(-2*a*dt))
> >   VarX
> > }
> > DeltaX <-function(sigma,a,dt) {                       ######Defines the change of X
> >   DeltaX<- sqrt(3*VarX(sigma,a,dt))
> >   DeltaX<-value(DeltaX)
> > }
> >
> > Mfactor<-function(a,dt)  {                           #######Factor multiplicative
> >   Mfactor<- exp(-a*dt)-1
> >   Mfactor
> > }
> >
> > KNode<-function(sigma,x,a,j,dt) {                    ######Central Node
> >   KNode<- round(ExpX(x,a,dt)/DeltaX(sigma,a,dt))
> >   KNode
> > }
> >
> > ####### Probability Calculations taking into account different
> > branches HWMProb <- function (a,j,dt) {
> >   ######################### DESCRIPTION
> > #####################################
> >   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> > dt)) / 2)                     ######### Probability X going up
> >   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2)
> > ######## Probability X going middle
> >   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> Mfactor(a,
> > dt)) / 2)                  #######  Probability X going down
> >   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j *
> > Mfactor(a, dt)) / 2                 ####### Top branch probability going up
> >   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j *
> > Mfactor(a, dt)              ####### Top branch probability going MID
> >   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j *
> > Mfactor(a, dt)) / 2               ####### Top branch probability going DOWN
> >   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> > Mfactor(a, dt)) / 2           ####### Bottom branch probability going u
> >   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j *
> > Mfactor(a, dt)               ####### Bottom branch probability going MID
> >   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j *
> > Mfactor(a, dt)) / 2              ####### Bottom branch probability going DOWN
> >
> >   if (j==0) {
> >     prb["0","1"] <- ProbUP(a,j,dt)
> >     prb["0","0"] <- ProbMID(a,j,dt)
> >     prb["0","-1"] <- ProbDWN(a,j,dt)
> >   }
> >   else {
> >     if (j==jmax) {
> >       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
> >     }
> >     else {
> >       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
> >      prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
> >     } # Close 2nd IF
> >   } # Close 1st IF
> > } #Close Formula
> >
> > for (j in 0:2) {
> >   HWMProb(a,j,dt)
> >
> > }
> >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From suelitera at outlook.com  Fri Nov  3 07:57:33 2017
From: suelitera at outlook.com (Wang ChenXi)
Date: Fri, 3 Nov 2017 06:57:33 +0000
Subject: [R] Pairwise comparison, TukeyHSD, glht, ANCOVA
Message-ID: <TY1PR0201MB0912258EEF97E716E901E576B85D0@TY1PR0201MB0912.apcprd02.prod.outlook.com>

Hi,

I'm wondering if i can use the function "TukeyHSD" to perform the all pairwise comparisons of a "aov()" model with one factor (e.g., GROUP) and one continuous covariate (e.g., AGE). I did for example:

library(multcomp)
data('litter', package = 'multcomp')
litter.aov <- aov(weight ~ gesttime + dose, data = litter)
TukeyHSD(litter.aov, which = 'dose')

and i get a warning message like this:
Warning message:
In replications(paste("~", xx), data = mf): non-factor ignored: gesttime

Is this process above correct? What's the meaning of the warning message? And does "TukeyHSD" apply to badly unbalanced designs?

In addition, is there any difference between the processes above and below?

litter.mc <- glht(litter.aov, linfct = mcp(dose = 'Tukey'))
summary(litter.mc)

Sincerely,
Sue




	[[alternative HTML version deleted]]


From Eric.Pueyo at avivainvestors.com  Fri Nov  3 12:16:20 2017
From: Eric.Pueyo at avivainvestors.com (Eric.Pueyo at avivainvestors.com)
Date: Fri, 3 Nov 2017 11:16:20 +0000
Subject: [R] repeat a function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB834A@SRVEXCHCM301.precheza.cz>
References: <4f1bb8cfe3f145b1b46ff7ea3517337e@DB4PR7001MB0030.015d.mgd.msft.net>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB81F1@SRVEXCHCM301.precheza.cz>
 <a8a78eb5324b46ed97f050ace3a021e3@DB4PR7001MB0030.015d.mgd.msft.net>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB834A@SRVEXCHCM301.precheza.cz>
Message-ID: <fa876421341d4fc285d1ffad3a035e01@DB4PR7001MB0030.015d.mgd.msft.net>

Thanks Petr. Really appreciated!

Many thanks,
Eric

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: 03 November 2017 07:54
To: Eric Pueyo; r-help at r-project.org
Subject: RE: [R] repeat a function

Hi

Well, I am not an expert in this field so I cannot comment your approach. I wanted only to point out that building matrix your way is like scratching your left ear with right hand, especially in R. What if you want increase size of your matrix?

E.g. you use function ProbUP once for row "0" and than for rows different from jmax (if I correctly understand your code). Use of any function depends on two parameters (row and column, let them call u and v)

>   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> dt)) / 2)          ######### Probability X going up
>   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2) 
> ######## Probability X going middle
>   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - 
> j * Mfactor(a,
> dt)) / 2)

Functions are quite similar, you basically need to find how combination of row and column number results in desired j value. However it could be quite tricky and if your approach works and you do not want to extend it or to make it more general, you could stay with it.

Cheers
Petr


> -----Original Message-----
> From: Eric.Pueyo at avivainvestors.com 
> [mailto:Eric.Pueyo at avivainvestors.com]
> Sent: Thursday, November 2, 2017 5:54 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
> Subject: RE: [R] repeat a function
>
> Hi Petr,
>
> Many thanks for your response.
>
> Basically I want to create a probability matrix to be used in a 
> trinomial tree going forward. This is the reason why I thought to 
> build the matrix around 0 would be much more efficient. I need to loop 
> through because the probabilities will depend on my node and is not 
> always the same per row (e.g. if N> jmax, jmax being defined in 
> another function) I found a workaround. Please see below.
> Thereafter I want to optimize this function. Hopefully it works.
>
> Many thanks,
> Eric
>
> HWMProb <- function(N) {
>   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> dt)) / 2)          ######### Probability X going up
>   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2) 
> ######## Probability X going middle
>   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 - j * Mfactor(a,
> dt)) / 2)          #######  Probability X going down
>   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j *
> Mfactor(a, dt)) / 2     ####### Top branch probability going up
>   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j *
> Mfactor(a, dt)          ####### Top branch probability going MID
>   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j *
> Mfactor(a, dt)) / 2        ####### Top branch probability going DOWN
>   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> Mfactor(a, dt)) / 2        ####### Bottom branch probability going u
>   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j *
> Mfactor(a, dt)        ####### Bottom branch probability going MID
>   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j *
> Mfactor(a, dt)) / 2   ####### Bottom branch probability going DOWN
>
> if (N>jmax) N=jmax
>
> for (j in 0:N) {
>   if (j==0) {
>     prb["0","1"] <<- ProbUP(a,j,dt)
>     prb["0","0"] <<- ProbMID(a,j,dt)
>     prb["0","-1"] <<- ProbDWN(a,j,dt)
>   }
>   else {
>     if (j==jmax) {
>       prb[paste(j,sep = ""),"1"] <<- TOPProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <<- TOPProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <<- TOPProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <<- BTTMProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <<- BTTMProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <<- BTTMProbDWN(a,-j,dt)
>     }
>     else {
>       prb[paste(j,sep = ""),"1"] <<- ProbUP(a,j,dt)
>       prb[paste(j,sep = ""),"0"] <<- ProbMID(a,j,dt)
>       prb[paste(j,sep = ""),"-1"] <<- ProbDWN(a,j,dt)
>       prb[paste(-j,sep = ""),"1"] <<- ProbUP(a,-j,dt)
>       prb[paste(-j,sep = ""),"0"] <<- ProbMID(a,-j,dt)
>       prb[paste(-j,sep = ""),"-1"] <<- ProbDWN(a,-j,dt)
>     } # Close 2nd IF
>   } # Close 1st IF
> } #end for
> }
>
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: 02 November 2017 15:56
> To: Eric Pueyo; r-help at r-project.org
> Subject: RE: [R] repeat a function
>
> Hi Eric
>
> I did not see any answer and frankly speaking I cannot provide you 
> with canned help.
>
> AFAIK if a function is defined within another function (which is your 
> case) it cannot be called directly so it is necessary to define it in global environment.
>
> >  fff <- function(x) {
> +  myf <- function(a) a+2
> +  myf(x)^2}
> >
> > fff(5)
> [1] 49
> > myf(5)
> Error in myf(5) : could not find function "myf"
> >
>
> Your function set is quite complicated but I wonder why would it be 
> necessary to use for cycle for what seems to be simple table. 
> Everything seems quite deterministic.
>
> Basically you have combination of rows (-2,-1,0,1,2) and columns -1,-,1.
> expand.grid(u=-2:2, v=-1:1)
> for each row you can than use one function with parameters u, v and a and dt.
> After you calculate vector of results, you can easily transform it to 
> matrix by setting dim argument to it.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> > Eric.Pueyo at avivainvestors.com
> > Sent: Wednesday, November 1, 2017 1:31 PM
> > To: r-help at r-project.org
> > Subject: [R] repeat a function
> >
> > I want to populate the matrix prb through the function HWMProb <- 
> > function
> > (a,j,dt) that encapsulates different functions (please see code 
> > below), using j=
> > 0:2 for each j.
> >
> > It only populates prb if I specify each function independently in 
> > the global environment and then run the loop with the iF statement, 
> > as per
> below.
> > for (j in 0:2) {
> >   if (j==0) {
> >     prb["0","1"] <- ProbUP(a,j,dt)
> >     prb["0","0"] <- ProbMID(a,j,dt)
> >     prb["0","-1"] <- ProbDWN(a,j,dt)
> >   }
> >   else {
> >     if (j==jmax) {
> >       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
> >     }
> >     else {
> >       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
> >     } # Close 2nd IF
> >   } # Close 1st IF
> > }
> >
> > Many thanks in advance.
> > Kind regards,
> >
> > Eric Pueyo
> > Investment Risk Analyst
> > Email:
> > Eric.Pueyo at avivainvestors.com<mailto:Eric.Pueyo at avivainvestors.com>
> > D: +44 (0)20 7809 8070
> > No. 1 Undershaft, London EC3P 3DQ
> > Web:
> > www.avivainvestors.com<https://urldefense.proofpoint.com/v2/url?u=ht
> > tp
> > -
> >
> 3A__www.avivainvestors.com_&d=CwMFAg&c=zUO0BtkCe66yJvAZ4cAvZg&r=-
> > 34SVFvqwmZvbxD0ShuYglbuijP84lygitjFgiP1fxI&m=kRg3I7ESFxV-
> > KaNbYHN6DPupgyEmFCiThNO6oDnpAFs&s=tQa1EuXKNfzRgiR2HgG0H_tW_X-
> > BCpgebe5AL9A_GC8&e=>
> >
> > jmax<-2
> > prb <-matrix(0L,nrow=5, ncol=3)
> > rownames(prb) <- c(seq(-2,2, by = 1))
> > colnames(prb) <- c(-1,0,1)
> > a<- 0.1
> > dt<-1
> >
> > ExpX <-function(x,a,dt) {                              ######Defines the Expectation of X
> > on t+1 | t
> > ExpX <- x*exp(-a*dt)
> > ExpX
> > }
> > Mfactor<-function(a,dt)  {                           #######Factor multiplicative
> >   Mfactor<- exp(-a*dt)-1
> >   Mfactor
> > }
> > VarX <-function(sigma,a,dt) {                         #######Defubes the Variance of X
> > on t+1 | t
> >   VarX <- (sigma^2/(2*a))*(1-exp(-2*a*dt))
> >   VarX
> > }
> > DeltaX <-function(sigma,a,dt) {                       ######Defines the change of X
> >   DeltaX<- sqrt(3*VarX(sigma,a,dt))
> >   DeltaX<-value(DeltaX)
> > }
> >
> > Mfactor<-function(a,dt)  {                           #######Factor multiplicative
> >   Mfactor<- exp(-a*dt)-1
> >   Mfactor
> > }
> >
> > KNode<-function(sigma,x,a,j,dt) {                    ######Central Node
> >   KNode<- round(ExpX(x,a,dt)/DeltaX(sigma,a,dt))
> >   KNode
> > }
> >
> > ####### Probability Calculations taking into account different 
> > branches HWMProb <- function (a,j,dt) {
> >   ######################### DESCRIPTION 
> > #####################################
> >   ProbUP<- function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 + j * Mfactor(a,
> > dt)) / 2)                     ######### Probability X going up
> >   ProbMID<- function(a, j, dt) 2 / 3 - (j ^ 2 * Mfactor(a, dt) ^ 2) 
> > ######## Probability X going middle
> >   ProbDWN<-function( a, j, dt) 1 / 6 + ((j ^ 2 * Mfactor(a, dt) ^ 2 
> > - j *
> Mfactor(a,
> > dt)) / 2)                  #######  Probability X going down
> >   TOPProbUP<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + 3 * j *
> > Mfactor(a, dt)) / 2                 ####### Top branch probability going up
> >   TOPProbMID<- function(a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 - 2 * j *
> > Mfactor(a, dt)              ####### Top branch probability going MID
> >   TOPProbDWN<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 + j *
> > Mfactor(a, dt)) / 2               ####### Top branch probability going DOWN
> >   BTTMProbUP<- function( a, j, dt) 1 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - j *
> > Mfactor(a, dt)) / 2           ####### Bottom branch probability going u
> >   BTTMProbMID<- function( a, j, dt) -1 / 3 - j ^ 2 * Mfactor(a, dt) ^ 2 + 2 * j *
> > Mfactor(a, dt)               ####### Bottom branch probability going MID
> >   BTTMProbDWN<- function( a, j, dt) 7 / 6 + (j ^ 2 * Mfactor(a, dt) ^ 2 - 3 * j *
> > Mfactor(a, dt)) / 2              ####### Bottom branch probability going DOWN
> >
> >   if (j==0) {
> >     prb["0","1"] <- ProbUP(a,j,dt)
> >     prb["0","0"] <- ProbMID(a,j,dt)
> >     prb["0","-1"] <- ProbDWN(a,j,dt)
> >   }
> >   else {
> >     if (j==jmax) {
> >       prb[paste(j,sep = ""),"1"] <- TOPProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- TOPProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- TOPProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- BTTMProbUP(a,-j,dt)
> >       prb[paste(-j,sep = ""),"0"] <- BTTMProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- BTTMProbDWN(a,-j,dt)
> >     }
> >     else {
> >       prb[paste(j,sep = ""),"1"] <- ProbUP(a,j,dt)
> >       prb[paste(j,sep = ""),"0"] <- ProbMID(a,j,dt)
> >       prb[paste(j,sep = ""),"-1"] <- ProbDWN(a,j,dt)
> >       prb[paste(-j,sep = ""),"1"] <- ProbUP(a,-j,dt)
> >      prb[paste(-j,sep = ""),"0"] <- ProbMID(a,-j,dt)
> >       prb[paste(-j,sep = ""),"-1"] <- ProbDWN(a,-j,dt)
> >     } # Close 2nd IF
> >   } # Close 1st IF
> > } #Close Formula
> >
> > for (j in 0:2) {
> >   HWMProb(a,j,dt)
> >
> > }
> >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

This email transmission and any attachments may contain confidential or legally privileged information that is intended for the addressee(s) only. Any views or opinions presented are solely those of the author and do not necessarily represent those of Aviva Investors. If you are not the intended recipient or person responsible for delivering this information to the intended recipient you are hereby notified that any disclosure, copying, distribution or reliance upon the contents of this email is strictly prohibited. If you have received this email transmission in error please notify the sender immediately so that we may arrange for its proper delivery and delete the message from your inbox.

Aviva Investors Global Services Limited, registered in England No. 1151805. Entered on the Financial Services Register, No: 119178. Authorised and regulated by the Financial Conduct Authority.

Aviva Investors Pensions Limited, registered in England No. 1059606. Entered on the Financial Services Register, No: 110410. Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.

Aviva Investors UK Fund Services Limited, registered in England No. 1973412. Entered on the Financial Services Register, No. 119310. Authorised and regulated by the Financial Conduct Authority. 

Aviva Investors UK Funds Limited, registered in England No. 2503054. Entered on the Financial Services Register, No. 147088. Authorised and regulated by the Financial Conduct Authority. 

Registered Office for all companies: St Helen?s, 1 Undershaft, London EC3P 3DQ. VAT number: 105 4373 00.

Telephone calls to Aviva Investors may be recorded for training or monitoring purposes. We may monitor traffic data of both business and personal emails. By replying to this email, you consent to us monitoring the content of any emails you send to or receive from Aviva Investors.

From bryangoh39 at hotmail.com  Fri Nov  3 14:50:29 2017
From: bryangoh39 at hotmail.com (Peng Sian Goh)
Date: Fri, 3 Nov 2017 13:50:29 +0000
Subject: [R] as.spikeTrain
Message-ID: <SG2PR04MB12150E36E03B2E773BFDA5CCC35D0@SG2PR04MB1215.apcprd04.prod.outlook.com>

Hi all,


I have recently used the as.spikeTrain function in the STAR Packages but instead of using the CAL1S data that could be found in the package, I used data from other sources.


I am able to convert the data into the required data frame but when I execute the as.spikeTrain function: datafile <- lapply(list_data,as.spikeTrain)


It will give this error:


Error in FUN(X[[i]], ...) :
  The elements of X[[i]] should be all different.

Error in FUN(X[[i]], ...) :
  X[[i]] should have strictly increasing elements.

I found out that as.spikeTrain will only work when the raw data (in txt, csv or any other format) doesnt contain numbers that are repeated and it numbers should also be arranged in increasing order.

May i know why the limitation?

As far as I understand by looking at other spiketrain datasets, the data doesnt follow the increasing trends and many have repeated numbers.

Do advice.

Thanks



Regards,


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Nov  3 15:34:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 3 Nov 2017 07:34:29 -0700
Subject: [R] as.spikeTrain
In-Reply-To: <SG2PR04MB12150E36E03B2E773BFDA5CCC35D0@SG2PR04MB1215.apcprd04.prod.outlook.com>
References: <SG2PR04MB12150E36E03B2E773BFDA5CCC35D0@SG2PR04MB1215.apcprd04.prod.outlook.com>
Message-ID: <CAGxFJbQNocdG+C=m8M6nLU6iz4UQqeaAeqqnhNemnpbans1NuA@mail.gmail.com>

I believe this query is OT here and would best be addressed by either a
careful reading of the package documentation or by contacting the package
maintainer, found by maintainer("STAR").

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Nov 3, 2017 at 6:50 AM, Peng Sian Goh <bryangoh39 at hotmail.com>
wrote:

> Hi all,
>
>
> I have recently used the as.spikeTrain function in the STAR Packages but
> instead of using the CAL1S data that could be found in the package, I used
> data from other sources.
>
>
> I am able to convert the data into the required data frame but when I
> execute the as.spikeTrain function: datafile <- lapply(list_data,as.
> spikeTrain)
>
>
> It will give this error:
>
>
> Error in FUN(X[[i]], ...) :
>   The elements of X[[i]] should be all different.
>
> Error in FUN(X[[i]], ...) :
>   X[[i]] should have strictly increasing elements.
>
> I found out that as.spikeTrain will only work when the raw data (in txt,
> csv or any other format) doesnt contain numbers that are repeated and it
> numbers should also be arranged in increasing order.
>
> May i know why the limitation?
>
> As far as I understand by looking at other spiketrain datasets, the data
> doesnt follow the increasing trends and many have repeated numbers.
>
> Do advice.
>
> Thanks
>
>
>
> Regards,
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gbalas07 at gmail.com  Fri Nov  3 23:39:37 2017
From: gbalas07 at gmail.com (George Balas)
Date: Sat, 4 Nov 2017 00:39:37 +0200
Subject: [R] Problem with r project in ubuntu xenial
Message-ID: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>

I have a problem with R in Ubuntu 16.04. I do not know if it is mine pc or
general problem but I was not able to find solution on Internet.
First of all I can not change locale to greek by getting this message:
"In Sys.setlocale("LC_CTYPE", "Greek") :
  OS reports request to set locale to "Greek" cannot be honored"
Second and more serious is that I can not use some functions like
graph_from_adjacency_matrix or print_all I get these messeges:
"could not find function "graph_from_adjacency_matrix""
"could not find function "print_all"".
I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on rstudio
or ubuntu terminal.
On my pc I also run win 10 with the same installs and I do not have the
above problems, but I work on ubuntu and can not change Os all the time.
Please help me.

Thank you for your time,
George
gbalas07 at gmail.com

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Nov  4 01:09:22 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 4 Nov 2017 01:09:22 +0100
Subject: [R] Problem with r project in ubuntu xenial
In-Reply-To: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
References: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
Message-ID: <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>


> On 3 Nov 2017, at 23:39 , George Balas <gbalas07 at gmail.com> wrote:
> 
> I have a problem with R in Ubuntu 16.04. I do not know if it is mine pc or
> general problem but I was not able to find solution on Internet.
> First of all I can not change locale to greek by getting this message:
> "In Sys.setlocale("LC_CTYPE", "Greek") :
>  OS reports request to set locale to "Greek" cannot be honored"

The Greek locale is likely not called "Greek" outside of Windows. More likely "el_GR.UTF-8" or thereabouts (check your locale database, I'm on a Mac). These things are not standardized across platforms.

> Second and more serious is that I can not use some functions like
> graph_from_adjacency_matrix or print_all I get these messeges:
> "could not find function "graph_from_adjacency_matrix""
> "could not find function "print_all"".

Missing library(igraph)?

-pd

> I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on rstudio
> or ubuntu terminal.
> On my pc I also run win 10 with the same installs and I do not have the
> above problems, but I work on ubuntu and can not change Os all the time.
> Please help me.
> 
> Thank you for your time,
> George
> gbalas07 at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Sat Nov  4 01:22:43 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 3 Nov 2017 17:22:43 -0700
Subject: [R] Problem with r project in ubuntu xenial
In-Reply-To: <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>
References: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
 <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>
Message-ID: <B4DBC5FF-AA98-440D-92C7-D6792D44B568@comcast.net>


> On Nov 3, 2017, at 5:09 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 3 Nov 2017, at 23:39 , George Balas <gbalas07 at gmail.com> wrote:
>> 
>> I have a problem with R in Ubuntu 16.04. I do not know if it is mine pc or
>> general problem but I was not able to find solution on Internet.
>> First of all I can not change locale to greek by getting this message:
>> "In Sys.setlocale("LC_CTYPE", "Greek") :
>> OS reports request to set locale to "Greek" cannot be honored"
> 
> The Greek locale is likely not called "Greek" outside of Windows. More likely "el_GR.UTF-8" or thereabouts (check your locale database, I'm on a Mac). These things are not standardized across platforms.
> 

Also

From help(locales): Attempts to change the character set by Sys.setlocale("LC_CTYPE") that implies a different character set during a session may not work and are likely to lead to some confusion because it may not affect the native encoding.


>> Second and more serious is that I can not use some functions like
>> graph_from_adjacency_matrix or print_all I get these messeges:
>> "could not find function "graph_from_adjacency_matrix""
>> "could not find function "print_all"".
> 
> Missing library(igraph)?
> 
> -pd
> 
>> I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on rstudio
>> or ubuntu terminal.
>> On my pc I also run win 10 with the same installs and I do not have the
>> above problems, but I work on ubuntu and can not change Os all the time.
>> Please help me.
>> 
>> Thank you for your time,
>> George
>> gbalas07 at gmail.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From kentp3 at uni.coventry.ac.uk  Sat Nov  4 14:30:03 2017
From: kentp3 at uni.coventry.ac.uk (Paul Kent)
Date: Sat, 4 Nov 2017 13:30:03 +0000
Subject: [R] Question - TukeyHSD
Message-ID: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>

Hi,


I've been performing some TukeyHSD tests in R and have come across papers that include all the necessary information (means, sample size and SE) for me to perform the piecewise comparison by hand. I can reach out to the authors to get the original dataset, but it raises the question, can I perform the Test with the information I have and save myself some time? Is there a way to somehow construct an aov element to feed the TukeyHSD function, or is there another way to proceed.


Many thanks.


Paul Kent

Gold rating for teaching excellence
Teaching Excellence Framework (TEF)

Ranked No.12 UK university
The Guardian University Guide 2018

UK's highest ranking new university
The Guardian and the Complete University Guides 2018

Top 4 for Student Experience and Teaching Quality
The Times and The Sunday Times Good University Guide 2018

NOTICE

This message and any files transmitted with it is intended for the addressee only and may contain information that is confidential or privileged. Unauthorised use is strictly prohibited. If you are not the addressee, you should not read, copy, disclose or otherwise use this message, except for the purpose of delivery to the addressee.

Any views or opinions expressed within this e-mail are those of the author and do not necessarily represent those of Coventry University.

	[[alternative HTML version deleted]]


From rararoche at hotmail.com  Sat Nov  4 12:45:27 2017
From: rararoche at hotmail.com (sarah roche)
Date: Sat, 4 Nov 2017 11:45:27 +0000
Subject: [R] R
Message-ID: <DB6PR0902MB16725E8069796DE439429011BC520@DB6PR0902MB1672.eurprd09.prod.outlook.com>

To whom it may concern,


I cannot seem to load the data no matter what package I download I was wondering if you could please look at my screen shots and if you could suggest what I could do to fix it please. Thank you very much for your time.


Kind regards,

Sarah

From jdnewmil at dcn.davis.ca.us  Sat Nov  4 17:40:47 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 04 Nov 2017 09:40:47 -0700
Subject: [R] R
In-Reply-To: <DB6PR0902MB16725E8069796DE439429011BC520@DB6PR0902MB1672.eurprd09.prod.outlook.com>
References: <DB6PR0902MB16725E8069796DE439429011BC520@DB6PR0902MB1672.eurprd09.prod.outlook.com>
Message-ID: <F2F374D1-2394-4744-AF95-B908F6408D66@dcn.davis.ca.us>

Sorry, but there are restrictions on mailing list attachments (read the Posting Guide) and your attachments did not get through. 

However, even if they had come through, we would need you to describe the sequence of actions you took, because computers in general respond to your actions, and most of the key responses R provides are text messages in response to your text commands. Screen shots are a poor way to communicate these exchanges.  Try reading [1][2][3] for help on how to do this clearly. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On November 4, 2017 4:45:27 AM PDT, sarah roche <rararoche at hotmail.com> wrote:
>To whom it may concern,
>
>
>I cannot seem to load the data no matter what package I download I was
>wondering if you could please look at my screen shots and if you could
>suggest what I could do to fix it please. Thank you very much for your
>time.
>
>
>Kind regards,
>
>Sarah
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Nov  4 21:33:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 4 Nov 2017 13:33:50 -0700
Subject: [R] Question - TukeyHSD
In-Reply-To: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>
References: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>
Message-ID: <CAGxFJbTuvJjpDJN9S0awX3WTNn1i=L3gcNbV7u9Le4Dj6dh3YA@mail.gmail.com>

AFAICS, without knowing the structure of your data and what specifically
you wish to do, how could one answer your question? -- which is probably
yes, you can do it, but without further info, ??? Maybe someone with a
better crystal ball can help -- or you could clarify.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Nov 4, 2017 at 6:30 AM, Paul Kent <kentp3 at uni.coventry.ac.uk> wrote:

> Hi,
>
>
> I've been performing some TukeyHSD tests in R and have come across papers
> that include all the necessary information (means, sample size and SE) for
> me to perform the piecewise comparison by hand. I can reach out to the
> authors to get the original dataset, but it raises the question, can I
> perform the Test with the information I have and save myself some time? Is
> there a way to somehow construct an aov element to feed the TukeyHSD
> function, or is there another way to proceed.
>
>
> Many thanks.
>
>
> Paul Kent
>
> Gold rating for teaching excellence
> Teaching Excellence Framework (TEF)
>
> Ranked No.12 UK university
> The Guardian University Guide 2018
>
> UK's highest ranking new university
> The Guardian and the Complete University Guides 2018
>
> Top 4 for Student Experience and Teaching Quality
> The Times and The Sunday Times Good University Guide 2018
>
> NOTICE
>
> This message and any files transmitted with it is intended for the
> addressee only and may contain information that is confidential or
> privileged. Unauthorised use is strictly prohibited. If you are not the
> addressee, you should not read, copy, disclose or otherwise use this
> message, except for the purpose of delivery to the addressee.
>
> Any views or opinions expressed within this e-mail are those of the author
> and do not necessarily represent those of Coventry University.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gbalas07 at gmail.com  Sat Nov  4 23:07:39 2017
From: gbalas07 at gmail.com (George Balas)
Date: Sun, 5 Nov 2017 00:07:39 +0200
Subject: [R] Problem with r project in ubuntu xenial
In-Reply-To: <B4DBC5FF-AA98-440D-92C7-D6792D44B568@comcast.net>
References: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
 <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>
 <B4DBC5FF-AA98-440D-92C7-D6792D44B568@comcast.net>
Message-ID: <CADwjDbpCtP9MR-GKnsEo2HCARGz7WhQjxO4zZOOVLDxOW305Mw@mail.gmail.com>

-Well it seems that it is getting "el_GR.UTF-8" but still I am not able to
read files written in greek, there are only "????" instead of letters.
-Also, I forgot to mention that I do load igraph library when I try
"graph_from_adjacency_matrix".
When I check igraph in packages dialog I can not see functions with
underscores between words, only dots.

2017-11-04 2:22 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Nov 3, 2017, at 5:09 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> >
> >> On 3 Nov 2017, at 23:39 , George Balas <gbalas07 at gmail.com> wrote:
> >>
> >> I have a problem with R in Ubuntu 16.04. I do not know if it is mine pc
> or
> >> general problem but I was not able to find solution on Internet.
> >> First of all I can not change locale to greek by getting this message:
> >> "In Sys.setlocale("LC_CTYPE", "Greek") :
> >> OS reports request to set locale to "Greek" cannot be honored"
> >
> > The Greek locale is likely not called "Greek" outside of Windows. More
> likely "el_GR.UTF-8" or thereabouts (check your locale database, I'm on a
> Mac). These things are not standardized across platforms.
> >
>
> Also
>
> From help(locales): Attempts to change the character set by
> Sys.setlocale("LC_CTYPE") that implies a different character set during a
> session may not work and are likely to lead to some confusion because it
> may not affect the native encoding.
>
>
> >> Second and more serious is that I can not use some functions like
> >> graph_from_adjacency_matrix or print_all I get these messeges:
> >> "could not find function "graph_from_adjacency_matrix""
> >> "could not find function "print_all"".
> >
> > Missing library(igraph)?
> >
> > -pd
> >
> >> I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on
> rstudio
> >> or ubuntu terminal.
> >> On my pc I also run win 10 with the same installs and I do not have the
> >> above problems, but I work on ubuntu and can not change Os all the time.
> >> Please help me.
> >>
> >> Thank you for your time,
> >> George
> >> gbalas07 at gmail.com
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Sun Nov  5 05:04:57 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 5 Nov 2017 00:04:57 -0400
Subject: [R] Question - TukeyHSD
In-Reply-To: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>
References: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>
Message-ID: <CAGx1TMBjcVdwJfX7Fb0yR-yQd1Z+6t9jYE9CauoMi-Xe_EvRdA@mail.gmail.com>

Assuming you have as your model a one-way ANOVA, you can use the
aovSufficient function in HH.

## install.packages("HH") ## if you don't have it yet
library(HH)
?aovSufficient

On Sat, Nov 4, 2017 at 9:30 AM, Paul Kent <kentp3 at uni.coventry.ac.uk> wrote:
> Hi,
>
>
> I've been performing some TukeyHSD tests in R and have come across papers that include all the necessary information (means, sample size and SE) for me to perform the piecewise comparison by hand. I can reach out to the authors to get the original dataset, but it raises the question, can I perform the Test with the information I have and save myself some time? Is there a way to somehow construct an aov element to feed the TukeyHSD function, or is there another way to proceed.
>
>
> Many thanks.
>
>
> Paul Kent
>
> Gold rating for teaching excellence
> Teaching Excellence Framework (TEF)
>
> Ranked No.12 UK university
> The Guardian University Guide 2018
>
> UK's highest ranking new university
> The Guardian and the Complete University Guides 2018
>
> Top 4 for Student Experience and Teaching Quality
> The Times and The Sunday Times Good University Guide 2018
>
> NOTICE
>
> This message and any files transmitted with it is intended for the addressee only and may contain information that is confidential or privileged. Unauthorised use is strictly prohibited. If you are not the addressee, you should not read, copy, disclose or otherwise use this message, except for the purpose of delivery to the addressee.
>
> Any views or opinions expressed within this e-mail are those of the author and do not necessarily represent those of Coventry University.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Sun Nov  5 11:17:07 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Sun, 5 Nov 2017 10:17:07 +0000 (UTC)
Subject: [R] Question - TukeyHSD
In-Reply-To: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>
References: <AM4PR01MB1491999DFD2DE1C52CDDC016E3520@AM4PR01MB1491.eurprd01.prod.exchangelabs.com>
Message-ID: <372880796.2340212.1509877027436@mail.yahoo.com>

I may be missing the point, but if you can do the calculations by hand could you not write a function in R to do the same and apply it to a data.frame of the values?
 

    On Saturday, November 4, 2017, 11:01:59 AM EDT, Paul Kent <kentp3 at uni.coventry.ac.uk> wrote:  
 
 Hi,


I've been performing some TukeyHSD tests in R and have come across papers that include all the necessary information (means, sample size and SE) for me to perform the piecewise comparison by hand. I can reach out to the authors to get the original dataset, but it raises the question, can I perform the Test with the information I have and save myself some time? Is there a way to somehow construct an aov element to feed the TukeyHSD function, or is there another way to proceed.


Many thanks.


Paul Kent

Gold rating for teaching excellence
Teaching Excellence Framework (TEF)

Ranked No.12 UK university
The Guardian University Guide 2018

UK's highest ranking new university
The Guardian and the Complete University Guides 2018

Top 4 for Student Experience and Teaching Quality
The Times and The Sunday Times Good University Guide 2018

NOTICE

This message and any files transmitted with it is intended for the addressee only and may contain information that is confidential or privileged. Unauthorised use is strictly prohibited. If you are not the addressee, you should not read, copy, disclose or otherwise use this message, except for the purpose of delivery to the addressee.

Any views or opinions expressed within this e-mail are those of the author and do not necessarily represent those of Coventry University.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From Goran.Bergqvist at jagareforbundet.se  Sun Nov  5 15:03:48 2017
From: Goran.Bergqvist at jagareforbundet.se (=?iso-8859-1?Q?G=F6ran_Bergqvist?=)
Date: Sun, 5 Nov 2017 14:03:48 +0000
Subject: [R] Change colour of line in logi.hist.plot
Message-ID: <9C500214DD8DB547BB8FBD816EB128EB4205C6DC@sjfmail02.hunter.lan>

I am using the function logi.hist.plot in package popbio. I want to change the colour of the probability line from the default red to black. I have not been able to find out how to do that.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Nov  5 18:07:54 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 5 Nov 2017 09:07:54 -0800
Subject: [R] Change colour of line in logi.hist.plot
In-Reply-To: <9C500214DD8DB547BB8FBD816EB128EB4205C6DC@sjfmail02.hunter.lan>
References: <9C500214DD8DB547BB8FBD816EB128EB4205C6DC@sjfmail02.hunter.lan>
Message-ID: <CAGxFJbTU-gMrQrWCSZ4DN5GhxMRefyRJOLYqKcLyE20LcYEFOg@mail.gmail.com>

Warning: Untested.

Note the "..." argument in the functions Help docs. This means "additional
optional arguments," which are passed down to underlying function calls.
The question is: what arguments? For plotting functions, especially those
using base graphics, it usually means the same sort of optional arguments
one would use for the plain plot.default() function. Lattice graphics is
somewhat similar for many of these arguments; ggplot graphics quite
different. But anyway, have a look at ?plot.default and try col = "black"
or maybe "col.line" = black. If this doesn't work (and you may have already
have tried this), hopefully someone else will have a better answer.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Nov 5, 2017 at 6:03 AM, G?ran Bergqvist <
Goran.Bergqvist at jagareforbundet.se> wrote:

> I am using the function logi.hist.plot in package popbio. I want to change
> the colour of the probability line from the default red to black. I have
> not been able to find out how to do that.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Nov  5 18:17:17 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 5 Nov 2017 09:17:17 -0800
Subject: [R] Change colour of line in logi.hist.plot
In-Reply-To: <9C500214DD8DB547BB8FBD816EB128EB4205C6DC@sjfmail02.hunter.lan>
References: <9C500214DD8DB547BB8FBD816EB128EB4205C6DC@sjfmail02.hunter.lan>
Message-ID: <16CFC58D-30DD-4047-B771-A24FB4D57EBC@comcast.net>


> On Nov 5, 2017, at 6:03 AM, G?ran Bergqvist <Goran.Bergqvist at jagareforbundet.se> wrote:
> 
> I am using the function logi.hist.plot in package popbio. I want to change the colour of the probability line from the default red to black. I have not been able to find out how to do that.

If you look at the code for that function you see this line:

logi.curve <- function(independ, depend, mod = logi.mod, 
        col.cur = "red", lwd.cur = 4) {
Since it's the only occurence of "red" that's probably where "the money lies". You can either do a "hard hack" where you alter the value of the parameters to that inner function,

... or you can add a named parameter after the dots in the outer parameter list such as:
   

 function (independ, depend, logi.mod = 1, type = "dit", boxp = TRUE, 
    rug = FALSE, ylabel = "Probability", ylabel2 = "Frequency", 
    xlabel = "", mainlabel = "", las.h = 1, counts = FALSE, ...,  col.cur = "red")

... and modify the inner function to read:

     logi.curve <- function(independ, depend, mod = logi.mod, 
        col.cur = col.cur, lwd.cur = 4) {


> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ahsanzahir at yahoo.com  Sun Nov  5 18:28:43 2017
From: ahsanzahir at yahoo.com (Ahsan Zahir)
Date: Sun, 5 Nov 2017 21:28:43 +0400
Subject: [R] Help in R
Message-ID: <CFE160EA-B276-4EC2-A5A4-E3BD28BB84A6@yahoo.com>


Hey,

I am a beginner in R.

How do I read last 10 values from column- Movie, from a dataset?

Pls help.

Sent from my iPhone


From dwinsemius at comcast.net  Sun Nov  5 19:38:35 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 5 Nov 2017 10:38:35 -0800
Subject: [R] Help in R
In-Reply-To: <CFE160EA-B276-4EC2-A5A4-E3BD28BB84A6@yahoo.com>
References: <CFE160EA-B276-4EC2-A5A4-E3BD28BB84A6@yahoo.com>
Message-ID: <B27C309C-0EF4-411A-A927-06EC7DEA1476@comcast.net>


> On Nov 5, 2017, at 9:28 AM, Ahsan Zahir via R-help <r-help at r-project.org> wrote:
> 
> 
> Hey,
> 
> I am a beginner in R.
> 
> How do I read last 10 values from column- Movie, from a dataset?

Some questions are so simple that they strongly suggest no prior effort at self-leanrning. In such cases the usual recommendation given at Rhelp is that you read an introductory text. Many of us used the "Introduction to R" that is shipped with every copy of R:

https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf


> 
> Pls help.
> 
> Sent from my iPhone
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ulrik.stervbo at gmail.com  Sun Nov  5 20:18:46 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sun, 05 Nov 2017 19:18:46 +0000
Subject: [R] Help in R
In-Reply-To: <B27C309C-0EF4-411A-A927-06EC7DEA1476@comcast.net>
References: <CFE160EA-B276-4EC2-A5A4-E3BD28BB84A6@yahoo.com>
 <B27C309C-0EF4-411A-A927-06EC7DEA1476@comcast.net>
Message-ID: <CAKVAULNZ17iHa=UPXnExCcZ2jFDboCr=X7VffTPp3vywQO7g7w@mail.gmail.com>

R can have a bit of a learning curve... There are several ways to achieve
your goal - depending on what you want:

test_df <- data.frame(Movie = letters, some.value = rnorm(26))

test_df$Movie[1:10]

test_df$Movie[sample(c(1:26), 10)]

test_df[sample(c(1:26), 10), ]

Do read a tutorial or two on R - "Introduction to R" as suggested by David
or something else - so you can explain the code above to yourself.

HTH
Ulrik

On Sun, 5 Nov 2017 at 19:38 David Winsemius <dwinsemius at comcast.net> wrote:

>
> > On Nov 5, 2017, at 9:28 AM, Ahsan Zahir via R-help <r-help at r-project.org>
> wrote:
> >
> >
> > Hey,
> >
> > I am a beginner in R.
> >
> > How do I read last 10 values from column- Movie, from a dataset?
>
> Some questions are so simple that they strongly suggest no prior effort at
> self-leanrning. In such cases the usual recommendation given at Rhelp is
> that you read an introductory text. Many of us used the "Introduction to R"
> that is shipped with every copy of R:
>
> https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf
>
>
> >
> > Pls help.
> >
> > Sent from my iPhone
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Nov  5 20:56:00 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 05 Nov 2017 19:56:00 +0000
Subject: [R] Help in R
In-Reply-To: <CAKVAULNZ17iHa=UPXnExCcZ2jFDboCr=X7VffTPp3vywQO7g7w@mail.gmail.com>
References: <CFE160EA-B276-4EC2-A5A4-E3BD28BB84A6@yahoo.com>
 <B27C309C-0EF4-411A-A927-06EC7DEA1476@comcast.net>
 <CAKVAULNZ17iHa=UPXnExCcZ2jFDboCr=X7VffTPp3vywQO7g7w@mail.gmail.com>
Message-ID: <59FF6CD0.3020506@sapo.pt>

Hello,

Also

tail(test_df$Movie, 10)

Hope this helps,

Rui Barradas

Em 05-11-2017 19:18, Ulrik Stervbo escreveu:
> R can have a bit of a learning curve... There are several ways to achieve
> your goal - depending on what you want:
>
> test_df <- data.frame(Movie = letters, some.value = rnorm(26))
>
> test_df$Movie[1:10]
>
> test_df$Movie[sample(c(1:26), 10)]
>
> test_df[sample(c(1:26), 10), ]
>
> Do read a tutorial or two on R - "Introduction to R" as suggested by David
> or something else - so you can explain the code above to yourself.
>
> HTH
> Ulrik
>
> On Sun, 5 Nov 2017 at 19:38 David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>>> On Nov 5, 2017, at 9:28 AM, Ahsan Zahir via R-help <r-help at r-project.org>
>> wrote:
>>>
>>>
>>> Hey,
>>>
>>> I am a beginner in R.
>>>
>>> How do I read last 10 values from column- Movie, from a dataset?
>>
>> Some questions are so simple that they strongly suggest no prior effort at
>> self-leanrning. In such cases the usual recommendation given at Rhelp is
>> that you read an introductory text. Many of us used the "Introduction to R"
>> that is shipped with every copy of R:
>>
>> https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf
>>
>>
>>>
>>> Pls help.
>>>
>>> Sent from my iPhone
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>   -Gehm's Corollary to Clarke's Third Law
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Sun Nov  5 23:29:09 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sun, 05 Nov 2017 22:29:09 +0000
Subject: [R] Help in R
In-Reply-To: <59FF6CD0.3020506@sapo.pt>
References: <CFE160EA-B276-4EC2-A5A4-E3BD28BB84A6@yahoo.com>
 <B27C309C-0EF4-411A-A927-06EC7DEA1476@comcast.net>
 <CAKVAULNZ17iHa=UPXnExCcZ2jFDboCr=X7VffTPp3vywQO7g7w@mail.gmail.com>
 <59FF6CD0.3020506@sapo.pt>
Message-ID: <CAKVAULMPOH1Hzx_Tyi51Zeq6nuDCfc1CYy17gXhX-T7bFTa2cA@mail.gmail.com>

And

head(test_df$Movie, 10)

For function completeness :-)

Rui Barradas <ruipbarradas at sapo.pt> schrieb am So., 5. Nov. 2017, 20:56:

> Hello,
>
> Also
>
> tail(test_df$Movie, 10)
>
> Hope this helps,
>
> Rui Barradas
>
> Em 05-11-2017 19:18, Ulrik Stervbo escreveu:
> > R can have a bit of a learning curve... There are several ways to achieve
> > your goal - depending on what you want:
> >
> > test_df <- data.frame(Movie = letters, some.value = rnorm(26))
> >
> > test_df$Movie[1:10]
> >
> > test_df$Movie[sample(c(1:26), 10)]
> >
> > test_df[sample(c(1:26), 10), ]
> >
> > Do read a tutorial or two on R - "Introduction to R" as suggested by
> David
> > or something else - so you can explain the code above to yourself.
> >
> > HTH
> > Ulrik
> >
> > On Sun, 5 Nov 2017 at 19:38 David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >>
> >>> On Nov 5, 2017, at 9:28 AM, Ahsan Zahir via R-help <
> r-help at r-project.org>
> >> wrote:
> >>>
> >>>
> >>> Hey,
> >>>
> >>> I am a beginner in R.
> >>>
> >>> How do I read last 10 values from column- Movie, from a dataset?
> >>
> >> Some questions are so simple that they strongly suggest no prior effort
> at
> >> self-leanrning. In such cases the usual recommendation given at Rhelp is
> >> that you read an introductory text. Many of us used the "Introduction
> to R"
> >> that is shipped with every copy of R:
> >>
> >> https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf
> >>
> >>
> >>>
> >>> Pls help.
> >>>
> >>> Sent from my iPhone
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >> 'Any technology distinguishable from magic is insufficiently advanced.'
> >>   -Gehm's Corollary to Clarke's Third Law
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From megov31 at yahoo.com  Mon Nov  6 04:21:07 2017
From: megov31 at yahoo.com (Meghna Govil)
Date: Sun, 5 Nov 2017 21:21:07 -0600
Subject: [R] Survival model error
Message-ID: <18B5F0E2-99EC-4C86-83E2-D338F26C7FA7@yahoo.com>


Hi - Below is my code and then the error when I run the last line. 
 
time_np <- train1_na$tte
event_np <- train1_na$censored
 
 
X_np <- cbind(
  train1_na$AMT, 
  train1_na$DISCOUNT_AMT,
  train1_na$high_price_pcnt,
  train1_na$EM_RECEIVED,
  train1_na$DM_RECEIVED,
  train1_na$TXN_WITH_RINGCODE,
  train1_na$WEB,
  train1_na$clearance_pcnt,
  train1_na$bts_pcnt,
  train1_na$sales_pcnt,
  train1_na$holiday_pcnt,
  train1_na$TXN,
  train1_na$REDEEMED_REWARDS
 
  )
 
# Kaplan-Meier non-parametric analysis 

kmsurvival_np <- survfit(Surv(time_np,event_np) ~ X_np)
 
Error in `[.default`(y, who, 1) : (subscript) logical subscript too long
 
Any ideas?  
I have tried several things and still get this error.  
 

Thanks,
Meghna


From dwinsemius at comcast.net  Mon Nov  6 07:58:20 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 5 Nov 2017 22:58:20 -0800
Subject: [R] Survival model error
In-Reply-To: <18B5F0E2-99EC-4C86-83E2-D338F26C7FA7@yahoo.com>
References: <18B5F0E2-99EC-4C86-83E2-D338F26C7FA7@yahoo.com>
Message-ID: <F527DFDC-99D5-4812-A0D0-1373F0C14542@comcast.net>

You should stop trying to use matrices on the RHS and using separate vectors to Surv. Instead use a data argument and have the names in your formula refer to column names. 

? 
David

Sent from my iPhone

> On Nov 5, 2017, at 7:21 PM, Meghna Govil via R-help <r-help at r-project.org> wrote:
> 
> 
> Hi - Below is my code and then the error when I run the last line. 
> 
> time_np <- train1_na$tte
> event_np <- train1_na$censored
> 
> 
> X_np <- cbind(
>  train1_na$AMT, 
>  train1_na$DISCOUNT_AMT,
>  train1_na$high_price_pcnt,
>  train1_na$EM_RECEIVED,
>  train1_na$DM_RECEIVED,
>  train1_na$TXN_WITH_RINGCODE,
>  train1_na$WEB,
>  train1_na$clearance_pcnt,
>  train1_na$bts_pcnt,
>  train1_na$sales_pcnt,
>  train1_na$holiday_pcnt,
>  train1_na$TXN,
>  train1_na$REDEEMED_REWARDS
> 
>  )
> 
> # Kaplan-Meier non-parametric analysis 
> 
> kmsurvival_np <- survfit(Surv(time_np,event_np) ~ X_np)
> 
> Error in `[.default`(y, who, 1) : (subscript) logical subscript too long
> 
> Any ideas?  
> I have tried several things and still get this error.  
> 
> 
> Thanks,
> Meghna
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Goran.Bergqvist at jagareforbundet.se  Mon Nov  6 07:58:08 2017
From: Goran.Bergqvist at jagareforbundet.se (=?utf-8?B?R8O2cmFuIEJlcmdxdmlzdA==?=)
Date: Mon, 6 Nov 2017 06:58:08 +0000
Subject: [R] Change colour of line in logi.hist.plot
In-Reply-To: <16CFC58D-30DD-4047-B771-A24FB4D57EBC@comcast.net>
References: <9C500214DD8DB547BB8FBD816EB128EB4205C6DC@sjfmail02.hunter.lan>
 <16CFC58D-30DD-4047-B771-A24FB4D57EBC@comcast.net>
Message-ID: <9C500214DD8DB547BB8FBD816EB128EB420633D1@sjfmail02.hunter.lan>

Thank you. This worked fine.

-----Ursprungligt meddelande-----
Fr?n: David Winsemius [mailto:dwinsemius at comcast.net] 
Skickat: den 5 november 2017 18:17
Till: G?ran Bergqvist <Goran.Bergqvist at jagareforbundet.se>
Kopia: r-help at r-project.org
?mne: Re: [R] Change colour of line in logi.hist.plot


> On Nov 5, 2017, at 6:03 AM, G?ran Bergqvist <Goran.Bergqvist at jagareforbundet.se> wrote:
> 
> I am using the function logi.hist.plot in package popbio. I want to change the colour of the probability line from the default red to black. I have not been able to find out how to do that.

If you look at the code for that function you see this line:

logi.curve <- function(independ, depend, mod = logi.mod, 
        col.cur = "red", lwd.cur = 4) {
Since it's the only occurence of "red" that's probably where "the money lies". You can either do a "hard hack" where you alter the value of the parameters to that inner function,

... or you can add a named parameter after the dots in the outer parameter list such as:
   

 function (independ, depend, logi.mod = 1, type = "dit", boxp = TRUE, 
    rug = FALSE, ylabel = "Probability", ylabel2 = "Frequency", 
    xlabel = "", mainlabel = "", las.h = 1, counts = FALSE, ...,  col.cur = "red")

... and modify the inner function to read:

     logi.curve <- function(independ, depend, mod = logi.mod, 
        col.cur = col.cur, lwd.cur = 4) {


> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






From khollam.kamlesh33 at gmail.com  Mon Nov  6 09:23:49 2017
From: khollam.kamlesh33 at gmail.com (Kamlesh Khollam)
Date: Mon, 6 Nov 2017 13:53:49 +0530
Subject: [R] Multiple CSV files in different sheets of an Excel file
Message-ID: <CAKXOaMzGPAZmq6PuiYppycwJFBCNh-Xkv6UUUy+qxoGg1QDfZg@mail.gmail.com>

Hi Team,
I am tried "WriteXLS" package for merging 2 csv files. R script runs
successfully but does not create CSVmerge file.

Appreciate our help.

?Best Regards,
Kamlesh Khollam?

	[[alternative HTML version deleted]]


From megov31 at yahoo.com  Mon Nov  6 14:45:35 2017
From: megov31 at yahoo.com (Meghna Govil)
Date: Mon, 6 Nov 2017 07:45:35 -0600
Subject: [R] Survival model error
In-Reply-To: <F527DFDC-99D5-4812-A0D0-1373F0C14542@comcast.net>
References: <18B5F0E2-99EC-4C86-83E2-D338F26C7FA7@yahoo.com>
 <F527DFDC-99D5-4812-A0D0-1373F0C14542@comcast.net>
Message-ID: <C54F0373-F18C-407F-B421-A78B38C39997@yahoo.com>

Thanks David. Could you show me how to do that in my example ? 

Thanks,
Meghna

> On Nov 6, 2017, at 12:58 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> You should stop trying to use matrices on the RHS and using separate vectors to Surv. Instead use a data argument and have the names in your formula refer to column names. 
> 
> ? 
> David
> 
> Sent from my iPhone
> 
>> On Nov 5, 2017, at 7:21 PM, Meghna Govil via R-help <r-help at r-project.org> wrote:
>> 
>> 
>> Hi - Below is my code and then the error when I run the last line. 
>> 
>> time_np <- train1_na$tte
>> event_np <- train1_na$censored
>> 
>> 
>> X_np <- cbind(
>> train1_na$AMT, 
>> train1_na$DISCOUNT_AMT,
>> train1_na$high_price_pcnt,
>> train1_na$EM_RECEIVED,
>> train1_na$DM_RECEIVED,
>> train1_na$TXN_WITH_RINGCODE,
>> train1_na$WEB,
>> train1_na$clearance_pcnt,
>> train1_na$bts_pcnt,
>> train1_na$sales_pcnt,
>> train1_na$holiday_pcnt,
>> train1_na$TXN,
>> train1_na$REDEEMED_REWARDS
>> 
>> )
>> 
>> # Kaplan-Meier non-parametric analysis 
>> 
>> kmsurvival_np <- survfit(Surv(time_np,event_np) ~ X_np)
>> 
>> Error in `[.default`(y, who, 1) : (subscript) logical subscript too long
>> 
>> Any ideas?  
>> I have tried several things and still get this error.  
>> 
>> 
>> Thanks,
>> Meghna
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From marc_schwartz at me.com  Mon Nov  6 15:47:54 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 06 Nov 2017 09:47:54 -0500
Subject: [R] Multiple CSV files in different sheets of an Excel file
In-Reply-To: <CAKXOaMzGPAZmq6PuiYppycwJFBCNh-Xkv6UUUy+qxoGg1QDfZg@mail.gmail.com>
References: <CAKXOaMzGPAZmq6PuiYppycwJFBCNh-Xkv6UUUy+qxoGg1QDfZg@mail.gmail.com>
Message-ID: <2DADA5E8-F254-4086-9797-C8E8196ACF6F@me.com>



> On Nov 6, 2017, at 3:23 AM, Kamlesh Khollam <khollam.kamlesh33 at gmail.com> wrote:
> 
> Hi Team,
> I am tried "WriteXLS" package for merging 2 csv files. R script runs
> successfully but does not create CSVmerge file.
> 
> Appreciate our help.
> 
> ?Best Regards,
> Kamlesh Khollam?

Hi,

You appear to be replying to a thread from January of 2016, or almost two years ago, based upon the subject line.

You have not provided any information (e.g. the code you used, sample data, any error messages, other relevant information) to allow us to help you.

The WriteXLS package is designed to do one thing, export R data frames to Excel files. 

There is no data management functionality in the package, so if you want to "merge", "stack" or otherwise manipulate R data frames, you need to do that using code outside of the functions contained in the package.

One of the posts from the thread in 2016 is:

  https://stat.ethz.ch/pipermail/r-help/2016-January/435342.html

in which I provided sample code that would enable someone to read in two CSV files to an R list object, and then export those to two worksheets in an Excel file using the WriteXLS package, along with some hints on generalizing the approach to a larger number of CSV files.

Perhaps you should review that, and if that is not what you want to do, post back with more detailed information.

Regards,

Marc Schwartz


From lists at dewey.myzen.co.uk  Mon Nov  6 16:14:04 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 6 Nov 2017 15:14:04 +0000
Subject: [R] Survival model error
In-Reply-To: <C54F0373-F18C-407F-B421-A78B38C39997@yahoo.com>
References: <18B5F0E2-99EC-4C86-83E2-D338F26C7FA7@yahoo.com>
 <F527DFDC-99D5-4812-A0D0-1373F0C14542@comcast.net>
 <C54F0373-F18C-407F-B421-A78B38C39997@yahoo.com>
Message-ID: <781ad219-318d-3321-1014-724226a6c506@dewey.myzen.co.uk>

Try putting your data.frame (train_na) as argument to the data= 
parameter and then in the formula put the actual variable names but 
without the train_na$ prefix.

On 06/11/2017 13:45, Meghna Govil via R-help wrote:
> Thanks David. Could you show me how to do that in my example ?
> 
> Thanks,
> Meghna
> 
>> On Nov 6, 2017, at 12:58 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> You should stop trying to use matrices on the RHS and using separate vectors to Surv. Instead use a data argument and have the names in your formula refer to column names.
>>
>> ?
>> David
>>
>> Sent from my iPhone
>>
>>> On Nov 5, 2017, at 7:21 PM, Meghna Govil via R-help <r-help at r-project.org> wrote:
>>>
>>>
>>> Hi - Below is my code and then the error when I run the last line.
>>>
>>> time_np <- train1_na$tte
>>> event_np <- train1_na$censored
>>>
>>>
>>> X_np <- cbind(
>>> train1_na$AMT,
>>> train1_na$DISCOUNT_AMT,
>>> train1_na$high_price_pcnt,
>>> train1_na$EM_RECEIVED,
>>> train1_na$DM_RECEIVED,
>>> train1_na$TXN_WITH_RINGCODE,
>>> train1_na$WEB,
>>> train1_na$clearance_pcnt,
>>> train1_na$bts_pcnt,
>>> train1_na$sales_pcnt,
>>> train1_na$holiday_pcnt,
>>> train1_na$TXN,
>>> train1_na$REDEEMED_REWARDS
>>>
>>> )
>>>
>>> # Kaplan-Meier non-parametric analysis
>>>
>>> kmsurvival_np <- survfit(Surv(time_np,event_np) ~ X_np)
>>>
>>> Error in `[.default`(y, who, 1) : (subscript) logical subscript too long
>>>
>>> Any ideas?
>>> I have tried several things and still get this error.
>>>
>>>
>>> Thanks,
>>> Meghna
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Mon Nov  6 16:36:00 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 06 Nov 2017 07:36:00 -0800
Subject: [R] Multiple CSV files in different sheets of an Excel file
In-Reply-To: <CAKXOaMzGPAZmq6PuiYppycwJFBCNh-Xkv6UUUy+qxoGg1QDfZg@mail.gmail.com>
References: <CAKXOaMzGPAZmq6PuiYppycwJFBCNh-Xkv6UUUy+qxoGg1QDfZg@mail.gmail.com>
Message-ID: <F944016B-CF71-4C76-AC5C-3C10DC03BDC8@dcn.davis.ca.us>

You need to be more specific about what you mean by "merge" (read e.g. ?merge and ?rbind) and show what you did already using a reproducible example [1][2][3].

The fact that you mentioned sheets suggests you are writing to Excel files... they can be troublesome for storing data (NA values,  size, unstructured layout, you can Google for more reasons) so unless you specifically have a requirement to interface with Excel you might consider CSV, zip, feather, or hdf5.

If you have Java installed, the openxlsx package can be used to write a list of data frames in one statement. If you use lapply with read.csv to read the data in then this could be fairly compact, depending on what you mean by "merge".

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

-- 
Sent from my phone. Please excuse my brevity.

On November 6, 2017 12:23:49 AM PST, Kamlesh Khollam <khollam.kamlesh33 at gmail.com> wrote:
>Hi Team,
>I am tried "WriteXLS" package for merging 2 csv files. R script runs
>successfully but does not create CSVmerge file.
>
>Appreciate our help.
>
>?Best Regards,
>Kamlesh Khollam?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Nov  6 18:06:45 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Nov 2017 09:06:45 -0800
Subject: [R] Survival model error
In-Reply-To: <C54F0373-F18C-407F-B421-A78B38C39997@yahoo.com>
References: <18B5F0E2-99EC-4C86-83E2-D338F26C7FA7@yahoo.com>
 <F527DFDC-99D5-4812-A0D0-1373F0C14542@comcast.net>
 <C54F0373-F18C-407F-B421-A78B38C39997@yahoo.com>
Message-ID: <80BF9DEA-90DA-4212-A789-A9DF13612BC6@comcast.net>


> On Nov 6, 2017, at 5:45 AM, Meghna Govil <megov31 at yahoo.com> wrote:
> 
> Thanks David. Could you show me how to do that in my example ? 

Possibly:

kmsurvival_np <- survfit(Surv( tte, censored) ~ . , data=train1_na)

I say "possibly" because I don't know whether all the columns of `train1_na` were included in the matrix you constructed. If they weren't then you would need to do something like:

kmsurvival_np <- survfit(Surv( tte, censored) ~ <lots of names separated by "+"'s> , data=train1_na)


The formalism of `reg_func( Y , Xm)` Where Xm is a matrix is typical for various machine-learning types of procedures, but breaks the "process-names-in-an-environment model of typical R regression functions. R regression functions often omit "step-down" options so loved by beginning SAS users.


> 
> Thanks,
> Meghna
> 
>> On Nov 6, 2017, at 12:58 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> You should stop trying to use matrices on the RHS and using separate vectors to Surv. Instead use a data argument and have the names in your formula refer to column names. 
>> 
>> ? 
>> David
>> 
>> Sent from my iPhone
>> 
>>> On Nov 5, 2017, at 7:21 PM, Meghna Govil via R-help <r-help at r-project.org> wrote:
>>> 
>>> 
>>> Hi - Below is my code and then the error when I run the last line. 
>>> 
>>> time_np <- train1_na$tte
>>> event_np <- train1_na$censored
>>> 
>>> 
>>> X_np <- cbind(
>>> train1_na$AMT, 
>>> train1_na$DISCOUNT_AMT,
>>> train1_na$high_price_pcnt,
>>> train1_na$EM_RECEIVED,
>>> train1_na$DM_RECEIVED,
>>> train1_na$TXN_WITH_RINGCODE,
>>> train1_na$WEB,
>>> train1_na$clearance_pcnt,
>>> train1_na$bts_pcnt,
>>> train1_na$sales_pcnt,
>>> train1_na$holiday_pcnt,
>>> train1_na$TXN,
>>> train1_na$REDEEMED_REWARDS
>>> 
>>> )
>>> 
>>> # Kaplan-Meier non-parametric analysis 
>>> 
>>> kmsurvival_np <- survfit(Surv(time_np,event_np) ~ X_np)
>>> 
>>> Error in `[.default`(y, who, 1) : (subscript) logical subscript too long
>>> 
>>> Any ideas?  
>>> I have tried several things and still get this error.  
>>> 
>>> 
>>> Thanks,
>>> Meghna
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From milujisb at gmail.com  Mon Nov  6 18:12:06 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Mon, 6 Nov 2017 18:12:06 +0100
Subject: [R] Error in Zero inflated model (ziP) with bam
Message-ID: <CAMLwc7O-XAfc_-GSyX_C=AJBj2hb9x-KNe3CrO=kuEgUJsYy-Q@mail.gmail.com>

Dear all,

I am trying to use 'bam' to run the following generalized additive model:

###
m <- bam(result ~ factor(city) + factor(year) + lnpopulation +
s(lnincome_pc) + ,data=full_df,na.action=na.omit,family=ziP(theta = NULL,
link = "identity",b=0))

But getting the following error:

###
Error in bam(result :
  extended families not supported by bam

The documentation for 'bam' mentions the following "This is a family object
specifying the distribution and link to use in fitting etc. See glm and
family for more details. The extended families listed in family.mgcv can
also be used."

The family.mgcv does include ziP. What am I doing wrong? Any guidance will
be appreciated. Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov  6 18:30:06 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Nov 2017 09:30:06 -0800
Subject: [R] Error in Zero inflated model (ziP) with bam
In-Reply-To: <CAMLwc7O-XAfc_-GSyX_C=AJBj2hb9x-KNe3CrO=kuEgUJsYy-Q@mail.gmail.com>
References: <CAMLwc7O-XAfc_-GSyX_C=AJBj2hb9x-KNe3CrO=kuEgUJsYy-Q@mail.gmail.com>
Message-ID: <CAGxFJbQ=obViwGBXnBc22W7YrBujuJxCi0tub7odMv+VE210kQ@mail.gmail.com>

Do you have the mgcv package installed (I think it's part of the standard
distro, though) /loaded? ziP is there, not in BAM.

Other than that, sorry, no clue.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Nov 6, 2017 at 9:12 AM, Miluji Sb <milujisb at gmail.com> wrote:

> Dear all,
>
> I am trying to use 'bam' to run the following generalized additive model:
>
> ###
> m <- bam(result ~ factor(city) + factor(year) + lnpopulation +
> s(lnincome_pc) + ,data=full_df,na.action=na.omit,family=ziP(theta = NULL,
> link = "identity",b=0))
>
> But getting the following error:
>
> ###
> Error in bam(result :
>   extended families not supported by bam
>
> The documentation for 'bam' mentions the following "This is a family object
> specifying the distribution and link to use in fitting etc. See glm and
> family for more details. The extended families listed in family.mgcv can
> also be used."
>
> The family.mgcv does include ziP. What am I doing wrong? Any guidance will
> be appreciated. Thank you!
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Mon Nov  6 18:40:23 2017
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Mon, 06 Nov 2017 19:40:23 +0200
Subject: [R] For each entry type in column?
Message-ID: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>

How can I do a for loop that does to a data.frame column what:

for x in xs:

does in Python?

Obviously the data.frame column in question holds "levels". What if the 
data.frame is in matrix form?

BR, Matti


From bgunter.4567 at gmail.com  Mon Nov  6 18:55:45 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Nov 2017 09:55:45 -0800
Subject: [R] For each entry type in column?
In-Reply-To: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
Message-ID: <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>

Time to go through a tutorial or two! -- This forum cannot replace such
self study.

Your query evidences some basic confusion, but ?tapply or the equivalent
lapply(split(...)) construct are most likely relevant.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:

> How can I do a for loop that does to a data.frame column what:
>
> for x in xs:
>
> does in Python?
>
> Obviously the data.frame column in question holds "levels". What if the
> data.frame is in matrix form?
>
> BR, Matti
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boneill at epixanalytics.com  Mon Nov  6 16:26:39 2017
From: boneill at epixanalytics.com (Barbara O'Neill)
Date: Mon, 6 Nov 2017 15:26:39 +0000
Subject: [R] QRA with R Course 12-4 to 12-7-17 - Ft. Collins, CO
Message-ID: <DM5PR2001MB18676EED656933A714ED201FA8500@DM5PR2001MB1867.namprd20.prod.outlook.com>

Quantitative Risk Analysis with R
Fort Collins, Colorado, USA
December 4-7, 2017

This course will cover the core principles of quantitative risk analysis and Monte Carlo simulation modeling. The focus of the course is on how to conduct accurate and effective quantitative risk analyses, including best practices of risk modeling, selecting the appropriate distribution, using data and expert opinion, and avoiding common mistakes. Both Bayesian and frequentist methods will be discussed. Prior experience using R or other simulation tools is not required.
For additional information and to register please visit:
http://www.epixanalytics.com/quantitative-risk-analysis-with-r-4-days.html

To register by phone or for any questions please contact:
Barbara O'Neill, boneill at epixanalytics.com<mailto:boneill at epixanalytics.com>
Ph: +1 303 440 8524

EpiX Analytics
www.epixanalytics.com<http://www.epixanalytics.com>




	[[alternative HTML version deleted]]


From monglao at ifc.org  Mon Nov  6 15:02:09 2017
From: monglao at ifc.org (Ma. Regina Paz Saquido Onglao)
Date: Mon, 6 Nov 2017 14:02:09 +0000
Subject: [R] [R-pkgs] New package: data360r to access trade and governance
	open	data
In-Reply-To: <BN6PR01MB2834288B81C99C7FAD720EE4AB500@BN6PR01MB2834.prod.exchangelabs.com>
References: <BN6PR01MB2834288B81C99C7FAD720EE4AB500@BN6PR01MB2834.prod.exchangelabs.com>
Message-ID: <BN6PR01MB2834F5141E5C21865320B7B4AB500@BN6PR01MB2834.prod.exchangelabs.com>

Hi everyone,

We've recently launched data360r, now available on CRAN at https://cran.r-project.org/web/packages/data360r/index.html

This package makes it easy to engage with the APIs of the TCdata360 and Govdata360 open data platforms at https://tcdata360.worldbank.org/ and https://govdata360.worldbank.org/, respectively. These APIs provide access to over 5000 trade, competitiveness, and governance indicator data, metadata, and related information from over 80 sources both inside and outside the World Bank Group. Package functions include easier download of data sets, metadata, and related information, as well as searching based on user-inputted query.

Additional information can be seen at:
+ See how it works through detailed use cases at https://tcdata360.worldbank.org/tools/data360r
+ Read about data360r's benefits in this blog: https://blogs.worldbank.org/opendata/introducing-data360r-data-power-r
+ Check out a cool usecase using data360r and Bob Rudis' streamgraph package: http://blogs.worldbank.org/opendata/interactive-product-export-streamgraphs-data360r-now-cran
+ Code can be seen at my github repo: https://github.com/mrpsonglao/data360r

If you have any questions, feedback, or suggestions, I'd be more than happy to hear these. Feel free to send me an email at monglao at ifc.org.


Cheers,

Ma. Regina Paz S. Onglao

Data Scientist

Trade and Competitiveness (T&C) Global Practice

World Bank Group


E

monglao at ifc.org

W

https://tcdata360.worldbank.org/


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bgunter.4567 at gmail.com  Mon Nov  6 19:00:03 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Nov 2017 10:00:03 -0800
Subject: [R] For each entry type in column?
In-Reply-To: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
Message-ID: <CAGxFJbR-CeFB+XSLu=kUVEvPWPTa-Zq85pXzudDx1eGCsG-hjA@mail.gmail.com>

Prrobably also worth mentioning for this sort of thing is the "tidyverse"
machinery, for which the RStudio site should probably be your first port of
call. This will however require learning alternative, and probably
additional, paradigms.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:

> How can I do a for loop that does to a data.frame column what:
>
> for x in xs:
>
> does in Python?
>
> Obviously the data.frame column in question holds "levels". What if the
> data.frame is in matrix form?
>
> BR, Matti
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Mon Nov  6 20:13:47 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Mon, 6 Nov 2017 20:13:47 +0100
Subject: [R] Error in Zero inflated model (ziP) with bam
In-Reply-To: <CAGxFJbQ=obViwGBXnBc22W7YrBujuJxCi0tub7odMv+VE210kQ@mail.gmail.com>
References: <CAMLwc7O-XAfc_-GSyX_C=AJBj2hb9x-KNe3CrO=kuEgUJsYy-Q@mail.gmail.com>
 <CAGxFJbQ=obViwGBXnBc22W7YrBujuJxCi0tub7odMv+VE210kQ@mail.gmail.com>
Message-ID: <CAMLwc7PzkgDvi3VvFWbtHjGvdtjUf1anayt6uzin_eGZafbbwQ@mail.gmail.com>

Thanks for your reply. Yes, installed (reinstalled) and loaded. I am a bit
baffled...

Sincerely,

Milu

On Mon, Nov 6, 2017 at 6:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Do you have the mgcv package installed (I think it's part of the standard
> distro, though) /loaded? ziP is there, not in BAM.
>
> Other than that, sorry, no clue.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Nov 6, 2017 at 9:12 AM, Miluji Sb <milujisb at gmail.com> wrote:
>
>> Dear all,
>>
>> I am trying to use 'bam' to run the following generalized additive model:
>>
>> ###
>> m <- bam(result ~ factor(city) + factor(year) + lnpopulation +
>> s(lnincome_pc) + ,data=full_df,na.action=na.omit,family=ziP(theta = NULL,
>> link = "identity",b=0))
>>
>> But getting the following error:
>>
>> ###
>> Error in bam(result :
>>   extended families not supported by bam
>>
>> The documentation for 'bam' mentions the following "This is a family
>> object
>> specifying the distribution and link to use in fitting etc. See glm and
>> family for more details. The extended families listed in family.mgcv can
>> also be used."
>>
>> The family.mgcv does include ziP. What am I doing wrong? Any guidance will
>> be appreciated. Thank you!
>>
>> Sincerely,
>>
>> Milu
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Mon Nov  6 20:26:24 2017
From: mviljamaa at kapsi.fi (Matti Viljamaa)
Date: Mon, 6 Nov 2017 21:26:24 +0200
Subject: [R] For each entry type in column?
In-Reply-To: <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
Message-ID: <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>

It?s sometimes faster to ask from someone who has already learnt the syntax.
In this case one has to do e.g.

names(data$somecol)

To get the collection and then iteration through it is almost like in Python:

for(i in names(data$somecol)) {
   # do something
}

> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
> 
> Time to go through a tutorial or two! -- This forum cannot replace such self study.
> 
> Your query evidences some basic confusion, but ?tapply or the equivalent lapply(split(...)) construct are most likely relevant.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi <mailto:mviljamaa at kapsi.fi>> wrote:
> How can I do a for loop that does to a data.frame column what:
> 
> for x in xs:
> 
> does in Python?
> 
> Obviously the data.frame column in question holds "levels". What if the data.frame is in matrix form?
> 
> BR, Matti
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov  6 20:36:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Nov 2017 11:36:29 -0800
Subject: [R] For each entry type in column?
In-Reply-To: <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
 <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>
Message-ID: <CAGxFJbSzgWqU2ivCfAKvpVh+L-XNptCBK7fvmovviZQYLNzB9w@mail.gmail.com>

Except that syntax is wrong:

> d <- data.frame (a = 1:3, b = letters[1:3])
> names(d$a)
NULL


-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Nov 6, 2017 at 11:26 AM, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:

> It?s sometimes faster to ask from someone who has already learnt the
> syntax.
> In this case one has to do e.g.
>
> names(data$somecol)
>
> To get the collection and then iteration through it is almost like in
> Python:
>
> for(i in names(data$somecol)) {
>    # do something
> }
>
> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
>
> Time to go through a tutorial or two! -- This forum cannot replace such
> self study.
>
> Your query evidences some basic confusion, but ?tapply or the equivalent
> lapply(split(...)) construct are most likely relevant.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
>
>> How can I do a for loop that does to a data.frame column what:
>>
>> for x in xs:
>>
>> does in Python?
>>
>> Obviously the data.frame column in question holds "levels". What if the
>> data.frame is in matrix form?
>>
>> BR, Matti
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Nov  6 20:37:00 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 06 Nov 2017 11:37:00 -0800
Subject: [R] For each entry type in column?
In-Reply-To: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
Message-ID: <7CB718E7-05B9-434A-AC2B-9F8CEA4A1AAD@dcn.davis.ca.us>

All data frames "look like" matrices, but none of them "are" matrices. I think we need you to follow the Posting Guide and supply an R reproducible example that gives us a concrete idea what the data structure is that you are working with, and an example of what you expect to get out of the code you want us to show you.  The dput function can be a lifesaver in helping you provide R code that can reproduce in our R sessions the data you have in front of you. Read more in [1][2] and [3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On November 6, 2017 9:40:23 AM PST, mviljamaa <mviljamaa at kapsi.fi> wrote:
>How can I do a for loop that does to a data.frame column what:
>
>for x in xs:
>
>does in Python?
>
>Obviously the data.frame column in question holds "levels". What if the
>
>data.frame is in matrix form?
>
>BR, Matti
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Nov  6 20:43:01 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 06 Nov 2017 11:43:01 -0800
Subject: [R] For each entry type in column?
In-Reply-To: <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
 <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>
Message-ID: <E919B3AD-6D84-489D-8C7E-5F40206E03A1@dcn.davis.ca.us>

Maybe you are thinking of the levels function rather than the names function? Which still presumes the column is a factor column, when it might actually be a character column (in which case you might use the unique function). Again, a reproducible example would stop the guessing. 
-- 
Sent from my phone. Please excuse my brevity.

On November 6, 2017 11:26:24 AM PST, Matti Viljamaa <mviljamaa at kapsi.fi> wrote:
>It?s sometimes faster to ask from someone who has already learnt the
>syntax.
>In this case one has to do e.g.
>
>names(data$somecol)
>
>To get the collection and then iteration through it is almost like in
>Python:
>
>for(i in names(data$somecol)) {
>   # do something
>}
>
>> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
>> 
>> Time to go through a tutorial or two! -- This forum cannot replace
>such self study.
>> 
>> Your query evidences some basic confusion, but ?tapply or the
>equivalent lapply(split(...)) construct are most likely relevant.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming
>along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi
><mailto:mviljamaa at kapsi.fi>> wrote:
>> How can I do a for loop that does to a data.frame column what:
>> 
>> for x in xs:
>> 
>> does in Python?
>> 
>> Obviously the data.frame column in question holds "levels". What if
>the data.frame is in matrix form?
>> 
>> BR, Matti
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
><http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Nov  6 20:49:27 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 06 Nov 2017 19:49:27 +0000
Subject: [R] For each entry type in column?
In-Reply-To: <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
 <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi>
Message-ID: <5A00BCC7.8020908@sapo.pt>

Hello,

If you want to loop through the columns of a data.frame you can do

for(i in names(df)){
     [code]
}

Another way would be

lapply(names(df), function(somecol) class(df[[somecol]]))

where class(df[[somecol]]) is just an example, you would use whatever 
fits your needs.

When you say that the column in question holds "levels" do you mean it's 
a factor? (factors are R's categorical variables.)

Hope this helps,

Rui Barradas


Em 06-11-2017 19:26, Matti Viljamaa escreveu:
> It?s sometimes faster to ask from someone who has already learnt the syntax.
> In this case one has to do e.g.
>
> names(data$somecol)
>
> To get the collection and then iteration through it is almost like in Python:
>
> for(i in names(data$somecol)) {
>     # do something
> }
>
>> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
>>
>> Time to go through a tutorial or two! -- This forum cannot replace such self study.
>>
>> Your query evidences some basic confusion, but ?tapply or the equivalent lapply(split(...)) construct are most likely relevant.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi <mailto:mviljamaa at kapsi.fi>> wrote:
>> How can I do a for loop that does to a data.frame column what:
>>
>> for x in xs:
>>
>> does in Python?
>>
>> Obviously the data.frame column in question holds "levels". What if the data.frame is in matrix form?
>>
>> BR, Matti
>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Tue Nov  7 00:28:39 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 6 Nov 2017 18:28:39 -0500
Subject: [R] For each entry type in column?
In-Reply-To: <5A00BCC7.8020908@sapo.pt>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
 <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi> <5A00BCC7.8020908@sapo.pt>
Message-ID: <16AD8048-C02A-4897-ACE8-1EB40A1AB4D6@utoronto.ca>

Matti -

Since you are asking about looping through a column, not looping across columns, it is simply the following:


# Note: data.frame() turns strings into factors by default.
myDF <- data.frame(type = c("a", "j", "a", "a", "j"),
                   weight = c(12.3, 6.8, 10.5, NA, "5.5"))

myDF$type  # ... is a vector of factors

for(type in myDF$type) {
  print(type)
}

# or (less explicit in the code and will break if the order of columns
# ever changes):
for(type in myDF[ , 1]) {
  print(type)
}

# In a matrix, all elemnts have to be of the same type. Let's make a
# matrix of characters: 

myMat <- matrix(cbind(as.character(myDF$type),
                      c("red", "green", "red", "red", "green")),
                ncol = 2)

for(type in myMat[ , 1]) {
  print(type)
}

As others have remarked, for added efficiency with large datasets we often use functions from the apply() family, rather than for-loops.


I hope this helps,
Boris

PS: don't call your data frames "df" since df() is a function and this may make your code hard to read.



> On Nov 6, 2017, at 2:49 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> If you want to loop through the columns of a data.frame you can do
> 
> for(i in names(df)){
>    [code]
> }
> 
> Another way would be
> 
> lapply(names(df), function(somecol) class(df[[somecol]]))
> 
> where class(df[[somecol]]) is just an example, you would use whatever fits your needs.
> 
> When you say that the column in question holds "levels" do you mean it's a factor? (factors are R's categorical variables.)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> Em 06-11-2017 19:26, Matti Viljamaa escreveu:
>> It?s sometimes faster to ask from someone who has already learnt the syntax.
>> In this case one has to do e.g.
>> 
>> names(data$somecol)
>> 
>> To get the collection and then iteration through it is almost like in Python:
>> 
>> for(i in names(data$somecol)) {
>>    # do something
>> }
>> 
>>> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
>>> 
>>> Time to go through a tutorial or two! -- This forum cannot replace such self study.
>>> 
>>> Your query evidences some basic confusion, but ?tapply or the equivalent lapply(split(...)) construct are most likely relevant.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi <mailto:mviljamaa at kapsi.fi>> wrote:
>>> How can I do a for loop that does to a data.frame column what:
>>> 
>>> for x in xs:
>>> 
>>> does in Python?
>>> 
>>> Obviously the data.frame column in question holds "levels". What if the data.frame is in matrix form?
>>> 
>>> BR, Matti
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Nov  7 00:47:40 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Nov 2017 15:47:40 -0800
Subject: [R] For each entry type in column?
In-Reply-To: <16AD8048-C02A-4897-ACE8-1EB40A1AB4D6@utoronto.ca>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
 <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi> <5A00BCC7.8020908@sapo.pt>
 <16AD8048-C02A-4897-ACE8-1EB40A1AB4D6@utoronto.ca>
Message-ID: <CAGxFJbRTQr4+fm5448ytZMpdBGUx2i0S65oK2J8VN2WW0fHBWQ@mail.gmail.com>

Boris:

"As others have remarked, for added efficiency with large datasets we often
use functions from the apply() family, rather than for-loops."

That is generally false, though it is a common misconception. Apply-type
functions are used to maintain fidelity -- and for some, clarity -- to a
functional programming paradigm.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Nov 6, 2017 at 3:28 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Matti -
>
> Since you are asking about looping through a column, not looping across
> columns, it is simply the following:
>
>
> # Note: data.frame() turns strings into factors by default.
> myDF <- data.frame(type = c("a", "j", "a", "a", "j"),
>                    weight = c(12.3, 6.8, 10.5, NA, "5.5"))
>
> myDF$type  # ... is a vector of factors
>
> for(type in myDF$type) {
>   print(type)
> }
>
> # or (less explicit in the code and will break if the order of columns
> # ever changes):
> for(type in myDF[ , 1]) {
>   print(type)
> }
>
> # In a matrix, all elemnts have to be of the same type. Let's make a
> # matrix of characters:
>
> myMat <- matrix(cbind(as.character(myDF$type),
>                       c("red", "green", "red", "red", "green")),
>                 ncol = 2)
>
> for(type in myMat[ , 1]) {
>   print(type)
> }
>
> As others have remarked, for added efficiency with large datasets we often
> use functions from the apply() family, rather than for-loops.
>
>
> I hope this helps,
> Boris
>
> PS: don't call your data frames "df" since df() is a function and this may
> make your code hard to read.
>
>
>
> > On Nov 6, 2017, at 2:49 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > If you want to loop through the columns of a data.frame you can do
> >
> > for(i in names(df)){
> >    [code]
> > }
> >
> > Another way would be
> >
> > lapply(names(df), function(somecol) class(df[[somecol]]))
> >
> > where class(df[[somecol]]) is just an example, you would use whatever
> fits your needs.
> >
> > When you say that the column in question holds "levels" do you mean it's
> a factor? (factors are R's categorical variables.)
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > Em 06-11-2017 19:26, Matti Viljamaa escreveu:
> >> It?s sometimes faster to ask from someone who has already learnt the
> syntax.
> >> In this case one has to do e.g.
> >>
> >> names(data$somecol)
> >>
> >> To get the collection and then iteration through it is almost like in
> Python:
> >>
> >> for(i in names(data$somecol)) {
> >>    # do something
> >> }
> >>
> >>> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
> >>>
> >>> Time to go through a tutorial or two! -- This forum cannot replace
> such self study.
> >>>
> >>> Your query evidences some basic confusion, but ?tapply or the
> equivalent lapply(split(...)) construct are most likely relevant.
> >>>
> >>> Cheers,
> >>> Bert
> >>>
> >>>
> >>>
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi <mailto:
> mviljamaa at kapsi.fi>> wrote:
> >>> How can I do a for loop that does to a data.frame column what:
> >>>
> >>> for x in xs:
> >>>
> >>> does in Python?
> >>>
> >>> Obviously the data.frame column in question holds "levels". What if
> the data.frame is in matrix form?
> >>>
> >>> BR, Matti
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> >>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue Nov  7 00:50:43 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 6 Nov 2017 18:50:43 -0500
Subject: [R] For each entry type in column?
In-Reply-To: <CAGxFJbRTQr4+fm5448ytZMpdBGUx2i0S65oK2J8VN2WW0fHBWQ@mail.gmail.com>
References: <911a1a6054b8b2d3ab860c5c59c36e14@kapsi.fi>
 <CAGxFJbR0iLJOXmarrhuzfK-zjxLMuMMiWWgAKOLauo1YtYfMsQ@mail.gmail.com>
 <507B1725-758E-44C8-A784-276A88BA3181@kapsi.fi> <5A00BCC7.8020908@sapo.pt>
 <16AD8048-C02A-4897-ACE8-1EB40A1AB4D6@utoronto.ca>
 <CAGxFJbRTQr4+fm5448ytZMpdBGUx2i0S65oK2J8VN2WW0fHBWQ@mail.gmail.com>
Message-ID: <085EC4A9-84E9-4BBB-AFAB-6ADFF9A87466@utoronto.ca>

You are right.





> On Nov 6, 2017, at 6:47 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Boris:
> 
> "As others have remarked, for added efficiency with large datasets we often use functions from the apply() family, rather than for-loops."
> 
> That is generally false, though it is a common misconception. Apply-type functions are used to maintain fidelity -- and for some, clarity -- to a functional programming paradigm.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Nov 6, 2017 at 3:28 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Matti -
> 
> Since you are asking about looping through a column, not looping across columns, it is simply the following:
> 
> 
> # Note: data.frame() turns strings into factors by default.
> myDF <- data.frame(type = c("a", "j", "a", "a", "j"),
>                    weight = c(12.3, 6.8, 10.5, NA, "5.5"))
> 
> myDF$type  # ... is a vector of factors
> 
> for(type in myDF$type) {
>   print(type)
> }
> 
> # or (less explicit in the code and will break if the order of columns
> # ever changes):
> for(type in myDF[ , 1]) {
>   print(type)
> }
> 
> # In a matrix, all elemnts have to be of the same type. Let's make a
> # matrix of characters:
> 
> myMat <- matrix(cbind(as.character(myDF$type),
>                       c("red", "green", "red", "red", "green")),
>                 ncol = 2)
> 
> for(type in myMat[ , 1]) {
>   print(type)
> }
> 
> As others have remarked, for added efficiency with large datasets we often use functions from the apply() family, rather than for-loops.
> 
> 
> I hope this helps,
> Boris
> 
> PS: don't call your data frames "df" since df() is a function and this may make your code hard to read.
> 
> 
> 
> > On Nov 6, 2017, at 2:49 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > If you want to loop through the columns of a data.frame you can do
> >
> > for(i in names(df)){
> >    [code]
> > }
> >
> > Another way would be
> >
> > lapply(names(df), function(somecol) class(df[[somecol]]))
> >
> > where class(df[[somecol]]) is just an example, you would use whatever fits your needs.
> >
> > When you say that the column in question holds "levels" do you mean it's a factor? (factors are R's categorical variables.)
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > Em 06-11-2017 19:26, Matti Viljamaa escreveu:
> >> It?s sometimes faster to ask from someone who has already learnt the syntax.
> >> In this case one has to do e.g.
> >>
> >> names(data$somecol)
> >>
> >> To get the collection and then iteration through it is almost like in Python:
> >>
> >> for(i in names(data$somecol)) {
> >>    # do something
> >> }
> >>
> >>> Bert Gunter <bgunter.4567 at gmail.com> kirjoitti 6.11.2017 kello 19.55:
> >>>
> >>> Time to go through a tutorial or two! -- This forum cannot replace such self study.
> >>>
> >>> Your query evidences some basic confusion, but ?tapply or the equivalent lapply(split(...)) construct are most likely relevant.
> >>>
> >>> Cheers,
> >>> Bert
> >>>
> >>>
> >>>
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>> On Mon, Nov 6, 2017 at 9:40 AM, mviljamaa <mviljamaa at kapsi.fi <mailto:mviljamaa at kapsi.fi>> wrote:
> >>> How can I do a for loop that does to a data.frame column what:
> >>>
> >>> for x in xs:
> >>>
> >>> does in Python?
> >>>
> >>> Obviously the data.frame column in question holds "levels". What if the data.frame is in matrix form?
> >>>
> >>> BR, Matti
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From karlhugoandre at gmail.com  Tue Nov  7 06:02:02 2017
From: karlhugoandre at gmail.com (=?UTF-8?Q?Hugo_Andr=C3=A9?=)
Date: Tue, 7 Nov 2017 00:02:02 -0500
Subject: [R] Using MLE on a somewhat unusual likelihood function
Message-ID: <CAGRKcvQ4x2n4c7y0DZ-q4hh+ysVVJt8zZMd4V8tKgg6eO_VO=w@mail.gmail.com>

So I am trying to use the mle command (from stats4 package) to estimate a
number of parameters using data but it keeps throwing up this error message:

Error in solve.default(oout$hessian) :
  Lapack routine dgesv: system is exactly singular: U[1,1] = 0

This error sometimes indicates that the list of starting values is too far
from optimum but this is unlikely since I picked values close to where the
parameters usually end up. I have also tried switching these around a bit.

Here is the code:

  xhat = c(statemw-(1-alpha)*rval)
  survivalf <- function(x) {(1-plnorm(statemw,mean=mu,sd=logalpha))}

wagefn <- function(lam, eta, alpha, xhat, mu, logalpha)  {
  n=nrow(cpsdata2)
  wagevec = matrix(nrow=n,ncol=1)
    for (i in 1:n) {

    if (cpsdata2[i,2] > 0){
     wagevec[i,] <-
c(eta*lam*survivalf(statemw)*exp(-lam*survivalf(statemw)*cpsdata2[i,2,]))
    } else if (cpsdata2[i,1,]==statemw) {
      wagevec[i,] <-
c(lam*(survivalf(statemw)-survivalf((statemw-(1-alpha)*xhat)/alpha))/(eta+lam*survivalf(statemw)))
    } else if (cpsdata2[i,1,]>statemw) {
      wagevec[i,] <-
c(lam*plnorm((cpsdata2[i,1,]-(1-alpha)*xhat)/alpha,mean=mu,sd=logalpha)/(alpha*(eta+lam*survivalf(statemw))))
    }
      else {
       wagevec[i,] <- NA
      }
    }
  lnwagevec <- log(wagevec)
  -sum(lnwagevec>-200 & ln2wagevec<200, na.rm=TRUE)
}

fit <- mle(wagefn, start=listmat, method= "L-BFGS-B",lower=
c(-Inf,0),upper=c(Inf,Inf)


I know the likelihood function is a handful but it does return a reasonable
looking vector of values. The "lnwagevec>-200" etc is an inelegant way of
preventing values of Inf and -Inf from entering the sum, the actual values
rarely go as high as 8 or low as -5.

Thank you in advance to anyone responding!
/Hugo

	[[alternative HTML version deleted]]


From karagullemre at gmail.com  Tue Nov  7 08:46:01 2017
From: karagullemre at gmail.com (=?utf-8?Q?Emre_Karag=C3=BClle?=)
Date: Tue, 7 Nov 2017 10:46:01 +0300
Subject: [R] FW: Time Series
In-Reply-To: <5a005421.87d8500a.6d75c.d9c3@mx.google.com>
References: <5a005421.87d8500a.6d75c.d9c3@mx.google.com>
Message-ID: <5a0164b6.ec9e500a.abe7f.338e@mx.google.com>


Hi,
I would like to ask a question about time series.
I am trying to convert my data into time series data.
I have hourly data from ?2015-12-18 00:00? to ?2017-10-24 23:00?
I am trying the following codes but they are not working.
Could you help me out?

tseri <- ts(data ,seq(from=as.POSIXct("2015-12-18 00:00:00"), to=as.POSIXct("2017-10-24 23:00:00"), by="hour"))

tseri <- ts(data ,seq(from=as.Date("2015-12-18 00:00:00"), to=as.Date("2017-10-24 23:00:00"), by="hour"))


Thank you 

--
Emre



	[[alternative HTML version deleted]]


From khollam.kamlesh33 at gmail.com  Tue Nov  7 08:50:00 2017
From: khollam.kamlesh33 at gmail.com (Kamlesh Khollam)
Date: Tue, 7 Nov 2017 13:20:00 +0530
Subject: [R] Multiple CSV files in different sheets of an Excel file
In-Reply-To: <2DADA5E8-F254-4086-9797-C8E8196ACF6F@me.com>
References: <CAKXOaMzGPAZmq6PuiYppycwJFBCNh-Xkv6UUUy+qxoGg1QDfZg@mail.gmail.com>
 <2DADA5E8-F254-4086-9797-C8E8196ACF6F@me.com>
Message-ID: <CAKXOaMxh1NhQd-VLqmsww_ou=ukmxgbdnNDWPsY1y9j5hp-hbw@mail.gmail.com>

Hi Marc and Team,
Apology for the late reply.

I went through the github code for WriteXLS and accordingly passed required
arguments. Its working fine now. I am able to create a excel workbook with
multiple csv's. By Merge I mean create a excel workbook by adding multiple
csv's as different sheets in it.

Thank you again for your help and your time.

On Mon, Nov 6, 2017 at 8:17 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

>
>
> > On Nov 6, 2017, at 3:23 AM, Kamlesh Khollam <khollam.kamlesh33 at gmail.com>
> wrote:
> >
> > Hi Team,
> > I am tried "WriteXLS" package for merging 2 csv files. R script runs
> > successfully but does not create CSVmerge file.
> >
> > Appreciate our help.
> >
> > ?Best Regards,
> > Kamlesh Khollam?
>
> Hi,
>
> You appear to be replying to a thread from January of 2016, or almost two
> years ago, based upon the subject line.
>
> You have not provided any information (e.g. the code you used, sample
> data, any error messages, other relevant information) to allow us to help
> you.
>
> The WriteXLS package is designed to do one thing, export R data frames to
> Excel files.
>
> There is no data management functionality in the package, so if you want
> to "merge", "stack" or otherwise manipulate R data frames, you need to do
> that using code outside of the functions contained in the package.
>
> One of the posts from the thread in 2016 is:
>
>   https://stat.ethz.ch/pipermail/r-help/2016-January/435342.html
>
> in which I provided sample code that would enable someone to read in two
> CSV files to an R list object, and then export those to two worksheets in
> an Excel file using the WriteXLS package, along with some hints on
> generalizing the approach to a larger number of CSV files.
>
> Perhaps you should review that, and if that is not what you want to do,
> post back with more detailed information.
>
> Regards,
>
> Marc Schwartz
>
>


-- 
Best Regards,
Kamlesh Khollam
Contact No: +91 7798424144

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Tue Nov  7 08:59:09 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 7 Nov 2017 01:59:09 -0600
Subject: [R] FW: Time Series
In-Reply-To: <5a0164b6.ec9e500a.abe7f.338e@mx.google.com>
References: <5a005421.87d8500a.6d75c.d9c3@mx.google.com>
 <5a0164b6.ec9e500a.abe7f.338e@mx.google.com>
Message-ID: <CACxE24nL+2d76sU3ttQ+MKOuOU2pKDx4p4=zHTe41hcd-i1JmA@mail.gmail.com>

Hello!

What is the error message, please?

At first glance, you are using the "ts" function.  That doesn't work for
hourly frequency.

You may want to create a zoo object.

This is Round One.

Sincerely,
Erin


On Tue, Nov 7, 2017 at 1:46 AM, Emre Karag?lle <karagullemre at gmail.com>
wrote:

>
> Hi,
> I would like to ask a question about time series.
> I am trying to convert my data into time series data.
> I have hourly data from ?2015-12-18 00:00? to ?2017-10-24 23:00?
> I am trying the following codes but they are not working.
> Could you help me out?
>
> tseri <- ts(data ,seq(from=as.POSIXct("2015-12-18 00:00:00"),
> to=as.POSIXct("2017-10-24 23:00:00"), by="hour"))
>
> tseri <- ts(data ,seq(from=as.Date("2015-12-18 00:00:00"),
> to=as.Date("2017-10-24 23:00:00"), by="hour"))
>
>
> Thank you
>
> --
> Emre
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Nov  7 09:08:02 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 7 Nov 2017 10:08:02 +0200
Subject: [R] FW: Time Series
In-Reply-To: <CACxE24nL+2d76sU3ttQ+MKOuOU2pKDx4p4=zHTe41hcd-i1JmA@mail.gmail.com>
References: <5a005421.87d8500a.6d75c.d9c3@mx.google.com>
 <5a0164b6.ec9e500a.abe7f.338e@mx.google.com>
 <CACxE24nL+2d76sU3ttQ+MKOuOU2pKDx4p4=zHTe41hcd-i1JmA@mail.gmail.com>
Message-ID: <CAGgJW76xh+SKeOZq_GLPp+gx=Rm9RB_-CKo=1NnbmAtsSHHghQ@mail.gmail.com>

Following Erin's pointer:

library(zoo)
times     <- seq(from=as.POSIXct("2015-12-18 00:00:00"),
to=as.POSIXct("2017-10-24 23:00:00"), by="hour")
mydata <- rnorm(length(times))
tseri      <- zoo( x=mydata, order.by=times )

HTH,
Eric


On Tue, Nov 7, 2017 at 9:59 AM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello!
>
> What is the error message, please?
>
> At first glance, you are using the "ts" function.  That doesn't work for
> hourly frequency.
>
> You may want to create a zoo object.
>
> This is Round One.
>
> Sincerely,
> Erin
>
>
> On Tue, Nov 7, 2017 at 1:46 AM, Emre Karag?lle <karagullemre at gmail.com>
> wrote:
>
> >
> > Hi,
> > I would like to ask a question about time series.
> > I am trying to convert my data into time series data.
> > I have hourly data from ?2015-12-18 00:00? to ?2017-10-24 23:00?
> > I am trying the following codes but they are not working.
> > Could you help me out?
> >
> > tseri <- ts(data ,seq(from=as.POSIXct("2015-12-18 00:00:00"),
> > to=as.POSIXct("2017-10-24 23:00:00"), by="hour"))
> >
> > tseri <- ts(data ,seq(from=as.Date("2015-12-18 00:00:00"),
> > to=as.Date("2017-10-24 23:00:00"), by="hour"))
> >
> >
> > Thank you
> >
> > --
> > Emre
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Nov  7 10:53:45 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 7 Nov 2017 11:53:45 +0200
Subject: [R] Fwd:  FW: Time Series
In-Reply-To: <5a017a10.878e500a.f957f.487a@mx.google.com>
References: <5a005421.87d8500a.6d75c.d9c3@mx.google.com>
 <5a0164b6.ec9e500a.abe7f.338e@mx.google.com>
 <CACxE24nL+2d76sU3ttQ+MKOuOU2pKDx4p4=zHTe41hcd-i1JmA@mail.gmail.com>
 <CAGgJW76xh+SKeOZq_GLPp+gx=Rm9RB_-CKo=1NnbmAtsSHHghQ@mail.gmail.com>
 <5a017a10.878e500a.f957f.487a@mx.google.com>
Message-ID: <CAGgJW74OP+SpG9QE-DmTigujU2wmAJZZ7cfRqCjQfxCMeiAn7w@mail.gmail.com>

[Please send replies to r-help, not individual  responders]
Emre,
In R, when you call a function defined via something like
f <- function( foo, bar )
then you can call it as, for, example

a <- f(x,y)

or

a <- f(foo=x, bar=y)

or even

a <- f( bar=y, foo=x)   # notice I switched the order!

The first approach requires you to pass the arguments in the same order as
the function is expecting.
In the second and third examples you can pass the arguments in any order
you want since you have indicated the variable names.
The point is that the variable name goes on the left of the '=' and the
values (or variables) you are passing go on the right of the '='.

The zoo function is defined as
zoo( x = NULL, order.by = index(x), etc ... )

In my example code I passed the variable 'mydata' to the parameter 'x' via

zoo(x=mydata, order.by=times)

If you called your local variable x then you can call zoo via

zoo(x=x, order.by=whatever)  # using the 'named parameters' approach

or

zoo(x, order.by=whatever)   # where zoo will match the first argument to
the first parameter in its definition.

Hopefully this will help you understand why some of your attempts worked
and some did not work.

Regards,
Eric



Hi Erin and Eric

As both of you suggested I followed the Erin?s command

It  is failed with the following command

when I wrote x , which is numeric vector. I says that unused argument.

tseri      <- zoo( x=mydata, order.by=times )



when use  it without x=mydata like,

tseri      <- zoo( x, order.by=times )



it works.

I checked it by following command

x[times==as.POSIXct("2015-12-18 02:00:00")] and it gave me the true value.



Do you think it is okay?



By the way, I appreciate for fast reply.

Thank you.



--
Emre



*From: *Eric Berger <ericjberger at gmail.com>
*Sent: *Tuesday, November 7, 2017 11:08 AM
*To: *Erin Hodgess <erinm.hodgess at gmail.com>
*Cc: *Emre Karag?lle <karagullemre at gmail.com>; r-help at r-project.org
*Subject: *Re: [R] FW: Time Series



Following Erin's pointer:



library(zoo)
times     <- seq(from=as.POSIXct("2015-12-18 00:00:00"),
to=as.POSIXct("2017-10-24 23:00:00"), by="hour")
mydata <- rnorm(length(times))
tseri      <- zoo( x=mydata, order.by=times )



HTH,

Eric





On Tue, Nov 7, 2017 at 9:59 AM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

Hello!

What is the error message, please?

At first glance, you are using the "ts" function.  That doesn't work for
hourly frequency.

You may want to create a zoo object.

This is Round One.

Sincerely,
Erin


On Tue, Nov 7, 2017 at 1:46 AM, Emre Karag?lle <karagullemre at gmail.com>
wrote:


>
> Hi,
> I would like to ask a question about time series.
> I am trying to convert my data into time series data.
> I have hourly data from ?2015-12-18 00:00? to ?2017-10-24 23:00?
> I am trying the following codes but they are not working.
> Could you help me out?
>
> tseri <- ts(data ,seq(from=as.POSIXct("2015-12-18 00:00:00"),
> to=as.POSIXct("2017-10-24 23:00:00"), by="hour"))
>
> tseri <- ts(data ,seq(from=as.Date("2015-12-18 00:00:00"),
> to=as.Date("2017-10-24 23:00:00"), by="hour"))
>
>
> Thank you
>
> --
> Emre
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Nov  7 11:38:50 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 7 Nov 2017 11:38:50 +0100
Subject: [R] Using MLE on a somewhat unusual likelihood function
In-Reply-To: <CAGRKcvQ4x2n4c7y0DZ-q4hh+ysVVJt8zZMd4V8tKgg6eO_VO=w@mail.gmail.com>
References: <CAGRKcvQ4x2n4c7y0DZ-q4hh+ysVVJt8zZMd4V8tKgg6eO_VO=w@mail.gmail.com>
Message-ID: <E2E7FD42-37C2-4DDB-B208-A16144C6F5E6@gmail.com>

(inline)
> On 7 Nov 2017, at 06:02 , Hugo Andr? <karlhugoandre at gmail.com> wrote:
> 
> So I am trying to use the mle command (from stats4 package) to estimate a
> number of parameters using data but it keeps throwing up this error message:
> 
> Error in solve.default(oout$hessian) :
>  Lapack routine dgesv: system is exactly singular: U[1,1] = 0
> 
> This error sometimes indicates that the list of starting values is too far
> from optimum but this is unlikely since I picked values close to where the
> parameters usually end up. I have also tried switching these around a bit.
> 
> Here is the code:
> 
>  xhat = c(statemw-(1-alpha)*rval)
>  survivalf <- function(x) {(1-plnorm(statemw,mean=mu,sd=logalpha))}
> 
> wagefn <- function(lam, eta, alpha, xhat, mu, logalpha)  {
>  n=nrow(cpsdata2)
>  wagevec = matrix(nrow=n,ncol=1)
>    for (i in 1:n) {
> 
>    if (cpsdata2[i,2] > 0){
>     wagevec[i,] <-
> c(eta*lam*survivalf(statemw)*exp(-lam*survivalf(statemw)*cpsdata2[i,2,]))
>    } else if (cpsdata2[i,1,]==statemw) {
>      wagevec[i,] <-
> c(lam*(survivalf(statemw)-survivalf((statemw-(1-alpha)*xhat)/alpha))/(eta+lam*survivalf(statemw)))
>    } else if (cpsdata2[i,1,]>statemw) {
>      wagevec[i,] <-
> c(lam*plnorm((cpsdata2[i,1,]-(1-alpha)*xhat)/alpha,mean=mu,sd=logalpha)/(alpha*(eta+lam*survivalf(statemw))))
>    }
>      else {
>       wagevec[i,] <- NA
>      }
>    }
>  lnwagevec <- log(wagevec)
>  -sum(lnwagevec>-200 & ln2wagevec<200, na.rm=TRUE)
> }
> 
> fit <- mle(wagefn, start=listmat, method= "L-BFGS-B",lower=
> c(-Inf,0),upper=c(Inf,Inf)
> 
> 
> I know the likelihood function is a handful but it does return a reasonable
> looking vector of values. The "lnwagevec>-200" etc is an inelegant way of
> preventing values of Inf and -Inf from entering the sum, the actual values
> rarely go as high as 8 or low as -5.
> 

If you're getting infinite likelihoods, something may be needing a rethink, but first this:

I don't think

 -sum(lnwagevec>-200 & ln2wagevec<200, na.rm=TRUE)

does what I think you think it does....

Presumably you wanted -sum(lnagevec[lnwagevec>-200 & ln2wagevec<200], na.rm=TRUE)

-pd


> Thank you in advance to anyone responding!
> /Hugo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Tue Nov  7 13:59:19 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 7 Nov 2017 13:59:19 +0100
Subject: [R] Using MLE on a somewhat unusual likelihood function
In-Reply-To: <E2E7FD42-37C2-4DDB-B208-A16144C6F5E6@gmail.com>
References: <CAGRKcvQ4x2n4c7y0DZ-q4hh+ysVVJt8zZMd4V8tKgg6eO_VO=w@mail.gmail.com>
 <E2E7FD42-37C2-4DDB-B208-A16144C6F5E6@gmail.com>
Message-ID: <C9805BD9-F038-4CBC-938D-29EAAC7C61BF@gmail.com>


> On 7 Nov 2017, at 11:38 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Presumably you wanted -sum(lnagevec[lnwagevec>-200 & ln2wagevec<200], na.rm=TRUE)

Well, after correcting the obvious spelling error. Sorry about that...

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lorenzo.isella at gmail.com  Tue Nov  7 15:22:10 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 7 Nov 2017 15:22:10 +0100
Subject: [R] Fitdistrplus and Custom Probability Density
Message-ID: <CAE-ioUx2ptN14OBP6KKnpFjuwMFsqoRfcxPdYyvxEq6axZfzKA@mail.gmail.com>

Dear All,
Apologies for not providing a reproducible example, but if I could, then I
would be able to answer myself my question.
Essentially, I am trying to fit a very complicated custom probability
distribution to some data.
Fitdistrplus does in principle everything which I need, but if require me
to specify not only the density function d, but also the cumulative p and
and inverse cumulative function q (see for instance

http://www.stat.umn.edu/geyer/old/5101/rlook.html

to understand what these quantities are in the case of a normal
distribution).

The analytical calculation of p and q is a big task in my case, so my
question is if there is a workaround for this, i.e. a way to fit the
unknown parameters of my probability distribution without specifying (at
least analytically) p and q, but only the density d.
Many thanks

Lorenzo

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Nov  7 15:58:53 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 7 Nov 2017 16:58:53 +0200
Subject: [R] Fitdistrplus and Custom Probability Density
In-Reply-To: <CAE-ioUx2ptN14OBP6KKnpFjuwMFsqoRfcxPdYyvxEq6axZfzKA@mail.gmail.com>
References: <CAE-ioUx2ptN14OBP6KKnpFjuwMFsqoRfcxPdYyvxEq6axZfzKA@mail.gmail.com>
Message-ID: <CAGgJW74LoKqpiNKeE_jsy+UJ3fP+gA5MdkcKaykUpmUiTyMp7Q@mail.gmail.com>

Why not define your own functions based on d?
e.g.
myCumDist <- function(x) { integrate(d, lower=-Inf, upper=x)$value  }
myQuantile <- function(x) { uniroot(f=function(y) { h(y) - x },
interval=c(-5,5)) }  # limits -5,5 should be replaced by your own which
might require some fiddling

e.g.
d <- function(x) { exp(-x^2/2)/(sqrt(2*pi)) }  # just an example for you to
test with; use your own density d(x) in your case

Then define myCumDist, myQuantile as above and compare with pnorm, qnorm.

HTH,
Eric




On Tue, Nov 7, 2017 at 4:22 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> Apologies for not providing a reproducible example, but if I could, then I
> would be able to answer myself my question.
> Essentially, I am trying to fit a very complicated custom probability
> distribution to some data.
> Fitdistrplus does in principle everything which I need, but if require me
> to specify not only the density function d, but also the cumulative p and
> and inverse cumulative function q (see for instance
>
> http://www.stat.umn.edu/geyer/old/5101/rlook.html
>
> to understand what these quantities are in the case of a normal
> distribution).
>
> The analytical calculation of p and q is a big task in my case, so my
> question is if there is a workaround for this, i.e. a way to fit the
> unknown parameters of my probability distribution without specifying (at
> least analytically) p and q, but only the density d.
> Many thanks
>
> Lorenzo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From L.J.Bonnett at liverpool.ac.uk  Tue Nov  7 16:22:38 2017
From: L.J.Bonnett at liverpool.ac.uk (Bonnett, Laura)
Date: Tue, 7 Nov 2017 15:22:38 +0000
Subject: [R] Survfit when new data has only 1 row of data
Message-ID: <16a0df4b468c49ff9ef1bd03ad422825@liverpool.ac.uk>

Dear R-help,

I am using R version 3.4.0 within Windows, and survival 2.41-3.  I have fit a Prentice Williams and Peterson-Counting Process model to my data as shown below.  This is basically an extension of the Cox model for interval censored data.  My dataset, bdat5 can be found here: https://drive.google.com/open?id=1sQSBEe1uBzh_gYbcj4P5Kuephvalc3gh 

cfitcp2 <- coxph(Surv(start,stop,status)~sex+rels+factor(treat)+log(age)+log(tcrate3+0.01)+cluster(trialno)+strata(enum),data=bdat5,model=TRUE,x=TRUE,y=TRUE)

I would now like to use the model to predict the probability of zero events by two years - this is equivalent to the survival probability at 2 years I believe.  This is so that I can compare the output to similar estimates obtained from negative binomial, and zero-inflated negative binomial models for the same data (albeit in a different format)

To my mind, and based on what I've read, the best way to do this is to use survfit.  I want to make predictions for each individual, therefore, I have tried this code:
  
trialnos <- unique(bdat5$trialno) 
prob0 <- function(ids,dataset,model,time){
		probs <- rep(0,length(ids))
		for(i in 1:length(ids)){
		print(i)
		sdata <- subset(dataset,trialno==ids[i])
		sfit <- survfit(model,newdata=sdata)
		probs[i] <-sum(summary(sfit,time)$surv)
		}
		return(probs)
		}
prob0ests <- prob0(trialnos,bdat5,cfitcp2,730)

When I do this for the first three trial numbers I get:
0.3001021 2993.4531767    0.3445589

The unusually large "probability" arises when there is only 1 row of data for the relevant trial number.  Can anyone therefore explain why there is a problem when "sdata" is only 1 row, and ideally provide a solution?

Many thanks,
Laura

Dr Laura Bonnett
NIHR Post-Doctoral Fellow

Department of Biostatistics,
Waterhouse Building, Block F,
1-5 Brownlow Street,
University of Liverpool,
Liverpool,
L69 3GL

0151 795 9686
L.J.Bonnett at liverpool.ac.uk 


From dwinsemius at comcast.net  Tue Nov  7 17:55:23 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 7 Nov 2017 08:55:23 -0800
Subject: [R] Fitdistrplus and Custom Probability Density
In-Reply-To: <CAGgJW74LoKqpiNKeE_jsy+UJ3fP+gA5MdkcKaykUpmUiTyMp7Q@mail.gmail.com>
References: <CAE-ioUx2ptN14OBP6KKnpFjuwMFsqoRfcxPdYyvxEq6axZfzKA@mail.gmail.com>
 <CAGgJW74LoKqpiNKeE_jsy+UJ3fP+gA5MdkcKaykUpmUiTyMp7Q@mail.gmail.com>
Message-ID: <3FF957B9-F574-45A9-B767-4CD5A8BFDA26@comcast.net>


> On Nov 7, 2017, at 6:58 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
> Why not define your own functions based on d?
> e.g.
> myCumDist <- function(x) { integrate(d, lower=-Inf, upper=x)$value  }
> myQuantile <- function(x) { uniroot(f=function(y) { h(y) - x },
> interval=c(-5,5)) }  # limits -5,5 should be replaced by your own which
> might require some fiddling

My test gave an error regarding a missing `h` function. Perhaps you meant something like:

myQuantile <- function(x) { uniroot(f=function(y) { myCumDist(y)-x },
   interval=c(-5,5))$root }

I added the $root extraction so it now returns a numeric value instead of a list. I wondered if that might be somewhat slow, and considered the possibility of building a close aproximation that didn't require a combined integration and rootfinding operation for every value using approxfun() on a suitable range of p-values in the range [0,1]

-- 
David.
> 
> e.g.
> d <- function(x) { exp(-x^2/2)/(sqrt(2*pi)) }  # just an example for you to
> test with; use your own density d(x) in your case
> 
> Then define myCumDist, myQuantile as above and compare with pnorm, qnorm.
> 
> HTH,
> Eric
> 
> 
> 
> 
> On Tue, Nov 7, 2017 at 4:22 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
> wrote:
> 
>> Dear All,
>> Apologies for not providing a reproducible example, but if I could, then I
>> would be able to answer myself my question.
>> Essentially, I am trying to fit a very complicated custom probability
>> distribution to some data.
>> Fitdistrplus does in principle everything which I need, but if require me
>> to specify not only the density function d, but also the cumulative p and
>> and inverse cumulative function q (see for instance
>> 
>> http://www.stat.umn.edu/geyer/old/5101/rlook.html
>> 
>> to understand what these quantities are in the case of a normal
>> distribution).
>> 
>> The analytical calculation of p and q is a big task in my case, so my
>> question is if there is a workaround for this, i.e. a way to fit the
>> unknown parameters of my probability distribution without specifying (at
>> least analytically) p and q, but only the density d.
>> Many thanks
>> 
>> Lorenzo
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From chalabi.elahe at yahoo.de  Tue Nov  7 17:14:40 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Tue, 7 Nov 2017 16:14:40 +0000 (UTC)
Subject: [R] fill histogram in ggplot
References: <305684686.7040678.1510071280707.ref@mail.yahoo.com>
Message-ID: <305684686.7040678.1510071280707@mail.yahoo.com>

Hi all,

I have the following data and I have a histogram for mms like

     ggplot(hist,aes(x=hist$mms))+   geom_histogram(binwidth=1,fill="white",color="black")and then I want to fill the color of histogram by probable=1 and probable=0, could anyone help me in this?

My data:
structure(list(probable = c(1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 
0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, NA, 0L, 1L, NA, NA, 0L, 1L, 
NA, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 
1L, 0L, NA, 1L, NA, NA, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 
1L, NA, 0L, 0L, 1L, 0L, 1L, NA, 1L, 0L, 0L, 0L, 0L, 0L, 1L, NA, 
0L, 1L, 0L, 1L, NA, 0L, 1L, NA, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 
1L, 1L, 0L, 0L, 1L, 0L, NA, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 
0L, NA, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, NA, 0L, NA, 1L, 0L, 1L, 
1L, 1L, 1L, NA, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 
1L, NA, NA, 0L, 1L, 0L, 0L, 0L, NA, 1L, NA, NA, 1L, 0L, 1L, 1L, 
0L, 1L, 0L, NA, 1L, 1L, 1L, NA, 0L, 0L, 1L, NA, NA, 1L, 0L, 0L, 
NA, 1L, 1L, 1L, 0L, 0L, NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, NA, 
0L, 0L, 0L, 0L, 0L, NA, 0L, NA, 0L, 1L, NA, 1L, 1L, 1L, 1L, 1L, 
0L, 1L, 1L, NA, 0L, 1L, NA, 1L, 1L, 1L, 1L, 0L, 1L, NA, 1L, 0L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, NA, 1L, 1L, 
1L, 1L, NA, NA, 1L, NA, 1L, 1L, 1L, NA, NA, NA, 1L, NA, 1L, NA, 
NA, NA, 1L, 1L, 1L, NA, NA, NA, 1L, 1L, NA, 1L, NA, 1L, 1L, 1L, 
NA, 1L, 1L, NA, NA, NA, NA, NA, 1L, 1L, 1L, 1L, NA, 1L, NA, NA, 
NA, NA, 0L, 0L, 0L, 0L, 0L, NA, 1L, 1L, 0L, 0L, 1L, NA, NA, NA, 
NA, 1L, NA, NA, 1L, NA, 1L, 1L, NA, 1L, 1L, NA, NA, 1L, 1L, NA, 
NA, 1L, NA, 1L, NA, 1L, NA, NA, NA, NA, NA, NA, 1L, NA, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, NA, NA, 1L, NA, NA, NA, 1L, NA, 
1L, 1L, 1L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1L, NA, NA, 
NA, 1L, 1L, NA, 1L, 1L, 1L, NA, NA, NA, 1L, 1L, NA, NA, 1L, 1L, 
1L, 1L, NA, NA, NA, NA, 1L, 1L, 1L, 1L, NA, NA, 1L, NA, 1L, NA, 
NA, NA, NA, NA, 1L, NA, NA, NA, 1L, NA, 1L, 1L, 1L, NA, NA, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, NA, 1L, 1L, 1L, 1L, 0L, NA, 
1L, 1L, NA, 1L, 1L, NA, NA, NA, NA, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 
1L, NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 
1L, 1L, 1L, NA, 0L, 1L, NA, 0L, 0L, 0L, 1L, 1L, NA, 1L, 1L, NA, 
0L, 0L, 1L, NA, 0L, 0L, 1L, 0L, NA, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 
1L, NA, NA, 0L, 1L, 1L, NA, 1L, NA, NA, 0L, NA, 1L, NA, NA, 1L, 
NA, 1L, 1L, NA, 1L), mms = c(18L, 30L, 20L, 23L, 28L, 22L, 30L, 
20L, 14L, 30L, 16L, 28L, 28L, 29L, 11L, 28L, 27L, 16L, 29L, 27L, 
21L, 29L, 26L, 29L, 23L, 28L, 24L, 30L, 30L, 18L, 30L, 23L, 19L, 
18L, 26L, 30L, 13L, 29L, 30L, 30L, 27L, 26L, 28L, 26L, 25L, 29L, 
26L, 23L, 29L, 23L, 28L, 29L, 30L, 25L, 17L, 30L, 14L, 24L, 19L, 
30L, 30L, 27L, 29L, 18L, 22L, 8L, 30L, 28L, 30L, 30L, 30L, 30L, 
29L, 30L, 17L, 30L, 10L, 24L, 30L, 28L, 30L, 30L, 24L, 29L, 27L, 
30L, 30L, 29L, 30L, 30L, 23L, 30L, 27L, 10L, 29L, 17L, 28L, 30L, 
19L, 30L, 24L, 15L, 30L, 29L, 20L, 28L, 27L, 10L, 29L, 30L, 29L, 
20L, 28L, 25L, 27L, 25L, 29L, 22L, 17L, 28L, 19L, 20L, 16L, 25L, 
25L, 13L, 30L, 28L, 30L, 30L, 29L, 16L, 20L, 25L, 17L, 17L, 29L, 
18L, 18L, 16L, 29L, 19L, 26L, 30L, 30L, 16L, 18L, 14L, 28L, 12L, 
26L, 29L, 25L, 28L, 12L, 30L, 29L, 16L, 22L, 25L, 15L, 30L, 28L, 
22L, 25L, 27L, 17L, 29L, 30L, 28L, 17L, 23L, 21L, 28L, 30L, 18L, 
21L, 29L, 26L, 22L, 23L, 26L, 20L, 29L, 15L, 29L, 30L, 28L, 29L, 
29L, 25L, 27L, 23L, 30L, 14L, 27L, 18L, 16L, 19L, 13L, 18L, 28L, 
13L, 24L, 30L, 30L, 20L, 25L, 29L, 11L, 20L, 16L, 30L, 16L, 30L, 
20L, 30L, 20L, 22L, 19L, 23L, 16L, 19L, 13L, 13L, 25L, 19L, 9L, 
14L, 25L, 23L, 24L, 20L, 24L, 18L, 18L, 19L, 10L, 20L, 11L, 17L, 
19L, 22L, 6L, 18L, 25L, 17L, 25L, 22L, 29L, 22L, 16L, 8L, 10L, 
27L, 10L, 18L, 19L, 22L, 28L, 19L, 18L, 25L, 18L, 3L, 10L, 16L, 
10L, 29L, 22L, 29L, 12L, 15L, 24L, 17L, 6L, 5L, 14L, 27L, 13L, 
28L, 16L, 20L, 29L, 27L, 30L, 30L, 29L, 30L, 28L, 11L, 30L, 29L, 
6L, 30L, 16L, 9L, 23L, 10L, 23L, 17L, 24L, 9L, 9L, 18L, 18L, 
20L, 5L, 27L, 22L, 22L, 8L, 14L, 26L, 24L, 29L, 21L, 23L, 22L, 
23L, 25L, 6L, 20L, 20L, 2L, 8L, 19L, 20L, 5L, 17L, 20L, 15L, 
5L, 5L, 20L, 21L, 29L, 25L, 13L, 10L, 21L, 25L, 26L, 13L, 10L, 
7L, 11L, 18L, 19L, 14L, 27L, 22L, 18L, 7L, 22L, 11L, 12L, 16L, 
15L, 27L, 27L, 17L, 13L, 16L, 25L, 7L, 19L, 10L, 29L, 20L, 25L, 
25L, 24L, 15L, 20L, 9L, 5L, 17L, 28L, 24L, 7L, 5L, 13L, 30L, 
12L, 11L, 15L, 26L, 27L, 19L, 10L, 26L, 29L, 17L, 29L, 18L, 13L, 
17L, 14L, 14L, 9L, 19L, 7L, 4L, 20L, 14L, 22L, 27L, 16L, 18L, 
10L, 20L, 12L, 21L, 22L, 5L, 12L, 14L, 13L, 11L, 12L, 20L, 6L, 
28L, 9L, 20L, 16L, 16L, 2L, 24L, 21L, 26L, 23L, 18L, 10L, 23L, 
28L, 16L, 30L, 29L, 17L, 14L, 5L, 17L, 26L, 10L, 6L, 17L, 9L, 
17L, 18L, 9L, 24L, 20L, 11L, 18L, 29L, 17L, 5L, 22L, 12L, 29L, 
20L, 8L, 30L, 29L, 29L, 20L, 3L, 18L, 22L, 8L, 24L, 29L, 29L, 
13L, 23L, 30L, 30L, 13L, 28L, 13L, 12L, 29L, 30L, 17L, 14L, 16L, 
23L, 12L, 20L, 30L, 28L, 20L, 13L, 23L, 13L, 14L, 21L, 26L, 25L, 
6L, 9L, 18L, 18L, 25L, 27L, 15L, 10L, 7L)), .Names = c("probable", 
"mms"), row.names = c(NA, -510L), class = "data.frame")

Thanks for any help!
Elahe


From dawn1313 at gmail.com  Tue Nov  7 20:15:51 2017
From: dawn1313 at gmail.com (Yin)
Date: Tue, 7 Nov 2017 12:15:51 -0700
Subject: [R] Pathview xml issue
Message-ID: <CABtBq8FzXkMJ2YwWDUhFq0uK=eFBiRYJDNEy3AtfoGozJ8Cj=A@mail.gmail.com>

Hi,

I'm using GAGE/pathview to analyze my RNA-seq and phospho-protein data. The
following error occurs after this command line below:

>pv.out.list <- sapply(path.ids2[1:3], function(pid) pathview(
  gene.data = cnts.d, pathway.id = pid, gene.idtype="SYMBOL",kegg.native =
F,
  same.layer = T, species = "hsa", kegg.dir = "test", out.suffix = "up"))


Start tag expected, '<' not found
Warning: Parsing test/hsa04510.xml file failed, please check the file!

That .xml file is empty, while .png file exists. The issue is there is no
pathway with my data mapped (red and blue nodes). Can you please help that?

Thank you!
Best,
Shu

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Nov  7 20:49:00 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 07 Nov 2017 19:49:00 +0000
Subject: [R] fill histogram in ggplot
In-Reply-To: <305684686.7040678.1510071280707@mail.yahoo.com>
References: <305684686.7040678.1510071280707.ref@mail.yahoo.com>
 <305684686.7040678.1510071280707@mail.yahoo.com>
Message-ID: <CAKVAULO1jM5EwRx7Hshnmc4FTzc6e+Ya7-uBE8RT5L176a5gSQ@mail.gmail.com>

Hi Elahe,

You pass 'probable' to the fill aesthetic along the lines of;

ggplot(hist) +
aes(x=mms, fill = probable) +   geom_histogram(binwidth=1)

The NAs might give you three and not two colours.

I'm guessing you want distinct colours. In this case 'probable' should be a
factor and not an integer.

HTH
Ulrik

Elahe chalabi via R-help <r-help at r-project.org> schrieb am Di., 7. Nov.
2017, 18:35:

> Hi all,
>
> I have the following data and I have a histogram for mms like
>
>      ggplot(hist,aes(x=hist$mms))+
>  geom_histogram(binwidth=1,fill="white",color="black")and then I want to
> fill the color of histogram by probable=1 and probable=0, could anyone help
> me in this?
>
> My data:
> structure(list(probable = c(1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L,
> 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, NA, 0L, 1L, NA, NA, 0L, 1L,
> NA, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L,
> 1L, 0L, NA, 1L, NA, NA, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L,
> 1L, NA, 0L, 0L, 1L, 0L, 1L, NA, 1L, 0L, 0L, 0L, 0L, 0L, 1L, NA,
> 0L, 1L, 0L, 1L, NA, 0L, 1L, NA, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
> 1L, 1L, 0L, 0L, 1L, 0L, NA, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L,
> 0L, NA, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, NA, 0L, NA, 1L, 0L, 1L,
> 1L, 1L, 1L, NA, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, NA,
> 1L, NA, NA, 0L, 1L, 0L, 0L, 0L, NA, 1L, NA, NA, 1L, 0L, 1L, 1L,
> 0L, 1L, 0L, NA, 1L, 1L, 1L, NA, 0L, 0L, 1L, NA, NA, 1L, 0L, 0L,
> NA, 1L, 1L, 1L, 0L, 0L, NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, NA,
> 0L, 0L, 0L, 0L, 0L, NA, 0L, NA, 0L, 1L, NA, 1L, 1L, 1L, 1L, 1L,
> 0L, 1L, 1L, NA, 0L, 1L, NA, 1L, 1L, 1L, 1L, 0L, 1L, NA, 1L, 0L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, NA, 1L, 1L,
> 1L, 1L, NA, NA, 1L, NA, 1L, 1L, 1L, NA, NA, NA, 1L, NA, 1L, NA,
> NA, NA, 1L, 1L, 1L, NA, NA, NA, 1L, 1L, NA, 1L, NA, 1L, 1L, 1L,
> NA, 1L, 1L, NA, NA, NA, NA, NA, 1L, 1L, 1L, 1L, NA, 1L, NA, NA,
> NA, NA, 0L, 0L, 0L, 0L, 0L, NA, 1L, 1L, 0L, 0L, 1L, NA, NA, NA,
> NA, 1L, NA, NA, 1L, NA, 1L, 1L, NA, 1L, 1L, NA, NA, 1L, 1L, NA,
> NA, 1L, NA, 1L, NA, 1L, NA, NA, NA, NA, NA, NA, 1L, NA, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, NA, NA, 1L, NA, NA, NA, 1L, NA,
> 1L, 1L, 1L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1L, NA, NA,
> NA, 1L, 1L, NA, 1L, 1L, 1L, NA, NA, NA, 1L, 1L, NA, NA, 1L, 1L,
> 1L, 1L, NA, NA, NA, NA, 1L, 1L, 1L, 1L, NA, NA, 1L, NA, 1L, NA,
> NA, NA, NA, NA, 1L, NA, NA, NA, 1L, NA, 1L, 1L, 1L, NA, NA, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, NA, 1L, 1L, 1L, 1L, 0L, NA,
> 1L, 1L, NA, 1L, 1L, NA, NA, NA, NA, 1L, 1L, 0L, 1L, 0L, 0L, 1L,
> 1L, NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA,
> 1L, 1L, 1L, NA, 0L, 1L, NA, 0L, 0L, 0L, 1L, 1L, NA, 1L, 1L, NA,
> 0L, 0L, 1L, NA, 0L, 0L, 1L, 0L, NA, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
> 1L, NA, NA, 0L, 1L, 1L, NA, 1L, NA, NA, 0L, NA, 1L, NA, NA, 1L,
> NA, 1L, 1L, NA, 1L), mms = c(18L, 30L, 20L, 23L, 28L, 22L, 30L,
> 20L, 14L, 30L, 16L, 28L, 28L, 29L, 11L, 28L, 27L, 16L, 29L, 27L,
> 21L, 29L, 26L, 29L, 23L, 28L, 24L, 30L, 30L, 18L, 30L, 23L, 19L,
> 18L, 26L, 30L, 13L, 29L, 30L, 30L, 27L, 26L, 28L, 26L, 25L, 29L,
> 26L, 23L, 29L, 23L, 28L, 29L, 30L, 25L, 17L, 30L, 14L, 24L, 19L,
> 30L, 30L, 27L, 29L, 18L, 22L, 8L, 30L, 28L, 30L, 30L, 30L, 30L,
> 29L, 30L, 17L, 30L, 10L, 24L, 30L, 28L, 30L, 30L, 24L, 29L, 27L,
> 30L, 30L, 29L, 30L, 30L, 23L, 30L, 27L, 10L, 29L, 17L, 28L, 30L,
> 19L, 30L, 24L, 15L, 30L, 29L, 20L, 28L, 27L, 10L, 29L, 30L, 29L,
> 20L, 28L, 25L, 27L, 25L, 29L, 22L, 17L, 28L, 19L, 20L, 16L, 25L,
> 25L, 13L, 30L, 28L, 30L, 30L, 29L, 16L, 20L, 25L, 17L, 17L, 29L,
> 18L, 18L, 16L, 29L, 19L, 26L, 30L, 30L, 16L, 18L, 14L, 28L, 12L,
> 26L, 29L, 25L, 28L, 12L, 30L, 29L, 16L, 22L, 25L, 15L, 30L, 28L,
> 22L, 25L, 27L, 17L, 29L, 30L, 28L, 17L, 23L, 21L, 28L, 30L, 18L,
> 21L, 29L, 26L, 22L, 23L, 26L, 20L, 29L, 15L, 29L, 30L, 28L, 29L,
> 29L, 25L, 27L, 23L, 30L, 14L, 27L, 18L, 16L, 19L, 13L, 18L, 28L,
> 13L, 24L, 30L, 30L, 20L, 25L, 29L, 11L, 20L, 16L, 30L, 16L, 30L,
> 20L, 30L, 20L, 22L, 19L, 23L, 16L, 19L, 13L, 13L, 25L, 19L, 9L,
> 14L, 25L, 23L, 24L, 20L, 24L, 18L, 18L, 19L, 10L, 20L, 11L, 17L,
> 19L, 22L, 6L, 18L, 25L, 17L, 25L, 22L, 29L, 22L, 16L, 8L, 10L,
> 27L, 10L, 18L, 19L, 22L, 28L, 19L, 18L, 25L, 18L, 3L, 10L, 16L,
> 10L, 29L, 22L, 29L, 12L, 15L, 24L, 17L, 6L, 5L, 14L, 27L, 13L,
> 28L, 16L, 20L, 29L, 27L, 30L, 30L, 29L, 30L, 28L, 11L, 30L, 29L,
> 6L, 30L, 16L, 9L, 23L, 10L, 23L, 17L, 24L, 9L, 9L, 18L, 18L,
> 20L, 5L, 27L, 22L, 22L, 8L, 14L, 26L, 24L, 29L, 21L, 23L, 22L,
> 23L, 25L, 6L, 20L, 20L, 2L, 8L, 19L, 20L, 5L, 17L, 20L, 15L,
> 5L, 5L, 20L, 21L, 29L, 25L, 13L, 10L, 21L, 25L, 26L, 13L, 10L,
> 7L, 11L, 18L, 19L, 14L, 27L, 22L, 18L, 7L, 22L, 11L, 12L, 16L,
> 15L, 27L, 27L, 17L, 13L, 16L, 25L, 7L, 19L, 10L, 29L, 20L, 25L,
> 25L, 24L, 15L, 20L, 9L, 5L, 17L, 28L, 24L, 7L, 5L, 13L, 30L,
> 12L, 11L, 15L, 26L, 27L, 19L, 10L, 26L, 29L, 17L, 29L, 18L, 13L,
> 17L, 14L, 14L, 9L, 19L, 7L, 4L, 20L, 14L, 22L, 27L, 16L, 18L,
> 10L, 20L, 12L, 21L, 22L, 5L, 12L, 14L, 13L, 11L, 12L, 20L, 6L,
> 28L, 9L, 20L, 16L, 16L, 2L, 24L, 21L, 26L, 23L, 18L, 10L, 23L,
> 28L, 16L, 30L, 29L, 17L, 14L, 5L, 17L, 26L, 10L, 6L, 17L, 9L,
> 17L, 18L, 9L, 24L, 20L, 11L, 18L, 29L, 17L, 5L, 22L, 12L, 29L,
> 20L, 8L, 30L, 29L, 29L, 20L, 3L, 18L, 22L, 8L, 24L, 29L, 29L,
> 13L, 23L, 30L, 30L, 13L, 28L, 13L, 12L, 29L, 30L, 17L, 14L, 16L,
> 23L, 12L, 20L, 30L, 28L, 20L, 13L, 23L, 13L, 14L, 21L, 26L, 25L,
> 6L, 9L, 18L, 18L, 25L, 27L, 15L, 10L, 7L)), .Names = c("probable",
> "mms"), row.names = c(NA, -510L), class = "data.frame")
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Backer at uib.no  Tue Nov  7 21:01:02 2017
From: Backer at uib.no (Tom Backer Johnsen)
Date: Tue, 7 Nov 2017 21:01:02 +0100
Subject: [R] Missing information in source()
Message-ID: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>

Dear R-help,

I am running a Mac under Sierra, with R version 3.4.2 and RStudio 1.1.383.  When running head () or tail () on an object in a script using source (<script name>) nothing appears in the output file, but if I use these commands in the normal R window the normal output appears.

What am I doing wrong?

Tom Backer Johnsen
University of Bergen
Norway

From wdunlap at tibco.com  Tue Nov  7 21:32:35 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 7 Nov 2017 12:32:35 -0800
Subject: [R] Missing information in source()
In-Reply-To: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
References: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
Message-ID: <CAF8bMcbWjVECUBUOi2t_zMO-EtOuwUvKhR_qairZaMUHcMt_Ng@mail.gmail.com>

Either change your script by adding print(...) calls where you want to see
something printed or change the call to source() by adding print.eval=TRUE
or echo=TRUE.   E.g.,

> cat(file = tf <- tempfile(), "head(10:1)\ntail(letters)\nx <-
gamma(0:4)\nx\n")
> source(tf)
Warning message:
In gamma(0:4) : NaNs produced
> source(tf, print.eval=TRUE)
[1] 10  9  8  7  6  5
[1] "u" "v" "w" "x" "y" "z"
[1] NaN   1   1   2   6
Warning message:
In gamma(0:4) : NaNs produced
> source(tf, echo=TRUE, print.eval=TRUE)

> head(10:1)
[1] 10  9  8  7  6  5

> tail(letters)
[1] "u" "v" "w" "x" "y" "z"

> x <- gamma(0:4)

> x
[1] NaN   1   1   2   6
Warning message:
In gamma(0:4) : NaNs produced
>

Calling options(warn=1) before calling source() will keep the warnings near
the lines that caused them.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 7, 2017 at 12:01 PM, Tom Backer Johnsen <Backer at uib.no> wrote:

> Dear R-help,
>
> I am running a Mac under Sierra, with R version 3.4.2 and RStudio
> 1.1.383.  When running head () or tail () on an object in a script using
> source (<script name>) nothing appears in the output file, but if I use
> these commands in the normal R window the normal output appears.
>
> What am I doing wrong?
>
> Tom Backer Johnsen
> University of Bergen
> Norway
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Nov  7 21:33:29 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 7 Nov 2017 15:33:29 -0500
Subject: [R] Missing information in source()
In-Reply-To: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
References: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
Message-ID: <c81e8f9d-3f6c-78db-4d49-f9b20c311608@gmail.com>

On 07/11/2017 3:01 PM, Tom Backer Johnsen wrote:
> Dear R-help,
> 
> I am running a Mac under Sierra, with R version 3.4.2 and RStudio 1.1.383.  When running head () or tail () on an object in a script using source (<script name>) nothing appears in the output file, but if I use these commands in the normal R window the normal output appears.
> 
> What am I doing wrong?

You aren't printing the results.  source() has an argument "print.eval" 
which defaults to FALSE; you can change it.  A common way to do that is 
to set echo=TRUE, but echoing the input is not necessary.

So use

source(filename, echo = TRUE)

for a lot of output, or

source(filename, print.eval = TRUE)

for somewhat less.

In most cases an explicit print() will be needed if the head() or tail() 
is in a loop or in a function.

Duncan Murdoch


From djnordlund at gmail.com  Tue Nov  7 21:37:50 2017
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Tue, 7 Nov 2017 12:37:50 -0800
Subject: [R] Missing information in source()
In-Reply-To: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
References: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
Message-ID: <991a516f-e9de-b252-612c-fa65a4050adc@gmail.com>

On 11/7/2017 12:01 PM, Tom Backer Johnsen wrote:
> Dear R-help,
> 
> I am running a Mac under Sierra, with R version 3.4.2 and RStudio 1.1.383.  When running head () or tail () on an object in a script using source (<script name>) nothing appears in the output file, but if I use these commands in the normal R window the normal output appears.
> 
> What am I doing wrong?
> 
> Tom Backer Johnsen
> University of Bergen
> Norway
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

I believe you need to wrap your call to head/tail in a print statement:

print(head(_whatever_))


Hope this is helpful,


Dan



-- 
Daniel Nordlund
Port Townsend, WA  USA


From jdnewmil at dcn.davis.ca.us  Tue Nov  7 22:27:56 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 07 Nov 2017 13:27:56 -0800
Subject: [R] Pathview xml issue
In-Reply-To: <CABtBq8FzXkMJ2YwWDUhFq0uK=eFBiRYJDNEy3AtfoGozJ8Cj=A@mail.gmail.com>
References: <CABtBq8FzXkMJ2YwWDUhFq0uK=eFBiRYJDNEy3AtfoGozJ8Cj=A@mail.gmail.com>
Message-ID: <7152A791-FCE3-4A2E-AD97-8199E5EECF3F@dcn.davis.ca.us>

Between the lack of a reproducible example and the question being about a Bioconductor package, you probably won't see much response here. Try the Bioconductor mailing list? 
-- 
Sent from my phone. Please excuse my brevity.

On November 7, 2017 11:15:51 AM PST, Yin <dawn1313 at gmail.com> wrote:
>Hi,
>
>I'm using GAGE/pathview to analyze my RNA-seq and phospho-protein data.
>The
>following error occurs after this command line below:
>
>>pv.out.list <- sapply(path.ids2[1:3], function(pid) pathview(
>gene.data = cnts.d, pathway.id = pid, gene.idtype="SYMBOL",kegg.native
>=
>F,
>same.layer = T, species = "hsa", kegg.dir = "test", out.suffix = "up"))
>
>
>Start tag expected, '<' not found
>Warning: Parsing test/hsa04510.xml file failed, please check the file!
>
>That .xml file is empty, while .png file exists. The issue is there is
>no
>pathway with my data mapped (red and blue nodes). Can you please help
>that?
>
>Thank you!
>Best,
>Shu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Tue Nov  7 23:38:38 2017
From: davidsmi at microsoft.com (David Smith (CLOUD AI))
Date: Tue, 7 Nov 2017 22:38:38 +0000
Subject: [R] Revolutions blog: October 2017 roundup
Message-ID: <BN6PR21MB0497093012344C7AD5906E76C8510@BN6PR21MB0497.namprd21.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests
have written about R every weekday at the Revolutions blog
(http://blog.revolutionanalytics.com) and every month I post a summary
of articles from the previous month of particular interest to readers
of r-help.

In case you missed them, here are some articles related to R from the
month of October:

A recent survey of competitors on the Kaggle platform reveals that Python (76%)
and R (59%) are the preferred tools for building predictive models:
http://blog.revolutionanalytics.com/2017/10/survey-of-kagglers.html

Microsoft's "Team Data Science Process" has been updated with new guidelines on
use of the IDEAR framework for R and Python:
http://blog.revolutionanalytics.com/2017/10/recent-updates-to-the-team-data-science-process.html

Microsoft R Open 3.4.2 is now available for Windows, Mac and Linux:
http://blog.revolutionanalytics.com/2017/10/microsoft-r-open-342-now-available.html

Using the foreach package to estimate bias of rpart trees via bootstrapping:
http://blog.revolutionanalytics.com/2017/10/bias-bootstrap-foreach.html

Replays of webinars on the Azure Data Science VM, and on document collection
analysis with Azure ML Workbench, are now available:
http://blog.revolutionanalytics.com/2017/10/two-upcoming-webinars.html

The "officer" package makes it possible to create PowerPoint and Word documents
from R http://blog.revolutionanalytics.com/2017/10/office-charts.html, and even
include editable R charts
http://blog.revolutionanalytics.com/2017/10/office-charts.html

An online book on statistical machine learning with the MicrosoftML package:
http://blog.revolutionanalytics.com/2017/10/statistical-machine-learning-with-microsoft-ml.html

An updated list of major events in the history of the R project, 1992-2016:
http://blog.revolutionanalytics.com/2017/10/updated-history-of-r.html

An overview of the R manuals, now also available in Bookdown format:
http://blog.revolutionanalytics.com/2017/10/r-manuals-bookdown.html

An analysis comparing the speeds of bikes and taxis for trips across New York
City: http://blog.revolutionanalytics.com/2017/10/bokes-taxis-nyc.html

Vision-based AI techniques used to estimate the population of snow leopards:
http://blog.revolutionanalytics.com/2017/10/snow-leopards.html

ROpenSci interviews me (David Smith) about working in the R community:
http://blog.revolutionanalytics.com/2017/10/my-interview-with-ropensci.html

A generational neural network, implemented in R, synthesizes startup names and
business plans:
http://blog.revolutionanalytics.com/2017/10/an-ai-pitches-startup-ideas.html

Two R-themed crosswords: a cryptic one by Barry Rowlingson
http://blog.revolutionanalytics.com/2017/10/a-cryptic-crossword-with-an-r-twist.html,
and a standard one from R-Ladies DC
http://blog.revolutionanalytics.com/2017/10/r-crossword.html

A tutorial on using Azure Data Lake Analytics with R:
http://blog.revolutionanalytics.com/2017/10/adla-with-r.html

The remarkable growth of R, as seen in StackOverflow traffic data:
http://blog.revolutionanalytics.com/2017/10/rs-remarkable-growth.html

Version 1.0.0 of the dplyrXdf package, providing dplyr operations for Microsoft
R out-of-memory data files, is now available:
http://blog.revolutionanalytics.com/2017/10/announcing-dplyrxdf-10.html

The GPU-enabled Deep Learning Virtual Machine on Azure includes R, Spark,
Tensorflow and more:
http://blog.revolutionanalytics.com/2017/10/deep-learning-vm.html

A comparison of assault death rates in the US and other advanced democracies,
generated in R by Kieran Healy:
http://blog.revolutionanalytics.com/2017/10/assault-death-rates.html

And some general interest stories (not necessarily related to R):

* Analysis of the film Ex Machina, and others
  http://blog.revolutionanalytics.com/2017/10/because-its-friday-movies-with-mikey.html

* Time-lapse video of a 30-day voyage on a cargo ship:
  http://blog.revolutionanalytics.com/2017/10/because-its-friday-30-days-of-cargo.html

* Films made with Line Rider:
  http://blog.revolutionanalytics.com/2017/10/because-its-friday-line-rider.html

* A website suggests a random cause of death, from CDC data:
  http://blog.revolutionanalytics.com/2017/10/because-its-friday-death-risk.html 

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft AI & Research? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From reichmanj at sbcglobal.net  Tue Nov  7 23:40:38 2017
From: reichmanj at sbcglobal.net (Jeff Reichman	)
Date: Tue, 7 Nov 2017 16:40:38 -0600
Subject: [R] Error when attempting to see "Corpus" metadata
Message-ID: <000a01d35819$6f55ff90$4e01feb0$@sbcglobal.net>

R Project

 

I receive the erro highlighted in yellow when attempting to combine two
Corpus, so I'm assuming I'm not combining the two variables (nb_pos and
nb_neg) in the following line

 

nb_all <- c(nb_pos,nb_neg,recursive=TRUE) # anyone see anything wrong with
this line of code

 

--------------------------------------------------

 

> library("tm")

Loading required package: NLP

> nb_pos <- Corpus(DirSource(path_to_pos_folder), readerControl =
list(language="en")) # appears to be correct

> nb_neg <- Corpus(DirSource(path_to_neg_folder), readerControl =
list(language="en")) # appears to be correct       

> nb_all <- c(nb_pos,nb_neg,recursive=TRUE)

> 

> meta(nb_all[[1]])

Error in UseMethod("meta", x) : 

  no applicable method for 'meta' applied to an object of class "character"

 

Jeff Reichman


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Nov  7 21:25:21 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 07 Nov 2017 20:25:21 +0000
Subject: [R] Missing information in source()
In-Reply-To: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
References: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
Message-ID: <5A0216B1.1040405@sapo.pt>

Hello,

Try

print(head(...))

Hope this helps,

Rui Barradas

Em 07-11-2017 20:01, Tom Backer Johnsen escreveu:
> Dear R-help,
>
> I am running a Mac under Sierra, with R version 3.4.2 and RStudio 1.1.383.  When running head () or tail () on an object in a script using source (<script name>) nothing appears in the output file, but if I use these commands in the normal R window the normal output appears.
>
> What am I doing wrong?
>
> Tom Backer Johnsen
> University of Bergen
> Norway
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gbalas07 at gmail.com  Wed Nov  8 00:46:43 2017
From: gbalas07 at gmail.com (George Balas)
Date: Wed, 8 Nov 2017 01:46:43 +0200
Subject: [R] Problem with r project in ubuntu xenial
In-Reply-To: <CADwjDbpCtP9MR-GKnsEo2HCARGz7WhQjxO4zZOOVLDxOW305Mw@mail.gmail.com>
References: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
 <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>
 <B4DBC5FF-AA98-440D-92C7-D6792D44B568@comcast.net>
 <CADwjDbpCtP9MR-GKnsEo2HCARGz7WhQjxO4zZOOVLDxOW305Mw@mail.gmail.com>
Message-ID: <CADwjDboKa98-8JC8Cig0cW4Zn6L2TB+v6q5ogycQkVztNDnWxw@mail.gmail.com>

For anyone who sees this conversation.

There is a bug in installation of igraph in R language in Ubuntu. There is
a solution in stackoverflow. We have to use the devtools. Write this code:
install.packages("devtools")
library(devtools)
install_github("igraph/rigraph")

If there are errors installing devtools just install any package that
comments.

On Nov 5, 2017 00:07, "George Balas" <gbalas07 at gmail.com> wrote:

> -Well it seems that it is getting "el_GR.UTF-8" but still I am not able
> to read files written in greek, there are only "????" instead of letters.
> -Also, I forgot to mention that I do load igraph library when I try "graph_from_adjacency_matrix".
> When I check igraph in packages dialog I can not see functions with
> underscores between words, only dots.
>
> 2017-11-04 2:22 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>
>>
>> > On Nov 3, 2017, at 5:09 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>> >
>> >
>> >> On 3 Nov 2017, at 23:39 , George Balas <gbalas07 at gmail.com> wrote:
>> >>
>> >> I have a problem with R in Ubuntu 16.04. I do not know if it is mine
>> pc or
>> >> general problem but I was not able to find solution on Internet.
>> >> First of all I can not change locale to greek by getting this message:
>> >> "In Sys.setlocale("LC_CTYPE", "Greek") :
>> >> OS reports request to set locale to "Greek" cannot be honored"
>> >
>> > The Greek locale is likely not called "Greek" outside of Windows. More
>> likely "el_GR.UTF-8" or thereabouts (check your locale database, I'm on a
>> Mac). These things are not standardized across platforms.
>> >
>>
>> Also
>>
>> From help(locales): Attempts to change the character set by
>> Sys.setlocale("LC_CTYPE") that implies a different character set during a
>> session may not work and are likely to lead to some confusion because it
>> may not affect the native encoding.
>>
>>
>> >> Second and more serious is that I can not use some functions like
>> >> graph_from_adjacency_matrix or print_all I get these messeges:
>> >> "could not find function "graph_from_adjacency_matrix""
>> >> "could not find function "print_all"".
>> >
>> > Missing library(igraph)?
>> >
>> > -pd
>> >
>> >> I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on
>> rstudio
>> >> or ubuntu terminal.
>> >> On my pc I also run win 10 with the same installs and I do not have the
>> >> above problems, but I work on ubuntu and can not change Os all the
>> time.
>> >> Please help me.
>> >>
>> >> Thank you for your time,
>> >> George
>> >> gbalas07 at gmail.com
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Peter Dalgaard, Professor,
>> > Center for Statistics, Copenhagen Business School
>> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> > Phone: (+45)38153501
>> > Office: A 4.23
>> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>  -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov  8 03:14:04 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 7 Nov 2017 18:14:04 -0800
Subject: [R] Problem with r project in ubuntu xenial
In-Reply-To: <CADwjDboKa98-8JC8Cig0cW4Zn6L2TB+v6q5ogycQkVztNDnWxw@mail.gmail.com>
References: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
 <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>
 <B4DBC5FF-AA98-440D-92C7-D6792D44B568@comcast.net>
 <CADwjDbpCtP9MR-GKnsEo2HCARGz7WhQjxO4zZOOVLDxOW305Mw@mail.gmail.com>
 <CADwjDboKa98-8JC8Cig0cW4Zn6L2TB+v6q5ogycQkVztNDnWxw@mail.gmail.com>
Message-ID: <AB90EE83-29C9-4EC3-9B20-EB635312E0E7@comcast.net>


> On Nov 7, 2017, at 3:46 PM, George Balas <gbalas07 at gmail.com> wrote:
> 
> For anyone who sees this conversation.
> 
> There is a bug in installation of igraph in R language in Ubuntu. There is
> a solution in stackoverflow. We have to use the devtools. Write this code:
> install.packages("devtools")
> library(devtools)
> install_github("igraph/rigraph")

If there is a bug in the development version of igraph (which is not really part of R but rather a contributed package) then the correct place to send a message would have been, not to rhelp, but rather to the maintainer. It would of course be necessary to say what the bug appears to be. I don't see any error message or description of a bug in this message. The package DESCRIPTION files says:

BugReports: https://github.com/igraph/igraph/issues

The github page says the proper installation sequence for the development version is:

devtools::install_github("gaborcsardi/pkgconfig")
devtools::install_github("igraph/rigraph")

Rhelp is not the correct place for pre-release bug discussion of contributed packages.

Again, the github pages suggests that you send issues to the correct mailing list: igraph-help mailing list

https://lists.nongnu.org/mailman/listinfo/igraph-help


-- 
David.
> 
> If there are errors installing devtools just install any package that
> comments.
> 
> On Nov 5, 2017 00:07, "George Balas" <gbalas07 at gmail.com> wrote:
> 
>> -Well it seems that it is getting "el_GR.UTF-8" but still I am not able
>> to read files written in greek, there are only "????" instead of letters.
>> -Also, I forgot to mention that I do load igraph library when I try "graph_from_adjacency_matrix".
>> When I check igraph in packages dialog I can not see functions with
>> underscores between words, only dots.
>> 
>> 2017-11-04 2:22 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>> 
>>> 
>>>> On Nov 3, 2017, at 5:09 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>>>> 
>>>> 
>>>>> On 3 Nov 2017, at 23:39 , George Balas <gbalas07 at gmail.com> wrote:
>>>>> 
>>>>> I have a problem with R in Ubuntu 16.04. I do not know if it is mine
>>> pc or
>>>>> general problem but I was not able to find solution on Internet.
>>>>> First of all I can not change locale to greek by getting this message:
>>>>> "In Sys.setlocale("LC_CTYPE", "Greek") :
>>>>> OS reports request to set locale to "Greek" cannot be honored"
>>>> 
>>>> The Greek locale is likely not called "Greek" outside of Windows. More
>>> likely "el_GR.UTF-8" or thereabouts (check your locale database, I'm on a
>>> Mac). These things are not standardized across platforms.
>>>> 
>>> 
>>> Also
>>> 
>>> From help(locales): Attempts to change the character set by
>>> Sys.setlocale("LC_CTYPE") that implies a different character set during a
>>> session may not work and are likely to lead to some confusion because it
>>> may not affect the native encoding.
>>> 
>>> 
>>>>> Second and more serious is that I can not use some functions like
>>>>> graph_from_adjacency_matrix or print_all I get these messeges:
>>>>> "could not find function "graph_from_adjacency_matrix""
>>>>> "could not find function "print_all"".
>>>> 
>>>> Missing library(igraph)?
>>>> 
>>>> -pd
>>>> 
>>>>> I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on
>>> rstudio
>>>>> or ubuntu terminal.
>>>>> On my pc I also run win 10 with the same installs and I do not have the
>>>>> above problems, but I work on ubuntu and can not change Os all the
>>> time.
>>>>> Please help me.
>>>>> 
>>>>> Thank you for your time,
>>>>> George
>>>>> gbalas07 at gmail.com
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> --
>>>> Peter Dalgaard, Professor,
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Office: A 4.23
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>> -Gehm's Corollary to Clarke's Third Law
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From zcatav at gmail.com  Wed Nov  8 08:50:10 2017
From: zcatav at gmail.com (=?UTF-8?Q?Zeki_=C3=87ATAV?=)
Date: Wed, 8 Nov 2017 09:50:10 +0200
Subject: [R] Ggplot error
Message-ID: <CAP6VsR+so0tQLMbh+1VH2Z1jHiq73Y8C9+95KaeLXjvgUJ5SUg@mail.gmail.com>

Hello,
I've an error recently.

ggplot(data = mtcars, aes(x= wt, y= mpg)) + geom_line()
Error: Found object is not a stat.

> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.3 LTS

Matrix products: default
BLAS: /usr/lib/openblas-base/libblas.so.3
LAPACK: /usr/lib/libopenblasp-r0.2.18.so

locale:
 [1] LC_CTYPE=tr_TR.UTF-8       LC_NUMERIC=C
 LC_TIME=tr_TR.UTF-8
 [4] LC_COLLATE=tr_TR.UTF-8     LC_MONETARY=tr_TR.UTF-8
LC_MESSAGES=tr_TR.UTF-8
 [7] LC_PAPER=tr_TR.UTF-8       LC_NAME=C                  LC_ADDRESS=C

[10] LC_TELEPHONE=C             LC_MEASUREMENT=tr_TR.UTF-8
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] dplyr_0.7.4     purrr_0.2.4     readr_1.1.1     tidyr_0.7.2
 tibble_1.3.4    tidyverse_1.1.1
[7] ggplot2_2.2.1

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.13       lubridate_1.7.1    lattice_0.20-35    class_7.3-14
     assertthat_0.2.0
 [6] ipred_0.9-6        psych_1.7.8        foreach_1.4.3      R6_2.2.2
     cellranger_1.1.0
[11] plyr_1.8.4         stats4_3.4.2       httr_1.3.1         rlang_0.1.4
      lazyeval_0.2.1
[16] caret_6.0-77       readxl_1.0.0       kernlab_0.9-25     rpart_4.1-11
     Matrix_1.2-11
[21] splines_3.4.2      CVST_0.2-1         ddalpha_1.3.1      gower_0.1.2
      stringr_1.2.0
[26] foreign_0.8-69     munsell_0.4.3      broom_0.4.2
compiler_3.4.2     modelr_0.1.1
[31] pkgconfig_2.0.1    mnormt_1.5-5       dimRed_0.1.0       nnet_7.3-12
      prodlim_1.6.1
[36] DRR_0.0.2          codetools_0.2-15   RcppRoll_0.2.2     withr_2.1.0
      MASS_7.3-47
[41] recipes_0.1.0      ModelMetrics_1.1.0 grid_3.4.2         nlme_3.1-131
     jsonlite_1.5
[46] gtable_0.2.0       magrittr_1.5       scales_0.5.0
 stringi_1.1.5      reshape2_1.4.2
[51] bindrcpp_0.2       timeDate_3012.100  robustbase_0.92-8  xml2_1.1.1
     lava_1.5.1
[56] iterators_1.0.8    tools_3.4.2        forcats_0.2.0      glue_1.2.0
     DEoptimR_1.0-8
[61] sfsmisc_1.1-1      hms_0.3            parallel_3.4.2
 survival_2.41-3    yaml_2.1.14
[66] colorspace_1.3-2   rvest_0.3.2        bindr_0.1          haven_1.1.0


> conflicts(detail = TRUE)
$.GlobalEnv
[1] "iris"

$`package:dplyr`
 [1] "%>%"           "%>%"           "add_row"       "as_data_frame"
"as_tibble"     "data_frame"
 [7] "data_frame_"   "frame_data"    "glimpse"       "lst"
 "lst_"          "tbl_sum"
[13] "tibble"        "tribble"       "trunc_mat"     "type_sum"
"filter"        "lag"
[19] "intersect"     "setdiff"       "setequal"      "union"

$`package:purrr`
[1] "%>%" "%>%"

$`package:tidyr`
[1] "%>%" "%>%"

$`package:tibble`
 [1] "add_row"       "as_data_frame" "as_tibble"     "data_frame"
"data_frame_"   "frame_data"
 [7] "glimpse"       "lst"           "lst_"          "tbl_sum"
 "tibble"        "tribble"
[13] "trunc_mat"     "type_sum"

$`package:ggplot2`
[1] "Position"

$`package:stats`
[1] "filter" "lag"

$`package:datasets`
[1] "iris"

$`package:methods`
[1] "body<-"    "kronecker"

$`package:base`
[1] "body<-"    "intersect" "kronecker" "Position"  "setdiff"   "setequal"
"union"


How can I solve this problem?
Thanks.

--
Zeki ?atav
zekicatav.com

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov  8 10:15:59 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 8 Nov 2017 11:15:59 +0200
Subject: [R] Ggplot error
In-Reply-To: <CAP6VsR+so0tQLMbh+1VH2Z1jHiq73Y8C9+95KaeLXjvgUJ5SUg@mail.gmail.com>
References: <CAP6VsR+so0tQLMbh+1VH2Z1jHiq73Y8C9+95KaeLXjvgUJ5SUg@mail.gmail.com>
Message-ID: <CAGgJW77ekPo7SXhhYSHWnUjOYtDgVXzijnLdOsOUY2S_GhfXHA@mail.gmail.com>

I was not able to reproduce this problem. I tried two environments
1. Ubuntu 14.04.5 LTS, R version 3.4.2 (same R version as yours)
2. Windows 10, same R version



On Wed, Nov 8, 2017 at 9:50 AM, Zeki ?ATAV <zcatav at gmail.com> wrote:

> Hello,
> I've an error recently.
>
> ggplot(data = mtcars, aes(x= wt, y= mpg)) + geom_line()
> Error: Found object is not a stat.
>
> > sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.3 LTS
>
> Matrix products: default
> BLAS: /usr/lib/openblas-base/libblas.so.3
> LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>
> locale:
>  [1] LC_CTYPE=tr_TR.UTF-8       LC_NUMERIC=C
>  LC_TIME=tr_TR.UTF-8
>  [4] LC_COLLATE=tr_TR.UTF-8     LC_MONETARY=tr_TR.UTF-8
> LC_MESSAGES=tr_TR.UTF-8
>  [7] LC_PAPER=tr_TR.UTF-8       LC_NAME=C                  LC_ADDRESS=C
>
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=tr_TR.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] dplyr_0.7.4     purrr_0.2.4     readr_1.1.1     tidyr_0.7.2
>  tibble_1.3.4    tidyverse_1.1.1
> [7] ggplot2_2.2.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.13       lubridate_1.7.1    lattice_0.20-35    class_7.3-14
>      assertthat_0.2.0
>  [6] ipred_0.9-6        psych_1.7.8        foreach_1.4.3      R6_2.2.2
>      cellranger_1.1.0
> [11] plyr_1.8.4         stats4_3.4.2       httr_1.3.1         rlang_0.1.4
>       lazyeval_0.2.1
> [16] caret_6.0-77       readxl_1.0.0       kernlab_0.9-25     rpart_4.1-11
>      Matrix_1.2-11
> [21] splines_3.4.2      CVST_0.2-1         ddalpha_1.3.1      gower_0.1.2
>       stringr_1.2.0
> [26] foreign_0.8-69     munsell_0.4.3      broom_0.4.2
> compiler_3.4.2     modelr_0.1.1
> [31] pkgconfig_2.0.1    mnormt_1.5-5       dimRed_0.1.0       nnet_7.3-12
>       prodlim_1.6.1
> [36] DRR_0.0.2          codetools_0.2-15   RcppRoll_0.2.2     withr_2.1.0
>       MASS_7.3-47
> [41] recipes_0.1.0      ModelMetrics_1.1.0 grid_3.4.2         nlme_3.1-131
>      jsonlite_1.5
> [46] gtable_0.2.0       magrittr_1.5       scales_0.5.0
>  stringi_1.1.5      reshape2_1.4.2
> [51] bindrcpp_0.2       timeDate_3012.100  robustbase_0.92-8  xml2_1.1.1
>      lava_1.5.1
> [56] iterators_1.0.8    tools_3.4.2        forcats_0.2.0      glue_1.2.0
>      DEoptimR_1.0-8
> [61] sfsmisc_1.1-1      hms_0.3            parallel_3.4.2
>  survival_2.41-3    yaml_2.1.14
> [66] colorspace_1.3-2   rvest_0.3.2        bindr_0.1          haven_1.1.0
>
>
> > conflicts(detail = TRUE)
> $.GlobalEnv
> [1] "iris"
>
> $`package:dplyr`
>  [1] "%>%"           "%>%"           "add_row"       "as_data_frame"
> "as_tibble"     "data_frame"
>  [7] "data_frame_"   "frame_data"    "glimpse"       "lst"
>  "lst_"          "tbl_sum"
> [13] "tibble"        "tribble"       "trunc_mat"     "type_sum"
> "filter"        "lag"
> [19] "intersect"     "setdiff"       "setequal"      "union"
>
> $`package:purrr`
> [1] "%>%" "%>%"
>
> $`package:tidyr`
> [1] "%>%" "%>%"
>
> $`package:tibble`
>  [1] "add_row"       "as_data_frame" "as_tibble"     "data_frame"
> "data_frame_"   "frame_data"
>  [7] "glimpse"       "lst"           "lst_"          "tbl_sum"
>  "tibble"        "tribble"
> [13] "trunc_mat"     "type_sum"
>
> $`package:ggplot2`
> [1] "Position"
>
> $`package:stats`
> [1] "filter" "lag"
>
> $`package:datasets`
> [1] "iris"
>
> $`package:methods`
> [1] "body<-"    "kronecker"
>
> $`package:base`
> [1] "body<-"    "intersect" "kronecker" "Position"  "setdiff"   "setequal"
> "union"
>
>
> How can I solve this problem?
> Thanks.
>
> --
> Zeki ?atav
> zekicatav.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From zcatav at gmail.com  Wed Nov  8 12:26:42 2017
From: zcatav at gmail.com (=?UTF-8?Q?Zeki_=C3=87ATAV?=)
Date: Wed, 8 Nov 2017 13:26:42 +0200
Subject: [R] Ggplot error
In-Reply-To: <536983251.4314313.1510138375207@mail.yahoo.com>
References: <CAP6VsR+so0tQLMbh+1VH2Z1jHiq73Y8C9+95KaeLXjvgUJ5SUg@mail.gmail.com>
 <CAGgJW77ekPo7SXhhYSHWnUjOYtDgVXzijnLdOsOUY2S_GhfXHA@mail.gmail.com>
 <536983251.4314313.1510138375207@mail.yahoo.com>
Message-ID: <CAP6VsRLR0x-O3A+G6cUAnwvtiHASA4kvN+iD-ovMpMEMkHcrhA@mail.gmail.com>

Thanks,
I think, I found the problem. It seems to related locale setting.
If I start with 'LANG=C R' everything's good.

--
Zeki ?atav
zekicatav.com

On Nov 8, 2017 1:56 PM, "John Kane" <jrkrideau at yahoo.ca> wrote:

I get the same result as Eric  with
R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 17.04

It looks like you have "tidyverse" loaded so I tried it with just ggplot2
loaded and with tidyverse loaded.

On Wednesday, November 8, 2017, 4:16:14 AM EST, Eric Berger <
ericjberger at gmail.com> wrote:


I was not able to reproduce this problem. I tried two environments
1. Ubuntu 14.04.5 LTS, R version 3.4.2 (same R version as yours)
2. Windows 10, same R version



On Wed, Nov 8, 2017 at 9:50 AM, Zeki ?ATAV <zcatav at gmail.com> wrote:

> Hello,
> I've an error recently.
>
> ggplot(data = mtcars, aes(x= wt, y= mpg)) + geom_line()
> Error: Found object is not a stat.
>
> > sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.3 LTS
>
> Matrix products: default
> BLAS: /usr/lib/openblas-base/libblas.so.3
> LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>
> locale:
>  [1] LC_CTYPE=tr_TR.UTF-8      LC_NUMERIC=C
>  LC_TIME=tr_TR.UTF-8
>  [4] LC_COLLATE=tr_TR.UTF-8    LC_MONETARY=tr_TR.UTF-8
> LC_MESSAGES=tr_TR.UTF-8
>  [7] LC_PAPER=tr_TR.UTF-8      LC_NAME=C                  LC_ADDRESS=C
>
> [10] LC_TELEPHONE=C            LC_MEASUREMENT=tr_TR.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats    graphics  grDevices utils    datasets  methods  base
>
> other attached packages:
> [1] dplyr_0.7.4    purrr_0.2.4    readr_1.1.1    tidyr_0.7.2
>  tibble_1.3.4    tidyverse_1.1.1
> [7] ggplot2_2.2.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.13      lubridate_1.7.1    lattice_0.20-35    class_7.3-14
>      assertthat_0.2.0
>  [6] ipred_0.9-6        psych_1.7.8        foreach_1.4.3      R6_2.2.2
>      cellranger_1.1.0
> [11] plyr_1.8.4        stats4_3.4.2      httr_1.3.1        rlang_0.1.4
>      lazyeval_0.2.1
> [16] caret_6.0-77      readxl_1.0.0      kernlab_0.9-25    rpart_4.1-11
>      Matrix_1.2-11
> [21] splines_3.4.2      CVST_0.2-1        ddalpha_1.3.1      gower_0.1.2
>      stringr_1.2.0
> [26] foreign_0.8-69    munsell_0.4.3      broom_0.4.2
> compiler_3.4.2    modelr_0.1.1
> [31] pkgconfig_2.0.1    mnormt_1.5-5      dimRed_0.1.0      nnet_7.3-12
>      prodlim_1.6.1
> [36] DRR_0.0.2          codetools_0.2-15  RcppRoll_0.2.2    withr_2.1.0
>      MASS_7.3-47
> [41] recipes_0.1.0      ModelMetrics_1.1.0 grid_3.4.2        nlme_3.1-131
>      jsonlite_1.5
> [46] gtable_0.2.0      magrittr_1.5      scales_0.5.0
>  stringi_1.1.5      reshape2_1.4.2
> [51] bindrcpp_0.2      timeDate_3012.100  robustbase_0.92-8  xml2_1.1.1
>      lava_1.5.1
> [56] iterators_1.0.8    tools_3.4.2        forcats_0.2.0      glue_1.2.0
>      DEoptimR_1.0-8
> [61] sfsmisc_1.1-1      hms_0.3            parallel_3.4.2
>  survival_2.41-3    yaml_2.1.14
> [66] colorspace_1.3-2  rvest_0.3.2        bindr_0.1          haven_1.1.0
>
>
> > conflicts(detail = TRUE)
> $.GlobalEnv
> [1] "iris"
>
> $`package:dplyr`
>  [1] "%>%"          "%>%"          "add_row"      "as_data_frame"
> "as_tibble"    "data_frame"
>  [7] "data_frame_"  "frame_data"    "glimpse"      "lst"
>  "lst_"          "tbl_sum"
> [13] "tibble"        "tribble"      "trunc_mat"    "type_sum"
> "filter"        "lag"
> [19] "intersect"    "setdiff"      "setequal"      "union"
>
> $`package:purrr`
> [1] "%>%" "%>%"
>
> $`package:tidyr`
> [1] "%>%" "%>%"
>
> $`package:tibble`
>  [1] "add_row"      "as_data_frame" "as_tibble"    "data_frame"
> "data_frame_"  "frame_data"
>  [7] "glimpse"      "lst"          "lst_"          "tbl_sum"
>  "tibble"        "tribble"
> [13] "trunc_mat"    "type_sum"
>
> $`package:ggplot2`
> [1] "Position"
>
> $`package:stats`
> [1] "filter" "lag"
>
> $`package:datasets`
> [1] "iris"
>
> $`package:methods`
> [1] "body<-"    "kronecker"
>
> $`package:base`
> [1] "body<-"    "intersect" "kronecker" "Position"  "setdiff"  "setequal"
> "union"
>
>
> How can I solve this problem?
> Thanks.
>
> --
> Zeki ?atav
> zekicatav.com
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Nov  8 13:17:04 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 8 Nov 2017 07:17:04 -0500
Subject: [R] Problem with r project in ubuntu xenial
In-Reply-To: <CADwjDboKa98-8JC8Cig0cW4Zn6L2TB+v6q5ogycQkVztNDnWxw@mail.gmail.com>
References: <CADwjDbo-i+uv9yY=u20UoLJgKKHNx25RN3EFFNvUGiQfntiHxg@mail.gmail.com>
 <C6AB1755-59FD-4C76-8D7B-2D0EF0B75412@gmail.com>
 <B4DBC5FF-AA98-440D-92C7-D6792D44B568@comcast.net>
 <CADwjDbpCtP9MR-GKnsEo2HCARGz7WhQjxO4zZOOVLDxOW305Mw@mail.gmail.com>
 <CADwjDboKa98-8JC8Cig0cW4Zn6L2TB+v6q5ogycQkVztNDnWxw@mail.gmail.com>
Message-ID: <CA+vqiLFJ_CAs3jt7YhtD9N9gmb52z2W7EDXgRSK0sTGxytQ_FQ@mail.gmail.com>

On Tue, Nov 7, 2017 at 6:46 PM, George Balas <gbalas07 at gmail.com> wrote:
> For anyone who sees this conversation.
>
> There is a bug in installation of igraph in R language in Ubuntu. There is
> a solution in stackoverflow.

A link would be nice.

 We have to use the devtools. Write this code:
> install.packages("devtools")
> library(devtools)
> install_github("igraph/rigraph")

This is a temporary work-around that is only needed until igraph is
updated in CRAN. The bug report is at
https://github.com/igraph/rigraph/issues/234

>
> If there are errors installing devtools just install any package that
> comments.

I don't follow this part.

Best,
Ista

>
> On Nov 5, 2017 00:07, "George Balas" <gbalas07 at gmail.com> wrote:
>
>> -Well it seems that it is getting "el_GR.UTF-8" but still I am not able
>> to read files written in greek, there are only "????" instead of letters.
>> -Also, I forgot to mention that I do load igraph library when I try "graph_from_adjacency_matrix".
>> When I check igraph in packages dialog I can not see functions with
>> underscores between words, only dots.
>>
>> 2017-11-04 2:22 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>>
>>>
>>> > On Nov 3, 2017, at 5:09 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>>> >
>>> >
>>> >> On 3 Nov 2017, at 23:39 , George Balas <gbalas07 at gmail.com> wrote:
>>> >>
>>> >> I have a problem with R in Ubuntu 16.04. I do not know if it is mine
>>> pc or
>>> >> general problem but I was not able to find solution on Internet.
>>> >> First of all I can not change locale to greek by getting this message:
>>> >> "In Sys.setlocale("LC_CTYPE", "Greek") :
>>> >> OS reports request to set locale to "Greek" cannot be honored"
>>> >
>>> > The Greek locale is likely not called "Greek" outside of Windows. More
>>> likely "el_GR.UTF-8" or thereabouts (check your locale database, I'm on a
>>> Mac). These things are not standardized across platforms.
>>> >
>>>
>>> Also
>>>
>>> From help(locales): Attempts to change the character set by
>>> Sys.setlocale("LC_CTYPE") that implies a different character set during a
>>> session may not work and are likely to lead to some confusion because it
>>> may not affect the native encoding.
>>>
>>>
>>> >> Second and more serious is that I can not use some functions like
>>> >> graph_from_adjacency_matrix or print_all I get these messeges:
>>> >> "could not find function "graph_from_adjacency_matrix""
>>> >> "could not find function "print_all"".
>>> >
>>> > Missing library(igraph)?
>>> >
>>> > -pd
>>> >
>>> >> I am using R version 3.4.2 (2017-09-28) -- "Short Summer" either on
>>> rstudio
>>> >> or ubuntu terminal.
>>> >> On my pc I also run win 10 with the same installs and I do not have the
>>> >> above problems, but I work on ubuntu and can not change Os all the
>>> time.
>>> >> Please help me.
>>> >>
>>> >> Thank you for your time,
>>> >> George
>>> >> gbalas07 at gmail.com
>>> >>
>>> >>      [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > --
>>> > Peter Dalgaard, Professor,
>>> > Center for Statistics, Copenhagen Business School
>>> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> > Phone: (+45)38153501
>>> > Office: A 4.23
>>> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>>  -Gehm's Corollary to Clarke's Third Law
>>>
>>>
>>>
>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Wed Nov  8 13:54:22 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 8 Nov 2017 07:54:22 -0500
Subject: [R] Adding Records to a Table in R
In-Reply-To: <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
References: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
 <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
Message-ID: <CAMOcQfN3Mza1ETXUJ+gZH3FhUed9ZkA1scEBaanfwOZC=hrAwA@mail.gmail.com>

Dear Eric, thank you for your kind reply,

Assume dataset1Frame is the table containing the missing dates,

and TransitDateFrame <- seq(as.Date(dataset1Frame[1,1]),
as.Date(dataset1Frame[nrow(dataset1Frame),1]), "months")

#dataset1Frame is basically reading some fields  from a SQL Server table,
the first one being the date

#here dataset1Frame[1,1] is the first date that appears in the table
#dataset1Frame[nrow(dataset1Frame),1] is the last date available in the
table

if(nrow(dataset1Frame)!=nrow(TransitDateFrame)){
    for(i in 1:nrow(dataset1Frame)){
        if(!TransitDateFrame[i,1] %in% dataset1Frame){
            dataset1Frame <- rbind(dataset1Frame,
TransitDateFrame[i,])}else{
                dataset1Frame}
    }
}

I used this code but didn?t work, maybe I am doing something wrong here?

Best regards,

Paul

2017-11-01 15:21 GMT-05:00 Eric Berger <ericjberger at gmail.com>:

> Hi Paul,
>
> #First I set up some sample data since I don't have a copy of your data
> dtOrig <- as.Date( c("1985-04-01","1985-07-01","1985-12-01","1986-04-01"))
> dfOrig <- data.frame( TransitDate=dtOrig, Transits=c(100,100,500,325),
> CargoTons=c(1000,1080,3785,4200) )
>
> #Generate the complete set of dates as a data frame
> dfDates<- data.frame( TransitDate=seq(from=as.Date("1985-04-01"),by="1
> month",length=13) )
>
> # do the merge adding the "missing" rows (where NA will appear)
> dfNew  <- merge(dfDates, dfOrig, by="TransitDate", all.x=TRUE )
>
> # replace the NA's by zero
> dfNew[is.na(dfNew)] <- 0
>
> HTH,
> Eric
>
>
> On Wed, Nov 1, 2017 at 9:45 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear R friends,
>>
>> I am currently working with time series data, and I have a table(as data
>> frame) that has looks like this (TransitDate are in format = "%e-%B-%Y") :
>>
>> TransitDate       Transits      CargoTons
>> 1985-04-01        100            2500
>> 1985-05-01        135            4500
>> 1985-06-01        120            1750
>> 1985-07-01        100            3750
>> 1985-08-01        200            1250
>>
>> The problem is, that there are several periods that don?t exist in the
>> table, so it has the following behavior:
>>
>> TransitDate        Transits      CargoTons
>> 1985-04-01        100             1000
>> 1985-07-01        100             1080
>> 1985-12-01        500             3785
>> 1986-04-01        325             4200
>> .
>> .
>> 2017-09-01        400             2350 (*this is the last observation)
>>
>> You can see in the last table fragment that the series jumps from
>> 1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01 making
>> the
>> time series quite irregular (non-constant chronologically speaking).
>>
>> What I want to do is create a dummy table that has the sequence from the
>> first observation (1985-04-01) up to the last one (2017-09-01) and then
>> develop a code that checks if the dates contained in the dummy table exist
>> in the original table, if they don?t exist then add those dates and put
>> zeroes on the fields.
>>
>> How can I achieve this?
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Wed Nov  8 14:46:12 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 8 Nov 2017 08:46:12 -0500
Subject: [R] Adding Records to a Table in R
In-Reply-To: <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
References: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
 <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
Message-ID: <CAMOcQfMdOpYcEWqSmRa_6ER2CrEXGFnAh_5FNMf-baNrRq8HqA@mail.gmail.com>

Dear Eric,

Hope you are doing great. I also tried the following:

#First I created the complete date sequence

TransitDateFrame <- data.frame(TransitDate=seq(as.Date(dataset1[1,1]),
as.Date(dataset1[nrow(dataset1),1]), by = "month"))

#Then I did the merging

 dataset1NEW <- merge(TransitDateFrame, dataset1, by="TransitDate",
all.x=TRUE)

Now it has, as expected the total number of rows. The problem is, it filled
absolutely everything with NAs, and this shouldn?t be the case since there
are dates that actually have data.

why is this happening?

I am attaching the dataset1 table as a .csv document for your reference.
Basically what I want is to bring all the values in dataset1 and only add
the dates missing with value 0.

Best regards,

Paul

2017-11-01 15:21 GMT-05:00 Eric Berger <ericjberger at gmail.com>:

> Hi Paul,
>
> #First I set up some sample data since I don't have a copy of your data
> dtOrig <- as.Date( c("1985-04-01","1985-07-01","1985-12-01","1986-04-01"))
> dfOrig <- data.frame( TransitDate=dtOrig, Transits=c(100,100,500,325),
> CargoTons=c(1000,1080,3785,4200) )
>
> #Generate the complete set of dates as a data frame
> dfDates<- data.frame( TransitDate=seq(from=as.Date("1985-04-01"),by="1
> month",length=13) )
>
> # do the merge adding the "missing" rows (where NA will appear)
> dfNew  <- merge(dfDates, dfOrig, by="TransitDate", all.x=TRUE )
>
> # replace the NA's by zero
> dfNew[is.na(dfNew)] <- 0
>
> HTH,
> Eric
>
>
> On Wed, Nov 1, 2017 at 9:45 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear R friends,
>>
>> I am currently working with time series data, and I have a table(as data
>> frame) that has looks like this (TransitDate are in format = "%e-%B-%Y") :
>>
>> TransitDate       Transits      CargoTons
>> 1985-04-01        100            2500
>> 1985-05-01        135            4500
>> 1985-06-01        120            1750
>> 1985-07-01        100            3750
>> 1985-08-01        200            1250
>>
>> The problem is, that there are several periods that don?t exist in the
>> table, so it has the following behavior:
>>
>> TransitDate        Transits      CargoTons
>> 1985-04-01        100             1000
>> 1985-07-01        100             1080
>> 1985-12-01        500             3785
>> 1986-04-01        325             4200
>> .
>> .
>> 2017-09-01        400             2350 (*this is the last observation)
>>
>> You can see in the last table fragment that the series jumps from
>> 1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01 making
>> the
>> time series quite irregular (non-constant chronologically speaking).
>>
>> What I want to do is create a dummy table that has the sequence from the
>> first observation (1985-04-01) up to the last one (2017-09-01) and then
>> develop a code that checks if the dates contained in the dummy table exist
>> in the original table, if they don?t exist then add those dates and put
>> zeroes on the fields.
>>
>> How can I achieve this?
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

From petr.pikal at precheza.cz  Wed Nov  8 15:32:15 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 8 Nov 2017 14:32:15 +0000
Subject: [R] Adding Records to a Table in R
In-Reply-To: <CAMOcQfMdOpYcEWqSmRa_6ER2CrEXGFnAh_5FNMf-baNrRq8HqA@mail.gmail.com>
References: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
 <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
 <CAMOcQfMdOpYcEWqSmRa_6ER2CrEXGFnAh_5FNMf-baNrRq8HqA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8B3C@SRVEXCHCM301.precheza.cz>

Hi

Instead of attachments copy directly result of dput(TransitDateFrame) and dput(dataset1) to your email. Or, if your data have more than about 20 rows you could copy only part of it.

dput(TransitDateFrame[,1:20])
dput(dataset1[,1:20])

Only with this approach we can evaluate your data in all aspects and provide correct answer.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
> Sent: Wednesday, November 8, 2017 2:46 PM
> To: Eric Berger <ericjberger at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Adding Records to a Table in R
>
> Dear Eric,
>
> Hope you are doing great. I also tried the following:
>
> #First I created the complete date sequence
>
> TransitDateFrame <- data.frame(TransitDate=seq(as.Date(dataset1[1,1]),
> as.Date(dataset1[nrow(dataset1),1]), by = "month"))
>
> #Then I did the merging
>
>  dataset1NEW <- merge(TransitDateFrame, dataset1, by="TransitDate",
> all.x=TRUE)
>
> Now it has, as expected the total number of rows. The problem is, it filled
> absolutely everything with NAs, and this shouldn?t be the case since there are
> dates that actually have data.
>
> why is this happening?
>
> I am attaching the dataset1 table as a .csv document for your reference.
> Basically what I want is to bring all the values in dataset1 and only add the
> dates missing with value 0.
>
> Best regards,
>
> Paul
>
> 2017-11-01 15:21 GMT-05:00 Eric Berger <ericjberger at gmail.com>:
>
> > Hi Paul,
> >
> > #First I set up some sample data since I don't have a copy of your
> > data dtOrig <- as.Date(
> > c("1985-04-01","1985-07-01","1985-12-01","1986-04-01"))
> > dfOrig <- data.frame( TransitDate=dtOrig, Transits=c(100,100,500,325),
> > CargoTons=c(1000,1080,3785,4200) )
> >
> > #Generate the complete set of dates as a data frame
> > dfDates<- data.frame( TransitDate=seq(from=as.Date("1985-04-01"),by="1
> > month",length=13) )
> >
> > # do the merge adding the "missing" rows (where NA will appear) dfNew
> > <- merge(dfDates, dfOrig, by="TransitDate", all.x=TRUE )
> >
> > # replace the NA's by zero
> > dfNew[is.na(dfNew)] <- 0
> >
> > HTH,
> > Eric
> >
> >
> > On Wed, Nov 1, 2017 at 9:45 PM, Paul Bernal <paulbernal07 at gmail.com>
> > wrote:
> >
> >> Dear R friends,
> >>
> >> I am currently working with time series data, and I have a table(as
> >> data
> >> frame) that has looks like this (TransitDate are in format = "%e-%B-%Y") :
> >>
> >> TransitDate       Transits      CargoTons
> >> 1985-04-01        100            2500
> >> 1985-05-01        135            4500
> >> 1985-06-01        120            1750
> >> 1985-07-01        100            3750
> >> 1985-08-01        200            1250
> >>
> >> The problem is, that there are several periods that don?t exist in
> >> the table, so it has the following behavior:
> >>
> >> TransitDate        Transits      CargoTons
> >> 1985-04-01        100             1000
> >> 1985-07-01        100             1080
> >> 1985-12-01        500             3785
> >> 1986-04-01        325             4200
> >> .
> >> .
> >> 2017-09-01        400             2350 (*this is the last observation)
> >>
> >> You can see in the last table fragment that the series jumps from
> >> 1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01
> >> making the time series quite irregular (non-constant chronologically
> >> speaking).
> >>
> >> What I want to do is create a dummy table that has the sequence from
> >> the first observation (1985-04-01) up to the last one (2017-09-01)
> >> and then develop a code that checks if the dates contained in the
> >> dummy table exist in the original table, if they don?t exist then add
> >> those dates and put zeroes on the fields.
> >>
> >> How can I achieve this?
> >>
> >> Any help will be greatly appreciated,
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >
> >
> >
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Nov  8 15:43:27 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 8 Nov 2017 14:43:27 +0000
Subject: [R] Adding Records to a Table in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8B3C@SRVEXCHCM301.precheza.cz>
References: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
 <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
 <CAMOcQfMdOpYcEWqSmRa_6ER2CrEXGFnAh_5FNMf-baNrRq8HqA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8B3C@SRVEXCHCM301.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8B5D@SRVEXCHCM301.precheza.cz>

Sorry, I was too quick

Should be
dput(TransitDateFrame[1:20,])
dput(dataset1[1:20, ])

Cheers
Petr

> Hi
>
> Instead of attachments copy directly result of dput(TransitDateFrame) and
> dput(dataset1) to your email. Or, if your data have more than about 20 rows
> you could copy only part of it.
>
> dput(TransitDateFrame[,1:20])
> dput(dataset1[,1:20])


>
> Only with this approach we can evaluate your data in all aspects and provide
> correct answer.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> > Bernal
> > Sent: Wednesday, November 8, 2017 2:46 PM
> > To: Eric Berger <ericjberger at gmail.com>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Adding Records to a Table in R
> >
> > Dear Eric,
> >
> > Hope you are doing great. I also tried the following:
> >
> > #First I created the complete date sequence
> >
> > TransitDateFrame <- data.frame(TransitDate=seq(as.Date(dataset1[1,1]),
> > as.Date(dataset1[nrow(dataset1),1]), by = "month"))
> >
> > #Then I did the merging
> >
> >  dataset1NEW <- merge(TransitDateFrame, dataset1, by="TransitDate",
> > all.x=TRUE)
> >
> > Now it has, as expected the total number of rows. The problem is, it
> > filled absolutely everything with NAs, and this shouldn?t be the case
> > since there are dates that actually have data.
> >
> > why is this happening?
> >
> > I am attaching the dataset1 table as a .csv document for your reference.
> > Basically what I want is to bring all the values in dataset1 and only
> > add the dates missing with value 0.
> >
> > Best regards,
> >
> > Paul
> >
> > 2017-11-01 15:21 GMT-05:00 Eric Berger <ericjberger at gmail.com>:
> >
> > > Hi Paul,
> > >
> > > #First I set up some sample data since I don't have a copy of your
> > > data dtOrig <- as.Date(
> > > c("1985-04-01","1985-07-01","1985-12-01","1986-04-01"))
> > > dfOrig <- data.frame( TransitDate=dtOrig,
> > > Transits=c(100,100,500,325),
> > > CargoTons=c(1000,1080,3785,4200) )
> > >
> > > #Generate the complete set of dates as a data frame
> > > dfDates<- data.frame(
> > > TransitDate=seq(from=as.Date("1985-04-01"),by="1
> > > month",length=13) )
> > >
> > > # do the merge adding the "missing" rows (where NA will appear)
> > > dfNew
> > > <- merge(dfDates, dfOrig, by="TransitDate", all.x=TRUE )
> > >
> > > # replace the NA's by zero
> > > dfNew[is.na(dfNew)] <- 0
> > >
> > > HTH,
> > > Eric
> > >
> > >
> > > On Wed, Nov 1, 2017 at 9:45 PM, Paul Bernal <paulbernal07 at gmail.com>
> > > wrote:
> > >
> > >> Dear R friends,
> > >>
> > >> I am currently working with time series data, and I have a table(as
> > >> data
> > >> frame) that has looks like this (TransitDate are in format = "%e-%B-%Y") :
> > >>
> > >> TransitDate       Transits      CargoTons
> > >> 1985-04-01        100            2500
> > >> 1985-05-01        135            4500
> > >> 1985-06-01        120            1750
> > >> 1985-07-01        100            3750
> > >> 1985-08-01        200            1250
> > >>
> > >> The problem is, that there are several periods that don?t exist in
> > >> the table, so it has the following behavior:
> > >>
> > >> TransitDate        Transits      CargoTons
> > >> 1985-04-01        100             1000
> > >> 1985-07-01        100             1080
> > >> 1985-12-01        500             3785
> > >> 1986-04-01        325             4200
> > >> .
> > >> .
> > >> 2017-09-01        400             2350 (*this is the last observation)
> > >>
> > >> You can see in the last table fragment that the series jumps from
> > >> 1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01
> > >> making the time series quite irregular (non-constant
> > >> chronologically speaking).
> > >>
> > >> What I want to do is create a dummy table that has the sequence
> > >> from the first observation (1985-04-01) up to the last one
> > >> (2017-09-01) and then develop a code that checks if the dates
> > >> contained in the dummy table exist in the original table, if they
> > >> don?t exist then add those dates and put zeroes on the fields.
> > >>
> > >> How can I achieve this?
> > >>
> > >> Any help will be greatly appreciated,
> > >>
> > >> Best regards,
> > >>
> > >> Paul
> > >>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ericjberger at gmail.com  Wed Nov  8 15:44:07 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 8 Nov 2017 16:44:07 +0200
Subject: [R] Adding Records to a Table in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8B3C@SRVEXCHCM301.precheza.cz>
References: <CAMOcQfPLt9x40fEKFHfK9FLw7AWQAJwrn6-D+7HqXmr4Qmk=+g@mail.gmail.com>
 <CAGgJW74LE6nv8gyYqx9Ni-5Az3dnCPafxzZ0E_krKGUe7PpJ8g@mail.gmail.com>
 <CAMOcQfMdOpYcEWqSmRa_6ER2CrEXGFnAh_5FNMf-baNrRq8HqA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8B3C@SRVEXCHCM301.precheza.cz>
Message-ID: <CAGgJW77eLY+3SY0NJLu4RZue3dWLWZ6XV3_atae75wTzkTTPqA@mail.gmail.com>

Hi Paul,
The following worked for me:

library(lubridate)
dataset1 <- read.csv("dataset1.csv",stringsAsFactors=FALSE)
dataset1$TransitDate <- mdy(dataset1$TransitDate)
TransitDateFrame <- data.frame(TransitDate=seq(as.Date("1985-10-01"),
as.Date("2017-10-01"), by = "month"))
dataset1NEW <- merge(TransitDateFrame, dataset1, by="TransitDate",
all.x=TRUE)

HTH,
Eric



On Wed, Nov 8, 2017 at 4:32 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Instead of attachments copy directly result of dput(TransitDateFrame) and
> dput(dataset1) to your email. Or, if your data have more than about 20 rows
> you could copy only part of it.
>
> dput(TransitDateFrame[,1:20])
> dput(dataset1[,1:20])
>
> Only with this approach we can evaluate your data in all aspects and
> provide correct answer.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Bernal
> > Sent: Wednesday, November 8, 2017 2:46 PM
> > To: Eric Berger <ericjberger at gmail.com>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Adding Records to a Table in R
> >
> > Dear Eric,
> >
> > Hope you are doing great. I also tried the following:
> >
> > #First I created the complete date sequence
> >
> > TransitDateFrame <- data.frame(TransitDate=seq(as.Date(dataset1[1,1]),
> > as.Date(dataset1[nrow(dataset1),1]), by = "month"))
> >
> > #Then I did the merging
> >
> >  dataset1NEW <- merge(TransitDateFrame, dataset1, by="TransitDate",
> > all.x=TRUE)
> >
> > Now it has, as expected the total number of rows. The problem is, it
> filled
> > absolutely everything with NAs, and this shouldn?t be the case since
> there are
> > dates that actually have data.
> >
> > why is this happening?
> >
> > I am attaching the dataset1 table as a .csv document for your reference.
> > Basically what I want is to bring all the values in dataset1 and only
> add the
> > dates missing with value 0.
> >
> > Best regards,
> >
> > Paul
> >
> > 2017-11-01 15:21 GMT-05:00 Eric Berger <ericjberger at gmail.com>:
> >
> > > Hi Paul,
> > >
> > > #First I set up some sample data since I don't have a copy of your
> > > data dtOrig <- as.Date(
> > > c("1985-04-01","1985-07-01","1985-12-01","1986-04-01"))
> > > dfOrig <- data.frame( TransitDate=dtOrig, Transits=c(100,100,500,325),
> > > CargoTons=c(1000,1080,3785,4200) )
> > >
> > > #Generate the complete set of dates as a data frame
> > > dfDates<- data.frame( TransitDate=seq(from=as.Date("1985-04-01"),by="1
> > > month",length=13) )
> > >
> > > # do the merge adding the "missing" rows (where NA will appear) dfNew
> > > <- merge(dfDates, dfOrig, by="TransitDate", all.x=TRUE )
> > >
> > > # replace the NA's by zero
> > > dfNew[is.na(dfNew)] <- 0
> > >
> > > HTH,
> > > Eric
> > >
> > >
> > > On Wed, Nov 1, 2017 at 9:45 PM, Paul Bernal <paulbernal07 at gmail.com>
> > > wrote:
> > >
> > >> Dear R friends,
> > >>
> > >> I am currently working with time series data, and I have a table(as
> > >> data
> > >> frame) that has looks like this (TransitDate are in format =
> "%e-%B-%Y") :
> > >>
> > >> TransitDate       Transits      CargoTons
> > >> 1985-04-01        100            2500
> > >> 1985-05-01        135            4500
> > >> 1985-06-01        120            1750
> > >> 1985-07-01        100            3750
> > >> 1985-08-01        200            1250
> > >>
> > >> The problem is, that there are several periods that don?t exist in
> > >> the table, so it has the following behavior:
> > >>
> > >> TransitDate        Transits      CargoTons
> > >> 1985-04-01        100             1000
> > >> 1985-07-01        100             1080
> > >> 1985-12-01        500             3785
> > >> 1986-04-01        325             4200
> > >> .
> > >> .
> > >> 2017-09-01        400             2350 (*this is the last observation)
> > >>
> > >> You can see in the last table fragment that the series jumps from
> > >> 1985-04-01 to 1985-07-01, then it jumps from there to 1985-12-01
> > >> making the time series quite irregular (non-constant chronologically
> > >> speaking).
> > >>
> > >> What I want to do is create a dummy table that has the sequence from
> > >> the first observation (1985-04-01) up to the last one (2017-09-01)
> > >> and then develop a code that checks if the dates contained in the
> > >> dummy table exist in the original table, if they don?t exist then add
> > >> those dates and put zeroes on the fields.
> > >>
> > >> How can I achieve this?
> > >>
> > >> Any help will be greatly appreciated,
> > >>
> > >> Best regards,
> > >>
> > >> Paul
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posti
> > >> ng-guide.html and provide commented, minimal, self-contained,
> > >> reproducible code.
> > >
> > >
> > >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Wed Nov  8 11:50:46 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Wed, 8 Nov 2017 10:50:46 +0000 (UTC)
Subject: [R] dendrogram adjustment in heatmap.2
References: <118412143.5253056.1510138247000.ref@mail.yahoo.com>
Message-ID: <118412143.5253056.1510138247000@mail.yahoo.com>

Dear R Community,
Is there a way to adjust the line width of the dendrogram in heat map.2 function? I tried "lwd", but it didn't work...
Also, is there a way to adjust the general height/width/position of the dendrogram using heatmap.2 function? I feel the portion of the dendrogram is huge compared with the overall graph. I would like to squeeze them a bit.
Thank you very much for any inputs!
Kind regards,
Ace


	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Wed Nov  8 11:52:55 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 8 Nov 2017 10:52:55 +0000 (UTC)
Subject: [R] Ggplot error
In-Reply-To: <CAGgJW77ekPo7SXhhYSHWnUjOYtDgVXzijnLdOsOUY2S_GhfXHA@mail.gmail.com>
References: <CAP6VsR+so0tQLMbh+1VH2Z1jHiq73Y8C9+95KaeLXjvgUJ5SUg@mail.gmail.com>
 <CAGgJW77ekPo7SXhhYSHWnUjOYtDgVXzijnLdOsOUY2S_GhfXHA@mail.gmail.com>
Message-ID: <536983251.4314313.1510138375207@mail.yahoo.com>

 I get the same result as Eric? withR version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 17.04
It looks like you have "tidyverse" loaded so I tried it with just ggplot2 loaded and with tidyverse loaded.? 

    On Wednesday, November 8, 2017, 4:16:14 AM EST, Eric Berger <ericjberger at gmail.com> wrote:  
 
 I was not able to reproduce this problem. I tried two environments
1. Ubuntu 14.04.5 LTS, R version 3.4.2 (same R version as yours)
2. Windows 10, same R version



On Wed, Nov 8, 2017 at 9:50 AM, Zeki ?ATAV <zcatav at gmail.com> wrote:

> Hello,
> I've an error recently.
>
> ggplot(data = mtcars, aes(x= wt, y= mpg)) + geom_line()
> Error: Found object is not a stat.
>
> > sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.3 LTS
>
> Matrix products: default
> BLAS: /usr/lib/openblas-base/libblas.so.3
> LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>
> locale:
>? [1] LC_CTYPE=tr_TR.UTF-8? ? ? LC_NUMERIC=C
>? LC_TIME=tr_TR.UTF-8
>? [4] LC_COLLATE=tr_TR.UTF-8? ? LC_MONETARY=tr_TR.UTF-8
> LC_MESSAGES=tr_TR.UTF-8
>? [7] LC_PAPER=tr_TR.UTF-8? ? ? LC_NAME=C? ? ? ? ? ? ? ? ? LC_ADDRESS=C
>
> [10] LC_TELEPHONE=C? ? ? ? ? ? LC_MEASUREMENT=tr_TR.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats? ? graphics? grDevices utils? ? datasets? methods? base
>
> other attached packages:
> [1] dplyr_0.7.4? ? purrr_0.2.4? ? readr_1.1.1? ? tidyr_0.7.2
>? tibble_1.3.4? ? tidyverse_1.1.1
> [7] ggplot2_2.2.1
>
> loaded via a namespace (and not attached):
>? [1] Rcpp_0.12.13? ? ? lubridate_1.7.1? ? lattice_0.20-35? ? class_7.3-14
>? ? ? assertthat_0.2.0
>? [6] ipred_0.9-6? ? ? ? psych_1.7.8? ? ? ? foreach_1.4.3? ? ? R6_2.2.2
>? ? ? cellranger_1.1.0
> [11] plyr_1.8.4? ? ? ? stats4_3.4.2? ? ? httr_1.3.1? ? ? ? rlang_0.1.4
>? ? ? lazyeval_0.2.1
> [16] caret_6.0-77? ? ? readxl_1.0.0? ? ? kernlab_0.9-25? ? rpart_4.1-11
>? ? ? Matrix_1.2-11
> [21] splines_3.4.2? ? ? CVST_0.2-1? ? ? ? ddalpha_1.3.1? ? ? gower_0.1.2
>? ? ? stringr_1.2.0
> [26] foreign_0.8-69? ? munsell_0.4.3? ? ? broom_0.4.2
> compiler_3.4.2? ? modelr_0.1.1
> [31] pkgconfig_2.0.1? ? mnormt_1.5-5? ? ? dimRed_0.1.0? ? ? nnet_7.3-12
>? ? ? prodlim_1.6.1
> [36] DRR_0.0.2? ? ? ? ? codetools_0.2-15? RcppRoll_0.2.2? ? withr_2.1.0
>? ? ? MASS_7.3-47
> [41] recipes_0.1.0? ? ? ModelMetrics_1.1.0 grid_3.4.2? ? ? ? nlme_3.1-131
>? ? ? jsonlite_1.5
> [46] gtable_0.2.0? ? ? magrittr_1.5? ? ? scales_0.5.0
>? stringi_1.1.5? ? ? reshape2_1.4.2
> [51] bindrcpp_0.2? ? ? timeDate_3012.100? robustbase_0.92-8? xml2_1.1.1
>? ? ? lava_1.5.1
> [56] iterators_1.0.8? ? tools_3.4.2? ? ? ? forcats_0.2.0? ? ? glue_1.2.0
>? ? ? DEoptimR_1.0-8
> [61] sfsmisc_1.1-1? ? ? hms_0.3? ? ? ? ? ? parallel_3.4.2
>? survival_2.41-3? ? yaml_2.1.14
> [66] colorspace_1.3-2? rvest_0.3.2? ? ? ? bindr_0.1? ? ? ? ? haven_1.1.0
>
>
> > conflicts(detail = TRUE)
> $.GlobalEnv
> [1] "iris"
>
> $`package:dplyr`
>? [1] "%>%"? ? ? ? ? "%>%"? ? ? ? ? "add_row"? ? ? "as_data_frame"
> "as_tibble"? ? "data_frame"
>? [7] "data_frame_"? "frame_data"? ? "glimpse"? ? ? "lst"
>? "lst_"? ? ? ? ? "tbl_sum"
> [13] "tibble"? ? ? ? "tribble"? ? ? "trunc_mat"? ? "type_sum"
> "filter"? ? ? ? "lag"
> [19] "intersect"? ? "setdiff"? ? ? "setequal"? ? ? "union"
>
> $`package:purrr`
> [1] "%>%" "%>%"
>
> $`package:tidyr`
> [1] "%>%" "%>%"
>
> $`package:tibble`
>? [1] "add_row"? ? ? "as_data_frame" "as_tibble"? ? "data_frame"
> "data_frame_"? "frame_data"
>? [7] "glimpse"? ? ? "lst"? ? ? ? ? "lst_"? ? ? ? ? "tbl_sum"
>? "tibble"? ? ? ? "tribble"
> [13] "trunc_mat"? ? "type_sum"
>
> $`package:ggplot2`
> [1] "Position"
>
> $`package:stats`
> [1] "filter" "lag"
>
> $`package:datasets`
> [1] "iris"
>
> $`package:methods`
> [1] "body<-"? ? "kronecker"
>
> $`package:base`
> [1] "body<-"? ? "intersect" "kronecker" "Position"? "setdiff"? "setequal"
> "union"
>
>
> How can I solve this problem?
> Thanks.
>
> --
> Zeki ?atav
> zekicatav.com
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From florian.oswald at gmail.com  Wed Nov  8 12:14:51 2017
From: florian.oswald at gmail.com (Florian Oswald)
Date: Wed, 8 Nov 2017 12:14:51 +0100
Subject: [R] Sharing an R installation via NFS on ubuntu cluster
Message-ID: <CAKezR-xiLjogz+YhtBMGvVWtOAehJstq_T=7NTgB2ZXj+zgoGw@mail.gmail.com>

hi all,

i want to share an R installation from a master node to several compute
nodes via NFS. all nodes run ubuntu 16.04. I tried building R from source
but hit a wall several times because of missing dependencies. So I am
looking for something that uses the usual apt-get install proceedure, but
would place the installation in the non-standard location. For context,
right now I would have to share all of

*root at master*:*~*  whereis R

R: /usr/bin/R /usr/lib/R /etc/R /usr/local/lib/R /usr/share/R
/usr/share/man/man1/R.1.gz

and I would like to install R into a new folder on the master node, say,
NFS_share, and share just that.

I found that `dpkg` has an option `--root=directory` to specify a non
standard install location for a debian package installation. but i'm not
even sure how this would work on ubuntu (can i install a debian packge on
ubuntu?!)

thanks for any help!
florian

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Nov  8 17:37:20 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 8 Nov 2017 11:37:20 -0500
Subject: [R] Sharing an R installation via NFS on ubuntu cluster
In-Reply-To: <CAKezR-xiLjogz+YhtBMGvVWtOAehJstq_T=7NTgB2ZXj+zgoGw@mail.gmail.com>
References: <CAKezR-xiLjogz+YhtBMGvVWtOAehJstq_T=7NTgB2ZXj+zgoGw@mail.gmail.com>
Message-ID: <CA+vqiLFdkR09o8DS6F-R=kw6ed_7o+VRw4p6b2YV+Qkuphtg8g@mail.gmail.com>

On Wed, Nov 8, 2017 at 6:14 AM, Florian Oswald <florian.oswald at gmail.com> wrote:
> hi all,
>
> i want to share an R installation from a master node to several compute
> nodes via NFS. all nodes run ubuntu 16.04. I tried building R from source
> but hit a wall several times because of missing dependencies.

apt-get build-dep r-base

should take care of that.

--Ista

So I am
> looking for something that uses the usual apt-get install proceedure, but
> would place the installation in the non-standard location. For context,
> right now I would have to share all of
>
> *root at master*:*~*  whereis R
>
> R: /usr/bin/R /usr/lib/R /etc/R /usr/local/lib/R /usr/share/R
> /usr/share/man/man1/R.1.gz
>
> and I would like to install R into a new folder on the master node, say,
> NFS_share, and share just that.
>
> I found that `dpkg` has an option `--root=directory` to specify a non
> standard install location for a debian package installation. but i'm not
> even sure how this would work on ubuntu (can i install a debian packge on
> ubuntu?!)
>
> thanks for any help!
> florian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Backer at uib.no  Wed Nov  8 19:28:09 2017
From: Backer at uib.no (Tom Backer Johnsen)
Date: Wed, 8 Nov 2017 19:28:09 +0100
Subject: [R] Missing information in source()
In-Reply-To: <5A0216B1.1040405@sapo.pt>
References: <884C82AC-89C7-4F40-8FE2-FDDF4423E2CB@uib.no>
 <5A0216B1.1040405@sapo.pt>
Message-ID: <23007921-4BA4-4BAD-ACD3-0B4FE1077E40@uib.no>

Hello

Thank you all for most useful responses.  I was looking for answers in the wrong place, that is why I have not responded before!

Tom Backer Johnsen

> On 7 Nov 2017, at 21:25, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Try
> 
> print(head(...))
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 07-11-2017 20:01, Tom Backer Johnsen escreveu:
>> Dear R-help,
>> 
>> I am running a Mac under Sierra, with R version 3.4.2 and RStudio 1.1.383.  When running head () or tail () on an object in a script using source (<script name>) nothing appears in the output file, but if I use these commands in the normal R window the normal output appears.
>> 
>> What am I doing wrong?
>> 
>> Tom Backer Johnsen
>> University of Bergen
>> Norway
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 


From reichmanj at sbcglobal.net  Thu Nov  9 00:05:13 2017
From: reichmanj at sbcglobal.net (Jeff Reichman	)
Date: Wed, 8 Nov 2017 17:05:13 -0600
Subject: [R] Help Converting Calendars
Message-ID: <000001d358e6$0b624bb0$2226e310$@sbcglobal.net>

R-Help

Trying  to convert a Gregorian calendar dataset to a Persian calendar
dataset.  But I end up with a list and not sure what to do.  For example ...

dates <- c("2017-10-1","2017-10-2","2017-10-3")
myData <- data.frame(dates)
myData$dates <- as.Date(myData$dates, format = "%Y-%m-%d")
> myData
       dates
1 2017-10-01
2 2017-10-02
3 2017-10-03
library(ConvCalendar)
p.dates <- as.OtherDate(myData$dates,"persian")
# after convering I get the following list
> p.dates
$day
[1]  9 10 11

$month
[1] 7 7 7

$year
[1] 1396 1396 1396

attr(,"row.names")
[1] 1 2 3
attr(,"class")
[1] "OtherDate"
attr(,"calendar")
[1] "persian"

How do I take that,  to end up with 

       dates	p_dates
1 2017-10-01	1396-7-9
2 2017-10-02	1396-7-10
3 2017-10-03	1396-7-11

Jeff Reichman
Penn State


From dcarlson at tamu.edu  Thu Nov  9 00:32:16 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 8 Nov 2017 23:32:16 +0000
Subject: [R] Help Converting Calendars
In-Reply-To: <000001d358e6$0b624bb0$2226e310$@sbcglobal.net>
References: <000001d358e6$0b624bb0$2226e310$@sbcglobal.net>
Message-ID: <7481af7033a241d4a2589710c711d009@exch-2p-mbx-w4.ads.tamu.edu>

How about

> p_dates <- paste0(p.dates[[3]], "-", p.dates[[2]], "-", p.dates[[1]])
> myData$p_dates <- p_dates
> print(myData, right=FALSE)
  dates      p_dates  
1 2017-10-01 1396-7-9 
2 2017-10-02 1396-7-10
3 2017-10-03 1396-7-11
> str(myData)
'data.frame':   3 obs. of  2 variables:
 $ dates  : Date, format: "2017-10-01" "2017-10-02" ...
 $ p_dates: chr  "1396-7-9" "1396-7-10" "1396-7-11"

But p_dates is a character field so it will not work with numeric expressions:

> with(myData, dates[3] - dates[1])
Time difference of 2 days
# But
> with(myData, p_dates[3] - p_dates[1])
Error in p_dates[3] - p_dates[1] : 
  non-numeric argument to binary operator

-----------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Reichman 
Sent: Wednesday, November 8, 2017 5:05 PM
To: r-help at r-project.org
Subject: [R] Help Converting Calendars

R-Help

Trying  to convert a Gregorian calendar dataset to a Persian calendar
dataset.  But I end up with a list and not sure what to do.  For example ...

dates <- c("2017-10-1","2017-10-2","2017-10-3")
myData <- data.frame(dates)
myData$dates <- as.Date(myData$dates, format = "%Y-%m-%d")
> myData
       dates
1 2017-10-01
2 2017-10-02
3 2017-10-03
library(ConvCalendar)
p.dates <- as.OtherDate(myData$dates,"persian")
# after convering I get the following list
> p.dates
$day
[1]  9 10 11

$month
[1] 7 7 7

$year
[1] 1396 1396 1396

attr(,"row.names")
[1] 1 2 3
attr(,"class")
[1] "OtherDate"
attr(,"calendar")
[1] "persian"

How do I take that,  to end up with 

       dates	p_dates
1 2017-10-01	1396-7-9
2 2017-10-02	1396-7-10
3 2017-10-03	1396-7-11

Jeff Reichman
Penn State

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Nov  9 01:10:11 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 9 Nov 2017 11:10:11 +1100
Subject: [R] Help Converting Calendars
In-Reply-To: <7481af7033a241d4a2589710c711d009@exch-2p-mbx-w4.ads.tamu.edu>
References: <000001d358e6$0b624bb0$2226e310$@sbcglobal.net>
 <7481af7033a241d4a2589710c711d009@exch-2p-mbx-w4.ads.tamu.edu>
Message-ID: <CA+8X3fVK2drFdz9HF3u9yhXnZNQY-UH9keKrrZPvQOFD1T4C1w@mail.gmail.com>

Or if you want a slightly prettier output:

formatDate<-function(x) {
 return(paste(x$year,formatC(x$month,width=2,flag=0),
 formatC(x$day,width=2,flag=0),sep="-"))
}
formatDate(p.dates)

Jim


On Thu, Nov 9, 2017 at 10:32 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> How about
>
>> p_dates <- paste0(p.dates[[3]], "-", p.dates[[2]], "-", p.dates[[1]])
>> myData$p_dates <- p_dates
>> print(myData, right=FALSE)
>   dates      p_dates
> 1 2017-10-01 1396-7-9
> 2 2017-10-02 1396-7-10
> 3 2017-10-03 1396-7-11
>> str(myData)
> 'data.frame':   3 obs. of  2 variables:
>  $ dates  : Date, format: "2017-10-01" "2017-10-02" ...
>  $ p_dates: chr  "1396-7-9" "1396-7-10" "1396-7-11"
>
> But p_dates is a character field so it will not work with numeric expressions:
>
>> with(myData, dates[3] - dates[1])
> Time difference of 2 days
> # But
>> with(myData, p_dates[3] - p_dates[1])
> Error in p_dates[3] - p_dates[1] :
>   non-numeric argument to binary operator
>
> -----------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Reichman
> Sent: Wednesday, November 8, 2017 5:05 PM
> To: r-help at r-project.org
> Subject: [R] Help Converting Calendars
>
> R-Help
>
> Trying  to convert a Gregorian calendar dataset to a Persian calendar
> dataset.  But I end up with a list and not sure what to do.  For example ...
>
> dates <- c("2017-10-1","2017-10-2","2017-10-3")
> myData <- data.frame(dates)
> myData$dates <- as.Date(myData$dates, format = "%Y-%m-%d")
>> myData
>        dates
> 1 2017-10-01
> 2 2017-10-02
> 3 2017-10-03
> library(ConvCalendar)
> p.dates <- as.OtherDate(myData$dates,"persian")
> # after convering I get the following list
>> p.dates
> $day
> [1]  9 10 11
>
> $month
> [1] 7 7 7
>
> $year
> [1] 1396 1396 1396
>
> attr(,"row.names")
> [1] 1 2 3
> attr(,"class")
> [1] "OtherDate"
> attr(,"calendar")
> [1] "persian"
>
> How do I take that,  to end up with
>
>        dates    p_dates
> 1 2017-10-01    1396-7-9
> 2 2017-10-02    1396-7-10
> 3 2017-10-03    1396-7-11
>
> Jeff Reichman
> Penn State
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From johnlukore at gmail.com  Thu Nov  9 04:39:59 2017
From: johnlukore at gmail.com (john lukore)
Date: Thu, 9 Nov 2017 11:39:59 +0800
Subject: [R] R-help
Message-ID: <CA+1JU67ZuS5Yg7s7o6nuYgUnpECmVaDu6fxB3QBc_6X5F=62uA@mail.gmail.com>

Generate a clustered pattern in [0; 1]2 as follows:

(a) Generate nc, say 20, independent cluster centres (which can be called
parents) that are distributed i.i.d. uniformly in the unit square;

 (b) then n daughters are assigned i.i.d. uniformly to these parents and
such that each daughter is located i.i.d. uniformly in a disk of radius r =
0:1 centred at her parent, under the periodic boundary conditions (i.e. the
square = a torus).


My attempt so far is:


set.seed(1) library(spatstat)

 n_parent <- 2

 n_daughter <- 4

r = 0.1

cnt <- n

W <- disc(radius=3, centre=c(0,0)) i <- 1

 while(i <= n_daughter){

d_x <- runif(1)

d_y <- runif(1)

if (d_x ^2+d_y^2 <r) {

 i = i+1}}


#need a condition here such that (d_x,d_y) lies in B(0,r)

 #where B(0,r) is a ball of center origin and of radius r

In above we should obtain one ball with n_daughters. Next step is to
generate parent centers and distribute the n_daughters in the ball into
n_parents.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Nov  9 09:37:02 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 9 Nov 2017 08:37:02 +0000
Subject: [R] R-help
In-Reply-To: <CA+1JU67ZuS5Yg7s7o6nuYgUnpECmVaDu6fxB3QBc_6X5F=62uA@mail.gmail.com>
References: <CA+1JU67ZuS5Yg7s7o6nuYgUnpECmVaDu6fxB3QBc_6X5F=62uA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8C5E@SRVEXCHCM301.precheza.cz>

Hi

it smells like a homework, this list has no homework policy.

Anyway, maybe the sample approach could be used.

Generate x,y coordinates - ?expand.grid
sample n centers - ?sample
select all points within defined area - ?point.in.polygon, package sp
select desired number of points - ?sample

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of john lukore
> Sent: Thursday, November 9, 2017 4:40 AM
> To: r-help at r-project.org
> Subject: [R] R-help
>
> Generate a clustered pattern in [0; 1]2 as follows:
>
> (a) Generate nc, say 20, independent cluster centres (which can be called
> parents) that are distributed i.i.d. uniformly in the unit square;
>
>  (b) then n daughters are assigned i.i.d. uniformly to these parents and such
> that each daughter is located i.i.d. uniformly in a disk of radius r =
> 0:1 centred at her parent, under the periodic boundary conditions (i.e. the
> square = a torus).
>
>
> My attempt so far is:
>
>
> set.seed(1) library(spatstat)
>
>  n_parent <- 2
>
>  n_daughter <- 4
>
> r = 0.1
>
> cnt <- n
>
> W <- disc(radius=3, centre=c(0,0)) i <- 1
>
>  while(i <= n_daughter){
>
> d_x <- runif(1)
>
> d_y <- runif(1)
>
> if (d_x ^2+d_y^2 <r) {
>
>  i = i+1}}
>
>
> #need a condition here such that (d_x,d_y) lies in B(0,r)
>
>  #where B(0,r) is a ball of center origin and of radius r
>
> In above we should obtain one ball with n_daughters. Next step is to generate
> parent centers and distribute the n_daughters in the ball into n_parents.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From florian.oswald at gmail.com  Thu Nov  9 11:07:16 2017
From: florian.oswald at gmail.com (Florian Oswald)
Date: Thu, 9 Nov 2017 11:07:16 +0100
Subject: [R] Sharing an R installation via NFS on ubuntu cluster
In-Reply-To: <CA+vqiLFdkR09o8DS6F-R=kw6ed_7o+VRw4p6b2YV+Qkuphtg8g@mail.gmail.com>
References: <CAKezR-xiLjogz+YhtBMGvVWtOAehJstq_T=7NTgB2ZXj+zgoGw@mail.gmail.com>
 <CA+vqiLFdkR09o8DS6F-R=kw6ed_7o+VRw4p6b2YV+Qkuphtg8g@mail.gmail.com>
Message-ID: <CAKezR-yb+2LxmHGzO7ofh+xg0QuSQE93v_Xzj_p+vzAPa5KPQg@mail.gmail.com>

I can install R with

sudo apt-get update
sudo apt-get install r-base


this is not my problem, and indeed, not my question. my question was how
could I share the resulting R installation over NFS? Do I have to export
every location where apt-get installs a component or can I force apt-get to
place the installation in a certain location?



On 8 November 2017 at 17:37, Ista Zahn <istazahn at gmail.com> wrote:

> On Wed, Nov 8, 2017 at 6:14 AM, Florian Oswald <florian.oswald at gmail.com>
> wrote:
> > hi all,
> >
> > i want to share an R installation from a master node to several compute
> > nodes via NFS. all nodes run ubuntu 16.04. I tried building R from source
> > but hit a wall several times because of missing dependencies.
>
> apt-get build-dep r-base
>
> should take care of that.
>
> --Ista
>
> So I am
> > looking for something that uses the usual apt-get install proceedure, but
> > would place the installation in the non-standard location. For context,
> > right now I would have to share all of
> >
> > *root at master*:*~*  whereis R
> >
> > R: /usr/bin/R /usr/lib/R /etc/R /usr/local/lib/R /usr/share/R
> > /usr/share/man/man1/R.1.gz
> >
> > and I would like to install R into a new folder on the master node, say,
> > NFS_share, and share just that.
> >
> > I found that `dpkg` has an option `--root=directory` to specify a non
> > standard install location for a debian package installation. but i'm not
> > even sure how this would work on ubuntu (can i install a debian packge on
> > ubuntu?!)
> >
> > thanks for any help!
> > florian
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cimentadaj at gmail.com  Thu Nov  9 00:02:53 2017
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Thu, 9 Nov 2017 00:02:53 +0100
Subject: [R] [R-pkgs] Release of ess 0.0.1
Message-ID: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw@mail.gmail.com>

Dear CRANers!

I'm happy to announce the release of ess 0.0.1 a package designed to
download data from the European Social Survey
<http://www.europeansocialsurvey.org/> directly into R as easily as
possible. It has a few helper functions to download rounds/waves, rounds
for a selected country and to show which rounds/countries are available.

This is an exciting moment for the release considering that just last week
the ESS released it's 8th round, which is already available in the package.
You can checkout some brief examples here
<https://twitter.com/cimentadaj/status/928394896700051461> or a more
detailed description in the vignette
<https://cran.r-project.org/web/packages/ess/vignettes/ess_r_stata_users.html>.
Bugs
and improvements can be issued in the Github repository
<https://github.com/cimentadaj/ess>. This is the first release and I'm sure
there's a lot of room for improvement.

Thanks!
-----------------------------------


Jorge Cimentada
*https://cimentadaj.github.io/ <https://cimentadaj.github.io/>*

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From massimo.bressan at arpa.veneto.it  Thu Nov  9 12:20:52 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 9 Nov 2017 12:20:52 +0100 (CET)
Subject: [R] weighted average grouped by variables
Message-ID: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>

hi all 

I have this dataframe (created as a reproducible example) 

mydf<-structure(list(date_time = structure(c(1508238000, 1508238000, 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""), 
direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c("A", "B"), class = "factor"), 
type = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class = "factor"), 
avg_speed = c(41.1029082774049, 40.3333333333333, 40.3157894736842, 36.0869565217391, 33.4065155807365, 37.6222222222222, 35.5), 
n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)), 
.Names = c("date_time", "direction", "type", "speed", "n_vehicles"), 
row.names = c(NA, -7L), 
class = "data.frame") 

mydf 

and I need to get to this final result 

mydf_final<-structure(list(date_time = structure(c(1508238000, 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""), 
type = structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class = "factor"), 
weighted_avg_speed = c(36.39029, 38.56521, 37.53333, 36.08696), 
n_vehicles = c(1153L,69L,45L,23L)), 
.Names = c("date_time", "type", "weighted_avg_speed", "n_vehicles"), 
row.names = c(NA, -4L), 
class = "data.frame") 

mydf_final 


my question: 
how to compute a weighted mean i.e. "weighted_avg_speed" 
from "speed" (the values whose weighted mean is to be computed) and "n_vehicles" (the weights) 
grouped by "date_time" and "type"? 

to be noted the complication of the case "motorcycle" (not present in both directions) 

any help for that? 

thank you 

max 



	[[alternative HTML version deleted]]


From istazahn at gmail.com  Thu Nov  9 13:08:33 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 9 Nov 2017 07:08:33 -0500
Subject: [R] Sharing an R installation via NFS on ubuntu cluster
In-Reply-To: <CAKezR-yb+2LxmHGzO7ofh+xg0QuSQE93v_Xzj_p+vzAPa5KPQg@mail.gmail.com>
References: <CAKezR-xiLjogz+YhtBMGvVWtOAehJstq_T=7NTgB2ZXj+zgoGw@mail.gmail.com>
 <CA+vqiLFdkR09o8DS6F-R=kw6ed_7o+VRw4p6b2YV+Qkuphtg8g@mail.gmail.com>
 <CAKezR-yb+2LxmHGzO7ofh+xg0QuSQE93v_Xzj_p+vzAPa5KPQg@mail.gmail.com>
Message-ID: <CA+vqiLFyEccrpRyKyUwKXQoOmQmL0e2VWm-_n6RPF3AjrUHS6w@mail.gmail.com>

On Nov 9, 2017 5:07 AM, "Florian Oswald" <florian.oswald at gmail.com> wrote:

I can install R with

sudo apt-get update
sudo apt-get install r-base


this is not my problem, and indeed, not my question.

my question was how could I share the resulting R installation over NFS? Do
I have to export every location where apt-get installs a component or can I
force apt-get to place the installation in a certain location?


Sounds like a question for an ubuntu forum, or r-sig-debian perhaps.



On 8 November 2017 at 17:37, Ista Zahn <istazahn at gmail.com> wrote:

> On Wed, Nov 8, 2017 at 6:14 AM, Florian Oswald <florian.oswald at gmail.com>
> wrote:
> > hi all,
> >
> > i want to share an R installation from a master node to several compute
> > nodes via NFS. all nodes run ubuntu 16.04. I tried building R from source
> > but hit a wall several times because of missing dependencies.
>
> apt-get build-dep r-base
>
> should take care of that.
>
> --Ista
>
> So I am
> > looking for something that uses the usual apt-get install proceedure, but
> > would place the installation in the non-standard location. For context,
> > right now I would have to share all of
> >
> > *root at master*:*~*  whereis R
> >
> > R: /usr/bin/R /usr/lib/R /etc/R /usr/local/lib/R /usr/share/R
> > /usr/share/man/man1/R.1.gz
> >
> > and I would like to install R into a new folder on the master node, say,
> > NFS_share, and share just that.
> >
> > I found that `dpkg` has an option `--root=directory` to specify a non
> > standard install location for a debian package installation. but i'm not
> > even sure how this would work on ubuntu (can i install a debian packge on
> > ubuntu?!)
> >
> > thanks for any help!
> > florian
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From massimo.bressan at arpa.veneto.it  Thu Nov  9 14:16:33 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 9 Nov 2017 14:16:33 +0100 (CET)
Subject: [R] weighted average grouped by variables
In-Reply-To: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>

Hello 

an update about my question: I worked out the following solution (with the package "dplyr") 

library(dplyr) 

mydf%>% 
mutate(speed_vehicles=n_vehicles*mydf$speed) %>% 
group_by(date_time,type) %>% 
summarise( 
sum_n_times_speed=sum(speed_vehicles), 
n_vehicles=sum(n_vehicles), 
vel=sum(speed_vehicles)/sum(n_vehicles) 
) 


In fact I was hoping to manage everything in a "one-go": i.e. without the need to create the "intermediate" variable called "speed_vehicles" and with the use of the function weighted.mean() 

any hints for a different approach much appreciated 

thanks 



Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <r-help at r-project.org> 
Inviato: Gioved?, 9 novembre 2017 12:20:52 
Oggetto: weighted average grouped by variables 

hi all 

I have this dataframe (created as a reproducible example) 

mydf<-structure(list(date_time = structure(c(1508238000, 1508238000, 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""), 
direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c("A", "B"), class = "factor"), 
type = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class = "factor"), 
avg_speed = c(41.1029082774049, 40.3333333333333, 40.3157894736842, 36.0869565217391, 33.4065155807365, 37.6222222222222, 35.5), 
n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)), 
.Names = c("date_time", "direction", "type", "speed", "n_vehicles"), 
row.names = c(NA, -7L), 
class = "data.frame") 

mydf 

and I need to get to this final result 

mydf_final<-structure(list(date_time = structure(c(1508238000, 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""), 
type = structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class = "factor"), 
weighted_avg_speed = c(36.39029, 38.56521, 37.53333, 36.08696), 
n_vehicles = c(1153L,69L,45L,23L)), 
.Names = c("date_time", "type", "weighted_avg_speed", "n_vehicles"), 
row.names = c(NA, -4L), 
class = "data.frame") 

mydf_final 


my question: 
how to compute a weighted mean i.e. "weighted_avg_speed" 
from "speed" (the values whose weighted mean is to be computed) and "n_vehicles" (the weights) 
grouped by "date_time" and "type"? 

to be noted the complication of the case "motorcycle" (not present in both directions) 

any help for that? 

thank you 

max 



-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Nov  9 14:27:46 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 09 Nov 2017 13:27:46 +0000
Subject: [R] weighted average grouped by variables
In-Reply-To: <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <5A0457D2.9090604@sapo.pt>

Hello,

Using base R only, the following seems to do what you want.

with(mydf, ave(speed, date_time, type, FUN = weighted.mean, w = n_vehicles))


Hope this helps,

Rui Barradas

Em 09-11-2017 13:16, Massimo Bressan escreveu:
> Hello
>
> an update about my question: I worked out the following solution (with the package "dplyr")
>
> library(dplyr)
>
> mydf%>%
> mutate(speed_vehicles=n_vehicles*mydf$speed) %>%
> group_by(date_time,type) %>%
> summarise(
> sum_n_times_speed=sum(speed_vehicles),
> n_vehicles=sum(n_vehicles),
> vel=sum(speed_vehicles)/sum(n_vehicles)
> )
>
>
> In fact I was hoping to manage everything in a "one-go": i.e. without the need to create the "intermediate" variable called "speed_vehicles" and with the use of the function weighted.mean()
>
> any hints for a different approach much appreciated
>
> thanks
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <r-help at r-project.org>
> Inviato: Gioved?, 9 novembre 2017 12:20:52
> Oggetto: weighted average grouped by variables
>
> hi all
>
> I have this dataframe (created as a reproducible example)
>
> mydf<-structure(list(date_time = structure(c(1508238000, 1508238000, 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""),
> direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c("A", "B"), class = "factor"),
> type = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class = "factor"),
> avg_speed = c(41.1029082774049, 40.3333333333333, 40.3157894736842, 36.0869565217391, 33.4065155807365, 37.6222222222222, 35.5),
> n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)),
> .Names = c("date_time", "direction", "type", "speed", "n_vehicles"),
> row.names = c(NA, -7L),
> class = "data.frame")
>
> mydf
>
> and I need to get to this final result
>
> mydf_final<-structure(list(date_time = structure(c(1508238000, 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""),
> type = structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class = "factor"),
> weighted_avg_speed = c(36.39029, 38.56521, 37.53333, 36.08696),
> n_vehicles = c(1153L,69L,45L,23L)),
> .Names = c("date_time", "type", "weighted_avg_speed", "n_vehicles"),
> row.names = c(NA, -4L),
> class = "data.frame")
>
> mydf_final
>
>
> my question:
> how to compute a weighted mean i.e. "weighted_avg_speed"
> from "speed" (the values whose weighted mean is to be computed) and "n_vehicles" (the weights)
> grouped by "date_time" and "type"?
>
> to be noted the complication of the case "motorcycle" (not present in both directions)
>
> any help for that?
>
> thank you
>
> max
>
>
>


From ruipbarradas at sapo.pt  Thu Nov  9 14:30:31 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 09 Nov 2017 13:30:31 +0000
Subject: [R] weighted average grouped by variables
In-Reply-To: <5A0457D2.9090604@sapo.pt>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
 <5A0457D2.9090604@sapo.pt>
Message-ID: <5A045877.9040509@sapo.pt>

Sorry, I messed up. Only checked the final result after sending the 
previous mail. The solution is wrong.

Rui Barradas

Em 09-11-2017 13:27, Rui Barradas escreveu:
> Hello,
>
> Using base R only, the following seems to do what you want.
>
> with(mydf, ave(speed, date_time, type, FUN = weighted.mean, w =
> n_vehicles))
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 09-11-2017 13:16, Massimo Bressan escreveu:
>> Hello
>>
>> an update about my question: I worked out the following solution (with
>> the package "dplyr")
>>
>> library(dplyr)
>>
>> mydf%>%
>> mutate(speed_vehicles=n_vehicles*mydf$speed) %>%
>> group_by(date_time,type) %>%
>> summarise(
>> sum_n_times_speed=sum(speed_vehicles),
>> n_vehicles=sum(n_vehicles),
>> vel=sum(speed_vehicles)/sum(n_vehicles)
>> )
>>
>>
>> In fact I was hoping to manage everything in a "one-go": i.e. without
>> the need to create the "intermediate" variable called "speed_vehicles"
>> and with the use of the function weighted.mean()
>>
>> any hints for a different approach much appreciated
>>
>> thanks
>>
>>
>>
>> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
>> A: "r-help" <r-help at r-project.org>
>> Inviato: Gioved?, 9 novembre 2017 12:20:52
>> Oggetto: weighted average grouped by variables
>>
>> hi all
>>
>> I have this dataframe (created as a reproducible example)
>>
>> mydf<-structure(list(date_time = structure(c(1508238000, 1508238000,
>> 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class =
>> c("POSIXct", "POSIXt"), tzone = ""),
>> direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c("A",
>> "B"), class = "factor"),
>> type = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L), .Label = c("car",
>> "light_duty", "heavy_duty", "motorcycle"), class = "factor"),
>> avg_speed = c(41.1029082774049, 40.3333333333333, 40.3157894736842,
>> 36.0869565217391, 33.4065155807365, 37.6222222222222, 35.5),
>> n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)),
>> .Names = c("date_time", "direction", "type", "speed", "n_vehicles"),
>> row.names = c(NA, -7L),
>> class = "data.frame")
>>
>> mydf
>>
>> and I need to get to this final result
>>
>> mydf_final<-structure(list(date_time = structure(c(1508238000,
>> 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"),
>> tzone = ""),
>> type = structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty",
>> "heavy_duty", "motorcycle"), class = "factor"),
>> weighted_avg_speed = c(36.39029, 38.56521, 37.53333, 36.08696),
>> n_vehicles = c(1153L,69L,45L,23L)),
>> .Names = c("date_time", "type", "weighted_avg_speed", "n_vehicles"),
>> row.names = c(NA, -4L),
>> class = "data.frame")
>>
>> mydf_final
>>
>>
>> my question:
>> how to compute a weighted mean i.e. "weighted_avg_speed"
>> from "speed" (the values whose weighted mean is to be computed) and
>> "n_vehicles" (the weights)
>> grouped by "date_time" and "type"?
>>
>> to be noted the complication of the case "motorcycle" (not present in
>> both directions)
>>
>> any help for that?
>>
>> thank you
>>
>> max
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Nov  9 14:58:52 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 9 Nov 2017 13:58:52 +0000
Subject: [R] weighted average grouped by variables
In-Reply-To: <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8D67@SRVEXCHCM301.precheza.cz>

Hi

Thanks for working example.

you could use split/ lapply approach, however it is probably not much better than dplyr method.

sapply(split(mydf, mydf$type), function(speed, n_vehicles) sum(mydf$speed*mydf$n_vehicles)/sum(mydf$n_vehicles))
gives you averages

aggregate(mydf$n_vehicles, list(mydf$type), sum)$x
gives you sums

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Massimo
> Bressan
> Sent: Thursday, November 9, 2017 2:17 PM
> To: r-help <r-help at r-project.org>
> Subject: Re: [R] weighted average grouped by variables
>
> Hello
>
> an update about my question: I worked out the following solution (with the
> package "dplyr")
>
> library(dplyr)
>
> mydf%>%
> mutate(speed_vehicles=n_vehicles*mydf$speed) %>%
> group_by(date_time,type) %>%
> summarise(
> sum_n_times_speed=sum(speed_vehicles),
> n_vehicles=sum(n_vehicles),
> vel=sum(speed_vehicles)/sum(n_vehicles)
> )
>
>
> In fact I was hoping to manage everything in a "one-go": i.e. without the need
> to create the "intermediate" variable called "speed_vehicles" and with the use
> of the function weighted.mean()
>
> any hints for a different approach much appreciated
>
> thanks
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <r-help at r-project.org>
> Inviato: Gioved?, 9 novembre 2017 12:20:52
> Oggetto: weighted average grouped by variables
>
> hi all
>
> I have this dataframe (created as a reproducible example)
>
> mydf<-structure(list(date_time = structure(c(1508238000, 1508238000,
> 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class =
> c("POSIXct", "POSIXt"), tzone = ""), direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L,
> 2L), .Label = c("A", "B"), class = "factor"), type = structure(c(1L, 2L, 3L, 4L, 1L,
> 2L, 3L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class =
> "factor"), avg_speed = c(41.1029082774049, 40.3333333333333,
> 40.3157894736842, 36.0869565217391, 33.4065155807365,
> 37.6222222222222, 35.5), n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)),
> .Names = c("date_time", "direction", "type", "speed", "n_vehicles"), row.names
> = c(NA, -7L), class = "data.frame")
>
> mydf
>
> and I need to get to this final result
>
> mydf_final<-structure(list(date_time = structure(c(1508238000, 1508238000,
> 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""), type =
> structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty", "heavy_duty",
> "motorcycle"), class = "factor"), weighted_avg_speed = c(36.39029, 38.56521,
> 37.53333, 36.08696), n_vehicles = c(1153L,69L,45L,23L)), .Names =
> c("date_time", "type", "weighted_avg_speed", "n_vehicles"), row.names =
> c(NA, -4L), class = "data.frame")
>
> mydf_final
>
>
> my question:
> how to compute a weighted mean i.e. "weighted_avg_speed"
> from "speed" (the values whose weighted mean is to be computed) and
> "n_vehicles" (the weights) grouped by "date_time" and "type"?
>
> to be noted the complication of the case "motorcycle" (not present in both
> directions)
>
> any help for that?
>
> thank you
>
> max
>
>
>
> --
>
> ------------------------------------------------------------
> Massimo Bressan
>
> ARPAV
> Agenzia Regionale per la Prevenzione e
> Protezione Ambientale del Veneto
>
> Dipartimento Provinciale di Treviso
> Via Santa Barbara, 5/a
> 31100 Treviso, Italy
>
> tel: +39 0422 558545
> fax: +39 0422 558516
> e-mail: massimo.bressan at arpa.veneto.it
> ------------------------------------------------------------
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From tgs77m at yahoo.com  Thu Nov  9 15:07:27 2017
From: tgs77m at yahoo.com (Thomas Subia)
Date: Thu, 9 Nov 2017 06:07:27 -0800
Subject: [R] ggplot2 error
Message-ID: <003601d35964$14514b30$3cf3e190$@yahoo.com>

Hello all,

 

Zeki(?) reported:

> ggplot(data = mtcars, aes(x= wt, y= mpg)) + geom_line()

> Error: Found object is not a stat.

 

Using R v3.4.62 and R studio, I'm unable to reproduce this error.

 

All the best,

Thomas Subia

 


	[[alternative HTML version deleted]]


From massimo.bressan at arpa.veneto.it  Thu Nov  9 15:45:23 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 9 Nov 2017 15:45:23 +0100 (CET)
Subject: [R] weighted average grouped by variables
In-Reply-To: <CAJuCY5xi7g1sqvkqqfLWQPpoyRMjOY0ynVCr8jfvEcqug8D0Fw@mail.gmail.com>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
 <CAJuCY5xi7g1sqvkqqfLWQPpoyRMjOY0ynVCr8jfvEcqug8D0Fw@mail.gmail.com>
Message-ID: <1656597343.27688176.1510238723966.JavaMail.zimbra@arpa.veneto.it>

hi thierry 

thanks for your reply 

yes, you are right, your solution is more straightforward 

best 


Da: "Thierry Onkelinx" <thierry.onkelinx at inbo.be> 
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
Cc: "r-help" <r-help at r-project.org> 
Inviato: Gioved?, 9 novembre 2017 15:17:31 
Oggetto: Re: [R] weighted average grouped by variables 

Dear Massimo, 

It seems straightforward to use weighted.mean() in a dplyr context 

library(dplyr) 
mydf %>% 
group_by(date_time, type) %>% 
summarise(vel = weighted.mean(speed, n_vehicles)) 

Best regards, 



ir. Thierry Onkelinx 
Statisticus / Statistician 

Vlaamse Overheid / Government of Flanders 
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST 
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance 
thierry.onkelinx at inbo.be 
Kliniekstraat 25, B-1070 Brussel 
www.inbo.be 

/////////////////////////////////////////////////////////////////////////////////////////// 
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher 
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey 
/////////////////////////////////////////////////////////////////////////////////////////// 


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis. 
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel. 

/////////////////////////////////////////////////////////////////////////////////////////// 



-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 

	[[alternative HTML version deleted]]


From sds at gnu.org  Thu Nov  9 15:57:27 2017
From: sds at gnu.org (Sam Steingold)
Date: Thu, 09 Nov 2017 09:57:27 -0500
Subject: [R] [R-pkgs] Release of ess 0.0.1
In-Reply-To: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw__27066.4877411493$1510224810$gmane$org@mail.gmail.com>
 (Jorge Cimentada's message of "Thu, 9 Nov 2017 00:02:53 +0100")
References: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw__27066.4877411493$1510224810$gmane$org@mail.gmail.com>
Message-ID: <lzlgjfcxew.fsf@gnu.org>

> * Jorge Cimentada <pvzragnqnw at tznvy.pbz> [2017-11-09 00:02:53 +0100]:
>
> I'm happy to announce the release of ess 0.0.1 a package designed to
> download data from the European Social Survey

Given the existence of ESS (Emacs Speaks Statistics -
https://ess.r-project.org/) the package name "ess" seems unfortunate.

-- 
Sam Steingold (http://sds.podval.org/) on darwin Ns 10.3.1504
http://steingoldpsychology.com http://www.childpsy.net http://iris.org.il
http://mideasttruth.com http://thereligionofpeace.com https://jihadwatch.org
MS Windows: error: the operation completed successfully.


From macqueen1 at llnl.gov  Thu Nov  9 16:33:27 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 9 Nov 2017 15:33:27 +0000
Subject: [R] R-help
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8C5E@SRVEXCHCM301.precheza.cz>
References: <CA+1JU67ZuS5Yg7s7o6nuYgUnpECmVaDu6fxB3QBc_6X5F=62uA@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8C5E@SRVEXCHCM301.precheza.cz>
Message-ID: <966C1A52-3C69-4D06-8A80-095A6F27548F@llnl.gov>

A trip to the Spatial Task View on CRAN might be in order. The RandomFields package comes to mind.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 11/9/17, 12:37 AM, "R-help on behalf of PIKAL Petr" <r-help-bounces at r-project.org on behalf of petr.pikal at precheza.cz> wrote:

    Hi
    
    it smells like a homework, this list has no homework policy.
    
    Anyway, maybe the sample approach could be used.
    
    Generate x,y coordinates - ?expand.grid
    sample n centers - ?sample
    select all points within defined area - ?point.in.polygon, package sp
    select desired number of points - ?sample
    
    Cheers
    Petr
    
    > -----Original Message-----
    > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of john lukore
    > Sent: Thursday, November 9, 2017 4:40 AM
    > To: r-help at r-project.org
    > Subject: [R] R-help
    >
    > Generate a clustered pattern in [0; 1]2 as follows:
    >
    > (a) Generate nc, say 20, independent cluster centres (which can be called
    > parents) that are distributed i.i.d. uniformly in the unit square;
    >
    >  (b) then n daughters are assigned i.i.d. uniformly to these parents and such
    > that each daughter is located i.i.d. uniformly in a disk of radius r =
    > 0:1 centred at her parent, under the periodic boundary conditions (i.e. the
    > square = a torus).
    >
    >
    > My attempt so far is:
    >
    >
    > set.seed(1) library(spatstat)
    >
    >  n_parent <- 2
    >
    >  n_daughter <- 4
    >
    > r = 0.1
    >
    > cnt <- n
    >
    > W <- disc(radius=3, centre=c(0,0)) i <- 1
    >
    >  while(i <= n_daughter){
    >
    > d_x <- runif(1)
    >
    > d_y <- runif(1)
    >
    > if (d_x ^2+d_y^2 <r) {
    >
    >  i = i+1}}
    >
    >
    > #need a condition here such that (d_x,d_y) lies in B(0,r)
    >
    >  #where B(0,r) is a ball of center origin and of radius r
    >
    > In above we should obtain one ball with n_daughters. Next step is to generate
    > parent centers and distribute the n_daughters in the ball into n_parents.
    >
    >       [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ________________________________
    Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
    Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
    Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
    Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
    
    V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
    - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
    - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
    - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
    - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
    
    This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
    If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
    If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
    The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
    
    In case that this e-mail forms part of business dealings:
    - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
    - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
    - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
    - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From pd.mes at cbs.dk  Thu Nov  9 16:49:25 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 9 Nov 2017 15:49:25 +0000
Subject: [R] R 3.4.3 scheduled for November 30
Message-ID: <5D651A71-84E7-4183-BAE2-8AAB3282BEEC@cbs.dk>

Full schedule available on developer.r-project.org (pending auto-update from SVN)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From thierry.onkelinx at inbo.be  Thu Nov  9 15:17:31 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 9 Nov 2017 15:17:31 +0100
Subject: [R] weighted average grouped by variables
In-Reply-To: <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAJuCY5xi7g1sqvkqqfLWQPpoyRMjOY0ynVCr8jfvEcqug8D0Fw@mail.gmail.com>

Dear Massimo,

It seems straightforward to use weighted.mean() in a dplyr context

library(dplyr)
mydf %>%
  group_by(date_time, type) %>%
  summarise(vel = weighted.mean(speed, n_vehicles))

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[image: Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging
in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis. Vanaf
dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.]
<https://overheid.vlaanderen.be/mobiliteitsplan-herman-teirlinckgebouw>
Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
Brussel.

///////////////////////////////////////////////////////////////////////////////////////////
<https://www.inbo.be>

2017-11-09 14:16 GMT+01:00 Massimo Bressan <massimo.bressan at arpa.veneto.it>:

> Hello
>
> an update about my question: I worked out the following solution (with the
> package "dplyr")
>
> library(dplyr)
>
> mydf%>%
> mutate(speed_vehicles=n_vehicles*mydf$speed) %>%
> group_by(date_time,type) %>%
> summarise(
> sum_n_times_speed=sum(speed_vehicles),
> n_vehicles=sum(n_vehicles),
> vel=sum(speed_vehicles)/sum(n_vehicles)
> )
>
>
> In fact I was hoping to manage everything in a "one-go": i.e. without the
> need to create the "intermediate" variable called "speed_vehicles" and with
> the use of the function weighted.mean()
>
> any hints for a different approach much appreciated
>
> thanks
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <r-help at r-project.org>
> Inviato: Gioved?, 9 novembre 2017 12:20:52
> Oggetto: weighted average grouped by variables
>
> hi all
>
> I have this dataframe (created as a reproducible example)
>
> mydf<-structure(list(date_time = structure(c(1508238000, 1508238000,
> 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class =
> c("POSIXct", "POSIXt"), tzone = ""),
> direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c("A", "B"),
> class = "factor"),
> type = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L), .Label = c("car",
> "light_duty", "heavy_duty", "motorcycle"), class = "factor"),
> avg_speed = c(41.1029082774049, 40.3333333333333, 40.3157894736842,
> 36.0869565217391, 33.4065155807365, 37.6222222222222, 35.5),
> n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)),
> .Names = c("date_time", "direction", "type", "speed", "n_vehicles"),
> row.names = c(NA, -7L),
> class = "data.frame")
>
> mydf
>
> and I need to get to this final result
>
> mydf_final<-structure(list(date_time = structure(c(1508238000,
> 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone
> = ""),
> type = structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty",
> "heavy_duty", "motorcycle"), class = "factor"),
> weighted_avg_speed = c(36.39029, 38.56521, 37.53333, 36.08696),
> n_vehicles = c(1153L,69L,45L,23L)),
> .Names = c("date_time", "type", "weighted_avg_speed", "n_vehicles"),
> row.names = c(NA, -4L),
> class = "data.frame")
>
> mydf_final
>
>
> my question:
> how to compute a weighted mean i.e. "weighted_avg_speed"
> from "speed" (the values whose weighted mean is to be computed) and
> "n_vehicles" (the weights)
> grouped by "date_time" and "type"?
>
> to be noted the complication of the case "motorcycle" (not present in both
> directions)
>
> any help for that?
>
> thank you
>
> max
>
>
>
> --
>
> ------------------------------------------------------------
> Massimo Bressan
>
> ARPAV
> Agenzia Regionale per la Prevenzione e
> Protezione Ambientale del Veneto
>
> Dipartimento Provinciale di Treviso
> Via Santa Barbara, 5/a
> 31100 Treviso, Italy
>
> tel: +39 0422 558545
> fax: +39 0422 558516
> e-mail: massimo.bressan at arpa.veneto.it
> ------------------------------------------------------------
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From joon7261 at gmail.com  Thu Nov  9 16:05:35 2017
From: joon7261 at gmail.com (Hye Joon Yoon)
Date: Fri, 10 Nov 2017 00:05:35 +0900
Subject: [R] R basic
Message-ID: <CAJS-AHvpjYTD-DXndOwFAuzfv-Wei8RejD=NMjede0P_FM=FJQ@mail.gmail.com>

Can anyone help with scripting the commands below?

1. Add/create a new column to df and name it as ShortPause .
2. Convert ShortPause as a factor variable.
3. ShortPause will have two levels (short and long). Assign short if pause
is smaller than 0.1, and assign
long otherwise.
4. How many ?syntax==intransitive? observations were realized with a tap
(tapped==Tapped)? (Use xtabs()
and ftable() to calculate this.)

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Nov  9 19:08:25 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 9 Nov 2017 13:08:25 -0500
Subject: [R] R basic
In-Reply-To: <CAJS-AHvpjYTD-DXndOwFAuzfv-Wei8RejD=NMjede0P_FM=FJQ@mail.gmail.com>
References: <CAJS-AHvpjYTD-DXndOwFAuzfv-Wei8RejD=NMjede0P_FM=FJQ@mail.gmail.com>
Message-ID: <AFC74736-0D15-41E1-8AAA-7F20B42F7132@utoronto.ca>

Hi -

This list has a "no homework" policy, but we can certainly help once you show what effort you have put into this yourself. Read the posting guide, especially regarding the instructions re. reproducible examples, and follow them exactly.

Cheers,
B.




> On Nov 9, 2017, at 10:05 AM, Hye Joon Yoon <joon7261 at gmail.com> wrote:
> 
> Can anyone help with scripting the commands below?
> 
> 1. Add/create a new column to df and name it as ShortPause .
> 2. Convert ShortPause as a factor variable.
> 3. ShortPause will have two levels (short and long). Assign short if pause
> is smaller than 0.1, and assign
> long otherwise.
> 4. How many ?syntax==intransitive? observations were realized with a tap
> (tapped==Tapped)? (Use xtabs()
> and ftable() to calculate this.)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jeanphilippe.fontaine at gssi.infn.it  Thu Nov  9 19:13:29 2017
From: jeanphilippe.fontaine at gssi.infn.it (jean-philippe)
Date: Thu, 9 Nov 2017 19:13:29 +0100
Subject: [R] R basic
In-Reply-To: <CAJS-AHvpjYTD-DXndOwFAuzfv-Wei8RejD=NMjede0P_FM=FJQ@mail.gmail.com>
References: <CAJS-AHvpjYTD-DXndOwFAuzfv-Wei8RejD=NMjede0P_FM=FJQ@mail.gmail.com>
Message-ID: <5A049AC9.8090307@gssi.infn.it>

Hi,

Since you didn't provide us any detail of what you tried to do so far, I 
can point you out to the dplyr library.
It will make your life easier while dealing with dataframes (well at 
least it makes mine easier).


Cheers


Jean-Philippe
On 09/11/2017 16:05, Hye Joon Yoon wrote:
> Can anyone help with scripting the commands below?
>
> 1. Add/create a new column to df and name it as ShortPause .
> 2. Convert ShortPause as a factor variable.
> 3. ShortPause will have two levels (short and long). Assign short if pause
> is smaller than 0.1, and assign
> long otherwise.
> 4. How many ?syntax==intransitive? observations were realized with a tap
> (tapped==Tapped)? (Use xtabs()
> and ftable() to calculate this.)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Jean-Philippe Fontaine
PhD Student in Astroparticle Physics,
Gran Sasso Science Institute (GSSI),
Viale Francesco Crispi 7,
67100 L'Aquila, Italy
Mobile: +393487128593, +33615653774


From allaisone1 at hotmail.com  Thu Nov  9 20:44:15 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Thu, 9 Nov 2017 19:44:15 +0000
Subject: [R] Calculating frequencies of multiple values in 200 colomns
Message-ID: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>


Hi All


I have a dataset of 200 columns and 1000 rows , there are 3 repeated values under each column (7,8,10). I wanted to calculate the frequency of each value under each column and then apply the function maf () given that the frequency of each value is known. I can do the analysis step by step like this :-


> Values


         A       B       C       ... 200

1      7       10      7

2      7       8        7

3      10     8        7

4       8      7         10

.

.

.

1000


For column A : I calculate the frequency for the 3 values as follows :

 count7 <- length(which(Values$A == 7))

count8 <- length(which(Values$A == 8))

count10 <- length(which(Values$A == 10))


count7 = 2, count8 = 1 , count10= 1.


Then, I create a vector  and type the frequencies manually :


 Freq<- c( count7=2  ,count8= 1,count10=1)


Then I apply the function maf ()  :-

maf(Freq)


This gives me the result I need for column A , could you please help me

to perform the analysis for all of the 200 columns at once ?


Regards

Allahisone


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Nov  9 21:56:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Nov 2017 12:56:39 -0800
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>

This is not a good way to do things! R has many powerful built in functions
to do this sort of thing for you. Searching  -- e.g. at rseek.org or even a
plain old google search -- can help you find them. Also, it looks like you
need to go through a tutorial or two to learn more about R's basic
functionality.

In this case, something like (no reproducible example given, so can't
confirm):

apply(Values, 2, function(x)maf(tabulate(x)))

should be close to what you want .


Cheers,
Bert







Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:

>
> Hi All
>
>
> I have a dataset of 200 columns and 1000 rows , there are 3 repeated
> values under each column (7,8,10). I wanted to calculate the frequency of
> each value under each column and then apply the function maf () given that
> the frequency of each value is known. I can do the analysis step by step
> like this :-
>
>
> > Values
>
>
>          A       B       C       ... 200
>
> 1      7       10      7
>
> 2      7       8        7
>
> 3      10     8        7
>
> 4       8      7         10
>
> .
>
> .
>
> .
>
> 1000
>
>
> For column A : I calculate the frequency for the 3 values as follows :
>
>  count7 <- length(which(Values$A == 7))
>
> count8 <- length(which(Values$A == 8))
>
> count10 <- length(which(Values$A == 10))
>
>
> count7 = 2, count8 = 1 , count10= 1.
>
>
> Then, I create a vector  and type the frequencies manually :
>
>
>  Freq<- c( count7=2  ,count8= 1,count10=1)
>
>
> Then I apply the function maf ()  :-
>
> maf(Freq)
>
>
> This gives me the result I need for column A , could you please help me
>
> to perform the analysis for all of the 200 columns at once ?
>
>
> Regards
>
> Allahisone
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Nov 10 00:51:35 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Nov 2017 15:51:35 -0800
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>
 <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>

Always reply to the list. I am not a free, private consultant!

"For example, if I have the values : 1 , 2 , 3 in each column, applying
Tabulate () would calculate the frequency of 1 and 2 without 3"

Huh??

> x <- sample(1:3,10,TRUE)
> x
 [1] 1 3 1 1 1 3 2 3 2 1
> tabulate(x)
[1] 5 2 3

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 9, 2017 at 3:44 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:

> Thank you so much for your replay
>
>
> Actually, I tried apply() function but struggled with the part of writing
> the appropriate function inside it which calculate the frequency of the 3
> values. Tabulate () function is a good start but the problem is that this
> calculates the frequency of two values only per column which means that
> when I apply maf () function , maf value will be calculated using the
> frequency of these 2 values only without considering the frequency of the
> 3rd value. For example, if I have the values : 1 , 2 , 3 in each column,
> applying Tabulate () would calculate the frequency of 1 and 2 without 3 . I
> need a way to calculate the frequencies of all of the 3 values so the
> calculation of maf will be correct as it will consider all the 3
> frequencies but not only 2 .
>
>
> Regards
>
> Allahisone
> ------------------------------
> *From:* Bert Gunter <bgunter.4567 at gmail.com>
> *Sent:* 09 November 2017 20:56:39
> *To:* Allaisone 1
> *Cc:* r-help at R-project.org
> *Subject:* Re: [R] Calculating frequencies of multiple values in 200
> colomns
>
> This is not a good way to do things! R has many powerful built in
> functions to do this sort of thing for you. Searching  -- e.g. at
> rseek.org or even a plain old google search -- can help you find them.
> Also, it looks like you need to go through a tutorial or two to learn more
> about R's basic functionality.
>
> In this case, something like (no reproducible example given, so can't
> confirm):
>
> apply(Values, 2, function(x)maf(tabulate(x)))
>
> should be close to what you want .
>
>
> Cheers,
> Bert
>
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com>
> wrote:
>
>>
>> Hi All
>>
>>
>> I have a dataset of 200 columns and 1000 rows , there are 3 repeated
>> values under each column (7,8,10). I wanted to calculate the frequency of
>> each value under each column and then apply the function maf () given that
>> the frequency of each value is known. I can do the analysis step by step
>> like this :-
>>
>>
>> > Values
>>
>>
>>          A       B       C       ... 200
>>
>> 1      7       10      7
>>
>> 2      7       8        7
>>
>> 3      10     8        7
>>
>> 4       8      7         10
>>
>> .
>>
>> .
>>
>> .
>>
>> 1000
>>
>>
>> For column A : I calculate the frequency for the 3 values as follows :
>>
>>  count7 <- length(which(Values$A == 7))
>>
>> count8 <- length(which(Values$A == 8))
>>
>> count10 <- length(which(Values$A == 10))
>>
>>
>> count7 = 2, count8 = 1 , count10= 1.
>>
>>
>> Then, I create a vector  and type the frequencies manually :
>>
>>
>>  Freq<- c( count7=2  ,count8= 1,count10=1)
>>
>>
>> Then I apply the function maf ()  :-
>>
>> maf(Freq)
>>
>>
>> This gives me the result I need for column A , could you please help me
>>
>> to perform the analysis for all of the 200 columns at once ?
>>
>>
>> Regards
>>
>> Allahisone
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From marna.wagley at gmail.com  Fri Nov 10 10:21:46 2017
From: marna.wagley at gmail.com (Marna Wagley)
Date: Fri, 10 Nov 2017 01:21:46 -0800
Subject: [R] How to create separate legend for each plot in the function of
 facet_wrap in ggplot2?
Message-ID: <CAMwU6B11WDouT9SKYpO0RhJ8VDjkW_7qbgBjDwy7YZDGP_O1Mw@mail.gmail.com>

Hi R users,
I need to create more than 20 figures (one for each group) in one page. I
have a  common  legend for 20 figures using the facet_wrap. However the
range of the values among the groups are very wide. For example one group
has the value of 0 to 3, but the values of some of the groups has ranged
from 0 to 20 so that when I used a single common legend for all 20 figures,
I could not display the contrast of the values in some of the figures.
Therefore I wanted to create the figures with *a separate legend*.In this
way, I can display the gradient of the values in each figure.  Any
suggestions on how I can create it.

The example is given below, *I wanted to create a separate legend with
keeping legend inside of each of the figure*.

library(ggplot2)

dat<-structure(list(X = c(289.6, 289.7, 289.8, 289.9, 290, 290.1,

927.8, 927.9, 928, 928.1, 928.2, 928.3), Y = c(789.1, 789.2,

789.3, 789.4, 789.5, 789.6, 171.1, 171.2, 171.3, 171.4, 171.5,

171.6), value = c(0.05, 0.06, 0.07, 0.09, 0.1, 0.11, 0.06, 0.05,

0.05, 0.06, 0.1, 1.5), group = structure(c(1L, 1L, 1L, 1L, 1L,

1L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class = "factor")),
.Names = c("X",

"Y", "value", "group"), class = "data.frame", row.names = c(NA,

-12L))


AB<-ggplot(data = dat, aes(x = X, y = Y, color =  value)) +  geom_point(size
=2) +

coord_equal() +  theme_bw()+ scale_color_gradientn(colours = terrain.colors(
7))

AB+facet_wrap(~group,  scales="free")+theme(strip.text = element_text(size
= 8))




Thanks


MW

	[[alternative HTML version deleted]]


From dominik.schneider at colorado.edu  Fri Nov 10 10:24:58 2017
From: dominik.schneider at colorado.edu (Dominik Schneider)
Date: Fri, 10 Nov 2017 10:24:58 +0100
Subject: [R] How to create separate legend for each plot in the function
 of facet_wrap in ggplot2?
In-Reply-To: <CAMwU6B11WDouT9SKYpO0RhJ8VDjkW_7qbgBjDwy7YZDGP_O1Mw@mail.gmail.com>
References: <CAMwU6B11WDouT9SKYpO0RhJ8VDjkW_7qbgBjDwy7YZDGP_O1Mw@mail.gmail.com>
Message-ID: <CAF1jk_kkOM_SJ5t=ZmVoNV46C6QuaVQ=NwM96cf091h1U0J3Sg@mail.gmail.com>

That's not the point of facet_wrap so check out the cowplot package for
combining multiple ggplot objects (with legends) into one figure.

On Fri, Nov 10, 2017 at 10:21 AM, Marna Wagley <marna.wagley at gmail.com>
wrote:

> Hi R users,
> I need to create more than 20 figures (one for each group) in one page. I
> have a  common  legend for 20 figures using the facet_wrap. However the
> range of the values among the groups are very wide. For example one group
> has the value of 0 to 3, but the values of some of the groups has ranged
> from 0 to 20 so that when I used a single common legend for all 20 figures,
> I could not display the contrast of the values in some of the figures.
> Therefore I wanted to create the figures with *a separate legend*.In this
> way, I can display the gradient of the values in each figure.  Any
> suggestions on how I can create it.
>
> The example is given below, *I wanted to create a separate legend with
> keeping legend inside of each of the figure*.
>
> library(ggplot2)
>
> dat<-structure(list(X = c(289.6, 289.7, 289.8, 289.9, 290, 290.1,
>
> 927.8, 927.9, 928, 928.1, 928.2, 928.3), Y = c(789.1, 789.2,
>
> 789.3, 789.4, 789.5, 789.6, 171.1, 171.2, 171.3, 171.4, 171.5,
>
> 171.6), value = c(0.05, 0.06, 0.07, 0.09, 0.1, 0.11, 0.06, 0.05,
>
> 0.05, 0.06, 0.1, 1.5), group = structure(c(1L, 1L, 1L, 1L, 1L,
>
> 1L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class = "factor")),
> .Names = c("X",
>
> "Y", "value", "group"), class = "data.frame", row.names = c(NA,
>
> -12L))
>
>
> AB<-ggplot(data = dat, aes(x = X, y = Y, color =  value)) +
> geom_point(size
> =2) +
>
> coord_equal() +  theme_bw()+ scale_color_gradientn(colours =
> terrain.colors(
> 7))
>
> AB+facet_wrap(~group,  scales="free")+theme(strip.text = element_text(size
> = 8))
>
>
>
>
> Thanks
>
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cimentadaj at gmail.com  Fri Nov 10 14:31:43 2017
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 10 Nov 2017 14:31:43 +0100
Subject: [R] [R-pkgs] Release of ess 0.0.1
In-Reply-To: <AB0FBD69-0BEF-4A6A-B515-CA540546BD56@icloud.com>
References: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw__27066.4877411493$1510224810$gmane$org@mail.gmail.com>
 <lzlgjfcxew.fsf@gnu.org> <AB0FBD69-0BEF-4A6A-B515-CA540546BD56@icloud.com>
Message-ID: <CALdB+JH5khDk_CsTj96+MtcRbuZJH978Wx6QT-NRBJ4fT-b_gw@mail.gmail.com>

Thanks to all. Will consider this change in future releases.

-----------------------------------


Jorge Cimentada
*https://cimentadaj.github.io/ <https://cimentadaj.github.io/>*


On Fri, Nov 10, 2017 at 12:41 PM, Rainer Krug <rainer_krug at icloud.com>
wrote:

>
>
> On 9 Nov 2017, at 15:57, Sam Steingold <sds at gnu.org> wrote:
>
> * Jorge Cimentada <pvzragnqnw at tznvy.pbz> [2017-11-09 00:02:53 +0100]:
>
> I'm happy to announce the release of ess 0.0.1 a package designed to
> download data from the European Social Survey
>
>
> Given the existence of ESS (Emacs Speaks Statistics -
> https://ess.r-project.org/) the package name "ess" seems unfortunate.
>
>
> Agreed. I would suggest to rename the package to avoid conflicts (ESS
> includes some R code, And I wouldn?t wonder if they would like to include
> it in a package?).
>
>
>
> --
> Sam Steingold (http://sds.podval.org/) on darwin Ns 10.3.1504
> http://steingoldpsychology.com http://www.childpsy.net http://iris.org.il
> http://mideasttruth.com http://thereligionofpeace.com
> https://jihadwatch.org
> MS Windows: error: the operation completed successfully.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> University of Z?rich
>
> Cell:       +41 (0)78 630 66 57 <+41%2078%20630%2066%2057>
> email:      Rainer at krugs.de <Rainer at krugs.de>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
>
>
>

	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Fri Nov 10 10:32:45 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Fri, 10 Nov 2017 09:32:45 +0000
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>
 <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>
Message-ID: <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>



Thank you for your effort Bert..,


I knew what is the problem now, the values (1,2,3) were only an example. The values I have are 0 , 1, 2 . Tabulate () function seem to ignore calculating the frequency of 0 values and this is my exact problem as the frequency of 0 values should also be calculated for the maf to be calculated correctly.

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 09 November 2017 23:51:35
To: Allaisone 1; R-help
Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns

[[elided Hotmail spam]]

"For example, if I have the values : 1 , 2 , 3 in each column, applying Tabulate () would calculate the frequency of 1 and 2 without 3"

Huh??

> x <- sample(1:3,10,TRUE)
> x
 [1] 1 3 1 1 1 3 2 3 2 1
> tabulate(x)
[1] 5 2 3

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 9, 2017 at 3:44 PM, Allaisone 1 <allaisone1 at hotmail.com<mailto:allaisone1 at hotmail.com>> wrote:

Thank you so much for your replay


Actually, I tried apply() function but struggled with the part of writing the appropriate function inside it which calculate the frequency of the 3 values. Tabulate () function is a good start but the problem is that this calculates the frequency of two values only per column which means that when I apply maf () function , maf value will be calculated using the frequency of these 2 values only without considering the frequency of the 3rd value. For example, if I have the values : 1 , 2 , 3 in each column, applying Tabulate () would calculate the frequency of 1 and 2 without 3 . I need a way to calculate the frequencies of all of the 3 values so the calculation of maf will be correct as it will consider all the 3 frequencies but not only 2 .


Regards

Allahisone

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
Sent: 09 November 2017 20:56:39
To: Allaisone 1
Cc: r-help at R-project.org
Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns

This is not a good way to do things! R has many powerful built in functions to do this sort of thing for you. Searching  -- e.g. at rseek.org<http://rseek.org> or even a plain old google search -- can help you find them. Also, it looks like you need to go through a tutorial or two to learn more about R's basic functionality.

In this case, something like (no reproducible example given, so can't confirm):

apply(Values, 2, function(x)maf(tabulate(x)))

should be close to what you want .


Cheers,
Bert







Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com<mailto:allaisone1 at hotmail.com>> wrote:

Hi All


I have a dataset of 200 columns and 1000 rows , there are 3 repeated values under each column (7,8,10). I wanted to calculate the frequency of each value under each column and then apply the function maf () given that the frequency of each value is known. I can do the analysis step by step like this :-


> Values


         A       B       C       ... 200

1      7       10      7

2      7       8        7

3      10     8        7

4       8      7         10

.

.

.




For column A : I calculate the frequency for the 3 values as follows :

 count7 <- length(which(Values$A == 7))

count8 <- length(which(Values$A == 8))

count10 <- length(which(Values$A == 10))


count7 = 2, count8 = 1 , count10= 1.


Then, I create a vector  and type the frequencies manually :


 Freq<- c( count7=2  ,count8= 1,count10=1)


Then I apply the function maf ()  :-

maf(Freq)


This gives me the result I need for column A , could you please help me

to perform the analysis for all of the 200 columns at once ?


Regards

Allahisone


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From rainer_krug at icloud.com  Fri Nov 10 12:41:29 2017
From: rainer_krug at icloud.com (Rainer Krug)
Date: Fri, 10 Nov 2017 12:41:29 +0100
Subject: [R] [R-pkgs] Release of ess 0.0.1
In-Reply-To: <lzlgjfcxew.fsf@gnu.org>
References: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw__27066.4877411493$1510224810$gmane$org@mail.gmail.com>
 <lzlgjfcxew.fsf@gnu.org>
Message-ID: <AB0FBD69-0BEF-4A6A-B515-CA540546BD56@icloud.com>



> On 9 Nov 2017, at 15:57, Sam Steingold <sds at gnu.org> wrote:
> 
>> * Jorge Cimentada <pvzragnqnw at tznvy.pbz> [2017-11-09 00:02:53 +0100]:
>> 
>> I'm happy to announce the release of ess 0.0.1 a package designed to
>> download data from the European Social Survey
> 
> Given the existence of ESS (Emacs Speaks Statistics -
> https://ess.r-project.org/) the package name "ess" seems unfortunate.

Agreed. I would suggest to rename the package to avoid conflicts (ESS includes some R code, And I wouldn?t wonder if they would like to include it in a package?).


> 
> -- 
> Sam Steingold (http://sds.podval.org/) on darwin Ns 10.3.1504
> http://steingoldpsychology.com http://www.childpsy.net http://iris.org.il
> http://mideasttruth.com http://thereligionofpeace.com https://jihadwatch.org
> MS Windows: error: the operation completed successfully.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri Nov 10 14:43:25 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 10 Nov 2017 08:43:25 -0500
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>
 <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>
 <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <0D3189D6-117D-48B6-9534-CD3751B7328C@utoronto.ca>

|> x <- sample(0:2, 10, replace = TRUE)
|> x
 [1] 1 0 2 1 0 2 2 0 2 1
|> tabulate(x)
[1] 3 4
|> table(x)
x
0 1 2 
3 3 4 



B.



> On Nov 10, 2017, at 4:32 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> 
> 
> Thank you for your effort Bert..,
> 
> 
> I knew what is the problem now, the values (1,2,3) were only an example. The values I have are 0 , 1, 2 . Tabulate () function seem to ignore calculating the frequency of 0 values and this is my exact problem as the frequency of 0 values should also be calculated for the maf to be calculated correctly.
> 
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 09 November 2017 23:51:35
> To: Allaisone 1; R-help
> Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns
> 
> [[elided Hotmail spam]]
> 
> "For example, if I have the values : 1 , 2 , 3 in each column, applying Tabulate () would calculate the frequency of 1 and 2 without 3"
> 
> Huh??
> 
>> x <- sample(1:3,10,TRUE)
>> x
> [1] 1 3 1 1 1 3 2 3 2 1
>> tabulate(x)
> [1] 5 2 3
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Nov 9, 2017 at 3:44 PM, Allaisone 1 <allaisone1 at hotmail.com<mailto:allaisone1 at hotmail.com>> wrote:
> 
> Thank you so much for your replay
> 
> 
> Actually, I tried apply() function but struggled with the part of writing the appropriate function inside it which calculate the frequency of the 3 values. Tabulate () function is a good start but the problem is that this calculates the frequency of two values only per column which means that when I apply maf () function , maf value will be calculated using the frequency of these 2 values only without considering the frequency of the 3rd value. For example, if I have the values : 1 , 2 , 3 in each column, applying Tabulate () would calculate the frequency of 1 and 2 without 3 . I need a way to calculate the frequencies of all of the 3 values so the calculation of maf will be correct as it will consider all the 3 frequencies but not only 2 .
> 
> 
> Regards
> 
> Allahisone
> 
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
> Sent: 09 November 2017 20:56:39
> To: Allaisone 1
> Cc: r-help at R-project.org
> Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns
> 
> This is not a good way to do things! R has many powerful built in functions to do this sort of thing for you. Searching  -- e.g. at rseek.org<http://rseek.org> or even a plain old google search -- can help you find them. Also, it looks like you need to go through a tutorial or two to learn more about R's basic functionality.
> 
> In this case, something like (no reproducible example given, so can't confirm):
> 
> apply(Values, 2, function(x)maf(tabulate(x)))
> 
> should be close to what you want .
> 
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com<mailto:allaisone1 at hotmail.com>> wrote:
> 
> Hi All
> 
> 
> I have a dataset of 200 columns and 1000 rows , there are 3 repeated values under each column (7,8,10). I wanted to calculate the frequency of each value under each column and then apply the function maf () given that the frequency of each value is known. I can do the analysis step by step like this :-
> 
> 
>> Values
> 
> 
>         A       B       C       ... 200
> 
> 1      7       10      7
> 
> 2      7       8        7
> 
> 3      10     8        7
> 
> 4       8      7         10
> 
> .
> 
> .
> 
> .
> 
> 
> 
> 
> For column A : I calculate the frequency for the 3 values as follows :
> 
> count7 <- length(which(Values$A == 7))
> 
> count8 <- length(which(Values$A == 8))
> 
> count10 <- length(which(Values$A == 10))
> 
> 
> count7 = 2, count8 = 1 , count10= 1.
> 
> 
> Then, I create a vector  and type the frequencies manually :
> 
> 
> Freq<- c( count7=2  ,count8= 1,count10=1)
> 
> 
> Then I apply the function maf ()  :-
> 
> maf(Freq)
> 
> 
> This gives me the result I need for column A , could you please help me
> 
> to perform the analysis for all of the 200 columns at once ?
> 
> 
> Regards
> 
> Allahisone
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Fri Nov 10 15:12:14 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Nov 2017 15:12:14 +0100
Subject: [R] [R-pkgs] Release of ess 0.0.1
In-Reply-To: <CALdB+JH5khDk_CsTj96+MtcRbuZJH978Wx6QT-NRBJ4fT-b_gw@mail.gmail.com>
References: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw__27066.4877411493$1510224810$gmane$org@mail.gmail.com>
 <lzlgjfcxew.fsf@gnu.org>
 <AB0FBD69-0BEF-4A6A-B515-CA540546BD56@icloud.com>
 <CALdB+JH5khDk_CsTj96+MtcRbuZJH978Wx6QT-NRBJ4fT-b_gw@mail.gmail.com>
Message-ID: <23045.46014.298736.93636@stat.math.ethz.ch>

>>>>> Jorge Cimentada <cimentadaj at gmail.com>
>>>>>     on Fri, 10 Nov 2017 14:31:43 +0100 writes:

    > Thanks to all. Will consider this change in future releases.
    > -----------------------------------


    > Jorge Cimentada
    > *https://cimentadaj.github.io/ <https://cimentadaj.github.io/>*


    > On Fri, Nov 10, 2017 at 12:41 PM, Rainer Krug <rainer_krug at icloud.com>
    > wrote:

    >> On 9 Nov 2017, at 15:57, Sam Steingold <sds at gnu.org> wrote:
    >> 
    >> * Jorge Cimentada <pvzragnqnw at tznvy.pbz> [2017-11-09 00:02:53 +0100]:
    >> 
    >> I'm happy to announce the release of ess 0.0.1 a package designed to
    >> download data from the European Social Survey
    >> 
    >> 
    >> Given the existence of ESS (Emacs Speaks Statistics -
    >> https://ess.r-project.org/) the package name "ess" seems unfortunate.
    >> 
    >> 
    >> Agreed. I would suggest to rename the package to avoid conflicts (ESS
    >> includes some R code, And I wouldn?t wonder if they would like to include
    >> it in a package?).

As a matter of fact, we (the ESS core developers) have e-chatted
about this and came to the conclusion that we could get along fine with
an unrelated R package called 'ess', notably as the acronym also
makes sense for the European Social Survey.

We'd like to ask the 'ess' package authors to add something like the
following to their ess/DESCRIPTION file:

  This package ess is named to match the European Social Survey (ESS).
  It is unrelated to the Emacs Speaks Statistics (ESS) project, an
  emacs-based Integrated Development Environment hosted at
  https://ess.r-project.org

and last but not least we have thought of 'reserving'  ESSR  as
the name of a CRAN package that we'd consider using for the R
part of ESS (there are others, considerably less used, notably
Julia, Stata and SAS).

Martin Maechler, ETH Zurich
for ESS core developers


From marc_schwartz at me.com  Fri Nov 10 15:34:39 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 10 Nov 2017 09:34:39 -0500
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <0D3189D6-117D-48B6-9534-CD3751B7328C@utoronto.ca>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>
 <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>
 <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <0D3189D6-117D-48B6-9534-CD3751B7328C@utoronto.ca>
Message-ID: <8B53D3BF-BE40-46EA-B583-54152C6A09AD@me.com>

Hi,

To clarify the default behavior that Boris is referencing below, note the definition of the 'bin' argument to the tabulate() function:

bin: a numeric vector ***(of positive integers)***, or a factor. Long vectors are supported.

I added the asterisks for emphasis.

This is also noted in the examples used for the function in ?tabulate at the bottom of the help page.

The second argument, 'nbins', which defaults to max(1, bin, na.rm = TRUE), also affects the output:

> tabulate(c(2, 3, 5))
[1] 0 1 1 0 1

In this case, with each element in the returned vector indicating how many 1's, 2's, 3's, 4's and 5's are present in the source vector.

Compare that to:

> tabulate(c(2, 3, 5), nbins = 3)
[1] 0 1 1

In the above example, 5 is ignored.

Note also that tabulate(), unlike table(), does not return a named vector, just the frequencies.

While tabulate() is used within the table() function, reviewing the code for the latter reveals how the default behavior of tabulate() is modified and preceded/wrapped in other code for use there.

Regards,

Marc Schwartz


> On Nov 10, 2017, at 8:43 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> |> x <- sample(0:2, 10, replace = TRUE)
> |> x
> [1] 1 0 2 1 0 2 2 0 2 1
> |> tabulate(x)
> [1] 3 4
> |> table(x)
> x
> 0 1 2 
> 3 3 4 
> 
> 
> 
> B.
> 
> 
> 
>> On Nov 10, 2017, at 4:32 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>> 
>> 
>> 
>> Thank you for your effort Bert..,
>> 
>> 
>> I knew what is the problem now, the values (1,2,3) were only an example. The values I have are 0 , 1, 2 . Tabulate () function seem to ignore calculating the frequency of 0 values and this is my exact problem as the frequency of 0 values should also be calculated for the maf to be calculated correctly.
>> 
>> ________________________________
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Sent: 09 November 2017 23:51:35
>> To: Allaisone 1; R-help
>> Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns
>> 
>> [[elided Hotmail spam]]
>> 
>> "For example, if I have the values : 1 , 2 , 3 in each column, applying Tabulate () would calculate the frequency of 1 and 2 without 3"
>> 
>> Huh??
>> 
>>> x <- sample(1:3,10,TRUE)
>>> x
>> [1] 1 3 1 1 1 3 2 3 2 1
>>> tabulate(x)
>> [1] 5 2 3
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Nov 9, 2017 at 3:44 PM, Allaisone 1 <allaisone1 at hotmail.com<mailto:allaisone1 at hotmail.com>> wrote:
>> 
>> Thank you so much for your replay
>> 
>> 
>> Actually, I tried apply() function but struggled with the part of writing the appropriate function inside it which calculate the frequency of the 3 values. Tabulate () function is a good start but the problem is that this calculates the frequency of two values only per column which means that when I apply maf () function , maf value will be calculated using the frequency of these 2 values only without considering the frequency of the 3rd value. For example, if I have the values : 1 , 2 , 3 in each column, applying Tabulate () would calculate the frequency of 1 and 2 without 3 . I need a way to calculate the frequencies of all of the 3 values so the calculation of maf will be correct as it will consider all the 3 frequencies but not only 2 .
>> 
>> 
>> Regards
>> 
>> Allahisone
>> 
>> ________________________________
>> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
>> Sent: 09 November 2017 20:56:39
>> To: Allaisone 1
>> Cc: r-help at R-project.org
>> Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns
>> 
>> This is not a good way to do things! R has many powerful built in functions to do this sort of thing for you. Searching  -- e.g. at rseek.org<http://rseek.org> or even a plain old google search -- can help you find them. Also, it looks like you need to go through a tutorial or two to learn more about R's basic functionality.
>> 
>> In this case, something like (no reproducible example given, so can't confirm):
>> 
>> apply(Values, 2, function(x)maf(tabulate(x)))
>> 
>> should be close to what you want .
>> 
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com<mailto:allaisone1 at hotmail.com>> wrote:
>> 
>> Hi All
>> 
>> 
>> I have a dataset of 200 columns and 1000 rows , there are 3 repeated values under each column (7,8,10). I wanted to calculate the frequency of each value under each column and then apply the function maf () given that the frequency of each value is known. I can do the analysis step by step like this :-
>> 
>> 
>>> Values
>> 
>> 
>>        A       B       C       ... 200
>> 
>> 1      7       10      7
>> 
>> 2      7       8        7
>> 
>> 3      10     8        7
>> 
>> 4       8      7         10
>> 
>> .
>> 
>> .
>> 
>> .
>> 
>> 
>> 
>> 
>> For column A : I calculate the frequency for the 3 values as follows :
>> 
>> count7 <- length(which(Values$A == 7))
>> 
>> count8 <- length(which(Values$A == 8))
>> 
>> count10 <- length(which(Values$A == 10))
>> 
>> 
>> count7 = 2, count8 = 1 , count10= 1.
>> 
>> 
>> Then, I create a vector  and type the frequencies manually :
>> 
>> 
>> Freq<- c( count7=2  ,count8= 1,count10=1)
>> 
>> 
>> Then I apply the function maf ()  :-
>> 
>> maf(Freq)
>> 
>> 
>> This gives me the result I need for column A , could you please help me
>> 
>> to perform the analysis for all of the 200 columns at once ?
>> 
>> 
>> Regards
>> 
>> Allahisone


From cimentadaj at gmail.com  Fri Nov 10 17:15:19 2017
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 10 Nov 2017 17:15:19 +0100
Subject: [R] [R-pkgs] Release of ess 0.0.1
In-Reply-To: <23045.46014.298736.93636@stat.math.ethz.ch>
References: <CALdB+JGPQRf2pr8WMGGtg1ku2JQkyMH-0bqvpycDSa-rjQDXTw__27066.4877411493$1510224810$gmane$org@mail.gmail.com>
 <lzlgjfcxew.fsf@gnu.org> <AB0FBD69-0BEF-4A6A-B515-CA540546BD56@icloud.com>
 <CALdB+JH5khDk_CsTj96+MtcRbuZJH978Wx6QT-NRBJ4fT-b_gw@mail.gmail.com>
 <23045.46014.298736.93636@stat.math.ethz.ch>
Message-ID: <CALdB+JGEuEVDv-c0xCHJFnpxWiL7tJEpp-9=mbBm1-Sz35h4Ow@mail.gmail.com>

Hi Martin,

This makes a lot of sense. Once I update the package I will add it. Could
the authors of the 'ESSR' package also add a similar note to their
DESCRIPTION file once the R part of ESS is released?

  This package 'ESSR' is named to match the Emacs Speaks Statistics (ESS)
project.
  It is unrelated to the 'ess' package, designed to download data from the
European
  Social Survey available at http://www.europeansocialsurvey.org

Thanks for raising these thoughts.



-----------------------------------


Jorge Cimentada
*https://cimentadaj.github.io/ <https://cimentadaj.github.io/>*


On Fri, Nov 10, 2017 at 3:12 PM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Jorge Cimentada <cimentadaj at gmail.com>
> >>>>>     on Fri, 10 Nov 2017 14:31:43 +0100 writes:
>
>     > Thanks to all. Will consider this change in future releases.
>     > -----------------------------------
>
>
>     > Jorge Cimentada
>     > *https://cimentadaj.github.io/ <https://cimentadaj.github.io/>*
>
>
>     > On Fri, Nov 10, 2017 at 12:41 PM, Rainer Krug <
> rainer_krug at icloud.com>
>     > wrote:
>
>     >> On 9 Nov 2017, at 15:57, Sam Steingold <sds at gnu.org> wrote:
>     >>
>     >> * Jorge Cimentada <pvzragnqnw at tznvy.pbz> [2017-11-09 00:02:53
> +0100]:
>     >>
>     >> I'm happy to announce the release of ess 0.0.1 a package designed to
>     >> download data from the European Social Survey
>     >>
>     >>
>     >> Given the existence of ESS (Emacs Speaks Statistics -
>     >> https://ess.r-project.org/) the package name "ess" seems
> unfortunate.
>     >>
>     >>
>     >> Agreed. I would suggest to rename the package to avoid conflicts
> (ESS
>     >> includes some R code, And I wouldn?t wonder if they would like to
> include
>     >> it in a package?).
>
> As a matter of fact, we (the ESS core developers) have e-chatted
> about this and came to the conclusion that we could get along fine with
> an unrelated R package called 'ess', notably as the acronym also
> makes sense for the European Social Survey.
>
> We'd like to ask the 'ess' package authors to add something like the
> following to their ess/DESCRIPTION file:
>
>   This package ess is named to match the European Social Survey (ESS).
>   It is unrelated to the Emacs Speaks Statistics (ESS) project, an
>   emacs-based Integrated Development Environment hosted at
>   https://ess.r-project.org
>
> and last but not least we have thought of 'reserving'  ESSR  as
> the name of a CRAN package that we'd consider using for the R
> part of ESS (there are others, considerably less used, notably
> Julia, Stata and SAS).
>
> Martin Maechler, ETH Zurich
> for ESS core developers
>
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Fri Nov 10 17:28:44 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 10 Nov 2017 18:28:44 +0200
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <8B53D3BF-BE40-46EA-B583-54152C6A09AD@me.com>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>
 <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>
 <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <0D3189D6-117D-48B6-9534-CD3751B7328C@utoronto.ca>
 <8B53D3BF-BE40-46EA-B583-54152C6A09AD@me.com>
Message-ID: <CAGgJW77tHAsec7u_-wVvTKBBRg__j3U3iXhwAjSPsOQxehvw0g@mail.gmail.com>

How about this workaround - add 1 to the vector
x <- c(1,0,2,1,0,2,2,0,2,1)
tabulate(x)
# [1] 3 4
tabulate(x+1)
#[1] 3 3 4


On Fri, Nov 10, 2017 at 4:34 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> To clarify the default behavior that Boris is referencing below, note the
> definition of the 'bin' argument to the tabulate() function:
>
> bin: a numeric vector ***(of positive integers)***, or a factor. Long
> vectors are supported.
>
> I added the asterisks for emphasis.
>
> This is also noted in the examples used for the function in ?tabulate at
> the bottom of the help page.
>
> The second argument, 'nbins', which defaults to max(1, bin, na.rm = TRUE),
> also affects the output:
>
> > tabulate(c(2, 3, 5))
> [1] 0 1 1 0 1
>
> In this case, with each element in the returned vector indicating how many
> 1's, 2's, 3's, 4's and 5's are present in the source vector.
>
> Compare that to:
>
> > tabulate(c(2, 3, 5), nbins = 3)
> [1] 0 1 1
>
> In the above example, 5 is ignored.
>
> Note also that tabulate(), unlike table(), does not return a named vector,
> just the frequencies.
>
> While tabulate() is used within the table() function, reviewing the code
> for the latter reveals how the default behavior of tabulate() is modified
> and preceded/wrapped in other code for use there.
>
> Regards,
>
> Marc Schwartz
>
>
> > On Nov 10, 2017, at 8:43 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> >
> > |> x <- sample(0:2, 10, replace = TRUE)
> > |> x
> > [1] 1 0 2 1 0 2 2 0 2 1
> > |> tabulate(x)
> > [1] 3 4
> > |> table(x)
> > x
> > 0 1 2
> > 3 3 4
> >
> >
> >
> > B.
> >
> >
> >
> >> On Nov 10, 2017, at 4:32 AM, Allaisone 1 <allaisone1 at hotmail.com>
> wrote:
> >>
> >>
> >>
> >> Thank you for your effort Bert..,
> >>
> >>
> >> I knew what is the problem now, the values (1,2,3) were only an
> example. The values I have are 0 , 1, 2 . Tabulate () function seem to
> ignore calculating the frequency of 0 values and this is my exact problem
> as the frequency of 0 values should also be calculated for the maf to be
> calculated correctly.
> >>
> >> ________________________________
> >> From: Bert Gunter <bgunter.4567 at gmail.com>
> >> Sent: 09 November 2017 23:51:35
> >> To: Allaisone 1; R-help
> >> Subject: Re: [R] Calculating frequencies of multiple values in 200
> colomns
> >>
> >> [[elided Hotmail spam]]
> >>
> >> "For example, if I have the values : 1 , 2 , 3 in each column, applying
> Tabulate () would calculate the frequency of 1 and 2 without 3"
> >>
> >> Huh??
> >>
> >>> x <- sample(1:3,10,TRUE)
> >>> x
> >> [1] 1 3 1 1 1 3 2 3 2 1
> >>> tabulate(x)
> >> [1] 5 2 3
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >> On Thu, Nov 9, 2017 at 3:44 PM, Allaisone 1 <allaisone1 at hotmail.com<
> mailto:allaisone1 at hotmail.com>> wrote:
> >>
> >> Thank you so much for your replay
> >>
> >>
> >> Actually, I tried apply() function but struggled with the part of
> writing the appropriate function inside it which calculate the frequency of
> the 3 values. Tabulate () function is a good start but the problem is that
> this calculates the frequency of two values only per column which means
> that when I apply maf () function , maf value will be calculated using the
> frequency of these 2 values only without considering the frequency of the
> 3rd value. For example, if I have the values : 1 , 2 , 3 in each column,
> applying Tabulate () would calculate the frequency of 1 and 2 without 3 . I
> need a way to calculate the frequencies of all of the 3 values so the
> calculation of maf will be correct as it will consider all the 3
> frequencies but not only 2 .
> >>
> >>
> >> Regards
> >>
> >> Allahisone
> >>
> >> ________________________________
> >> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com
> >>
> >> Sent: 09 November 2017 20:56:39
> >> To: Allaisone 1
> >> Cc: r-help at R-project.org
> >> Subject: Re: [R] Calculating frequencies of multiple values in 200
> colomns
> >>
> >> This is not a good way to do things! R has many powerful built in
> functions to do this sort of thing for you. Searching  -- e.g. at
> rseek.org<http://rseek.org> or even a plain old google search -- can help
> you find them. Also, it looks like you need to go through a tutorial or two
> to learn more about R's basic functionality.
> >>
> >> In this case, something like (no reproducible example given, so can't
> confirm):
> >>
> >> apply(Values, 2, function(x)maf(tabulate(x)))
> >>
> >> should be close to what you want .
> >>
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >> On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com<
> mailto:allaisone1 at hotmail.com>> wrote:
> >>
> >> Hi All
> >>
> >>
> >> I have a dataset of 200 columns and 1000 rows , there are 3 repeated
> values under each column (7,8,10). I wanted to calculate the frequency of
> each value under each column and then apply the function maf () given that
> the frequency of each value is known. I can do the analysis step by step
> like this :-
> >>
> >>
> >>> Values
> >>
> >>
> >>        A       B       C       ... 200
> >>
> >> 1      7       10      7
> >>
> >> 2      7       8        7
> >>
> >> 3      10     8        7
> >>
> >> 4       8      7         10
> >>
> >> .
> >>
> >> .
> >>
> >> .
> >>
> >>
> >>
> >>
> >> For column A : I calculate the frequency for the 3 values as follows :
> >>
> >> count7 <- length(which(Values$A == 7))
> >>
> >> count8 <- length(which(Values$A == 8))
> >>
> >> count10 <- length(which(Values$A == 10))
> >>
> >>
> >> count7 = 2, count8 = 1 , count10= 1.
> >>
> >>
> >> Then, I create a vector  and type the frequencies manually :
> >>
> >>
> >> Freq<- c( count7=2  ,count8= 1,count10=1)
> >>
> >>
> >> Then I apply the function maf ()  :-
> >>
> >> maf(Freq)
> >>
> >>
> >> This gives me the result I need for column A , could you please help me
> >>
> >> to perform the analysis for all of the 200 columns at once ?
> >>
> >>
> >> Regards
> >>
> >> Allahisone
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Nov 10 17:32:34 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 10 Nov 2017 08:32:34 -0800
Subject: [R] Calculating frequencies of multiple values in 200 colomns
In-Reply-To: <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB00201137AF54C5DF8212DEA180570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQYEcL7f_5JUEXdEvz_Zuojx9JWCTwhD+wwv87uGfoxBQ@mail.gmail.com>
 <AM5P195MB002016961C23F69EB0E5CDF280570@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbSE4fzqieS195VTqjd=rD94C+RyBx5rxEopjA_Q6nL3Qw@mail.gmail.com>
 <AM5P195MB00209C46E3BD29712AD39B3A80540@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcbNEt9=ykp84xLhc_4tdygz2JYT5x3HETOCuH3j9wmuRg@mail.gmail.com>

Use table(factor(x, levels=your3values))

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Nov 10, 2017 at 1:32 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:

>
>
> Thank you for your effort Bert..,
>
>
> I knew what is the problem now, the values (1,2,3) were only an example.
> The values I have are 0 , 1, 2 . Tabulate () function seem to ignore
> calculating the frequency of 0 values and this is my exact problem as the
> frequency of 0 values should also be calculated for the maf to be
> calculated correctly.
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 09 November 2017 23:51:35
> To: Allaisone 1; R-help
> Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns
>
> [[elided Hotmail spam]]
>
> "For example, if I have the values : 1 , 2 , 3 in each column, applying
> Tabulate () would calculate the frequency of 1 and 2 without 3"
>
> Huh??
>
> > x <- sample(1:3,10,TRUE)
> > x
>  [1] 1 3 1 1 1 3 2 3 2 1
> > tabulate(x)
> [1] 5 2 3
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Nov 9, 2017 at 3:44 PM, Allaisone 1 <allaisone1 at hotmail.com<
> mailto:allaisone1 at hotmail.com>> wrote:
>
> Thank you so much for your replay
>
>
> Actually, I tried apply() function but struggled with the part of writing
> the appropriate function inside it which calculate the frequency of the 3
> values. Tabulate () function is a good start but the problem is that this
> calculates the frequency of two values only per column which means that
> when I apply maf () function , maf value will be calculated using the
> frequency of these 2 values only without considering the frequency of the
> 3rd value. For example, if I have the values : 1 , 2 , 3 in each column,
> applying Tabulate () would calculate the frequency of 1 and 2 without 3 . I
> need a way to calculate the frequencies of all of the 3 values so the
> calculation of maf will be correct as it will consider all the 3
> frequencies but not only 2 .
>
>
> Regards
>
> Allahisone
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
> Sent: 09 November 2017 20:56:39
> To: Allaisone 1
> Cc: r-help at R-project.org
> Subject: Re: [R] Calculating frequencies of multiple values in 200 colomns
>
> This is not a good way to do things! R has many powerful built in
> functions to do this sort of thing for you. Searching  -- e.g. at
> rseek.org<http://rseek.org> or even a plain old google search -- can help
> you find them. Also, it looks like you need to go through a tutorial or two
> to learn more about R's basic functionality.
>
> In this case, something like (no reproducible example given, so can't
> confirm):
>
> apply(Values, 2, function(x)maf(tabulate(x)))
>
> should be close to what you want .
>
>
> Cheers,
> Bert
>
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Nov 9, 2017 at 11:44 AM, Allaisone 1 <allaisone1 at hotmail.com<
> mailto:allaisone1 at hotmail.com>> wrote:
>
> Hi All
>
>
> I have a dataset of 200 columns and 1000 rows , there are 3 repeated
> values under each column (7,8,10). I wanted to calculate the frequency of
> each value under each column and then apply the function maf () given that
> the frequency of each value is known. I can do the analysis step by step
> like this :-
>
>
> > Values
>
>
>          A       B       C       ... 200
>
> 1      7       10      7
>
> 2      7       8        7
>
> 3      10     8        7
>
> 4       8      7         10
>
> .
>
> .
>
> .
>
>
>
>
> For column A : I calculate the frequency for the 3 values as follows :
>
>  count7 <- length(which(Values$A == 7))
>
> count8 <- length(which(Values$A == 8))
>
> count10 <- length(which(Values$A == 10))
>
>
> count7 = 2, count8 = 1 , count10= 1.
>
>
> Then, I create a vector  and type the frequencies manually :
>
>
>  Freq<- c( count7=2  ,count8= 1,count10=1)
>
>
> Then I apply the function maf ()  :-
>
> maf(Freq)
>
>
> This gives me the result I need for column A , could you please help me
>
> to perform the analysis for all of the 200 columns at once ?
>
>
> Regards
>
> Allahisone
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Stephen.Bond at cibc.com  Fri Nov 10 17:49:54 2017
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Fri, 10 Nov 2017 16:49:54 +0000
Subject: [R] update R version in windows
Message-ID: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>

Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
If I manually upgrade, then I have to manually re-install 50 packages.
Thank you.

Stephen B


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Nov 10 17:59:29 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 10 Nov 2017 16:59:29 +0000
Subject: [R] update R version in windows
In-Reply-To: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <bb615e54-035e-9a46-ac6c-0b25a1db25da@dewey.myzen.co.uk>

Dear Stephen

Does section 2.8 in the Windows FAQ help you?

Michael

On 10/11/2017 16:49, Bond, Stephen wrote:
> Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
> If I manually upgrade, then I have to manually re-install 50 packages.
> Thank you.
> 
> Stephen B
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Fri Nov 10 18:00:04 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Nov 2017 09:00:04 -0800
Subject: [R] update R version in windows
In-Reply-To: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <CAGxFJbQV8E4j8jBRfG07QcygBjPJ1JtL6rEVquZujLdnvy1NFQ@mail.gmail.com>

?update.packages

Should take care of packages. Manually reinstalling R binaries seems
straightforward enough that it isn't much of a burden; but installing from
source may be a different story, depending on your OS.

The RStudio interface automates much of this, but it may not be enough for
you or what you want.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Nov 10, 2017 at 8:49 AM, Bond, Stephen <Stephen.Bond at cibc.com>
wrote:

> Is there a utility which will allow me to upgrade my R version and update
> all packages from the old version?
> If I manually upgrade, then I have to manually re-install 50 packages.
> Thank you.
>
> Stephen B
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Fri Nov 10 18:16:06 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 10 Nov 2017 12:16:06 -0500
Subject: [R] update R version in windows
In-Reply-To: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <CAGx1TMD==_hhPidfUP70zPWcppmA4hAczRLv=CzLFp4T3vztwA@mail.gmail.com>

Try the installr package. It was designed for this purpose.

On Fri, Nov 10, 2017 at 11:49 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
> If I manually upgrade, then I have to manually re-install 50 packages.
> Thank you.
>
> Stephen B
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From janoroyland at outlook.com  Fri Nov 10 17:04:10 2017
From: janoroyland at outlook.com (=?iso-8859-1?Q?Jan_Olsen_R=F8yland?=)
Date: Fri, 10 Nov 2017 16:04:10 +0000
Subject: [R] R and LINGO?
Message-ID: <HE1PR0202MB2875B2D44AA2BC744819A89DB5540@HE1PR0202MB2875.eurprd02.prod.outlook.com>

Hei
Im struggling with this problem:
b) Another company wants to compose the optimal project portfolio based on the following 5-
year project proposals. In the table, the cash flow for each project in each year is shown.
Project 1 Project 2 Project 3 Project 4 Project 5 Project 6
1st year of the project -58 -32 -18 -31 -33 -39
2nd year of the project 17 17 11 4 21 30
3rd year of the project 26 30 13 19 20 9
4th year of the project 18 7 4 7 22 13
5th year of the project 40 6 7 17 6 13
In this case, the company can also choose which year each project should commence. These six
candidate projects can begin either in 2018, in 2019 or in 2020, or not at all.
The current proposal is to undertake project 1, 2, 3 and 5, with project 3 and 5 starting in 2018,
project 2 in 2019 and project 1 in 2020. Available funds by the end of year 2017 will be 70 mill.
The resulting cash flow is given in the following table:
Project 1 Project 2 Project 3 Project 5
Total cash flow
from projects
Available
funds
2017 70
2018 -18 -33 -51 19
2019 -32 11 21 0 19
2020 -58 17 13 20 -8 11
2021 17 30 4 22 73 84
2022 26 7 7 6 46 130
2023 18 6 24 154
2024 40 40 194
Formulate an optimization model in LINGO to determine which projects to undertake, and in which
years. The goal is to maximize available funds by the end of year 2024, while making sure that
available funds are always non-negative throughout the planning horizon. How much can the
improve compared to the current proposal? (For simplicity, assume zero discount rate.)

Med Vennelig Hilsen
Jan Olsen R?yland


	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Fri Nov 10 19:18:41 2017
From: profjcnash at gmail.com (J C Nash)
Date: Fri, 10 Nov 2017 13:18:41 -0500
Subject: [R] update R version in windows
Message-ID: <eb6abf16-d156-b648-6e47-d3236ca13971@gmail.com>

However, trying this on Linux Mint gave

  package ?installr? is not available (for R version 3.4.2)

Has the package not been updated yet?


JN


Try the installr package. It was designed for this purpose.

On Fri, Nov 10, 2017 at 11:49 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
> If I manually upgrade, then I have to manually re-install 50 packages.
> Thank you.
>
> Stephen B
>
>


From rmh at temple.edu  Fri Nov 10 19:25:51 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 10 Nov 2017 13:25:51 -0500
Subject: [R] update R version in windows
In-Reply-To: <eb6abf16-d156-b648-6e47-d3236ca13971@gmail.com>
References: <eb6abf16-d156-b648-6e47-d3236ca13971@gmail.com>
Message-ID: <CAGx1TMD-Vj=5ZsFL7ZLCTg0PJXP9d7kbbDNqrOunj6Wm6+x1gw@mail.gmail.com>

installr is Windows-specific.  From the DESCRIPTION
OS_type:windows

I would guess that some of it would work on other OS, but you would
have to check.
If it looks useful elsewhere you should tell Tal
Maintainer:Tal Galili <tal.galili at gmail.com>

Rich

On Fri, Nov 10, 2017 at 1:18 PM, J C Nash <profjcnash at gmail.com> wrote:
> However, trying this on Linux Mint gave
>
>   package ?installr? is not available (for R version 3.4.2)
>
> Has the package not been updated yet?
>
>
> JN
>
>
> Try the installr package. It was designed for this purpose.
>
> On Fri, Nov 10, 2017 at 11:49 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
>> Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
>> If I manually upgrade, then I have to manually re-install 50 packages.
>> Thank you.
>>
>> Stephen B
>>
>>


From Stephen.Bond at cibc.com  Fri Nov 10 19:33:49 2017
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Fri, 10 Nov 2017 18:33:49 +0000
Subject: [R] update R version in windows
In-Reply-To: <eb6abf16-d156-b648-6e47-d3236ca13971@gmail.com>
References: <eb6abf16-d156-b648-6e47-d3236ca13971@gmail.com>
Message-ID: <624EC9773CAB044ABA65327271BED9B6217FF5ED@CBMCC-X10-MB06.ad.cibc.com>

This issue does not exist on Linux. My Ubuntu updates both R and all packages.

Stephen B


-----Original Message-----
From: J C Nash [mailto:profjcnash at gmail.com] 
Sent: Friday, November 10, 2017 1:19 PM
To: r-help; RICHARD M. HEIBERGER; Bond, Stephen
Subject: Re: [R] update R version in windows

However, trying this on Linux Mint gave

  package ?installr? is not available (for R version 3.4.2)

Has the package not been updated yet?


JN


Try the installr package. It was designed for this purpose.

On Fri, Nov 10, 2017 at 11:49 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
> If I manually upgrade, then I have to manually re-install 50 packages.
> Thank you.
>
> Stephen B
>
>

From marc_schwartz at me.com  Fri Nov 10 19:37:16 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 10 Nov 2017 13:37:16 -0500
Subject: [R] R and LINGO?
In-Reply-To: <HE1PR0202MB2875B2D44AA2BC744819A89DB5540@HE1PR0202MB2875.eurprd02.prod.outlook.com>
References: <HE1PR0202MB2875B2D44AA2BC744819A89DB5540@HE1PR0202MB2875.eurprd02.prod.outlook.com>
Message-ID: <F9A555BF-2942-4B2E-B634-8F92EA1641DA@me.com>

Hi,

A few comments:

1. You appear to be replying to a post on the R-Help list from 2010:

  https://stat.ethz.ch/pipermail/r-help/2010-June/242714.html


2. Nothing that you have below appears to be directly related to R, but to LINGO:

  http://www.lindo.com/index.php/products/lingo-and-optimization-modeling

which appears to be a commercial product based upon a Google search.


3. If you need assistance with LINGO, contact them for support.


4. To the extent R is at all relevant to your problem, they appear to have an interface to R, which is also a commercial product:

  http://www.lindo.com/index.php/ls-downloads?catid=82&id=106:r-lingo-resource-page

You should contact them for support with the product.


5. Even if this was related to R, this appears to be a homework problem of some type and the R lists do not assist with homework.


Regards,

Marc Schwartz



> On Nov 10, 2017, at 11:04 AM, Jan Olsen R?yland <janoroyland at outlook.com> wrote:
> 
> Hei
> Im struggling with this problem:
> b) Another company wants to compose the optimal project portfolio based on the following 5-
> year project proposals. In the table, the cash flow for each project in each year is shown.
> Project 1 Project 2 Project 3 Project 4 Project 5 Project 6
> 1st year of the project -58 -32 -18 -31 -33 -39
> 2nd year of the project 17 17 11 4 21 30
> 3rd year of the project 26 30 13 19 20 9
> 4th year of the project 18 7 4 7 22 13
> 5th year of the project 40 6 7 17 6 13
> In this case, the company can also choose which year each project should commence. These six
> candidate projects can begin either in 2018, in 2019 or in 2020, or not at all.
> The current proposal is to undertake project 1, 2, 3 and 5, with project 3 and 5 starting in 2018,
> project 2 in 2019 and project 1 in 2020. Available funds by the end of year 2017 will be 70 mill.
> The resulting cash flow is given in the following table:
> Project 1 Project 2 Project 3 Project 5
> Total cash flow
> from projects
> Available
> funds
> 2017 70
> 2018 -18 -33 -51 19
> 2019 -32 11 21 0 19
> 2020 -58 17 13 20 -8 11
> 2021 17 30 4 22 73 84
> 2022 26 7 7 6 46 130
> 2023 18 6 24 154
> 2024 40 40 194
> Formulate an optimization model in LINGO to determine which projects to undertake, and in which
> years. The goal is to maximize available funds by the end of year 2024, while making sure that
> available funds are always non-negative throughout the planning horizon. How much can the
> improve compared to the current proposal? (For simplicity, assume zero discount rate.)
> 
> Med Vennelig Hilsen
> Jan Olsen R?yland
> 


From Stephen.Bond at cibc.com  Fri Nov 10 19:45:25 2017
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Fri, 10 Nov 2017 18:45:25 +0000
Subject: [R] update R version in windows
In-Reply-To: <CABDKo+zRc9EgeoPPSuDfBPmwF=Af4afyomL_8+i5bFMeiT0v+A@mail.gmail.com>
References: <624EC9773CAB044ABA65327271BED9B6217FF333@CBMCC-X10-MB06.ad.cibc.com>
 <CABDKo+zRc9EgeoPPSuDfBPmwF=Af4afyomL_8+i5bFMeiT0v+A@mail.gmail.com>
Message-ID: <624EC9773CAB044ABA65327271BED9B6217FF610@CBMCC-X10-MB06.ad.cibc.com>

Thanks Caitlin and Richard MH. Works great.

Stephen

From: Caitlin [mailto:bioprogrammer at gmail.com]
Sent: Friday, November 10, 2017 12:33 PM
To: Bond, Stephen
Subject: Re: [R] update R version in windows

install.packages("installr")

updateR()

rather...

On Friday, November 10, 2017, Bond, Stephen <Stephen.Bond at cibc.com<mailto:Stephen.Bond at cibc.com>> wrote:
Is there a utility which will allow me to upgrade my R version and update all packages from the old version?
If I manually upgrade, then I have to manually re-install 50 packages.
Thank you.

Stephen B


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<javascript:;> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Nov 10 20:21:21 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 10 Nov 2017 11:21:21 -0800
Subject: [R] R and LINGO?
In-Reply-To: <HE1PR0202MB2875B2D44AA2BC744819A89DB5540@HE1PR0202MB2875.eurprd02.prod.outlook.com>
References: <HE1PR0202MB2875B2D44AA2BC744819A89DB5540@HE1PR0202MB2875.eurprd02.prod.outlook.com>
Message-ID: <897CA479-C7F9-4A37-8801-A65597AA521E@dcn.davis.ca.us>

That is interesting that you are having difficulty. Well, not really... please read the Posting Guide:

a) No homework questions. Use the resources offered in your educational environment (school, MOOC, etc.).

b) If this is not homework then frame your question with example R code... this is a forum about R, not about finance (or other domain-specific concepts). You don't have to know the answer to ask it, but you have to show us which R skill or function you need help with, using example data and some attempt at a solution.

c) LINGO appears to be commercial software that offers an interface for R... the use of LINGO is definitely off topic here... we expect to be able to run your code examples using R and CRAN resources to be relevant to all R users. 
-- 
Sent from my phone. Please excuse my brevity.

On November 10, 2017 8:04:10 AM PST, "Jan Olsen R?yland" <janoroyland at outlook.com> wrote:
>Hei
>Im struggling with this problem:
>b) Another company wants to compose the optimal project portfolio based
>on the following 5-
>year project proposals. In the table, the cash flow for each project in
>each year is shown.
>Project 1 Project 2 Project 3 Project 4 Project 5 Project 6
>1st year of the project -58 -32 -18 -31 -33 -39
>2nd year of the project 17 17 11 4 21 30
>3rd year of the project 26 30 13 19 20 9
>4th year of the project 18 7 4 7 22 13
>5th year of the project 40 6 7 17 6 13
>In this case, the company can also choose which year each project
>should commence. These six
>candidate projects can begin either in 2018, in 2019 or in 2020, or not
>at all.
>The current proposal is to undertake project 1, 2, 3 and 5, with
>project 3 and 5 starting in 2018,
>project 2 in 2019 and project 1 in 2020. Available funds by the end of
>year 2017 will be 70 mill.
>The resulting cash flow is given in the following table:
>Project 1 Project 2 Project 3 Project 5
>Total cash flow
>from projects
>Available
>funds
>2017 70
>2018 -18 -33 -51 19
>2019 -32 11 21 0 19
>2020 -58 17 13 20 -8 11
>2021 17 30 4 22 73 84
>2022 26 7 7 6 46 130
>2023 18 6 24 154
>2024 40 40 194
>Formulate an optimization model in LINGO to determine which projects to
>undertake, and in which
>years. The goal is to maximize available funds by the end of year 2024,
>while making sure that
>available funds are always non-negative throughout the planning
>horizon. How much can the
>improve compared to the current proposal? (For simplicity, assume zero
>discount rate.)
>
>Med Vennelig Hilsen
>Jan Olsen R?yland
>
>
>	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Nov 10 20:33:05 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 10 Nov 2017 11:33:05 -0800
Subject: [R] update R version in windows
In-Reply-To: <624EC9773CAB044ABA65327271BED9B6217FF5ED@CBMCC-X10-MB06.ad.cibc.com>
References: <eb6abf16-d156-b648-6e47-d3236ca13971@gmail.com>
 <624EC9773CAB044ABA65327271BED9B6217FF5ED@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <B869A581-4D04-48A8-92DB-72239AFFEB03@dcn.davis.ca.us>

That only works if you use apt-get for all package installs... I don't even know if that is possible. Use of install.packages within R works the same on all platforms... that is, upgrading R by a minor version (3.3 to 3.4) causes R to go looking for user-installed packages in a new library directory, while patchlevel upgrades (3.4.1 to 3.4.2) keep using the same library directory (read the R Installation and Administration Manual).
-- 
Sent from my phone. Please excuse my brevity.

On November 10, 2017 10:33:49 AM PST, "Bond, Stephen" <Stephen.Bond at cibc.com> wrote:
>This issue does not exist on Linux. My Ubuntu updates both R and all
>packages.
>
>Stephen B
>
>
>-----Original Message-----
>From: J C Nash [mailto:profjcnash at gmail.com] 
>Sent: Friday, November 10, 2017 1:19 PM
>To: r-help; RICHARD M. HEIBERGER; Bond, Stephen
>Subject: Re: [R] update R version in windows
>
>However, trying this on Linux Mint gave
>
>  package ?installr? is not available (for R version 3.4.2)
>
>Has the package not been updated yet?
>
>
>JN
>
>
>Try the installr package. It was designed for this purpose.
>
>On Fri, Nov 10, 2017 at 11:49 AM, Bond, Stephen <Stephen.Bond at
>cibc.com> wrote:
>> Is there a utility which will allow me to upgrade my R version and
>update all packages from the old version?
>> If I manually upgrade, then I have to manually re-install 50
>packages.
>> Thank you.
>>
>> Stephen B
>>
>>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Sat Nov 11 01:20:15 2017
From: motyocska at yahoo.com (Andras Farkas)
Date: Sat, 11 Nov 2017 00:20:15 +0000 (UTC)
Subject: [R] effects package x axis labels
References: <566413594.606773.1510359615293.ref@mail.yahoo.com>
Message-ID: <566413594.606773.1510359615293@mail.yahoo.com>

Dear All,

probably a simple enough solution but don;t seem to be able to get my head around it...example based on a publicly available data set:

mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
library(effects)
plot(allEffects(mylogit)
? ? ?,axes=list(y=list(lab="Prob(xyz)"))
)

axes=list(y=list(lab="Prob(xyz)")) changes the y axis labels for all 3 plots... Any thoughts on how I could change the x axis labels to let say 'black' (plot 1), 'white'?(plot 2) and 'green' (plot 3)?for the 3 respective plots produced??


appreciate the help...

Andras?


From bhh at xs4all.nl  Sat Nov 11 11:25:59 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 11 Nov 2017 11:25:59 +0100
Subject: [R] weighted average grouped by variables
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8D67@SRVEXCHCM301.precheza.cz>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8D67@SRVEXCHCM301.precheza.cz>
Message-ID: <797B5053-2AD0-4966-ABB1-A344A14BAABC@xs4all.nl>


> On 9 Nov 2017, at 14:58, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
> Thanks for working example.
> 
> you could use split/ lapply approach, however it is probably not much better than dplyr method.
> 
> sapply(split(mydf, mydf$type), function(speed, n_vehicles) sum(mydf$speed*mydf$n_vehicles)/sum(mydf$n_vehicles))
> gives you averages
> 

The result of this calculation is:

     car light_duty heavy_duty motorcycle 
  36.54109   36.54109   36.54109   36.54109 

But this doesn't give the same result as the dplyr method which is:

            date_time       type      vel
               <dttm>     <fctr>    <dbl>
1 2017-10-17 13:00:00        car 36.39029
2 2017-10-17 13:00:00 light_duty 38.56522
3 2017-10-17 13:00:00 heavy_duty 37.53333
4 2017-10-17 13:00:00 motorcycle 36.08696

The base R way of getting the result should be modified slightly into

sapply(split(mydf, mydf$type), function(Z) sum(Z$speed*Z$n_vehicles)/sum(Z$n_vehicles))

Calculations are done on the elements of the list provided by split.
The result now is:

      car light_duty heavy_duty motorcycle 
  36.39029   38.56522   37.53333   36.08696 

Obviously now the same as the dplyr method.

Berend Hasselman

> aggregate(mydf$n_vehicles, list(mydf$type), sum)$x
> gives you sums
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Massimo
>> Bressan
>> Sent: Thursday, November 9, 2017 2:17 PM
>> To: r-help <r-help at r-project.org>
>> Subject: Re: [R] weighted average grouped by variables
>> 
>> Hello
>> 
>> an update about my question: I worked out the following solution (with the
>> package "dplyr")
>> 
>> library(dplyr)
>> 
>> mydf%>%
>> mutate(speed_vehicles=n_vehicles*mydf$speed) %>%
>> group_by(date_time,type) %>%
>> summarise(
>> sum_n_times_speed=sum(speed_vehicles),
>> n_vehicles=sum(n_vehicles),
>> vel=sum(speed_vehicles)/sum(n_vehicles)
>> )
>> 
>> 
>> In fact I was hoping to manage everything in a "one-go": i.e. without the need
>> to create the "intermediate" variable called "speed_vehicles" and with the use
>> of the function weighted.mean()
>> 
>> any hints for a different approach much appreciated
>> 
>> thanks
>> 
>> 
>> 
>> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
>> A: "r-help" <r-help at r-project.org>
>> Inviato: Gioved?, 9 novembre 2017 12:20:52
>> Oggetto: weighted average grouped by variables
>> 
>> hi all
>> 
>> I have this dataframe (created as a reproducible example)
>> 
>> mydf<-structure(list(date_time = structure(c(1508238000, 1508238000,
>> 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class =
>> c("POSIXct", "POSIXt"), tzone = ""), direction = structure(c(1L, 1L, 1L, 1L, 2L, 2L,
>> 2L), .Label = c("A", "B"), class = "factor"), type = structure(c(1L, 2L, 3L, 4L, 1L,
>> 2L, 3L), .Label = c("car", "light_duty", "heavy_duty", "motorcycle"), class =
>> "factor"), avg_speed = c(41.1029082774049, 40.3333333333333,
>> 40.3157894736842, 36.0869565217391, 33.4065155807365,
>> 37.6222222222222, 35.5), n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)),
>> .Names = c("date_time", "direction", "type", "speed", "n_vehicles"), row.names
>> = c(NA, -7L), class = "data.frame")
>> 
>> mydf
>> 
>> and I need to get to this final result
>> 
>> mydf_final<-structure(list(date_time = structure(c(1508238000, 1508238000,
>> 1508238000, 1508238000), class = c("POSIXct", "POSIXt"), tzone = ""), type =
>> structure(c(1L, 2L, 3L, 4L), .Label = c("car", "light_duty", "heavy_duty",
>> "motorcycle"), class = "factor"), weighted_avg_speed = c(36.39029, 38.56521,
>> 37.53333, 36.08696), n_vehicles = c(1153L,69L,45L,23L)), .Names =
>> c("date_time", "type", "weighted_avg_speed", "n_vehicles"), row.names =
>> c(NA, -4L), class = "data.frame")
>> 
>> mydf_final
>> 
>> 
>> my question:
>> how to compute a weighted mean i.e. "weighted_avg_speed"
>> from "speed" (the values whose weighted mean is to be computed) and
>> "n_vehicles" (the weights) grouped by "date_time" and "type"?
>> 
>> to be noted the complication of the case "motorcycle" (not present in both
>> directions)
>> 
>> any help for that?
>> 
>> thank you
>> 
>> max
>> 
>> 
>> 
>> --
>> 
>> ------------------------------------------------------------
>> Massimo Bressan
>> 
>> ARPAV
>> Agenzia Regionale per la Prevenzione e
>> Protezione Ambientale del Veneto
>> 
>> Dipartimento Provinciale di Treviso
>> Via Santa Barbara, 5/a
>> 31100 Treviso, Italy
>> 
>> tel: +39 0422 558545
>> fax: +39 0422 558516
>> e-mail: massimo.bressan at arpa.veneto.it
>> ------------------------------------------------------------
>> 
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Sat Nov 11 13:42:00 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Sat, 11 Nov 2017 14:42:00 +0200
Subject: [R] effects package x axis labels
In-Reply-To: <566413594.606773.1510359615293@mail.yahoo.com>
References: <566413594.606773.1510359615293.ref@mail.yahoo.com>
 <566413594.606773.1510359615293@mail.yahoo.com>
Message-ID: <CAGgJW77vVRLMZkdmKs4SAem=kODvKgCeE_E5B1NUp11tMOy=zQ@mail.gmail.com>

Hi Andras,
I have not used this package before but I did the following steps to arrive
at an answer. Hopefully both the answer is what you are looking for and
also the steps to understand how you can answer such questions yourself in
the future.
1. R is an object-oriented language, but there are several ways in which
classes are supported. In particular, methods for some classes don't reside
with the class but with extensions to "generic" functions. The 'plot'
function is such an example. So the first step is to understand the class
returned by the function allEffects.

> myObj <- allEffects(mylogit)
> class(myObj)
# efflist

2. Next look at the documentation for the extensions to 'plot' for an
'efflist' class

> ?plot.efflist

3. Search in the help documentation for 'axes' to understand what is going
on (they also supply a lot of examples at the end of the help page). A few
experiments and the following seems to do what you asked for:
> plot(allEffects(mylogit),
+
axes=list(x=list(gre=list(lab="black"),gpa=list(lab="white"),rank=list(lab="green")),
+                y=list(lab="Prob(xyz)")))

HTH,
Eric



On Sat, Nov 11, 2017 at 2:20 AM, Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Dear All,
>
> probably a simple enough solution but don;t seem to be able to get my head
> around it...example based on a publicly available data set:
>
> mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
> mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family =
> "binomial")
> library(effects)
> plot(allEffects(mylogit)
>      ,axes=list(y=list(lab="Prob(xyz)"))
> )
>
> axes=list(y=list(lab="Prob(xyz)")) changes the y axis labels for all 3
> plots... Any thoughts on how I could change the x axis labels to let say
> 'black' (plot 1), 'white' (plot 2) and 'green' (plot 3) for the 3
> respective plots produced?
>
>
> appreciate the help...
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kevin683 at gmail.com  Sat Nov 11 20:56:50 2017
From: kevin683 at gmail.com (Kevin Taylor)
Date: Sat, 11 Nov 2017 13:56:50 -0600
Subject: [R] Primer for working with survey data in R
Message-ID: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>

I am taking a behavioral stats graduate class and the instructor is using
SPSS. I'm trying to follow along in R.

Recently in class we started working with scales and survey data, computing
Cronbach's Alpha, reversing values for reverse coded items, etc.

Also, SPSS has some built in functionality for entering the meta-data for
your survey, e.g. the possible values for items, the text of the question,
etc.

I haven't been able to find any survey guidance for R other than how to run
the actual calculations (Cronbach's, reversing values).

Are there tutorials, books, or other primers, that would guide a newbie
step by step through using R for working with survey data? It would be
helpful to see how others are doing these things. (Not just how to run the
mathematical operations but how to work with and manage the data.) Possibly
this would be in conjunction with some packages such as Likert or Scales.

TIA.

--Kevin

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Nov 11 23:00:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Nov 2017 14:00:18 -0800
Subject: [R] Primer for working with survey data in R
In-Reply-To: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
References: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
Message-ID: <CAGxFJbSqJfwadoHknFXdZt6uT+Wb_RHR2PpLwXmojcWXz3zBFQ@mail.gmail.com>

Dunno. But ...

1. Web Search (eg on "Survey tutorials using R" and similar)

2. R's survey package, which includes vignettes.

3. CRAN Task View:  https://cran.r-project.org/web/views/SocialSciences.html


HTH.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Nov 11, 2017 at 11:56 AM, Kevin Taylor <kevin683 at gmail.com> wrote:

> I am taking a behavioral stats graduate class and the instructor is using
> SPSS. I'm trying to follow along in R.
>
> Recently in class we started working with scales and survey data, computing
> Cronbach's Alpha, reversing values for reverse coded items, etc.
>
> Also, SPSS has some built in functionality for entering the meta-data for
> your survey, e.g. the possible values for items, the text of the question,
> etc.
>
> I haven't been able to find any survey guidance for R other than how to run
> the actual calculations (Cronbach's, reversing values).
>
> Are there tutorials, books, or other primers, that would guide a newbie
> step by step through using R for working with survey data? It would be
> helpful to see how others are doing these things. (Not just how to run the
> mathematical operations but how to work with and manage the data.) Possibly
> this would be in conjunction with some packages such as Likert or Scales.
>
> TIA.
>
> --Kevin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Nov 11 23:10:00 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 11 Nov 2017 14:10:00 -0800
Subject: [R] Primer for working with survey data in R
In-Reply-To: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
References: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
Message-ID: <C5C1D1E3-6C54-4112-9D2B-6E40B9ACE072@comcast.net>


> On Nov 11, 2017, at 11:56 AM, Kevin Taylor <kevin683 at gmail.com> wrote:
> 
> I am taking a behavioral stats graduate class and the instructor is using
> SPSS. I'm trying to follow along in R.
> 
> Recently in class we started working with scales and survey data, computing
> Cronbach's Alpha, reversing values for reverse coded items, etc.
> 
> Also, SPSS has some built in functionality for entering the meta-data for
> your survey, e.g. the possible values for items, the text of the question,
> etc.
> 
> I haven't been able to find any survey guidance for R other than how to run
> the actual calculations (Cronbach's, reversing values).
> 
> Are there tutorials, books, or other primers, that would guide a newbie
> step by step through using R for working with survey data? It would be
> helpful to see how others are doing these things. (Not just how to run the
> mathematical operations but how to work with and manage the data.) Possibly
> this would be in conjunction with some packages such as Likert or Scales.

Try looking at:

http://personality-project.org/r/psych/

-- 
David.
> 
> TIA.
> 
> --Kevin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil at dcn.davis.ca.us  Sat Nov 11 23:35:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Nov 2017 14:35:03 -0800
Subject: [R] Primer for working with survey data in R
In-Reply-To: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
References: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
Message-ID: <B49E4D56-875B-4BFA-A524-8910ACEEA004@dcn.davis.ca.us>

You really should have pointed out that you cross-posted this question [1] so we wouldn't repeat things. You were already pointed at the task view on this subject there. Be sure to look for vignettes in the relevant packages.

I cannot point you to domain-specific examples, though I came across some in the brief search I did that lead me to your redundant question, so you probably ought to clarify what you have looked at and why it wasn't helpful. 

You mention specifying possible values... I will point out that many people turn off the automatic conversion to factor when reading categorical data, instead converting those columns to factors explicitly using the factor function:

dta$cat1 <- factor( dta$cat1, levels=c( "democrat", "republican", "libertarian", "independent", "other" ) )

There is also a package that focuses on factors ("forcats") that may have functions in it useful to your work.

I would put actual questions in a separate data frame with the question numbers and use the merge function if/when needed... but this is not my usual working area... some dedicated packages might put that info into attributes. 

[1] https://stats.stackexchange.com/questions/313220/doing-survey-analysis-in-r
-- 
Sent from my phone. Please excuse my brevity.

On November 11, 2017 11:56:50 AM PST, Kevin Taylor <kevin683 at gmail.com> wrote:
>I am taking a behavioral stats graduate class and the instructor is
>using
>SPSS. I'm trying to follow along in R.
>
>Recently in class we started working with scales and survey data,
>computing
>Cronbach's Alpha, reversing values for reverse coded items, etc.
>
>Also, SPSS has some built in functionality for entering the meta-data
>for
>your survey, e.g. the possible values for items, the text of the
>question,
>etc.
>
>I haven't been able to find any survey guidance for R other than how to
>run
>the actual calculations (Cronbach's, reversing values).
>
>Are there tutorials, books, or other primers, that would guide a newbie
>step by step through using R for working with survey data? It would be
>helpful to see how others are doing these things. (Not just how to run
>the
>mathematical operations but how to work with and manage the data.)
>Possibly
>this would be in conjunction with some packages such as Likert or
>Scales.
>
>TIA.
>
>--Kevin
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sat Nov 11 23:36:49 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 11 Nov 2017 22:36:49 +0000
Subject: [R] Primer for working with survey data in R
In-Reply-To: <29929_1510435630_vABLR9s1024264_CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
References: <29929_1510435630_vABLR9s1024264_CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83670DBC2@FHSDB4H16-2.csu.mcmaster.ca>

Dear Kevin,

In addition to the advice you've received, take a look at the survey package. It's not quite what you're asking for, but in fact it's probably more useful, in that it provides correct statistical inference for data collected in complex surveys. The package is described in an article,  T. Lumley (2004), Analysis of complex survey samples, Journal of Statistical Software 9(1): 1-19, and a book, T. Lumley, Complex Surveys: A Guide to Analysis Using R, Wiley, 2010, both by the package author.

I hope that this helps,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin Taylor
> Sent: Saturday, November 11, 2017 2:57 PM
> To: r-help at r-project.org
> Subject: [R] Primer for working with survey data in R
> 
> I am taking a behavioral stats graduate class and the instructor is using SPSS.
> I'm trying to follow along in R.
> 
> Recently in class we started working with scales and survey data, computing
> Cronbach's Alpha, reversing values for reverse coded items, etc.
> 
> Also, SPSS has some built in functionality for entering the meta-data for your
> survey, e.g. the possible values for items, the text of the question, etc.
> 
> I haven't been able to find any survey guidance for R other than how to run the
> actual calculations (Cronbach's, reversing values).
> 
> Are there tutorials, books, or other primers, that would guide a newbie step by
> step through using R for working with survey data? It would be helpful to see
> how others are doing these things. (Not just how to run the mathematical
> operations but how to work with and manage the data.) Possibly this would be
> in conjunction with some packages such as Likert or Scales.
> 
> TIA.
> 
> --Kevin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Nov 12 04:56:59 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 11 Nov 2017 19:56:59 -0800
Subject: [R] Primer for working with survey data in R
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83670DBC2@FHSDB4H16-2.csu.mcmaster.ca>
References: <29929_1510435630_vABLR9s1024264_CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83670DBC2@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <1363E923-EAAC-47AA-8861-497CDB9306EE@comcast.net>


> On Nov 11, 2017, at 2:36 PM, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Kevin,
> 
> In addition to the advice you've received, take a look at the survey package. It's not quite what you're asking for, but in fact it's probably more useful, in that it provides correct statistical inference for data collected in complex surveys. The package is described in an article,  T. Lumley (2004), Analysis of complex survey samples, Journal of Statistical Software 9(1): 1-19, and a book, T. Lumley, Complex Surveys: A Guide to Analysis Using R, Wiley, 2010, both by the package author.

Although the same thought occurred to me after reading the initial question, I decided against suggesting the survey package. I consulted the recommended book above and it has none of the requested statistics. It is designed for surveys that use complex sampling designs requiring weighting the observations. I also consulted the Social Sciences Task View and it seemed unhelpful for the specific requests. It seemed likely to me that even a graduate course in behavioral statistics would be focussed on the sorts of questions that the psych package delivers. The  website maintained by Revelle has several tutorials that include developed examples using R to deliver the requested measure. Obviously "reversing values" is something that would require learning basic R manipulation of factor variables.

-- 
David.

> 
> I hope that this helps,
> John
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin Taylor
>> Sent: Saturday, November 11, 2017 2:57 PM
>> To: r-help at r-project.org
>> Subject: [R] Primer for working with survey data in R
>> 
>> I am taking a behavioral stats graduate class and the instructor is using SPSS.
>> I'm trying to follow along in R.
>> 
>> Recently in class we started working with scales and survey data, computing
>> Cronbach's Alpha, reversing values for reverse coded items, etc.
>> 
>> Also, SPSS has some built in functionality for entering the meta-data for your
>> survey, e.g. the possible values for items, the text of the question, etc.
>> 
>> I haven't been able to find any survey guidance for R other than how to run the
>> actual calculations (Cronbach's, reversing values).
>> 
>> Are there tutorials, books, or other primers, that would guide a newbie step by
>> step through using R for working with survey data? It would be helpful to see
>> how others are doing these things. (Not just how to run the mathematical
>> operations but how to work with and manage the data.) Possibly this would be
>> in conjunction with some packages such as Likert or Scales.
>> 
>> TIA.
>> 
>> --Kevin
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From lists at dewey.myzen.co.uk  Sun Nov 12 11:15:51 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 12 Nov 2017 10:15:51 +0000
Subject: [R] Primer for working with survey data in R
In-Reply-To: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
References: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
Message-ID: <340cae3d-ae91-4757-7a3f-1c18c8143481@dewey.myzen.co.uk>

Dear Kevin

The nearest equivalent to the SPSS VALUE LABELS is the labels in 
factor(). If you want to attach labels to a whole question like VARIABLE 
LABELS then you may want to use an attribute using attr()

Michael

On 11/11/2017 19:56, Kevin Taylor wrote:
> I am taking a behavioral stats graduate class and the instructor is using
> SPSS. I'm trying to follow along in R.
> 
> Recently in class we started working with scales and survey data, computing
> Cronbach's Alpha, reversing values for reverse coded items, etc.
> 
> Also, SPSS has some built in functionality for entering the meta-data for
> your survey, e.g. the possible values for items, the text of the question,
> etc.
> 
> I haven't been able to find any survey guidance for R other than how to run
> the actual calculations (Cronbach's, reversing values).
> 
> Are there tutorials, books, or other primers, that would guide a newbie
> step by step through using R for working with survey data? It would be
> helpful to see how others are doing these things. (Not just how to run the
> mathematical operations but how to work with and manage the data.) Possibly
> this would be in conjunction with some packages such as Likert or Scales.
> 
> TIA.
> 
> --Kevin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From mdtiemann at gmail.com  Sun Nov 12 15:15:45 2017
From: mdtiemann at gmail.com (Michael Tiemann)
Date: Sun, 12 Nov 2017 09:15:45 -0500
Subject: [R] create waveform sawtooth
Message-ID: <6179F592-C76B-46BD-AC3E-3F774D69130F@gmail.com>

My tuneR sawtooth wave function generator is broken.

When I use the sine function, I get exactly what I expect: a sine wave whose frequency is defined by the freq parameter.  In particular, higher frequencies have shorter wavelengths (more cycles per second means shorter waves).  When I create a sawtooth wave, the opposite seems to occur: higher frequencies result in longer waves.  But that?s not all: as frequencies increase, it appears that wavelengths increase to infinite length, then get shorter again as the wave reverses, then it gets longer and flips again.

Here?s a small file that demonstrates the bad sawtooth waves:

library(tuneR)

sample_rate <- 12000
reverse <- FALSE
mycolors=c("red","orange","yellow","green","cyan","blue","violet","magenta")
plot(sawtooth(110,duration=round(sample_rate/100),samp.rate=sample_rate,xunit="samples")@left,type="l")
freqs <- c(111,112,113,114,115,116,117,118)
for (i in 1:length(freqs)) {
    temp <- sine(freqs[i],duration=round(sample_rate/100),samp.rate=sample_rate,xunit="samples")
    lines(temp at left,type="l",lty=2,col=mycolors[i])
}




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Nov 13 00:57:27 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 12 Nov 2017 15:57:27 -0800
Subject: [R] create waveform sawtooth
In-Reply-To: <6179F592-C76B-46BD-AC3E-3F774D69130F@gmail.com>
References: <6179F592-C76B-46BD-AC3E-3F774D69130F@gmail.com>
Message-ID: <1A47E1CA-E6D1-473D-9FA1-BA338A91F8FB@dcn.davis.ca.us>

Ccing the maintainer if the tuneR package. 

Looks to me like sawtooth (and square) don't behave as expected when using xunit="samples". Workaround is to use xunit="time" instead:

sawtooth(110,duration=1/100,samp.rate=sample_rate,xunit="time")

I looked at the code but found it to be opaque.
-- 
Sent from my phone. Please excuse my brevity.

On November 12, 2017 6:15:45 AM PST, Michael Tiemann <mdtiemann at gmail.com> wrote:
>My tuneR sawtooth wave function generator is broken.
>
>When I use the sine function, I get exactly what I expect: a sine wave
>whose frequency is defined by the freq parameter.  In particular,
>higher frequencies have shorter wavelengths (more cycles per second
>means shorter waves).  When I create a sawtooth wave, the opposite
>seems to occur: higher frequencies result in longer waves.  But that?s
>not all: as frequencies increase, it appears that wavelengths increase
>to infinite length, then get shorter again as the wave reverses, then
>it gets longer and flips again.
>
>Here?s a small file that demonstrates the bad sawtooth waves:
>
>library(tuneR)
>
>sample_rate <- 12000
>reverse <- FALSE
>mycolors=c("red","orange","yellow","green","cyan","blue","violet","magenta")
>plot(sawtooth(110,duration=round(sample_rate/100),samp.rate=sample_rate,xunit="samples")@left,type="l")
>freqs <- c(111,112,113,114,115,116,117,118)
>for (i in 1:length(freqs)) {
>temp <-
>sine(freqs[i],duration=round(sample_rate/100),samp.rate=sample_rate,xunit="samples")
>    lines(temp at left,type="l",lty=2,col=mycolors[i])
>}
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Nov 13 07:51:12 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 13 Nov 2017 06:51:12 +0000
Subject: [R] weighted average grouped by variables
In-Reply-To: <797B5053-2AD0-4966-ABB1-A344A14BAABC@xs4all.nl>
References: <10774838.27624927.1510226452328.JavaMail.zimbra@arpa.veneto.it>
 <226601418.27662629.1510233393919.JavaMail.zimbra@arpa.veneto.it>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB8D67@SRVEXCHCM301.precheza.cz>
 <797B5053-2AD0-4966-ABB1-A344A14BAABC@xs4all.nl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB9F29@SRVEXCHCM301.precheza.cz>

Hi Berend

Yes you are correct. My fault, I did not test it before sending.

Cheers
Petr

> -----Original Message-----
> From: Berend Hasselman [mailto:bhh at xs4all.nl]
> Sent: Saturday, November 11, 2017 11:26 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Massimo Bressan <massimo.bressan at arpa.veneto.it>; r-help <r-help at r-
> project.org>
> Subject: Re: [R] weighted average grouped by variables
>
>
> > On 9 Nov 2017, at 14:58, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Hi
> >
> > Thanks for working example.
> >
> > you could use split/ lapply approach, however it is probably not much better
> than dplyr method.
> >
> > sapply(split(mydf, mydf$type), function(speed, n_vehicles)
> > sum(mydf$speed*mydf$n_vehicles)/sum(mydf$n_vehicles))
> > gives you averages
> >
>
> The result of this calculation is:
>
>      car light_duty heavy_duty motorcycle
>   36.54109   36.54109   36.54109   36.54109
>
> But this doesn't give the same result as the dplyr method which is:
>
>             date_time       type      vel
>                <dttm>     <fctr>    <dbl>
> 1 2017-10-17 13:00:00        car 36.39029
> 2 2017-10-17 13:00:00 light_duty 38.56522
> 3 2017-10-17 13:00:00 heavy_duty 37.53333
> 4 2017-10-17 13:00:00 motorcycle 36.08696
>
> The base R way of getting the result should be modified slightly into
>
> sapply(split(mydf, mydf$type), function(Z)
> sum(Z$speed*Z$n_vehicles)/sum(Z$n_vehicles))
>
> Calculations are done on the elements of the list provided by split.
> The result now is:
>
>       car light_duty heavy_duty motorcycle
>   36.39029   38.56522   37.53333   36.08696
>
> Obviously now the same as the dplyr method.
>
> Berend Hasselman
>
> > aggregate(mydf$n_vehicles, list(mydf$type), sum)$x gives you sums
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Massimo Bressan
> >> Sent: Thursday, November 9, 2017 2:17 PM
> >> To: r-help <r-help at r-project.org>
> >> Subject: Re: [R] weighted average grouped by variables
> >>
> >> Hello
> >>
> >> an update about my question: I worked out the following solution
> >> (with the package "dplyr")
> >>
> >> library(dplyr)
> >>
> >> mydf%>%
> >> mutate(speed_vehicles=n_vehicles*mydf$speed) %>%
> >> group_by(date_time,type) %>%
> >> summarise(
> >> sum_n_times_speed=sum(speed_vehicles),
> >> n_vehicles=sum(n_vehicles),
> >> vel=sum(speed_vehicles)/sum(n_vehicles)
> >> )
> >>
> >>
> >> In fact I was hoping to manage everything in a "one-go": i.e. without
> >> the need to create the "intermediate" variable called
> >> "speed_vehicles" and with the use of the function weighted.mean()
> >>
> >> any hints for a different approach much appreciated
> >>
> >> thanks
> >>
> >>
> >>
> >> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> >> A: "r-help" <r-help at r-project.org>
> >> Inviato: Gioved?, 9 novembre 2017 12:20:52
> >> Oggetto: weighted average grouped by variables
> >>
> >> hi all
> >>
> >> I have this dataframe (created as a reproducible example)
> >>
> >> mydf<-structure(list(date_time = structure(c(1508238000, 1508238000,
> >> 1508238000, 1508238000, 1508238000, 1508238000, 1508238000), class =
> >> c("POSIXct", "POSIXt"), tzone = ""), direction = structure(c(1L, 1L,
> >> 1L, 1L, 2L, 2L, 2L), .Label = c("A", "B"), class = "factor"), type =
> >> structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L), .Label = c("car",
> >> "light_duty", "heavy_duty", "motorcycle"), class = "factor"),
> >> avg_speed = c(41.1029082774049, 40.3333333333333, 40.3157894736842,
> >> 36.0869565217391, 33.4065155807365, 37.6222222222222, 35.5),
> >> n_vehicles = c(447L, 24L, 19L, 23L, 706L, 45L, 26L)), .Names =
> >> c("date_time", "direction", "type", "speed", "n_vehicles"), row.names
> >> = c(NA, -7L), class = "data.frame")
> >>
> >> mydf
> >>
> >> and I need to get to this final result
> >>
> >> mydf_final<-structure(list(date_time = structure(c(1508238000,
> >> 1508238000, 1508238000, 1508238000), class = c("POSIXct", "POSIXt"),
> >> tzone = ""), type = structure(c(1L, 2L, 3L, 4L), .Label = c("car",
> >> "light_duty", "heavy_duty", "motorcycle"), class = "factor"),
> >> weighted_avg_speed = c(36.39029, 38.56521, 37.53333, 36.08696),
> >> n_vehicles = c(1153L,69L,45L,23L)), .Names = c("date_time", "type",
> >> "weighted_avg_speed", "n_vehicles"), row.names = c(NA, -4L), class =
> >> "data.frame")
> >>
> >> mydf_final
> >>
> >>
> >> my question:
> >> how to compute a weighted mean i.e. "weighted_avg_speed"
> >> from "speed" (the values whose weighted mean is to be computed) and
> >> "n_vehicles" (the weights) grouped by "date_time" and "type"?
> >>
> >> to be noted the complication of the case "motorcycle" (not present in
> >> both
> >> directions)
> >>
> >> any help for that?
> >>
> >> thank you
> >>
> >> max
> >>
> >>
> >>
> >> --
> >>
> >> ------------------------------------------------------------
> >> Massimo Bressan
> >>
> >> ARPAV
> >> Agenzia Regionale per la Prevenzione e Protezione Ambientale del
> >> Veneto
> >>
> >> Dipartimento Provinciale di Treviso
> >> Via Santa Barbara, 5/a
> >> 31100 Treviso, Italy
> >>
> >> tel: +39 0422 558545
> >> fax: +39 0422 558516
> >> e-mail: massimo.bressan at arpa.veneto.it
> >> ------------------------------------------------------------
> >>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a
> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s
> dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from your
> system.
> > If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance of
> the offer on the part of the recipient containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of the
> person represented by the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bayat194 at yahoo.com  Mon Nov 13 06:58:56 2017
From: bayat194 at yahoo.com (Javad Bayat)
Date: Mon, 13 Nov 2017 05:58:56 +0000 (UTC)
Subject: [R] Convert poly line to polygon in R
References: <1316118538.788642.1510552736908.ref@mail.yahoo.com>
Message-ID: <1316118538.788642.1510552736908@mail.yahoo.com>

I have a shape file as poly line and I want to convert it to polygon.Is it possible to do that in R?lake <-readShapeLines("./lake_main_utm.shp")proj4string(lake) <- CRS("+proj=utm +zone=39 +datum=WGS84")

Sincerely.

	[[alternative HTML version deleted]]


From bayat194 at yahoo.com  Mon Nov 13 07:04:45 2017
From: bayat194 at yahoo.com (Javad Bayat)
Date: Mon, 13 Nov 2017 06:04:45 +0000 (UTC)
Subject: [R] how to label station names on point
References: <993274400.791579.1510553085931.ref@mail.yahoo.com>
Message-ID: <993274400.791579.1510553085931@mail.yahoo.com>

I have a shapefile point and I plot it over my polygon. Is it possible to label station names over points?Sincerely.
S_Point = readOGR(".","point")plot(S_Point,add=TRUE,col="black",pch=20,cex=2)




	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Nov 13 09:31:21 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 13 Nov 2017 19:31:21 +1100
Subject: [R] how to label station names on point
In-Reply-To: <993274400.791579.1510553085931@mail.yahoo.com>
References: <993274400.791579.1510553085931.ref@mail.yahoo.com>
 <993274400.791579.1510553085931@mail.yahoo.com>
Message-ID: <CA+8X3fXROqagcLtCBa-Tg5z0YY9SJ5DPu5vBzOW+9SO8OtCQ0A@mail.gmail.com>

Hi Javad,
You can place text using the "text" function or for a slightly fancier
label, try boxed.labels in the plotrix package.

Jim


On Mon, Nov 13, 2017 at 5:04 PM, Javad Bayat via R-help
<r-help at r-project.org> wrote:
> I have a shapefile point and I plot it over my polygon. Is it possible to label station names over points?Sincerely.
> S_Point = readOGR(".","point")plot(S_Point,add=TRUE,col="black",pch=20,cex=2)
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Nov 13 09:47:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 13 Nov 2017 00:47:18 -0800
Subject: [R] Convert poly line to polygon in R
In-Reply-To: <1316118538.788642.1510552736908@mail.yahoo.com>
References: <1316118538.788642.1510552736908.ref@mail.yahoo.com>
 <1316118538.788642.1510552736908@mail.yahoo.com>
Message-ID: <366C4AFA-8611-48BA-AEAF-C9BF7FD1D87C@dcn.davis.ca.us>

Might want to post this on R-sig-geo.

Might also want to post in plain text format... see below how your message got messed up coming through the mailing list.
-- 
Sent from my phone. Please excuse my brevity.

On November 12, 2017 9:58:56 PM PST, Javad Bayat via R-help <r-help at r-project.org> wrote:
>I have a shape file as poly line and I want to convert it to polygon.Is
>it possible to do that in R?lake
><-readShapeLines("./lake_main_utm.shp")proj4string(lake) <-
>CRS("+proj=utm +zone=39 +datum=WGS84")
>
>Sincerely.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From albin.blaschka at standortsanalyse.net  Mon Nov 13 15:41:44 2017
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Mon, 13 Nov 2017 15:41:44 +0100
Subject: [R] Primer for working with survey data in R
In-Reply-To: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
References: <CAFw44i06yMGvNu_j5UQ_hUxUeA7OW_WWGZn8pOFiFHJYdqS_+A@mail.gmail.com>
Message-ID: <e20c10c99311f5554afebae5cb4fbf50@standortsanalyse.net>

Am 11.11.2017 20:56, schrieb Kevin Taylor:

>    Also, SPSS has some built in functionality for entering the 
> meta-data for
>    your survey, e.g. the possible values for items, the text of the 
> question,
>    etc.


Hello!
Maybe the sjmisc together with the sjplot package are helpful - 
specially the first one has explicitly functions for labeled data in the 
sense of SPSS...

http://www.strengejacke.de/sjPlot/sjmisc/
https://strengejacke.wordpress.com/sjplot-r-package/

HTH,
Albin


-- 
| Dr.rer.nat. Albin Blaschka
| Etrichstrasse 26, A-5020 Salzburg
| * www.standortsanalyse.net *
| * www.researchgate.net/profile/Albin_Blaschka *
| - It's hard to live in the mountains, hard but not hopeless!


From morkus at protonmail.com  Mon Nov 13 13:48:36 2017
From: morkus at protonmail.com (Morkus)
Date: Mon, 13 Nov 2017 07:48:36 -0500
Subject: [R] Where to get support for Rserve?
Message-ID: <bGORJByA-BQCZ9sTsENnLt4inqijbWdhGKTU3FHQnY9Tp06npccop5RsDS_B-ixpnq6lYMqqLcfWUJyHFmS41px6BZaRkoYlEcSMUmdn6fc=@protonmail.com>

Hello,

I'm using Rserve with Java and although it works OK for 50 or 60 requests, eventually Rserve simply stops responding and I have to force-quit and restart Rserve. During this time the JVM is fine and Tomcat (app server) is fine, too.

The basic Java code does this:
--------------------------------------------
1. Create an R Connection
2. Execute an R Script via Rserve "eval" statements
3. Close the R Connection.

I was going to use a memory profiler to see what was going on but Tomcat is not showing any Java-code memory leaks.

Looking at the Rserve page, I see everything about the Rseve author...except for a way to contact him (unless I somehow missed that.)

This may not be the correct R forum to ask this question, but I need to start somewhere.

*** Note, in the past I've posted messages like this to the R developer forum only to be told that that programming forum is not the right forum as it's only for "pure" R programming ***

Would appreciate any suggestions.

Thanks,

- M

Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov 13 17:34:49 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 13 Nov 2017 08:34:49 -0800
Subject: [R] Where to get support for Rserve?
In-Reply-To: <bGORJByA-BQCZ9sTsENnLt4inqijbWdhGKTU3FHQnY9Tp06npccop5RsDS_B-ixpnq6lYMqqLcfWUJyHFmS41px6BZaRkoYlEcSMUmdn6fc=@protonmail.com>
References: <bGORJByA-BQCZ9sTsENnLt4inqijbWdhGKTU3FHQnY9Tp06npccop5RsDS_B-ixpnq6lYMqqLcfWUJyHFmS41px6BZaRkoYlEcSMUmdn6fc=@protonmail.com>
Message-ID: <CAGxFJbTUNut4+yBTXbJ6=eQvT=ccwqeRs1JEjDGoiFLN5=HS8A@mail.gmail.com>

?maintainer

## i.e.

maintainer("rserve")

Also, please search. A web search on simply "rserve" brought up what
appeared to be many relevant hits.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Nov 13, 2017 at 4:48 AM, Morkus via R-help <r-help at r-project.org>
wrote:

> Hello,
>
> I'm using Rserve with Java and although it works OK for 50 or 60 requests,
> eventually Rserve simply stops responding and I have to force-quit and
> restart Rserve. During this time the JVM is fine and Tomcat (app server) is
> fine, too.
>
> The basic Java code does this:
> --------------------------------------------
> 1. Create an R Connection
> 2. Execute an R Script via Rserve "eval" statements
> 3. Close the R Connection.
>
> I was going to use a memory profiler to see what was going on but Tomcat
> is not showing any Java-code memory leaks.
>
> Looking at the Rserve page, I see everything about the Rseve
> author...except for a way to contact him (unless I somehow missed that.)
>
> This may not be the correct R forum to ask this question, but I need to
> start somewhere.
>
> *** Note, in the past I've posted messages like this to the R developer
> forum only to be told that that programming forum is not the right forum as
> it's only for "pure" R programming ***
>
> Would appreciate any suggestions.
>
> Thanks,
>
> - M
>
> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> email.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Nov 13 18:04:59 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 13 Nov 2017 09:04:59 -0800
Subject: [R] Where to get support for Rserve?
In-Reply-To: <bGORJByA-BQCZ9sTsENnLt4inqijbWdhGKTU3FHQnY9Tp06npccop5RsDS_B-ixpnq6lYMqqLcfWUJyHFmS41px6BZaRkoYlEcSMUmdn6fc=@protonmail.com>
References: <bGORJByA-BQCZ9sTsENnLt4inqijbWdhGKTU3FHQnY9Tp06npccop5RsDS_B-ixpnq6lYMqqLcfWUJyHFmS41px6BZaRkoYlEcSMUmdn6fc=@protonmail.com>
Message-ID: <CAF8bMcYZPfBWuQ0hErUgu-QkgknV6+m-a2qgDmDtCcO=JLVthQ@mail.gmail.com>

> I see everything about the Rseve author...except for a way
> to contact him (unless I somehow missed that.)

Look at the BugReports and Maintainer components of
packageDescription("Rserve").
Use the former if it exists - it is typically a URL.  The latter is also
given by
maintainer("Rserve").

Or use utils::bug.report(package="Rserve") to make a bug report on the
package.  It
uses the above logic to decide how to submit the report.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 13, 2017 at 4:48 AM, Morkus via R-help <r-help at r-project.org>
wrote:

> Hello,
>
> I'm using Rserve with Java and although it works OK for 50 or 60 requests,
> eventually Rserve simply stops responding and I have to force-quit and
> restart Rserve. During this time the JVM is fine and Tomcat (app server) is
> fine, too.
>
> The basic Java code does this:
> --------------------------------------------
> 1. Create an R Connection
> 2. Execute an R Script via Rserve "eval" statements
> 3. Close the R Connection.
>
> I was going to use a memory profiler to see what was going on but Tomcat
> is not showing any Java-code memory leaks.
>
> Looking at the Rserve page, I see everything about the Rseve
> author...except for a way to contact him (unless I somehow missed that.)
>
> This may not be the correct R forum to ask this question, but I need to
> start somewhere.
>
> *** Note, in the past I've posted messages like this to the R developer
> forum only to be told that that programming forum is not the right forum as
> it's only for "pure" R programming ***
>
> Would appreciate any suggestions.
>
> Thanks,
>
> - M
>
> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> email.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From morkus at protonmail.com  Mon Nov 13 19:52:41 2017
From: morkus at protonmail.com (Morkus)
Date: Mon, 13 Nov 2017 13:52:41 -0500
Subject: [R] Where to get support for Rserve?
In-Reply-To: <CAGxFJbTUNut4+yBTXbJ6=eQvT=ccwqeRs1JEjDGoiFLN5=HS8A@mail.gmail.com>
References: <bGORJByA-BQCZ9sTsENnLt4inqijbWdhGKTU3FHQnY9Tp06npccop5RsDS_B-ixpnq6lYMqqLcfWUJyHFmS41px6BZaRkoYlEcSMUmdn6fc=@protonmail.com>
 <CAGxFJbTUNut4+yBTXbJ6=eQvT=ccwqeRs1JEjDGoiFLN5=HS8A@mail.gmail.com>
Message-ID: <Hhm7NHFzV83udXIPVtBu8ZD7KSL6vTDwhlwxpkx-hoNV9hYOrQ4GUnQnO3akD8liEhyZWa3zw5X4zX2nE7KIachBXjRoJ1OkYXBd8vWJcBc=@protonmail.com>

Hey Bert,

That's super helpful (maintainer ("rserve")). I had no idea. :)

So much good stuff right there in R.

I didn't find any relevant hits looking on the web for my particular problem, but I'll email the maintainer.

Thanks very much.

- M

Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.

> -------- Original Message --------
> Subject: Re: [R] Where to get support for Rserve?
> Local Time: November 13, 2017 11:34 AM
> UTC Time: November 13, 2017 4:34 PM
> From: bgunter.4567 at gmail.com
> To: Morkus <morkus at protonmail.com>
> r-help at r-project.org <r-help at r-project.org>
>
> ?maintainer
> ## i.e.
>
> maintainer("rserve")
>
> Also, please search. A web search on simply "rserve" brought up what appeared to be many relevant hits.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Nov 13, 2017 at 4:48 AM, Morkus via R-help <r-help at r-project.org> wrote:
>
>> Hello,
>>
>> I'm using Rserve with Java and although it works OK for 50 or 60 requests, eventually Rserve simply stops responding and I have to force-quit and restart Rserve. During this time the JVM is fine and Tomcat (app server) is fine, too.
>>
>> The basic Java code does this:
>> --------------------------------------------
>> 1. Create an R Connection
>> 2. Execute an R Script via Rserve "eval" statements
>> 3. Close the R Connection.
>>
>> I was going to use a memory profiler to see what was going on but Tomcat is not showing any Java-code memory leaks.
>>
>> Looking at the Rserve page, I see everything about the Rseve author...except for a way to contact him (unless I somehow missed that.)
>>
>> This may not be the correct R forum to ask this question, but I need to start somewhere.
>>
>> *** Note, in the past I've posted messages like this to the R developer forum only to be told that that programming forum is not the right forum as it's only for "pure" R programming ***
>>
>> Would appreciate any suggestions.
>>
>> Thanks,
>>
>> - M
>>
>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From nell.redu at hotmail.fr  Mon Nov 13 23:01:57 2017
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Mon, 13 Nov 2017 22:01:57 +0000
Subject: [R] Bootstrap analysis from a conditional logistic regression
Message-ID: <DM5PR05MB2793BC019CF0A98BDF95240F992B0@DM5PR05MB2793.namprd05.prod.outlook.com>

Nelly Reduan a partag? un fichier OneDrive avec vous. Pour l?afficher, cliquez sur le lien ci-dessous.


<https://1drv.ms/u/s!Apkg2VlgfYyDgRAeVIM0nEajx0Fb>
[https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Apkg2VlgfYyDgRAeVIM0nEajx0Fb>

Screenshot 2017-11-12 18.49.43.png<https://1drv.ms/u/s!Apkg2VlgfYyDgRAeVIM0nEajx0Fb>




Hello

How can I perform a bootstrap analysis from a conditional logistic regression? The model has been built using the `clogit` function (`survival` package)? The model has the following structure:

    mod <- clogit(event ~ forest + log_area +forest:log_time  + cluster(ID_individual)  +   strata(ID_strata), method = "efron", data = data , x=T, y=T)

Using bootstrapping, I would like to have a measure of uncertainty around the estimates of beta coefficients.

I am using the following code but I don't know how to consider strata and cluster arguments.

    library(boot)
    boot.clogit <- function(data, indices){
      new_data <- data[indices,]
      mod <- clogit(event ~ forest + log_area + forest:log_time  + cluster(ID_individual)  +  strata(ID_strata),
                    method = "efron", data = new_data, x=T, y=T)
      coefficients(mod)
    }

    boot_data <- boot(data=data, statistic=boot.clogit, R=5000)

I have attached an overview of my data set.

Thank you very much for your time.
Best regards,
Nell






	[[alternative HTML version deleted]]


From mdtiemann at gmail.com  Mon Nov 13 23:28:41 2017
From: mdtiemann at gmail.com (Michael Tiemann)
Date: Mon, 13 Nov 2017 17:28:41 -0500
Subject: [R] create waveform sawtooth
In-Reply-To: <1A47E1CA-E6D1-473D-9FA1-BA338A91F8FB@dcn.davis.ca.us>
References: <6179F592-C76B-46BD-AC3E-3F774D69130F@gmail.com>
 <1A47E1CA-E6D1-473D-9FA1-BA338A91F8FB@dcn.davis.ca.us>
Message-ID: <CAGzp6CHvkkPv6QzaEiRX8FfMSGAWeVe3RQn4-eZNdN03QmquCw@mail.gmail.com>

Here is perhaps a better sawtooth wave generator:

sawtooth <- function(freq, duration = samp.rate, from = 0, samp.rate =
44100, bit = 1,

                     stereo = FALSE, xunit = c("samples", "time"), reverse
= FALSE, ...){

    xunit <- match.arg(xunit)

    durFrom <- preWaveform(freq = freq, duration = duration, from = from,

xunit = xunit, samp.rate = samp.rate)

    channel <-
rep(seq(1,-1,length=samp.rate/freq),length=durFrom["duration"])

    if(!is.logical(reverse) || length(reverse) != 1)

stop("'reverse' must be a logical value of length 1")

    if(reverse) channel <- rev(channel)

    postWaveform(channel = channel, samp.rate = samp.rate,

bit = bit, stereo = stereo, ...)

}


On Sun, Nov 12, 2017 at 6:57 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Ccing the maintainer if the tuneR package.
>
> Looks to me like sawtooth (and square) don't behave as expected when using
> xunit="samples". Workaround is to use xunit="time" instead:
>
> sawtooth(110,duration=1/100,samp.rate=sample_rate,xunit="time")
>
> I looked at the code but found it to be opaque.
> --
> Sent from my phone. Please excuse my brevity.
>
> On November 12, 2017 6:15:45 AM PST, Michael Tiemann <mdtiemann at gmail.com>
> wrote:
> >My tuneR sawtooth wave function generator is broken.
> >
> >When I use the sine function, I get exactly what I expect: a sine wave
> >whose frequency is defined by the freq parameter.  In particular,
> >higher frequencies have shorter wavelengths (more cycles per second
> >means shorter waves).  When I create a sawtooth wave, the opposite
> >seems to occur: higher frequencies result in longer waves.  But that?s
> >not all: as frequencies increase, it appears that wavelengths increase
> >to infinite length, then get shorter again as the wave reverses, then
> >it gets longer and flips again.
> >
> >Here?s a small file that demonstrates the bad sawtooth waves:
> >
> >library(tuneR)
> >
> >sample_rate <- 12000
> >reverse <- FALSE
> >mycolors=c("red","orange","yellow","green","cyan","blue",
> "violet","magenta")
> >plot(sawtooth(110,duration=round(sample_rate/100),samp.
> rate=sample_rate,xunit="samples")@left,type="l")
> >freqs <- c(111,112,113,114,115,116,117,118)
> >for (i in 1:length(freqs)) {
> >temp <-
> >sine(freqs[i],duration=round(sample_rate/100),samp.rate=
> sample_rate,xunit="samples")
> >    lines(temp at left,type="l",lty=2,col=mycolors[i])
> >}
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Nov 13 23:55:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 13 Nov 2017 14:55:11 -0800
Subject: [R] Bootstrap analysis from a conditional logistic regression
In-Reply-To: <DM5PR05MB2793BC019CF0A98BDF95240F992B0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB2793BC019CF0A98BDF95240F992B0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <ECD3A92F-8BD4-4C90-956D-25415BF329D4@comcast.net>


> On Nov 13, 2017, at 2:01 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> 
> Nelly Reduan a partag? un fichier OneDrive avec vous. Pour l?afficher, cliquez sur le lien ci-dessous.
> 
> 
> <https://1drv.ms/u/s!Apkg2VlgfYyDgRAeVIM0nEajx0Fb>
> [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Apkg2VlgfYyDgRAeVIM0nEajx0Fb>
> 
> Screenshot 2017-11-12 18.49.43.png<https://1drv.ms/u/s!Apkg2VlgfYyDgRAeVIM0nEajx0Fb>
> 
> 
> 
> 
> Hello
> 
> How can I perform a bootstrap analysis from a conditional logistic regression? The model has been built using the `clogit` function (`survival` package)? The model has the following structure:
> 
>    mod <- clogit(event ~ forest + log_area +forest:log_time  + cluster(ID_individual)  +   strata(ID_strata), method = "efron", data = data , x=T, y=T)
> 
> Using bootstrapping, I would like to have a measure of uncertainty around the estimates of beta coefficients.
> 
> I am using the following code but I don't know how to consider strata and cluster arguments.
> 
>    library(boot)
>    boot.clogit <- function(data, indices){
>      new_data <- data[indices,]
>      mod <- clogit(event ~ forest + log_area + forest:log_time  + cluster(ID_individual)  +  strata(ID_strata),
>                    method = "efron", data = new_data, x=T, y=T)
>      coefficients(mod)
>    }
> 
>    boot_data <- boot(data=data, statistic=boot.clogit, R=5000)
> 
> I have attached an overview of my data set.

You probably tried to attach something but you failed to note the section in the listinfo or posting guide where the list owners describe the rules for attachments. I think you would need to describe the sampling design more thoroughly. A simple description of the data layout may not be sufficient.

 The fact that you are clustering on individuals suggests you have some sort of repeated measures design and that you have somehow matched the individual to controls in some unstated ratio (handled by the strata. (Admittedly all guesswork and the more knowledgeable respondents (among which I'm not likely to reside)  are often hesitant to contribute substantive commentary unless they can narrow down range of possible design issues. I read Davison and Hinkley as suggesting that sampling by group but then keeping sampled groups undisturbed may have better chance of resulting in estimates of variances that match the superpopulation. See pages 100-102 of their book.

If my reading of that section is correct then I should think you would arrange you data so groups are in the long direction and single groups occupy a line of data with a single index. Then you would probably rearrange the data within the boot.clogit function so that the "inner" clogit call can handle it correctly.

-- 
David.
> 
> Thank you very much for your time.
> Best regards,
> Nell
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From acefix at rocketmail.com  Tue Nov 14 14:13:19 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 14 Nov 2017 13:13:19 +0000 (UTC)
Subject: [R] error message for function: lmer (from lme4 package)
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
Message-ID: <370300864.1670135.1510665199052@mail.yahoo.com>

Dear R Community,
My data have 3 conditions and each condition has 6 replicates. I am trying to fit my data for a linear mixed model using the lmer function from lme4 package to find the random effects of the replicates; however, I got the error message. Here are the example codes:
>example.3=data.frame(levels=as.numeric(XXX[,c(4)]),replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep("13",6)))> example.3? ? levels replicate conditions1? 43.1111 ? ? ? ? 0 ? ? ? ? 112? 42.0942 ? ? ? ? 1 ? ? ? ? 113? 57.8131 ? ? ? ? 2 ? ? ? ? 114? 57.1726 ? ? ? ? 3 ? ? ? ? 115? 77.8678 ? ? ? ? 4 ? ? ? ? 116? 44.7578 ? ? ? ? 5 ? ? ? ? 117? 69.5078 ? ? ? ? 0 ? ? ? ? 128? 52.0581 ? ? ? ? 1 ? ? ? ? 129? 40.0602 ? ? ? ? 2 ? ? ? ? 1210 45.5487 ? ? ? ? 3 ? ? ? ? 1211 43.6201 ? ? ? ? 4 ? ? ? ? 1212 60.4939 ? ? ? ? 5 ? ? ? ? 1213 64.1932 ? ? ? ? 0 ? ? ? ? 1314 53.4055 ? ? ? ? 1 ? ? ? ? 1315 59.6701 ? ? ? ? 2 ? ? ? ? 1316 52.6922 ? ? ? ? 3 ? ? ? ? 1317 53.8712 ? ? ? ? 4 ? ? ? ? 1318 60.2770 ? ? ? ? 5 ? ? ? ? 13> m.example.3=lmer(as.numeric(levels)~conditions+(conditions|replicate),data=example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable>?
Could anyone help me figure out how to fix the issue??
Thank you very much for any inputs!
Ace

	[[alternative HTML version deleted]]


From mikkel.grum at gmail.com  Tue Nov 14 15:15:03 2017
From: mikkel.grum at gmail.com (Mikkel Grum)
Date: Tue, 14 Nov 2017 14:15:03 +0000
Subject: [R] Dates to numeric in for loop
Message-ID: <CAHTNcxsLkwT_UprH_BCK-L0g+8JH0MU5ksB0P7Mjc+R38_cSyA@mail.gmail.com>

Hi

Can anyone explain why a date becomes numeric when you loop over a series
of dates?

> dt <- Sys.Date()
> dt
[1] "2017-11-14"
> class(dt)
[1] "Date"
> dts <- dt - 1:0
> class(dts)
[1] "Date"
>
> for (i in dts) {
+     print(i)
+     print(class(i))
+     print(as.Date(i, "1970-01-01"))
+     print(class(as.Date(i, "1970-01-01")))
+ }
[1] 17483
[1] "numeric"
[1] "2017-11-13"
[1] "Date"
[1] 17484
[1] "numeric"
[1] "2017-11-14"
[1] "Date"

Why is this apparently not a bug? Are there other types that change type
when looped over?

Kind regards
Mikkel



_____________________________________________________
*Mikkel Grum*
+44 7377337321 (mobile)
mikkelgrum (Skype)

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Nov 14 18:19:15 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 14 Nov 2017 09:19:15 -0800
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <370300864.1670135.1510665199052@mail.yahoo.com>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
Message-ID: <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>


> On Nov 14, 2017, at 5:13 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Dear R Community,
> My data have 3 conditions and each condition has 6 replicates. I am trying to fit my data for a linear mixed model using the lmer function from lme4 package to find the random effects of the replicates;

Better venue for this question might be SIG-mixed-models. See the link avaialble at the bottom of every posting from rhelp:

https://stat.ethz.ch/mailman/listinfo/r-help:



> however, I got the error message. Here are the example codes:
>> example.3=data.frame(levels=as.numeric(XXX[,c(4)]),replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep("13",6)))> example.3    levels replicate conditions1  43.1111         0         112  42.0942         1         113  57.8131         2         114  57.1726         3         115  77.8678         4         116  44.7578         5         117  69.5078         0         128  52.0581         1         129  40.0602         2         1210 45.5487         3         1211 43.6201         4         1212 60.4939         5         1213 64.1932         0         1314 53.4055         1         1315 59.6701         2         1316 52.6922         3         1317 53.8712         4         1318 60.2770         5         13> m.example.3=lmer(as.numeric(levels)~conditions+(conditions|replicate),data=example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable> 
> Could anyone help me figure out how to fix the issue? 
> Thank you very much for any inputs!
> Ace
> 
> 	[[alternative HTML version deleted]]

Complete mess. If you haven't yet been advised to posting in plain text, then this should be your wakeup call. If you have, then why are you ignoring sensible advice?


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil at dcn.davis.ca.us  Tue Nov 14 19:59:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 14 Nov 2017 10:59:42 -0800
Subject: [R] Dates to numeric in for loop
In-Reply-To: <CAHTNcxsLkwT_UprH_BCK-L0g+8JH0MU5ksB0P7Mjc+R38_cSyA@mail.gmail.com>
References: <CAHTNcxsLkwT_UprH_BCK-L0g+8JH0MU5ksB0P7Mjc+R38_cSyA@mail.gmail.com>
Message-ID: <72895D7A-CCF9-43AD-80D2-556F44BC7FF4@dcn.davis.ca.us>

"Date" means "numeric with an attribute of class='Date' ", so what actually happened was that the for loop dropped the class attribute. In most cases using the seq_along() function lets you step through index values to extract values from your original vectors. In general, any S3 object will behave this way in a for loop. 

for ( i in seq_along( dts ) ) {
  print( class( dts[ i ] ) )
}
-- 
Sent from my phone. Please excuse my brevity.

On November 14, 2017 6:15:03 AM PST, Mikkel Grum <mikkel.grum at gmail.com> wrote:
>Hi
>
>Can anyone explain why a date becomes numeric when you loop over a
>series
>of dates?
>
>> dt <- Sys.Date()
>> dt
>[1] "2017-11-14"
>> class(dt)
>[1] "Date"
>> dts <- dt - 1:0
>> class(dts)
>[1] "Date"
>>
>> for (i in dts) {
>+     print(i)
>+     print(class(i))
>+     print(as.Date(i, "1970-01-01"))
>+     print(class(as.Date(i, "1970-01-01")))
>+ }
>[1] 17483
>[1] "numeric"
>[1] "2017-11-13"
>[1] "Date"
>[1] 17484
>[1] "numeric"
>[1] "2017-11-14"
>[1] "Date"
>
>Why is this apparently not a bug? Are there other types that change
>type
>when looped over?
>
>Kind regards
>Mikkel
>
>
>
>_____________________________________________________
>*Mikkel Grum*
>+44 7377337321 (mobile)
>mikkelgrum (Skype)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruiyangliu94 at gmail.com  Tue Nov 14 21:43:22 2017
From: ruiyangliu94 at gmail.com (=?utf-8?B?5YiY55Ge6Ziz?=)
Date: Tue, 14 Nov 2017 14:43:22 -0600
Subject: [R] Converting a string to variable names
Message-ID: <3577B47C-2B27-4115-87CC-71F0F26C3B3E@gmail.com>

Hi,
Suppose that I want to do a series of plots with the y value for each plot as PC1, PC2, PC3? How could I accomplish this using a for loop?
Suppose the code like this:

For (index in seq(1,16)){
plot(x=(a given set of value),y=paste(?PC?,as.character(index),sep=??)
}

But this would not work because y is assigned a string instead of the variable names. So how could I assign y with a variable name instead of a string? Your reply would be appreciated!
Ruiyang Liu

From acefix at rocketmail.com  Tue Nov 14 21:49:58 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 14 Nov 2017 20:49:58 +0000 (UTC)
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
 <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
Message-ID: <1068192069.31543.1510692598176@mail.yahoo.com>

Hi, David,
Thank you very much for getting back to me! Sorry about the messy code example. I am re-posting here (including the error message):
> example.3=data.frame(levels=as.numeric(XXX[,c(4)]),replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep("13",6)))> example.3? ? levels replicate conditions1? 43.1111 ? ? ? ? 0 ? ? ? ? 112? 42.0942 ? ? ? ? 1 ? ? ? ? 113? 57.8131 ? ? ? ? 2 ? ? ? ? 114? 57.1726 ? ? ? ? 3 ? ? ? ? 115? 77.8678 ? ? ? ? 4 ? ? ? ? 116? 44.7578 ? ? ? ? 5 ? ? ? ? 117? 69.5078 ? ? ? ? 0 ? ? ? ? 128? 52.0581 ? ? ? ? 1 ? ? ? ? 129? 40.0602 ? ? ? ? 2 ? ? ? ? 1210 45.5487 ? ? ? ? 3 ? ? ? ? 1211 43.6201 ? ? ? ? 4 ? ? ? ? 1212 60.4939 ? ? ? ? 5 ? ? ? ? 1213 64.1932 ? ? ? ? 0 ? ? ? ? 1314 53.4055 ? ? ? ? 1 ? ? ? ? 1315 59.6701 ? ? ? ? 2 ? ? ? ? 1316 52.6922 ? ? ? ? 3 ? ? ? ? 1317 53.8712 ? ? ? ? 4 ? ? ? ? 1318 60.2770 ? ? ? ? 5 ? ? ? ? 13> m.example.3=lmer(as.numeric(levels)~conditions+(conditions|replicate),data=example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable>?
Please let me know if it is readable this time.?
Again, many thanks for your time and please help me fix the issue.
Kind regards,
Ace 

    On Tuesday, November 14, 2017 12:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
 

 
> On Nov 14, 2017, at 5:13 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Dear R Community,
> My data have 3 conditions and each condition has 6 replicates. I am trying to fit my data for a linear mixed model using the lmer function from lme4 package to find the random effects of the replicates;

Better venue for this question might be SIG-mixed-models. See the link avaialble at the bottom of every posting from rhelp:

https://stat.ethz.ch/mailman/listinfo/r-help:



> however, I got the error message. Here are the example codes:
>> example.3=data.frame(levels=as.numeric(XXX[,c(4)]),replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep("13",6)))> example.3? ? levels replicate conditions1? 43.1111? ? ? ? 0? ? ? ? 112? 42.0942? ? ? ? 1? ? ? ? 113? 57.8131? ? ? ? 2? ? ? ? 114? 57.1726? ? ? ? 3? ? ? ? 115? 77.8678? ? ? ? 4? ? ? ? 116? 44.7578? ? ? ? 5? ? ? ? 117? 69.5078? ? ? ? 0? ? ? ? 128? 52.0581? ? ? ? 1? ? ? ? 129? 40.0602? ? ? ? 2? ? ? ? 1210 45.5487? ? ? ? 3? ? ? ? 1211 43.6201? ? ? ? 4? ? ? ? 1212 60.4939? ? ? ? 5? ? ? ? 1213 64.1932? ? ? ? 0? ? ? ? 1314 53.4055? ? ? ? 1? ? ? ? 1315 59.6701? ? ? ? 2? ? ? ? 1316 52.6922? ? ? ? 3? ? ? ? 1317 53.8712? ? ? ? 4? ? ? ? 1318 60.2770? ? ? ? 5? ? ? ? 13> m.example.3=lmer(as.numeric(levels)~conditions+(conditions|replicate),data=example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable> 
> Could anyone help me figure out how to fix the issue? 
> Thank you very much for any inputs!
> Ace
> 
> ??? [[alternative HTML version deleted]]

Complete mess. If you haven't yet been advised to posting in plain text, then this should be your wakeup call. If you have, then why are you ignoring sensible advice?


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law






   
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Nov 14 23:39:10 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Nov 2017 09:39:10 +1100
Subject: [R] Converting a string to variable names
In-Reply-To: <3577B47C-2B27-4115-87CC-71F0F26C3B3E@gmail.com>
References: <3577B47C-2B27-4115-87CC-71F0F26C3B3E@gmail.com>
Message-ID: <CA+8X3fXjF6ZbjHmNvXtxx0t8Py_8jv4b2siP8y1jXT8NwdoPgA@mail.gmail.com>

Hi Ruiyang,
I think you want "get":

For (index in seq(1,16)){
plot(x=(a given set of value),y=get(paste(?PC?,as.character(index),sep=??)))
}

On Wed, Nov 15, 2017 at 7:43 AM, ??? <ruiyangliu94 at gmail.com> wrote:
> Hi,
> Suppose that I want to do a series of plots with the y value for each plot as PC1, PC2, PC3? How could I accomplish this using a for loop?
> Suppose the code like this:
>
> For (index in seq(1,16)){
> plot(x=(a given set of value),y=paste(?PC?,as.character(index),sep=??)
> }
>
> But this would not work because y is assigned a string instead of the variable names. So how could I assign y with a variable name instead of a string? Your reply would be appreciated!
> Ruiyang Liu
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reichmanj at sbcglobal.net  Wed Nov 15 00:03:33 2017
From: reichmanj at sbcglobal.net (Jeff Reichman	)
Date: Tue, 14 Nov 2017 17:03:33 -0600
Subject: [R] Aggregating Data
Message-ID: <012601d35d9c$cbf41a10$63dc4e30$@sbcglobal.net>

R-Help

I created a "shortdate"  for the purpose of aggregating each var (S72 .S119)
by daily sum , but not sure how to handle using a POSIXlt object.

> myData$shortdate <- strftime(myData$time, format="%Y/%m/%d")
> head(myData)
                 time s72 s79 s82 s83 s116 s119  shortdate
1 2016-10-03 00:00:00   0   0   1   0    0    0 2016/10/03
2 2016-10-03 01:00:00   0   0   0   0    0    0 2016/10/03
3 2016-10-03 02:00:00   0   0   0   0   24    0 2016/10/03
4 2016-10-03 03:00:00   1   0   0   0    0    0 2016/10/03
5 2016-10-03 04:00:00   0   0   0   0    1    0 2016/10/03
6 2016-10-03 05:00:00   1   0   1   0    0    1 2016/10/03

Jeff


	[[alternative HTML version deleted]]


From reichmanj at sbcglobal.net  Wed Nov 15 00:11:27 2017
From: reichmanj at sbcglobal.net (Jeff Reichman	)
Date: Tue, 14 Nov 2017 17:11:27 -0600
Subject: [R] Aggregating Data
Message-ID: <012b01d35d9d$e6b756e0$b42604a0$@sbcglobal.net>

R-Help

Please disregard as I figure something out, unless there is a more elegant
way ...

myData.sum <- aggregate(x =
myData[c("s72","s79","s82","s83","s116","s119")],
                     FUN = sum,
                     by = list(Group.date = myData$shortdate))
> head(myData.sum)
  Group.date s72 s79 s82 s83 s116 s119
1 2016/10/03  75  74  36  33   96   10
2 2016/10/04  90  76  40  56  137    9
3 2016/10/05 106  83  38  51   90   10
4 2016/10/06  93  87  31  43   97   15
5 2016/10/07  88  96  33  48  125   12
6 2016/10/08  64  39  22  30   63    5



I created a "shortdate"  for the purpose of aggregating each var (S72 .S119)
by daily sum , but not sure how to handle using a POSIXlt object.

> myData$shortdate <- strftime(myData$time, format="%Y/%m/%d")
> head(myData)
                 time s72 s79 s82 s83 s116 s119  shortdate
1 2016-10-03 00:00:00   0   0   1   0    0    0 2016/10/03
2 2016-10-03 01:00:00   0   0   0   0    0    0 2016/10/03
3 2016-10-03 02:00:00   0   0   0   0   24    0 2016/10/03
4 2016-10-03 03:00:00   1   0   0   0    0    0 2016/10/03
5 2016-10-03 04:00:00   0   0   0   0    1    0 2016/10/03
6 2016-10-03 05:00:00   1   0   1   0    0    1 2016/10/03

Jeff


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Nov 15 00:12:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Nov 2017 15:12:21 -0800
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <1068192069.31543.1510692598176@mail.yahoo.com>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
 <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
 <1068192069.31543.1510692598176@mail.yahoo.com>
Message-ID: <CAGxFJbQV+aXXPdz1XuumW0m0NC07QdWiRmbZ_epqRmAC=sYo1Q@mail.gmail.com>

Still a complete mess!

Post in **plain text**. This should be an option in your email software.
Please seek local help if you cannot figure out how to do this.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Nov 14, 2017 at 12:49 PM, Fix Ace via R-help <r-help at r-project.org>
wrote:

> Hi, David,
> Thank you very much for getting back to me! Sorry about the messy code
> example. I am re-posting here (including the error message):
> > example.3=data.frame(levels=as.numeric(XXX[,c(4)]),
> replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(
> rep("11",6),rep("12",6),rep("13",6)))> example.3    levels replicate
> conditions1  43.1111         0         112  42.0942         1         113
> 57.8131         2         114  57.1726         3         115  77.8678
>   4         116  44.7578         5         117  69.5078         0
> 128  52.0581         1         129  40.0602         2         1210 45.5487
>         3         1211 43.6201         4         1212 60.4939         5
>     1213 64.1932         0         1314 53.4055         1         1315
> 59.6701         2         1316 52.6922         3         1317 53.8712
>   4         1318 60.2770         5         13> m.example.3=lmer(as.numeric(
> levels)~conditions+(conditions|replicate),data=example.3)Error: number of
> observations (=18) <= number of random effects (=18) for term (conditions |
> replicate); the random-effects parameters and the residual variance (or
> scale parameter) are probably unidentifiable>
> Please let me know if it is readable this time.
> Again, many thanks for your time and please help me fix the issue.
> Kind regards,
> Ace
>
>     On Tuesday, November 14, 2017 12:19 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
>
>
>
> > On Nov 14, 2017, at 5:13 AM, Fix Ace via R-help <r-help at r-project.org>
> wrote:
> >
> > Dear R Community,
> > My data have 3 conditions and each condition has 6 replicates. I am
> trying to fit my data for a linear mixed model using the lmer function from
> lme4 package to find the random effects of the replicates;
>
> Better venue for this question might be SIG-mixed-models. See the link
> avaialble at the bottom of every posting from rhelp:
>
> https://stat.ethz.ch/mailman/listinfo/r-help:
>
>
>
> > however, I got the error message. Here are the example codes:
> >> example.3=data.frame(levels=as.numeric(XXX[,c(4)]),
> replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(
> rep("11",6),rep("12",6),rep("13",6)))> example.3    levels replicate
> conditions1  43.1111        0        112  42.0942        1        113
> 57.8131        2        114  57.1726        3        115  77.8678        4
>       116  44.7578        5        117  69.5078        0        128
> 52.0581        1        129  40.0602        2        1210 45.5487        3
>       1211 43.6201        4        1212 60.4939        5        1213
> 64.1932        0        1314 53.4055        1        1315 59.6701        2
>       1316 52.6922        3        1317 53.8712        4        1318
> 60.2770        5        13> m.example.3=lmer(as.numeric(
> levels)~conditions+(conditions|replicate),data=example.3)Error: number of
> observations (=18) <= number of random effects (=18) for term (conditions |
> replicate); the random-effects parameters and the residual variance (or
> scale parameter) are probably unidentifiable>
> > Could anyone help me figure out how to fix the issue?
> > Thank you very much for any inputs!
> > Ace
> >
> >     [[alternative HTML version deleted]]
>
> Complete mess. If you haven't yet been advised to posting in plain text,
> then this should be your wakeup call. If you have, then why are you
> ignoring sensible advice?
>
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
> -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov 15 00:54:07 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 14 Nov 2017 15:54:07 -0800
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <1068192069.31543.1510692598176@mail.yahoo.com>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
 <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
 <1068192069.31543.1510692598176@mail.yahoo.com>
Message-ID: <8F38D80A-5E1E-4C8C-BE72-240B34F34F3D@comcast.net>


> On Nov 14, 2017, at 12:49 PM, Fix Ace <acefix at rocketmail.com> wrote:
> 
> Hi, David,
> 
> Thank you very much for getting back to me! Sorry about the messy code example. I am re-posting here (including the error message):
> 
> > example.3=data.frame(levels=as.numeric(XXX[,c(4)]),replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep("13",6)))
> > example.3
>     levels replicate conditions
> 1  43.1111         0         11
> 2  42.0942         1         11
> 3  57.8131         2         11
> 4  57.1726         3         11
> 5  77.8678         4         11
> 6  44.7578         5         11
> 7  69.5078         0         12
> 8  52.0581         1         12
> 9  40.0602         2         12
> 10 45.5487         3         12
> 11 43.6201         4         12
> 12 60.4939         5         12
> 13 64.1932         0         13
> 14 53.4055         1         13
> 15 59.6701         2         13
> 16 52.6922         3         13
> 17 53.8712         4         13
> 18 60.2770         5         13
> > m.example.3=lmer(as.numeric(levels)~conditions+(conditions|replicate),data=example.3)
> Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

The error message seems fairly clear. The formula you have provided is asking for estimation of too many parameters. I think you probably want:

m.example.3=lmer(levels~conditions+(1|replicate),data=example.3)

... although your description of the hypothesis under test is ... non-existent.

-- 
David.
> > 
> 
> Please let me know if it is readable this time. 
> 
> Again, many thanks for your time and please help me fix the issue.
> 
> Kind regards,
> 
> Ace
> 
> 
> On Tuesday, November 14, 2017 12:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> > On Nov 14, 2017, at 5:13 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> > 
> > Dear R Community,
> > My data have 3 conditions and each condition has 6 replicates. I am trying to fit my data for a linear mixed model using the lmer function from lme4 package to find the random effects of the replicates;
> 
> Better venue for this question might be SIG-mixed-models. See the link avaialble at the bottom of every posting from rhelp:
> 
> https://stat.ethz.ch/mailman/listinfo/r-help:
> 
> 
> 
> 
> > however, I got the error message. Here are the example codes:
> >> example.3=data.frame(levels=as.numeric(XXX[,c(4)]),replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep("13",6)))> example.3    levels replicate conditions1  43.1111        0         112  42.0942        1        113  57.8131        2        114  57.1726        3        115  77.8678        4        116  44.7578        5        117  69.5078        0        128  52.0581        1        129  40.0602        2        1210 45.5487        3        1211 43.6201        4        1212 60.4939        5        1213 64.1932        0        1314 53.4055        1        1315 59.6701        2        1316 52.6922        3        1317 53.8712        4        1318 60.2770        5        13> m.example.3=lmer(as.numeric(levels)~conditions+(conditions|replicate),data=example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable> 
> > Could anyone help me figure out how to fix the issue? 
> > Thank you very much for any inputs!
> > Ace
> 
> > 
> >     [[alternative HTML version deleted]]
> 
> Complete mess. If you haven't yet been advised to posting in plain text, then this should be your wakeup call. If you have, then why are you ignoring sensible advice?
> 
> 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'  -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From bgunter.4567 at gmail.com  Wed Nov 15 02:11:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Nov 2017 17:11:39 -0800
Subject: [R] lapply and runif issue?
Message-ID: <CAGxFJbT0eUn7GTmJgpEvwhGhAwC4c+vKPMhBYLg2jwHYKxmn4A@mail.gmail.com>

Could someone please explain the following? I did check bug reports, but
did not recognize the issue there. I am reluctant to call it a bug, as it
is much more likely my misunderstanding. Ergo my request for clarification:

## As expected:

> lapply(1:3, rnorm, n = 3)
[[1]]
[1] 2.481575 1.998182 1.312786

[[2]]
[1] 2.858383 1.827863 1.699015

[[3]]
[1] 1.821910 2.530091 3.995677


## Unexpected by me:

> lapply(1:3, runif, n = 3)
[[1]]
[1] 1 1 1

[[2]]
[1] NaN NaN NaN

[[3]]
[1] NaN NaN NaN

Warning messages:
1: In FUN(X[[i]], ...) : NAs produced
2: In FUN(X[[i]], ...) : NAs produced


## But note, as expected:

> lapply(1:3, function(x)runif(3))
[[1]]
[1] 0.2950459 0.8490556 0.4303680

[[2]]
[1] 0.5961144 0.5330914 0.2363679

[[3]]
[1] 0.8079495 0.1431838 0.3671915



Many thanks for any clarification.

-- Bert

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Nov 15 03:11:25 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 14 Nov 2017 21:11:25 -0500
Subject: [R] lapply and runif issue?
In-Reply-To: <CAGxFJbT0eUn7GTmJgpEvwhGhAwC4c+vKPMhBYLg2jwHYKxmn4A@mail.gmail.com>
References: <CAGxFJbT0eUn7GTmJgpEvwhGhAwC4c+vKPMhBYLg2jwHYKxmn4A@mail.gmail.com>
Message-ID: <CA+vqiLFNu7YJ=T3UB_om8nvx8Azm1cCTaGBYPExdsC7=7VBR1A@mail.gmail.com>

Hi Bert,

On Tue, Nov 14, 2017 at 8:11 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Could someone please explain the following? I did check bug reports, but
> did not recognize the issue there. I am reluctant to call it a bug, as it
> is much more likely my misunderstanding. Ergo my request for clarification:
>
> ## As expected:
>
>> lapply(1:3, rnorm, n = 3)
> [[1]]
> [1] 2.481575 1.998182 1.312786
>
> [[2]]
> [1] 2.858383 1.827863 1.699015
>
> [[3]]
> [1] 1.821910 2.530091 3.995677
>

Exactly what expectation do you imagine the above is consistent with? Does

> lapply(100*(1:3), rnorm, n = 3)
[[1]]
[1] 100.35425  99.29429  98.69429

[[2]]
[1] 198.2963 201.1031 201.1077

[[3]]
[1] 299.7012 298.3700 298.0684

change your assessment?

>
> ## Unexpected by me:
>
>> lapply(1:3, runif, n = 3)
> [[1]]
> [1] 1 1 1
>
> [[2]]
> [1] NaN NaN NaN
>
> [[3]]
> [1] NaN NaN NaN
>
> Warning messages:
> 1: In FUN(X[[i]], ...) : NAs produced
> 2: In FUN(X[[i]], ...) : NAs produced

The first argument to runif is named 'n'. Thus,

lapply(1:3, runif)

means roughly

list(runif(n = 1), runif(n = 2), runif(n = 3))

But you specify than lapply(1:3, runif, n = 3). Since the first
argument ('n') is already specified, the X values from lapply get
"pushed" to the second argument. That is,

lapply(1:3, runif, n = 3)

means roughly

list(runif(n = 3, min = 1), runif(n = 3, min = 2), runif(n = 3, min = 3))

Note that this is exactly the same thing that happens with

lapply(1:3, rnorm, n = 3), though it becomes more obvious with

lapply(100*(1:3), rnorm, n = 3)

That is,

lapply(1:3, rnorm, n = 3)

means roughly

list(rnorm(n = 3, mean = 1), rnorm(n = 3, mean = 2), rnorm(n = 3, mean = 3))

>
>
> ## But note, as expected:
>
>> lapply(1:3, function(x)runif(3))
> [[1]]
> [1] 0.2950459 0.8490556 0.4303680
>
> [[2]]
> [1] 0.5961144 0.5330914 0.2363679
>
> [[3]]
> [1] 0.8079495 0.1431838 0.3671915

Sure, because you never use x in the body of your anonymous function.

As a final note, what you seem to expect can be achieved with

replicate(3, rnorm(n = 3), simplify = FALSE)

and

replicate(3, runif(n = 3), simplify = FALSE)


Best,
Ista

>
>
>
> Many thanks for any clarification.
>
> -- Bert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Nov 15 04:06:46 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Nov 2017 19:06:46 -0800
Subject: [R] lapply and runif issue?
In-Reply-To: <CA+vqiLFNu7YJ=T3UB_om8nvx8Azm1cCTaGBYPExdsC7=7VBR1A@mail.gmail.com>
References: <CAGxFJbT0eUn7GTmJgpEvwhGhAwC4c+vKPMhBYLg2jwHYKxmn4A@mail.gmail.com>
 <CA+vqiLFNu7YJ=T3UB_om8nvx8Azm1cCTaGBYPExdsC7=7VBR1A@mail.gmail.com>
Message-ID: <CAGxFJbT+u8E0YhV9NrdzVsB-rZy06kGJur35v3JVd-ZcHC9xqA@mail.gmail.com>

Thanks, Ista. That explains it.

What I missed is the following "note" in ?lapply:

"This means that the recorded call is always of the form FUN(X[[i]], ...),
with i replaced by the current (integer or double) index. "

That being the case, X[[i]] gets passed to the first available argument,
which for runif(n=3, min, max) is the min argument, as you said. This is a
subtlety (to me, anyway) of which I was unaware. Which is why I hesitated
to call it a bug. It ain't! It is documented -- I just failed to read
carefully enough.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Nov 14, 2017 at 6:11 PM, Ista Zahn <istazahn at gmail.com> wrote:

> Hi Bert,
>
> On Tue, Nov 14, 2017 at 8:11 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > Could someone please explain the following? I did check bug reports, but
> > did not recognize the issue there. I am reluctant to call it a bug, as it
> > is much more likely my misunderstanding. Ergo my request for
> clarification:
> >
> > ## As expected:
> >
> >> lapply(1:3, rnorm, n = 3)
> > [[1]]
> > [1] 2.481575 1.998182 1.312786
> >
> > [[2]]
> > [1] 2.858383 1.827863 1.699015
> >
> > [[3]]
> > [1] 1.821910 2.530091 3.995677
> >
>
> Exactly what expectation do you imagine the above is consistent with? Does
>
> > lapply(100*(1:3), rnorm, n = 3)
> [[1]]
> [1] 100.35425  99.29429  98.69429
>
> [[2]]
> [1] 198.2963 201.1031 201.1077
>
> [[3]]
> [1] 299.7012 298.3700 298.0684
>
> change your assessment?
>
> >
> > ## Unexpected by me:
> >
> >> lapply(1:3, runif, n = 3)
> > [[1]]
> > [1] 1 1 1
> >
> > [[2]]
> > [1] NaN NaN NaN
> >
> > [[3]]
> > [1] NaN NaN NaN
> >
> > Warning messages:
> > 1: In FUN(X[[i]], ...) : NAs produced
> > 2: In FUN(X[[i]], ...) : NAs produced
>
> The first argument to runif is named 'n'. Thus,
>
> lapply(1:3, runif)
>
> means roughly
>
> list(runif(n = 1), runif(n = 2), runif(n = 3))
>
> But you specify than lapply(1:3, runif, n = 3). Since the first
> argument ('n') is already specified, the X values from lapply get
> "pushed" to the second argument. That is,
>
> lapply(1:3, runif, n = 3)
>
> means roughly
>
> list(runif(n = 3, min = 1), runif(n = 3, min = 2), runif(n = 3, min = 3))
>
> Note that this is exactly the same thing that happens with
>
> lapply(1:3, rnorm, n = 3), though it becomes more obvious with
>
> lapply(100*(1:3), rnorm, n = 3)
>
> That is,
>
> lapply(1:3, rnorm, n = 3)
>
> means roughly
>
> list(rnorm(n = 3, mean = 1), rnorm(n = 3, mean = 2), rnorm(n = 3, mean =
> 3))
>
> >
> >
> > ## But note, as expected:
> >
> >> lapply(1:3, function(x)runif(3))
> > [[1]]
> > [1] 0.2950459 0.8490556 0.4303680
> >
> > [[2]]
> > [1] 0.5961144 0.5330914 0.2363679
> >
> > [[3]]
> > [1] 0.8079495 0.1431838 0.3671915
>
> Sure, because you never use x in the body of your anonymous function.
>
> As a final note, what you seem to expect can be achieved with
>
> replicate(3, rnorm(n = 3), simplify = FALSE)
>
> and
>
> replicate(3, runif(n = 3), simplify = FALSE)
>
>
> Best,
> Ista
>
> >
> >
> >
> > Many thanks for any clarification.
> >
> > -- Bert
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mli11 at unb.ca  Wed Nov 15 01:39:02 2017
From: mli11 at unb.ca (Mingke Li)
Date: Wed, 15 Nov 2017 00:39:02 +0000
Subject: [R] Autologistic regression in R
Message-ID: <YQBPR0101MB1843C7BBB3A62A1EC32AD6E2C7290@YQBPR0101MB1843.CANPRD01.PROD.OUTLOOK.COM>

Hi,

I am new to autologistic regression and R. I do have questions when starting a project in which I believe autologistic regression is needed.

I have a point layer whose attribute table stores the values of the dependent variable and all the independent variables. I hope to to fit an autologistic model to analyze which factors or combinations of factors have effects on the presence/absence of the dependent variable (1 or 0).

I found other papers which applied autologistic regression in their study almost used a grid system and defined their window sizes. So, my question is do I have to convert my point layer to a grid system if I want to do this analysis with R?

Also, what should I consider when I generate the grid system? How to determine a proper size of cells? How about the searching window sizes?

Many Thanks.

Erin


	[[alternative HTML version deleted]]


From rahulutube69 at gmail.com  Wed Nov 15 06:40:20 2017
From: rahulutube69 at gmail.com (Rahul singh)
Date: Wed, 15 Nov 2017 11:10:20 +0530
Subject: [R] NEED HELP : Association in single DTM
Message-ID: <CAGprg3Jn=KUZMQZfqDUMfW5Y2ptjcgKJC+q1TmrFGGc+_oJcWg@mail.gmail.com>

I have free text data in a single text document. I create a corpus, and
then a document term matrix out of it. I can create a word cloud too.

But when I do word association for the same, using "findAssocs(), it always
returns numeric(0).

EX : findAssocs(dtm, "king" ,000000000000000000000.1)

I read on stack overflow that it is because I have a single document.

What is the workaround for the same ?

	[[alternative HTML version deleted]]


From alex at chaotic-neutral.de  Wed Nov 15 09:44:11 2017
From: alex at chaotic-neutral.de (Alexander Engelhardt)
Date: Wed, 15 Nov 2017 09:44:11 +0100
Subject: [R] Is there a tool to find unused functions?
Message-ID: <5f008ed3-7c61-5a7f-655a-7cbd2e1dc009@chaotic-neutral.de>

I've inherited a large R codebase which has grown over a few years and a 
few different developers.

It contains many things I'd like to delete:
- Unused functions
- Variable definitions that are never called
- Unreachable code

I'd write that myself, it would even be fun, but I don't want to 
reinvent the wheel.
Is there an R package that can find these things?

I've heard of lintr, but I'm not sure if it's the right tool, since, 
unfortunately, the code is in a folder (not a package) with many R files 
that are sourced from one master file and lintr can only check a single 
file or an actual package, from what I understand. A workaround of 
course would be to concatenate all files into one R script.

I'd appreciate any hints on how to best solve this.

Thanks in advance,
Alex


From jeremiejuste at gmail.com  Wed Nov 15 10:08:48 2017
From: jeremiejuste at gmail.com (Jeremie Juste)
Date: Wed, 15 Nov 2017 10:08:48 +0100
Subject: [R] Problems installing mice package
Message-ID: <87efozvrhb.fsf@freegnu.noherd.org>



Hello,

I tried intalling mice package and got the following error:

* installing *source* package ?mice? ...
** package ?mice? successfully unpacked and MD5 sums checked
** libs
g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2  -c RcppExports.cpp -o RcppExports.o
g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2  -c match.cpp -o match.o
g++ -shared -L/usr/local/lib -o mice.so RcppExports.o match.o Welcome to R! Goodbye!
g++: error: Welcome: No such file or directory
g++: error: to: No such file or directory
g++: error: R!: No such file or directory
g++: error: Goodbye!: No such file or directory
/usr/local/lib/R/share/make/shlib.mk:6: recipe for target 'mice.so' failed
make: *** [mice.so] Error 1
ERROR: compilation failed for package ?mice?
* removing ?/home/djj/R/x86_64-pc-linux-gnu-library/3.4/mice?

The downloaded source packages are in
	?/tmp/Rtmpgam70t/downloaded_packages?
Error in library(mice) : there is no package called ?mice?
In addition: Warning message:
In install.packages(deparse(substitute(mice)), repos = "http://cran.us.r-project.org") :
  installation of package ?mice? had non-zero exit status

I'm unable to resolve it. Any help please?

Best regards,

Jeremie


From jmhannon.ucdavis at gmail.com  Wed Nov 15 10:44:09 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 15 Nov 2017 01:44:09 -0800
Subject: [R] Is there a tool to find unused functions?
In-Reply-To: <5f008ed3-7c61-5a7f-655a-7cbd2e1dc009@chaotic-neutral.de>
References: <5f008ed3-7c61-5a7f-655a-7cbd2e1dc009@chaotic-neutral.de>
Message-ID: <CACdH2ZZ6i8=-Ap32B6H-xrmB+LRCoPNyvEVfMYQ6BLKYYjYm9g@mail.gmail.com>

mvbutils::foodweb produces a graphical display of the hierarchy (or
network or ...) of function calls.  Isolated functions are not called.
This might help you.

-- Mike


On Wed, Nov 15, 2017 at 12:44 AM, Alexander Engelhardt
<alex at chaotic-neutral.de> wrote:
> I've inherited a large R codebase which has grown over a few years and a few
> different developers.
>
> It contains many things I'd like to delete:
> - Unused functions
> - Variable definitions that are never called
> - Unreachable code
>
> I'd write that myself, it would even be fun, but I don't want to reinvent
> the wheel.
> Is there an R package that can find these things?
>
> I've heard of lintr, but I'm not sure if it's the right tool, since,
> unfortunately, the code is in a folder (not a package) with many R files
> that are sourced from one master file and lintr can only check a single file
> or an actual package, from what I understand. A workaround of course would
> be to concatenate all files into one R script.
>
> I'd appreciate any hints on how to best solve this.
>
> Thanks in advance,
> Alex
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jeremiejuste at gmail.com  Wed Nov 15 11:02:12 2017
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Wed, 15 Nov 2017 11:02:12 +0100
Subject: [R] Problems installing mice package
In-Reply-To: <87efozvrhb.fsf@freegnu.noherd.org>
References: <87efozvrhb.fsf@freegnu.noherd.org>
Message-ID: <CAPHJcdC_ssRHi84Z2b=M8FxcgADhnvso2mcF2jW4ctGdiBf6Gg@mail.gmail.com>

Hello,

The installation of the developpment version seems to go through
https://github.com/stefvanbuuren/mice,

Best regards,

Jeremie

On Wed, Nov 15, 2017 at 10:08 AM, Jeremie Juste <jeremiejuste at gmail.com>
wrote:

>
>
> Hello,
>
> I tried intalling mice package and got the following error:
>
> * installing *source* package ?mice? ...
> ** package ?mice? successfully unpacked and MD5 sums checked
> ** libs
> g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-
> linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2
> -c RcppExports.cpp -o RcppExports.o
> g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-
> linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2
> -c match.cpp -o match.o
> g++ -shared -L/usr/local/lib -o mice.so RcppExports.o match.o Welcome to
> R! Goodbye!
> g++: error: Welcome: No such file or directory
> g++: error: to: No such file or directory
> g++: error: R!: No such file or directory
> g++: error: Goodbye!: No such file or directory
> /usr/local/lib/R/share/make/shlib.mk:6: recipe for target 'mice.so' failed
> make: *** [mice.so] Error 1
> ERROR: compilation failed for package ?mice?
> * removing ?/home/djj/R/x86_64-pc-linux-gnu-library/3.4/mice?
>
> The downloaded source packages are in
>         ?/tmp/Rtmpgam70t/downloaded_packages?
> Error in library(mice) : there is no package called ?mice?
> In addition: Warning message:
> In install.packages(deparse(substitute(mice)), repos = "
> http://cran.us.r-project.org") :
>   installation of package ?mice? had non-zero exit status
>
> I'm unable to resolve it. Any help please?
>
> Best regards,
>
> Jeremie
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Wed Nov 15 12:09:06 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 15 Nov 2017 16:39:06 +0530
Subject: [R] How to read PMML data from a text file and convert it to a
	model ?
Message-ID: <CAC8=1erA2pJ+De81Lb9Hp=UTLk=-v-qqziQBGBFKB1X-LsYHWw@mail.gmail.com>

Dear All,

I want to save the XML representation of a model using PMML. Then I want to
read the model and predict using the model and a new  dataset.

This is described in this blog post :
https://www.r-bloggers.com/predictive-modeling-using-r-and-the-openscoring-engine-a-pmml-approach/

I am able to save the PMML representation of the model. I am not able to
read this representation convert it into  a model.  How can I do that ?

Here is a MWE :

library(pmml)
mydata<- iris

# Creating a model

mymodel <- lm(Sepal.Length ~ Sepal.Width, data = mydata)
#Computing its pmml representation and storing it to a file
saveXML(pmml(mymodel),file = "myfile.xml")

testingReading <- fileToXMLNode("myfile.txt")

> testingReading
<PMML version="4.3" xmlns="http://www.dmg.org/PMML-4_3">
 <Header>
  <Application name="JPMML-R" version="1.2.20"/>
  <Timestamp>2017-11-15T10:37:29Z</Timestamp>
 </Header>
 <DataDictionary>
  <DataField name="Sepal.Length" optype="continuous" dataType="double"/>
  <DataField name="Sepal.Width" optype="continuous" dataType="double"/>
 </DataDictionary>
 <RegressionModel functionName="regression">
  <MiningSchema>
   <MiningField name="Sepal.Length" usageType="target"/>
   <MiningField name="Sepal.Width"/>
  </MiningSchema>
  <RegressionTable intercept="6.526222550894482">
   <NumericPredictor name="Sepal.Width" coefficient="-0.22336106112990006"/>
  </RegressionTable>
 </RegressionModel>
</PMML>
Warning messages:
1: In structure(x$children, class = "XMLNodeList") :
  Calling 'structure(NULL, *)' is deprecated, as NULL cannot have
attributes.
  Consider 'structure(list(), *)' instead.
2: In structure(x$children, class = "XMLNodeList") :
  Calling 'structure(NULL, *)' is deprecated, as NULL cannot have
attributes.
  Consider 'structure(list(), *)' instead.
3: In structure(x$children, class = "XMLNodeList") :
  Calling 'structure(NULL, *)' is deprecated, as NULL cannot have
attributes.
  Consider 'structure(list(), *)' instead.
4: In structure(x$children, class = "XMLNodeList") :
  Calling 'structure(NULL, *)' is deprecated, as NULL cannot have
attributes.
  Consider 'structure(list(), *)' instead.
5: In structure(x$children, class = "XMLNodeList") :
  Calling 'structure(NULL, *)' is deprecated, as NULL cannot have
attributes.
  Consider 'structure(list(), *)' instead.
6: In structure(x$children, class = "XMLNodeList") :
  Calling 'structure(NULL, *)' is deprecated, as NULL cannot have
attributes.
  Consider 'structure(list(), *)' instead.
>

Can someone show me how to extract the model from the variable
testingReading and predict using this model at the values of rnorm(100) ?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From alex at chaotic-neutral.de  Wed Nov 15 13:25:18 2017
From: alex at chaotic-neutral.de (Alexander Engelhardt)
Date: Wed, 15 Nov 2017 13:25:18 +0100
Subject: [R] Is there a tool to find unused functions?
In-Reply-To: <CACdH2ZZ6i8=-Ap32B6H-xrmB+LRCoPNyvEVfMYQ6BLKYYjYm9g@mail.gmail.com>
References: <5f008ed3-7c61-5a7f-655a-7cbd2e1dc009@chaotic-neutral.de>
 <CACdH2ZZ6i8=-Ap32B6H-xrmB+LRCoPNyvEVfMYQ6BLKYYjYm9g@mail.gmail.com>
Message-ID: <14e291f3-3d1d-95f2-e0af-c8c3693e2ccc@chaotic-neutral.de>

Thanks, that helps! The visualization is very messy, because I have 
about 100 functions, but foodweb() returns a matrix of which function 
calls which, and the functions callers.of("myfunc") and 
callees.of("myfunc") do exactly what I was looking for.

 ?- Alex


On 11/15/2017 10:44 AM, Michael Hannon wrote:
> mvbutils::foodweb produces a graphical display of the hierarchy (or
> network or ...) of function calls.  Isolated functions are not called.
> This might help you.
>
> -- Mike
>
>
> On Wed, Nov 15, 2017 at 12:44 AM, Alexander Engelhardt
> <alex at chaotic-neutral.de> wrote:
>> I've inherited a large R codebase which has grown over a few years and a few
>> different developers.
>>
>> It contains many things I'd like to delete:
>> - Unused functions
>> - Variable definitions that are never called
>> - Unreachable code
>>
>> I'd write that myself, it would even be fun, but I don't want to reinvent
>> the wheel.
>> Is there an R package that can find these things?
>>
>> I've heard of lintr, but I'm not sure if it's the right tool, since,
>> unfortunately, the code is in a folder (not a package) with many R files
>> that are sourced from one master file and lintr can only check a single file
>> or an actual package, from what I understand. A workaround of course would
>> be to concatenate all files into one R script.
>>
>> I'd appreciate any hints on how to best solve this.
>>
>> Thanks in advance,
>> Alex
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tonja.krueger at web.de  Wed Nov 15 10:46:43 2017
From: tonja.krueger at web.de (tonja.krueger at web.de)
Date: Wed, 15 Nov 2017 10:46:43 +0100
Subject: [R] ks.test() with 2 samples vs. 1 sample an distr. function
Message-ID: <trinity-894420b6-0e9e-4a02-9833-586b045b0163-1510739203535@3c-app-webde-bap37>

Dear all,
I have a question concerning the ks.test() function. I tryed to calculate the example given on the German wikipedia page.
xi <- c(9.41,9.92,11.55,11.6,11.73,12,12.06,13.3)
I get the right results when I calculate: ks.test(xi,pnorm,11,1)
Now the question: shouldn't I obtain the same or a very similar result if I commpare the sample and a calculated sample from the distribution?
p<- c(0.125, 0.250, 0.375, 0.500, 0.625, 0.750, 0.875, 0.9999)
x <- qnorm(p,11,1)
ks.test(xi,x)
Why don't I?
Thanks for helping me!
Tonja


From boris.steipe at utoronto.ca  Wed Nov 15 14:38:42 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 15 Nov 2017 08:38:42 -0500
Subject: [R] NEED HELP : Association in single DTM
In-Reply-To: <CAGprg3Jn=KUZMQZfqDUMfW5Y2ptjcgKJC+q1TmrFGGc+_oJcWg@mail.gmail.com>
References: <CAGprg3Jn=KUZMQZfqDUMfW5Y2ptjcgKJC+q1TmrFGGc+_oJcWg@mail.gmail.com>
Message-ID: <1D92EF71-9B85-469B-9AE4-A93B26617ED4@utoronto.ca>

If you consider the definition of a DTM, and that findAssoc() computes associations between words as correlations across documents(!), you will realize that you can't what you want from a single document. Indeed, what kind of an "association" would you even be looking for?

B.



> On Nov 15, 2017, at 12:40 AM, Rahul singh <rahulutube69 at gmail.com> wrote:
> 
> I have free text data in a single text document. I create a corpus, and
> then a document term matrix out of it. I can create a word cloud too.
> 
> But when I do word association for the same, using "findAssocs(), it always
> returns numeric(0).
> 
> EX : findAssocs(dtm, "king" ,000000000000000000000.1)
> 
> I read on stack overflow that it is because I have a single document.
> 
> What is the workaround for the same ?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Nov 15 16:44:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Nov 2017 07:44:26 -0800
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <1013628048.379831.1510751364535@mail.yahoo.com>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
 <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
 <1068192069.31543.1510692598176@mail.yahoo.com>
 <CAGxFJbQV+aXXPdz1XuumW0m0NC07QdWiRmbZ_epqRmAC=sYo1Q@mail.gmail.com>
 <1013628048.379831.1510751364535@mail.yahoo.com>
Message-ID: <CAGxFJbRLmR545pwKDLWwH8ZuBFywy2hjJO35aFAbFuHnNbODiQ@mail.gmail.com>

Always cc the list, which I have done here. I am not a (free) private
consultant, nor do I have all the answers.

Based on what you sent me, which is not what you have previously posted,
you failed to load the lme3 package. See ?library.

As for the appropriateness of your modeling, you should do what David
already suggested and post to the r-sig-mixed-models list instead.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 15, 2017 at 5:09 AM, Fix Ace <acefix at rocketmail.com> wrote:

> Hi, Bert,
>
> Sorry about that! David seemed to be able to read the post since he
> replied. Here I just email you the sample code and error message:
>
> > example.3=data.frame(levels=as.numeric(XXX[,c(4)]),
> replicate=rep(c("0","1","2","3","4","5"),3),conditions=c(rep("11",6),rep("12",6),rep(>
> example.3
>     levels replicate conditions
> 1  43.1111         0         11
> 2  42.0942         1         11
> 3  57.8131         2         11
> 4  57.1726         3         11
> 5  77.8678         4         11
> 6  44.7578         5         11
> 7  69.5078         0         12
> 8  52.0581         1         12
> 9  40.0602         2         12
> 10 45.5487         3         12
> 11 43.6201         4         12
> 12 60.4939         5         12
> 13 64.1932         0         13
> 14 53.4055         1         13
> 15 59.6701         2         13
> 16 52.6922         3         13
> 17 53.8712         4         13
> 18 60.2770         5         13
> > m.example.3=lmer(as.numeric(levels)~conditions+(
> conditions|replicate),data=example.3)
> Error in lmer(as.numeric(levels) ~ conditions + (conditions | replicate),
> :
>   could not find function "lmer"
> >
>
> Hopefully you could read it and provide some comments!
>
> Thank you very much for your time.
>
> Kind regards,
>
> Ace
>
>
>
>
> On Tuesday, November 14, 2017 6:12 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>
> Still a complete mess!
>
> Post in **plain text**. This should be an option in your email software.
> Please seek local help if you cannot figure out how to do this.
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Nov 14, 2017 at 12:49 PM, Fix Ace via R-help <r-help at r-project.org
> > wrote:
>
> Hi, David,
> Thank you very much for getting back to me! Sorry about the messy code
> example. I am re-posting here (including the error message):
> > example.3=data.frame(levels= as.numeric(XXX[,c(4)]),
> replicate=rep(c("0","1","2"," 3","4","5"),3),conditions=c(
> rep("11",6),rep("12",6),rep(" 13",6)))> example.3    levels replicate
> conditions1  43.1111         0         112  42.0942         1         113
> 57.8131         2         114  57.1726         3         115  77.8678
>   4         116  44.7578         5         117  69.5078         0
> 128  52.0581         1         129  40.0602         2         1210 45.5487
>         3         1211 43.6201         4         1212 60.4939         5
>     1213 64.1932         0         1314 53.4055         1         1315
> 59.6701         2         1316 52.6922         3         1317 53.8712
>   4         1318 60.2770         5         13> m.example.3=lmer(as.numeric(
> levels)~conditions+( conditions|replicate),data= example.3)Error: number of
> observations (=18) <= number of random effects (=18) for term (conditions |
> replicate); the random-effects parameters and the residual variance (or
> scale parameter) are probably unidentifiable>
> Please let me know if it is readable this time.
> Again, many thanks for your time and please help me fix the issue.
> Kind regards,
> Ace
>
>     On Tuesday, November 14, 2017 12:19 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
>
>
>
> > On Nov 14, 2017, at 5:13 AM, Fix Ace via R-help <r-help at r-project.org>
> wrote:
> >
> > Dear R Community,
> > My data have 3 conditions and each condition has 6 replicates. I am
> trying to fit my data for a linear mixed model using the lmer function from
> lme4 package to find the random effects of the replicates;
>
> Better venue for this question might be SIG-mixed-models. See the link
> avaialble at the bottom of every posting from rhelp:
>
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>:
>
>
>
> > however, I got the error message. Here are the example codes:
> >> example.3=data.frame(levels= as.numeric(XXX[,c(4)]),
> replicate=rep(c("0","1","2"," 3","4","5"),3),conditions=c(
> rep("11",6),rep("12",6),rep(" 13",6)))> example.3    levels replicate
> conditions1  43.1111        0        112  42.0942        1        113
> 57.8131        2        114  57.1726        3        115  77.8678        4
>       116  44.7578        5        117  69.5078        0        128
> 52.0581        1        129  40.0602        2        1210 45.5487        3
>       1211 43.6201        4        1212 60.4939        5        1213
> 64.1932        0        1314 53.4055        1        1315 59.6701        2
>       1316 52.6922        3        1317 53.8712        4        1318
> 60.2770        5        13> m.example.3=lmer(as.numeric(
> levels)~conditions+( conditions|replicate),data= example.3)Error: number of
> observations (=18) <= number of random effects (=18) for term (conditions |
> replicate); the random-effects parameters and the residual variance (or
> scale parameter) are probably unidentifiable>
> > Could anyone help me figure out how to fix the issue?
> > Thank you very much for any inputs!
> > Ace
> >
> >     [[alternative HTML version deleted]]
>
> Complete mess. If you haven't yet been advised to posting in plain text,
> then this should be your wakeup call. If you have, then why are you
> ignoring sensible advice?
>
>
> >
> > ______________________________ ________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
> -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Nov 15 16:56:09 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 15 Nov 2017 15:56:09 +0000
Subject: [R] ks.test() with 2 samples vs. 1 sample an distr. function
In-Reply-To: <trinity-894420b6-0e9e-4a02-9833-586b045b0163-1510739203535@3c-app-webde-bap37>
References: <trinity-894420b6-0e9e-4a02-9833-586b045b0163-1510739203535@3c-app-webde-bap37>
Message-ID: <92f0962b75c94ec8b052c062a1e804ee@exch-2p-mbx-w2.ads.tamu.edu>

In the first example you are performing a one-sample test against a continuous cumulative distribution (in this case a normal distribution). In the second case you are performing a two-sample test. You drew your values for x non-randomly by specifying fixed intervals along a normal distribution, but ks.test() just sees that you have provided two samples, not one sample and values along a cumulative distribution.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of tonja.krueger at web.de
Sent: Wednesday, November 15, 2017 3:47 AM
To: r-help at r-project.org
Subject: [R] ks.test() with 2 samples vs. 1 sample an distr. function

Dear all,
I have a question concerning the ks.test() function. I tryed to calculate the example given on the German wikipedia page.
xi <- c(9.41,9.92,11.55,11.6,11.73,12,12.06,13.3)
I get the right results when I calculate: ks.test(xi,pnorm,11,1) Now the question: shouldn't I obtain the same or a very similar result if I commpare the sample and a calculated sample from the distribution?
p<- c(0.125, 0.250, 0.375, 0.500, 0.625, 0.750, 0.875, 0.9999) x <- qnorm(p,11,1)
ks.test(xi,x)
Why don't I?
Thanks for helping me!
Tonja

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Nov 15 17:38:32 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Nov 2017 08:38:32 -0800
Subject: [R] lapply and runif issue?
In-Reply-To: <CAGxFJbT0eUn7GTmJgpEvwhGhAwC4c+vKPMhBYLg2jwHYKxmn4A@mail.gmail.com>
References: <CAGxFJbT0eUn7GTmJgpEvwhGhAwC4c+vKPMhBYLg2jwHYKxmn4A@mail.gmail.com>
Message-ID: <CAF8bMcbs5pq7exi_+QK0pPPrT8nPvs4YuGsnLmU=wBzNEtOzYg@mail.gmail.com>

Your lapply is making the call
   runif(n=3, min=i)
for i in 1:3.  That runif's 3 argument is 'max', with default value 1
so that is equivalent to calling
   runif(n=3, min=i, max=1)
When i>max, outside the domain of the family of uniform distributions,
runif returns NaN's.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 14, 2017 at 5:11 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Could someone please explain the following? I did check bug reports, but
> did not recognize the issue there. I am reluctant to call it a bug, as it
> is much more likely my misunderstanding. Ergo my request for clarification:
>
> ## As expected:
>
> > lapply(1:3, rnorm, n = 3)
> [[1]]
> [1] 2.481575 1.998182 1.312786
>
> [[2]]
> [1] 2.858383 1.827863 1.699015
>
> [[3]]
> [1] 1.821910 2.530091 3.995677
>
>
> ## Unexpected by me:
>
> > lapply(1:3, runif, n = 3)
> [[1]]
> [1] 1 1 1
>
> [[2]]
> [1] NaN NaN NaN
>
> [[3]]
> [1] NaN NaN NaN
>
> Warning messages:
> 1: In FUN(X[[i]], ...) : NAs produced
> 2: In FUN(X[[i]], ...) : NAs produced
>
>
> ## But note, as expected:
>
> > lapply(1:3, function(x)runif(3))
> [[1]]
> [1] 0.2950459 0.8490556 0.4303680
>
> [[2]]
> [1] 0.5961144 0.5330914 0.2363679
>
> [[3]]
> [1] 0.8079495 0.1431838 0.3671915
>
>
>
> Many thanks for any clarification.
>
> -- Bert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov 15 18:49:55 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 15 Nov 2017 09:49:55 -0800
Subject: [R] Problems installing mice package
In-Reply-To: <87efozvrhb.fsf@freegnu.noherd.org>
References: <87efozvrhb.fsf@freegnu.noherd.org>
Message-ID: <1F9E067C-98C5-4857-BF7D-62C8DAD935B3@comcast.net>


> On Nov 15, 2017, at 1:08 AM, Jeremie Juste <jeremiejuste at gmail.com> wrote:
> 
> 
> 
> Hello,
> 
> I tried intalling mice package and got the following error:
> 
> * installing *source* package ?mice? ...
> ** package ?mice? successfully unpacked and MD5 sums checked
> ** libs
> g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2  -c RcppExports.cpp -o RcppExports.o
> g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2  -c match.cpp -o match.o
> g++ -shared -L/usr/local/lib -o mice.so RcppExports.o match.o Welcome to R! Goodbye!

Somehow you have sent an R "welcome message" to the installer script. What was the action that started all this? Were you in an R session or was this something done from a bash console?

> g++: error: Welcome: No such file or directory
> g++: error: to: No such file or directory
> g++: error: R!: No such file or directory
> g++: error: Goodbye!: No such file or directory
> /usr/local/lib/R/share/make/shlib.mk:6: recipe for target 'mice.so' failed
> make: *** [mice.so] Error 1
> ERROR: compilation failed for package ?mice?
> * removing ?/home/djj/R/x86_64-pc-linux-gnu-library/3.4/mice?
> 
> The downloaded source packages are in
> 	?/tmp/Rtmpgam70t/downloaded_packages?
> Error in library(mice) : there is no package called ?mice?
> In addition: Warning message:
> In  :

That's a rather strange method for invoking install.packages. Usually it would be just:

install.packages("mice", repos = "http://cran.us.r-project.org")



Your best venue for linux installation questions is probably:

https://stat.ethz.ch/mailman/listinfo/r-sig-db


>  installation of package ?mice? had non-zero exit status
> 
> I'm unable to resolve it. Any help please?
> 
> Best regards,
> 
> Jeremie
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwinsemius at comcast.net  Wed Nov 15 19:44:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 15 Nov 2017 10:44:22 -0800
Subject: [R] Autologistic regression in R
In-Reply-To: <YQBPR0101MB1843C7BBB3A62A1EC32AD6E2C7290@YQBPR0101MB1843.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR0101MB1843C7BBB3A62A1EC32AD6E2C7290@YQBPR0101MB1843.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <277C8506-5D99-49CD-9989-9738279B46E8@comcast.net>


> On Nov 14, 2017, at 4:39 PM, Mingke Li <mli11 at unb.ca> wrote:
> 
> Hi,
> 
> I am new to autologistic regression and R. I do have questions when starting a project in which I believe autologistic regression is needed.
> 
> I have a point layer whose attribute table stores the values of the dependent variable and all the independent variables. I hope to to fit an autologistic model to analyze which factors or combinations of factors have effects on the presence/absence of the dependent variable (1 or 0).
> 
> I found other papers which applied autologistic regression in their study almost used a grid system and defined their window sizes. So, my question is do I have to convert my point layer to a grid system if I want to do this analysis with R?
> 
> Also, what should I consider when I generate the grid system? How to determine a proper size of cells? How about the searching window sizes?

Have you read the Posting Guide?

-- 
David.
> 
> Many Thanks.
> 
> Erin
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From crosspide at hotmail.com  Wed Nov 15 19:52:10 2017
From: crosspide at hotmail.com (Cristina Pascual)
Date: Wed, 15 Nov 2017 18:52:10 +0000
Subject: [R] R6 object that is a list of referenced object
In-Reply-To: <HE1PR0201MB2348E3EFC69EC470DB0F6DE0A94D0@HE1PR0201MB2348.eurprd02.prod.outlook.com>
References: <HE1PR0201MB2348E3EFC69EC470DB0F6DE0A94D0@HE1PR0201MB2348.eurprd02.prod.outlook.com>
Message-ID: <VI1PR0202MB3375A6D30BAE1EC4C3F11523A9290@VI1PR0202MB3375.eurprd02.prod.outlook.com>

Dear community,


I am having a class, let's say Person,


Person <-  R6Class("Person",
                     public = list(
                       idPerson = NULL,
                       name = NULL,
                       age = NULL,
                       initialize = function(idPerson = NA, name = NA, age = NA) {
                        self$idPerson <- idPerson
                        self$name <- name
                        self$age <- age
                       }
                     ) # public

) # Person


I have created:

Person1 <- Particle$new(1,'a',4)

Person2 <- Particle$new(2,'b',5)


and I also have a class Community:


Community <- R6Class("Community",
                 public = list(
                   e = NULL,
                   initialize = function() self$e <- Person$new()
                 )
)


I want to create


Community1 = List<Person>


and add Person1 and Person2 to Community1 (Community1 <- Community1$add(Person1)

                                                                                    Community1 <- Community1$add(Person2)


????)


How can I write this with R6? I cannot find the proper example in the website.


Can anybody help me?

Thanks in advance,


	[[alternative HTML version deleted]]


From crosspide at hotmail.com  Wed Nov 15 19:55:53 2017
From: crosspide at hotmail.com (Cristina Pascual)
Date: Wed, 15 Nov 2017 18:55:53 +0000
Subject: [R] R6 object that is a list of referenced object
Message-ID: <VI1PR0202MB3375D48BA7287160DF6C39A2A9290@VI1PR0202MB3375.eurprd02.prod.outlook.com>

Dear community,

I am having a class, let's say Person,

Person <-  R6Class("Person",
                     public = list(
                       idPerson = NULL,
                       name = NULL,
                       age = NULL,
                       initialize = function(idPerson = NA, name = NA, age = NA) {
                        self$idPerson <- idPerson
                        self$name <- name
                        self$age <- age
                       }
                     ) # public

) # Person

I have created:
Person1 <- Person$new(1,'a',4)
Person2 <- Person$new(2,'b',5)

and I also have a class Community:

Community <- R6Class("Community",
                 public = list(
                   e = NULL,
                   initialize = function() self$e <- Person$new()
                 )
)

I want to create

Community1 = List<Person>

and add Person1 and Person2 to Community1 (Community1 <- Community1$add(Person1)
                                                                                    Community1 <- Community1$add(Person2)

????)

How can I write this with R6? I cannot find the proper example in the website.

Can anybody help me?

Thanks in advance,



	[[alternative HTML version deleted]]


From jeremiejuste at gmail.com  Wed Nov 15 21:24:00 2017
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Wed, 15 Nov 2017 21:24:00 +0100
Subject: [R] Problems installing mice package
In-Reply-To: <1F9E067C-98C5-4857-BF7D-62C8DAD935B3@comcast.net>
References: <87efozvrhb.fsf@freegnu.noherd.org>
 <1F9E067C-98C5-4857-BF7D-62C8DAD935B3@comcast.net>
Message-ID: <CAPHJcdAygRHxqLV7mL2q97cGOOdz6FoMtQGhX=SKmwSxDjqs=Q@mail.gmail.com>

Hello,

Many thanks for your time

My mistake was to put <cat("Welcome to R!\n")> in the .Rprofile.
I've never got any problem with the package installation before though.

Best regards,

Jeremie


On Wed, Nov 15, 2017 at 6:49 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 15, 2017, at 1:08 AM, Jeremie Juste <jeremiejuste at gmail.com>
> wrote:
> >
> >
> >
> > Hello,
> >
> > I tried intalling mice package and got the following error:
> >
> > * installing *source* package ?mice? ...
> > ** package ?mice? successfully unpacked and MD5 sums checked
> > ** libs
> > g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-
> linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2
> -c RcppExports.cpp -o RcppExports.o
> > g++  -I/usr/local/lib/R/include -DNDEBUG  -I"/home/djj/R/x86_64-pc-
> linux-gnu-library/3.4/Rcpp/include" -I/usr/local/include   -fpic  -g -O2
> -c match.cpp -o match.o
> > g++ -shared -L/usr/local/lib -o mice.so RcppExports.o match.o Welcome to
> R! Goodbye!
>
> Somehow you have sent an R "welcome message" to the installer script. What
> was the action that started all this? Were you in an R session or was this
> something done from a bash console?
>
> > g++: error: Welcome: No such file or directory
> > g++: error: to: No such file or directory
> > g++: error: R!: No such file or directory
> > g++: error: Goodbye!: No such file or directory
> > /usr/local/lib/R/share/make/shlib.mk:6: recipe for target 'mice.so'
> failed
> > make: *** [mice.so] Error 1
> > ERROR: compilation failed for package ?mice?
> > * removing ?/home/djj/R/x86_64-pc-linux-gnu-library/3.4/mice?
> >
> > The downloaded source packages are in
> >       ?/tmp/Rtmpgam70t/downloaded_packages?
> > Error in library(mice) : there is no package called ?mice?
> > In addition: Warning message:
> > In  :
>
> That's a rather strange method for invoking install.packages. Usually it
> would be just:
>
> install.packages("mice", repos = "http://cran.us.r-project.org")
>
>
>
> Your best venue for linux installation questions is probably:
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-db
>
>
> >  installation of package ?mice? had non-zero exit status
> >
> > I'm unable to resolve it. Any help please?
> >
> > Best regards,
> >
> > Jeremie
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>


-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From lemesmachado at gmail.com  Wed Nov 15 14:39:37 2017
From: lemesmachado at gmail.com (=?UTF-8?Q?Jo=C3=A3o_Paulo_Lemes_Machado?=)
Date: Wed, 15 Nov 2017 11:39:37 -0200
Subject: [R] Creating a SQL R package
Message-ID: <CAE8X0UWNzBvdaGTA0Tj9cfgpEfoMBwA5QTGRh1wDcMrEDfemvw@mail.gmail.com>

Hello everyone. My name is Jo?o Paulo I am a
master's student in the course of  omputer
science.

I intend to create a package for the R that
makes the SQL language commands available for use. I know that there are
already some packages that execute SQL commands within R. However, most of
these commands require querys to be passed as a string. I wish SQL commands
could be used more naturally.

For example: If I want to select all the columns
of a dataframe by limiting the first 10 rows I use the following command:
dataframe [1:10,]

In SQL would be: Select * from datarrame limit
10.

My idea is to ease the transition of people
which as I have enough knowledge in SQL, and enable that R can be used as a
mysql workbench to execute querys on databases. What do you think? Any tips on
where to start?

	[[alternative HTML version deleted]]


From asafaneh at yahoo.com  Wed Nov 15 16:13:29 2017
From: asafaneh at yahoo.com (Ashraf Afana)
Date: Wed, 15 Nov 2017 15:13:29 +0000 (UTC)
Subject: [R] Rasterize function with maximum in R
References: <212223796.958680.1510758809773.ref@mail.yahoo.com>
Message-ID: <212223796.958680.1510758809773@mail.yahoo.com>

 
Hi all,

I have some concerns regarding the rasterize option in R and I would like to know if the fun=max in rasterize in R provides similar results to the one achieved by using "Polygon to Raster using maximum-combined-area" in ArcGIS?

I'm trying to rasterize a habitat layer to a raster of 10m spatial resolution using the function 'max' (e.g. r <- rasterize(ht, r, "Priority", fun = 'max') and I would like to assign the habitat of the largest overlapping area, which is similar to the ?maximum-combined-area?. My original layer contains the habitat information as a character string values (e.g. K1, K2, I1, I2, I3, etc.) of 20 classes. Before resterizing, I have converted these classes to numeric (e.g. in my case 1 to 20).
I have my doubts about the validity and type of maximums generated by this code. From what I can see, I?m not sure if the use of fun= ?max? in Rasterize in R implies the use of the absolute maximum or the combined maximum area. My point is if I convert the original character string values of Priority to numeric, the maximum for the numeric values will have nothing to do with the maximum combined area under cover. For example, if we have a pixel which is covered by 90% of habitat 1 and 10% of habitat 15, the value of the pixel will be assigned to the habitat 15. Does that make any sense? Any suggestion or clarification would be appreciated.Regards
?Ashraf,?


	[[alternative HTML version deleted]]


From hasan.diwan at gmail.com  Wed Nov 15 22:50:28 2017
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Wed, 15 Nov 2017 13:50:28 -0800
Subject: [R] Creating a SQL R package
In-Reply-To: <CAE8X0UWNzBvdaGTA0Tj9cfgpEfoMBwA5QTGRh1wDcMrEDfemvw@mail.gmail.com>
References: <CAE8X0UWNzBvdaGTA0Tj9cfgpEfoMBwA5QTGRh1wDcMrEDfemvw@mail.gmail.com>
Message-ID: <CAP+bYWCpFHJp9WNeYRJ3uks08BHn-g-EgukT3HCmf0U7xJ+wYA@mail.gmail.com>

Joao,

On 15 November 2017 at 05:39, Jo?o Paulo Lemes Machado <
lemesmachado at gmail.com> wrote:

> I intend to create a package for the R that
> makes the SQL language commands available for use.  What do you think? Any
> tips on
> where to start?
>

https://github.com/ggrothendieck/sqldf seems to be what you're trying to
duplicate. -- H



-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=
get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using http://bit.ly/
hd1ScheduleRequest.
Si vous voudrais faire connnaisance, allez a http://bit.ly/
hd1ScheduleRequest.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Nov 15 23:13:13 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Nov 2017 14:13:13 -0800
Subject: [R] Rasterize function with maximum in R
In-Reply-To: <212223796.958680.1510758809773@mail.yahoo.com>
References: <212223796.958680.1510758809773.ref@mail.yahoo.com>
 <212223796.958680.1510758809773@mail.yahoo.com>
Message-ID: <CAGxFJbRLTyy7S9H=JQPFYYqbin2uk8+Ohy5EPZS2HArEkHj6HA@mail.gmail.com>

I believe you should post this on the r-sig-geo list, not here. You are
much more likely to find the relevant expertise there.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 15, 2017 at 7:13 AM, Ashraf Afana via R-help <
r-help at r-project.org> wrote:

>
> Hi all,
>
> I have some concerns regarding the rasterize option in R and I would like
> to know if the fun=max in rasterize in R provides similar results to the
> one achieved by using "Polygon to Raster using maximum-combined-area" in
> ArcGIS?
>
> I'm trying to rasterize a habitat layer to a raster of 10m spatial
> resolution using the function 'max' (e.g. r <- rasterize(ht, r, "Priority",
> fun = 'max') and I would like to assign the habitat of the largest
> overlapping area, which is similar to the ?maximum-combined-area?. My
> original layer contains the habitat information as a character string
> values (e.g. K1, K2, I1, I2, I3, etc.) of 20 classes. Before resterizing, I
> have converted these classes to numeric (e.g. in my case 1 to 20).
> I have my doubts about the validity and type of maximums generated by this
> code. From what I can see, I?m not sure if the use of fun= ?max? in
> Rasterize in R implies the use of the absolute maximum or the combined
> maximum area. My point is if I convert the original character string values
> of Priority to numeric, the maximum for the numeric values will have
> nothing to do with the maximum combined area under cover. For example, if
> we have a pixel which is covered by 90% of habitat 1 and 10% of habitat 15,
> the value of the pixel will be assigned to the habitat 15. Does that make
> any sense? Any suggestion or clarification would be appreciated.Regards
>  Ashraf,
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruiyangliu94 at gmail.com  Wed Nov 15 23:22:14 2017
From: ruiyangliu94 at gmail.com (=?utf-8?B?5YiY55Ge6Ziz?=)
Date: Wed, 15 Nov 2017 16:22:14 -0600
Subject: [R] Converting a string to variable names
In-Reply-To: <CA+8X3fXjF6ZbjHmNvXtxx0t8Py_8jv4b2siP8y1jXT8NwdoPgA@mail.gmail.com>
References: <3577B47C-2B27-4115-87CC-71F0F26C3B3E@gmail.com>
 <CA+8X3fXjF6ZbjHmNvXtxx0t8Py_8jv4b2siP8y1jXT8NwdoPgA@mail.gmail.com>
Message-ID: <CF18B198-D31A-4AC3-A9EC-295D01A26189@gmail.com>

Hi,

Thanks for your reply.

I just came up with another question about a similar but different thing:

Say I have a bunch of data.frame variables named P1,P2,P3? I want to assign them row names according to symbols in the first column, and I want to do this using a for loop. How could I accomplish this?


for (test_sample in c(1:10)){
+ x<-as.name(paste(?P",as.character(test_sampel),sep=""))
+ rownames(x)<-get((paste(?P?,as.character(test_sample),sep="")))[,1]
+ }

This would not work probably because x is simply a name instead of a data.frame variable(Error: "attempt to set 'rownames' on an object with no dimensions"). But I could not find the right way out? How should I solve it?

Thanks!

Ruiyang


> On Nov 14, 2017, at 4:39 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Ruiyang,
> I think you want "get":
> 
> For (index in seq(1,16)){
> plot(x=(a given set of value),y=get(paste(?PC?,as.character(index),sep=??)))
> }
> 
> On Wed, Nov 15, 2017 at 7:43 AM, ??? <ruiyangliu94 at gmail.com> wrote:
>> Hi,
>> Suppose that I want to do a series of plots with the y value for each plot as PC1, PC2, PC3? How could I accomplish this using a for loop?
>> Suppose the code like this:
>> 
>> For (index in seq(1,16)){
>> plot(x=(a given set of value),y=paste(?PC?,as.character(index),sep=??)
>> }
>> 
>> But this would not work because y is assigned a string instead of the variable names. So how could I assign y with a variable name instead of a string? Your reply would be appreciated!
>> Ruiyang Liu
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Nov 15 23:41:06 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Nov 2017 09:41:06 +1100
Subject: [R] Converting a string to variable names
In-Reply-To: <CF18B198-D31A-4AC3-A9EC-295D01A26189@gmail.com>
References: <3577B47C-2B27-4115-87CC-71F0F26C3B3E@gmail.com>
 <CA+8X3fXjF6ZbjHmNvXtxx0t8Py_8jv4b2siP8y1jXT8NwdoPgA@mail.gmail.com>
 <CF18B198-D31A-4AC3-A9EC-295D01A26189@gmail.com>
Message-ID: <CA+8X3fUcHpj3=+XZneLkHJwq8y_WjE=xNOZnaS=0XDxq6LAWSw@mail.gmail.com>

Hi Ruiyang,
In this case you don't want the "get", just the strings produced by "paste":

mydf<-data.frame(col1=LETTERS[1:10],col2=1:10)
rownames(mydf)<-paste("P",mydf$col1,sep="")

Jim

On Thu, Nov 16, 2017 at 9:22 AM, ??? <ruiyangliu94 at gmail.com> wrote:
> Hi,
>
> Thanks for your reply.
>
> I just came up with another question about a similar but different thing:
>
> Say I have a bunch of data.frame variables named P1,P2,P3? I want to assign them row names according to symbols in the first column, and I want to do this using a for loop. How could I accomplish this?
>
>
> for (test_sample in c(1:10)){
> + x<-as.name(paste(?P",as.character(test_sampel),sep=""))
> + rownames(x)<-get((paste(?P?,as.character(test_sample),sep="")))[,1]
> + }
>
> This would not work probably because x is simply a name instead of a data.frame variable(Error: "attempt to set 'rownames' on an object with no dimensions"). But I could not find the right way out? How should I solve it?
>
> Thanks!
>
> Ruiyang
>
>
>> On Nov 14, 2017, at 4:39 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Ruiyang,
>> I think you want "get":
>>
>> For (index in seq(1,16)){
>> plot(x=(a given set of value),y=get(paste(?PC?,as.character(index),sep=??)))
>> }
>>
>> On Wed, Nov 15, 2017 at 7:43 AM, ??? <ruiyangliu94 at gmail.com> wrote:
>>> Hi,
>>> Suppose that I want to do a series of plots with the y value for each plot as PC1, PC2, PC3? How could I accomplish this using a for loop?
>>> Suppose the code like this:
>>>
>>> For (index in seq(1,16)){
>>> plot(x=(a given set of value),y=paste(?PC?,as.character(index),sep=??)
>>> }
>>>
>>> But this would not work because y is assigned a string instead of the variable names. So how could I assign y with a variable name instead of a string? Your reply would be appreciated!
>>> Ruiyang Liu
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rahulutube69 at gmail.com  Thu Nov 16 03:17:29 2017
From: rahulutube69 at gmail.com (Rahul singh)
Date: Thu, 16 Nov 2017 07:47:29 +0530
Subject: [R] NEED HELP : Association in single DTM
In-Reply-To: <1D92EF71-9B85-469B-9AE4-A93B26617ED4@utoronto.ca>
References: <CAGprg3Jn=KUZMQZfqDUMfW5Y2ptjcgKJC+q1TmrFGGc+_oJcWg@mail.gmail.com>
 <1D92EF71-9B85-469B-9AE4-A93B26617ED4@utoronto.ca>
Message-ID: <CAGprg3LQLRix1s65bWWtXS3YvXMm7N93Kfr36Y8t3oe0f+xF6Q@mail.gmail.com>

Hi Boris,

In that case, if I have lot of free text data (let us assume part of an
Election speech) in one single TEXT document, and i want to find the
association of the top 3 most frequently occurring words with the other
words in the speech, what method do I adopt ?

On Wed, Nov 15, 2017 at 7:08 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> If you consider the definition of a DTM, and that findAssoc() computes
> associations between words as correlations across documents(!), you will
> realize that you can't what you want from a single document. Indeed, what
> kind of an "association" would you even be looking for?
>
> B.
>
>
>
> > On Nov 15, 2017, at 12:40 AM, Rahul singh <rahulutube69 at gmail.com>
> wrote:
> >
> > I have free text data in a single text document. I create a corpus, and
> > then a document term matrix out of it. I can create a word cloud too.
> >
> > But when I do word association for the same, using "findAssocs(), it
> always
> > returns numeric(0).
> >
> > EX : findAssocs(dtm, "king" ,000000000000000000000.1)
> >
> > I read on stack overflow that it is because I have a single document.
> >
> > What is the workaround for the same ?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Nov 16 04:35:04 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Nov 2017 19:35:04 -0800
Subject: [R] NEED HELP : Association in single DTM
In-Reply-To: <CAGprg3LQLRix1s65bWWtXS3YvXMm7N93Kfr36Y8t3oe0f+xF6Q@mail.gmail.com>
References: <CAGprg3Jn=KUZMQZfqDUMfW5Y2ptjcgKJC+q1TmrFGGc+_oJcWg@mail.gmail.com>
 <1D92EF71-9B85-469B-9AE4-A93B26617ED4@utoronto.ca>
 <CAGprg3LQLRix1s65bWWtXS3YvXMm7N93Kfr36Y8t3oe0f+xF6Q@mail.gmail.com>
Message-ID: <CAGxFJbTdQawAESyf4zB2ecg4MWuwnLztP7sPryt7874+gEkWSw@mail.gmail.com>

In general, statistical methodology queries, which seems to be your
concern,  are offtopic here.This list is about R programming.  Consider
stats.stackexchange.com  for statistical queries.

However, the CRAN task view on natural language processing might be useful,
so you may wish to check it:

https://cran.r-project.org/web/views/NaturalLanguageProcessing.html

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 15, 2017 at 6:17 PM, Rahul singh <rahulutube69 at gmail.com> wrote:

> Hi Boris,
>
> In that case, if I have lot of free text data (let us assume part of an
> Election speech) in one single TEXT document, and i want to find the
> association of the top 3 most frequently occurring words with the other
> words in the speech, what method do I adopt ?
>
> On Wed, Nov 15, 2017 at 7:08 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
> > If you consider the definition of a DTM, and that findAssoc() computes
> > associations between words as correlations across documents(!), you will
> > realize that you can't what you want from a single document. Indeed, what
> > kind of an "association" would you even be looking for?
> >
> > B.
> >
> >
> >
> > > On Nov 15, 2017, at 12:40 AM, Rahul singh <rahulutube69 at gmail.com>
> > wrote:
> > >
> > > I have free text data in a single text document. I create a corpus, and
> > > then a document term matrix out of it. I can create a word cloud too.
> > >
> > > But when I do word association for the same, using "findAssocs(), it
> > always
> > > returns numeric(0).
> > >
> > > EX : findAssocs(dtm, "king" ,000000000000000000000.1)
> > >
> > > I read on stack overflow that it is because I have a single document.
> > >
> > > What is the workaround for the same ?
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Nov 16 05:28:59 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 15 Nov 2017 23:28:59 -0500
Subject: [R] NEED HELP : Association in single DTM
In-Reply-To: <CAGxFJbTdQawAESyf4zB2ecg4MWuwnLztP7sPryt7874+gEkWSw@mail.gmail.com>
References: <CAGprg3Jn=KUZMQZfqDUMfW5Y2ptjcgKJC+q1TmrFGGc+_oJcWg@mail.gmail.com>
 <1D92EF71-9B85-469B-9AE4-A93B26617ED4@utoronto.ca>
 <CAGprg3LQLRix1s65bWWtXS3YvXMm7N93Kfr36Y8t3oe0f+xF6Q@mail.gmail.com>
 <CAGxFJbTdQawAESyf4zB2ecg4MWuwnLztP7sPryt7874+gEkWSw@mail.gmail.com>
Message-ID: <B638A272-949F-4644-8F8F-0B68E755F35B@utoronto.ca>

No - the CRAN task view is not going to help you at all, since you need to think more about the question that you are trying to ask before you can start worrying about which packages to pursue it with.

In your case this hinges on the question what you mean by "association". In the same phrase? In the same sentence? Adjacent? Or separated by k words? For what k?

Once you come clear on that, we can probably show you ways to translate your procedure into R code. But - as Bert mentioned - we are not well positioned to define the procedure for you.

Boris




> On Nov 15, 2017, at 10:35 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> In general, statistical methodology queries, which seems to be your concern,  are offtopic here.This list is about R programming.  Consider stats.stackexchange.com  for statistical queries. 
> 
> However, the CRAN task view on natural language processing might be useful, so you may wish to check it:
> 
> https://cran.r-project.org/web/views/NaturalLanguageProcessing.html
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Wed, Nov 15, 2017 at 6:17 PM, Rahul singh <rahulutube69 at gmail.com> wrote:
> Hi Boris,
> 
> In that case, if I have lot of free text data (let us assume part of an
> Election speech) in one single TEXT document, and i want to find the
> association of the top 3 most frequently occurring words with the other
> words in the speech, what method do I adopt ?
> 
> On Wed, Nov 15, 2017 at 7:08 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> 
> > If you consider the definition of a DTM, and that findAssoc() computes
> > associations between words as correlations across documents(!), you will
> > realize that you can't what you want from a single document. Indeed, what
> > kind of an "association" would you even be looking for?
> >
> > B.
> >
> >
> >
> > > On Nov 15, 2017, at 12:40 AM, Rahul singh <rahulutube69 at gmail.com>
> > wrote:
> > >
> > > I have free text data in a single text document. I create a corpus, and
> > > then a document term matrix out of it. I can create a word cloud too.
> > >
> > > But when I do word association for the same, using "findAssocs(), it
> > always
> > > returns numeric(0).
> > >
> > > EX : findAssocs(dtm, "king" ,000000000000000000000.1)
> > >
> > > I read on stack overflow that it is because I have a single document.
> > >
> > > What is the workaround for the same ?
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.ca.us  Thu Nov 16 08:55:29 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 15 Nov 2017 23:55:29 -0800 (PST)
Subject: [R] R6 object that is a list of referenced object
In-Reply-To: <VI1PR0202MB3375D48BA7287160DF6C39A2A9290@VI1PR0202MB3375.eurprd02.prod.outlook.com>
References: <VI1PR0202MB3375D48BA7287160DF6C39A2A9290@VI1PR0202MB3375.eurprd02.prod.outlook.com>
Message-ID: <alpine.BSF.2.00.1711152326020.22214@pedal.dcn.davis.ca.us>

See below.

On Wed, 15 Nov 2017, Cristina Pascual wrote:

> Dear community,
>
> I am having a class, let's say Person,
>
> Person <-  R6Class("Person",
>                     public = list(
>                       idPerson = NULL,
>                       name = NULL,
>                       age = NULL,
>                       initialize = function(idPerson = NA, name = NA, age = NA) {

It is a bad idea to setup default values for all your parameters in any 
function, but particularly so for an initialization function. A Person 
with NA in the idPerson field is essentially unusable, so encouraging the 
creation of such an object is very bad practice.

>                        self$idPerson <- idPerson
>                        self$name <- name
>                        self$age <- age
>                       }
>                     ) # public
>
> ) # Person
>
> I have created:
> Person1 <- Person$new(1,'a',4)
> Person2 <- Person$new(2,'b',5)
>
> and I also have a class Community:
>
> Community <- R6Class("Community",
>                 public = list(
>                   e = NULL,
>                   initialize = function() self$e <- Person$new()

Initializing a Community with a bogus person is as bad as the idPerson 
being NA. It makes a lot more sense to have the set of persons in a 
community be the null set than to have a minimum of one person in the 
community who happens to have invalid identification.

>                 )
> )
>
> I want to create
>
> Community1 = List<Person>
>
> and add Person1 and Person2 to Community1 (Community1 <- Community1$add(Person1)
>                                                                                    Community1 <- Community1$add(Person2)
>
> ????)
>
> How can I write this with R6? I cannot find the proper example in the website.
>
> Can anybody help me?
>
> Thanks in advance,

You don't seem to be very familiar with either R or conventional 
object-oriented design. Although I am giving you a reprex below, I 
recommend that you avoid R6 until you are more familiar with how normal 
functional programming and S3 object oriented coding styles work in R. 
Using R6 as a crutch to avoid that learning process will only lead you to 
frustration and inefficient data handling. That is, this whole thing 
should just be a data frame.

########################################
library(R6)
Person <-  R6Class( "Person"
                   , public = list( 
idPerson = NA
                                  , 
name = NA
                                  , 
age = NA
                                  , 
initialize = function( idPerson

                      , name

                      , age

                      ) {

                self$idPerson <- 
idPerson

                self$name <- name

                self$age <- age

              }
                      ) # public
                   ) # Person

Person1 <- Person$new( 1, 'a', 4 )
Person2 <- Person$new( 2, 'b', 5 )

Community <- R6Class( "Community"
                     , public = 
list( e = NULL

, addPerson = function( p ) {

    self$e <- append( self$e, p )

   }

)
                     )

Community1 <- Community$new()
Community1$addPerson( Person1 )
Community1$addPerson( Person2 )
Community1$e
#> [[1]]
#> <Person>
#>   Public:
#>     age: 4
#>     clone: function (deep = 
FALSE)
#>     idPerson: 1
#>     initialize: function 
(idPerson, name, age)
#>     name: a
#>
#> [[2]]
#> <Person>
#>   Public:
#>     age: 5
#>     clone: function (deep = 
FALSE)
#>     idPerson: 2
#>     initialize: function 
(idPerson, name, age)
#>     name: b

# Standard R approach:
Person1a <- data.frame( idPerson = 1
                       , name = "a"
                       , age = 4
                       , stringsAsFactors = FALSE
                       )
Person2a <- data.frame( idPerson = 2
                       , name = "b"
                       , age = 5
                       , stringsAsFactors = FALSE
                       )
Community1a <- rbind( Person1a, Person2a )
Community1a
#>   idPerson name age
#> 1        1    a   4
#> 2        2    b   5
########################################

>
>
>
> 	[[alternative HTML version deleted]]

Please POST IN PLAIN TEXT FORMAT. This is a setting you must make in 
your email program, and failure to do so will lead to us seeing different 
things than you send (that is, we see varying degrees of scrambling of 
your message if you send HTML-formatted emails). Read the Posting Guide 
mentioned below for more success tips.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ericjberger at gmail.com  Thu Nov 16 11:03:13 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 16 Nov 2017 12:03:13 +0200
Subject: [R] R6 object that is a list of referenced object
In-Reply-To: <alpine.BSF.2.00.1711152326020.22214@pedal.dcn.davis.ca.us>
References: <VI1PR0202MB3375D48BA7287160DF6C39A2A9290@VI1PR0202MB3375.eurprd02.prod.outlook.com>
 <alpine.BSF.2.00.1711152326020.22214@pedal.dcn.davis.ca.us>
Message-ID: <CAGgJW76z+Jgy9OYgToWfsHdOfwhyiY3y1XtRK7HgbszPJQBfYQ@mail.gmail.com>

Hi Cristina,
You can try this:

> Community <- R6Class("Community",
                       public = list(
                         e = NULL,
                         initialize = function() { self$e <- list() },
                         add = function( person ) { self$e[[ length(self$e)
+ 1]] <<- person }
                       )
  )

> crowd <- Community$new()
> crowd$add(Person1)
> crowd$add(Person2)
> crowd$e

HTH,
Eric


On Thu, Nov 16, 2017 at 9:55 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> See below.
>
> On Wed, 15 Nov 2017, Cristina Pascual wrote:
>
> Dear community,
>>
>> I am having a class, let's say Person,
>>
>> Person <-  R6Class("Person",
>>                     public = list(
>>                       idPerson = NULL,
>>                       name = NULL,
>>                       age = NULL,
>>                       initialize = function(idPerson = NA, name = NA, age
>> = NA) {
>>
>
> It is a bad idea to setup default values for all your parameters in any
> function, but particularly so for an initialization function. A Person with
> NA in the idPerson field is essentially unusable, so encouraging the
> creation of such an object is very bad practice.
>
>                        self$idPerson <- idPerson
>>                        self$name <- name
>>                        self$age <- age
>>                       }
>>                     ) # public
>>
>> ) # Person
>>
>> I have created:
>> Person1 <- Person$new(1,'a',4)
>> Person2 <- Person$new(2,'b',5)
>>
>> and I also have a class Community:
>>
>> Community <- R6Class("Community",
>>                 public = list(
>>                   e = NULL,
>>                   initialize = function() self$e <- Person$new()
>>
>
> Initializing a Community with a bogus person is as bad as the idPerson
> being NA. It makes a lot more sense to have the set of persons in a
> community be the null set than to have a minimum of one person in the
> community who happens to have invalid identification.
>
>                 )
>> )
>>
>> I want to create
>>
>> Community1 = List<Person>
>>
>> and add Person1 and Person2 to Community1 (Community1 <-
>> Community1$add(Person1)
>>
>>          Community1 <- Community1$add(Person2)
>>
>> ????)
>>
>> How can I write this with R6? I cannot find the proper example in the
>> website.
>>
>> Can anybody help me?
>>
>> Thanks in advance,
>>
>
> You don't seem to be very familiar with either R or conventional
> object-oriented design. Although I am giving you a reprex below, I
> recommend that you avoid R6 until you are more familiar with how normal
> functional programming and S3 object oriented coding styles work in R.
> Using R6 as a crutch to avoid that learning process will only lead you to
> frustration and inefficient data handling. That is, this whole thing should
> just be a data frame.
>
> ########################################
> library(R6)
> Person <-  R6Class( "Person"
>                   , public = list( idPerson = NA
>                                  , name = NA
>                                  , age = NA
>                                  , initialize = function( idPerson
>
>                      , name
>
>                      , age
>
>                      ) {
>
>                self$idPerson <- idPerson
>
>                self$name <- name
>
>                self$age <- age
>
>              }
>                      ) # public
>                   ) # Person
>
> Person1 <- Person$new( 1, 'a', 4 )
> Person2 <- Person$new( 2, 'b', 5 )
>
> Community <- R6Class( "Community"
>                     , public = list( e = NULL
>
> , addPerson = function( p ) {
>
>    self$e <- append( self$e, p )
>
>   }
>
> )
>                     )
>
> Community1 <- Community$new()
> Community1$addPerson( Person1 )
> Community1$addPerson( Person2 )
> Community1$e
> #> [[1]]
> #> <Person>
> #>   Public:
> #>     age: 4
> #>     clone: function (deep = FALSE)
> #>     idPerson: 1
> #>     initialize: function (idPerson, name, age)
> #>     name: a
> #>
> #> [[2]]
> #> <Person>
> #>   Public:
> #>     age: 5
> #>     clone: function (deep = FALSE)
> #>     idPerson: 2
> #>     initialize: function (idPerson, name, age)
> #>     name: b
>
> # Standard R approach:
> Person1a <- data.frame( idPerson = 1
>                       , name = "a"
>                       , age = 4
>                       , stringsAsFactors = FALSE
>                       )
> Person2a <- data.frame( idPerson = 2
>                       , name = "b"
>                       , age = 5
>                       , stringsAsFactors = FALSE
>                       )
> Community1a <- rbind( Person1a, Person2a )
> Community1a
> #>   idPerson name age
> #> 1        1    a   4
> #> 2        2    b   5
> ########################################
>
>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>
> Please POST IN PLAIN TEXT FORMAT. This is a setting you must make in your
> email program, and failure to do so will lead to us seeing different things
> than you send (that is, we see varying degrees of scrambling of your
> message if you send HTML-formatted emails). Read the Posting Guide
> mentioned below for more success tips.
>
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From AlexanderB.22 at hotmail.de  Thu Nov 16 15:25:16 2017
From: AlexanderB.22 at hotmail.de (=?utf-8?B?QWxleGFuZGVyIEJlcmdtw7xsbGVy?=)
Date: Thu, 16 Nov 2017 14:25:16 +0000
Subject: [R] Yield-to-Maturity problem
Message-ID: <VI1PR06MB1198AFEE4AD390618087159B8F2E0@VI1PR06MB1198.eurprd06.prod.outlook.com>

Hello everybody,

I am not very advanced in my R skills so I really hope anybody of you can help me with this problem on which I have been working for hours.

I would like to write a function, which can guess the yield-to-maturity for any values: C, NV, r, s1, s2, and for a freely chosen tolerance (tol).

Additionaly, for freely chosen T; -> s1, s2, s3, ..., sT

I appreciate your help so much.
Greetings,

Alexandra Becker


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Nov 16 16:55:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 16 Nov 2017 07:55:20 -0800
Subject: [R] Yield-to-Maturity problem
In-Reply-To: <VI1PR06MB1198AFEE4AD390618087159B8F2E0@VI1PR06MB1198.eurprd06.prod.outlook.com>
References: <VI1PR06MB1198AFEE4AD390618087159B8F2E0@VI1PR06MB1198.eurprd06.prod.outlook.com>
Message-ID: <CAGxFJbT660+PFFyn4uWnX9rXAdto0ZrH63co7zdyFqUjQwo8tQ@mail.gmail.com>

This list has a no homework policy.

Also, please read the posting guidebelow to learn what sorts of posts are
legitimate and how to post.
Note: plain text , not html, which often gets mangked by the server.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 16, 2017 at 6:25 AM, Alexander Bergm?ller <
AlexanderB.22 at hotmail.de> wrote:

> Hello everybody,
>
> I am not very advanced in my R skills so I really hope anybody of you can
> help me with this problem on which I have been working for hours.
>
> I would like to write a function, which can guess the yield-to-maturity
> for any values: C, NV, r, s1, s2, and for a freely chosen tolerance (tol).
>
> Additionaly, for freely chosen T; -> s1, s2, s3, ..., sT
>
> I appreciate your help so much.
> Greetings,
>
> Alexandra Becker
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Nov 16 17:00:48 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 Nov 2017 17:00:48 +0100
Subject: [R] ks.test() with 2 samples vs. 1 sample an distr. function
In-Reply-To: <92f0962b75c94ec8b052c062a1e804ee@exch-2p-mbx-w2.ads.tamu.edu>
References: <trinity-894420b6-0e9e-4a02-9833-586b045b0163-1510739203535@3c-app-webde-bap37>
 <92f0962b75c94ec8b052c062a1e804ee@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <E36C98A6-49A8-4DC1-B073-BF59F16251E8@gmail.com>

I suspect that that reply just replicates the question. 

There are two issues: The distribution of the test statistic is different, which may be unsurprising. However, the test statistic itself is also different which may be a bit more subtle. It may help to plot(ecdf(xi)) and similarly x. The 2-sample KS statistic will is the maximum vertical distance between two step functions, so with 2x8 points, it will be a multiple of .125. The 1-sample version is the max distance between a step function and a smooth curve.

-pd

 
> On 15 Nov 2017, at 16:56 , David L Carlson <dcarlson at tamu.edu> wrote:
> 
> In the first example you are performing a one-sample test against a continuous cumulative distribution (in this case a normal distribution). In the second case you are performing a two-sample test. You drew your values for x non-randomly by specifying fixed intervals along a normal distribution, but ks.test() just sees that you have provided two samples, not one sample and values along a cumulative distribution.
> 
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of tonja.krueger at web.de
> Sent: Wednesday, November 15, 2017 3:47 AM
> To: r-help at r-project.org
> Subject: [R] ks.test() with 2 samples vs. 1 sample an distr. function
> 
> Dear all,
> I have a question concerning the ks.test() function. I tryed to calculate the example given on the German wikipedia page.
> xi <- c(9.41,9.92,11.55,11.6,11.73,12,12.06,13.3)
> I get the right results when I calculate: ks.test(xi,pnorm,11,1) Now the question: shouldn't I obtain the same or a very similar result if I commpare the sample and a calculated sample from the distribution?
> p<- c(0.125, 0.250, 0.375, 0.500, 0.625, 0.750, 0.875, 0.9999) x <- qnorm(p,11,1)
> ks.test(xi,x)
> Why don't I?
> Thanks for helping me!
> Tonja
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Thu Nov 16 17:23:31 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 Nov 2017 17:23:31 +0100
Subject: [R] Yield-to-Maturity problem
In-Reply-To: <CAGxFJbT660+PFFyn4uWnX9rXAdto0ZrH63co7zdyFqUjQwo8tQ@mail.gmail.com>
References: <VI1PR06MB1198AFEE4AD390618087159B8F2E0@VI1PR06MB1198.eurprd06.prod.outlook.com>
 <CAGxFJbT660+PFFyn4uWnX9rXAdto0ZrH63co7zdyFqUjQwo8tQ@mail.gmail.com>
Message-ID: <0E264B65-426A-4B45-BFB9-AC917EEF364E@gmail.com>

This isn't all that likely to be homework, Bert....

However, Alexander, you may find that not many readers are familiar with YTM concepts. 

There's a chapter with R examples in Ruppert+Matteson's book (if you have SpringerLink, you may be able to download for free). Otherwise you could try searching CRAN, but be warned that you may get considerably more than you wished for. Some packages do look like they could be relevant. 

-pd

> On 16 Nov 2017, at 16:55 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> This list has a no homework policy.
> 
> Also, please read the posting guidebelow to learn what sorts of posts are
> legitimate and how to post.
> Note: plain text , not html, which often gets mangked by the server.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Nov 16, 2017 at 6:25 AM, Alexander Bergm?ller <
> AlexanderB.22 at hotmail.de> wrote:
> 
>> Hello everybody,
>> 
>> I am not very advanced in my R skills so I really hope anybody of you can
>> help me with this problem on which I have been working for hours.
>> 
>> I would like to write a function, which can guess the yield-to-maturity
>> for any values: C, NV, r, s1, s2, and for a freely chosen tolerance (tol).
>> 
>> Additionaly, for freely chosen T; -> s1, s2, s3, ..., sT
>> 
>> I appreciate your help so much.
>> Greetings,
>> 
>> Alexandra Becker
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marc_schwartz at me.com  Thu Nov 16 17:30:54 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 16 Nov 2017 11:30:54 -0500
Subject: [R] Yield-to-Maturity problem
In-Reply-To: <0E264B65-426A-4B45-BFB9-AC917EEF364E@gmail.com>
References: <VI1PR06MB1198AFEE4AD390618087159B8F2E0@VI1PR06MB1198.eurprd06.prod.outlook.com>
 <CAGxFJbT660+PFFyn4uWnX9rXAdto0ZrH63co7zdyFqUjQwo8tQ@mail.gmail.com>
 <0E264B65-426A-4B45-BFB9-AC917EEF364E@gmail.com>
Message-ID: <55422C03-2DBF-42A3-B953-C964D992ADE8@me.com>

Hi,

Another resource would be R-SIG-Finance, which is an R e-mail list focused in this domain:

  https://stat.ethz.ch/mailman/listinfo/r-sig-finance <https://stat.ethz.ch/mailman/listinfo/r-sig-finance>

as well as the Finance Task View:

  https://cran.r-project.org/web/views/Finance.html <https://cran.r-project.org/web/views/Finance.html>


Regards,

Marc Schwartz


> On Nov 16, 2017, at 11:23 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> This isn't all that likely to be homework, Bert....
> 
> However, Alexander, you may find that not many readers are familiar with YTM concepts. 
> 
> There's a chapter with R examples in Ruppert+Matteson's book (if you have SpringerLink, you may be able to download for free). Otherwise you could try searching CRAN, but be warned that you may get considerably more than you wished for. Some packages do look like they could be relevant. 
> 
> -pd
> 
>> On 16 Nov 2017, at 16:55 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> This list has a no homework policy.
>> 
>> Also, please read the posting guidebelow to learn what sorts of posts are
>> legitimate and how to post.
>> Note: plain text , not html, which often gets mangked by the server.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Nov 16, 2017 at 6:25 AM, Alexander Bergm?ller <
>> AlexanderB.22 at hotmail.de> wrote:
>> 
>>> Hello everybody,
>>> 
>>> I am not very advanced in my R skills so I really hope anybody of you can
>>> help me with this problem on which I have been working for hours.
>>> 
>>> I would like to write a function, which can guess the yield-to-maturity
>>> for any values: C, NV, r, s1, s2, and for a freely chosen tolerance (tol).
>>> 
>>> Additionaly, for freely chosen T; -> s1, s2, s3, ..., sT
>>> 
>>> I appreciate your help so much.
>>> Greetings,
>>> 
>>> Alexandra Becker
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Thu Nov 16 19:47:11 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Thu, 16 Nov 2017 18:47:11 +0000 (UTC)
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <CAGxFJbRLmR545pwKDLWwH8ZuBFywy2hjJO35aFAbFuHnNbODiQ@mail.gmail.com>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
 <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
 <1068192069.31543.1510692598176@mail.yahoo.com>
 <CAGxFJbQV+aXXPdz1XuumW0m0NC07QdWiRmbZ_epqRmAC=sYo1Q@mail.gmail.com>
 <1013628048.379831.1510751364535@mail.yahoo.com>
 <CAGxFJbRLmR545pwKDLWwH8ZuBFywy2hjJO35aFAbFuHnNbODiQ@mail.gmail.com>
Message-ID: <1245530428.1247053.1510858031103@mail.yahoo.com>

Hi, Bert,
Thank you?very much for the comments and suggestions!
Ace 

    On Wednesday, November 15, 2017 10:44 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 Always cc the list, which I have done here. I am not a (free) private consultant, nor do I have all the answers.

Based on what you sent me, which is not what you have previously posted, you failed to load the lme3 package. See ?library.

As for the appropriateness of your modeling, you should do what David already suggested and post to the r-sig-mixed-models list instead.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 15, 2017 at 5:09 AM, Fix Ace <acefix at rocketmail.com> wrote:

Hi, Bert,
Sorry about that! David seemed to be able to read the post since he replied. Here I just email you the sample code and error message:
> example.3=data.frame(levels= as.numeric(XXX[,c(4)]), replicate=rep(c("0","1","2"," 3","4","5"),3),conditions=c( rep("11",6),rep("12",6),rep(> example.3? ? levels replicate conditions1? 43.1111 ? ? ? ? 0 ? ? ? ? 112? 42.0942 ? ? ? ? 1 ? ? ? ? 113? 57.8131 ? ? ? ? 2 ? ? ? ? 114? 57.1726 ? ? ? ? 3 ? ? ? ? 115? 77.8678 ? ? ? ? 4 ? ? ? ? 116? 44.7578 ? ? ? ? 5 ? ? ? ? 117? 69.5078 ? ? ? ? 0 ? ? ? ? 128? 52.0581 ? ? ? ? 1 ? ? ? ? 129? 40.0602 ? ? ? ? 2 ? ? ? ? 1210 45.5487 ? ? ? ? 3 ? ? ? ? 1211 43.6201 ? ? ? ? 4 ? ? ? ? 1212 60.4939 ? ? ? ? 5 ? ? ? ? 1213 64.1932 ? ? ? ? 0 ? ? ? ? 1314 53.4055 ? ? ? ? 1 ? ? ? ? 1315 59.6701 ? ? ? ? 2 ? ? ? ? 1316 52.6922 ? ? ? ? 3 ? ? ? ? 1317 53.8712 ? ? ? ? 4 ? ? ? ? 1318 60.2770 ? ? ? ? 5 ? ? ? ? 13> m.example.3=lmer(as.numeric( levels)~conditions+( conditions|replicate),data= example.3)Error in lmer(as.numeric(levels) ~ conditions + (conditions | replicate),? :?? could not find function "lmer">?
Hopefully you could read it and provide some comments!
Thank you very much for your time.
Kind regards,
Ace

 

    On Tuesday, November 14, 2017 6:12 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 Still a complete mess!

Post in **plain text**. This should be an option in your email software. Please seek local help if you cannot figure out how to do this.

-- Bert? 



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Nov 14, 2017 at 12:49 PM, Fix Ace via R-help <r-help at r-project.org> wrote:

Hi, David,
Thank you very much for getting back to me! Sorry about the messy code example. I am re-posting here (including the error message):
> example.3=data.frame(levels= as.numeric(XXX[,c(4)]), replicate=rep(c("0","1","2"," 3","4","5"),3),conditions=c( rep("11",6),rep("12",6),rep(" 13",6)))> example.3? ? levels replicate conditions1? 43.1111 ? ? ? ? 0 ? ? ? ? 112? 42.0942 ? ? ? ? 1 ? ? ? ? 113? 57.8131 ? ? ? ? 2 ? ? ? ? 114? 57.1726 ? ? ? ? 3 ? ? ? ? 115? 77.8678 ? ? ? ? 4 ? ? ? ? 116? 44.7578 ? ? ? ? 5 ? ? ? ? 117? 69.5078 ? ? ? ? 0 ? ? ? ? 128? 52.0581 ? ? ? ? 1 ? ? ? ? 129? 40.0602 ? ? ? ? 2 ? ? ? ? 1210 45.5487 ? ? ? ? 3 ? ? ? ? 1211 43.6201 ? ? ? ? 4 ? ? ? ? 1212 60.4939 ? ? ? ? 5 ? ? ? ? 1213 64.1932 ? ? ? ? 0 ? ? ? ? 1314 53.4055 ? ? ? ? 1 ? ? ? ? 1315 59.6701 ? ? ? ? 2 ? ? ? ? 1316 52.6922 ? ? ? ? 3 ? ? ? ? 1317 53.8712 ? ? ? ? 4 ? ? ? ? 1318 60.2770 ? ? ? ? 5 ? ? ? ? 13> m.example.3=lmer(as.numeric( levels)~conditions+( conditions|replicate),data= example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable>?
Please let me know if it is readable this time.?
Again, many thanks for your time and please help me fix the issue.
Kind regards,
Ace

? ? On Tuesday, November 14, 2017 12:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:



> On Nov 14, 2017, at 5:13 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
>
> Dear R Community,
> My data have 3 conditions and each condition has 6 replicates. I am trying to fit my data for a linear mixed model using the lmer function from lme4 package to find the random effects of the replicates;

Better venue for this question might be SIG-mixed-models. See the link avaialble at the bottom of every posting from rhelp:

https://stat.ethz.ch/mailman/ listinfo/r-help:



> however, I got the error message. Here are the example codes:
>> example.3=data.frame(levels= as.numeric(XXX[,c(4)]), replicate=rep(c("0","1","2"," 3","4","5"),3),conditions=c( rep("11",6),rep("12",6),rep(" 13",6)))> example.3? ? levels replicate conditions1? 43.1111? ? ? ? 0? ? ? ? 112? 42.0942? ? ? ? 1? ? ? ? 113? 57.8131? ? ? ? 2? ? ? ? 114? 57.1726? ? ? ? 3? ? ? ? 115? 77.8678? ? ? ? 4? ? ? ? 116? 44.7578? ? ? ? 5? ? ? ? 117? 69.5078? ? ? ? 0? ? ? ? 128? 52.0581? ? ? ? 1? ? ? ? 129? 40.0602? ? ? ? 2? ? ? ? 1210 45.5487? ? ? ? 3? ? ? ? 1211 43.6201? ? ? ? 4? ? ? ? 1212 60.4939? ? ? ? 5? ? ? ? 1213 64.1932? ? ? ? 0? ? ? ? 1314 53.4055? ? ? ? 1? ? ? ? 1315 59.6701? ? ? ? 2? ? ? ? 1316 52.6922? ? ? ? 3? ? ? ? 1317 53.8712? ? ? ? 4? ? ? ? 1318 60.2770? ? ? ? 5? ? ? ? 13> m.example.3=lmer(as.numeric( levels)~conditions+( conditions|replicate),data= example.3)Error: number of observations (=18) <= number of random effects (=18) for term (conditions | replicate); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable>
> Could anyone help me figure out how to fix the issue?
> Thank you very much for any inputs!
> Ace
>
> ??? [[alternative HTML version deleted]]

Complete mess. If you haven't yet been advised to posting in plain text, then this should be your wakeup call. If you have, then why are you ignoring sensible advice?


>
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law







? ? ? ? [[alternative HTML version deleted]]

______________________________ ________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/ listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   



   
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Nov 16 22:53:04 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 16 Nov 2017 16:53:04 -0500
Subject: [R] Risks of using "function <- package::function" ?
Message-ID: <BF38FDC9-57B8-4EFC-9EE5-CA46C8784A2D@utoronto.ca>

Large packages sometimes mask each other's functions and that creates a headache, especially for teaching code, since function signatures may depend on which order packages were loaded in. One of my students proposed using the idiom

  <function> <- <package>::<function>

... in a preamble, when we use just a small subset of functions from a larger package. I like that idea and can't see obvious disadvantages(1).

Are there subtle risks to that approach?

Thanks!
Boris


(1) I think there could be an issue when packages that are loaded later depend on and extend a function that has has been made local. But I'm not even sure what happens then, and it may be more of a hypothetical anyway - can't even think of a situation with which to test it off the top of my head.


From macqueen1 at llnl.gov  Thu Nov 16 23:12:41 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 16 Nov 2017 22:12:41 +0000
Subject: [R] Convert poly line to polygon in R
In-Reply-To: <366C4AFA-8611-48BA-AEAF-C9BF7FD1D87C@dcn.davis.ca.us>
References: <1316118538.788642.1510552736908.ref@mail.yahoo.com>
 <1316118538.788642.1510552736908@mail.yahoo.com>
 <366C4AFA-8611-48BA-AEAF-C9BF7FD1D87C@dcn.davis.ca.us>
Message-ID: <7EE71891-9E1F-422C-BAB5-BB0697F0C5EC@llnl.gov>

In addition to which, the
  rgeos
package may have something.

If it's just a single polyline, it may be pretty easy to pull out the coordinates as a two column matrix, append the first row at the end, and rebuild it as a polygon.

The readOGR function in the rgdal package is probably a better choice for loading a shapfile into R. See also the relatively new package named "sf".

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 11/13/17, 12:47 AM, "R-help on behalf of Jeff Newmiller" <r-help-bounces at r-project.org on behalf of jdnewmil at dcn.davis.ca.us> wrote:

    Might want to post this on R-sig-geo.
    
    Might also want to post in plain text format... see below how your message got messed up coming through the mailing list.
    -- 
    Sent from my phone. Please excuse my brevity.
    
    On November 12, 2017 9:58:56 PM PST, Javad Bayat via R-help <r-help at r-project.org> wrote:
    >I have a shape file as poly line and I want to convert it to polygon.Is
    >it possible to do that in R?lake
    ><-readShapeLines("./lake_main_utm.shp")proj4string(lake) <-
    >CRS("+proj=utm +zone=39 +datum=WGS84")
    >
    >Sincerely.
    >
    >	[[alternative HTML version deleted]]
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From murdoch.duncan at gmail.com  Fri Nov 17 01:46:15 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 Nov 2017 19:46:15 -0500
Subject: [R] Risks of using "function <- package::function" ?
In-Reply-To: <BF38FDC9-57B8-4EFC-9EE5-CA46C8784A2D@utoronto.ca>
References: <BF38FDC9-57B8-4EFC-9EE5-CA46C8784A2D@utoronto.ca>
Message-ID: <c92e99e4-da61-e588-c736-eeb25fa77f5e@gmail.com>

On 16/11/2017 4:53 PM, Boris Steipe wrote:
> Large packages sometimes mask each other's functions and that creates a headache, especially for teaching code, since function signatures may depend on which order packages were loaded in. One of my students proposed using the idiom
> 
>    <function> <- <package>::<function>
> 
> ... in a preamble, when we use just a small subset of functions from a larger package. I like that idea and can't see obvious disadvantages(1).
> 
> Are there subtle risks to that approach?

You might do it twice.  R isn't going to complain if you have

filter <- stats::filter

# some other code here...

filter <- dplyr::filter

in your code, but the second one will overwrite the first one.

The normal way to handle this is in the NAMESPACE file, where you should 
have

importFrom(stats, filter)

If you then have

importFrom(dplyr, filter)

you should get an warning:

Warning: replacing previous import ?stats::filter? by ?dplyr::filter? 
when loading ?testpkg?.

Duncan Murdoch


From david.paul at statmetrics.biz  Fri Nov 17 02:47:41 2017
From: david.paul at statmetrics.biz (David Paul)
Date: Thu, 16 Nov 2017 17:47:41 -0800
Subject: [R] 'fractal' package
Message-ID: <00f601d35f46$10367470$30a35d50$@statmetrics.biz>

https://rdrr.io/rforge/fractal/

https://cran.r-project.org/web/packages/fractal/fractal.pdf

 

 

Hi,

 

I am trying to learn about nonlinear time series, and fractal time series
analysis in particular.  I am interested in becoming proficient with the
'fractal' package.   I have two specific questions:

 

1. I have a basic understanding of ARMA and ARIMA models.  Can someone
recommend a good introductory text on nonlinear time series that emphasizes
practical application?  I am definitely not looking for a theoretical text
on stochastic process.

 

2. Can someone point me in the direction of case studies where the 'fractal'
package has been used to analyze the stock market?  My main interests are in
the DOW Transportation Index and the S&P500, but in the absence of these
kinds of case studies I will happily study any practical case studies that
utilize the 'fractal' package.

 

 

Many Thanks in Advance,

 

David Paul

 


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Nov 17 08:30:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 16 Nov 2017 23:30:40 -0800
Subject: [R] Risks of using "function <- package::function" ?
In-Reply-To: <c92e99e4-da61-e588-c736-eeb25fa77f5e@gmail.com>
References: <BF38FDC9-57B8-4EFC-9EE5-CA46C8784A2D@utoronto.ca>
 <c92e99e4-da61-e588-c736-eeb25fa77f5e@gmail.com>
Message-ID: <54FB7337-7453-4897-BD68-3C2128D6AF26@dcn.davis.ca.us>

Obvious?  How about "obscurity"? Just directly use pkg::fun if you have name collision. 
-- 
Sent from my phone. Please excuse my brevity.

On November 16, 2017 4:46:15 PM PST, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 16/11/2017 4:53 PM, Boris Steipe wrote:
>> Large packages sometimes mask each other's functions and that creates
>a headache, especially for teaching code, since function signatures may
>depend on which order packages were loaded in. One of my students
>proposed using the idiom
>> 
>>    <function> <- <package>::<function>
>> 
>> ... in a preamble, when we use just a small subset of functions from
>a larger package. I like that idea and can't see obvious
>disadvantages(1).
>> 
>> Are there subtle risks to that approach?
>
>You might do it twice.  R isn't going to complain if you have
>
>filter <- stats::filter
>
># some other code here...
>
>filter <- dplyr::filter
>
>in your code, but the second one will overwrite the first one.
>
>The normal way to handle this is in the NAMESPACE file, where you
>should 
>have
>
>importFrom(stats, filter)
>
>If you then have
>
>importFrom(dplyr, filter)
>
>you should get an warning:
>
>Warning: replacing previous import ?stats::filter? by ?dplyr::filter? 
>when loading ?testpkg?.
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From stefano.sofia at regione.marche.it  Fri Nov 17 09:40:24 2017
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 17 Nov 2017 08:40:24 +0000
Subject: [R] How to produce rainfall maps
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F471AE00E@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F471AE00E@ESINO.regionemarche.intra>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F471AE0D5@ESINO.regionemarche.intra>

Dear R users,
I need to produce rainfall maps using R.
I know that this is possible, I looked though the web, I found the example below reported (the author is Andrew Tredennick).
I would ask you if this is the most performing way to make rainfall maps; if yes would someone be able to give me an example of how file.asc and pointfile.csv should be? If no would somebody please show me another way providing a small example?

Thank you for your help
Stefano


library(raster)
library(ggplot2)

#open ASCII file using ?raster? command, which converts the ASCII to a raster object
map <- raster(?/your/path/to/file.asc?)

#convert the raster to points for plotting
map.p <- rasterToPoints(map)

#Make the points a dataframe for ggplot
df <- data.frame(map.p)
#Make appropriate column headings
colnames(df) <- c(?Longitude?, ?Latitude?, ?MAP?)

#Call in point data, in this case a fake transect (csv file with lat and lon coordinates)
sites <- data.frame(read.csv(?/your/path/to/pointfile.csv?))

#Now make the map
ggplot(data=df, aes(y=Latitude, x=Longitude)) +
geom_raster(aes(fill=MAP)) +
geom_point(data=sites, aes(x=x, y=y), color=?white?, size=3, shape=4) +
theme_bw() +
coord_equal() +
scale_fill_gradient(?MAP (mm/yr)?, limits=c(0,2500)) +
theme(axis.title.x = element_text(size=16),
axis.title.y = element_text(size=16, angle=90),
axis.text.x = element_text(size=14),
axis.text.y = element_text(size=14),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.position = ?right?,
legend.key = element_blank()
)



         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Fri Nov 17 10:36:48 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 17 Nov 2017 11:36:48 +0200
Subject: [R] Risks of using "function <- package::function" ?
In-Reply-To: <54FB7337-7453-4897-BD68-3C2128D6AF26@dcn.davis.ca.us>
References: <BF38FDC9-57B8-4EFC-9EE5-CA46C8784A2D@utoronto.ca>
 <c92e99e4-da61-e588-c736-eeb25fa77f5e@gmail.com>
 <54FB7337-7453-4897-BD68-3C2128D6AF26@dcn.davis.ca.us>
Message-ID: <CAGgJW74U15fNHzRXoMdmK6rhhoTevfhGOJAquR9G5Kyd5Mfpnw@mail.gmail.com>

As Jeff recommends, I use the pkg::fun for clarity.
However I probably use it more than needed (e.g. I use the dplyr:: prefix
on all dplyr function calls instead of just the functions with name
collisions).
Are there any tools that can be used (like a form of lint) to identify uses
of functions without the pkg:: prefix and which are part of a name
collision?
One could then edit the code to include the pkg:: prefix to disambiguate
those cases and verify via a repeated use of such a tool that there are no
outstanding cases.

Or alternative approaches to the issue?

Thanks,
Eric


On Fri, Nov 17, 2017 at 9:30 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Obvious?  How about "obscurity"? Just directly use pkg::fun if you have
> name collision.
> --
> Sent from my phone. Please excuse my brevity.
>
> On November 16, 2017 4:46:15 PM PST, Duncan Murdoch <
> murdoch.duncan at gmail.com> wrote:
> >On 16/11/2017 4:53 PM, Boris Steipe wrote:
> >> Large packages sometimes mask each other's functions and that creates
> >a headache, especially for teaching code, since function signatures may
> >depend on which order packages were loaded in. One of my students
> >proposed using the idiom
> >>
> >>    <function> <- <package>::<function>
> >>
> >> ... in a preamble, when we use just a small subset of functions from
> >a larger package. I like that idea and can't see obvious
> >disadvantages(1).
> >>
> >> Are there subtle risks to that approach?
> >
> >You might do it twice.  R isn't going to complain if you have
> >
> >filter <- stats::filter
> >
> ># some other code here...
> >
> >filter <- dplyr::filter
> >
> >in your code, but the second one will overwrite the first one.
> >
> >The normal way to handle this is in the NAMESPACE file, where you
> >should
> >have
> >
> >importFrom(stats, filter)
> >
> >If you then have
> >
> >importFrom(dplyr, filter)
> >
> >you should get an warning:
> >
> >Warning: replacing previous import ?stats::filter? by ?dplyr::filter?
> >when loading ?testpkg?.
> >
> >Duncan Murdoch
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From psoppat at yahoo.com  Fri Nov 17 10:05:44 2017
From: psoppat at yahoo.com (psoppat)
Date: Fri, 17 Nov 2017 14:35:44 +0530
Subject: [R] Multivariate mixture distributions
Message-ID: <0uhlown4j5syan0c90rp4uhg.1510908373048@email.android.com>


    
Hello, I am searching for a way to generate random values from a multivariate mixture distribution. For starters, one could create a mixture distribution consisting of a gamma or normal distribution and then a tail/spike of values in a normal distribution (eg as in Figure 1,?A Eyre-Walker, PD Keightley. 2007. The distribution of fitness effects of new mutations. Nature Review Genetics 8: 610-618)
I am not certain how to implement this in the R environment. The implementation becomes even more difficult if one wants to generalize this distribution to multiple variables that are related to one another via some correlation structure. The analogous situation is a multivariate normal distribution with the shape given by the covariance matrix.?
What I need for my research program is to generate values for each of 3 random variables with ("one-dimensional") distributions as in Figure 1 and yet simultaneously choose a value for each variable so that the resolved values are correlated in some way (eg if a high value for variable 1 is chosen, it is likely that values 2 and 3 are low).
Thanks in advance for the help.
Patrick SoprovichBiology Department, Dalhousie University


	[[alternative HTML version deleted]]


From robertobakker at gmail.com  Fri Nov 17 10:41:15 2017
From: robertobakker at gmail.com (P. Roberto Bakker)
Date: Fri, 17 Nov 2017 10:41:15 +0100
Subject: [R] Dataframe is character
Message-ID: <CAKDq9_OS0nz1ujin3fLjdi8HgTKYStFbzau56gDfn5H9nZxFYw@mail.gmail.com>

Hi everybody,

Question: why are my dataframe and numeric variables a character?

I read an excel file via readxl but my dataframe is a character, and
numeric variables, eg "yi", are also a character.
My excelfile is in English numeric
Sometimes the dataframe was indeed a dataframe, but I do not know why it
did sometimes.
Thank you in advance, Roberto
PS I used "guess". The problem is not solve by using "text", "numeric" etc

My syntax (I think I cannot send the excel file as binary?)

> library(readxl)
> library(readxl)
> library(metafor)
> setwd("C:/docs/Work2/Statistic_Analyses/MetaQTcAD")
> getwd()
[1] "C:/docs/Work2/Statistic_Analyses/MetaQTcAD"
>

> dat <- read_excel("Hedges-g_QTc MA_R05.xlsx", sheet = 2, col_names=TRUE,
col_types = c("guess"))
> class("dat")
[1] "character"
> class("yi")
[1] "character"
>

	[[alternative HTML version deleted]]


From calandra at rgzm.de  Fri Nov 17 11:31:58 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Fri, 17 Nov 2017 11:31:58 +0100
Subject: [R] Dataframe is character
In-Reply-To: <CAKDq9_OS0nz1ujin3fLjdi8HgTKYStFbzau56gDfn5H9nZxFYw@mail.gmail.com>
References: <CAKDq9_OS0nz1ujin3fLjdi8HgTKYStFbzau56gDfn5H9nZxFYw@mail.gmail.com>
Message-ID: <04c1ffe4-7fa3-30e9-1b50-561d442f7c73@rgzm.de>

Hi Roberto,

This often happens when there are some non-numeric characters. You would 
have to check it.
Without more information, e.g. dput(dat), you will have to find by yourself.

HTH,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/11/2017 10:41, P. Roberto Bakker wrote:
> Hi everybody,
>
> Question: why are my dataframe and numeric variables a character?
>
> I read an excel file via readxl but my dataframe is a character, and
> numeric variables, eg "yi", are also a character.
> My excelfile is in English numeric
> Sometimes the dataframe was indeed a dataframe, but I do not know why it
> did sometimes.
> Thank you in advance, Roberto
> PS I used "guess". The problem is not solve by using "text", "numeric" etc
>
> My syntax (I think I cannot send the excel file as binary?)
>
>> library(readxl)
>> library(readxl)
>> library(metafor)
>> setwd("C:/docs/Work2/Statistic_Analyses/MetaQTcAD")
>> getwd()
> [1] "C:/docs/Work2/Statistic_Analyses/MetaQTcAD"
>> dat <- read_excel("Hedges-g_QTc MA_R05.xlsx", sheet = 2, col_names=TRUE,
> col_types = c("guess"))
>> class("dat")
> [1] "character"
>> class("yi")
> [1] "character"
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From oleumpetra at gmail.com  Fri Nov 17 11:02:51 2017
From: oleumpetra at gmail.com (Petra Oleum)
Date: Fri, 17 Nov 2017 23:02:51 +1300
Subject: [R] Dataframe is character
In-Reply-To: <CAKDq9_OS0nz1ujin3fLjdi8HgTKYStFbzau56gDfn5H9nZxFYw@mail.gmail.com>
References: <CAKDq9_OS0nz1ujin3fLjdi8HgTKYStFbzau56gDfn5H9nZxFYw@mail.gmail.com>
Message-ID: <20171117100251.GA7386@minoc>

class("dat") is different from class(dat), which is what you actually want.

On 17-11-17, P. Roberto Bakker wrote:
> Hi everybody,
> 
> Question: why are my dataframe and numeric variables a character?
> 
> I read an excel file via readxl but my dataframe is a character, and
> numeric variables, eg "yi", are also a character.
> My excelfile is in English numeric
> Sometimes the dataframe was indeed a dataframe, but I do not know why it
> did sometimes.
> Thank you in advance, Roberto
> PS I used "guess". The problem is not solve by using "text", "numeric" etc
> 
> My syntax (I think I cannot send the excel file as binary?)
> 
> > library(readxl)
> > library(readxl)
> > library(metafor)
> > setwd("C:/docs/Work2/Statistic_Analyses/MetaQTcAD")
> > getwd()
> [1] "C:/docs/Work2/Statistic_Analyses/MetaQTcAD"
> >
> 
> > dat <- read_excel("Hedges-g_QTc MA_R05.xlsx", sheet = 2, col_names=TRUE,
> col_types = c("guess"))
> > class("dat")
> [1] "character"
> > class("yi")
> [1] "character"
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From calandra at rgzm.de  Fri Nov 17 12:21:29 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Fri, 17 Nov 2017 12:21:29 +0100
Subject: [R] Dataframe is character
In-Reply-To: <20171117100251.GA7386@minoc>
References: <CAKDq9_OS0nz1ujin3fLjdi8HgTKYStFbzau56gDfn5H9nZxFYw@mail.gmail.com>
 <20171117100251.GA7386@minoc>
Message-ID: <e1c2a24f-be52-73a6-f9bf-5f9f5d7fac0e@rgzm.de>

Good one, did not even notice that...!

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/11/2017 11:02, Petra Oleum wrote:
> class("dat") is different from class(dat), which is what you actually want.
>
> On 17-11-17, P. Roberto Bakker wrote:
>> Hi everybody,
>>
>> Question: why are my dataframe and numeric variables a character?
>>
>> I read an excel file via readxl but my dataframe is a character, and
>> numeric variables, eg "yi", are also a character.
>> My excelfile is in English numeric
>> Sometimes the dataframe was indeed a dataframe, but I do not know why it
>> did sometimes.
>> Thank you in advance, Roberto
>> PS I used "guess". The problem is not solve by using "text", "numeric" etc
>>
>> My syntax (I think I cannot send the excel file as binary?)
>>
>>> library(readxl)
>>> library(readxl)
>>> library(metafor)
>>> setwd("C:/docs/Work2/Statistic_Analyses/MetaQTcAD")
>>> getwd()
>> [1] "C:/docs/Work2/Statistic_Analyses/MetaQTcAD"
>>> dat <- read_excel("Hedges-g_QTc MA_R05.xlsx", sheet = 2, col_names=TRUE,
>> col_types = c("guess"))
>>> class("dat")
>> [1] "character"
>>> class("yi")
>> [1] "character"
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Fri Nov 17 12:25:19 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Nov 2017 06:25:19 -0500
Subject: [R] Risks of using "function <- package::function" ?
In-Reply-To: <54FB7337-7453-4897-BD68-3C2128D6AF26@dcn.davis.ca.us>
References: <BF38FDC9-57B8-4EFC-9EE5-CA46C8784A2D@utoronto.ca>
 <c92e99e4-da61-e588-c736-eeb25fa77f5e@gmail.com>
 <54FB7337-7453-4897-BD68-3C2128D6AF26@dcn.davis.ca.us>
Message-ID: <a0c2e196-1844-8d35-6c10-df7b60e85dd8@gmail.com>

On 17/11/2017 2:30 AM, Jeff Newmiller wrote:
> Obvious?  How about "obscurity"? Just directly use pkg::fun if you have name collision.
> 

One disadvantage of this is that the availability of pkg may not be 
checked until you use it.  Package checks will complain if you haven't 
declared in the DESCRIPTION file that you are importing from pkg, but 
the package will run even if you ignore that check.

But one thing I just realized is that Boris was probably not talking 
about writing a package, he was likely thinking about writing scripts. 
Then DESCRIPTION and NAMESPACE files don't exist, and his student's 
suggestion seems like a reasonable idea, more in the spirit of named 
imports than using "library(pkg)"  or "require(pkg)".

Duncan Murdoch


From r-subscribe at mail.ru  Fri Nov 17 15:15:56 2017
From: r-subscribe at mail.ru (=?UTF-8?B?QmVnaW5uZXI=?=)
Date: Fri, 17 Nov 2017 17:15:56 +0300
Subject: [R] =?utf-8?q?RStudio_blank_upon_opening?=
In-Reply-To: <mailman.0.1510916401.50083.r-help@r-project.org>
References: <mailman.0.1510916401.50083.r-help@r-project.org>
Message-ID: <1510928156.461043931@f205.i.mail.ru>


I'm having a problem: RStudio (on  ?desktop comp) blank upon opening (after I update Win7). I tried different things (reinstalled R and RStudio, backuping? RStudio settings folder... etc)! C an I launch Rstudio direct from
RGui(32bit)? or some else way to solve this problem? Thanks! P.S. I? launch RStudio with Ctrl-RStudio (that is set the path to R)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Nov 17 15:41:04 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Nov 2017 06:41:04 -0800
Subject: [R] RStudio blank upon opening
In-Reply-To: <1510928156.461043931@f205.i.mail.ru>
References: <mailman.0.1510916401.50083.r-help@r-project.org>
 <1510928156.461043931@f205.i.mail.ru>
Message-ID: <120CCA4A-9B49-4EA4-8DA5-9D4DA67B7154@dcn.davis.ca.us>

You should ask this in the RStudio support forums.. it is not about R.

I will say anecdotally regarding such behavior that RStudio expects  certain directories that it creates to be hidden (e.g. the .Rproj.user directory for projects) so if you copied or otherwise messed with those files then this might happen.  However,  your description does not mention projects and I don't know what other directories or files might lead to such behavior, so do go and ask people more likely to know the answer.
-- 
Sent from my phone. Please excuse my brevity.

On November 17, 2017 6:15:56 AM PST, Beginner via R-help <r-help at r-project.org> wrote:
>
>I'm having a problem: RStudio (on  ?desktop comp) blank upon opening
>(after I update Win7). I tried different things (reinstalled R and
>RStudio, backuping? RStudio settings folder... etc)! C an I launch
>Rstudio direct from
>RGui(32bit)? or some else way to solve this problem? Thanks! P.S. I?
>launch RStudio with Ctrl-RStudio (that is set the path to R)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Fri Nov 17 15:42:45 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 17 Nov 2017 14:42:45 +0000
Subject: [R] RStudio blank upon opening
In-Reply-To: <1510928156.461043931@f205.i.mail.ru>
References: <mailman.0.1510916401.50083.r-help@r-project.org>
 <1510928156.461043931@f205.i.mail.ru>
Message-ID: <154fe556-905b-bd41-4014-a9e3a45755b5@dewey.myzen.co.uk>

I believe RStudio has its own help forums where you might find expert 
advice.

On 17/11/2017 14:15, Beginner via R-help wrote:
> 
> I'm having a problem: RStudio (on  ?desktop comp) blank upon opening (after I update Win7). I tried different things (reinstalled R and RStudio, backuping? RStudio settings folder... etc)! C an I launch Rstudio direct from
> RGui(32bit)? or some else way to solve this problem? Thanks! P.S. I? launch RStudio with Ctrl-RStudio (that is set the path to R)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From azzalini at stat.unipd.it  Fri Nov 17 16:47:33 2017
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Fri, 17 Nov 2017 16:47:33 +0100
Subject: [R] HTML documentation is not in the expected location
Message-ID: <17719e39-d7e5-2330-82cb-6ceb4007f7f3@stat.unipd.it>

Since I have updated my Linux system, and consequently re-installed R, I 
am unable to see HTML documentation which I used to access via a web 
browser. To be more specific, my R installation is declared to be here:

 > R RHOME
/usr/local/lib/R

However, if I look at a location such as
/usr/local/lib/R/library/base/html

this contains only two entries  	

File: 00Index.html
File: R.css

Clicking on 00Index.html, it shows the full list of entries which one 
expects to see, but clicking on one of them, 'abs' say, inevitably leads 
to the message 'File not found'.

The documentation exists (at least in the text form): from within R, 
the command ?abs shows the documentation file. However its HTML version 
is not where I expect it to find ...which is where I did it find for 
many years, until the above-mentioned Linux update.

The current system is as follows:

PRETTY_NAME="Debian GNU/Linux 9 (stretch)"
NAME="Debian GNU/Linux"
VERSION_ID="9"
 > uname -a
Linux tamiso 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u2 (2017-06-26) 
x86_64 GNU/Linux

 > cat /etc/debian_version
9.0
 > gcc --version
gcc (Debian 6.3.0-18) 6.3.0 20170516

The current R installation is
R version 3.4.2 (2017-09-28) -- "Short Summer"
but the same problem existed with 3.4.1 after the system update.

When I (re-)install R, everything seems fine; no error messages are 
generated.

Can anyone tell me how to put the HTML documentation files in the right 
place?

Best regards,

Adelchi Azzalini


From murdoch.duncan at gmail.com  Fri Nov 17 17:03:42 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Nov 2017 11:03:42 -0500
Subject: [R] HTML documentation is not in the expected location
In-Reply-To: <17719e39-d7e5-2330-82cb-6ceb4007f7f3@stat.unipd.it>
References: <17719e39-d7e5-2330-82cb-6ceb4007f7f3@stat.unipd.it>
Message-ID: <b132c56e-24f4-0ac1-4a28-a021fef05206@gmail.com>

On 17/11/2017 10:47 AM, Adelchi Azzalini wrote:
> Since I have updated my Linux system, and consequently re-installed R, I
> am unable to see HTML documentation which I used to access via a web
> browser. To be more specific, my R installation is declared to be here:
> 
>   > R RHOME
> /usr/local/lib/R
> 
> However, if I look at a location such as
> /usr/local/lib/R/library/base/html
> 
> this contains only two entries  	
> 
> File: 00Index.html
> File: R.css
> 
> Clicking on 00Index.html, it shows the full list of entries which one
> expects to see, but clicking on one of them, 'abs' say, inevitably leads
> to the message 'File not found'.
> 
> The documentation exists (at least in the text form): from within R,
> the command ?abs shows the documentation file. However its HTML version
> is not where I expect it to find ...which is where I did it find for
> many years, until the above-mentioned Linux update.
> 
> The current system is as follows:
> 
> PRETTY_NAME="Debian GNU/Linux 9 (stretch)"
> NAME="Debian GNU/Linux"
> VERSION_ID="9"
>   > uname -a
> Linux tamiso 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u2 (2017-06-26)
> x86_64 GNU/Linux
> 
>   > cat /etc/debian_version
> 9.0
>   > gcc --version
> gcc (Debian 6.3.0-18) 6.3.0 20170516
> 
> The current R installation is
> R version 3.4.2 (2017-09-28) -- "Short Summer"
> but the same problem existed with 3.4.1 after the system update.
> 
> When I (re-)install R, everything seems fine; no error messages are
> generated.
> 
> Can anyone tell me how to put the HTML documentation files in the right
> place?
> 

By default the documentation is produced on demand, but you can ask to 
produce it all at once.  See section 2.2 of the Installation and 
Administration manual.

Duncan Murdoch


From azzalini at stat.unipd.it  Fri Nov 17 19:01:41 2017
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Fri, 17 Nov 2017 19:01:41 +0100
Subject: [R] HTML documentation is not in the expected location
In-Reply-To: <b132c56e-24f4-0ac1-4a28-a021fef05206@gmail.com>
References: <17719e39-d7e5-2330-82cb-6ceb4007f7f3@stat.unipd.it>
 <b132c56e-24f4-0ac1-4a28-a021fef05206@gmail.com>
Message-ID: <22364AEF-BF3F-4AAE-B535-81AF2152609E@stat.unipd.it>

Thanks for the useful clarification. This has solved the issue. I am  puzzled on why the problem has not shown up for a decade (at least), as I have had the HTML in place without explicitly asking for it.  However, this is a lesser problem.

Best wishes,

Adelchi


> On 17 Nov 2017, at 17:03, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 17/11/2017 10:47 AM, Adelchi Azzalini wrote:
>> Since I have updated my Linux system, and consequently re-installed R, I
>> am unable to see HTML documentation which I used to access via a web
>> browser. To be more specific, my R installation is declared to be here:
>>  > R RHOME
>> /usr/local/lib/R
>> However, if I look at a location such as
>> /usr/local/lib/R/library/base/html
>> this contains only two entries  	
>> File: 00Index.html
>> File: R.css
>> Clicking on 00Index.html, it shows the full list of entries which one
>> expects to see, but clicking on one of them, 'abs' say, inevitably leads
>> to the message 'File not found'.
>> The documentation exists (at least in the text form): from within R,
>> the command ?abs shows the documentation file. However its HTML version
>> is not where I expect it to find ...which is where I did it find for
>> many years, until the above-mentioned Linux update.
>> The current system is as follows:
>> PRETTY_NAME="Debian GNU/Linux 9 (stretch)"
>> NAME="Debian GNU/Linux"
>> VERSION_ID="9"
>>  > uname -a
>> Linux tamiso 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u2 (2017-06-26)
>> x86_64 GNU/Linux
>>  > cat /etc/debian_version
>> 9.0
>>  > gcc --version
>> gcc (Debian 6.3.0-18) 6.3.0 20170516
>> The current R installation is
>> R version 3.4.2 (2017-09-28) -- "Short Summer"
>> but the same problem existed with 3.4.1 after the system update.
>> When I (re-)install R, everything seems fine; no error messages are
>> generated.
>> Can anyone tell me how to put the HTML documentation files in the right
>> place?
> 
> By default the documentation is produced on demand, but you can ask to produce it all at once.  See section 2.2 of the Installation and Administration manual.
> 
> Duncan Murdoch
> 


From allaisone1 at hotmail.com  Fri Nov 17 18:59:33 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Fri, 17 Nov 2017 17:59:33 +0000
Subject: [R] Complicated analysis for huge databases
Message-ID: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>


Hi all ..,


I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-


> MyData

       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600

1    33                 55             1             0           1        2       0

2    33                 55              3             1          0        2        2

3    33                 55              5             2          1        1         2

4    44                 66               7            0          2         2        2

5   44                  66               4            1          1          0       1

6   44                  66                9            2          0          1       2

.

.

600,000



I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).


I can do the analysis  for the entire column but not group by group like this :


MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))

How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.

In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
I have another sheet contains names of columns of interest like this :

>ColOfinterest

Col
I
IV
V
.
.
300

Any one would help with the best combination of syntax to perform this complex analysis?

Regards
Allaisone







	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Nov 17 19:44:27 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 17 Nov 2017 18:44:27 +0000
Subject: [R] Converting a string to variable names
In-Reply-To: <CF18B198-D31A-4AC3-A9EC-295D01A26189@gmail.com>
References: <3577B47C-2B27-4115-87CC-71F0F26C3B3E@gmail.com>
 <CA+8X3fXjF6ZbjHmNvXtxx0t8Py_8jv4b2siP8y1jXT8NwdoPgA@mail.gmail.com>
 <CF18B198-D31A-4AC3-A9EC-295D01A26189@gmail.com>
Message-ID: <64BCBFD7-8009-4CBD-8C1B-E4FE32A77C50@llnl.gov>

Do you mean that you have
    One data frame, and it has a bunch of variables within it named P1, P2, P3...
or
    A bunch of data frames names P1, P2, P3...
?

I'll assume it's the latter. Here is one way:

dfnms < c('P1', 'P2', 'P3')

for (nm in dfnms) {
  tmp <- get(nm)
  rownames(tmp) <- tmp[[1]]
  assign(nm, tmp)
}

The get() and assign() functions have position and/or environment arguments. You might have to supply those.

You wouldn't have to use get() and assign() if the data frames were stored as elements of a list. This is sometimes a good way to do things.

mydfs <- list(P1=P1, P2=P2, P3=P3)
for (idf in seq(mydfs)) rownames(mydfs[[idf]]) <- mydfs[[idf]][[1]]

Of course, then you can't do, for example,
  plot( P1$x, P1$y)
you would have to do
  plot(mydf$P1$x, mydf$P1$y)

or instead of
   with(P1, plot(x,y))
you would have to do
   with(mydf$P1, plot(x,y))

(all of the above is untested, so watch out for typing errors)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 11/15/17, 2:22 PM, "R-help on behalf of ???" <r-help-bounces at r-project.org on behalf of ruiyangliu94 at gmail.com> wrote:

    Hi,
    
    Thanks for your reply.
    
    I just came up with another question about a similar but different thing:
    
    Say I have a bunch of data.frame variables named P1,P2,P3? I want to assign them row names according to symbols in the first column, and I want to do this using a for loop. How could I accomplish this?
    
    
    for (test_sample in c(1:10)){
    + x<-as.name(paste(?P",as.character(test_sampel),sep=""))
    + rownames(x)<-get((paste(?P?,as.character(test_sample),sep="")))[,1]
    + }
    
    This would not work probably because x is simply a name instead of a data.frame variable(Error: "attempt to set 'rownames' on an object with no dimensions"). But I could not find the right way out? How should I solve it?
    
    Thanks!
    
    Ruiyang
    
    
    > On Nov 14, 2017, at 4:39 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
    > 
    > Hi Ruiyang,
    > I think you want "get":
    > 
    > For (index in seq(1,16)){
    > plot(x=(a given set of value),y=get(paste(?PC?,as.character(index),sep=??)))
    > }
    > 
    > On Wed, Nov 15, 2017 at 7:43 AM, ??? <ruiyangliu94 at gmail.com> wrote:
    >> Hi,
    >> Suppose that I want to do a series of plots with the y value for each plot as PC1, PC2, PC3? How could I accomplish this using a for loop?
    >> Suppose the code like this:
    >> 
    >> For (index in seq(1,16)){
    >> plot(x=(a given set of value),y=paste(?PC?,as.character(index),sep=??)
    >> }
    >> 
    >> But this would not work because y is assigned a string instead of the variable names. So how could I assign y with a variable name instead of a string? Your reply would be appreciated!
    >> Ruiyang Liu
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Fri Nov 17 22:12:06 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 17 Nov 2017 16:12:06 -0500
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>

Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns. 


B.

> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> 
> Hi all ..,
> 
> 
> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
> 
> 
>> MyData
> 
>       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
> 
> 1    33                 55             1             0           1        2       0
> 
> 2    33                 55              3             1          0        2        2
> 
> 3    33                 55              5             2          1        1         2
> 
> 4    44                 66               7            0          2         2        2
> 
> 5   44                  66               4            1          1          0       1
> 
> 6   44                  66                9            2          0          1       2
> 
> .
> 
> .
> 
> 600,000
> 
> 
> 
> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
> 
> 
> I can do the analysis  for the entire column but not group by group like this :
> 
> 
> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
> 
> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
> 
> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
> I have another sheet contains names of columns of interest like this :
> 
>> ColOfinterest
> 
> Col
> I
> IV
> V
> .
> .
> 300
> 
> Any one would help with the best combination of syntax to perform this complex analysis?
> 
> Regards
> Allaisone
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Nov 18 01:09:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Nov 2017 16:09:05 -0800
Subject: [R] error message for function: lmer (from lme4 package)
In-Reply-To: <1245530428.1247053.1510858031103@mail.yahoo.com>
References: <370300864.1670135.1510665199052.ref@mail.yahoo.com>
 <370300864.1670135.1510665199052@mail.yahoo.com>
 <636CAE9E-88D9-4C36-877E-38DE0A0F657D@comcast.net>
 <1068192069.31543.1510692598176@mail.yahoo.com>
 <CAGxFJbQV+aXXPdz1XuumW0m0NC07QdWiRmbZ_epqRmAC=sYo1Q@mail.gmail.com>
 <1013628048.379831.1510751364535@mail.yahoo.com>
 <CAGxFJbRLmR545pwKDLWwH8ZuBFywy2hjJO35aFAbFuHnNbODiQ@mail.gmail.com>
 <1245530428.1247053.1510858031103@mail.yahoo.com>
Message-ID: <AD1DC6E2-EEF2-47E6-BDC1-11C3C4293F33@comcast.net>


> snipped
> 
> Hi, Bert,
> Sorry about that! David seemed to be able to read the post since he replied.

The only reason it appear readable was that you copied me as well as the list. Then HTML was still  the basic format although it did npt appear that way to me since my reader could handle it without difficulty. Everybody else saw a "complete mess" as Bert accurately put it.

Again, learn to post in plain text. Learn to post data objects with dput.

-- 
David.
> Here I just email you the sample code and error message:
>> example.3=data.frame(levels= as.numeric(XXX[,c(4)]), replicate=rep(c("0","1","2"," 3","4","5"),3),conditions=c( rep("11",6),rep("12",6),rep(> example.3    levels replicate conditions1  43.1111         0         112  42.0942         1         113  57.8131         2         114  57.1726         3         115  77.8678         4         116  44.7578         5         117  69.5078         0         128  52.0581         1         129  40.0602         2         1210 45.5487         3         1211 43.6201         4         1212 60.4939         5         1213 64.1932         0         1314 53.4055         1         1315 59.6701         2         1316 52.6922         3         1317 53.8712         4         1318 60.2770         5         13> m.example.3=lmer(as.numeric( levels)~conditions+( conditions|replicate),data= example.3)Error in lmer(as.numeric(levels) ~ conditions + (conditions | replicate),  :   could not find function "lmer"> 
> Hopefully you could read it and provide some comments!
> Thank you very much for your time.
> Kind regards,
> Ace

snipped

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From valkremk at gmail.com  Sat Nov 18 01:28:09 2017
From: valkremk at gmail.com (Val)
Date: Fri, 17 Nov 2017 18:28:09 -0600
Subject: [R] family
Message-ID: <CAJOiR6bRF6vnr-JJW20Yg+XfGaPb+y3WBgDx-nCuawAOBtGUAw@mail.gmail.com>

Hi all,
I am reading a huge data set(12M rows) that contains family information,
Offspring, Parent1 and Parent2

Parent1 and parent2 should be in the first column as an offspring
before their offspring information. Their parent information (parent1
and parent2) should be  set to zero, if unknown.  Also the first
column should be unique.


Here is my sample data  set  and desired output.


fam <- read.table(textConnection(" offspring  Parent1 Parent2
Smith Alex1  Alexa
Carla Alex1     0
Jacky Smith   Abbot
Jack  0       Jacky
Almo  Jack    Carla
 "),header = TRUE)



desired output.
Offspring Parent1 Parent2
Alex1      0        0
Alexa      0        0
Abbot      0        0
Smith    Alex1  Alexa
Carla    Alex1      0
Jacky    Smith   Abbot
Jack       0     Jacky
Almo     Jack    Carla

Thank you.


From r.turner at auckland.ac.nz  Sat Nov 18 01:34:03 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 18 Nov 2017 13:34:03 +1300
Subject: [R] tcltk problems
Message-ID: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>


It recently came to my attention that my R installation no longer has 
tcltk capability.

I can't figure out why or what to do about it.

I built R from source.  I configured using the "--with-tcltk" flag.  The 
build and install *seemed* to go OK, but after realising I didn't have 
tcltk capability I looked into config.log.

There I found:

> configure:39486: checking for tclConfig.sh
> configure:39519: result: no
> configure:39528: checking for tclConfig.sh in library (sub)directories
> configure:39549: result: no
> configure:39561: checking for tkConfig.sh
> configure:39594: result: no
> configure:39603: checking for tkConfig.sh in library (sub)directories
> configure:39624: result: no
> configure:39721: checking for tcl.h
> conftest.c:249:17: fatal error: tcl.h: No such file or directory
> compilation terminated.

I have tcl and tk (and the -dev versions) installed on my machine, and 
they are apparently up-to-date).

Moreover if I do "locate tclConfig.sh" I get:

> /usr/lib/tcl8.6/tclConfig.sh
> /usr/lib/x86_64-linux-gnu/tcl8.6/tclConfig.sh

And likewise "locate tcl.h" produces:

> /usr/include/tcl8.6/tcl.h
> /usr/include/tcl8.6/tcl-private/generic/tcl.h

So why can't "configure" find these files, and how can I tell it where 
to find them?

I'm running Ubuntu 16.04 and my last install of R was of version 3.4.2.

My installation procedure always worked in the past ....

Thanks for any tips.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From boris.steipe at utoronto.ca  Sat Nov 18 01:35:16 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 17 Nov 2017 19:35:16 -0500
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>

Something like the following?

AllMAFs <- list()

for (i in length(SeparatedGroupsofmealsCombs) {
  AllMAFs[[i]] <- apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf(tabulate(x+1)))
}


(untested, of course)
Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-) 



B.



> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> 
> Thanks Boris , this was very helpful but I'm struggling with the last part.
> 
> 1) I combined the first 2 columns :-
> 
>  
> library(tidyr)
> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
> SingleMealsCode <- SingleMealsCode[,-2]
> 
>   2) I separated this dataframe into different dataframes based on "MealsCombination"
>    column so R will recognize each meal combination separately :
> 
> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
> 
> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see 
> a list of different databases, each of which represents a different Meal combinations which is great.
> 
> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
> 
> when I run this code as before :-
> 
> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1))) 
> 
> an error message says : dim(X) must have a positive length . I'm not sure which length 
> I need to specify.. any suggestions to correct this syntax ?  
> 
> Regards
> Allaisone
> From: Boris Steipe <boris.steipe at utoronto.ca>
> Sent: 17 November 2017 21:12:06
> To: Allaisone 1
> Cc: R-help
> Subject: Re: [R] Complicated analysis for huge databases
>  
> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns. 
> 
> 
> B.
> 
> > On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> > 
> > 
> > Hi all ..,
> > 
> > 
> > I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
> > 
> > 
> >> MyData
> > 
> >       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
> > 
> > 1    33                 55             1             0           1        2       0
> > 
> > 2    33                 55              3             1          0        2        2
> > 
> > 3    33                 55              5             2          1        1         2
> > 
> > 4    44                 66               7            0          2         2        2
> > 
> > 5   44                  66               4            1          1          0       1
> > 
> > 6   44                  66                9            2          0          1       2
> > 
> > .
> > 
> > .
> > 
> > 600,000
> > 
> > 
> > 
> > I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
> > 
> > 
> > I can do the analysis  for the entire column but not group by group like this :
> > 
> > 
> > MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
> > 
> > How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
> > 
> > In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
> > I have another sheet contains names of columns of interest like this :
> > 
> >> ColOfinterest
> > 
> > Col
> > I
> > IV
> > V
> > .
> > .
> > 300
> > 
> > Any one would help with the best combination of syntax to perform this complex analysis?
> > 
> > Regards
> > Allaisone
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Nov 18 01:54:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Nov 2017 16:54:07 -0800
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
Message-ID: <CAGxFJbQVjRudDiSd0Cqabiy0o_oTxjc1jshPhWpvNZ9eKnmH+w@mail.gmail.com>

Or do it at one go using ?tapply and friends

Bert

On Nov 17, 2017 1:12 PM, "Boris Steipe" <boris.steipe at utoronto.ca> wrote:

> Combine columns 1 and 2 into a column with a single ID like "33.55",
> "44.66" and use split() on these IDs to break up your dataset. Iterate over
> the list of data frames split() returns.
>
>
> B.
>
> > On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com>
> wrote:
> >
> >
> > Hi all ..,
> >
> >
> > I have a large dataset of around 600,000 rows and 600 columns. The first
> col is codes for Meal A, the second columns is codes for Meal B. The third
> column is customers IDs where each customer had a combination of meals.
> Each column of the rest columns contains values 0,1,or 2. The dataset is
> organised in a way so that the first group of customers had similar meals
> combinations, this is followed by another group of customers with similar
> meals combinations but different from the first group and so on. The
> dataset looks like this :-
> >
> >
> >> MyData
> >
> >       Meal A     Meal B     Cust.ID      I            II        III
>  IV   ...... 600
> >
> > 1    33                 55             1             0           1
>   2       0
> >
> > 2    33                 55              3             1          0
>   2        2
> >
> > 3    33                 55              5             2          1
>   1         2
> >
> > 4    44                 66               7            0          2
>    2        2
> >
> > 5   44                  66               4            1          1
>     0       1
> >
> > 6   44                  66                9            2          0
>     1       2
> >
> > .
> >
> > .
> >
> > 600,000
> >
> >
> >
> > I wanted to find maf() for each column(from 4 to 600) after calculating
> the frequency of the 3 values (0,1,2) but this should be done group by
> group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
> >
> >
> > I can do the analysis  for the entire column but not group by group like
> this :
> >
> >
> > MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
> >
> > How can I modify this code to tell R to do the analysis group by group
> for each column so I get maf value for 33-55 group of clolumn I, then maf
> value for group 44-66 in the same column I,then the rest of groups in this
> column and do the same for the remaining columns.
> >
> > In fact, I'm interested in doing this analysis for only 300 columns but
> all of the 600 columns.
> > I have another sheet contains names of columns of interest like this :
> >
> >> ColOfinterest
> >
> > Col
> > I
> > IV
> > V
> > .
> > .
> > 300
> >
> > Any one would help with the best combination of syntax to perform this
> complex analysis?
> >
> > Regards
> > Allaisone
> >
> >
> >
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Nov 18 02:32:10 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Nov 2017 17:32:10 -0800
Subject: [R] family
In-Reply-To: <CAJOiR6bRF6vnr-JJW20Yg+XfGaPb+y3WBgDx-nCuawAOBtGUAw@mail.gmail.com>
References: <CAJOiR6bRF6vnr-JJW20Yg+XfGaPb+y3WBgDx-nCuawAOBtGUAw@mail.gmail.com>
Message-ID: <39AA3453-5981-4653-B150-AF890248AF41@dcn.davis.ca.us>

This question is about algorithm help... or rather, "do my work for me", not about R.

Study up on "directed acyclic graphs" [1]... there actually are some packages related to such data structures on CRAN (e.g. pooh::tsort, Task View gR "gRaphical Models in R"), but you should at least be aware of the possible approaches before we talk about implementing (that is the "R" part that is on topic here) one of them on this list. 

[1] https://en.wikipedia.org/wiki/Topological_sorting
-- 
Sent from my phone. Please excuse my brevity.

On November 17, 2017 4:28:09 PM PST, Val <valkremk at gmail.com> wrote:
>Hi all,
>I am reading a huge data set(12M rows) that contains family
>information,
>Offspring, Parent1 and Parent2
>
>Parent1 and parent2 should be in the first column as an offspring
>before their offspring information. Their parent information (parent1
>and parent2) should be  set to zero, if unknown.  Also the first
>column should be unique.
>
>
>Here is my sample data  set  and desired output.
>
>
>fam <- read.table(textConnection(" offspring  Parent1 Parent2
>Smith Alex1  Alexa
>Carla Alex1     0
>Jacky Smith   Abbot
>Jack  0       Jacky
>Almo  Jack    Carla
> "),header = TRUE)
>
>
>
>desired output.
>Offspring Parent1 Parent2
>Alex1      0        0
>Alexa      0        0
>Abbot      0        0
>Smith    Alex1  Alexa
>Carla    Alex1      0
>Jacky    Smith   Abbot
>Jack       0     Jacky
>Almo     Jack    Carla
>
>Thank you.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Nov 18 03:17:26 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Nov 2017 18:17:26 -0800
Subject: [R] family
In-Reply-To: <CAJOiR6bRF6vnr-JJW20Yg+XfGaPb+y3WBgDx-nCuawAOBtGUAw@mail.gmail.com>
References: <CAJOiR6bRF6vnr-JJW20Yg+XfGaPb+y3WBgDx-nCuawAOBtGUAw@mail.gmail.com>
Message-ID: <6E339F2E-207B-44B9-BAC7-21446E66FE6D@comcast.net>


> On Nov 17, 2017, at 4:28 PM, Val <valkremk at gmail.com> wrote:
> 
> Hi all,
> I am reading a huge data set(12M rows) that contains family information,
> Offspring, Parent1 and Parent2
> 
> Parent1 and parent2 should be in the first column as an offspring
> before their offspring information. Their parent information (parent1
> and parent2) should be  set to zero, if unknown.  Also the first
> column should be unique.
> 
> 
> Here is my sample data  set  and desired output.
> 
> 
> fam <- read.table(textConnection(" offspring  Parent1 Parent2
> Smith Alex1  Alexa
> Carla Alex1     0
> Jacky Smith   Abbot
> Jack  0       Jacky
> Almo  Jack    Carla
> "),header = TRUE)
> 
> 
> 
> desired output.
> Offspring Parent1 Parent2
> Alex1      0        0
> Alexa      0        0
> Abbot      0        0
> Smith    Alex1  Alexa
> Carla    Alex1      0
> Jacky    Smith   Abbot
> Jack       0     Jacky
> Almo     Jack    Carla

You might get useful ideas by looking at ?'%in%" and ?union (set operations)

> fam$Parent1[!fam$Parent1 %in% fam$offspring]
[1] "Alex1" "Alex1" "0"    
> fam$Parent2[!fam$Parent1 %in% fam$offspring]
[1] "Alexa" "0"     "Jacky"

David.
> 
> Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From erinm.hodgess at gmail.com  Sat Nov 18 05:00:31 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 17 Nov 2017 22:00:31 -0600
Subject: [R] tcltk problems
In-Reply-To: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
Message-ID: <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>

When I have compiled from sourced on Ubuntu, I did NOT include the
"with-tcltk" and it worked fine.  Did you try that, please?

Thanks,
Erin


On Fri, Nov 17, 2017 at 6:34 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> It recently came to my attention that my R installation no longer has
> tcltk capability.
>
> I can't figure out why or what to do about it.
>
> I built R from source.  I configured using the "--with-tcltk" flag.  The
> build and install *seemed* to go OK, but after realising I didn't have
> tcltk capability I looked into config.log.
>
> There I found:
>
> configure:39486: checking for tclConfig.sh
>> configure:39519: result: no
>> configure:39528: checking for tclConfig.sh in library (sub)directories
>> configure:39549: result: no
>> configure:39561: checking for tkConfig.sh
>> configure:39594: result: no
>> configure:39603: checking for tkConfig.sh in library (sub)directories
>> configure:39624: result: no
>> configure:39721: checking for tcl.h
>> conftest.c:249:17: fatal error: tcl.h: No such file or directory
>> compilation terminated.
>>
>
> I have tcl and tk (and the -dev versions) installed on my machine, and
> they are apparently up-to-date).
>
> Moreover if I do "locate tclConfig.sh" I get:
>
> /usr/lib/tcl8.6/tclConfig.sh
>> /usr/lib/x86_64-linux-gnu/tcl8.6/tclConfig.sh
>>
>
> And likewise "locate tcl.h" produces:
>
> /usr/include/tcl8.6/tcl.h
>> /usr/include/tcl8.6/tcl-private/generic/tcl.h
>>
>
> So why can't "configure" find these files, and how can I tell it where to
> find them?
>
> I'm running Ubuntu 16.04 and my last install of R was of version 3.4.2.
>
> My installation procedure always worked in the past ....
>
> Thanks for any tips.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Nov 18 05:43:11 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 18 Nov 2017 17:43:11 +1300
Subject: [R] tcltk problems
In-Reply-To: <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
Message-ID: <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>

On 18/11/17 17:00, Erin Hodgess wrote:
> When I have compiled from sourced on Ubuntu, I did NOT include the 
> "with-tcltk" and it worked fine.? Did you try that, please?

In the past I have configured without using the "--with-tcltk" flag,
and R of course built just fine.  But it *did not* have tcltk 
capability.  When I wanted that capability I had to start using the
aforesaid flag.

It makes absolutely no sense that one would get tcltk capability when 
configuring without the flag but *not* get it when configuring *with* 
the flag.  If that is indeed the case then this definitely constitutes a 
bug in the "configure" system.

I cannot believe that it would work to leave out the flag, but I'll try 
it just for the sake of "completeness".

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sat Nov 18 05:56:56 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 18 Nov 2017 17:56:56 +1300
Subject: [R] tcltk problems
In-Reply-To: <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
Message-ID: <3053c2f7-3389-9542-c1b8-41a18bf8204c@auckland.ac.nz>


On 18/11/17 17:00, Erin Hodgess wrote:

> When I have compiled from sourced on Ubuntu, I did NOT include the 
> "with-tcltk" and it worked fine.? Did you try that, please?

As I said, this idea makes absolutely no sense, but OK, I tried it.
And of course it didn't work.

Using the newly built R I ran capabilities() and got:

>        jpeg         png        tiff       tcltk         X11        aqua 
>        TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
>    http/ftp     sockets      libxml        fifo      cledit       iconv 
>        TRUE        TRUE        TRUE        TRUE        TRUE        TRUE 
>         NLS     profmem       cairo         ICU long.double     libcurl 
>        TRUE       FALSE        TRUE        TRUE        TRUE        TRUE 

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From peter.langfelder at gmail.com  Sat Nov 18 06:18:10 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 17 Nov 2017 21:18:10 -0800
Subject: [R] tcltk problems
In-Reply-To: <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
Message-ID: <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>

Rolf,

looking at the configure script I believe you need to specify

--with-tcl-config=/usr/lib/tcl8.6/tclConfig.sh

and similarly

--with-tk-config=<location of tkConfig.sh>

HTH,

Peter


On Fri, Nov 17, 2017 at 8:43 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 18/11/17 17:00, Erin Hodgess wrote:
>>
>> When I have compiled from sourced on Ubuntu, I did NOT include the
>> "with-tcltk" and it worked fine.  Did you try that, please?
>
>
> In the past I have configured without using the "--with-tcltk" flag,
> and R of course built just fine.  But it *did not* have tcltk capability.
> When I wanted that capability I had to start using the
> aforesaid flag.
>
> It makes absolutely no sense that one would get tcltk capability when
> configuring without the flag but *not* get it when configuring *with* the
> flag.  If that is indeed the case then this definitely constitutes a bug in
> the "configure" system.
>
> I cannot believe that it would work to leave out the flag, but I'll try it
> just for the sake of "completeness".
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From allaisone1 at hotmail.com  Sat Nov 18 01:15:14 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Sat, 18 Nov 2017 00:15:14 +0000
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
Message-ID: <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>


Thanks Boris , this was very helpful but I'm struggling with the last part.

1) I combined the first 2 columns :-


library(tidyr)
SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
SingleMealsCode <- SingleMealsCode[,-2]

  2) I separated this dataframe into different dataframes based on "MealsCombination"
   column so R will recognize each meal combination separately :

SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)

after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
a list of different databases, each of which represents a different Meal combinations which is great.

No, I'm struggling with the last part, how can I run the maf code for all dataframes?

when I run this code as before :-

maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))

an error message says : dim(X) must have a positive length . I'm not sure which length
I need to specify.. any suggestions to correct this syntax ?

Regards
Allaisone

________________________________
From: Boris Steipe <boris.steipe at utoronto.ca>
Sent: 17 November 2017 21:12:06
To: Allaisone 1
Cc: R-help
Subject: Re: [R] Complicated analysis for huge databases

Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.


B.

> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
>
> Hi all ..,
>
>
> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
>
>
>> MyData
>
>       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
>
> 1    33                 55             1             0           1        2       0
>
> 2    33                 55              3             1          0        2        2
>
> 3    33                 55              5             2          1        1         2
>
> 4    44                 66               7            0          2         2        2
>
> 5   44                  66               4            1          1          0       1
>
> 6   44                  66                9            2          0          1       2
>
> .
>
> .
>
> 600,000
>
>
>
> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
>
>
> I can do the analysis  for the entire column but not group by group like this :
>
>
> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
>
> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
>
> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
> I have another sheet contains names of columns of interest like this :
>
>> ColOfinterest
>
> Col
> I
> IV
> V
> .
> .
> 300
>
> Any one would help with the best combination of syntax to perform this complex analysis?
>
> Regards
> Allaisone
>
>
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Sat Nov 18 10:52:13 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Sat, 18 Nov 2017 09:52:13 +0000
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
Message-ID: <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Although the loop seems to be formulated correctly I wonder why
it gives me these errors :

-object 'i' not found
- unexpected '}' in "}"


the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for

for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-


> mafsforeachcolumns(I,II,...600)foreachcombination

      MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
1          33-55                          1             0.124      0.10      0.65       0.467
                                                  3
                                                  5

2      44-66                                7           0.134     0.43       0.64       0.479
                                                  4
                                                  9

.

.

~180 dataframes


________________________________
From: Boris Steipe <boris.steipe at utoronto.ca>
Sent: 18 November 2017 00:35:16
To: Allaisone 1; R-help
Subject: Re: [R] Complicated analysis for huge databases

Something like the following?

AllMAFs <- list()

for (i in length(SeparatedGroupsofmealsCombs) {
  AllMAFs[[i]] <- apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf(tabulate(x+1)))
}


(untested, of course)
Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)



B.



> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
>
> Thanks Boris , this was very helpful but I'm struggling with the last part.
>
> 1) I combined the first 2 columns :-
>
>
> library(tidyr)
> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
> SingleMealsCode <- SingleMealsCode[,-2]
>
>   2) I separated this dataframe into different dataframes based on "MealsCombination"
>    column so R will recognize each meal combination separately :
>
> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
>
> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
> a list of different databases, each of which represents a different Meal combinations which is great.
>
> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
>
> when I run this code as before :-
>
> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
>
> an error message says : dim(X) must have a positive length . I'm not sure which length
> I need to specify.. any suggestions to correct this syntax ?
>
> Regards
> Allaisone
> From: Boris Steipe <boris.steipe at utoronto.ca>
> Sent: 17 November 2017 21:12:06
> To: Allaisone 1
> Cc: R-help
> Subject: Re: [R] Complicated analysis for huge databases
>
> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
>
>
> B.
>
> > On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> >
> >
> > Hi all ..,
> >
> >
> > I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
> >
> >
> >> MyData
> >
> >       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
> >
> > 1    33                 55             1             0           1        2       0
> >
> > 2    33                 55              3             1          0        2        2
> >
> > 3    33                 55              5             2          1        1         2
> >
> > 4    44                 66               7            0          2         2        2
> >
> > 5   44                  66               4            1          1          0       1
> >
> > 6   44                  66                9            2          0          1       2
> >
> > .
> >
> > .
> >
> > 600,000
> >
> >
> >
> > I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
> >
> >
> > I can do the analysis  for the entire column but not group by group like this :
> >
> >
> > MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
> >
> > How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
> >
> > In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
> > I have another sheet contains names of columns of interest like this :
> >
> >> ColOfinterest
> >
> > Col
> > I
> > IV
> > V
> > .
> > .
> > 300
> >
> > Any one would help with the best combination of syntax to perform this complex analysis?
> >
> > Regards
> > Allaisone
> >
> >
> >
> >
> >
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Nov 18 14:04:22 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 18 Nov 2017 14:04:22 +0100
Subject: [R] tcltk problems
In-Reply-To: <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
Message-ID: <D36FE936-1418-4CE6-866D-6CFABAB1DAD9@gmail.com>

That should probably work, but I wonder whether the root cause might be non-installation of Ubuntu "-devel" (or is it "-dev"?) Tcl and Tk packages. It doesn't look quite right to have to tell R's configure about a path that depends on the current Tcl/Tk version. I would have expected that tclConfig.sh would be found in /usr/lib or /usr/local/lib.

-pd 

> On 18 Nov 2017, at 06:18 , Peter Langfelder <peter.langfelder at gmail.com> wrote:
> 
> Rolf,
> 
> looking at the configure script I believe you need to specify
> 
> --with-tcl-config=/usr/lib/tcl8.6/tclConfig.sh
> 
> and similarly
> 
> --with-tk-config=<location of tkConfig.sh>
> 
> HTH,
> 
> Peter
> 
> 
> On Fri, Nov 17, 2017 at 8:43 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 18/11/17 17:00, Erin Hodgess wrote:
>>> 
>>> When I have compiled from sourced on Ubuntu, I did NOT include the
>>> "with-tcltk" and it worked fine.  Did you try that, please?
>> 
>> 
>> In the past I have configured without using the "--with-tcltk" flag,
>> and R of course built just fine.  But it *did not* have tcltk capability.
>> When I wanted that capability I had to start using the
>> aforesaid flag.
>> 
>> It makes absolutely no sense that one would get tcltk capability when
>> configuring without the flag but *not* get it when configuring *with* the
>> flag.  If that is indeed the case then this definitely constitutes a bug in
>> the "configure" system.
>> 
>> I cannot believe that it would work to leave out the flag, but I'll try it
>> just for the sake of "completeness".
>> 
>> cheers,
>> 
>> Rolf
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From alkauffm at fastmail.fm  Sat Nov 18 17:36:17 2017
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Sat, 18 Nov 2017 17:36:17 +0100
Subject: [R] tcltk problems
In-Reply-To: <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
Message-ID: <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>

Did you istall the tcl- and tk-devel packages?

Best, Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Sa, 18. Nov 2017, um 05:00, schrieb Erin Hodgess:
> When I have compiled from sourced on Ubuntu, I did NOT include the
> "with-tcltk" and it worked fine.  Did you try that, please?
> 
> Thanks,
> Erin
> 
> 
> On Fri, Nov 17, 2017 at 6:34 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> 
> >
> > It recently came to my attention that my R installation no longer has
> > tcltk capability.
> >
> > I can't figure out why or what to do about it.
> >
> > I built R from source.  I configured using the "--with-tcltk" flag.  The
> > build and install *seemed* to go OK, but after realising I didn't have
> > tcltk capability I looked into config.log.
> >
> > There I found:
> >
> > configure:39486: checking for tclConfig.sh
> >> configure:39519: result: no
> >> configure:39528: checking for tclConfig.sh in library (sub)directories
> >> configure:39549: result: no
> >> configure:39561: checking for tkConfig.sh
> >> configure:39594: result: no
> >> configure:39603: checking for tkConfig.sh in library (sub)directories
> >> configure:39624: result: no
> >> configure:39721: checking for tcl.h
> >> conftest.c:249:17: fatal error: tcl.h: No such file or directory
> >> compilation terminated.
> >>
> >
> > I have tcl and tk (and the -dev versions) installed on my machine, and
> > they are apparently up-to-date).
> >
> > Moreover if I do "locate tclConfig.sh" I get:
> >
> > /usr/lib/tcl8.6/tclConfig.sh
> >> /usr/lib/x86_64-linux-gnu/tcl8.6/tclConfig.sh
> >>
> >
> > And likewise "locate tcl.h" produces:
> >
> > /usr/include/tcl8.6/tcl.h
> >> /usr/include/tcl8.6/tcl-private/generic/tcl.h
> >>
> >
> > So why can't "configure" find these files, and how can I tell it where to
> > find them?
> >
> > I'm running Ubuntu 16.04 and my last install of R was of version 3.4.2.
> >
> > My installation procedure always worked in the past ....
> >
> > Thanks for any tips.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> > ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Sat Nov 18 18:05:20 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 18 Nov 2017 11:05:20 -0600
Subject: [R] tcltk problems
In-Reply-To: <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>
Message-ID: <23056.26704.357636.927950@bud.eddelbuettel.com>


Rolf,

A few quick points as I just noticed this thread (as I don't regularly dip
into r-help any more):

 1)  You really do not need to builds R locally on Ubuntu. I update the
     Debian package hours after Peter cuts a release. Michael rolls Ubuntu
     releases off these typically the same or next day, which arrive at CRAN
     in less than 72 hours after a release.

     See https://cloud.r-project.org/bin/linux/ubuntu/README.html

     I run these binaries myself on several personal machines and dozens more
     at work.  They. Just. Work.  Why not take advantage of a freebie?

 2)  If you still want to build locally, simply copy what we do. Our sources
     are public.  The debian/control for r-base (for Debian, albeit, don't
     have Michael's here but tcl/tk has not changed in year) has

        Build-Depends: gcc (>= 4:4.1.0), [...], tcl8.6-dev, tk8.6-dev, [...]

     so make sure you install those two package, and the debian/rules does

	./configure --prefix=/usr			\
                    [....]
		    --with-tcltk			\
                    [....]

        [...]

	$(MAKE)	    [...]

     ie nothing special for configure or make.

     My most recent build then logged

        checking for tclConfig.sh... no
        checking for tclConfig.sh in library (sub)directories... /usr/lib/tcl8.6/tclConfig.sh
        checking for tkConfig.sh... no
        checking for tkConfig.sh in library (sub)directories... /usr/lib/tk8.6/tkConfig.sh
        checking tcl.h usability... yes
        checking tcl.h presence... yes
        checking for tcl.h... yes
        checking tk.h usability... yes
        checking tk.h presence... yes
        checking for tk.h... yes
        checking whether compiling/linking Tcl/Tk code works... yes

     which echos what Peter already said. Its final state report for
     configure was

        R is now configured for x86_64-pc-linux-gnu
        
          Source directory:          .
          Installation directory:    /usr
        
          C compiler:                gcc -std=gnu99  -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g
          Fortran 77 compiler:       gfortran  -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong
        
          Default C++ compiler:      g++   -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g
          C++98 compiler:            g++ -std=gnu++98 -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g
          C++11 compiler:            g++ -std=gnu++11 -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g
          C++14 compiler:            g++  -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g
          C++17 compiler:            g++ -std=gnu++17 -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g
          Fortran 90/95 compiler:    gfortran -g -O2 -fdebug-prefix-map=/build/r-base-3.4.2=. -fstack-protector-strong
          Obj-C compiler:	      
        
          Interfaces supported:      X11, tcltk
          External libraries:        readline, BLAS(generic), LAPACK(generic), curl
          Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
          Options enabled:           shared R library, R profiling, memory profiling
        
          Capabilities skipped:      
          Options not enabled:       shared BLAS
        
          Recommended packages:      no

     which looks pretty good to me. No capabilities. All batteries
     included. (And rec'd packages is no as we package them individually).

 3)  r-help is the wrong list for these questions. Come to r-sig-debian
     which covers R on .deb based systems.  We don't bite, and it is low volume

Cheers, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From dwinsemius at comcast.net  Sat Nov 18 21:06:56 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 18 Nov 2017 12:06:56 -0800
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
 <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>


> On Nov 18, 2017, at 1:52 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> Although the loop seems to be formulated correctly I wonder why
> it gives me these errors :
> 
> -object 'i' not found
> - unexpected '}' in "}"

You probably did not copy the entire code offered. But we cannot know since you did not "show your code", not=r did you post complete error messages. Both of these practices are strongly recommended by the Posting Guide. Please read it (again?).

-- 
David.
> 
> 
> the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for
> 
> for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-
> 
> 
>> mafsforeachcolumns(I,II,...600)foreachcombination
> 
>      MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
> 1          33-55                          1             0.124      0.10      0.65       0.467
>                                                  3
>                                                  5
> 
> 2      44-66                                7           0.134     0.43       0.64       0.479
>                                                  4
>                                                  9
> 
> .
> 
> .
> 
> ~180 dataframes
> 
> 
> ________________________________
> From: Boris Steipe <boris.steipe at utoronto.ca>
> Sent: 18 November 2017 00:35:16
> To: Allaisone 1; R-help
> Subject: Re: [R] Complicated analysis for huge databases
> 
> Something like the following?
> 
> AllMAFs <- list()
> 
> for (i in length(SeparatedGroupsofmealsCombs) {
>  AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
> }
> 
> 
> (untested, of course)
> Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)
> 
> 
> 
> B.
> 
> 
> 
>> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>> 
>> 
>> Thanks Boris , this was very helpful but I'm struggling with the last part.
>> 
>> 1) I combined the first 2 columns :-
>> 
>> 
>> library(tidyr)
>> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
>> SingleMealsCode <- SingleMealsCode[,-2]
>> 
>>  2) I separated this dataframe into different dataframes based on "MealsCombination"
>>   column so R will recognize each meal combination separately :
>> 
>> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
>> 
>> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
>> a list of different databases, each of which represents a different Meal combinations which is great.
>> 
>> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
>> 
>> when I run this code as before :-
>> 
>> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
>> 
>> an error message says : dim(X) must have a positive length . I'm not sure which length
>> I need to specify.. any suggestions to correct this syntax ?
>> 
>> Regards
>> Allaisone
>> From: Boris Steipe <boris.steipe at utoronto.ca>
>> Sent: 17 November 2017 21:12:06
>> To: Allaisone 1
>> Cc: R-help
>> Subject: Re: [R] Complicated analysis for huge databases
>> 
>> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
>> 
>> 
>> B.
>> 
>>> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>> 
>>> 
>>> Hi all ..,
>>> 
>>> 
>>> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
>>> 
>>> 
>>>> MyData
>>> 
>>>      Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
>>> 
>>> 1    33                 55             1             0           1        2       0
>>> 
>>> 2    33                 55              3             1          0        2        2
>>> 
>>> 3    33                 55              5             2          1        1         2
>>> 
>>> 4    44                 66               7            0          2         2        2
>>> 
>>> 5   44                  66               4            1          1          0       1
>>> 
>>> 6   44                  66                9            2          0          1       2
>>> 
>>> .
>>> 
>>> .
>>> 
>>> 600,000
>>> 
>>> 
>>> 
>>> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
>>> 
>>> 
>>> I can do the analysis  for the entire column but not group by group like this :
>>> 
>>> 
>>> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
>>> 
>>> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
>>> 
>>> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
>>> I have another sheet contains names of columns of interest like this :
>>> 
>>>> ColOfinterest
>>> 
>>> Col
>>> I
>>> IV
>>> V
>>> .
>>> .
>>> 300
>>> 
>>> Any one would help with the best combination of syntax to perform this complex analysis?
>>> 
>>> Regards
>>> Allaisone
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From hugomh at gmx.fr  Sat Nov 18 19:55:09 2017
From: hugomh at gmx.fr (hmh)
Date: Sat, 18 Nov 2017 19:55:09 +0100
Subject: [R] Using cforest on a hierarchically structured dataset
In-Reply-To: <0b991156-88ce-f950-4cf6-c2dd8030bc11@gmx.fr>
References: <0b991156-88ce-f950-4cf6-c2dd8030bc11@gmx.fr>
Message-ID: <0423efa3-e5f6-9ec0-4d01-b1588f56a0ca@gmx.fr>

Hi,


I am facing a hierarchically structured dataset, and I am not sure of 
the right way to analyses it with cforest, if their is one.

- - BACKGROUND & PROBLEM

We are analyzing the behavior of some social birds facing different 
temperature conditions.


The behaviors of the birds were recorder during many sessions of 2 hours.


Conditional RF (cforest) are quite useful for this analysis since, we 
have a large number of variables describing the temperature during the 2 
hours, they are rather highly correlated, and we expect they have some 
non linear effects on the behavior.


For the other behaviors, for each individual and each session of 2 
hours, we recorded the frequency.

For each session of 2 hours, we have only one value for the variables 
related to the temperature, since these variables are for example

minimal and maximal temperature, median temperature, and different 
measures of the variance of the temperature.


Visually the dataset thus looks like this:

Y_behaviour_frequency?? Individual?? Session?? X1?? X2 X3?? ...
 ????????????????? 0.5???????? ind1??????? S1??? 5 10??? 7?? ...
 ???????????????? 0.55???????? ind2??????? S1??? 5 10??? 7?? ...
 ????????????????? 0.2???????? ind3??????? S1??? 5 10??? 7?? ...
...?????????????????????????????????????? S1??? 5 10??? 7?? ...
 ????????????????? 0.3???????? ind1??????? S2?? 15 7?? 50?? ...
 ???????????????? 0.01???????? ind5??????? S2?? 15 7?? 50?? ...
...?????????????????????????????????????? S2?? 15 7?? 50?? ...
 ????????????????? 0.4???????? ind1??????? S3??? 2 8??? 5?? ...
 ???????????????? 0.05???????? ind3??????? S3??? 2 8??? 5?? ...
 ????????????????? 0.1???????? ind4??????? S3??? 2 8??? 5?? ...
 ????????????????? 0.2???????? ind5??????? S3??? 2 8??? 5?? ...
...?????????????????????????????????????? S3??? 2 8??? 5?? ...
... ... ... ... ... ... ... ... ... ... ... ... ... ... ...?? ...

If I run a classical cforest on this dataset, explaining 
Y_behaviour_frequency with Individual, Session and all the X... 
variables, I end up with some conditional relative importances similar 
to the attached plot:

They are all very very low, but none is negative. The absence of 
negative conditional relative importance is annoying since we were 
selecting variables using the threshold of minus two times the lowest 
conditional relative importance.


- - QUESTIONS

1) have you ever faced one of these situations of

 ??? - all very low conditional relative importances

 ??? - all positives conditional relative importances

 ??? - hierarchically structured dataset analyzed with cforest

?


I think, but I am not sure, the very low but all positive conditional 
importance might come from the hierarchically structured dataset:

Since RF are based on bootstraps, when bootstrapping in at each 
iteration, all sessions or almost all sessions of 2 hours are sampled, 
although they are the main source of variation.

The bootstrap would need to be itself hierarchic, first sampling the 
sessions and then sampling the individual in the sampled session of 2 hours.


2) It's easy to perform such kind of hierarchic bootstrap in R, but have 
you ever heard about it in a random forest ?

The question was asked 4 years ago:

here: 
https://stats.stackexchange.com/questions/62840/random-forest-and-cluster-level-bootstrapping

and here: 
https://stats.stackexchange.com/questions/93156/random-forest-on-multi-level-hierarchical-structured-data

but the main track "hie-ran-forest" also called "HieRanFor" seems 
aborted. (https://r-forge.r-project.org/R/?group_id=2021)



Thanks for your help,

cheers.


hugo


-- 
- no title specified

Hugo Math?-Hubert

BU-G19

postdoc

eawag (Swiss Federal Institute of Aquatic Science and Technology)
Evolutionary Ecology 
<http://www.eawag.ch/en/department/eco/main-focus/evolutionary-ecology/>- 
About me 
<http://www.eawag.ch/en/aboutus/portrait/organisation/staff/profile/hugo-mathe-hubert/>

?berlandstrasse 133
P.O.Box 611
8600 D?bendorf, Switzerland

- - - - - - - - - - - - - - - - - -

Thoughts appear from doubts and die in convictions. Therefore, doubts 
are an indication of strength and convictions an indication of weakness. 
Yet, most people believe the opposite.

- - - - - - - - - - - - - - - - - -

Les r?flexions naissent dans les doutes et meurent dans les certitudes. 
Les doutes sont donc un signe de force et les certitudes un signe de 
faiblesse. La plupart des gens sont pourtant certains du contraire.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.pdf
Type: application/pdf
Size: 5040 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20171118/9b88135c/attachment.pdf>

From r.turner at auckland.ac.nz  Sat Nov 18 22:32:57 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 19 Nov 2017 10:32:57 +1300
Subject: [R] [FORGED] Re:  tcltk problems
In-Reply-To: <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>
Message-ID: <1efdb8fa-0a7a-9dfa-18fd-204d16e55b4a@auckland.ac.nz>


On 19/11/17 05:36, Albrecht Kauffmann wrote:

> Did you istall the tcl- and tk-devel packages?

(a) That should be "dev" not "devel".

(b) The answer to your question is, yes, as I made clear in my original 
post.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From boris.steipe at utoronto.ca  Sat Nov 18 22:44:25 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 18 Nov 2017 16:44:25 -0500
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
 <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>
 <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <3779662A-42A4-42AD-8D00-07BC437E6554@utoronto.ca>


The correct code is: 

   for (i in 1:length(SeparatedGroupsofmealsCombs)) { ...


I had mentioned that this is untested, but the error is so obvious ...




B.



> On Nov 18, 2017, at 4:40 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> 
> The loop : 
> 
> AllMAFs <- list()
>  
>  for (i in length(SeparatedGroupsofmealsCombs) {
>   AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
> }
> 
> gives these errors (I tried this many times and I'm sure I copied it entirely) :-
> Error in apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x) maf(tabulate(x +  : 
>   object 'i' not found
> >  }
> Error: unexpected '}' in " }"
> 
> 
> The lapply function :
>   results<-lapply(SeparatedGroupsofmealsCombs , function(x)maf(tabulate(x+1)))
> gives this error :-
> Error in FUN(left, right) : non-numeric argument to binary operator
> 
> I have been trying since yesterday but but until now I'm not able to identify 
> the correct syntax.
> 
> 
> 
> 
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: 18 November 2017 20:06:56
> To: Allaisone 1
> Cc: Boris Steipe; R-help
> Subject: Re: [R] Complicated analysis for huge databases
>  
> 
> > On Nov 18, 2017, at 1:52 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> > 
> > Although the loop seems to be formulated correctly I wonder why
> > it gives me these errors :
> > 
> > -object 'i' not found
> > - unexpected '}' in "}"
> 
> You probably did not copy the entire code offered. But we cannot know since you did not "show your code", not=r did you post complete error messages. Both of these practices are strongly recommended by the Posting Guide. Please read it (again?).
> 
> -- 
> David.
> > 
> > 
> > the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for
> > 
> > for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-
> > 
> > 
> >> mafsforeachcolumns(I,II,...600)foreachcombination
> > 
> >      MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
> > 1          33-55                          1             0.124      0.10      0.65       0.467
> >                                                  3
> >                                                  5
> > 
> > 2      44-66                                7           0.134     0.43       0.64       0.479
> >                                                  4
> >                                                  9
> > 
> > .
> > 
> > .
> > 
> > ~180 dataframes
> > 
> > 
> > ________________________________
> > From: Boris Steipe <boris.steipe at utoronto.ca>
> > Sent: 18 November 2017 00:35:16
> > To: Allaisone 1; R-help
> > Subject: Re: [R] Complicated analysis for huge databases
> > 
> > Something like the following?
> > 
> > AllMAFs <- list()
> > 
> > for (i in length(SeparatedGroupsofmealsCombs) {
> >  AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
> > }
> > 
> > 
> > (untested, of course)
> > Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)
> > 
> > 
> > 
> > B.
> > 
> > 
> > 
> >> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> >> 
> >> 
> >> Thanks Boris , this was very helpful but I'm struggling with the last part.
> >> 
> >> 1) I combined the first 2 columns :-
> >> 
> >> 
> >> library(tidyr)
> >> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
> >> SingleMealsCode <- SingleMealsCode[,-2]
> >> 
> >>  2) I separated this dataframe into different dataframes based on "MealsCombination"
> >>   column so R will recognize each meal combination separately :
> >> 
> >> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
> >> 
> >> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
> >> a list of different databases, each of which represents a different Meal combinations which is great.
> >> 
> >> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
> >> 
> >> when I run this code as before :-
> >> 
> >> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
> >> 
> >> an error message says : dim(X) must have a positive length . I'm not sure which length
> >> I need to specify.. any suggestions to correct this syntax ?
> >> 
> >> Regards
> >> Allaisone
> >> From: Boris Steipe <boris.steipe at utoronto.ca>
> >> Sent: 17 November 2017 21:12:06
> >> To: Allaisone 1
> >> Cc: R-help
> >> Subject: Re: [R] Complicated analysis for huge databases
> >> 
> >> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
> >> 
> >> 
> >> B.
> >> 
> >>> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> >>> 
> >>> 
> >>> Hi all ..,
> >>> 
> >>> 
> >>> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
> >>> 
> >>> 
> >>>> MyData
> >>> 
> >>>      Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
> >>> 
> >>> 1    33                 55             1             0           1        2       0
> >>> 
> >>> 2    33                 55              3             1          0        2        2
> >>> 
> >>> 3    33                 55              5             2          1        1         2
> >>> 
> >>> 4    44                 66               7            0          2         2        2
> >>> 
> >>> 5   44                  66               4            1          1          0       1
> >>> 
> >>> 6   44                  66                9            2          0          1       2
> >>> 
> >>> .
> >>> 
> >>> .
> >>> 
> >>> 600,000
> >>> 
> >>> 
> >>> 
> >>> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
> >>> 
> >>> 
> >>> I can do the analysis  for the entire column but not group by group like this :
> >>> 
> >>> 
> >>> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
> >>> 
> >>> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
> >>> 
> >>> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
> >>> I have another sheet contains names of columns of interest like this :
> >>> 
> >>>> ColOfinterest
> >>> 
> >>> Col
> >>> I
> >>> IV
> >>> V
> >>> .
> >>> .
> >>> 300
> >>> 
> >>> Any one would help with the best combination of syntax to perform this complex analysis?
> >>> 
> >>> Regards
> >>> Allaisone
> >>> 
> >>> 
> >>> 
> >>> 
> >>> 
> >>> 
> >>> 
> >>>       [[alternative HTML version deleted]]
> >>> 
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From pdalgd at gmail.com  Sat Nov 18 23:20:25 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 18 Nov 2017 23:20:25 +0100
Subject: [R] [FORGED] Re:  tcltk problems
In-Reply-To: <1efdb8fa-0a7a-9dfa-18fd-204d16e55b4a@auckland.ac.nz>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>
 <1efdb8fa-0a7a-9dfa-18fd-204d16e55b4a@auckland.ac.nz>
Message-ID: <ABB58E4D-954D-4E9D-8D48-57F069E8B218@gmail.com>

Hum, missed that bit. Looking at the configure script, the only way I can see it failing to look in /usr/lib/tcl8.6 is if ${LIBnn} is not "lib". Any chance it might be set to lib64?

-pd 


> On 18 Nov 2017, at 22:32 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 19/11/17 05:36, Albrecht Kauffmann wrote:
> 
>> Did you istall the tcl- and tk-devel packages?
> 
> (a) That should be "dev" not "devel".
> 
> (b) The answer to your question is, yes, as I made clear in my original post.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From allaisone1 at hotmail.com  Sat Nov 18 22:40:35 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Sat, 18 Nov 2017 21:40:35 +0000
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
 <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>
Message-ID: <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>


The loop :


AllMAFs <- list()

 for (i in length(SeparatedGroupsofmealsCombs) {
  AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
}


gives these errors (I tried this many times and I'm sure I copied it entirely) :-

Error in apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x) maf(tabulate(x +  :
  object 'i' not found
>  }
Error: unexpected '}' in " }"


The lapply function :
  results<-lapply(SeparatedGroupsofmealsCombs , function(x)maf(tabulate(x+1)))
gives this error :-
Error in FUN(left, right) : non-numeric argument to binary operator

I have been trying since yesterday but but until now I'm not able to identify
the correct syntax.




________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: 18 November 2017 20:06:56
To: Allaisone 1
Cc: Boris Steipe; R-help
Subject: Re: [R] Complicated analysis for huge databases


> On Nov 18, 2017, at 1:52 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
> Although the loop seems to be formulated correctly I wonder why
> it gives me these errors :
>
> -object 'i' not found
> - unexpected '}' in "}"

You probably did not copy the entire code offered. But we cannot know since you did not "show your code", not=r did you post complete error messages. Both of these practices are strongly recommended by the Posting Guide. Please read it (again?).

--
David.
>
>
> the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for
>
> for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-
>
>
>> mafsforeachcolumns(I,II,...600)foreachcombination
>
>      MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
> 1          33-55                          1             0.124      0.10      0.65       0.467
>                                                  3
>                                                  5
>
> 2      44-66                                7           0.134     0.43       0.64       0.479
>                                                  4
>                                                  9
>
> .
>
> .
>
> ~180 dataframes
>
>
> ________________________________
> From: Boris Steipe <boris.steipe at utoronto.ca>
> Sent: 18 November 2017 00:35:16
> To: Allaisone 1; R-help
> Subject: Re: [R] Complicated analysis for huge databases
>
> Something like the following?
>
> AllMAFs <- list()
>
> for (i in length(SeparatedGroupsofmealsCombs) {
>  AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
> }
>
>
> (untested, of course)
> Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)
>
>
>
> B.
>
>
>
>> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>>
>> Thanks Boris , this was very helpful but I'm struggling with the last part.
>>
>> 1) I combined the first 2 columns :-
>>
>>
>> library(tidyr)
>> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
>> SingleMealsCode <- SingleMealsCode[,-2]
>>
>>  2) I separated this dataframe into different dataframes based on "MealsCombination"
>>   column so R will recognize each meal combination separately :
>>
>> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
>>
>> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
>> a list of different databases, each of which represents a different Meal combinations which is great.
>>
>> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
>>
>> when I run this code as before :-
>>
>> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
>>
>> an error message says : dim(X) must have a positive length . I'm not sure which length
>> I need to specify.. any suggestions to correct this syntax ?
>>
>> Regards
>> Allaisone
>> From: Boris Steipe <boris.steipe at utoronto.ca>
>> Sent: 17 November 2017 21:12:06
>> To: Allaisone 1
>> Cc: R-help
>> Subject: Re: [R] Complicated analysis for huge databases
>>
>> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
>>
>>
>> B.
>>
>>> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>
>>>
>>> Hi all ..,
>>>
>>>
>>> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
>>>
>>>
>>>> MyData
>>>
>>>      Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
>>>
>>> 1    33                 55             1             0           1        2       0
>>>
>>> 2    33                 55              3             1          0        2        2
>>>
>>> 3    33                 55              5             2          1        1         2
>>>
>>> 4    44                 66               7            0          2         2        2
>>>
>>> 5   44                  66               4            1          1          0       1
>>>
>>> 6   44                  66                9            2          0          1       2
>>>
>>> .
>>>
>>> .
>>>
>>> 600,000
>>>
>>>
>>>
>>> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
>>>
>>>
>>> I can do the analysis  for the entire column but not group by group like this :
>>>
>>>
>>> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
>>>
>>> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
>>>
>>> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
>>> I have another sheet contains names of columns of interest like this :
>>>
>>>> ColOfinterest
>>>
>>> Col
>>> I
>>> IV
>>> V
>>> .
>>> .
>>> 300
>>>
>>> Any one would help with the best combination of syntax to perform this complex analysis?
>>>
>>> Regards
>>> Allaisone
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Nov 19 00:15:15 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 18 Nov 2017 18:15:15 -0500
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
 <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>
 <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <e1df4d44-71af-622b-6da0-f0624a2e5df2@gmail.com>

On 18/11/2017 4:40 PM, Allaisone 1 wrote:
> 
> The loop :
> 
> 
> AllMAFs <- list()
> 
>   for (i in length(SeparatedGroupsofmealsCombs) {
>    AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
> }
> 
> 
> gives these errors (I tried this many times and I'm sure I copied it entirely) :-
> 
> Error in apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x) maf(tabulate(x +  :
>    object 'i' not found
>>   }
> Error: unexpected '}' in " }"

The first line of the for loop is short by one ")".  You should have 
seen this error after the first line:

Error: unexpected '{' in " for (i in length(SeparatedGroupsofmealsCombs) {"

Once that line is thrown away, the message about i makes sense:

AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, 
function(x)maf( tabulate( x+1) ))

refers to a variable "i" that has never been defined.

Duncan Murdoch

> 
> 
> The lapply function :
>    results<-lapply(SeparatedGroupsofmealsCombs , function(x)maf(tabulate(x+1)))
> gives this error :-
> Error in FUN(left, right) : non-numeric argument to binary operator
> 
> I have been trying since yesterday but but until now I'm not able to identify
> the correct syntax
> 
> 
> 
> 
> ________________________________
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: 18 November 2017 20:06:56
> To: Allaisone 1
> Cc: Boris Steipe; R-help
> Subject: Re: [R] Complicated analysis for huge databases
> 
> 
>> On Nov 18, 2017, at 1:52 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Although the loop seems to be formulated correctly I wonder why
>> it gives me these errors :
>>
>> -object 'i' not found
>> - unexpected '}' in "}"
> 
> You probably did not copy the entire code offered. But we cannot know since you did not "show your code", not=r did you post complete error messages. Both of these practices are strongly recommended by the Posting Guide. Please read it (again?).
> 
> --
> David.
>>
>>
>> the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for
>>
>> for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-
>>
>>
>>> mafsforeachcolumns(I,II,...600)foreachcombination
>>
>>       MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
>> 1          33-55                          1             0.124      0.10      0.65       0.467
>>                                                   3
>>                                                   5
>>
>> 2      44-66                                7           0.134     0.43       0.64       0.479
>>                                                   4
>>                                                   9
>>
>> .
>>
>> .
>>
>> ~180 dataframes
>>
>>
>> ________________________________
>> From: Boris Steipe <boris.steipe at utoronto.ca>
>> Sent: 18 November 2017 00:35:16
>> To: Allaisone 1; R-help
>> Subject: Re: [R] Complicated analysis for huge databases
>>
>> Something like the following?
>>
>> AllMAFs <- list()
>>
>> for (i in length(SeparatedGroupsofmealsCombs) {
>>   AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
>> }
>>
>>
>> (untested, of course)
>> Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)
>>
>>
>>
>> B.
>>
>>
>>
>>> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>
>>>
>>> Thanks Boris , this was very helpful but I'm struggling with the last part.
>>>
>>> 1) I combined the first 2 columns :-
>>>
>>>
>>> library(tidyr)
>>> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
>>> SingleMealsCode <- SingleMealsCode[,-2]
>>>
>>>   2) I separated this dataframe into different dataframes based on "MealsCombination"
>>>    column so R will recognize each meal combination separately :
>>>
>>> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
>>>
>>> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
>>> a list of different databases, each of which represents a different Meal combinations which is great.
>>>
>>> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
>>>
>>> when I run this code as before :-
>>>
>>> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
>>>
>>> an error message says : dim(X) must have a positive length . I'm not sure which length
>>> I need to specify.. any suggestions to correct this syntax ?
>>>
>>> Regards
>>> Allaisone
>>> From: Boris Steipe <boris.steipe at utoronto.ca>
>>> Sent: 17 November 2017 21:12:06
>>> To: Allaisone 1
>>> Cc: R-help
>>> Subject: Re: [R] Complicated analysis for huge databases
>>>
>>> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
>>>
>>>
>>> B.
>>>
>>>> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>>
>>>>
>>>> Hi all ..,
>>>>
>>>>
>>>> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
>>>>
>>>>
>>>>> MyData
>>>>
>>>>       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
>>>>
>>>> 1    33                 55             1             0           1        2       0
>>>>
>>>> 2    33                 55              3             1          0        2        2
>>>>
>>>> 3    33                 55              5             2          1        1         2
>>>>
>>>> 4    44                 66               7            0          2         2        2
>>>>
>>>> 5   44                  66               4            1          1          0       1
>>>>
>>>> 6   44                  66                9            2          0          1       2
>>>>
>>>> .
>>>>
>>>> .
>>>>
>>>> 600,000
>>>>
>>>>
>>>>
>>>> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
>>>>
>>>>
>>>> I can do the analysis  for the entire column but not group by group like this :
>>>>
>>>>
>>>> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
>>>>
>>>> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
>>>>
>>>> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
>>>> I have another sheet contains names of columns of interest like this :
>>>>
>>>>> ColOfinterest
>>>>
>>>> Col
>>>> I
>>>> IV
>>>> V
>>>> .
>>>> .
>>>> 300
>>>>
>>>> Any one would help with the best combination of syntax to perform this complex analysis?
>>>>
>>>> Regards
>>>> Allaisone
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Sun Nov 19 02:02:40 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 19 Nov 2017 14:02:40 +1300
Subject: [R] tcltk problems
In-Reply-To: <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
Message-ID: <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>

On 18/11/17 18:18, Peter Langfelder wrote:
> Rolf,
> 
> looking at the configure script I believe you need to specify
> 
> --with-tcl-config=/usr/lib/tcl8.6/tclConfig.sh
> 
> and similarly
> 
> --with-tk-config=<location of tkConfig.sh>
> 
> HTH.

Yes it helped.  Thank you. I don't really understand why, but.

I had previously (following an off-list suggestion from Berwin Turlach) 
put in symbolic links in /usr/lib:

      tclConfig.sh -> tcl8.6/tclConfig.sh*
and
      tkConfig.sh -> tk8.6/tclConfig.sh

so if the configure was by default looking for these files in /usr/lib 
it should have found them.  But it seemed not to.

In respect of Dirk's suggestion that I try using pre-built ubuntu R, I 
decided to try that and did

sudo apt update
sudo apt-get install r-base

and that kind of worked --- but naturally it screwed something up.  I 
can no longer load a "personal" library of utilities --- when I try this
(either having the load command in my .Rprofile or by invoking
R --vanilla) R crashes and tries to dump core.

Now, after having successfully installed R from source (following Peter 
Langfelder's tip) I still cannot load my utilities library.  Something 
got changed by the "install r-base" procedure, and there would appear to 
be no way of tracking down just what got changed.

It's things like that which make me want to "do it myself" as much as 
possible.

W.r.t. Peter Dalgaard's suggestion/question about ${LIBnn}$:  I looked 
through R-3.4.2/configure and can see nowhere that LIBnn gets set. 
(Lots of references to LIBnn, but nowhere that its value gets set equal 
to something.)

BTW I (of course) am using the configure file that comes with R-3.4.2; I 
haven't changed anything.  So if anyone looks at the R-3.4.2 configure 
file they should see exactly what I see.

Then I scanned through BldDir/config.log and found:

LIBnn='lib64'

(on line 19901 !!!)

So it would appear that Peter D.'s conjecture is correct.

OTOH this is waaayyy after the "checking for tclConfig.sh" business, 
which happens at about line 15101 of config.log.  So how does it have an 
impact on that?

And how did LIBnn get to be set to 'lib64'?  I certainly didn't do it, 
and there's nothing about 'lib64' in the environment variables that I 
have set.

I remain mystified.

cheers,

Rolf

P.S.  On a whim, I scanned through config.log some more and found many, 
many errors logged and many, many "compilation terminated" notes.  In 
particular there seem to be problems with a file "confdef.h", which 
repeatedly seems to give rise to "fatal errors".  (Where is confdef.h?
It seems to be nowhere.)

But this was from a "*successful*" configure (using Peter L.'s 
suggestion.) So it would appear that these errors were harmless.  Mostly 
harmless???

R.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From allaisone1 at hotmail.com  Sun Nov 19 01:15:45 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Sun, 19 Nov 2017 00:15:45 +0000
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <e1df4d44-71af-622b-6da0-f0624a2e5df2@gmail.com>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
 <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>
 <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <e1df4d44-71af-622b-6da0-f0624a2e5df2@gmail.com>
Message-ID: <AM5P195MB0020B91DB9B8B4CF5E38BF97802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Thanks but a new error appeared with the loop :


Error in x + 1 : non-numeric argument to binary operator


I think this can be solved by converting columns (I,II,II,..600) into "numeric" instead of

the current "int" type as shown below in the structure of "33_55" dataframe .


$ 33_55:'data.frame': 256 obs. of  600 variables:
  ..$ MealsCombinations                 : chr [1:256] "33_55" "33_55" ....
  ..$ ID                               : num [1:256] 1  3  5  ...
  ..$ I                   : int [1:256] 1 1 2 1 1 2 1 2 1 1 ...
  ..$ II                    : int [1:256] 2 1 2 2 1 2 2 2 2 2 ...
  ..$ III                  : int [1:256] 1 1 2 1 1 2 1 2 1 1 ...
  ..$ IV                  : int [1:256] 2 2 2 2 2 2 2 2 2 2 ...


any suggestions to solve this issue rather than unlisting the list as this will affect

the current shape of data (i.e. being separated dataframes). I need to find maf  for each column(I,II,III..600) under this dataframe (33_55) and the rest of dataframes.

________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: 18 November 2017 23:15:15
To: Allaisone 1; David Winsemius
Cc: R-help
Subject: Re: [R] Complicated analysis for huge databases

On 18/11/2017 4:40 PM, Allaisone 1 wrote:
>
> The loop :
>
>
> AllMAFs <- list()
>
>   for (i in length(SeparatedGroupsofmealsCombs) {
>    AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
> }
>
>
> gives these errors (I tried this many times and I'm sure I copied it entirely) :-
>
> Error in apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x) maf(tabulate(x +  :
>    object 'i' not found
>>   }
> Error: unexpected '}' in " }"

The first line of the for loop is short by one ")".  You should have
seen this error after the first line:

Error: unexpected '{' in " for (i in length(SeparatedGroupsofmealsCombs) {"

Once that line is thrown away, the message about i makes sense:

AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2,
function(x)maf( tabulate( x+1) ))

refers to a variable "i" that has never been defined.

Duncan Murdoch

>
>
> The lapply function :
>    results<-lapply(SeparatedGroupsofmealsCombs , function(x)maf(tabulate(x+1)))
> gives this error :-
> Error in FUN(left, right) : non-numeric argument to binary operator
>
> I have been trying since yesterday but but until now I'm not able to identify
> the correct syntax
>
>
>
>
> ________________________________
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: 18 November 2017 20:06:56
> To: Allaisone 1
> Cc: Boris Steipe; R-help
> Subject: Re: [R] Complicated analysis for huge databases
>
>
>> On Nov 18, 2017, at 1:52 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Although the loop seems to be formulated correctly I wonder why
>> it gives me these errors :
>>
>> -object 'i' not found
>> - unexpected '}' in "}"
>
> You probably did not copy the entire code offered. But we cannot know since you did not "show your code", not=r did you post complete error messages. Both of these practices are strongly recommended by the Posting Guide. Please read it (again?).
>
> --
> David.
>>
>>
>> the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for
>>
>> for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-
>>
>>
>>> mafsforeachcolumns(I,II,...600)foreachcombination
>>
>>       MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
>> 1          33-55                          1             0.124      0.10      0.65       0.467
>>                                                   3
>>                                                   5
>>
>> 2      44-66                                7           0.134     0.43       0.64       0.479
>>                                                   4
>>                                                   9
>>
>> .
>>
>> .
>>
>> ~180 dataframes
>>
>>
>> ________________________________
>> From: Boris Steipe <boris.steipe at utoronto.ca>
>> Sent: 18 November 2017 00:35:16
>> To: Allaisone 1; R-help
>> Subject: Re: [R] Complicated analysis for huge databases
>>
>> Something like the following?
>>
>> AllMAFs <- list()
>>
>> for (i in length(SeparatedGroupsofmealsCombs) {
>>   AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
>> }
>>
>>
>> (untested, of course)
>> Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)
>>
>>
>>
>> B.
>>
>>
>>
>>> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>
>>>
>>> Thanks Boris , this was very helpful but I'm struggling with the last part.
>>>
>>> 1) I combined the first 2 columns :-
>>>
>>>
>>> library(tidyr)
>>> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
>>> SingleMealsCode <- SingleMealsCode[,-2]
>>>
>>>   2) I separated this dataframe into different dataframes based on "MealsCombination"
>>>    column so R will recognize each meal combination separately :
>>>
>>> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
>>>
>>> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
>>> a list of different databases, each of which represents a different Meal combinations which is great.
>>>
>>> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
>>>
>>> when I run this code as before :-
>>>
>>> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
>>>
>>> an error message says : dim(X) must have a positive length . I'm not sure which length
>>> I need to specify.. any suggestions to correct this syntax ?
>>>
>>> Regards
>>> Allaisone
>>> From: Boris Steipe <boris.steipe at utoronto.ca>
>>> Sent: 17 November 2017 21:12:06
>>> To: Allaisone 1
>>> Cc: R-help
>>> Subject: Re: [R] Complicated analysis for huge databases
>>>
>>> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
>>>
>>>
>>> B.
>>>
>>>> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>>
>>>>
>>>> Hi all ..,
>>>>
>>>>
>>>> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
>>>>
>>>>
>>>>> MyData
>>>>
>>>>       Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
>>>>
>>>> 1    33                 55             1             0           1        2       0
>>>>
>>>> 2    33                 55              3             1          0        2        2
>>>>
>>>> 3    33                 55              5             2          1        1         2
>>>>
>>>> 4    44                 66               7            0          2         2        2
>>>>
>>>> 5   44                  66               4            1          1          0       1
>>>>
>>>> 6   44                  66                9            2          0          1       2
>>>>
>>>> .
>>>>
>>>> .
>>>>
>>>> 600,000
>>>>
>>>>
>>>>
>>>> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
>>>>
>>>>
>>>> I can do the analysis  for the entire column but not group by group like this :
>>>>
>>>>
>>>> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
>>>>
>>>> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
>>>>
>>>> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
>>>> I have another sheet contains names of columns of interest like this :
>>>>
>>>>> ColOfinterest
>>>>
>>>> Col
>>>> I
>>>> IV
>>>> V
>>>> .
>>>> .
>>>> 300
>>>>
>>>> Any one would help with the best combination of syntax to perform this complex analysis?
>>>>
>>>> Regards
>>>> Allaisone
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From ainorprogram at gmail.com  Sun Nov 19 01:21:08 2017
From: ainorprogram at gmail.com (Aino Rprogram)
Date: Sat, 18 Nov 2017 16:21:08 -0800
Subject: [R] Changeing logarithms
Message-ID: <CAOu56Xv0ZHV81GZ6z54V1G0nv2ZTPD5BrXTTSAik_WfBkFCA5A@mail.gmail.com>

Hi!

I'm using a large panel data, and now I have faced some difficulties with
my analysis. The predictors are not normally distributed and there are
quite many outliers (some of them are influential though).

I have tried to change the logarythm, but i'm not sure, how to do that. I
want also draw a plot picture in which logarythms of predictors x and y are
changed. How could I do that?

Thanx before-hand!

Liz

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Nov 19 12:02:16 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 19 Nov 2017 12:02:16 +0100
Subject: [R] tcltk problems
In-Reply-To: <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
 <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
Message-ID: <F19D8150-F613-41E4-9ACE-0FB5C1DC87A8@gmail.com>

This is normal, but you're not reading it right. Typically, a program conftest.c is generated on the fly and contains something like a #include of something you may or may not have. The first part of the program is labeled /* conftest.h */ which indicates that it is taken from that file of standard definitions. 

The contents of confdefs.h is actually mostly irrelevant (though I suppose there are cases when it isn't), the interesting bit is usually the line(s) that comes from elsewhere, e.g.

....
| #define HAVE_UNISTD_H 1
| #define HAVE_UTIME_H 1
| #define HAVE_ARPA_INET_H 1
| /* end confdefs.h.  */
| #include <dl.h>
configure:23459: result: no
configure:23459: checking for dl.h
configure:23459: result: no

This whole thint is about whether or not your system contains dl.h. When the compile fails, configure concludes that it doesn't. 

You only get to see the programs when they fail, but the same mechanism is behind all the other tests, like

configure:23459: checking langinfo.h presence
configure:23459: gcc -arch x86_64 -E -I/usr/local/include conftest.c
configure:23459: $? = 0
configure:23459: result: yes
configure:23459: checking for langinfo.h
configure:23459: result: yes

In some other cases, there is a rudimentary main() function, usually to check existence of specific library routines, and in a few cases there is a check whether the compiled program  actually runs.


-pd

> On 19 Nov 2017, at 02:02 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> P.S.  On a whim, I scanned through config.log some more and found many, many errors logged and many, many "compilation terminated" notes.  In particular there seem to be problems with a file "confdef.h", which repeatedly seems to give rise to "fatal errors".  (Where is confdef.h?
> It seems to be nowhere.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Sun Nov 19 12:17:59 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 19 Nov 2017 12:17:59 +0100
Subject: [R] tcltk problems
In-Reply-To: <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
 <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
Message-ID: <27A8F4D0-F97D-464B-B790-FEB4E9CDD7CF@gmail.com>

Dirk may want to dig in here:

Seems like you have a system with a /usr/lib64 dir for 64 bit libraries, but Tcl files in /usr/lib. If that is not an anomaly, it looks like we have a configure bug (conceiveably, a system might be using /usr/lib for architecture-independent files, and lib64/lib32 for binaries). It doesn't look too hard to modify configure to also check /usr/lib, but we probably shouldn't do it if one user has shot himself in the foot somehow.

-pd

> On 19 Nov 2017, at 02:02 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> Then I scanned through BldDir/config.log and found:
> 
> LIBnn='lib64'
> 
> (on line 19901 !!!)
> 
> So it would appear that Peter D.'s conjecture is correct.
> 
> OTOH this is waaayyy after the "checking for tclConfig.sh" business, which happens at about line 15101 of config.log.  So how does it have an impact on that?
> 
> And how did LIBnn get to be set to 'lib64'?  I certainly didn't do it, and there's nothing about 'lib64' in the environment variables that I have set.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maranrx at gmail.com  Sun Nov 19 11:28:48 2017
From: maranrx at gmail.com (Mani Maran)
Date: Sun, 19 Nov 2017 15:58:48 +0530
Subject: [R] IVIVC EXAMPLE OR program
In-Reply-To: <CALnpv0oS1Dc9n8v146VPJxXc52tSfebmvXYPFao3hbRedBqJ=A@mail.gmail.com>
References: <CALnpv0rB1ZVrNZ983ibRoP5gX8FORLHoNuZZgOMJbHawHv16Qg@mail.gmail.com>
 <CALnpv0oF1EMBGOto2cFOLwimRVhTE5JpF6ggy5D58bOYNsc=pw@mail.gmail.com>
 <CALnpv0pT9oq_DoKn6s1eFve8700C0a8-WsZA16Ve7J_wBCtAcw@mail.gmail.com>
 <CALnpv0qn1oTAE8GTw16jPaU_zmmPRC1CZeRywz8VsPJo9qYHMA@mail.gmail.com>
 <CALnpv0oyBHSg4CrxZuHHrBcKXxEq17yatCHXWHoZaNc2gRD_+Q@mail.gmail.com>
 <CALnpv0rNwc+J+ezZycR=oJNUvd-3ZtgukKvOJ9TmY9h=xFBR8g@mail.gmail.com>
 <CALnpv0o3hT5ntRSaFSZdn_F+paH_A2Qbo3QCP5cHywQKVpBnGA@mail.gmail.com>
 <CALnpv0rVBbCJ_WM9ZDedzyGAhB9AE1dyorzrR08Em3otW2bwMg@mail.gmail.com>
 <CALnpv0qkRjBvJg+Dr=hj945J_Z6-aFc=9LoEM+iBoUSud1Fc_w@mail.gmail.com>
 <CALnpv0oS1Dc9n8v146VPJxXc52tSfebmvXYPFao3hbRedBqJ=A@mail.gmail.com>
Message-ID: <CALnpv0qdqZd5LprL1t5xmJY=_aszUvOC1DsrOookcS0V+2wczQ@mail.gmail.com>

Dear developer this softwere is very much useful thanks for the everyones
availability first.

I need the programm to run an IVIVC  for an IR BCS class 2 product.
I have dissolution upto 45 mins and plasma profile upto 72 hours. For test
and reference products of pilot study which is actually failed for cmax
parameter. To predict the upcoming formulations of the same product  with
varying release rates I need atlease rank order IVIVC program please help
me. If possible please share example how to compile the data in .csv file.

Thanks in advance.

Regards,
Manimaran

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun Nov 19 13:31:30 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 19 Nov 2017 12:31:30 +0000
Subject: [R] Changeing logarithms
In-Reply-To: <CAOu56Xv0ZHV81GZ6z54V1G0nv2ZTPD5BrXTTSAik_WfBkFCA5A@mail.gmail.com>
References: <CAOu56Xv0ZHV81GZ6z54V1G0nv2ZTPD5BrXTTSAik_WfBkFCA5A@mail.gmail.com>
Message-ID: <9bdd8a83-5a75-bff4-730d-0a36d452d6f5@dewey.myzen.co.uk>

Dear Liz

I am not sure I completely understand your problem but you can create a 
new variable by going

newVariable <- log(oldVariable)

or in many cases just use log(oldVariable) where you previously used 
oldVariable

Michael

On 19/11/2017 00:21, Aino Rprogram wrote:
> Hi!
> 
> I'm using a large panel data, and now I have faced some difficulties with
> my analysis. The predictors are not normally distributed and there are
> quite many outliers (some of them are influential though).
> 
> I have tried to change the logarythm, but i'm not sure, how to do that. I
> want also draw a plot picture in which logarythms of predictors x and y are
> changed. How could I do that?
> 
> Thanx before-hand!
> 
> Liz
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jsorkin at som.umaryland.edu  Sun Nov 19 14:46:29 2017
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Sun, 19 Nov 2017 13:46:29 +0000
Subject: [R] Changeing logarithms
In-Reply-To: <CAOu56Xv0ZHV81GZ6z54V1G0nv2ZTPD5BrXTTSAik_WfBkFCA5A@mail.gmail.com>
References: <CAOu56Xv0ZHV81GZ6z54V1G0nv2ZTPD5BrXTTSAik_WfBkFCA5A@mail.gmail.com>
Message-ID: <BN6PR03MB297779667A7EC15569DCFFC0E22D0@BN6PR03MB2977.namprd03.prod.outlook.com>

I am not certain what question you are asking. Perhaps the following will help:


log(x) give the natural logarithm of x

log10(x) gives the common (base 10) logarithm of x.

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Aino Rprogram <ainorprogram at gmail.com>
Sent: Saturday, November 18, 2017 7:21 PM
To: r-help at r-project.org
Subject: [R] Changeing logarithms

Hi!

I'm using a large panel data, and now I have faced some difficulties with
my analysis. The predictors are not normally distributed and there are
quite many outliers (some of them are influential though).

I have tried to change the logarythm, but i'm not sure, how to do that. I
want also draw a plot picture in which logarythms of predictors x and y are
changed. How could I do that?

Thanx before-hand!

Liz

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From edd at debian.org  Sun Nov 19 15:15:47 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 19 Nov 2017 08:15:47 -0600
Subject: [R] tcltk problems
In-Reply-To: <27A8F4D0-F97D-464B-B790-FEB4E9CDD7CF@gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
 <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
 <27A8F4D0-F97D-464B-B790-FEB4E9CDD7CF@gmail.com>
Message-ID: <23057.37395.189418.430559@bud.eddelbuettel.com>


On 19 November 2017 at 12:17, peter dalgaard wrote:
| Dirk may want to dig in here:

I respectfully decline.

R builds fine on every Ubuntu system, and always has.  No bug in R, or
Ubuntu, or Debian (which would be cup of tea). There is the distro package
(which may be older if an older distro like 16.04 is used) and there always
is a current package at CRAN based on Michael's build of my packages. Always.

Of course a lot of people also locally build R, or maybe R-devel. There is no
general issue here as best as I can tell.

| [...] if one user has shot himself in the foot somehow.

My brief reading suggests that this is the case.

Nothing good comes off moving files around in /usr as was done.  It creates
local non-standard circumstances. You cannot expect standardized build to
anticipate each and every possible non-standard modification.

This discussion is still on the wrong list too.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From boris.steipe at utoronto.ca  Sun Nov 19 17:56:10 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 19 Nov 2017 11:56:10 -0500
Subject: [R] Complicated analysis for huge databases
In-Reply-To: <AM5P195MB0020B91DB9B8B4CF5E38BF97802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002023DF3FEDA3CD012151CA802F0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <9A3BA472-4BD1-47A9-BCF1-F4566D92AE9A@utoronto.ca>
 <AM5P195MB0020DD8A838D166164B711CC802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <24642274-F484-4803-9302-8BEF61BC194C@utoronto.ca>
 <AM5P195MB00208BD0FB0AE16311C528BB802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <3841A7C3-E94E-45EA-BDC8-F45CB5E94F23@comcast.net>
 <AM5P195MB0020D178E00F92173BC25859802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <e1df4d44-71af-622b-6da0-f0624a2e5df2@gmail.com>
 <AM5P195MB0020B91DB9B8B4CF5E38BF97802C0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <72C038E4-39D3-426A-91F5-E66B39FA8362@utoronto.ca>

Here are some elementary facts for you to ponder:

R > is.numeric(1)
[1] TRUE
R > is.integer(1)
[1] FALSE
R > is.numeric(1L)
[1] TRUE
R > is.integer(1L)
[1] TRUE
R > 1 + 1
[1] 2
R > 1 + 1L
[1] 2
R > 1L + 1L
[1] 2
R > 1L + "1"
Error in 1L + "1" : non-numeric argument to binary operator


Now, here is a word of caution: Your analysis of the error, and your failure to spot the egregious error that I had made in a previous post (embarrassing, I know) tells me that you are way out of your league with even simple data handling in R. You may get this to run somehow, but unless you step back and invest some serious time in a systematic introduction to R, you are going to let yourself down, and others who rely on your work.

That's going to be all from me.


B.


> On Nov 18, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> Thanks but a new error appeared with the loop :
> 
> 
> Error in x + 1 : non-numeric argument to binary operator
> 
> 
> I think this can be solved by converting columns (I,II,II,..600) into "numeric" instead of
> 
> the current "int" type as shown below in the structure of "33_55" dataframe .
> 
> 
> $ 33_55:'data.frame': 256 obs. of  600 variables:
>  ..$ MealsCombinations                 : chr [1:256] "33_55" "33_55" ....
>  ..$ ID                               : num [1:256] 1  3  5  ...
>  ..$ I                   : int [1:256] 1 1 2 1 1 2 1 2 1 1 ...
>  ..$ II                    : int [1:256] 2 1 2 2 1 2 2 2 2 2 ...
>  ..$ III                  : int [1:256] 1 1 2 1 1 2 1 2 1 1 ...
>  ..$ IV                  : int [1:256] 2 2 2 2 2 2 2 2 2 2 ...
> 
> 
> any suggestions to solve this issue rather than unlisting the list as this will affect
> 
> the current shape of data (i.e. being separated dataframes). I need to find maf  for each column(I,II,III..600) under this dataframe (33_55) and the rest of dataframes.
> 
> ________________________________
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> Sent: 18 November 2017 23:15:15
> To: Allaisone 1; David Winsemius
> Cc: R-help
> Subject: Re: [R] Complicated analysis for huge databases
> 
> On 18/11/2017 4:40 PM, Allaisone 1 wrote:
>> 
>> The loop :
>> 
>> 
>> AllMAFs <- list()
>> 
>>  for (i in length(SeparatedGroupsofmealsCombs) {
>>   AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
>> }
>> 
>> 
>> gives these errors (I tried this many times and I'm sure I copied it entirely) :-
>> 
>> Error in apply(SeparatedGroupsofmealsCombs[[i]], 2, function(x) maf(tabulate(x +  :
>>   object 'i' not found
>>>  }
>> Error: unexpected '}' in " }"
> 
> The first line of the for loop is short by one ")".  You should have
> seen this error after the first line:
> 
> Error: unexpected '{' in " for (i in length(SeparatedGroupsofmealsCombs) {"
> 
> Once that line is thrown away, the message about i makes sense:
> 
> AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2,
> function(x)maf( tabulate( x+1) ))
> 
> refers to a variable "i" that has never been defined.
> 
> Duncan Murdoch
> 
>> 
>> 
>> The lapply function :
>>   results<-lapply(SeparatedGroupsofmealsCombs , function(x)maf(tabulate(x+1)))
>> gives this error :-
>> Error in FUN(left, right) : non-numeric argument to binary operator
>> 
>> I have been trying since yesterday but but until now I'm not able to identify
>> the correct syntax
>> 
>> 
>> 
>> 
>> ________________________________
>> From: David Winsemius <dwinsemius at comcast.net>
>> Sent: 18 November 2017 20:06:56
>> To: Allaisone 1
>> Cc: Boris Steipe; R-help
>> Subject: Re: [R] Complicated analysis for huge databases
>> 
>> 
>>> On Nov 18, 2017, at 1:52 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>> 
>>> Although the loop seems to be formulated correctly I wonder why
>>> it gives me these errors :
>>> 
>>> -object 'i' not found
>>> - unexpected '}' in "}"
>> 
>> You probably did not copy the entire code offered. But we cannot know since you did not "show your code", not=r did you post complete error messages. Both of these practices are strongly recommended by the Posting Guide. Please read it (again?).
>> 
>> --
>> David.
>>> 
>>> 
>>> the desired output is expected to be very large as for each dataframe in the list of dataframes I expect to see maf value for each of the 600 columns! and this is only for
>>> 
>>> for one dataframe in the list .. I have around 150-200 dataframes.. not sure how R will store these results.. but first I need the analysis to be done correctly. The final output has to be something like this :-
>>> 
>>> 
>>>> mafsforeachcolumns(I,II,...600)foreachcombination
>>> 
>>>      MealsCombinations    Cust.ID      I              II            III             IV       ...... 600
>>> 1          33-55                          1             0.124      0.10      0.65       0.467
>>>                                                  3
>>>                                                  5
>>> 
>>> 2      44-66                                7           0.134     0.43       0.64       0.479
>>>                                                  4
>>>                                                  9
>>> 
>>> .
>>> 
>>> .
>>> 
>>> ~180 dataframes
>>> 
>>> 
>>> ________________________________
>>> From: Boris Steipe <boris.steipe at utoronto.ca>
>>> Sent: 18 November 2017 00:35:16
>>> To: Allaisone 1; R-help
>>> Subject: Re: [R] Complicated analysis for huge databases
>>> 
>>> Something like the following?
>>> 
>>> AllMAFs <- list()
>>> 
>>> for (i in length(SeparatedGroupsofmealsCombs) {
>>>  AllMAFs[[i]] <- apply( SeparatedGroupsofmealsCombs[[i]], 2, function(x)maf( tabulate( x+1) ))
>>> }
>>> 
>>> 
>>> (untested, of course)
>>> Also the solution is a bit generic since I don't know what the output of maf() looks like in your case, and I don't understand why you use tabulate because I would have assumed that's what maf() does - but that's not for me to worry about :-)
>>> 
>>> 
>>> 
>>> B.
>>> 
>>> 
>>> 
>>>> On Nov 17, 2017, at 7:15 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>> 
>>>> 
>>>> Thanks Boris , this was very helpful but I'm struggling with the last part.
>>>> 
>>>> 1) I combined the first 2 columns :-
>>>> 
>>>> 
>>>> library(tidyr)
>>>> SingleMealsCode <-unite(MyData, MealsCombinations, c(MealA, MealB), remove=FALSE)
>>>> SingleMealsCode <- SingleMealsCode[,-2]
>>>> 
>>>>  2) I separated this dataframe into different dataframes based on "MealsCombination"
>>>>   column so R will recognize each meal combination separately :
>>>> 
>>>> SeparatedGroupsofmealsCombs <- split(SingleMealCode,SingleMealCode$MealsCombinations)
>>>> 
>>>> after investigating the structure of "SeparatedGroupsofmealsCombs" , I can see
>>>> a list of different databases, each of which represents a different Meal combinations which is great.
>>>> 
>>>> No, I'm struggling with the last part, how can I run the maf code for all dataframes?
>>>> 
>>>> when I run this code as before :-
>>>> 
>>>> maf <- apply(SeparatedGroupsofmealsCombs, 2, function(x)maf(tabulate(x+1)))
>>>> 
>>>> an error message says : dim(X) must have a positive length . I'm not sure which length
>>>> I need to specify.. any suggestions to correct this syntax ?
>>>> 
>>>> Regards
>>>> Allaisone
>>>> From: Boris Steipe <boris.steipe at utoronto.ca>
>>>> Sent: 17 November 2017 21:12:06
>>>> To: Allaisone 1
>>>> Cc: R-help
>>>> Subject: Re: [R] Complicated analysis for huge databases
>>>> 
>>>> Combine columns 1 and 2 into a column with a single ID like "33.55", "44.66" and use split() on these IDs to break up your dataset. Iterate over the list of data frames split() returns.
>>>> 
>>>> 
>>>> B.
>>>> 
>>>>> On Nov 17, 2017, at 12:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>>>> 
>>>>> 
>>>>> Hi all ..,
>>>>> 
>>>>> 
>>>>> I have a large dataset of around 600,000 rows and 600 columns. The first col is codes for Meal A, the second columns is codes for Meal B. The third column is customers IDs where each customer had a combination of meals. Each column of the rest columns contains values 0,1,or 2. The dataset is organised in a way so that the first group of customers had similar meals combinations, this is followed by another group of customers with similar meals combinations but different from the first group and so on. The dataset looks like this :-
>>>>> 
>>>>> 
>>>>>> MyData
>>>>> 
>>>>>      Meal A     Meal B     Cust.ID      I            II        III     IV   ...... 600
>>>>> 
>>>>> 1    33                 55             1             0           1        2       0
>>>>> 
>>>>> 2    33                 55              3             1          0        2        2
>>>>> 
>>>>> 3    33                 55              5             2          1        1         2
>>>>> 
>>>>> 4    44                 66               7            0          2         2        2
>>>>> 
>>>>> 5   44                  66               4            1          1          0       1
>>>>> 
>>>>> 6   44                  66                9            2          0          1       2
>>>>> 
>>>>> .
>>>>> 
>>>>> .
>>>>> 
>>>>> 600,000
>>>>> 
>>>>> 
>>>>> 
>>>>> I wanted to find maf() for each column(from 4 to 600) after calculating the frequency of the 3 values (0,1,2) but this should be done group by group (i.e. group(33-55) : rows 1:3 then group(44-66) :rows 4:6 and so on).
>>>>> 
>>>>> 
>>>>> I can do the analysis  for the entire column but not group by group like this :
>>>>> 
>>>>> 
>>>>> MAF <- apply(MyData[,4:600], 2, function(x)maf(tabulate(x+1)))
>>>>> 
>>>>> How can I modify this code to tell R to do the analysis group by group for each column so I get maf value for 33-55 group of clolumn I, then maf value for group 44-66 in the same column I,then the rest of groups in this column and do the same for the remaining columns.
>>>>> 
>>>>> In fact, I'm interested in doing this analysis for only 300 columns but all of the 600 columns.
>>>>> I have another sheet contains names of columns of interest like this :
>>>>> 
>>>>>> ColOfinterest
>>>>> 
>>>>> Col
>>>>> I
>>>>> IV
>>>>> V
>>>>> .
>>>>> .
>>>>> 300
>>>>> 
>>>>> Any one would help with the best combination of syntax to perform this complex analysis?
>>>>> 
>>>>> Regards
>>>>> Allaisone
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>> 
>> 
>> 
>> 
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sun Nov 19 20:38:42 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 20 Nov 2017 08:38:42 +1300
Subject: [R] tcltk problems
In-Reply-To: <23057.37395.189418.430559@bud.eddelbuettel.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
 <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
 <27A8F4D0-F97D-464B-B790-FEB4E9CDD7CF@gmail.com>
 <23057.37395.189418.430559@bud.eddelbuettel.com>
Message-ID: <62d0ec7b-bc50-1a33-06f4-f9227b3a2209@auckland.ac.nz>

On 20/11/17 03:15, Dirk Eddelbuettel wrote:
> 
> On 19 November 2017 at 12:17, peter dalgaard wrote:
> | Dirk may want to dig in here:
> 
> I respectfully decline.
> 
> R builds fine on every Ubuntu system, and always has.  No bug in R, or
> Ubuntu, or Debian (which would be cup of tea). There is the distro package
> (which may be older if an older distro like 16.04 is used) and there always
> is a current package at CRAN based on Michael's build of my packages. Always.
> 
> Of course a lot of people also locally build R, or maybe R-devel. There is no
> general issue here as best as I can tell.
> 
> | [...] if one user has shot himself in the foot somehow.
> 
> My brief reading suggests that this is the case.

Point of order Mr. Chairman.  It is completely unfair to say that I shot 
myself in the foot.

I did:

sudo apt-get install tcl
sudo apt-get install tcl8.6.dev

and similarly for tk stuff.

I downloaded the source for R-3.4.2 and ran ../R-3.4.2/configure (from a 
"parallel" directory "BldDir".

It stuffed up, apparently being unable to find tclConfig.sh and tkConfig.sh.

*After* the stuff-up I put in symbolic links in /usr/lib to these file 
in the subdirectories (in which apt-get install apparently placed them.)
This was done according to a suggestion from Berwin Turlach, who found 
that there were similar symbolic links in his file system.  This did not
help however.

Peter Langfelder's suggestion, saying very explicitly what flags I 
should provide to "configure" in respect of the *Config.sh files, *DID* 
work.

I did *not* move any files around.  I did *not* make any alterations to
the configure script.  I did not modify anything, in a "non-standard" 
way --- or even in a standard way!  I just used the software provided, 
in the prescribed manner, and it did not work.

> Nothing good comes off moving files around in /usr as was done.  It creates
> local non-standard circumstances. You cannot expect standardized build to
> anticipate each and every possible non-standard modification.
> 
> This discussion is still on the wrong list too.

Well, OK.  What list *should* it be on?  I was asking for help with an R 
problem.  It seems to me that R-help is appropriate.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From edd at debian.org  Sun Nov 19 21:03:42 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 19 Nov 2017 14:03:42 -0600
Subject: [R] tcltk problems
In-Reply-To: <62d0ec7b-bc50-1a33-06f4-f9227b3a2209@auckland.ac.nz>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <beff36b5-1292-d922-cafe-0f08441dd5b0@auckland.ac.nz>
 <CA+hbrhVMTe5OgQONrnLH8+xf5YLThyt8OeLYNVavRS+a-9wqwg@mail.gmail.com>
 <8036cf0b-bd31-4ffa-60db-4c6af6787020@auckland.ac.nz>
 <27A8F4D0-F97D-464B-B790-FEB4E9CDD7CF@gmail.com>
 <23057.37395.189418.430559@bud.eddelbuettel.com>
 <62d0ec7b-bc50-1a33-06f4-f9227b3a2209@auckland.ac.nz>
Message-ID: <23057.58270.573651.555015@bud.eddelbuettel.com>


On 20 November 2017 at 08:38, Rolf Turner wrote:
| Point of order Mr. Chairman.  It is completely unfair to say that I shot 
| myself in the foot.

You moved files [or, in this case, created symlinks] below /usr.

Most of us repeatedly said you should not have to.

| Well, OK.  What list *should* it be on?  I was asking for help with an R 
| problem.  It seems to me that R-help is appropriate.

r-sig-debian, as my first email here said, and in concordance with all R
mailing list help and information.  

I am removing myself from CCs. The tone of these emails is such that I prefer
to focus on other things. You can do on your systems whatever you want -- but
if it breaks you get to keep the pieces.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From petr.pikal at precheza.cz  Mon Nov 20 11:26:09 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 20 Nov 2017 10:26:09 +0000
Subject: [R] IVIVC EXAMPLE OR program
In-Reply-To: <CALnpv0qdqZd5LprL1t5xmJY=_aszUvOC1DsrOookcS0V+2wczQ@mail.gmail.com>
References: <CALnpv0rB1ZVrNZ983ibRoP5gX8FORLHoNuZZgOMJbHawHv16Qg@mail.gmail.com>
 <CALnpv0oF1EMBGOto2cFOLwimRVhTE5JpF6ggy5D58bOYNsc=pw@mail.gmail.com>
 <CALnpv0pT9oq_DoKn6s1eFve8700C0a8-WsZA16Ve7J_wBCtAcw@mail.gmail.com>
 <CALnpv0qn1oTAE8GTw16jPaU_zmmPRC1CZeRywz8VsPJo9qYHMA@mail.gmail.com>
 <CALnpv0oyBHSg4CrxZuHHrBcKXxEq17yatCHXWHoZaNc2gRD_+Q@mail.gmail.com>
 <CALnpv0rNwc+J+ezZycR=oJNUvd-3ZtgukKvOJ9TmY9h=xFBR8g@mail.gmail.com>
 <CALnpv0o3hT5ntRSaFSZdn_F+paH_A2Qbo3QCP5cHywQKVpBnGA@mail.gmail.com>
 <CALnpv0rVBbCJ_WM9ZDedzyGAhB9AE1dyorzrR08Em3otW2bwMg@mail.gmail.com>
 <CALnpv0qkRjBvJg+Dr=hj945J_Z6-aFc=9LoEM+iBoUSud1Fc_w@mail.gmail.com>
 <CALnpv0oS1Dc9n8v146VPJxXc52tSfebmvXYPFao3hbRedBqJ=A@mail.gmail.com>
 <CALnpv0qdqZd5LprL1t5xmJY=_aszUvOC1DsrOookcS0V+2wczQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABAB9B@SRVEXCHCM301.precheza.cz>

Hi

Your question is rather vague, but R, as usual, provide tools for almost any type of analysis.

With some google help I found
http://pkpd.kmu.edu.tw/ivivc/

which could be probably used for your task (do not ask me how, I am not an expert)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mani Maran
> Sent: Sunday, November 19, 2017 11:29 AM
> To: r-help at r-project.org
> Subject: [R] IVIVC EXAMPLE OR program
>
> Dear developer this softwere is very much useful thanks for the everyones
> availability first.
>
> I need the programm to run an IVIVC  for an IR BCS class 2 product.
> I have dissolution upto 45 mins and plasma profile upto 72 hours. For test and
> reference products of pilot study which is actually failed for cmax parameter.
> To predict the upcoming formulations of the same product  with varying
> release rates I need atlease rank order IVIVC program please help me. If
> possible please share example how to compile the data in .csv file.
>
> Thanks in advance.
>
> Regards,
> Manimaran
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From johanlarsson at outlook.com  Wed Nov 15 18:47:04 2017
From: johanlarsson at outlook.com (Johan Larsson)
Date: Wed, 15 Nov 2017 17:47:04 +0000
Subject: [R] [R-pkgs] eulerr 3.0.0
Message-ID: <DB6PR0801MB16222BA118538ADA24459DB1C0290@DB6PR0801MB1622.eurprd08.prod.outlook.com>

Dear R users,

I have just published a major update to my R package eulerr, which constructs and plots area-proportional Euler and Venn diagrams. The new update, version 3.0.0, allows the user to now also plot Euler diagrams using ellipses in addition to circles, which enables accurate diagrams for a wider range of inputs. This is the first software solution that features Euler diagrams with ellipses for more than 3 sets.

For a quick introduction, check out the shiny application for the package at http://jolars.co/eulerr or visit https://CRAN.R-project.org/package=eulerr to learn about the application in detail. You can also read about all the new updates at https://cran.r-project.org/web/packages/eulerr/news.html which also includes updated algorithms for arranging diagrams, ports of existing code to C++, and updates to the default color palettes.

If you are interested in collaborating on the project, please visit the development page at https://github.com/jolars/eulerr 

All the best,
Johan Larsson

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From berwin.turlach at gmail.com  Mon Nov 20 11:36:03 2017
From: berwin.turlach at gmail.com (Berwin A Turlach)
Date: Mon, 20 Nov 2017 18:36:03 +0800
Subject: [R] [FORGED] Re:  tcltk problems
In-Reply-To: <ABB58E4D-954D-4E9D-8D48-57F069E8B218@gmail.com>
References: <7fec5a75-eff8-90c6-797d-13a202bfdeae@auckland.ac.nz>
 <CACxE24ndKV0x3YyiGyvZ+T+Us99pR9OE2UT2ejHiQfUyokku6A@mail.gmail.com>
 <1511022977.4065255.1176920008.023E7F2F@webmail.messagingengine.com>
 <1efdb8fa-0a7a-9dfa-18fd-204d16e55b4a@auckland.ac.nz>
 <ABB58E4D-954D-4E9D-8D48-57F069E8B218@gmail.com>
Message-ID: <20171120183603.691695de@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Peter,

On Sat, 18 Nov 2017 23:20:25 +0100
peter dalgaard <pdalgd at gmail.com> wrote:

> Hum, missed that bit. Looking at the configure script, the only way I
> can see it failing to look in /usr/lib/tcl8.6 is if ${LIBnn} is not
> "lib". Any chance it might be set to lib64?

Well, yes, in an earlier e-mail Rolf said:

    Then I scanned through BldDir/config.log and found:
    LIBnn='lib64'
    (on line 19901 !!!)

But that seems to be the output of the configuration as determined
by ./configure.

The question is why ${LIBnn} is set to this value.  If not through some
environment variable or config.site, the only way I can see that the relevant 
code snippet[1] (lines 3788-3806 of R 3.4.2's configure, quoted below) sets
${LIBnn} to 'lib64' is if /usr/lib64 exist.

This should not be the case on a 64bit Ubuntu machine.  My machine
has /usr/lib, /usr/lib32 and /usr/libx32.  As far as I know, Ubuntu
(and also Debian? But I have not used Debian for a long time) has always
placed its 64bit libraries into /lib and the 32bit libraries
into e.g. /lib32.  And nowadays, one has also /usr/lib/i386-linux-gnu for
32bit libraries and /usr/lib/x86_64-linux-gnu for 64bit libraries.

As far as I can tell, RedHat used /lib for the 32bit libraries
and /lib64 for the 64bit libraries.  And I believe that most (all?) of
R core that were using linux were using RedHat.  But I could be wrong.
Definitely remember that I always found the multiple-architecture part
in "R Installation and Administration" confusing to read as my linux
system had no /lib64 directories. :)

Finally, if ${LIBnn} is set to 'lib' then the relevant code snippet[2] 
(lines 39527-39543 of R 3.4.2's configure, quoted below), would find
tclConfig.sh; regardless on whether it is in /usr/lib
or /usr/lib/tcl8.6.  Of course, if ${LIBnn} is set to 'lib64',
then ./configure will not find tclConfig.sh on an Ubuntu machine.

So Rolf should probably check whether there is a /usr/lib64 directory
on his machine.  If so, why is it there?  Perhaps some other software
installed from source created it? The contents of the directory might give
some clues.  If a /usr/lib64 exist on Rolf's machine, he should probably use
config.site to set ${LIBnn} to 'lib' (line 146 in R 3.4.2's
config.site) so that ./configure can automagically find tclConfig.sh
again......

Cheers,

	Berwin

PS: Who is now wondering whether his 32bit compile of R is actually
using the 64bit version of TCL/TK on his system....  One day I might
find out... :)

[1]
## We need to establish suitable defaults for a 64-bit OS
libnn=lib
case "${host_os}" in
  linux*)
    ## Not all distros use this: some choose to march out of step
    ## Allow for ppc64le (Debian calls ppc64el), powerpc64le ...
    case "${host_cpu}" in
      x86_64|mips64|ppc64*|powerpc64*|sparc64|s390x)
        if test -d /usr/lib64; then
          libnn=lib64
	fi
      ;;
    esac
    ;;
  solaris*)
    ## libnn=lib/sparcv9 ## on 64-bit only, but that's compiler-specific
    ;;
esac
: ${LIBnn=$libnn}

[2]
if test -z "${TCL_CONFIG}"; then
  { $as_echo "$as_me:${as_lineno-$LINENO}: checking for tclConfig.sh in library (sub)directories" >&5
$as_echo_n "checking for tclConfig.sh in library (sub)directories... " >&6; }
if ${r_cv_path_TCL_CONFIG+:} false; then :
  $as_echo_n "(cached) " >&6
else
  for ldir in /usr/local/${LIBnn} /usr/${LIBnn} /${LIBnn} /opt/lib /sw/lib /opt/csw/lib /usr/sfw/lib /opt/freeware/lib; do
  for dir in \
      ${ldir} \
      `ls -d ${ldir}/tcl[8-9].[0-9]* 2>/dev/null | sort -r`; do
    if test -f ${dir}/tclConfig.sh; then
      r_cv_path_TCL_CONFIG="${dir}/tclConfig.sh"
      break 2
    fi
  done
done
fi


From mlathouri at yahoo.gr  Mon Nov 20 12:38:25 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 20 Nov 2017 11:38:25 +0000 (UTC)
Subject: [R] change colour in barplot
References: <1879879839.2879265.1511177905599.ref@mail.yahoo.com>
Message-ID: <1879879839.2879265.1511177905599@mail.yahoo.com>

 Dear all
I know that it is a very simple question but it seems that I cannot change the colour in the bars.
I have the following dataframe:?
A ? ? ? ? ? ? ? ?? B ? ? ? ? ? ? ? ? C ? ? ? ? ? D ? ? ? ?? E ? ? ? ? ? ? ? ? ?? F ? ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ?0.0.24 ? ? ? ?? 152460 ? ? ? ? 474 ? ? ? 5.5 ? ? ?? 612000 ? ? ? ? ? 59061000 ? ? ? 1540313
and here is the script:
setwd("~/Desktop")
emission<-read.csv("emission from land.csv")
attach(emission)
#define the formulas
Emission_from_Land<-A*B*C*DEmission_from_Access_Road<-E*(F/1000000)*CEmissions_from_well<-(G/1000000)*E*C
#combine my outputs into a new dataframe
dat<-cbind(Emission_from_Land, Emission_from_Access_Road, Emissions_from_well_pad)
#plot a barplot
barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE, col=c("blue", "red", "orange"), 
??????? main ="Well Site Construction Emissions", legend.text=c("Land", "Access", "Well"), 
??????? args.legend = list(x="bottom", horiz="TRUE", bty="n", inset=c(-0.5, -0.25)))
When I add the col= argument, the colour changes in the legend but not the actual bars in the plot. I don't know what I am doing wrong. I know that I am missing something but I cannot figure it out.?
I would very much appreciate for your help.?
Many thanks,Maria
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Nov 20 12:53:15 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 Nov 2017 06:53:15 -0500
Subject: [R] change colour in barplot
In-Reply-To: <1879879839.2879265.1511177905599@mail.yahoo.com>
References: <1879879839.2879265.1511177905599.ref@mail.yahoo.com>
 <1879879839.2879265.1511177905599@mail.yahoo.com>
Message-ID: <ff7798b5-67e2-5e67-ff44-f185f804f925@gmail.com>

On 20/11/2017 6:38 AM, Maria Lathouri via R-help wrote:
>   Dear all
> I know that it is a very simple question but it seems that I cannot change the colour in the bars.
> I have the following dataframe:
> A ? ? ? ? ? ? ? ?? B ? ? ? ? ? ? ? ? C ? ? ? ? ? D ? ? ? ?? E ? ? ? ? ? ? ? ? ?? F ? ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ?0.0.24 ? ? ? ?? 152460 ? ? ? ? 474 ? ? ? 5.5 ? ? ?? 612000 ? ? ? ? ? 59061000 ? ? ? 1540313
> and here is the script:
> setwd("~/Desktop")
> emission<-read.csv("emission from land.csv")
> attach(emission)
> #define the formulas
> Emission_from_Land<-A*B*C*DEmission_from_Access_Road<-E*(F/1000000)*CEmissions_from_well<-(G/1000000)*E*C
> #combine my outputs into a new dataframe
> dat<-cbind(Emission_from_Land, Emission_from_Access_Road, Emissions_from_well_pad)
> #plot a barplot
> barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE, col=c("blue", "red", "orange"),
>  ??????? main ="Well Site Construction Emissions", legend.text=c("Land", "Access", "Well"),
>  ??????? args.legend = list(x="bottom", horiz="TRUE", bty="n", inset=c(-0.5, -0.25)))
> When I add the col= argument, the colour changes in the legend but not the actual bars in the plot. I don't know what I am doing wrong. I know that I am missing something but I cannot figure it out.
> I would very much appreciate for your help.

We don't have your data, so we can't reproduce that plot.  But when I do 
the following, I see three colours:

dat <- matrix(1:9, ncol=3)*0.5e9
par(mfrow=c(2,2))
barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE, 
col=c("blue", "red", "orange"),
          main ="Well Site Construction Emissions", 
legend.text=c("Land", "Access", "Well"),
          args.legend = list(x="bottom", horiz="TRUE", bty="n", 
inset=c(-0.5, -0.25)))

So you'll need to give us a reproducible example if you want help.

Duncan Murdoch


From mlathouri at yahoo.gr  Mon Nov 20 13:09:34 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 20 Nov 2017 12:09:34 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBjaGFuZ2UgY29sb3VyIGluIGJhcnBsb3Q=?=
In-Reply-To: <ff7798b5-67e2-5e67-ff44-f185f804f925@gmail.com>
References: <1879879839.2879265.1511177905599.ref@mail.yahoo.com>
 <1879879839.2879265.1511177905599@mail.yahoo.com>
 <ff7798b5-67e2-5e67-ff44-f185f804f925@gmail.com>
Message-ID: <394018881.2934614.1511179774849@mail.yahoo.com>

Dear all,?
I am really sorry for this. I have attached the script and a .csv file with an example.?
Hope this will help.
Many thanks,Maria 

    ???? 11:53 ?.?. ???????, 20 ????????? 2017, ?/? Duncan Murdoch <murdoch.duncan at gmail.com> ??????:
 

 On 20/11/2017 6:38 AM, Maria Lathouri via R-help wrote:
>? Dear all
> I know that it is a very simple question but it seems that I cannot change the colour in the bars.
> I have the following dataframe:
> A ? ? ? ? ? ? ? ?? B ? ? ? ? ? ? ? ? C ? ? ? ? ? D ? ? ? ?? E ? ? ? ? ? ? ? ? ?? F ? ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ?0.0.24 ? ? ? ?? 152460 ? ? ? ? 474 ? ? ? 5.5 ? ? ?? 612000 ? ? ? ? ? 59061000 ? ? ? 1540313
> and here is the script:
> setwd("~/Desktop")
> emission<-read.csv("emission from land.csv")
> attach(emission)
> #define the formulas
> Emission_from_Land<-A*B*C*DEmission_from_Access_Road<-E*(F/1000000)*CEmissions_from_well<-(G/1000000)*E*C
> #combine my outputs into a new dataframe
> dat<-cbind(Emission_from_Land, Emission_from_Access_Road, Emissions_from_well_pad)
> #plot a barplot
> barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE, col=c("blue", "red", "orange"),
>? ??????? main ="Well Site Construction Emissions", legend.text=c("Land", "Access", "Well"),
>? ??????? args.legend = list(x="bottom", horiz="TRUE", bty="n", inset=c(-0.5, -0.25)))
> When I add the col= argument, the colour changes in the legend but not the actual bars in the plot. I don't know what I am doing wrong. I know that I am missing something but I cannot figure it out.
> I would very much appreciate for your help.

We don't have your data, so we can't reproduce that plot.? But when I do 
the following, I see three colours:

dat <- matrix(1:9, ncol=3)*0.5e9
par(mfrow=c(2,2))
barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE, 
col=c("blue", "red", "orange"),
? ? ? ? ? main ="Well Site Construction Emissions", 
legend.text=c("Land", "Access", "Well"),
? ? ? ? ? args.legend = list(x="bottom", horiz="TRUE", bty="n", 
inset=c(-0.5, -0.25)))

So you'll need to give us a reproducible example if you want help.

Duncan Murdoch


   

From murdoch.duncan at gmail.com  Mon Nov 20 13:27:24 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 Nov 2017 07:27:24 -0500
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBjaGFuZ2UgY29sb3VyIGluIGJhcnBsb3Q=?=
In-Reply-To: <394018881.2934614.1511179774849@mail.yahoo.com>
References: <1879879839.2879265.1511177905599.ref@mail.yahoo.com>
 <1879879839.2879265.1511177905599@mail.yahoo.com>
 <ff7798b5-67e2-5e67-ff44-f185f804f925@gmail.com>
 <394018881.2934614.1511179774849@mail.yahoo.com>
Message-ID: <d060f1de-512c-3279-d788-aecaa31460d3@gmail.com>

On 20/11/2017 7:09 AM, Maria Lathouri wrote:
> Dear all,
> 
> I am really sorry for this. I have attached the script and a .csv file
> with an example.

The problem is that you have dat as a matrix with only one row.
barplot() applies the colours to the rows of dat; since you have only 
one row, everything ends up blue.

You can fix this by creating dat as a vector using

dat<-c(Emission_from_Land, Emission_from_Access_Road,
            Emissions_from_well_pad)

or by using "beside = TRUE" in the arguments to barplot.  These will 
give similar but slightly different results; I don't know which one is 
better for you, but I like the vector solution better.

Duncan Murdoch

> 
> Hope this will help.
> 
> Many thanks,
> Maria
> 
> 
> ???? 11:53 ?.?. ???????, 20 ????????? 2017, ?/? Duncan Murdoch 
> <murdoch.duncan at gmail.com> ??????:
> 
> 
> On 20/11/2017 6:38 AM, Maria Lathouri via R-help wrote:
>  >? Dear all
>  > I know that it is a very simple question but it seems that I cannot 
> change the colour in the bars.
>  > I have the following dataframe:
>  > A ? ? ? ? ? ? ? ?? B ? ? ? ? ? ? ? ? C ? ? ? ? ? D ? ? ? ?? E         
>  ? ? ? ? ?? F ? ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ?0.0.24 ? ? ? ?? 152460 
>  ? ? ? ? 474 ? ? ? 5.5 ? ? ?? 612000 ? ? ? ? ? 59061000 ? ? ? 1540313
>  > and here is the script:
>  > setwd("~/Desktop")
>  > emission<-read.csv("emission from land.csv")
>  > attach(emission)
>  > #define the formulas
>  > 
> Emission_from_Land<-A*B*C*DEmission_from_Access_Road<-E*(F/1000000)*CEmissions_from_well<-(G/1000000)*E*C
>  > #combine my outputs into a new dataframe
>  > dat<-cbind(Emission_from_Land, Emission_from_Access_Road, 
> Emissions_from_well_pad)
>  > #plot a barplot
>  > barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), 
> axisnames=FALSE, col=c("blue", "red", "orange"),
>  >? ??????? main ="Well Site Construction Emissions", 
> legend.text=c("Land", "Access", "Well"),
>  >? ??????? args.legend = list(x="bottom", horiz="TRUE", bty="n", 
> inset=c(-0.5, -0.25)))
>  > When I add the col= argument, the colour changes in the legend but 
> not the actual bars in the plot. I don't know what I am doing wrong. I 
> know that I am missing something but I cannot figure it out.
>  > I would very much appreciate for your help.
> 
> We don't have your data, so we can't reproduce that plot.? But when I do
> the following, I see three colours:
> 
> dat <- matrix(1:9, ncol=3)*0.5e9
> par(mfrow=c(2,2))
> 
> barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE,
> col=c("blue", "red", "orange"),
>  ? ? ? ? ? main ="Well Site Construction Emissions",
> legend.text=c("Land", "Access", "Well"),
>  ? ? ? ? ? args.legend = list(x="bottom", horiz="TRUE", bty="n",
> inset=c(-0.5, -0.25)))
> 
> 
> So you'll need to give us a reproducible example if you want help.
> 
> Duncan Murdoch
> 
> 
>


From mlathouri at yahoo.gr  Mon Nov 20 13:43:39 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 20 Nov 2017 12:43:39 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6IM6jz4fOtc+EOiAgY2hhbmdlIGNvbG91ciBp?=
 =?utf-8?q?n_barplot?=
In-Reply-To: <d060f1de-512c-3279-d788-aecaa31460d3@gmail.com>
References: <1879879839.2879265.1511177905599.ref@mail.yahoo.com>
 <1879879839.2879265.1511177905599@mail.yahoo.com>
 <ff7798b5-67e2-5e67-ff44-f185f804f925@gmail.com>
 <394018881.2934614.1511179774849@mail.yahoo.com>
 <d060f1de-512c-3279-d788-aecaa31460d3@gmail.com>
Message-ID: <1284636001.2984580.1511181819237@mail.yahoo.com>

Dear Duncan
Many thanks for this; actually the vector solution works much better.?
Best,?Maria 

    ???? 12:27 ?.?. ???????, 20 ????????? 2017, ?/? Duncan Murdoch <murdoch.duncan at gmail.com> ??????:
 

 On 20/11/2017 7:09 AM, Maria Lathouri wrote:
> Dear all,
> 
> I am really sorry for this. I have attached the script and a .csv file
> with an example.

The problem is that you have dat as a matrix with only one row.
barplot() applies the colours to the rows of dat; since you have only 
one row, everything ends up blue.

You can fix this by creating dat as a vector using

dat<-c(Emission_from_Land, Emission_from_Access_Road,
? ? ? ? ? ? Emissions_from_well_pad)

or by using "beside = TRUE" in the arguments to barplot.? These will 
give similar but slightly different results; I don't know which one is 
better for you, but I like the vector solution better.

Duncan Murdoch

> 
> Hope this will help.
> 
> Many thanks,
> Maria
> 
> 
> ???? 11:53 ?.?. ???????, 20 ????????? 2017, ?/? Duncan Murdoch 
> <murdoch.duncan at gmail.com> ??????:
> 
> 
> On 20/11/2017 6:38 AM, Maria Lathouri via R-help wrote:
>? >? Dear all
>? > I know that it is a very simple question but it seems that I cannot 
> change the colour in the bars.
>? > I have the following dataframe:
>? > A ? ? ? ? ? ? ? ?? B ? ? ? ? ? ? ? ? C ? ? ? ? ? D ? ? ? ?? E? ? ? ? 
>? ? ? ? ? ?? F ? ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ?0.0.24 ? ? ? ?? 152460 
>? ? ? ? ? 474 ? ? ? 5.5 ? ? ?? 612000 ? ? ? ? ? 59061000 ? ? ? 1540313
>? > and here is the script:
>? > setwd("~/Desktop")
>? > emission<-read.csv("emission from land.csv")
>? > attach(emission)
>? > #define the formulas
>? > 
> Emission_from_Land<-A*B*C*DEmission_from_Access_Road<-E*(F/1000000)*CEmissions_from_well<-(G/1000000)*E*C
>? > #combine my outputs into a new dataframe
>? > dat<-cbind(Emission_from_Land, Emission_from_Access_Road, 
> Emissions_from_well_pad)
>? > #plot a barplot
>? > barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), 
> axisnames=FALSE, col=c("blue", "red", "orange"),
>? >? ??????? main ="Well Site Construction Emissions", 
> legend.text=c("Land", "Access", "Well"),
>? >? ??????? args.legend = list(x="bottom", horiz="TRUE", bty="n", 
> inset=c(-0.5, -0.25)))
>? > When I add the col= argument, the colour changes in the legend but 
> not the actual bars in the plot. I don't know what I am doing wrong. I 
> know that I am missing something but I cannot figure it out.
>? > I would very much appreciate for your help.
> 
> We don't have your data, so we can't reproduce that plot.? But when I do
> the following, I see three colours:
> 
> dat <- matrix(1:9, ncol=3)*0.5e9
> par(mfrow=c(2,2))
> 
> barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE,
> col=c("blue", "red", "orange"),
>? ? ? ? ? ? main ="Well Site Construction Emissions",
> legend.text=c("Land", "Access", "Well"),
>? ? ? ? ? ? args.legend = list(x="bottom", horiz="TRUE", bty="n",
> inset=c(-0.5, -0.25)))
> 
> 
> So you'll need to give us a reproducible example if you want help.
> 
> Duncan Murdoch
> 
> 
> 



   
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Nov 20 15:47:12 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 20 Nov 2017 06:47:12 -0800
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBjaGFuZ2UgY29sb3VyIGluIGJhcnBsb3Q=?=
In-Reply-To: <394018881.2934614.1511179774849@mail.yahoo.com>
References: <1879879839.2879265.1511177905599.ref@mail.yahoo.com>
 <1879879839.2879265.1511177905599@mail.yahoo.com>
 <ff7798b5-67e2-5e67-ff44-f185f804f925@gmail.com>
 <394018881.2934614.1511179774849@mail.yahoo.com>
Message-ID: <D2D4C7BC-1D73-4B6B-8A4F-ABB947762B36@dcn.davis.ca.us>

Just so you know, your attachments were stripped on the mailing list both times. It was your direct cc to Duncan that allowed him to see your attachments. Please avoid using attachments in the future, and if you must anyway then read the Posting Guide about which MIME type attachments are allowed so others can contribute to the discussion and benefit from the exchange you do have. (You can verify how your email/attachments came through by reading it on the mailing list archives.)
-- 
Sent from my phone. Please excuse my brevity.

On November 20, 2017 4:09:34 AM PST, Maria Lathouri via R-help <r-help at r-project.org> wrote:
>Dear all,?
>I am really sorry for this. I have attached the script and a .csv file
>with an example.?
>Hope this will help.
>Many thanks,Maria 
>
>???? 11:53 ?.?. ???????, 20 ????????? 2017, ?/? Duncan Murdoch
><murdoch.duncan at gmail.com> ??????:
> 
>
> On 20/11/2017 6:38 AM, Maria Lathouri via R-help wrote:
>>? Dear all
>> I know that it is a very simple question but it seems that I cannot
>change the colour in the bars.
>> I have the following dataframe:
>> A ? ? ? ? ? ? ? ?? B ? ? ? ? ? ? ? ? C ? ? ? ? ? D ? ? ? ?? E ? ? ? ?
>? ? ? ? ?? F ? ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ?0.0.24 ? ? ? ?? 152460
>? ? ? ? 474 ? ? ? 5.5 ? ? ?? 612000 ? ? ? ? ? 59061000 ? ? ? 1540313
>> and here is the script:
>> setwd("~/Desktop")
>> emission<-read.csv("emission from land.csv")
>> attach(emission)
>> #define the formulas
>>
>Emission_from_Land<-A*B*C*DEmission_from_Access_Road<-E*(F/1000000)*CEmissions_from_well<-(G/1000000)*E*C
>> #combine my outputs into a new dataframe
>> dat<-cbind(Emission_from_Land, Emission_from_Access_Road,
>Emissions_from_well_pad)
>> #plot a barplot
>> barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10),
>axisnames=FALSE, col=c("blue", "red", "orange"),
>>? ??????? main ="Well Site Construction Emissions",
>legend.text=c("Land", "Access", "Well"),
>>? ??????? args.legend = list(x="bottom", horiz="TRUE", bty="n",
>inset=c(-0.5, -0.25)))
>> When I add the col= argument, the colour changes in the legend but
>not the actual bars in the plot. I don't know what I am doing wrong. I
>know that I am missing something but I cannot figure it out.
>> I would very much appreciate for your help.
>
>We don't have your data, so we can't reproduce that plot.? But when I
>do 
>the following, I see three colours:
>
>dat <- matrix(1:9, ncol=3)*0.5e9
>par(mfrow=c(2,2))
>barplot(dat, ylab="Kg-CO2 Eq", ylim=c(0.0e+00, 2e+10), axisnames=FALSE,
>
>col=c("blue", "red", "orange"),
>? ? ? ? ? main ="Well Site Construction Emissions", 
>legend.text=c("Land", "Access", "Well"),
>? ? ? ? ? args.legend = list(x="bottom", horiz="TRUE", bty="n", 
>inset=c(-0.5, -0.25)))
>
>So you'll need to give us a reproducible example if you want help.
>
>Duncan Murdoch
>
>
>   
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kevbleakley at gmail.com  Mon Nov 20 16:27:44 2017
From: kevbleakley at gmail.com (kevin bleakley)
Date: Mon, 20 Nov 2017 16:27:44 +0100
Subject: [R] Cursor lag: Mac High Sierra, R 3.4.2, Macbook Air 2017
Message-ID: <CAGtqQu_jOxvM6iUdW=fAyHSzjwfmv_Y8PK5042-r723EnnPrJA@mail.gmail.com>

Hi,

I'm running High Sierra on a new "2017" Macbook Air.  I upgraded R from a
previous version (3.2 or 3.3 ?) and now there is a huge lag on the curser
in the R command window itself and in script files. I am not using RStudio.

There is a page on GitHub detailing the same problem currently when using
Rstudio. I have no idea whether this problem is related or not.

Cheers
Kevin

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Nov 21 03:39:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 20 Nov 2017 18:39:03 -0800
Subject: [R] Cursor lag: Mac High Sierra, R 3.4.2, Macbook Air 2017
In-Reply-To: <CAGtqQu_jOxvM6iUdW=fAyHSzjwfmv_Y8PK5042-r723EnnPrJA@mail.gmail.com>
References: <CAGtqQu_jOxvM6iUdW=fAyHSzjwfmv_Y8PK5042-r723EnnPrJA@mail.gmail.com>
Message-ID: <CD137BB1-7C80-4245-8AE5-B8E1B10C0B85@dcn.davis.ca.us>

This is an excellent example of a question that would be appropriate for the R-sig-mac mailing list. Do read the Posting Guide. 
-- 
Sent from my phone. Please excuse my brevity.

On November 20, 2017 7:27:44 AM PST, kevin bleakley <kevbleakley at gmail.com> wrote:
>Hi,
>
>I'm running High Sierra on a new "2017" Macbook Air.  I upgraded R from
>a
>previous version (3.2 or 3.3 ?) and now there is a huge lag on the
>curser
>in the R command window itself and in script files. I am not using
>RStudio.
>
>There is a page on GitHub detailing the same problem currently when
>using
>Rstudio. I have no idea whether this problem is related or not.
>
>Cheers
>Kevin
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From joerodonnell at gmail.com  Tue Nov 21 07:02:04 2017
From: joerodonnell at gmail.com (Joe O)
Date: Mon, 20 Nov 2017 23:02:04 -0700
Subject: [R] Do I need to transform backtest returns before using pbo
 (probability of backtest overfitting) package functions?
Message-ID: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>

Hello,

I'm trying to understand how to use the pbo package by looking at a
vignette. I'm curious about a part of the vignette that creates simulated
returns data. The package author transforms his simulated returns in a way
that I'm unfamiliar with, and that I haven't been able to find an
explanation for after searching around. I'm curious if I need to replicate
the transformation with real returns. For context, here is the vignette
(cleaned up a bit to make it reproducible):

(Full vignette:
https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)

library(pbo)
#First, we assemble the trials into an NxT matrix where each column
#represents a trial and each trial has the same length T. This example
#is random data so the backtest should be overfit.`

set.seed(765)
n <- 100
t <- 2400
m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
                       dimnames=list(1:t,1:n)), check.names=FALSE)

sr_base <- 0
mu_base <- sr_base/(252.0)
sigma_base <- 1.00/(252.0)**0.5
for ( i in 1:n ) {
  m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
  m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
#We can use any performance evaluation function that can work with the
#reassembled sub-matrices during the cross validation iterations.
#Following the original paper we can use the Sharpe ratio as

sharpe <- function(x,rf=0.03/252) {
  sr <- apply(x,2,function(col) {
    er = col - rf
    return(mean(er)/sd(er))
  })
  return(sr)}
#Now that we have the trials matrix we can pass it to the pbo function
 #for analysis.

my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)

summary(my_pbo)

Here's the portion i'm curious about:

sr_base <- 0
mu_base <- sr_base/(252.0)
sigma_base <- 1.00/(252.0)**0.5
for ( i in 1:n ) {
  m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
  m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}

Why is the data transformed within the for loop, and does this kind of
re-scaling and re-centering need to be done with real returns? Or is this
just something the author is doing to make his simulated returns look more
like the real thing?

Googling around turned up some articles regarding scaling volatility to the
square root of time, but the scaling in the code here doesn't look quite
like what I've seen. Re-scalings I've seen involve multiplying some short
term (i.e. daily) measure of volatility by the root of time, but this isn't
quite that. Also, the documentation for the package doesn't include this
chunk of re-scaling and re-centering code. Documentation: https://cran.r-
project.org/web/packages/pbo/pbo.pdf

So:

   -

   Why is the data transformed in this way/what is result of this
   transformation?
   -

   Is it only necessary for this simulated data, or do I need to
   similarly transform real returns?

I read in the posting guide that stats questions are acceptable given
certain conditions, I hope this counts. Thanks for reading,

-Joe

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov 21 13:10:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 21 Nov 2017 04:10:14 -0800
Subject: [R] Do I need to transform backtest returns before using pbo
 (probability of backtest overfitting) package functions?
In-Reply-To: <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
References: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>
 <CAGxFJbT3CN_ex=NHQf5EXwgtzR=24xBd-iua+kb-ugS41FBZ6A@mail.gmail.com>
 <CAGxFJbROLCqAzu2BSpiAX1JvBvrhPcQZdU8YQC-64KO-3KzL9g@mail.gmail.com>
 <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
Message-ID: <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>

Wrong list.

Post on r-sig-finance instead.

Cheers,
Bert



On Nov 20, 2017 11:25 PM, "Joe O" <joerodonnell at gmail.com> wrote:

Hello,

I'm trying to understand how to use the pbo package by looking at a
vignette. I'm curious about a part of the vignette that creates simulated
returns data. The package author transforms his simulated returns in a way
that I'm unfamiliar with, and that I haven't been able to find an
explanation for after searching around. I'm curious if I need to replicate
the transformation with real returns. For context, here is the vignette
(cleaned up a bit to make it reproducible):

(Full vignette:
https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)

library(pbo)
#First, we assemble the trials into an NxT matrix where each column
#represents a trial and each trial has the same length T. This example
#is random data so the backtest should be overfit.`

set.seed(765)
n <- 100
t <- 2400
m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
                       dimnames=list(1:t,1:n)), check.names=FALSE)

sr_base <- 0
mu_base <- sr_base/(252.0)
sigma_base <- 1.00/(252.0)**0.5
for ( i in 1:n ) {
  m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
  m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
#We can use any performance evaluation function that can work with the
#reassembled sub-matrices during the cross validation iterations.
#Following the original paper we can use the Sharpe ratio as

sharpe <- function(x,rf=0.03/252) {
  sr <- apply(x,2,function(col) {
    er = col - rf
    return(mean(er)/sd(er))
  })
  return(sr)}
#Now that we have the trials matrix we can pass it to the pbo function
 #for analysis.

my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)

summary(my_pbo)

Here's the portion i'm curious about:

sr_base <- 0
mu_base <- sr_base/(252.0)
sigma_base <- 1.00/(252.0)**0.5
for ( i in 1:n ) {
  m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
  m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}

Why is the data transformed within the for loop, and does this kind of
re-scaling and re-centering need to be done with real returns? Or is this
just something the author is doing to make his simulated returns look more
like the real thing?

Googling around turned up some articles regarding scaling volatility to the
square root of time, but the scaling in the code here doesn't look quite
like what I've seen. Re-scalings I've seen involve multiplying some short
term (i.e. daily) measure of volatility by the root of time, but this isn't
quite that. Also, the documentation for the package doesn't include this
chunk of re-scaling and re-centering code. Documentation: https://cran.r-
project.org/web/packages/pbo/pbo.pdf

So:

   -

   Why is the data transformed in this way/what is result of this
   transformation?
   -

   Is it only necessary for this simulated data, or do I need to
   similarly transform real returns?

I read in the posting guide that stats questions are acceptable given
certain conditions, I hope this counts. Thanks for reading,

-Joe

<http://www.avg.com/email-signature?utm_medium=email&
utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&
utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Nov 21 13:33:04 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 21 Nov 2017 14:33:04 +0200
Subject: [R] Do I need to transform backtest returns before using pbo
 (probability of backtest overfitting) package functions?
In-Reply-To: <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>
References: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>
 <CAGxFJbT3CN_ex=NHQf5EXwgtzR=24xBd-iua+kb-ugS41FBZ6A@mail.gmail.com>
 <CAGxFJbROLCqAzu2BSpiAX1JvBvrhPcQZdU8YQC-64KO-3KzL9g@mail.gmail.com>
 <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
 <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>
Message-ID: <CAGgJW74SsEgfn2i1qHBP2ZPiR3iwcgXBNL2M4Lv-23M02q=e7Q@mail.gmail.com>

Hi Joe,
The centering and re-scaling is done for the purposes of his example, and
also to be consistent with his definition of the sharpe function.
In particular, note that the sharpe function has the rf (riskfree)
parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
to a DAILY rate, expressed in decimal.
That means that the other argument to this function, x, should be DAILY
returns, expressed in decimal.

Suppose he wanted to create random data from a distribution of returns with
ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in decimal.
The equivalent DAILY

Then he does two steps: (1) generate a matrix of random values from the
N(0,1) distribution. (2) convert them to DAILY
After initializing the matrix with random values (from N(0,1)), he now
wants to create a series of DAILY
sr_base <- 0
mu_base <- sr_base/(252.0)
sigma_base <- 1.00/(252.0)**0.5
for ( i in 1:n ) {
  m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
  m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}

On Tue, Nov 21, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Wrong list.
>
> Post on r-sig-finance instead.
>
> Cheers,
> Bert
>
>
>
> On Nov 20, 2017 11:25 PM, "Joe O" <joerodonnell at gmail.com> wrote:
>
> Hello,
>
> I'm trying to understand how to use the pbo package by looking at a
> vignette. I'm curious about a part of the vignette that creates simulated
> returns data. The package author transforms his simulated returns in a way
> that I'm unfamiliar with, and that I haven't been able to find an
> explanation for after searching around. I'm curious if I need to replicate
> the transformation with real returns. For context, here is the vignette
> (cleaned up a bit to make it reproducible):
>
> (Full vignette:
> https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)
>
> library(pbo)
> #First, we assemble the trials into an NxT matrix where each column
> #represents a trial and each trial has the same length T. This example
> #is random data so the backtest should be overfit.`
>
> set.seed(765)
> n <- 100
> t <- 2400
> m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
>                        dimnames=list(1:t,1:n)), check.names=FALSE)
>
> sr_base <- 0
> mu_base <- sr_base/(252.0)
> sigma_base <- 1.00/(252.0)**0.5
> for ( i in 1:n ) {
>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
> #We can use any performance evaluation function that can work with the
> #reassembled sub-matrices during the cross validation iterations.
> #Following the original paper we can use the Sharpe ratio as
>
> sharpe <- function(x,rf=0.03/252) {
>   sr <- apply(x,2,function(col) {
>     er = col - rf
>     return(mean(er)/sd(er))
>   })
>   return(sr)}
> #Now that we have the trials matrix we can pass it to the pbo function
>  #for analysis.
>
> my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)
>
> summary(my_pbo)
>
> Here's the portion i'm curious about:
>
> sr_base <- 0
> mu_base <- sr_base/(252.0)
> sigma_base <- 1.00/(252.0)**0.5
> for ( i in 1:n ) {
>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>
> Why is the data transformed within the for loop, and does this kind of
> re-scaling and re-centering need to be done with real returns? Or is this
> just something the author is doing to make his simulated returns look more
> like the real thing?
>
> Googling around turned up some articles regarding scaling volatility to the
> square root of time, but the scaling in the code here doesn't look quite
> like what I've seen. Re-scalings I've seen involve multiplying some short
> term (i.e. daily) measure of volatility by the root of time, but this isn't
> quite that. Also, the documentation for the package doesn't include this
> chunk of re-scaling and re-centering code. Documentation: https://cran.r-
> project.org/web/packages/pbo/pbo.pdf
>
> So:
>
>    -
>
>    Why is the data transformed in this way/what is result of this
>    transformation?
>    -
>
>    Is it only necessary for this simulated data, or do I need to
>    similarly transform real returns?
>
> I read in the posting guide that stats questions are acceptable given
> certain conditions, I hope this counts. Thanks for reading,
>
> -Joe
>
> <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From yadavneog at gmail.com  Tue Nov 21 09:48:08 2017
From: yadavneog at gmail.com (yadav neog)
Date: Tue, 21 Nov 2017 14:18:08 +0530
Subject: [R] help
Message-ID: <CACdLcRxP1L8CXrjMjAp+_2039LyNe-aZmFvY9oXbAMH_V+2UTA@mail.gmail.com>

I am working on  Johansen cointegration test,  using urca and var package.
in the selection of var, I have got following results.

>VARselect(newd, lag.max = 10,type = "none")

$selection
AIC(n)  HQ(n)  SC(n) FPE(n)
     6      6      6      5

$criteria
                   1             2             3             4
 5    6    7    8    9
AIC(n) -3.818646e+01 -3.864064e+01 -3.833435e+01 -4.089169e+01
 NaN -Inf -Inf -Inf -Inf
HQ(n)  -3.754345e+01 -3.744647e+01 -3.658903e+01 -3.859523e+01
 NaN -Inf -Inf -Inf -Inf
SC(n)  -3.630096e+01 -3.513899e+01 -3.321655e+01 -3.415775e+01
 NaN -Inf -Inf -Inf -Inf
FPE(n)  2.700145e-17  2.114513e-17  5.350381e-17  2.035215e-17
-9.147714e-65    0    0    0    0
         10
AIC(n) -Inf
HQ(n)  -Inf
SC(n)  -Inf
FPE(n)    0

Warning messages:
1: In log(sigma.det) : NaNs produced
2: In log(sigma.det) : NaNs produced
3: In log(sigma.det) : NaNs produced

so do in my ca.jo test... I have found similar NaNs results. please help me
in solving the problem.
Yadawananda Neog
Research Scholar
Department of Economics
Banaras Hindu University
Mob. 9838545073

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Nov 21 13:36:15 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 21 Nov 2017 14:36:15 +0200
Subject: [R] Do I need to transform backtest returns before using pbo
 (probability of backtest overfitting) package functions?
In-Reply-To: <CAGgJW74SsEgfn2i1qHBP2ZPiR3iwcgXBNL2M4Lv-23M02q=e7Q@mail.gmail.com>
References: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>
 <CAGxFJbT3CN_ex=NHQf5EXwgtzR=24xBd-iua+kb-ugS41FBZ6A@mail.gmail.com>
 <CAGxFJbROLCqAzu2BSpiAX1JvBvrhPcQZdU8YQC-64KO-3KzL9g@mail.gmail.com>
 <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
 <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>
 <CAGgJW74SsEgfn2i1qHBP2ZPiR3iwcgXBNL2M4Lv-23M02q=e7Q@mail.gmail.com>
Message-ID: <CAGgJW77o2EOVGVbrOOhn103KOkp4BotK_gYeZxgAx36Hwdr2bA@mail.gmail.com>

[re-sending - previous email went out by accident before complete]
Hi Joe,
The centering and re-scaling is done for the purposes of his example, and
also to be consistent with his definition of the sharpe function.
In particular, note that the sharpe function has the rf (riskfree)
parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
to a DAILY rate, expressed in decimal.
That means that the other argument to this function, x, should be DAILY
returns, expressed in decimal.

Suppose he wanted to create random data from a distribution of returns with
ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in decimal.
The equivalent DAILY returns would have mean MU_D = MU_A / 252 and standard
deviation SIGMA_D =  SIGMA_A/SQRT(252).

He calls MU_D by the name mu_base  and  SIGMA_D by the name sigma_base.

His loop now converts the random numbers in his matrix so that each column
has mean MU_D and std deviation SIGMA_D.

HTH,
Eric



On Tue, Nov 21, 2017 at 2:33 PM, Eric Berger <ericjberger at gmail.com> wrote:

> Hi Joe,
> The centering and re-scaling is done for the purposes of his example, and
> also to be consistent with his definition of the sharpe function.
> In particular, note that the sharpe function has the rf (riskfree)
> parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
> to a DAILY rate, expressed in decimal.
> That means that the other argument to this function, x, should be DAILY
> returns, expressed in decimal.
>
> Suppose he wanted to create random data from a distribution of returns
> with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in
> decimal.
> The equivalent DAILY
>
> Then he does two steps: (1) generate a matrix of random values from the
> N(0,1) distribution. (2) convert them to DAILY
> After initializing the matrix with random values (from N(0,1)), he now
> wants to create a series of DAILY
> sr_base <- 0
> mu_base <- sr_base/(252.0)
> sigma_base <- 1.00/(252.0)**0.5
> for ( i in 1:n ) {
>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>
> On Tue, Nov 21, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Wrong list.
>>
>> Post on r-sig-finance instead.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> On Nov 20, 2017 11:25 PM, "Joe O" <joerodonnell at gmail.com> wrote:
>>
>> Hello,
>>
>> I'm trying to understand how to use the pbo package by looking at a
>> vignette. I'm curious about a part of the vignette that creates simulated
>> returns data. The package author transforms his simulated returns in a way
>> that I'm unfamiliar with, and that I haven't been able to find an
>> explanation for after searching around. I'm curious if I need to replicate
>> the transformation with real returns. For context, here is the vignette
>> (cleaned up a bit to make it reproducible):
>>
>> (Full vignette:
>> https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)
>>
>> library(pbo)
>> #First, we assemble the trials into an NxT matrix where each column
>> #represents a trial and each trial has the same length T. This example
>> #is random data so the backtest should be overfit.`
>>
>> set.seed(765)
>> n <- 100
>> t <- 2400
>> m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
>>                        dimnames=list(1:t,1:n)), check.names=FALSE)
>>
>> sr_base <- 0
>> mu_base <- sr_base/(252.0)
>> sigma_base <- 1.00/(252.0)**0.5
>> for ( i in 1:n ) {
>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>> #We can use any performance evaluation function that can work with the
>> #reassembled sub-matrices during the cross validation iterations.
>> #Following the original paper we can use the Sharpe ratio as
>>
>> sharpe <- function(x,rf=0.03/252) {
>>   sr <- apply(x,2,function(col) {
>>     er = col - rf
>>     return(mean(er)/sd(er))
>>   })
>>   return(sr)}
>> #Now that we have the trials matrix we can pass it to the pbo function
>>  #for analysis.
>>
>> my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)
>>
>> summary(my_pbo)
>>
>> Here's the portion i'm curious about:
>>
>> sr_base <- 0
>> mu_base <- sr_base/(252.0)
>> sigma_base <- 1.00/(252.0)**0.5
>> for ( i in 1:n ) {
>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>
>> Why is the data transformed within the for loop, and does this kind of
>> re-scaling and re-centering need to be done with real returns? Or is this
>> just something the author is doing to make his simulated returns look more
>> like the real thing?
>>
>> Googling around turned up some articles regarding scaling volatility to
>> the
>> square root of time, but the scaling in the code here doesn't look quite
>> like what I've seen. Re-scalings I've seen involve multiplying some short
>> term (i.e. daily) measure of volatility by the root of time, but this
>> isn't
>> quite that. Also, the documentation for the package doesn't include this
>> chunk of re-scaling and re-centering code. Documentation: https://cran.r-
>> project.org/web/packages/pbo/pbo.pdf
>>
>> So:
>>
>>    -
>>
>>    Why is the data transformed in this way/what is result of this
>>    transformation?
>>    -
>>
>>    Is it only necessary for this simulated data, or do I need to
>>    similarly transform real returns?
>>
>> I read in the posting guide that stats questions are acceptable given
>> certain conditions, I hope this counts. Thanks for reading,
>>
>> -Joe
>>
>> <http://www.avg.com/email-signature?utm_medium=email&
>> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>> Virus-free.
>> www.avg.com
>> <http://www.avg.com/email-signature?utm_medium=email&
>> utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>> >
>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Nov 21 16:43:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Nov 2017 07:43:30 -0800
Subject: [R] help
In-Reply-To: <CACdLcRxP1L8CXrjMjAp+_2039LyNe-aZmFvY9oXbAMH_V+2UTA@mail.gmail.com>
References: <CACdLcRxP1L8CXrjMjAp+_2039LyNe-aZmFvY9oXbAMH_V+2UTA@mail.gmail.com>
Message-ID: <09347715-3E3A-4243-98CB-94992098028D@dcn.davis.ca.us>

Your example is incomplete... as the bottom of this and every post says, we need to be able to proceed from an empty R environment to wherever you are having the problem (reproducible), in as few steps as possible (minimal). The example needs to include data, preferably in R syntax as the dput function creates... see the howtos referenced below for help with that.  [1], [2], [3]

You also need to set your email program to send plain text format, since HTML gets mangled to various degrees as it gets forced into text format going through the mailing list. Read the Posting Guide. 

A wild guess is that you have negative values in your data or too few data points...

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On November 21, 2017 12:48:08 AM PST, yadav neog <yadavneog at gmail.com> wrote:
>I am working on  Johansen cointegration test,  using urca and var
>package.
>in the selection of var, I have got following results.
>
>>VARselect(newd, lag.max = 10,type = "none")
>
>$selection
>AIC(n)  HQ(n)  SC(n) FPE(n)
>     6      6      6      5
>
>$criteria
>                   1             2             3             4
> 5    6    7    8    9
>AIC(n) -3.818646e+01 -3.864064e+01 -3.833435e+01 -4.089169e+01
> NaN -Inf -Inf -Inf -Inf
>HQ(n)  -3.754345e+01 -3.744647e+01 -3.658903e+01 -3.859523e+01
> NaN -Inf -Inf -Inf -Inf
>SC(n)  -3.630096e+01 -3.513899e+01 -3.321655e+01 -3.415775e+01
> NaN -Inf -Inf -Inf -Inf
>FPE(n)  2.700145e-17  2.114513e-17  5.350381e-17  2.035215e-17
>-9.147714e-65    0    0    0    0
>         10
>AIC(n) -Inf
>HQ(n)  -Inf
>SC(n)  -Inf
>FPE(n)    0
>
>Warning messages:
>1: In log(sigma.det) : NaNs produced
>2: In log(sigma.det) : NaNs produced
>3: In log(sigma.det) : NaNs produced
>
>so do in my ca.jo test... I have found similar NaNs results. please
>help me
>in solving the problem.
>Yadawananda Neog
>Research Scholar
>Department of Economics
>Banaras Hindu University
>Mob. 9838545073
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From muthu.psg.swift at gmail.com  Tue Nov 21 16:13:33 2017
From: muthu.psg.swift at gmail.com (muthu m)
Date: Tue, 21 Nov 2017 15:13:33 +0000
Subject: [R] R-How to unlist data frame multiple structured list column
 value and new column
Message-ID: <BM1PR0101MB16669D1EC1E90A1A53C25D4EE9230@BM1PR0101MB1666.INDPRD01.PROD.OUTLOOK.COM>

Hi,

How to unlist  list column value and add column into data frame.

Data frame

ID      ContractDe                                                                       PassengersDe                                                    TrainnerDe

  1      list(ConID=c("Zx","78yu"),ConRes = c("98","Tut"))                             list(PassID =1,PassIt="Lits,uy")                         list(Trnid=1,Trncont =5,EmpAddInfo=list(list(CohID ="pi",InVoice=77)))

  2      list(ConID=c("Half","Yut","Weq"),ConRes =c("ref","Cr"))                       list(PassID =c("pfil","Q"),Name ="Tic",PassIt="S5,Y1     list(Trnid=7,Trncont =3,EmpAddInfo=list(list(CohID =c("AB","NI","OL"),InVoice = c("4","Y"))))

  3      list(ConID=c("Ui","pric"),ConRes = c("Num","Patch"))                          list(PassID =1,PassIt ="St,Bp")                          list(Trnid=c("U", "l"),Trncont=c("10","78"),EmpAddInfo=list(list(CohID =c("AB","NI","OL"),InVoice =c("4","Y"))))

  4      list(ConID=c("2","7","IO"),ConRes = c("Res","Qty"),ConVal =c("Wno", "ip"))    list(PassID =1,Name ="RT",Name1 ="RR",PassIt="st7,st9")  list(Trnid=c("1", "3"),Trncont=c("yt","re"),EmpAddInfo=list(list(CohID =c("Ly","qp"),InVoice =c("2","P"))))





Expected data frame.

ID   ConID         ConRes    ConVal     PassID       PassIt    Name   Name1     Trnid    Trncont    CohID    InVoice

 1   Zx,78yu       98,Tut     NA          1          Lits,uy    NA     NA         1        5         pi         77

 2   Half,Yut,Weq  ref,Cr     NA          pfil,Q     S5,Y1      Tic    NA         7        3       AB,NI,OL     4,Y

 3   Ui,pric       Num,Patch  NA           1         St,Bp      NA     NA         U,l    10,78     AB,NI,OL     4,Y

 4   2,7,IO        Res,Qty    Wno,ip       1         st7,st9    RT     st7,st9     1,3   yt,re       Ly,qp      2,P



dput


structure(list(ID = c("1", "2", "3","4"), ContractDe = list(
    structure(list(ConID = c("Zx", "78yu"), ConRes = c("98",
    "Tut")), .Names = c("ConID", "ConRes"), class = "data.frame", row.names = 1:2),
    structure(list(ConID = c("Half", "Yut","Weq"), ConRes = c("ref",
    "Cr")), .Names = c("ConID", "ConRes"), class = "data.frame", row.names = 1:2),
structure(list(ConID = c("Ui", "pric"), ConRes = c("Num",
    "Patch")), .Names = c("ConID", "ConRes"), class = "data.frame", row.names = 1:2),
    structure(list(ConID = c("2", "7","IO"), ConRes = c("Res",
    "Qty"),ConVal=c("Wno","ip")), .Names = c("ConID", "ConRes","ConVal"), class = "data.frame", row.names = 1:2)),
    PassengersDe = list(structure(list(PassID = 1, PassIt = "Lits, uy"), .Names = c("PassID",
    "PassIt"), class = "data.frame", row.names = 1L), structure(list(
        PassID = c("pfil","Q"), Name = "Tic", PassIt = "S5, Y1"), .Names = c("PassID",
    "Name", "PassIt"), class = "data.frame", row.names = 1L),
structure(list(PassID = 1, PassIt = "St, Bp"), .Names = c("PassID",
    "PassIt"), class = "data.frame", row.names = 1L),
structure(list(PassID = 1, Name = "RT", Name1 = "RR", PassIt = "st7, st9"), .Names = c("PassID",
    "Name", "Name1", "PassIt"), class = "data.frame", row.names = 1L)),
    TrainnerDe = list(structure(list(Trnid = 1, Trncont = 5, EmpAddInfo = list(
        structure(list(CohID = "pi", InVoice = 77), .Names = c("CohID",
        "InVoice"), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
    "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L),
        structure(list(Trnid =7,Trncont = 3, EmpAddInfo = list(structure(list(
            CohID = c("AB", "NI", "OL"), InVoice = c("4", "Y")), .Names = c("CohID",
        "InVoice"), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
        "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L),
structure(list(Trnid =c("U","l"),Trncont =c("10","78"), EmpAddInfo = list(structure(list(
            CohID = c("AB", "NI", "OL"), InVoice = c("4", "Y")), .Names = c("CohID",
        "InVoice"), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
        "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L),
        structure(list(Trnid = c("1","3"), Trncont = c("yt","re"), EmpAddInfo = list(structure(list(
            CohID = c("Ly","qp"), InVoice = c("2","P")), .Names = c("CohID", "InVoice"
        ), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
        "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L))), .Names = c("ID",
"ContractDe", "PassengersDe", "TrainnerDe"), row.names = c(NA, 4L), class = "data.frame")


i was stuck on this change part of my project, please help me to out this. Thanks.



Sent from Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From yadavneog at gmail.com  Tue Nov 21 17:15:11 2017
From: yadavneog at gmail.com (yadav neog)
Date: Tue, 21 Nov 2017 21:45:11 +0530
Subject: [R] help
In-Reply-To: <09347715-3E3A-4243-98CB-94992098028D@dcn.davis.ca.us>
References: <CACdLcRxP1L8CXrjMjAp+_2039LyNe-aZmFvY9oXbAMH_V+2UTA@mail.gmail.com>
 <09347715-3E3A-4243-98CB-94992098028D@dcn.davis.ca.us>
Message-ID: <CACdLcRy=2Mvwp_P21f5QoEZzTRWQftJskY47WNm71A_HS-znVg@mail.gmail.com>

thank you for your valuable reply. I  have attached my commands, results, and
data with this mail..maybe it will be beneficial for you to feedback.

On Tue, Nov 21, 2017 at 9:13 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Your example is incomplete... as the bottom of this and every post says,
> we need to be able to proceed from an empty R environment to wherever you
> are having the problem (reproducible), in as few steps as possible
> (minimal). The example needs to include data, preferably in R syntax as the
> dput function creates... see the howtos referenced below for help with
> that.  [1], [2], [3]
>
> You also need to set your email program to send plain text format, since
> HTML gets mangled to various degrees as it gets forced into text format
> going through the mailing list. Read the Posting Guide.
>
> A wild guess is that you have negative values in your data or too few data
> points...
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-
> a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the
> vignette)
> --
> Sent from my phone. Please excuse my brevity.
>
> On November 21, 2017 12:48:08 AM PST, yadav neog <yadavneog at gmail.com>
> wrote:
> >I am working on  Johansen cointegration test,  using urca and var
> >package.
> >in the selection of var, I have got following results.
> >
> >>VARselect(newd, lag.max = 10,type = "none")
> >
> >$selection
> >AIC(n)  HQ(n)  SC(n) FPE(n)
> >     6      6      6      5
> >
> >$criteria
> >                   1             2             3             4
> > 5    6    7    8    9
> >AIC(n) -3.818646e+01 -3.864064e+01 -3.833435e+01 -4.089169e+01
> > NaN -Inf -Inf -Inf -Inf
> >HQ(n)  -3.754345e+01 -3.744647e+01 -3.658903e+01 -3.859523e+01
> > NaN -Inf -Inf -Inf -Inf
> >SC(n)  -3.630096e+01 -3.513899e+01 -3.321655e+01 -3.415775e+01
> > NaN -Inf -Inf -Inf -Inf
> >FPE(n)  2.700145e-17  2.114513e-17  5.350381e-17  2.035215e-17
> >-9.147714e-65    0    0    0    0
> >         10
> >AIC(n) -Inf
> >HQ(n)  -Inf
> >SC(n)  -Inf
> >FPE(n)    0
> >
> >Warning messages:
> >1: In log(sigma.det) : NaNs produced
> >2: In log(sigma.det) : NaNs produced
> >3: In log(sigma.det) : NaNs produced
> >
> >so do in my ca.jo test... I have found similar NaNs results. please
> >help me
> >in solving the problem.
> >Yadawananda Neog
> >Research Scholar
> >Department of Economics
> >Banaras Hindu University
> >Mob. 9838545073
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>



-- 
Yadawananda Neog
Research Scholar
Department of Economics
Banaras Hindu University
Mob. 9838545073

From dwinsemius at comcast.net  Tue Nov 21 18:32:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Nov 2017 09:32:05 -0800
Subject: [R] help
In-Reply-To: <CACdLcRy=2Mvwp_P21f5QoEZzTRWQftJskY47WNm71A_HS-znVg@mail.gmail.com>
References: <CACdLcRxP1L8CXrjMjAp+_2039LyNe-aZmFvY9oXbAMH_V+2UTA@mail.gmail.com>
 <09347715-3E3A-4243-98CB-94992098028D@dcn.davis.ca.us>
 <CACdLcRy=2Mvwp_P21f5QoEZzTRWQftJskY47WNm71A_HS-znVg@mail.gmail.com>
Message-ID: <2DB82AF3-7E41-410E-8A2B-0D278DB63FC6@comcast.net>


> On Nov 21, 2017, at 8:15 AM, yadav neog <yadavneog at gmail.com> wrote:
> 
> thank you for your valuable reply. I  have attached my commands, results, and
> data with this mail..maybe it will be beneficial for you to feedback.

If you had read the Posting Guide (and lsitinfo), you should have noted the special requirements regarding  attachments. The only person who received your attachments was Jeff. So you are essentially at his mercy regarding how he handles private communications.

-- 
David.


> 
> On Tue, Nov 21, 2017 at 9:13 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> Your example is incomplete... as the bottom of this and every post says,
>> we need to be able to proceed from an empty R environment to wherever you
>> are having the problem (reproducible), in as few steps as possible
>> (minimal). The example needs to include data, preferably in R syntax as the
>> dput function creates... see the howtos referenced below for help with
>> that.  [1], [2], [3]
>> 
>> You also need to set your email program to send plain text format, since
>> HTML gets mangled to various degrees as it gets forced into text format
>> going through the mailing list. Read the Posting Guide.
>> 
>> A wild guess is that you have negative values in your data or too few data
>> points...
>> 
>> [1] http://stackoverflow.com/questions/5963269/how-to-make-
>> a-great-r-reproducible-example
>> 
>> [2] http://adv-r.had.co.nz/Reproducibility.html
>> 
>> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the
>> vignette)
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On November 21, 2017 12:48:08 AM PST, yadav neog <yadavneog at gmail.com>
>> wrote:
>>> I am working on  Johansen cointegration test,  using urca and var
>>> package.
>>> in the selection of var, I have got following results.
>>> 
>>>> VARselect(newd, lag.max = 10,type = "none")
>>> 
>>> $selection
>>> AIC(n)  HQ(n)  SC(n) FPE(n)
>>>    6      6      6      5
>>> 
>>> $criteria
>>>                  1             2             3             4
>>> 5    6    7    8    9
>>> AIC(n) -3.818646e+01 -3.864064e+01 -3.833435e+01 -4.089169e+01
>>> NaN -Inf -Inf -Inf -Inf
>>> HQ(n)  -3.754345e+01 -3.744647e+01 -3.658903e+01 -3.859523e+01
>>> NaN -Inf -Inf -Inf -Inf
>>> SC(n)  -3.630096e+01 -3.513899e+01 -3.321655e+01 -3.415775e+01
>>> NaN -Inf -Inf -Inf -Inf
>>> FPE(n)  2.700145e-17  2.114513e-17  5.350381e-17  2.035215e-17
>>> -9.147714e-65    0    0    0    0
>>>        10
>>> AIC(n) -Inf
>>> HQ(n)  -Inf
>>> SC(n)  -Inf
>>> FPE(n)    0
>>> 
>>> Warning messages:
>>> 1: In log(sigma.det) : NaNs produced
>>> 2: In log(sigma.det) : NaNs produced
>>> 3: In log(sigma.det) : NaNs produced
>>> 
>>> so do in my ca.jo test... I have found similar NaNs results. please
>>> help me
>>> in solving the problem.
>>> Yadawananda Neog
>>> Research Scholar
>>> Department of Economics
>>> Banaras Hindu University
>>> Mob. 9838545073
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil at dcn.davis.ca.us  Tue Nov 21 18:56:26 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Nov 2017 09:56:26 -0800
Subject: [R] help
In-Reply-To: <CACdLcRy=2Mvwp_P21f5QoEZzTRWQftJskY47WNm71A_HS-znVg@mail.gmail.com>
References: <CACdLcRxP1L8CXrjMjAp+_2039LyNe-aZmFvY9oXbAMH_V+2UTA@mail.gmail.com>
 <09347715-3E3A-4243-98CB-94992098028D@dcn.davis.ca.us>
 <CACdLcRy=2Mvwp_P21f5QoEZzTRWQftJskY47WNm71A_HS-znVg@mail.gmail.com>
Message-ID: <47F87693-051A-42F3-A4CC-7A0237AD90C5@dcn.davis.ca.us>

Microsoft Word documents are inappropriate, and attachments almost always get stripped by the mailing list.

Please read the referenced information this time before trying again, and especially the Posting Guide. 
-- 
Sent from my phone. Please excuse my brevity.

On November 21, 2017 8:15:11 AM PST, yadav neog <yadavneog at gmail.com> wrote:
>thank you for your valuable reply. I  have attached my commands,
>results, and
>data with this mail..maybe it will be beneficial for you to feedback.
>
>On Tue, Nov 21, 2017 at 9:13 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Your example is incomplete... as the bottom of this and every post
>says,
>> we need to be able to proceed from an empty R environment to wherever
>you
>> are having the problem (reproducible), in as few steps as possible
>> (minimal). The example needs to include data, preferably in R syntax
>as the
>> dput function creates... see the howtos referenced below for help
>with
>> that.  [1], [2], [3]
>>
>> You also need to set your email program to send plain text format,
>since
>> HTML gets mangled to various degrees as it gets forced into text
>format
>> going through the mailing list. Read the Posting Guide.
>>
>> A wild guess is that you have negative values in your data or too few
>data
>> points...
>>
>> [1] http://stackoverflow.com/questions/5963269/how-to-make-
>> a-great-r-reproducible-example
>>
>> [2] http://adv-r.had.co.nz/Reproducibility.html
>>
>> [3] https://cran.r-project.org/web/packages/reprex/index.html (read
>the
>> vignette)
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 21, 2017 12:48:08 AM PST, yadav neog
><yadavneog at gmail.com>
>> wrote:
>> >I am working on  Johansen cointegration test,  using urca and var
>> >package.
>> >in the selection of var, I have got following results.
>> >
>> >>VARselect(newd, lag.max = 10,type = "none")
>> >
>> >$selection
>> >AIC(n)  HQ(n)  SC(n) FPE(n)
>> >     6      6      6      5
>> >
>> >$criteria
>> >                   1             2             3             4
>> > 5    6    7    8    9
>> >AIC(n) -3.818646e+01 -3.864064e+01 -3.833435e+01 -4.089169e+01
>> > NaN -Inf -Inf -Inf -Inf
>> >HQ(n)  -3.754345e+01 -3.744647e+01 -3.658903e+01 -3.859523e+01
>> > NaN -Inf -Inf -Inf -Inf
>> >SC(n)  -3.630096e+01 -3.513899e+01 -3.321655e+01 -3.415775e+01
>> > NaN -Inf -Inf -Inf -Inf
>> >FPE(n)  2.700145e-17  2.114513e-17  5.350381e-17  2.035215e-17
>> >-9.147714e-65    0    0    0    0
>> >         10
>> >AIC(n) -Inf
>> >HQ(n)  -Inf
>> >SC(n)  -Inf
>> >FPE(n)    0
>> >
>> >Warning messages:
>> >1: In log(sigma.det) : NaNs produced
>> >2: In log(sigma.det) : NaNs produced
>> >3: In log(sigma.det) : NaNs produced
>> >
>> >so do in my ca.jo test... I have found similar NaNs results. please
>> >help me
>> >in solving the problem.
>> >Yadawananda Neog
>> >Research Scholar
>> >Department of Economics
>> >Banaras Hindu University
>> >Mob. 9838545073
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>


From sarah.goslee at gmail.com  Tue Nov 21 19:12:06 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 21 Nov 2017 13:12:06 -0500
Subject: [R] How to produce rainfall maps
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F471AE0D5@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F471AE00E@ESINO.regionemarche.intra>
 <8B435C9568170B469AE31E8891E8CC4F471AE0D5@ESINO.regionemarche.intra>
Message-ID: <CAM_vjunToO=sqFWPRRYcWJTL9AOh_3TBnNpcORo+oN-ZGhGR_w@mail.gmail.com>

Hi,

You might get more help from the R-sig-geo list, which is devoted to
spatial topics.

However.

The *.asc file is an ArcGIS raster export format. You should use
whatever the appropriate import commands are for your own gridded
rainfall data. If you have a different format, you might or might not
be able to import it directly with raster.

?raster will tell you more about the kinds of formats that function
can handle importing.

I'm not sure what the intent of converting a raster to point data
actually is; if you have point data, then import it as point data. If
you have gridded data, then map it as gridded data. But if it makes
sense to you, then go for it.

The comments in your code sample explain what the CSV file should be:
coordinates of the points to be mapped.

I'm not even certain from your question what your objective is.

What kind of rainfall data are you starting with?
What kind of maps do you want to produce?

Sarah



On Fri, Nov 17, 2017 at 3:40 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R users,
> I need to produce rainfall maps using R.
> I know that this is possible, I looked though the web, I found the example below reported (the author is Andrew Tredennick).
> I would ask you if this is the most performing way to make rainfall maps; if yes would someone be able to give me an example of how file.asc and pointfile.csv should be? If no would somebody please show me another way providing a small example?
>
> Thank you for your help
> Stefano
>
>
> library(raster)
> library(ggplot2)
>
> #open ASCII file using ?raster? command, which converts the ASCII to a raster object
> map <- raster(?/your/path/to/file.asc?)
>
> #convert the raster to points for plotting
> map.p <- rasterToPoints(map)
>
> #Make the points a dataframe for ggplot
> df <- data.frame(map.p)
> #Make appropriate column headings
> colnames(df) <- c(?Longitude?, ?Latitude?, ?MAP?)
>
> #Call in point data, in this case a fake transect (csv file with lat and lon coordinates)
> sites <- data.frame(read.csv(?/your/path/to/pointfile.csv?))
>
> #Now make the map
> ggplot(data=df, aes(y=Latitude, x=Longitude)) +
> geom_raster(aes(fill=MAP)) +
> geom_point(data=sites, aes(x=x, y=y), color=?white?, size=3, shape=4) +
> theme_bw() +
> coord_equal() +
> scale_fill_gradient(?MAP (mm/yr)?, limits=c(0,2500)) +
> theme(axis.title.x = element_text(size=16),
> axis.title.y = element_text(size=16, angle=90),
> axis.text.x = element_text(size=14),
> axis.text.y = element_text(size=14),
> panel.grid.major = element_blank(),
> panel.grid.minor = element_blank(),
> legend.position = ?right?,
> legend.key = element_blank()
> )
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From iwritecode2 at gmail.com  Tue Nov 21 20:14:45 2017
From: iwritecode2 at gmail.com (Robert Wilkins)
Date: Tue, 21 Nov 2017 14:14:45 -0500
Subject: [R] Best way to study internals of R ( mix of C, C++, Fortran,
	and R itself)?
Message-ID: <CAGW5CW92nEXgGm2Cs0SD56PfQRCmy_i_vnf9MprH=bQ6JPPy=g@mail.gmail.com>

How difficult is it to get a good feel for the internals of R, if you want
to learn the general code base, but also the CPU intensive stuff ( much of
it in C or Fortran?) and the ways in which the general code and the CPU
intensive stuff is connected together?

R has a very large audience, but my understanding is that only a small
group have a good understanding of the internals (and some of those will
eventually move on to something else in their career, or retire
altogether).

While I'm at it, a second question: 15 years ago, nobody would ever offer a
job based on R skills ( SAS, yes, SPSS, maybe, but R skills, year after
year, did not imply job offers). How much has that changed, both for R and
for NumPy/Pandas/SciPy ?

thanks in advance

Robert

	[[alternative HTML version deleted]]


From joerodonnell at gmail.com  Tue Nov 21 21:42:24 2017
From: joerodonnell at gmail.com (Joe O)
Date: Tue, 21 Nov 2017 13:42:24 -0700
Subject: [R] Do I need to transform backtest returns before using pbo
 (probability of backtest overfitting) package functions?
In-Reply-To: <CAGgJW77o2EOVGVbrOOhn103KOkp4BotK_gYeZxgAx36Hwdr2bA@mail.gmail.com>
References: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>
 <CAGxFJbT3CN_ex=NHQf5EXwgtzR=24xBd-iua+kb-ugS41FBZ6A@mail.gmail.com>
 <CAGxFJbROLCqAzu2BSpiAX1JvBvrhPcQZdU8YQC-64KO-3KzL9g@mail.gmail.com>
 <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
 <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>
 <CAGgJW74SsEgfn2i1qHBP2ZPiR3iwcgXBNL2M4Lv-23M02q=e7Q@mail.gmail.com>
 <CAGgJW77o2EOVGVbrOOhn103KOkp4BotK_gYeZxgAx36Hwdr2bA@mail.gmail.com>
Message-ID: <CA+BE2NO+yD9WaD9DQ7Ec+77ruiqyOsY+bMJ8fRh-KYoMTYVUYg@mail.gmail.com>

Hi Eric,

Thank you, that helps a lot. If I'm understanding correctly, if I?m wanting
to use actual returns from backtests rather than simulated returns, I would
need to make sure my risk-adjusted return measure, sharpe ratio in this
case, matches up in scale with my returns (i.e. daily returns with daily
sharpe, monthly with monthly, etc). And I wouldn?t need to transform
returns like the simulated returns are in the vignette, as the real returns
are going to have whatever properties they have (meaning they will have
whatever average and std dev they happen to have). Is that correct?

Thanks, -Joe


On Tue, Nov 21, 2017 at 5:36 AM, Eric Berger <ericjberger at gmail.com> wrote:

> [re-sending - previous email went out by accident before complete]
> Hi Joe,
> The centering and re-scaling is done for the purposes of his example, and
> also to be consistent with his definition of the sharpe function.
> In particular, note that the sharpe function has the rf (riskfree)
> parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
> to a DAILY rate, expressed in decimal.
> That means that the other argument to this function, x, should be DAILY
> returns, expressed in decimal.
>
> Suppose he wanted to create random data from a distribution of returns
> with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in
> decimal.
> The equivalent DAILY returns would have mean MU_D = MU_A / 252 and
> standard deviation SIGMA_D =  SIGMA_A/SQRT(252).
>
> He calls MU_D by the name mu_base  and  SIGMA_D by the name sigma_base.
>
> His loop now converts the random numbers in his matrix so that each column
> has mean MU_D and std deviation SIGMA_D.
>
> HTH,
> Eric
>
>
>
> On Tue, Nov 21, 2017 at 2:33 PM, Eric Berger <ericjberger at gmail.com>
> wrote:
>
>> Hi Joe,
>> The centering and re-scaling is done for the purposes of his example, and
>> also to be consistent with his definition of the sharpe function.
>> In particular, note that the sharpe function has the rf (riskfree)
>> parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
>> to a DAILY rate, expressed in decimal.
>> That means that the other argument to this function, x, should be DAILY
>> returns, expressed in decimal.
>>
>> Suppose he wanted to create random data from a distribution of returns
>> with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in
>> decimal.
>> The equivalent DAILY
>>
>> Then he does two steps: (1) generate a matrix of random values from the
>> N(0,1) distribution. (2) convert them to DAILY
>> After initializing the matrix with random values (from N(0,1)), he now
>> wants to create a series of DAILY
>> sr_base <- 0
>> mu_base <- sr_base/(252.0)
>> sigma_base <- 1.00/(252.0)**0.5
>> for ( i in 1:n ) {
>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>
>> On Tue, Nov 21, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> Wrong list.
>>>
>>> Post on r-sig-finance instead.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>> On Nov 20, 2017 11:25 PM, "Joe O" <joerodonnell at gmail.com> wrote:
>>>
>>> Hello,
>>>
>>> I'm trying to understand how to use the pbo package by looking at a
>>> vignette. I'm curious about a part of the vignette that creates simulated
>>> returns data. The package author transforms his simulated returns in a
>>> way
>>> that I'm unfamiliar with, and that I haven't been able to find an
>>> explanation for after searching around. I'm curious if I need to
>>> replicate
>>> the transformation with real returns. For context, here is the vignette
>>> (cleaned up a bit to make it reproducible):
>>>
>>> (Full vignette:
>>> https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)
>>>
>>> library(pbo)
>>> #First, we assemble the trials into an NxT matrix where each column
>>> #represents a trial and each trial has the same length T. This example
>>> #is random data so the backtest should be overfit.`
>>>
>>> set.seed(765)
>>> n <- 100
>>> t <- 2400
>>> m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
>>>                        dimnames=list(1:t,1:n)), check.names=FALSE)
>>>
>>> sr_base <- 0
>>> mu_base <- sr_base/(252.0)
>>> sigma_base <- 1.00/(252.0)**0.5
>>> for ( i in 1:n ) {
>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>> #We can use any performance evaluation function that can work with the
>>> #reassembled sub-matrices during the cross validation iterations.
>>> #Following the original paper we can use the Sharpe ratio as
>>>
>>> sharpe <- function(x,rf=0.03/252) {
>>>   sr <- apply(x,2,function(col) {
>>>     er = col - rf
>>>     return(mean(er)/sd(er))
>>>   })
>>>   return(sr)}
>>> #Now that we have the trials matrix we can pass it to the pbo function
>>>  #for analysis.
>>>
>>> my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)
>>>
>>> summary(my_pbo)
>>>
>>> Here's the portion i'm curious about:
>>>
>>> sr_base <- 0
>>> mu_base <- sr_base/(252.0)
>>> sigma_base <- 1.00/(252.0)**0.5
>>> for ( i in 1:n ) {
>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>>
>>> Why is the data transformed within the for loop, and does this kind of
>>> re-scaling and re-centering need to be done with real returns? Or is this
>>> just something the author is doing to make his simulated returns look
>>> more
>>> like the real thing?
>>>
>>> Googling around turned up some articles regarding scaling volatility to
>>> the
>>> square root of time, but the scaling in the code here doesn't look quite
>>> like what I've seen. Re-scalings I've seen involve multiplying some short
>>> term (i.e. daily) measure of volatility by the root of time, but this
>>> isn't
>>> quite that. Also, the documentation for the package doesn't include this
>>> chunk of re-scaling and re-centering code. Documentation:
>>> https://cran.r-
>>> project.org/web/packages/pbo/pbo.pdf
>>>
>>> So:
>>>
>>>    -
>>>
>>>    Why is the data transformed in this way/what is result of this
>>>    transformation?
>>>    -
>>>
>>>    Is it only necessary for this simulated data, or do I need to
>>>    similarly transform real returns?
>>>
>>> I read in the posting guide that stats questions are acceptable given
>>> certain conditions, I hope this counts. Thanks for reading,
>>>
>>> -Joe
>>>
>>> <http://www.avg.com/email-signature?utm_medium=email&
>>> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>> Virus-free.
>>> www.avg.com
>>> <http://www.avg.com/email-signature?utm_medium=email&
>>> utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>> >
>>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From naras at stanford.edu  Tue Nov 21 18:53:04 2017
From: naras at stanford.edu (Balasubramanian Narasimhan)
Date: Tue, 21 Nov 2017 09:53:04 -0800
Subject: [R] [R-pkgs] CVXR: Convex Programming in R
Message-ID: <2dc989fa-4338-a16f-7572-cb8321cff0d3@stanford.edu>

Dear R Users,

We are pleased to announce the first release of CVXR which implements 
Disciplined Convex Programming (DCP) in R on CRAN. Like CVXPY in Python, 
CVXR provides a domain specific language for formulating 
convexoptimization problems in a natural way following mathematical 
convention and DCP rules. The system analyzes the problem, verifies its 
convexity, converts it into a canonical form, and hands it off to an 
appropriate solver to obtain the solution.

Applications of convex programming are described in a paper available at

https://stanford.edu/~boyd/papers/pdf/cvxr_paper.pdf 
<https://stanford.edu/%7Eboyd/papers/pdf/cvxr_paper.pdf> .

An introductory vignette is included in the package.? A number of 
further examples are available at https://cvxr.rbind.io.

We welcome your feedback and issues on Github ( 
https://github.com/anqif/CVXR ).

--

Anqi Fu, Balasubramanian Narasimhan, Stephen Boyd

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From ericjberger at gmail.com  Tue Nov 21 22:17:42 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 21 Nov 2017 23:17:42 +0200
Subject: [R] Do I need to transform backtest returns before using pbo
	(probability of backtest overfitting) package functions?
In-Reply-To: <CA+BE2NO+yD9WaD9DQ7Ec+77ruiqyOsY+bMJ8fRh-KYoMTYVUYg@mail.gmail.com>
References: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>
 <CAGxFJbT3CN_ex=NHQf5EXwgtzR=24xBd-iua+kb-ugS41FBZ6A@mail.gmail.com>
 <CAGxFJbROLCqAzu2BSpiAX1JvBvrhPcQZdU8YQC-64KO-3KzL9g@mail.gmail.com>
 <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
 <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>
 <CAGgJW74SsEgfn2i1qHBP2ZPiR3iwcgXBNL2M4Lv-23M02q=e7Q@mail.gmail.com>
 <CAGgJW77o2EOVGVbrOOhn103KOkp4BotK_gYeZxgAx36Hwdr2bA@mail.gmail.com>
 <CA+BE2NO+yD9WaD9DQ7Ec+77ruiqyOsY+bMJ8fRh-KYoMTYVUYg@mail.gmail.com>
Message-ID: <EE5E3CF2-9603-49FE-B6B6-0AD6E8FD8B65@gmail.com>

Correct 

Sent from my iPhone

> On 21 Nov 2017, at 22:42, Joe O <joerodonnell at gmail.com> wrote:
> 
> Hi Eric,
> 
> Thank you, that helps a lot. If I'm understanding correctly, if I?m wanting to use actual returns from backtests rather than simulated returns, I would need to make sure my risk-adjusted return measure, sharpe ratio in this case, matches up in scale with my returns (i.e. daily returns with daily sharpe, monthly with monthly, etc). And I wouldn?t need to transform returns like the simulated returns are in the vignette, as the real returns are going to have whatever properties they have (meaning they will have whatever average and std dev they happen to have). Is that correct? 
> 
> Thanks, -Joe
> 
> 
>> On Tue, Nov 21, 2017 at 5:36 AM, Eric Berger <ericjberger at gmail.com> wrote:
>> [re-sending - previous email went out by accident before complete]
>> Hi Joe,
>> The centering and re-scaling is done for the purposes of his example, and also to be consistent with his definition of the sharpe function.
>> In particular, note that the sharpe function has the rf (riskfree) parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted to a DAILY rate, expressed in decimal.
>> That means that the other argument to this function, x, should be DAILY returns, expressed in decimal.
>> 
>> Suppose he wanted to create random data from a distribution of returns with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in decimal. 
>> The equivalent DAILY returns would have mean MU_D = MU_A / 252 and standard deviation SIGMA_D =  SIGMA_A/SQRT(252).
>> 
>> He calls MU_D by the name mu_base  and  SIGMA_D by the name sigma_base.
>> 
>> His loop now converts the random numbers in his matrix so that each column has mean MU_D and std deviation SIGMA_D.
>> 
>> HTH,
>> Eric
>> 
>> 
>> 
>>> On Tue, Nov 21, 2017 at 2:33 PM, Eric Berger <ericjberger at gmail.com> wrote:
>>> Hi Joe,
>>> The centering and re-scaling is done for the purposes of his example, and also to be consistent with his definition of the sharpe function.
>>> In particular, note that the sharpe function has the rf (riskfree) parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted to a DAILY rate, expressed in decimal.
>>> That means that the other argument to this function, x, should be DAILY returns, expressed in decimal.
>>> 
>>> Suppose he wanted to create random data from a distribution of returns with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in decimal. 
>>> The equivalent DAILY
>>> 
>>> Then he does two steps: (1) generate a matrix of random values from the N(0,1) distribution. (2) convert them to DAILY
>>> After initializing the matrix with random values (from N(0,1)), he now wants to create a series of DAILY
>>> sr_base <- 0
>>> mu_base <- sr_base/(252.0)
>>> sigma_base <- 1.00/(252.0)**0.5
>>> for ( i in 1:n ) {
>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>> 
>>>> On Tue, Nov 21, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> Wrong list.
>>>> 
>>>> Post on r-sig-finance instead.
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> 
>>>> 
>>>> On Nov 20, 2017 11:25 PM, "Joe O" <joerodonnell at gmail.com> wrote:
>>>> 
>>>> Hello,
>>>> 
>>>> I'm trying to understand how to use the pbo package by looking at a
>>>> vignette. I'm curious about a part of the vignette that creates simulated
>>>> returns data. The package author transforms his simulated returns in a way
>>>> that I'm unfamiliar with, and that I haven't been able to find an
>>>> explanation for after searching around. I'm curious if I need to replicate
>>>> the transformation with real returns. For context, here is the vignette
>>>> (cleaned up a bit to make it reproducible):
>>>> 
>>>> (Full vignette:
>>>> https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)
>>>> 
>>>> library(pbo)
>>>> #First, we assemble the trials into an NxT matrix where each column
>>>> #represents a trial and each trial has the same length T. This example
>>>> #is random data so the backtest should be overfit.`
>>>> 
>>>> set.seed(765)
>>>> n <- 100
>>>> t <- 2400
>>>> m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
>>>>                        dimnames=list(1:t,1:n)), check.names=FALSE)
>>>> 
>>>> sr_base <- 0
>>>> mu_base <- sr_base/(252.0)
>>>> sigma_base <- 1.00/(252.0)**0.5
>>>> for ( i in 1:n ) {
>>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>>> #We can use any performance evaluation function that can work with the
>>>> #reassembled sub-matrices during the cross validation iterations.
>>>> #Following the original paper we can use the Sharpe ratio as
>>>> 
>>>> sharpe <- function(x,rf=0.03/252) {
>>>>   sr <- apply(x,2,function(col) {
>>>>     er = col - rf
>>>>     return(mean(er)/sd(er))
>>>>   })
>>>>   return(sr)}
>>>> #Now that we have the trials matrix we can pass it to the pbo function
>>>>  #for analysis.
>>>> 
>>>> my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)
>>>> 
>>>> summary(my_pbo)
>>>> 
>>>> Here's the portion i'm curious about:
>>>> 
>>>> sr_base <- 0
>>>> mu_base <- sr_base/(252.0)
>>>> sigma_base <- 1.00/(252.0)**0.5
>>>> for ( i in 1:n ) {
>>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>>> 
>>>> Why is the data transformed within the for loop, and does this kind of
>>>> re-scaling and re-centering need to be done with real returns? Or is this
>>>> just something the author is doing to make his simulated returns look more
>>>> like the real thing?
>>>> 
>>>> Googling around turned up some articles regarding scaling volatility to the
>>>> square root of time, but the scaling in the code here doesn't look quite
>>>> like what I've seen. Re-scalings I've seen involve multiplying some short
>>>> term (i.e. daily) measure of volatility by the root of time, but this isn't
>>>> quite that. Also, the documentation for the package doesn't include this
>>>> chunk of re-scaling and re-centering code. Documentation: https://cran.r-
>>>> project.org/web/packages/pbo/pbo.pdf
>>>> 
>>>> So:
>>>> 
>>>>    -
>>>> 
>>>>    Why is the data transformed in this way/what is result of this
>>>>    transformation?
>>>>    -
>>>> 
>>>>    Is it only necessary for this simulated data, or do I need to
>>>>    similarly transform real returns?
>>>> 
>>>> I read in the posting guide that stats questions are acceptable given
>>>> certain conditions, I hope this counts. Thanks for reading,
>>>> 
>>>> -Joe
>>>> 
>>>> <http://www.avg.com/email-signature?utm_medium=email&
>>>> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>>> Virus-free.
>>>> www.avg.com
>>>> <http://www.avg.com/email-signature?utm_medium=email&
>>>> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Nov 21 22:19:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Nov 2017 13:19:16 -0800
Subject: [R] Best way to study internals of R ( mix of C, C++, Fortran,
	and R itself)?
In-Reply-To: <CAGW5CW92nEXgGm2Cs0SD56PfQRCmy_i_vnf9MprH=bQ6JPPy=g@mail.gmail.com>
References: <CAGW5CW92nEXgGm2Cs0SD56PfQRCmy_i_vnf9MprH=bQ6JPPy=g@mail.gmail.com>
Message-ID: <8A1956C4-B753-4F50-962D-803C09366065@dcn.davis.ca.us>

1) What is easy for one person may be very hard for another, so your question is really unanswerable. You do need to know C and Fortran to get through the source code. Get started soon reading the R Internals document if it sounds interesting to you... you are bound to learn something even if you don't stick with it. If you have questions about the internals though, you should read the Posting Guide to find out where to ask them (hint: not here).

2) There are lots of blogs and surveys out there about how R's popularity has increased over time, though Python seems to have higher billing in job descriptions I have seen. Generally if you know multiple tools and the underlying theory you are working with then you are more likely to succeed, so don't limit yourself by dismissing R for reasons of comparative popularity.
-- 
Sent from my phone. Please excuse my brevity.

On November 21, 2017 11:14:45 AM PST, Robert Wilkins <iwritecode2 at gmail.com> wrote:
>How difficult is it to get a good feel for the internals of R, if you
>want
>to learn the general code base, but also the CPU intensive stuff ( much
>of
>it in C or Fortran?) and the ways in which the general code and the CPU
>intensive stuff is connected together?
>
>R has a very large audience, but my understanding is that only a small
>group have a good understanding of the internals (and some of those
>will
>eventually move on to something else in their career, or retire
>altogether).
>
>While I'm at it, a second question: 15 years ago, nobody would ever
>offer a
>job based on R skills ( SAS, yes, SPSS, maybe, but R skills, year after
>year, did not imply job offers). How much has that changed, both for R
>and
>for NumPy/Pandas/SciPy ?
>
>thanks in advance
>
>Robert
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From joerodonnell at gmail.com  Tue Nov 21 22:19:32 2017
From: joerodonnell at gmail.com (Joe O)
Date: Tue, 21 Nov 2017 14:19:32 -0700
Subject: [R] Do I need to transform backtest returns before using pbo
 (probability of backtest overfitting) package functions?
In-Reply-To: <EE5E3CF2-9603-49FE-B6B6-0AD6E8FD8B65@gmail.com>
References: <CA+BE2NMkjDP00rMvSUYAAf8-Ocq-mD8ke1-RyPcZNPZAvYQQCQ@mail.gmail.com>
 <CAGxFJbT3CN_ex=NHQf5EXwgtzR=24xBd-iua+kb-ugS41FBZ6A@mail.gmail.com>
 <CAGxFJbROLCqAzu2BSpiAX1JvBvrhPcQZdU8YQC-64KO-3KzL9g@mail.gmail.com>
 <CAGxFJbRk5Uw6v2D-wGnpMfWOqx4P3EwqL=1J_9QC7_xj7a_jcg@mail.gmail.com>
 <CAGxFJbSxWBf2utPipWh=AqoGJREytS5OWWD9bdkUcKOdHfxqHQ@mail.gmail.com>
 <CAGgJW74SsEgfn2i1qHBP2ZPiR3iwcgXBNL2M4Lv-23M02q=e7Q@mail.gmail.com>
 <CAGgJW77o2EOVGVbrOOhn103KOkp4BotK_gYeZxgAx36Hwdr2bA@mail.gmail.com>
 <CA+BE2NO+yD9WaD9DQ7Ec+77ruiqyOsY+bMJ8fRh-KYoMTYVUYg@mail.gmail.com>
 <EE5E3CF2-9603-49FE-B6B6-0AD6E8FD8B65@gmail.com>
Message-ID: <CA+BE2NOOpJCkAMvBFAWoUUNwFbYj8p3DptyGWCtYsP+k51=MNg@mail.gmail.com>

Fantastic! Thank you for your help, -Joe

On Tue, Nov 21, 2017 at 2:17 PM, Eric Berger <ericjberger at gmail.com> wrote:

> Correct
>
> Sent from my iPhone
>
> On 21 Nov 2017, at 22:42, Joe O <joerodonnell at gmail.com> wrote:
>
> Hi Eric,
>
> Thank you, that helps a lot. If I'm understanding correctly, if I?m
> wanting to use actual returns from backtests rather than simulated returns,
> I would need to make sure my risk-adjusted return measure, sharpe ratio in
> this case, matches up in scale with my returns (i.e. daily returns with
> daily sharpe, monthly with monthly, etc). And I wouldn?t need to transform
> returns like the simulated returns are in the vignette, as the real returns
> are going to have whatever properties they have (meaning they will have
> whatever average and std dev they happen to have). Is that correct?
>
> Thanks, -Joe
>
>
> On Tue, Nov 21, 2017 at 5:36 AM, Eric Berger <ericjberger at gmail.com>
> wrote:
>
>> [re-sending - previous email went out by accident before complete]
>> Hi Joe,
>> The centering and re-scaling is done for the purposes of his example, and
>> also to be consistent with his definition of the sharpe function.
>> In particular, note that the sharpe function has the rf (riskfree)
>> parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
>> to a DAILY rate, expressed in decimal.
>> That means that the other argument to this function, x, should be DAILY
>> returns, expressed in decimal.
>>
>> Suppose he wanted to create random data from a distribution of returns
>> with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in
>> decimal.
>> The equivalent DAILY returns would have mean MU_D = MU_A / 252 and
>> standard deviation SIGMA_D =  SIGMA_A/SQRT(252).
>>
>> He calls MU_D by the name mu_base  and  SIGMA_D by the name sigma_base.
>>
>> His loop now converts the random numbers in his matrix so that each
>> column has mean MU_D and std deviation SIGMA_D.
>>
>> HTH,
>> Eric
>>
>>
>>
>> On Tue, Nov 21, 2017 at 2:33 PM, Eric Berger <ericjberger at gmail.com>
>> wrote:
>>
>>> Hi Joe,
>>> The centering and re-scaling is done for the purposes of his example,
>>> and also to be consistent with his definition of the sharpe function.
>>> In particular, note that the sharpe function has the rf (riskfree)
>>> parameter with a default value of .03/252 i.e. an ANNUAL 3% rate converted
>>> to a DAILY rate, expressed in decimal.
>>> That means that the other argument to this function, x, should be DAILY
>>> returns, expressed in decimal.
>>>
>>> Suppose he wanted to create random data from a distribution of returns
>>> with ANNUAL mean MU_A and ANNUAL std deviation SIGMA_A, both stated in
>>> decimal.
>>> The equivalent DAILY
>>>
>>> Then he does two steps: (1) generate a matrix of random values from the
>>> N(0,1) distribution. (2) convert them to DAILY
>>> After initializing the matrix with random values (from N(0,1)), he now
>>> wants to create a series of DAILY
>>> sr_base <- 0
>>> mu_base <- sr_base/(252.0)
>>> sigma_base <- 1.00/(252.0)**0.5
>>> for ( i in 1:n ) {
>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>>
>>> On Tue, Nov 21, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>>> Wrong list.
>>>>
>>>> Post on r-sig-finance instead.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>>
>>>> On Nov 20, 2017 11:25 PM, "Joe O" <joerodonnell at gmail.com> wrote:
>>>>
>>>> Hello,
>>>>
>>>> I'm trying to understand how to use the pbo package by looking at a
>>>> vignette. I'm curious about a part of the vignette that creates
>>>> simulated
>>>> returns data. The package author transforms his simulated returns in a
>>>> way
>>>> that I'm unfamiliar with, and that I haven't been able to find an
>>>> explanation for after searching around. I'm curious if I need to
>>>> replicate
>>>> the transformation with real returns. For context, here is the vignette
>>>> (cleaned up a bit to make it reproducible):
>>>>
>>>> (Full vignette:
>>>> https://cran.r-project.org/web/packages/pbo/vignettes/pbo.html)
>>>>
>>>> library(pbo)
>>>> #First, we assemble the trials into an NxT matrix where each column
>>>> #represents a trial and each trial has the same length T. This example
>>>> #is random data so the backtest should be overfit.`
>>>>
>>>> set.seed(765)
>>>> n <- 100
>>>> t <- 2400
>>>> m <- data.frame(matrix(rnorm(n*t),nrow=t,ncol=n,
>>>>                        dimnames=list(1:t,1:n)), check.names=FALSE)
>>>>
>>>> sr_base <- 0
>>>> mu_base <- sr_base/(252.0)
>>>> sigma_base <- 1.00/(252.0)**0.5
>>>> for ( i in 1:n ) {
>>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>>> #We can use any performance evaluation function that can work with the
>>>> #reassembled sub-matrices during the cross validation iterations.
>>>> #Following the original paper we can use the Sharpe ratio as
>>>>
>>>> sharpe <- function(x,rf=0.03/252) {
>>>>   sr <- apply(x,2,function(col) {
>>>>     er = col - rf
>>>>     return(mean(er)/sd(er))
>>>>   })
>>>>   return(sr)}
>>>> #Now that we have the trials matrix we can pass it to the pbo function
>>>>  #for analysis.
>>>>
>>>> my_pbo <- pbo(m,s=8,f=sharpe,threshold=0)
>>>>
>>>> summary(my_pbo)
>>>>
>>>> Here's the portion i'm curious about:
>>>>
>>>> sr_base <- 0
>>>> mu_base <- sr_base/(252.0)
>>>> sigma_base <- 1.00/(252.0)**0.5
>>>> for ( i in 1:n ) {
>>>>   m[,i] = m[,i] * sigma_base / sd(m[,i]) # re-scale
>>>>   m[,i] = m[,i] + mu_base - mean(m[,i]) # re-center}
>>>>
>>>> Why is the data transformed within the for loop, and does this kind of
>>>> re-scaling and re-centering need to be done with real returns? Or is
>>>> this
>>>> just something the author is doing to make his simulated returns look
>>>> more
>>>> like the real thing?
>>>>
>>>> Googling around turned up some articles regarding scaling volatility to
>>>> the
>>>> square root of time, but the scaling in the code here doesn't look quite
>>>> like what I've seen. Re-scalings I've seen involve multiplying some
>>>> short
>>>> term (i.e. daily) measure of volatility by the root of time, but this
>>>> isn't
>>>> quite that. Also, the documentation for the package doesn't include this
>>>> chunk of re-scaling and re-centering code. Documentation:
>>>> https://cran.r-
>>>> project.org/web/packages/pbo/pbo.pdf
>>>>
>>>> So:
>>>>
>>>>    -
>>>>
>>>>    Why is the data transformed in this way/what is result of this
>>>>    transformation?
>>>>    -
>>>>
>>>>    Is it only necessary for this simulated data, or do I need to
>>>>    similarly transform real returns?
>>>>
>>>> I read in the posting guide that stats questions are acceptable given
>>>> certain conditions, I hope this counts. Thanks for reading,
>>>>
>>>> -Joe
>>>>
>>>> <http://www.avg.com/email-signature?utm_medium=email&
>>>> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>>> Virus-free.
>>>> www.avg.com
>>>> <http://www.avg.com/email-signature?utm_medium=email&
>>>> utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>>> >
>>>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Nov 21 22:24:42 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Nov 2017 16:24:42 -0500
Subject: [R] Best way to study internals of R ( mix of C, C++, Fortran,
 and R itself)?
In-Reply-To: <CAGW5CW92nEXgGm2Cs0SD56PfQRCmy_i_vnf9MprH=bQ6JPPy=g@mail.gmail.com>
References: <CAGW5CW92nEXgGm2Cs0SD56PfQRCmy_i_vnf9MprH=bQ6JPPy=g@mail.gmail.com>
Message-ID: <1d24ee12-351a-5cf5-9f0b-96e71965bf28@gmail.com>

On 21/11/2017 2:14 PM, Robert Wilkins wrote:
> How difficult is it to get a good feel for the internals of R, if you want
> to learn the general code base, but also the CPU intensive stuff ( much of
> it in C or Fortran?) and the ways in which the general code and the CPU
> intensive stuff is connected together?

That's a pretty difficult question to answer.  How hard compared to what?

> 
> R has a very large audience, but my understanding is that only a small
> group have a good understanding of the internals (and some of those will
> eventually move on to something else in their career, or retire
> altogether).

That's true, but the good news is that there are people who know the 
internals now who didn't know them 5 or 10 years ago.  So there is 
renewal happening.  And there are a number of independent 
implementations of the language or subsets of it; see the Wikipedia 
article <https://en.wikipedia.org/wiki/R_(programming_language)>.

> While I'm at it, a second question: 15 years ago, nobody would ever offer a
> job based on R skills ( SAS, yes, SPSS, maybe, but R skills, year after
> year, did not imply job offers). How much has that changed, both for R and
> for NumPy/Pandas/SciPy ?
> 

The web page <http://r4stats.com/articles/popularity/> is fairly up to 
date.  It doesn't say what things were like in 2002, but in early 2017, 
the ranking was Python > R > SAS in the count of job ads in data 
science.  In 2012 it was SAS > Python > R (but R and Python were very 
close).

Duncan Murdoch


From Heinzen.Ethan at mayo.edu  Mon Nov 20 20:26:31 2017
From: Heinzen.Ethan at mayo.edu (Heinzen, Ethan P.)
Date: Mon, 20 Nov 2017 19:26:31 +0000
Subject: [R] [R-pkgs] elo v1.0.0: Elo Ratings
Message-ID: <375144$8caemt@ironport10.mayo.edu>

Dear useRs,

I'm pleased to announce the v1.0.0 major release of the "elo" package on CRAN (https://cran.r-project.org/package=elo).

This package implements a flexible framework for calculating Elo ratings of any two-team-per-matchup system (chess, sports leagues, 'Go', etc.).  It is capable of evaluating a variety of matchups, Elo rating updates, and win probabilities, all based on the basic Elo rating system.  For details, see the vignette included in the package.  Bug reports and other contributions are always welcome on the "elo" package GitHub page: https://github.com/eheinzen/elo.

Cheers,
Ethan Heinzen
heinzen.ethan at mayo.edu<mailto:heinzen.ethan at mayo.edu>
https://github.com/eheinzen

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From gforister at gmail.com  Tue Nov 21 23:14:51 2017
From: gforister at gmail.com (Glen Forister)
Date: Tue, 21 Nov 2017 14:14:51 -0800
Subject: [R] mystery "158"
Message-ID: <CAND=aS1xvEGVKNTph2AkRqp892vybfi1-EVz2zCzr2h90muf1A@mail.gmail.com>

This is a simple problem, but a mystery to me.
I'm trying to grab $Family "Scelionidae" from one dataframe and put it into
another dataframe occupied with NA in $Family.  The result is a "158" ends
up there instead of Scelionidae.
Simply put      fam$Family[1] <- least$Family[1]

If I have made a mistake here, can somebody point it out.  I've included
the simple steps I got there showing the structure and heads of the objects.
=====  add a col of NA  = Family
> least$Family <- NA; str(least)
'data.frame':    243 obs. of  6 variables:
 $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
 $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
 $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
 $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
 $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
 $ Family: logi  NA NA NA NA NA NA ...
>head(least,2)
  sp Fallon Dimen Farm Sums Family
1  1     14    10    6   30     NA
3  3     11    13    2   26     NA
>
> #next change the property logi to char
> least$Family <- as.character(least$Family)
> str(least)
'data.frame':    243 obs. of  6 variables:
 $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
 $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
 $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
 $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
 $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
 $ Family: chr  NA NA NA NA ...
>#  This is where I will grab the info to put into the above.
> head(fam,2)
         Family Sp
1   Scelionidae  1
2         Aphid  2
>#  This shows the id of my object I want to copy
> fam$Family[1]
[1] Scelionidae
180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
>
># This shows me copying Scelionidae into dataframe least
> least$Family[1] <- fam$Family[1]
>
>#    Here is where I don't get what I expect, but 158
>str(least);
'data.frame':    243 obs. of  6 variables:
 $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
 $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
 $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
 $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
 $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
 $ Family: chr  "158" NA NA NA ...
>head(least, 1)
  sp Fallon Dimen Farm Sums Family
1  1     14     10        6       30    158
>
>#    Showing what I wanted to copy still exists.
> fam$Family[1]
[1] Scelionidae
180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Wed Nov 22 00:00:17 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 21 Nov 2017 15:00:17 -0800
Subject: [R] mystery "158"
In-Reply-To: <CAND=aS1xvEGVKNTph2AkRqp892vybfi1-EVz2zCzr2h90muf1A@mail.gmail.com>
References: <CAND=aS1xvEGVKNTph2AkRqp892vybfi1-EVz2zCzr2h90muf1A@mail.gmail.com>
Message-ID: <CA+hbrhVxcJuBdAtTrfXxAQ7Z9vG_60-J8p4PiEaKkkbzcVHQEg@mail.gmail.com>

Your data frame fam contains factors. Turn it into character strings using

fam$Family = as.character(fam$Family)

and try again. It may be helpful if you read up on R's factors, see ?factor.

HTH,

Peter

On Tue, Nov 21, 2017 at 2:14 PM, Glen Forister <gforister at gmail.com> wrote:
> This is a simple problem, but a mystery to me.
> I'm trying to grab $Family "Scelionidae" from one dataframe and put it into
> another dataframe occupied with NA in $Family.  The result is a "158" ends
> up there instead of Scelionidae.
> Simply put      fam$Family[1] <- least$Family[1]
>
> If I have made a mistake here, can somebody point it out.  I've included
> the simple steps I got there showing the structure and heads of the objects.
> =====  add a col of NA  = Family
>> least$Family <- NA; str(least)
> 'data.frame':    243 obs. of  6 variables:
>  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
>  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
>  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
>  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
>  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
>  $ Family: logi  NA NA NA NA NA NA ...
>>head(least,2)
>   sp Fallon Dimen Farm Sums Family
> 1  1     14    10    6   30     NA
> 3  3     11    13    2   26     NA
>>
>> #next change the property logi to char
>> least$Family <- as.character(least$Family)
>> str(least)
> 'data.frame':    243 obs. of  6 variables:
>  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
>  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
>  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
>  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
>  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
>  $ Family: chr  NA NA NA NA ...
>>#  This is where I will grab the info to put into the above.
>> head(fam,2)
>          Family Sp
> 1   Scelionidae  1
> 2         Aphid  2
>>#  This shows the id of my object I want to copy
>> fam$Family[1]
> [1] Scelionidae
> 180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
>>
>># This shows me copying Scelionidae into dataframe least
>> least$Family[1] <- fam$Family[1]
>>
>>#    Here is where I don't get what I expect, but 158
>>str(least);
> 'data.frame':    243 obs. of  6 variables:
>  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
>  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
>  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
>  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
>  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
>  $ Family: chr  "158" NA NA NA ...
>>head(least, 1)
>   sp Fallon Dimen Farm Sums Family
> 1  1     14     10        6       30    158
>>
>>#    Showing what I wanted to copy still exists.
>> fam$Family[1]
> [1] Scelionidae
> 180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Nov 22 03:53:29 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Nov 2017 18:53:29 -0800
Subject: [R] R-How to unlist data frame multiple structured list column
	value and new column
In-Reply-To: <BM1PR0101MB16669D1EC1E90A1A53C25D4EE9230@BM1PR0101MB1666.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR0101MB16669D1EC1E90A1A53C25D4EE9230@BM1PR0101MB1666.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <70F3382B-40FC-4599-BB50-6D46F5DF28CD@comcast.net>


> On Nov 21, 2017, at 7:13 AM, muthu m <muthu.psg.swift at gmail.com> wrote:
> 
> Hi,
> 
> How to unlist  list column value and add column into data frame.

After looking at this and playing with the output of dput on the first 4 rows in this sample of what I suspect is a much larger data object my suspicion is that this cam from a JSON file or a SQL file and got inappropriately rearranged into a dataframe. It probably should have been processed differently. My advice would be to go back a couple of steps to the original data input process and see if you can deliver a less mangled version of your data.

-- 
David.
> 
> Data frame
> 
> ID      ContractDe                                                                       PassengersDe                                                    TrainnerDe
> 
>  1      list(ConID=c("Zx","78yu"),ConRes = c("98","Tut"))                             list(PassID =1,PassIt="Lits,uy")                         list(Trnid=1,Trncont =5,EmpAddInfo=list(list(CohID ="pi",InVoice=77)))
> 
>  2      list(ConID=c("Half","Yut","Weq"),ConRes =c("ref","Cr"))                       list(PassID =c("pfil","Q"),Name ="Tic",PassIt="S5,Y1     list(Trnid=7,Trncont =3,EmpAddInfo=list(list(CohID =c("AB","NI","OL"),InVoice = c("4","Y"))))
> 
>  3      list(ConID=c("Ui","pric"),ConRes = c("Num","Patch"))                          list(PassID =1,PassIt ="St,Bp")                          list(Trnid=c("U", "l"),Trncont=c("10","78"),EmpAddInfo=list(list(CohID =c("AB","NI","OL"),InVoice =c("4","Y"))))
> 
>  4      list(ConID=c("2","7","IO"),ConRes = c("Res","Qty"),ConVal =c("Wno", "ip"))    list(PassID =1,Name ="RT",Name1 ="RR",PassIt="st7,st9")  list(Trnid=c("1", "3"),Trncont=c("yt","re"),EmpAddInfo=list(list(CohID =c("Ly","qp"),InVoice =c("2","P"))))
> 
> 
> 
> 
> 
> Expected data frame.
> 
> ID   ConID         ConRes    ConVal     PassID       PassIt    Name   Name1     Trnid    Trncont    CohID    InVoice
> 
> 1   Zx,78yu       98,Tut     NA          1          Lits,uy    NA     NA         1        5         pi         77
> 
> 2   Half,Yut,Weq  ref,Cr     NA          pfil,Q     S5,Y1      Tic    NA         7        3       AB,NI,OL     4,Y
> 
> 3   Ui,pric       Num,Patch  NA           1         St,Bp      NA     NA         U,l    10,78     AB,NI,OL     4,Y
> 
> 4   2,7,IO        Res,Qty    Wno,ip       1         st7,st9    RT     st7,st9     1,3   yt,re       Ly,qp      2,P
> 
> 
> 
> dput
> 
> 
> structure(list(ID = c("1", "2", "3","4"), ContractDe = list(
>    structure(list(ConID = c("Zx", "78yu"), ConRes = c("98",
>    "Tut")), .Names = c("ConID", "ConRes"), class = "data.frame", row.names = 1:2),
>    structure(list(ConID = c("Half", "Yut","Weq"), ConRes = c("ref",
>    "Cr")), .Names = c("ConID", "ConRes"), class = "data.frame", row.names = 1:2),
> structure(list(ConID = c("Ui", "pric"), ConRes = c("Num",
>    "Patch")), .Names = c("ConID", "ConRes"), class = "data.frame", row.names = 1:2),
>    structure(list(ConID = c("2", "7","IO"), ConRes = c("Res",
>    "Qty"),ConVal=c("Wno","ip")), .Names = c("ConID", "ConRes","ConVal"), class = "data.frame", row.names = 1:2)),
>    PassengersDe = list(structure(list(PassID = 1, PassIt = "Lits, uy"), .Names = c("PassID",
>    "PassIt"), class = "data.frame", row.names = 1L), structure(list(
>        PassID = c("pfil","Q"), Name = "Tic", PassIt = "S5, Y1"), .Names = c("PassID",
>    "Name", "PassIt"), class = "data.frame", row.names = 1L),
> structure(list(PassID = 1, PassIt = "St, Bp"), .Names = c("PassID",
>    "PassIt"), class = "data.frame", row.names = 1L),
> structure(list(PassID = 1, Name = "RT", Name1 = "RR", PassIt = "st7, st9"), .Names = c("PassID",
>    "Name", "Name1", "PassIt"), class = "data.frame", row.names = 1L)),
>    TrainnerDe = list(structure(list(Trnid = 1, Trncont = 5, EmpAddInfo = list(
>        structure(list(CohID = "pi", InVoice = 77), .Names = c("CohID",
>        "InVoice"), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
>    "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L),
>        structure(list(Trnid =7,Trncont = 3, EmpAddInfo = list(structure(list(
>            CohID = c("AB", "NI", "OL"), InVoice = c("4", "Y")), .Names = c("CohID",
>        "InVoice"), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
>        "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L),
> structure(list(Trnid =c("U","l"),Trncont =c("10","78"), EmpAddInfo = list(structure(list(
>            CohID = c("AB", "NI", "OL"), InVoice = c("4", "Y")), .Names = c("CohID",
>        "InVoice"), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
>        "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L),
>        structure(list(Trnid = c("1","3"), Trncont = c("yt","re"), EmpAddInfo = list(structure(list(
>            CohID = c("Ly","qp"), InVoice = c("2","P")), .Names = c("CohID", "InVoice"
>        ), class = "data.frame", row.names = 1L))), .Names = c("Trnid",
>        "Trncont", "EmpAddInfo"), class = "data.frame", row.names = 1L))), .Names = c("ID",
> "ContractDe", "PassengersDe", "TrainnerDe"), row.names = c(NA, 4L), class = "data.frame")
> 
> 
> i was stuck on this change part of my project, please help me to out this. Thanks.
> 
> 
> 
> Sent from Outlook<http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jtelleriar at gmail.com  Wed Nov 22 00:04:18 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Wed, 22 Nov 2017 00:04:18 +0100
Subject: [R] Best way to study internals of R ( mix of C, C++, Fortran,
 and R itself)?
In-Reply-To: <8A1956C4-B753-4F50-962D-803C09366065@dcn.davis.ca.us>
References: <CAGW5CW92nEXgGm2Cs0SD56PfQRCmy_i_vnf9MprH=bQ6JPPy=g@mail.gmail.com>
 <8A1956C4-B753-4F50-962D-803C09366065@dcn.davis.ca.us>
Message-ID: <CANNd7=k1D2aHF=SQaLsAZUDda18+ckG8jNgzR_8z44K0o1=5UQ@mail.gmail.com>

The R Community made a call for one person to be in charge of R Contributed
Documentation, and I have done a request for being in charge of such duty.

If assigned, my plan is to implement Atlassian's Confluence along the R
Community (Accessed though R Project.org), in order to generate a Wiki and
Document Store for R, at all levels (R Internals, User Tutorials, etc.)

In a similar way the Apache Software Foundation does:
https://cwiki.apache.org/confluence/dashboard.action

So contribution and user guide for internals could be documented in such
platform for future users.


El 21/11/2017 10:26 p. m., "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
escribi?:

> 1) What is easy for one person may be very hard for another, so your
> question is really unanswerable. You do need to know C and Fortran to get
> through the source code. Get started soon reading the R Internals document
> if it sounds interesting to you... you are bound to learn something even if
> you don't stick with it. If you have questions about the internals though,
> you should read the Posting Guide to find out where to ask them (hint: not
> here).
>
> 2) There are lots of blogs and surveys out there about how R's popularity
> has increased over time, though Python seems to have higher billing in job
> descriptions I have seen. Generally if you know multiple tools and the
> underlying theory you are working with then you are more likely to succeed,
> so don't limit yourself by dismissing R for reasons of comparative
> popularity.
> --
> Sent from my phone. Please excuse my brevity.
>
> On November 21, 2017 11:14:45 AM PST, Robert Wilkins <
> iwritecode2 at gmail.com> wrote:
> >How difficult is it to get a good feel for the internals of R, if you
> >want
> >to learn the general code base, but also the CPU intensive stuff ( much
> >of
> >it in C or Fortran?) and the ways in which the general code and the CPU
> >intensive stuff is connected together?
> >
> >R has a very large audience, but my understanding is that only a small
> >group have a good understanding of the internals (and some of those
> >will
> >eventually move on to something else in their career, or retire
> >altogether).
> >
> >While I'm at it, a second question: 15 years ago, nobody would ever
> >offer a
> >job based on R skills ( SAS, yes, SPSS, maybe, but R skills, year after
> >year, did not imply job offers). How much has that changed, both for R
> >and
> >for NumPy/Pandas/SciPy ?
> >
> >thanks in advance
> >
> >Robert
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Nov 22 10:15:05 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 22 Nov 2017 09:15:05 +0000
Subject: [R] mystery "158"
In-Reply-To: <CA+hbrhVxcJuBdAtTrfXxAQ7Z9vG_60-J8p4PiEaKkkbzcVHQEg@mail.gmail.com>
References: <CAND=aS1xvEGVKNTph2AkRqp892vybfi1-EVz2zCzr2h90muf1A@mail.gmail.com>
 <CA+hbrhVxcJuBdAtTrfXxAQ7Z9vG_60-J8p4PiEaKkkbzcVHQEg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB087@SRVEXCHCM301.precheza.cz>

Well, ?factor does not say anything about this behaviour (assigning numeric code instead of level of factor). And actually if you do assignment for whole vector the result is different (vector in data frame is changed to factor).

> temp2$fff[1]<-vec[1]
> head(temp2,2)
  pokus minuty  fff
1   T42    240    3
2   T42    300 <NA>
> temp2$fff<-vec
> head(temp2,2)
  pokus minuty fff
1   T42    240   c
2   T42    300   c
>
> is.factor(vec[1])
[1] TRUE

I am not experieenced enough to explain what is happening but it is probably combination selection ?"[" and assignment ?"<-" operation.

I was not able to pinpoint explanation of this in help pages but maybe I only did not read it correctly.

dput(temp2)
temp2 <- structure(list(pokus = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L
), .Label = c("T42", "T43", "T44", "T45", "T46", "T47", "T48",
"T49"), class = "factor"), minuty = structure(c(2L, 3L, 4L, 2L,
3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 2L, 3L, 4L, 2L, 3L, 2L, 3L, 2L,
3L, 2L, 3L), .Label = c("180", "240", "300", "360", "420", "480"
), class = "factor"), fff = c(NA_character_, NA_character_, NA_character_,
NA_character_, NA_character_, NA_character_, NA_character_, NA_character_,
NA_character_, NA_character_, NA_character_, NA_character_, NA_character_,
NA_character_, NA_character_, NA_character_, NA_character_, NA_character_,
NA_character_, NA_character_, NA_character_, NA_character_, NA_character_
)), .Names = c("pokus", "minuty", "fff"), row.names = c(NA, -23L
), class = "data.frame")

> dput(vec)
vec <- structure(c(3L, 3L, 2L, 5L, 3L, 4L, 2L, 2L, 1L, 1L, 5L, 3L, 4L,
1L, 2L, 5L, 2L, 4L, 5L, 5L, 2L, 5L, 4L), .Label = c("a", "b",
"c", "d", "e"), class = "factor")

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter
> Langfelder
> Sent: Wednesday, November 22, 2017 12:00 AM
> To: Glen Forister <gforister at gmail.com>
> Cc: R <r-help at r-project.org>
> Subject: Re: [R] mystery "158"
>
> Your data frame fam contains factors. Turn it into character strings using
>
> fam$Family = as.character(fam$Family)
>
> and try again. It may be helpful if you read up on R's factors, see ?factor.
>
> HTH,
>
> Peter
>
> On Tue, Nov 21, 2017 at 2:14 PM, Glen Forister <gforister at gmail.com> wrote:
> > This is a simple problem, but a mystery to me.
> > I'm trying to grab $Family "Scelionidae" from one dataframe and put it
> > into another dataframe occupied with NA in $Family.  The result is a
> > "158" ends up there instead of Scelionidae.
> > Simply put      fam$Family[1] <- least$Family[1]
> >
> > If I have made a mistake here, can somebody point it out.  I've
> > included the simple steps I got there showing the structure and heads of the
> objects.
> > =====  add a col of NA  = Family
> >> least$Family <- NA; str(least)
> > 'data.frame':    243 obs. of  6 variables:
> >  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
> >  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
> >  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
> >  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
> >  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
> >  $ Family: logi  NA NA NA NA NA NA ...
> >>head(least,2)
> >   sp Fallon Dimen Farm Sums Family
> > 1  1     14    10    6   30     NA
> > 3  3     11    13    2   26     NA
> >>
> >> #next change the property logi to char least$Family <-
> >> as.character(least$Family)
> >> str(least)
> > 'data.frame':    243 obs. of  6 variables:
> >  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
> >  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
> >  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
> >  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
> >  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
> >  $ Family: chr  NA NA NA NA ...
> >>#  This is where I will grab the info to put into the above.
> >> head(fam,2)
> >          Family Sp
> > 1   Scelionidae  1
> > 2         Aphid  2
> >>#  This shows the id of my object I want to copy  fam$Family[1]
> > [1] Scelionidae
> > 180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
> >>
> >># This shows me copying Scelionidae into dataframe least
> >>least$Family[1] <- fam$Family[1]
> >>
> >>#    Here is where I don't get what I expect, but 158
> >>str(least);
> > 'data.frame':    243 obs. of  6 variables:
> >  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
> >  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
> >  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
> >  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
> >  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
> >  $ Family: chr  "158" NA NA NA ...
> >>head(least, 1)
> >   sp Fallon Dimen Farm Sums Family
> > 1  1     14     10        6       30    158
> >>
> >>#    Showing what I wanted to copy still exists.
> >> fam$Family[1]
> > [1] Scelionidae
> > 180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mdsumner at gmail.com  Wed Nov 22 10:48:04 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 22 Nov 2017 09:48:04 +0000
Subject: [R] How to produce rainfall maps
In-Reply-To: <CAM_vjunToO=sqFWPRRYcWJTL9AOh_3TBnNpcORo+oN-ZGhGR_w@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F471AE00E@ESINO.regionemarche.intra>
 <8B435C9568170B469AE31E8891E8CC4F471AE0D5@ESINO.regionemarche.intra>
 <CAM_vjunToO=sqFWPRRYcWJTL9AOh_3TBnNpcORo+oN-ZGhGR_w@mail.gmail.com>
Message-ID: <CAAcGz9-N3MFiyeewc3V8OUicY+b4yjXXHBiucK5ZvDn1LeajvQ@mail.gmail.com>

Fwiw the engine behind geom_raster needs explicit observation-per-row form
for input (with no structural normalization), so conversion to points is
perfectly proper here,  albeit confusing in context. (It's closer to what
graphics devices actually use ultimately, but the expansion is laid out
very early in ggplot2 because there's no standard for intermediate forms.)

Cheers, Mike

On Wed, 22 Nov 2017, 07:12 Sarah Goslee, <sarah.goslee at gmail.com> wrote:

> Hi,
>
> You might get more help from the R-sig-geo list, which is devoted to
> spatial topics.
>
> However.
>
> The *.asc file is an ArcGIS raster export format. You should use
> whatever the appropriate import commands are for your own gridded
> rainfall data. If you have a different format, you might or might not
> be able to import it directly with raster.
>
> ?raster will tell you more about the kinds of formats that function
> can handle importing.
>
> I'm not sure what the intent of converting a raster to point data
> actually is; if you have point data, then import it as point data. If
> you have gridded data, then map it as gridded data. But if it makes
> sense to you, then go for it.
>
> The comments in your code sample explain what the CSV file should be:
> coordinates of the points to be mapped.
>
> I'm not even certain from your question what your objective is.
>
> What kind of rainfall data are you starting with?
> What kind of maps do you want to produce?
>
> Sarah
>
>
>
> On Fri, Nov 17, 2017 at 3:40 AM, Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> > Dear R users,
> > I need to produce rainfall maps using R.
> > I know that this is possible, I looked though the web, I found the
> example below reported (the author is Andrew Tredennick).
> > I would ask you if this is the most performing way to make rainfall
> maps; if yes would someone be able to give me an example of how file.asc
> and pointfile.csv should be? If no would somebody please show me another
> way providing a small example?
> >
> > Thank you for your help
> > Stefano
> >
> >
> > library(raster)
> > library(ggplot2)
> >
> > #open ASCII file using ?raster? command, which converts the ASCII to a
> raster object
> > map <- raster(?/your/path/to/file.asc?)
> >
> > #convert the raster to points for plotting
> > map.p <- rasterToPoints(map)
> >
> > #Make the points a dataframe for ggplot
> > df <- data.frame(map.p)
> > #Make appropriate column headings
> > colnames(df) <- c(?Longitude?, ?Latitude?, ?MAP?)
> >
> > #Call in point data, in this case a fake transect (csv file with lat and
> lon coordinates)
> > sites <- data.frame(read.csv(?/your/path/to/pointfile.csv?))
> >
> > #Now make the map
> > ggplot(data=df, aes(y=Latitude, x=Longitude)) +
> > geom_raster(aes(fill=MAP)) +
> > geom_point(data=sites, aes(x=x, y=y), color=?white?, size=3, shape=4) +
> > theme_bw() +
> > coord_equal() +
> > scale_fill_gradient(?MAP (mm/yr)?, limits=c(0,2500)) +
> > theme(axis.title.x = element_text(size=16),
> > axis.title.y = element_text(size=16, angle=90),
> > axis.text.x = element_text(size=14),
> > axis.text.y = element_text(size=14),
> > panel.grid.major = element_blank(),
> > panel.grid.minor = element_blank(),
> > legend.position = ?right?,
> > legend.key = element_blank()
> > )
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo----------------
> > Stefano Sofia PhD
> > Area Meteorologica e  Area nivologica - Centro Funzionale
> > Servizio Protezione Civile - Regione Marche
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona
> > Uff: 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------
> >
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From massimo.bressan at arpa.veneto.it  Wed Nov 22 11:34:50 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Wed, 22 Nov 2017 11:34:50 +0100 (CET)
Subject: [R] assign NA to rows by test on multiple columns of a data frame
Message-ID: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>



Given this data frame (a simplified, essential reproducible example) 




A<-c(8,7,10,1,5) 

A_flag<-c(10,0,1,0,2) 

B<-c(5,6,2,1,0) 

B_flag<-c(12,9,0,5,0) 




mydf<-data.frame(A, A_flag, B, B_flag) 




# this is my initial df 

mydf 




I want to get to this final situation 




i<-which(mydf$A_flag==0) 

mydf$A[i]<-NA 




ii<-which(mydf$B_flag==0) 

mydf$B[ii]<-NA 




# this is my final df 

mydf 




By considering that I have to perform this task in a data frame with many columns I?m wondering if there is a compact and effective way to get the final result with just one ?sweep? of the dataframe? 




I was thinking to the function apply or lapply but I can not properly conceive how to? 




any hint for that? 

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Nov 22 11:49:08 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 22 Nov 2017 10:49:08 +0000
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <e371d421-482e-503a-1c6d-1869c3c13807@sapo.pt>

Hello,

Try the following.


icol <- which(grepl("flag", names(mydf)))
mydf[icol] <- lapply(mydf[icol], function(x){
         is.na(x) <- x == 0
         x
     })

mydf
#   A A_flag B B_flag
#1  8     10 5     12
#2  7     NA 6      9
#3 10      1 2     NA
#4  1     NA 1      5
#5  5      2 0     NA


Hope this helps,

Rui Barradas

On 11/22/2017 10:34 AM, Massimo Bressan wrote:
> 
> 
> Given this data frame (a simplified, essential reproducible example)
> 
> 
> 
> 
> A<-c(8,7,10,1,5)
> 
> A_flag<-c(10,0,1,0,2)
> 
> B<-c(5,6,2,1,0)
> 
> B_flag<-c(12,9,0,5,0)
> 
> 
> 
> 
> mydf<-data.frame(A, A_flag, B, B_flag)
> 
> 
> 
> 
> # this is my initial df
> 
> mydf
> 
> 
> 
> 
> I want to get to this final situation
> 
> 
> 
> 
> i<-which(mydf$A_flag==0)
> 
> mydf$A[i]<-NA
> 
> 
> 
> 
> ii<-which(mydf$B_flag==0)
> 
> mydf$B[ii]<-NA
> 
> 
> 
> 
> # this is my final df
> 
> mydf
> 
> 
> 
> 
> By considering that I have to perform this task in a data frame with many columns I?m wondering if there is a compact and effective way to get the final result with just one ?sweep? of the dataframe?
> 
> 
> 
> 
> I was thinking to the function apply or lapply but I can not properly conceive how to?
> 
> 
> 
> 
> any hint for that?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lterlemez at anadolu.edu.tr  Wed Nov 22 12:13:01 2017
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Wed, 22 Nov 2017 11:13:01 +0000
Subject: [R] ccomp Composition and ggtern plot...
Message-ID: <D63B366B.1CC79%lterlemez@anadolu.edu.tr>

Dear Users,

I would like to use compositions package with ggplot/ggtern, other composition classes of compositional package can be used with ggtern by converting to data frame but I could do anything with c(ount)comp class. Ggplot/ggtern can not recognise comp and also can not be converted to data frame. Is there any other way to do this?

Thank you in advance,

Levent TERLEMEZ.



________________________________

Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z, y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini yans?tmayabilir.

This electronic mail and any files transmitted with it are intended for the private use of the people named above. If you are not the intended recipient and received this message in error, forwarding, copying or use of any of the information is strictly prohibited. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal. In this case, please immediately notify the sender and delete it from your system. Anadolu University does not guarantee the accuracy or completeness of any information included in this message. Therefore, by any means Anadolu University is not responsible for the content of the message, and the transmission, reception, storage, and use of the information. The opinions expressed in this message only belong to the sender of it and may not reflect the opinions of Anadolu University.

	[[alternative HTML version deleted]]


From massimo.bressan at arpa.veneto.it  Wed Nov 22 12:19:29 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Wed, 22 Nov 2017 12:19:29 +0100 (CET)
Subject: [R] assign NA to rows by test on multiple columns of a data
 frame
In-Reply-To: <e371d421-482e-503a-1c6d-1869c3c13807@sapo.pt>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
 <e371d421-482e-503a-1c6d-1869c3c13807@sapo.pt>
Message-ID: <2064693094.29483749.1511349569658.JavaMail.zimbra@arpa.veneto.it>

...well, I don't think this is exactly the expected result (see my post)

to be noted that the columns affected should be "A" and "B"

thanks for the help

max

----- Messaggio originale -----
Da: "Rui Barradas" <ruipbarradas at sapo.pt>
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>, "r-help" <r-help at r-project.org>
Inviato: Mercoled?, 22 novembre 2017 11:49:08
Oggetto: Re: [R] assign NA to rows by test on multiple columns of a data frame

Hello,

Try the following.


icol <- which(grepl("flag", names(mydf)))
mydf[icol] <- lapply(mydf[icol], function(x){
         is.na(x) <- x == 0
         x
     })

mydf
#   A A_flag B B_flag
#1  8     10 5     12
#2  7     NA 6      9
#3 10      1 2     NA
#4  1     NA 1      5
#5  5      2 0     NA


Hope this helps,

Rui Barradas

On 11/22/2017 10:34 AM, Massimo Bressan wrote:
> 
> 
> Given this data frame (a simplified, essential reproducible example)
> 
> 
> 
> 
> A<-c(8,7,10,1,5)
> 
> A_flag<-c(10,0,1,0,2)
> 
> B<-c(5,6,2,1,0)
> 
> B_flag<-c(12,9,0,5,0)
> 
> 
> 
> 
> mydf<-data.frame(A, A_flag, B, B_flag)
> 
> 
> 
> 
> # this is my initial df
> 
> mydf
> 
> 
> 
> 
> I want to get to this final situation
> 
> 
> 
> 
> i<-which(mydf$A_flag==0)
> 
> mydf$A[i]<-NA
> 
> 
> 
> 
> ii<-which(mydf$B_flag==0)
> 
> mydf$B[ii]<-NA
> 
> 
> 
> 
> # this is my final df
> 
> mydf
> 
> 
> 
> 
> By considering that I have to perform this task in a data frame with many columns I?m wondering if there is a compact and effective way to get the final result with just one ?sweep? of the dataframe?
> 
> 
> 
> 
> I was thinking to the function apply or lapply but I can not properly conceive how to?
> 
> 
> 
> 
> any hint for that?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
------------------------------------------------------------
Massimo Bressan 

ARPAV
Agenzia Regionale per la Prevenzione e
Protezione Ambientale del Veneto

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545
fax: +39 0422 558516
e-mail: massimo.bressan at arpa.veneto.it


From ruipbarradas at sapo.pt  Wed Nov 22 13:59:03 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 22 Nov 2017 12:59:03 +0000
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <2064693094.29483749.1511349569658.JavaMail.zimbra@arpa.veneto.it>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
 <e371d421-482e-503a-1c6d-1869c3c13807@sapo.pt>
 <2064693094.29483749.1511349569658.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <33fbf6fe-36fa-ec3a-771d-278f2d4ad399@sapo.pt>

Hello,

Sorry, I obviously read in a hurry.


icol <- grepl("flag", names(mydf))
is.na(mydf[!icol]) <- mydf[icol] == 0

mydf
#   A A_flag  B B_flag
#1  8     10  5     12
#2 NA      0  6      9
#3 10      1 NA      0
#4 NA      0  1      5
#5  5      2 NA      0


Hope this helps,

Rui Barradas

On 11/22/2017 11:19 AM, Massimo Bressan wrote:
> ...well, I don't think this is exactly the expected result (see my post)
> 
> to be noted that the columns affected should be "A" and "B"
> 
> thanks for the help
> 
> max
> 
> ----- Messaggio originale -----
> Da: "Rui Barradas" <ruipbarradas at sapo.pt>
> A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>, "r-help" <r-help at r-project.org>
> Inviato: Mercoled?, 22 novembre 2017 11:49:08
> Oggetto: Re: [R] assign NA to rows by test on multiple columns of a data frame
> 
> Hello,
> 
> Try the following.
> 
> 
> icol <- which(grepl("flag", names(mydf)))
> mydf[icol] <- lapply(mydf[icol], function(x){
>           is.na(x) <- x == 0
>           x
>       })
> 
> mydf
> #   A A_flag B B_flag
> #1  8     10 5     12
> #2  7     NA 6      9
> #3 10      1 2     NA
> #4  1     NA 1      5
> #5  5      2 0     NA
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 11/22/2017 10:34 AM, Massimo Bressan wrote:
>>
>>
>> Given this data frame (a simplified, essential reproducible example)
>>
>>
>>
>>
>> A<-c(8,7,10,1,5)
>>
>> A_flag<-c(10,0,1,0,2)
>>
>> B<-c(5,6,2,1,0)
>>
>> B_flag<-c(12,9,0,5,0)
>>
>>
>>
>>
>> mydf<-data.frame(A, A_flag, B, B_flag)
>>
>>
>>
>>
>> # this is my initial df
>>
>> mydf
>>
>>
>>
>>
>> I want to get to this final situation
>>
>>
>>
>>
>> i<-which(mydf$A_flag==0)
>>
>> mydf$A[i]<-NA
>>
>>
>>
>>
>> ii<-which(mydf$B_flag==0)
>>
>> mydf$B[ii]<-NA
>>
>>
>>
>>
>> # this is my final df
>>
>> mydf
>>
>>
>>
>>
>> By considering that I have to perform this task in a data frame with many columns I?m wondering if there is a compact and effective way to get the final result with just one ?sweep? of the dataframe?
>>
>>
>>
>>
>> I was thinking to the function apply or lapply but I can not properly conceive how to?
>>
>>
>>
>>
>> any hint for that?
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From esawiek at gmail.com  Wed Nov 22 14:37:13 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 22 Nov 2017 08:37:13 -0500
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CA+ZkTxsk+5PGcbHeDKM_z2GQ9LLtoMQ2g49L_J3fCxX4xKDhAA@mail.gmail.com>

Hi *Massimo,*

*Try this.*

*a <- mydf==0mydf[a] <- NAHTHEK*

On Wed, Nov 22, 2017 at 5:34 AM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

>
>
> Given this data frame (a simplified, essential reproducible example)
>
>
>
>
> A<-c(8,7,10,1,5)
>
> A_flag<-c(10,0,1,0,2)
>
> B<-c(5,6,2,1,0)
>
> B_flag<-c(12,9,0,5,0)
>
>
>
>
> mydf<-data.frame(A, A_flag, B, B_flag)
>
>
>
>
> # this is my initial df
>
> mydf
>
>
>
>
> I want to get to this final situation
>
>
>
>
> i<-which(mydf$A_flag==0)
>
> mydf$A[i]<-NA
>
>
>
>
> ii<-which(mydf$B_flag==0)
>
> mydf$B[ii]<-NA
>
>
>
>
> # this is my final df
>
> mydf
>
>
>
>
> By considering that I have to perform this task in a data frame with many
> columns I?m wondering if there is a compact and effective way to get the
> final result with just one ?sweep? of the dataframe?
>
>
>
>
> I was thinking to the function apply or lapply but I can not properly
> conceive how to?
>
>
>
>
> any hint for that?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Wed Nov 22 14:44:00 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 22 Nov 2017 08:44:00 -0500
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <CA+ZkTxsk+5PGcbHeDKM_z2GQ9LLtoMQ2g49L_J3fCxX4xKDhAA@mail.gmail.com>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
 <CA+ZkTxsk+5PGcbHeDKM_z2GQ9LLtoMQ2g49L_J3fCxX4xKDhAA@mail.gmail.com>
Message-ID: <CA+ZkTxsM8KjYk+hzN1s=Lf07X1Cz-CO-=bi8XuDd5yR7o8m=cw@mail.gmail.com>

OPS,

Sorry i did not read the post carfully. Mine will not work if you have
zeros on columns A and B.. But you could modify it to work for specific
columns i believe.

EK

On Wed, Nov 22, 2017 at 8:37 AM, Ek Esawi <esawiek at gmail.com> wrote:

> Hi *Massimo,*
>
> *Try this.*
>
> *a <- mydf==0mydf[a] <- NAHTHEK*
>
> On Wed, Nov 22, 2017 at 5:34 AM, Massimo Bressan <
> massimo.bressan at arpa.veneto.it> wrote:
>
>>
>>
>> Given this data frame (a simplified, essential reproducible example)
>>
>>
>>
>>
>> A<-c(8,7,10,1,5)
>>
>> A_flag<-c(10,0,1,0,2)
>>
>> B<-c(5,6,2,1,0)
>>
>> B_flag<-c(12,9,0,5,0)
>>
>>
>>
>>
>> mydf<-data.frame(A, A_flag, B, B_flag)
>>
>>
>>
>>
>> # this is my initial df
>>
>> mydf
>>
>>
>>
>>
>> I want to get to this final situation
>>
>>
>>
>>
>> i<-which(mydf$A_flag==0)
>>
>> mydf$A[i]<-NA
>>
>>
>>
>>
>> ii<-which(mydf$B_flag==0)
>>
>> mydf$B[ii]<-NA
>>
>>
>>
>>
>> # this is my final df
>>
>> mydf
>>
>>
>>
>>
>> By considering that I have to perform this task in a data frame with many
>> columns I?m wondering if there is a compact and effective way to get the
>> final result with just one ?sweep? of the dataframe?
>>
>>
>>
>>
>> I was thinking to the function apply or lapply but I can not properly
>> conceive how to?
>>
>>
>>
>>
>> any hint for that?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Wed Nov 22 16:54:52 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 22 Nov 2017 10:54:52 -0500
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <CA+ZkTxsM8KjYk+hzN1s=Lf07X1Cz-CO-=bi8XuDd5yR7o8m=cw@mail.gmail.com>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
 <CA+ZkTxsk+5PGcbHeDKM_z2GQ9LLtoMQ2g49L_J3fCxX4xKDhAA@mail.gmail.com>
 <CA+ZkTxsM8KjYk+hzN1s=Lf07X1Cz-CO-=bi8XuDd5yR7o8m=cw@mail.gmail.com>
Message-ID: <CA+ZkTxvANxCgV7NSni1fKzaUBRuNP0iF1y7M44g7D_F7WqAAeA@mail.gmail.com>

Hi--

I too misread the question twice and i may have mistakenly posted non-text
answer earlier.  Below is a step by step solution that works provided that
your real data frame has the same structure (alternative columns as in your
example). You could combine all the steps in 2 statements.
Best of luck

EK


a <- grep("_flag",colnames(mydf))
b <- mydf[,a]==0
c <- mydf[,a-1]
c[b] <- NA
mydf[,a-1] <- c
mydf
 A A_flag  B B_flag
1  8     10  5     12
2 NA      0  6      9
3 10      1 NA      0
4 NA      0  1      5
5  5      2 NA      0

On Wed, Nov 22, 2017 at 8:44 AM, Ek Esawi <esawiek at gmail.com> wrote:

> OPS,
>
> Sorry i did not read the post carfully. Mine will not work if you have
> zeros on columns A and B.. But you could modify it to work for specific
> columns i believe.
>
> EK
>
> On Wed, Nov 22, 2017 at 8:37 AM, Ek Esawi <esawiek at gmail.com> wrote:
>
>> Hi *Massimo,*
>>
>> *Try this.*
>>
>> *a <- mydf==0mydf[a] <- NAHTHEK*
>>
>> On Wed, Nov 22, 2017 at 5:34 AM, Massimo Bressan <
>> massimo.bressan at arpa.veneto.it> wrote:
>>
>>>
>>>
>>> Given this data frame (a simplified, essential reproducible example)
>>>
>>>
>>>
>>>
>>> A<-c(8,7,10,1,5)
>>>
>>> A_flag<-c(10,0,1,0,2)
>>>
>>> B<-c(5,6,2,1,0)
>>>
>>> B_flag<-c(12,9,0,5,0)
>>>
>>>
>>>
>>>
>>> mydf<-data.frame(A, A_flag, B, B_flag)
>>>
>>>
>>>
>>>
>>> # this is my initial df
>>>
>>> mydf
>>>
>>>
>>>
>>>
>>> I want to get to this final situation
>>>
>>>
>>>
>>>
>>> i<-which(mydf$A_flag==0)
>>>
>>> mydf$A[i]<-NA
>>>
>>>
>>>
>>>
>>> ii<-which(mydf$B_flag==0)
>>>
>>> mydf$B[ii]<-NA
>>>
>>>
>>>
>>>
>>> # this is my final df
>>>
>>> mydf
>>>
>>>
>>>
>>>
>>> By considering that I have to perform this task in a data frame with
>>> many columns I?m wondering if there is a compact and effective way to get
>>> the final result with just one ?sweep? of the dataframe?
>>>
>>>
>>>
>>>
>>> I was thinking to the function apply or lapply but I can not properly
>>> conceive how to?
>>>
>>>
>>>
>>>
>>> any hint for that?
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Nov 22 17:07:56 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 22 Nov 2017 08:07:56 -0800
Subject: [R] mystery "158"
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB087@SRVEXCHCM301.precheza.cz>
References: <CAND=aS1xvEGVKNTph2AkRqp892vybfi1-EVz2zCzr2h90muf1A@mail.gmail.com>
 <CA+hbrhVxcJuBdAtTrfXxAQ7Z9vG_60-J8p4PiEaKkkbzcVHQEg@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB087@SRVEXCHCM301.precheza.cz>
Message-ID: <CAF8bMcYJ6LnagwpUEn=EMWzgm4EG3J67RQvM01dfmMVzNG-Skg@mail.gmail.com>

I think the '[<-' function for atomic types doesn't pay attention
to the class of the right hand side, only to its mode.  It strips all
the attributes of the RHS, including the class.

> f <- function(x) { x[2] <- factor("z", levels=letters) ; x }
> f(101:103)
[1] 101  26 103
> f(c("One","Two","Three"))
[1] "One"   "26"    "Three"
> f(exp(1i*(1:4)))
[1]  0.5403023+0.8414710i 26.0000000+0.0000000i -0.9899925+0.1411200i
-0.6536436-0.7568025i
> f(list(One=1,Two=2))
$One
[1] 1

$Two
[1] 26


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 22, 2017 at 1:15 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Well, ?factor does not say anything about this behaviour (assigning
> numeric code instead of level of factor). And actually if you do assignment
> for whole vector the result is different (vector in data frame is changed
> to factor).
>
> > temp2$fff[1]<-vec[1]
> > head(temp2,2)
>   pokus minuty  fff
> 1   T42    240    3
> 2   T42    300 <NA>
> > temp2$fff<-vec
> > head(temp2,2)
>   pokus minuty fff
> 1   T42    240   c
> 2   T42    300   c
> >
> > is.factor(vec[1])
> [1] TRUE
>
> I am not experieenced enough to explain what is happening but it is
> probably combination selection ?"[" and assignment ?"<-" operation.
>
> I was not able to pinpoint explanation of this in help pages but maybe I
> only did not read it correctly.
>
> dput(temp2)
> temp2 <- structure(list(pokus = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L
> ), .Label = c("T42", "T43", "T44", "T45", "T46", "T47", "T48",
> "T49"), class = "factor"), minuty = structure(c(2L, 3L, 4L, 2L,
> 3L, 4L, 5L, 6L, 1L, 2L, 3L, 4L, 2L, 3L, 4L, 2L, 3L, 2L, 3L, 2L,
> 3L, 2L, 3L), .Label = c("180", "240", "300", "360", "420", "480"
> ), class = "factor"), fff = c(NA_character_, NA_character_, NA_character_,
> NA_character_, NA_character_, NA_character_, NA_character_, NA_character_,
> NA_character_, NA_character_, NA_character_, NA_character_, NA_character_,
> NA_character_, NA_character_, NA_character_, NA_character_, NA_character_,
> NA_character_, NA_character_, NA_character_, NA_character_, NA_character_
> )), .Names = c("pokus", "minuty", "fff"), row.names = c(NA, -23L
> ), class = "data.frame")
>
> > dput(vec)
> vec <- structure(c(3L, 3L, 2L, 5L, 3L, 4L, 2L, 2L, 1L, 1L, 5L, 3L, 4L,
> 1L, 2L, 5L, 2L, 4L, 5L, 5L, 2L, 5L, 4L), .Label = c("a", "b",
> "c", "d", "e"), class = "factor")
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter
> > Langfelder
> > Sent: Wednesday, November 22, 2017 12:00 AM
> > To: Glen Forister <gforister at gmail.com>
> > Cc: R <r-help at r-project.org>
> > Subject: Re: [R] mystery "158"
> >
> > Your data frame fam contains factors. Turn it into character strings
> using
> >
> > fam$Family = as.character(fam$Family)
> >
> > and try again. It may be helpful if you read up on R's factors, see
> ?factor.
> >
> > HTH,
> >
> > Peter
> >
> > On Tue, Nov 21, 2017 at 2:14 PM, Glen Forister <gforister at gmail.com>
> wrote:
> > > This is a simple problem, but a mystery to me.
> > > I'm trying to grab $Family "Scelionidae" from one dataframe and put it
> > > into another dataframe occupied with NA in $Family.  The result is a
> > > "158" ends up there instead of Scelionidae.
> > > Simply put      fam$Family[1] <- least$Family[1]
> > >
> > > If I have made a mistake here, can somebody point it out.  I've
> > > included the simple steps I got there showing the structure and heads
> of the
> > objects.
> > > =====  add a col of NA  = Family
> > >> least$Family <- NA; str(least)
> > > 'data.frame':    243 obs. of  6 variables:
> > >  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
> > >  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
> > >  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
> > >  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
> > >  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
> > >  $ Family: logi  NA NA NA NA NA NA ...
> > >>head(least,2)
> > >   sp Fallon Dimen Farm Sums Family
> > > 1  1     14    10    6   30     NA
> > > 3  3     11    13    2   26     NA
> > >>
> > >> #next change the property logi to char least$Family <-
> > >> as.character(least$Family)
> > >> str(least)
> > > 'data.frame':    243 obs. of  6 variables:
> > >  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
> > >  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
> > >  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
> > >  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
> > >  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
> > >  $ Family: chr  NA NA NA NA ...
> > >>#  This is where I will grab the info to put into the above.
> > >> head(fam,2)
> > >          Family Sp
> > > 1   Scelionidae  1
> > > 2         Aphid  2
> > >>#  This shows the id of my object I want to copy  fam$Family[1]
> > > [1] Scelionidae
> > > 180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
> > >>
> > >># This shows me copying Scelionidae into dataframe least
> > >>least$Family[1] <- fam$Family[1]
> > >>
> > >>#    Here is where I don't get what I expect, but 158
> > >>str(least);
> > > 'data.frame':    243 obs. of  6 variables:
> > >  $ sp    : int  1 3 5 6 8 11 13 15 18 19 ...
> > >  $ Fallon: int  14 11 109 6 1 44 70 23 4 100 ...
> > >  $ Dimen : int  10 13 52 2 1 19 18 0 2 116 ...
> > >  $ Farm  : int  6 2 3 0 0 2 0 1 2 1 ...
> > >  $ Sums  : int  30 26 164 8 2 65 88 24 8 217 ...
> > >  $ Family: chr  "158" NA NA NA ...
> > >>head(least, 1)
> > >   sp Fallon Dimen Farm Sums Family
> > > 1  1     14     10        6       30    158
> > >>
> > >>#    Showing what I wanted to copy still exists.
> > >> fam$Family[1]
> > > [1] Scelionidae
> > > 180 Levels:  ? ? = 97 ? immature ? sp sample ?? ???? 1 2 3 ... wolf?
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Wed Nov 22 17:29:58 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 22 Nov 2017 10:29:58 -0600
Subject: [R] function pointers?
Message-ID: <CAErODj_B8-T8pgEbwanYxgPkw2FxFDZ76xeRaWJX3t9F+O1zHQ@mail.gmail.com>

We have a project that calls for the creation of a list of many
distribution objects.  Distributions can be of various types, with
various parameters, but we ran into some problems. I started testing
on a simple list of rnorm-based objects.

I was a little surprised at the RAM storage requirements, here's an example:

N <- 10000
closureList <- vector("list", N)
nsize = sample(x = 1:100, size = N, replace = TRUE)
for (i in seq_along(nsize)){
    closureList[[i]] <- list(func = rnorm, n = nsize[i])
}
format(object.size(closureList), units = "Mb")

Output says
22.4 MB

I noticed that if I do not name the objects in the list, then the
storage drops to 19.9 MB.

That seemed like a lot of storage for a function's name. Why so much?
My colleagues think the RAM use is high because this is a closure
(hence closureList).  I can't even convince myself it actually is a
closure. The R source has

rnorm <- function(n, mean=0, sd=1) .Call(C_rnorm, n, mean, sd)

The storage holding 10000 copies of rnorm, but we really only need 1,
which we can use in the objects.

Thinking of this like C,  I am looking to pass in a pointer to the
function.  I found my way to the idea of putting a function in an
environment in order to pass it by reference:

rnormPointer <- function(inputValue1, inputValue2){
    object <- new.env(parent=globalenv())
    object$distr <- inputValue1
    object$n <- inputValue2
    class(object) <- 'pointer'
    object
}

## Experiment with that
gg <- rnormPointer(rnorm, 33)
gg$distr(gg$n)

ptrList <- vector("list", N)
for(i in seq_along(nsize)) {
    ptrList[[i]] <- rnormPointer(rnorm, nsize[i])
}
format(object.size(ptrList), units = "Mb")

The required storage is reduced to 2.6 Mb. Thats 1/10 of the RAM
required for closureList.  This thing works in the way I expect

## can pass in the unnamed arguments for n, mean and sd here
ptrList[[1]]$distr(33, 100, 10)
## Or the named arguments
ptrList[[1]]$distr(1, sd = 100)

This environment trick mostly works, so far as I can see, but I have
these questions.

1. Is the object.size() return accurate for ptrList?  Do I really
reduce storage to that amount, or is the required storage someplace
else (in the new environment) that is not included in object.size()?

2. Am I running with scissors here? Unexpected bad things await?

3. Why is the storage for closureList so great? It looks to me like
rnorm is just this little thing:

function (n, mean = 0, sd = 1)
.Call(C_rnorm, n, mean, sd)
<bytecode: 0x55cc9988cae0>

4. Could I learn (you show me?) to store the bytecode address as a
thing and use it in the objects?  I'd guess that is the fastest
possible way. In an Objective-C problem in the olden days, we found
the method-lookup was a major slowdown and one of the programmers
showed us how to save the lookup and use it over and over.

pj



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From bgunter.4567 at gmail.com  Wed Nov 22 17:32:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 22 Nov 2017 08:32:33 -0800
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAGxFJbQReoUQpgir_e1CC5dW_aq_NkQvXbBYsSh=ty=2Zmi0ww@mail.gmail.com>

Do you mean like this:

mydf <- within(mydf, {
      is.na(A)<- !A_flag
      is.na(B)<- !B_flag
      }
   )

> mydf
   A A_flag  B B_flag
1  8     10  5     12
2 NA      0  6      9
3 10      1 NA      0
4 NA      0  1      5
5  5      2 NA      0


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 22, 2017 at 2:34 AM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

>
>
> Given this data frame (a simplified, essential reproducible example)
>
>
>
>
> A<-c(8,7,10,1,5)
>
> A_flag<-c(10,0,1,0,2)
>
> B<-c(5,6,2,1,0)
>
> B_flag<-c(12,9,0,5,0)
>
>
>
>
> mydf<-data.frame(A, A_flag, B, B_flag)
>
>
>
>
> # this is my initial df
>
> mydf
>
>
>
>
> I want to get to this final situation
>
>
>
>
> i<-which(mydf$A_flag==0)
>
> mydf$A[i]<-NA
>
>
>
>
> ii<-which(mydf$B_flag==0)
>
> mydf$B[ii]<-NA
>
>
>
>
> # this is my final df
>
> mydf
>
>
>
>
> By considering that I have to perform this task in a data frame with many
> columns I?m wondering if there is a compact and effective way to get the
> final result with just one ?sweep? of the dataframe?
>
>
>
>
> I was thinking to the function apply or lapply but I can not properly
> conceive how to?
>
>
>
>
> any hint for that?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Nov 22 18:38:26 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 22 Nov 2017 12:38:26 -0500
Subject: [R] function pointers?
In-Reply-To: <CAErODj_B8-T8pgEbwanYxgPkw2FxFDZ76xeRaWJX3t9F+O1zHQ@mail.gmail.com>
References: <CAErODj_B8-T8pgEbwanYxgPkw2FxFDZ76xeRaWJX3t9F+O1zHQ@mail.gmail.com>
Message-ID: <49ff7185-dbba-2212-53ff-0626e7da2a4b@gmail.com>

On 22/11/2017 11:29 AM, Paul Johnson wrote:
> We have a project that calls for the creation of a list of many
> distribution objects.  Distributions can be of various types, with
> various parameters, but we ran into some problems. I started testing
> on a simple list of rnorm-based objects.
> 
> I was a little surprised at the RAM storage requirements, here's an example:
> 
> N <- 10000
> closureList <- vector("list", N)
> nsize = sample(x = 1:100, size = N, replace = TRUE)
> for (i in seq_along(nsize)){
>      closureList[[i]] <- list(func = rnorm, n = nsize[i])
> }
> format(object.size(closureList), units = "Mb")
> 
> Output says
> 22.4 MB
> 

You should read the help page for object.size.  You're doing exactly the 
kind of thing that causes it to give overestimates of the amount of 
memory being used.

I'd suggest turning on memory profiling in Rprof() for a more accurate 
result, but it seems to be broken:

 > Rprof(memory.profiling=TRUE)
 > N <- 10000
 > closureList <- vector("list", N)
 > nsize = sample(x = 1:100, size = N, replace = TRUE)
 > for (i in seq_along(nsize)){
+     closureList[[i]] <- list(func = rnorm, n = nsize[i])
+ }
 > format(object.size(closureList), units = "Mb")
[1] "19.2 Mb"
 > Rprof(NULL)
 > summaryRprof()
Error in rowsum.default(c(as.vector(new.ftable), fcounts), 
c(names(new.ftable),  :
   unimplemented type 'NULL' in 'HashTableSetup'
In addition: Warning message:
In is.na(x) : is.na() applied to non-(list or vector) of type 'NULL'


Duncan Murdoch

> I noticed that if I do not name the objects in the list, then the
> storage drops to 19.9 MB.
> 
> That seemed like a lot of storage for a function's name. Why so much?
> My colleagues think the RAM use is high because this is a closure
> (hence closureList).  I can't even convince myself it actually is a
> closure. The R source has
> 
> rnorm <- function(n, mean=0, sd=1) .Call(C_rnorm, n, mean, sd)
> 
> The storage holding 10000 copies of rnorm, but we really only need 1,
> which we can use in the objects.
> 
> Thinking of this like C,  I am looking to pass in a pointer to the
> function.  I found my way to the idea of putting a function in an
> environment in order to pass it by reference:
> 
> rnormPointer <- function(inputValue1, inputValue2){
>      object <- new.env(parent=globalenv())
>      object$distr <- inputValue1
>      object$n <- inputValue2
>      class(object) <- 'pointer'
>      object
> }
> 
> ## Experiment with that
> gg <- rnormPointer(rnorm, 33)
> gg$distr(gg$n)
> 
> ptrList <- vector("list", N)
> for(i in seq_along(nsize)) {
>      ptrList[[i]] <- rnormPointer(rnorm, nsize[i])
> }
> format(object.size(ptrList), units = "Mb")
> 
> The required storage is reduced to 2.6 Mb. Thats 1/10 of the RAM
> required for closureList.  This thing works in the way I expect
> 
> ## can pass in the unnamed arguments for n, mean and sd here
> ptrList[[1]]$distr(33, 100, 10)
> ## Or the named arguments
> ptrList[[1]]$distr(1, sd = 100)
> 
> This environment trick mostly works, so far as I can see, but I have
> these questions.
> 
> 1. Is the object.size() return accurate for ptrList?  Do I really
> reduce storage to that amount, or is the required storage someplace
> else (in the new environment) that is not included in object.size()?
> 
> 2. Am I running with scissors here? Unexpected bad things await?
> 
> 3. Why is the storage for closureList so great? It looks to me like
> rnorm is just this little thing:
> 
> function (n, mean = 0, sd = 1)
> .Call(C_rnorm, n, mean, sd)
> <bytecode: 0x55cc9988cae0>
> 
> 4. Could I learn (you show me?) to store the bytecode address as a
> thing and use it in the objects?  I'd guess that is the fastest
> possible way. In an Objective-C problem in the olden days, we found
> the method-lookup was a major slowdown and one of the programmers
> showed us how to save the lookup and use it over and over.
> 
> pj
> 
> 
>


From e_f_sh at yahoo.com  Wed Nov 22 20:14:45 2017
From: e_f_sh at yahoo.com (Elham Fakharizade)
Date: Wed, 22 Nov 2017 19:14:45 +0000 (UTC)
Subject: [R] Fw: modified mankendal
In-Reply-To: <1817811789.954223.1511371398869@mail.yahoo.com>
References: <1817811789.954223.1511371398869.ref@mail.yahoo.com>
 <1817811789.954223.1511371398869@mail.yahoo.com>
Message-ID: <459423036.1023642.1511378085857@mail.yahoo.com>


 Hello DearI used modifiedmk package for trend analyses.this is my script
?require(modifiedmk)X1<-read.table("c:/elham/first article/r/Spring_NDVI-1.txt",skip=2,header=FALSE)d=dim(X1)
outMK<-matrix(-999,nrow=4,ncol=d[2])for (c in 1:d[2]){MK<-tfpwmk(X1[,c])outMK[1,c]<-getElement(MK,"S")outMK[2,c]<-getElement(MK,"Var(S)")outMK[3,c]<-getElement(MK,"Sen's Slope")outMK[4,c]<-getElement(MK,"P-value")}?unfortunetally I got this error:
Error in if (S == 0) { : missing value where TRUE/FALSE needed
would you please help me to solve itSincerely yoursElham


  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Nov 22 21:23:24 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 22 Nov 2017 12:23:24 -0800
Subject: [R] ccomp Composition and ggtern plot...
In-Reply-To: <D63B366B.1CC79%lterlemez@anadolu.edu.tr>
References: <D63B366B.1CC79%lterlemez@anadolu.edu.tr>
Message-ID: <28C94FF2-1EE3-42C9-B5F2-FA50CEBAFD4B@dcn.davis.ca.us>

I have no clue what this package is for, but reading the help page for the ccomp function tells you that it returns a numeric vector or matrix. How do YOU want to display information from this numeric vector? That will determine how you would put it into a data frame.
-- 
Sent from my phone. Please excuse my brevity.

On November 22, 2017 3:13:01 AM PST, Levent TERLEMEZ via R-help <r-help at r-project.org> wrote:
>Dear Users,
>
>I would like to use compositions package with ggplot/ggtern, other
>composition classes of compositional package can be used with ggtern by
>converting to data frame but I could do anything with c(ount)comp
>class. Ggplot/ggtern can not recognise comp and also can not be
>converted to data frame. Is there any other way to do this?
>
>Thank you in advance,
>
>Levent TERLEMEZ.
>
>
>
>________________________________
>
>Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da
>isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta
>olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel
>ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla
>ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z,
>y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen
>mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi
>bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda
>herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde
>olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve
>saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca
>g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini
>yans?tmayabilir.
>
>This electronic mail and any files transmitted with it are intended for
>the private use of the people named above. If you are not the intended
>recipient and received this message in error, forwarding, copying or
>use of any of the information is strictly prohibited. Any dissemination
>or use of this information by a person other than the intended
>recipient is unauthorized and may be illegal. In this case, please
>immediately notify the sender and delete it from your system. Anadolu
>University does not guarantee the accuracy or completeness of any
>information included in this message. Therefore, by any means Anadolu
>University is not responsible for the content of the message, and the
>transmission, reception, storage, and use of the information. The
>opinions expressed in this message only belong to the sender of it and
>may not reflect the opinions of Anadolu University.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From massimo.bressan at arpa.veneto.it  Thu Nov 23 08:52:07 2017
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 23 Nov 2017 08:52:07 +0100 (CET)
Subject: [R] assign NA to rows by test on multiple columns of a data
 frame
In-Reply-To: <CAGxFJbQReoUQpgir_e1CC5dW_aq_NkQvXbBYsSh=ty=2Zmi0ww@mail.gmail.com>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
 <CAGxFJbQReoUQpgir_e1CC5dW_aq_NkQvXbBYsSh=ty=2Zmi0ww@mail.gmail.com>
Message-ID: <720239457.29593020.1511423527744.JavaMail.zimbra@arpa.veneto.it>

yes, it works, even if I do not really get how and why it's working the combination of logical results (could you provide some insights for that?)

moreover, and most of all, I was hoping for a compact solution because I need to deal with MANY columns (more than 40) in data frame with the same basic structure as the simplified example I posted 

thanks

m


----- Messaggio originale -----
Da: "Bert Gunter" <bgunter.4567 at gmail.com>
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
Cc: "r-help" <r-help at r-project.org>
Inviato: Mercoled?, 22 novembre 2017 17:32:33
Oggetto: Re: [R] assign NA to rows by test on multiple columns of a data frame

Do you mean like this:

mydf <- within(mydf, {
      is.na(A)<- !A_flag
      is.na(B)<- !B_flag
      }
   )

> mydf
   A A_flag  B B_flag
1  8     10  5     12
2 NA      0  6      9
3 10      1 NA      0
4 NA      0  1      5
5  5      2 NA      0


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 22, 2017 at 2:34 AM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

>
>
> Given this data frame (a simplified, essential reproducible example)
>
>
>
>
> A<-c(8,7,10,1,5)
>
> A_flag<-c(10,0,1,0,2)
>
> B<-c(5,6,2,1,0)
>
> B_flag<-c(12,9,0,5,0)
>
>
>
>
> mydf<-data.frame(A, A_flag, B, B_flag)
>
>
>
>
> # this is my initial df
>
> mydf
>
>
>
>
> I want to get to this final situation
>
>
>
>
> i<-which(mydf$A_flag==0)
>
> mydf$A[i]<-NA
>
>
>
>
> ii<-which(mydf$B_flag==0)
>
> mydf$B[ii]<-NA
>
>
>
>
> # this is my final df
>
> mydf
>
>
>
>
> By considering that I have to perform this task in a data frame with many
> columns I?m wondering if there is a compact and effective way to get the
> final result with just one ?sweep? of the dataframe?
>
>
>
>
> I was thinking to the function apply or lapply but I can not properly
> conceive how to?
>
>
>
>
> any hint for that?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 


From stefano.sofia at regione.marche.it  Thu Nov 23 09:04:34 2017
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 23 Nov 2017 08:04:34 +0000
Subject: [R] How to produce rainfall maps
In-Reply-To: <CAAcGz9-N3MFiyeewc3V8OUicY+b4yjXXHBiucK5ZvDn1LeajvQ@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F471AE00E@ESINO.regionemarche.intra>
 <8B435C9568170B469AE31E8891E8CC4F471AE0D5@ESINO.regionemarche.intra>
 <CAM_vjunToO=sqFWPRRYcWJTL9AOh_3TBnNpcORo+oN-ZGhGR_w@mail.gmail.com>,
 <CAAcGz9-N3MFiyeewc3V8OUicY+b4yjXXHBiucK5ZvDn1LeajvQ@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F471BA3C2@CHIENTI.regionemarche.intra>

Thank you Sarah and Mike for your explanations.
My final objective is to produce maps (png image or any kind of extension I can import in LaTeX) where rainfall data are interpolated, using the Inverse Distance method or Kriging.
My input file (pointfile.csv in the reported example) reports the station code, lat and long of the meteorological station and the rainfall value (which might be the cumulate of a week or ten days or the period I need to investigate). Here a small example:

Station_Code, Init_Year, Init_Month, Init_Day, Init_Hour, Init_Minute, Fin_Year, Fin_Month, Fin_Day, Fin_Hour, Fin_Minute, Rainfall_Cumulate, Long, Lat
1056,  2017 , 11 , 1 , 0 , 0 ,  2017 , 11 , 11 , 0 , 0 ,  28.40, 12.786904,  43.851849
1064,  2017 , 11 , 1 , 0 , 0 ,  2017 , 11 , 11 , 0 , 0 ,  27.20, 12.967556,  43.762669
1072,  2017 , 11 , 1 , 0 , 0 ,  2017 , 11 , 11 , 0 , 0 ,  21.80, 12.897710,  43.907555

As far as I can understand (as you can see, I am not an expert on GIS or any spatial topic)
- my input file pointfile.csv is in "observation-per-row form";
- I need a grid (file.asc) where I can interpolate my rainfall data (I can get it, a resolution of 1km will be enough for me)
- ggplot should produce the map I need; but where are the options for the interpolation method?

Again, any help will be appreciated.
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area Nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------
________________________________
Da: Michael Sumner [mdsumner at gmail.com]
Inviato: mercoled? 22 novembre 2017 10.48
A: Sarah Goslee
Cc: Stefano Sofia; r-help at r-project.org
Oggetto: Re: [R] How to produce rainfall maps


Fwiw the engine behind geom_raster needs explicit observation-per-row form for input (with no structural normalization), so conversion to points is perfectly proper here,  albeit confusing in context. (It's closer to what graphics devices actually use ultimately, but the expansion is laid out very early in ggplot2 because there's no standard for intermediate forms.)

Cheers, Mike

On Wed, 22 Nov 2017, 07:12 Sarah Goslee, <sarah.goslee at gmail.com<mailto:sarah.goslee at gmail.com>> wrote:
Hi,

You might get more help from the R-sig-geo list, which is devoted to
spatial topics.

However.

The *.asc file is an ArcGIS raster export format. You should use
whatever the appropriate import commands are for your own gridded
rainfall data. If you have a different format, you might or might not
be able to import it directly with raster.

?raster will tell you more about the kinds of formats that function
can handle importing.

I'm not sure what the intent of converting a raster to point data
actually is; if you have point data, then import it as point data. If
you have gridded data, then map it as gridded data. But if it makes
sense to you, then go for it.

The comments in your code sample explain what the CSV file should be:
coordinates of the points to be mapped.

I'm not even certain from your question what your objective is.

What kind of rainfall data are you starting with?
What kind of maps do you want to produce?

Sarah



On Fri, Nov 17, 2017 at 3:40 AM, Stefano Sofia
<stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>> wrote:
> Dear R users,
> I need to produce rainfall maps using R.
> I know that this is possible, I looked though the web, I found the example below reported (the author is Andrew Tredennick).
> I would ask you if this is the most performing way to make rainfall maps; if yes would someone be able to give me an example of how file.asc and pointfile.csv should be? If no would somebody please show me another way providing a small example?
>
> Thank you for your help
> Stefano
>
>
> library(raster)
> library(ggplot2)
>
> #open ASCII file using ?raster? command, which converts the ASCII to a raster object
> map <- raster(?/your/path/to/file.asc?)
>
> #convert the raster to points for plotting
> map.p <- rasterToPoints(map)
>
> #Make the points a dataframe for ggplot
> df <- data.frame(map.p)
> #Make appropriate column headings
> colnames(df) <- c(?Longitude?, ?Latitude?, ?MAP?)
>
> #Call in point data, in this case a fake transect (csv file with lat and lon coordinates)
> sites <- data.frame(read.csv(?/your/path/to/pointfile.csv?))
>
> #Now make the map
> ggplot(data=df, aes(y=Latitude, x=Longitude)) +
> geom_raster(aes(fill=MAP)) +
> geom_point(data=sites, aes(x=x, y=y), color=?white?, size=3, shape=4) +
> theme_bw() +
> coord_equal() +
> scale_fill_gradient(?MAP (mm/yr)?, limits=c(0,2500)) +
> theme(axis.title.x = element_text(size=16),
> axis.title.y = element_text(size=16, angle=90),
> axis.text.x = element_text(size=14),
> axis.text.y = element_text(size=14),
> panel.grid.major = element_blank(),
> panel.grid.minor = element_blank(),
> legend.position = ?right?,
> legend.key = element_blank()
> )
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
> ---Oo---------oO----------------
>


--
Sarah Goslee
http://www.functionaldiversity.org

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From R.E.Crump at warwick.ac.uk  Thu Nov 23 12:44:24 2017
From: R.E.Crump at warwick.ac.uk (Crump, Ron)
Date: Thu, 23 Nov 2017 11:44:24 +0000
Subject: [R] ccomp Composition and ggtern plot...
Message-ID: <effdecca-a949-5dc9-6dcd-0d25171c5ecd@warwick.ac.uk>

> I would like to use compositions package with ggplot/ggtern, other
> composition classes of compositional package can be used with ggtern
> by converting to data frame but I could do anything with c(ount)comp
> class. Ggplot/ggtern can not recognise comp and also can not be converted > to data frame. Is there any other way to do this?

As Jeff pointed out, the help page says ccomp creates a vector
or matrix. But it assigns a class of 'ccomp', and there is no
obvious way to coerce this directly to a data.frame for use with
ggplot (but I'm not very good with classes so I may be wrong).

However, it does appear to be just a matrix(or vector) with a
class added (I presume to facilitate the provision of class
specific functions), so you can convert it to a matrix (vector)
with attr( my_ccomp, 'class' ) <- NULL and go from there.

eg

library(compositions)
data(SimulatedAmounts)
my_ccomp <- ccomp(sa.lognormals)
print(class(my_ccomp))
attr(my_ccomp,'class')<-NULL
print(class(my_ccomp))
my_ccomp_df <- as.data.frame(my_ccomp)
# or, as I've just seen in the code of plot.ccomp,
# my_ccomp_df <- as.data.frame(unclass(my_ccomp))

Regards,
Ron.

From lterlemez at anadolu.edu.tr  Thu Nov 23 12:54:32 2017
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Thu, 23 Nov 2017 11:54:32 +0000
Subject: [R] ccomp Composition and ggtern plot...
In-Reply-To: <28C94FF2-1EE3-42C9-B5F2-FA50CEBAFD4B@dcn.davis.ca.us>
References: <D63B366B.1CC79%lterlemez@anadolu.edu.tr>
 <28C94FF2-1EE3-42C9-B5F2-FA50CEBAFD4B@dcn.davis.ca.us>
Message-ID: <D63C901E.1CC9B%lterlemez@anadolu.edu.tr>

Thank you for your kind and quick answers, Jeff Newmiller and Ron Crump. I
looked at the help pages, but I missed the point you underlined.. Solved
the problem.

Levent TERLEMEZ.



On 22.11.2017 23:23, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

>I have no clue what this package is for, but reading the help page for
>the ccomp function tells you that it returns a numeric vector or matrix.
>How do YOU want to display information from this numeric vector? That
>will determine how you would put it into a data frame.
>--
>Sent from my phone. Please excuse my brevity.
>
>On November 22, 2017 3:13:01 AM PST, Levent TERLEMEZ via R-help
><r-help at r-project.org> wrote:
>>Dear Users,
>>
>>I would like to use compositions package with ggplot/ggtern, other
>>composition classes of compositional package can be used with ggtern by
>>converting to data frame but I could do anything with c(ount)comp
>>class. Ggplot/ggtern can not recognise comp and also can not be
>>converted to data frame. Is there any other way to do this?
>>
>>Thank you in advance,
>>
>>Levent TERLEMEZ.
>>
>>
>>
>>________________________________
>>
>>Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da
>>isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta
>>olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel
>>ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla
>>ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z,
>>y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen
>>mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi
>>bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda
>>herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde
>>olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve
>>saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca
>>g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini
>>yans?tmayabilir.
>>
>>This electronic mail and any files transmitted with it are intended for
>>the private use of the people named above. If you are not the intended
>>recipient and received this message in error, forwarding, copying or
>>use of any of the information is strictly prohibited. Any dissemination
>>or use of this information by a person other than the intended
>>recipient is unauthorized and may be illegal. In this case, please
>>immediately notify the sender and delete it from your system. Anadolu
>>University does not guarantee the accuracy or completeness of any
>>information included in this message. Therefore, by any means Anadolu
>>University is not responsible for the content of the message, and the
>>transmission, reception, storage, and use of the information. The
>>opinions expressed in this message only belong to the sender of it and
>>may not reflect the opinions of Anadolu University.
>>
>>      [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.



________________________________

Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z, y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini yans?tmayabilir.

This electronic mail and any files transmitted with it are intended for the private use of the people named above. If you are not the intended recipient and received this message in error, forwarding, copying or use of any of the information is strictly prohibited. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal. In this case, please immediately notify the sender and delete it from your system. Anadolu University does not guarantee the accuracy or completeness of any information included in this message. Therefore, by any means Anadolu University is not responsible for the content of the message, and the transmission, reception, storage, and use of the information. The opinions expressed in this message only belong to the sender of it and may not reflect the opinions of Anadolu University.

From loris.bennett at fu-berlin.de  Thu Nov 23 13:34:01 2017
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 23 Nov 2017 13:34:01 +0100
Subject: [R] libPaths displays truncated path?
Message-ID: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>

Hi,

TL;DR
-----

  I define the path

    /cm/shared/apps/R/site-library/3.4.2

  and add it to libPath.  Why does libPath then display it as

    /cm/shared/apps/R/site-library/3.4

  ?

Long version
------------

I run a cluster of diskless nodes for which the OS is loaded
directly into RAM and other software is provided by an NFS server.
However, in the case of R, we use the R version provided by the OS and
just install additional packages on the NFS server.

So that R can find these additional packages, I have the following in
the site-wide Rprofile

  v <- R.Version()
  base_path = "/cm/shared/apps/R/site-library/"
  major_minor_version = paste(v["major"],v["minor"],sep=".")
  cm_shared_lib_path = paste0(base_path,major_minor_version)
  full_cm_shared_lib_path <- c(file.path(chartr("\\", "/", R.home()), "site-library"), cm_shared_lib_path)
  .libPaths( c( .libPaths(), full_cm_shared_lib_path ) )

Thus, when I start R I get this:

  > full_cm_shared_lib_path
  [1] "/usr/lib64/R/site-library"           
  [2] "/cm/shared/apps/R/site-library/3.4.2"

but also this

   > .libPaths()
  [1] "/home/loris/R/x86_64-redhat-linux-gnu-library/3.4"
  [2] "/usr/lib64/R/library"                             
  [3] "/usr/share/R/library"                             
  [4] "/usr/lib64/R/site-library"                        
  [5] "/cm/shared/apps/R/site-library/3.4"       

However, in order to get R to find the packages, I have to add a
symbolic link, thus:

  [/cm/shared/apps/R/site-library] $ ls -l 3.4.2
  lrwxrwxrwx 1 root root 3 Nov 23 09:21 3.4.2 -> 3.4

So, my mistake was to think that "minor" would return "4", whereas it in
fact returns "4.2".  So I actually set the path to ".../3.4.2" and
that's where R looks for packages.

But why does libPaths display the the path I *thought* I had set, but in
fact looks at the path I *really did* set?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From eliza_botto at outlook.com  Thu Nov 23 15:30:53 2017
From: eliza_botto at outlook.com (Eliza Botto)
Date: Thu, 23 Nov 2017 14:30:53 +0000
Subject: [R] adding percentage secondary y-axis
Message-ID: <DB6PR0901MB1192F2D3A39844569038599A9A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>

Dear useRs,


I have this dataset (D) with three columns.


> dput(D)

structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
16, 17, 18, 19, 20, 2.990484802, 3.005018792, 3.019552781, 3.03408677,
3.048620759, 3.063154749, 3.077688738, 3.092222727, 3.106756717,
3.121290706, 3.135824695, 3.150358684, 3.164892674, 3.179426663,
3.193960652, 3.208494642, 3.223028631, 3.23756262, 3.252096609,
3.266630599, 0.488381368, 0.976762736, 1.465144104, 1.953525472,
2.44190684, 2.930288208, 3.418669576, 3.907050944, 4.395432311,
4.883813679, 5.372195047, 5.860576415, 6.348957783, 6.837339151,
7.325720519, 7.814101887, 8.302483255, 8.790864623, 9.279245991,
9.767627359), .Dim = c(20L, 3L))


The first column represents the index values while the second column contains the response values. The third column in actually the percentage increase in the response values by increasing a unit index value.


I made a plot and obtained a single line by;


>plot(D[,1],D[,2],type="l")


The primary y-axis represents the usual response values. Now I want to add a secondary y-axis representing  the percentage value shown against response value. So that, when a reader sees the graph she could easily visualize not only the decimal response value but also the percentage increase against that response value from the secondary axis without plotting any extra line.


I thank you in advance,


Stay Blessed!!!!



Eliza


UoS

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Nov 23 16:51:02 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 23 Nov 2017 07:51:02 -0800
Subject: [R] assign NA to rows by test on multiple columns of a data
	frame
In-Reply-To: <720239457.29593020.1511423527744.JavaMail.zimbra@arpa.veneto.it>
References: <32231001.29470595.1511346890032.JavaMail.zimbra@arpa.veneto.it>
 <CAGxFJbQReoUQpgir_e1CC5dW_aq_NkQvXbBYsSh=ty=2Zmi0ww@mail.gmail.com>
 <720239457.29593020.1511423527744.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAGxFJbTABG4PiB7epykpELuRYk6D8Vs2fXPAsuXnh1+quSsk_w@mail.gmail.com>

Inline.

-- Bert


On Wed, Nov 22, 2017 at 11:52 PM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

> yes, it works, even if I do not really get how and why it's working the
> combination of logical results (could you provide some insights for that?)
>


Read the docs!

?"!"
?NA

explain

Then a more "compact" (but probably less efficient) solution just loops
over the indices:

##UNTESTED
choices <- ***column numbers of _flag columns***
chng <- ***column numbers of columns that will have values changed to NA***
for(i in seq_along choices) mydf[, ] <- is.na(mydf[, chng[i]) <- !mydf[,
choices[i]]




>
> moreover, and most of all, I was hoping for a compact solution because I
> need to deal with MANY columns (more than 40) in data frame with the same
> basic structure as the simplified example I posted
>
> thanks
>
> m
>
>
> ----- Messaggio originale -----
> Da: "Bert Gunter" <bgunter.4567 at gmail.com>
> A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> Cc: "r-help" <r-help at r-project.org>
> Inviato: Mercoled?, 22 novembre 2017 17:32:33
> Oggetto: Re: [R] assign NA to rows by test on multiple columns of a data
> frame
>
> Do you mean like this:
>
> mydf <- within(mydf, {
>       is.na(A)<- !A_flag
>       is.na(B)<- !B_flag
>       }
>    )
>
> > mydf
>    A A_flag  B B_flag
> 1  8     10  5     12
> 2 NA      0  6      9
> 3 10      1 NA      0
> 4 NA      0  1      5
> 5  5      2 NA      0
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Nov 22, 2017 at 2:34 AM, Massimo Bressan <
> massimo.bressan at arpa.veneto.it> wrote:
>
> >
> >
> > Given this data frame (a simplified, essential reproducible example)
> >
> >
> >
> >
> > A<-c(8,7,10,1,5)
> >
> > A_flag<-c(10,0,1,0,2)
> >
> > B<-c(5,6,2,1,0)
> >
> > B_flag<-c(12,9,0,5,0)
> >
> >
> >
> >
> > mydf<-data.frame(A, A_flag, B, B_flag)
> >
> >
> >
> >
> > # this is my initial df
> >
> > mydf
> >
> >
> >
> >
> > I want to get to this final situation
> >
> >
> >
> >
> > i<-which(mydf$A_flag==0)
> >
> > mydf$A[i]<-NA
> >
> >
> >
> >
> > ii<-which(mydf$B_flag==0)
> >
> > mydf$B[ii]<-NA
> >
> >
> >
> >
> > # this is my final df
> >
> > mydf
> >
> >
> >
> >
> > By considering that I have to perform this task in a data frame with many
> > columns I?m wondering if there is a compact and effective way to get the
> > final result with just one ?sweep? of the dataframe?
> >
> >
> >
> >
> > I was thinking to the function apply or lapply but I can not properly
> > conceive how to?
> >
> >
> >
> >
> > any hint for that?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> --
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Nov 23 17:22:39 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 23 Nov 2017 16:22:39 +0000
Subject: [R] adding percentage secondary y-axis
In-Reply-To: <DB6PR0901MB1192F2D3A39844569038599A9A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
References: <DB6PR0901MB1192F2D3A39844569038599A9A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB421@SRVEXCHCM301.precheza.cz>

Hi

It is usually not recommended but if you insist

maybe
library(plotrix)
?twoord.plot
twoord.plot(lx=D[,1],ly=D[,2], rx=D[,1], ry=D[,3])

or

plot.yy(x=D[,1],yright=D[,3], yleft=D[,2])

which allows only one x axis (see below).

Cheers
Petr

plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,
    xlab = NULL, yylab = list(NA, NA), pch = c(1, 2),
    col = c(1,2), linky = F, smooth = 0, lwds = 1, length = 10,
        format = "%d/%m", rect = NULL, type = "p", ...)
{
    par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
    plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,
        pch = pch[1], col = col[1], type = type, ...)
    if (!is.null(rect))
        rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
    points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab,
        pch = pch[1], col = col[1], ...)
    axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
    if (linky)
        lines(x, yright, col = col[1], ...)
    if (smooth != 0)
        lines(supsmu(x, yright, span = smooth), col = col[1],
            lwd = lwds, ...)
    if (is.na(yylab[[1]]))
        mtext(deparse(substitute(yright)), side = 4, outer = T,
            line = 1, col = col[1], ...)
    else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],
        ...)
    par(new = T)
    plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
        pch = pch[2], col = col[2], ...)
    box()
    axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
        col.axis = col[2])
    if (!inherits(x, c("Date", "POSIXt")))
        axis(1, pretty(range(x, na.rm = T), 10))
    else {
        if (inherits(x, "POSIXt")) {
            l <- length(x)
            axis(1, at = x[seq(1, l, length = length)],
            labels = format(as.POSIXct(x[seq(1,l, length = length)]),
            format = format))
        }
        else {
            if (inherits(x, "Date")) {
                l <- length(x)
                axis(1, at = x[seq(1, l, length = length)],
                labels = format(as.Date(x[seq(1,l, length = length)]),
                format = format))
            }
            else {
                print("Not suitable x axis")
            }
        }
    }
    if (is.na(yylab[[2]]))
        mtext(deparse(substitute(yleft)), side = 2, line = 2,
            col = col[2], ...)
    else mtext(yylab[[2]], side = 2, line = 2, col = col[2],
        ...)
    if (linky)
        lines(x, yleft, col = col[2], lty = 2, ...)
    if (smooth != 0)
        lines(supsmu(x, yleft, span = smooth), col = col[2],
            lty = 2, lwd = lwds, ...)
  }





> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eliza Botto
> Sent: Thursday, November 23, 2017 3:31 PM
> To: r-help at r-project.org
> Subject: [R] adding percentage secondary y-axis
>
> Dear useRs,
>
>
> I have this dataset (D) with three columns.
>
>
> > dput(D)
>
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
> 2.990484802, 3.005018792, 3.019552781, 3.03408677, 3.048620759,
> 3.063154749, 3.077688738, 3.092222727, 3.106756717, 3.121290706,
> 3.135824695, 3.150358684, 3.164892674, 3.179426663, 3.193960652,
> 3.208494642, 3.223028631, 3.23756262, 3.252096609, 3.266630599,
> 0.488381368, 0.976762736, 1.465144104, 1.953525472, 2.44190684,
> 2.930288208, 3.418669576, 3.907050944, 4.395432311, 4.883813679,
> 5.372195047, 5.860576415, 6.348957783, 6.837339151, 7.325720519,
> 7.814101887, 8.302483255, 8.790864623, 9.279245991, 9.767627359), .Dim =
> c(20L, 3L))
>
>
> The first column represents the index values while the second column contains
> the response values. The third column in actually the percentage increase in the
> response values by increasing a unit index value.
>
>
> I made a plot and obtained a single line by;
>
>
> >plot(D[,1],D[,2],type="l")
>
>
> The primary y-axis represents the usual response values. Now I want to add a
> secondary y-axis representing  the percentage value shown against response
> value. So that, when a reader sees the graph she could easily visualize not only
> the decimal response value but also the percentage increase against that
> response value from the secondary axis without plotting any extra line.
>
>
> I thank you in advance,
>
>
> Stay Blessed!!!!
>
>
>
> Eliza
>
>
> UoS
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ccberry at ucsd.edu  Thu Nov 23 17:29:39 2017
From: ccberry at ucsd.edu (Berry, Charles)
Date: Thu, 23 Nov 2017 16:29:39 +0000
Subject: [R] libPaths displays truncated path?
In-Reply-To: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
References: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <2D0457B5-8BC5-465C-8952-7D3627345326@ucsd.edu>


> On Nov 23, 2017, at 4:34 AM, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
> 
> Hi,
> 
> TL;DR
> -----
> 
>  I define the path
> 
>    /cm/shared/apps/R/site-library/3.4.2
> 
>  and add it to libPath.  Why does libPath then display it as
> 
>    /cm/shared/apps/R/site-library/3.4
> 
>  ?
> 

Because it is a symbolic link.

?.libPaths says

"For consistency, the paths are always normalized by normalizePath(winslash = "/")."

and ?normalizePath says

"...the Unix-alike platform ... attempts to turn paths into absolute paths in their canonical form (no ./, ../ nor symbolic links)."  

HTH,

Chuck

From dwinsemius at comcast.net  Thu Nov 23 17:36:46 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 23 Nov 2017 08:36:46 -0800
Subject: [R] libPaths displays truncated path?
In-Reply-To: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
References: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <AA86BB48-320F-46EF-ACFC-4EB878ED6CC4@comcast.net>


> On Nov 23, 2017, at 4:34 AM, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
> 
> Hi,
> 
> TL;DR
> -----
> 
>  I define the path
> 
>    /cm/shared/apps/R/site-library/3.4.2
> 
>  and add it to libPath.  Why does libPath then display it as
> 
>    /cm/shared/apps/R/site-library/3.4

Generally one only has a different library for each major version of R. Major versions are consider just the first two numbers in the dot-separated versions system. Apparently libPaths is "smart" enough to make an effort to adhere to that convention.  It appears your definition of "major" differs from the usual convention.

-- 
David
> 
>  ?
> 
> Long version
> ------------
> 
> I run a cluster of diskless nodes for which the OS is loaded
> directly into RAM and other software is provided by an NFS server.
> However, in the case of R, we use the R version provided by the OS and
> just install additional packages on the NFS server.
> 
> So that R can find these additional packages, I have the following in
> the site-wide Rprofile
> 
>  v <- R.Version()
>  base_path = "/cm/shared/apps/R/site-library/"
>  major_minor_version = paste(v["major"],v["minor"],sep=".")
>  cm_shared_lib_path = paste0(base_path,major_minor_version)
>  full_cm_shared_lib_path <- c(file.path(chartr("\\", "/", R.home()), "site-library"), cm_shared_lib_path)
>  .libPaths( c( .libPaths(), full_cm_shared_lib_path ) )
> 
> Thus, when I start R I get this:
> 
>> full_cm_shared_lib_path
>  [1] "/usr/lib64/R/site-library"           
>  [2] "/cm/shared/apps/R/site-library/3.4.2"
> 
> but also this
> 
>> .libPaths()
>  [1] "/home/loris/R/x86_64-redhat-linux-gnu-library/3.4"
>  [2] "/usr/lib64/R/library"                             
>  [3] "/usr/share/R/library"                             
>  [4] "/usr/lib64/R/site-library"                        
>  [5] "/cm/shared/apps/R/site-library/3.4"       
> 
> However, in order to get R to find the packages, I have to add a
> symbolic link, thus:
> 
>  [/cm/shared/apps/R/site-library] $ ls -l 3.4.2
>  lrwxrwxrwx 1 root root 3 Nov 23 09:21 3.4.2 -> 3.4
> 
> So, my mistake was to think that "minor" would return "4", whereas it in
> fact returns "4.2".  So I actually set the path to ".../3.4.2" and
> that's where R looks for packages.
> 
> But why does libPaths display the the path I *thought* I had set, but in
> fact looks at the path I *really did* set?
> 
> Cheers,
> 
> Loris
> 
> -- 
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jholtman at gmail.com  Thu Nov 23 17:57:08 2017
From: jholtman at gmail.com (jim holtman)
Date: Thu, 23 Nov 2017 11:57:08 -0500
Subject: [R] function pointers?
In-Reply-To: <CAErODj_B8-T8pgEbwanYxgPkw2FxFDZ76xeRaWJX3t9F+O1zHQ@mail.gmail.com>
References: <CAErODj_B8-T8pgEbwanYxgPkw2FxFDZ76xeRaWJX3t9F+O1zHQ@mail.gmail.com>
Message-ID: <CAAxdm-42BfWBRzzdv=J2fKNNQSgN=JxKxPcT7oBQN6+wCpaaEA@mail.gmail.com>

I am replying to the first part of the question about the size of the
object.  It is probably best to use the "object_size" function in the
"pryr" package:

 ?object_size? works similarly to ?object.size?, but counts more
     accurately and includes the size of environments. ?compare_size?
     makes it easy to compare the output of ?object_size? and
     ?object.size?.

Here is what you get from the same code:

> N <- 10000
> closureList <- vector("list", N)
> nsize = sample(x = 1:100, size = N, replace = TRUE)
> for (i in seq_along(nsize)){
+     closureList[[i]] <- list(func = rnorm, n = nsize[i])
+ }
> format(object.size(closureList), units = "Mb")
[1] "22.4 Mb"
> pryr::compare_size(closureList)
    base     pryr
23520040  2241776

You will notice that you get back a size that is 10X smaller because it is
accounting for the shared space.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Nov 22, 2017 at 11:29 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:

> We have a project that calls for the creation of a list of many
> distribution objects.  Distributions can be of various types, with
> various parameters, but we ran into some problems. I started testing
> on a simple list of rnorm-based objects.
>
> I was a little surprised at the RAM storage requirements, here's an
> example:
>
> N <- 10000
> closureList <- vector("list", N)
> nsize = sample(x = 1:100, size = N, replace = TRUE)
> for (i in seq_along(nsize)){
>     closureList[[i]] <- list(func = rnorm, n = nsize[i])
> }
> format(object.size(closureList), units = "Mb")
>
> Output says
> 22.4 MB
>
> I noticed that if I do not name the objects in the list, then the
> storage drops to 19.9 MB.
>
> That seemed like a lot of storage for a function's name. Why so much?
> My colleagues think the RAM use is high because this is a closure
> (hence closureList).  I can't even convince myself it actually is a
> closure. The R source has
>
> rnorm <- function(n, mean=0, sd=1) .Call(C_rnorm, n, mean, sd)
>
> The storage holding 10000 copies of rnorm, but we really only need 1,
> which we can use in the objects.
>
> Thinking of this like C,  I am looking to pass in a pointer to the
> function.  I found my way to the idea of putting a function in an
> environment in order to pass it by reference:
>
> rnormPointer <- function(inputValue1, inputValue2){
>     object <- new.env(parent=globalenv())
>     object$distr <- inputValue1
>     object$n <- inputValue2
>     class(object) <- 'pointer'
>     object
> }
>
> ## Experiment with that
> gg <- rnormPointer(rnorm, 33)
> gg$distr(gg$n)
>
> ptrList <- vector("list", N)
> for(i in seq_along(nsize)) {
>     ptrList[[i]] <- rnormPointer(rnorm, nsize[i])
> }
> format(object.size(ptrList), units = "Mb")
>
> The required storage is reduced to 2.6 Mb. Thats 1/10 of the RAM
> required for closureList.  This thing works in the way I expect
>
> ## can pass in the unnamed arguments for n, mean and sd here
> ptrList[[1]]$distr(33, 100, 10)
> ## Or the named arguments
> ptrList[[1]]$distr(1, sd = 100)
>
> This environment trick mostly works, so far as I can see, but I have
> these questions.
>
> 1. Is the object.size() return accurate for ptrList?  Do I really
> reduce storage to that amount, or is the required storage someplace
> else (in the new environment) that is not included in object.size()?
>
> 2. Am I running with scissors here? Unexpected bad things await?
>
> 3. Why is the storage for closureList so great? It looks to me like
> rnorm is just this little thing:
>
> function (n, mean = 0, sd = 1)
> .Call(C_rnorm, n, mean, sd)
> <bytecode: 0x55cc9988cae0>
>
> 4. Could I learn (you show me?) to store the bytecode address as a
> thing and use it in the objects?  I'd guess that is the fastest
> possible way. In an Objective-C problem in the olden days, we found
> the method-lookup was a major slowdown and one of the programmers
> showed us how to save the lookup and use it over and over.
>
> pj
>
>
>
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From eliza_botto at outlook.com  Thu Nov 23 18:28:22 2017
From: eliza_botto at outlook.com (Eliza Botto)
Date: Thu, 23 Nov 2017 17:28:22 +0000
Subject: [R] adding percentage secondary y-axis
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB421@SRVEXCHCM301.precheza.cz>
References: <DB6PR0901MB1192F2D3A39844569038599A9A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>,
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB421@SRVEXCHCM301.precheza.cz>
Message-ID: <DB6PR0901MB1192E919F0B3F6BFFB36E0D59A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>

Thank you very much peter.

It worked out nicely.

I have additional question. How can I get Y-axis on log-scale?

Thank you very much in Advance,


Eliza

UoS
PP


________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: 23 November 2017 16:22:39
To: Eliza Botto; r-help at r-project.org
Subject: RE: adding percentage secondary y-axis

Hi

It is usually not recommended but if you insist

maybe
library(plotrix)
?twoord.plot
twoord.plot(lx=D[,1],ly=D[,2], rx=D[,1], ry=D[,3])

or

plot.yy(x=D[,1],yright=D[,3], yleft=D[,2])

which allows only one x axis (see below).

Cheers
Petr

plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,
    xlab = NULL, yylab = list(NA, NA), pch = c(1, 2),
    col = c(1,2), linky = F, smooth = 0, lwds = 1, length = 10,
        format = "%d/%m", rect = NULL, type = "p", ...)
{
    par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
    plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,
        pch = pch[1], col = col[1], type = type, ...)
    if (!is.null(rect))
        rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
    points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab,
        pch = pch[1], col = col[1], ...)
    axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
    if (linky)
        lines(x, yright, col = col[1], ...)
    if (smooth != 0)
        lines(supsmu(x, yright, span = smooth), col = col[1],
            lwd = lwds, ...)
    if (is.na(yylab[[1]]))
        mtext(deparse(substitute(yright)), side = 4, outer = T,
            line = 1, col = col[1], ...)
    else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],
        ...)
    par(new = T)
    plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
        pch = pch[2], col = col[2], ...)
    box()
    axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
        col.axis = col[2])
    if (!inherits(x, c("Date", "POSIXt")))
        axis(1, pretty(range(x, na.rm = T), 10))
    else {
        if (inherits(x, "POSIXt")) {
            l <- length(x)
            axis(1, at = x[seq(1, l, length = length)],
            labels = format(as.POSIXct(x[seq(1,l, length = length)]),
            format = format))
        }
        else {
            if (inherits(x, "Date")) {
                l <- length(x)
                axis(1, at = x[seq(1, l, length = length)],
                labels = format(as.Date(x[seq(1,l, length = length)]),
                format = format))
            }
            else {
                print("Not suitable x axis")
            }
        }
    }
    if (is.na(yylab[[2]]))
        mtext(deparse(substitute(yleft)), side = 2, line = 2,
            col = col[2], ...)
    else mtext(yylab[[2]], side = 2, line = 2, col = col[2],
        ...)
    if (linky)
        lines(x, yleft, col = col[2], lty = 2, ...)
    if (smooth != 0)
        lines(supsmu(x, yleft, span = smooth), col = col[2],
            lty = 2, lwd = lwds, ...)
  }





> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eliza Botto
> Sent: Thursday, November 23, 2017 3:31 PM
> To: r-help at r-project.org
> Subject: [R] adding percentage secondary y-axis
>
> Dear useRs,
>
>
> I have this dataset (D) with three columns.
>
>
> > dput(D)
>
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
> 2.990484802, 3.005018792, 3.019552781, 3.03408677, 3.048620759,
> 3.063154749, 3.077688738, 3.092222727, 3.106756717, 3.121290706,
> 3.135824695, 3.150358684, 3.164892674, 3.179426663, 3.193960652,
> 3.208494642, 3.223028631, 3.23756262, 3.252096609, 3.266630599,
> 0.488381368, 0.976762736, 1.465144104, 1.953525472, 2.44190684,
> 2.930288208, 3.418669576, 3.907050944, 4.395432311, 4.883813679,
> 5.372195047, 5.860576415, 6.348957783, 6.837339151, 7.325720519,
> 7.814101887, 8.302483255, 8.790864623, 9.279245991, 9.767627359), .Dim =
> c(20L, 3L))
>
>
> The first column represents the index values while the second column contains
> the response values. The third column in actually the percentage increase in the
> response values by increasing a unit index value.
>
>
> I made a plot and obtained a single line by;
>
>
> >plot(D[,1],D[,2],type="l")
>
>
> The primary y-axis represents the usual response values. Now I want to add a
> secondary y-axis representing  the percentage value shown against response
> value. So that, when a reader sees the graph she could easily visualize not only
> the decimal response value but also the percentage increase against that
> response value from the secondary axis without plotting any extra line.
>
>
> I thank you in advance,
>
>
> Stay Blessed!!!!
>
>
>
> Eliza
>
>
> UoS
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Nov 23 19:07:40 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 23 Nov 2017 19:07:40 +0100
Subject: [R] libPaths displays truncated path?
In-Reply-To: <AA86BB48-320F-46EF-ACFC-4EB878ED6CC4@comcast.net>
References: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
 <AA86BB48-320F-46EF-ACFC-4EB878ED6CC4@comcast.net>
Message-ID: <D7CCFDF4-A797-4B3C-B2DC-D92D59273AD4@gmail.com>


> On 23 Nov 2017, at 17:36 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Nov 23, 2017, at 4:34 AM, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>> 
>> Hi,
>> 
>> TL;DR
>> -----
>> 
>> I define the path
>> 
>>   /cm/shared/apps/R/site-library/3.4.2
>> 
>> and add it to libPath.  Why does libPath then display it as
>> 
>>   /cm/shared/apps/R/site-library/3.4
> 
> Generally one only has a different library for each major version of R. Major versions are consider just the first two numbers in the dot-separated versions system. Apparently libPaths is "smart" enough to make an effort to adhere to that convention.  It appears your definition of "major" differs from the usual convention.

Nope. Chuck B. is almost certainly right: The symlink did it, with the normalizePath, in .libPaths(). (And the OP has cause and effect reversed.)

Not even R functions are smart enough to make a decision like you suggest without actually containing code to do it:

> .libPaths
function (new) 
{
    if (!missing(new)) {
        new <- Sys.glob(path.expand(new))
        paths <- c(new, .Library.site, .Library)
        paths <- paths[dir.exists(paths)]
        .lib.loc <<- unique(normalizePath(paths, "/"))
    }
    else .lib.loc
}
<bytecode: 0x10219a988>
<environment: 0x1021985f0>

-pd

> 
> -- 
> David
>> 
>> ?
>> 
>> Long version
>> ------------
>> 
>> I run a cluster of diskless nodes for which the OS is loaded
>> directly into RAM and other software is provided by an NFS server.
>> However, in the case of R, we use the R version provided by the OS and
>> just install additional packages on the NFS server.
>> 
>> So that R can find these additional packages, I have the following in
>> the site-wide Rprofile
>> 
>> v <- R.Version()
>> base_path = "/cm/shared/apps/R/site-library/"
>> major_minor_version = paste(v["major"],v["minor"],sep=".")
>> cm_shared_lib_path = paste0(base_path,major_minor_version)
>> full_cm_shared_lib_path <- c(file.path(chartr("\\", "/", R.home()), "site-library"), cm_shared_lib_path)
>> .libPaths( c( .libPaths(), full_cm_shared_lib_path ) )
>> 
>> Thus, when I start R I get this:
>> 
>>> full_cm_shared_lib_path
>> [1] "/usr/lib64/R/site-library"           
>> [2] "/cm/shared/apps/R/site-library/3.4.2"
>> 
>> but also this
>> 
>>> .libPaths()
>> [1] "/home/loris/R/x86_64-redhat-linux-gnu-library/3.4"
>> [2] "/usr/lib64/R/library"                             
>> [3] "/usr/share/R/library"                             
>> [4] "/usr/lib64/R/site-library"                        
>> [5] "/cm/shared/apps/R/site-library/3.4"       
>> 
>> However, in order to get R to find the packages, I have to add a
>> symbolic link, thus:
>> 
>> [/cm/shared/apps/R/site-library] $ ls -l 3.4.2
>> lrwxrwxrwx 1 root root 3 Nov 23 09:21 3.4.2 -> 3.4
>> 
>> So, my mistake was to think that "minor" would return "4", whereas it in
>> fact returns "4.2".  So I actually set the path to ".../3.4.2" and
>> that's where R looks for packages.
>> 
>> But why does libPaths display the the path I *thought* I had set, but in
>> fact looks at the path I *really did* set?
>> 
>> Cheers,
>> 
>> Loris
>> 
>> -- 
>> Dr. Loris Bennett (Mr.)
>> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at yahoo.ca  Thu Nov 23 19:21:41 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 23 Nov 2017 18:21:41 +0000 (UTC)
Subject: [R] adding percentage secondary y-axis
In-Reply-To: <DB6PR0901MB1192E919F0B3F6BFFB36E0D59A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
References: <DB6PR0901MB1192F2D3A39844569038599A9A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB421@SRVEXCHCM301.precheza.cz>
 <DB6PR0901MB1192E919F0B3F6BFFB36E0D59A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
Message-ID: <543813851.1465860.1511461301059@mail.yahoo.com>

 
Actually Petr, I don't see that a secondary y-axis a problem here. If I understand it correctly Eliza is simply presenting the same data against two different scales. We in North America sometimes need to do the same thing when graphing, say? temperature data. We might want degrees Celsius on the y-axis and degrees Fahrenheit on the secondary y-axis because the USA still uses the antiquated Imperial measurement system. I don't think even Hadley would object here.
The deadly sin of a secondary y-axis is when there are two different variables are being graphed, say speed on the first axis and gasoline consumption on the other axis.? It creates a perceptual nightmare.? 
    On Thursday, November 23, 2017, 12:28:36 PM EST, Eliza Botto <eliza_botto at outlook.com> wrote:  
 
 Thank you very much peter.

It worked out nicely.

I have additional question. How can I get Y-axis on log-scale?

Thank you very much in Advance,


Eliza

UoS
PP


________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: 23 November 2017 16:22:39
To: Eliza Botto; r-help at r-project.org
Subject: RE: adding percentage secondary y-axis

Hi

It is usually not recommended but if you insist

maybe
library(plotrix)
?twoord.plot
twoord.plot(lx=D[,1],ly=D[,2], rx=D[,1], ry=D[,3])

or

plot.yy(x=D[,1],yright=D[,3], yleft=D[,2])

which allows only one x axis (see below).

Cheers
Petr

plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,
? ? xlab = NULL, yylab = list(NA, NA), pch = c(1, 2),
? ? col = c(1,2), linky = F, smooth = 0, lwds = 1, length = 10,
? ? ? ? format = "%d/%m", rect = NULL, type = "p", ...)
{
? ? par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
? ? plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,
? ? ? ? pch = pch[1], col = col[1], type = type, ...)
? ? if (!is.null(rect))
? ? ? ? rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
? ? points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab,
? ? ? ? pch = pch[1], col = col[1], ...)
? ? axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
? ? if (linky)
? ? ? ? lines(x, yright, col = col[1], ...)
? ? if (smooth != 0)
? ? ? ? lines(supsmu(x, yright, span = smooth), col = col[1],
? ? ? ? ? ? lwd = lwds, ...)
? ? if (is.na(yylab[[1]]))
? ? ? ? mtext(deparse(substitute(yright)), side = 4, outer = T,
? ? ? ? ? ? line = 1, col = col[1], ...)
? ? else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],
? ? ? ? ...)
? ? par(new = T)
? ? plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
? ? ? ? pch = pch[2], col = col[2], ...)
? ? box()
? ? axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
? ? ? ? col.axis = col[2])
? ? if (!inherits(x, c("Date", "POSIXt")))
? ? ? ? axis(1, pretty(range(x, na.rm = T), 10))
? ? else {
? ? ? ? if (inherits(x, "POSIXt")) {
? ? ? ? ? ? l <- length(x)
? ? ? ? ? ? axis(1, at = x[seq(1, l, length = length)],
? ? ? ? ? ? labels = format(as.POSIXct(x[seq(1,l, length = length)]),
? ? ? ? ? ? format = format))
? ? ? ? }
? ? ? ? else {
? ? ? ? ? ? if (inherits(x, "Date")) {
? ? ? ? ? ? ? ? l <- length(x)
? ? ? ? ? ? ? ? axis(1, at = x[seq(1, l, length = length)],
? ? ? ? ? ? ? ? labels = format(as.Date(x[seq(1,l, length = length)]),
? ? ? ? ? ? ? ? format = format))
? ? ? ? ? ? }
? ? ? ? ? ? else {
? ? ? ? ? ? ? ? print("Not suitable x axis")
? ? ? ? ? ? }
? ? ? ? }
? ? }
? ? if (is.na(yylab[[2]]))
? ? ? ? mtext(deparse(substitute(yleft)), side = 2, line = 2,
? ? ? ? ? ? col = col[2], ...)
? ? else mtext(yylab[[2]], side = 2, line = 2, col = col[2],
? ? ? ? ...)
? ? if (linky)
? ? ? ? lines(x, yleft, col = col[2], lty = 2, ...)
? ? if (smooth != 0)
? ? ? ? lines(supsmu(x, yleft, span = smooth), col = col[2],
? ? ? ? ? ? lty = 2, lwd = lwds, ...)
? }





> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eliza Botto
> Sent: Thursday, November 23, 2017 3:31 PM
> To: r-help at r-project.org
> Subject: [R] adding percentage secondary y-axis
>
> Dear useRs,
>
>
> I have this dataset (D) with three columns.
>
>
> > dput(D)
>
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
> 2.990484802, 3.005018792, 3.019552781, 3.03408677, 3.048620759,
> 3.063154749, 3.077688738, 3.092222727, 3.106756717, 3.121290706,
> 3.135824695, 3.150358684, 3.164892674, 3.179426663, 3.193960652,
> 3.208494642, 3.223028631, 3.23756262, 3.252096609, 3.266630599,
> 0.488381368, 0.976762736, 1.465144104, 1.953525472, 2.44190684,
> 2.930288208, 3.418669576, 3.907050944, 4.395432311, 4.883813679,
> 5.372195047, 5.860576415, 6.348957783, 6.837339151, 7.325720519,
> 7.814101887, 8.302483255, 8.790864623, 9.279245991, 9.767627359), .Dim =
> c(20L, 3L))
>
>
> The first column represents the index values while the second column contains
> the response values. The third column in actually the percentage increase in the
> response values by increasing a unit index value.
>
>
> I made a plot and obtained a single line by;
>
>
> >plot(D[,1],D[,2],type="l")
>
>
> The primary y-axis represents the usual response values. Now I want to add a
> secondary y-axis representing? the percentage value shown against response
> value. So that, when a reader sees the graph she could easily visualize not only
> the decimal response value but also the percentage increase against that
> response value from the secondary axis without plotting any extra line.
>
>
> I thank you in advance,
>
>
> Stay Blessed!!!!
>
>
>
> Eliza
>
>
> UoS
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

??? [[alternative HTML version deleted]]
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Thu Nov 23 13:12:01 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 23 Nov 2017 12:12:01 +0000 (UTC)
Subject: [R] Fw: modified mankendal
In-Reply-To: <459423036.1023642.1511378085857@mail.yahoo.com>
References: <1817811789.954223.1511371398869.ref@mail.yahoo.com>
 <1817811789.954223.1511371398869@mail.yahoo.com>
 <459423036.1023642.1511378085857@mail.yahoo.com>
Message-ID: <1777453301.1348183.1511439121065@mail.yahoo.com>

 Would you resubmit your question in plain text mode?? 
This is a plain text list and the HTML gets stripped away. What is left is this
Hello DearI used modifiedmk package for trend analyses.this is my script
?require(modifiedmk)X1<-read.table("c:/elham/first article/r/Spring_NDVI-1.txt",skip=2,header=FALSE)d=dim(X1)
outMK<-matrix(-999,nrow=4,ncol=d[2])for (c in 1:d[2]){MK<-tfpwmk(X1[,c])outMK[1,c]<-getElement(MK,"S")outMK[2,c]<-getElement(MK,"Var(S)")outMK[3,c]<-getElement(MK,"Sen's Slope")outMK[4,c]<-getElement(MK,"P-value")}?unfortunetally I got this error:
Error in if (S == 0) { : missing value where TRUE/FALSE needed
would you please help me to solve itSincerely yoursElham
It is very close to unreadable. You should read the posting guide at the bottom of each email. 
You might also find these links useful:
How to make a great R reproducible example? aka MCVE (Minimal, Complete, and Verifiable Example)


| 
| 
| 
|  |  |

 |

 |
| 
|  | 
How to make a great R reproducible example? aka MCVE (Minimal, Complete,...

When discussing performance with colleagues, teaching, sending a bug report or searching for guidance on mailing...
 |

 |

 |




    On Wednesday, November 22, 2017, 3:24:05 PM EST, Elham Fakharizade via R-help <r-help at r-project.org> wrote:  
 
 
 Hello DearI used modifiedmk package for trend analyses.this is my script
?require(modifiedmk)X1<-read.table("c:/elham/first article/r/Spring_NDVI-1.txt",skip=2,header=FALSE)d=dim(X1)
outMK<-matrix(-999,nrow=4,ncol=d[2])for (c in 1:d[2]){MK<-tfpwmk(X1[,c])outMK[1,c]<-getElement(MK,"S")outMK[2,c]<-getElement(MK,"Var(S)")outMK[3,c]<-getElement(MK,"Sen's Slope")outMK[4,c]<-getElement(MK,"P-value")}?unfortunetally I got this error:
Error in if (S == 0) { : missing value where TRUE/FALSE needed
would you please help me to solve itSincerely yoursElham


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Fri Nov 24 00:05:45 2017
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 23 Nov 2017 15:05:45 -0800
Subject: [R] installing "rgl" package
Message-ID: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>

Hi Rxperts,
I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
your assistance .. I tried several leads available on various discussion
fora and nothing helped so far.


* installing *source* package ?rgl? ...checking for gcc... gcc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for gcc... (cached) gcc -std=gnu99
checking whether we are using the GNU C compiler... (cached) yes
checking whether gcc -std=gnu99 accepts -g... (cached) yes
checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
checking for libpng-config... yes
configure: using libpng-config
configure: using libpng dynamic linkage
checking for X... libraries , headers
checking GL/gl.h usability... yes
checking GL/gl.h presence... yes
checking for GL/gl.h... yes
checking GL/glu.h usability... yes
checking GL/glu.h presence... yes
checking for GL/glu.h... yes
checking for glEnd in -lGL... noconfigure: error: missing required
library GLERROR: configuration failed for package ?rgl?* removing
?/data/R/lib/rgl?Warning in install.packages :
  installation of package ?rgl? had non-zero exit status

Checking the system dependencies based on README..

system('dpkg -l |grep  libgl1')ii  libgl1-mesa-dev
  10.1.3-0ubuntu0.6                       amd64        free
implementation of the OpenGL API -- GLX development files

> system('dpkg -l |grep  libglu1')ii  libglu1-mesa:amd64                    9.0.0-2                                 amd64        Mesa OpenGL utility library (GLU)
ii  libglu1-mesa-dev                      9.0.0-2
           amd64        Mesa OpenGL utility library -- development
files

> system('dpkg -l |grep  libpng')ii  libpng12-0:amd64                      1.2.50-1ubuntu2.14.04.2                 amd64        PNG library - runtime
ii  libpng12-dev                          1.2.50-1ubuntu2.14.04.2
           amd64        PNG library - development

I also tried installing .. using the following command..
install.packages("rgl",dep=T,
INSTALL_opts="--no-multiarch",
configure.args=c(rgl="--with-gl-includes=/usr/include/GL"))

Thanks so much for your help!
Santosh

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 24 00:10:54 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 23 Nov 2017 18:10:54 -0500
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
Message-ID: <d9b2f7c6-4160-4496-88cb-365003a7449c@gmail.com>

On 23/11/2017 6:05 PM, Santosh wrote:
> Hi Rxperts,
> I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
> your assistance .. I tried several leads available on various discussion
> fora and nothing helped so far.

Your message is really hard to follow, since you posted in HTML.  You 
need the OpenGL development packages.  On Ubuntu, that probably means 
MesaGL, but I don't know the names of the development packages.

Duncan Murdoch

> 
> 
> * installing *source* package ?rgl? ...checking for gcc... gcc -std=gnu99
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for gcc... (cached) gcc -std=gnu99
> checking whether we are using the GNU C compiler... (cached) yes
> checking whether gcc -std=gnu99 accepts -g... (cached) yes
> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
> checking for libpng-config... yes
> configure: using libpng-config
> configure: using libpng dynamic linkage
> checking for X... libraries , headers
> checking GL/gl.h usability... yes
> checking GL/gl.h presence... yes
> checking for GL/gl.h... yes
> checking GL/glu.h usability... yes
> checking GL/glu.h presence... yes
> checking for GL/glu.h... yes
> checking for glEnd in -lGL... noconfigure: error: missing required
> library GLERROR: configuration failed for package ?rgl?* removing
> ?/data/R/lib/rgl?Warning in install.packages :
>    installation of package ?rgl? had non-zero exit status
> 
> Checking the system dependencies based on README..
> 
> system('dpkg -l |grep  libgl1')ii  libgl1-mesa-dev
>    10.1.3-0ubuntu0.6                       amd64        free
> implementation of the OpenGL API -- GLX development files
> 
>> system('dpkg -l |grep  libglu1')ii  libglu1-mesa:amd64                    9.0.0-2                                 amd64        Mesa OpenGL utility library (GLU)
> ii  libglu1-mesa-dev                      9.0.0-2
>             amd64        Mesa OpenGL utility library -- development
> files
> 
>> system('dpkg -l |grep  libpng')ii  libpng12-0:amd64                      1.2.50-1ubuntu2.14.04.2                 amd64        PNG library - runtime
> ii  libpng12-dev                          1.2.50-1ubuntu2.14.04.2
>             amd64        PNG library - development
> 
> I also tried installing .. using the following command..
> install.packages("rgl",dep=T,
> INSTALL_opts="--no-multiarch",
> configure.args=c(rgl="--with-gl-includes=/usr/include/GL"))
> 
> Thanks so much for your help!
> Santosh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Fri Nov 24 04:33:11 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Nov 2017 14:33:11 +1100
Subject: [R] Fw: modified mankendal
In-Reply-To: <459423036.1023642.1511378085857@mail.yahoo.com>
References: <1817811789.954223.1511371398869.ref@mail.yahoo.com>
 <1817811789.954223.1511371398869@mail.yahoo.com>
 <459423036.1023642.1511378085857@mail.yahoo.com>
Message-ID: <CA+8X3fUqze+AG4NOMyoumMYb1Yk_jFiJdaytPyHZ3478T=PC=Q@mail.gmail.com>

Hi Elham,
The error message is pretty explicit. Check your dataset for missing values.

Jim

On Thu, Nov 23, 2017 at 6:14 AM, Elham Fakharizade via R-help
<r-help at r-project.org> wrote:
>
>  Hello DearI used modifiedmk package for trend analyses.this is my script
>  require(modifiedmk)X1<-read.table("c:/elham/first article/r/Spring_NDVI-1.txt",skip=2,header=FALSE)d=dim(X1)
> outMK<-matrix(-999,nrow=4,ncol=d[2])for (c in 1:d[2]){MK<-tfpwmk(X1[,c])outMK[1,c]<-getElement(MK,"S")outMK[2,c]<-getElement(MK,"Var(S)")outMK[3,c]<-getElement(MK,"Sen's Slope")outMK[4,c]<-getElement(MK,"P-value")} unfortunetally I got this error:
> Error in if (S == 0) { : missing value where TRUE/FALSE needed
> would you please help me to solve itSincerely yoursElham
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Nov 24 06:04:59 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 24 Nov 2017 18:04:59 +1300
Subject: [R] [FORGED] Re:  installing "rgl" package
In-Reply-To: <d9b2f7c6-4160-4496-88cb-365003a7449c@gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <d9b2f7c6-4160-4496-88cb-365003a7449c@gmail.com>
Message-ID: <1ec40423-3f0a-aba4-8dd2-e182cb7e161d@auckland.ac.nz>

On 24/11/17 12:10, Duncan Murdoch wrote:
> On 23/11/2017 6:05 PM, Santosh wrote:
>> Hi Rxperts,
>> I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
>> your assistance .. I tried several leads available on various discussion
>> fora and nothing helped so far.
> 
> Your message is really hard to follow, since you posted in HTML.? You 
> need the OpenGL development packages.? On Ubuntu, that probably means 
> MesaGL, but I don't know the names of the development packages. >
> Duncan Murdoch
> 

The installation of rgl runs without complaint on my system, so 
apparently I have whatever libraries are needed.

I did "apt-show-versions | grep mesa" on my laptop (a trick I just 
learned from Berwin Turlach; thanks Berwin!) and got a slew of bumff:

> libegl1-mesa:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> libegl1-mesa-drivers:amd64/xenial-updates 12.0.6-0ubuntu0.16.04.1 uptodate
> libgl1-mesa-dev:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> libgl1-mesa-dri:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> libgl1-mesa-glx:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> libglapi-mesa:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> libglu1-mesa:amd64/xenial 9.0.0-2.1 uptodate
> libglu1-mesa-dev:amd64/xenial 9.0.0-2.1 uptodate
> libwayland-egl1-mesa:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> mesa-common-dev:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate
> mesa-utils:amd64/xenial 8.3.0-1 uptodate
> mesa-vdpau-drivers:amd64/xenial-updates 17.0.7-0ubuntu0.16.04.2 uptodate

(There were also a bunch of lines referring to i386 versions not being
installed; I deleted these to save space.)

So it would seem that you need to do at least:

     sudo apt-get install libegl1-mesa
     sudo apt-get install libegl1-mesa-dev

Doing this may result in the other bumff that is referred to getting 
installed automatically.  Try it and see if it works.  If not, keep 
doing the sudo apt-get install thing to the other bits and pieces until 
it does work.

Hope this helps; kind of a case of the blind leading the blind, but I 
*think* this should get you going with rgl.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

>>
>>
>> * installing *source* package ?rgl? ...checking for gcc... gcc -std=gnu99
>> checking whether the C compiler works... yes
>> checking for C compiler default output file name... a.out
>> checking for suffix of executables...
>> checking whether we are cross compiling... no
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc -std=gnu99 accepts -g... yes
>> checking for gcc -std=gnu99 option to accept ISO C89... none needed
>> checking how to run the C preprocessor... gcc -std=gnu99 -E
>> checking for gcc... (cached) gcc -std=gnu99
>> checking whether we are using the GNU C compiler... (cached) yes
>> checking whether gcc -std=gnu99 accepts -g... (cached) yes
>> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none 
>> needed
>> checking for libpng-config... yes
>> configure: using libpng-config
>> configure: using libpng dynamic linkage
>> checking for X... libraries , headers
>> checking GL/gl.h usability... yes
>> checking GL/gl.h presence... yes
>> checking for GL/gl.h... yes
>> checking GL/glu.h usability... yes
>> checking GL/glu.h presence... yes
>> checking for GL/glu.h... yes
>> checking for glEnd in -lGL... noconfigure: error: missing required
>> library GLERROR: configuration failed for package ?rgl?* removing
>> ?/data/R/lib/rgl?Warning in install.packages :
>> ?? installation of package ?rgl? had non-zero exit status
>>
>> Checking the system dependencies based on README..
>>
>> system('dpkg -l |grep? libgl1')ii? libgl1-mesa-dev
>> ?? 10.1.3-0ubuntu0.6?????????????????????? amd64??????? free
>> implementation of the OpenGL API -- GLX development files
>>
>>> system('dpkg -l |grep? libglu1')ii  
>>> libglu1-mesa:amd64                    
>>> 9.0.0-2???????????????????????????????? amd64??????? Mesa OpenGL 
>>> utility library (GLU)
>> ii? libglu1-mesa-dev????????????????????? 9.0.0-2
>> ??????????? amd64??????? Mesa OpenGL utility library -- development
>> files
>>
>>> system('dpkg -l |grep? libpng')ii  
>>> libpng12-0:amd64                      
>>> 1.2.50-1ubuntu2.14.04.2???????????????? amd64??????? PNG library - 
>>> runtime
>> ii? libpng12-dev????????????????????????? 1.2.50-1ubuntu2.14.04.2
>> ??????????? amd64??????? PNG library - development
>>
>> I also tried installing .. using the following command..
>> install.packages("rgl",dep=T,
>> INSTALL_opts="--no-multiarch",
>> configure.args=c(rgl="--with-gl-includes=/usr/include/GL"))


From loris.bennett at fu-berlin.de  Fri Nov 24 07:58:31 2017
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Fri, 24 Nov 2017 07:58:31 +0100
Subject: [R] libPaths displays truncated path?
In-Reply-To: <2D0457B5-8BC5-465C-8952-7D3627345326@ucsd.edu> (Charles Berry's
 message of "Thu, 23 Nov 2017 16:29:39 +0000")
References: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
 <2D0457B5-8BC5-465C-8952-7D3627345326@ucsd.edu>
Message-ID: <871skojh7s.fsf@hornfels.zedat.fu-berlin.de>

"Berry, Charles" <ccberry at ucsd.edu> writes:

>> On Nov 23, 2017, at 4:34 AM, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>> 
>> Hi,
>> 
>> TL;DR
>> -----
>> 
>>  I define the path
>> 
>>    /cm/shared/apps/R/site-library/3.4.2
>> 
>>  and add it to libPath.  Why does libPath then display it as
>> 
>>    /cm/shared/apps/R/site-library/3.4
>> 
>>  ?
>> 
>
> Because it is a symbolic link.
>
> ?.libPaths says
>
> "For consistency, the paths are always normalized by normalizePath(winslash = "/")."
>
> and ?normalizePath says
>
> "...the Unix-alike platform ... attempts to turn paths into absolute paths in their canonical form (no ./, ../ nor symbolic links)."  
>
> HTH,
>
> Chuck

That explains it.  A tad bizarre to my mind, but, as usual with R and as
I should have known, documented.

Thanks,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From petr.pikal at precheza.cz  Fri Nov 24 08:03:57 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Nov 2017 07:03:57 +0000
Subject: [R] adding percentage secondary y-axis
In-Reply-To: <DB6PR0901MB1192E919F0B3F6BFFB36E0D59A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
References: <DB6PR0901MB1192F2D3A39844569038599A9A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>,
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB421@SRVEXCHCM301.precheza.cz>
 <DB6PR0901MB1192E919F0B3F6BFFB36E0D59A210@DB6PR0901MB1192.eurprd09.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB4C7@SRVEXCHCM301.precheza.cz>

Hi

Not sure about twoord.plot, try its help page.

I did not intend log Y axis in my function.
This
plot.yy(x=D[,1],yright=D[,3], yleft=D[,2], log="y")

gives you log right axis.

You have the code, you can modify it according to your desire.

Cheers
Petr

From: Eliza Botto [mailto:eliza_botto at outlook.com]
Sent: Thursday, November 23, 2017 6:28 PM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
Subject: Re: adding percentage secondary y-axis

Thank you very much peter.

It worked out nicely.

I have additional question. How can I get Y-axis on log-scale?

Thank you very much in Advance,

Eliza

UoS
PP

________________________________
From: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Sent: 23 November 2017 16:22:39
To: Eliza Botto; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: RE: adding percentage secondary y-axis

Hi

It is usually not recommended but if you insist

maybe
library(plotrix)
?twoord.plot
twoord.plot(lx=D[,1],ly=D[,2], rx=D[,1], ry=D[,3])

or

plot.yy(x=D[,1],yright=D[,3], yleft=D[,2])

which allows only one x axis (see below).

Cheers
Petr

plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,
    xlab = NULL, yylab = list(NA, NA), pch = c(1, 2),
    col = c(1,2), linky = F, smooth = 0, lwds = 1, length = 10,
        format = "%d/%m", rect = NULL, type = "p", ...)
{
    par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
    plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,
        pch = pch[1], col = col[1], type = type, ...)
    if (!is.null(rect))
        rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
    points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab,
        pch = pch[1], col = col[1], ...)
    axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
    if (linky)
        lines(x, yright, col = col[1], ...)
    if (smooth != 0)
        lines(supsmu(x, yright, span = smooth), col = col[1],
            lwd = lwds, ...)
    if (is.na(yylab[[1]]))
        mtext(deparse(substitute(yright)), side = 4, outer = T,
            line = 1, col = col[1], ...)
    else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],
        ...)
    par(new = T)
    plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
        pch = pch[2], col = col[2], ...)
    box()
    axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
        col.axis = col[2])
    if (!inherits(x, c("Date", "POSIXt")))
        axis(1, pretty(range(x, na.rm = T), 10))
    else {
        if (inherits(x, "POSIXt")) {
            l <- length(x)
            axis(1, at = x[seq(1, l, length = length)],
            labels = format(as.POSIXct(x[seq(1,l, length = length)]),
            format = format))
        }
        else {
            if (inherits(x, "Date")) {
                l <- length(x)
                axis(1, at = x[seq(1, l, length = length)],
                labels = format(as.Date(x[seq(1,l, length = length)]),
                format = format))
            }
            else {
                print("Not suitable x axis")
            }
        }
    }
    if (is.na(yylab[[2]]))
        mtext(deparse(substitute(yleft)), side = 2, line = 2,
            col = col[2], ...)
    else mtext(yylab[[2]], side = 2, line = 2, col = col[2],
        ...)
    if (linky)
        lines(x, yleft, col = col[2], lty = 2, ...)
    if (smooth != 0)
        lines(supsmu(x, yleft, span = smooth), col = col[2],
            lty = 2, lwd = lwds, ...)
  }





> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eliza Botto
> Sent: Thursday, November 23, 2017 3:31 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] adding percentage secondary y-axis
>
> Dear useRs,
>
>
> I have this dataset (D) with three columns.
>
>
> > dput(D)
>
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
> 2.990484802, 3.005018792, 3.019552781, 3.03408677, 3.048620759,
> 3.063154749, 3.077688738, 3.092222727, 3.106756717, 3.121290706,
> 3.135824695, 3.150358684, 3.164892674, 3.179426663, 3.193960652,
> 3.208494642, 3.223028631, 3.23756262, 3.252096609, 3.266630599,
> 0.488381368, 0.976762736, 1.465144104, 1.953525472, 2.44190684,
> 2.930288208, 3.418669576, 3.907050944, 4.395432311, 4.883813679,
> 5.372195047, 5.860576415, 6.348957783, 6.837339151, 7.325720519,
> 7.814101887, 8.302483255, 8.790864623, 9.279245991, 9.767627359), .Dim =
> c(20L, 3L))
>
>
> The first column represents the index values while the second column contains
> the response values. The third column in actually the percentage increase in the
> response values by increasing a unit index value.
>
>
> I made a plot and obtained a single line by;
>
>
> >plot(D[,1],D[,2],type="l")
>
>
> The primary y-axis represents the usual response values. Now I want to add a
> secondary y-axis representing  the percentage value shown against response
> value. So that, when a reader sees the graph she could easily visualize not only
> the decimal response value but also the percentage increase against that
> response value from the secondary axis without plotting any extra line.
>
>
> I thank you in advance,
>
>
> Stay Blessed!!!!
>
>
>
> Eliza
>
>
> UoS
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Nov 24 09:59:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Nov 2017 19:59:58 +1100
Subject: [R] Fw: modified mankendal
In-Reply-To: <1427109934.1668423.1511513102026@mail.yahoo.com>
References: <1817811789.954223.1511371398869.ref@mail.yahoo.com>
 <1817811789.954223.1511371398869@mail.yahoo.com>
 <459423036.1023642.1511378085857@mail.yahoo.com>
 <CA+8X3fUqze+AG4NOMyoumMYb1Yk_jFiJdaytPyHZ3478T=PC=Q@mail.gmail.com>
 <1427109934.1668423.1511513102026@mail.yahoo.com>
Message-ID: <CA+8X3fVvYUDXeyZeT_9+C1BiQKtKvtM3Mr=+N5X=QEoudW0KcA@mail.gmail.com>

Hi Elham,
The error message:

Error in if (S == 0) { : missing value where TRUE/FALSE needed

means that for at least one S, the value is missing. The best advice I
can give you is to load the data frame X1 as in your code above, and
try something like:

which.na<-function(x) return(which(is.na(x)))
sapply(X1,which.na)

You will then get a list of the positions of any NA values in X1.

Jim

On Fri, Nov 24, 2017 at 7:45 PM, Elham Fakharizade <e_f_sh at yahoo.com> wrote:
> Hello Dear Jim
> Thanks for your answering
> I have more than 65000 data in my file I search for NA or NAN but nothing
> find. how can I search for missing value?
> Sincerely yours
> Elham
>
> Elham Fakharizadeshirazi.
>
> Doctoral guest researcher in Institute of Meteorology,
>
> Department of Earth Sciences,
>
> Free university of Berlin,
>
> Berlin, Germany.
>
>
>
> On Friday, November 24, 2017, 4:33:12 AM GMT+1, Jim Lemon
> <drjimlemon at gmail.com> wrote:
>
>
> Hi Elham,
> The error message is pretty explicit. Check your dataset for missing values.
>
> Jim
>
> On Thu, Nov 23, 2017 at 6:14 AM, Elham Fakharizade via R-help
> <r-help at r-project.org> wrote:
>>
>>  Hello DearI used modifiedmk package for trend analyses.this is my script
>>  require(modifiedmk)X1<-read.table("c:/elham/first
>> article/r/Spring_NDVI-1.txt",skip=2,header=FALSE)d=dim(X1)
>> outMK<-matrix(-999,nrow=4,ncol=d[2])for (c in
>> 1:d[2]){MK<-tfpwmk(X1[,c])outMK[1,c]<-getElement(MK,"S")outMK[2,c]<-getElement(MK,"Var(S)")outMK[3,c]<-getElement(MK,"Sen's
>> Slope")outMK[4,c]<-getElement(MK,"P-value")} unfortunetally I got this
>> error:
>> Error in if (S == 0) { : missing value where TRUE/FALSE needed
>> would you please help me to solve itSincerely yoursElham
>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From p_connolly at slingshot.co.nz  Fri Nov 24 10:04:46 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Fri, 24 Nov 2017 22:04:46 +1300
Subject: [R] Using bartMachine with the caret package
Message-ID: <20171124090446.GA4428@slingshot.co.nz>

Dave Langer in this video https://www.youtube.com/watch?v=z8PRU46I3NY
uses the titanic data as an example of using caret to create xgbTree
models.  The caret train() function has a tuneGrid parameter which
takes a list set up like so:

tune.grid <- expand.grid(eta = c(0.05, 0.075, 0.1),
                         nrounds = c(50, 75, 100),
                         max_depth = 6:8,
                         min_child_weight = c(2, 2.25, 2.5),
                         colsample_bytree = (3:5)/10,
                         gamma = 0, subsample = 1)

That approach also worked with my data.  By making the corresponding
adjustments, I was also successful with gbm, bstTree and extraTree
models but I can't get it to work with bartMachine models. I get
dozens of messages like these:

bartMachine initializing with 50 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 19 total features...
bartMachine sigsq estimated...
bartMachine initializing with 30 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 19 total features...
bartMachine sigsq estimated...

[...]

And eventually,  this:

Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :2     NA's   :2     NA's   :2    


If I omit the tuneGrid parameter, I get a model and predictions
comparable to those from the other models.  If I could tune the
parameters I would possibly get better predictions.

Possibly relevant is the fact that formula method of defining the
model seems not to work.  I had to use the method of supplying x and y
specifically.  I couldn't find how to use the 'recipe' method.  All
the specific links in the help files were dead.

Any suggestions welcome.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From petr.pikal at precheza.cz  Fri Nov 24 12:27:41 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Nov 2017 11:27:41 +0000
Subject: [R] number to volume weighted distribution
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB5ED@SRVEXCHCM301.precheza.cz>

Dear all

Strictly speaking it is not R question but as you are the most capable persons I know I give it a try.

I am strugling with recalculation of number weighted to volume weighted distribution.

Suppose I have objects (cubes) with size

x<- c(rep(10,20), rep(100, 10), rep(300,5))
I can get

plot(ecdf(x))

or the number weighted average

mean(x)
[1] 77.14286

or volume weighted average
weighted.mean(x, (x/sum(x^3)))
[1] 204.4444

However I am struggling with volume weighted ecdf.

Can you please give me some hints?

Cheers
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Fri Nov 24 12:35:51 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 24 Nov 2017 06:35:51 -0500
Subject: [R] number to volume weighted distribution
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB5ED@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB5ED@SRVEXCHCM301.precheza.cz>
Message-ID: <e415ef62-4b92-135c-ae7b-e65b0dcf808a@gmail.com>

On 24/11/2017 6:27 AM, PIKAL Petr wrote:
> Dear all
> 
> Strictly speaking it is not R question but as you are the most capable persons I know I give it a try.
> 
> I am strugling with recalculation of number weighted to volume weighted distribution.
> 
> Suppose I have objects (cubes) with size
> 
> x<- c(rep(10,20), rep(100, 10), rep(300,5))
> I can get
> 
> plot(ecdf(x))
> 
> or the number weighted average
> 
> mean(x)
> [1] 77.14286
> 
> or volume weighted average
> weighted.mean(x, (x/sum(x^3)))
> [1] 204.4444
> 
> However I am struggling with volume weighted ecdf.
> 
> Can you please give me some hints?

I believe base R doesn't have a function for this, but Google says it 
exists in a couple of packages:  spatstat, Hmisc.  But you seem to be 
asking about a definition rather than a function:  it is obtained simply 
by normalizing the weights to sum to 1, then evaluating cumulative sums 
of them.

Duncan Murdoch


From istazahn at gmail.com  Fri Nov 24 13:58:55 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 24 Nov 2017 07:58:55 -0500
Subject: [R] installing "rgl" package
In-Reply-To: <CA+vqiLE3ojHMpnSaAXmDxwT6FxETiDXEhabPapu9DPX_mKvx1A@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <d9b2f7c6-4160-4496-88cb-365003a7449c@gmail.com>
 <CA+vqiLECWKwmx9GdEktsV75159=kN32oNvk0E7S1ReV2DN4iTw@mail.gmail.com>
 <CA+vqiLE3ojHMpnSaAXmDxwT6FxETiDXEhabPapu9DPX_mKvx1A@mail.gmail.com>
Message-ID: <CA+vqiLFpoWpUiUsEHPMVpJP8OjdNxbjh+S0s8n50d=rftx1U-g@mail.gmail.com>

On Nov 23, 2017 6:16 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

On 23/11/2017 6:05 PM, Santosh wrote:

> Hi Rxperts,
> I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
> your assistance .. I tried several leads available on various discussion
> fora and nothing helped so far.
>

Your message is really hard to follow, since you posted in HTML.  You need
the OpenGL development packages.  On Ubuntu, that probably means MesaGL,
but I don't know the names of the development packages.


Fortunately there is no need to memorize them:

apt-get build-dep r-cran-rgl

should be all you need.


Duncan Murdoch



>
> * installing *source* package ?rgl? ...checking for gcc... gcc -std=gnu99
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for gcc... (cached) gcc -std=gnu99
> checking whether we are using the GNU C compiler... (cached) yes
> checking whether gcc -std=gnu99 accepts -g... (cached) yes
> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none
> needed
> checking for libpng-config... yes
> configure: using libpng-config
> configure: using libpng dynamic linkage
> checking for X... libraries , headers
> checking GL/gl.h usability... yes
> checking GL/gl.h presence... yes
> checking for GL/gl.h... yes
> checking GL/glu.h usability... yes
> checking GL/glu.h presence... yes
> checking for GL/glu.h... yes
> checking for glEnd in -lGL... noconfigure: error: missing required
> library GLERROR: configuration failed for package ?rgl?* removing
> ?/data/R/lib/rgl?Warning in install.packages :
>    installation of package ?rgl? had non-zero exit status
>
> Checking the system dependencies based on README..
>
> system('dpkg -l |grep  libgl1')ii  libgl1-mesa-dev
>    10.1.3-0ubuntu0.6                       amd64        free
> implementation of the OpenGL API -- GLX development files
>
> system('dpkg -l |grep  libglu1')ii  libglu1-mesa:amd64
>> 9.0.0-2                                 amd64        Mesa OpenGL utility
>> library (GLU)
>>
> ii  libglu1-mesa-dev                      9.0.0-2
>             amd64        Mesa OpenGL utility library -- development
> files
>
> system('dpkg -l |grep  libpng')ii  libpng12-0:amd64
>> 1.2.50-1ubuntu2.14.04.2                 amd64        PNG library - runtime
>>
> ii  libpng12-dev                          1.2.50-1ubuntu2.14.04.2
>             amd64        PNG library - development
>
> I also tried installing .. using the following command..
> install.packages("rgl",dep=T,
> INSTALL_opts="--no-multiarch",
> configure.args=c(rgl="--with-gl-includes=/usr/include/GL"))
>
> Thanks so much for your help!
> Santosh
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Nov 24 14:13:04 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 24 Nov 2017 07:13:04 -0600
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
Message-ID: <23064.6880.475963.233683@bud.eddelbuettel.com>


On 23 November 2017 at 15:05, Santosh wrote:
| I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
| your assistance .. I tried several leads available on various discussion
| fora and nothing helped so far.

Install the _pre-built binary package_ via

    sudo apt install r-cran-rgl

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From petr.pikal at precheza.cz  Fri Nov 24 14:30:01 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Nov 2017 13:30:01 +0000
Subject: [R] number to volume weighted distribution
In-Reply-To: <e415ef62-4b92-135c-ae7b-e65b0dcf808a@gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB5ED@SRVEXCHCM301.precheza.cz>
 <e415ef62-4b92-135c-ae7b-e65b0dcf808a@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB640@SRVEXCHCM301.precheza.cz>

Hi Duncan

I tried Ecdf and/or wtd.quantile from Hmisc and it is working (probably).
Ecdf(x, q=.5)
Ecdf(x, weights=xw,col=2, add=T, q=.5)
wtd.quantile(x)
  0%  25%  50%  75% 100%
  10   10   10  100  300
wtd.quantile(x, weights=xw, type="i/n")
      0%      25%      50%      75%     100%
 10.0000 138.8667 192.5778 246.2889 300.0000

But could you please be more specific in this?

> But you seem to be asking about a
> definition rather than a function:  it is obtained simply by normalizing the
> weights to sum to 1, then evaluating cumulative sums of them.

Actually, when I correctly calculate weights

xw <- (x^3)/sum(x^3)
sum(xw) equals to 1

but how can I plot ecdf with volume weighted data. Obviously

ecdf(x*xw) or ecdf(x^3*xw) is not correct.

Cheers
Petr

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, November 24, 2017 12:36 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
> Subject: Re: [R] number to volume weighted distribution
>
> On 24/11/2017 6:27 AM, PIKAL Petr wrote:
> > Dear all
> >
> > Strictly speaking it is not R question but as you are the most capable persons I
> know I give it a try.
> >
> > I am strugling with recalculation of number weighted to volume weighted
> distribution.
> >
> > Suppose I have objects (cubes) with size
> >
> > x<- c(rep(10,20), rep(100, 10), rep(300,5)) I can get
> >
> > plot(ecdf(x))
> >
> > or the number weighted average
> >
> > mean(x)
> > [1] 77.14286
> >
> > or volume weighted average
> > weighted.mean(x, (x/sum(x^3)))
> > [1] 204.4444
> >
> > However I am struggling with volume weighted ecdf.
> >
> > Can you please give me some hints?
>
> I believe base R doesn't have a function for this, but Google says it exists in a
> couple of packages:  spatstat, Hmisc.  But you seem to be asking about a
> definition rather than a function:  it is obtained simply by normalizing the
> weights to sum to 1, then evaluating cumulative sums of them.
>
> Duncan Murdoch

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From loris.bennett at fu-berlin.de  Fri Nov 24 15:29:18 2017
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Fri, 24 Nov 2017 15:29:18 +0100
Subject: [R] libPaths displays truncated path?
In-Reply-To: <48FB9917-1FD8-415C-ADCA-62E579A11383@gmail.com> (peter
 dalgaard's message of "Fri, 24 Nov 2017 10:40:34 +0100")
References: <87zi7db2di.fsf@hornfels.zedat.fu-berlin.de>
 <AA86BB48-320F-46EF-ACFC-4EB878ED6CC4@comcast.net>
 <D7CCFDF4-A797-4B3C-B2DC-D92D59273AD4@gmail.com>
 <87zi7ci1uh.fsf@hornfels.zedat.fu-berlin.de>
 <48FB9917-1FD8-415C-ADCA-62E579A11383@gmail.com>
Message-ID: <87o9nrda2p.fsf@hornfels.zedat.fu-berlin.de>

peter dalgaard <pdalgd at gmail.com> writes:

[snip (40 lines)]

>> I don't quite understand the point about cause and effect.  If
>> normalizePath changes the symbolic link from
>> 
>>  /cm/shared/apps/R/site-library/3.4.2
>> 
>> to the actual directory
>> 
>>  /cm/shared/apps/R/site-library/3.4
>> 
>> in libPaths, why does R fail to find the packages *unless* the symbolic
>> link exists?
>
>
> I was unclear/confused about that. I somehow got the impression that
> the symlink was the cause of the problem that it solved, but that is
> not true.
>
> AFAICT there are two scenarios
>
> Ground facts:
>
> library is in  .../3.4
> you're trying to add .../3.4.2 using .libPaths
>
> (A) no symlink:
>
> Actual libpath will have .../3.4.2 which isn't there --> FAIL
>
> (B) symlink in place
>
> Actual libpath normalized to use .../3.4 which is there --> SUCCESS
>
> If normalizePath hadn't been applied, (B) would still succeed, the
> libpath would be to 3.4.2 which exists as a link to 3.4 and (A) would
> still fail because you are fundamentally looking in the wrong place.
>
> -pd

Now I understand.  I had scenario A and FAIL, then added the symbolic
link to get B and SUCCESS, whereby normalizePath means that the actual
directory and not the symbolic link is being used.

It all makes sense now (in an odd sort of way).  Thank you.

[snip (13 lines)]

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From allaisone1 at hotmail.com  Fri Nov 24 12:09:00 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Fri, 24 Nov 2017 11:09:00 +0000
Subject: [R] Multiple sets of proportion tests
Message-ID: <AM5P195MB002057E636996B8C79A5F00D80260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>


Hi all ,


I have a dataframe  of 200 columns and 2 rows. The first row in each column contains the frequency of cases in group I . The second row in each column contains the frequency of cases in group II. The frequency of trails is a fixed value for group I(e.g.200) and it is also another fixed values for group II (e.g. 100). The dataset looks like this :-


> Mydata


                                      variable I      variable II    Variable III  ......... 200

Freq.of cases (gp I)      6493               9375               5524

Freq. of cases (gpII)     509                  462                 54



The result I need for the first column can be given using this code :


 MyResultsI <- prop.test(Mydata$variable I ,c(200,100))
for the second  column :-
MyResultsII <- prop.test(Mydata$variable II ,c(200,100))  and so on ..


I need to do the analysis for all columns and have only the columns with significant p-value results to be written in the the third row under each column so the final output has to be something like this :-


                                      variable I        Variable III  .........

Freq.of cases (gp I)      6493                   5524

Freq. of cases (gpII)     509                      54

p-values                          0.02               0.010

Note, for example, that the 2nd column has bee removed as it resulted in a non-significant p-value result while col 1 and col 3 were included since p-value is less than 0.05.

I'm not sure how to get the p-values only without other details but for the analysis itself , I believe it can be done with apply() function but its not clear to me how to specify the 2nd argument(n=samlpe sizes) in the prop.test.

 MyResults <- apply(Mydata, 2, function(x)prop.test(Mydata,c(200,100))

How can I modify the "n" argument part to solve the issue of non-equivalent length between "x" and "n" ?. How can I modify this further to return only significant p-values results ?. Any help would be very appreciated ..

Regards

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Fri Nov 24 20:30:50 2017
From: santosh2005 at gmail.com (Santosh)
Date: Fri, 24 Nov 2017 11:30:50 -0800
Subject: [R] installing "rgl" package
In-Reply-To: <23064.6880.475963.233683@bud.eddelbuettel.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
Message-ID: <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>

Hi All, Duncan, Rolf, Ista, DIrk,

Thanks for the suggestions and I tried all of them (as suggested by Duncan,
Rolf, Ista and Dirk)... I still get similar error as before while
installing 'rgl' package.. I also tried to manually configure "rgl" and got
an error message (please see below for the verbatim output).  Would highly
any further ideas/suggestions!

*In my system, "GL" library is present under "/usr/include/GL"*

Here are the libraries available (as suggested by Rolf)

After installing some of them, I continue to get the same error message,
please below the output messages in config.log after I ran "./configure")


"ii  r-cran-rgl                            0.93.996-1
        amd64        GNU R package for three-dimensional visualisation
using OpenGL"

"ii  libegl1-mesa:amd64                    10.1.3-0ubuntu0.6
       amd64        free implementation of the EGL API -- runtime"

"ii  libegl1-mesa-dev                      10.1.3-0ubuntu0.6
       amd64        free implementation of the EGL API -- development files"

"ii  libegl1-mesa-drivers:amd64            10.1.3-0ubuntu0.6
       amd64        free implementation of the EGL API -- hardware drivers"

"ii  libgl1-mesa-dev                       10.1.3-0ubuntu0.6
       amd64        free implementation of the OpenGL API -- GLX
development files"

"ii  libgl1-mesa-dri:amd64                 10.1.3-0ubuntu0.6
       amd64        free implementation of the OpenGL API -- DRI modules"


"ii  libgl1-mesa-glx:amd64                 10.1.3-0ubuntu0.6
       amd64        free implementation of the OpenGL API -- GLX runtime"


"ii  libglapi-mesa:amd64                   10.1.3-0ubuntu0.6
       amd64        free implementation of the GL API -- shared library"

"ii  libglu1-mesa:amd64                    9.0.0-2
       amd64        Mesa OpenGL utility library (GLU)"

"ii  libglu1-mesa-dev                      9.0.0-2
       amd64        Mesa OpenGL utility library -- development files"

"ii  libwayland-client0:amd64              1.4.0-1ubuntu1
        amd64        wayland compositor infrastructure - client library"

"ii  libwayland-cursor0:amd64              1.4.0-1ubuntu1
        amd64        wayland compositor infrastructure - cursor library"

"ii  libwayland-dev                        1.4.0-1ubuntu1
        amd64        wayland compositor infrastructure - development files"

"ii  libwayland-egl1-mesa:amd64            10.1.3-0ubuntu0.6
       amd64        implementation of the Wayland EGL platform -- runtime"

"ii  libwayland-server0:amd64              1.4.0-1ubuntu1
        amd64        wayland compositor infrastructure - server library"

"ii  mesa-common-dev                       10.1.3-0ubuntu0.6
       amd64        Developer documentation for Mesa"

"ii  mesa-vdpau-drivers:amd64              10.1.3-0ubuntu0.6
       amd64        Mesa VDPAU video acceleration drivers"

"ii  mesa-utils                            8.1.0-2
       amd64        Miscellaneous Mesa GL utilities"


The error message when installing "rgl" library,

* installing *source* package ?rgl? ...

checking for gcc... gcc -std=gnu99

checking whether the C compiler works... yes

checking for C compiler default output file name... a.out

checking for suffix of executables...

checking whether we are cross compiling... no

checking for suffix of object files... o

checking whether we are using the GNU C compiler... yes

checking whether gcc -std=gnu99 accepts -g... yes

checking for gcc -std=gnu99 option to accept ISO C89... none needed

checking how to run the C preprocessor... gcc -std=gnu99 -E

checking for gcc... (cached) gcc -std=gnu99

checking whether we are using the GNU C compiler... (cached) yes

checking whether gcc -std=gnu99 accepts -g... (cached) yes

checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed

checking for libpng-config... yes

configure: using libpng-config

configure: using libpng dynamic linkage

checking for X... libraries , headers

checking GL/gl.h usability... yes

checking GL/gl.h presence... yes

checking for GL/gl.h... yes

checking GL/glu.h usability... yes

checking GL/glu.h presence... yes

checking for GL/glu.h... yes

checking for glEnd in -lGL... no

configure: error: missing required library GL

ERROR: configuration failed for package ?rgl?

* removing ?/data/R/lib/rgl?

Warning in install.packages :

  installation of package ?rgl? had non-zero exit status


The error message as seen in config.log (after manually running
"./configure" under "rgl")

configure:4263: checking for glEnd in -lGL
configure:4288: gcc -std=gnu99 -o conftest -g -O2 -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Werror=format-security
-D_FORTIFY_SOURCE=2 -g  -DHAVE_PNG_H -I/usr/include/libpng12
conftest.c -lGL   -L/usr/lib/x86_64-linux-gnu -lpng12 -lX11
>&5*/*usr/bin/ld: cannot find -lGL
collect2: error: ld returned 1 exit status
configure:4288: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""
| #define PACKAGE_TARNAME ""
| #define PACKAGE_VERSION ""
| #define PACKAGE_STRING ""
| #define PACKAGE_BUGREPORT ""
| #define PACKAGE_URL ""
| #define HAVE_GL_GL_H 1
| #define HAVE_GL_GLU_H 1
| /* end confdefs.h.  */
|
| /* Override any GCC internal prototype to avoid an error.
|    Use char because int might match the return type of a GCC
|    builtin and then its argument prototype would still apply.  */
| #ifdef __cplusplus
| extern "C"
| #endif
| char glEnd ();
| int
| main ()
| {
| return glEnd ();
|   ;
|   return 0;
| }configure:4298: result: no
configure:4311: error: missing required library GL

Thanks a ton, again!
Santosh

On Fri, Nov 24, 2017 at 5:13 AM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 23 November 2017 at 15:05, Santosh wrote:
> | I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
> | your assistance .. I tried several leads available on various discussion
> | fora and nothing helped so far.
>
> Install the _pre-built binary package_ via
>
>     sudo apt install r-cran-rgl
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 24 21:39:52 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 24 Nov 2017 15:39:52 -0500
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
Message-ID: <743193c7-8bc3-1bf3-2d8a-0700dcb082a7@gmail.com>

On 24/11/2017 2:30 PM, Santosh wrote:
> Hi All, Duncan, Rolf, Ista, DIrk,
> 
> Thanks for the suggestions and I tried all of them (as suggested by Duncan,
> Rolf, Ista and Dirk)... I still get similar error as before while
> installing 'rgl' package.. I also tried to manually configure "rgl" and got
> an error message (please see below for the verbatim output).  Would highly
> any further ideas/suggestions!
> 
> *In my system, "GL" library is present under "/usr/include/GL"*

That's the include file.  The error is saying you don't have libGL.so, 
which it is looking for in /usr/lib/x86_64-linux-gnu.  Do you have that 
file?  Is it there, and marked as executable?

It's probably a symbolic link; on an old Ubuntu system I just checked, 
it points to mesa/libGL.so, which is also a symlink, pointing to 
mesa/libGL.so.1.2.0, which is executable.

Duncan Murdoch


> 
> Here are the libraries available (as suggested by Rolf)
> 
> After installing some of them, I continue to get the same error message,
> please below the output messages in config.log after I ran "./configure")
> 
> 
> "ii  r-cran-rgl                            0.93.996-1
>          amd64        GNU R package for three-dimensional visualisation
> using OpenGL"
> 
> "ii  libegl1-mesa:amd64                    10.1.3-0ubuntu0.6
>         amd64        free implementation of the EGL API -- runtime"
> 
> "ii  libegl1-mesa-dev                      10.1.3-0ubuntu0.6
>         amd64        free implementation of the EGL API -- development files"
> 
> "ii  libegl1-mesa-drivers:amd64            10.1.3-0ubuntu0.6
>         amd64        free implementation of the EGL API -- hardware drivers"
> 
> "ii  libgl1-mesa-dev                       10.1.3-0ubuntu0.6
>         amd64        free implementation of the OpenGL API -- GLX
> development files"
> 
> "ii  libgl1-mesa-dri:amd64                 10.1.3-0ubuntu0.6
>         amd64        free implementation of the OpenGL API -- DRI modules"
> 
> 
> "ii  libgl1-mesa-glx:amd64                 10.1.3-0ubuntu0.6
>         amd64        free implementation of the OpenGL API -- GLX runtime"
> 
> 
> "ii  libglapi-mesa:amd64                   10.1.3-0ubuntu0.6
>         amd64        free implementation of the GL API -- shared library"
> 
> "ii  libglu1-mesa:amd64                    9.0.0-2
>         amd64        Mesa OpenGL utility library (GLU)"
> 
> "ii  libglu1-mesa-dev                      9.0.0-2
>         amd64        Mesa OpenGL utility library -- development files"
> 
> "ii  libwayland-client0:amd64              1.4.0-1ubuntu1
>          amd64        wayland compositor infrastructure - client library"
> 
> "ii  libwayland-cursor0:amd64              1.4.0-1ubuntu1
>          amd64        wayland compositor infrastructure - cursor library"
> 
> "ii  libwayland-dev                        1.4.0-1ubuntu1
>          amd64        wayland compositor infrastructure - development files"
> 
> "ii  libwayland-egl1-mesa:amd64            10.1.3-0ubuntu0.6
>         amd64        implementation of the Wayland EGL platform -- runtime"
> 
> "ii  libwayland-server0:amd64              1.4.0-1ubuntu1
>          amd64        wayland compositor infrastructure - server library"
> 
> "ii  mesa-common-dev                       10.1.3-0ubuntu0.6
>         amd64        Developer documentation for Mesa"
> 
> "ii  mesa-vdpau-drivers:amd64              10.1.3-0ubuntu0.6
>         amd64        Mesa VDPAU video acceleration drivers"
> 
> "ii  mesa-utils                            8.1.0-2
>         amd64        Miscellaneous Mesa GL utilities"
> 
> 
> The error message when installing "rgl" library,
> 
> * installing *source* package ?rgl? ...
> 
> checking for gcc... gcc -std=gnu99
> 
> checking whether the C compiler works... yes
> 
> checking for C compiler default output file name... a.out
> 
> checking for suffix of executables...
> 
> checking whether we are cross compiling... no
> 
> checking for suffix of object files... o
> 
> checking whether we are using the GNU C compiler... yes
> 
> checking whether gcc -std=gnu99 accepts -g... yes
> 
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> 
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> 
> checking for gcc... (cached) gcc -std=gnu99
> 
> checking whether we are using the GNU C compiler... (cached) yes
> 
> checking whether gcc -std=gnu99 accepts -g... (cached) yes
> 
> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
> 
> checking for libpng-config... yes
> 
> configure: using libpng-config
> 
> configure: using libpng dynamic linkage
> 
> checking for X... libraries , headers
> 
> checking GL/gl.h usability... yes
> 
> checking GL/gl.h presence... yes
> 
> checking for GL/gl.h... yes
> 
> checking GL/glu.h usability... yes
> 
> checking GL/glu.h presence... yes
> 
> checking for GL/glu.h... yes
> 
> checking for glEnd in -lGL... no
> 
> configure: error: missing required library GL
> 
> ERROR: configuration failed for package ?rgl?
> 
> * removing ?/data/R/lib/rgl?
> 
> Warning in install.packages :
> 
>    installation of package ?rgl? had non-zero exit status
> 
> 
> The error message as seen in config.log (after manually running
> "./configure" under "rgl")
> 
> configure:4263: checking for glEnd in -lGL
> configure:4288: gcc -std=gnu99 -o conftest -g -O2 -fstack-protector
> --param=ssp-buffer-size=4 -Wformat -Werror=format-security
> -D_FORTIFY_SOURCE=2 -g  -DHAVE_PNG_H -I/usr/include/libpng12
> conftest.c -lGL   -L/usr/lib/x86_64-linux-gnu -lpng12 -lX11
>> &5*/*usr/bin/ld: cannot find -lGL
> collect2: error: ld returned 1 exit status
> configure:4288: $? = 1
> configure: failed program was:
> | /* confdefs.h */
> | #define PACKAGE_NAME ""
> | #define PACKAGE_TARNAME ""
> | #define PACKAGE_VERSION ""
> | #define PACKAGE_STRING ""
> | #define PACKAGE_BUGREPORT ""
> | #define PACKAGE_URL ""
> | #define HAVE_GL_GL_H 1
> | #define HAVE_GL_GLU_H 1
> | /* end confdefs.h.  */
> |
> | /* Override any GCC internal prototype to avoid an error.
> |    Use char because int might match the return type of a GCC
> |    builtin and then its argument prototype would still apply.  */
> | #ifdef __cplusplus
> | extern "C"
> | #endif
> | char glEnd ();
> | int
> | main ()
> | {
> | return glEnd ();
> |   ;
> |   return 0;
> | }configure:4298: result: no
> configure:4311: error: missing required library GL
> 
> Thanks a ton, again!
> Santosh
> 
> On Fri, Nov 24, 2017 at 5:13 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
> 
>>
>> On 23 November 2017 at 15:05, Santosh wrote:
>> | I am trying to install 'rgl' package in Ubuntu.. Would highly appreciate
>> | your assistance .. I tried several leads available on various discussion
>> | fora and nothing helped so far.
>>
>> Install the _pre-built binary package_ via
>>
>>      sudo apt install r-cran-rgl
>>
>> Dirk
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thierry.onkelinx at inbo.be  Fri Nov 24 22:02:12 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 24 Nov 2017 22:02:12 +0100
Subject: [R] number to volume weighted distribution
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB640@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB5ED@SRVEXCHCM301.precheza.cz>
 <e415ef62-4b92-135c-ae7b-e65b0dcf808a@gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB640@SRVEXCHCM301.precheza.cz>
Message-ID: <CAJuCY5yRHVf57f1QCY+nUT_Em+D1EZyRfSzu-45wSojR27pSPg@mail.gmail.com>

Hi Petr,

I think that Duncan suggests something like this:

x<- c(rep(10,20), rep(300,5), rep(100, 10))
tx <- table(x)

prop.x <- tx / sum(tx)
vx <- as.integer(names(tx))
prop.wx <- tx * vx / sum(tx * vx)

plot(ecdf(x))
plot(vx, cumsum(prop.x), ylim = 0:1)
plot(vx, cumsum(prop.wx), ylim = 0:1)

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-11-24 14:30 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
> Hi Duncan
>
> I tried Ecdf and/or wtd.quantile from Hmisc and it is working (probably).
> Ecdf(x, q=.5)
> Ecdf(x, weights=xw,col=2, add=T, q=.5)
> wtd.quantile(x)
>   0%  25%  50%  75% 100%
>   10   10   10  100  300
> wtd.quantile(x, weights=xw, type="i/n")
>       0%      25%      50%      75%     100%
>  10.0000 138.8667 192.5778 246.2889 300.0000
>
> But could you please be more specific in this?
>
>> But you seem to be asking about a
>> definition rather than a function:  it is obtained simply by normalizing the
>> weights to sum to 1, then evaluating cumulative sums of them.
>
> Actually, when I correctly calculate weights
>
> xw <- (x^3)/sum(x^3)
> sum(xw) equals to 1
>
> but how can I plot ecdf with volume weighted data. Obviously
>
> ecdf(x*xw) or ecdf(x^3*xw) is not correct.
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Friday, November 24, 2017 12:36 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
>> Subject: Re: [R] number to volume weighted distribution
>>
>> On 24/11/2017 6:27 AM, PIKAL Petr wrote:
>> > Dear all
>> >
>> > Strictly speaking it is not R question but as you are the most capable persons I
>> know I give it a try.
>> >
>> > I am strugling with recalculation of number weighted to volume weighted
>> distribution.
>> >
>> > Suppose I have objects (cubes) with size
>> >
>> > x<- c(rep(10,20), rep(100, 10), rep(300,5)) I can get
>> >
>> > plot(ecdf(x))
>> >
>> > or the number weighted average
>> >
>> > mean(x)
>> > [1] 77.14286
>> >
>> > or volume weighted average
>> > weighted.mean(x, (x/sum(x^3)))
>> > [1] 204.4444
>> >
>> > However I am struggling with volume weighted ecdf.
>> >
>> > Can you please give me some hints?
>>
>> I believe base R doesn't have a function for this, but Google says it exists in a
>> couple of packages:  spatstat, Hmisc.  But you seem to be asking about a
>> definition rather than a function:  it is obtained simply by normalizing the
>> weights to sum to 1, then evaluating cumulative sums of them.
>>
>> Duncan Murdoch
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Fri Nov 24 22:06:39 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 24 Nov 2017 22:06:39 +0100
Subject: [R] Multiple sets of proportion tests
In-Reply-To: <AM5P195MB002057E636996B8C79A5F00D80260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002057E636996B8C79A5F00D80260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAJuCY5wW5DEfwk8x_BJ7_jFTXRURd-vFScB4mte=+GSQmg=Kiw@mail.gmail.com>

Hi anonymous,

?prop.test states that it returns a list. And one of the element is
'p.value'.  str() on the output of prop.test() reveals that too. So
prop.test()$p.value or prop.test()["p.value"] should work.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-11-24 12:09 GMT+01:00 Allaisone 1 <allaisone1 at hotmail.com>:
>
> Hi all ,
>
>
> I have a dataframe  of 200 columns and 2 rows. The first row in each column contains the frequency of cases in group I . The second row in each column contains the frequency of cases in group II. The frequency of trails is a fixed value for group I(e.g.200) and it is also another fixed values for group II (e.g. 100). The dataset looks like this :-
>
>
>> Mydata
>
>
>                                       variable I      variable II    Variable III  ......... 200
>
> Freq.of cases (gp I)      6493               9375               5524
>
> Freq. of cases (gpII)     509                  462                 54
>
>
>
> The result I need for the first column can be given using this code :
>
>
>  MyResultsI <- prop.test(Mydata$variable I ,c(200,100))
> for the second  column :-
> MyResultsII <- prop.test(Mydata$variable II ,c(200,100))  and so on ..
>
>
> I need to do the analysis for all columns and have only the columns with significant p-value results to be written in the the third row under each column so the final output has to be something like this :-
>
>
>                                       variable I        Variable III  .........
>
> Freq.of cases (gp I)      6493                   5524
>
> Freq. of cases (gpII)     509                      54
>
> p-values                          0.02               0.010
>
> Note, for example, that the 2nd column has bee removed as it resulted in a non-significant p-value result while col 1 and col 3 were included since p-value is less than 0.05.
>
> I'm not sure how to get the p-values only without other details but for the analysis itself , I believe it can be done with apply() function but its not clear to me how to specify the 2nd argument(n=samlpe sizes) in the prop.test.
>
>  MyResults <- apply(Mydata, 2, function(x)prop.test(Mydata,c(200,100))
>
> How can I modify the "n" argument part to solve the issue of non-equivalent length between "x" and "n" ?. How can I modify this further to return only significant p-values results ?. Any help would be very appreciated ..
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From santosh2005 at gmail.com  Fri Nov 24 23:24:12 2017
From: santosh2005 at gmail.com (Santosh)
Date: Fri, 24 Nov 2017 14:24:12 -0800
Subject: [R] installing "rgl" package
In-Reply-To: <743193c7-8bc3-1bf3-2d8a-0700dcb082a7@gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <743193c7-8bc3-1bf3-2d8a-0700dcb082a7@gmail.com>
Message-ID: <CAN_e6XtkHriH+_sMXT_LQ4oYf=gRKCyL1Nx6WuXMbY=36e3S8Q@mail.gmail.com>

Hi Duncan, and others..

Yes, below are the search results. it is linked to mesa/libGL.so and is
again point to libGL.so -> libGL.so.1.2.0 . However, I could not find
libGL.so.1.2.0 or its source. Where is libGL.so.1.2.0 expected to be
located?


/usr/lib/libGL.so.1

/usr/lib/x86_64-linux-gnu/libGL.so
/usr/lib/x86_64-linux-gnu/libGL.so.1
/usr/lib/x86_64-linux-gnu/mesa/libGL.so


Thanks again,
Santosh

On Fri, Nov 24, 2017 at 12:39 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/11/2017 2:30 PM, Santosh wrote:
>
>> Hi All, Duncan, Rolf, Ista, DIrk,
>>
>> Thanks for the suggestions and I tried all of them (as suggested by
>> Duncan,
>> Rolf, Ista and Dirk)... I still get similar error as before while
>> installing 'rgl' package.. I also tried to manually configure "rgl" and
>> got
>> an error message (please see below for the verbatim output).  Would highly
>> any further ideas/suggestions!
>>
>> *In my system, "GL" library is present under "/usr/include/GL"*
>>
>
> That's the include file.  The error is saying you don't have libGL.so,
> which it is looking for in /usr/lib/x86_64-linux-gnu.  Do you have that
> file?  Is it there, and marked as executable?
>
> It's probably a symbolic link; on an old Ubuntu system I just checked, it
> points to mesa/libGL.so, which is also a symlink, pointing to
> mesa/libGL.so.1.2.0, which is executable.
>
> Duncan Murdoch
>
>
>
>> Here are the libraries available (as suggested by Rolf)
>>
>> After installing some of them, I continue to get the same error message,
>> please below the output messages in config.log after I ran "./configure")
>>
>>
>> "ii  r-cran-rgl                            0.93.996-1
>>          amd64        GNU R package for three-dimensional visualisation
>> using OpenGL"
>>
>> "ii  libegl1-mesa:amd64                    10.1.3-0ubuntu0.6
>>         amd64        free implementation of the EGL API -- runtime"
>>
>> "ii  libegl1-mesa-dev                      10.1.3-0ubuntu0.6
>>         amd64        free implementation of the EGL API -- development
>> files"
>>
>> "ii  libegl1-mesa-drivers:amd64            10.1.3-0ubuntu0.6
>>         amd64        free implementation of the EGL API -- hardware
>> drivers"
>>
>> "ii  libgl1-mesa-dev                       10.1.3-0ubuntu0.6
>>         amd64        free implementation of the OpenGL API -- GLX
>> development files"
>>
>> "ii  libgl1-mesa-dri:amd64                 10.1.3-0ubuntu0.6
>>         amd64        free implementation of the OpenGL API -- DRI modules"
>>
>>
>> "ii  libgl1-mesa-glx:amd64                 10.1.3-0ubuntu0.6
>>         amd64        free implementation of the OpenGL API -- GLX runtime"
>>
>>
>> "ii  libglapi-mesa:amd64                   10.1.3-0ubuntu0.6
>>         amd64        free implementation of the GL API -- shared library"
>>
>> "ii  libglu1-mesa:amd64                    9.0.0-2
>>         amd64        Mesa OpenGL utility library (GLU)"
>>
>> "ii  libglu1-mesa-dev                      9.0.0-2
>>         amd64        Mesa OpenGL utility library -- development files"
>>
>> "ii  libwayland-client0:amd64              1.4.0-1ubuntu1
>>          amd64        wayland compositor infrastructure - client library"
>>
>> "ii  libwayland-cursor0:amd64              1.4.0-1ubuntu1
>>          amd64        wayland compositor infrastructure - cursor library"
>>
>> "ii  libwayland-dev                        1.4.0-1ubuntu1
>>          amd64        wayland compositor infrastructure - development
>> files"
>>
>> "ii  libwayland-egl1-mesa:amd64            10.1.3-0ubuntu0.6
>>         amd64        implementation of the Wayland EGL platform --
>> runtime"
>>
>> "ii  libwayland-server0:amd64              1.4.0-1ubuntu1
>>          amd64        wayland compositor infrastructure - server library"
>>
>> "ii  mesa-common-dev                       10.1.3-0ubuntu0.6
>>         amd64        Developer documentation for Mesa"
>>
>> "ii  mesa-vdpau-drivers:amd64              10.1.3-0ubuntu0.6
>>         amd64        Mesa VDPAU video acceleration drivers"
>>
>> "ii  mesa-utils                            8.1.0-2
>>         amd64        Miscellaneous Mesa GL utilities"
>>
>>
>> The error message when installing "rgl" library,
>>
>> * installing *source* package ?rgl? ...
>>
>> checking for gcc... gcc -std=gnu99
>>
>> checking whether the C compiler works... yes
>>
>> checking for C compiler default output file name... a.out
>>
>> checking for suffix of executables...
>>
>> checking whether we are cross compiling... no
>>
>> checking for suffix of object files... o
>>
>> checking whether we are using the GNU C compiler... yes
>>
>> checking whether gcc -std=gnu99 accepts -g... yes
>>
>> checking for gcc -std=gnu99 option to accept ISO C89... none needed
>>
>> checking how to run the C preprocessor... gcc -std=gnu99 -E
>>
>> checking for gcc... (cached) gcc -std=gnu99
>>
>> checking whether we are using the GNU C compiler... (cached) yes
>>
>> checking whether gcc -std=gnu99 accepts -g... (cached) yes
>>
>> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none
>> needed
>>
>> checking for libpng-config... yes
>>
>> configure: using libpng-config
>>
>> configure: using libpng dynamic linkage
>>
>> checking for X... libraries , headers
>>
>> checking GL/gl.h usability... yes
>>
>> checking GL/gl.h presence... yes
>>
>> checking for GL/gl.h... yes
>>
>> checking GL/glu.h usability... yes
>>
>> checking GL/glu.h presence... yes
>>
>> checking for GL/glu.h... yes
>>
>> checking for glEnd in -lGL... no
>>
>> configure: error: missing required library GL
>>
>> ERROR: configuration failed for package ?rgl?
>>
>> * removing ?/data/R/lib/rgl?
>>
>> Warning in install.packages :
>>
>>    installation of package ?rgl? had non-zero exit status
>>
>>
>> The error message as seen in config.log (after manually running
>> "./configure" under "rgl")
>>
>> configure:4263: checking for glEnd in -lGL
>> configure:4288: gcc -std=gnu99 -o conftest -g -O2 -fstack-protector
>> --param=ssp-buffer-size=4 -Wformat -Werror=format-security
>> -D_FORTIFY_SOURCE=2 -g  -DHAVE_PNG_H -I/usr/include/libpng12
>> conftest.c -lGL   -L/usr/lib/x86_64-linux-gnu -lpng12 -lX11
>>
>>> &5*/*usr/bin/ld: cannot find -lGL
>>>
>> collect2: error: ld returned 1 exit status
>> configure:4288: $? = 1
>> configure: failed program was:
>> | /* confdefs.h */
>> | #define PACKAGE_NAME ""
>> | #define PACKAGE_TARNAME ""
>> | #define PACKAGE_VERSION ""
>> | #define PACKAGE_STRING ""
>> | #define PACKAGE_BUGREPORT ""
>> | #define PACKAGE_URL ""
>> | #define HAVE_GL_GL_H 1
>> | #define HAVE_GL_GLU_H 1
>> | /* end confdefs.h.  */
>> |
>> | /* Override any GCC internal prototype to avoid an error.
>> |    Use char because int might match the return type of a GCC
>> |    builtin and then its argument prototype would still apply.  */
>> | #ifdef __cplusplus
>> | extern "C"
>> | #endif
>> | char glEnd ();
>> | int
>> | main ()
>> | {
>> | return glEnd ();
>> |   ;
>> |   return 0;
>> | }configure:4298: result: no
>> configure:4311: error: missing required library GL
>>
>> Thanks a ton, again!
>> Santosh
>>
>> On Fri, Nov 24, 2017 at 5:13 AM, Dirk Eddelbuettel <edd at debian.org>
>> wrote:
>>
>>
>>> On 23 November 2017 at 15:05, Santosh wrote:
>>> | I am trying to install 'rgl' package in Ubuntu.. Would highly
>>> appreciate
>>> | your assistance .. I tried several leads available on various
>>> discussion
>>> | fora and nothing helped so far.
>>>
>>> Install the _pre-built binary package_ via
>>>
>>>      sudo apt install r-cran-rgl
>>>
>>> Dirk
>>>
>>> --
>>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 24 23:33:30 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 24 Nov 2017 17:33:30 -0500
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XtkHriH+_sMXT_LQ4oYf=gRKCyL1Nx6WuXMbY=36e3S8Q@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <743193c7-8bc3-1bf3-2d8a-0700dcb082a7@gmail.com>
 <CAN_e6XtkHriH+_sMXT_LQ4oYf=gRKCyL1Nx6WuXMbY=36e3S8Q@mail.gmail.com>
Message-ID: <2f330706-35bc-acaa-d529-305898e42edb@gmail.com>

On 24/11/2017 5:24 PM, Santosh wrote:
> Hi Duncan, and others..
> 
> Yes, below are the search results. it is linked to mesa/libGL.so and is 
> again point to libGL.so -> libGL.so.1.2.0?. However, I could not find 
> libGL.so.1.2.0 or its source. Where is libGL.so.1.2.0 expected to be 
> located?

Mine was in /usr/lib/x86_64-linux-gnu/mesa/.

Duncan Murdoch

> 
> 
> /usr/lib/libGL.so.1
> 
> /usr/lib/x86_64-linux-gnu/libGL.so /usr/lib/x86_64-linux-gnu/libGL.so.1 
> /usr/lib/x86_64-linux-gnu/mesa/libGL.so
> 
> 
> Thanks again,
> Santosh
> 
> On Fri, Nov 24, 2017 at 12:39 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 24/11/2017 2:30 PM, Santosh wrote:
> 
>         Hi All, Duncan, Rolf, Ista, DIrk,
> 
>         Thanks for the suggestions and I tried all of them (as suggested
>         by Duncan,
>         Rolf, Ista and Dirk)... I still get similar error as before while
>         installing 'rgl' package.. I also tried to manually configure
>         "rgl" and got
>         an error message (please see below for the verbatim output). 
>         Would highly
>         any further ideas/suggestions!
> 
>         *In my system, "GL" library is present under "/usr/include/GL"*
> 
> 
>     That's the include file.? The error is saying you don't have
>     libGL.so, which it is looking for in /usr/lib/x86_64-linux-gnu.? Do
>     you have that file?? Is it there, and marked as executable?
> 
>     It's probably a symbolic link; on an old Ubuntu system I just
>     checked, it points to mesa/libGL.so, which is also a symlink,
>     pointing to mesa/libGL.so.1.2.0, which is executable.
> 
>     Duncan Murdoch
> 
> 
> 
>         Here are the libraries available (as suggested by Rolf)
> 
>         After installing some of them, I continue to get the same error
>         message,
>         please below the output messages in config.log after I ran
>         "./configure")
> 
> 
>         "ii? r-cran-rgl? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.93.996-1
>          ? ? ? ? ?amd64? ? ? ? GNU R package for three-dimensional
>         visualisation
>         using OpenGL"
> 
>         "ii? libegl1-mesa:amd64? ? ? ? ? ? ? ? ? ? 10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the EGL API -- runtime"
> 
>         "ii? libegl1-mesa-dev? ? ? ? ? ? ? ? ? ? ? 10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the EGL API --
>         development files"
> 
>         "ii? libegl1-mesa-drivers:amd64? ? ? ? ? ? 10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the EGL API --
>         hardware drivers"
> 
>         "ii? libgl1-mesa-dev? ? ? ? ? ? ? ? ? ? ? ?10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the OpenGL API -- GLX
>         development files"
> 
>         "ii? libgl1-mesa-dri:amd64? ? ? ? ? ? ? ? ?10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the OpenGL API --
>         DRI modules"
> 
> 
>         "ii? libgl1-mesa-glx:amd64? ? ? ? ? ? ? ? ?10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the OpenGL API --
>         GLX runtime"
> 
> 
>         "ii? libglapi-mesa:amd64? ? ? ? ? ? ? ? ? ?10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? free implementation of the GL API --
>         shared library"
> 
>         "ii? libglu1-mesa:amd64? ? ? ? ? ? ? ? ? ? 9.0.0-2
>          ? ? ? ? amd64? ? ? ? Mesa OpenGL utility library (GLU)"
> 
>         "ii? libglu1-mesa-dev? ? ? ? ? ? ? ? ? ? ? 9.0.0-2
>          ? ? ? ? amd64? ? ? ? Mesa OpenGL utility library -- development
>         files"
> 
>         "ii? libwayland-client0:amd64? ? ? ? ? ? ? 1.4.0-1ubuntu1
>          ? ? ? ? ?amd64? ? ? ? wayland compositor infrastructure -
>         client library"
> 
>         "ii? libwayland-cursor0:amd64? ? ? ? ? ? ? 1.4.0-1ubuntu1
>          ? ? ? ? ?amd64? ? ? ? wayland compositor infrastructure -
>         cursor library"
> 
>         "ii? libwayland-dev? ? ? ? ? ? ? ? ? ? ? ? 1.4.0-1ubuntu1
>          ? ? ? ? ?amd64? ? ? ? wayland compositor infrastructure -
>         development files"
> 
>         "ii? libwayland-egl1-mesa:amd64? ? ? ? ? ? 10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? implementation of the Wayland EGL platform
>         -- runtime"
> 
>         "ii? libwayland-server0:amd64? ? ? ? ? ? ? 1.4.0-1ubuntu1
>          ? ? ? ? ?amd64? ? ? ? wayland compositor infrastructure -
>         server library"
> 
>         "ii? mesa-common-dev? ? ? ? ? ? ? ? ? ? ? ?10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? Developer documentation for Mesa"
> 
>         "ii? mesa-vdpau-drivers:amd64? ? ? ? ? ? ? 10.1.3-0ubuntu0.6
>          ? ? ? ? amd64? ? ? ? Mesa VDPAU video acceleration drivers"
> 
>         "ii? mesa-utils? ? ? ? ? ? ? ? ? ? ? ? ? ? 8.1.0-2
>          ? ? ? ? amd64? ? ? ? Miscellaneous Mesa GL utilities"
> 
> 
>         The error message when installing "rgl" library,
> 
>         * installing *source* package ?rgl? ...
> 
>         checking for gcc... gcc -std=gnu99
> 
>         checking whether the C compiler works... yes
> 
>         checking for C compiler default output file name... a.out
> 
>         checking for suffix of executables...
> 
>         checking whether we are cross compiling... no
> 
>         checking for suffix of object files... o
> 
>         checking whether we are using the GNU C compiler... yes
> 
>         checking whether gcc -std=gnu99 accepts -g... yes
> 
>         checking for gcc -std=gnu99 option to accept ISO C89... none needed
> 
>         checking how to run the C preprocessor... gcc -std=gnu99 -E
> 
>         checking for gcc... (cached) gcc -std=gnu99
> 
>         checking whether we are using the GNU C compiler... (cached) yes
> 
>         checking whether gcc -std=gnu99 accepts -g... (cached) yes
> 
>         checking for gcc -std=gnu99 option to accept ISO C89... (cached)
>         none needed
> 
>         checking for libpng-config... yes
> 
>         configure: using libpng-config
> 
>         configure: using libpng dynamic linkage
> 
>         checking for X... libraries , headers
> 
>         checking GL/gl.h usability... yes
> 
>         checking GL/gl.h presence... yes
> 
>         checking for GL/gl.h... yes
> 
>         checking GL/glu.h usability... yes
> 
>         checking GL/glu.h presence... yes
> 
>         checking for GL/glu.h... yes
> 
>         checking for glEnd in -lGL... no
> 
>         configure: error: missing required library GL
> 
>         ERROR: configuration failed for package ?rgl?
> 
>         * removing ?/data/R/lib/rgl?
> 
>         Warning in install.packages :
> 
>          ? ?installation of package ?rgl? had non-zero exit status
> 
> 
>         The error message as seen in config.log (after manually running
>         "./configure" under "rgl")
> 
>         configure:4263: checking for glEnd in -lGL
>         configure:4288: gcc -std=gnu99 -o conftest -g -O2 -fstack-protector
>         --param=ssp-buffer-size=4 -Wformat -Werror=format-security
>         -D_FORTIFY_SOURCE=2 -g? -DHAVE_PNG_H -I/usr/include/libpng12
>         conftest.c -lGL? ?-L/usr/lib/x86_64-linux-gnu -lpng12 -lX11
> 
>             &5*/*usr/bin/ld: cannot find -lGL
> 
>         collect2: error: ld returned 1 exit status
>         configure:4288: $? = 1
>         configure: failed program was:
>         | /* confdefs.h */
>         | #define PACKAGE_NAME ""
>         | #define PACKAGE_TARNAME ""
>         | #define PACKAGE_VERSION ""
>         | #define PACKAGE_STRING ""
>         | #define PACKAGE_BUGREPORT ""
>         | #define PACKAGE_URL ""
>         | #define HAVE_GL_GL_H 1
>         | #define HAVE_GL_GLU_H 1
>         | /* end confdefs.h.? */
>         |
>         | /* Override any GCC internal prototype to avoid an error.
>         |? ? Use char because int might match the return type of a GCC
>         |? ? builtin and then its argument prototype would still apply.? */
>         | #ifdef __cplusplus
>         | extern "C"
>         | #endif
>         | char glEnd ();
>         | int
>         | main ()
>         | {
>         | return glEnd ();
>         |? ?;
>         |? ?return 0;
>         | }configure:4298: result: no
>         configure:4311: error: missing required library GL
> 
>         Thanks a ton, again!
>         Santosh
> 
>         On Fri, Nov 24, 2017 at 5:13 AM, Dirk Eddelbuettel
>         <edd at debian.org <mailto:edd at debian.org>> wrote:
> 
> 
>             On 23 November 2017 at 15:05, Santosh wrote:
>             | I am trying to install 'rgl' package in Ubuntu.. Would
>             highly appreciate
>             | your assistance .. I tried several leads available on
>             various discussion
>             | fora and nothing helped so far.
> 
>             Install the _pre-built binary package_ via
> 
>              ? ? ?sudo apt install r-cran-rgl
> 
>             Dirk
> 
>             --
>             http://dirk.eddelbuettel.com | @eddelbuettel |
>             edd at debian.org <mailto:edd at debian.org>
> 
> 
>          ? ? ? ? [[alternative HTML version deleted]]
> 
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From edd at debian.org  Fri Nov 24 23:45:47 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 24 Nov 2017 16:45:47 -0600
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
Message-ID: <23064.41243.718222.536196@bud.eddelbuettel.com>


On 24 November 2017 at 11:30, Santosh wrote:
| Hi All, Duncan, Rolf, Ista, DIrk,
| 
| Thanks for the suggestions and I tried all of them (as suggested by Duncan,
| Rolf, Ista and Dirk)... I still get similar error as before while
| installing 'rgl' package.. I also tried to manually configure "rgl" and got
| an error message (please see below for the verbatim output).  Would highly
| any further ideas/suggestions!
| 
| *In my system, "GL" library is present under "/usr/include/GL"*
| 
| Here are the libraries available (as suggested by Rolf)
| 
| After installing some of them, I continue to get the same error message,
| please below the output messages in config.log after I ran "./configure")
| 
| 
| "ii  r-cran-rgl                            0.93.996-1
|         amd64        GNU R package for three-dimensional visualisation
| using OpenGL"

That means you _have_ the rgl package installed, and can stop everything you
are doing.

You do _not_ need to install it from source via R. You have it from Ubuntu.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From santosh2005 at gmail.com  Fri Nov 24 23:54:23 2017
From: santosh2005 at gmail.com (Santosh)
Date: Fri, 24 Nov 2017 14:54:23 -0800
Subject: [R] installing "rgl" package
In-Reply-To: <2f330706-35bc-acaa-d529-305898e42edb@gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <743193c7-8bc3-1bf3-2d8a-0700dcb082a7@gmail.com>
 <CAN_e6XtkHriH+_sMXT_LQ4oYf=gRKCyL1Nx6WuXMbY=36e3S8Q@mail.gmail.com>
 <2f330706-35bc-acaa-d529-305898e42edb@gmail.com>
Message-ID: <CAN_e6XumywRvjxg1v2j5xg312tqwhWY1gawAiZyPgdEP6BcFbQ@mail.gmail.com>

Hi Duncan, Dirk, & Others,

Mine has also like this...
/usr/lib/x86_64-linux-gnu/libGL.so -> mesa/libGL.so  ->  libGL.so.1.2.0

however, I could not find the source of libGL.so.1.2.0

Dirk, I just now saw your response... Yes, r-cran-rgl and ibgl1-mesa-glx
<https://packages.ubuntu.com/quantal/libgl1-mesa-glx-dbg> are the latest
available now.  How do I install R package "rgl" successfully? it gives the
error about glEnd... and removes the  R package "rgl".

Thanks again,
Santosh


On Fri, Nov 24, 2017 at 2:33 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/11/2017 5:24 PM, Santosh wrote:
>
>> Hi Duncan, and others..
>>
>> Yes, below are the search results. it is linked to mesa/libGL.so and is
>> again point to libGL.so -> libGL.so.1.2.0 . However, I could not find
>> libGL.so.1.2.0 or its source. Where is libGL.so.1.2.0 expected to be
>> located?
>>
>
> Mine was in /usr/lib/x86_64-linux-gnu/mesa/.
>
> Duncan Murdoch
>
>
>>
>> /usr/lib/libGL.so.1
>>
>> /usr/lib/x86_64-linux-gnu/libGL.so /usr/lib/x86_64-linux-gnu/libGL.so.1
>> /usr/lib/x86_64-linux-gnu/mesa/libGL.so
>>
>>
>> Thanks again,
>> Santosh
>>
>> On Fri, Nov 24, 2017 at 12:39 PM, Duncan Murdoch <
>> murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 24/11/2017 2:30 PM, Santosh wrote:
>>
>>         Hi All, Duncan, Rolf, Ista, DIrk,
>>
>>         Thanks for the suggestions and I tried all of them (as suggested
>>         by Duncan,
>>         Rolf, Ista and Dirk)... I still get similar error as before while
>>         installing 'rgl' package.. I also tried to manually configure
>>         "rgl" and got
>>         an error message (please see below for the verbatim output).
>>    Would highly
>>         any further ideas/suggestions!
>>
>>         *In my system, "GL" library is present under "/usr/include/GL"*
>>
>>
>>     That's the include file.  The error is saying you don't have
>>     libGL.so, which it is looking for in /usr/lib/x86_64-linux-gnu.  Do
>>     you have that file?  Is it there, and marked as executable?
>>
>>     It's probably a symbolic link; on an old Ubuntu system I just
>>     checked, it points to mesa/libGL.so, which is also a symlink,
>>     pointing to mesa/libGL.so.1.2.0, which is executable.
>>
>>     Duncan Murdoch
>>
>>
>>
>>         Here are the libraries available (as suggested by Rolf)
>>
>>         After installing some of them, I continue to get the same error
>>         message,
>>         please below the output messages in config.log after I ran
>>         "./configure")
>>
>>
>>         "ii  r-cran-rgl                            0.93.996-1
>>                   amd64        GNU R package for three-dimensional
>>         visualisation
>>         using OpenGL"
>>
>>         "ii  libegl1-mesa:amd64                    10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the EGL API --
>> runtime"
>>
>>         "ii  libegl1-mesa-dev                      10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the EGL API --
>>         development files"
>>
>>         "ii  libegl1-mesa-drivers:amd64            10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the EGL API --
>>         hardware drivers"
>>
>>         "ii  libgl1-mesa-dev                       10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the OpenGL API -- GLX
>>         development files"
>>
>>         "ii  libgl1-mesa-dri:amd64                 10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the OpenGL API --
>>         DRI modules"
>>
>>
>>         "ii  libgl1-mesa-glx:amd64                 10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the OpenGL API --
>>         GLX runtime"
>>
>>
>>         "ii  libglapi-mesa:amd64                   10.1.3-0ubuntu0.6
>>                  amd64        free implementation of the GL API --
>>         shared library"
>>
>>         "ii  libglu1-mesa:amd64                    9.0.0-2
>>                  amd64        Mesa OpenGL utility library (GLU)"
>>
>>         "ii  libglu1-mesa-dev                      9.0.0-2
>>                  amd64        Mesa OpenGL utility library -- development
>>         files"
>>
>>         "ii  libwayland-client0:amd64              1.4.0-1ubuntu1
>>                   amd64        wayland compositor infrastructure -
>>         client library"
>>
>>         "ii  libwayland-cursor0:amd64              1.4.0-1ubuntu1
>>                   amd64        wayland compositor infrastructure -
>>         cursor library"
>>
>>         "ii  libwayland-dev                        1.4.0-1ubuntu1
>>                   amd64        wayland compositor infrastructure -
>>         development files"
>>
>>         "ii  libwayland-egl1-mesa:amd64            10.1.3-0ubuntu0.6
>>                  amd64        implementation of the Wayland EGL platform
>>         -- runtime"
>>
>>         "ii  libwayland-server0:amd64              1.4.0-1ubuntu1
>>                   amd64        wayland compositor infrastructure -
>>         server library"
>>
>>         "ii  mesa-common-dev                       10.1.3-0ubuntu0.6
>>                  amd64        Developer documentation for Mesa"
>>
>>         "ii  mesa-vdpau-drivers:amd64              10.1.3-0ubuntu0.6
>>                  amd64        Mesa VDPAU video acceleration drivers"
>>
>>         "ii  mesa-utils                            8.1.0-2
>>                  amd64        Miscellaneous Mesa GL utilities"
>>
>>
>>         The error message when installing "rgl" library,
>>
>>         * installing *source* package ?rgl? ...
>>
>>         checking for gcc... gcc -std=gnu99
>>
>>         checking whether the C compiler works... yes
>>
>>         checking for C compiler default output file name... a.out
>>
>>         checking for suffix of executables...
>>
>>         checking whether we are cross compiling... no
>>
>>         checking for suffix of object files... o
>>
>>         checking whether we are using the GNU C compiler... yes
>>
>>         checking whether gcc -std=gnu99 accepts -g... yes
>>
>>         checking for gcc -std=gnu99 option to accept ISO C89... none
>> needed
>>
>>         checking how to run the C preprocessor... gcc -std=gnu99 -E
>>
>>         checking for gcc... (cached) gcc -std=gnu99
>>
>>         checking whether we are using the GNU C compiler... (cached) yes
>>
>>         checking whether gcc -std=gnu99 accepts -g... (cached) yes
>>
>>         checking for gcc -std=gnu99 option to accept ISO C89... (cached)
>>         none needed
>>
>>         checking for libpng-config... yes
>>
>>         configure: using libpng-config
>>
>>         configure: using libpng dynamic linkage
>>
>>         checking for X... libraries , headers
>>
>>         checking GL/gl.h usability... yes
>>
>>         checking GL/gl.h presence... yes
>>
>>         checking for GL/gl.h... yes
>>
>>         checking GL/glu.h usability... yes
>>
>>         checking GL/glu.h presence... yes
>>
>>         checking for GL/glu.h... yes
>>
>>         checking for glEnd in -lGL... no
>>
>>         configure: error: missing required library GL
>>
>>         ERROR: configuration failed for package ?rgl?
>>
>>         * removing ?/data/R/lib/rgl?
>>
>>         Warning in install.packages :
>>
>>             installation of package ?rgl? had non-zero exit status
>>
>>
>>         The error message as seen in config.log (after manually running
>>         "./configure" under "rgl")
>>
>>         configure:4263: checking for glEnd in -lGL
>>         configure:4288: gcc -std=gnu99 -o conftest -g -O2
>> -fstack-protector
>>         --param=ssp-buffer-size=4 -Wformat -Werror=format-security
>>         -D_FORTIFY_SOURCE=2 -g  -DHAVE_PNG_H -I/usr/include/libpng12
>>         conftest.c -lGL   -L/usr/lib/x86_64-linux-gnu -lpng12 -lX11
>>
>>             &5*/*usr/bin/ld: cannot find -lGL
>>
>>         collect2: error: ld returned 1 exit status
>>         configure:4288: $? = 1
>>         configure: failed program was:
>>         | /* confdefs.h */
>>         | #define PACKAGE_NAME ""
>>         | #define PACKAGE_TARNAME ""
>>         | #define PACKAGE_VERSION ""
>>         | #define PACKAGE_STRING ""
>>         | #define PACKAGE_BUGREPORT ""
>>         | #define PACKAGE_URL ""
>>         | #define HAVE_GL_GL_H 1
>>         | #define HAVE_GL_GLU_H 1
>>         | /* end confdefs.h.  */
>>         |
>>         | /* Override any GCC internal prototype to avoid an error.
>>         |    Use char because int might match the return type of a GCC
>>         |    builtin and then its argument prototype would still apply.
>> */
>>         | #ifdef __cplusplus
>>         | extern "C"
>>         | #endif
>>         | char glEnd ();
>>         | int
>>         | main ()
>>         | {
>>         | return glEnd ();
>>         |   ;
>>         |   return 0;
>>         | }configure:4298: result: no
>>         configure:4311: error: missing required library GL
>>
>>         Thanks a ton, again!
>>         Santosh
>>
>>         On Fri, Nov 24, 2017 at 5:13 AM, Dirk Eddelbuettel
>>         <edd at debian.org <mailto:edd at debian.org>> wrote:
>>
>>
>>             On 23 November 2017 at 15:05, Santosh wrote:
>>             | I am trying to install 'rgl' package in Ubuntu.. Would
>>             highly appreciate
>>             | your assistance .. I tried several leads available on
>>             various discussion
>>             | fora and nothing helped so far.
>>
>>             Install the _pre-built binary package_ via
>>
>>                   sudo apt install r-cran-rgl
>>
>>             Dirk
>>
>>             --
>>             http://dirk.eddelbuettel.com | @eddelbuettel |
>>             edd at debian.org <mailto:edd at debian.org>
>>
>>
>>                  [[alternative HTML version deleted]]
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Nov 25 00:05:33 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 24 Nov 2017 18:05:33 -0500
Subject: [R] installing "rgl" package
In-Reply-To: <23064.41243.718222.536196@bud.eddelbuettel.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <23064.41243.718222.536196@bud.eddelbuettel.com>
Message-ID: <60f13d26-7cde-d44b-5b88-9b7ed3333fb3@gmail.com>

On 24/11/2017 5:45 PM, Dirk Eddelbuettel wrote:
> 
> On 24 November 2017 at 11:30, Santosh wrote:
> | Hi All, Duncan, Rolf, Ista, DIrk,
> |
> | Thanks for the suggestions and I tried all of them (as suggested by Duncan,
> | Rolf, Ista and Dirk)... I still get similar error as before while
> | installing 'rgl' package.. I also tried to manually configure "rgl" and got
> | an error message (please see below for the verbatim output).  Would highly
> | any further ideas/suggestions!
> |
> | *In my system, "GL" library is present under "/usr/include/GL"*
> |
> | Here are the libraries available (as suggested by Rolf)
> |
> | After installing some of them, I continue to get the same error message,
> | please below the output messages in config.log after I ran "./configure")
> |
> |
> | "ii  r-cran-rgl                            0.93.996-1
> |         amd64        GNU R package for three-dimensional visualisation
> | using OpenGL"
> 
> That means you _have_ the rgl package installed, and can stop everything you
> are doing.
> 
> You do _not_ need to install it from source via R. You have it from Ubuntu.
> 

Actually the version on CRAN is pretty old, so I'd recommend people do 
install it from source, getting the source from R-forge.  Since that is 
a development site the quality varies over time, but right at this 
minute I would say it is better than the CRAN version.

Re Santosh's error messages:  it looks as though the Mesa installation 
is messed up.  I'd recommend uninstalling it, making sure there's no 
remnant of Mesa anywhere, then reinstalling it.

Duncan Murdoch


From santosh2005 at gmail.com  Sat Nov 25 00:45:31 2017
From: santosh2005 at gmail.com (Santosh)
Date: Fri, 24 Nov 2017 15:45:31 -0800
Subject: [R] installing "rgl" package
In-Reply-To: <60f13d26-7cde-d44b-5b88-9b7ed3333fb3@gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <23064.41243.718222.536196@bud.eddelbuettel.com>
 <60f13d26-7cde-d44b-5b88-9b7ed3333fb3@gmail.com>
Message-ID: <CAN_e6XsPO3b6tCo0PYCqVN0_Yqq1_S2p1LVkvpovMnt9EkDJTQ@mail.gmail.com>

Hi Duncan,
Thanks for the suggestions. How do I uninstall mesa related installations?
Do I need to uninstall all of "mesa" or only the specific ones?

Santosh

On Fri, Nov 24, 2017 at 3:05 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/11/2017 5:45 PM, Dirk Eddelbuettel wrote:
>
>>
>> On 24 November 2017 at 11:30, Santosh wrote:
>> | Hi All, Duncan, Rolf, Ista, DIrk,
>> |
>> | Thanks for the suggestions and I tried all of them (as suggested by
>> Duncan,
>> | Rolf, Ista and Dirk)... I still get similar error as before while
>> | installing 'rgl' package.. I also tried to manually configure "rgl" and
>> got
>> | an error message (please see below for the verbatim output).  Would
>> highly
>> | any further ideas/suggestions!
>> |
>> | *In my system, "GL" library is present under "/usr/include/GL"*
>> |
>> | Here are the libraries available (as suggested by Rolf)
>> |
>> | After installing some of them, I continue to get the same error message,
>> | please below the output messages in config.log after I ran
>> "./configure")
>> |
>> |
>> | "ii  r-cran-rgl                            0.93.996-1
>> |         amd64        GNU R package for three-dimensional visualisation
>> | using OpenGL"
>>
>> That means you _have_ the rgl package installed, and can stop everything
>> you
>> are doing.
>>
>> You do _not_ need to install it from source via R. You have it from
>> Ubuntu.
>>
>>
> Actually the version on CRAN is pretty old, so I'd recommend people do
> install it from source, getting the source from R-forge.  Since that is a
> development site the quality varies over time, but right at this minute I
> would say it is better than the CRAN version.
>
> Re Santosh's error messages:  it looks as though the Mesa installation is
> messed up.  I'd recommend uninstalling it, making sure there's no remnant
> of Mesa anywhere, then reinstalling it.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Sat Nov 25 00:35:55 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Fri, 24 Nov 2017 23:35:55 +0000
Subject: [R] Multiple sets of proportion tests
In-Reply-To: <CAJuCY5wW5DEfwk8x_BJ7_jFTXRURd-vFScB4mte=+GSQmg=Kiw@mail.gmail.com>
References: <AM5P195MB002057E636996B8C79A5F00D80260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAJuCY5wW5DEfwk8x_BJ7_jFTXRURd-vFScB4mte=+GSQmg=Kiw@mail.gmail.com>
Message-ID: <AM5P195MB0020AEC615FC079011BB675780260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Thank you for clarifying this point but my main question was about how to modify my code to do the analysis correctly. The code I mentioned :-

MyResults <- apply(Mydata, 2, function(x)prop.test(Mydata,c(200,100))



Results in this error : 'x' and 'n' must have the same length in the prop.test(x,n).


How can I modify "x' or "n" arguments so the analysis gives me the desired output

shown in my previous post ?

________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: 24 November 2017 21:06:39
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Multiple sets of proportion tests

Hi anonymous,

?prop.test states that it returns a list. And one of the element is
'p.value'.  str() on the output of prop.test() reveals that too. So
prop.test()$p.value or prop.test()["p.value"] should work.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-11-24 12:09 GMT+01:00 Allaisone 1 <allaisone1 at hotmail.com>:
>
> Hi all ,
>
>
> I have a dataframe  of 200 columns and 2 rows. The first row in each column contains the frequency of cases in group I . The second row in each column contains the frequency of cases in group II. The frequency of trails is a fixed value for group I(e.g.200) and it is also another fixed values for group II (e.g. 100). The dataset looks like this :-
>
>
>> Mydata
>
>
>                                       variable I      variable II    Variable III  ......... 200
>
> Freq.of cases (gp I)      6493               9375               5524
>
> Freq. of cases (gpII)     509                  462                 54
>
>
>
> The result I need for the first column can be given using this code :
>
>
>  MyResultsI <- prop.test(Mydata$variable I ,c(200,100))
> for the second  column :-
> MyResultsII <- prop.test(Mydata$variable II ,c(200,100))  and so on ..
>
>
> I need to do the analysis for all columns and have only the columns with significant p-value results to be written in the the third row under each column so the final output has to be something like this :-
>
>
>                                       variable I        Variable III  .........
>
> Freq.of cases (gp I)      6493                   5524
>
> Freq. of cases (gpII)     509                      54
>
> p-values                          0.02               0.010
>
> Note, for example, that the 2nd column has bee removed as it resulted in a non-significant p-value result while col 1 and col 3 were included since p-value is less than 0.05.
>
> I'm not sure how to get the p-values only without other details but for the analysis itself , I believe it can be done with apply() function but its not clear to me how to specify the 2nd argument(n=samlpe sizes) in the prop.test.
>
>  MyResults <- apply(Mydata, 2, function(x)prop.test(Mydata,c(200,100))
>
> How can I modify the "n" argument part to solve the issue of non-equivalent length between "x" and "n" ?. How can I modify this further to return only significant p-values results ?. Any help would be very appreciated ..
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From larssonlubo at gmail.com  Sat Nov 25 03:00:02 2017
From: larssonlubo at gmail.com (Lubo Larsson)
Date: Fri, 24 Nov 2017 20:00:02 -0600
Subject: [R] Cannot start OpenBUGS from R2WinBugs
Message-ID: <CAF4B2TBVWP96spB=Y3ebpH4Dxrt2K-rvoQbL4zRbVs72pf0Wkw@mail.gmail.com>

Hello,

I'm running R version 3.4.2 on Windows. I have a program written in
BUGS which I can successfully run from the R2WinBUGS package.

I would also like to try and use the same package to use OpenBUGS
(version 3.2.3) rather than WinBUGS.

The initial output looks ok (shown below), but the OpenBUGS executable
is never started. Instead I see a process running called
?BugsHelper.exe *32? in the Windows Task manager, and the R bugs()
call just hangs.

Can anyone suggest a reason why this is happening?

(Apologies if this should be on a more specialized list, but I did not
see one that looked any more suitable. Please anyone let me know
otherwise.)

Best,
John

?Loading required namespace: BRugs
Welcome to BRugs connected to OpenBUGS version 3.2.3
model is syntactically correct
data loaded
model compiled
Initializing chain 1:
model is initialized
model is already initialized
Sampling has been started ...?


From dwinsemius at comcast.net  Sat Nov 25 18:49:26 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 25 Nov 2017 09:49:26 -0800
Subject: [R] Multiple sets of proportion tests
In-Reply-To: <AM5P195MB0020AEC615FC079011BB675780260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB002057E636996B8C79A5F00D80260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAJuCY5wW5DEfwk8x_BJ7_jFTXRURd-vFScB4mte=+GSQmg=Kiw@mail.gmail.com>
 <AM5P195MB0020AEC615FC079011BB675780260@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <05BC6A62-8D5F-4E9F-B665-F91DF8DB64ED@comcast.net>


> On Nov 24, 2017, at 3:35 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> 
> Thank you for clarifying this point but my main question was about how to modify my code to do the analysis correctly.

You need to first clarify what your proposed statistical hypothesis might be. If you are doing prop.test on 300 columns you have a serious multiple comparisons issue in your analysis plan that you have not recognized. Removing the columns that "fail" a test set at nominal level of 0.05 is statistical malpractice.


> The code I mentioned :-
> 
> MyResults <- apply(Mydata, 2, function(x)prop.test(Mydata,c(200,100))


The code as written appears to have the obvious error of using `Mydata` as an argument inside the prop.test function. Should almost certainly be `x` instead. (I suspect the length of the 'x'-argument to prop.test will be on the order of 200 and the length of n is 2, hence the error.)

It would also be ideal if you could post the output of dput(Mydata[,1:3] ).


> Results in this error : 'x' and 'n' must have the same length in the prop.test(x,n).
> 
> 
> How can I modify "x' or "n" arguments so the analysis gives me the desired output

You desperately need to read the help page for the function you are using. This need was pointed out to you, but it appears to me that you have ignored Thierry's advice. (Going back to your original example ... The x variable is supposed to be the number of success and the n variable is the number of trials. So in all instances n MUST be greater than or equal to x. Your data example is going to fail that requirement even after you correct the semantic error noted above.)

(And do learn to post with plain text.)
-- 
David.
> 
> shown in my previous post ?
> 
> ________________________________
> From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Sent: 24 November 2017 21:06:39
> To: Allaisone 1
> Cc: r-help at r-project.org
> Subject: Re: [R] Multiple sets of proportion tests
> 
> Hi anonymous,
> 
> ?prop.test states that it returns a list. And one of the element is
> 'p.value'.  str() on the output of prop.test() reveals that too. So
> prop.test()$p.value or prop.test()["p.value"] should work.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be<http://www.inbo.be>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 2017-11-24 12:09 GMT+01:00 Allaisone 1 <allaisone1 at hotmail.com>:
>> 
>> Hi all ,
>> 
>> 
>> I have a dataframe  of 200 columns and 2 rows. The first row in each column contains the frequency of cases in group I . The second row in each column contains the frequency of cases in group II. The frequency of trails is a fixed value for group I(e.g.200) and it is also another fixed values for group II (e.g. 100). The dataset looks like this :-
>> 
>> 
>>> Mydata
>> 
>> 
>>                                      variable I      variable II    Variable III  ......... 200
>> 
>> Freq.of cases (gp I)      6493               9375               5524
>> 
>> Freq. of cases (gpII)     509                  462                 54
>> 
>> 
>> 
>> The result I need for the first column can be given using this code :
>> 
>> 
>> MyResultsI <- prop.test(Mydata$variable I ,c(200,100))
>> for the second  column :-
>> MyResultsII <- prop.test(Mydata$variable II ,c(200,100))  and so on ..
>> 
>> 
>> I need to do the analysis for all columns and have only the columns with significant p-value results to be written in the the third row under each column so the final output has to be something like this :-
>> 
>> 
>>                                      variable I        Variable III  .........
>> 
>> Freq.of cases (gp I)      6493                   5524
>> 
>> Freq. of cases (gpII)     509                      54
>> 
>> p-values                          0.02               0.010
>> 
>> Note, for example, that the 2nd column has bee removed as it resulted in a non-significant p-value result while col 1 and col 3 were included since p-value is less than 0.05.
>> 
>> I'm not sure how to get the p-values only without other details but for the analysis itself , I believe it can be done with apply() function but its not clear to me how to specify the 2nd argument(n=samlpe sizes) in the prop.test.
>> 
>> MyResults <- apply(Mydata, 2, function(x)prop.test(Mydata,c(200,100))
>> 
>> How can I modify the "n" argument part to solve the issue of non-equivalent length between "x" and "n" ?. How can I modify this further to return only significant p-values results ?. Any help would be very appreciated ..
>> 
>> Regards
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From david.hutchinson at canada.ca  Sat Nov 25 20:18:31 2017
From: david.hutchinson at canada.ca (Hutchinson, David (EC))
Date: Sat, 25 Nov 2017 19:18:31 +0000
Subject: [R] dplyr - add/expand rows
Message-ID: <mailman.9.1511650858.1574.r-help@r-project.org>

I have a returned tibble of station operational record similar to the following:

> data.collection
# A tibble: 5 x 4
  STATION_NUMBER YEAR_FROM YEAR_TO RECORD
           <chr>     <int>   <int>  <chr>
1        07EA001      1960    1960    QMS
2        07EA001      1961    1970    QMC
3        07EA001      1971    1971    QMM
4        07EA001      1972    1976    QMC
5        07EA001      1977    1983    QRC

I would like to reshape this to one operational record (row) per year per station. Something like:

07EA001              1960      QMS
07EA001              1961      QMC
07EA001              1962      QMC
07EA001              1963      QMC
...
07EA001              1971      QMM

Can this be done in dplyr easily?

Thanks in advance,

David

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Nov 26 01:49:36 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 25 Nov 2017 16:49:36 -0800
Subject: [R] dplyr - add/expand rows
In-Reply-To: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
Message-ID: <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>

dplyr may have something for this, but in base R I think the following does
what you want.  I've shortened the name of your data set to 'd'.

i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
david.hutchinson at canada.ca> wrote:

> I have a returned tibble of station operational record similar to the
> following:
>
> > data.collection
> # A tibble: 5 x 4
>   STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>            <chr>     <int>   <int>  <chr>
> 1        07EA001      1960    1960    QMS
> 2        07EA001      1961    1970    QMC
> 3        07EA001      1971    1971    QMM
> 4        07EA001      1972    1976    QMC
> 5        07EA001      1977    1983    QRC
>
> I would like to reshape this to one operational record (row) per year per
> station. Something like:
>
> 07EA001              1960      QMS
> 07EA001              1961      QMC
> 07EA001              1962      QMC
> 07EA001              1963      QMC
> ...
> 07EA001              1971      QMM
>
> Can this be done in dplyr easily?
>
> Thanks in advance,
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tsvibar at gmail.com  Sun Nov 26 07:11:23 2017
From: tsvibar at gmail.com (Micha Silver)
Date: Sun, 26 Nov 2017 08:11:23 +0200
Subject: [R] How to produce rainfall maps
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F471BA3C2@CHIENTI.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F471AE00E@ESINO.regionemarche.intra>
 <8B435C9568170B469AE31E8891E8CC4F471AE0D5@ESINO.regionemarche.intra>
 <CAM_vjunToO=sqFWPRRYcWJTL9AOh_3TBnNpcORo+oN-ZGhGR_w@mail.gmail.com>
 <CAAcGz9-N3MFiyeewc3V8OUicY+b4yjXXHBiucK5ZvDn1LeajvQ@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F471BA3C2@CHIENTI.regionemarche.intra>
Message-ID: <2c1881c3-3423-d088-8a1e-9bae16e18d01@gmail.com>

Hi

On 11/23/2017 10:04 AM, Stefano Sofia wrote:
> Thank you Sarah and Mike for your explanations. My final objective is 
> to produce maps (png image or any kind of extension I can import in 
> LaTeX) where rainfall data are interpolated, using the Inverse 
> Distance method or Kriging. My input file (pointfile.csv in the 
> reported example) reports the station code, lat and long of the 
> meteorological station and the rainfall value (which might be the 
> cumulate of a week or ten days or the period I need to investigate). 
> Here a small example: Station_Code, Init_Year, Init_Month, Init_Day, 
> Init_Hour, Init_Minute, Fin_Year, Fin_Month, Fin_Day, Fin_Hour, 
> Fin_Minute, Rainfall_Cumulate, Long, Lat 1056, 2017 , 11 , 1 , 0 , 0 , 
> 2017 , 11 , 11 , 0 , 0 , 28.40, 12.786904, 43.851849 1064, 2017 , 11 , 
> 1 , 0 , 0 , 2017 , 11 , 11 , 0 , 0 , 27.20, 12.967556, 43.762669 1072, 
> 2017 , 11 , 1 , 0 , 0 , 2017 , 11 , 11 , 0 , 0 , 21.80, 12.897710, 
> 43.907555 As far as I can understand (as you can see, I am not an 
> expert on GIS or any spatial topic) - my input file pointfile.csv is 
> in "observation-per-row form"; - I need a grid (file.asc) where I can 
> interpolate my rainfall data (I can get it, a resolution of 1km will 
> be enough for me)
If I understand, in order to interpolate point data to a grid, the steps 
you need to do in R are:

 1. import the CSV of rain data and convert to a SpatialPointsDataFrame
 2. Convert that SPDF to a projected coordinate system, such as UTM, for
    kriging
 3. create an empty grid as the target for kriging, probably based on
    the extent of the rain data
 4. Run kriging using the point rain data and target grid

Here's a basic workflow for the above

#-----------------------------------

# Required libraries

library(gstat)
library(automap)
library(rgdal)

# Read in CSV file and convert to SPDF
rain_data <- read.csv("pointfile.csv")
str(rain_data)

# Check what you have so far

point_coords <- rain_data[c("Long","Lat")]
coordinates(rain_data) <- point_coords
p4str <- CRS("+init=epsg:4326")? # Since the coordinates are in 
Long/Lat, first declare this CRS
proj4string(rain_data) <- p4str


# Now Convert to UTM

p4str_UTM <- CRS("+init=epsg:32633")
rain_data_UTM <- spTransform(rain_data, p4str_UTM)

str(rain_data_UTM)??? # Check that this is a SPDF in the UTM coordinate 
system


# Create Grid for kriging output, using the extent of the rain data SPDF
minx <-? rain_data_UTM at bbox[1,1]
maxx <- rain_data_UTM at bbox[1,2]
miny <- rain_data_UTM at bbox[2,1]
maxy <- rain_data_UTM at bbox[2,2]
pixel <- 1000??? ??? # Each pixel will be 1000 meters
grd <- expand.grid(x=seq(minx, maxx, by=pixel), y=seq(miny, maxy, by=pixel))
coordinates(grd) <- ~x+y
gridded(grd) <- TRUE
proj4string(grd) <- p4str_UTM

# Kriging, using autoKrige which creates a best guess variogram

# The formula for ordinary kriging is "<data_column> ~ 1"

OK_rain <- autoKrige(Rainfall_Cumulate ~ 1, rain_data_UTM, grd)

#-----------------------------------


The kriging result contains a component "prediction" which you can 
either plot directly, convert to an R raster object for plotting with 
ggplot2, or export to a Geotiff.


HTH,

Micha

> Dear R users,
>> I need to produce rainfall maps using R. I know that this is 
>> possible, I looked though the web, I found the example below reported 
>> (the author is Andrew Tredennick). I would ask you if this is the 
>> most performing way to make rainfall maps; if yes would someone be 
>> able to give me an example of how file.asc and pointfile.csv should 
>> be? If no would somebody please show me another way providing a small 
>> example? Thank you for your help Stefano

-- Micha Silver Ben Gurion Univ. Sde Boker, Remote Sensing Lab cell: 
+972-523-665918


From dwinsemius at comcast.net  Sun Nov 26 18:52:41 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 26 Nov 2017 09:52:41 -0800
Subject: [R] dplyr - add/expand rows
In-Reply-To: <20171125230059.59C4C7F3@hypatia.math.ethz.ch>
References: <20171125230059.59C4C7F3@hypatia.math.ethz.ch>
Message-ID: <DAF902A3-3AEB-445C-A41B-401C220D2947@comcast.net>


> On Nov 25, 2017, at 11:18 AM, Hutchinson, David (EC) <david.hutchinson at canada.ca> wrote:
> 
> I have a returned tibble of station operational record similar to the following:
> 
>> data.collection
> # A tibble: 5 x 4
>  STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>           <chr>     <int>   <int>  <chr>
> 1        07EA001      1960    1960    QMS
> 2        07EA001      1961    1970    QMC
> 3        07EA001      1971    1971    QMM
> 4        07EA001      1972    1976    QMC
> 5        07EA001      1977    1983    QRC
> 
> I would like to reshape this to one operational record (row) per year per station. Something like:
> 
> 07EA001              1960      QMS
> 07EA001              1961      QMC
> 07EA001              1962      QMC
> 07EA001              1963      QMC
> ...
> 07EA001              1971      QMM
> 
> Can this be done in dplyr easily?

Probably, yes. This looks like a feasible plan might be to "fill-in" the gaps with a last observation carried forward value within categories of station number. The na.locf function in package zoo is very handy for some of these tasks. Or.... Perhaps merging this data with a skeleton data object with station numbers and a `seq`-built vectors for the range of years.  Why don't you post a data example with sufficient complexity to represent the problem? Perhaps:

 dput( head( data.collection, 20) )

It's clear that the first 5 lines are not sufficient since there's only one station. It's kind of a pain to try to construct tibble objects from their print output representations. And posting code to build examples is a specific suggestion in the Posting Guide.

-- 
David
> 
> Thanks in advance,
> 
> David
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ramiro at precisionbioassay.com  Sun Nov 26 19:02:55 2017
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Sun, 26 Nov 2017 18:02:55 +0000
Subject: [R] withTimeout does not timeout nlme anymore
Message-ID: <674A2A8C-FFFE-4461-AB28-8D76A27ECA78@precisionbioassay.com>

Hello,

I was relying on withTimeout (from R.utils) to help me stop nlme when it ?hangs?.  However, recently this stopped working.  I am pasting a reproducible example below: withTimeout should stop nlme after 10 seconds but in this example it does not.  I tried this both on a linux (64 bit, CentOS 7, R 3.4.1, nlme 3.1-131 R.util 2.6) and mac (Sierra 10.13.1, R 3.4.2, same versions or nlme and R.utils).  It takes over R and I need to use brute-force to stop it.  As mentioned, this used to work.

Note that I made my example with fake data so that it would not fit for the purposes of asking for advice on how to create a timeout for it (with withTimeout or other alternatives), so my question is not about convergence.

Thank you in advance for any help,
Ramiro

library(nlme)
library(R.utils)

dat<-data.frame(x=c(3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,3.68887945411394,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.99573227355399,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405,2.30258509299405<tel:(850)%20929-9405>,2.30258509299405,2.30258509299405,2.30258509299405,1.6094379124341,1.6094379124<tel:(609)%20437-9124>341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,1.6094379124341,0.916290731874155,0.9162907318<tel:(916)%20290-7318>74155,0.916290731874155,0.916290731874155,0.916290731874155,0.916290731874155,0.9162907318<tel:(916)%20290-7318>74155,0.916290731874155,0.916290731874155,0.916290731874155,0.916290731874155,0.9162907318<tel:(916)%20290-7318>74155,0.22314355131421,0.22314355131421,0.22314355131421,0.22314355131421<tel:(435)%20513-1421>,0.22314355131421,0.22314355131421,0.22314355131421,0.22314355131421,0.22314355131421,0.22314355131421,0.22314355131421<tel:(435)%20513-1421>,0.22314355131421,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-0.470003629245736,-1.8562979903<tel:(856)%20297-9903>6563,-1.85629799036563,-1.85629799036563<tel:(979)%20903-6563>,-1.85629799036563,-1.85629799036563,-1.8562979903<tel:(856)%20297-9903>6563,-1.85629799036563,-1.85629799036563<tel:(979)%20903-6563>,-1.85629799036563,-1.85629799036563,-1.8562979903<tel:(856)%20297-9903>6563,-1.85629799036563),y=c(2.3306628084907,-0.306486430184119,3.01207464681402,2.70060231852225,1.33725293267784,5.34369780941295,-0.267201590516114,-1.84139069320937,6.72827177196847,4.52822844192102,1.29157107569539<tel:(710)%20756-9539>,6.91891489430213,-0.759969537970881,1.3082989382<tel:(308)%20298-9382>3302,5.71564722091342,0.436763799674933,1.57330523686824,0.59916586097872,-2.71489460284645,0.711401656644295,-1.17314498858428,-3.34898667814291,3.25224958038328,4.49653456047519,3.40551393855124,3.50650476797142,-1.03926072184952,-2.10354107253151,1.02223260549667,1.33664269096021,4.11266309099612,0.515909252507941,2.8675357708<tel:(867)%20535-7708>4899,2.30080960365487,-4.05493845681005,1.29014437931301,-0.345028313039861,-0.270467043587825,2.18311160982943,0.103101257423303,1.44085444118562,1.44323046208807,1.01066792503854,1.21135794615458,1.32870697360187,1.23403866773281,-0.0960240778852603,-0.580707472247756,1.86075279947663,-1.22088596363264,2.14706773430471,2.52940367724292,0.0632800795606095,-0.857701981133018,1.56980334185512,-1.04879027396504,3.7755553345997,3.02040837800239,3.14723252808468,-1.70718593989965,2.66032762515534,-0.436415482887527<tel:(548)%20288-7527>,2.93587449357705,-0.216693302109348,1.13180451539961,-2.30917214206847,2.03616728416112,-0.027042599451753,4.13768334184361,3.63437837292452,-0.336366845605401,0.0607021250007267,-0.546652566416743,-1.48502861431819,-0.4416995677<tel:(441)%20699-5677>41434,-1.18356734673208,2.19947568241773,-3.3731107438774,-0.569618141275733,-1.34910482405571,-0.821676122645021,-0.210494924487845,2.76805610971345,-1.50099018527536,2.81874922657008,-2.47892179680143,-0.237168391583651,1.05384076104419,1.35730105037783,-0.889060319407602,1.29407560544756,-0.0145655801680721,2.62874531083287,-0.188992792468916,-2.36877528363888,0.193706203424581),id=c("a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3"),f.block=c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4))
fpl.B.range <- function(lx,logbase,A,B,C,D) {
  A/(1+logbase^(-B*(lx-C)))+D
}
myFormula<-list(formula(A~id),formula(B~id),formula(C~id),formula(D~id))
INIT <- c(A.a1=1,A.a2<https://maps.google.com/?q=1,A.a2&entry=gmail&source=g>=0,A.a3=0,B=1,B.a2=0,B.a3=0,C=0,C.a2=0,C.a3=0,D=1,D.a2<https://maps.google.com/?q=1,D.a2&entry=gmail&source=g>=0,D.a3=0)

try({withTimeout(nlme(model=y~fpl.B.range(x,exp(1),A,B,C,D),
                      control=nlmeControl(maxIter=50,pnlsMaxIter=7,msMaxIter=50,niterEM=25),
                      data=dat, na.action=na.omit,
                      fixed=myFormula,random=list(f.block=pdSymm(A+B+C+D~1)),
                      start=INIT),timeout=10)})



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Nov 26 20:10:06 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 26 Nov 2017 11:10:06 -0800
Subject: [R] dplyr - add/expand rows
In-Reply-To: <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
Message-ID: <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>

To David W.'s point about lack of a suitable reprex ("reproducible
example"), Bill's solution seems to be for only one station.

Here is a reprex and modification that I think does what was requested for
multiple stations, again using base R and data frames, not dplyr and
tibbles.

First the reprex with **two** stations:

> d <- data.frame( station = rep(c("one","two"),c(5,4)),
               from = c(60,61,71,72,76,60,65,82,83),
                to = c(60,70,71,76,83,64, 81, 82,83),
                record = c("A","B","C","B","D","B","B","D","E"))

> d
  station from to record
1     one   60 60      A
2     one   61 70      B
3     one   71 71      C
4     one   72 76      B
5     one   76 83      D
6     two   60 64      B
7     two   65 81      B
8     two   82 82      D
9     two   83 83      E

## Now the conversion code using base R, especially by():

> out <- by(d, d$station, function(x) with(x, {
+    i <- to - from +1
+    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
+ }))


> out <- data.frame(station =
rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = NULL)


> out
   station YEAR RECORD
1      one   60      A
2      one   61      B
3      one   62      B
4      one   63      B
5      one   64      B
6      one   65      B
7      one   66      B
8      one   67      B
9      one   68      B
10     one   69      B
11     one   70      B
12     one   71      C
13     one   72      B
14     one   73      B
15     one   74      B
16     one   75      B
17     one   76      B
18     one   76      D
19     one   77      D
20     one   78      D
21     one   79      D
22     one   80      D
23     one   81      D
24     one   82      D
25     one   83      D
26     two   60      B
27     two   61      B
28     two   62      B
29     two   63      B
30     two   64      B
31     two   65      B
32     two   66      B
33     two   67      B
34     two   68      B
35     two   69      B
36     two   70      B
37     two   71      B
38     two   72      B
39     two   73      B
40     two   74      B
41     two   75      B
42     two   76      B
43     two   77      B
44     two   78      B
45     two   79      B
46     two   80      B
47     two   81      B
48     two   82      D
49     two   83      E

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
r-help at r-project.org> wrote:

> dplyr may have something for this, but in base R I think the following does
> what you want.  I've shortened the name of your data set to 'd'.
>
> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
> david.hutchinson at canada.ca> wrote:
>
> > I have a returned tibble of station operational record similar to the
> > following:
> >
> > > data.collection
> > # A tibble: 5 x 4
> >   STATION_NUMBER YEAR_FROM YEAR_TO RECORD
> >            <chr>     <int>   <int>  <chr>
> > 1        07EA001      1960    1960    QMS
> > 2        07EA001      1961    1970    QMC
> > 3        07EA001      1971    1971    QMM
> > 4        07EA001      1972    1976    QMC
> > 5        07EA001      1977    1983    QRC
> >
> > I would like to reshape this to one operational record (row) per year per
> > station. Something like:
> >
> > 07EA001              1960      QMS
> > 07EA001              1961      QMC
> > 07EA001              1962      QMC
> > 07EA001              1963      QMC
> > ...
> > 07EA001              1971      QMM
> >
> > Can this be done in dplyr easily?
> >
> > Thanks in advance,
> >
> > David
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Sun Nov 26 21:05:39 2017
From: santosh2005 at gmail.com (Santosh)
Date: Sun, 26 Nov 2017 12:05:39 -0800
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XsPO3b6tCo0PYCqVN0_Yqq1_S2p1LVkvpovMnt9EkDJTQ@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <23064.41243.718222.536196@bud.eddelbuettel.com>
 <60f13d26-7cde-d44b-5b88-9b7ed3333fb3@gmail.com>
 <CAN_e6XsPO3b6tCo0PYCqVN0_Yqq1_S2p1LVkvpovMnt9EkDJTQ@mail.gmail.com>
Message-ID: <CAN_e6XsNoTp-nwHmxrgA9m1BwudmCrjXp=HxHBU2yii0GTAs7w@mail.gmail.com>

Hi Rxperts,

I tried with r-cran-rgl (based on the default installation of Ubuntu) with
reinstalled rgl package from R-forge.. I get the missing GL/gl.h header.
Didn't reinstall Mesa libraries per recommendations of Duncan.

* installing *source* package ?rgl? ...** package ?rgl? successfully
unpacked and MD5 sums checkedchecking for gcc... gcc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for gcc... (cached) gcc -std=gnu99
checking whether we are using the GNU C compiler... (cached) yes
checking whether gcc -std=gnu99 accepts -g... (cached) yes
checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
checking for libpng-config... yes
configure: using libpng-config
configure: using libpng dynamic linkage
checking for X... libraries , headers
checking GL/gl.h usability... no
checking GL/gl.h presence... no
checking for GL/gl.h... no
checking GL/glu.h usability... no
checking GL/glu.h presence... no
checking for GL/glu.h... noconfigure: error: missing required header
GL/gl.hERROR: configuration failed for package ?rgl?
* removing ?/data/R/lib/rgl?Warning in install.packages :
  installation of package ?rgl? had non-zero exit status


On Fri, Nov 24, 2017 at 3:45 PM, Santosh <santosh2005 at gmail.com> wrote:

> Hi Duncan,
> Thanks for the suggestions. How do I uninstall mesa related installations?
> Do I need to uninstall all of "mesa" or only the specific ones?
>
> Santosh
>
> On Fri, Nov 24, 2017 at 3:05 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 24/11/2017 5:45 PM, Dirk Eddelbuettel wrote:
>>
>>>
>>> On 24 November 2017 at 11:30, Santosh wrote:
>>> | Hi All, Duncan, Rolf, Ista, DIrk,
>>> |
>>> | Thanks for the suggestions and I tried all of them (as suggested by
>>> Duncan,
>>> | Rolf, Ista and Dirk)... I still get similar error as before while
>>> | installing 'rgl' package.. I also tried to manually configure "rgl"
>>> and got
>>> | an error message (please see below for the verbatim output).  Would
>>> highly
>>> | any further ideas/suggestions!
>>> |
>>> | *In my system, "GL" library is present under "/usr/include/GL"*
>>> |
>>> | Here are the libraries available (as suggested by Rolf)
>>> |
>>> | After installing some of them, I continue to get the same error
>>> message,
>>> | please below the output messages in config.log after I ran
>>> "./configure")
>>> |
>>> |
>>> | "ii  r-cran-rgl                            0.93.996-1
>>> |         amd64        GNU R package for three-dimensional visualisation
>>> | using OpenGL"
>>>
>>> That means you _have_ the rgl package installed, and can stop everything
>>> you
>>> are doing.
>>>
>>> You do _not_ need to install it from source via R. You have it from
>>> Ubuntu.
>>>
>>>
>> Actually the version on CRAN is pretty old, so I'd recommend people do
>> install it from source, getting the source from R-forge.  Since that is a
>> development site the quality varies over time, but right at this minute I
>> would say it is better than the CRAN version.
>>
>> Re Santosh's error messages:  it looks as though the Mesa installation is
>> messed up.  I'd recommend uninstalling it, making sure there's no remnant
>> of Mesa anywhere, then reinstalling it.
>>
>> Duncan Murdoch
>>
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Nov 26 21:12:34 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 26 Nov 2017 15:12:34 -0500
Subject: [R] installing "rgl" package
In-Reply-To: <CAN_e6XsNoTp-nwHmxrgA9m1BwudmCrjXp=HxHBU2yii0GTAs7w@mail.gmail.com>
References: <CAN_e6XsQw6Zfnj7emVLBHasFD-3eyCa8Y0o-jUSQTjEwxrsXew@mail.gmail.com>
 <23064.6880.475963.233683@bud.eddelbuettel.com>
 <CAN_e6XsC3b22UsrQ6Fe+5aGNTEL7fzovJi_FNgCpoyekmXPDyw@mail.gmail.com>
 <23064.41243.718222.536196@bud.eddelbuettel.com>
 <60f13d26-7cde-d44b-5b88-9b7ed3333fb3@gmail.com>
 <CAN_e6XsPO3b6tCo0PYCqVN0_Yqq1_S2p1LVkvpovMnt9EkDJTQ@mail.gmail.com>
 <CAN_e6XsNoTp-nwHmxrgA9m1BwudmCrjXp=HxHBU2yii0GTAs7w@mail.gmail.com>
Message-ID: <d229072f-e2bc-b902-c615-1342fe36c66a@gmail.com>

On 26/11/2017 3:05 PM, Santosh wrote:
> Hi Rxperts,
> 
> I tried with r-cran-rgl (based on the default installation of Ubuntu) 
> with reinstalled rgl package from R-forge.. I get the missing GL/gl.h 
> header. Didn't reinstall Mesa libraries per recommendations of Duncan.

None of your messages have indicated that the header is missing.  You're 
missing the library.  According to one of your earlier messages, it 
sounded as though the missing file is 
/usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0.

Duncan Murdoch
> 
> * installing *source* package ?rgl? ... ** package ?rgl? successfully 
> unpacked and MD5 sums checked checking for gcc... gcc -std=gnu99 
> checking whether the C compiler works... yes checking for C compiler 
> default output file name... a.out checking for suffix of executables... 
> checking whether we are cross compiling... no checking for suffix of 
> object files... o checking whether we are using the GNU C compiler... 
> yes checking whether gcc -std=gnu99 accepts -g... yes checking for gcc 
> -std=gnu99 option to accept ISO C89... none needed checking how to run 
> the C preprocessor... gcc -std=gnu99 -E checking for gcc... (cached) gcc 
> -std=gnu99 checking whether we are using the GNU C compiler... (cached) 
> yes checking whether gcc -std=gnu99 accepts -g... (cached) yes checking 
> for gcc -std=gnu99 option to accept ISO C89... (cached) none needed 
> checking for libpng-config... yes configure: using libpng-config 
> configure: using libpng dynamic linkage checking for X... libraries , 
> headers checking GL/gl.h usability... no checking GL/gl.h presence... no 
> checking for GL/gl.h... no checking GL/glu.h usability... no checking 
> GL/glu.h presence... no checking for GL/glu.h... no configure: error: 
> missing required header GL/gl.h ERROR: configuration failed for package 
> ?rgl? * removing ?/data/R/lib/rgl? Warning in install.packages : 
> installation of package ?rgl? had non-zero exit status
> 
> 
> On Fri, Nov 24, 2017 at 3:45 PM, Santosh <santosh2005 at gmail.com 
> <mailto:santosh2005 at gmail.com>> wrote:
> 
>     Hi Duncan,
>     Thanks for the suggestions. How do I uninstall mesa related
>     installations? Do I need to uninstall all of "mesa" or only the
>     specific ones?
> 
>     Santosh
> 
>     On Fri, Nov 24, 2017 at 3:05 PM, Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>         On 24/11/2017 5:45 PM, Dirk Eddelbuettel wrote:
> 
> 
>             On 24 November 2017 at 11:30, Santosh wrote:
>             | Hi All, Duncan, Rolf, Ista, DIrk,
>             |
>             | Thanks for the suggestions and I tried all of them (as
>             suggested by Duncan,
>             | Rolf, Ista and Dirk)... I still get similar error as
>             before while
>             | installing 'rgl' package.. I also tried to manually
>             configure "rgl" and got
>             | an error message (please see below for the verbatim
>             output).? Would highly
>             | any further ideas/suggestions!
>             |
>             | *In my system, "GL" library is present under
>             "/usr/include/GL"*
>             |
>             | Here are the libraries available (as suggested by Rolf)
>             |
>             | After installing some of them, I continue to get the same
>             error message,
>             | please below the output messages in config.log after I ran
>             "./configure")
>             |
>             |
>             | "ii? r-cran-rgl? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.93.996-1
>             |? ? ? ? ?amd64? ? ? ? GNU R package for three-dimensional
>             visualisation
>             | using OpenGL"
> 
>             That means you _have_ the rgl package installed, and can
>             stop everything you
>             are doing.
> 
>             You do _not_ need to install it from source via R. You have
>             it from Ubuntu.
> 
> 
>         Actually the version on CRAN is pretty old, so I'd recommend
>         people do install it from source, getting the source from
>         R-forge.? Since that is a development site the quality varies
>         over time, but right at this minute I would say it is better
>         than the CRAN version.
> 
>         Re Santosh's error messages:? it looks as though the Mesa
>         installation is messed up.? I'd recommend uninstalling it,
>         making sure there's no remnant of Mesa anywhere, then
>         reinstalling it.
> 
>         Duncan Murdoch
> 
> 
>


From jholtman at gmail.com  Mon Nov 27 02:42:59 2017
From: jholtman at gmail.com (jim holtman)
Date: Sun, 26 Nov 2017 20:42:59 -0500
Subject: [R] dplyr - add/expand rows
In-Reply-To: <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
Message-ID: <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>

try this:

##########################################

library(dplyr)

input <- tribble(
  ~station, ~from, ~to, ~record,
 "07EA001" ,    1960  ,  1960  , "QMS",
 "07EA001"  ,   1961 ,   1970  , "QMC",
 "07EA001" ,    1971  ,  1971  , "QMM",
 "07EA001" ,    1972  ,  1976  , "QMC",
 "07EA001" ,    1977  ,  1983  , "QRC"
)

result <- input %>%
  rowwise() %>%
  do(tibble(station = .$station,
            year = seq(.$from, .$to),
            record = .$record)
  )

###########################



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> To David W.'s point about lack of a suitable reprex ("reproducible
> example"), Bill's solution seems to be for only one station.
>
> Here is a reprex and modification that I think does what was requested for
> multiple stations, again using base R and data frames, not dplyr and
> tibbles.
>
> First the reprex with **two** stations:
>
> > d <- data.frame( station = rep(c("one","two"),c(5,4)),
>                from = c(60,61,71,72,76,60,65,82,83),
>                 to = c(60,70,71,76,83,64, 81, 82,83),
>                 record = c("A","B","C","B","D","B","B","D","E"))
>
> > d
>   station from to record
> 1     one   60 60      A
> 2     one   61 70      B
> 3     one   71 71      C
> 4     one   72 76      B
> 5     one   76 83      D
> 6     two   60 64      B
> 7     two   65 81      B
> 8     two   82 82      D
> 9     two   83 83      E
>
> ## Now the conversion code using base R, especially by():
>
> > out <- by(d, d$station, function(x) with(x, {
> +    i <- to - from +1
> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
> + }))
>
>
> > out <- data.frame(station =
> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = NULL)
>
>
> > out
>    station YEAR RECORD
> 1      one   60      A
> 2      one   61      B
> 3      one   62      B
> 4      one   63      B
> 5      one   64      B
> 6      one   65      B
> 7      one   66      B
> 8      one   67      B
> 9      one   68      B
> 10     one   69      B
> 11     one   70      B
> 12     one   71      C
> 13     one   72      B
> 14     one   73      B
> 15     one   74      B
> 16     one   75      B
> 17     one   76      B
> 18     one   76      D
> 19     one   77      D
> 20     one   78      D
> 21     one   79      D
> 22     one   80      D
> 23     one   81      D
> 24     one   82      D
> 25     one   83      D
> 26     two   60      B
> 27     two   61      B
> 28     two   62      B
> 29     two   63      B
> 30     two   64      B
> 31     two   65      B
> 32     two   66      B
> 33     two   67      B
> 34     two   68      B
> 35     two   69      B
> 36     two   70      B
> 37     two   71      B
> 38     two   72      B
> 39     two   73      B
> 40     two   74      B
> 41     two   75      B
> 42     two   76      B
> 43     two   77      B
> 44     two   78      B
> 45     two   79      B
> 46     two   80      B
> 47     two   81      B
> 48     two   82      D
> 49     two   83      E
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
> r-help at r-project.org> wrote:
>
> > dplyr may have something for this, but in base R I think the following
> does
> > what you want.  I've shortened the name of your data set to 'd'.
> >
> > i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
> > j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
> > transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
> > david.hutchinson at canada.ca> wrote:
> >
> > > I have a returned tibble of station operational record similar to the
> > > following:
> > >
> > > > data.collection
> > > # A tibble: 5 x 4
> > >   STATION_NUMBER YEAR_FROM YEAR_TO RECORD
> > >            <chr>     <int>   <int>  <chr>
> > > 1        07EA001      1960    1960    QMS
> > > 2        07EA001      1961    1970    QMC
> > > 3        07EA001      1971    1971    QMM
> > > 4        07EA001      1972    1976    QMC
> > > 5        07EA001      1977    1983    QRC
> > >
> > > I would like to reshape this to one operational record (row) per year
> per
> > > station. Something like:
> > >
> > > 07EA001              1960      QMS
> > > 07EA001              1961      QMC
> > > 07EA001              1962      QMC
> > > 07EA001              1963      QMC
> > > ...
> > > 07EA001              1971      QMM
> > >
> > > Can this be done in dplyr easily?
> > >
> > > Thanks in advance,
> > >
> > > David
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ispanyolcom at gmail.com  Mon Nov 27 09:56:15 2017
From: ispanyolcom at gmail.com (Engin YILMAZ)
Date: Mon, 27 Nov 2017 11:56:15 +0300
Subject: [R] Scatterplot of many variables against a single variable
Message-ID: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>

Dear

I try to realize one scatter matrix which draws *one single variable to all
variables* with *regression line* . You can see my eviews version  in the
annex .

How can I draw this graph with R studio?


Sincerely
Engin YILMAZ

From drjimlemon at gmail.com  Mon Nov 27 10:42:29 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 27 Nov 2017 20:42:29 +1100
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
Message-ID: <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>

Hi Engin,
Sadly, your illustration was ambushed on the way to the list. Perhaps
you want something like this:

# proportion of useful answers to your request
pua<-sort(runif(20))
#legibility of your request
lor<-sort(runif(20))+runif(20,-0.5,0.5)
# is a data set provided?
dsp<-sort(runif(20))+runif(20,-0.5,0.5)
# generate a linear model for the above
pua.lm<-lm(pua~lor+dsp)
# get the coefficients
pua.lm

Call:
lm(formula = pua ~ lor + dsp)

Coefficients:
(Intercept)          lor          dsp
    0.1692       0.6132       0.3311

plot(pua~lor,col="red",main="Proportion of useful answers by request quality")
points(pua~dsp,col="blue",pch=2)
abline(0.1692,0.6132,col="red")
abline(0.1692,0.3311,col="blue")

So, the more readable your request and the quality of the data that
you provide, the more useful answers you are likely to receive.

Jim


On Mon, Nov 27, 2017 at 7:56 PM, Engin YILMAZ <ispanyolcom at gmail.com> wrote:
> Dear
>
> I try to realize one scatter matrix which draws *one single variable to all
> variables* with *regression line* . You can see my eviews version  in the
> annex .
>
> How can I draw this graph with R studio?
>
>
> Sincerely
> Engin YILMAZ
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Nov 27 10:58:36 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Nov 2017 09:58:36 +0000
Subject: [R] number to volume weighted distribution
In-Reply-To: <CAJuCY5yRHVf57f1QCY+nUT_Em+D1EZyRfSzu-45wSojR27pSPg@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB5ED@SRVEXCHCM301.precheza.cz>
 <e415ef62-4b92-135c-ae7b-e65b0dcf808a@gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB640@SRVEXCHCM301.precheza.cz>
 <CAJuCY5yRHVf57f1QCY+nUT_Em+D1EZyRfSzu-45wSojR27pSPg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFABB91D@SRVEXCHCM301.precheza.cz>

Hi Thierry

Thanks for clarifiyng. I spoke about using ecdf because it gives me possibility to calculate proportion of objects below some threshold (quantiles) quite easily.

quantInv <- function(distr, value) ecdf(distr)(value)

> quantInv(x,80)*100
[1] 57.14286

I believe that such value could be calculated from this cumsum construction too. However with real data (hundereds of "x" values), Ecdf and wtd.quantile works quite good so I can live without it (I do not want to reinvent wheel).

Thanks again.
Cheers
Petr


> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: Friday, November 24, 2017 10:02 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
> Subject: Re: [R] number to volume weighted distribution
>
> Hi Petr,
>
> I think that Duncan suggests something like this:
>
> x<- c(rep(10,20), rep(300,5), rep(100, 10)) tx <- table(x)
>
> prop.x <- tx / sum(tx)
> vx <- as.integer(names(tx))
> prop.wx <- tx * vx / sum(tx * vx)
>
> plot(ecdf(x))
> plot(vx, cumsum(prop.x), ylim = 0:1)
> plot(vx, cumsum(prop.wx), ylim = 0:1)
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team
> Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be Kliniekstraat 25, B-1070 Brussel www.inbo.be
>
>
>
>
> 2017-11-24 14:30 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
> > Hi Duncan
> >
> > I tried Ecdf and/or wtd.quantile from Hmisc and it is working (probably).
> > Ecdf(x, q=.5)
> > Ecdf(x, weights=xw,col=2, add=T, q=.5)
> > wtd.quantile(x)
> >   0%  25%  50%  75% 100%
> >   10   10   10  100  300
> > wtd.quantile(x, weights=xw, type="i/n")
> >       0%      25%      50%      75%     100%
> >  10.0000 138.8667 192.5778 246.2889 300.0000
> >
> > But could you please be more specific in this?
> >
> >> But you seem to be asking about a
> >> definition rather than a function:  it is obtained simply by
> >> normalizing the weights to sum to 1, then evaluating cumulative sums of
> them.
> >
> > Actually, when I correctly calculate weights
> >
> > xw <- (x^3)/sum(x^3)
> > sum(xw) equals to 1
> >
> > but how can I plot ecdf with volume weighted data. Obviously
> >
> > ecdf(x*xw) or ecdf(x^3*xw) is not correct.
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> >> Sent: Friday, November 24, 2017 12:36 PM
> >> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
> >> Subject: Re: [R] number to volume weighted distribution
> >>
> >> On 24/11/2017 6:27 AM, PIKAL Petr wrote:
> >> > Dear all
> >> >
> >> > Strictly speaking it is not R question but as you are the most
> >> > capable persons I
> >> know I give it a try.
> >> >
> >> > I am strugling with recalculation of number weighted to volume
> >> > weighted
> >> distribution.
> >> >
> >> > Suppose I have objects (cubes) with size
> >> >
> >> > x<- c(rep(10,20), rep(100, 10), rep(300,5)) I can get
> >> >
> >> > plot(ecdf(x))
> >> >
> >> > or the number weighted average
> >> >
> >> > mean(x)
> >> > [1] 77.14286
> >> >
> >> > or volume weighted average
> >> > weighted.mean(x, (x/sum(x^3)))
> >> > [1] 204.4444
> >> >
> >> > However I am struggling with volume weighted ecdf.
> >> >
> >> > Can you please give me some hints?
> >>
> >> I believe base R doesn't have a function for this, but Google says it
> >> exists in a couple of packages:  spatstat, Hmisc.  But you seem to be
> >> asking about a definition rather than a function:  it is obtained
> >> simply by normalizing the weights to sum to 1, then evaluating cumulative
> sums of them.
> >>
> >> Duncan Murdoch
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ericjberger at gmail.com  Mon Nov 27 11:27:38 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 27 Nov 2017 12:27:38 +0200
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
Message-ID: <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>

LOL. Great reply Jim.
(N.B. Jim's conclusion is "debatable" by a judicious choice of seed. e.g.
set.seed(79) suggests that making the request more readable will actually
lower the number of useful answers. :-))


On Mon, Nov 27, 2017 at 11:42 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Engin,
> Sadly, your illustration was ambushed on the way to the list. Perhaps
> you want something like this:
>
> # proportion of useful answers to your request
> pua<-sort(runif(20))
> #legibility of your request
> lor<-sort(runif(20))+runif(20,-0.5,0.5)
> # is a data set provided?
> dsp<-sort(runif(20))+runif(20,-0.5,0.5)
> # generate a linear model for the above
> pua.lm<-lm(pua~lor+dsp)
> # get the coefficients
> pua.lm
>
> Call:
> lm(formula = pua ~ lor + dsp)
>
> Coefficients:
> (Intercept)          lor          dsp
>     0.1692       0.6132       0.3311
>
> plot(pua~lor,col="red",main="Proportion of useful answers by request
> quality")
> points(pua~dsp,col="blue",pch=2)
> abline(0.1692,0.6132,col="red")
> abline(0.1692,0.3311,col="blue")
>
> So, the more readable your request and the quality of the data that
> you provide, the more useful answers you are likely to receive.
>
> Jim
>
>
> On Mon, Nov 27, 2017 at 7:56 PM, Engin YILMAZ <ispanyolcom at gmail.com>
> wrote:
> > Dear
> >
> > I try to realize one scatter matrix which draws *one single variable to
> all
> > variables* with *regression line* . You can see my eviews version  in the
> > annex .
> >
> > How can I draw this graph with R studio?
> >
> >
> > Sincerely
> > Engin YILMAZ
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ispanyolcom at gmail.com  Mon Nov 27 11:59:10 2017
From: ispanyolcom at gmail.com (Engin YILMAZ)
Date: Mon, 27 Nov 2017 13:59:10 +0300
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
 <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>
Message-ID: <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>

Dear Berger and Jim

Can you see my eviews example in the annex? (scattersample.jpg)

Sincerely
Engin

2017-11-27 13:27 GMT+03:00 Eric Berger <ericjberger at gmail.com>:

> LOL. Great reply Jim.
> (N.B. Jim's conclusion is "debatable" by a judicious choice of seed. e.g.
> set.seed(79) suggests that making the request more readable will actually
> lower the number of useful answers. :-))
>
>
> On Mon, Nov 27, 2017 at 11:42 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Engin,
>> Sadly, your illustration was ambushed on the way to the list. Perhaps
>> you want something like this:
>>
>> # proportion of useful answers to your request
>> pua<-sort(runif(20))
>> #legibility of your request
>> lor<-sort(runif(20))+runif(20,-0.5,0.5)
>> # is a data set provided?
>> dsp<-sort(runif(20))+runif(20,-0.5,0.5)
>> # generate a linear model for the above
>> pua.lm<-lm(pua~lor+dsp)
>> # get the coefficients
>> pua.lm
>>
>> Call:
>> lm(formula = pua ~ lor + dsp)
>>
>> Coefficients:
>> (Intercept)          lor          dsp
>>     0.1692       0.6132       0.3311
>>
>> plot(pua~lor,col="red",main="Proportion of useful answers by request
>> quality")
>> points(pua~dsp,col="blue",pch=2)
>> abline(0.1692,0.6132,col="red")
>> abline(0.1692,0.3311,col="blue")
>>
>> So, the more readable your request and the quality of the data that
>> you provide, the more useful answers you are likely to receive.
>>
>> Jim
>>
>>
>> On Mon, Nov 27, 2017 at 7:56 PM, Engin YILMAZ <ispanyolcom at gmail.com>
>> wrote:
>> > Dear
>> >
>> > I try to realize one scatter matrix which draws *one single variable to
>> all
>> > variables* with *regression line* . You can see my eviews version  in
>> the
>> > annex .
>> >
>> > How can I draw this graph with R studio?
>> >
>> >
>> > Sincerely
>> > Engin YILMAZ
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
*Sayg?lar?mla*
Engin YILMAZ

From sezenismail at gmail.com  Mon Nov 27 14:00:02 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Mon, 27 Nov 2017 16:00:02 +0300
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
 <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>
 <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>
Message-ID: <03018120-FD0E-466B-B28E-9985026EDD07@gmail.com>


> On 27 Nov 2017, at 13:59, Engin YILMAZ <ispanyolcom at gmail.com> wrote:
> 
> Dear Berger and Jim
> 
> Can you see my eviews example in the annex? (scattersample.jpg)
> 
> Sincerely
> Engin

Please, use an image hosting service (i.e. https://imgbb.com/) to share images in the list and share the link in the email.


From ulrik.stervbo at gmail.com  Mon Nov 27 14:15:10 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 27 Nov 2017 13:15:10 +0000
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <03018120-FD0E-466B-B28E-9985026EDD07@gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
 <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>
 <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>
 <03018120-FD0E-466B-B28E-9985026EDD07@gmail.com>
Message-ID: <CAKVAULO5ZVJHEW7qq8dQ4Cy2SLoa9Vx_DUEjKYmqDfyfMXPiag@mail.gmail.com>

ggplot and facets might be useful.

Ulrik

Ismail SEZEN <sezenismail at gmail.com> schrieb am Mo., 27. Nov. 2017, 14:06:

>
> > On 27 Nov 2017, at 13:59, Engin YILMAZ <ispanyolcom at gmail.com> wrote:
> >
> > Dear Berger and Jim
> >
> > Can you see my eviews example in the annex? (scattersample.jpg)
> >
> > Sincerely
> > Engin
>
> Please, use an image hosting service (i.e. https://imgbb.com/) to share
> images in the list and share the link in the email.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Nov 27 15:52:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Nov 2017 06:52:59 -0800
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
 <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>
 <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>
Message-ID: <694D1389-3FA3-410C-B78D-C446906C9C0D@dcn.davis.ca.us>

You do not appear to have read the Posting Guide mentioned at the bottom if this and every posting on the mailing list. 

Only a very few attachment types are allowed through the mailing list... and due to the way many email programs fail to identify them properly, even those few types may not make it through.

Also, this is a plain text email list... any time you send HTML-formatted email it gets converted to plain text with varying amounts of scrambling... you really need to tell your email program to send plain text format or we may see something very different than you saw when you sent it. 

Luckily, R is a text based programing environment, so if you include a complete (with sample data), minimal (so we don't get lost looking at code you already have working), reproducible (so we can run it from scratch in our R environment) example of your problem in the main body of your plain text email, we should be able to help you efficiently. If you don't do that, we usually won't understand what your problem is and could either bounce useless emails back and forth or may just not reply at all. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On November 27, 2017 2:59:10 AM PST, Engin YILMAZ <ispanyolcom at gmail.com> wrote:
>Dear Berger and Jim
>
>Can you see my eviews example in the annex? (scattersample.jpg)
>
>Sincerely
>Engin
>
>2017-11-27 13:27 GMT+03:00 Eric Berger <ericjberger at gmail.com>:
>
>> LOL. Great reply Jim.
>> (N.B. Jim's conclusion is "debatable" by a judicious choice of seed.
>e.g.
>> set.seed(79) suggests that making the request more readable will
>actually
>> lower the number of useful answers. :-))
>>
>>
>> On Mon, Nov 27, 2017 at 11:42 AM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>>
>>> Hi Engin,
>>> Sadly, your illustration was ambushed on the way to the list.
>Perhaps
>>> you want something like this:
>>>
>>> # proportion of useful answers to your request
>>> pua<-sort(runif(20))
>>> #legibility of your request
>>> lor<-sort(runif(20))+runif(20,-0.5,0.5)
>>> # is a data set provided?
>>> dsp<-sort(runif(20))+runif(20,-0.5,0.5)
>>> # generate a linear model for the above
>>> pua.lm<-lm(pua~lor+dsp)
>>> # get the coefficients
>>> pua.lm
>>>
>>> Call:
>>> lm(formula = pua ~ lor + dsp)
>>>
>>> Coefficients:
>>> (Intercept)          lor          dsp
>>>     0.1692       0.6132       0.3311
>>>
>>> plot(pua~lor,col="red",main="Proportion of useful answers by request
>>> quality")
>>> points(pua~dsp,col="blue",pch=2)
>>> abline(0.1692,0.6132,col="red")
>>> abline(0.1692,0.3311,col="blue")
>>>
>>> So, the more readable your request and the quality of the data that
>>> you provide, the more useful answers you are likely to receive.
>>>
>>> Jim
>>>
>>>
>>> On Mon, Nov 27, 2017 at 7:56 PM, Engin YILMAZ
><ispanyolcom at gmail.com>
>>> wrote:
>>> > Dear
>>> >
>>> > I try to realize one scatter matrix which draws *one single
>variable to
>>> all
>>> > variables* with *regression line* . You can see my eviews version 
>in
>>> the
>>> > annex .
>>> >
>>> > How can I draw this graph with R studio?
>>> >
>>> >
>>> > Sincerely
>>> > Engin YILMAZ
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
>-- 
>*Sayg?lar?mla*
>Engin YILMAZ
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ispanyolcom at gmail.com  Mon Nov 27 19:21:37 2017
From: ispanyolcom at gmail.com (Engin YILMAZ)
Date: Mon, 27 Nov 2017 21:21:37 +0300
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <694D1389-3FA3-410C-B78D-C446906C9C0D@dcn.davis.ca.us>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <CA+8X3fXPa0b45T6vi75t=Atn7uVO-_OdwiX0UehdkCBdrS5asg@mail.gmail.com>
 <CAGgJW75ThTBFTOZ7bTd8m7CaxN6rQVR0pq+qWAMHaDn_KPGzhQ@mail.gmail.com>
 <CAMUSX8oyxEJH=vPkxZdbF_qjr54UXnzq7=abzbjD_xiAXMxmFw@mail.gmail.com>
 <694D1389-3FA3-410C-B78D-C446906C9C0D@dcn.davis.ca.us>
Message-ID: <CAMUSX8pWVpeYhWGmCCoCxGqZ1gqRfH3sTPFW6YR_=E6cHdXcaA@mail.gmail.com>

Dear Users

I embed my sample

https://ibb.co/dhc23R

or

<a href="https://ibb.co/dhc23R"><img src="
https://preview.ibb.co/eEDaOR/scattersample.jpg" alt="scattersample"
border="0"></a>

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

2017-11-27 17:52 GMT+03:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> You do not appear to have read the Posting Guide mentioned at the bottom
> if this and every posting on the mailing list.
>
> Only a very few attachment types are allowed through the mailing list...
> and due to the way many email programs fail to identify them properly, even
> those few types may not make it through.
>
> Also, this is a plain text email list... any time you send HTML-formatted
> email it gets converted to plain text with varying amounts of scrambling...
> you really need to tell your email program to send plain text format or we
> may see something very different than you saw when you sent it.
>
> Luckily, R is a text based programing environment, so if you include a
> complete (with sample data), minimal (so we don't get lost looking at code
> you already have working), reproducible (so we can run it from scratch in
> our R environment) example of your problem in the main body of your plain
> text email, we should be able to help you efficiently. If you don't do
> that, we usually won't understand what your problem is and could either
> bounce useless emails back and forth or may just not reply at all.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-
> a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the
> vignette)
> --
> Sent from my phone. Please excuse my brevity.
>
> On November 27, 2017 2:59:10 AM PST, Engin YILMAZ <ispanyolcom at gmail.com>
> wrote:
> >Dear Berger and Jim
> >
> >Can you see my eviews example in the annex? (scattersample.jpg)
> >
> >Sincerely
> >Engin
> >
> >2017-11-27 13:27 GMT+03:00 Eric Berger <ericjberger at gmail.com>:
> >
> >> LOL. Great reply Jim.
> >> (N.B. Jim's conclusion is "debatable" by a judicious choice of seed.
> >e.g.
> >> set.seed(79) suggests that making the request more readable will
> >actually
> >> lower the number of useful answers. :-))
> >>
> >>
> >> On Mon, Nov 27, 2017 at 11:42 AM, Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >>
> >>> Hi Engin,
> >>> Sadly, your illustration was ambushed on the way to the list.
> >Perhaps
> >>> you want something like this:
> >>>
> >>> # proportion of useful answers to your request
> >>> pua<-sort(runif(20))
> >>> #legibility of your request
> >>> lor<-sort(runif(20))+runif(20,-0.5,0.5)
> >>> # is a data set provided?
> >>> dsp<-sort(runif(20))+runif(20,-0.5,0.5)
> >>> # generate a linear model for the above
> >>> pua.lm<-lm(pua~lor+dsp)
> >>> # get the coefficients
> >>> pua.lm
> >>>
> >>> Call:
> >>> lm(formula = pua ~ lor + dsp)
> >>>
> >>> Coefficients:
> >>> (Intercept)          lor          dsp
> >>>     0.1692       0.6132       0.3311
> >>>
> >>> plot(pua~lor,col="red",main="Proportion of useful answers by request
> >>> quality")
> >>> points(pua~dsp,col="blue",pch=2)
> >>> abline(0.1692,0.6132,col="red")
> >>> abline(0.1692,0.3311,col="blue")
> >>>
> >>> So, the more readable your request and the quality of the data that
> >>> you provide, the more useful answers you are likely to receive.
> >>>
> >>> Jim
> >>>
> >>>
> >>> On Mon, Nov 27, 2017 at 7:56 PM, Engin YILMAZ
> ><ispanyolcom at gmail.com>
> >>> wrote:
> >>> > Dear
> >>> >
> >>> > I try to realize one scatter matrix which draws *one single
> >variable to
> >>> all
> >>> > variables* with *regression line* . You can see my eviews version
> >in
> >>> the
> >>> > annex .
> >>> >
> >>> > How can I draw this graph with R studio?
> >>> >
> >>> >
> >>> > Sincerely
> >>> > Engin YILMAZ
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >
> >--
> >*Sayg?lar?mla*
> >Engin YILMAZ
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Sayg?lar?mla*
Engin YILMAZ

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Nov 27 20:08:27 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 27 Nov 2017 19:08:27 +0000
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
Message-ID: <18B4B3C9-D3E4-452A-9A88-2FF3F5046B6C@llnl.gov>

Here's the quickest way I know of to get a scatterplot of many variables against a single variable. I create example data to illustrate.

x <- 1:10
ys <- matrix( runif(30), ncol=3)

matplot(x,ys)
## or, a little better,
matplot(x,ys, type='b')

To add regression lines:

for (iy in seq(ncol(ys))) abline(lsfit(x, ys[,iy]))

Coloring the regression lines to match the matplot will take a little more work (but not a lot more).

Don't ask me about putting the regression line formulas on the plot like in Excel. I don't do things that way...

There is probably something in ggplot2 or some other package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 11/27/17, 12:56 AM, "R-help on behalf of Engin YILMAZ" <r-help-bounces at r-project.org on behalf of ispanyolcom at gmail.com> wrote:

    Dear
    
    I try to realize one scatter matrix which draws *one single variable to all
    variables* with *regression line* . You can see my eviews version  in the
    annex .
    
    How can I draw this graph with R studio?
    
    
    Sincerely
    Engin YILMAZ
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From koyamaakihiro at yahoo.com  Mon Nov 27 19:12:42 2017
From: koyamaakihiro at yahoo.com (Akihiro Koyama)
Date: Mon, 27 Nov 2017 18:12:42 +0000 (UTC)
Subject: [R] How to extract coefficients from sequential (type 1) ANOVAs
 using lmer and lme
References: <769665331.4165652.1511806362647.ref@mail.yahoo.com>
Message-ID: <769665331.4165652.1511806362647@mail.yahoo.com>

I wantto run sequential ANOVAs (i.e. type I sums of squares), and trying to getresults including ANOVA tables and associated coefficients for predictive variables(I am using the R 3.4.2 version). I think ANOVA tables look right, but believecoefficients are wrong. Specifically, it looks like that the coefficients arefrom ANOVA with ?marginal? (type III sums of squares). I have tried both lme (nlmepackage) and lmer (lme4 + lmerTEST packages). Examples of the results arebelow:


?

?
> #mixed-effect modelusing lme

>model.short.psme.bulk.d13c.3 <- lme(isotopebulk_add_log ~narea+sampleheight, random= ~1|tree, 

+??????????????????????????? data =ht_data_short_psme, na.action = na.exclude)

> 


?
>anova(model.short.psme.bulk.d13c.3, type ="sequential")

???????????? numDF denDF?? F-value p-value

(Intercept)????? 1????3 1840.5678? <.0001

narea??????????? 1???? 2??18.4876? 0.0501

sampleheight???? 1????2?? 11.6159? 0.0764


?
>anova(model.short.psme.bulk.d13c.3, type ="marginal")

???????????? numDF denDF? F-value p-value

(Intercept)????? 1????3 629.4711? 0.0001

narea???? ???????1????2?? 2.7831? 0.2372

sampleheight???? 1????2? 11.6159? 0.0764

> 

>summary(model.short.psme.bulk.d13c.3, type ="sequential")$tTable

?????????????????? Value? Std.Error DF??t-value????? p-value

(Intercept)?? 1.76871397 0.07049685? 3 25.089262 0.0001388446

narea??????? -0.09295561 0.05571991? 2 -1.668266 0.2372012082

sampleheight? 0.13232709 0.03882599? 2?3.408209 0.0763589527

?(Intercept)??1.76871397 0.07049685? 3 25.0892620.0001388446


?
>summary(model.short.psme.bulk.d13c.3, type ="marginal")$tTable

?????????????????? Value? Std.Error DF??t-value????? p-value

(Intercept)?? 1.76871397 0.07049685? 3 25.089262 0.0001388446

narea??????? -0.09295561 0.05571991? 2 -1.668266 0.2372012082

sampleheight? 0.13232709 0.03882599? 2?3.408209 0.0763589527


?

?
Ibelieve the results from summary() are for ?marginal? instead of ?sequential?ANOVA because the p-value (i.e., 0.237 for narea) in summary are identical tothose in tables from ?marginal?. I also used lmer in the lme4 pacakge to findthe same results (summary() results look like from ?marginal?).


?
Cananybody tell me how to get coefficients for ?sequential? ANOVAs? Thank you.


	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Mon Nov 27 21:18:03 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Mon, 27 Nov 2017 23:18:03 +0300
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
Message-ID: <90BB0E28-5D74-4E8C-81D3-91138A901538@gmail.com>


> On 27 Nov 2017, at 11:56, Engin YILMAZ <ispanyolcom at gmail.com> wrote:
> 
> Dear
> 
> I try to realize one scatter matrix which draws *one single variable to all
> variables* with *regression line* . You can see my eviews version  in the
> annex .
> 
> How can I draw this graph with R studio?

A tiny note; You do calculations in R not RSudio. RStudio is a tool (IDE) to use R in an easy way.

The code below shows how to accomplish this task easily by ggplot. It?s adapted from [1].

library(ggplot2)
library(reshape2)

# This is your initial data.frame and you want scatterplots of all variables against x1.
foo <- data.frame(x1 = runif(50, 0, 1), 
                  x2 = runif(50, 0, 1), 
                  x3 = runif(50, 0, 1), 
                  x4 = runif(50, 0, 1))

# melt data. This is very handy function from reshape2 library.
foo2 <- melt(foo, "x1?)

# plot points and add lm lines.
ggplot(foo2, aes(value, x1)) +  
  geom_point() + 
  geom_smooth(method=lm) +
  facet_grid(.~variable)


1- https://stackoverflow.com/questions/24648729/plot-one-numeric-variable-against-n-numeric-variables-in-n-plots

isezen

From mashranga at yahoo.com  Tue Nov 28 13:32:44 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 28 Nov 2017 12:32:44 +0000 (UTC)
Subject: [R] Extract all point in a quadrats by spatstat package
References: <1670911523.3535972.1511872364204.ref@mail.yahoo.com>
Message-ID: <1670911523.3535972.1511872364204@mail.yahoo.com>

Hi,

With the following code i can divides window into quadrats and counts the numbers of points in each quadrat.

library(spatstat)
X <- runifpoint(50)
quadratcount(X)
quadratcount(X, 4, 5)
quadratcount(X, xbreaks=c(0, 0.3, 1), ybreaks=c(0, 0.4, 0.8, 1))
qX <-? quadratcount(X, 4, 5)
plot(X)
plot(qX, add=TRUE)

But I want to mark each? quadrats? and select/ extract only those points by selecting quadrats id .?
Can anyone plese help me regarding this issue ?
Thanks in advance .



Regards.............
Tanvir Ahamed 
Stockholm, Sweden???? |??mashranga at yahoo.com 


From ispanyolcom at gmail.com  Tue Nov 28 14:40:30 2017
From: ispanyolcom at gmail.com (Engin YILMAZ)
Date: Tue, 28 Nov 2017 16:40:30 +0300
Subject: [R] Scatterplot of many variables against a single variable
In-Reply-To: <90BB0E28-5D74-4E8C-81D3-91138A901538@gmail.com>
References: <CAMUSX8p=i+nTbZZt-4Yz7FiqV-G+7ggfjiAwuuVe8ny=8OaLZw@mail.gmail.com>
 <90BB0E28-5D74-4E8C-81D3-91138A901538@gmail.com>
Message-ID: <CAMUSX8o5NkhzjUEu38ewXXGN1Z0hKtj4HepKrtCK1gBZ4NxXhw@mail.gmail.com>

Thanks all users

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

2017-11-27 23:18 GMT+03:00 Ismail SEZEN <sezenismail at gmail.com>:

>
> > On 27 Nov 2017, at 11:56, Engin YILMAZ <ispanyolcom at gmail.com> wrote:
> >
> > Dear
> >
> > I try to realize one scatter matrix which draws *one single variable to
> all
> > variables* with *regression line* . You can see my eviews version  in the
> > annex .
> >
> > How can I draw this graph with R studio?
>
> A tiny note; You do calculations in R not RSudio. RStudio is a tool (IDE)
> to use R in an easy way.
>
> The code below shows how to accomplish this task easily by ggplot. It?s
> adapted from [1].
>
> library(ggplot2)
> library(reshape2)
>
> # This is your initial data.frame and you want scatterplots of all
> variables against x1.
> foo <- data.frame(x1 = runif(50, 0, 1),
>                   x2 = runif(50, 0, 1),
>                   x3 = runif(50, 0, 1),
>                   x4 = runif(50, 0, 1))
>
> # melt data. This is very handy function from reshape2 library.
> foo2 <- melt(foo, "x1?)
>
> # plot points and add lm lines.
> ggplot(foo2, aes(value, x1)) +
>   geom_point() +
>   geom_smooth(method=lm) +
>   facet_grid(.~variable)
>
>
> 1- https://stackoverflow.com/questions/24648729/plot-one-
> numeric-variable-against-n-numeric-variables-in-n-plots
>
> isezen




-- 
*Sayg?lar?mla*
Engin YILMAZ

	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Tue Nov 28 16:34:03 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 28 Nov 2017 10:34:03 -0500
Subject: [R] dplyr - add/expand rows
In-Reply-To: <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
Message-ID: <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>

On 11/26/2017 08:42 PM, jim holtman wrote:
> try this:
> 
> ##########################################
> 
> library(dplyr)
> 
> input <- tribble(
>    ~station, ~from, ~to, ~record,
>   "07EA001" ,    1960  ,  1960  , "QMS",
>   "07EA001"  ,   1961 ,   1970  , "QMC",
>   "07EA001" ,    1971  ,  1971  , "QMM",
>   "07EA001" ,    1972  ,  1976  , "QMC",
>   "07EA001" ,    1977  ,  1983  , "QRC"
> )
> 
> result <- input %>%
>    rowwise() %>%
>    do(tibble(station = .$station,
>              year = seq(.$from, .$to),
>              record = .$record)
>    )
> 
> ###########################

In a bit more 'base R' mode I did

   input$year <- with(input, Map(seq, from, to))
   res0 <- with(input, Map(data.frame, station=station, year=year,
       record=record))
    as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3

resulting in

 > as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
    station  year record
     <fctr> <int> <fctr>
  1 07EA001  1960    QMS
  2 07EA001  1961    QMC
  3 07EA001  1962    QMC
  4 07EA001  1963    QMC
  5 07EA001  1964    QMC
  6 07EA001  1965    QMC
  7 07EA001  1966    QMC
  8 07EA001  1967    QMC
  9 07EA001  1968    QMC
10 07EA001  1969    QMC
# ... with 14 more rows

I though I should have been able to use `tibble` in the second step, but 
that leads to a (cryptic) error

 > res0 <- with(input, Map(tibble, station=station, year=year, 
record=record))Error in captureDots(strict = `__quosured`) :
   the argument has already been evaluated

The 'station' and 'record' columns are factors, so different from the 
original input, but this seems the appropriate data type for theses columns.

It's interesting to compare the 'specialized' knowledge needed for each 
approach -- rowwise(), do(), .$ for tidyverse, with(), do.call(), maybe 
rbind() and Map() for base R.

Martin

> 
> 
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> To David W.'s point about lack of a suitable reprex ("reproducible
>> example"), Bill's solution seems to be for only one station.
>>
>> Here is a reprex and modification that I think does what was requested for
>> multiple stations, again using base R and data frames, not dplyr and
>> tibbles.
>>
>> First the reprex with **two** stations:
>>
>>> d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>                 from = c(60,61,71,72,76,60,65,82,83),
>>                  to = c(60,70,71,76,83,64, 81, 82,83),
>>                  record = c("A","B","C","B","D","B","B","D","E"))
>>
>>> d
>>    station from to record
>> 1     one   60 60      A
>> 2     one   61 70      B
>> 3     one   71 71      C
>> 4     one   72 76      B
>> 5     one   76 83      D
>> 6     two   60 64      B
>> 7     two   65 81      B
>> 8     two   82 82      D
>> 9     two   83 83      E
>>
>> ## Now the conversion code using base R, especially by():
>>
>>> out <- by(d, d$station, function(x) with(x, {
>> +    i <- to - from +1
>> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
>> + }))
>>
>>
>>> out <- data.frame(station =
>> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = NULL)
>>
>>
>>> out
>>     station YEAR RECORD
>> 1      one   60      A
>> 2      one   61      B
>> 3      one   62      B
>> 4      one   63      B
>> 5      one   64      B
>> 6      one   65      B
>> 7      one   66      B
>> 8      one   67      B
>> 9      one   68      B
>> 10     one   69      B
>> 11     one   70      B
>> 12     one   71      C
>> 13     one   72      B
>> 14     one   73      B
>> 15     one   74      B
>> 16     one   75      B
>> 17     one   76      B
>> 18     one   76      D
>> 19     one   77      D
>> 20     one   78      D
>> 21     one   79      D
>> 22     one   80      D
>> 23     one   81      D
>> 24     one   82      D
>> 25     one   83      D
>> 26     two   60      B
>> 27     two   61      B
>> 28     two   62      B
>> 29     two   63      B
>> 30     two   64      B
>> 31     two   65      B
>> 32     two   66      B
>> 33     two   67      B
>> 34     two   68      B
>> 35     two   69      B
>> 36     two   70      B
>> 37     two   71      B
>> 38     two   72      B
>> 39     two   73      B
>> 40     two   74      B
>> 41     two   75      B
>> 42     two   76      B
>> 43     two   77      B
>> 44     two   78      B
>> 45     two   79      B
>> 46     two   80      B
>> 47     two   81      B
>> 48     two   82      D
>> 49     two   83      E
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>> r-help at r-project.org> wrote:
>>
>>> dplyr may have something for this, but in base R I think the following
>> does
>>> what you want.  I've shortened the name of your data set to 'd'.
>>>
>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>> david.hutchinson at canada.ca> wrote:
>>>
>>>> I have a returned tibble of station operational record similar to the
>>>> following:
>>>>
>>>>> data.collection
>>>> # A tibble: 5 x 4
>>>>    STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>>>             <chr>     <int>   <int>  <chr>
>>>> 1        07EA001      1960    1960    QMS
>>>> 2        07EA001      1961    1970    QMC
>>>> 3        07EA001      1971    1971    QMM
>>>> 4        07EA001      1972    1976    QMC
>>>> 5        07EA001      1977    1983    QRC
>>>>
>>>> I would like to reshape this to one operational record (row) per year
>> per
>>>> station. Something like:
>>>>
>>>> 07EA001              1960      QMS
>>>> 07EA001              1961      QMC
>>>> 07EA001              1962      QMC
>>>> 07EA001              1963      QMC
>>>> ...
>>>> 07EA001              1971      QMM
>>>>
>>>> Can this be done in dplyr easily?
>>>>
>>>> Thanks in advance,
>>>>
>>>> David
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From cesc.pla at gmail.com  Tue Nov 28 15:00:47 2017
From: cesc.pla at gmail.com (=?UTF-8?Q?Francesc_Pla_Junc=C3=A0?=)
Date: Tue, 28 Nov 2017 15:00:47 +0100
Subject: [R] Repeated measures Tukey
Message-ID: <CAMh6vMuTAfeqME5RA7h50GmHSsaLqDXgb6e=WwfF8DW4UaBosw@mail.gmail.com>

Thanks in advance for your help.

I am running a repeated measures ANOVA in r. The same group undergoes to
four different treatment conditions. So, all individuals are treated with
treatments A, B, C and D in four different occasions.
Once I get a significant ANOVA, I first run a paired samples t-test using
the code:

t.test(X1,X2,paired=TRUE) #being x1 the punctuation after treatment 1 and
x2 the punctuation after
treatment 2.

After this, I run a Tukey posthoc test for repeated measures as stated in
gribblelab:

require(nlme)
a1<-lme(x~factortmnt,random=~1|factorid/factortmnt,data=mydata)
print(anova(a1))

require(multcomp)
summary(glht(a1,linfct=mcp(factortmnt="Tukey")))

The fact is that once I get both results, there are some occasions in which
I get lower p values with Tukeys correction than in paired t-tests.

How is it possible? Isn't Tukey more restrictive than paired t-tests?

Cesc

	[[alternative HTML version deleted]]


From Snoep.Jose at kpmg.nl  Tue Nov 28 09:50:47 2017
From: Snoep.Jose at kpmg.nl (Snoep, Jose)
Date: Tue, 28 Nov 2017 08:50:47 +0000
Subject: [R] Thiel's Uncertainty Coefficient
Message-ID: <VI1P138MB00154AC47F901CC9D7E583F79D3A0@VI1P138MB0015.EURP138.PROD.OUTLOOK.COM>

Dear sir Schwartz,

In response to a granted online request  to receive R code in order to generate Theil's Uncertainty coefficient, I was hoping I could receive the same favor.

https://stat.ethz.ch/pipermail/r-help/2011-May/279210.html

Thank you in advance, I hope to hear from you.

Kind regards,

Jos? Snoep
Stagiair Universitair | MC ES - SOFY
+31 6 13060740
Snoep.Jose at kpmg.nl<mailto:Snoep.Jose at kpmg.nl>  | MyLinkedIn <https://www.linkedin.com/in/josesnoep/>  |  www.kpmg.nl<http://www.kpmg.com/nl>
KPMG | Laan van Langerhuize 1, 1186 DS Amstelveen

KPMG Advisory N.V., handelsregisternummer 33263682


**********************************************************************



------------------------------------------------------------------------ 
The information in this e-mail (and any attachments) is intended exclusively for the addressee(s). Any use by a party other than the addressee(s) is prohibited. The information may be confidential in nature and fall under a duty of non-disclosure. If you are not the addressee, please notify the sender and delete this e-mail. KPMG cannot guarantee that e-mail communications are secure and error-free and does not accept any liability for damages resulting from the use of e-mail. Our services and other work are carried out under an agreement of instruction (overeenkomst van opdracht) that is subject to the general terms and conditions of the contracting KPMG firm. These general terms and conditions are available on our website (www.kpmg.nl/algemenevoorwaarden) and will be forwarded upon request.
Agreements with and statements from KPMG are only legally binding upon KPMG if they are confirmed in writing and signed by an authorized person.
------------------------------------------------------------------------ 




	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov 28 17:57:16 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Nov 2017 08:57:16 -0800
Subject: [R] Repeated measures Tukey
In-Reply-To: <CAMh6vMuTAfeqME5RA7h50GmHSsaLqDXgb6e=WwfF8DW4UaBosw@mail.gmail.com>
References: <CAMh6vMuTAfeqME5RA7h50GmHSsaLqDXgb6e=WwfF8DW4UaBosw@mail.gmail.com>
Message-ID: <CAGxFJbSz5bwcGiMRd-KRXKc6uwEb80WeuVhr8kf22d6p6KsYLA@mail.gmail.com>

This list is about R programming help, not statistics, although they do
sometimes overlap. However, as this appears to be entirely a statistics
issue, it really belongs on a statistics list like stats.stackexchange.com
, not here.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Nov 28, 2017 at 6:00 AM, Francesc Pla Junc? <cesc.pla at gmail.com>
wrote:

> Thanks in advance for your help.
>
> I am running a repeated measures ANOVA in r. The same group undergoes to
> four different treatment conditions. So, all individuals are treated with
> treatments A, B, C and D in four different occasions.
> Once I get a significant ANOVA, I first run a paired samples t-test using
> the code:
>
> t.test(X1,X2,paired=TRUE) #being x1 the punctuation after treatment 1 and
> x2 the punctuation after
> treatment 2.
>
> After this, I run a Tukey posthoc test for repeated measures as stated in
> gribblelab:
>
> require(nlme)
> a1<-lme(x~factortmnt,random=~1|factorid/factortmnt,data=mydata)
> print(anova(a1))
>
> require(multcomp)
> summary(glht(a1,linfct=mcp(factortmnt="Tukey")))
>
> The fact is that once I get both results, there are some occasions in which
> I get lower p values with Tukeys correction than in paired t-tests.
>
> How is it possible? Isn't Tukey more restrictive than paired t-tests?
>
> Cesc
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Nov 28 18:15:29 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 28 Nov 2017 12:15:29 -0500
Subject: [R] Thiel's Uncertainty Coefficient
In-Reply-To: <VI1P138MB00154AC47F901CC9D7E583F79D3A0@VI1P138MB0015.EURP138.PROD.OUTLOOK.COM>
References: <VI1P138MB00154AC47F901CC9D7E583F79D3A0@VI1P138MB0015.EURP138.PROD.OUTLOOK.COM>
Message-ID: <89F25E7D-2BD7-4633-AA5A-282B420108F2@me.com>

Hi Jose,

Just be aware that you sent an e-mail, with a salutation to me specifically, to a large e-mail distribution list. It would have been better to simply send it directly to me via the e-mail in the post that you link to below.

The code in question has been available for a number of years on GitHub here:

  https://gist.github.com/marcschwartz/3665743

starting around line 218.

Regards,

Marc


> On Nov 28, 2017, at 3:50 AM, Snoep, Jose <Snoep.Jose at kpmg.nl> wrote:
> 
> Dear sir Schwartz,
> 
> In response to a granted online request  to receive R code in order to generate Theil's Uncertainty coefficient, I was hoping I could receive the same favor.
> 
> https://stat.ethz.ch/pipermail/r-help/2011-May/279210.html
> 
> Thank you in advance, I hope to hear from you.
> 
> Kind regards,
> 
> Jos? Snoep
> Stagiair Universitair | MC ES - SOFY
> +31 6 13060740
> Snoep.Jose at kpmg.nl<mailto:Snoep.Jose at kpmg.nl>  | MyLinkedIn <https://www.linkedin.com/in/josesnoep/>  |  www.kpmg.nl<http://www.kpmg.com/nl>
> KPMG | Laan van Langerhuize 1, 1186 DS Amstelveen
> 
> KPMG Advisory N.V., handelsregisternummer 33263682
> 


From lawrence.michael at gene.com  Tue Nov 28 18:49:58 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 28 Nov 2017 09:49:58 -0800
Subject: [R] dplyr - add/expand rows
In-Reply-To: <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
 <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>
Message-ID: <CAOQ5Nyf2HY_TJ3mZ7=4BZ2Og_0LPVFPTZwRc2JoA-cvdNmHHpw@mail.gmail.com>

Or with the Bioconductor IRanges package:

df <- with(input, DataFrame(station, year=IRanges(from, to), record))
expand(df, "year")

DataFrame with 24 rows and 3 columns
        station     year      record
    <character> <integer> <character>
1       07EA001      1960         QMS
2       07EA001      1961         QMC
3       07EA001      1962         QMC
4       07EA001      1963         QMC
5       07EA001      1964         QMC
...         ...       ...         ...
20      07EA001      1979         QRC
21      07EA001      1980         QRC
22      07EA001      1981         QRC
23      07EA001      1982         QRC
24      07EA001      1983         QRC

If you tell the computer more about your data, it can do more things for
you.

Michael

On Tue, Nov 28, 2017 at 7:34 AM, Martin Morgan <
martin.morgan at roswellpark.org> wrote:

> On 11/26/2017 08:42 PM, jim holtman wrote:
>
>> try this:
>>
>> ##########################################
>>
>> library(dplyr)
>>
>> input <- tribble(
>>    ~station, ~from, ~to, ~record,
>>   "07EA001" ,    1960  ,  1960  , "QMS",
>>   "07EA001"  ,   1961 ,   1970  , "QMC",
>>   "07EA001" ,    1971  ,  1971  , "QMM",
>>   "07EA001" ,    1972  ,  1976  , "QMC",
>>   "07EA001" ,    1977  ,  1983  , "QRC"
>> )
>>
>> result <- input %>%
>>    rowwise() %>%
>>    do(tibble(station = .$station,
>>              year = seq(.$from, .$to),
>>              record = .$record)
>>    )
>>
>> ###########################
>>
>
> In a bit more 'base R' mode I did
>
>   input$year <- with(input, Map(seq, from, to))
>   res0 <- with(input, Map(data.frame, station=station, year=year,
>       record=record))
>    as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>
> resulting in
>
> > as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>    station  year record
>     <fctr> <int> <fctr>
>  1 07EA001  1960    QMS
>  2 07EA001  1961    QMC
>  3 07EA001  1962    QMC
>  4 07EA001  1963    QMC
>  5 07EA001  1964    QMC
>  6 07EA001  1965    QMC
>  7 07EA001  1966    QMC
>  8 07EA001  1967    QMC
>  9 07EA001  1968    QMC
> 10 07EA001  1969    QMC
> # ... with 14 more rows
>
> I though I should have been able to use `tibble` in the second step, but
> that leads to a (cryptic) error
>
> > res0 <- with(input, Map(tibble, station=station, year=year,
> record=record))Error in captureDots(strict = `__quosured`) :
>   the argument has already been evaluated
>
> The 'station' and 'record' columns are factors, so different from the
> original input, but this seems the appropriate data type for theses columns.
>
> It's interesting to compare the 'specialized' knowledge needed for each
> approach -- rowwise(), do(), .$ for tidyverse, with(), do.call(), maybe
> rbind() and Map() for base R.
>
> Martin
>
>
>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>> To David W.'s point about lack of a suitable reprex ("reproducible
>>> example"), Bill's solution seems to be for only one station.
>>>
>>> Here is a reprex and modification that I think does what was requested
>>> for
>>> multiple stations, again using base R and data frames, not dplyr and
>>> tibbles.
>>>
>>> First the reprex with **two** stations:
>>>
>>> d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>>>
>>>                 from = c(60,61,71,72,76,60,65,82,83),
>>>                  to = c(60,70,71,76,83,64, 81, 82,83),
>>>                  record = c("A","B","C","B","D","B","B","D","E"))
>>>
>>> d
>>>>
>>>    station from to record
>>> 1     one   60 60      A
>>> 2     one   61 70      B
>>> 3     one   71 71      C
>>> 4     one   72 76      B
>>> 5     one   76 83      D
>>> 6     two   60 64      B
>>> 7     two   65 81      B
>>> 8     two   82 82      D
>>> 9     two   83 83      E
>>>
>>> ## Now the conversion code using base R, especially by():
>>>
>>> out <- by(d, d$station, function(x) with(x, {
>>>>
>>> +    i <- to - from +1
>>> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
>>> + }))
>>>
>>>
>>> out <- data.frame(station =
>>>>
>>> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = NULL)
>>>
>>>
>>> out
>>>>
>>>     station YEAR RECORD
>>> 1      one   60      A
>>> 2      one   61      B
>>> 3      one   62      B
>>> 4      one   63      B
>>> 5      one   64      B
>>> 6      one   65      B
>>> 7      one   66      B
>>> 8      one   67      B
>>> 9      one   68      B
>>> 10     one   69      B
>>> 11     one   70      B
>>> 12     one   71      C
>>> 13     one   72      B
>>> 14     one   73      B
>>> 15     one   74      B
>>> 16     one   75      B
>>> 17     one   76      B
>>> 18     one   76      D
>>> 19     one   77      D
>>> 20     one   78      D
>>> 21     one   79      D
>>> 22     one   80      D
>>> 23     one   81      D
>>> 24     one   82      D
>>> 25     one   83      D
>>> 26     two   60      B
>>> 27     two   61      B
>>> 28     two   62      B
>>> 29     two   63      B
>>> 30     two   64      B
>>> 31     two   65      B
>>> 32     two   66      B
>>> 33     two   67      B
>>> 34     two   68      B
>>> 35     two   69      B
>>> 36     two   70      B
>>> 37     two   71      B
>>> 38     two   72      B
>>> 39     two   73      B
>>> 40     two   74      B
>>> 41     two   75      B
>>> 42     two   76      B
>>> 43     two   77      B
>>> 44     two   78      B
>>> 45     two   79      B
>>> 46     two   80      B
>>> 47     two   81      B
>>> 48     two   82      D
>>> 49     two   83      E
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>>> r-help at r-project.org> wrote:
>>>
>>> dplyr may have something for this, but in base R I think the following
>>>>
>>> does
>>>
>>>> what you want.  I've shortened the name of your data set to 'd'.
>>>>
>>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>>> david.hutchinson at canada.ca> wrote:
>>>>
>>>> I have a returned tibble of station operational record similar to the
>>>>> following:
>>>>>
>>>>> data.collection
>>>>>>
>>>>> # A tibble: 5 x 4
>>>>>    STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>>>>             <chr>     <int>   <int>  <chr>
>>>>> 1        07EA001      1960    1960    QMS
>>>>> 2        07EA001      1961    1970    QMC
>>>>> 3        07EA001      1971    1971    QMM
>>>>> 4        07EA001      1972    1976    QMC
>>>>> 5        07EA001      1977    1983    QRC
>>>>>
>>>>> I would like to reshape this to one operational record (row) per year
>>>>>
>>>> per
>>>
>>>> station. Something like:
>>>>>
>>>>> 07EA001              1960      QMS
>>>>> 07EA001              1961      QMC
>>>>> 07EA001              1962      QMC
>>>>> 07EA001              1963      QMC
>>>>> ...
>>>>> 07EA001              1971      QMM
>>>>>
>>>>> Can this be done in dplyr easily?
>>>>>
>>>>> Thanks in advance,
>>>>>
>>>>> David
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> This email message may contain legally privileged and/or...{{dropped:2}}
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Nov 28 22:42:47 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 28 Nov 2017 13:42:47 -0800
Subject: [R] dplyr - add/expand rows
In-Reply-To: <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
Message-ID: <CAF8bMcZ++bRQ3gze1AOzQPkvHa0jhT+-GfbS1JkFz_J31XV+Lw@mail.gmail.com>

Bert wrote
  ... Bill's solution seems to be for only one station.

No, it works for any number of stations.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Nov 26, 2017 at 11:10 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> To David W.'s point about lack of a suitable reprex ("reproducible
> example"), Bill's solution seems to be for only one station.
>
> Here is a reprex and modification that I think does what was requested for
> multiple stations, again using base R and data frames, not dplyr and
> tibbles.
>
> First the reprex with **two** stations:
>
> > d <- data.frame( station = rep(c("one","two"),c(5,4)),
>                from = c(60,61,71,72,76,60,65,82,83),
>                 to = c(60,70,71,76,83,64, 81, 82,83),
>                 record = c("A","B","C","B","D","B","B","D","E"))
>
> > d
>   station from to record
> 1     one   60 60      A
> 2     one   61 70      B
> 3     one   71 71      C
> 4     one   72 76      B
> 5     one   76 83      D
> 6     two   60 64      B
> 7     two   65 81      B
> 8     two   82 82      D
> 9     two   83 83      E
>
> ## Now the conversion code using base R, especially by():
>
> > out <- by(d, d$station, function(x) with(x, {
> +    i <- to - from +1
> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
> + }))
>
>
> > out <- data.frame(station = rep(names(out),sapply(out,nrow)),do.call(rbind,out),
> row.names = NULL)
>
>
> > out
>    station YEAR RECORD
> 1      one   60      A
> 2      one   61      B
> 3      one   62      B
> 4      one   63      B
> 5      one   64      B
> 6      one   65      B
> 7      one   66      B
> 8      one   67      B
> 9      one   68      B
> 10     one   69      B
> 11     one   70      B
> 12     one   71      C
> 13     one   72      B
> 14     one   73      B
> 15     one   74      B
> 16     one   75      B
> 17     one   76      B
> 18     one   76      D
> 19     one   77      D
> 20     one   78      D
> 21     one   79      D
> 22     one   80      D
> 23     one   81      D
> 24     one   82      D
> 25     one   83      D
> 26     two   60      B
> 27     two   61      B
> 28     two   62      B
> 29     two   63      B
> 30     two   64      B
> 31     two   65      B
> 32     two   66      B
> 33     two   67      B
> 34     two   68      B
> 35     two   69      B
> 36     two   70      B
> 37     two   71      B
> 38     two   72      B
> 39     two   73      B
> 40     two   74      B
> 41     two   75      B
> 42     two   76      B
> 43     two   77      B
> 44     two   78      B
> 45     two   79      B
> 46     two   80      B
> 47     two   81      B
> 48     two   82      D
> 49     two   83      E
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
> r-help at r-project.org> wrote:
>
>> dplyr may have something for this, but in base R I think the following
>> does
>> what you want.  I've shortened the name of your data set to 'd'.
>>
>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>> david.hutchinson at canada.ca> wrote:
>>
>> > I have a returned tibble of station operational record similar to the
>> > following:
>> >
>> > > data.collection
>> > # A tibble: 5 x 4
>> >   STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>> >            <chr>     <int>   <int>  <chr>
>> > 1        07EA001      1960    1960    QMS
>> > 2        07EA001      1961    1970    QMC
>> > 3        07EA001      1971    1971    QMM
>> > 4        07EA001      1972    1976    QMC
>> > 5        07EA001      1977    1983    QRC
>> >
>> > I would like to reshape this to one operational record (row) per year
>> per
>> > station. Something like:
>> >
>> > 07EA001              1960      QMS
>> > 07EA001              1961      QMC
>> > 07EA001              1962      QMC
>> > 07EA001              1963      QMC
>> > ...
>> > 07EA001              1971      QMM
>> >
>> > Can this be done in dplyr easily?
>> >
>> > Thanks in advance,
>> >
>> > David
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov 28 23:08:23 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Nov 2017 14:08:23 -0800
Subject: [R] dplyr - add/expand rows
In-Reply-To: <CAF8bMcZ++bRQ3gze1AOzQPkvHa0jhT+-GfbS1JkFz_J31XV+Lw@mail.gmail.com>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAF8bMcZ++bRQ3gze1AOzQPkvHa0jhT+-GfbS1JkFz_J31XV+Lw@mail.gmail.com>
Message-ID: <CAGxFJbQ+kNpHmODr916i-2_yNjhB5WxXh_SXwSgM8OhRN6GUKg@mail.gmail.com>

Bill et al.:

Yes, I see it now. Thank you for the correction.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Nov 28, 2017 at 1:42 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Bert wrote
>   ... Bill's solution seems to be for only one station.
>
> No, it works for any number of stations.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sun, Nov 26, 2017 at 11:10 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> To David W.'s point about lack of a suitable reprex ("reproducible
>> example"), Bill's solution seems to be for only one station.
>>
>> Here is a reprex and modification that I think does what was requested
>> for multiple stations, again using base R and data frames, not dplyr and
>> tibbles.
>>
>> First the reprex with **two** stations:
>>
>> > d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>                from = c(60,61,71,72,76,60,65,82,83),
>>                 to = c(60,70,71,76,83,64, 81, 82,83),
>>                 record = c("A","B","C","B","D","B","B","D","E"))
>>
>> > d
>>   station from to record
>> 1     one   60 60      A
>> 2     one   61 70      B
>> 3     one   71 71      C
>> 4     one   72 76      B
>> 5     one   76 83      D
>> 6     two   60 64      B
>> 7     two   65 81      B
>> 8     two   82 82      D
>> 9     two   83 83      E
>>
>> ## Now the conversion code using base R, especially by():
>>
>> > out <- by(d, d$station, function(x) with(x, {
>> +    i <- to - from +1
>> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
>> + }))
>>
>>
>> > out <- data.frame(station = rep(names(out),sapply(out,nrow)),do.call(rbind,out),
>> row.names = NULL)
>>
>>
>> > out
>>    station YEAR RECORD
>> 1      one   60      A
>> 2      one   61      B
>> 3      one   62      B
>> 4      one   63      B
>> 5      one   64      B
>> 6      one   65      B
>> 7      one   66      B
>> 8      one   67      B
>> 9      one   68      B
>> 10     one   69      B
>> 11     one   70      B
>> 12     one   71      C
>> 13     one   72      B
>> 14     one   73      B
>> 15     one   74      B
>> 16     one   75      B
>> 17     one   76      B
>> 18     one   76      D
>> 19     one   77      D
>> 20     one   78      D
>> 21     one   79      D
>> 22     one   80      D
>> 23     one   81      D
>> 24     one   82      D
>> 25     one   83      D
>> 26     two   60      B
>> 27     two   61      B
>> 28     two   62      B
>> 29     two   63      B
>> 30     two   64      B
>> 31     two   65      B
>> 32     two   66      B
>> 33     two   67      B
>> 34     two   68      B
>> 35     two   69      B
>> 36     two   70      B
>> 37     two   71      B
>> 38     two   72      B
>> 39     two   73      B
>> 40     two   74      B
>> 41     two   75      B
>> 42     two   76      B
>> 43     two   77      B
>> 44     two   78      B
>> 45     two   79      B
>> 46     two   80      B
>> 47     two   81      B
>> 48     two   82      D
>> 49     two   83      E
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>> r-help at r-project.org> wrote:
>>
>>> dplyr may have something for this, but in base R I think the following
>>> does
>>> what you want.  I've shortened the name of your data set to 'd'.
>>>
>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>> david.hutchinson at canada.ca> wrote:
>>>
>>> > I have a returned tibble of station operational record similar to the
>>> > following:
>>> >
>>> > > data.collection
>>> > # A tibble: 5 x 4
>>> >   STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>> >            <chr>     <int>   <int>  <chr>
>>> > 1        07EA001      1960    1960    QMS
>>> > 2        07EA001      1961    1970    QMC
>>> > 3        07EA001      1971    1971    QMM
>>> > 4        07EA001      1972    1976    QMC
>>> > 5        07EA001      1977    1983    QRC
>>> >
>>> > I would like to reshape this to one operational record (row) per year
>>> per
>>> > station. Something like:
>>> >
>>> > 07EA001              1960      QMS
>>> > 07EA001              1961      QMC
>>> > 07EA001              1962      QMC
>>> > 07EA001              1963      QMC
>>> > ...
>>> > 07EA001              1971      QMM
>>> >
>>> > Can this be done in dplyr easily?
>>> >
>>> > Thanks in advance,
>>> >
>>> > David
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/
>>> > posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Wed Nov 29 11:21:23 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 29 Nov 2017 11:21:23 +0100
Subject: [R] How to extract coefficients from sequential (type 1),
 ANOVAs using lmer and lme
In-Reply-To: <2e617573-081d-30ec-33b7-e1db1f32c927@mpi.nl>
References: <2e617573-081d-30ec-33b7-e1db1f32c927@mpi.nl>
Message-ID: <0f7aa8ec-685d-6a4b-48f4-82cc62f80c13@mpi.nl>

(This time with the r-help in the recipients...)

Be careful when mixing lme4 and lmerTest together -- lmerTest extends
and changes the behavior of various lme4 functions.

>From the help page for lme4-anova (?lme4::anova.merMod)

>      ?anova?: returns the sequential decomposition of the contributions
>           of fixed-effects terms or, for multiple arguments, model
>           comparison statistics.  For objects of class ?lmerMod? the
>           default behavior is to refit the models with ML if fitted
>           with ?REML = TRUE?, this can be controlled via the ?refit?
>           argument. See also ?anova?.

So lme4-anova will give you sequential tests; note, however, that lme4
won't calculate the denominator degrees of freedom for you and thus
won't give p-values. See the FAQ
(https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f)

>From the help page for lmerTest-anova (?lmerTest::anova.merModLmerTest):
> Usage:
> 
>      ## S4 method for signature 'merModLmerTest'
>      anova(object, ... , ddf="Satterthwaite", 
>      type=3)
>      
> Arguments:
> 
...
>     type: type of hypothesis to be tested. Could be type=3 or type=2 or
>           type = 1 (The definition comes from SAS theory)


So lmerTest-anova by default gives you Type III ('marginal', although
Type II is what actually gives you tests that respect the Principle of
Marginality; see John Fox's Applied Regression Analysis (book) or
Venables' "Exegeses on Linear Models"
(https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf) for more information
on that. Type I tests are the sequential tests, so with anova(model,
type=1), you will get the sequential tests you want. lmerTest will
approximate the denominator degrees of freedom for you (using
Satterthwaite method by default, or the more computationally intensive
Kenward-Roger method), so you'll get p-values if that's what you want.

Finally, it's important to note two things:

1. The "type"-argument for nlme::summary doesn't actually do anything
(see ?nlme::summary.lme). It's just passed onto the 'print' method,
where it's silently ignored. The 'type' of sum of squares is an
ANOVA-thing; the closest correspondence in terms of model coefficients
is the coding of your categorical contrasts. See the literature
mentioned above for more details as well as Dale Barr's discussion on
simple vs. main effects in regression models
(http://talklab.psy.gla.ac.uk/tvw/catpred/).

(?nlme::anova.lme does have indeed have a 'type' argument.)

2. It is possible for the sequential tests and the marginal tests to
yield the same results. Again, see the above literature. You have no
interactions in your model and continuous (i.e. not-categorical)
predictors, so if they're orthogonal, then the sequential and marginal
tests will be numerically the same, even if they test different
hypotheses. (See section 5.2, starting on page 14; the sequential tests
are the "eliminating" tests, while the marginal tests are the "ignoring"
tests in that explanation.)

Best,
Phillip


On 28/11/17 12:00, r-help-request at r-project.org wrote:
> I wantto run sequential ANOVAs (i.e. type I sums of squares), and trying to getresults including ANOVA tables and associated coefficients for predictive variables(I am using the R 3.4.2 version). I think ANOVA tables look right, but believecoefficients are wrong. Specifically, it looks like that the coefficients arefrom ANOVA with ?marginal? (type III sums of squares). I have tried both lme (nlmepackage) and lmer (lme4 + lmerTEST packages). Examples of the results arebelow:
> 


<snip>


> Ibelieve the results from summary() are for ?marginal? instead of ?sequential?ANOVA because the p-value (i.e., 0.237 for narea) in summary are identical tothose in tables from ?marginal?. I also used lmer in the lme4 pacakge to findthe same results (summary() results look like from ?marginal?).
> 
> 
> Cananybody tell me how to get coefficients for ?sequential? ANOVAs? Thank you.
>


From Jan-Philipp.Werning at whu.edu  Wed Nov 29 12:29:59 2017
From: Jan-Philipp.Werning at whu.edu (Werning, Jan-Philipp)
Date: Wed, 29 Nov 2017 11:29:59 +0000
Subject: [R] DeSolve Package and Moving Average
Message-ID: <03BE06B0-C6F6-4293-B287-25C11BAD3220@whu.edu>

Dear all,


I am using the DeSolve Package to simulate a system dynamics model. At the problematic point in the model, I basically want to decide how many products shall be produced to be sold. In order to determine the amount a basic forecasting model of using the average of the last 12 time periods shall be used. My code looks like the following.

? [?]

# Time units in month
START<-0; FINISH<-120; STEP<-1

# Set seed for reproducability

 set.seed(123)

# Create time vector
simtime  <- seq(START, FINISH, by=STEP)

# Create a stock vector with initial values
stocks   <- c([?])

# Create an aux vector for the fixed aux values
auxs    <- c([?])


model <- function(time, stocks, auxs){
  with(as.list(c(stocks, auxs)),{

[? ?lots of aux, flow, and stock functions? ? ]


aMovingAverage  <-  ifelse(exists("ResultsSimulation")=="FALSE",10000,movavg(ResultsSimulation$TotalSales, 12, type = "s?))


return (list(c([?]))

  })
}

# Call Solver, and store results in a data frame
ResultsSimulation <-  data.frame(ode(y=stocks, times=simtime, func = model,
                      parms=auxs, method="euler"))

[?]?

My problem is, that the moving average (function: movavg) is only computed once and the same value is used in every timestep of the model. I.e. When running the model for the first time, 10000 is used, running it for the next time the total sales value of the first timestep is used. Since only one timestep exists, this is logical. Yet  I would expect the movavg function to produce a new value in each of the 120 timesteps, as it is the case with all other flow, stock and aux calculations as well.

It would be great if you could help me with fixing this problem.


Many thanks in advance!

Yours,

Jan





	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Nov 29 14:49:38 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 29 Nov 2017 15:49:38 +0200
Subject: [R] DeSolve Package and Moving Average
In-Reply-To: <03BE06B0-C6F6-4293-B287-25C11BAD3220@whu.edu>
References: <03BE06B0-C6F6-4293-B287-25C11BAD3220@whu.edu>
Message-ID: <CAGgJW74TtRJSeLk+G3YS9N9bNo8YOYy8s_RKnA5cymRSB9yYbA@mail.gmail.com>

Since you only provide pseudo-code I will give a guess as to the source of
the problem.
It is easy to get "burned" by use of the ifelse statement. Its results have
the same "shape" as the first argument.
My suggestion is to try replacing ifelse by a standard

if ( .... ) {
} else {
}

HTH,
Eric



On Wed, Nov 29, 2017 at 1:29 PM, Werning, Jan-Philipp <
Jan-Philipp.Werning at whu.edu> wrote:

> Dear all,
>
>
> I am using the DeSolve Package to simulate a system dynamics model. At the
> problematic point in the model, I basically want to decide how many
> products shall be produced to be sold. In order to determine the amount a
> basic forecasting model of using the average of the last 12 time periods
> shall be used. My code looks like the following.
>
> ? [?]
>
> # Time units in month
> START<-0; FINISH<-120; STEP<-1
>
> # Set seed for reproducability
>
>  set.seed(123)
>
> # Create time vector
> simtime  <- seq(START, FINISH, by=STEP)
>
> # Create a stock vector with initial values
> stocks   <- c([?])
>
> # Create an aux vector for the fixed aux values
> auxs    <- c([?])
>
>
> model <- function(time, stocks, auxs){
>   with(as.list(c(stocks, auxs)),{
>
> [? ?lots of aux, flow, and stock functions? ? ]
>
>
> aMovingAverage  <-  ifelse(exists("ResultsSimulation")=="FALSE",
> 10000,movavg(ResultsSimulation$TotalSales, 12, type = "s?))
>
>
> return (list(c([?]))
>
>   })
> }
>
> # Call Solver, and store results in a data frame
> ResultsSimulation <-  data.frame(ode(y=stocks, times=simtime, func = model,
>                       parms=auxs, method="euler"))
>
> [?]?
>
> My problem is, that the moving average (function: movavg) is only computed
> once and the same value is used in every timestep of the model. I.e. When
> running the model for the first time, 10000 is used, running it for the
> next time the total sales value of the first timestep is used. Since only
> one timestep exists, this is logical. Yet  I would expect the movavg
> function to produce a new value in each of the 120 timesteps, as it is the
> case with all other flow, stock and aux calculations as well.
>
> It would be great if you could help me with fixing this problem.
>
>
> Many thanks in advance!
>
> Yours,
>
> Jan
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From larry.martell at gmail.com  Wed Nov 29 15:28:23 2017
From: larry.martell at gmail.com (Larry Martell)
Date: Wed, 29 Nov 2017 09:28:23 -0500
Subject: [R] Preventing repeated package installation,
	or pre installing packages
Message-ID: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>

I have a R script that I call from python using rpy2. It uses dplyr, doBy,
and ggplot2. The script has install.packages commands for these 3 packages.
Even thought the packages are already installed it still downloads,
builds, and installs them, which is very time consuming. Is there a way to
have it only do the install if the package is not already installed?

Also, I run in a docker container, so after the container is instantiated
the packages are not there the first time the script runs. Is there a way
to pre load the packages, in which case I would not need the
install.packages commands for these packages and my above question would
become moot.

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Wed Nov 29 17:05:48 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 29 Nov 2017 16:05:48 +0000
Subject: [R] Preventing repeated package installation,
 or pre installing packages
In-Reply-To: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>
References: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>
Message-ID: <9bb1aea9-cb5f-007b-1cb4-693f55743a8f@dewey.myzen.co.uk>

Dear Larry

As far as your first question is concerned I think one of require or 
requireNamespace may be what you need.

Michael

On 29/11/2017 14:28, Larry Martell wrote:
> I have a R script that I call from python using rpy2. It uses dplyr, doBy,
> and ggplot2. The script has install.packages commands for these 3 packages.
> Even thought the packages are already installed it still downloads,
> builds, and installs them, which is very time consuming. Is there a way to
> have it only do the install if the package is not already installed?
> 
> Also, I run in a docker container, so after the container is instantiated
> the packages are not there the first time the script runs. Is there a way
> to pre load the packages, in which case I would not need the
> install.packages commands for these packages and my above question would
> become moot.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From Rainer at krugs.de  Wed Nov 29 17:14:55 2017
From: Rainer at krugs.de (Rainer Krug)
Date: Wed, 29 Nov 2017 17:14:55 +0100
Subject: [R] Preventing repeated package installation,
 or pre installing packages
In-Reply-To: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>
References: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>
Message-ID: <2AA35173-BBBF-4580-A366-16E14AC61EE2@krugs.de>



> On 29 Nov 2017, at 15:28, Larry Martell <larry.martell at gmail.com> wrote:
> 
> I have a R script that I call from python using rpy2. It uses dplyr, doBy,
> and ggplot2. The script has install.packages commands for these 3 packages.
> Even thought the packages are already installed it still downloads,
> builds, and installs them, which is very time consuming. Is there a way to
> have it only do the install if the package is not already installed?

You could use something like


if (!require(dplyr)) {
install.packages(?dplyr?)
library(dplyr)
}

where require() returns FALSE if it fails to load the package.


> 
> Also, I run in a docker container, so after the container is instantiated
> the packages are not there the first time the script runs. Is there a way
> to pre load the packages, in which case I would not need the
> install.packages commands for these packages and my above question would
> become moot.

Yes - add them to you Docker file, but this is a docker question, not R. Check out the Rocker Dockerfiles to see how you can do this.

Rainer

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20171129/4ecc1b87/attachment.sig>

From thierry.onkelinx at inbo.be  Wed Nov 29 17:20:38 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 29 Nov 2017 17:20:38 +0100
Subject: [R] Preventing repeated package installation,
	or pre installing packages
In-Reply-To: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>
References: <CACwCsY4h5vKiHmpnhULXT=_sgJrGc6i+Tf9acCZdg4exXR1AbQ@mail.gmail.com>
Message-ID: <CAJuCY5xZNOcpzD_DfQ6cd3ROH6hYJLx9fbsCpG7aVvN3PY9wtQ@mail.gmail.com>

Dear Larry,

Have a look at https://github.com/inbo/rstable That is a dockerfile
with a stable version of R and a set of packages.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-11-29 15:28 GMT+01:00 Larry Martell <larry.martell at gmail.com>:
> I have a R script that I call from python using rpy2. It uses dplyr, doBy,
> and ggplot2. The script has install.packages commands for these 3 packages.
> Even thought the packages are already installed it still downloads,
> builds, and installs them, which is very time consuming. Is there a way to
> have it only do the install if the package is not already installed?
>
> Also, I run in a docker container, so after the container is instantiated
> the packages are not there the first time the script runs. Is there a way
> to pre load the packages, in which case I would not need the
> install.packages commands for these packages and my above question would
> become moot.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From iwritecode2 at gmail.com  Wed Nov 29 17:37:21 2017
From: iwritecode2 at gmail.com (Robert Wilkins)
Date: Wed, 29 Nov 2017 11:37:21 -0500
Subject: [R] Data cleaning & Data preparation, what do R users want?
Message-ID: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>

R has a very wide audience, clinical research, astronomy, psychology, and
so on and so on.
I would consider data analysis work to be three stages: data preparation,
statistical analysis, and producing the report.
This regards the process of getting the data ready for analysis and
reporting, sometimes called "data cleaning" or "data munging" or "data
wrangling".

So as regards tools for data preparation, speaking to the highly diverse
audience mentioned, here is my question:

What do you want?
Or are you already quite happy with the range of tools that is currently
before you?

[BTW,  I posed the same question last week to the r-devel list, and was
advised that r-help might be a more suitable audience by one of the
moderators.]

Robert Wilkins

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Nov 29 17:48:04 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Nov 2017 08:48:04 -0800
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
Message-ID: <CAGxFJbRJoAGXPJMeF7G08oTBQ7ihT6UWR7-xZq4-XjCRLRZbZg@mail.gmail.com>

I don't think my view is of interest to many, so offlist.

I reject this:

" I would consider data analysis work to be three stages: data preparation,
statistical analysis, and producing the report."

For example, there is no such thing as "outliers" -- data to be removed as
part of cleaning/preparation -- without a statistical model to be an
"outlier" **from**, which is part of the statistical analysis. And the
structure of the data (data preparation) may need to change depending on
the course of the analysis (including graphics, also part of the analysis).
So I think your view reflects a na?ve view of the nature of data analysis,
which is an iterative and holistic process. I suspect your training is as a
computer scientist and you have not done much 1-1 consulting with
researchers, though you should certainly feel free to reject this canard.
Building software for large scale automated analysis of data required a
much different analytical paradigm than the statistical consulting model,
which is largely my background.

No reply necessary. Just my opinion, which you are of course free to trash.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 29, 2017 at 8:37 AM, Robert Wilkins <iwritecode2 at gmail.com>
wrote:

> R has a very wide audience, clinical research, astronomy, psychology, and
> so on and so on.
> I would consider data analysis work to be three stages: data preparation,
> statistical analysis, and producing the report.
> This regards the process of getting the data ready for analysis and
> reporting, sometimes called "data cleaning" or "data munging" or "data
> wrangling".
>
> So as regards tools for data preparation, speaking to the highly diverse
> audience mentioned, here is my question:
>
> What do you want?
> Or are you already quite happy with the range of tools that is currently
> before you?
>
> [BTW,  I posed the same question last week to the r-devel list, and was
> advised that r-help might be a more suitable audience by one of the
> moderators.]
>
> Robert Wilkins
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cryan at binghamton.edu  Wed Nov 29 17:52:20 2017
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Wed, 29 Nov 2017 11:52:20 -0500
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
Message-ID: <ee68de89-2503-2c99-1501-ee7f76a2595c@binghamton.edu>

Great question. What do I want? I want my co-workers to stop using Excel
spreadsheets for data entry, storage, and sharing! I want them to
understand the value of data discipline. But alas . . . .

I work in a county health department in the US. Between dplyr, stringr,
grep, grepl, and the base R read() functions, I'm doing OK.

I need to learn more about APIs, so I can see if I can make R directly
grab data from, e.g. our state health department sources. My biggest
hassle is having to download a data file, save it somewhere, and then
open R and read it in. I'd like to be able to do it all in R. Would make
the generation of recurring reports easier.

--Chris Ryan

Robert Wilkins wrote:
> R has a very wide audience, clinical research, astronomy, psychology, and
> so on and so on.
> I would consider data analysis work to be three stages: data preparation,
> statistical analysis, and producing the report.
> This regards the process of getting the data ready for analysis and
> reporting, sometimes called "data cleaning" or "data munging" or "data
> wrangling".
> 
> So as regards tools for data preparation, speaking to the highly diverse
> audience mentioned, here is my question:
> 
> What do you want?
> Or are you already quite happy with the range of tools that is currently
> before you?
> 
> [BTW,  I posed the same question last week to the r-devel list, and was
> advised that r-help might be a more suitable audience by one of the
> moderators.]
> 
> Robert Wilkins
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Wed Nov 29 17:49:12 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Nov 2017 08:49:12 -0800
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <CAGxFJbRJoAGXPJMeF7G08oTBQ7ihT6UWR7-xZq4-XjCRLRZbZg@mail.gmail.com>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
 <CAGxFJbRJoAGXPJMeF7G08oTBQ7ihT6UWR7-xZq4-XjCRLRZbZg@mail.gmail.com>
Message-ID: <CAGxFJbTLhyH8qt4JMuR977e_YFW-n=AEBSN_P_oWhco_8UhAaQ@mail.gmail.com>

Oh Crap! I mistakenly replied onlist. PLEASE IGNORE -- these are only my
ignorant opinions.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Nov 29, 2017 at 8:48 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I don't think my view is of interest to many, so offlist.
>
> I reject this:
>
> " I would consider data analysis work to be three stages: data preparation,
> statistical analysis, and producing the report."
>
> For example, there is no such thing as "outliers" -- data to be removed as
> part of cleaning/preparation -- without a statistical model to be an
> "outlier" **from**, which is part of the statistical analysis. And the
> structure of the data (data preparation) may need to change depending on
> the course of the analysis (including graphics, also part of the analysis).
> So I think your view reflects a na?ve view of the nature of data analysis,
> which is an iterative and holistic process. I suspect your training is as a
> computer scientist and you have not done much 1-1 consulting with
> researchers, though you should certainly feel free to reject this canard.
> Building software for large scale automated analysis of data required a
> much different analytical paradigm than the statistical consulting model,
> which is largely my background.
>
> No reply necessary. Just my opinion, which you are of course free to trash.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Nov 29, 2017 at 8:37 AM, Robert Wilkins <iwritecode2 at gmail.com>
> wrote:
>
>> R has a very wide audience, clinical research, astronomy, psychology, and
>> so on and so on.
>> I would consider data analysis work to be three stages: data preparation,
>> statistical analysis, and producing the report.
>> This regards the process of getting the data ready for analysis and
>> reporting, sometimes called "data cleaning" or "data munging" or "data
>> wrangling".
>>
>> So as regards tools for data preparation, speaking to the highly diverse
>> audience mentioned, here is my question:
>>
>> What do you want?
>> Or are you already quite happy with the range of tools that is currently
>> before you?
>>
>> [BTW,  I posed the same question last week to the r-devel list, and was
>> advised that r-help might be a more suitable audience by one of the
>> moderators.]
>>
>> Robert Wilkins
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From iwritecode2 at gmail.com  Wed Nov 29 18:08:24 2017
From: iwritecode2 at gmail.com (Robert Wilkins)
Date: Wed, 29 Nov 2017 12:08:24 -0500
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <ee68de89-2503-2c99-1501-ee7f76a2595c@binghamton.edu>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
 <ee68de89-2503-2c99-1501-ee7f76a2595c@binghamton.edu>
Message-ID: <CAGW5CW-Xk5TNehFMJHnEKpGg5+L7ERJqK1AmzD1s3AMs9Gyv2w@mail.gmail.com>

Christopher,

OK, well what about a range of functions in an R package that
automatically, with very little syntax, pulls in data from a variety of
formats (CSV, SQLite, and so on) and converts them to an R data frame. You
seem to be pointing to something like that.
Something like that, in some form or another, probably already exists,
though it might be either imperfect (not as user-friendly as possible) or
not well publicised, or both.
Or another tangent: your co-workers are not going to stop using Excel,
whether you like it or not, and many end-users are stuck in the exact same
position as you (co-workers who deliver the data in Excel). I will guess
that data stored in Excel tends to be dirty in somewhat predictable ways.
(And again, those other end-user's coworkers are not going to change their
behaviour). And so: a data munging tool that makes it as easy as possible
to clean up the data in Excel spreadsheets and export them to R data
frames. One prerequisite: an understanding of what tends to go wrong with
data with Excel ( the data in Excel tends to be dirty, but dirty in what
way?).

Thank you for your response Christopher. What state are you in?


On Wed, Nov 29, 2017 at 11:52 AM, Christopher W. Ryan <cryan at binghamton.edu>
wrote:

> Great question. What do I want? I want my co-workers to stop using Excel
> spreadsheets for data entry, storage, and sharing! I want them to
> understand the value of data discipline. But alas . . . .
>
> I work in a county health department in the US. Between dplyr, stringr,
> grep, grepl, and the base R read() functions, I'm doing OK.
>
> I need to learn more about APIs, so I can see if I can make R directly
> grab data from, e.g. our state health department sources. My biggest
> hassle is having to download a data file, save it somewhere, and then
> open R and read it in. I'd like to be able to do it all in R. Would make
> the generation of recurring reports easier.
>
> --Chris Ryan
>
> Robert Wilkins wrote:
> > R has a very wide audience, clinical research, astronomy, psychology, and
> > so on and so on.
> > I would consider data analysis work to be three stages: data preparation,
> > statistical analysis, and producing the report.
> > This regards the process of getting the data ready for analysis and
> > reporting, sometimes called "data cleaning" or "data munging" or "data
> > wrangling".
> >
> > So as regards tools for data preparation, speaking to the highly diverse
> > audience mentioned, here is my question:
> >
> > What do you want?
> > Or are you already quite happy with the range of tools that is currently
> > before you?
> >
> > [BTW,  I posed the same question last week to the r-devel list, and was
> > advised that r-help might be a more suitable audience by one of the
> > moderators.]
> >
> > Robert Wilkins
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Wed Nov 29 18:34:21 2017
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 29 Nov 2017 17:34:21 +0000 (UTC)
Subject: [R] SAMseq errors
References: <1738614577.4527986.1511976861531.ref@mail.yahoo.com>
Message-ID: <1738614577.4527986.1511976861531@mail.yahoo.com>

Hi, I am trying to using SAMseq() to analyze my RNA-seq experiment (20000 genes x 550 samples) with survival endpoint. It quickly give the following error:
> library(samr)Loading required package: imputeLoading required package: matrixStats
Attaching package: ?matrixStats?
The following objects are masked from ?package:Biobase?:
? ? anyMissing, rowMedians
Warning messages:1: package ?samr? was built under R version 3.3.3?2: package ?matrixStats? was built under R version 3.3.3
> samfit<-SAMseq(data, PFI.time,censoring.status=PFI.status, resp.type="Survival")
Estimating sequencing depths...Error in quantile.default(prop, c(0.25, 0.75)) :?? missing values and NaN's not allowed if 'na.rm' is FALSEIn addition: Warning message:In sum(x) : integer overflow - use sum(as.numeric(.))Error during wrapup: cannot open the connection
> sessionInfo()R version 3.3.2 (2016-10-31)Platform: x86_64-w64-mingw32/x64 (64-bit)Running under: Windows 7 x64 (build 7601) Service Pack 1
locale:[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United States.1252? ? LC_MONETARY=English_United States.1252[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? ? ?LC_TIME=English_United States.1252? ??
attached base packages:[1] stats? ? ?graphics? grDevices datasets? utils? ? ?methods? ?base? ? ?
other attached packages:[1] samr_2.0? ? ? ? ? ? ?matrixStats_0.52.2? ?impute_1.48.0? ? ? ? BiocInstaller_1.24.0 rcom_3.1-3? ? ? ? ? ?rscproxy_2.1-1? ? ??
loaded via a namespace (and not attached):[1] tools_3.3.2

I checked, my data matrix and y variables have no missing values. Anyone has suggestions what's going on?
Thank you!
John

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Wed Nov 29 18:39:24 2017
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 29 Nov 2017 17:39:24 +0000 (UTC)
Subject: [R] SAMseq errors
In-Reply-To: <1738614577.4527986.1511976861531@mail.yahoo.com>
References: <1738614577.4527986.1511976861531.ref@mail.yahoo.com>
 <1738614577.4527986.1511976861531@mail.yahoo.com>
Message-ID: <59247338.4542401.1511977164607@mail.yahoo.com>

Sorry forgot to use plain text format, hope this time it works:

Hi, I am trying to using SAMseq() to analyze my RNA-seq experiment (20000 genes x 550 samples) with survival endpoint. It quickly give the following error:

> library(samr)
Loading required package: impute
Loading required package: matrixStats

Attaching package: ?matrixStats?

The following objects are masked from ?package:Biobase?:

? ? anyMissing, rowMedians

Warning messages:
1: package ?samr? was built under R version 3.3.3?
2: package ?matrixStats? was built under R version 3.3.3

> samfit<-SAMseq(data, PFI.time,censoring.status=PFI.status, resp.type="Survival")

Estimating sequencing depths...
Error in quantile.default(prop, c(0.25, 0.75)) :?
? missing values and NaN's not allowed if 'na.rm' is FALSE
In addition: Warning message:
In sum(x) : integer overflow - use sum(as.numeric(.))
Error during wrapup: cannot open the connection

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United States.1252? ? LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? ? ?LC_TIME=English_United States.1252? ??

attached base packages:
[1] stats? ? ?graphics? grDevices datasets? utils? ? ?methods? ?base? ? ?

other attached packages:
[1] samr_2.0? ? ? ? ? ? ?matrixStats_0.52.2? ?impute_1.48.0? ? ? ? BiocInstaller_1.24.0 rcom_3.1-3? ? ? ? ? ?rscproxy_2.1-1? ? ??

loaded via a namespace (and not attached):
[1] tools_3.3.2


I checked, my data matrix and y variables have no missing values. Anyone has suggestions what's going on?

Thank you!

John


From jdnewmil at dcn.davis.ca.us  Wed Nov 29 18:58:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 29 Nov 2017 09:58:18 -0800
Subject: [R] SAMseq errors
In-Reply-To: <59247338.4542401.1511977164607@mail.yahoo.com>
References: <1738614577.4527986.1511976861531.ref@mail.yahoo.com>
 <1738614577.4527986.1511976861531@mail.yahoo.com>
 <59247338.4542401.1511977164607@mail.yahoo.com>
Message-ID: <B9D1967C-FE7C-44AA-BB66-EEAFA1632B29@dcn.davis.ca.us>

A) This list is a general interest list on the R language... you have posed your question as if you were looking for domain experts such as you might be more likely to find on the Bioconductor mailing list. 

B) Example is not reproducible. [1][2][3]

C) Just because your data don't have missing values does not mean that your early analysis steps don't create them, e.g. by taking the logarithm of negative numbers. Look at intermediate values in your analysis, and read the documentation for steps you are treating as "magic black boxes".

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On November 29, 2017 9:39:24 AM PST, array chip via R-help <r-help at r-project.org> wrote:
>Sorry forgot to use plain text format, hope this time it works:
>
>Hi, I am trying to using SAMseq() to analyze my RNA-seq experiment
>(20000 genes x 550 samples) with survival endpoint. It quickly give the
>following error:
>
>> library(samr)
>Loading required package: impute
>Loading required package: matrixStats
>
>Attaching package: ?matrixStats?
>
>The following objects are masked from ?package:Biobase?:
>
>? ? anyMissing, rowMedians
>
>Warning messages:
>1: package ?samr? was built under R version 3.3.3?
>2: package ?matrixStats? was built under R version 3.3.3
>
>> samfit<-SAMseq(data, PFI.time,censoring.status=PFI.status,
>resp.type="Survival")
>
>Estimating sequencing depths...
>Error in quantile.default(prop, c(0.25, 0.75)) :?
>? missing values and NaN's not allowed if 'na.rm' is FALSE
>In addition: Warning message:
>In sum(x) : integer overflow - use sum(as.numeric(.))
>Error during wrapup: cannot open the connection
>
>> sessionInfo()
>R version 3.3.2 (2016-10-31)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>locale:
>[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
>States.1252? ? LC_MONETARY=English_United States.1252
>[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? ? ?LC_TIME=English_United
>States.1252? ??
>
>attached base packages:
>[1] stats? ? ?graphics? grDevices datasets? utils? ? ?methods? ?base? ?
>?
>
>other attached packages:
>[1] samr_2.0? ? ? ? ? ? ?matrixStats_0.52.2? ?impute_1.48.0? ? ? ?
>BiocInstaller_1.24.0 rcom_3.1-3? ? ? ? ? ?rscproxy_2.1-1? ? ??
>
>loaded via a namespace (and not attached):
>[1] tools_3.3.2
>
>
>I checked, my data matrix and y variables have no missing values.
>Anyone has suggestions what's going on?
>
>Thank you!
>
>John
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jyotibga2 at gmail.com  Wed Nov 29 18:20:04 2017
From: jyotibga2 at gmail.com (Jyoti Bhogal)
Date: Wed, 29 Nov 2017 22:50:04 +0530
Subject: [R] 2^3 confounded factorial experiment
Message-ID: <5a1eec53.4b77630a.a7290.94d3@mx.google.com>

The following R commands were written:
>help.search("factorial")
>data(npk)
>npk
>coef(npk.aov)

In the output of coef command, please explain me the interpretation of coefficients of block1 to block 6 in this 2^3 confounded factorial experiment.

Thanks.
	[[alternative HTML version deleted]]


From kydaviddoyle at gmail.com  Wed Nov 29 22:07:34 2017
From: kydaviddoyle at gmail.com (David Doyle)
Date: Wed, 29 Nov 2017 15:07:34 -0600
Subject: [R] Removing a data subset
Message-ID: <CACftpvoBJurz0Tq0ET76f_GU+72E0uwQBAaW3ph7W6iFOKOoqQ@mail.gmail.com>

Say I have a dataset that looks like

Location    Year      GW_Elv
MW01        1999       546.63
MW02        1999       474.21
MW03        1999       471.94
MW04        1999        466.80
MW01        2000        545.90
MW02        2000        546.10

The whole dataset is at http://doylesdartden.com/ExampleData.csv
and I use the code below to do the graph but I want to do it without MW01.
How can I remove MW01??

I'm sure I can do it by SubSeting but I can not figure out how to do it.

Thank you
David

--------------------------------------------------------------

library(ggplot2)

MyData <- read.csv("http://doylesdartden.com/ExampleData.csv", header=TRUE,
sep=",")



#Sets whic are detections and nondetects
MyData$Detections <- ifelse(MyData$D_GW_Elv ==1, "Detected", "NonDetect")

#Removes the NAs
MyDataWONA <- MyData[!is.na(MyData$Detections), ]

#does the plot
p <- ggplot(data = MyDataWONA, aes(x=Year, y=GW_Elv , col=Detections)) +
  geom_point(aes(shape=Detections)) +

  ##sets the colors
  scale_colour_manual(values=c("black","red")) + #scale_y_log10() +

  #location of the legend
  theme(legend.position=c("right")) +

  #sets the line color, type and size
  geom_line(colour="black", linetype="dotted", size=0.5) +
  ylab("Elevation Feet Mean Sea Level")

## does the graph using the Location IDs as the different Locations.
p + facet_grid(Location ~ .)

	[[alternative HTML version deleted]]


From toth.denes at kogentum.hu  Wed Nov 29 22:15:58 2017
From: toth.denes at kogentum.hu (=?UTF-8?B?VMOzdGggRMOpbmVz?=)
Date: Wed, 29 Nov 2017 22:15:58 +0100
Subject: [R] dplyr - add/expand rows
In-Reply-To: <CAOQ5Nyf2HY_TJ3mZ7=4BZ2Og_0LPVFPTZwRc2JoA-cvdNmHHpw@mail.gmail.com>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
 <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>
 <CAOQ5Nyf2HY_TJ3mZ7=4BZ2Og_0LPVFPTZwRc2JoA-cvdNmHHpw@mail.gmail.com>
Message-ID: <b4d8ba31-e0c8-a242-408b-5fc0475ba19a@kogentum.hu>

Hi,

A benchmarking study with an additional (data.table-based) solution. 
Enjoy! ;)

Cheers,
Denes


--------------------------


## packages ##########################

library(dplyr)
library(data.table)
library(IRanges)
library(microbenchmark)

## prepare example dataset ###########

## use Bert's example, with 2000 stations instead of 2
d_df <- data.frame( station = rep(rep(c("one","two"),c(5,4)), 1000L),
                     from = as.integer(c(60,61,71,72,76,60,65,82,83)),
                     to = as.integer(c(60,70,71,76,83,64, 81, 82,83)),
                     record = c("A","B","C","B","D","B","B","D","E"),
                     stringsAsFactors = FALSE)
stations <- rle(d_df$station)
stations$value <- gsub(
   " ", "0",
   paste0("station", format(1:length(stations$value), width = 6)))
d_df$station <- rep(stations$value, stations$lengths)

## prepare tibble and data.table versions
d_tbl <- as_tibble(d_df)
d_dt <- as.data.table(d_df)

## solutions ##########################

## Bert - by
fun_bert <- function(d) {
   out <- by(
     d, d$station, function(x) with(x, {
       i <- to - from +1
       data.frame(record =rep(record,i),
                  year =sequence(i) -1 + rep(from,i),
                  stringsAsFactors = FALSE)
     }))
   data.frame(station = rep(names(out), sapply(out,nrow)),
              do.call(rbind,out),
              row.names = NULL,
              stringsAsFactors = FALSE)
}

## Bill - transform
fun_bill <- function(d) {
   i <- rep(seq_len(nrow(d)), d$to-d$from+1)
   j <- sequence(d$to-d$from+1)
   transform(d[i,], year=from+j-1, from=NULL, to=NULL)
}

## Michael - IRanges
fun_michael <- function(d) {
   df <- with(d, DataFrame(station, record, year=IRanges(from, to)))
   expand(df, "year")
}

## Jim - dplyr
fun_jim <- function(d) {
   d %>%
     rowwise() %>%
     do(tibble(station = .$station,
               record = .$record,
               year = seq(.$from, .$to))
     )
}

## Martin - Map
fun_martin <- function(d) {
   d$year <- with(d, Map(seq, from, to))
   res0 <- with(d, Map(data.frame,
                       station=station,
                       record=record,
                       year=year,
                       MoreArgs = list(stringsAsFactors = FALSE)))
   do.call(rbind, unname(res0))
}

## Denes - simple data.table
fun_denes <- function(d) {
   out <- d[, .(year = from:to), by = .(station, from, record)]
   out[, from := NULL]
}

## Check equality ################################
all.equal(fun_bill(d_df), fun_bert(d_df),
           check.attributes = FALSE)
all.equal(fun_bill(d_df), fun_martin(d_df),
           check.attributes = FALSE)
all.equal(fun_bill(d_df), as.data.frame(fun_michael(d_df)),
           check.attributes = FALSE)
all.equal(fun_bill(d_df), as.data.frame(fun_denes(d_dt)),
           check.attributes = FALSE)
# Be prepared: this solution is super slow
all.equal(fun_bill(d_df), as.data.frame(fun_jim(d_tbl)),
           check.attributes = FALSE)

## Benchmark #####################################

## Martin
print(system.time(fun_martin(d_df)))

## Bert
print(system.time(fun_bert(d_df)))

## Top 3
print(
   microbenchmark(
     fun_bill(d_df),
     fun_michael(d_df),
     fun_denes(d_dt),
     times = 100L
   )
)


-------------------------

On 11/28/2017 06:49 PM, Michael Lawrence wrote:
> Or with the Bioconductor IRanges package:
> 
> df <- with(input, DataFrame(station, year=IRanges(from, to), record))
> expand(df, "year")
> 
> DataFrame with 24 rows and 3 columns
>          station     year      record
>      <character> <integer> <character>
> 1       07EA001      1960         QMS
> 2       07EA001      1961         QMC
> 3       07EA001      1962         QMC
> 4       07EA001      1963         QMC
> 5       07EA001      1964         QMC
> ...         ...       ...         ...
> 20      07EA001      1979         QRC
> 21      07EA001      1980         QRC
> 22      07EA001      1981         QRC
> 23      07EA001      1982         QRC
> 24      07EA001      1983         QRC
> 
> If you tell the computer more about your data, it can do more things for
> you.
> 
> Michael
> 
> On Tue, Nov 28, 2017 at 7:34 AM, Martin Morgan <
> martin.morgan at roswellpark.org> wrote:
> 
>> On 11/26/2017 08:42 PM, jim holtman wrote:
>>
>>> try this:
>>>
>>> ##########################################
>>>
>>> library(dplyr)
>>>
>>> input <- tribble(
>>>     ~station, ~from, ~to, ~record,
>>>    "07EA001" ,    1960  ,  1960  , "QMS",
>>>    "07EA001"  ,   1961 ,   1970  , "QMC",
>>>    "07EA001" ,    1971  ,  1971  , "QMM",
>>>    "07EA001" ,    1972  ,  1976  , "QMC",
>>>    "07EA001" ,    1977  ,  1983  , "QRC"
>>> )
>>>
>>> result <- input %>%
>>>     rowwise() %>%
>>>     do(tibble(station = .$station,
>>>               year = seq(.$from, .$to),
>>>               record = .$record)
>>>     )
>>>
>>> ###########################
>>>
>>
>> In a bit more 'base R' mode I did
>>
>>    input$year <- with(input, Map(seq, from, to))
>>    res0 <- with(input, Map(data.frame, station=station, year=year,
>>        record=record))
>>     as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>
>> resulting in
>>
>>> as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>     station  year record
>>      <fctr> <int> <fctr>
>>   1 07EA001  1960    QMS
>>   2 07EA001  1961    QMC
>>   3 07EA001  1962    QMC
>>   4 07EA001  1963    QMC
>>   5 07EA001  1964    QMC
>>   6 07EA001  1965    QMC
>>   7 07EA001  1966    QMC
>>   8 07EA001  1967    QMC
>>   9 07EA001  1968    QMC
>> 10 07EA001  1969    QMC
>> # ... with 14 more rows
>>
>> I though I should have been able to use `tibble` in the second step, but
>> that leads to a (cryptic) error
>>
>>> res0 <- with(input, Map(tibble, station=station, year=year,
>> record=record))Error in captureDots(strict = `__quosured`) :
>>    the argument has already been evaluated
>>
>> The 'station' and 'record' columns are factors, so different from the
>> original input, but this seems the appropriate data type for theses columns.
>>
>> It's interesting to compare the 'specialized' knowledge needed for each
>> approach -- rowwise(), do(), .$ for tidyverse, with(), do.call(), maybe
>> rbind() and Map() for base R.
>>
>> Martin
>>
>>
>>
>>>
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>> On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>> To David W.'s point about lack of a suitable reprex ("reproducible
>>>> example"), Bill's solution seems to be for only one station.
>>>>
>>>> Here is a reprex and modification that I think does what was requested
>>>> for
>>>> multiple stations, again using base R and data frames, not dplyr and
>>>> tibbles.
>>>>
>>>> First the reprex with **two** stations:
>>>>
>>>> d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>>>>
>>>>                  from = c(60,61,71,72,76,60,65,82,83),
>>>>                   to = c(60,70,71,76,83,64, 81, 82,83),
>>>>                   record = c("A","B","C","B","D","B","B","D","E"))
>>>>
>>>> d
>>>>>
>>>>     station from to record
>>>> 1     one   60 60      A
>>>> 2     one   61 70      B
>>>> 3     one   71 71      C
>>>> 4     one   72 76      B
>>>> 5     one   76 83      D
>>>> 6     two   60 64      B
>>>> 7     two   65 81      B
>>>> 8     two   82 82      D
>>>> 9     two   83 83      E
>>>>
>>>> ## Now the conversion code using base R, especially by():
>>>>
>>>> out <- by(d, d$station, function(x) with(x, {
>>>>>
>>>> +    i <- to - from +1
>>>> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD =rep(record,i))
>>>> + }))
>>>>
>>>>
>>>> out <- data.frame(station =
>>>>>
>>>> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = NULL)
>>>>
>>>>
>>>> out
>>>>>
>>>>      station YEAR RECORD
>>>> 1      one   60      A
>>>> 2      one   61      B
>>>> 3      one   62      B
>>>> 4      one   63      B
>>>> 5      one   64      B
>>>> 6      one   65      B
>>>> 7      one   66      B
>>>> 8      one   67      B
>>>> 9      one   68      B
>>>> 10     one   69      B
>>>> 11     one   70      B
>>>> 12     one   71      C
>>>> 13     one   72      B
>>>> 14     one   73      B
>>>> 15     one   74      B
>>>> 16     one   75      B
>>>> 17     one   76      B
>>>> 18     one   76      D
>>>> 19     one   77      D
>>>> 20     one   78      D
>>>> 21     one   79      D
>>>> 22     one   80      D
>>>> 23     one   81      D
>>>> 24     one   82      D
>>>> 25     one   83      D
>>>> 26     two   60      B
>>>> 27     two   61      B
>>>> 28     two   62      B
>>>> 29     two   63      B
>>>> 30     two   64      B
>>>> 31     two   65      B
>>>> 32     two   66      B
>>>> 33     two   67      B
>>>> 34     two   68      B
>>>> 35     two   69      B
>>>> 36     two   70      B
>>>> 37     two   71      B
>>>> 38     two   72      B
>>>> 39     two   73      B
>>>> 40     two   74      B
>>>> 41     two   75      B
>>>> 42     two   76      B
>>>> 43     two   77      B
>>>> 44     two   78      B
>>>> 45     two   79      B
>>>> 46     two   80      B
>>>> 47     two   81      B
>>>> 48     two   82      D
>>>> 49     two   83      E
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and
>>>> sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>>>> r-help at r-project.org> wrote:
>>>>
>>>> dplyr may have something for this, but in base R I think the following
>>>>>
>>>> does
>>>>
>>>>> what you want.  I've shortened the name of your data set to 'd'.
>>>>>
>>>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>>>
>>>>>
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>>>> david.hutchinson at canada.ca> wrote:
>>>>>
>>>>> I have a returned tibble of station operational record similar to the
>>>>>> following:
>>>>>>
>>>>>> data.collection
>>>>>>>
>>>>>> # A tibble: 5 x 4
>>>>>>     STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>>>>>              <chr>     <int>   <int>  <chr>
>>>>>> 1        07EA001      1960    1960    QMS
>>>>>> 2        07EA001      1961    1970    QMC
>>>>>> 3        07EA001      1971    1971    QMM
>>>>>> 4        07EA001      1972    1976    QMC
>>>>>> 5        07EA001      1977    1983    QRC
>>>>>>
>>>>>> I would like to reshape this to one operational record (row) per year
>>>>>>
>>>>> per
>>>>
>>>>> station. Something like:
>>>>>>
>>>>>> 07EA001              1960      QMS
>>>>>> 07EA001              1961      QMC
>>>>>> 07EA001              1962      QMC
>>>>>> 07EA001              1963      QMC
>>>>>> ...
>>>>>> 07EA001              1971      QMM
>>>>>>
>>>>>> Can this be done in dplyr easily?
>>>>>>
>>>>>> Thanks in advance,
>>>>>>
>>>>>> David
>>>>>>
>>>>>>           [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> This email message may contain legally privileged and/or...{{dropped:2}}
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr. T?th D?nes ?gyvezet?
Kogentum Kft.
Tel.: 06-30-2583723
Web: www.kogentum.hu


From martin.morgan at roswellpark.org  Wed Nov 29 22:46:41 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 29 Nov 2017 16:46:41 -0500
Subject: [R] dplyr - add/expand rows
In-Reply-To: <b4d8ba31-e0c8-a242-408b-5fc0475ba19a@kogentum.hu>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
 <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>
 <CAOQ5Nyf2HY_TJ3mZ7=4BZ2Og_0LPVFPTZwRc2JoA-cvdNmHHpw@mail.gmail.com>
 <b4d8ba31-e0c8-a242-408b-5fc0475ba19a@kogentum.hu>
Message-ID: <afe8885e-b8c8-fee8-e1eb-6a0585f67d68@roswellpark.org>

On 11/29/2017 04:15 PM, T?th D?nes wrote:
> Hi,
> 
> A benchmarking study with an additional (data.table-based) solution. 

I don't think speed is the right benchmark (I do agree that correctness 
is!).

For the R-help list, maybe something about least specialized R knowledge 
required would be appropriate? I'd say there were some 'hard' solutions 
-- Michael (deep understanding of Bioconductor and IRanges), Toth (deep 
understanding of data.table), Jim (at least for me moderate 
understanding of dplyr,especially the .$ notation; a simpler dplyr 
answer might have moved this response out of the 'difficult' category, 
especially given the familiarity of the OP with dplyr). I'd vote for 
Bill's as requiring the least specialized knowledge of R (though the +/- 
1 indexing is an easy thing to get wrong).

A different criteria might be reuse across analysis scenarios. Bill 
seems to win here again, since the principles are very general and at 
least moderately efficient (both Bert and Martin's solutions are 
essentially R-level iterations and have poor scalability, as 
demonstrated in the microbenchmarks; Bill's is mostly vectorized). 
Certainly data.table, dplyr, and IRanges are extremely useful within the 
confines of the problem domains they address.

Martin

> Enjoy! ;)
> 
> Cheers,
> Denes
> 
> 
> --------------------------
> 
> 
> ## packages ##########################
> 
> library(dplyr)
> library(data.table)
> library(IRanges)
> library(microbenchmark)
> 
> ## prepare example dataset ###########
> 
> ## use Bert's example, with 2000 stations instead of 2
> d_df <- data.frame( station = rep(rep(c("one","two"),c(5,4)), 1000L),
>  ??????????????????? from = as.integer(c(60,61,71,72,76,60,65,82,83)),
>  ??????????????????? to = as.integer(c(60,70,71,76,83,64, 81, 82,83)),
>  ??????????????????? record = c("A","B","C","B","D","B","B","D","E"),
>  ??????????????????? stringsAsFactors = FALSE)
> stations <- rle(d_df$station)
> stations$value <- gsub(
>  ? " ", "0",
>  ? paste0("station", format(1:length(stations$value), width = 6)))
> d_df$station <- rep(stations$value, stations$lengths)
> 
> ## prepare tibble and data.table versions
> d_tbl <- as_tibble(d_df)
> d_dt <- as.data.table(d_df)
> 
> ## solutions ##########################
> 
> ## Bert - by
> fun_bert <- function(d) {
>  ? out <- by(
>  ??? d, d$station, function(x) with(x, {
>  ????? i <- to - from +1
>  ????? data.frame(record =rep(record,i),
>  ???????????????? year =sequence(i) -1 + rep(from,i),
>  ???????????????? stringsAsFactors = FALSE)
>  ??? }))
>  ? data.frame(station = rep(names(out), sapply(out,nrow)),
>  ???????????? do.call(rbind,out),
>  ???????????? row.names = NULL,
>  ???????????? stringsAsFactors = FALSE)
> }
> 
> ## Bill - transform
> fun_bill <- function(d) {
>  ? i <- rep(seq_len(nrow(d)), d$to-d$from+1)
>  ? j <- sequence(d$to-d$from+1)
>  ? transform(d[i,], year=from+j-1, from=NULL, to=NULL)
> }
> 
> ## Michael - IRanges
> fun_michael <- function(d) {
>  ? df <- with(d, DataFrame(station, record, year=IRanges(from, to)))
>  ? expand(df, "year")
> }
> 
> ## Jim - dplyr
> fun_jim <- function(d) {
>  ? d %>%
>  ??? rowwise() %>%
>  ??? do(tibble(station = .$station,
>  ????????????? record = .$record,
>  ????????????? year = seq(.$from, .$to))
>  ??? )
> }
> 
> ## Martin - Map
> fun_martin <- function(d) {
>  ? d$year <- with(d, Map(seq, from, to))
>  ? res0 <- with(d, Map(data.frame,
>  ????????????????????? station=station,
>  ????????????????????? record=record,
>  ????????????????????? year=year,
>  ????????????????????? MoreArgs = list(stringsAsFactors = FALSE)))
>  ? do.call(rbind, unname(res0))
> }
> 
> ## Denes - simple data.table
> fun_denes <- function(d) {
>  ? out <- d[, .(year = from:to), by = .(station, from, record)]
>  ? out[, from := NULL]
> }
> 
> ## Check equality ################################
> all.equal(fun_bill(d_df), fun_bert(d_df),
>  ????????? check.attributes = FALSE)
> all.equal(fun_bill(d_df), fun_martin(d_df),
>  ????????? check.attributes = FALSE)
> all.equal(fun_bill(d_df), as.data.frame(fun_michael(d_df)),
>  ????????? check.attributes = FALSE)
> all.equal(fun_bill(d_df), as.data.frame(fun_denes(d_dt)),
>  ????????? check.attributes = FALSE)
> # Be prepared: this solution is super slow
> all.equal(fun_bill(d_df), as.data.frame(fun_jim(d_tbl)),
>  ????????? check.attributes = FALSE)
> 
> ## Benchmark #####################################
> 
> ## Martin
> print(system.time(fun_martin(d_df)))
> 
> ## Bert
> print(system.time(fun_bert(d_df)))
> 
> ## Top 3
> print(
>  ? microbenchmark(
>  ??? fun_bill(d_df),
>  ??? fun_michael(d_df),
>  ??? fun_denes(d_dt),
>  ??? times = 100L
>  ? )
> )
> 
> 
> -------------------------
> 
> On 11/28/2017 06:49 PM, Michael Lawrence wrote:
>> Or with the Bioconductor IRanges package:
>>
>> df <- with(input, DataFrame(station, year=IRanges(from, to), record))
>> expand(df, "year")
>>
>> DataFrame with 24 rows and 3 columns
>> ???????? station???? year????? record
>> ???? <character> <integer> <character>
>> 1?????? 07EA001????? 1960???????? QMS
>> 2?????? 07EA001????? 1961???????? QMC
>> 3?????? 07EA001????? 1962???????? QMC
>> 4?????? 07EA001????? 1963???????? QMC
>> 5?????? 07EA001????? 1964???????? QMC
>> ...???????? ...?????? ...???????? ...
>> 20????? 07EA001????? 1979???????? QRC
>> 21????? 07EA001????? 1980???????? QRC
>> 22????? 07EA001????? 1981???????? QRC
>> 23????? 07EA001????? 1982???????? QRC
>> 24????? 07EA001????? 1983???????? QRC
>>
>> If you tell the computer more about your data, it can do more things for
>> you.
>>
>> Michael
>>
>> On Tue, Nov 28, 2017 at 7:34 AM, Martin Morgan <
>> martin.morgan at roswellpark.org> wrote:
>>
>>> On 11/26/2017 08:42 PM, jim holtman wrote:
>>>
>>>> try this:
>>>>
>>>> ##########################################
>>>>
>>>> library(dplyr)
>>>>
>>>> input <- tribble(
>>>> ??? ~station, ~from, ~to, ~record,
>>>> ?? "07EA001" ,??? 1960? ,? 1960? , "QMS",
>>>> ?? "07EA001"? ,?? 1961 ,?? 1970? , "QMC",
>>>> ?? "07EA001" ,??? 1971? ,? 1971? , "QMM",
>>>> ?? "07EA001" ,??? 1972? ,? 1976? , "QMC",
>>>> ?? "07EA001" ,??? 1977? ,? 1983? , "QRC"
>>>> )
>>>>
>>>> result <- input %>%
>>>> ??? rowwise() %>%
>>>> ??? do(tibble(station = .$station,
>>>> ????????????? year = seq(.$from, .$to),
>>>> ????????????? record = .$record)
>>>> ??? )
>>>>
>>>> ###########################
>>>>
>>>
>>> In a bit more 'base R' mode I did
>>>
>>> ?? input$year <- with(input, Map(seq, from, to))
>>> ?? res0 <- with(input, Map(data.frame, station=station, year=year,
>>> ?????? record=record))
>>> ??? as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>>
>>> resulting in
>>>
>>>> as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>> ??? station? year record
>>> ???? <fctr> <int> <fctr>
>>> ? 1 07EA001? 1960??? QMS
>>> ? 2 07EA001? 1961??? QMC
>>> ? 3 07EA001? 1962??? QMC
>>> ? 4 07EA001? 1963??? QMC
>>> ? 5 07EA001? 1964??? QMC
>>> ? 6 07EA001? 1965??? QMC
>>> ? 7 07EA001? 1966??? QMC
>>> ? 8 07EA001? 1967??? QMC
>>> ? 9 07EA001? 1968??? QMC
>>> 10 07EA001? 1969??? QMC
>>> # ... with 14 more rows
>>>
>>> I though I should have been able to use `tibble` in the second step, but
>>> that leads to a (cryptic) error
>>>
>>>> res0 <- with(input, Map(tibble, station=station, year=year,
>>> record=record))Error in captureDots(strict = `__quosured`) :
>>> ?? the argument has already been evaluated
>>>
>>> The 'station' and 'record' columns are factors, so different from the
>>> original input, but this seems the appropriate data type for theses 
>>> columns.
>>>
>>> It's interesting to compare the 'specialized' knowledge needed for each
>>> approach -- rowwise(), do(), .$ for tidyverse, with(), do.call(), maybe
>>> rbind() and Map() for base R.
>>>
>>> Martin
>>>
>>>
>>>
>>>>
>>>>
>>>> Jim Holtman
>>>> Data Munger Guru
>>>>
>>>> What is the problem that you are trying to solve?
>>>> Tell me what you want to do, not how you want to do it.
>>>>
>>>> On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>>
>>>> To David W.'s point about lack of a suitable reprex ("reproducible
>>>>> example"), Bill's solution seems to be for only one station.
>>>>>
>>>>> Here is a reprex and modification that I think does what was requested
>>>>> for
>>>>> multiple stations, again using base R and data frames, not dplyr and
>>>>> tibbles.
>>>>>
>>>>> First the reprex with **two** stations:
>>>>>
>>>>> d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>>>>>
>>>>> ???????????????? from = c(60,61,71,72,76,60,65,82,83),
>>>>> ????????????????? to = c(60,70,71,76,83,64, 81, 82,83),
>>>>> ????????????????? record = c("A","B","C","B","D","B","B","D","E"))
>>>>>
>>>>> d
>>>>>>
>>>>> ??? station from to record
>>>>> 1???? one?? 60 60????? A
>>>>> 2???? one?? 61 70????? B
>>>>> 3???? one?? 71 71????? C
>>>>> 4???? one?? 72 76????? B
>>>>> 5???? one?? 76 83????? D
>>>>> 6???? two?? 60 64????? B
>>>>> 7???? two?? 65 81????? B
>>>>> 8???? two?? 82 82????? D
>>>>> 9???? two?? 83 83????? E
>>>>>
>>>>> ## Now the conversion code using base R, especially by():
>>>>>
>>>>> out <- by(d, d$station, function(x) with(x, {
>>>>>>
>>>>> +??? i <- to - from +1
>>>>> +??? data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD 
>>>>> =rep(record,i))
>>>>> + }))
>>>>>
>>>>>
>>>>> out <- data.frame(station =
>>>>>>
>>>>> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = NULL)
>>>>>
>>>>>
>>>>> out
>>>>>>
>>>>> ???? station YEAR RECORD
>>>>> 1????? one?? 60????? A
>>>>> 2????? one?? 61????? B
>>>>> 3????? one?? 62????? B
>>>>> 4????? one?? 63????? B
>>>>> 5????? one?? 64????? B
>>>>> 6????? one?? 65????? B
>>>>> 7????? one?? 66????? B
>>>>> 8????? one?? 67????? B
>>>>> 9????? one?? 68????? B
>>>>> 10???? one?? 69????? B
>>>>> 11???? one?? 70????? B
>>>>> 12???? one?? 71????? C
>>>>> 13???? one?? 72????? B
>>>>> 14???? one?? 73????? B
>>>>> 15???? one?? 74????? B
>>>>> 16???? one?? 75????? B
>>>>> 17???? one?? 76????? B
>>>>> 18???? one?? 76????? D
>>>>> 19???? one?? 77????? D
>>>>> 20???? one?? 78????? D
>>>>> 21???? one?? 79????? D
>>>>> 22???? one?? 80????? D
>>>>> 23???? one?? 81????? D
>>>>> 24???? one?? 82????? D
>>>>> 25???? one?? 83????? D
>>>>> 26???? two?? 60????? B
>>>>> 27???? two?? 61????? B
>>>>> 28???? two?? 62????? B
>>>>> 29???? two?? 63????? B
>>>>> 30???? two?? 64????? B
>>>>> 31???? two?? 65????? B
>>>>> 32???? two?? 66????? B
>>>>> 33???? two?? 67????? B
>>>>> 34???? two?? 68????? B
>>>>> 35???? two?? 69????? B
>>>>> 36???? two?? 70????? B
>>>>> 37???? two?? 71????? B
>>>>> 38???? two?? 72????? B
>>>>> 39???? two?? 73????? B
>>>>> 40???? two?? 74????? B
>>>>> 41???? two?? 75????? B
>>>>> 42???? two?? 76????? B
>>>>> 43???? two?? 77????? B
>>>>> 44???? two?? 78????? B
>>>>> 45???? two?? 79????? B
>>>>> 46???? two?? 80????? B
>>>>> 47???? two?? 81????? B
>>>>> 48???? two?? 82????? D
>>>>> 49???? two?? 83????? E
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>>>>> r-help at r-project.org> wrote:
>>>>>
>>>>> dplyr may have something for this, but in base R I think the following
>>>>>>
>>>>> does
>>>>>
>>>>>> what you want.? I've shortened the name of your data set to 'd'.
>>>>>>
>>>>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>>>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>>>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>>>>
>>>>>>
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>>>>> david.hutchinson at canada.ca> wrote:
>>>>>>
>>>>>> I have a returned tibble of station operational record similar to the
>>>>>>> following:
>>>>>>>
>>>>>>> data.collection
>>>>>>>>
>>>>>>> # A tibble: 5 x 4
>>>>>>> ??? STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>>>>>> ???????????? <chr>???? <int>?? <int>? <chr>
>>>>>>> 1??????? 07EA001????? 1960??? 1960??? QMS
>>>>>>> 2??????? 07EA001????? 1961??? 1970??? QMC
>>>>>>> 3??????? 07EA001????? 1971??? 1971??? QMM
>>>>>>> 4??????? 07EA001????? 1972??? 1976??? QMC
>>>>>>> 5??????? 07EA001????? 1977??? 1983??? QRC
>>>>>>>
>>>>>>> I would like to reshape this to one operational record (row) per 
>>>>>>> year
>>>>>>>
>>>>>> per
>>>>>
>>>>>> station. Something like:
>>>>>>>
>>>>>>> 07EA001????????????? 1960????? QMS
>>>>>>> 07EA001????????????? 1961????? QMC
>>>>>>> 07EA001????????????? 1962????? QMC
>>>>>>> 07EA001????????????? 1963????? QMC
>>>>>>> ...
>>>>>>> 07EA001????????????? 1971????? QMM
>>>>>>>
>>>>>>> Can this be done in dplyr easily?
>>>>>>>
>>>>>>> Thanks in advance,
>>>>>>>
>>>>>>> David
>>>>>>>
>>>>>>> ????????? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>> posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>> ????????? [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>> ????????? [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>> ???????? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>> This email message may contain legally privileged and/or...{{dropped:2}}
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From Rainer.Schuermann at gmx.net  Wed Nov 29 23:31:13 2017
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Thu, 30 Nov 2017 06:31:13 +0800
Subject: [R] Removing a data subset
In-Reply-To: <CACftpvoBJurz0Tq0ET76f_GU+72E0uwQBAaW3ph7W6iFOKOoqQ@mail.gmail.com>
References: <CACftpvoBJurz0Tq0ET76f_GU+72E0uwQBAaW3ph7W6iFOKOoqQ@mail.gmail.com>
Message-ID: <2264810.4gBqtGvG0X@nizza>

Reading in the data from the file

    x <- read.csv( "ExampleData.csv", header = TRUE, stringsAsFactors = FALSE )

Subsetting  as you want

    x <- x[ x$Location != "MW01", ]

This selects all rows where the value in column 'Location' is not equal to "MW01". The comma after that ensures that all columns are copied into the amended data.frame.

Rgds,
Rainer

On Mittwoch, 29. November 2017 15:07:34 +08 David Doyle wrote:
> Say I have a dataset that looks like
> 
> Location    Year      GW_Elv
> MW01        1999       546.63
> MW02        1999       474.21
> MW03        1999       471.94
> MW04        1999        466.80
> MW01        2000        545.90
> MW02        2000        546.10
> 
> The whole dataset is at http://doylesdartden.com/ExampleData.csv
> and I use the code below to do the graph but I want to do it without MW01.
> How can I remove MW01??
> 
> I'm sure I can do it by SubSeting but I can not figure out how to do it.
> 
> Thank you
> David
> 
> --------------------------------------------------------------
> 
> library(ggplot2)
> 
> MyData <- read.csv("http://doylesdartden.com/ExampleData.csv", header=TRUE,
> sep=",")
> 
> 
> 
> #Sets whic are detections and nondetects
> MyData$Detections <- ifelse(MyData$D_GW_Elv ==1, "Detected", "NonDetect")
> 
> #Removes the NAs
> MyDataWONA <- MyData[!is.na(MyData$Detections), ]
> 
> #does the plot
> p <- ggplot(data = MyDataWONA, aes(x=Year, y=GW_Elv , col=Detections)) +
>   geom_point(aes(shape=Detections)) +
> 
>   ##sets the colors
>   scale_colour_manual(values=c("black","red")) + #scale_y_log10() +
> 
>   #location of the legend
>   theme(legend.position=c("right")) +
> 
>   #sets the line color, type and size
>   geom_line(colour="black", linetype="dotted", size=0.5) +
>   ylab("Elevation Feet Mean Sea Level")
> 
> ## does the graph using the Location IDs as the different Locations.
> p + facet_grid(Location ~ .)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From toth.denes at kogentum.hu  Wed Nov 29 23:47:01 2017
From: toth.denes at kogentum.hu (=?UTF-8?B?VMOzdGggRMOpbmVz?=)
Date: Wed, 29 Nov 2017 23:47:01 +0100
Subject: [R] dplyr - add/expand rows
In-Reply-To: <afe8885e-b8c8-fee8-e1eb-6a0585f67d68@roswellpark.org>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
 <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>
 <CAOQ5Nyf2HY_TJ3mZ7=4BZ2Og_0LPVFPTZwRc2JoA-cvdNmHHpw@mail.gmail.com>
 <b4d8ba31-e0c8-a242-408b-5fc0475ba19a@kogentum.hu>
 <afe8885e-b8c8-fee8-e1eb-6a0585f67d68@roswellpark.org>
Message-ID: <251d3bb5-3a2c-7bbf-9dbb-61eca411e4e7@kogentum.hu>

Hi Martin,

On 11/29/2017 10:46 PM, Martin Morgan wrote:
> On 11/29/2017 04:15 PM, T?th D?nes wrote:
>> Hi,
>>
>> A benchmarking study with an additional (data.table-based) solution. 
> 
> I don't think speed is the right benchmark (I do agree that correctness 
> is!).

Well, agree, and sorry for the wording. It was really just an exercise 
and not a full evaluation of the approaches. When I read the avalanche 
of solutions neither of which mentioning data.table (my first choice for 
data.frame-manipulations), I became curious how a one-liner data.table 
code performs against the other solutions in terms of speed and 
readability.
Second, I quite often have the feeling that dplyr is extremely overused 
among novice (and sometimes even experienced) R users nowadays. This is 
unfortunate, as the present example also illustrates.

Regards,
Denes

> 
> For the R-help list, maybe something about least specialized R knowledge 
> required would be appropriate? I'd say there were some 'hard' solutions 
> -- Michael (deep understanding of Bioconductor and IRanges), Toth (deep 
> understanding of data.table), Jim (at least for me moderate 
> understanding of dplyr,especially the .$ notation; a simpler dplyr 
> answer might have moved this response out of the 'difficult' category, 
> especially given the familiarity of the OP with dplyr). I'd vote for 
> Bill's as requiring the least specialized knowledge of R (though the +/- 
> 1 indexing is an easy thing to get wrong).
> 
> A different criteria might be reuse across analysis scenarios. Bill 
> seems to win here again, since the principles are very general and at 
> least moderately efficient (both Bert and Martin's solutions are 
> essentially R-level iterations and have poor scalability, as 
> demonstrated in the microbenchmarks; Bill's is mostly vectorized). 
> Certainly data.table, dplyr, and IRanges are extremely useful within the 
> confines of the problem domains they address.
> 
> Martin
> 
>> Enjoy! ;)
>>
>> Cheers,
>> Denes
>>
>>
>> --------------------------
>>
>>
>> ## packages ##########################
>>
>> library(dplyr)
>> library(data.table)
>> library(IRanges)
>> library(microbenchmark)
>>
>> ## prepare example dataset ###########
>>
>> ## use Bert's example, with 2000 stations instead of 2
>> d_df <- data.frame( station = rep(rep(c("one","two"),c(5,4)), 1000L),
>>                      from = as.integer(c(60,61,71,72,76,60,65,82,83)),
>>                      to = as.integer(c(60,70,71,76,83,64, 81, 82,83)),
>>                      record = c("A","B","C","B","D","B","B","D","E"),
>>                      stringsAsFactors = FALSE)
>> stations <- rle(d_df$station)
>> stations$value <- gsub(
>>    " ", "0",
>>    paste0("station", format(1:length(stations$value), width = 6)))
>> d_df$station <- rep(stations$value, stations$lengths)
>>
>> ## prepare tibble and data.table versions
>> d_tbl <- as_tibble(d_df)
>> d_dt <- as.data.table(d_df)
>>
>> ## solutions ##########################
>>
>> ## Bert - by
>> fun_bert <- function(d) {
>>    out <- by(
>>      d, d$station, function(x) with(x, {
>>        i <- to - from +1
>>        data.frame(record =rep(record,i),
>>                   year =sequence(i) -1 + rep(from,i),
>>                   stringsAsFactors = FALSE)
>>      }))
>>    data.frame(station = rep(names(out), sapply(out,nrow)),
>>               do.call(rbind,out),
>>               row.names = NULL,
>>               stringsAsFactors = FALSE)
>> }
>>
>> ## Bill - transform
>> fun_bill <- function(d) {
>>    i <- rep(seq_len(nrow(d)), d$to-d$from+1)
>>    j <- sequence(d$to-d$from+1)
>>    transform(d[i,], year=from+j-1, from=NULL, to=NULL)
>> }
>>
>> ## Michael - IRanges
>> fun_michael <- function(d) {
>>    df <- with(d, DataFrame(station, record, year=IRanges(from, to)))
>>    expand(df, "year")
>> }
>>
>> ## Jim - dplyr
>> fun_jim <- function(d) {
>>    d %>%
>>      rowwise() %>%
>>      do(tibble(station = .$station,
>>                record = .$record,
>>                year = seq(.$from, .$to))
>>      )
>> }
>>
>> ## Martin - Map
>> fun_martin <- function(d) {
>>    d$year <- with(d, Map(seq, from, to))
>>    res0 <- with(d, Map(data.frame,
>>                        station=station,
>>                        record=record,
>>                        year=year,
>>                        MoreArgs = list(stringsAsFactors = FALSE)))
>>    do.call(rbind, unname(res0))
>> }
>>
>> ## Denes - simple data.table
>> fun_denes <- function(d) {
>>    out <- d[, .(year = from:to), by = .(station, from, record)]
>>    out[, from := NULL]
>> }
>>
>> ## Check equality ################################
>> all.equal(fun_bill(d_df), fun_bert(d_df),
>>            check.attributes = FALSE)
>> all.equal(fun_bill(d_df), fun_martin(d_df),
>>            check.attributes = FALSE)
>> all.equal(fun_bill(d_df), as.data.frame(fun_michael(d_df)),
>>            check.attributes = FALSE)
>> all.equal(fun_bill(d_df), as.data.frame(fun_denes(d_dt)),
>>            check.attributes = FALSE)
>> # Be prepared: this solution is super slow
>> all.equal(fun_bill(d_df), as.data.frame(fun_jim(d_tbl)),
>>            check.attributes = FALSE)
>>
>> ## Benchmark #####################################
>>
>> ## Martin
>> print(system.time(fun_martin(d_df)))
>>
>> ## Bert
>> print(system.time(fun_bert(d_df)))
>>
>> ## Top 3
>> print(
>>    microbenchmark(
>>      fun_bill(d_df),
>>      fun_michael(d_df),
>>      fun_denes(d_dt),
>>      times = 100L
>>    )
>> )
>>
>>
>> -------------------------
>>
>> On 11/28/2017 06:49 PM, Michael Lawrence wrote:
>>> Or with the Bioconductor IRanges package:
>>>
>>> df <- with(input, DataFrame(station, year=IRanges(from, to), record))
>>> expand(df, "year")
>>>
>>> DataFrame with 24 rows and 3 columns
>>>          station     year      record
>>>      <character> <integer> <character>
>>> 1       07EA001      1960         QMS
>>> 2       07EA001      1961         QMC
>>> 3       07EA001      1962         QMC
>>> 4       07EA001      1963         QMC
>>> 5       07EA001      1964         QMC
>>> ...         ...       ...         ...
>>> 20      07EA001      1979         QRC
>>> 21      07EA001      1980         QRC
>>> 22      07EA001      1981         QRC
>>> 23      07EA001      1982         QRC
>>> 24      07EA001      1983         QRC
>>>
>>> If you tell the computer more about your data, it can do more things for
>>> you.
>>>
>>> Michael
>>>
>>> On Tue, Nov 28, 2017 at 7:34 AM, Martin Morgan <
>>> martin.morgan at roswellpark.org> wrote:
>>>
>>>> On 11/26/2017 08:42 PM, jim holtman wrote:
>>>>
>>>>> try this:
>>>>>
>>>>> ##########################################
>>>>>
>>>>> library(dplyr)
>>>>>
>>>>> input <- tribble(
>>>>>     ~station, ~from, ~to, ~record,
>>>>>    "07EA001" ,    1960  ,  1960  , "QMS",
>>>>>    "07EA001"  ,   1961 ,   1970  , "QMC",
>>>>>    "07EA001" ,    1971  ,  1971  , "QMM",
>>>>>    "07EA001" ,    1972  ,  1976  , "QMC",
>>>>>    "07EA001" ,    1977  ,  1983  , "QRC"
>>>>> )
>>>>>
>>>>> result <- input %>%
>>>>>     rowwise() %>%
>>>>>     do(tibble(station = .$station,
>>>>>               year = seq(.$from, .$to),
>>>>>               record = .$record)
>>>>>     )
>>>>>
>>>>> ###########################
>>>>>
>>>>
>>>> In a bit more 'base R' mode I did
>>>>
>>>>    input$year <- with(input, Map(seq, from, to))
>>>>    res0 <- with(input, Map(data.frame, station=station, year=year,
>>>>        record=record))
>>>>     as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>>>
>>>> resulting in
>>>>
>>>>> as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>>>     station  year record
>>>>      <fctr> <int> <fctr>
>>>>   1 07EA001  1960    QMS
>>>>   2 07EA001  1961    QMC
>>>>   3 07EA001  1962    QMC
>>>>   4 07EA001  1963    QMC
>>>>   5 07EA001  1964    QMC
>>>>   6 07EA001  1965    QMC
>>>>   7 07EA001  1966    QMC
>>>>   8 07EA001  1967    QMC
>>>>   9 07EA001  1968    QMC
>>>> 10 07EA001  1969    QMC
>>>> # ... with 14 more rows
>>>>
>>>> I though I should have been able to use `tibble` in the second step, 
>>>> but
>>>> that leads to a (cryptic) error
>>>>
>>>>> res0 <- with(input, Map(tibble, station=station, year=year,
>>>> record=record))Error in captureDots(strict = `__quosured`) :
>>>>    the argument has already been evaluated
>>>>
>>>> The 'station' and 'record' columns are factors, so different from the
>>>> original input, but this seems the appropriate data type for theses 
>>>> columns.
>>>>
>>>> It's interesting to compare the 'specialized' knowledge needed for each
>>>> approach -- rowwise(), do(), .$ for tidyverse, with(), do.call(), maybe
>>>> rbind() and Map() for base R.
>>>>
>>>> Martin
>>>>
>>>>
>>>>
>>>>>
>>>>>
>>>>> Jim Holtman
>>>>> Data Munger Guru
>>>>>
>>>>> What is the problem that you are trying to solve?
>>>>> Tell me what you want to do, not how you want to do it.
>>>>>
>>>>> On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> To David W.'s point about lack of a suitable reprex ("reproducible
>>>>>> example"), Bill's solution seems to be for only one station.
>>>>>>
>>>>>> Here is a reprex and modification that I think does what was 
>>>>>> requested
>>>>>> for
>>>>>> multiple stations, again using base R and data frames, not dplyr and
>>>>>> tibbles.
>>>>>>
>>>>>> First the reprex with **two** stations:
>>>>>>
>>>>>> d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>>>>>>
>>>>>>                  from = c(60,61,71,72,76,60,65,82,83),
>>>>>>                   to = c(60,70,71,76,83,64, 81, 82,83),
>>>>>>                   record = c("A","B","C","B","D","B","B","D","E"))
>>>>>>
>>>>>> d
>>>>>>>
>>>>>>     station from to record
>>>>>> 1     one   60 60      A
>>>>>> 2     one   61 70      B
>>>>>> 3     one   71 71      C
>>>>>> 4     one   72 76      B
>>>>>> 5     one   76 83      D
>>>>>> 6     two   60 64      B
>>>>>> 7     two   65 81      B
>>>>>> 8     two   82 82      D
>>>>>> 9     two   83 83      E
>>>>>>
>>>>>> ## Now the conversion code using base R, especially by():
>>>>>>
>>>>>> out <- by(d, d$station, function(x) with(x, {
>>>>>>>
>>>>>> +    i <- to - from +1
>>>>>> +    data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD 
>>>>>> =rep(record,i))
>>>>>> + }))
>>>>>>
>>>>>>
>>>>>> out <- data.frame(station =
>>>>>>>
>>>>>> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = 
>>>>>> NULL)
>>>>>>
>>>>>>
>>>>>> out
>>>>>>>
>>>>>>      station YEAR RECORD
>>>>>> 1      one   60      A
>>>>>> 2      one   61      B
>>>>>> 3      one   62      B
>>>>>> 4      one   63      B
>>>>>> 5      one   64      B
>>>>>> 6      one   65      B
>>>>>> 7      one   66      B
>>>>>> 8      one   67      B
>>>>>> 9      one   68      B
>>>>>> 10     one   69      B
>>>>>> 11     one   70      B
>>>>>> 12     one   71      C
>>>>>> 13     one   72      B
>>>>>> 14     one   73      B
>>>>>> 15     one   74      B
>>>>>> 16     one   75      B
>>>>>> 17     one   76      B
>>>>>> 18     one   76      D
>>>>>> 19     one   77      D
>>>>>> 20     one   78      D
>>>>>> 21     one   79      D
>>>>>> 22     one   80      D
>>>>>> 23     one   81      D
>>>>>> 24     one   82      D
>>>>>> 25     one   83      D
>>>>>> 26     two   60      B
>>>>>> 27     two   61      B
>>>>>> 28     two   62      B
>>>>>> 29     two   63      B
>>>>>> 30     two   64      B
>>>>>> 31     two   65      B
>>>>>> 32     two   66      B
>>>>>> 33     two   67      B
>>>>>> 34     two   68      B
>>>>>> 35     two   69      B
>>>>>> 36     two   70      B
>>>>>> 37     two   71      B
>>>>>> 38     two   72      B
>>>>>> 39     two   73      B
>>>>>> 40     two   74      B
>>>>>> 41     two   75      B
>>>>>> 42     two   76      B
>>>>>> 43     two   77      B
>>>>>> 44     two   78      B
>>>>>> 45     two   79      B
>>>>>> 46     two   80      B
>>>>>> 47     two   81      B
>>>>>> 48     two   82      D
>>>>>> 49     two   83      E
>>>>>>
>>>>>> Cheers,
>>>>>> Bert
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming 
>>>>>> along
>>>>>> and
>>>>>> sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>>>>>> r-help at r-project.org> wrote:
>>>>>>
>>>>>> dplyr may have something for this, but in base R I think the 
>>>>>> following
>>>>>>>
>>>>>> does
>>>>>>
>>>>>>> what you want.  I've shortened the name of your data set to 'd'.
>>>>>>>
>>>>>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>>>>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>>>>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>>>>>
>>>>>>>
>>>>>>> Bill Dunlap
>>>>>>> TIBCO Software
>>>>>>> wdunlap tibco.com
>>>>>>>
>>>>>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>>>>>> david.hutchinson at canada.ca> wrote:
>>>>>>>
>>>>>>> I have a returned tibble of station operational record similar to 
>>>>>>> the
>>>>>>>> following:
>>>>>>>>
>>>>>>>> data.collection
>>>>>>>>>
>>>>>>>> # A tibble: 5 x 4
>>>>>>>>     STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>>>>>>>              <chr>     <int>   <int>  <chr>
>>>>>>>> 1        07EA001      1960    1960    QMS
>>>>>>>> 2        07EA001      1961    1970    QMC
>>>>>>>> 3        07EA001      1971    1971    QMM
>>>>>>>> 4        07EA001      1972    1976    QMC
>>>>>>>> 5        07EA001      1977    1983    QRC
>>>>>>>>
>>>>>>>> I would like to reshape this to one operational record (row) per 
>>>>>>>> year
>>>>>>>>
>>>>>>> per
>>>>>>
>>>>>>> station. Something like:
>>>>>>>>
>>>>>>>> 07EA001              1960      QMS
>>>>>>>> 07EA001              1961      QMC
>>>>>>>> 07EA001              1962      QMC
>>>>>>>> 07EA001              1963      QMC
>>>>>>>> ...
>>>>>>>> 07EA001              1971      QMM
>>>>>>>>
>>>>>>>> Can this be done in dplyr easily?
>>>>>>>>
>>>>>>>> Thanks in advance,
>>>>>>>>
>>>>>>>> David
>>>>>>>>
>>>>>>>>           [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>>> posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>>
>>>>>>>           [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>> posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>>           [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>> This email message may contain legally privileged 
>>>> and/or...{{dropped:2}}
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 
> This email message may contain legally privileged and/or confidential 
> information.  If you are not the intended recipient(s), or the employee 
> or agent responsible for the delivery of this message to the intended 
> recipient(s), you are hereby notified that any disclosure, copying, 
> distribution, or use of this email message is prohibited.  If you have 
> received this message in error, please notify the sender immediately by 
> e-mail and delete this email message from your computer. Thank you.
> 

-- 
Dr. T?th D?nes ?gyvezet?
Kogentum Kft.
Tel.: 06-30-2583723
Web: www.kogentum.hu


From martin.morgan at roswellpark.org  Wed Nov 29 23:58:46 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 29 Nov 2017 17:58:46 -0500
Subject: [R] dplyr - add/expand rows
In-Reply-To: <251d3bb5-3a2c-7bbf-9dbb-61eca411e4e7@kogentum.hu>
References: <20171125230059.EC95712E8@hypatia.math.ethz.ch>
 <CAF8bMcb=t36WGCb4_u65OOGrjF33OEgt_WLSGGJg992Kdsccuw@mail.gmail.com>
 <CAGxFJbS-QWOMwmjS3-4PAiLwriGEO_Qh2x7UqCy8_4UQtHXnYA@mail.gmail.com>
 <CAAxdm-4szTX6mevd2GmrVgERNL-ccwzgJoSoFAmJaaOKczQeYA@mail.gmail.com>
 <7610b4a0-42a5-bf5c-a6be-6e4a55c0884e@roswellpark.org>
 <CAOQ5Nyf2HY_TJ3mZ7=4BZ2Og_0LPVFPTZwRc2JoA-cvdNmHHpw@mail.gmail.com>
 <b4d8ba31-e0c8-a242-408b-5fc0475ba19a@kogentum.hu>
 <afe8885e-b8c8-fee8-e1eb-6a0585f67d68@roswellpark.org>
 <251d3bb5-3a2c-7bbf-9dbb-61eca411e4e7@kogentum.hu>
Message-ID: <092c1ba4-b6e9-fdcc-d631-e386c15d5fac@roswellpark.org>

On 11/29/2017 05:47 PM, T?th D?nes wrote:
> Hi Martin,
> 
> On 11/29/2017 10:46 PM, Martin Morgan wrote:
>> On 11/29/2017 04:15 PM, T?th D?nes wrote:
>>> Hi,
>>>
>>> A benchmarking study with an additional (data.table-based) solution. 
>>
>> I don't think speed is the right benchmark (I do agree that 
>> correctness is!).
> 
> Well, agree, and sorry for the wording. It was really just an exercise 
> and not a full evaluation of the approaches. When I read the avalanche 
> of solutions neither of which mentioning data.table (my first choice for 
> data.frame-manipulations), I became curious how a one-liner data.table 
> code performs against the other solutions in terms of speed and 
> readability.
> Second, I quite often have the feeling that dplyr is extremely overused 
> among novice (and sometimes even experienced) R users nowadays. This is 
> unfortunate, as the present example also illustrates.

Another solution is Bill's approach and dplyr's implementation (adding 
the 1L to keep integers integers!)

fun_bill1 <- function(d) {
   i <- rep(seq_len(nrow(d)), d$to - d$from + 1L)
   j <- sequence(d$to - d$from + 1L)
   ## d[i,] %>% mutate(year = from + j - 1L, from = NULL, to = NULL)
   mutate(d[i,], year = from + j - 1L, from = NULL, to = NULL)
}

which is competitive with IRanges and data.table (the more dplyr-ish? 
solution

   d[i, ] %>% mutate(year = from + j - 1L) %>%
       select(station, record, year))

has intermediate performance) and might appeal to those introduced to R 
through dplyr but wanting more base R knowledge, and vice versa. I think 
if dplyr introduces new users to R, or exposes R users to new approaches 
for working with data, that's great!

Martin


> 
> Regards,
> Denes
> 
>>
>> For the R-help list, maybe something about least specialized R 
>> knowledge required would be appropriate? I'd say there were some 
>> 'hard' solutions -- Michael (deep understanding of Bioconductor and 
>> IRanges), Toth (deep understanding of data.table), Jim (at least for 
>> me moderate understanding of dplyr,especially the .$ notation; a 
>> simpler dplyr answer might have moved this response out of the 
>> 'difficult' category, especially given the familiarity of the OP with 
>> dplyr). I'd vote for Bill's as requiring the least specialized 
>> knowledge of R (though the +/- 1 indexing is an easy thing to get wrong).
>>
>> A different criteria might be reuse across analysis scenarios. Bill 
>> seems to win here again, since the principles are very general and at 
>> least moderately efficient (both Bert and Martin's solutions are 
>> essentially R-level iterations and have poor scalability, as 
>> demonstrated in the microbenchmarks; Bill's is mostly vectorized). 
>> Certainly data.table, dplyr, and IRanges are extremely useful within 
>> the confines of the problem domains they address.
>>
>> Martin
>>
>>> Enjoy! ;)
>>>
>>> Cheers,
>>> Denes
>>>
>>>
>>> --------------------------
>>>
>>>
>>> ## packages ##########################
>>>
>>> library(dplyr)
>>> library(data.table)
>>> library(IRanges)
>>> library(microbenchmark)
>>>
>>> ## prepare example dataset ###########
>>>
>>> ## use Bert's example, with 2000 stations instead of 2
>>> d_df <- data.frame( station = rep(rep(c("one","two"),c(5,4)), 1000L),
>>> ???????????????????? from = as.integer(c(60,61,71,72,76,60,65,82,83)),
>>> ???????????????????? to = as.integer(c(60,70,71,76,83,64, 81, 82,83)),
>>> ???????????????????? record = c("A","B","C","B","D","B","B","D","E"),
>>> ???????????????????? stringsAsFactors = FALSE)
>>> stations <- rle(d_df$station)
>>> stations$value <- gsub(
>>> ?? " ", "0",
>>> ?? paste0("station", format(1:length(stations$value), width = 6)))
>>> d_df$station <- rep(stations$value, stations$lengths)
>>>
>>> ## prepare tibble and data.table versions
>>> d_tbl <- as_tibble(d_df)
>>> d_dt <- as.data.table(d_df)
>>>
>>> ## solutions ##########################
>>>
>>> ## Bert - by
>>> fun_bert <- function(d) {
>>> ?? out <- by(
>>> ???? d, d$station, function(x) with(x, {
>>> ?????? i <- to - from +1
>>> ?????? data.frame(record =rep(record,i),
>>> ????????????????? year =sequence(i) -1 + rep(from,i),
>>> ????????????????? stringsAsFactors = FALSE)
>>> ???? }))
>>> ?? data.frame(station = rep(names(out), sapply(out,nrow)),
>>> ????????????? do.call(rbind,out),
>>> ????????????? row.names = NULL,
>>> ????????????? stringsAsFactors = FALSE)
>>> }
>>>
>>> ## Bill - transform
>>> fun_bill <- function(d) {
>>> ?? i <- rep(seq_len(nrow(d)), d$to-d$from+1)
>>> ?? j <- sequence(d$to-d$from+1)
>>> ?? transform(d[i,], year=from+j-1, from=NULL, to=NULL)
>>> }
>>>
>>> ## Michael - IRanges
>>> fun_michael <- function(d) {
>>> ?? df <- with(d, DataFrame(station, record, year=IRanges(from, to)))
>>> ?? expand(df, "year")
>>> }
>>>
>>> ## Jim - dplyr
>>> fun_jim <- function(d) {
>>> ?? d %>%
>>> ???? rowwise() %>%
>>> ???? do(tibble(station = .$station,
>>> ?????????????? record = .$record,
>>> ?????????????? year = seq(.$from, .$to))
>>> ???? )
>>> }
>>>
>>> ## Martin - Map
>>> fun_martin <- function(d) {
>>> ?? d$year <- with(d, Map(seq, from, to))
>>> ?? res0 <- with(d, Map(data.frame,
>>> ?????????????????????? station=station,
>>> ?????????????????????? record=record,
>>> ?????????????????????? year=year,
>>> ?????????????????????? MoreArgs = list(stringsAsFactors = FALSE)))
>>> ?? do.call(rbind, unname(res0))
>>> }
>>>
>>> ## Denes - simple data.table
>>> fun_denes <- function(d) {
>>> ?? out <- d[, .(year = from:to), by = .(station, from, record)]
>>> ?? out[, from := NULL]
>>> }
>>>
>>> ## Check equality ################################
>>> all.equal(fun_bill(d_df), fun_bert(d_df),
>>> ?????????? check.attributes = FALSE)
>>> all.equal(fun_bill(d_df), fun_martin(d_df),
>>> ?????????? check.attributes = FALSE)
>>> all.equal(fun_bill(d_df), as.data.frame(fun_michael(d_df)),
>>> ?????????? check.attributes = FALSE)
>>> all.equal(fun_bill(d_df), as.data.frame(fun_denes(d_dt)),
>>> ?????????? check.attributes = FALSE)
>>> # Be prepared: this solution is super slow
>>> all.equal(fun_bill(d_df), as.data.frame(fun_jim(d_tbl)),
>>> ?????????? check.attributes = FALSE)
>>>
>>> ## Benchmark #####################################
>>>
>>> ## Martin
>>> print(system.time(fun_martin(d_df)))
>>>
>>> ## Bert
>>> print(system.time(fun_bert(d_df)))
>>>
>>> ## Top 3
>>> print(
>>> ?? microbenchmark(
>>> ???? fun_bill(d_df),
>>> ???? fun_michael(d_df),
>>> ???? fun_denes(d_dt),
>>> ???? times = 100L
>>> ?? )
>>> )
>>>
>>>
>>> -------------------------
>>>
>>> On 11/28/2017 06:49 PM, Michael Lawrence wrote:
>>>> Or with the Bioconductor IRanges package:
>>>>
>>>> df <- with(input, DataFrame(station, year=IRanges(from, to), record))
>>>> expand(df, "year")
>>>>
>>>> DataFrame with 24 rows and 3 columns
>>>> ???????? station???? year????? record
>>>> ???? <character> <integer> <character>
>>>> 1?????? 07EA001????? 1960???????? QMS
>>>> 2?????? 07EA001????? 1961???????? QMC
>>>> 3?????? 07EA001????? 1962???????? QMC
>>>> 4?????? 07EA001????? 1963???????? QMC
>>>> 5?????? 07EA001????? 1964???????? QMC
>>>> ...???????? ...?????? ...???????? ...
>>>> 20????? 07EA001????? 1979???????? QRC
>>>> 21????? 07EA001????? 1980???????? QRC
>>>> 22????? 07EA001????? 1981???????? QRC
>>>> 23????? 07EA001????? 1982???????? QRC
>>>> 24????? 07EA001????? 1983???????? QRC
>>>>
>>>> If you tell the computer more about your data, it can do more things 
>>>> for
>>>> you.
>>>>
>>>> Michael
>>>>
>>>> On Tue, Nov 28, 2017 at 7:34 AM, Martin Morgan <
>>>> martin.morgan at roswellpark.org> wrote:
>>>>
>>>>> On 11/26/2017 08:42 PM, jim holtman wrote:
>>>>>
>>>>>> try this:
>>>>>>
>>>>>> ##########################################
>>>>>>
>>>>>> library(dplyr)
>>>>>>
>>>>>> input <- tribble(
>>>>>> ??? ~station, ~from, ~to, ~record,
>>>>>> ?? "07EA001" ,??? 1960? ,? 1960? , "QMS",
>>>>>> ?? "07EA001"? ,?? 1961 ,?? 1970? , "QMC",
>>>>>> ?? "07EA001" ,??? 1971? ,? 1971? , "QMM",
>>>>>> ?? "07EA001" ,??? 1972? ,? 1976? , "QMC",
>>>>>> ?? "07EA001" ,??? 1977? ,? 1983? , "QRC"
>>>>>> )
>>>>>>
>>>>>> result <- input %>%
>>>>>> ??? rowwise() %>%
>>>>>> ??? do(tibble(station = .$station,
>>>>>> ????????????? year = seq(.$from, .$to),
>>>>>> ????????????? record = .$record)
>>>>>> ??? )
>>>>>>
>>>>>> ###########################
>>>>>>
>>>>>
>>>>> In a bit more 'base R' mode I did
>>>>>
>>>>> ?? input$year <- with(input, Map(seq, from, to))
>>>>> ?? res0 <- with(input, Map(data.frame, station=station, year=year,
>>>>> ?????? record=record))
>>>>> ??? as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>>>>
>>>>> resulting in
>>>>>
>>>>>> as_tibble(do.call(rbind, unname(res0)))# A tibble: 24 x 3
>>>>> ??? station? year record
>>>>> ???? <fctr> <int> <fctr>
>>>>> ? 1 07EA001? 1960??? QMS
>>>>> ? 2 07EA001? 1961??? QMC
>>>>> ? 3 07EA001? 1962??? QMC
>>>>> ? 4 07EA001? 1963??? QMC
>>>>> ? 5 07EA001? 1964??? QMC
>>>>> ? 6 07EA001? 1965??? QMC
>>>>> ? 7 07EA001? 1966??? QMC
>>>>> ? 8 07EA001? 1967??? QMC
>>>>> ? 9 07EA001? 1968??? QMC
>>>>> 10 07EA001? 1969??? QMC
>>>>> # ... with 14 more rows
>>>>>
>>>>> I though I should have been able to use `tibble` in the second 
>>>>> step, but
>>>>> that leads to a (cryptic) error
>>>>>
>>>>>> res0 <- with(input, Map(tibble, station=station, year=year,
>>>>> record=record))Error in captureDots(strict = `__quosured`) :
>>>>> ?? the argument has already been evaluated
>>>>>
>>>>> The 'station' and 'record' columns are factors, so different from the
>>>>> original input, but this seems the appropriate data type for theses 
>>>>> columns.
>>>>>
>>>>> It's interesting to compare the 'specialized' knowledge needed for 
>>>>> each
>>>>> approach -- rowwise(), do(), .$ for tidyverse, with(), do.call(), 
>>>>> maybe
>>>>> rbind() and Map() for base R.
>>>>>
>>>>> Martin
>>>>>
>>>>>
>>>>>
>>>>>>
>>>>>>
>>>>>> Jim Holtman
>>>>>> Data Munger Guru
>>>>>>
>>>>>> What is the problem that you are trying to solve?
>>>>>> Tell me what you want to do, not how you want to do it.
>>>>>>
>>>>>> On Sun, Nov 26, 2017 at 2:10 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> To David W.'s point about lack of a suitable reprex ("reproducible
>>>>>>> example"), Bill's solution seems to be for only one station.
>>>>>>>
>>>>>>> Here is a reprex and modification that I think does what was 
>>>>>>> requested
>>>>>>> for
>>>>>>> multiple stations, again using base R and data frames, not dplyr and
>>>>>>> tibbles.
>>>>>>>
>>>>>>> First the reprex with **two** stations:
>>>>>>>
>>>>>>> d <- data.frame( station = rep(c("one","two"),c(5,4)),
>>>>>>>>
>>>>>>> ???????????????? from = c(60,61,71,72,76,60,65,82,83),
>>>>>>> ????????????????? to = c(60,70,71,76,83,64, 81, 82,83),
>>>>>>> ????????????????? record = c("A","B","C","B","D","B","B","D","E"))
>>>>>>>
>>>>>>> d
>>>>>>>>
>>>>>>> ??? station from to record
>>>>>>> 1???? one?? 60 60????? A
>>>>>>> 2???? one?? 61 70????? B
>>>>>>> 3???? one?? 71 71????? C
>>>>>>> 4???? one?? 72 76????? B
>>>>>>> 5???? one?? 76 83????? D
>>>>>>> 6???? two?? 60 64????? B
>>>>>>> 7???? two?? 65 81????? B
>>>>>>> 8???? two?? 82 82????? D
>>>>>>> 9???? two?? 83 83????? E
>>>>>>>
>>>>>>> ## Now the conversion code using base R, especially by():
>>>>>>>
>>>>>>> out <- by(d, d$station, function(x) with(x, {
>>>>>>>>
>>>>>>> +??? i <- to - from +1
>>>>>>> +??? data.frame(YEAR =sequence(i) -1 +rep(from,i), RECORD 
>>>>>>> =rep(record,i))
>>>>>>> + }))
>>>>>>>
>>>>>>>
>>>>>>> out <- data.frame(station =
>>>>>>>>
>>>>>>> rep(names(out),sapply(out,nrow)),do.call(rbind,out), row.names = 
>>>>>>> NULL)
>>>>>>>
>>>>>>>
>>>>>>> out
>>>>>>>>
>>>>>>> ???? station YEAR RECORD
>>>>>>> 1????? one?? 60????? A
>>>>>>> 2????? one?? 61????? B
>>>>>>> 3????? one?? 62????? B
>>>>>>> 4????? one?? 63????? B
>>>>>>> 5????? one?? 64????? B
>>>>>>> 6????? one?? 65????? B
>>>>>>> 7????? one?? 66????? B
>>>>>>> 8????? one?? 67????? B
>>>>>>> 9????? one?? 68????? B
>>>>>>> 10???? one?? 69????? B
>>>>>>> 11???? one?? 70????? B
>>>>>>> 12???? one?? 71????? C
>>>>>>> 13???? one?? 72????? B
>>>>>>> 14???? one?? 73????? B
>>>>>>> 15???? one?? 74????? B
>>>>>>> 16???? one?? 75????? B
>>>>>>> 17???? one?? 76????? B
>>>>>>> 18???? one?? 76????? D
>>>>>>> 19???? one?? 77????? D
>>>>>>> 20???? one?? 78????? D
>>>>>>> 21???? one?? 79????? D
>>>>>>> 22???? one?? 80????? D
>>>>>>> 23???? one?? 81????? D
>>>>>>> 24???? one?? 82????? D
>>>>>>> 25???? one?? 83????? D
>>>>>>> 26???? two?? 60????? B
>>>>>>> 27???? two?? 61????? B
>>>>>>> 28???? two?? 62????? B
>>>>>>> 29???? two?? 63????? B
>>>>>>> 30???? two?? 64????? B
>>>>>>> 31???? two?? 65????? B
>>>>>>> 32???? two?? 66????? B
>>>>>>> 33???? two?? 67????? B
>>>>>>> 34???? two?? 68????? B
>>>>>>> 35???? two?? 69????? B
>>>>>>> 36???? two?? 70????? B
>>>>>>> 37???? two?? 71????? B
>>>>>>> 38???? two?? 72????? B
>>>>>>> 39???? two?? 73????? B
>>>>>>> 40???? two?? 74????? B
>>>>>>> 41???? two?? 75????? B
>>>>>>> 42???? two?? 76????? B
>>>>>>> 43???? two?? 77????? B
>>>>>>> 44???? two?? 78????? B
>>>>>>> 45???? two?? 79????? B
>>>>>>> 46???? two?? 80????? B
>>>>>>> 47???? two?? 81????? B
>>>>>>> 48???? two?? 82????? D
>>>>>>> 49???? two?? 83????? E
>>>>>>>
>>>>>>> Cheers,
>>>>>>> Bert
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Bert Gunter
>>>>>>>
>>>>>>> "The trouble with having an open mind is that people keep coming 
>>>>>>> along
>>>>>>> and
>>>>>>> sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>>
>>>>>>> On Sat, Nov 25, 2017 at 4:49 PM, William Dunlap via R-help <
>>>>>>> r-help at r-project.org> wrote:
>>>>>>>
>>>>>>> dplyr may have something for this, but in base R I think the 
>>>>>>> following
>>>>>>>>
>>>>>>> does
>>>>>>>
>>>>>>>> what you want.? I've shortened the name of your data set to 'd'.
>>>>>>>>
>>>>>>>> i <- rep(seq_len(nrow(d)), d$YEAR_TO-d$YEAR_FROM+1)
>>>>>>>> j <- sequence(d$YEAR_TO-d$YEAR_FROM+1)
>>>>>>>> transform(d[i,], YEAR=YEAR_FROM+j-1, YEAR_FROM=NULL, YEAR_TO=NULL)
>>>>>>>>
>>>>>>>>
>>>>>>>> Bill Dunlap
>>>>>>>> TIBCO Software
>>>>>>>> wdunlap tibco.com
>>>>>>>>
>>>>>>>> On Sat, Nov 25, 2017 at 11:18 AM, Hutchinson, David (EC) <
>>>>>>>> david.hutchinson at canada.ca> wrote:
>>>>>>>>
>>>>>>>> I have a returned tibble of station operational record similar 
>>>>>>>> to the
>>>>>>>>> following:
>>>>>>>>>
>>>>>>>>> data.collection
>>>>>>>>>>
>>>>>>>>> # A tibble: 5 x 4
>>>>>>>>> ??? STATION_NUMBER YEAR_FROM YEAR_TO RECORD
>>>>>>>>> ???????????? <chr>???? <int>?? <int>? <chr>
>>>>>>>>> 1??????? 07EA001????? 1960??? 1960??? QMS
>>>>>>>>> 2??????? 07EA001????? 1961??? 1970??? QMC
>>>>>>>>> 3??????? 07EA001????? 1971??? 1971??? QMM
>>>>>>>>> 4??????? 07EA001????? 1972??? 1976??? QMC
>>>>>>>>> 5??????? 07EA001????? 1977??? 1983??? QRC
>>>>>>>>>
>>>>>>>>> I would like to reshape this to one operational record (row) 
>>>>>>>>> per year
>>>>>>>>>
>>>>>>>> per
>>>>>>>
>>>>>>>> station. Something like:
>>>>>>>>>
>>>>>>>>> 07EA001????????????? 1960????? QMS
>>>>>>>>> 07EA001????????????? 1961????? QMC
>>>>>>>>> 07EA001????????????? 1962????? QMC
>>>>>>>>> 07EA001????????????? 1963????? QMC
>>>>>>>>> ...
>>>>>>>>> 07EA001????????????? 1971????? QMM
>>>>>>>>>
>>>>>>>>> Can this be done in dplyr easily?
>>>>>>>>>
>>>>>>>>> Thanks in advance,
>>>>>>>>>
>>>>>>>>> David
>>>>>>>>>
>>>>>>>>> ????????? [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>>>> posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>>
>>>>>>>>>
>>>>>>>> ????????? [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>>> posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>>
>>>>>>> ????????? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>> posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>> ???????? [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>>> ng-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>
>>>>> This email message may contain legally privileged 
>>>>> and/or...{{dropped:2}}
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ??? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>>
>> This email message may contain legally privileged and/or confidential 
>> information.? If you are not the intended recipient(s), or the 
>> employee or agent responsible for the delivery of this message to the 
>> intended recipient(s), you are hereby notified that any disclosure, 
>> copying, distribution, or use of this email message is prohibited.? If 
>> you have received this message in error, please notify the sender 
>> immediately by e-mail and delete this email message from your 
>> computer. Thank you.
>>
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From drjimlemon at gmail.com  Thu Nov 30 00:54:53 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Nov 2017 10:54:53 +1100
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
Message-ID: <CA+8X3fXU300O-R2KTZw2GpoWWnWvMS4htqvdBySOudVrrTG6hg@mail.gmail.com>

Hi Robert,
People want different levels of automation in the software they use.
What concerns many of us is the desire for the function
"figure-out-what-this-data-is-import-it-and-get-rid-of-bad-values".
Such users typically want something that justifies its use by being
written by someone who seems to know what they're doing and lots of
other people use it. One advantage of many R functions is their
modular construction. This encourages users to at least consider the
steps that are taken rather than just accept what comes out of that
long tube.

Take the contentious problem of outlier identification. If I just let
the black box peel off some values, I don't know what I have lost. On
the other hand, if I import data and examine it with a summary
function, I may find that one woman has a height of 5.2 meters. I can
range check by looking up the Guinness Book of Records. It's an
outlier. I can estimate the probability of such a height.  Hmm, about
4 standard deviations above the mean. It's an outlier. I can attempt a
Sherlock Holmes. "Watson, I conclude that an imperial measure (5'2")
has been recorded as a metric value". It's not an outlier.

The more R gravitates toward "black box" functions, the more some
users are encouraged to let them do the work.You pays your money and
you takes your chances.

Jim


On Thu, Nov 30, 2017 at 3:37 AM, Robert Wilkins <iwritecode2 at gmail.com> wrote:
> R has a very wide audience, clinical research, astronomy, psychology, and
> so on and so on.
> I would consider data analysis work to be three stages: data preparation,
> statistical analysis, and producing the report.
> This regards the process of getting the data ready for analysis and
> reporting, sometimes called "data cleaning" or "data munging" or "data
> wrangling".
>
> So as regards tools for data preparation, speaking to the highly diverse
> audience mentioned, here is my question:
>
> What do you want?
> Or are you already quite happy with the range of tools that is currently
> before you?
>
> [BTW,  I posed the same question last week to the r-devel list, and was
> advised that r-help might be a more suitable audience by one of the
> moderators.]
>
> Robert Wilkins
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Nov 30 01:00:46 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Nov 2017 11:00:46 +1100
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <CA+8X3fXU300O-R2KTZw2GpoWWnWvMS4htqvdBySOudVrrTG6hg@mail.gmail.com>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
 <CA+8X3fXU300O-R2KTZw2GpoWWnWvMS4htqvdBySOudVrrTG6hg@mail.gmail.com>
Message-ID: <CA+8X3fXHb_OcMYJd9B9=5TsZTpmMbBgwF85T-Z3uhyXL7VxJrw@mail.gmail.com>

Hi again,
Typo in the last email. Should read "about 40 standard deviations".

Jim

On Thu, Nov 30, 2017 at 10:54 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Robert,
> People want different levels of automation in the software they use.
> What concerns many of us is the desire for the function
> "figure-out-what-this-data-is-import-it-and-get-rid-of-bad-values".
> Such users typically want something that justifies its use by being
> written by someone who seems to know what they're doing and lots of
> other people use it. One advantage of many R functions is their
> modular construction. This encourages users to at least consider the
> steps that are taken rather than just accept what comes out of that
> long tube.
>
> Take the contentious problem of outlier identification. If I just let
> the black box peel off some values, I don't know what I have lost. On
> the other hand, if I import data and examine it with a summary
> function, I may find that one woman has a height of 5.2 meters. I can
> range check by looking up the Guinness Book of Records. It's an
> outlier. I can estimate the probability of such a height.  Hmm, about
> 4 standard deviations above the mean. It's an outlier. I can attempt a
> Sherlock Holmes. "Watson, I conclude that an imperial measure (5'2")
> has been recorded as a metric value". It's not an outlier.
>
> The more R gravitates toward "black box" functions, the more some
> users are encouraged to let them do the work.You pays your money and
> you takes your chances.
>
> Jim
>
>
> On Thu, Nov 30, 2017 at 3:37 AM, Robert Wilkins <iwritecode2 at gmail.com> wrote:
>> R has a very wide audience, clinical research, astronomy, psychology, and
>> so on and so on.
>> I would consider data analysis work to be three stages: data preparation,
>> statistical analysis, and producing the report.
>> This regards the process of getting the data ready for analysis and
>> reporting, sometimes called "data cleaning" or "data munging" or "data
>> wrangling".
>>
>> So as regards tools for data preparation, speaking to the highly diverse
>> audience mentioned, here is my question:
>>
>> What do you want?
>> Or are you already quite happy with the range of tools that is currently
>> before you?
>>
>> [BTW,  I posed the same question last week to the r-devel list, and was
>> advised that r-help might be a more suitable audience by one of the
>> moderators.]
>>
>> Robert Wilkins
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Nov 30 01:06:57 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 29 Nov 2017 16:06:57 -0800
Subject: [R] 2^3 confounded factorial experiment
In-Reply-To: <5a1eec53.4b77630a.a7290.94d3@mx.google.com>
References: <5a1eec53.4b77630a.a7290.94d3@mx.google.com>
Message-ID: <25E41473-8863-4DB6-9114-244A03C8EF26@comcast.net>


> On Nov 29, 2017, at 9:20 AM, Jyoti Bhogal <jyotibga2 at gmail.com> wrote:
> 
> The following R commands were written:
>> help.search("factorial")
>> data(npk)
>> npk
>> coef(npk.aov)
> 
> In the output of coef command, please explain me the interpretation of coefficients of block1 to block 6 in this 2^3 confounded factorial experiment.

This is very much a statistics question and as such is off-topic (as it also would be off-topic on StackOverflow.) Rhelp is for persons having difficulty coding the R language itself.

Consider CrossValidated.com but read their posting help section first since this is really very terse question. Better would be to include the output and make your best interpretation so peolple get the sense you at least put in some individual effort.

> 
> Thanks.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From calandra at rgzm.de  Thu Nov 30 08:52:53 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Thu, 30 Nov 2017 08:52:53 +0100
Subject: [R] Removing a data subset
In-Reply-To: <CACftpvoBJurz0Tq0ET76f_GU+72E0uwQBAaW3ph7W6iFOKOoqQ@mail.gmail.com>
References: <CACftpvoBJurz0Tq0ET76f_GU+72E0uwQBAaW3ph7W6iFOKOoqQ@mail.gmail.com>
Message-ID: <4a0dec2d-9121-38ec-db34-136b4a1d5b40@rgzm.de>

Hi David,

You "just" need to learn how to subset your data.frame, see functions 
like ?subset and ?"[", as well as a good guide to understand the subtleties!

Some graphic functions also have a built-in argument to subset within 
the function (e.g. argument 'subset' in 'plot.formula'), although the 
ggplot() function doesn't seem to have it.

In any case, I would recommend you spend some time learning that aspect, 
as you will always need it in one situation or another.

HTH,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 29/11/2017 22:07, David Doyle wrote:
> Say I have a dataset that looks like
>
> Location    Year      GW_Elv
> MW01        1999       546.63
> MW02        1999       474.21
> MW03        1999       471.94
> MW04        1999        466.80
> MW01        2000        545.90
> MW02        2000        546.10
>
> The whole dataset is at http://doylesdartden.com/ExampleData.csv
> and I use the code below to do the graph but I want to do it without MW01.
> How can I remove MW01??
>
> I'm sure I can do it by SubSeting but I can not figure out how to do it.
>
> Thank you
> David
>
> --------------------------------------------------------------
>
> library(ggplot2)
>
> MyData <- read.csv("http://doylesdartden.com/ExampleData.csv", header=TRUE,
> sep=",")
>
>
>
> #Sets whic are detections and nondetects
> MyData$Detections <- ifelse(MyData$D_GW_Elv ==1, "Detected", "NonDetect")
>
> #Removes the NAs
> MyDataWONA <- MyData[!is.na(MyData$Detections), ]
>
> #does the plot
> p <- ggplot(data = MyDataWONA, aes(x=Year, y=GW_Elv , col=Detections)) +
>    geom_point(aes(shape=Detections)) +
>
>    ##sets the colors
>    scale_colour_manual(values=c("black","red")) + #scale_y_log10() +
>
>    #location of the legend
>    theme(legend.position=c("right")) +
>
>    #sets the line color, type and size
>    geom_line(colour="black", linetype="dotted", size=0.5) +
>    ylab("Elevation Feet Mean Sea Level")
>
> ## does the graph using the Location IDs as the different Locations.
> p + facet_grid(Location ~ .)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dominik.schneider at colorado.edu  Thu Nov 30 10:11:02 2017
From: dominik.schneider at colorado.edu (Dominik Schneider)
Date: Thu, 30 Nov 2017 10:11:02 +0100
Subject: [R] Data cleaning & Data preparation, what do R users want?
In-Reply-To: <CA+8X3fXHb_OcMYJd9B9=5TsZTpmMbBgwF85T-Z3uhyXL7VxJrw@mail.gmail.com>
References: <CAGW5CW9iGfDpLBu89Soe_81JUBZo86pfxAj+ynfPxdVA+8WBkQ@mail.gmail.com>
 <CA+8X3fXU300O-R2KTZw2GpoWWnWvMS4htqvdBySOudVrrTG6hg@mail.gmail.com>
 <CA+8X3fXHb_OcMYJd9B9=5TsZTpmMbBgwF85T-Z3uhyXL7VxJrw@mail.gmail.com>
Message-ID: <CAF1jk_=S4PatyvoR8tUys5d8gJxyEVnbu9WTZ17MQtS2_N_01g@mail.gmail.com>

I would agree that getting data into R from various sources is the biggest
pain point. Even if there is an api, the results are not always consistent
and you have to do lots of dimension checking to get it right. Or there
isn't an open api at all and you have to hack it by web scraping or
otherwise- http://enpiar.com/2017/08/11/one-hour-package/

On Thu, Nov 30, 2017 at 1:00 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi again,
> Typo in the last email. Should read "about 40 standard deviations".
>
> Jim
>
> On Thu, Nov 30, 2017 at 10:54 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi Robert,
> > People want different levels of automation in the software they use.
> > What concerns many of us is the desire for the function
> > "figure-out-what-this-data-is-import-it-and-get-rid-of-bad-values".
> > Such users typically want something that justifies its use by being
> > written by someone who seems to know what they're doing and lots of
> > other people use it. One advantage of many R functions is their
> > modular construction. This encourages users to at least consider the
> > steps that are taken rather than just accept what comes out of that
> > long tube.
> >
> > Take the contentious problem of outlier identification. If I just let
> > the black box peel off some values, I don't know what I have lost. On
> > the other hand, if I import data and examine it with a summary
> > function, I may find that one woman has a height of 5.2 meters. I can
> > range check by looking up the Guinness Book of Records. It's an
> > outlier. I can estimate the probability of such a height.  Hmm, about
> > 4 standard deviations above the mean. It's an outlier. I can attempt a
> > Sherlock Holmes. "Watson, I conclude that an imperial measure (5'2")
> > has been recorded as a metric value". It's not an outlier.
> >
> > The more R gravitates toward "black box" functions, the more some
> > users are encouraged to let them do the work.You pays your money and
> > you takes your chances.
> >
> > Jim
> >
> >
> > On Thu, Nov 30, 2017 at 3:37 AM, Robert Wilkins <iwritecode2 at gmail.com>
> wrote:
> >> R has a very wide audience, clinical research, astronomy, psychology,
> and
> >> so on and so on.
> >> I would consider data analysis work to be three stages: data
> preparation,
> >> statistical analysis, and producing the report.
> >> This regards the process of getting the data ready for analysis and
> >> reporting, sometimes called "data cleaning" or "data munging" or "data
> >> wrangling".
> >>
> >> So as regards tools for data preparation, speaking to the highly diverse
> >> audience mentioned, here is my question:
> >>
> >> What do you want?
> >> Or are you already quite happy with the range of tools that is currently
> >> before you?
> >>
> >> [BTW,  I posed the same question last week to the r-devel list, and was
> >> advised that r-help might be a more suitable audience by one of the
> >> moderators.]
> >>
> >> Robert Wilkins
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Thu Nov 30 10:56:18 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 30 Nov 2017 09:56:18 +0000
Subject: [R] R 3.4.3 is released
Message-ID: <53ED0ECA-CE49-4CFB-93E6-8967C83F4492@cbs.dk>

The build system rolled up R-3.4.3.tar.gz (codename "Kite-Eating Tree") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.4.3.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard



These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = f12a9c3881197b20b08dd3d1f9d005e6
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 32a94aba902b293cf8b8dbbf4113f2ab
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = cd01b91d7a7acd614ad72bd571bf26b3
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 71562183d75dd2080d86c42bbf733bb7
MD5 (R-latest.tar.gz) = bc55db54f992fda9049201ca62d2a584
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f60d286bb7294cef00cb0eed4052a66f
MD5 (VERSION-INFO.dcf) = 2f9cc25704594a615a8c8248d0dcd804
MD5 (R-3/R-3.4.3.tar.gz) = bc55db54f992fda9049201ca62d2a584

6474d9791fff6a74936296bde3fcb569477f5958e4326189bd6e5ab878e0cd4f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
7936facb07e752869342808b9c8879d0e270b1a9ec92b67ef4dd87496abfef0a  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
97a082deb0a67a341f2c88a881c56a409a81c1af697732c3b15d8226d3970231  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
a10f84be31f897456a31d31690df2fdc3f21a197f28b4d04332cc85005dcd0d2  NEWS.2
7a3cb831de5b4151e1f890113ed207527b7d4b16df9ec6b35e0964170007f426  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
52f934a4e8581945cbc1ba234932749066b5744cbd3b1cb467ba6ef164975163  THANKS
598f9c6b562c7106f741b9cdc2cc7d0bae364645f103e6ecb49e57625e28308b  VERSION-INFO.dcf
7a3cb831de5b4151e1f890113ed207527b7d4b16df9ec6b35e0964170007f426  R-3/R-3.4.3.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 3.4.3:

  INSTALLATION on a UNIX-ALIKE:

    * A workaround has been added for the changes in location of
      time-zone files in macOS 10.13 'High Sierra' and again in
      10.13.1, so the default time zone is deduced correctly from the
      system setting when R is configured with --with-internal-tzcode
      (the default on macOS).

    * R CMD javareconf has been updated to recognize the use of a Java
      9 SDK on macOS.

  BUG FIXES:

    * raw(0) & raw(0) and raw(0) | raw(0) again return raw(0) (rather
      than logical(0)).

    * intToUtf8() converts integers corresponding to surrogate code
      points to NA rather than invalid UTF-8, as well as values larger
      than the current Unicode maximum of 0x10FFFF.  (This aligns with
      the current RFC3629.)

    * Fix calling of methods on S4 generics that dispatch on ... when
      the call contains ....

    * Following Unicode 'Corrigendum 9', the UTF-8 representations of
      U+FFFE and U+FFFF are now regarded as valid by utf8ToInt().

    * range(c(TRUE, NA), finite = TRUE) and similar no longer return
      NA. (Reported by Lukas Stadler.)

    * The self starting function attr(SSlogis, "initial") now also
      works when the y values have exact minimum zero and is slightly
      changed in general, behaving symmetrically in the y range.

    * The printing of named raw vectors is now formatted nicely as for
      other such atomic vectors, thanks to Lukas Stadler.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From traxplayer at gmail.com  Thu Nov 30 15:27:55 2017
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 30 Nov 2017 15:27:55 +0100
Subject: [R] Help avoiding setting column type two times
Message-ID: <CAGAA5bfn4aczf3+ohP9BjC8c4AY7+-ReQW-G7nKZpnO-S_RrNQ@mail.gmail.com>

Hi,
  I think and hope this a good place to ask for code review for a R
beginners?

  I have made a R script which generates a dataset based on 2009 danish
referendum and it does work.

  But I think the code could be better and I would any comments how the
code can be improved.
  At least I would like to know how I avoid converting several of the
columns to factors in the end of the code?

Description of the code:

  It reads a lot of xml-files from ../raw/ and saves a data.frame with
information
from these xml-files.

  In the ../raw/ directiory I have placed the xml-files which I got from
"Statistics Denmark"
  I have also put these xml-files on my website and they can be download
freely from http://20dage.dk/R/referendum-2009/raw.tar.gz

  The code is below but I have also put the code at this place:
http://20dage.dk/R/referendum-2009/convert_from_xml.R

Best Regards
Martin M. S. Pedersen

-------
library(xml2)

convert_one_file <- function(url) {
    x <- read_xml(url)

    Sted <- xml_find_first(x, ".//Sted")
    StedType <- xml_attr(Sted, "Type")
    StedTekst <- xml_text(Sted)

    Parti <- xml_find_all(x, ".//Parti")
    PartiId <- xml_attr(Parti, "Id")
    PartiBogstav <- xml_attr(Parti, "Bogstav")
    PartiNavn <- xml_attr(Parti, "Navn")


    StemmerAntal <- xml_attr(Parti, "StemmerAntal")
    Stemmeberettigede <- xml_integer(xml_find_first(x,
".//Stemmeberettigede"))
    DeltagelsePct <- xml_double(xml_find_first(x, ".//DeltagelsePct"))
    IAltGyldigeStemmer <- xml_integer(xml_find_first(x,
".//IAltGyldigeStemmer"))
    BlankeStemmer <- xml_integer(xml_find_first(x, ".//BlankeStemmer"))
    AndreUgyldigeStemmer <- xml_integer(xml_find_first(x,
".//AndreUgyldigeStemmer"))

    data.frame(cbind(StedType, StedTekst, PartiId, PartiBogstav, PartiNavn,
                 StemmerAntal, Stemmeberettigede, DeltagelsePct,
IAltGyldigeStemmer,
       BlankeStemmer, AndreUgyldigeStemmer), stringsAsFactors = FALSE)
}

raw_path <- "../raw"
filenames <- dir(path = raw_path, pattern = "fintal_.*", full.names = T)

result <- data.frame(StedType = factor(),
                     StedTekst = character(),
                     PartiId   = factor(),
                     PartiBogstav = factor(),
                     PartiNavn    = factor(),
                     StemmerAntal = integer(),
                     Stemmeberettigede = integer(),
                     DeltagelsePct = numeric(),
                     IAltGyldigeStemmer = integer(),
                     BlankeStemmer = integer(),
                     AndreUgyldigeStemmer = integer(),
                     stringsAsFactors = FALSE)

for (i in 1:length(filenames)) {
    #cat(paste0(filenames[i],"\n"))
    returnCode <-  tryCatch({
       result <- rbind(result, convert_one_file(filenames[i]))
    }, error = function(e) {
       cat(paste0(filenames[i]," failed:\n",e,"\n"))
    })
}

result$StedType <- as.factor(result$StedType)
result$PartiId <- as.factor(result$PartiId)
result$PartiBogstav <- as.factor(result$PartiBogstav)
result$PartiNavn <- as.factor(result$PartiNavn)
result$StemmerAntal <- as.integer(result$StemmerAntal)
result$Stemmeberettigede <- as.integer(result$Stemmeberettigede)
result$DeltagelsePct <- as.numeric(result$DeltagelsePct)
result$IAltGyldigeStemmer <- as.integer(result$IAltGyldigeStemmer)
result$BlankeStemmer <- as.integer(result$BlankeStemmer)
result$AndreUgyldigeStemmer <- as.integer(result$AndreUgyldigeStemmer)
str(result)
save(result, file = "folkeafstemning2009.Rdata")

	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Thu Nov 30 15:33:51 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 30 Nov 2017 15:33:51 +0100
Subject: [R] Help avoiding setting column type two times
In-Reply-To: <CAGAA5bfn4aczf3+ohP9BjC8c4AY7+-ReQW-G7nKZpnO-S_RrNQ@mail.gmail.com>
References: <CAGAA5bfn4aczf3+ohP9BjC8c4AY7+-ReQW-G7nKZpnO-S_RrNQ@mail.gmail.com>
Message-ID: <7baa28a8-9bb8-5ac3-08ff-6f1ef1750ecd@math.uni-giessen.de>

See below.

Am 30.11.2017 um 15:27 schrieb Martin M?ller Skarbiniks Pedersen:
> Hi,
>    I think and hope this a good place to ask for code review for a R
> beginners?
> 
>    I have made a R script which generates a dataset based on 2009 danish
> referendum and it does work.
> 
>    But I think the code could be better and I would any comments how the
> code can be improved.
>    At least I would like to know how I avoid converting several of the
> columns to factors in the end of the code?
> 
> Description of the code:
> 
>    It reads a lot of xml-files from ../raw/ and saves a data.frame with
> information
> from these xml-files.
> 
>    In the ../raw/ directiory I have placed the xml-files which I got from
> "Statistics Denmark"
>    I have also put these xml-files on my website and they can be download
> freely from http://20dage.dk/R/referendum-2009/raw.tar.gz
> 
>    The code is below but I have also put the code at this place:
> http://20dage.dk/R/referendum-2009/convert_from_xml.R
> 
> Best Regards
> Martin M. S. Pedersen
> 
> -------
> library(xml2)
> 
> convert_one_file <- function(url) {
>      x <- read_xml(url)
> 
>      Sted <- xml_find_first(x, ".//Sted")
>      StedType <- xml_attr(Sted, "Type")
>      StedTekst <- xml_text(Sted)
> 
>      Parti <- xml_find_all(x, ".//Parti")
>      PartiId <- xml_attr(Parti, "Id")
>      PartiBogstav <- xml_attr(Parti, "Bogstav")
>      PartiNavn <- xml_attr(Parti, "Navn")
> 
> 
>      StemmerAntal <- xml_attr(Parti, "StemmerAntal")
>      Stemmeberettigede <- xml_integer(xml_find_first(x,
> ".//Stemmeberettigede"))
>      DeltagelsePct <- xml_double(xml_find_first(x, ".//DeltagelsePct"))
>      IAltGyldigeStemmer <- xml_integer(xml_find_first(x,
> ".//IAltGyldigeStemmer"))
>      BlankeStemmer <- xml_integer(xml_find_first(x, ".//BlankeStemmer"))
>      AndreUgyldigeStemmer <- xml_integer(xml_find_first(x,
> ".//AndreUgyldigeStemmer"))
> 
>      data.frame(cbind(StedType, StedTekst, PartiId, PartiBogstav, PartiNavn,
>                   StemmerAntal, Stemmeberettigede, DeltagelsePct,
> IAltGyldigeStemmer,
>         BlankeStemmer, AndreUgyldigeStemmer), stringsAsFactors = FALSE)
> }
> 
> raw_path <- "../raw"
> filenames <- dir(path = raw_path, pattern = "fintal_.*", full.names = T)
> 
> result <- data.frame(StedType = factor(),
>                       StedTekst = character(),
>                       PartiId   = factor(),
>                       PartiBogstav = factor(),
>                       PartiNavn    = factor(),
>                       StemmerAntal = integer(),
>                       Stemmeberettigede = integer(),
>                       DeltagelsePct = numeric(),
>                       IAltGyldigeStemmer = integer(),
>                       BlankeStemmer = integer(),
>                       AndreUgyldigeStemmer = integer(),
>                       stringsAsFactors = FALSE)
> 
> for (i in 1:length(filenames)) {
>      #cat(paste0(filenames[i],"\n"))
>      returnCode <-  tryCatch({
>         result <- rbind(result, convert_one_file(filenames[i]))
>      }, error = function(e) {
>         cat(paste0(filenames[i]," failed:\n",e,"\n"))
>      })
> }
> 
> result$StedType <- as.factor(result$StedType)
> result$PartiId <- as.factor(result$PartiId)
> result$PartiBogstav <- as.factor(result$PartiBogstav)
> result$PartiNavn <- as.factor(result$PartiNavn)
> result$StemmerAntal <- as.integer(result$StemmerAntal)
> result$Stemmeberettigede <- as.integer(result$Stemmeberettigede)
> result$DeltagelsePct <- as.numeric(result$DeltagelsePct)
> result$IAltGyldigeStemmer <- as.integer(result$IAltGyldigeStemmer)
> result$BlankeStemmer <- as.integer(result$BlankeStemmer)
> result$AndreUgyldigeStemmer <- as.integer(result$AndreUgyldigeStemmer)
> str(result)
> save(result, file = "folkeafstemning2009.Rdata")

Maybe two loops simplify this a little bit for you (not tested):

for(v in c("StedType", <etc.>))
  result[[v]] <- factor(result[[v]])

for(v in c("StemmerAntal", <etc.>))
  result[[v]] <- as.integer(result[[v]])

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Nov 30 17:23:37 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 30 Nov 2017 08:23:37 -0800
Subject: [R] Help avoiding setting column type two times
In-Reply-To: <CAGAA5bfn4aczf3+ohP9BjC8c4AY7+-ReQW-G7nKZpnO-S_RrNQ@mail.gmail.com>
References: <CAGAA5bfn4aczf3+ohP9BjC8c4AY7+-ReQW-G7nKZpnO-S_RrNQ@mail.gmail.com>
Message-ID: <54939B2F-AAFB-468A-8D9C-CD143AA883D4@comcast.net>


> On Nov 30, 2017, at 6:27 AM, Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
> 
> Hi,
>  I think and hope this a good place to ask for code review for a R
> beginners?
> 
>  I have made a R script which generates a dataset based on 2009 danish
> referendum and it does work.
> 
>  But I think the code could be better and I would any comments how the
> code can be improved.
>  At least I would like to know how I avoid converting several of the
> columns to factors in the end of the code?
> 
> Description of the code:
> 
>  It reads a lot of xml-files from ../raw/ and saves a data.frame with
> information
> from these xml-files.
> 
>  In the ../raw/ directiory I have placed the xml-files which I got from
> "Statistics Denmark"
>  I have also put these xml-files on my website and they can be download
> freely from http://20dage.dk/R/referendum-2009/raw.tar.gz
> 
>  The code is below but I have also put the code at this place:
> http://20dage.dk/R/referendum-2009/convert_from_xml.R
> 
> Best Regards
> Martin M. S. Pedersen
> 
> -------
> library(xml2)
> 
> convert_one_file <- function(url) {
>    x <- read_xml(url)
> 
>    Sted <- xml_find_first(x, ".//Sted")
>    StedType <- xml_attr(Sted, "Type")
>    StedTekst <- xml_text(Sted)
> 
>    Parti <- xml_find_all(x, ".//Parti")
>    PartiId <- xml_attr(Parti, "Id")
>    PartiBogstav <- xml_attr(Parti, "Bogstav")
>    PartiNavn <- xml_attr(Parti, "Navn")
> 
> 
>    StemmerAntal <- xml_attr(Parti, "StemmerAntal")
>    Stemmeberettigede <- xml_integer(xml_find_first(x,
> ".//Stemmeberettigede"))
>    DeltagelsePct <- xml_double(xml_find_first(x, ".//DeltagelsePct"))
>    IAltGyldigeStemmer <- xml_integer(xml_find_first(x,
> ".//IAltGyldigeStemmer"))
>    BlankeStemmer <- xml_integer(xml_find_first(x, ".//BlankeStemmer"))
>    AndreUgyldigeStemmer <- xml_integer(xml_find_first(x,
> ".//AndreUgyldigeStemmer"))
> 
>    data.frame(cbind(StedType, StedTekst, PartiId, PartiBogstav, PartiNavn,
>                 StemmerAntal, Stemmeberettigede, DeltagelsePct,
> IAltGyldigeStemmer,
>       BlankeStemmer, AndreUgyldigeStemmer), stringsAsFactors = FALSE)

The construction `data.frame(cbind( ...` is a serious source of potential error. The cbind coerces to matrix class which also then coerces to a single atomic class, either numeric or character. Factors loose all their meaning. Dates get messed up. Error ensues. Better would be:

 data.frame( StedType, StedTekst, PartiId, PartiBogstav, PartiNavn,
             StemmerAntal, Stemmeberettigede, DeltagelsePct,
             IAltGyldigeStemmer, BlankeStemmer, AndreUgyldigeStemmer,
             stringsAsFactors = FALSE)

-- 
David.


> }
> 
> raw_path <- "../raw"
> filenames <- dir(path = raw_path, pattern = "fintal_.*", full.names = T)
> 
> result <- data.frame(StedType = factor(),
>                     StedTekst = character(),
>                     PartiId   = factor(),
>                     PartiBogstav = factor(),
>                     PartiNavn    = factor(),
>                     StemmerAntal = integer(),
>                     Stemmeberettigede = integer(),
>                     DeltagelsePct = numeric(),
>                     IAltGyldigeStemmer = integer(),
>                     BlankeStemmer = integer(),
>                     AndreUgyldigeStemmer = integer(),
>                     stringsAsFactors = FALSE)
> 
> for (i in 1:length(filenames)) {
>    #cat(paste0(filenames[i],"\n"))
>    returnCode <-  tryCatch({
>       result <- rbind(result, convert_one_file(filenames[i]))
>    }, error = function(e) {
>       cat(paste0(filenames[i]," failed:\n",e,"\n"))
>    })
> }
> 
> result$StedType <- as.factor(result$StedType)
> result$PartiId <- as.factor(result$PartiId)
> result$PartiBogstav <- as.factor(result$PartiBogstav)
> result$PartiNavn <- as.factor(result$PartiNavn)
> result$StemmerAntal <- as.integer(result$StemmerAntal)
> result$Stemmeberettigede <- as.integer(result$Stemmeberettigede)
> result$DeltagelsePct <- as.numeric(result$DeltagelsePct)
> result$IAltGyldigeStemmer <- as.integer(result$IAltGyldigeStemmer)
> result$BlankeStemmer <- as.integer(result$BlankeStemmer)
> result$AndreUgyldigeStemmer <- as.integer(result$AndreUgyldigeStemmer)
> str(result)
> save(result, file = "folkeafstemning2009.Rdata")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From christian.roever at med.uni-goettingen.de  Thu Nov 30 08:50:45 2017
From: christian.roever at med.uni-goettingen.de (=?utf-8?B?UsO2dmVyLCBDaHJpc3RpYW4=?=)
Date: Thu, 30 Nov 2017 07:50:45 +0000
Subject: [R] [R-pkgs] bayesmeta 2.0 released
Message-ID: <1512028245.4722.68.camel@med.uni-goettingen.de>

Dear R users,

a new version (2.0) of the "bayesmeta" package for Bayesian random-
effects meta-analysis is now available on CRAN; see here:

??http://cran.r-project.org/package=bayesmeta

Along with the package now comes an extensive introduction to the topic
as well as the use of the package (also included as a package
vignette); see here:

??Bayesian random-effects meta-analysis using the bayesmeta R package
??http://arxiv.org/abs/1711.08683

Comments/questions/suggestions/... are, as always, welcome.

Happy meta-analysing,

Christian R?ver
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From kydaviddoyle at gmail.com  Thu Nov 30 17:50:36 2017
From: kydaviddoyle at gmail.com (David Doyle)
Date: Thu, 30 Nov 2017 10:50:36 -0600
Subject: [R] Removing a data subset
In-Reply-To: <2264810.4gBqtGvG0X@nizza>
References: <CACftpvoBJurz0Tq0ET76f_GU+72E0uwQBAaW3ph7W6iFOKOoqQ@mail.gmail.com>
 <2264810.4gBqtGvG0X@nizza>
Message-ID: <CACftpvqR47Rb=W+=jBW0WO=gYPQf5VwXXgzpv8YKC3Tnp=gXbQ@mail.gmail.com>

Thank Rainer and Jim!!

The end result was:
#Makes a new data set name "MyData_Minus_MW01" that contains all the data
where the Location Column is not equal to MW01 and the comma after that
ensures that all columns are copied into the amended data.frame.
MyData_Minus_MW01 <- MyData[ MyData$Location != "MW01", ]


The final code is as follows:

#Loads ggplot2
library(ggplot2)

#Loads data from internet and names it MyData
MyData <- read.csv( "http://doylesdartden.com/ExampleData.csv", header =
TRUE, stringsAsFactors = FALSE )

#Makes a new data set name "MyData_Minus_MW01" that contains all the data
where the Location Column is not equal to MW01 and the comma after that
ensures that all columns are copied into the amended data.frame.
MyData_Minus_MW01 <- MyData[ MyData$Location != "MW01", ]

#Sets whic are detections and nondetects
MyData_Minus_MW01$Detections <- ifelse(MyData_Minus_MW01$D_GW_Elv ==1,
"Detected", "NonDetect")

#Removes the NAs
MyData_Minus_MW01WONA <-
MyData_Minus_MW01[!is.na(MyData_Minus_MW01$Detections),
]

#does the plot
p <- ggplot(data = MyData_Minus_MW01WONA, aes(x=Year, y=GW_Elv ,
col=Detections)) +
  geom_point(aes(shape=Detections)) +

  ##sets the colors
  scale_colour_manual(values=c("black","red")) + #scale_y_log10() +

  #location of the legend
  theme(legend.position=c("right")) +

  #sets the line color, type and size
  geom_line(colour="black", linetype="dotted", size=0.5) +
  ylab("Elevation Feet Mean Sea Level")

## does the graph using the Location IDs as the different Locations.
p + facet_grid(Location ~ .)


Thanks again
David

	[[alternative HTML version deleted]]


From ryan-peterson at uiowa.edu  Wed Nov 29 19:39:58 2017
From: ryan-peterson at uiowa.edu (Peterson, Ryan A)
Date: Wed, 29 Nov 2017 18:39:58 +0000
Subject: [R] [R-pkgs] New package - bestNormalize
Message-ID: <MWHPR04MB1040325B5FB68C8ABCE31AC1E83B0@MWHPR04MB1040.namprd04.prod.outlook.com>

Hi R enthusiasts,


I am happy to announce a new package available on CRAN, bestNormalize (https://cran.r-project.org/web/packages/bestNormalize/). bestNormalize can be used for estimating a suite of normalizing transformations, including a new technique based on ranks which can guarantee normally distributed transformed data if there are no ties: ordered quantile normalization. The package is built to estimate the best normalizing transformation for a vector consistently and accurately. It implements the Box-Cox transformation, the Yeo-Johnson transformation, three types of Lambert WxF transformations, and the ordered quantile normalization transformation.


See the package vignette for a guide on how to use the package, as well as an application to some (included) scraped Autotrader data.


If you encounter any issues or would like to make contributions, please do so via the package's GitHub page: https://github.com/petersonR/bestNormalize

Ryan Peterson



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From proccontents at gmail.com  Thu Nov 30 21:50:19 2017
From: proccontents at gmail.com (SAS_learner)
Date: Thu, 30 Nov 2017 14:50:19 -0600
Subject: [R] Fwd: Wanted to learn R Language
In-Reply-To: <CAPEb7FTDxOiS2i7KAox5-ejQp3=3NiDBhw12w592Eo6HbSG7AQ@mail.gmail.com>
References: <CAPEb7FTDxOiS2i7KAox5-ejQp3=3NiDBhw12w592Eo6HbSG7AQ@mail.gmail.com>
Message-ID: <CAPo+ggsvtO-eDFMwkh4kxaJ+xH4yoWMLMJaFSV6q7OdXbkYZXA@mail.gmail.com>

Hello all ,

I am a SAS user for a while and wanted to learn to program in R . My
biggest hurdle to start, is to get the data (I work in clinical domain
) that too inside VPN secured access. The only way I can learn during
my work time is create my own data frames and create programs that can
be used for data ( either SDTM or AdAM data ) validation or checking
Table counts . For this I need to imitate the clinical data structure
. If there is any place or a package that help to start. I have couple
of dummy SAS datasets in my work area , but not sure how can I can
access them . Can anybody help me . Thanks ahead .


From drjimlemon at gmail.com  Thu Nov 30 22:13:04 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 1 Dec 2017 08:13:04 +1100
Subject: [R] Fwd: Wanted to learn R Language
In-Reply-To: <CAPo+ggsvtO-eDFMwkh4kxaJ+xH4yoWMLMJaFSV6q7OdXbkYZXA@mail.gmail.com>
References: <CAPEb7FTDxOiS2i7KAox5-ejQp3=3NiDBhw12w592Eo6HbSG7AQ@mail.gmail.com>
 <CAPo+ggsvtO-eDFMwkh4kxaJ+xH4yoWMLMJaFSV6q7OdXbkYZXA@mail.gmail.com>
Message-ID: <CA+8X3fVDgXHBuZiht+NDQzjeZ45SSGP_G=dTD6+QX4BVWi6XtA@mail.gmail.com>

Hi SAS_learner,
Have a look at the read.xport function in the foreign package.

Jim

On Fri, Dec 1, 2017 at 7:50 AM, SAS_learner <proccontents at gmail.com> wrote:
> Hello all ,
>
> I am a SAS user for a while and wanted to learn to program in R . My
> biggest hurdle to start, is to get the data (I work in clinical domain
> ) that too inside VPN secured access. The only way I can learn during
> my work time is create my own data frames and create programs that can
> be used for data ( either SDTM or AdAM data ) validation or checking
> Table counts . For this I need to imitate the clinical data structure
> . If there is any place or a package that help to start. I have couple
> of dummy SAS datasets in my work area , but not sure how can I can
> access them . Can anybody help me . Thanks ahead .
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Nov 30 22:23:16 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 30 Nov 2017 21:23:16 +0000
Subject: [R] Fwd: Wanted to learn R Language
In-Reply-To: <CA+8X3fVDgXHBuZiht+NDQzjeZ45SSGP_G=dTD6+QX4BVWi6XtA@mail.gmail.com>
References: <CAPEb7FTDxOiS2i7KAox5-ejQp3=3NiDBhw12w592Eo6HbSG7AQ@mail.gmail.com>
 <CAPo+ggsvtO-eDFMwkh4kxaJ+xH4yoWMLMJaFSV6q7OdXbkYZXA@mail.gmail.com>
 <CA+8X3fVDgXHBuZiht+NDQzjeZ45SSGP_G=dTD6+QX4BVWi6XtA@mail.gmail.com>
Message-ID: <8084736E-F40C-4E34-9866-F2A95CCE67B8@llnl.gov>

And if you have trouble with read.export(), then another option is to use SAS to export the data to a text file, then load it into R using R's read.table() function.

I would suggest that the SAS export be to a tab-delimited file, with column headers, and no quotes around text fields, but there are other options.

Pay careful attention to the stringsAsFactors argument of read.table, and I would suggest setting it to FALSE at first, at least until you learn enough about factors in R to know when to use them, and when not.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 11/30/17, 1:13 PM, "R-help on behalf of Jim Lemon" <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:

    Hi SAS_learner,
    Have a look at the read.xport function in the foreign package.
    
    Jim
    
    On Fri, Dec 1, 2017 at 7:50 AM, SAS_learner <proccontents at gmail.com> wrote:
    > Hello all ,
    >
    > I am a SAS user for a while and wanted to learn to program in R . My
    > biggest hurdle to start, is to get the data (I work in clinical domain
    > ) that too inside VPN secured access. The only way I can learn during
    > my work time is create my own data frames and create programs that can
    > be used for data ( either SDTM or AdAM data ) validation or checking
    > Table counts . For this I need to imitate the clinical data structure
    > . If there is any place or a package that help to start. I have couple
    > of dummy SAS datasets in my work area , but not sure how can I can
    > access them . Can anybody help me . Thanks ahead .
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


