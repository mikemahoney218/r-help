From dwinsemius at comcast.net  Sun Jan  1 00:57:39 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 31 Dec 2016 15:57:39 -0800
Subject: [R] GEOquery
In-Reply-To: <648058441.4592341.1483212130106@mail.yahoo.com>
References: <648058441.4592341.1483212130106.ref@mail.yahoo.com>
	<648058441.4592341.1483212130106@mail.yahoo.com>
Message-ID: <40997B3E-6C5F-46F8-962C-EA7EAEE60377@comcast.net>


> On Dec 31, 2016, at 11:22 AM, Elham - via R-help <r-help at r-project.org> wrote:
> 
> hello all,I am following this link http://genomicsclass.github.io/book/pages/GEOquery.html for importing data.but I have a problem in a step of (Access GSE Data Tables from GEO).in the example of tutorial there are 266 samples,but by this function
> dim(pData(gse[[1]]))head(pData(gse[[1]])[, 1:3])                                                                            the result in R is:
> 
>> dim(pData(gse[[1]]))[1] 266  47> head(pData(gse[[1]])[, 1:3])          title geo_accession                statusGSM540108   BC1     GSM540108 Public on May 05 2010GSM540109   BC2     GSM540109 Public on May 05 2010GSM540110   BC3     GSM540110 Public on May 05 2010GSM540111   BC4     GSM540111 Public on May 05 2010GSM540112   BC5     GSM540112 Public on May 05 2010GSM540113   BC6     GSM540113 Public on May 05 2010
> where is another samples? 
> 	[[alternative HTML version deleted]]


This is the first code seen at that page:

source("http://bioconductor.org/biocLite.R")
biocLite("GEOquery")

You were told earlier that rhelp is NOT the correct place to post questions about Bioconductor packages. What is the cause of your difficulty in understanding this fact?

-- 

David Winsemius
Alameda, CA, USA


From neverstop at hotmail.it  Sun Jan  1 11:56:39 2017
From: neverstop at hotmail.it (Neverstop .)
Date: Sun, 1 Jan 2017 10:56:39 +0000
Subject: [R] Fitting Hastie's principal surfaces in R
Message-ID: <AM2PR04MB08526D37DFF467206247A552C16C0@AM2PR04MB0852.eurprd04.prod.outlook.com>

Hello,

I need to summarize a three-dimensional dataset through a principal surface that passes through the middle of the data. Principal surfaces are non-linear generalization of the plane created by the first two principal components and provide a non-linear summary of p-dimensional dataset. Principal surfaces are described in this 1989 article by Hastie and Stuetzle: https://web.stanford.edu/~hastie/Papers/Principal_Curves.pdf . They were introduced by Trevor Hastie in his Ph.D dissertation: http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-r-276.pdf

I'm looking for a package to fit principal surfaces with R.
I've come across the package princurve created by TrevorHastie, but it allows to fit principal curves only. How can I fit two-dimensional principal surfaces in R?

Thank you.

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Sun Jan  1 15:49:06 2017
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 1 Jan 2017 14:49:06 +0000
Subject: [R] how to extract weighted data in "survey" package
Message-ID: <DM3PR13MB065282B9229E45F06A9BD22DFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>

Hi R Users,

Happy New Year


I wanted to see the data after  raw data was adjusted/weighted but I could not get it.  Any suggestions?

I would like to see which data points got more weight after the design was used.


I have given you an example what I tried but I was not successful .


Thanks


library(survey)

data(api)


rawData<-data.frame(API00=apistrat$api00, API99=apistrat$api99)

head(rawData)

dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)

svyplot(api00~api99, design=dstrat, style="bubble")


adjustedData<-data.frame(API00=(~api00, design=dstrat),API99=(~api99, design=dstrat ))

head(adjustedData)




	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sun Jan  1 16:00:27 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 1 Jan 2017 10:00:27 -0500
Subject: [R] how to extract weighted data in "survey" package
In-Reply-To: <DM3PR13MB065282B9229E45F06A9BD22DFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>
References: <DM3PR13MB065282B9229E45F06A9BD22DFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>
Message-ID: <CAOwvMDzX6ynvk3BiEEP=wkd-b2V2om9sJ39qe0+owTE8Xbt2kA@mail.gmail.com>

# load the survey library
library(survey)

# load the apistrat data.frame
data(api)

# look at the first six records
head(apistrat)

# look at the weight column only
apistrat$pw





On Sun, Jan 1, 2017 at 9:49 AM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Hi R Users,
>
> Happy New Year
>
>
> I wanted to see the data after  raw data was adjusted/weighted but I could
> not get it.  Any suggestions?
>
> I would like to see which data points got more weight after the design was
> used.
>
>
> I have given you an example what I tried but I was not successful .
>
>
> Thanks
>
>
> library(survey)
>
> data(api)
>
>
> rawData<-data.frame(API00=apistrat$api00, API99=apistrat$api99)
>
> head(rawData)
>
> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
> fpc=~fpc)
>
> svyplot(api00~api99, design=dstrat, style="bubble")
>
>
> adjustedData<-data.frame(API00=(~api00, design=dstrat),API99=(~api99,
> design=dstrat ))
>
> head(adjustedData)
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Sun Jan  1 17:11:01 2017
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 1 Jan 2017 16:11:01 +0000
Subject: [R] how to extract weighted data in "survey" package
In-Reply-To: <CAOwvMDzX6ynvk3BiEEP=wkd-b2V2om9sJ39qe0+owTE8Xbt2kA@mail.gmail.com>
References: <DM3PR13MB065282B9229E45F06A9BD22DFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>,
	<CAOwvMDzX6ynvk3BiEEP=wkd-b2V2om9sJ39qe0+owTE8Xbt2kA@mail.gmail.com>
Message-ID: <DM3PR13MB06523175F7F345CA8AF810BFFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>

Thank You Anthony for the message.

Why did not I get the same values in the following examples?

To get the adjusted value, should not we just multiphy by weight? For example, I multiplied "api00" by "column "pw" (mean(apistrat$api00*apistrat$pw/100)) but I did not get the same value as of survey package given. I think I did mistake. Any suggestions?




# load the survey library

library(survey)


# load the apistrat data.frame

data(api)


# look at the first six records

head(apistrat)


# look at the weight column only

apistrat$pw

# calcualet mean using raw data and afetr adjusted


svymean(~api00, dstrat)


mean(apistrat$api00*apistrat$pw/100)






________________________________
From: Anthony Damico <ajdamico at gmail.com>
Sent: January 1, 2017 8:00 AM
To: Kristi Glover
Cc: R-help
Subject: Re: [R] how to extract weighted data in "survey" package


# load the survey library
library(survey)

# load the apistrat data.frame
data(api)

# look at the first six records
head(apistrat)

# look at the weight column only
apistrat$pw





On Sun, Jan 1, 2017 at 9:49 AM, Kristi Glover <kristi.glover at hotmail.com<mailto:kristi.glover at hotmail.com>> wrote:
Hi R Users,

Happy New Year


I wanted to see the data after  raw data was adjusted/weighted but I could not get it.  Any suggestions?

I would like to see which data points got more weight after the design was used.


I have given you an example what I tried but I was not successful .


Thanks


library(survey)

data(api)


rawData<-data.frame(API00=apistrat$api00, API99=apistrat$api99)

head(rawData)

dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)

svyplot(api00~api99, design=dstrat, style="bubble")


adjustedData<-data.frame(API00=(~api00, design=dstrat),API99=(~api99, design=dstrat ))

head(adjustedData)




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sun Jan  1 18:00:02 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 1 Jan 2017 12:00:02 -0500
Subject: [R] how to extract weighted data in "survey" package
In-Reply-To: <DM3PR13MB06523175F7F345CA8AF810BFFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>
References: <DM3PR13MB065282B9229E45F06A9BD22DFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>
	<CAOwvMDzX6ynvk3BiEEP=wkd-b2V2om9sJ39qe0+owTE8Xbt2kA@mail.gmail.com>
	<DM3PR13MB06523175F7F345CA8AF810BFFA6C0@DM3PR13MB0652.namprd13.prod.outlook.com>
Message-ID: <CAOwvMDy+3bXbfn2wh2WA_zqNUKopSykPCVzynRqkv5yGKcfh5w@mail.gmail.com>

sum(apistrat$api00*apistrat$pw)/sum(apistrat$pw)

On Sun, Jan 1, 2017 at 11:11 AM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Thank You Anthony for the message.
>
> Why did not I get the same values in the following examples?
>
> To get the adjusted value, should not we just multiphy by weight? For
> example, I multiplied "api00" by "column "pw" (mean(apistrat$api00*
> apistrat$pw/100)) but I did not get the same value as of survey package
> given. I think I did mistake. Any suggestions?
>
>
>
>
> # load the survey library
>
> library(survey)
>
>
> # load the apistrat data.frame
>
> data(api)
>
>
> # look at the first six records
>
> head(apistrat)
>
>
> # look at the weight column only
>
> apistrat$pw
>
> # calcualet mean using raw data and afetr adjusted
>
>
> svymean(~api00, dstrat)
>
>
> mean(apistrat$api00*apistrat$pw/100)
>
>
>
>
>
>
> ------------------------------
> *From:* Anthony Damico <ajdamico at gmail.com>
> *Sent:* January 1, 2017 8:00 AM
> *To:* Kristi Glover
> *Cc:* R-help
> *Subject:* Re: [R] how to extract weighted data in "survey" package
>
>
> # load the survey library
> library(survey)
>
> # load the apistrat data.frame
> data(api)
>
> # look at the first six records
> head(apistrat)
>
> # look at the weight column only
> apistrat$pw
>
>
>
>
>
> On Sun, Jan 1, 2017 at 9:49 AM, Kristi Glover <kristi.glover at hotmail.com>
> wrote:
>
>> Hi R Users,
>>
>> Happy New Year
>>
>>
>> I wanted to see the data after  raw data was adjusted/weighted but I
>> could not get it.  Any suggestions?
>>
>> I would like to see which data points got more weight after the design
>> was used.
>>
>>
>> I have given you an example what I tried but I was not successful .
>>
>>
>> Thanks
>>
>>
>> library(survey)
>>
>> data(api)
>>
>>
>> rawData<-data.frame(API00=apistrat$api00, API99=apistrat$api99)
>>
>> head(rawData)
>>
>> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
>> fpc=~fpc)
>>
>> svyplot(api00~api99, design=dstrat, style="bubble")
>>
>>
>> adjustedData<-data.frame(API00=(~api00, design=dstrat),API99=(~api99,
>> design=dstrat ))
>>
>> head(adjustedData)
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Sun Jan  1 18:27:29 2017
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 1 Jan 2017 20:27:29 +0300
Subject: [R] Date Column error: 'origin' must be supplied
In-Reply-To: <alpine.DEB.2.20.1612301557330.18444@paninaro>
References: <CAGh51gSNOShj_cGLAig5wS-n4nbOWZ90wbDAnF0WAKvcs884Eg@mail.gmail.com>
	<alpine.DEB.2.20.1612301557330.18444@paninaro>
Message-ID: <CAGh51gTWS7B3Z1iTak2awPmWfyqvgBYTBuJuDSM7ouKprQUFtQ@mail.gmail.com>

Thanks. It is helpful!

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Fri, Dec 30, 2016 at 5:58 PM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Fri, 30 Dec 2016, Frederic Ntirenganya wrote:
>
> Hi All,
>>
>> I am creating date column on my data but getting the following error:
>>
>> #add date column dat1$Date=paste(as.Date(dat1$Year,dat1$Month,
>> dat1$Day, sep="-"))Error in as.Date.numeric(origin, ...) : 'origin'
>> must be supplied
>>
>
> You first need to paste() the character string and the coerce it with
> as.Date() - not the other way around:
>
> as.Date(paste(dat1$Year, dat1$Month, dat1$Day, sep="-"))
>
>
>>
>> I will appreciate any help from you guys. Thanks.
>> Here is the data.
>>
>>
>> dput(head(dat1))structure(list(Year = c(1984L, 1984L, 1984L, 1984L,
>> 1984L, 1984L
>> ), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, WindSpeed = c(5L,
>> 4L, 4L, 3L, 5L, 6L), Sunshine = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
>> ), Tmax = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin = c(14.5,
>> 16, 14.4, 14.8, 16.6, 15.4), Hmax = c(100L, 95L, 97L, 100L, 97L,
>> 99L), Hmin = c(45L, 62L, 72L, 55L, 54L, 63L), Station.Name =
>> structure(c(1L,
>> 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI AERO", class = "factor"),
>>    Elevation = c(1490L, 1490L, 1490L, 1490L, 1490L, 1490L),
>>    Longitude = c(30.11, 30.11, 30.11, 30.11, 30.11, 30.11),
>>    Latitude = c(-1.95, -1.95, -1.95, -1.95, -1.95, -1.95)), .Names =
>> c("Year",
>> "Month", "Day", "WindSpeed", "Sunshine", "Tmax", "Tmin", "Hmax",
>> "Hmin", "Station.Name", "Elevation", "Longitude", "Latitude"),
>> row.names = c(NA,
>> 6L), class = "data.frame")
>>
>>
>> Best Regards,
>>
>> Fredo
>>
>>
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Jan  1 21:26:43 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 1 Jan 2017 12:26:43 -0800
Subject: [R] Fitting Hastie's principal surfaces in R
In-Reply-To: <AM2PR04MB08526D37DFF467206247A552C16C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
References: <AM2PR04MB08526D37DFF467206247A552C16C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
Message-ID: <CAGxFJbTdS1TPB1XjJgfWaS7mMCLJaP1Ebvk0PpE5N5Sh-LhEMg@mail.gmail.com>

I couldn't find anything, but you might try searching on "thin plate
splines" on rseek.org. I realize these are different than principal
surfaces, but they might nevertheless be useful to you.   Or not.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 1, 2017 at 2:56 AM, Neverstop . <neverstop at hotmail.it> wrote:
> Hello,
>
> I need to summarize a three-dimensional dataset through a principal surface that passes through the middle of the data. Principal surfaces are non-linear generalization of the plane created by the first two principal components and provide a non-linear summary of p-dimensional dataset. Principal surfaces are described in this 1989 article by Hastie and Stuetzle: https://web.stanford.edu/~hastie/Papers/Principal_Curves.pdf . They were introduced by Trevor Hastie in his Ph.D dissertation: http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-r-276.pdf
>
> I'm looking for a package to fit principal surfaces with R.
> I've come across the package princurve created by TrevorHastie, but it allows to fit principal curves only. How can I fit two-dimensional principal surfaces in R?
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jan  1 22:47:54 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 Jan 2017 13:47:54 -0800
Subject: [R] Fitting Hastie's principal surfaces in R
In-Reply-To: <CAGxFJbTdS1TPB1XjJgfWaS7mMCLJaP1Ebvk0PpE5N5Sh-LhEMg@mail.gmail.com>
References: <AM2PR04MB08526D37DFF467206247A552C16C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
	<CAGxFJbTdS1TPB1XjJgfWaS7mMCLJaP1Ebvk0PpE5N5Sh-LhEMg@mail.gmail.com>
Message-ID: <C9CD7987-4B28-438C-8140-91761EC8D849@comcast.net>


> On Jan 1, 2017, at 12:26 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I couldn't find anything, but you might try searching on "thin plate
> splines" on rseek.org. I realize these are different than principal
> surfaces, but they might nevertheless be useful to you.   Or not.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Jan 1, 2017 at 2:56 AM, Neverstop . <neverstop at hotmail.it> wrote:
>> Hello,
>> 
>> I need to summarize a three-dimensional dataset through a principal surface that passes through the middle of the data. Principal surfaces are non-linear generalization of the plane created by the first two principal components and provide a non-linear summary of p-dimensional dataset. Principal surfaces are described in this 1989 article by Hastie and Stuetzle: https://web.stanford.edu/~hastie/Papers/Principal_Curves.pdf . They were introduced by Trevor Hastie in his Ph.D dissertation: http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-r-276.pdf
>> 
>> I'm looking for a package to fit principal surfaces with R.
>> I've come across the package princurve created by TrevorHastie, but it allows to fit principal curves only. How can I fit two-dimensional principal surfaces in R?

What are the operational requirements for satisfaction with this assignment? I wonder if a regression "surface" of some other sort would be sufficient?  Assuming the three dimensions are X,Y, Z, then a loess (or locfit) "surface" or a regression estimate that used a spline surface for  Z ~ X+Y would not be a principal surface, but should satisfy some of your other requirements. This question would become clearer if you would offer data for analysis (the lack of which is one reason that duplicates of this question were closed as off-topic at both CrossValidated.com and StackOverflow.)


>> 
>> Thank you.
>> 
>>        [[alternative HTML version deleted]]

R-help is a plain-text mailing list.

>> 

David Winsemius
Alameda, CA, USA


From honolulushane at gmail.com  Sun Jan  1 20:22:57 2017
From: honolulushane at gmail.com (Jeff Shane)
Date: Sun, 1 Jan 2017 14:22:57 -0500
Subject: [R] double subscripts with Greek letter
Message-ID: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>

Hi all,

I have a question which seems trivial but simply cannot figure out its
solution.

I want to type A_{\alpha,\beta} in the title of a plot. Uwe once pointed
out a solution

expression(A[alpha*beta])

But the output of the above command does not include the "," in the
subscript. Is there a way to solve my question? Thanks so much!

Regards,
Jeff

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Mon Jan  2 04:37:06 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 1 Jan 2017 21:37:06 -0600
Subject: [R] double subscripts with Greek letter
In-Reply-To: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
References: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
Message-ID: <CACxE24kpKJ8FBh+KUTKpPL_nedLxr4KwWTbhwM7i00L0woq5gg@mail.gmail.com>

Hello!

Here is a solution:

> plot(1:10)
> xa <- expression(A[list(alpha,beta)])
> title(xa)



On Sun, Jan 1, 2017 at 1:22 PM, Jeff Shane <honolulushane at gmail.com> wrote:

> Hi all,
>
> I have a question which seems trivial but simply cannot figure out its
> solution.
>
> I want to type A_{\alpha,\beta} in the title of a plot. Uwe once pointed
> out a solution
>
> expression(A[alpha*beta])
>
> But the output of the above command does not include the "," in the
> subscript. Is there a way to solve my question? Thanks so much!
>
> Regards,
> Jeff
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Jan  2 05:17:28 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 1 Jan 2017 20:17:28 -0800
Subject: [R] double subscripts with Greek letter
In-Reply-To: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
References: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
Message-ID: <CAF8bMcZF0rsD0WK4_-U1-Ya7n+RKiAnLW83TV4sXx5maDATEEQ@mail.gmail.com>

Does the following do well enough?
   plot(1,1);title(expression(A[paste(alpha,",",beta)]))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Jan 1, 2017 at 11:22 AM, Jeff Shane <honolulushane at gmail.com> wrote:

> Hi all,
>
> I have a question which seems trivial but simply cannot figure out its
> solution.
>
> I want to type A_{\alpha,\beta} in the title of a plot. Uwe once pointed
> out a solution
>
> expression(A[alpha*beta])
>
> But the output of the above command does not include the "," in the
> subscript. Is there a way to solve my question? Thanks so much!
>
> Regards,
> Jeff
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jan  2 05:29:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 1 Jan 2017 20:29:52 -0800
Subject: [R] double subscripts with Greek letter
In-Reply-To: <CACxE24kpKJ8FBh+KUTKpPL_nedLxr4KwWTbhwM7i00L0woq5gg@mail.gmail.com>
References: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
	<CACxE24kpKJ8FBh+KUTKpPL_nedLxr4KwWTbhwM7i00L0woq5gg@mail.gmail.com>
Message-ID: <CAGxFJbS=+FZOBLLUQmJ=0_HfX-4Jpyvsz1uhT5bX_RTc8bJvGg@mail.gmail.com>

... or perhaps simpler and more transparently:

plot(0:1 ~0:1, main = expression(A[alpha*","*beta]))

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jan 1, 2017 at 7:37 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> Here is a solution:
>
>> plot(1:10)
>> xa <- expression(A[list(alpha,beta)])
>> title(xa)
>
>
>
> On Sun, Jan 1, 2017 at 1:22 PM, Jeff Shane <honolulushane at gmail.com> wrote:
>
>> Hi all,
>>
>> I have a question which seems trivial but simply cannot figure out its
>> solution.
>>
>> I want to type A_{\alpha,\beta} in the title of a plot. Uwe once pointed
>> out a solution
>>
>> expression(A[alpha*beta])
>>
>> But the output of the above command does not include the "," in the
>> subscript. Is there a way to solve my question? Thanks so much!
>>
>> Regards,
>> Jeff
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jacksonmrodrigues at gmail.com  Mon Jan  2 17:47:14 2017
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Mon, 2 Jan 2017 13:47:14 -0300
Subject: [R] R in raspberry Pi
In-Reply-To: <CAPL76w95H0nryLnQBpAGuwgbthV3i=rFLokUkU91FXKijseypA@mail.gmail.com>
References: <CAPL76w9RRcxrQuWLEqfUevDxS9P0ZV6uOsihiqPNqVRLz9dFYg@mail.gmail.com>
	<CAPL76w_6CjDgv025y5TOzHWZ4NvMYWC_2uBuaqXKnh=mzu4aXw@mail.gmail.com>
	<CAPL76w8WtJcQE39ys0bNynVQZS=OP4x2+JEG9wtdkW1CYZ=LVA@mail.gmail.com>
	<CAPL76w8TeT2r0zZpMs=tjKL7S0tNf4wHe-wSwh2R-7W=TDJhPg@mail.gmail.com>
	<CAPL76w95H0nryLnQBpAGuwgbthV3i=rFLokUkU91FXKijseypA@mail.gmail.com>
Message-ID: <CAPL76w_m0M5vffm9GMz7Fsav4oP1arsCA4MwCF2Cgf74vcO99Q@mail.gmail.com>

Hi everybody,

Happy new year!!

I was wondering if it is possible to install and to run R to raspberry pi.

Has  anyone ever tried to run R in raspberry Pi 3? If so, how was the
experience? Any suggestion for a more appropriate  platform ?

Cheers

Jackson

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jan  2 18:32:04 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 2 Jan 2017 09:32:04 -0800
Subject: [R] R in raspberry Pi
In-Reply-To: <CAPL76w_m0M5vffm9GMz7Fsav4oP1arsCA4MwCF2Cgf74vcO99Q@mail.gmail.com>
References: <CAPL76w9RRcxrQuWLEqfUevDxS9P0ZV6uOsihiqPNqVRLz9dFYg@mail.gmail.com>
	<CAPL76w_6CjDgv025y5TOzHWZ4NvMYWC_2uBuaqXKnh=mzu4aXw@mail.gmail.com>
	<CAPL76w8WtJcQE39ys0bNynVQZS=OP4x2+JEG9wtdkW1CYZ=LVA@mail.gmail.com>
	<CAPL76w8TeT2r0zZpMs=tjKL7S0tNf4wHe-wSwh2R-7W=TDJhPg@mail.gmail.com>
	<CAPL76w95H0nryLnQBpAGuwgbthV3i=rFLokUkU91FXKijseypA@mail.gmail.com>
	<CAPL76w_m0M5vffm9GMz7Fsav4oP1arsCA4MwCF2Cgf74vcO99Q@mail.gmail.com>
Message-ID: <CAGxFJbT_MGDfp2_iJL5D09wPOXhtkwYeSJqXBo9-4_wc_1zUJQ@mail.gmail.com>

I would assume it's possible *if*

1) You could load a *nix OS and tools for which R is already compiled
2) You could load a *nix verstion and tools (C++ compiler, etc.) to
compile it from the publicly available source
3) If you had sufficient memory and processing power.

The CRAN website and rseek.org R search engine are probably good
places to follow up on your own if someone doesn't give you further
help here.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 2, 2017 at 8:47 AM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi everybody,
>
> Happy new year!!
>
> I was wondering if it is possible to install and to run R to raspberry pi.
>
> Has  anyone ever tried to run R in raspberry Pi 3? If so, how was the
> experience? Any suggestion for a more appropriate  platform ?
>
> Cheers
>
> Jackson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erich.subs at neuwirth.priv.at  Mon Jan  2 18:39:18 2017
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Mon, 2 Jan 2017 18:39:18 +0100
Subject: [R] R in raspberry Pi
In-Reply-To: <CAPL76w_m0M5vffm9GMz7Fsav4oP1arsCA4MwCF2Cgf74vcO99Q@mail.gmail.com>
References: <CAPL76w9RRcxrQuWLEqfUevDxS9P0ZV6uOsihiqPNqVRLz9dFYg@mail.gmail.com>
	<CAPL76w_6CjDgv025y5TOzHWZ4NvMYWC_2uBuaqXKnh=mzu4aXw@mail.gmail.com>
	<CAPL76w8WtJcQE39ys0bNynVQZS=OP4x2+JEG9wtdkW1CYZ=LVA@mail.gmail.com>
	<CAPL76w8TeT2r0zZpMs=tjKL7S0tNf4wHe-wSwh2R-7W=TDJhPg@mail.gmail.com>
	<CAPL76w95H0nryLnQBpAGuwgbthV3i=rFLokUkU91FXKijseypA@mail.gmail.com>
	<CAPL76w_m0M5vffm9GMz7Fsav4oP1arsCA4MwCF2Cgf74vcO99Q@mail.gmail.com>
Message-ID: <513A6E1F-5888-45BD-A3DF-047122C69B53@neuwirth.priv.at>

R is available for the standard Raspbian distribution.
sudo apt-get install r-base 
will give you a basic installation.

So far, hwoever, RStudio has not been made available in the distribution.


 
> On 2 Jan 2017, at 17:47, Jackson Rodrigues <jacksonmrodrigues at gmail.com> wrote:
> 
> Hi everybody,
> 
> Happy new year!!
> 
> I was wondering if it is possible to install and to run R to raspberry pi.
> 
> Has  anyone ever tried to run R in raspberry Pi 3? If so, how was the
> experience? Any suggestion for a more appropriate  platform ?
> 
> Cheers
> 
> Jackson
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chiarainserra.92 at gmail.com  Mon Jan  2 12:11:54 2017
From: chiarainserra.92 at gmail.com (Chiara Inserra)
Date: Mon, 2 Jan 2017 12:11:54 +0100
Subject: [R] KERNLAB
Message-ID: <CAMUhZxMi3XZD-487dJJmH_RtzXw4oXdnT39mBjcik+s5q3F=DA@mail.gmail.com>

I'm using "Kernlab" to apply the "Weighted Nadaraya Watson" by Kato (2012)
and Hall, Wolff, and Yao (1999).

I need to find this Gaussian Kernel in weights'calculation , where u=
(x-x0):
Kh(u) = h^(?1)*K(u/h).

I used:
rbf1 <- rbfdot(sigma = NULL)

but I have to find out "sigma" as the inverse width. I used ?sigest?
function but it is different at each run, and hyperparameter value seem to
be too high..


I have a couple of questions:
1. I must find lambda which maximize: f: sum(log(1+lambda*(x-x0)*Kh(u/h)
    But with rbf1 function I obtain a very small number and the log becames
0 (log of 1+ e^-230 etc)


2. Why I find different hyperparameter for each run? I should impose
set.seed? But why hyperparameter are so high?

3. Which formula I should use for sigma in rbf1?

Thank's in advance.

	[[alternative HTML version deleted]]


From fsbmat at gmail.com  Mon Jan  2 15:16:47 2017
From: fsbmat at gmail.com (Fernando de Souza Bastos)
Date: Mon, 2 Jan 2017 12:16:47 -0200
Subject: [R] Return of the gradient function when using Optim functions and
	colSums
Message-ID: <CAPTmxS0ad9f=bgOCwaH4qkVH4ofTFQOHxbMD470uMJnmbz0RgQ@mail.gmail.com>

Dear,

i am using the programming of the package "sampleSelection" for a study and
I do not understand the error of my simulation, I posted the detailed doubt
in stackoverflow! Link below:

http://stackoverflow.com/questions/41404416/return-of-the-gradient-function-when-using-optim-functions-and-colsums


Thank you!

best regards,

Fernando de Souza Bastos
Teacher of Mathematics and Statistics

Universidade Federal de Vi?osa (UFV)

Campus UFV - Florestal

PhD in progress in Statistics
Universidade Federal de Minas Gerais (UFMG)

	[[alternative HTML version deleted]]


From imarques at nemsolutions.com  Mon Jan  2 16:12:00 2017
From: imarques at nemsolutions.com (=?UTF-8?B?SW9uIE1hcnF1w6lz?=)
Date: Mon, 2 Jan 2017 16:12:00 +0100
Subject: [R] GGally ggpairs function parameters
Message-ID: <CA+BFa=Ti3sNy54-8BSoHxGvAYvy8BBQD1zF4eq5se232+-juRA@mail.gmail.com>

Hello R community,

I am trying to specify the input data in the upper, diag and/or lower
parameters of the ggpair function (GGally package). The dummy example
below adds two parameters to ggally_points, a data subsample and an
alpha value. However, the results show that the alpha is taken into
account but all the data is plotted, not just the three random points.

  library(GGally)
  library(dplyr)
  myData <- data.frame(x = c(1,2,3,4,5,6), y = c(7,8,9,9,8,7), z =
c("a","a","a","b","b","b"))
  ggpairs(myData, aes(colour = z), columns = 1:2,
          upper = list(continuous = wrap(ggally_cor, size = 10)),
          diag = list(continuous = wrap(ggally_densityDiag, alpha = 0.6)),
          lower = list(continuous = wrap(ggally_points, data =
sample_n(myData, 3), alpha = 0.6)))

I have tried passing the data parameter as a list with wrapp, defining
the modified ggally_points outside, but the result is the same. I have
also unsuccessfully tried to modify the mapping = aes(...) parameter.
What am I missing here?

Thank you!


Ion Marqu?s


From joeceradini at gmail.com  Mon Jan  2 21:01:13 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Mon, 2 Jan 2017 13:01:13 -0700
Subject: [R] Lubdridate: subset based on hour and minute
Message-ID: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>

Hi folks,

I must be missing something obvious/painfully simple here....

How do I subset a time vector based on hours AND minutes? So, in this
example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
I'm working with lubridate which separates the hours and minutes into
separate slots.

require(lubridate)

test <- hm(c("9:30", "10:00", "10:30", "11:00"))
test
[1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"

This gets 11 but not 1030
test[test at hour > 10]
[1] "11H 0M 0S"

This gets 1030 but not 11
test[test at hour > 9 & test at minute > 0]
[1] "10H 30M 0S"

Thanks and happy new year!
Joe


From roy.mendelssohn at noaa.gov  Mon Jan  2 21:13:24 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 2 Jan 2017 12:13:24 -0800
Subject: [R] Lubdridate: subset based on hour and minute
In-Reply-To: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
References: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
Message-ID: <62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>

Hi Joe:

See below.
> On Jan 2, 2017, at 12:01 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> 
> Hi folks,
> 
> I must be missing something obvious/painfully simple here....
> 
> How do I subset a time vector based on hours AND minutes? So, in this
> example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
> I'm working with lubridate which separates the hours and minutes into
> separate slots.
> 
> require(lubridate)
> 
> test <- hm(c("9:30", "10:00", "10:30", "11:00"))
> test
> [1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
> 
> This gets 11 but not 1030
> test[test at hour > 10]
> [1] "11H 0M 0S"
> 
> This gets 1030 but not 11
> test[test at hour > 9 & test at minute > 0]
> [1] "10H 30M 0S"

 test[test at hour > 9]
[1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S" 


You are using a logical "and" in your test - so the condition "test at minute > 0" isn't met for 11:00 and therefore it doesn't show up. as both conditions must be met  You could also do:

> test[test at hour >= 10]
[1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S" 

-HTH,

Roy

> 
> Thanks and happy new year!
> Joe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From joeceradini at gmail.com  Mon Jan  2 21:27:37 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Mon, 2 Jan 2017 13:27:37 -0700
Subject: [R] Lubdridate: subset based on hour and minute
In-Reply-To: <62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>
References: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
	<62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>
Message-ID: <CAKq2vL4t4X9X-haeM+F7oVzg=VO3xpT+LzW4eXhiRrbeK4JTdA@mail.gmail.com>

Thanks for the reply Roy!

Perhaps you're showing me the way and I'm missing it - how would I
subset to only 1030 and 1100, excluding 1000? It seems I would need to
say, give me all time greater than 10:00, but the hours and minutes
are in separate slots, which is throwing me off.

Thanks again.

On Mon, Jan 2, 2017 at 1:13 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi Joe:
>
> See below.
>> On Jan 2, 2017, at 12:01 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>
>> Hi folks,
>>
>> I must be missing something obvious/painfully simple here....
>>
>> How do I subset a time vector based on hours AND minutes? So, in this
>> example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
>> I'm working with lubridate which separates the hours and minutes into
>> separate slots.
>>
>> require(lubridate)
>>
>> test <- hm(c("9:30", "10:00", "10:30", "11:00"))
>> test
>> [1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>
>> This gets 11 but not 1030
>> test[test at hour > 10]
>> [1] "11H 0M 0S"
>>
>> This gets 1030 but not 11
>> test[test at hour > 9 & test at minute > 0]
>> [1] "10H 30M 0S"
>
>  test[test at hour > 9]
> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>
>
> You are using a logical "and" in your test - so the condition "test at minute > 0" isn't met for 11:00 and therefore it doesn't show up. as both conditions must be met  You could also do:
>
>> test[test at hour >= 10]
> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>
> -HTH,
>
> Roy
>
>>
>> Thanks and happy new year!
>> Joe
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org


From roy.mendelssohn at noaa.gov  Mon Jan  2 21:35:03 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 2 Jan 2017 12:35:03 -0800
Subject: [R] Lubdridate: subset based on hour and minute
In-Reply-To: <CAKq2vL4t4X9X-haeM+F7oVzg=VO3xpT+LzW4eXhiRrbeK4JTdA@mail.gmail.com>
References: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
	<62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>
	<CAKq2vL4t4X9X-haeM+F7oVzg=VO3xpT+LzW4eXhiRrbeK4JTdA@mail.gmail.com>
Message-ID: <6ABA58C1-458D-405C-9D45-773374BEF339@noaa.gov>

> test > hm("10:00")
[1] FALSE FALSE  TRUE  TRUE
> test[test > hm("10:00")]
[1] "10H 30M 0S" "11H 0M 0S" 

-Roy


> On Jan 2, 2017, at 12:27 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> 
> Thanks for the reply Roy!
> 
> Perhaps you're showing me the way and I'm missing it - how would I
> subset to only 1030 and 1100, excluding 1000? It seems I would need to
> say, give me all time greater than 10:00, but the hours and minutes
> are in separate slots, which is throwing me off.
> 
> Thanks again.
> 
> On Mon, Jan 2, 2017 at 1:13 PM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi Joe:
>> 
>> See below.
>>> On Jan 2, 2017, at 12:01 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>> 
>>> Hi folks,
>>> 
>>> I must be missing something obvious/painfully simple here....
>>> 
>>> How do I subset a time vector based on hours AND minutes? So, in this
>>> example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
>>> I'm working with lubridate which separates the hours and minutes into
>>> separate slots.
>>> 
>>> require(lubridate)
>>> 
>>> test <- hm(c("9:30", "10:00", "10:30", "11:00"))
>>> test
>>> [1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>> 
>>> This gets 11 but not 1030
>>> test[test at hour > 10]
>>> [1] "11H 0M 0S"
>>> 
>>> This gets 1030 but not 11
>>> test[test at hour > 9 & test at minute > 0]
>>> [1] "10H 30M 0S"
>> 
>> test[test at hour > 9]
>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>> 
>> 
>> You are using a logical "and" in your test - so the condition "test at minute > 0" isn't met for 11:00 and therefore it doesn't show up. as both conditions must be met  You could also do:
>> 
>>> test[test at hour >= 10]
>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>> 
>> -HTH,
>> 
>> Roy
>> 
>>> 
>>> Thanks and happy new year!
>>> Joe
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
> 
> 
> 
> -- 
> Cooperative Fish and Wildlife Research Unit
> Zoology and Physiology Dept.
> University of Wyoming
> JoeCeradini at gmail.com / 914.707.8506
> wyocoopunit.org

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From joeceradini at gmail.com  Mon Jan  2 21:39:01 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Mon, 2 Jan 2017 13:39:01 -0700
Subject: [R] Lubdridate: subset based on hour and minute
In-Reply-To: <6ABA58C1-458D-405C-9D45-773374BEF339@noaa.gov>
References: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
	<62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>
	<CAKq2vL4t4X9X-haeM+F7oVzg=VO3xpT+LzW4eXhiRrbeK4JTdA@mail.gmail.com>
	<6ABA58C1-458D-405C-9D45-773374BEF339@noaa.gov>
Message-ID: <CAKq2vL7YvRQwC67EF_XdL+pQR5nXpaa957O2hR_xeTN9ym7gyA@mail.gmail.com>

Bingo! Thanks! I somehow couldn't find an example like that via google.

Joe

On Mon, Jan 2, 2017 at 1:35 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
>> test > hm("10:00")
> [1] FALSE FALSE  TRUE  TRUE
>> test[test > hm("10:00")]
> [1] "10H 30M 0S" "11H 0M 0S"
>
> -Roy
>
>
>> On Jan 2, 2017, at 12:27 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>
>> Thanks for the reply Roy!
>>
>> Perhaps you're showing me the way and I'm missing it - how would I
>> subset to only 1030 and 1100, excluding 1000? It seems I would need to
>> say, give me all time greater than 10:00, but the hours and minutes
>> are in separate slots, which is throwing me off.
>>
>> Thanks again.
>>
>> On Mon, Jan 2, 2017 at 1:13 PM, Roy Mendelssohn - NOAA Federal
>> <roy.mendelssohn at noaa.gov> wrote:
>>> Hi Joe:
>>>
>>> See below.
>>>> On Jan 2, 2017, at 12:01 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>>>
>>>> Hi folks,
>>>>
>>>> I must be missing something obvious/painfully simple here....
>>>>
>>>> How do I subset a time vector based on hours AND minutes? So, in this
>>>> example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
>>>> I'm working with lubridate which separates the hours and minutes into
>>>> separate slots.
>>>>
>>>> require(lubridate)
>>>>
>>>> test <- hm(c("9:30", "10:00", "10:30", "11:00"))
>>>> test
>>>> [1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>>>
>>>> This gets 11 but not 1030
>>>> test[test at hour > 10]
>>>> [1] "11H 0M 0S"
>>>>
>>>> This gets 1030 but not 11
>>>> test[test at hour > 9 & test at minute > 0]
>>>> [1] "10H 30M 0S"
>>>
>>> test[test at hour > 9]
>>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>>
>>>
>>> You are using a logical "and" in your test - so the condition "test at minute > 0" isn't met for 11:00 and therefore it doesn't show up. as both conditions must be met  You could also do:
>>>
>>>> test[test at hour >= 10]
>>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>>
>>> -HTH,
>>>
>>> Roy
>>>
>>>>
>>>> Thanks and happy new year!
>>>> Joe
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new street address***
>>> 110 McAllister Way
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>
>>
>>
>>
>> --
>> Cooperative Fish and Wildlife Research Unit
>> Zoology and Physiology Dept.
>> University of Wyoming
>> JoeCeradini at gmail.com / 914.707.8506
>> wyocoopunit.org
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org


From roy.mendelssohn at noaa.gov  Mon Jan  2 21:44:17 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 2 Jan 2017 12:44:17 -0800
Subject: [R] Lubdridate: subset based on hour and minute
In-Reply-To: <CAKq2vL7YvRQwC67EF_XdL+pQR5nXpaa957O2hR_xeTN9ym7gyA@mail.gmail.com>
References: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
	<62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>
	<CAKq2vL4t4X9X-haeM+F7oVzg=VO3xpT+LzW4eXhiRrbeK4JTdA@mail.gmail.com>
	<6ABA58C1-458D-405C-9D45-773374BEF339@noaa.gov>
	<CAKq2vL7YvRQwC67EF_XdL+pQR5nXpaa957O2hR_xeTN9ym7gyA@mail.gmail.com>
Message-ID: <281827FA-ED1B-46C4-A754-722957CBB111@noaa.gov>

The trick is to realize times are stored internally in a special format,  though they can be displayed in several ways based on the internal representation.  The trick in doing comparison with times is to make certain what you are comparing with has also been put into the same internal time format.  This should make clear the basis for the logical tests:

> as.numeric(test)
[1] 34200 36000 37800 39600
> 
> as.numeric(hm("10:00"))
[1] 36000
> 

-Roy


> On Jan 2, 2017, at 12:39 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> 
> Bingo! Thanks! I somehow couldn't find an example like that via google.
> 
> Joe
> 
> On Mon, Jan 2, 2017 at 1:35 PM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>>> test > hm("10:00")
>> [1] FALSE FALSE  TRUE  TRUE
>>> test[test > hm("10:00")]
>> [1] "10H 30M 0S" "11H 0M 0S"
>> 
>> -Roy
>> 
>> 
>>> On Jan 2, 2017, at 12:27 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>> 
>>> Thanks for the reply Roy!
>>> 
>>> Perhaps you're showing me the way and I'm missing it - how would I
>>> subset to only 1030 and 1100, excluding 1000? It seems I would need to
>>> say, give me all time greater than 10:00, but the hours and minutes
>>> are in separate slots, which is throwing me off.
>>> 
>>> Thanks again.
>>> 
>>> On Mon, Jan 2, 2017 at 1:13 PM, Roy Mendelssohn - NOAA Federal
>>> <roy.mendelssohn at noaa.gov> wrote:
>>>> Hi Joe:
>>>> 
>>>> See below.
>>>>> On Jan 2, 2017, at 12:01 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>>>> 
>>>>> Hi folks,
>>>>> 
>>>>> I must be missing something obvious/painfully simple here....
>>>>> 
>>>>> How do I subset a time vector based on hours AND minutes? So, in this
>>>>> example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
>>>>> I'm working with lubridate which separates the hours and minutes into
>>>>> separate slots.
>>>>> 
>>>>> require(lubridate)
>>>>> 
>>>>> test <- hm(c("9:30", "10:00", "10:30", "11:00"))
>>>>> test
>>>>> [1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>>>> 
>>>>> This gets 11 but not 1030
>>>>> test[test at hour > 10]
>>>>> [1] "11H 0M 0S"
>>>>> 
>>>>> This gets 1030 but not 11
>>>>> test[test at hour > 9 & test at minute > 0]
>>>>> [1] "10H 30M 0S"
>>>> 
>>>> test[test at hour > 9]
>>>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>>> 
>>>> 
>>>> You are using a logical "and" in your test - so the condition "test at minute > 0" isn't met for 11:00 and therefore it doesn't show up. as both conditions must be met  You could also do:
>>>> 
>>>>> test[test at hour >= 10]
>>>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
>>>> 
>>>> -HTH,
>>>> 
>>>> Roy
>>>> 
>>>>> 
>>>>> Thanks and happy new year!
>>>>> Joe
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> **********************
>>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>>> **********************
>>>> Roy Mendelssohn
>>>> Supervisory Operations Research Analyst
>>>> NOAA/NMFS
>>>> Environmental Research Division
>>>> Southwest Fisheries Science Center
>>>> ***Note new street address***
>>>> 110 McAllister Way
>>>> Santa Cruz, CA 95060
>>>> Phone: (831)-420-3666
>>>> Fax: (831) 420-3980
>>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>> 
>>>> "Old age and treachery will overcome youth and skill."
>>>> "From those who have been given much, much will be expected"
>>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> Cooperative Fish and Wildlife Research Unit
>>> Zoology and Physiology Dept.
>>> University of Wyoming
>>> JoeCeradini at gmail.com / 914.707.8506
>>> wyocoopunit.org
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
> 
> 
> 
> -- 
> Cooperative Fish and Wildlife Research Unit
> Zoology and Physiology Dept.
> University of Wyoming
> JoeCeradini at gmail.com / 914.707.8506
> wyocoopunit.org

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From joeceradini at gmail.com  Mon Jan  2 21:47:07 2017
From: joeceradini at gmail.com (Joe Ceradini)
Date: Mon, 2 Jan 2017 13:47:07 -0700
Subject: [R] Lubdridate: subset based on hour and minute
In-Reply-To: <281827FA-ED1B-46C4-A754-722957CBB111@noaa.gov>
References: <CAKq2vL5FDYOQ3JcOERx4fexgg-uOBvXLnW7MecgPnHws-n4_Xw@mail.gmail.com>
	<62013C91-6F9C-4FD1-BBFE-1B092661BA85@noaa.gov>
	<CAKq2vL4t4X9X-haeM+F7oVzg=VO3xpT+LzW4eXhiRrbeK4JTdA@mail.gmail.com>
	<6ABA58C1-458D-405C-9D45-773374BEF339@noaa.gov>
	<CAKq2vL7YvRQwC67EF_XdL+pQR5nXpaa957O2hR_xeTN9ym7gyA@mail.gmail.com>
	<281827FA-ED1B-46C4-A754-722957CBB111@noaa.gov>
Message-ID: <CAKq2vL6Pr14U3=WrZ4KDHpYbdsDJx=q8gX9es75uKimWW__nRQ@mail.gmail.com>

Ahh, that makes more sense now. Thanks again.

On Mon, Jan 2, 2017 at 1:44 PM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> The trick is to realize times are stored internally in a special format,
> though they can be displayed in several ways based on the internal
> representation.  The trick in doing comparison with times is to make
> certain what you are comparing with has also been put into the same
> internal time format.  This should make clear the basis for the logical
> tests:
>
> > as.numeric(test)
> [1] 34200 36000 37800 39600
> >
> > as.numeric(hm("10:00"))
> [1] 36000
> >
>
> -Roy
>
>
> > On Jan 2, 2017, at 12:39 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> >
> > Bingo! Thanks! I somehow couldn't find an example like that via google.
> >
> > Joe
> >
> > On Mon, Jan 2, 2017 at 1:35 PM, Roy Mendelssohn - NOAA Federal
> > <roy.mendelssohn at noaa.gov> wrote:
> >>> test > hm("10:00")
> >> [1] FALSE FALSE  TRUE  TRUE
> >>> test[test > hm("10:00")]
> >> [1] "10H 30M 0S" "11H 0M 0S"
> >>
> >> -Roy
> >>
> >>
> >>> On Jan 2, 2017, at 12:27 PM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
> >>>
> >>> Thanks for the reply Roy!
> >>>
> >>> Perhaps you're showing me the way and I'm missing it - how would I
> >>> subset to only 1030 and 1100, excluding 1000? It seems I would need to
> >>> say, give me all time greater than 10:00, but the hours and minutes
> >>> are in separate slots, which is throwing me off.
> >>>
> >>> Thanks again.
> >>>
> >>> On Mon, Jan 2, 2017 at 1:13 PM, Roy Mendelssohn - NOAA Federal
> >>> <roy.mendelssohn at noaa.gov> wrote:
> >>>> Hi Joe:
> >>>>
> >>>> See below.
> >>>>> On Jan 2, 2017, at 12:01 PM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
> >>>>>
> >>>>> Hi folks,
> >>>>>
> >>>>> I must be missing something obvious/painfully simple here....
> >>>>>
> >>>>> How do I subset a time vector based on hours AND minutes? So, in this
> >>>>> example, I want all time greater than 10:00, i.e., 10:30 and 11:00.
> >>>>> I'm working with lubridate which separates the hours and minutes into
> >>>>> separate slots.
> >>>>>
> >>>>> require(lubridate)
> >>>>>
> >>>>> test <- hm(c("9:30", "10:00", "10:30", "11:00"))
> >>>>> test
> >>>>> [1] "9H 30M 0S"  "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
> >>>>>
> >>>>> This gets 11 but not 1030
> >>>>> test[test at hour > 10]
> >>>>> [1] "11H 0M 0S"
> >>>>>
> >>>>> This gets 1030 but not 11
> >>>>> test[test at hour > 9 & test at minute > 0]
> >>>>> [1] "10H 30M 0S"
> >>>>
> >>>> test[test at hour > 9]
> >>>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
> >>>>
> >>>>
> >>>> You are using a logical "and" in your test - so the condition
> "test at minute > 0" isn't met for 11:00 and therefore it doesn't show up.
> as both conditions must be met  You could also do:
> >>>>
> >>>>> test[test at hour >= 10]
> >>>> [1] "10H 0M 0S"  "10H 30M 0S" "11H 0M 0S"
> >>>>
> >>>> -HTH,
> >>>>
> >>>> Roy
> >>>>
> >>>>>
> >>>>> Thanks and happy new year!
> >>>>> Joe
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> **********************
> >>>> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> >>>> **********************
> >>>> Roy Mendelssohn
> >>>> Supervisory Operations Research Analyst
> >>>> NOAA/NMFS
> >>>> Environmental Research Division
> >>>> Southwest Fisheries Science Center
> >>>> ***Note new street address***
> >>>> 110 McAllister Way
> >>>> Santa Cruz, CA 95060
> >>>> Phone: (831)-420-3666
> >>>> Fax: (831) 420-3980
> >>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> >>>>
> >>>> "Old age and treachery will overcome youth and skill."
> >>>> "From those who have been given much, much will be expected"
> >>>> "the arc of the moral universe is long, but it bends toward justice"
> -MLK Jr.
> >>>>
> >>>
> >>>
> >>>
> >>> --
> >>> Cooperative Fish and Wildlife Research Unit
> >>> Zoology and Physiology Dept.
> >>> University of Wyoming
> >>> JoeCeradini at gmail.com / 914.707.8506
> >>> wyocoopunit.org
> >>
> >> **********************
> >> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> >> **********************
> >> Roy Mendelssohn
> >> Supervisory Operations Research Analyst
> >> NOAA/NMFS
> >> Environmental Research Division
> >> Southwest Fisheries Science Center
> >> ***Note new street address***
> >> 110 McAllister Way
> >> Santa Cruz, CA 95060
> >> Phone: (831)-420-3666
> >> Fax: (831) 420-3980
> >> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> >>
> >> "Old age and treachery will overcome youth and skill."
> >> "From those who have been given much, much will be expected"
> >> "the arc of the moral universe is long, but it bends toward justice"
> -MLK Jr.
> >>
> >
> >
> >
> > --
> > Cooperative Fish and Wildlife Research Unit
> > Zoology and Physiology Dept.
> > University of Wyoming
> > JoeCeradini at gmail.com / 914.707.8506
> > wyocoopunit.org
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>


-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From robin at organplayers.co.uk  Mon Jan  2 20:31:30 2017
From: robin at organplayers.co.uk (robinbt2)
Date: Mon, 2 Jan 2017 19:31:30 -0000
Subject: [R] R in raspberry Pi
Message-ID: <000801d2652e$df6f25b0$9e4d7110$@organplayers.co.uk>

One of the additional free online chapters to my book provides a step by
step guide to downloading and running R on the Raspberry Pi:
http://www.floppybunny.org/robin/web/rbook/online_chapters/r_and_the_raspber
ry_pi.pdf

All the best robin beaumont

For details of the entire book go to:
http://www.amazon.co.uk/dp/190790431X
Books website: http://www.floppybunny.org/robin/web/rbook/ 
producible code.


From zuofengshang at gmail.com  Mon Jan  2 22:24:20 2017
From: zuofengshang at gmail.com (Jeff Shane)
Date: Mon, 2 Jan 2017 16:24:20 -0500
Subject: [R] double subscripts with Greek letter
In-Reply-To: <CACxE24kpKJ8FBh+KUTKpPL_nedLxr4KwWTbhwM7i00L0woq5gg@mail.gmail.com>
References: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
	<CACxE24kpKJ8FBh+KUTKpPL_nedLxr4KwWTbhwM7i00L0woq5gg@mail.gmail.com>
Message-ID: <5841fbc8-d9f2-798e-be20-5bc7cc6392a6@gmail.com>

Thanks, Erin! This works well.


On 2017/1/1 22:37, Erin Hodgess wrote:
> Hello!
>
> Here is a solution:
>
> > plot(1:10)
> > xa <- expression(A[list(alpha,beta)])
> > title(xa)
>
>
>
> On Sun, Jan 1, 2017 at 1:22 PM, Jeff Shane <honolulushane at gmail.com 
> <mailto:honolulushane at gmail.com>> wrote:
>
>     Hi all,
>
>     I have a question which seems trivial but simply cannot figure out its
>     solution.
>
>     I want to type A_{\alpha,\beta} in the title of a plot. Uwe once
>     pointed
>     out a solution
>
>     expression(A[alpha*beta])
>
>     But the output of the above command does not include the "," in the
>     subscript. Is there a way to solve my question? Thanks so much!
>
>     Regards,
>     Jeff
>
>             [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com <mailto:erinm.hodgess at gmail.com>


	[[alternative HTML version deleted]]


From zuofengshang at gmail.com  Mon Jan  2 22:24:53 2017
From: zuofengshang at gmail.com (Jeff Shane)
Date: Mon, 2 Jan 2017 16:24:53 -0500
Subject: [R] double subscripts with Greek letter
In-Reply-To: <CAF8bMcZF0rsD0WK4_-U1-Ya7n+RKiAnLW83TV4sXx5maDATEEQ@mail.gmail.com>
References: <CAB5yqP8ghBn=mPrOdt2y_DAXBvO-+H-w+KV6do5-gZP6SX63Ug@mail.gmail.com>
	<CAF8bMcZF0rsD0WK4_-U1-Ya7n+RKiAnLW83TV4sXx5maDATEEQ@mail.gmail.com>
Message-ID: <389dded0-735e-35b1-749b-de4e8dda55df@gmail.com>

Thanks, Bill! Yes, your code works well.


On 2017/1/1 23:17, William Dunlap wrote:
> Does the following do well enough?
>    plot(1,1);title(expression(A[paste(alpha,",",beta)]))
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Sun, Jan 1, 2017 at 11:22 AM, Jeff Shane <honolulushane at gmail.com 
> <mailto:honolulushane at gmail.com>> wrote:
>
>     Hi all,
>
>     I have a question which seems trivial but simply cannot figure out its
>     solution.
>
>     I want to type A_{\alpha,\beta} in the title of a plot. Uwe once
>     pointed
>     out a solution
>
>     expression(A[alpha*beta])
>
>     But the output of the above command does not include the "," in the
>     subscript. Is there a way to solve my question? Thanks so much!
>
>     Regards,
>     Jeff
>
>             [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Tue Jan  3 02:10:11 2017
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 02 Jan 2017 20:10:11 -0500
Subject: [R] R in raspberry Pi
In-Reply-To: <000801d2652e$df6f25b0$9e4d7110$@organplayers.co.uk>
References: <000801d2652e$df6f25b0$9e4d7110$@organplayers.co.uk>
Message-ID: <586AB3AD020000CB0016B781@smtp.medicine.umaryland.edu>

Robin,
Your chapter sounds very interesting. Unfortunately it appears that it is not available, at least not to me.
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Jan 2, 2017, at 5:57 PM, robinbt2 <robin at organplayers.co.uk> wrote:
> 
> One of the additional free online chapters to my book provides a step by
> step guide to downloading and running R on the Raspberry Pi:
> http://www.floppybunny.org/robin/web/rbook/online_chapters/r_and_the_raspber
> ry_pi.pdf
> 
> All the best robin beaumont
> 
> For details of the entire book go to:
> http://www.amazon.co.uk/dp/190790431X
> Books website: http://www.floppybunny.org/robin/web/rbook/ 
> producible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From peter.langfelder at gmail.com  Tue Jan  3 02:16:42 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 2 Jan 2017 17:16:42 -0800
Subject: [R] R in raspberry Pi
In-Reply-To: <586AB3AD020000CB0016B781@smtp.medicine.umaryland.edu>
References: <000801d2652e$df6f25b0$9e4d7110$@organplayers.co.uk>
	<586AB3AD020000CB0016B781@smtp.medicine.umaryland.edu>
Message-ID: <CA+hbrhWENkm=woWwRfpOfmHg7MYx5pRRYTrYL3+WLtoTUQ483A@mail.gmail.com>

I can see the file under this link:

http://www.floppybunny.org/robin/web/rbook/online_chapters/r_and_the_raspberry_pi.pdf

Make sure the (English) words are not split - my first attempt
contained raspber_ry and thus it failed.

Peter

On Mon, Jan 2, 2017 at 5:10 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> Robin,
> Your chapter sounds very interesting. Unfortunately it appears that it is not available, at least not to me.
> John
>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>> On Jan 2, 2017, at 5:57 PM, robinbt2 <robin at organplayers.co.uk> wrote:
>>
>> One of the additional free online chapters to my book provides a step by
>> step guide to downloading and running R on the Raspberry Pi:
>> http://www.floppybunny.org/robin/web/rbook/online_chapters/r_and_the_raspber
>> ry_pi.pdf
>>
>> All the best robin beaumont
>>
>> For details of the entire book go to:
>> http://www.amazon.co.uk/dp/190790431X
>> Books website: http://www.floppybunny.org/robin/web/rbook/
>> producible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From csujasekhar at gmail.com  Tue Jan  3 10:38:37 2017
From: csujasekhar at gmail.com (Suja Sekhar C)
Date: Tue, 3 Jan 2017 15:08:37 +0530
Subject: [R] Reg. odds ratio for Nested logit model
Message-ID: <CAD5iE4h8LPPmS5kfw3f4j-8NYLJ0ZtirF5wW+A+ShK7OxSBBBg@mail.gmail.com>

Hi,

I am new to R. I find that I can get the odds ratio of a logit regression
by typing exp(coef(result)) . However for a nested logit model with an
inclusive value parameter, I am not sure how to get the odds ratio.
My code is below, with m1 containing my results. Please help me to get the
odds-ratios from the coefficients.

library(mlogit)
> dat1<- read.csv("Desktop/me.csv")
> dat1$id <- 1:11304
> dat1$mode <- as.character(dat1$choice_t)
# choice_t is my variable that takes a value 0 ,1 or 2. Here 0 is the only
branch for option A and 1 and 2 are sub-branches of option B.

mdat1 <- subset(dat1, select = c("mode?,?x1?,?x2?, ?x3?,?x4?, ?id"))
> ndat1 <- mlogit.data(mdat1, shape="wide", choice="mode")
# This creates 2 other alternatives as per the requirement of Nested Logit
model. There should be a set of variables for all the options 0, 1, and 2.
File ndat1 has therefore 3*11304 = 33912 firm- year observations.

Mode variable =1 for the choice that the firm makes in that year. So if the
firm has made a choice of 2 in an year it will take the value 1 for only
that firm-year observation.
> m1 <- mlogit(mode ~ 1| x1+x2+x3+x4, data=ndat1, + nests =
list(optionA=c("0"), optionB=c("1","2")),un.nest.el=TRUE )

> summary(m1)


Thank you,

Suja

	[[alternative HTML version deleted]]


From pwd7052 at yahoo.com  Tue Jan  3 07:20:25 2017
From: pwd7052 at yahoo.com (PWD7052)
Date: Tue, 3 Jan 2017 06:20:25 +0000 (UTC)
Subject: [R] Network validation (of sorts) using granger Causality in R
References: <1699499359.6140336.1483424425564.ref@mail.yahoo.com>
Message-ID: <1699499359.6140336.1483424425564@mail.yahoo.com>

Hi Everyone,

We have a question about whether one can to do a particular type of Granger Causality (GC) network validation in R. We hope you'll agree it's an interesting problem and that someone's figured out how to solve it.

We have a cellular network with n nodes (proteins).? We have two different n x s x k time series matrices that describe the network activity under two mutually exclusive conditions, C (cancerous cell) and H (healthy cell), where s is the length of the time series data, and k is the number of observations.
Using the time series matrices, we calculated two different n x n GC matrices, one for healthy cells and one for cancerous cells, so that ij th element in each matrix represents the GC influence of node i on node j.? Using the various standard tests, we know that many of the GC values are extremely significant.
Now we?re given a brand-new observation in the form of a n x s x 1 time series matrix Y that represents the activity of the same n nodes (we don?t know a priori whether the new data come from a healthy cell or a cancerous cell).
Given this matrix Y :
(1) How can we go about determining if Y comes from a cancerous cell (condition C) or a healthy cell (condition H)?
(2) Is there a package in R that we can use for this purpose?

Thank you very much!
Pat

	[[alternative HTML version deleted]]


From amelia_marsh08 at yahoo.com  Tue Jan  3 11:59:33 2017
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Tue, 3 Jan 2017 10:59:33 +0000 (UTC)
Subject: [R] Difference in Generalized Extreme Value distribution parameter
 estimations using lmom and fExtremes
References: <1723854341.6923937.1483441173108.ref@mail.yahoo.com>
Message-ID: <1723854341.6923937.1483441173108@mail.yahoo.com>

Dear R forum

I have following dataset

amounts = c(2803102.248,1088675.278,10394575.14,1007368.396,1004871.328,1092956.088,1020110.818,997371.4487,1000904.154,998105.9744,997434.3006,1080067.258,997594.7992,1000871.015,1001321.094,1000713.448,997591.2307,1469501.54,1066924.393,1074918.566,998628.6216,1002538.482,1056969.243,997386.2638,1.36951E+11,997996.9907,1001257.498,998297.1517,5253186.541,1005503.303,997785.7993,997327.4303,1037039.271,997353.5027,998297.0299,1072558.563,2713147.593,997679.0361,1015856.216,1424576097,999165.4936,998038.8554,3221340.057,1009576.799,5.84277E+12,18595873.96,1054794.099,1005800.558,997533.8031,997347.4897,2208865120,4224689.441,997660.4156,997325.1814,46809107.76,1200682.819,998921.9662,997540.1311,997594.3338,1109023.716,1007961.274,1939821.599,998260.2296,175808356.8,1005375.437,997412.0361,997383.9452,998863.5354,1554312.55,997791.3639,997355.1921,997476.2689,14557283.34,997937.3784,1013997.695,1006244.593,999265.8925,1052001.211,1005484.306,1258924.294,998740.9426,997896.5631,3613729.605,1000823.697,1656621.398,997874.4055,1056353.896,1000380.152,997576.3836,997442.5109,998563.4918,1032782.759,1010023.106,998578.6725,997344.4766,997310.5771,1002905.434,86902124.97,998396.3911,1245564.907) 


Using this dataset, I am trying to estimate the parameter values of Extreme Value Distribution. I am using the libraries lmom and fExtremes as follows:


library(lmom) 
library(fExtremes)

#____________________________________________________________ 


# Parameter estimation : Using lmom 


lmom <- samlmu(amounts) 
(parameters_of_GEV_lmom <- pelgev(lmom)) 


# OUTPUT: 

> parameters_of_GEV_lmom <- pelgev(lmom); parameters_of_GEV_lmom 


xi                      # Location Parameter
8.883402e+06

alpha                 # Scale Paramter
5.692228e+07 

k                       # Shape Parameter
-9.990491e-01 



# ________________________________________________________________________



# Parameter estimation : Using fExtremes

(parameters_of_GEV_fExtremes <- gevFit(amounts, type = "pwm")) 

# OUTPUT: 

Title: 
GEV Parameter Estimation 

Call: 
gevFit(x = amounts, type = "pwm") 

Estimation Type: 
gev pwm 

Estimated Parameters: 


xi                        # Shape Parameter
9.990479e-01


mu                       # Location Parameter
8.855115e+06


beta                      # Scale paramter
5.699583e+07 



# __________________________________________________________________

While it is obvious that the parameter values will differ as lmom is using L moments and fExtremes is using Probability Weighted Moment, my concern is about the shape parameter. The value of shape parameter is same across all methods except the sign.

While lmom estimates shape parameter = -0.99905, fExtremes estimates shape parameter = 0.99905. When I have used Statistical software to estimate the parameters, I got the parameter values exactly tallying with what lmom is generating but scale parameter was equal to 0.99905 (Positive value same as fExtremes value) and not -0.99905 which is generated by lmom libraray.

Can some one guide me.


With regards

Amelia


From paulbernal07 at gmail.com  Tue Jan  3 13:51:07 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 3 Jan 2017 07:51:07 -0500
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <DM5PR1601MB1147065D4B5DE2F83369C1E8F76B0@DM5PR1601MB1147.namprd16.prod.outlook.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<DM5PR1601MB1147065D4B5DE2F83369C1E8F76B0@DM5PR1601MB1147.namprd16.prod.outlook.com>
Message-ID: <CAMOcQfPLC=seYkLyd+c6=CHva5J0q0HOaEb=9sWGR3LaSh0T+Q@mail.gmail.com>

Hello Paulo,

Thanks for the reply. As a matter of fact, I used the command
install.packages("rzmq"), however, the error message kept showing.

Best regards,

Paul

2016-12-29 16:26 GMT-05:00 Paulo Moniz <pmoniz7 at hotmail.com>:

> hi Bernal, wouldn't the right  command be - install.packages("rzmq")
>
>
>
>
>
>
> ------------------------------
> *De:* R-help <r-help-bounces at r-project.org> em nome de Paul Bernal <
> paulbernal07 at gmail.com>
> *Enviado:* quinta-feira, 29 de dezembro de 2016 20:23
> *Para:* r-help at r-project.org; r-devel at r-project.org
> *Assunto:* [R] Problems when trying to install and load package "rzmq"
>
> After connecting to a mirror, I typed the following command:
>
> install.packages("rzqm")
>
> but I received the following message:
>
> ERROR: compilation failed for package 'rzmq'
>
> removing 'E:/Documents/R/win-library/3.3/rzmq'
>
> package which is only available in source form, and may need compilation of
> C/C++/Fortran: 'rzmq'
> These will not be installed
>
> The computer environment is Windows 8 64x bits
>
>
> Any help and/or guidance will be greatly appreciated
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> R-help -- Main R Mailing List: Primary help - Homepage - SfS
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and
> the availability of new code, questions and answers about problems and
> solutions using R ...
>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jan  3 14:56:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 Jan 2017 05:56:08 -0800
Subject: [R] Network validation (of sorts) using granger Causality in R
In-Reply-To: <1699499359.6140336.1483424425564@mail.yahoo.com>
References: <1699499359.6140336.1483424425564.ref@mail.yahoo.com>
	<1699499359.6140336.1483424425564@mail.yahoo.com>
Message-ID: <CAGxFJbQeofmq75CHmNYGnG-Gpy-+NQ-dCYZxzshCb040hJdtDg@mail.gmail.com>

Have you searched?!

"Granger causality" at rseek.org brought up what appeared to be many
relevant hits.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 2, 2017 at 10:20 PM, PWD7052 via R-help
<r-help at r-project.org> wrote:
> Hi Everyone,
>
> We have a question about whether one can to do a particular type of Granger Causality (GC) network validation in R. We hope you'll agree it's an interesting problem and that someone's figured out how to solve it.
>
> We have a cellular network with n nodes (proteins).  We have two different n x s x k time series matrices that describe the network activity under two mutually exclusive conditions, C (cancerous cell) and H (healthy cell), where s is the length of the time series data, and k is the number of observations.
> Using the time series matrices, we calculated two different n x n GC matrices, one for healthy cells and one for cancerous cells, so that ij th element in each matrix represents the GC influence of node i on node j.  Using the various standard tests, we know that many of the GC values are extremely significant.
> Now we?re given a brand-new observation in the form of a n x s x 1 time series matrix Y that represents the activity of the same n nodes (we don?t know a priori whether the new data come from a healthy cell or a cancerous cell).
> Given this matrix Y :
> (1) How can we go about determining if Y comes from a cancerous cell (condition C) or a healthy cell (condition H)?
> (2) Is there a package in R that we can use for this purpose?
>
> Thank you very much!
> Pat
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erdogancevher at gmail.com  Tue Jan  3 12:47:37 2017
From: erdogancevher at gmail.com (Erdogan CEVHER)
Date: Tue, 3 Jan 2017 14:47:37 +0300
Subject: [R] Network validation (of sorts) using granger Causality in R
In-Reply-To: <1699499359.6140336.1483424425564@mail.yahoo.com>
References: <1699499359.6140336.1483424425564.ref@mail.yahoo.com>
	<1699499359.6140336.1483424425564@mail.yahoo.com>
Message-ID: <CABrXyQUb2o9S0s8Z5tRJV2DDfJxt6DrHMSGs4ReXvomq3+WGcw@mail.gmail.com>

1. Describe better the distributions of obs to time series; i.e., describe
clearly the time series and obs with math'l notation briefly.

2. Use Conditional G-causality and/or partial G-causality, you can exceed
"the limit of max. number of variables = 11" in a VAR structure.

3. You can use R's FIAR package for CGC / PGC calculations. I advise
version 3 of that package.

4. Kamamoto Oscillators for "Graphical" GC methods perhaps may well suit to
your case.

5. Matlab's GCCA and MVGC packages cannot handle cointegration (in case
cointegrated vars exist) whereas you can handle cointegrated cases via CGC
and PGC.

2017-01-03 9:20 GMT+03:00 PWD7052 via R-help <r-help at r-project.org>:

> Hi Everyone,
>
> We have a question about whether one can to do a particular type of
> Granger Causality (GC) network validation in R. We hope you'll agree it's
> an interesting problem and that someone's figured out how to solve it.
>
> We have a cellular network with n nodes (proteins).  We have two different
> n x s x k time series matrices that describe the network activity under two
> mutually exclusive conditions, C (cancerous cell) and H (healthy cell),
> where s is the length of the time series data, and k is the number of
> observations.
> Using the time series matrices, we calculated two different n x n GC
> matrices, one for healthy cells and one for cancerous cells, so that ij th
> element in each matrix represents the GC influence of node i on node j.
> Using the various standard tests, we know that many of the GC values are
> extremely significant.
> Now we?re given a brand-new observation in the form of a n x s x 1 time
> series matrix Y that represents the activity of the same n nodes (we don?t
> know a priori whether the new data come from a healthy cell or a cancerous
> cell).
> Given this matrix Y :
> (1) How can we go about determining if Y comes from a cancerous cell
> (condition C) or a healthy cell (condition H)?
> (2) Is there a package in R that we can use for this purpose?
>
> Thank you very much!
> Pat
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Tue Jan  3 16:26:26 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 3 Jan 2017 10:26:26 -0500
Subject: [R] [Rd] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
	<387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>
	<CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>
Message-ID: <CAMOcQfOz_JX7iwVX0Z7Pys9u4Er_hDRdeTevmqnQwx=jg9q1AQ@mail.gmail.com>

Dear Whit,

Thank you for your valuable and kind reply. I will take a look at the link
you provided, however, I would also like to try to compile libzmq sources
for windows with R?s mingw, how can I do this? Or where can I find any
documents or guidance to try this?

Any help will be greatly appreciated,

Best regards,

Paul

2017-01-03 9:53 GMT-05:00 Whit Armstrong <armstrong.whit at gmail.com>:

> Hi, Paul.
>
> I maintian the rzmq project.
>
> love to get it running on windows, but zmq doesn't play nicely with R's
> mingw.
>
> These guys have taken the approach of building the entire zmq library
> inside the R package:
> https://github.com/snoweye/pbdZMQ
>
> I suggest you give it a try. or if you want to attempt to compile libzmq
> sources for windows w/ R's mingw, that would be welcome.
>
> -Whit
>
>
> On Tue, Jan 3, 2017 at 9:36 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> Possibly so.
>>
>> However, the ZeroMQ libraries do exist for Windows, so it might be
>> possible to get the package working there. However, CRAN probably won't
>> have the libraries, so cannot produce a binary package, and it is also
>> quite possible that the package author is not a Windows person.
>>
>> At the very least, you'll need some familiarity with the Windows
>> toolchain and be prepared to apply a fair amount of elbow grease.
>>
>> -pd
>>
>> (crosspost to r-help removed)
>>
>> On 29 Dec 2016, at 22:04 , Paul Bernal <paulbernal07 at gmail.com> wrote:
>>
>> > Dear Jeff,
>> >
>> > Thank you for your fast and kind reply. When you say that you do not
>> think
>> > this can be done on windows, then I would have to use something like
>> Ubuntu
>> > or Linux?
>> >
>> > Best regards
>> >
>> > Paul
>> >
>> > 2016-12-29 16:00 GMT-05:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> >
>> >> Read the system requirements [1]. I don't think you can do this on
>> windows.
>> >>
>> >> [1] https://cran.r-project.org/web/packages/rzmq/index.html
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On December 29, 2016 12:23:26 PM PST, Paul Bernal <
>> paulbernal07 at gmail.com>
>> >> wrote:
>> >>> After connecting to a mirror, I typed the following command:
>> >>>
>> >>> install.packages("rzqm")
>> >>>
>> >>> but I received the following message:
>> >>>
>> >>> ERROR: compilation failed for package 'rzmq'
>> >>>
>> >>> removing 'E:/Documents/R/win-library/3.3/rzmq'
>> >>>
>> >>> package which is only available in source form, and may need
>> >>> compilation of
>> >>> C/C++/Fortran: 'rzmq'
>> >>> These will not be installed
>> >>>
>> >>> The computer environment is Windows 8 64x bits
>> >>>
>> >>>
>> >>> Any help and/or guidance will be greatly appreciated
>> >>>
>> >>>      [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Jan  3 16:28:08 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 3 Jan 2017 15:28:08 +0000
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMOcQfPLC=seYkLyd+c6=CHva5J0q0HOaEb=9sWGR3LaSh0T+Q@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<DM5PR1601MB1147065D4B5DE2F83369C1E8F76B0@DM5PR1601MB1147.namprd16.prod.outlook.com>
	<CAMOcQfPLC=seYkLyd+c6=CHva5J0q0HOaEb=9sWGR3LaSh0T+Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC1D3@SRVEXCHCM301.precheza.cz>

Hi

It is clearly seen from CRAN that there is no binary for windows. So you either need to migrate to linux or you need to compile the package from source or maybe both.

You need to study how to compile a package as it is usually not trivial task, especially for somebody who does not compile packages regularly, as myself.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Bernal
> Sent: Tuesday, January 3, 2017 1:51 PM
> To: Paulo Moniz <pmoniz7 at hotmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Problems when trying to install and load package "rzmq"
>
> Hello Paulo,
>
> Thanks for the reply. As a matter of fact, I used the command
> install.packages("rzmq"), however, the error message kept showing.
>
> Best regards,
>
> Paul
>
> 2016-12-29 16:26 GMT-05:00 Paulo Moniz <pmoniz7 at hotmail.com>:
>
> > hi Bernal, wouldn't the right  command be - install.packages("rzmq")
> >
> >
> >
> >
> >
> >
> > ------------------------------
> > *De:* R-help <r-help-bounces at r-project.org> em nome de Paul Bernal <
> > paulbernal07 at gmail.com>
> > *Enviado:* quinta-feira, 29 de dezembro de 2016 20:23
> > *Para:* r-help at r-project.org; r-devel at r-project.org
> > *Assunto:* [R] Problems when trying to install and load package "rzmq"
> >
> > After connecting to a mirror, I typed the following command:
> >
> > install.packages("rzqm")
> >
> > but I received the following message:
> >
> > ERROR: compilation failed for package 'rzmq'
> >
> > removing 'E:/Documents/R/win-library/3.3/rzmq'
> >
> > package which is only available in source form, and may need
> > compilation of
> > C/C++/Fortran: 'rzmq'
> > These will not be installed
> >
> > The computer environment is Windows 8 64x bits
> >
> >
> > Any help and/or guidance will be greatly appreciated
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > R-help -- Main R Mailing List: Primary help - Homepage - SfS
> > <https://stat.ethz.ch/mailman/listinfo/r-help>
> > stat.ethz.ch
> > The main R mailing list, for announcements about the development of R
> > and the availability of new code, questions and answers about problems
> > and solutions using R ...
> >
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mehall at blm.gov  Tue Jan  3 16:55:53 2017
From: mehall at blm.gov (Hall, Mark)
Date: Tue, 3 Jan 2017 07:55:53 -0800
Subject: [R] Fitting Hastie's principal surfaces in R
In-Reply-To: <AM2PR04MB08526D37DFF467206247A552C16C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
References: <AM2PR04MB08526D37DFF467206247A552C16C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
Message-ID: <CANNh0ze8JodYj7B_iJgh0mmrK4pzUx_uRZp-4tdiY0VLH3+jTQ@mail.gmail.com>

Did you search for the princurve package?  Sounds like it may be what you
want.
See https://cran.r-project.org/web/packages/princurve/index.html

Best, MEH

Mark E. Hall, PhD
Assistant Field Manager
Black Rock Field Office
Winnemucca District Office
775-623-1529.

On Sun, Jan 1, 2017 at 2:56 AM, Neverstop . <neverstop at hotmail.it> wrote:

> Hello,
>
> I need to summarize a three-dimensional dataset through a principal
> surface that passes through the middle of the data. Principal surfaces are
> non-linear generalization of the plane created by the first two principal
> components and provide a non-linear summary of p-dimensional dataset.
> Principal surfaces are described in this 1989 article by Hastie and
> Stuetzle: https://web.stanford.edu/~hastie/Papers/Principal_Curves.pdf .
> They were introduced by Trevor Hastie in his Ph.D dissertation:
> http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-r-276.pdf
>
> I'm looking for a package to fit principal surfaces with R.
> I've come across the package princurve created by TrevorHastie, but it
> allows to fit principal curves only. How can I fit two-dimensional
> principal surfaces in R?
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Tue Jan  3 19:46:49 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 3 Jan 2017 13:46:49 -0500
Subject: [R] How to check R kernel (IRkernel) version used in Jupyter
Message-ID: <CAMOcQfOhefFJcVGhy_G3vquw-bQVS8GP7G7AmU+cdMDiyCY=3g@mail.gmail.com>

Dear friends,

I would like to know how can I do to check which IRkernel version I am
currently using?

Thanks beforehand for any valuable information you can share,

Best regards,

Paul

	[[alternative HTML version deleted]]


From alachanc at bates.edu  Tue Jan  3 17:27:24 2017
From: alachanc at bates.edu (Andrew Lachance)
Date: Tue, 3 Jan 2017 11:27:24 -0500
Subject: [R] XML to CSV
Message-ID: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>

up votdown votefavorite
<http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>

I am completely new to R and have tried to use several functions within the
xml packages to convert an XML to a csv and have had little success. Since
I am so new, I am not sure what the necessary steps are to complete this
conversion without a lot of NA.

-- 
Andrew D. Lachance
Chief of Service, Bates Emergency Medical Service
Residence Coordinator, Hopkins House
Bates College Class of 2017
alachanc at bates.edu <wcurley at bates.edu>
(207) 620-4854

	[[alternative HTML version deleted]]


From chuck.snell.email at gmail.com  Tue Jan  3 18:15:50 2017
From: chuck.snell.email at gmail.com (Chuck Snell)
Date: Tue, 3 Jan 2017 11:15:50 -0600
Subject: [R] machine learning goal (new to R )
Message-ID: <CAB7MhXh4w0DU1_ZOAuCu+md1PwtWcWwZO6eJwk2sSv+MRu2Ztg@mail.gmail.com>

Hello,

I am new to R, a computer programmer friend of mine recommended R for a
project I have on my plate.

(He is not a R guy but knows I need to consider it for the problem I
described to him)

Frist, I have plenty of data

I have been doing this task with regression models but was asked to try to
improve my accuracy.

I am forecasting an "output" which is numerical based upon forecasted
weather.

for extreme weather and stable weather my regression does decent. Meaning,
really cold and hot weather that has been cold or hot for a while.

What I miss is when things change, meaning if we have had mild weather then
a sudden change, intuitively we know things won't behave as if it had been
cold (or hot) for the last week or so but my regression obviously does not
consider the "history" or patterns.

What was suggested to me was consider some machine learning to identify the
patterns and so forth.

I have R installed and started searching around the libraries - seems
overwhelming.

I have found an example of machine learning for R that did "categories" -
maybe of flowers not sure.

What I need is not categories but a number for an estimate / forecast,

Can you recommend some routines / libraries / techniques to consider?

Thanks

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Jan  3 20:11:20 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 3 Jan 2017 14:11:20 -0500
Subject: [R] machine learning goal (new to R )
In-Reply-To: <CAB7MhXh4w0DU1_ZOAuCu+md1PwtWcWwZO6eJwk2sSv+MRu2Ztg@mail.gmail.com>
References: <CAB7MhXh4w0DU1_ZOAuCu+md1PwtWcWwZO6eJwk2sSv+MRu2Ztg@mail.gmail.com>
Message-ID: <CAM_vjukC94wyeHbCUJ_AvnMZUkOt18q5orp26EvOpA5nHMYK2w@mail.gmail.com>

There are a lot of machine learning options in R:
https://cran.r-project.org/web/views/MachineLearning.html

It sounds like you need to back up a step, and do some reading on the
statistical underpinnings of machine learning before you try to figure
out how to implement a particular method.

There are an enormous number of references online, from brief articles
to full courses. Here's one possible starting point:
https://statweb.stanford.edu/~tibs/ElemStatLearn/

The options are far too complex and numerous for anyone here to be
able to tell you the "right method" to use.

Sarah

On Tue, Jan 3, 2017 at 12:15 PM, Chuck Snell
<chuck.snell.email at gmail.com> wrote:
> Hello,
>
> I am new to R, a computer programmer friend of mine recommended R for a
> project I have on my plate.
>
> (He is not a R guy but knows I need to consider it for the problem I
> described to him)
>
> Frist, I have plenty of data
>
> I have been doing this task with regression models but was asked to try to
> improve my accuracy.
>
> I am forecasting an "output" which is numerical based upon forecasted
> weather.
>
> for extreme weather and stable weather my regression does decent. Meaning,
> really cold and hot weather that has been cold or hot for a while.
>
> What I miss is when things change, meaning if we have had mild weather then
> a sudden change, intuitively we know things won't behave as if it had been
> cold (or hot) for the last week or so but my regression obviously does not
> consider the "history" or patterns.
>
> What was suggested to me was consider some machine learning to identify the
> patterns and so forth.
>
> I have R installed and started searching around the libraries - seems
> overwhelming.
>
> I have found an example of machine learning for R that did "categories" -
> maybe of flowers not sure.
>
> What I need is not categories but a number for an estimate / forecast,
>
> Can you recommend some routines / libraries / techniques to consider?
>
> Thanks
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From btupper at bigelow.org  Tue Jan  3 20:29:38 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 3 Jan 2017 14:29:38 -0500
Subject: [R] XML to CSV
In-Reply-To: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>
References: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>
Message-ID: <B41EB1BE-2E3F-4315-9D72-F434D8DB353E@bigelow.org>

Hi,

It's hard to know what to advise - much depends upon the XML data you have and what you want to extract from it. Without knowing about those two things there is little anyone could do to help.  Can you post to the internet a to example data and provide the link here?  Then state explicitly what you want to have in hand at the end.

If you are just starting out I suggest that you try xml2 package ( https://cran.r-project.org/web/packages/xml2/ ) rather than XML package ( https://cran.r-project.org/web/packages/XML/ ). I have been using it much more since the authors added the ability to create xml nodes (rather than just extracting data from existing xml nodes).  

Cheers,
Ben

P.S.  Hello to my niece Olivia S on the Bates EMS team.


> On Jan 3, 2017, at 11:27 AM, Andrew Lachance <alachanc at bates.edu> wrote:
> 
> up votdown votefavorite
> <http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>
> 
> I am completely new to R and have tried to use several functions within the
> xml packages to convert an XML to a csv and have had little success. Since
> I am so new, I am not sure what the necessary steps are to complete this
> conversion without a lot of NA.
> 
> -- 
> Andrew D. Lachance
> Chief of Service, Bates Emergency Medical Service
> Residence Coordinator, Hopkins House
> Bates College Class of 2017
> alachanc at bates.edu <wcurley at bates.edu>
> (207) 620-4854
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From paulbernal07 at gmail.com  Tue Jan  3 20:45:55 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 3 Jan 2017 14:45:55 -0500
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC1D3@SRVEXCHCM301.precheza.cz>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<DM5PR1601MB1147065D4B5DE2F83369C1E8F76B0@DM5PR1601MB1147.namprd16.prod.outlook.com>
	<CAMOcQfPLC=seYkLyd+c6=CHva5J0q0HOaEb=9sWGR3LaSh0T+Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC1D3@SRVEXCHCM301.precheza.cz>
Message-ID: <CAMOcQfMZmDxuW0uEywbG6jY+Qm3UHsH9Z5N9wuRnfDGLq6kFFQ@mail.gmail.com>

Hello Petr,

Is it possible to compile the package (rzmq) from Ubuntu for Windows?

Best regards,

Paul

2017-01-03 10:28 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> It is clearly seen from CRAN that there is no binary for windows. So you
> either need to migrate to linux or you need to compile the package from
> source or maybe both.
>
> You need to study how to compile a package as it is usually not trivial
> task, especially for somebody who does not compile packages regularly, as
> myself.
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> > Bernal
> > Sent: Tuesday, January 3, 2017 1:51 PM
> > To: Paulo Moniz <pmoniz7 at hotmail.com>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Problems when trying to install and load package "rzmq"
> >
> > Hello Paulo,
> >
> > Thanks for the reply. As a matter of fact, I used the command
> > install.packages("rzmq"), however, the error message kept showing.
> >
> > Best regards,
> >
> > Paul
> >
> > 2016-12-29 16:26 GMT-05:00 Paulo Moniz <pmoniz7 at hotmail.com>:
> >
> > > hi Bernal, wouldn't the right  command be - install.packages("rzmq")
> > >
> > >
> > >
> > >
> > >
> > >
> > > ------------------------------
> > > *De:* R-help <r-help-bounces at r-project.org> em nome de Paul Bernal <
> > > paulbernal07 at gmail.com>
> > > *Enviado:* quinta-feira, 29 de dezembro de 2016 20:23
> > > *Para:* r-help at r-project.org; r-devel at r-project.org
> > > *Assunto:* [R] Problems when trying to install and load package "rzmq"
> > >
> > > After connecting to a mirror, I typed the following command:
> > >
> > > install.packages("rzqm")
> > >
> > > but I received the following message:
> > >
> > > ERROR: compilation failed for package 'rzmq'
> > >
> > > removing 'E:/Documents/R/win-library/3.3/rzmq'
> > >
> > > package which is only available in source form, and may need
> > > compilation of
> > > C/C++/Fortran: 'rzmq'
> > > These will not be installed
> > >
> > > The computer environment is Windows 8 64x bits
> > >
> > >
> > > Any help and/or guidance will be greatly appreciated
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > R-help -- Main R Mailing List: Primary help - Homepage - SfS
> > > <https://stat.ethz.ch/mailman/listinfo/r-help>
> > > stat.ethz.ch
> > > The main R mailing list, for announcements about the development of R
> > > and the availability of new code, questions and answers about problems
> > > and solutions using R ...
> > >
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html and provide commented, minimal, self-contained,
> > > reproducible code.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Jan  3 22:30:43 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 4 Jan 2017 10:30:43 +1300
Subject: [R] [FORGED] Re: Problems when trying to install and load
 package "rzmq"
In-Reply-To: <CAMOcQfMZmDxuW0uEywbG6jY+Qm3UHsH9Z5N9wuRnfDGLq6kFFQ@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<DM5PR1601MB1147065D4B5DE2F83369C1E8F76B0@DM5PR1601MB1147.namprd16.prod.outlook.com>
	<CAMOcQfPLC=seYkLyd+c6=CHva5J0q0HOaEb=9sWGR3LaSh0T+Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC1D3@SRVEXCHCM301.precheza.cz>
	<CAMOcQfMZmDxuW0uEywbG6jY+Qm3UHsH9Z5N9wuRnfDGLq6kFFQ@mail.gmail.com>
Message-ID: <b4600313-e4a5-9f93-e146-48bd58b1b537@auckland.ac.nz>

On 04/01/17 08:45, Paul Bernal wrote:
> Hello Petr,
>
> Is it possible to compile the package (rzmq) from Ubuntu for Windows?

No.  At least in my understanding, if you want a package to run on 
Windoze, you have to compile it for Windoze, on Windoze, using compilers 
that are adapted to Windoze.

A feasible approach for you would be to use the win-builder facility.
See the URL:

     https://win-builder.r-project.org/

You would have to be able to

* un-tar the source package
* edit the DESCRIPTION file so as to insert *your* email address
   under "maintainer"
* rebuild the (edited) package

To do this you would probably need to work on a Linux system.

Good luck.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From paulbernal07 at gmail.com  Tue Jan  3 22:49:37 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 3 Jan 2017 16:49:37 -0500
Subject: [R] Error when trying to install rzmq continued
Message-ID: <CAMOcQfM2-ibk+4L7Zn0dfaqLCbQEOu94f-icyofveCnhoHDxDg@mail.gmail.com>

Dear friends,

Thanks to all of you who took a a time to try to guide me. I get this error
message.

> install_github('armstrtw/rzmq')
Error in curl::curl_fetch_disk(url, x$path, handle = handle) :
  Couldn't connect to server

Any other way to work this out? My final goal is to get Jupyter to work
with R (be able to use R notebooks not just Python notebooks).

Best of regards and happy new year to all,

Paul

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Jan  3 23:43:50 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 3 Jan 2017 14:43:50 -0800
Subject: [R] getTimeLimit?
Message-ID: <CAF8bMca5J+Jv52O+iUXEfMQPRm31npx1t3q6q_3DarLk=t3j+Q@mail.gmail.com>

I am interested in measuring the time it takes to run an expression.
 system.time(expr) does this but I would like to have it report just 'more
than xxx seconds', where xxx is a argument to the timing function, when it
takes a long time.  This is useful automating the process of seeing how
processing time grows with the size of a dataset.

My latest attempt is the following function, which adds a 'censored=TRUE'
attribute when the cpu or elapsed time exceeds some limit:

system.time2 <- function (expr, gcFirst = TRUE, cpu = Inf, elapsed = Inf)
{
    setTimeLimit(cpu = cpu, elapsed = elapsed, transient = TRUE)
    censored <- NULL
    time <- system.time(gcFirst = gcFirst, tryCatch(expr, error =
function(e) if (grepl("reached (CPU|elapsed) time limit",
        conditionMessage(e)))
        censored <<- conditionMessage(e)
    else stop(e)))
    attr(time, "censored") <- censored
    time
}

It would be used as

> system.time(times <- lapply(10^(1:7), function(n)system.time2(for(i in
1:n)lgamma(1:i), elapsed=10) ))
   user  system elapsed
  33.55    0.25   33.82
> vapply(times, function(t)t[["elapsed"]], 0)
[1]  0.02  0.00  0.03  3.08 10.02 10.14 10.18
> # following gives which times are valid
> vapply(times, function(t)is.null(attr(t,"censored")), NA)
[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE

I have two questions.
* Is this a reasonable way to compute such a censored time?
* Is there a getTimeLimit()-like function?

Also, I think it would be nice if the error thrown when timing out had a
special class so I didn't have to rely on grepping the error message, but
that is true of lots of errors.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Jan  4 00:55:13 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 3 Jan 2017 15:55:13 -0800
Subject: [R] getTimeLimit?
In-Reply-To: <CAF8bMca5J+Jv52O+iUXEfMQPRm31npx1t3q6q_3DarLk=t3j+Q@mail.gmail.com>
References: <CAF8bMca5J+Jv52O+iUXEfMQPRm31npx1t3q6q_3DarLk=t3j+Q@mail.gmail.com>
Message-ID: <CAFDcVCQLvWR28wvvMOB_8O4bOc0zAh8qJDD=cVNYTsdSKMPt1w@mail.gmail.com>

On Tue, Jan 3, 2017 at 2:43 PM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> I am interested in measuring the time it takes to run an expression.
>  system.time(expr) does this but I would like to have it report just 'more
> than xxx seconds', where xxx is a argument to the timing function, when it
> takes a long time.  This is useful automating the process of seeing how
> processing time grows with the size of a dataset.
>
> My latest attempt is the following function, which adds a 'censored=TRUE'
> attribute when the cpu or elapsed time exceeds some limit:
>
> system.time2 <- function (expr, gcFirst = TRUE, cpu = Inf, elapsed = Inf)
> {
>     setTimeLimit(cpu = cpu, elapsed = elapsed, transient = TRUE)
>     censored <- NULL
>     time <- system.time(gcFirst = gcFirst, tryCatch(expr, error =
> function(e) if (grepl("reached (CPU|elapsed) time limit",
>         conditionMessage(e)))
>         censored <<- conditionMessage(e)
>     else stop(e)))
>     attr(time, "censored") <- censored
>     time
> }
>
> It would be used as
>
>> system.time(times <- lapply(10^(1:7), function(n)system.time2(for(i in
> 1:n)lgamma(1:i), elapsed=10) ))
>    user  system elapsed
>   33.55    0.25   33.82
>> vapply(times, function(t)t[["elapsed"]], 0)
> [1]  0.02  0.00  0.03  3.08 10.02 10.14 10.18
>> # following gives which times are valid
>> vapply(times, function(t)is.null(attr(t,"censored")), NA)
> [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>
> I have two questions.
> * Is this a reasonable way to compute such a censored time?
> * Is there a getTimeLimit()-like function?

I also wanted such a function, but I don't think it exists.
Internally in R the timeout is set in global variables 'cpuLimitValue'
and 'elapsedLimitValue'.  Grepping the source for it doesn't reveal
any external access to it, e.g.

$ grep -F "cpuLimitValue" -r --include="*.h" src/
src/include/Defn.h:extern0 double cpuLimitValue INI_as(-1.0);

$ grep -F "cpuLimitValue" -r --include="*.c" src/
src/main/sysutils.c:    cpuLimit = (cpuLimitValue > 0) ? data[0] +
data[1] + cpuLimitValue : -1.0;
src/main/sysutils.c:    cpuLimit = (cpuLimitValue > 0) ? data[0] +
data[1] + data[3] + data[4] + cpuLimitValue : -1.0;
src/main/sysutils.c:    double cpu, elapsed, old_cpu = cpuLimitValue,
src/main/sysutils.c:    if (R_FINITE(cpu) && cpu > 0) cpuLimitValue =
cpu; else cpuLimitValue = -1;
src/main/sysutils.c: cpuLimitValue = old_cpu;

Similar for 'elapsedLimitValue'.

>
> Also, I think it would be nice if the error thrown when timing out had a
> special class so I didn't have to rely on grepping the error message, but
> that is true of lots of errors.

FYI, R.utils::withTimeout() greps the error message (for any language;
https://github.com/HenrikBengtsson/R.utils/blob/2.5.0/R/withTimeout.R#L113-L114)
this way and returns an error of class TimeoutException.

FYI 2, there is as 'Working group for standard error (condition)
classes' proposal to the RConsortium "wishlist", cf.
https://github.com/RConsortium/wishlist/issues/6.

/Henrik

>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Wed Jan  4 04:07:34 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 4 Jan 2017 14:07:34 +1100
Subject: [R] Sweave: Incorporating warnings into a Sweave output chunck
Message-ID: <000601d26637$b2ea4e20$18beea60$@bigpond.com>

Dear All

There are some occasions I have run code in R without warning. 
After incorporating the code into an .Rnw file and running by Sweave I find
there are  warnings sent to the screen.  

On some occasions when I use Sweave(...)  I would like to incorporate the
warnings into the resulting tex file.
Until now I have done it manually which is a bit of a pain.

Does anyone know of a way?  It would be nice to have a Sweave option to
include it.

The only reference I can find is 

https://stat.ethz.ch/pipermail/r-help/2006-December/121892.html

which had no replies except this one on Nabble

http://r.789695.n4.nabble.com/R-Sweave-and-warning-messages-td814182.html

I have got the code from the attached Rnw file working in R version 3.3.1 
But there are some problems with it.

Below is  the code including some of the options and setup with the function
in one chunck
 
<<redefwarning, echo=FALSE>>=
  options(warn = 1)
  cons <- showConnections(all = TRUE)
 # .CurFileName <- get("file", env = parent.frame(3)) # modified by next
line
  .CurFileName <-
  as.vector(unlist(
  subset(data.frame(cons), class == "file" & nchar(description) > 0)[1]) )
  .PrefixName <- strsplit(.CurFileName, "\\.")[[1]][1]
  .LatexFileName <- paste(.PrefixName, "tex", sepo = ".")
  .LatexFileCon <-
  getConnection(what = as.integer(rownames(cons)[which(cons[,1] ==
.LatexFileName)]))
  sink(file = .LatexFileCon, append = TRUE, type = "message")

warningbck <- warning
warning <-
function (..., call. = TRUE, immediate. = FALSE, domain = NULL){

  args <- list(...)

  if (length(args) == 1 && inherits(args[[1]], "condition")) {

    cond <- args[[1]]
    message <- conditionMessage(cond)
    call <- conditionCall(cond)

    withRestarts({
      .Internal(.signalCondition(cond, message, call))
      .Internal(.dfltStop(message, call))
    },
    muffleWarning = function() NULL)

    invisible(message)

  }  else {

    if (length(args) > 0) {

      args <- lapply(list(...), as.character)

      if (is.null(domain) || !is.na(domain))
        args <- .Internal(gettext(domain, unlist(args)))
        message <- paste(args, collapse = "")

    } else{

      message <- ""
    }

    writeLines(text = "\n\\end{Sinput}\n\\begin{Soutput}", con =
.LatexFileCon)
    .Internal(warning(as.logical(call.), as.logical(immediate.), message))

    writeLines(text = "\\end{Soutput}\n\\begin{Sinput}", con =
.LatexFileCon)
  }
}

This puts the warning into the input chunck directly after the R command
e.g. as shown below

\begin{Sinput}
  clust.hw <- svydesign(ids = ~Patient, data = hw.dat)Warning in
svydesign.default(ids = ~Patient, data = hwd) :
  No weights or probabilities supplied, assuming equal probability

\end{Sinput}

I think that there also needs to be an argument about closing connections
somewhere in the code.

 Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


From petr.pikal at precheza.cz  Wed Jan  4 10:08:21 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 4 Jan 2017 09:08:21 +0000
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMOcQfMZmDxuW0uEywbG6jY+Qm3UHsH9Z5N9wuRnfDGLq6kFFQ@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<DM5PR1601MB1147065D4B5DE2F83369C1E8F76B0@DM5PR1601MB1147.namprd16.prod.outlook.com>
	<CAMOcQfPLC=seYkLyd+c6=CHva5J0q0HOaEb=9sWGR3LaSh0T+Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC1D3@SRVEXCHCM301.precheza.cz>
	<CAMOcQfMZmDxuW0uEywbG6jY+Qm3UHsH9Z5N9wuRnfDGLq6kFFQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC24B@SRVEXCHCM301.precheza.cz>

Hi

I am not at all an expert in such task. However from documentation it seems to me that it is not possible without some deeper understanding of linux and windows core.

rzmq

NeedsCompilation:

yes

SystemRequirements:

ZeroMQ >= 3.0.0 libraries and headers (see< http://www.zeromq.org/>; Debian packages libzmq3, libzmq3-dev, Fedora packages zeromq3, zeromq3-devel)


ZeroMQ
Windows
Windows is not supported at this time, but patches are welcome.
So on Windows you are out of the game unless you are able to mimic on Windows all above mentioned requirements on your own.

Cheers
Petr



From: Paul Bernal [mailto:paulbernal07 at gmail.com]
Sent: Tuesday, January 3, 2017 8:46 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Re: [R] Problems when trying to install and load package "rzmq"

Hello Petr,

Is it possible to compile the package (rzmq) from Ubuntu for Windows?

Best regards,

Paul

2017-01-03 10:28 GMT-05:00 PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:
Hi

It is clearly seen from CRAN that there is no binary for windows. So you either need to migrate to linux or you need to compile the package from source or maybe both.

You need to study how to compile a package as it is usually not trivial task, especially for somebody who does not compile packages regularly, as myself.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Paul
> Bernal
> Sent: Tuesday, January 3, 2017 1:51 PM
> To: Paulo Moniz <pmoniz7 at hotmail.com<mailto:pmoniz7 at hotmail.com>>
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Problems when trying to install and load package "rzmq"
>
> Hello Paulo,
>
> Thanks for the reply. As a matter of fact, I used the command
> install.packages("rzmq"), however, the error message kept showing.
>
> Best regards,
>
> Paul
>
> 2016-12-29 16:26 GMT-05:00 Paulo Moniz <pmoniz7 at hotmail.com<mailto:pmoniz7 at hotmail.com>>:
>
> > hi Bernal, wouldn't the right  command be - install.packages("rzmq")
> >
> >
> >
> >
> >
> >
> > ------------------------------
> > *De:* R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> em nome de Paul Bernal <
> > paulbernal07 at gmail.com<mailto:paulbernal07 at gmail.com>>
> > *Enviado:* quinta-feira, 29 de dezembro de 2016 20:23
> > *Para:* r-help at r-project.org<mailto:r-help at r-project.org>; r-devel at r-project.org<mailto:r-devel at r-project.org>
> > *Assunto:* [R] Problems when trying to install and load package "rzmq"
> >
> > After connecting to a mirror, I typed the following command:
> >
> > install.packages("rzqm")
> >
> > but I received the following message:
> >
> > ERROR: compilation failed for package 'rzmq'
> >
> > removing 'E:/Documents/R/win-library/3.3/rzmq'
> >
> > package which is only available in source form, and may need
> > compilation of
> > C/C++/Fortran: 'rzmq'
> > These will not be installed
> >
> > The computer environment is Windows 8 64x bits
> >
> >
> > Any help and/or guidance will be greatly appreciated
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > R-help -- Main R Mailing List: Primary help - Homepage - SfS
> > <https://stat.ethz.ch/mailman/listinfo/r-help>
> > stat.ethz.ch<http://stat.ethz.ch>
> > The main R mailing list, for announcements about the development of R
> > and the availability of new code, questions and answers about problems
> > and solutions using R ...
> >
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Wed Jan  4 10:41:47 2017
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 4 Jan 2017 17:41:47 +0800
Subject: [R] gls procedure in nlme
Message-ID: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>

I need help with gls{nlme}.
Specifically, I am estimating an equation with AR(1) using 
maximum-likelihood. I am not understanding the correlationoption below. 
Help appreciated.

===
library(nlme)
eq1<-log(chnimp)~log(chempi)+log(gas)+log(rtwex)+befile6+
                  affile6+afdec6
reg1<-gls(eq1,data=mydata,correlation=corAR1(),method="ML",verbose=T)


	[[alternative HTML version deleted]]


From vanrome54 at gmail.com  Wed Jan  4 10:28:08 2017
From: vanrome54 at gmail.com (Vanessa Romero)
Date: Wed, 4 Jan 2017 10:28:08 +0100
Subject: [R] Tobit Regression with unbalanced Panel Data
Message-ID: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>

Hello,

I am doing Tobit Regression in R, because my dependent variable is censored
at 0. I have unbalanced panel data, for 6 years, 107 companies. I use
package CensReg.

I have imported my database(T1).

I use pdata.frame to specify the structure of my panel data. Like:


*mydata<- pdata.frame (T1, index = c("firm", "year")) *
Afterwards:

*Tob <- censReg(formula=Imp ~ Bath + CEOTurnover + ChangeOCF + E + Sales +
ROE + GTA + Size , data = mydata, method="BHHH") *
(as explained here:
https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf)

I got here error message:


*Warnmeldung: In log(rEff$ercomp$sigma$id) : NaNs wurden erzeugt*

Another error message when *summary(Tob)*





*Call: censReg(formula = Imp ~ Bath + CEOTurnover + ChangeOCF + E + Sales +
ROE + GTA + Size, data = mydata, method = "BHHH") Observations: Total
Left-censored Uncensored Right-censored 606 469 137 0 Coefficients: Fehler
in printCoefmat(coef(x, logSigma = logSigma), digits = digits) : 'x' must
be coefficient matrix/data frame*

I am new to statistics and to R, what could be the problem or would you
suggest using other package.

Thank you,
Vanessa

	[[alternative HTML version deleted]]


From arne.henningsen at gmail.com  Wed Jan  4 11:02:47 2017
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Wed, 4 Jan 2017 11:02:47 +0100
Subject: [R] Tobit Regression with unbalanced Panel Data
In-Reply-To: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>
References: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>
Message-ID: <CAMTWbJjftwxLYD2cJYLB8Su4dD3Yb_ypt+RjTvnJM-juubOw+A@mail.gmail.com>

Dear Vanessa

Please provide a minimal *reproducible* example that illustrates your
problem, e.g. using a data set that is included in an R package.

Best regards,
Arne



On 4 January 2017 at 10:28, Vanessa Romero <vanrome54 at gmail.com> wrote:
> Hello,
>
> I am doing Tobit Regression in R, because my dependent variable is censored
> at 0. I have unbalanced panel data, for 6 years, 107 companies. I use
> package CensReg.
>
> I have imported my database(T1).
>
> I use pdata.frame to specify the structure of my panel data. Like:
>
>
> *mydata<- pdata.frame (T1, index = c("firm", "year")) *
> Afterwards:
>
> *Tob <- censReg(formula=Imp ~ Bath + CEOTurnover + ChangeOCF + E + Sales +
> ROE + GTA + Size , data = mydata, method="BHHH") *
> (as explained here:
> https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf)
>
> I got here error message:
>
>
> *Warnmeldung: In log(rEff$ercomp$sigma$id) : NaNs wurden erzeugt*
>
> Another error message when *summary(Tob)*
>
>
>
>
>
> *Call: censReg(formula = Imp ~ Bath + CEOTurnover + ChangeOCF + E + Sales +
> ROE + GTA + Size, data = mydata, method = "BHHH") Observations: Total
> Left-censored Uncensored Right-censored 606 469 137 0 Coefficients: Fehler
> in printCoefmat(coef(x, logSigma = logSigma), digits = digits) : 'x' must
> be coefficient matrix/data frame*
>
> I am new to statistics and to R, what could be the problem or would you
> suggest using other package.
>
> Thank you,
> Vanessa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Arne Henningsen
http://www.arne-henningsen.name


From petr.pikal at precheza.cz  Wed Jan  4 13:25:11 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 4 Jan 2017 12:25:11 +0000
Subject: [R] Tobit Regression with unbalanced Panel Data
In-Reply-To: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>
References: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC30B@SRVEXCHCM301.precheza.cz>

Hi

Although I cannot help you with your actual problem, you shall start with checking your data before doing any analysis. We do not have your data so it is hard to say what can be wrong. At least you shall provide result of

str(T1) and/or
str(mydata)

The first message is not an error but a warning that tells you about coercing some log values to NaN which can result e.g. from negative values.

log(-1)
[1] NaN
Warning message:
In log(-1) : NaNs produced

and probably some further calculation in summary function does not like it and throws error.

But without data it is only a guess.

And BTW, you shall post plain text not HTML.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vanessa
> Romero
> Sent: Wednesday, January 4, 2017 10:28 AM
> To: r-help at r-project.org
> Subject: [R] Tobit Regression with unbalanced Panel Data
>
> Hello,
>
> I am doing Tobit Regression in R, because my dependent variable is censored
> at 0. I have unbalanced panel data, for 6 years, 107 companies. I use package
> CensReg.
>
> I have imported my database(T1).
>
> I use pdata.frame to specify the structure of my panel data. Like:
>
>
> *mydata<- pdata.frame (T1, index = c("firm", "year")) *
> Afterwards:
>
> *Tob <- censReg(formula=Imp ~ Bath + CEOTurnover + ChangeOCF + E +
> Sales + ROE + GTA + Size , data = mydata, method="BHHH") * (as explained
> here:
> https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf)
>
> I got here error message:
>
>
> *Warnmeldung: In log(rEff$ercomp$sigma$id) : NaNs wurden erzeugt*
>
> Another error message when *summary(Tob)*
>
>
>
>
>
> *Call: censReg(formula = Imp ~ Bath + CEOTurnover + ChangeOCF + E + Sales
> + ROE + GTA + Size, data = mydata, method = "BHHH") Observations: Total
> Left-censored Uncensored Right-censored 606 469 137 0 Coefficients: Fehler
> in printCoefmat(coef(x, logSigma = logSigma), digits = digits) : 'x' must be
> coefficient matrix/data frame*
>
> I am new to statistics and to R, what could be the problem or would you
> suggest using other package.
>
> Thank you,
> Vanessa
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bastl73 at freenet.de  Wed Jan  4 17:09:39 2017
From: bastl73 at freenet.de (bastl73)
Date: Wed, 4 Jan 2017 16:09:39 +0000
Subject: [R] if zlib version >= 1.2.5... no
Message-ID: <201701041609.39050.bastl73@freenet.de>

Configuring R with zlib-1.2.10 I get this error:

checking for zlib.h... yes
checking if zlib version >= 1.2.5... no
checking whether zlib support suffices... configure: error: zlib library and headers 
are required

So I asked Mark from zlib about this problem and he wrote back:

>  exit(strncmp(ZLIB_VERSION, "1.2.5", 5) < 0);

strcmp("1.2.10", "1.2.5") will indicate incorrectly that the 1.2.10 is *less* than 
1.2.5. This is why there is ZLIB_VERNUM, which is a number that can be compared. So 
it should be simply:

    exit(ZLIB_VERNUM < 0x1250);


bastl


From roy.mendelssohn at noaa.gov  Wed Jan  4 18:00:14 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 4 Jan 2017 09:00:14 -0800
Subject: [R] xtractomatic v3.2.0
Message-ID: <B01CC843-F581-424D-87E0-E95C75C5E078@noaa.gov>

Hi All:

I am pleased to announce that xtractomatic v3.2.0 is now available on CRAN.  The changes in this version will be invisible to the user - the major changes are the use of https instead of http,  and some changes in the vignette so that multiple attempts are made to download the data (the vignette as published will  look the same as in the previous version,  just the raw .Rmd  file has changes).

If your institution requires or recommends the use of https, as is increasingly the case, then I recommend upgrading the package.  Existing code using the package should not be affected.

Thanks,

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pdalgd at gmail.com  Wed Jan  4 19:26:46 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 4 Jan 2017 19:26:46 +0100
Subject: [R] if zlib version >= 1.2.5... no
In-Reply-To: <201701041609.39050.bastl73@freenet.de>
References: <201701041609.39050.bastl73@freenet.de>
Message-ID: <3D396E8B-D727-42F8-BB01-24F3D1F59262@gmail.com>

This was fixed (independently?) in r-devel today:

Peter-Dalgaards-MacBook-Air:R pd$ svn log m4/R.m4 | head
------------------------------------------------------------------------
r71889 | lawrence | 2017-01-04 04:57:31 +0100 (Wed, 04 Jan 2017) | 4 lines

R_ZLIB macro tests ZLIB_VERNUM to handle zlib 1.2.10 (6 chars)

Thanks to George Hartzell for the fix.
---

-pd


> On 04 Jan 2017, at 17:09 , bastl73 <bastl73 at freenet.de> wrote:
> 
> Configuring R with zlib-1.2.10 I get this error:
> 
> checking for zlib.h... yes
> checking if zlib version >= 1.2.5... no
> checking whether zlib support suffices... configure: error: zlib library and headers 
> are required
> 
> So I asked Mark from zlib about this problem and he wrote back:
> 
>> exit(strncmp(ZLIB_VERSION, "1.2.5", 5) < 0);
> 
> strcmp("1.2.10", "1.2.5") will indicate incorrectly that the 1.2.10 is *less* than 
> 1.2.5. This is why there is ZLIB_VERNUM, which is a number that can be compared. So 
> it should be simply:
> 
>    exit(ZLIB_VERNUM < 0x1250);
> 
> 
> bastl
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Wed Jan  4 19:43:36 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 Jan 2017 10:43:36 -0800
Subject: [R] if zlib version >= 1.2.5... no
In-Reply-To: <201701041609.39050.bastl73@freenet.de>
References: <201701041609.39050.bastl73@freenet.de>
Message-ID: <889CFC12-ECA6-4208-9A28-7CEE78A60458@comcast.net>


> On Jan 4, 2017, at 8:09 AM, bastl73 <bastl73 at freenet.de> wrote:
> 
> Configuring R

Which "R" would that be?


> with zlib-1.2.10 I get this error:
> 
> checking for zlib.h... yes
> checking if zlib version >= 1.2.5... no
> checking whether zlib support suffices... configure: error: zlib library and headers 
> are required
> 
> So I asked Mark from zlib about this problem and he wrote back:
> 
>> exit(strncmp(ZLIB_VERSION, "1.2.5", 5) < 0);
> 
> strcmp("1.2.10", "1.2.5") will indicate incorrectly that the 1.2.10 is *less* than 
> 1.2.5. This is why there is ZLIB_VERNUM, which is a number that can be compared. So 
> it should be simply:
> 
>    exit(ZLIB_VERNUM < 0x1250);

I'm thinking this must be the world's shortest attempt at a bug report. I can find that code in a couple of places with a Google search:

A copy of material labelled as "part of R"

https://github.com/rho-devel/rho/blob/master/m4/R.m4

A diff file submitted by Ingo Feinerer to bsdports:

https://marc.info/?l=openbsd-ports&m=146229312201237&w=2

And using the Google advanced search function (since Google does not apparently index the R source):

https://svn.r-project.org/R/trunk/m4/R.m4

It appears the current version already has the code suggested as the correction:

https://svn.r-project.org/R/trunk/m4/R.m4

A bit below the section header :

## R_ZLIB

We see this code (which appears to be exactly the suggested edit by your correspondent.)

int main() {
#ifdef ZLIB_VERNUM
  if (ZLIB_VERNUM < 0x1250) {
    exit(1);
  }
  exit(0);

So you should check that you are working with the most recent version of R. If you are, and you still think this is a bug, then you should post a much, much more complete "trial bug report" to the R-devel at r-project.org mailing list. It should include a complete description of what you are attempting and full log files. Posting bug reports to r-help is just the wrong place and posting incorrect bug reports to bugzilla just annoys the maintainers.


> 
> bastl
> 

-- 

David Winsemius
Alameda, CA, USA


From thierry.onkelinx at inbo.be  Wed Jan  4 21:06:20 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 4 Jan 2017 21:06:20 +0100
Subject: [R] Sweave: Incorporating warnings into a Sweave output chunck
In-Reply-To: <000601d26637$b2ea4e20$18beea60$@bigpond.com>
References: <000601d26637$b2ea4e20$18beea60$@bigpond.com>
Message-ID: <CAJuCY5w+kZtvYAHyzM+kTGeA8DBihYnCRkKac6va-F5EqHNQ1w@mail.gmail.com>

Dear Duncan,

I'd recommend to switch from Sweave to knitr. Knitr has more options for
handling warnings and errors than Sweave.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-04 4:07 GMT+01:00 Duncan Mackay <dulcalma at bigpond.com>:

> Dear All
>
> There are some occasions I have run code in R without warning.
> After incorporating the code into an .Rnw file and running by Sweave I find
> there are  warnings sent to the screen.
>
> On some occasions when I use Sweave(...)  I would like to incorporate the
> warnings into the resulting tex file.
> Until now I have done it manually which is a bit of a pain.
>
> Does anyone know of a way?  It would be nice to have a Sweave option to
> include it.
>
> The only reference I can find is
>
> https://stat.ethz.ch/pipermail/r-help/2006-December/121892.html
>
> which had no replies except this one on Nabble
>
> http://r.789695.n4.nabble.com/R-Sweave-and-warning-messages-td814182.html
>
> I have got the code from the attached Rnw file working in R version 3.3.1
> But there are some problems with it.
>
> Below is  the code including some of the options and setup with the
> function
> in one chunck
>
> <<redefwarning, echo=FALSE>>=
>   options(warn = 1)
>   cons <- showConnections(all = TRUE)
>  # .CurFileName <- get("file", env = parent.frame(3)) # modified by next
> line
>   .CurFileName <-
>   as.vector(unlist(
>   subset(data.frame(cons), class == "file" & nchar(description) > 0)[1]) )
>   .PrefixName <- strsplit(.CurFileName, "\\.")[[1]][1]
>   .LatexFileName <- paste(.PrefixName, "tex", sepo = ".")
>   .LatexFileCon <-
>   getConnection(what = as.integer(rownames(cons)[which(cons[,1] ==
> .LatexFileName)]))
>   sink(file = .LatexFileCon, append = TRUE, type = "message")
>
> warningbck <- warning
> warning <-
> function (..., call. = TRUE, immediate. = FALSE, domain = NULL){
>
>   args <- list(...)
>
>   if (length(args) == 1 && inherits(args[[1]], "condition")) {
>
>     cond <- args[[1]]
>     message <- conditionMessage(cond)
>     call <- conditionCall(cond)
>
>     withRestarts({
>       .Internal(.signalCondition(cond, message, call))
>       .Internal(.dfltStop(message, call))
>     },
>     muffleWarning = function() NULL)
>
>     invisible(message)
>
>   }  else {
>
>     if (length(args) > 0) {
>
>       args <- lapply(list(...), as.character)
>
>       if (is.null(domain) || !is.na(domain))
>         args <- .Internal(gettext(domain, unlist(args)))
>         message <- paste(args, collapse = "")
>
>     } else{
>
>       message <- ""
>     }
>
>     writeLines(text = "\n\\end{Sinput}\n\\begin{Soutput}", con =
> .LatexFileCon)
>     .Internal(warning(as.logical(call.), as.logical(immediate.), message))
>
>     writeLines(text = "\\end{Soutput}\n\\begin{Sinput}", con =
> .LatexFileCon)
>   }
> }
>
> This puts the warning into the input chunck directly after the R command
> e.g. as shown below
>
> \begin{Sinput}
>   clust.hw <- svydesign(ids = ~Patient, data = hw.dat)Warning in
> svydesign.default(ids = ~Patient, data = hwd) :
>   No weights or probabilities supplied, assuming equal probability
>
> \end{Sinput}
>
> I think that there also needs to be an argument about closing connections
> somewhere in the code.
>
>  Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed Jan  4 21:45:08 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 4 Jan 2017 15:45:08 -0500
Subject: [R] XML to CSV
In-Reply-To: <CAMgrDmOKQbmc0pP8dsORvF7gfcQMAcis_CVBfC7QRLc+jHA89g@mail.gmail.com>
References: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>
	<B41EB1BE-2E3F-4315-9D72-F434D8DB353E@bigelow.org>
	<CAMgrDmOKQbmc0pP8dsORvF7gfcQMAcis_CVBfC7QRLc+jHA89g@mail.gmail.com>
Message-ID: <C8399CB8-5E8A-40A1-9295-15F77EBD6643@bigelow.org>

Hi,

You should keep replies on the list - you never know when someone will swoop in with the right answer to make your life easier.

Below is a simple example that uses xpath syntax to identify (and in this case retrieve) children that match your xpath expression.  xpath epxressions are sort of like /a/directory/structure/description so you can visualize elements of XML like nested folders or subdirectories.

Hopefully this will get you started.  A lot more on xpath here http://www.w3schools.com/xml/xml_xpath.asp  There are other extraction tools in xml2 - just type ?xml2 at the command prompt to see more.

Since you have more deeply nested elements you'll need to play with this a bit first.

library(xml2)
uri = 'http://www.w3schools.com/xml/simple.xml'
x = read_xml(uri)

name_nodes = xml_find_all(x, "//name")
name = xml_text(name_nodes)

price_nodes = xml_find_all(x, "//price")
price = xml_text(price_nodes)

calories_nodes = xml_find_all(x, "//calories")
calories = xml_double(calories_nodes)

X = data.frame(name, price, calories, stringsAsFactors = FALSE)
write.csv(X, file = 'foo.csv')

Cheers,
Ben

> On Jan 4, 2017, at 2:13 PM, Andrew Lachance <alachanc at bates.edu> wrote:
> 
> Hello Ben,
> 
> Thank you for the advice. I am extremely new to any sort of coding so I have learned a lot already. Essentially, I was given an XML file and was told to convert all of it to a csv so that it could be uploaded into a database. Unfortunately the information I am working with is medical information and can't really share it. I initially tried to convert it using online programs, however that ended up with a large amount of blank spaces that wasn't useful for uploading into the database.
> 
> So essentially, my goal is to parse all the data in the XML to a coherent, succinct CSV that could be uploaded. In the document, there are 361 patient files with 13 subcategories for each patient which further branches off to around 150 categories total. Since I am so new, I have been having a hard time seeing the bigger picture or knowing if there are any intermediary steps that will prevent all the blank spaces that the online conversion programs created.
> 
> I will look through the information on the xml2 package. Any advice or recommendations would be greatly appreciated as I have felt fairly stuck. Once again, thank you very much for your help.
> 
> Best,
> Andrew
> 
> On Tue, Jan 3, 2017 at 2:29 PM, Ben Tupper <btupper at bigelow.org <mailto:btupper at bigelow.org>> wrote:
> Hi,
> 
> It's hard to know what to advise - much depends upon the XML data you have and what you want to extract from it. Without knowing about those two things there is little anyone could do to help.  Can you post to the internet a to example data and provide the link here?  Then state explicitly what you want to have in hand at the end.
> 
> If you are just starting out I suggest that you try xml2 package ( https://cran.r-project.org/web/packages/xml2/ <https://cran.r-project.org/web/packages/xml2/> ) rather than XML package ( https://cran.r-project.org/web/packages/XML/ <https://cran.r-project.org/web/packages/XML/> ). I have been using it much more since the authors added the ability to create xml nodes (rather than just extracting data from existing xml nodes).
> 
> Cheers,
> Ben
> 
> P.S.  Hello to my niece Olivia S on the Bates EMS team.
> 
> 
> > On Jan 3, 2017, at 11:27 AM, Andrew Lachance <alachanc at bates.edu <mailto:alachanc at bates.edu>> wrote:
> >
> > up votdown votefavorite
> > <http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1# <http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>>
> >
> > I am completely new to R and have tried to use several functions within the
> > xml packages to convert an XML to a csv and have had little success. Since
> > I am so new, I am not sure what the necessary steps are to complete this
> > conversion without a lot of NA.
> >
> > --
> > Andrew D. Lachance
> > Chief of Service, Bates Emergency Medical Service
> > Residence Coordinator, Hopkins House
> > Bates College Class of 2017
> > alachanc at bates.edu <mailto:alachanc at bates.edu> <wcurley at bates.edu <mailto:wcurley at bates.edu>>
> > (207) 620-4854
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
> 
> 
> 
> 
> 
> 
> -- 
> Andrew D. Lachance
> Chief of Service, Bates Emergency Medical Service
> Residence Coordinator, Hopkins House
> Bates College Class of 2017
> alachanc at bates.edu <mailto:wcurley at bates.edu>
> (207) 620-4854

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jan  4 23:08:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 04 Jan 2017 14:08:59 -0800
Subject: [R] XML to CSV
In-Reply-To: <C8399CB8-5E8A-40A1-9295-15F77EBD6643@bigelow.org>
References: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>
	<B41EB1BE-2E3F-4315-9D72-F434D8DB353E@bigelow.org>
	<CAMgrDmOKQbmc0pP8dsORvF7gfcQMAcis_CVBfC7QRLc+jHA89g@mail.gmail.com>
	<C8399CB8-5E8A-40A1-9295-15F77EBD6643@bigelow.org>
Message-ID: <EFA2748B-6A6D-4152-9454-A40ADF077805@dcn.davis.ca.us>

Andrew... you really need to understand the outline/tree nature of your XML schema to understand why blanks might appear in your data when you try to squeeze it into a rectangular layout like CSV. Opening the file in a modern Web browser like Firefox can help you see the forest among the trees, since they can collapse/expand the subtrees. Keep in mind that understanding how XML works is really not the purpose of this list, but there are lots of books and tutorials about it such as the one mentioned by Ben. If your schema has many irregular subtrees it may be a poor match for fitting into one CSV and you might need to resort to putting it into a relational group of CSV files... but relational schema design is another off-topic area of study for this list. Once you know what you want to accomplish a little better (enough to make example input and output data sets) we can help you more with the R coding aspect of your problem... but guessing at your needs with no access to data is really not effective use of anyone's time. 
-- 
Sent from my phone. Please excuse my brevity.

On January 4, 2017 12:45:08 PM PST, Ben Tupper <btupper at bigelow.org> wrote:
>Hi,
>
>You should keep replies on the list - you never know when someone will
>swoop in with the right answer to make your life easier.
>
>Below is a simple example that uses xpath syntax to identify (and in
>this case retrieve) children that match your xpath expression.  xpath
>epxressions are sort of like /a/directory/structure/description so you
>can visualize elements of XML like nested folders or subdirectories.
>
>Hopefully this will get you started.  A lot more on xpath here
>http://www.w3schools.com/xml/xml_xpath.asp  There are other extraction
>tools in xml2 - just type ?xml2 at the command prompt to see more.
>
>Since you have more deeply nested elements you'll need to play with
>this a bit first.
>
>library(xml2)
>uri = 'http://www.w3schools.com/xml/simple.xml'
>x = read_xml(uri)
>
>name_nodes = xml_find_all(x, "//name")
>name = xml_text(name_nodes)
>
>price_nodes = xml_find_all(x, "//price")
>price = xml_text(price_nodes)
>
>calories_nodes = xml_find_all(x, "//calories")
>calories = xml_double(calories_nodes)
>
>X = data.frame(name, price, calories, stringsAsFactors = FALSE)
>write.csv(X, file = 'foo.csv')
>
>Cheers,
>Ben
>
>> On Jan 4, 2017, at 2:13 PM, Andrew Lachance <alachanc at bates.edu>
>wrote:
>> 
>> Hello Ben,
>> 
>> Thank you for the advice. I am extremely new to any sort of coding so
>I have learned a lot already. Essentially, I was given an XML file and
>was told to convert all of it to a csv so that it could be uploaded
>into a database. Unfortunately the information I am working with is
>medical information and can't really share it. I initially tried to
>convert it using online programs, however that ended up with a large
>amount of blank spaces that wasn't useful for uploading into the
>database.
>> 
>> So essentially, my goal is to parse all the data in the XML to a
>coherent, succinct CSV that could be uploaded. In the document, there
>are 361 patient files with 13 subcategories for each patient which
>further branches off to around 150 categories total. Since I am so new,
>I have been having a hard time seeing the bigger picture or knowing if
>there are any intermediary steps that will prevent all the blank spaces
>that the online conversion programs created.
>> 
>> I will look through the information on the xml2 package. Any advice
>or recommendations would be greatly appreciated as I have felt fairly
>stuck. Once again, thank you very much for your help.
>> 
>> Best,
>> Andrew
>> 
>> On Tue, Jan 3, 2017 at 2:29 PM, Ben Tupper <btupper at bigelow.org
><mailto:btupper at bigelow.org>> wrote:
>> Hi,
>> 
>> It's hard to know what to advise - much depends upon the XML data you
>have and what you want to extract from it. Without knowing about those
>two things there is little anyone could do to help.  Can you post to
>the internet a to example data and provide the link here?  Then state
>explicitly what you want to have in hand at the end.
>> 
>> If you are just starting out I suggest that you try xml2 package (
>https://cran.r-project.org/web/packages/xml2/
><https://cran.r-project.org/web/packages/xml2/> ) rather than XML
>package ( https://cran.r-project.org/web/packages/XML/
><https://cran.r-project.org/web/packages/XML/> ). I have been using it
>much more since the authors added the ability to create xml nodes
>(rather than just extracting data from existing xml nodes).
>> 
>> Cheers,
>> Ben
>> 
>> P.S.  Hello to my niece Olivia S on the Bates EMS team.
>> 
>> 
>> > On Jan 3, 2017, at 11:27 AM, Andrew Lachance <alachanc at bates.edu
><mailto:alachanc at bates.edu>> wrote:
>> >
>> > up votdown votefavorite
>> >
><http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#
><http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>>
>> >
>> > I am completely new to R and have tried to use several functions
>within the
>> > xml packages to convert an XML to a csv and have had little
>success. Since
>> > I am so new, I am not sure what the necessary steps are to complete
>this
>> > conversion without a lot of NA.
>> >
>> > --
>> > Andrew D. Lachance
>> > Chief of Service, Bates Emergency Medical Service
>> > Residence Coordinator, Hopkins House
>> > Bates College Class of 2017
>> > alachanc at bates.edu <mailto:alachanc at bates.edu> <wcurley at bates.edu
><mailto:wcurley at bates.edu>>
>> > (207) 620-4854
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
><http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org <http://www.bigelow.org/>
>> 
>> 
>> 
>> 
>> 
>> 
>> -- 
>> Andrew D. Lachance
>> Chief of Service, Bates Emergency Medical Service
>> Residence Coordinator, Hopkins House
>> Bates College Class of 2017
>> alachanc at bates.edu <mailto:wcurley at bates.edu>
>> (207) 620-4854
>
>Ben Tupper
>Bigelow Laboratory for Ocean Sciences
>60 Bigelow Drive, P.O. Box 380
>East Boothbay, Maine 04544
>http://www.bigelow.org
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Wed Jan  4 23:22:41 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 5 Jan 2017 09:22:41 +1100
Subject: [R] Sweave: Incorporating warnings into a Sweave output chunck
In-Reply-To: <CAJuCY5w+kZtvYAHyzM+kTGeA8DBihYnCRkKac6va-F5EqHNQ1w@mail.gmail.com>
References: <000601d26637$b2ea4e20$18beea60$@bigpond.com>
	<CAJuCY5w+kZtvYAHyzM+kTGeA8DBihYnCRkKac6va-F5EqHNQ1w@mail.gmail.com>
Message-ID: <000801d266d9$10fb3280$32f19780$@bigpond.com>

Hi Thierry

 

Thank you for your comments.

I had considered it in the past but decided against it. 

May think again about switching but would have to change a lot of macros in my text editor.

 

Regards

 

Duncan

 

 

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: Thursday, 5 January 2017 07:06
To: Duncan Mackay
Cc: R
Subject: Re: [R] Sweave: Incorporating warnings into a Sweave output chunck

 

Dear Duncan,

 

I'd recommend to switch from Sweave to knitr. Knitr has more options for handling warnings and errors than Sweave.

 

Best regards,




ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

 

2017-01-04 4:07 GMT+01:00 Duncan Mackay <dulcalma at bigpond.com>:

Dear All

There are some occasions I have run code in R without warning.
After incorporating the code into an .Rnw file and running by Sweave I find
there are  warnings sent to the screen.

On some occasions when I use Sweave(...)  I would like to incorporate the
warnings into the resulting tex file.
Until now I have done it manually which is a bit of a pain.

Does anyone know of a way?  It would be nice to have a Sweave option to
include it.

The only reference I can find is

https://stat.ethz.ch/pipermail/r-help/2006-December/121892.html

which had no replies except this one on Nabble

http://r.789695.n4.nabble.com/R-Sweave-and-warning-messages-td814182.html

I have got the code from the attached Rnw file working in R version 3.3.1
But there are some problems with it.

Below is  the code including some of the options and setup with the function
in one chunck

<<redefwarning, echo=FALSE>>=
  options(warn = 1)
  cons <- showConnections(all = TRUE)
 # .CurFileName <- get("file", env = parent.frame(3)) # modified by next
line
  .CurFileName <-
  as.vector(unlist(
  subset(data.frame(cons), class == "file" & nchar(description) > 0)[1]) )
  .PrefixName <- strsplit(.CurFileName, "\\. <file:///\\.> ")[[1]][1]
  .LatexFileName <- paste(.PrefixName, "tex", sepo = ".")
  .LatexFileCon <-
  getConnection(what = as.integer(rownames(cons)[which(cons[,1] ==
.LatexFileName)]))
  sink(file = .LatexFileCon, append = TRUE, type = "message")

warningbck <- warning
warning <-
function (..., call. = TRUE, immediate. = FALSE, domain = NULL){

  args <- list(...)

  if (length(args) == 1 && inherits(args[[1]], "condition")) {

    cond <- args[[1]]
    message <- conditionMessage(cond)
    call <- conditionCall(cond)

    withRestarts({
      .Internal(.signalCondition(cond, message, call))
      .Internal(.dfltStop(message, call))
    },
    muffleWarning = function() NULL)

    invisible(message)

  }  else {

    if (length(args) > 0) {

      args <- lapply(list(...), as.character)

      if (is.null(domain) || !is.na(domain))
        args <- .Internal(gettext(domain, unlist(args)))
        message <- paste(args, collapse = "")

    } else{

      message <- ""
    }

    writeLines(text = "\n\\end{Sinput}\n\\begin{Soutput}", con =
.LatexFileCon)
    .Internal(warning(as.logical(call.), as.logical(immediate.), message))

    writeLines(text = "\\end{Soutput}\n\\begin{Sinput} <file:///\\end%7bSoutput%7d\n\begin%7bSinput%7d> ", con =
.LatexFileCon)
  }
}

This puts the warning into the input chunck directly after the R command
e.g. as shown below

\begin{Sinput}
  clust.hw <- svydesign(ids = ~Patient, data = hw.dat)Warning in
svydesign.default(ids = ~Patient, data = hwd) :
  No weights or probabilities supplied, assuming equal probability

\end{Sinput}

I think that there also needs to be an argument about closing connections
somewhere in the code.

 Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From r at catwhisker.org  Thu Jan  5 04:40:10 2017
From: r at catwhisker.org (David Wolfskill)
Date: Wed, 4 Jan 2017 19:40:10 -0800
Subject: [R] How might I work with a data.frame where each physical row
 represents several logical rows?
Message-ID: <20170105034010.GP1115@albert.catwhisker.org>

I have (time series) data extracted from a repository that is stored
such that each record is for an hour, but each record contains an
ordered set of values throughout the hour.  In the following exmaple,
I'll show sets of 4, depicting 0, 15, 30, and 45 minutes after each
"start" point (respectively):

test_data <- structure(list(start = c(1482793200L, 1482793200L, 1482793200L, 
1482793200L, 1482793200L, 1482793200L, 1482793200L, 1482793200L, 
1482793200L, 1482793200L, 1482793200L, 1482793200L, 1482793200L, 
1482793200L, 1482793200L), hostname = c("c001.example.net", "c001.example.net", 
"c001.example.net", "c001.example.net", "c001.example.net", "c001.example.net", 
"c001.example.net", "c001.example.net", "c001.example.net", "c001.example.net", 
"c001.example.net", "c161.example.net", "c161.example.net", "c161.example.net", 
"c161.example.net"), mtype = c("health", "health", "net", "net", 
"net", "net", "net", "net", "net", "sys", "sys", "net", "sys", 
"sys", "sys"), limit_type = c("fill", "serve", "", "", "", "", 
"", "", "", "", "", "", "", "", ""), hw = c(1.16, 1.16, 1.16, 
1.16, 1.16, 1.16, 1.16, 1.16, 1.16, 1.16, 1.16, 1.21, 1.21, 1.21, 
1.21), fw = c("2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", 
"2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", 
"2017Q1.1.1", "2017Q1.1.1", "2016Q4.2.13", "2016Q4.2.13", "2016Q4.2.13", 
"2016Q4.2.13"), tcp_state = c("", "", "", "", "closed", "closing", 
"fin_wait_2", "last_ack", "syn_rcvd", "", "", "", "", "", ""), 
    value_type = c("limit", "limit", "", "", "", "", "", "", 
    "", "", "", "", "", "", ""), nic = c("all", "all", "", "", 
    "", "", "", "", "", "", "", "mce0", "", "", ""), name = c("in_download_window", 
    "in_download_window", "tcpOutSegs", "tcpRetransSegs", "tcp_connection_count", 
    "tcp_connection_count", "tcp_connection_count", "tcp_connection_count", 
    "tcp_connection_count", "CpuSystem", "CpuUser", "HCOutOctets", 
    "CpuIdle", "CpuSystem", "CpuUser"), values = c("[0.0, 0.0, 0.0, 0.0]", 
    "[0.0, 0.0, 0.0, 0.0]", "[260410.94547698632, 258469.54433635762, 260579.2186617577, 258763.2815145043]", 
    "[18436.311524062934, 18248.952271420356, 18201.62259198662, 17818.39529178736]", 
    "[5.0, 3.0, 3.0, 3.0]", "[3.0, 3.0, 2.0, 2.0]", "[670.0, 677.0, 685.0, 729.0]", 
    "[1162.0, 1192.0, 1148.0, 1110.0]", "[25.0, 60.0, 71.0, 33.0]", 
    "[11.0, 10.0, 11.0, 10.0]", "[2.0, 2.0, 2.0, 2.0]", "[7.873191635959294E9, 7.7377184658927E9, 7.876630519328283E9, 7.714521544912713E9]", 
    "[70.0, 70.0, 70.0, 70.0]", "[27.0, 26.0, 27.0, 26.0]", "[4.0, 4.0, 4.0, 4.0]"
    )), .Names = c("start", "hostname", "mtype", "limit_type", 
"hw", "fw", "tcp_state", "value_type", "nic", "name", "values"
), class = "data.frame", row.names = c(NA, -15L))


So of the 15 rows in the above example, row 8 (which depicts the TCP
connection counts in the "last ACK" state) has the values:

* 1162.0
* 1192.0
* 1148.0
* 1110.0

It seems to me that what is wanted is for each of the existing rows to be
replaced by a set of 4 (in this case) rows, where the other columns are
the same (save for "start", which is a timestamp, and should be adjusted
for the respective times).

I'm fairly sure I can write code to do that, but it would end up being
something like Perl implemented in R, which seems fairly grotesque: I
can't help but think that there ought to be a ... more elegant approach
in R (which is why I am sking for help).

(I will also end up collecting all of the records for a given timestamp
and hostname, and creating one very wide record with all of the data
from the set of records thus found.  I already have (yes, Perl) code to
do this -- though if there's a reasonable way to avoid that, I'm
interested.)

Once that's all done, I'll be examining various columns, subsetting
by attributes of the systems being compared -- but I already have
code to do that (that makes use of a different -- and rather more
fragile -- approach for extracting the data from its repository).

Thanks!

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Epistemology for post-truthers: How do we select parts of reality to ignore?

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 603 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170104/b83a0662/attachment.bin>

From dwinsemius at comcast.net  Thu Jan  5 05:33:46 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 Jan 2017 20:33:46 -0800
Subject: [R] How might I work with a data.frame where each physical row
	represents several logical rows?
In-Reply-To: <20170105034010.GP1115@albert.catwhisker.org>
References: <20170105034010.GP1115@albert.catwhisker.org>
Message-ID: <4D850227-149B-45C4-8E85-7F13725DE623@comcast.net>


> On Jan 4, 2017, at 7:40 PM, David Wolfskill <r at catwhisker.org> wrote:
> 
> I have (time series) data extracted from a repository that is stored
> such that each record is for an hour, but each record contains an
> ordered set of values throughout the hour.  In the following exmaple,
> I'll show sets of 4, depicting 0, 15, 30, and 45 minutes after each
> "start" point (respectively):
> 
> test_data <- structure(list(start = c(1482793200L, 1482793200L, 1482793200L, 
> 1482793200L, 1482793200L, 1482793200L, 1482793200L, 1482793200L, 
> 1482793200L, 1482793200L, 1482793200L, 1482793200L, 1482793200L, 
> 1482793200L, 1482793200L), hostname = c("c001.example.net", "c001.example.net", 
> "c001.example.net", "c001.example.net", "c001.example.net", "c001.example.net", 
> "c001.example.net", "c001.example.net", "c001.example.net", "c001.example.net", 
> "c001.example.net", "c161.example.net", "c161.example.net", "c161.example.net", 
> "c161.example.net"), mtype = c("health", "health", "net", "net", 
> "net", "net", "net", "net", "net", "sys", "sys", "net", "sys", 
> "sys", "sys"), limit_type = c("fill", "serve", "", "", "", "", 
> "", "", "", "", "", "", "", "", ""), hw = c(1.16, 1.16, 1.16, 
> 1.16, 1.16, 1.16, 1.16, 1.16, 1.16, 1.16, 1.16, 1.21, 1.21, 1.21, 
> 1.21), fw = c("2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", 
> "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", "2017Q1.1.1", 
> "2017Q1.1.1", "2017Q1.1.1", "2016Q4.2.13", "2016Q4.2.13", "2016Q4.2.13", 
> "2016Q4.2.13"), tcp_state = c("", "", "", "", "closed", "closing", 
> "fin_wait_2", "last_ack", "syn_rcvd", "", "", "", "", "", ""), 
>    value_type = c("limit", "limit", "", "", "", "", "", "", 
>    "", "", "", "", "", "", ""), nic = c("all", "all", "", "", 
>    "", "", "", "", "", "", "", "mce0", "", "", ""), name = c("in_download_window", 
>    "in_download_window", "tcpOutSegs", "tcpRetransSegs", "tcp_connection_count", 
>    "tcp_connection_count", "tcp_connection_count", "tcp_connection_count", 
>    "tcp_connection_count", "CpuSystem", "CpuUser", "HCOutOctets", 
>    "CpuIdle", "CpuSystem", "CpuUser"), values = c("[0.0, 0.0, 0.0, 0.0]", 
>    "[0.0, 0.0, 0.0, 0.0]", "[260410.94547698632, 258469.54433635762, 260579.2186617577, 258763.2815145043]", 
>    "[18436.311524062934, 18248.952271420356, 18201.62259198662, 17818.39529178736]", 
>    "[5.0, 3.0, 3.0, 3.0]", "[3.0, 3.0, 2.0, 2.0]", "[670.0, 677.0, 685.0, 729.0]", 
>    "[1162.0, 1192.0, 1148.0, 1110.0]", "[25.0, 60.0, 71.0, 33.0]", 
>    "[11.0, 10.0, 11.0, 10.0]", "[2.0, 2.0, 2.0, 2.0]", "[7.873191635959294E9, 7.7377184658927E9, 7.876630519328283E9, 7.714521544912713E9]", 
>    "[70.0, 70.0, 70.0, 70.0]", "[27.0, 26.0, 27.0, 26.0]", "[4.0, 4.0, 4.0, 4.0]"
>    )), .Names = c("start", "hostname", "mtype", "limit_type", 
> "hw", "fw", "tcp_state", "value_type", "nic", "name", "values"
> ), class = "data.frame", row.names = c(NA, -15L))
> 
> 
> So of the 15 rows in the above example, row 8 (which depicts the TCP
> connection counts in the "last ACK" state) has the values:
> 
> * 1162.0
> * 1192.0
> * 1148.0
> * 1110.0
> 
> It seems to me that what is wanted is for each of the existing rows to be
> replaced by a set of 4 (in this case) rows, where the other columns are
> the same (save for "start", which is a timestamp, and should be adjusted
> for the respective times).

Perhaps something like this:

# function to read the values in 'values':
 parse_values <- function(x) {scan(text= gsub( "\\[|\\]","",x), sep=",") }

# the apply function reads line-by-line
 new_dat <- apply(test_data, 1, function(d) data.frame( as.list(d[!names(d)  %in% "values"]), nvals <- parse_values(d['values']) ) )
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items

# Could suppress the report from scan by adding quiet = TRUE
# now take this list of 4 line data.frames and "rbind" them
# If you wanted these to remain character you would use stringsAsFactors=FALSE in the data.frame call
> new_df <- do.call("rbind", new_dat)
> head(new_df)
       start         hostname  mtype limit_type   hw         fw tcp_state value_type nic
1 1482793200 c001.example.net health       fill 1.16 2017Q1.1.1                limit all
2 1482793200 c001.example.net health       fill 1.16 2017Q1.1.1                limit all
3 1482793200 c001.example.net health       fill 1.16 2017Q1.1.1                limit all
4 1482793200 c001.example.net health       fill 1.16 2017Q1.1.1                limit all
5 1482793200 c001.example.net health      serve 1.16 2017Q1.1.1                limit all
6 1482793200 c001.example.net health      serve 1.16 2017Q1.1.1                limit all
                name nvals....parse_values.d..values...
1 in_download_window                                  0
2 in_download_window                                  0
3 in_download_window                                  0
4 in_download_window                                  0
5 in_download_window                                  0
6 in_download_window                                  0

str(new_df)
'data.frame':	60 obs. of  11 variables:
 $ start                             : Factor w/ 1 level "1482793200": 1 1 1 1 1 1 1 1 1 1 ...
 $ hostname                          : Factor w/ 2 levels "c001.example.net",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ mtype                             : Factor w/ 3 levels "health","net",..: 1 1 1 1 1 1 1 1 2 2 ...
 $ limit_type                        : Factor w/ 3 levels "fill","serve",..: 1 1 1 1 2 2 2 2 3 3 ...
 $ hw                                : Factor w/ 2 levels "1.16","1.21": 1 1 1 1 1 1 1 1 1 1 ...
 $ fw                                : Factor w/ 2 levels "2017Q1.1.1","2016Q4.2.13": 1 1 1 1 1 1 1 1 1 1 ...
 $ tcp_state                         : Factor w/ 6 levels "","closed","closing",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ value_type                        : Factor w/ 2 levels "limit","": 1 1 1 1 1 1 1 1 2 2 ...
 $ nic                               : Factor w/ 3 levels "all","","mce0": 1 1 1 1 1 1 1 1 2 2 ...
 $ name                              : Factor w/ 8 levels "in_download_window",..: 1 1 1 1 1 1 1 1 2 2 ...
 $ nvals....parse_values.d..values...: num  0 0 0 0 0 ...

> 

> I'm fairly sure I can write code to do that, but it would end up being
> something like Perl implemented in R, which seems fairly grotesque: I
> can't help but think that there ought to be a ... more elegant approach
> in R (which is why I am sking for help).
> 
> (I will also end up collecting all of the records for a given timestamp
> and hostname, and creating one very wide record with all of the data
> from the set of records thus found.  I already have (yes, Perl) code to
> do this -- though if there's a reasonable way to avoid that, I'm
> interested.)

I thought you wanted the data in long form.
> 
> Once that's all done, I'll be examining various columns, subsetting
> by attributes of the systems being compared -- but I already have
> code to do that (that makes use of a different -- and rather more
> fragile -- approach for extracting the data from its repository).
> 
> Thanks!
> 
> Peace,
> david
> -- 
> David H. Wolfskill				r at catwhisker.org
> Epistemology for post-truthers: How do we select parts of reality to ignore?
> 
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r at catwhisker.org  Thu Jan  5 05:51:02 2017
From: r at catwhisker.org (David Wolfskill)
Date: Wed, 4 Jan 2017 20:51:02 -0800
Subject: [R] How might I work with a data.frame where each physical row
 represents several logical rows?
In-Reply-To: <4D850227-149B-45C4-8E85-7F13725DE623@comcast.net>
References: <20170105034010.GP1115@albert.catwhisker.org>
	<4D850227-149B-45C4-8E85-7F13725DE623@comcast.net>
Message-ID: <20170105045102.GQ1115@albert.catwhisker.org>

On Wed, Jan 04, 2017 at 08:33:46PM -0800, David Winsemius wrote:
>  ...
> Perhaps something like this:
> 
> # function to read the values in 'values':
>  parse_values <- function(x) {scan(text= gsub( "\\[|\\]","",x), sep=",") }
> 
> # the apply function reads line-by-line
>  new_dat <- apply(test_data, 1, function(d) data.frame( as.list(d[!names(d)  %in% "values"]), nvals <- parse_values(d['values']) ) )

Hmmm.... OK; that looks a lot better than the stuff that was coming to
my mind -- thanks! :-)

> ...
> # Could suppress the report from scan by adding quiet = TRUE
> # now take this list of 4 line data.frames and "rbind" them
> # If you wanted these to remain character you would use stringsAsFactors=FALSE in the data.frame call
> > new_df <- do.call("rbind", new_dat)

Aye.

> ...
> > (I will also end up collecting all of the records for a given timestamp
> > and hostname, and creating one very wide record with all of the data
> > from the set of records thus found.  I already have (yes, Perl) code to
> > do this -- though if there's a reasonable way to avoid that, I'm
> > interested.)
> 
> I thought you wanted the data in long form.

Sorry; I'm not understanding what you mean: My background is a lot more
toward systems administration than statistical analysis.

The repository I'm using has a rather large number of individual metrics
from a given server -- each provided on a separate row.  (That's why one
of the columns is called "name" -- it provides the (base) "name" of the
metric that corresponds to the "values" on the given row.)  I'll plan to
assemble the rows for a given server & timestamp into a single row --
thuse, I would have the tcp_connection_count for the "last ACK" state
and for the "fin_wait_2" state, as well as CpuSystem, CpuUser, CpuIdle,
... for the given server & timestamp on a single row (eventually).

> ...

Thanks again!

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Epistemology for post-truthers: How do we select parts of reality to ignore?

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 603 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170104/98740ec4/attachment.bin>

From dwinsemius at comcast.net  Thu Jan  5 06:45:10 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 Jan 2017 21:45:10 -0800
Subject: [R] How might I work with a data.frame where each physical row
	represents several logical rows?
In-Reply-To: <20170105045102.GQ1115@albert.catwhisker.org>
References: <20170105034010.GP1115@albert.catwhisker.org>
	<4D850227-149B-45C4-8E85-7F13725DE623@comcast.net>
	<20170105045102.GQ1115@albert.catwhisker.org>
Message-ID: <4B4B8906-649D-4248-95B6-7F181A760B17@comcast.net>


> On Jan 4, 2017, at 8:51 PM, David Wolfskill <r at catwhisker.org> wrote:
> 
> On Wed, Jan 04, 2017 at 08:33:46PM -0800, David Winsemius wrote:
>> ...
>> Perhaps something like this:
>> 
>> # function to read the values in 'values':
>> parse_values <- function(x) {scan(text= gsub( "\\[|\\]","",x), sep=",") }
>> 
>> # the apply function reads line-by-line
>> new_dat <- apply(test_data, 1, function(d) data.frame( as.list(d[!names(d)  %in% "values"]), nvals <- parse_values(d['values']) ) )
> 
> Hmmm.... OK; that looks a lot better than the stuff that was coming to
> my mind -- thanks! :-)
> 
>> ...
>> # Could suppress the report from scan by adding quiet = TRUE
>> # now take this list of 4 line data.frames and "rbind" them
>> # If you wanted these to remain character you would use stringsAsFactors=FALSE in the data.frame call
>>> new_df <- do.call("rbind", new_dat)
> 
> Aye.
> 
>> ...
>>> (I will also end up collecting all of the records for a given timestamp
>>> and hostname, and creating one very wide record with all of the data
>>> from the set of records thus found.  I already have (yes, Perl) code to
>>> do this -- though if there's a reasonable way to avoid that, I'm
>>> interested.)
>> 
>> I thought you wanted the data in long form.
> 
> Sorry; I'm not understanding what you mean: My background is a lot more
> toward systems administration than statistical analysis.
> 
> The repository I'm using has a rather large number of individual metrics
> from a given server -- each provided on a separate row.  (That's why one
> of the columns is called "name" -- it provides the (base) "name" of the
> metric that corresponds to the "values" on the given row.)  I'll plan to
> assemble the rows for a given server & timestamp into a single row --
> thuse, I would have the tcp_connection_count for the "last ACK" state
> and for the "fin_wait_2" state, as well as CpuSystem, CpuUser, CpuIdle,
> ... for the given server & timestamp on a single row (eventually).

If you wanted it in wide form, you could just join the individual id columns to a named list made from the parsed 'values'.

> new_dat <- apply(test_data, 1, function(d) data.frame( as.list(d[!names(d)  %in% "values"]), as.list( setNames( parse_values(d['values']), paste0( "V", 1:4) ) ) ) )
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
Read 4 items
> new_df <- do.call("rbind", new_dat)
> 
> str(new_df)
'data.frame':	15 obs. of  14 variables:
 $ start     : Factor w/ 1 level "1482793200": 1 1 1 1 1 1 1 1 1 1 ...
 $ hostname  : Factor w/ 2 levels "c001.example.net",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ mtype     : Factor w/ 3 levels "health","net",..: 1 1 2 2 2 2 2 2 2 3 ...
 $ limit_type: Factor w/ 3 levels "fill","serve",..: 1 2 3 3 3 3 3 3 3 3 ...
 $ hw        : Factor w/ 2 levels "1.16","1.21": 1 1 1 1 1 1 1 1 1 1 ...
 $ fw        : Factor w/ 2 levels "2017Q1.1.1","2016Q4.2.13": 1 1 1 1 1 1 1 1 1 1 ...
 $ tcp_state : Factor w/ 6 levels "","closed","closing",..: 1 1 1 1 2 3 4 5 6 1 ...
 $ value_type: Factor w/ 2 levels "limit","": 1 1 2 2 2 2 2 2 2 2 ...
 $ nic       : Factor w/ 3 levels "all","","mce0": 1 1 2 2 2 2 2 2 2 2 ...
 $ name      : Factor w/ 8 levels "in_download_window",..: 1 1 2 3 4 4 4 4 4 5 ...
 $ V1        : num  0 0 260411 18436 5 ...
 $ V2        : num  0 0 258470 18249 3 ...
 $ V3        : num  0 0 260579 18202 3 ...
 $ V4        : num  0 0 258763 17818 3 ...



> 
>> ...
> 
> Thanks again!
> 
> Peace,
> david
> -- 
> David H. Wolfskill				r at catwhisker.org
> Epistemology for post-truthers: How do we select parts of reality to ignore?
> 
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu Jan  5 08:29:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 4 Jan 2017 23:29:16 -0800 (PST)
Subject: [R] How might I work with a data.frame where each physical row
 represents several logical rows?
In-Reply-To: <20170105045102.GQ1115@albert.catwhisker.org>
References: <20170105034010.GP1115@albert.catwhisker.org>
	<4D850227-149B-45C4-8E85-7F13725DE623@comcast.net>
	<20170105045102.GQ1115@albert.catwhisker.org>
Message-ID: <alpine.BSF.2.00.1701042320140.527@pedal.dcn.davis.ca.us>

Below is my interpretation of one way to achieve your stated goal. I don't 
know what analysis you plan to perform, but this seems unlikely to be be 
my preferred analysis format (I think I would probably analyze subsets of 
the records related to specific parts of the transactions).

library(dplyr)
library(tidyr)

fifteenminutes <- 15 * 60

# for education, show intermediate results
# strip out square brackets
View(   test_data
     %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
     )

# split the single column into multiple columns
View(   test_data
     %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
     %>% separate( values, paste0( "value", 0:3 ), ", *" )
     )

# pull separate value columns into one column called value, with a new
# column vcol to hold the name of the original column
View(   test_data
     %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
     %>% separate( values, paste0( "value", 0:3 ), ", *" )
     %>% gather( vcol, value, c( value0, value1, value2, value3 ) )
     )

# create a timestamp column for the individual values
View(   test_data
     %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
     %>% separate( values, paste0( "value", 0:3 ), ", *" )
     %>% gather( vcol, value, c( value0, value1, value2, value3 ) )
     %>% mutate( timestamp = start
                           + fifteenminutes
                             * as.numeric( sub( "value", "", vcol ) ) )
     )

# remove the old vcol column now that timestamp column is created
View(   test_data
     %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
     %>% separate( values, paste0( "value", 0:3 ), ", *" )
     %>% gather( vcol, value, c( value0, value1, value2, value3 ) )
     %>% mutate( timestamp = start
                           + fifteenminutes
                             * as.numeric( sub( "value", "", vcol ) ) )
     %>% select( -vcol )
     )

# unite several columns that currently distinguish various rows
View(   test_data
     %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
     %>% separate( values, paste0( "value", 0:3 ), ", *" )
     %>% gather( vcol, value, c( value0, value1, value2, value3 ) )
     %>% mutate( timestamp = start
                           + fifteenminutes
                             * as.numeric( sub( "value", "", vcol ) ) )
     %>% select( -vcol )
     %>% unite( mname, mtype, nic, tcp_state, limit_type, value_type, name )
     )

# spread values out into separate columns
test_data2 <- (   test_data
               %>% mutate( values = sub( "^\\[(.*)\\]$", "\\1", values ) )
               %>% separate( values, paste0( "value", 0:3 ), ", *" )
               %>% gather( vcol, value, c( value0, value1, value2, value3 ) 
)
               %>% mutate( timestamp = start + fifteenminutes * as.numeric( 
sub( "value", "", vcol ) ) )
               %>% select( -vcol )
               %>% unite( mname, mtype, nic, tcp_state, limit_type, 
value_type, name )
               %>% spread( mname, value )
               )

View( test_data2 )


On Wed, 4 Jan 2017, David Wolfskill wrote:

> On Wed, Jan 04, 2017 at 08:33:46PM -0800, David Winsemius wrote:
>>  ...
>> Perhaps something like this:
>>
>> # function to read the values in 'values':
>>  parse_values <- function(x) {scan(text= gsub( "\\[|\\]","",x), sep=",") }
>>
>> # the apply function reads line-by-line
>>  new_dat <- apply(test_data, 1, function(d) data.frame( as.list(d[!names(d)  %in% "values"]), nvals <- parse_values(d['values']) ) )
>
> Hmmm.... OK; that looks a lot better than the stuff that was coming to
> my mind -- thanks! :-)
>
>> ...
>> # Could suppress the report from scan by adding quiet = TRUE
>> # now take this list of 4 line data.frames and "rbind" them
>> # If you wanted these to remain character you would use stringsAsFactors=FALSE in the data.frame call
>>> new_df <- do.call("rbind", new_dat)
>
> Aye.
>
>> ...
>>> (I will also end up collecting all of the records for a given timestamp
>>> and hostname, and creating one very wide record with all of the data
>>> from the set of records thus found.  I already have (yes, Perl) code to
>>> do this -- though if there's a reasonable way to avoid that, I'm
>>> interested.)
>>
>> I thought you wanted the data in long form.
>
> Sorry; I'm not understanding what you mean: My background is a lot more
> toward systems administration than statistical analysis.
>
> The repository I'm using has a rather large number of individual metrics
> from a given server -- each provided on a separate row.  (That's why one
> of the columns is called "name" -- it provides the (base) "name" of the
> metric that corresponds to the "values" on the given row.)  I'll plan to
> assemble the rows for a given server & timestamp into a single row --
> thuse, I would have the tcp_connection_count for the "last ACK" state
> and for the "fin_wait_2" state, as well as CpuSystem, CpuUser, CpuIdle,
> ... for the given server & timestamp on a single row (eventually).
>
>> ...
>
> Thanks again!
>
> Peace,
> david
> -- 
> David H. Wolfskill				r at catwhisker.org
> Epistemology for post-truthers: How do we select parts of reality to ignore?
>
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From Gabriele.Franzini at nervianoms.com  Thu Jan  5 13:39:05 2017
From: Gabriele.Franzini at nervianoms.com (Franzini, Gabriele [Nervianoms])
Date: Thu, 5 Jan 2017 13:39:05 +0100
Subject: [R] XML to CSV
In-Reply-To: <EFA2748B-6A6D-4152-9454-A40ADF077805@dcn.davis.ca.us>
References: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com><B41EB1BE-2E3F-4315-9D72-F434D8DB353E@bigelow.org><CAMgrDmOKQbmc0pP8dsORvF7gfcQMAcis_CVBfC7QRLc+jHA89g@mail.gmail.com><C8399CB8-5E8A-40A1-9295-15F77EBD6643@bigelow.org>
	<EFA2748B-6A6D-4152-9454-A40ADF077805@dcn.davis.ca.us>
Message-ID: <69D768435B870B498704129A048CDB190F41F34C@nermbxs08.nervianoms.com>

Hello Andrew,

as you are "clean slate" anyway in handling XML files, you could take a look to XSLT processing -- also an off-topic area. 
There are free tools available around, and many examples of "XML to CSV XSLT" on StackOverflow.

HTH,
Gabriele

-----Original Message-----

On January 4, 2017 12:45:08 PM PST, Ben Tupper <btupper at bigelow.org> wrote:
>Hi,
>
>You should keep replies on the list - you never know when someone will
>swoop in with the right answer to make your life easier.
>
>Below is a simple example that uses xpath syntax to identify (and in
>this case retrieve) children that match your xpath expression.  xpath
>epxressions are sort of like /a/directory/structure/description so you
>can visualize elements of XML like nested folders or subdirectories.
>
>Hopefully this will get you started.  A lot more on xpath here
>http://www.w3schools.com/xml/xml_xpath.asp  There are other extraction
>tools in xml2 - just type ?xml2 at the command prompt to see more.
>
>Since you have more deeply nested elements you'll need to play with
>this a bit first.
>
>library(xml2)
>uri = 'http://www.w3schools.com/xml/simple.xml'
>x = read_xml(uri)
>
>name_nodes = xml_find_all(x, "//name")
>name = xml_text(name_nodes)
>
>price_nodes = xml_find_all(x, "//price")
>price = xml_text(price_nodes)
>
>calories_nodes = xml_find_all(x, "//calories")
>calories = xml_double(calories_nodes)
>
>X = data.frame(name, price, calories, stringsAsFactors = FALSE)
>write.csv(X, file = 'foo.csv')
>
>Cheers,
>Ben
>
>> On Jan 4, 2017, at 2:13 PM, Andrew Lachance <alachanc at bates.edu>
>wrote:
>> 
>> Hello Ben,
>> 
>> Thank you for the advice. I am extremely new to any sort of coding so
>I have learned a lot already. Essentially, I was given an XML file and
>was told to convert all of it to a csv so that it could be uploaded
>into a database. Unfortunately the information I am working with is
>medical information and can't really share it. I initially tried to
>convert it using online programs, however that ended up with a large
>amount of blank spaces that wasn't useful for uploading into the
>database.
>> 
>> So essentially, my goal is to parse all the data in the XML to a
>coherent, succinct CSV that could be uploaded. In the document, there
>are 361 patient files with 13 subcategories for each patient which
>further branches off to around 150 categories total. Since I am so new,
>I have been having a hard time seeing the bigger picture or knowing if
>there are any intermediary steps that will prevent all the blank spaces
>that the online conversion programs created.
>> 
>> I will look through the information on the xml2 package. Any advice
>or recommendations would be greatly appreciated as I have felt fairly
>stuck. Once again, thank you very much for your help.
>> 
>> Best,
>> Andrew
>> 
>> On Tue, Jan 3, 2017 at 2:29 PM, Ben Tupper <btupper at bigelow.org
><mailto:btupper at bigelow.org>> wrote:
>> Hi,
>> 
>> It's hard to know what to advise - much depends upon the XML data you
>have and what you want to extract from it. Without knowing about those
>two things there is little anyone could do to help.  Can you post to
>the internet a to example data and provide the link here?  Then state
>explicitly what you want to have in hand at the end.
>> 
>> If you are just starting out I suggest that you try xml2 package (
>https://cran.r-project.org/web/packages/xml2/
><https://cran.r-project.org/web/packages/xml2/> ) rather than XML
>package ( https://cran.r-project.org/web/packages/XML/
><https://cran.r-project.org/web/packages/XML/> ). I have been using it
>much more since the authors added the ability to create xml nodes
>(rather than just extracting data from existing xml nodes).
>> 
>> Cheers,
>> Ben
>> 
>> P.S.  Hello to my niece Olivia S on the Bates EMS team.
>> 
>> 
>> > On Jan 3, 2017, at 11:27 AM, Andrew Lachance <alachanc at bates.edu
><mailto:alachanc at bates.edu>> wrote:
>> >
>> > up votdown votefavorite
>> >
><http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#
><http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>>
>> >
>> > I am completely new to R and have tried to use several functions
>within the
>> > xml packages to convert an XML to a csv and have had little
>success. Since
>> > I am so new, I am not sure what the necessary steps are to complete
>this
>> > conversion without a lot of NA.
>> >
>> > --
>> > Andrew D. Lachance
>> > Chief of Service, Bates Emergency Medical Service
>> > Residence Coordinator, Hopkins House
>> > Bates College Class of 2017
>> > alachanc at bates.edu <mailto:alachanc at bates.edu> <wcurley at bates.edu
><mailto:wcurley at bates.edu>>
>> > (207) 620-4854
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
><http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org <http://www.bigelow.org/>
>> 
>> 
>> 
>> 
>> 
>> 
>> -- 
>> Andrew D. Lachance
>> Chief of Service, Bates Emergency Medical Service
>> Residence Coordinator, Hopkins House
>> Bates College Class of 2017
>> alachanc at bates.edu <mailto:wcurley at bates.edu>
>> (207) 620-4854
>
>Ben Tupper
>Bigelow Laboratory for Ocean Sciences
>60 Bigelow Drive, P.O. Box 380
>East Boothbay, Maine 04544
>http://www.bigelow.org
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From lordpreetam at gmail.com  Wed Jan  4 23:39:33 2017
From: lordpreetam at gmail.com (Preetam Pal)
Date: Thu, 5 Jan 2017 04:09:33 +0530
Subject: [R] Linear optimization with quadratic constraints
Message-ID: <CAHVFrXHH7MY-hFOtKK4i9O3AtLTxfwmEVr8pawnD5CZod8_-5A@mail.gmail.com>

Hello guys,

The context is ordinary multivariate regression with k (>1) regressors,
i.e. *Y = XB + Error*, where
Y = n X 1 vector of predicted variable,
X = n X (k + 1) matrix of regressor variables(including ones in the first
column)
B = (k+1) vector of coefficients, including intercept.

Say, I have already estimated B as B_hat = (X'X)^(-1) X'Y.

I have to solve the following program:

*minimize f(B) = LB*   ( L is a fixed vector 1 X (k+1)   )
such that:
*[(B-B_hat)' * X'X * (B-B_hat) ] / [ ( Y - XB_hat)' (Y - XB_hat) ] *  is
less than a given value *c*.

Note that this is a linear optimization program *with respect to B* with
quadratic constraints.

I don't understand how we can solve this optimization - I was going through
some online resources, each of which involve manually computing gradients
of the objective as well as constraint functions - which I want to avoid
(at least manually doing this).


Can you please help with solving this optimization problem? The inputs
would be:

   - X and Y
   - B_hat
   - L
   - c


Please let me know if any further information is required - the set-up is
pretty general.

Regards,
Preetam

	[[alternative HTML version deleted]]


From renger at vannieuwkoop.ch  Thu Jan  5 14:35:19 2017
From: renger at vannieuwkoop.ch (Renger van Nieuwkoop)
Date: Thu, 5 Jan 2017 13:35:19 +0000
Subject: [R] Problems with roxygen2 when building package
Message-ID: <5E17CCD4AACE3A4C8CFF411186AE819099019A21@EXDAG30-N2.hostallapps.net>

Hi
I am trying to build my own package. When I run in RStudio (R3.3.2, all packages updated, Roxygen available, Windows 10 machine) build-document, I get the following error message:

==> devtools::document(roclets=c('rd', 'collate', 'namespace', 'vignette'))

Fehler in check_dep_version(pkg, version, compare) : 
  Dependency package roxygen2 not available.
Ruft auf: suppressPackageStartupMessages ... <Anonymous> -> check_suggested -> check_dep_version
Ausf?hrung angehalten

Any suggestions, would be welcome

Renger

__________________________________________________
Dr. Renger van Nieuwkoop
Department of Management, Technology and Economics??????????? 
Centre for Energy Policy and Economics???????????????????????????????????????? ?????? 
Swiss Federal Institute of Technology Zurich??????????????????????? ?????????????? ??? 
Z?richbergstrasse 18, CH-8032 Zurich?????????????????????????????? ?????????????????????? ? 
Mobile:???+41 79 818 53 73
E-Mail:??? rengerv at ethz.ch 
?
Director Modelworks
Goldiwilstrasse 16 F
CH-3600 Thun
E-Mail:? info at modelworks.ch
Blog:????? http://blog.modelworks.ch?? 


From dwinsemius at comcast.net  Thu Jan  5 16:32:04 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Jan 2017 07:32:04 -0800
Subject: [R] Problems with roxygen2 when building package
In-Reply-To: <5E17CCD4AACE3A4C8CFF411186AE819099019A21@EXDAG30-N2.hostallapps.net>
References: <5E17CCD4AACE3A4C8CFF411186AE819099019A21@EXDAG30-N2.hostallapps.net>
Message-ID: <52803A7D-B5B7-49DC-9D51-547E220A53B7@comcast.net>


> On Jan 5, 2017, at 5:35 AM, Renger van Nieuwkoop <renger at vannieuwkoop.ch> wrote:
> 
> Hi
> I am trying to build my own package. When I run in RStudio (R3.3.2, all packages updated, Roxygen available, Windows 10 machine) build-document, I get the following error message:
> 
> ==> devtools::document(roclets=c('rd', 'collate', 'namespace', 'vignette'))
> 
> Fehler in check_dep_version(pkg, version, compare) : 
>  Dependency package roxygen2 not available.

The help page for that function says: " This function is a wrapper for the roxygenize() function from the roxygen2 package. See the documentation and vignettes of that package to learn how to use roxygen."

So if you don't have roxygen2 in your library paths.  .... error.


> Ruft auf: suppressPackageStartupMessages ... <Anonymous> -> check_suggested -> check_dep_version
> Ausf?hrung angehalten
> 
> Any suggestions, would be welcome

Check .libPaths(). Install roxygen2.

> 
> Renger
> 
> __________________________________________________
> Dr. Renger van Nieuwkoop
> Department of Management, Technology and Economics            
> Centre for Energy Policy and Economics                                                
> Swiss Federal Institute of Technology Zurich                                           
> Z?richbergstrasse 18, CH-8032 Zurich                                                        
> Mobile:   +41 79 818 53 73
> E-Mail:    rengerv at ethz.ch 
>  
> Director Modelworks
> Goldiwilstrasse 16 F
> CH-3600 Thun
> E-Mail:  info at modelworks.ch
> Blog:      http://blog.modelworks.ch   
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dan.abner99 at gmail.com  Thu Jan  5 17:01:33 2017
From: dan.abner99 at gmail.com (Dan Abner)
Date: Thu, 5 Jan 2017 11:01:33 -0500
Subject: [R] Generating a Special Histogram
Message-ID: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>

Hi all,

Is anyone aware of a package, function, or general R trick that would make
generating histograms like the one in the attachment easy in R (i.e.,
without manually drawing each individual horizontal line and specifying the
coordinates for a textbox for each number)?

I need to make ~12 of these for different samples of n=25, so the manual
approach would be very painful...

Thanks,

Dan
-------------- next part --------------
A non-text attachment was scrubbed...
Name: hist1.pdf
Type: application/pdf
Size: 98591 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170105/d76d9440/attachment.pdf>

From rmh at temple.edu  Thu Jan  5 17:11:04 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 5 Jan 2017 11:11:04 -0500
Subject: [R] Generating a Special Histogram
In-Reply-To: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
Message-ID: <CAGx1TMB1ejM7ATMwnRUNBuP1Hxsza8_BS5N-O77H4t2syAZGUg@mail.gmail.com>

I recommend the stem function.

> stem(wt)

  The decimal point is 1 digit(s) to the right of the |

  12 | 57
  14 | 4902479
  16 | 1233444349
  18 | 002507

> stem(wt, 2)

  The decimal point is 1 digit(s) to the right of the |

  13 | 57
  14 | 49
  15 | 02479
  16 | 1233444
  17 | 349
  18 | 0025
  19 | 07



On Thu, Jan 5, 2017 at 11:01 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> Is anyone aware of a package, function, or general R trick that would make
> generating histograms like the one in the attachment easy in R (i.e.,
> without manually drawing each individual horizontal line and specifying the
> coordinates for a textbox for each number)?
>
> I need to make ~12 of these for different samples of n=25, so the manual
> approach would be very painful...
>
> Thanks,
>
> Dan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Thu Jan  5 17:11:28 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 Jan 2017 11:11:28 -0500
Subject: [R] Generating a Special Histogram
In-Reply-To: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
Message-ID: <CAM_vjukJCHD=2-iRWKvOKzz29U+s4rbYF0sPF-zDV4K2VznJ8Q@mail.gmail.com>

Hi Dan,

I'd probably start by looking at the various examples for stem and
leaf plot in R.

stem() or aplpack::stem.leaf() might help you get started, or if you
don't need the fancy boxes, be sufficient.

Sarah

On Thu, Jan 5, 2017 at 11:01 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> Is anyone aware of a package, function, or general R trick that would make
> generating histograms like the one in the attachment easy in R (i.e.,
> without manually drawing each individual horizontal line and specifying the
> coordinates for a textbox for each number)?
>
> I need to make ~12 of these for different samples of n=25, so the manual
> approach would be very painful...
>
> Thanks,
>
> Dan
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Thu Jan  5 17:47:16 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 5 Jan 2017 11:47:16 -0500
Subject: [R] Generating a Special Histogram
In-Reply-To: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
Message-ID: <23c41c40-6725-3870-24b6-62420d794b9b@gmail.com>

On 05/01/2017 11:01 AM, Dan Abner wrote:
> Hi all,
>
> Is anyone aware of a package, function, or general R trick that would make
> generating histograms like the one in the attachment easy in R (i.e.,
> without manually drawing each individual horizontal line and specifying the
> coordinates for a textbox for each number)?
>
> I need to make ~12 of these for different samples of n=25, so the manual
> approach would be very painful...

You can write a function to do this pretty easily.  hist(..., 
plot=FALSE) does all the calculations for you; you just need to write 
the loop to draw the boxes.  For example,

myhist <- function(x) {
   histvals <- hist(x, plot = FALSE)
   with(histvals, {
     plot(range(breaks), range(c(0, counts)), type = "n")

     for (i in seq_along(histvals$counts)) {
       keep <- (breaks[i] < x & x <= breaks[i+1]) |
               (i == 1 & x == breaks[1])
       vals <- x[keep]
       for (j in seq_along(vals)) {
         rect(breaks[i], j-1, breaks[i+1], j)
         text(mids[i], j-0.5, vals[j])
       }
     }
   })
}

x <- round(rnorm(20, mean=166, sd=4))
myhist(x)

Duncan Murdoch


From suttoncarl at ymail.com  Thu Jan  5 19:09:20 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Thu, 5 Jan 2017 18:09:20 +0000 (UTC)
Subject: [R] Fw: Regex problem
In-Reply-To: <645156402.5640682.1483482544491@mail.yahoo.com>
References: <645156402.5640682.1483482544491.ref@mail.yahoo.com>
	<645156402.5640682.1483482544491@mail.yahoo.com>
Message-ID: <267068192.576547.1483639760628@mail.yahoo.com>

Re-sending help request, went to wrong addy first time.  
r-help-request at r-project.org

Belated Happy new year to the Guru's:

I have a data frame with 570+ columns and in those column headers yours truly has a few blunders.  Namely somehow I managed to end some of them with both an apostrophe ' and an ending quote.   I think the attached code finds the occurrences (not 100% sure) and feedback is appreciated.  This is my first attempt at regex and I have been googling and reading the last few days (including an R -Exercise).

Confused as to why the column names shows a "." instead of a " ' ".

Ignorant of why gregexpr and regexpr show attr(,"useBytes") as TRUE when the default is FALSE.  Is it possible I somehow messed them up last week?   Simply typing the function name in the console shows the defaults as FALSE.

I have not been able to build a construct to simply delete the apostrophe.  I have made several attempts to do this, and left one for your perusal.  The others were just to "off the wall" and embarrassing.

Lastly, is there a way for me to check that all of my column names end with a letter followed by a quote?  I am thinking something along the lines of "[[:alpha:]\\"" but I expect that will throw an error.  I stumbled upon the ' " problem when dplyr complained about it last week, and it is unsettling to think I may have more goofs.

Any suggestions of a good reference book is much appreciated.  I can see extended use of regex coming toward me and I am so ignorant it is frightening (all volunteer work, no $'s involved, but I dislike being incompetent).


#  regex problemdf1 <- data.frame("WhatAmI'" = 1:5, "WhoAreYou" = 11:15)
colnames(df1)
df1
ma_pattern <- "[[:punct:]][[:punct:]]" # Need single ][ in the middle??
grep(ma_pattern,colnames(df1))
ma_pattern <- "[[:punct:][:punct:]]"  #  single ][ worked
grep(ma_pattern,colnames(df1),value = TRUE)  #  found it
grepl(ma_pattern,colnames(df1)) 
gregexpr(ma_pattern,colnames(df1))   # at position 8
regexpr(ma_pattern,colnames(df1))

#sub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE,
#    fixed = FALSE, useBytes = FALSE)

#sub(ma_pattern,replacement = "'\\"",df1)
colnames(df1)

Carl Sutton


From dwinsemius at comcast.net  Thu Jan  5 20:12:32 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Jan 2017 11:12:32 -0800
Subject: [R] Fw: Regex problem
In-Reply-To: <267068192.576547.1483639760628@mail.yahoo.com>
References: <645156402.5640682.1483482544491.ref@mail.yahoo.com>
	<645156402.5640682.1483482544491@mail.yahoo.com>
	<267068192.576547.1483639760628@mail.yahoo.com>
Message-ID: <E7656E54-462B-4E35-A1BC-07FE945E8208@comcast.net>


> On Jan 5, 2017, at 10:09 AM, Carl Sutton via R-help <r-help at r-project.org> wrote:
> 
> Re-sending help request, went to wrong addy first time.  
> r-help-request at r-project.org
> 
> Belated Happy new year to the Guru's:
> 
> I have a data frame with 570+ columns and in those column headers yours truly has a few blunders.  Namely somehow I managed to end some of them with both an apostrophe ' and an ending quote.

Doubtful. You probably only have a single apostrophe and no "ending quote". In fact when I run your `problemdf`, the `make.names` function (called by data.frame) changed the apostrophe into a period. To actually get a trailing apostrophe with `data.frame` you would need to set check.names=FALSE:

df1 <- data.frame("WhatAmI\'" = 1:5, "WhoAreYou" = 11:15, check.names=FALSE)
colnames(df1)
#[1] "WhatAmI'"  "WhoAreYou"
There is no double quote in that name. Now to remove the offending apostrophe (or even multiple instances of them) just do this:

names(df) <- gsub( "\\'", "", names(df)


>   I think the attached code finds the occurrences (not 100% sure) and feedback is appreciated.  This is my first attempt at regex and I have been googling and reading the last few days (including an R -Exercise).
> 
> Confused as to why the column names shows a "." instead of a " ' ".

See above.



> 
> Ignorant of why gregexpr and regexpr show attr(,"useBytes") as TRUE when the default is FALSE.  Is it possible I somehow messed them up last week?   Simply typing the function name in the console shows the defaults as FALSE.
> 
> I have not been able to build a construct to simply delete the apostrophe.  I have made several attempts to do this, and left one for your perusal.  The others were just to "off the wall" and embarrassing.
> 
> Lastly, is there a way for me to check that all of my column names end with a letter followed by a quote?  I am thinking something along the lines of "[[:alpha:]\\"" but I expect that will throw an error.  I stumbled upon the ' " problem when dplyr complained about it last week, and it is unsettling to think I may have more goofs.
> 
> Any suggestions of a good reference book is much appreciated.  I can see extended use of regex coming toward me and I am so ignorant it is frightening (all volunteer work, no $'s involved, but I dislike being incompetent).

I learned regex by reading the ?regex page, and by looking up and working through questions on R-help by Gabor Grothendeick:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+regex#query:list%3Aorg.r-project.r-help%20regex%20from%3A%22Gabor%20Grothendieck%22+page:1+state:facets


There are also several online sites where you can get an expression by expression readout of what your regexes are doing. They do need the understanding that hte escape character for R and regex are the same and the means they need to be doubled in hte pattern arguments (but _not_ the replacement arguments).

-- 
David.


> 
> 
> #  regex problemdf1 <- data.frame("WhatAmI'" = 1:5, "WhoAreYou" = 11:15)
> colnames(df1)
> df1
> ma_pattern <- "[[:punct:]][[:punct:]]" # Need single ][ in the middle??
> grep(ma_pattern,colnames(df1))
> ma_pattern <- "[[:punct:][:punct:]]"  #  single ][ worked
> grep(ma_pattern,colnames(df1),value = TRUE)  #  found it
> grepl(ma_pattern,colnames(df1)) 
> gregexpr(ma_pattern,colnames(df1))   # at position 8
> regexpr(ma_pattern,colnames(df1))
> 
> #sub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE,
> #    fixed = FALSE, useBytes = FALSE)
> 
> #sub(ma_pattern,replacement = "'\\"",df1)
> colnames(df1)
> 
> Carl Sutton
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From paulbernal07 at gmail.com  Thu Jan  5 20:16:54 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 5 Jan 2017 14:16:54 -0500
Subject: [R] IRkernel Installation Issues
Message-ID: <CAMOcQfOtWEw_ga5ExVS+iaYYnVb9eks3O7SqNZbZgd3s=+b3Mw@mail.gmail.com>

Hello everyone,

I tried to get the IRkernel going doing the following:

install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
'devtools', 'uuid', 'digest'))

then taking care of proxy settings by doing:

library(devtools)

library(httr)

set_config(use_proxy(url="",port=8080,username="user",password="pswrd"))

then installed package install_github

then called library(githubinstall)

finally install_github(('IRkernel')

However the following error popped up: "Error in username %||%
getOption("github.user") %||% stop("Unknown username.") :
  Unknown username.

Any idea what could be wrong? I tried with buth my network username and
password and my github username and password without any success.

Regards,

Paul

	[[alternative HTML version deleted]]


From tolga.uzuner at gmail.com  Thu Jan  5 20:22:01 2017
From: tolga.uzuner at gmail.com (tolga.uzuner at gmail.com)
Date: Thu, 5 Jan 2017 14:22:01 -0500
Subject: [R] rJava
Message-ID: <586e9cd7.02ede90a.ad82a.310e@mx.google.com>

Dear R Users,
I am having the following problem with rJava, on a Windows 10 machine with R 3.3.2:

> library(rJava)
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: JAVA_HOME cannot be determined from the Registry
Error: package or namespace load failed for ?rJava?

Any help appreciated.
Thanks in advance


Sent from Mail for Windows 10


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jan  5 21:08:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 05 Jan 2017 12:08:50 -0800
Subject: [R] rJava
In-Reply-To: <586e9cd7.02ede90a.ad82a.310e@mx.google.com>
References: <586e9cd7.02ede90a.ad82a.310e@mx.google.com>
Message-ID: <27EAE38E-CC2C-448B-BA52-8F7F85B6D1ED@dcn.davis.ca.us>

I would guess that you don't have the Java runtime installed, or that the wordsize (32 or 64 bit) runtime you have installed is not compatible with the wordsize of the version of R that you are using. 

You really should read and heed the Posting Guide, which mentions things like mentioning your operating system and using plain text email rather than HTML to avoid us not seeing what you see (which is confusing at best).
-- 
Sent from my phone. Please excuse my brevity.

On January 5, 2017 11:22:01 AM PST, tolga.uzuner at gmail.com wrote:
>Dear R Users,
>I am having the following problem with rJava, on a Windows 10 machine
>with R 3.3.2:
>
>> library(rJava)
>Error : .onLoad failed in loadNamespace() for 'rJava', details:
>  call: fun(libname, pkgname)
>  error: JAVA_HOME cannot be determined from the Registry
>Error: package or namespace load failed for ?rJava?
>
>Any help appreciated.
>Thanks in advance
>
>
>Sent from Mail for Windows 10
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tolga.uzuner at gmail.com  Thu Jan  5 21:39:34 2017
From: tolga.uzuner at gmail.com (tolga.uzuner at gmail.com)
Date: Thu, 5 Jan 2017 15:39:34 -0500
Subject: [R] rJava
In-Reply-To: <27EAE38E-CC2C-448B-BA52-8F7F85B6D1ED@dcn.davis.ca.us>
References: <586e9cd7.02ede90a.ad82a.310e@mx.google.com>
	<27EAE38E-CC2C-448B-BA52-8F7F85B6D1ED@dcn.davis.ca.us>
Message-ID: <ACED8C15-6BA5-4418-A859-0DBF055BB4D3@gmail.com>

Many thanks and will post accordingly.
Tolga

> On Jan 5, 2017, at 3:08 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I would guess that you don't have the Java runtime installed, or that the wordsize (32 or 64 bit) runtime you have installed is not compatible with the wordsize of the version of R that you are using. 
> 
> You really should read and heed the Posting Guide, which mentions things like mentioning your operating system and using plain text email rather than HTML to avoid us not seeing what you see (which is confusing at best).
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On January 5, 2017 11:22:01 AM PST, tolga.uzuner at gmail.com wrote:
>> Dear R Users,
>> I am having the following problem with rJava, on a Windows 10 machine
>> with R 3.3.2:
>> 
>>> library(rJava)
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>> call: fun(libname, pkgname)
>> error: JAVA_HOME cannot be determined from the Registry
>> Error: package or namespace load failed for ?rJava?
>> 
>> Any help appreciated.
>> Thanks in advance
>> 
>> 
>> Sent from Mail for Windows 10
>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Jan  5 21:49:06 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 5 Jan 2017 20:49:06 +0000
Subject: [R] Generating a Special Histogram
In-Reply-To: <23c41c40-6725-3870-24b6-62420d794b9b@gmail.com>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
	<23c41c40-6725-3870-24b6-62420d794b9b@gmail.com>
Message-ID: <a0e19206b6f24752bb8a877921acfab5@exch-2p-mbx-w2.ads.tamu.edu>

Here's a different approach using barplot() to draw the boxes. The first line in the function sorts the values so that they are printed from lowest to highest on the histogram. If you want them in the original sequence, comment this line out. It also assumes you want intervals of 10:

set.seed(42)
wgt <- round(rnorm(45, 170, 15))

boxhist <- function(x) {
     x <- sort(x)
     obs <- 1:length(x)
     low <- floor(min(x/10))*10
     high <- ceiling(max(x/10))*10
     grp <- cut(x, breaks=c(seq(low, high, by=10)), include.lowest=TRUE)
     mat <- table(obs, grp)
     cols <- ncol(mat)
     barplot(mat, space=0, col="lightblue", xaxt="n")
     axis(1, 0:cols, seq(low, high, by=10))
     mat <- apply(mat, 2, cumsum) * mat
     xval <- apply(mat, 1, function(x) which(x > 0))
     yval <- apply(mat, 1, max)
     text(xval-.5, yval-.5, x)
}

boxhist(wgt)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Thursday, January 5, 2017 10:47 AM
To: Dan Abner; r-help at r-project.org
Subject: Re: [R] Generating a Special Histogram

On 05/01/2017 11:01 AM, Dan Abner wrote:
> Hi all,
>
> Is anyone aware of a package, function, or general R trick that would make
> generating histograms like the one in the attachment easy in R (i.e.,
> without manually drawing each individual horizontal line and specifying the
> coordinates for a textbox for each number)?
>
> I need to make ~12 of these for different samples of n=25, so the manual
> approach would be very painful...

You can write a function to do this pretty easily.  hist(..., 
plot=FALSE) does all the calculations for you; you just need to write 
the loop to draw the boxes.  For example,

myhist <- function(x) {
   histvals <- hist(x, plot = FALSE)
   with(histvals, {
     plot(range(breaks), range(c(0, counts)), type = "n")

     for (i in seq_along(histvals$counts)) {
       keep <- (breaks[i] < x & x <= breaks[i+1]) |
               (i == 1 & x == breaks[1])
       vals <- x[keep]
       for (j in seq_along(vals)) {
         rect(breaks[i], j-1, breaks[i+1], j)
         text(mids[i], j-0.5, vals[j])
       }
     }
   })
}

x <- round(rnorm(20, mean=166, sd=4))
myhist(x)

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: BoxHist.png
Type: image/png
Size: 8407 bytes
Desc: BoxHist.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170105/c6213613/attachment.png>

From dwinsemius at comcast.net  Thu Jan  5 22:12:25 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Jan 2017 13:12:25 -0800
Subject: [R] IRkernel Installation Issues
In-Reply-To: <CAMOcQfOtWEw_ga5ExVS+iaYYnVb9eks3O7SqNZbZgd3s=+b3Mw@mail.gmail.com>
References: <CAMOcQfOtWEw_ga5ExVS+iaYYnVb9eks3O7SqNZbZgd3s=+b3Mw@mail.gmail.com>
Message-ID: <33D9F8D6-D4D3-425D-B947-CE44D6FD1779@comcast.net>


> On Jan 5, 2017, at 11:16 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Hello everyone,
> 
> I tried to get the IRkernel going doing the following:
> 
> install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
> 'devtools', 'uuid', 'digest'))
> 
> then taking care of proxy settings by doing:
> 
> library(devtools)
> 
> library(httr)
> 
> set_config(use_proxy(url="",port=8080,username="user",password="pswrd"))
> 
> then installed package install_github
> 
> then called library(githubinstall)
> 
> finally install_github(('IRkernel')

The mismatch of parentheses makes me doubt this was an exact copy. I believe the username referred to in the error refers to the username of the author, not your username. Notice the form of all the examples on `?install_github` are of the form:  install_github("klutometis/roxygen")

 Why are you not trying the code suggested on the github page: 
https://github.com/IRkernel/IRkernel

 install_github('IRkernel/IRkernel')

(Worked for me on a Mac. No other username or pwd needed)


> 
> However the following error popped up: "Error in username %||%
> getOption("github.user") %||% stop("Unknown username.") :
>  Unknown username.
> 
> Any idea what could be wrong? I tried with buth my network username and
> password and my github username and password without any success.
> 
> Regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]

R-help is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Jan  5 22:31:17 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 6 Jan 2017 08:31:17 +1100
Subject: [R] Generating a Special Histogram
In-Reply-To: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
Message-ID: <CA+8X3fUN5bdpoAn43Cbj269PFzu_cBnPFc+rCVVRMBMEz3sR4g@mail.gmail.com>

Hi Dan,
This may help if your data is in the format below:

waffle.mat<-matrix(c(rep(NA,14),137,135,rep(NA,6),144,149,
 rep(NA,3),150,152,159,157,154,
 NA,163,164,164,161,162,165,164,rep(NA,5),179,173,173,
 rep(NA,4),182,180,185,180,
 rep(NA,6),197,190,rep(NA,8)),ncol=9)
waffle.col<-matrix("lightblue",ncol=9,nrow=8)
waffle.col[is.na(waffle.mat)]<-NA
waffle.border<-matrix("blue",ncol=9,nrow=8)
waffle.border[is.na(waffle.mat)]<-NA
library(plotrix)
# use a waffle plot
color2D.matplot(waffle.mat,cellcolors=waffle.col,border=waffle.border,
 show.values=TRUE,xat=10,yat=10,xlab="",ylab="")
axis(1,at=1:8,labels=seq(130,200,by=10))
axis(2,at=1:8)
axis.break(1)

Jim


On Fri, Jan 6, 2017 at 3:01 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> Is anyone aware of a package, function, or general R trick that would make
> generating histograms like the one in the attachment easy in R (i.e.,
> without manually drawing each individual horizontal line and specifying the
> coordinates for a textbox for each number)?
>
> I need to make ~12 of these for different samples of n=25, so the manual
> approach would be very painful...
>
> Thanks,
>
> Dan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Thu Jan  5 23:21:21 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 6 Jan 2017 11:21:21 +1300
Subject: [R] [FORGED] Re:  Generating a Special Histogram
In-Reply-To: <CA+8X3fUN5bdpoAn43Cbj269PFzu_cBnPFc+rCVVRMBMEz3sR4g@mail.gmail.com>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
	<CA+8X3fUN5bdpoAn43Cbj269PFzu_cBnPFc+rCVVRMBMEz3sR4g@mail.gmail.com>
Message-ID: <27e3cd86-4d55-6e45-80a7-d4b466e3f75a@auckland.ac.nz>

On 06/01/17 10:31, Jim Lemon wrote:
> Hi Dan,
> This may help if your data is in the format below:
>
> waffle.mat<-matrix(c(rep(NA,14),137,135,rep(NA,6),144,149,
>  rep(NA,3),150,152,159,157,154,
>  NA,163,164,164,161,162,165,164,rep(NA,5),179,173,173,
>  rep(NA,4),182,180,185,180,
>  rep(NA,6),197,190,rep(NA,8)),ncol=9)
> waffle.col<-matrix("lightblue",ncol=9,nrow=8)
> waffle.col[is.na(waffle.mat)]<-NA
> waffle.border<-matrix("blue",ncol=9,nrow=8)
> waffle.border[is.na(waffle.mat)]<-NA
> library(plotrix)
> # use a waffle plot
> color2D.matplot(waffle.mat,cellcolors=waffle.col,border=waffle.border,
>  show.values=TRUE,xat=10,yat=10,xlab="",ylab="")
> axis(1,at=1:8,labels=seq(130,200,by=10))
> axis(2,at=1:8)
> axis.break(1)

Being picky-picky-picky I would like to point out that Duncan's and 
David's functions don't *quite* reproduce the picture in the pdf file
that the OP attached, when called with the data from that picture:

egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
            161,162,165,164,179,173,173,182,180,185,180,197,190)
myhist(egdat)
boxhist(egdat)

It's a matter of including the left or right endpoints in the bins.

Duncan's function needs to swap "<" and "<=" in the definition of "keep"
(and make a corresponding adjustment in the "|" clause, so as to look at
the last rather than the first break value).

David's function needs to set "right=FALSE" in the call to cut().

Jim's waffle plot gets it right, at the expense of needing to have the
data organised in an inconvenient form.

All that being said, all of you blokes came up with solutions that are 
far beyond my capability of producing.  Hat's off to you.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Thu Jan  5 23:39:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 6 Jan 2017 09:39:24 +1100
Subject: [R] [FORGED] Re:  Generating a Special Histogram
In-Reply-To: <27e3cd86-4d55-6e45-80a7-d4b466e3f75a@auckland.ac.nz>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
	<CA+8X3fUN5bdpoAn43Cbj269PFzu_cBnPFc+rCVVRMBMEz3sR4g@mail.gmail.com>
	<27e3cd86-4d55-6e45-80a7-d4b466e3f75a@auckland.ac.nz>
Message-ID: <CA+8X3fXZ-qoEPimCp9H_r9k9em7fh34X6DOcC+vqbh-qqhYAoA@mail.gmail.com>

A worthy challenge, Rolf:

egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
           161,162,165,164,179,173,173,182,180,185,180,197,190)
egcut<-cut(egdat,breaks=seq(120,210,by=10),right=FALSE)
eglist<-vector("list",9)
for(egindex in 1:9) eglist[[egindex]]<-rev(egdat[as.numeric(egcut)==egindex])
egdf<-as.data.frame(lapply(eglist,function(x) x[1:8]))
names(egdf)<-paste("V",1:9,sep="")
waffle.mat<-as.matrix(sapply(egdf,rev))

Jim


On Fri, Jan 6, 2017 at 9:21 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 06/01/17 10:31, Jim Lemon wrote:
>>
>> Hi Dan,
>> This may help if your data is in the format below:
>>
>> waffle.mat<-matrix(c(rep(NA,14),137,135,rep(NA,6),144,149,
>>  rep(NA,3),150,152,159,157,154,
>>  NA,163,164,164,161,162,165,164,rep(NA,5),179,173,173,
>>  rep(NA,4),182,180,185,180,
>>  rep(NA,6),197,190,rep(NA,8)),ncol=9)
>> waffle.col<-matrix("lightblue",ncol=9,nrow=8)
>> waffle.col[is.na(waffle.mat)]<-NA
>> waffle.border<-matrix("blue",ncol=9,nrow=8)
>> waffle.border[is.na(waffle.mat)]<-NA
>> library(plotrix)
>> # use a waffle plot
>> color2D.matplot(waffle.mat,cellcolors=waffle.col,border=waffle.border,
>>  show.values=TRUE,xat=10,yat=10,xlab="",ylab="")
>> axis(1,at=1:8,labels=seq(130,200,by=10))
>> axis(2,at=1:8)
>> axis.break(1)
>
>
> Being picky-picky-picky I would like to point out that Duncan's and David's
> functions don't *quite* reproduce the picture in the pdf file
> that the OP attached, when called with the data from that picture:
>
> egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
>            161,162,165,164,179,173,173,182,180,185,180,197,190)
> myhist(egdat)
> boxhist(egdat)
>
> It's a matter of including the left or right endpoints in the bins.
>
> Duncan's function needs to swap "<" and "<=" in the definition of "keep"
> (and make a corresponding adjustment in the "|" clause, so as to look at
> the last rather than the first break value).
>
> David's function needs to set "right=FALSE" in the call to cut().
>
> Jim's waffle plot gets it right, at the expense of needing to have the
> data organised in an inconvenient form.
>
> All that being said, all of you blokes came up with solutions that are far
> beyond my capability of producing.  Hat's off to you.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Fri Jan  6 00:50:03 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 5 Jan 2017 18:50:03 -0500
Subject: [R] [FORGED] Re:  Generating a Special Histogram
In-Reply-To: <27e3cd86-4d55-6e45-80a7-d4b466e3f75a@auckland.ac.nz>
References: <CAPRGo-=kE49b6Rah7umtmMMnFZjxB1y0m22Q3kprCfe5Rp-_iA@mail.gmail.com>
	<CA+8X3fUN5bdpoAn43Cbj269PFzu_cBnPFc+rCVVRMBMEz3sR4g@mail.gmail.com>
	<27e3cd86-4d55-6e45-80a7-d4b466e3f75a@auckland.ac.nz>
Message-ID: <8356f827-28b2-295a-fefb-02b873342217@gmail.com>

On 05/01/2017 5:21 PM, Rolf Turner wrote:
> On 06/01/17 10:31, Jim Lemon wrote:
>> Hi Dan,
>> This may help if your data is in the format below:
>>
>> waffle.mat<-matrix(c(rep(NA,14),137,135,rep(NA,6),144,149,
>>  rep(NA,3),150,152,159,157,154,
>>  NA,163,164,164,161,162,165,164,rep(NA,5),179,173,173,
>>  rep(NA,4),182,180,185,180,
>>  rep(NA,6),197,190,rep(NA,8)),ncol=9)
>> waffle.col<-matrix("lightblue",ncol=9,nrow=8)
>> waffle.col[is.na(waffle.mat)]<-NA
>> waffle.border<-matrix("blue",ncol=9,nrow=8)
>> waffle.border[is.na(waffle.mat)]<-NA
>> library(plotrix)
>> # use a waffle plot
>> color2D.matplot(waffle.mat,cellcolors=waffle.col,border=waffle.border,
>>  show.values=TRUE,xat=10,yat=10,xlab="",ylab="")
>> axis(1,at=1:8,labels=seq(130,200,by=10))
>> axis(2,at=1:8)
>> axis.break(1)
>
> Being picky-picky-picky I would like to point out that Duncan's and
> David's functions don't *quite* reproduce the picture in the pdf file
> that the OP attached, when called with the data from that picture:
>
> egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
>             161,162,165,164,179,173,173,182,180,185,180,197,190)
> myhist(egdat)
> boxhist(egdat)
>
> It's a matter of including the left or right endpoints in the bins.
>
> Duncan's function needs to swap "<" and "<=" in the definition of "keep"
> (and make a corresponding adjustment in the "|" clause, so as to look at
> the last rather than the first break value).

Well, that's just because the attached picture was wrong :-).

Duncan

>
> David's function needs to set "right=FALSE" in the call to cut().
>
> Jim's waffle plot gets it right, at the expense of needing to have the
> data organised in an inconvenient form.
>
> All that being said, all of you blokes came up with solutions that are
> far beyond my capability of producing.  Hat's off to you.
>
> cheers,
>
> Rolf
>


From suttoncarl at ymail.com  Fri Jan  6 05:20:39 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 6 Jan 2017 04:20:39 +0000 (UTC)
Subject: [R] Fw: Regex problem
In-Reply-To: <E7656E54-462B-4E35-A1BC-07FE945E8208@comcast.net>
References: <645156402.5640682.1483482544491.ref@mail.yahoo.com>
	<645156402.5640682.1483482544491@mail.yahoo.com>
	<267068192.576547.1483639760628@mail.yahoo.com>
	<E7656E54-462B-4E35-A1BC-07FE945E8208@comcast.net>
Message-ID: <140079124.867005.1483676439390@mail.yahoo.com>

Thank you gentlemen, thank you!?? All worked as you said it would and my headers are now error free.
And David, thanks for the reference material cite.? I will looking at that this weekend.
?Carl Sutton 

    On Thursday, January 5, 2017 12:12 PM, David Winsemius <dwinsemius at comcast.net> wrote:
 
 

 
> On Jan 5, 2017, at 10:09 AM, Carl Sutton via R-help <r-help at r-project.org> wrote:
> 
> Re-sending help request, went to wrong addy first time.? 
> r-help-request at r-project.org
> 
> Belated Happy new year to the Guru's:
> 
> I have a data frame with 570+ columns and in those column headers yours truly has a few blunders.? Namely somehow I managed to end some of them with both an apostrophe ' and an ending quote.

Doubtful. You probably only have a single apostrophe and no "ending quote". In fact when I run your `problemdf`, the `make.names` function (called by data.frame) changed the apostrophe into a period. To actually get a trailing apostrophe with `data.frame` you would need to set check.names=FALSE:

df1 <- data.frame("WhatAmI\'" = 1:5, "WhoAreYou" = 11:15, check.names=FALSE)
colnames(df1)
#[1] "WhatAmI'"? "WhoAreYou"
There is no double quote in that name. Now to remove the offending apostrophe (or even multiple instances of them) just do this:

names(df) <- gsub( "\\'", "", names(df)


>? I think the attached code finds the occurrences (not 100% sure) and feedback is appreciated.? This is my first attempt at regex and I have been googling and reading the last few days (including an R -Exercise).
> 
> Confused as to why the column names shows a "." instead of a " ' ".

See above.



> 
> Ignorant of why gregexpr and regexpr show attr(,"useBytes") as TRUE when the default is FALSE.? Is it possible I somehow messed them up last week?? Simply typing the function name in the console shows the defaults as FALSE.
> 
> I have not been able to build a construct to simply delete the apostrophe.? I have made several attempts to do this, and left one for your perusal.? The others were just to "off the wall" and embarrassing.
> 
> Lastly, is there a way for me to check that all of my column names end with a letter followed by a quote?? I am thinking something along the lines of "[[:alpha:]\\"" but I expect that will throw an error.? I stumbled upon the ' " problem when dplyr complained about it last week, and it is unsettling to think I may have more goofs.
> 
> Any suggestions of a good reference book is much appreciated.? I can see extended use of regex coming toward me and I am so ignorant it is frightening (all volunteer work, no $'s involved, but I dislike being incompetent).

I learned regex by reading the ?regex page, and by looking up and working through questions on R-help by Gabor Grothendeick:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+regex#query:list%3Aorg.r-project.r-help%20regex%20from%3A%22Gabor%20Grothendieck%22+page:1+state:facets


There are also several online sites where you can get an expression by expression readout of what your regexes are doing. They do need the understanding that hte escape character for R and regex are the same and the means they need to be doubled in hte pattern arguments (but _not_ the replacement arguments).

-- 
David.


> 
> 
> #? regex problemdf1 <- data.frame("WhatAmI'" = 1:5, "WhoAreYou" = 11:15)
> colnames(df1)
> df1
> ma_pattern <- "[[:punct:]][[:punct:]]" # Need single ][ in the middle??
> grep(ma_pattern,colnames(df1))
> ma_pattern <- "[[:punct:][:punct:]]"? #? single ][ worked
> grep(ma_pattern,colnames(df1),value = TRUE)? #? found it
> grepl(ma_pattern,colnames(df1)) 
> gregexpr(ma_pattern,colnames(df1))? # at position 8
> regexpr(ma_pattern,colnames(df1))
> 
> #sub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE,
> #? ? fixed = FALSE, useBytes = FALSE)
> 
> #sub(ma_pattern,replacement = "'\\"",df1)
> colnames(df1)
> 
> Carl Sutton
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


 
   
	[[alternative HTML version deleted]]


From mm95nov at gmail.com  Thu Jan  5 21:40:19 2017
From: mm95nov at gmail.com (Malvika Marathe)
Date: Thu, 5 Jan 2017 15:40:19 -0500
Subject: [R] Assignment 1 (function error)
Message-ID: <AA67F179-B296-4B4A-850A-23528D048890@gmail.com>

Can you please help me with this assignment. I am having trouble with inputting the ID. At the moment, the function will calculate 1-the ID number you put in. I am not sure how to make it so that you can put only one number in or a range of your choosing (a range that doesn?t start with 1)




From elifbeyzacatalbas at gmail.com  Thu Jan  5 19:56:36 2017
From: elifbeyzacatalbas at gmail.com (=?UTF-8?B?ZWxpZiBiZXl6YSDDp2F0YWxiYcWf?=)
Date: Thu, 5 Jan 2017 20:56:36 +0200
Subject: [R] Dates and Times in R
Message-ID: <CAHN7+LJGibaY5VF79D-r85J78EvDndNush6tjkiTALY=pd4e1g@mail.gmail.com>

Dear Mrs/Mr

I am a meteorological engineer and currently I am a master of science
student in atmospheric science at Istanbul Technical University. I have
data analysis and visualization lesson and I am analyzing data in R
programming. I have to project in this lesson and I am working on wind
energy sector because of this I chose bReeze packages to examine wind data.
But I am having trouble reading time,Deadlines of my project is  9 January
2017. You can find my data in a attachment. I look forward to hearing from
you.

Sincerely,

Elif Beyza ?ATALBA?
Meteorological Engineer

From dwinsemius at comcast.net  Fri Jan  6 06:13:18 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Jan 2017 21:13:18 -0800
Subject: [R] Dates and Times in R
In-Reply-To: <CAHN7+LJGibaY5VF79D-r85J78EvDndNush6tjkiTALY=pd4e1g@mail.gmail.com>
References: <CAHN7+LJGibaY5VF79D-r85J78EvDndNush6tjkiTALY=pd4e1g@mail.gmail.com>
Message-ID: <6432E5B4-A6F3-405F-8C9D-F0592E6D0AFC@comcast.net>

You should read the Posting Guide.

> On Jan 5, 2017, at 10:56 AM, elif beyza ?atalba? <elifbeyzacatalbas at gmail.com> wrote:
> 
> Dear Mrs/Mr
> 
> I am a meteorological engineer and currently I am a master of science
> student in atmospheric science at Istanbul Technical University. I have
> data analysis and visualization lesson and I am analyzing data in R
> programming. I have to project in this lesson and I am working on wind
> energy sector because of this I chose bReeze packages to examine wind data.
> But I am having trouble reading time,Deadlines of my project is  9 January
> 2017. You can find my data in a attachment. I look forward to hearing from
> you.
> 
> Sincerely,
> 
> Elif Beyza ?ATALBA?
> Meteorological Engineer
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Jan  6 06:14:10 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Jan 2017 21:14:10 -0800
Subject: [R] Assignment 1 (function error)
In-Reply-To: <AA67F179-B296-4B4A-850A-23528D048890@gmail.com>
References: <AA67F179-B296-4B4A-850A-23528D048890@gmail.com>
Message-ID: <3FC463AC-F048-44C5-B0AA-ABDB4EA7C576@comcast.net>

You should read the Posting Guide.


> On Jan 5, 2017, at 12:40 PM, Malvika Marathe <mm95nov at gmail.com> wrote:
> 
> Can you please help me with this assignment. I am having trouble with inputting the ID. At the moment, the function will calculate 1-the ID number you put in. I am not sure how to make it so that you can put only one number in or a range of your choosing (a range that doesn?t start with 1)
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From chocold12 at gmail.com  Fri Jan  6 06:42:53 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 5 Jan 2017 22:42:53 -0700
Subject: [R] About concatenating strings
Message-ID: <CAN5afy-JsoE6gT-9+GkPRnz57UCdV2-AMh5qoHF=fUNz9ZX05g@mail.gmail.com>

Hi R users,

I'm trying to concatenate two strings, while each string has numbers.
For example, strings1 = c(1.2, 1.31, 1.4, 1.51, etc), strings2= c(2.1,
2.22, 2.3, 2.44, etc). I want to have all decimals for the two strings,
such as: strings1= c(1.20, 1.31, 1.40, 1.51, etc), string2 = c(2.10, 2.22,
2.30, 2.44, etc).
After concatenating, they become c(1.20--2.10, 1.31--2.22, 1.40--2.30,
1.51--2.44, etc)
I use the code below, but after digits=2 in the parentheses, the length of
each string has one more. What is the problem and how to do it another way?
Thanks.

cons  = paste(c(strings1, digits=2), c(strings2, digits=2), sep='-')

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Jan  6 06:46:31 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 5 Jan 2017 22:46:31 -0700
Subject: [R] About concatenating strings
In-Reply-To: <CAN5afy-JsoE6gT-9+GkPRnz57UCdV2-AMh5qoHF=fUNz9ZX05g@mail.gmail.com>
References: <CAN5afy-JsoE6gT-9+GkPRnz57UCdV2-AMh5qoHF=fUNz9ZX05g@mail.gmail.com>
Message-ID: <CAN5afy-ZFP0AJtP=AHtMg9wfg0_4vPo+fqkS_5_GV7YNjO23CA@mail.gmail.com>

I found that the last column is the digits 2.00, so the problem is solved.

On Thu, Jan 5, 2017 at 10:42 PM, lily li <chocold12 at gmail.com> wrote:

> Hi R users,
>
> I'm trying to concatenate two strings, while each string has numbers.
> For example, strings1 = c(1.2, 1.31, 1.4, 1.51, etc), strings2= c(2.1,
> 2.22, 2.3, 2.44, etc). I want to have all decimals for the two strings,
> such as: strings1= c(1.20, 1.31, 1.40, 1.51, etc), string2 = c(2.10, 2.22,
> 2.30, 2.44, etc).
> After concatenating, they become c(1.20--2.10, 1.31--2.22, 1.40--2.30,
> 1.51--2.44, etc)
> I use the code below, but after digits=2 in the parentheses, the length of
> each string has one more. What is the problem and how to do it another way?
> Thanks.
>
> cons  = paste(c(strings1, digits=2), c(strings2, digits=2), sep='-')
>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Jan  6 06:56:48 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 5 Jan 2017 22:56:48 -0700
Subject: [R] About concatenating strings
In-Reply-To: <CAN5afy-ZFP0AJtP=AHtMg9wfg0_4vPo+fqkS_5_GV7YNjO23CA@mail.gmail.com>
References: <CAN5afy-JsoE6gT-9+GkPRnz57UCdV2-AMh5qoHF=fUNz9ZX05g@mail.gmail.com>
	<CAN5afy-ZFP0AJtP=AHtMg9wfg0_4vPo+fqkS_5_GV7YNjO23CA@mail.gmail.com>
Message-ID: <CAN5afy8q+xE9tmd8oyzL1RJfu7vWmi8WbonUy0k_oGmE1BA=2w@mail.gmail.com>

Sorry for the emails. I just checked and the problem is still there. Is
there a proper way to reformat the decimal places, such as three or four
decimal places? Thanks.

If maintain four decimal places, the numbers are: 1.2000, 1.3100, 1.4000,
etc.

On Thu, Jan 5, 2017 at 10:46 PM, lily li <chocold12 at gmail.com> wrote:

> I found that the last column is the digits 2.00, so the problem is solved.
>
> On Thu, Jan 5, 2017 at 10:42 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi R users,
>>
>> I'm trying to concatenate two strings, while each string has numbers.
>> For example, strings1 = c(1.2, 1.31, 1.4, 1.51, etc), strings2= c(2.1,
>> 2.22, 2.3, 2.44, etc). I want to have all decimals for the two strings,
>> such as: strings1= c(1.20, 1.31, 1.40, 1.51, etc), string2 = c(2.10, 2.22,
>> 2.30, 2.44, etc).
>> After concatenating, they become c(1.20--2.10, 1.31--2.22, 1.40--2.30,
>> 1.51--2.44, etc)
>> I use the code below, but after digits=2 in the parentheses, the length
>> of each string has one more. What is the problem and how to do it another
>> way? Thanks.
>>
>> cons  = paste(c(strings1, digits=2), c(strings2, digits=2), sep='-')
>>
>>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Jan  6 07:27:07 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 6 Jan 2017 17:27:07 +1100
Subject: [R] About concatenating strings
In-Reply-To: <CAN5afy8q+xE9tmd8oyzL1RJfu7vWmi8WbonUy0k_oGmE1BA=2w@mail.gmail.com>
References: <CAN5afy-JsoE6gT-9+GkPRnz57UCdV2-AMh5qoHF=fUNz9ZX05g@mail.gmail.com>
	<CAN5afy-ZFP0AJtP=AHtMg9wfg0_4vPo+fqkS_5_GV7YNjO23CA@mail.gmail.com>
	<CAN5afy8q+xE9tmd8oyzL1RJfu7vWmi8WbonUy0k_oGmE1BA=2w@mail.gmail.com>
Message-ID: <CA+8X3fVg31HhHxQLphBnv7q0V+dj-6J6dG_dzQ-TyF2AB7WFKQ@mail.gmail.com>

Hi lily,
maybe this is what you want:

strings1<-c(1.2,1.31,1.4,1.51)
strings2<-c(2.1,2.22,2.3,2.44)
paste(formatC(strings1,digits=2,format="f"),
 formatC(strings2,digits=2,format="f"),sep="-")

Jim


On Fri, Jan 6, 2017 at 4:56 PM, lily li <chocold12 at gmail.com> wrote:
> Sorry for the emails. I just checked and the problem is still there. Is
> there a proper way to reformat the decimal places, such as three or four
> decimal places? Thanks.
>
> If maintain four decimal places, the numbers are: 1.2000, 1.3100, 1.4000,
> etc.
>
> On Thu, Jan 5, 2017 at 10:46 PM, lily li <chocold12 at gmail.com> wrote:
>
>> I found that the last column is the digits 2.00, so the problem is solved.
>>
>> On Thu, Jan 5, 2017 at 10:42 PM, lily li <chocold12 at gmail.com> wrote:
>>
>>> Hi R users,
>>>
>>> I'm trying to concatenate two strings, while each string has numbers.
>>> For example, strings1 = c(1.2, 1.31, 1.4, 1.51, etc), strings2= c(2.1,
>>> 2.22, 2.3, 2.44, etc). I want to have all decimals for the two strings,
>>> such as: strings1= c(1.20, 1.31, 1.40, 1.51, etc), string2 = c(2.10, 2.22,
>>> 2.30, 2.44, etc).
>>> After concatenating, they become c(1.20--2.10, 1.31--2.22, 1.40--2.30,
>>> 1.51--2.44, etc)
>>> I use the code below, but after digits=2 in the parentheses, the length
>>> of each string has one more. What is the problem and how to do it another
>>> way? Thanks.
>>>
>>> cons  = paste(c(strings1, digits=2), c(strings2, digits=2), sep='-')
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Jan  6 07:32:13 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 6 Jan 2017 17:32:13 +1100
Subject: [R] Assignment 1 (function error)
In-Reply-To: <AA67F179-B296-4B4A-850A-23528D048890@gmail.com>
References: <AA67F179-B296-4B4A-850A-23528D048890@gmail.com>
Message-ID: <CA+8X3fUhJGiXBH_fTmhCVzRCwLWQmgNDFBuwTSLJnfBOV6xmaw@mail.gmail.com>

Hi Malvika,
What David means is that we don't do people's homework for them. Have
a look at "An Introduction to R" that comes with the R distribution,
particularly about sequences and vectorization.

Jim


On Fri, Jan 6, 2017 at 7:40 AM, Malvika Marathe <mm95nov at gmail.com> wrote:
> Can you please help me with this assignment. I am having trouble with inputting the ID. At the moment, the function will calculate 1-the ID number you put in. I am not sure how to make it so that you can put only one number in or a range of your choosing (a range that doesn?t start with 1)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Jan  6 08:25:39 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 6 Jan 2017 07:25:39 +0000
Subject: [R] Dates and Times in R
In-Reply-To: <6432E5B4-A6F3-405F-8C9D-F0592E6D0AFC@comcast.net>
References: <CAHN7+LJGibaY5VF79D-r85J78EvDndNush6tjkiTALY=pd4e1g@mail.gmail.com>
	<6432E5B4-A6F3-405F-8C9D-F0592E6D0AFC@comcast.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC7AE@SRVEXCHCM301.precheza.cz>

Hi
It strongly reminds me following fortune

library(fortunes)
fortune("surgery")

Along with Posting guide you should also look at chapter 7 of R intro manual.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Friday, January 6, 2017 6:13 AM
> To: elif beyza ?atalba? <elifbeyzacatalbas at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Dates and Times in R
>
> You should read the Posting Guide.
>
> > On Jan 5, 2017, at 10:56 AM, elif beyza ?atalba?
> <elifbeyzacatalbas at gmail.com> wrote:
> >
> > Dear Mrs/Mr
> >
> > I am a meteorological engineer and currently I am a master of science
> > student in atmospheric science at Istanbul Technical University. I
> > have data analysis and visualization lesson and I am analyzing data in
> > R programming. I have to project in this lesson and I am working on
> > wind energy sector because of this I chose bReeze packages to examine
> wind data.
> > But I am having trouble reading time,Deadlines of my project is  9
> > January 2017. You can find my data in a attachment. I look forward to
> > hearing from you.
> >
> > Sincerely,
> >
> > Elif Beyza ?ATALBA?
> > Meteorological Engineer
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ulrik.stervbo at gmail.com  Fri Jan  6 11:23:05 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 06 Jan 2017 10:23:05 +0000
Subject: [R] Dates and Times in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC7AE@SRVEXCHCM301.precheza.cz>
References: <CAHN7+LJGibaY5VF79D-r85J78EvDndNush6tjkiTALY=pd4e1g@mail.gmail.com>
	<6432E5B4-A6F3-405F-8C9D-F0592E6D0AFC@comcast.net>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC7AE@SRVEXCHCM301.precheza.cz>
Message-ID: <CAKVAULNkWVwMNrHKGdiAJM7to49M35zoV8-7-hVckrqW=ntLFQ@mail.gmail.com>

The lubridate package might be helpful.

HTH
Ulrik

On Fri, 6 Jan 2017 at 08:28 PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> It strongly reminds me following fortune
>
> library(fortunes)
> fortune("surgery")
>
> Along with Posting guide you should also look at chapter 7 of R intro
> manual.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> > Winsemius
> > Sent: Friday, January 6, 2017 6:13 AM
> > To: elif beyza ?atalba? <elifbeyzacatalbas at gmail.com>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Dates and Times in R
> >
> > You should read the Posting Guide.
> >
> > > On Jan 5, 2017, at 10:56 AM, elif beyza ?atalba?
> > <elifbeyzacatalbas at gmail.com> wrote:
> > >
> > > Dear Mrs/Mr
> > >
> > > I am a meteorological engineer and currently I am a master of science
> > > student in atmospheric science at Istanbul Technical University. I
> > > have data analysis and visualization lesson and I am analyzing data in
> > > R programming. I have to project in this lesson and I am working on
> > > wind energy sector because of this I chose bReeze packages to examine
> > wind data.
> > > But I am having trouble reading time,Deadlines of my project is  9
> > > January 2017. You can find my data in a attachment. I look forward to
> > > hearing from you.
> > >
> > > Sincerely,
> > >
> > > Elif Beyza ?ATALBA?
> > > Meteorological Engineer
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From j.marchesi at imperial.ac.uk  Fri Jan  6 08:43:09 2017
From: j.marchesi at imperial.ac.uk (Marchesi, Julian)
Date: Fri, 6 Jan 2017 07:43:09 +0000
Subject: [R] testing whether clusters in a PCA plot are significantly
 different from one another
Message-ID: <DB4PR06MB032C5A26C7F9186D0190FD3AF630@DB4PR06MB032.eurprd06.prod.outlook.com>

A non-text attachment was scrubbed...
Name: Rplot_PCA.pdf
Type: application/pdf
Size: 5771 bytes
Desc: Rplot_PCA.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170106/b8b8613c/attachment.pdf>

From paulbernal07 at gmail.com  Fri Jan  6 14:42:06 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 6 Jan 2017 08:42:06 -0500
Subject: [R] IRkernel Installation Issues
In-Reply-To: <33D9F8D6-D4D3-425D-B947-CE44D6FD1779@comcast.net>
References: <CAMOcQfOtWEw_ga5ExVS+iaYYnVb9eks3O7SqNZbZgd3s=+b3Mw@mail.gmail.com>
	<33D9F8D6-D4D3-425D-B947-CE44D6FD1779@comcast.net>
Message-ID: <CAMOcQfPCcTx=Jd3SrWGThAZzQuVWbxguuUsSbS5Wa_=JC2uu0g@mail.gmail.com>

Dear friends,

Great news! I was able to install the IRkernel successfully and I am now
able to create R notebooks in Jupyter. Just in case anybody out there is
struggling with this too, here is what I did (I have Windows 8, but it will
probably work for Mac OS X as well):

1-Go to the page https://irkernel.github.io/installation
2-Open the R console (I have R version 3.3.2)
3-Go to the step where it says "Installing via supplied binary packages
(default on Windows + Mac OS X)
4-Instead of installing all the packages using one single command as
suggested in the installation instructions, go to the R console and install
all of the packages one by one, as follows
 >install.packages('repr')
 >install.packages('IRdisplay')
 >install.packages('evaluate')
 >install.packages('crayon')
 >install.packages('pbdZMQ')
 >install.packages('devtools')
 >install.packages('uuid')
 >install.packages('digest')
5-Connect to a CRAN mirror and select install packages, look for the
package githubinstall and clic on it to install it
6-Start loading each one of the packages installed like this:
 >library("repr")
 >library("IRdisplay")
 >library("evaluate")
 >library("crayon")
 >library("pbdZMQ")
 >library("devtools")
 >library("uuid")
 >library("digest")
 >library("githubinstall")
7-After this you have to update jsonlite which is a dependencie of package
githubinstall, you update jsonlite using the following command:
 >update.packages('jsonlite')
8-After this, you have to type the following commands:
 >library(httr)
 >set_config(use_proxy(url="the required IP", port=8080, username="your
network user", password="the password you use to unlock your computer"))
 >#you can get the required IP going to the command prompt and using the
command ping
 >#port has to be 8080
9-type use the command:
 >devtools::install_github('IRkernel/IRkernel')
10-Last but not least, type the following command:
 >IRkernel::installspec()

If you follow this instructions you should be able to install the IRkernel
successfully and start writing R notebooks in Jupyter.

Hope this helps,

Paul





2017-01-05 16:12 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Jan 5, 2017, at 11:16 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > Hello everyone,
> >
> > I tried to get the IRkernel going doing the following:
> >
> > install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
> > 'devtools', 'uuid', 'digest'))
> >
> > then taking care of proxy settings by doing:
> >
> > library(devtools)
> >
> > library(httr)
> >
> > set_config(use_proxy(url="",port=8080,username="user",password="pswrd"))
> >
> > then installed package install_github
> >
> > then called library(githubinstall)
> >
> > finally install_github(('IRkernel')
>
> The mismatch of parentheses makes me doubt this was an exact copy. I
> believe the username referred to in the error refers to the username of the
> author, not your username. Notice the form of all the examples on
> `?install_github` are of the form:  install_github("klutometis/roxygen")
>
>  Why are you not trying the code suggested on the github page:
> https://github.com/IRkernel/IRkernel
>
>  install_github('IRkernel/IRkernel')
>
> (Worked for me on a Mac. No other username or pwd needed)
>
>
> >
> > However the following error popped up: "Error in username %||%
> > getOption("github.user") %||% stop("Unknown username.") :
> >  Unknown username.
> >
> > Any idea what could be wrong? I tried with buth my network username and
> > password and my github username and password without any success.
> >
> > Regards,
> >
> > Paul
> >
> >       [[alternative HTML version deleted]]
>
> R-help is a plain text mailing list.
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Fri Jan  6 14:43:43 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 6 Jan 2017 08:43:43 -0500
Subject: [R] Problem with IRkernel Installation Solved - Instructions on how
 to Solve it
Message-ID: <CAMOcQfMNyxFK9fo6-7tOP4sTHpBAwOn0A5_2p0p0BQpBG4Gp2w@mail.gmail.com>

Dear friends,

Great news! I was able to install the IRkernel successfully and I am now
able to create R notebooks in Jupyter. Just in case anybody out there is
struggling with this too, here is what I did (I have Windows 8, but it will
probably work for Mac OS X as well):

1-Go to the page https://irkernel.github.io/installation
2-Open the R console (I have R version 3.3.2)
3-Go to the step where it says "Installing via supplied binary packages
(default on Windows + Mac OS X)
4-Instead of installing all the packages using one single command as
suggested in the installation instructions, go to the R console and install
all of the packages one by one, as follows
 >install.packages('repr')
 >install.packages('IRdisplay')
 >install.packages('evaluate')
 >install.packages('crayon')
 >install.packages('pbdZMQ')
 >install.packages('devtools')
 >install.packages('uuid')
 >install.packages('digest')
5-Connect to a CRAN mirror and select install packages, look for the
package githubinstall and clic on it to install it
6-Start loading each one of the packages installed like this:
 >library("repr")
 >library("IRdisplay")
 >library("evaluate")
 >library("crayon")
 >library("pbdZMQ")
 >library("devtools")
 >library("uuid")
 >library("digest")
 >library("githubinstall")
7-After this you have to update jsonlite which is a dependencie of package
githubinstall, you update jsonlite using the following command:
 >update.packages('jsonlite')
8-After this, you have to type the following commands:
 >library(httr)
 >set_config(use_proxy(url="the required IP", port=8080, username="your
network user", password="the password you use to unlock your computer"))
 >#you can get the required IP going to the command prompt and using the
command ping
 >#port has to be 8080
9-type use the command:
 >devtools::install_github('IRkernel/IRkernel')
10-Last but not least, type the following command:
 >IRkernel::installspec()

If you follow this instructions you should be able to install the IRkernel
successfully and start writing R notebooks in Jupyter.

Hope this helps,

	[[alternative HTML version deleted]]


From vanrome54 at gmail.com  Fri Jan  6 15:08:18 2017
From: vanrome54 at gmail.com (Vanessa Romero)
Date: Fri, 6 Jan 2017 15:08:18 +0100
Subject: [R] Tobit Regression with unbalanced Panel Data
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC30B@SRVEXCHCM301.precheza.cz>
References: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC30B@SRVEXCHCM301.precheza.cz>
Message-ID: <CABnhivu0F9yOWN6_an4_mdeQP68piMP8kMw0F6SJKWwg7hnTcg@mail.gmail.com>

Thank you for your answers.

I have just replaced pdata.frame with plm.data and it worked.

tobit1<- plm.data(T1, index = c("firm", "year"))

But I have two more questions, maybe someone could help:

summary(Tob)

Call:
censReg(formula = Imp ~ Bath + CEOTurnover + ChangeOCF + E +
    Sales + ROE + GTA + Size, data = tobit1, method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored
           606            469            137              0

Coefficients:
              Estimate Std. error    t value  Pr(> t)
(Intercept)  1.110e-03  5.648e-04      1.965   0.0494 *
Bath         7.442e-03  6.780e-03      1.098   0.2724
CEOTurnover -1.500e-03  2.742e-04     -5.472 4.45e-08 ***
ChangeOCF   -6.738e-03  1.272e-03     -5.297 1.18e-07 ***
E           -5.515e-02  5.304e-03    -10.398  < 2e-16 ***
Sales        8.009e-03  3.487e-04     22.971  < 2e-16 ***
ROE          2.921e-03  5.896e-06    495.331  < 2e-16 ***
GTA         -3.509e-03  1.174e-03     -2.989   0.0028 **
Size        -5.688e-04  1.220e-04     -4.662 3.13e-06 ***
logSigma    -5.401e+00  2.746e-04 -19668.028  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

BHHH maximisation, 150 iterations
Return code 4: Iteration limit exceeded.
Log-likelihood: -66915.77 on 10 Df

How can I calculate McFadden's adjusted  R2 in R?
How could I reduce iteration?

Thank you,
Vanessa



2017-01-04 13:25 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
>
> Hi
>
> Although I cannot help you with your actual problem, you shall start with checking your data before doing any analysis. We do not have your data so it is hard to say what can be wrong. At least you shall provide result of
>
> str(T1) and/or
> str(mydata)
>
> The first message is not an error but a warning that tells you about coercing some log values to NaN which can result e.g. from negative values.
>
> log(-1)
> [1] NaN
> Warning message:
> In log(-1) : NaNs produced
>
> and probably some further calculation in summary function does not like it and throws error.
>
> But without data it is only a guess.
>
> And BTW, you shall post plain text not HTML.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vanessa
> > Romero
> > Sent: Wednesday, January 4, 2017 10:28 AM
> > To: r-help at r-project.org
> > Subject: [R] Tobit Regression with unbalanced Panel Data
> >
> > Hello,
> >
> > I am doing Tobit Regression in R, because my dependent variable is censored
> > at 0. I have unbalanced panel data, for 6 years, 107 companies. I use package
> > CensReg.
> >
> > I have imported my database(T1).
> >
> > I use pdata.frame to specify the structure of my panel data. Like:
> >
> >
> > *mydata<- pdata.frame (T1, index = c("firm", "year")) *
> > Afterwards:
> >
> > *Tob <- censReg(formula=Imp ~ Bath + CEOTurnover + ChangeOCF + E +
> > Sales + ROE + GTA + Size , data = mydata, method="BHHH") * (as explained
> > here:
> > https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf)
> >
> > I got here error message:
> >
> >
> > *Warnmeldung: In log(rEff$ercomp$sigma$id) : NaNs wurden erzeugt*
> >
> > Another error message when *summary(Tob)*
> >
> >
> >
> >
> >
> > *Call: censReg(formula = Imp ~ Bath + CEOTurnover + ChangeOCF + E + Sales
> > + ROE + GTA + Size, data = mydata, method = "BHHH") Observations: Total
> > Left-censored Uncensored Right-censored 606 469 137 0 Coefficients: Fehler
> > in printCoefmat(coef(x, logSigma = logSigma), digits = digits) : 'x' must be
> > coefficient matrix/data frame*
> >
> > I am new to statistics and to R, what could be the problem or would you
> > suggest using other package.
> >
> > Thank you,
> > Vanessa
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From pdalgd at gmail.com  Fri Jan  6 15:50:48 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 6 Jan 2017 15:50:48 +0100
Subject: [R] Tobit Regression with unbalanced Panel Data
In-Reply-To: <CABnhivu0F9yOWN6_an4_mdeQP68piMP8kMw0F6SJKWwg7hnTcg@mail.gmail.com>
References: <CABnhivvR1XCOy=DaVA3J6DwdLXXn4UF0q=o9BQUigALgaNRNxw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FC30B@SRVEXCHCM301.precheza.cz>
	<CABnhivu0F9yOWN6_an4_mdeQP68piMP8kMw0F6SJKWwg7hnTcg@mail.gmail.com>
Message-ID: <DEEA2186-AD30-48B1-8CDC-F9CADDD177DD@gmail.com>


On 06 Jan 2017, at 15:08 , Vanessa Romero <vanrome54 at gmail.com> wrote:

> BHHH maximisation, 150 iterations
> Return code 4: Iteration limit exceeded.
> Log-likelihood: -66915.77 on 10 Df
> 
> How can I calculate McFadden's adjusted  R2 in R?

Google gets you there soon enough (e.g., "mcfadden r2 in r tobit"). One of the hits point to a Stata FAQ, explaining why McF's R^2 is nonsensical for tobit models....

> How could I reduce iteration?

Better starting values? In the absences of that, I think you want to _increase_ the limit, so that you are more sure that the procedure has converged. Also, a logSigma of -5.4 suggests that you are working with small numbers -- it sometimes helps to scale things by a factor of 100 or 1000.

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Fri Jan  6 16:29:13 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 6 Jan 2017 15:29:13 +0000
Subject: [R] testing whether clusters in a PCA plot are significantly
 different from one another
In-Reply-To: <DB4PR06MB032620BEA82F42A2E1883B5AF630@DB4PR06MB032.eurprd06.prod.outlook.com>
References: <DB4PR06MB032C5A26C7F9186D0190FD3AF630@DB4PR06MB032.eurprd06.prod.outlook.com>,
	<039934dba5414ea698219054f74eab60@exch-2p-mbx-w2.ads.tamu.edu>
	<DB4PR06MB032620BEA82F42A2E1883B5AF630@DB4PR06MB032.eurprd06.prod.outlook.com>
Message-ID: <9034304a63614fe990e380eaf133a238@exch-2p-mbx-w2.ads.tamu.edu>

In that case you should be able to use manova where pc1 and pc2 are the independent (response) variables and group (Baseline, HFD+P, HFD) is the dependent (explanatory) variable. Something like lm(cbind(pc1, pc2)~group). That will give you slopes for HFD+P and HFD (difference in mean relative to Baseline), t-values, and p-values for each component. You can get further diagnostics using package candisc. But your sample size is very small so there may be better approaches that a statistician specializing in medical research could suggest.

David C

-----Original Message-----
From: Marchesi, Julian [mailto:j.marchesi at imperial.ac.uk] 
Sent: Friday, January 6, 2017 9:02 AM
To: David L Carlson
Subject: Re: [R] testing whether clusters in a PCA plot are significantly different from one another

Dear David

The clusters are defined by the metadata which tells R where to draw the lines - no more no less

How would I put a P value to those clusters?

cheers

Julian

Julian R. Marchesi

Deputy Director and Professor of Clinical Microbiome Research at the  Centre for Digestive and Gut Health, Imperial College London, London W2 1NY Tel: +44 (0)20 331 26197

and

Professor of Human Microbiome Research at the School of Biosciences, Museum Avenue, Cardiff University, Cardiff, CF10 3AT, Tel: +44 (0)29 208 74188, Fax: +44 (0)29 20874305, Mobile 07885 569144




________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 06 January 2017 14:26
To: Marchesi, Julian
Subject: RE: [R] testing whether clusters in a PCA plot are significantly different from one another

You do not say how you defined the clusters in the plot that you attached. If you used the variables summarized by the principal components, the answer is yes, they are "significantly different".

Cluster analysis creates homogeneous clusters that will almost always be "significantly different" using standard tests such as analysis of variance. BUT these tests are only meaningful when the clusters are defined independently of the data.


David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marchesi, Julian
Sent: Friday, January 6, 2017 1:43 AM
To: 'r-help at r-project.org' <r-help at r-project.org>
Subject: [R] testing whether clusters in a PCA plot are significantly different from one another

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j.marchesi at imperial.ac.uk  Fri Jan  6 16:32:51 2017
From: j.marchesi at imperial.ac.uk (Marchesi, Julian)
Date: Fri, 6 Jan 2017 15:32:51 +0000
Subject: [R] testing whether clusters in a PCA plot are significantly
 different from one another
In-Reply-To: <9034304a63614fe990e380eaf133a238@exch-2p-mbx-w2.ads.tamu.edu>
References: <DB4PR06MB032C5A26C7F9186D0190FD3AF630@DB4PR06MB032.eurprd06.prod.outlook.com>,
	<039934dba5414ea698219054f74eab60@exch-2p-mbx-w2.ads.tamu.edu>
	<DB4PR06MB032620BEA82F42A2E1883B5AF630@DB4PR06MB032.eurprd06.prod.outlook.com>,
	<9034304a63614fe990e380eaf133a238@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <DB4PR06MB032BB6F277D23E4D50FC9A1AF630@DB4PR06MB032.eurprd06.prod.outlook.com>

many thanks david for such a swift response, really appreciate your help

cheers

Julian

Julian R. Marchesi

Deputy Director and Professor of Clinical Microbiome Research at the  Centre for Digestive and Gut Health, Imperial College London, London W2 1NY Tel: +44 (0)20 331 26197

and

Professor of Human Microbiome Research at the School of Biosciences, Museum Avenue, Cardiff University, Cardiff, CF10 3AT, Tel: +44 (0)29 208 74188, Fax: +44 (0)29 20874305, Mobile 07885 569144




________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 06 January 2017 15:29
To: Marchesi, Julian; r-help at r-project.org
Subject: RE: [R] testing whether clusters in a PCA plot are significantly different from one another

In that case you should be able to use manova where pc1 and pc2 are the independent (response) variables and group (Baseline, HFD+P, HFD) is the dependent (explanatory) variable. Something like lm(cbind(pc1, pc2)~group). That will give you slopes for HFD+P and HFD (difference in mean relative to Baseline), t-values, and p-values for each component. You can get further diagnostics using package candisc. But your sample size is very small so there may be better approaches that a statistician specializing in medical research could suggest.

David C

-----Original Message-----
From: Marchesi, Julian [mailto:j.marchesi at imperial.ac.uk]
Sent: Friday, January 6, 2017 9:02 AM
To: David L Carlson
Subject: Re: [R] testing whether clusters in a PCA plot are significantly different from one another

Dear David

The clusters are defined by the metadata which tells R where to draw the lines - no more no less

How would I put a P value to those clusters?

cheers

Julian

Julian R. Marchesi

Deputy Director and Professor of Clinical Microbiome Research at the  Centre for Digestive and Gut Health, Imperial College London, London W2 1NY Tel: +44 (0)20 331 26197

and

Professor of Human Microbiome Research at the School of Biosciences, Museum Avenue, Cardiff University, Cardiff, CF10 3AT, Tel: +44 (0)29 208 74188, Fax: +44 (0)29 20874305, Mobile 07885 569144




________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 06 January 2017 14:26
To: Marchesi, Julian
Subject: RE: [R] testing whether clusters in a PCA plot are significantly different from one another

You do not say how you defined the clusters in the plot that you attached. If you used the variables summarized by the principal components, the answer is yes, they are "significantly different".

Cluster analysis creates homogeneous clusters that will almost always be "significantly different" using standard tests such as analysis of variance. BUT these tests are only meaningful when the clusters are defined independently of the data.


David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marchesi, Julian
Sent: Friday, January 6, 2017 1:43 AM
To: 'r-help at r-project.org' <r-help at r-project.org>
Subject: [R] testing whether clusters in a PCA plot are significantly different from one another

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From maicel at infomed.sld.cu  Fri Jan  6 17:04:55 2017
From: maicel at infomed.sld.cu (maicel at infomed.sld.cu)
Date: Fri, 06 Jan 2017 11:04:55 -0500
Subject: [R] purrr::map and xml2:: read_xml
Message-ID: <20170106110455.66283tor8r9lz8rr@webmail.sld.cu>

Hi List, I am trying to extract the key words from 1403 papers in xml  
format. I programmed such codes but they do not work but they only do  
with the modification showed below. But that variation is not the one  
I need because the 1403 xml files do not match to those in my folder.  
Could you please tell me where are the mistakes in the codes list (A  
or B) to help me to correct them? The data frame columns are an id and  
the paths.

A-Does not work, but it is the one I need.

keyword <-
   muestra %>%
   select(path) %>%
   read_xmlmap(.f = function(x) { read_xml(x) %>%
        xml_find_all( ".//kwd") %>%
        xml_text(trim=T) })

B-It works but only with a small number of papers.

keyword <-
   muestra %>%
   select(path) %>%
    dplyr::sample_n(50) %>%
    unlist() %>%
   map(.f = function(x) { read_xml(x) %>%
        xml_find_all( ".//kwd") %>%
        xml_text(trim=T) })

Thank you,
Maicel Monzon MD, PHD


----------------------------------------------------------------




--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From ulrik.stervbo at gmail.com  Fri Jan  6 17:25:22 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 06 Jan 2017 16:25:22 +0000
Subject: [R] purrr::map and xml2:: read_xml
In-Reply-To: <20170106110455.66283tor8r9lz8rr@webmail.sld.cu>
References: <20170106110455.66283tor8r9lz8rr@webmail.sld.cu>
Message-ID: <CAKVAULPkPWKOD_GV4iWhYU=bBneWB=tJq39JpWxYW5RYfj_i4Q@mail.gmail.com>

Hi Maicel,

I'm guessing that B works on 50 files, and that A fails because there is no
function called 'read_xmlmap'. If the function that you map work well,
removing 'dplyr::sample_n(50)' from 'B' should solve the problem.

If that is not the case, we need a bit more information.

HTH
Ulrik

On Fri, 6 Jan 2017 at 17:08 <maicel at infomed.sld.cu> wrote:

> Hi List, I am trying to extract the key words from 1403 papers in xml
> format. I programmed such codes but they do not work but they only do
> with the modification showed below. But that variation is not the one
> I need because the 1403 xml files do not match to those in my folder.
> Could you please tell me where are the mistakes in the codes list (A
> or B) to help me to correct them? The data frame columns are an id and
> the paths.
>
> A-Does not work, but it is the one I need.
>
> keyword <-
>    muestra %>%
>    select(path) %>%
>    read_xmlmap(.f = function(x) { read_xml(x) %>%
>         xml_find_all( ".//kwd") %>%
>         xml_text(trim=T) })
>
> B-It works but only with a small number of papers.
>
> keyword <-
>    muestra %>%
>    select(path) %>%
>     dplyr::sample_n(50) %>%
>     unlist() %>%
>    map(.f = function(x) { read_xml(x) %>%
>         xml_find_all( ".//kwd") %>%
>         xml_text(trim=T) })
>
> Thank you,
> Maicel Monzon MD, PHD
>
>
> ----------------------------------------------------------------
>
>
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que
> ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema
> Nacional de Salud. La persona que envia este correo asume el compromiso de
> usar el servicio a tales fines y cumplir con las regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jacobwegelin at fastmail.fm  Fri Jan  6 18:03:39 2017
From: jacobwegelin at fastmail.fm (Jacob Wegelin)
Date: Fri, 6 Jan 2017 12:03:39 -0500
Subject: [R] extract minimal variables from model
Message-ID: <alpine.OSX.2.20.1611201539390.39990@qqt.local>

Given any regression model, created for instance by lm, lme, lmer, or rqs, such as

z1<-lm(weight~poly(Time,2), data=ChickWeight)

I would like a general way to obtain only those variables used for the model.  In the current example, this "minimal data frame" would consist of the "weight" and "Time" variables and none of the other columns of ChickWeight.

(Motivation: Sometimes the data frame contains thousands of variables which are not used in the current regression, and I do not want to keep copying and propagating them.)

The "model" component of the regression object doesn't serve this purpose:

> head(z1$model)
   weight poly(Time, 2).1 poly(Time, 2).2
1     42    -0.066020938     0.072002235
2     51    -0.053701293     0.031099018
3     59    -0.041381647    -0.001334588
4     64    -0.029062001    -0.025298582
5     76    -0.016742356    -0.040792965
6     93    -0.004422710    -0.047817737

The following awkward workaround seems to do it when variable names contain only "word characters" as defined by regex:

minimalvariablesfrommodel20161120 <-function(object, originaldata){
# 
stopifnot(!missing(originaldata))
stopifnot(!missing(object))
intersect(
 	unique(unlist(strsplit(format(object$call$formula), split="\\W", perl=TRUE)))
 	, names(originaldata)
 	)
}

> minimalvariablesfrommodel20161120(z1, ChickWeight)
[1] "weight" "Time" 
>

But if a variable has a space in its name, my workaround fails:

> ChickWeight$"dog tail"<-ChickWeight$Time
> z1<-lm(weight~poly(`dog tail`,2), data=ChickWeight)
> head(z1$model)
   weight poly(`dog tail`, 2).1 poly(`dog tail`, 2).2
1     42          -0.066020938           0.072002235
2     51          -0.053701293           0.031099018
3     59          -0.041381647          -0.001334588
4     64          -0.029062001          -0.025298582
5     76          -0.016742356          -0.040792965
6     93          -0.004422710          -0.047817737
> minimalvariablesfrommodel20161120(z1, ChickWeight)
[1] "weight"
>

Is there a more elegant, and hence more reliable, approach?

Thanks

Jacob A. Wegelin
Assistant Professor
C. Kenneth and Dianne Wright Center for Clinical and Translational Research
Department of Biostatistics
Virginia Commonwealth University
830 E. Main St., Seventh Floor
P. O. Box 980032
Richmond VA 23298-0032
U.S.A. 
URL: http://www.people.vcu.edu/~jwegelin


From marc_schwartz at me.com  Fri Jan  6 18:17:36 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 6 Jan 2017 11:17:36 -0600
Subject: [R] extract minimal variables from model
In-Reply-To: <alpine.OSX.2.20.1611201539390.39990@qqt.local>
References: <alpine.OSX.2.20.1611201539390.39990@qqt.local>
Message-ID: <1AD4E52B-8FAF-41AE-9D85-76F39A37912F@me.com>


> On Jan 6, 2017, at 11:03 AM, Jacob Wegelin <jacobwegelin at fastmail.fm> wrote:
> 
> Given any regression model, created for instance by lm, lme, lmer, or rqs, such as
> 
> z1<-lm(weight~poly(Time,2), data=ChickWeight)
> 
> I would like a general way to obtain only those variables used for the model.  In the current example, this "minimal data frame" would consist of the "weight" and "Time" variables and none of the other columns of ChickWeight.
> 
> (Motivation: Sometimes the data frame contains thousands of variables which are not used in the current regression, and I do not want to keep copying and propagating them.)
> 
> The "model" component of the regression object doesn't serve this purpose:
> 
>> head(z1$model)
>  weight poly(Time, 2).1 poly(Time, 2).2
> 1     42    -0.066020938     0.072002235
> 2     51    -0.053701293     0.031099018
> 3     59    -0.041381647    -0.001334588
> 4     64    -0.029062001    -0.025298582
> 5     76    -0.016742356    -0.040792965
> 6     93    -0.004422710    -0.047817737
> 
> The following awkward workaround seems to do it when variable names contain only "word characters" as defined by regex:
> 
> minimalvariablesfrommodel20161120 <-function(object, originaldata){
> # stopifnot(!missing(originaldata))
> stopifnot(!missing(object))
> intersect(
> 	unique(unlist(strsplit(format(object$call$formula), split="\\W", perl=TRUE)))
> 	, names(originaldata)
> 	)
> }
> 
>> minimalvariablesfrommodel20161120(z1, ChickWeight)
> [1] "weight" "Time" 
>> 
> 
> But if a variable has a space in its name, my workaround fails:
> 
>> ChickWeight$"dog tail"<-ChickWeight$Time
>> z1<-lm(weight~poly(`dog tail`,2), data=ChickWeight)
>> head(z1$model)
>  weight poly(`dog tail`, 2).1 poly(`dog tail`, 2).2
> 1     42          -0.066020938           0.072002235
> 2     51          -0.053701293           0.031099018
> 3     59          -0.041381647          -0.001334588
> 4     64          -0.029062001          -0.025298582
> 5     76          -0.016742356          -0.040792965
> 6     93          -0.004422710          -0.047817737
>> minimalvariablesfrommodel20161120(z1, ChickWeight)
> [1] "weight"
>> 
> 
> Is there a more elegant, and hence more reliable, approach?
> 
> Thanks
> 
> Jacob A. Wegelin


Jacob,

In general, if you have a model object 'm', you can use the following syntax:

  all.vars(terms(m))

See ?terms and ?all.vars, the latter also includes all.names().

Regards,

Marc Schwartz


From chocold12 at gmail.com  Fri Jan  6 19:00:30 2017
From: chocold12 at gmail.com (lily li)
Date: Fri, 6 Jan 2017 11:00:30 -0700
Subject: [R] About populating a dataframe in a loop
Message-ID: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>

Hi R users,

I have a question about filling a dataframe in R using a for loop.

I created an empty dataframe first and then filled it, using the code:
pre.mat = data.frame()
for(i in 1:10){
    mat.temp = data.frame(some values filled in)
    pre.mat = rbind(pre.mat, mat.temp)
}
However, the resulted dataframe has not all the rows that I desired for.
What is the problem and how to solve it? Thanks.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Fri Jan  6 19:00:59 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 6 Jan 2017 13:00:59 -0500
Subject: [R] Problem with IRkernel Installation Solved - Instructions on
 how to Solve it
In-Reply-To: <CAMOcQfMNyxFK9fo6-7tOP4sTHpBAwOn0A5_2p0p0BQpBG4Gp2w@mail.gmail.com>
References: <CAMOcQfMNyxFK9fo6-7tOP4sTHpBAwOn0A5_2p0p0BQpBG4Gp2w@mail.gmail.com>
Message-ID: <CA+vqiLF5TLpeOj0JzfOxSPh-4iNjGqCvaK0dSm-F+7DgXsMn4Q@mail.gmail.com>

On Fri, Jan 6, 2017 at 8:43 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Dear friends,
>
> Great news! I was able to install the IRkernel successfully and I am now
> able to create R notebooks in Jupyter.

Congratulations.

 Just in case anybody out there is
> struggling with this too, here is what I did (I have Windows 8, but it will
> probably work for Mac OS X as well):
>
> 1-Go to the page https://irkernel.github.io/installation
> 2-Open the R console (I have R version 3.3.2)
> 3-Go to the step where it says "Installing via supplied binary packages
> (default on Windows + Mac OS X)
> 4-Instead of installing all the packages using one single command as
> suggested in the installation instructions, go to the R console and install
> all of the packages one by one, as follows
>  >install.packages('repr')
>  >install.packages('IRdisplay')
>  >install.packages('evaluate')
>  >install.packages('crayon')
>  >install.packages('pbdZMQ')
>  >install.packages('devtools')
>  >install.packages('uuid')
>  >install.packages('digest')

This can hardly make any difference.

install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon',
'pbdZMQ', 'devtools', 'uuid', 'digest'))

is fine.

> 5-Connect to a CRAN mirror and select install packages, look for the
> package githubinstall and clic on it to install it

Why?

> 6-Start loading each one of the packages installed like this:
>  >library("repr")
>  >library("IRdisplay")
>  >library("evaluate")
>  >library("crayon")
>  >library("pbdZMQ")
>  >library("devtools")
>  >library("uuid")
>  >library("digest")
>  >library("githubinstall")

Attaching all these packages is not needed. The githubinstall package
is not needed at all.

> 7-After this you have to update jsonlite which is a dependencie of package
> githubinstall, you update jsonlite using the following command:
>  >update.packages('jsonlite')'

Also not needed, as githubinstall is not needed.

> 8-After this, you have to type the following commands:
>  >library(httr)
>  >set_config(use_proxy(url="the required IP", port=8080, username="your
> network user", password="the password you use to unlock your computer"))
>  >#you can get the required IP going to the command prompt and using the
> command ping
>  >#port has to be 8080

Maybe something like this is needed if you are behind a firewall, I
don't know. But none of that is generally needed.

> 9-type use the command:
>  >devtools::install_github('IRkernel/IRkernel')
> 10-Last but not least, type the following command:
>  >IRkernel::installspec()
>
> If you follow this instructions you should be able to install the IRkernel
> successfully and start writing R notebooks in Jupyter.
>
> Hope this helps,

I suspect it will confuse more than help unfortunately.

Best,
Ista

>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Fri Jan  6 19:12:15 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 06 Jan 2017 18:12:15 +0000
Subject: [R] About populating a dataframe in a loop
In-Reply-To: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
References: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
Message-ID: <586FDDFF.3000109@sapo.pt>

Hello,

Works with me:

set.seed(6574)

pre.mat = data.frame()
for(i in 1:10){
     mat.temp = data.frame(x = rnorm(5), A = sample(LETTERS, 5, TRUE))
     pre.mat = rbind(pre.mat, mat.temp)
}

nrow(pre.mat)  # should be 50


Can you give us an example that doesn't work?

Rui Barradas

Em 06-01-2017 18:00, lily li escreveu:
> Hi R users,
>
> I have a question about filling a dataframe in R using a for loop.
>
> I created an empty dataframe first and then filled it, using the code:
> pre.mat = data.frame()
> for(i in 1:10){
>      mat.temp = data.frame(some values filled in)
>      pre.mat = rbind(pre.mat, mat.temp)
> }
> However, the resulted dataframe has not all the rows that I desired for.
> What is the problem and how to solve it? Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From paulbernal07 at gmail.com  Fri Jan  6 20:11:16 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 6 Jan 2017 14:11:16 -0500
Subject: [R] Problem with IRkernel Installation Solved - Instructions on
 how to Solve it
In-Reply-To: <CA+vqiLF5TLpeOj0JzfOxSPh-4iNjGqCvaK0dSm-F+7DgXsMn4Q@mail.gmail.com>
References: <CAMOcQfMNyxFK9fo6-7tOP4sTHpBAwOn0A5_2p0p0BQpBG4Gp2w@mail.gmail.com>
	<CA+vqiLF5TLpeOj0JzfOxSPh-4iNjGqCvaK0dSm-F+7DgXsMn4Q@mail.gmail.com>
Message-ID: <CAMOcQfPAUzEto-OfNZh8mtzLtfWSxUir5rEsmnKYZL78TkBcQA@mail.gmail.com>

Ista,

If you do not appreciate it or do not find it useful, just discard the
message. I tried several things and this is what worked for me. If you have
another solution or a better solution let me know.

Regards,

Paul

2017-01-06 13:00 GMT-05:00 Ista Zahn <istazahn at gmail.com>:

> On Fri, Jan 6, 2017 at 8:43 AM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> > Dear friends,
> >
> > Great news! I was able to install the IRkernel successfully and I am now
> > able to create R notebooks in Jupyter.
>
> Congratulations.
>
>  Just in case anybody out there is
> > struggling with this too, here is what I did (I have Windows 8, but it
> will
> > probably work for Mac OS X as well):
> >
> > 1-Go to the page https://irkernel.github.io/installation
> > 2-Open the R console (I have R version 3.3.2)
> > 3-Go to the step where it says "Installing via supplied binary packages
> > (default on Windows + Mac OS X)
> > 4-Instead of installing all the packages using one single command as
> > suggested in the installation instructions, go to the R console and
> install
> > all of the packages one by one, as follows
> >  >install.packages('repr')
> >  >install.packages('IRdisplay')
> >  >install.packages('evaluate')
> >  >install.packages('crayon')
> >  >install.packages('pbdZMQ')
> >  >install.packages('devtools')
> >  >install.packages('uuid')
> >  >install.packages('digest')
>
> This can hardly make any difference.
>
> install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon',
> 'pbdZMQ', 'devtools', 'uuid', 'digest'))
>
> is fine.
>
> > 5-Connect to a CRAN mirror and select install packages, look for the
> > package githubinstall and clic on it to install it
>
> Why?
>
> > 6-Start loading each one of the packages installed like this:
> >  >library("repr")
> >  >library("IRdisplay")
> >  >library("evaluate")
> >  >library("crayon")
> >  >library("pbdZMQ")
> >  >library("devtools")
> >  >library("uuid")
> >  >library("digest")
> >  >library("githubinstall")
>
> Attaching all these packages is not needed. The githubinstall package
> is not needed at all.
>
> > 7-After this you have to update jsonlite which is a dependencie of
> package
> > githubinstall, you update jsonlite using the following command:
> >  >update.packages('jsonlite')'
>
> Also not needed, as githubinstall is not needed.
>
> > 8-After this, you have to type the following commands:
> >  >library(httr)
> >  >set_config(use_proxy(url="the required IP", port=8080, username="your
> > network user", password="the password you use to unlock your computer"))
> >  >#you can get the required IP going to the command prompt and using the
> > command ping
> >  >#port has to be 8080
>
> Maybe something like this is needed if you are behind a firewall, I
> don't know. But none of that is generally needed.
>
> > 9-type use the command:
> >  >devtools::install_github('IRkernel/IRkernel')
> > 10-Last but not least, type the following command:
> >  >IRkernel::installspec()
> >
> > If you follow this instructions you should be able to install the
> IRkernel
> > successfully and start writing R notebooks in Jupyter.
> >
> > Hope this helps,
>
> I suspect it will confuse more than help unfortunately.
>
> Best,
> Ista
>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Fri Jan  6 22:28:45 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 6 Jan 2017 16:28:45 -0500
Subject: [R] Problem with IRkernel Installation Solved - Instructions on
 how to Solve it
In-Reply-To: <CAMOcQfPAUzEto-OfNZh8mtzLtfWSxUir5rEsmnKYZL78TkBcQA@mail.gmail.com>
References: <CAMOcQfMNyxFK9fo6-7tOP4sTHpBAwOn0A5_2p0p0BQpBG4Gp2w@mail.gmail.com>
	<CA+vqiLF5TLpeOj0JzfOxSPh-4iNjGqCvaK0dSm-F+7DgXsMn4Q@mail.gmail.com>
	<CAMOcQfPAUzEto-OfNZh8mtzLtfWSxUir5rEsmnKYZL78TkBcQA@mail.gmail.com>
Message-ID: <CA+vqiLGjbzi16QQhb_JpOwR=Nu-4ihKDhsPzfZ=zv5CkVjAd6w@mail.gmail.com>

On Jan 6, 2017 2:11 PM, "Paul Bernal" <paulbernal07 at gmail.com> wrote:

Ista,

If you do not appreciate it or do not find it useful, just discard the
message.

It's not about me. My concern is for the people you potentially send on a
wild goose chase when all they really need to do is follow the IRkernel
documentation.

I tried several things and this is what worked for me. If you have another
solution or a better solution let me know.


A better solution is to follow the IRkernel installation instructions. If
it doesn't work ask for help by describing exactly what you did and exactly
what happened.

Best,
Ista


Regards,

Paul

2017-01-06 13:00 GMT-05:00 Ista Zahn <istazahn at gmail.com>:

> On Fri, Jan 6, 2017 at 8:43 AM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> > Dear friends,
> >
> > Great news! I was able to install the IRkernel successfully and I am now
> > able to create R notebooks in Jupyter.
>
> Congratulations.
>
>  Just in case anybody out there is
> > struggling with this too, here is what I did (I have Windows 8, but it
> will
> > probably work for Mac OS X as well):
> >
> > 1-Go to the page https://irkernel.github.io/installation
> > 2-Open the R console (I have R version 3.3.2)
> > 3-Go to the step where it says "Installing via supplied binary packages
> > (default on Windows + Mac OS X)
> > 4-Instead of installing all the packages using one single command as
> > suggested in the installation instructions, go to the R console and
> install
> > all of the packages one by one, as follows
> >  >install.packages('repr')
> >  >install.packages('IRdisplay')
> >  >install.packages('evaluate')
> >  >install.packages('crayon')
> >  >install.packages('pbdZMQ')
> >  >install.packages('devtools')
> >  >install.packages('uuid')
> >  >install.packages('digest')
>
> This can hardly make any difference.
>
> install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon',
> 'pbdZMQ', 'devtools', 'uuid', 'digest'))
>
> is fine.
>
> > 5-Connect to a CRAN mirror and select install packages, look for the
> > package githubinstall and clic on it to install it
>
> Why?
>
> > 6-Start loading each one of the packages installed like this:
> >  >library("repr")
> >  >library("IRdisplay")
> >  >library("evaluate")
> >  >library("crayon")
> >  >library("pbdZMQ")
> >  >library("devtools")
> >  >library("uuid")
> >  >library("digest")
> >  >library("githubinstall")
>
> Attaching all these packages is not needed. The githubinstall package
> is not needed at all.
>
> > 7-After this you have to update jsonlite which is a dependencie of
> package
> > githubinstall, you update jsonlite using the following command:
> >  >update.packages('jsonlite')'
>
> Also not needed, as githubinstall is not needed.
>
> > 8-After this, you have to type the following commands:
> >  >library(httr)
> >  >set_config(use_proxy(url="the required IP", port=8080, username="your
> > network user", password="the password you use to unlock your computer"))
> >  >#you can get the required IP going to the command prompt and using the
> > command ping
> >  >#port has to be 8080
>
> Maybe something like this is needed if you are behind a firewall, I
> don't know. But none of that is generally needed.
>
> > 9-type use the command:
> >  >devtools::install_github('IRkernel/IRkernel')
> > 10-Last but not least, type the following command:
> >  >IRkernel::installspec()
> >
> > If you follow this instructions you should be able to install the
> IRkernel
> > successfully and start writing R notebooks in Jupyter.
> >
> > Hope this helps,
>
> I suspect it will confuse more than help unfortunately.
>
> Best,
> Ista
>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Sat Jan  7 05:46:57 2017
From: chocold12 at gmail.com (lily li)
Date: Fri, 6 Jan 2017 21:46:57 -0700
Subject: [R] About populating a dataframe in a loop
In-Reply-To: <586FDDFF.3000109@sapo.pt>
References: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
	<586FDDFF.3000109@sapo.pt>
Message-ID: <CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>

Hi Rui,

Thanks for your reply. Yes, when I tried to rbind two dataframes, it works.
However, if there are more than 50, it got stuck for hours. When I tried to
terminate the process and open the csv file separately, it has only one
data frame. What is the problem? Thanks.


On Fri, Jan 6, 2017 at 11:12 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Works with me:
>
> set.seed(6574)
>
> pre.mat = data.frame()
> for(i in 1:10){
>     mat.temp = data.frame(x = rnorm(5), A = sample(LETTERS, 5, TRUE))
>     pre.mat = rbind(pre.mat, mat.temp)
> }
>
> nrow(pre.mat)  # should be 50
>
>
> Can you give us an example that doesn't work?
>
> Rui Barradas
>
>
> Em 06-01-2017 18:00, lily li escreveu:
>
>> Hi R users,
>>
>> I have a question about filling a dataframe in R using a for loop.
>>
>> I created an empty dataframe first and then filled it, using the code:
>> pre.mat = data.frame()
>> for(i in 1:10){
>>      mat.temp = data.frame(some values filled in)
>>      pre.mat = rbind(pre.mat, mat.temp)
>> }
>> However, the resulted dataframe has not all the rows that I desired for.
>> What is the problem and how to solve it? Thanks.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Sat Jan  7 06:07:05 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 7 Jan 2017 00:07:05 -0500
Subject: [R] About populating a dataframe in a loop
In-Reply-To: <CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>
References: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
	<586FDDFF.3000109@sapo.pt>
	<CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>
Message-ID: <CAGx1TMBQ72-UzJwASg+LVAd7ExZjpota6NFe=pBDYBkMpdgKjg@mail.gmail.com>

Incrementally increasing the size of an array is not efficient in R.
The recommended technique is to allocate as much space as you will
need, and then fill it.

> system.time({tmp <- 1:5 ; for (i in 1:1000) tmp <- rbind(tmp, 1:5)})
   user  system elapsed
  0.011   0.000   0.011
> dim(tmp)
[1] 1001    5
> system.time({tmp <- matrix(NA, 1001, 5); for (i in 1:1001) tmp[i,] <- 1:5})
   user  system elapsed
  0.001   0.000   0.001
> dim(tmp)
[1] 1001    5

On Fri, Jan 6, 2017 at 11:46 PM, lily li <chocold12 at gmail.com> wrote:
> Hi Rui,
>
> Thanks for your reply. Yes, when I tried to rbind two dataframes, it works.
> However, if there are more than 50, it got stuck for hours. When I tried to
> terminate the process and open the csv file separately, it has only one
> data frame. What is the problem? Thanks.
>
>
> On Fri, Jan 6, 2017 at 11:12 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Works with me:
>>
>> set.seed(6574)
>>
>> pre.mat = data.frame()
>> for(i in 1:10){
>>     mat.temp = data.frame(x = rnorm(5), A = sample(LETTERS, 5, TRUE))
>>     pre.mat = rbind(pre.mat, mat.temp)
>> }
>>
>> nrow(pre.mat)  # should be 50
>>
>>
>> Can you give us an example that doesn't work?
>>
>> Rui Barradas
>>
>>
>> Em 06-01-2017 18:00, lily li escreveu:
>>
>>> Hi R users,
>>>
>>> I have a question about filling a dataframe in R using a for loop.
>>>
>>> I created an empty dataframe first and then filled it, using the code:
>>> pre.mat = data.frame()
>>> for(i in 1:10){
>>>      mat.temp = data.frame(some values filled in)
>>>      pre.mat = rbind(pre.mat, mat.temp)
>>> }
>>> However, the resulted dataframe has not all the rows that I desired for.
>>> What is the problem and how to solve it? Thanks.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roundsjeremiah at gmail.com  Sat Jan  7 06:24:38 2017
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Fri, 6 Jan 2017 21:24:38 -0800
Subject: [R] About populating a dataframe in a loop
In-Reply-To: <CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>
References: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
	<586FDDFF.3000109@sapo.pt>
	<CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>
Message-ID: <CAOjnRsYYvEfTt5i2LvVZDHdoaekN-rVddnbn2RTLxQLORB_TsA@mail.gmail.com>

As a rule never rbind in a loop. It has O(n^2) run time because the rbind
itself can be O(n) (where n is the number of data.frames).  Instead either
put them all into a list with lapply or vector("list", length=) and then
datatable::rbindlist, do.call(rbind, thelist) or use the equivalent from
dplyr.  All of which will be much more efficient.



On Fri, Jan 6, 2017 at 8:46 PM, lily li <chocold12 at gmail.com> wrote:

> Hi Rui,
>
> Thanks for your reply. Yes, when I tried to rbind two dataframes, it works.
> However, if there are more than 50, it got stuck for hours. When I tried to
> terminate the process and open the csv file separately, it has only one
> data frame. What is the problem? Thanks.
>
>
> On Fri, Jan 6, 2017 at 11:12 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>
> > Hello,
> >
> > Works with me:
> >
> > set.seed(6574)
> >
> > pre.mat = data.frame()
> > for(i in 1:10){
> >     mat.temp = data.frame(x = rnorm(5), A = sample(LETTERS, 5, TRUE))
> >     pre.mat = rbind(pre.mat, mat.temp)
> > }
> >
> > nrow(pre.mat)  # should be 50
> >
> >
> > Can you give us an example that doesn't work?
> >
> > Rui Barradas
> >
> >
> > Em 06-01-2017 18:00, lily li escreveu:
> >
> >> Hi R users,
> >>
> >> I have a question about filling a dataframe in R using a for loop.
> >>
> >> I created an empty dataframe first and then filled it, using the code:
> >> pre.mat = data.frame()
> >> for(i in 1:10){
> >>      mat.temp = data.frame(some values filled in)
> >>      pre.mat = rbind(pre.mat, mat.temp)
> >> }
> >> However, the resulted dataframe has not all the rows that I desired for.
> >> What is the problem and how to solve it? Thanks.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Sat Jan  7 07:51:16 2017
From: chocold12 at gmail.com (lily li)
Date: Fri, 6 Jan 2017 23:51:16 -0700
Subject: [R] About populating a dataframe in a loop
In-Reply-To: <CAGx1TMBQ72-UzJwASg+LVAd7ExZjpota6NFe=pBDYBkMpdgKjg@mail.gmail.com>
References: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
	<586FDDFF.3000109@sapo.pt>
	<CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>
	<CAGx1TMBQ72-UzJwASg+LVAd7ExZjpota6NFe=pBDYBkMpdgKjg@mail.gmail.com>
Message-ID: <CAN5afy_PnSOtwAUy5v+gJQJVaR_DFam3NGD2SSEgpE=F4TLRfA@mail.gmail.com>

Thanks, Richard. But if the data cannot fill the constructed data frame,
will there be NA values?


On Fri, Jan 6, 2017 at 10:07 PM, Richard M. Heiberger <rmh at temple.edu>
wrote:

> Incrementally increasing the size of an array is not efficient in R.
> The recommended technique is to allocate as much space as you will
> need, and then fill it.
>
> > system.time({tmp <- 1:5 ; for (i in 1:1000) tmp <- rbind(tmp, 1:5)})
>    user  system elapsed
>   0.011   0.000   0.011
> > dim(tmp)
> [1] 1001    5
> > system.time({tmp <- matrix(NA, 1001, 5); for (i in 1:1001) tmp[i,] <-
> 1:5})
>    user  system elapsed
>   0.001   0.000   0.001
> > dim(tmp)
> [1] 1001    5
>
> On Fri, Jan 6, 2017 at 11:46 PM, lily li <chocold12 at gmail.com> wrote:
> > Hi Rui,
> >
> > Thanks for your reply. Yes, when I tried to rbind two dataframes, it
> works.
> > However, if there are more than 50, it got stuck for hours. When I tried
> to
> > terminate the process and open the csv file separately, it has only one
> > data frame. What is the problem? Thanks.
> >
> >
> > On Fri, Jan 6, 2017 at 11:12 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> Hello,
> >>
> >> Works with me:
> >>
> >> set.seed(6574)
> >>
> >> pre.mat = data.frame()
> >> for(i in 1:10){
> >>     mat.temp = data.frame(x = rnorm(5), A = sample(LETTERS, 5, TRUE))
> >>     pre.mat = rbind(pre.mat, mat.temp)
> >> }
> >>
> >> nrow(pre.mat)  # should be 50
> >>
> >>
> >> Can you give us an example that doesn't work?
> >>
> >> Rui Barradas
> >>
> >>
> >> Em 06-01-2017 18:00, lily li escreveu:
> >>
> >>> Hi R users,
> >>>
> >>> I have a question about filling a dataframe in R using a for loop.
> >>>
> >>> I created an empty dataframe first and then filled it, using the code:
> >>> pre.mat = data.frame()
> >>> for(i in 1:10){
> >>>      mat.temp = data.frame(some values filled in)
> >>>      pre.mat = rbind(pre.mat, mat.temp)
> >>> }
> >>> However, the resulted dataframe has not all the rows that I desired
> for.
> >>> What is the problem and how to solve it? Thanks.
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sjung at sonnet.ucla.edu  Fri Jan  6 22:31:26 2017
From: sjung at sonnet.ucla.edu (Jung, Su Yon)
Date: Fri, 6 Jan 2017 21:31:26 +0000
Subject: [R] What is c1 file and how to open it (.c1) in R program?
Message-ID: <SN2PR04MB2287B5544A11AF317E2175CAFD630@SN2PR04MB2287.namprd04.prod.outlook.com>

Hello,

I have a set of genetic data in .c1 file.
I plan to analyze using R.
However, I am not sure how to open the c1 file in R program (what is the command?) in order to look at the data?

Please, help.

Thank you.


Su Yon Jung, PhD, MPH
Assistant Professor for Translational Sciences Section
Jonsson Comprehensive Cancer Center
UCLA School of Nursing
700 Tiverton Ave, Factor Bldg #3-264
Los Angeles, CA 90095
Phone: (310) 825-2840
Fax: (310) 267-0413
E-mail: sjung at sonnet.ucla.edu<mailto:sjung at sonnet.ucla.edu>; suyonj at ucla.edu


	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sat Jan  7 10:31:00 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 7 Jan 2017 04:31:00 -0500
Subject: [R] if i paste this into my windows 3.3.2 R console, it crashes
Message-ID: <CAOwvMDydcHZe=GozzN0Z9Nk9UHpp_rLM1kDw2L+Zy-JhvSoMWw@mail.gmail.com>

hi, should i file this on https://bugs.r-project.org/  ?  thanks



# crash R with this command
dir.create( "C:/My Directory/PEW/Hispanic Trends/2015/2013 Recontact Survey
of Asian Ame
ricans              Field dates: 10/16/13 - 10/31/13 Respondents:
Nationally-rep
resentative sample of 802 Asian Americans ages 18 and older. Margin of
Error: +/
- 5.0 percentage points at the 95% confidence interval. This survey focused
on p
olitics, attitudes regarding immigration legislation, illegal immigration,
and n
aturalization./"  , recursive = TRUE , showWarnings = FALSE )



> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Jan  7 11:51:51 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 7 Jan 2017 21:51:51 +1100
Subject: [R] if i paste this into my windows 3.3.2 R console, it crashes
In-Reply-To: <CAOwvMDydcHZe=GozzN0Z9Nk9UHpp_rLM1kDw2L+Zy-JhvSoMWw@mail.gmail.com>
References: <CAOwvMDydcHZe=GozzN0Z9Nk9UHpp_rLM1kDw2L+Zy-JhvSoMWw@mail.gmail.com>
Message-ID: <CA+8X3fWxFn8+UriH3NTF4qtVHH_0G7=RRTBffqczJumBJPn=1Q@mail.gmail.com>

Hi Anthony,
I think you have included most of the forbidden characters in Windows
folder names and while I am too lazy to count the characters, you may
have exceeded the 259 character limit as well. Are there really
embedded EOLs as well? This is truly a masterpiece of computer
disobedience.

Jim


On Sat, Jan 7, 2017 at 8:31 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> hi, should i file this on https://bugs.r-project.org/  ?  thanks
>
>
>
> # crash R with this command
> dir.create( "C:/My Directory/PEW/Hispanic Trends/2015/2013 Recontact Survey
> of Asian Ame
> ricans              Field dates: 10/16/13 - 10/31/13 Respondents:
> Nationally-rep
> resentative sample of 802 Asian Americans ages 18 and older. Margin of
> Error: +/
> - 5.0 percentage points at the 95% confidence interval. This survey focused
> on p
> olitics, attitudes regarding immigration legislation, illegal immigration,
> and n
> aturalization./"  , recursive = TRUE , showWarnings = FALSE )
>
>
>
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Sat Jan  7 12:03:04 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 7 Jan 2017 06:03:04 -0500
Subject: [R] if i paste this into my windows 3.3.2 R console, it crashes
In-Reply-To: <CA+8X3fWxFn8+UriH3NTF4qtVHH_0G7=RRTBffqczJumBJPn=1Q@mail.gmail.com>
References: <CAOwvMDydcHZe=GozzN0Z9Nk9UHpp_rLM1kDw2L+Zy-JhvSoMWw@mail.gmail.com>
	<CA+8X3fWxFn8+UriH3NTF4qtVHH_0G7=RRTBffqczJumBJPn=1Q@mail.gmail.com>
Message-ID: <CAOwvMDwkdcdS9t4muyMqd-TYQZStxrQWhGKpNhj1QEKxDN2L=g@mail.gmail.com>

haha no doubt.  just want to confirm this counts as a reportable bug (
https://www.r-project.org/bugs.html) before bothering r-core




On Sat, Jan 7, 2017 at 5:51 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Anthony,
> I think you have included most of the forbidden characters in Windows
> folder names and while I am too lazy to count the characters, you may
> have exceeded the 259 character limit as well. Are there really
> embedded EOLs as well? This is truly a masterpiece of computer
> disobedience.
>
> Jim
>
>
> On Sat, Jan 7, 2017 at 8:31 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> > hi, should i file this on https://bugs.r-project.org/  ?  thanks
> >
> >
> >
> > # crash R with this command
> > dir.create( "C:/My Directory/PEW/Hispanic Trends/2015/2013 Recontact
> Survey
> > of Asian Ame
> > ricans              Field dates: 10/16/13 - 10/31/13 Respondents:
> > Nationally-rep
> > resentative sample of 802 Asian Americans ages 18 and older. Margin of
> > Error: +/
> > - 5.0 percentage points at the 95% confidence interval. This survey
> focused
> > on p
> > olitics, attitudes regarding immigration legislation, illegal
> immigration,
> > and n
> > aturalization./"  , recursive = TRUE , showWarnings = FALSE )
> >
> >
> >
> >> sessionInfo()
> > R version 3.3.2 (2016-10-31)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 10 x64 (build 10586)
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Jan  7 13:34:18 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 7 Jan 2017 07:34:18 -0500
Subject: [R] if i paste this into my windows 3.3.2 R console, it crashes
In-Reply-To: <CA+8X3fWxFn8+UriH3NTF4qtVHH_0G7=RRTBffqczJumBJPn=1Q@mail.gmail.com>
References: <CAOwvMDydcHZe=GozzN0Z9Nk9UHpp_rLM1kDw2L+Zy-JhvSoMWw@mail.gmail.com>
	<CA+8X3fWxFn8+UriH3NTF4qtVHH_0G7=RRTBffqczJumBJPn=1Q@mail.gmail.com>
Message-ID: <57e4f197-c1ac-5628-cfb1-66ff5b56a937@gmail.com>

On 07/01/2017 5:51 AM, Jim Lemon wrote:
> Hi Anthony,
> I think you have included most of the forbidden characters in Windows
> folder names and while I am too lazy to count the characters, you may
> have exceeded the 259 character limit as well. Are there really
> embedded EOLs as well? This is truly a masterpiece of computer
> disobedience.

I haven't looked closely to see what goes wrong, but the problems you 
list should lead to an error message, not a crash.  So yes, Anthony 
should report this as a bug.  Anthony, if you don't have a bug reporting 
account you won't be able to do so; write to me privately and I'll 
create one for you (with your choice of associated email address).

Duncan Murdoch

>
> Jim
>
>
> On Sat, Jan 7, 2017 at 8:31 PM, Anthony Damico <ajdamico at gmail.com> wrote:
>> hi, should i file this on https://bugs.r-project.org/  ?  thanks
>>
>>
>>
>> # crash R with this command
>> dir.create( "C:/My Directory/PEW/Hispanic Trends/2015/2013 Recontact Survey
>> of Asian Ame
>> ricans              Field dates: 10/16/13 - 10/31/13 Respondents:
>> Nationally-rep
>> resentative sample of 802 Asian Americans ages 18 and older. Margin of
>> Error: +/
>> - 5.0 percentage points at the 95% confidence interval. This survey focused
>> on p
>> olitics, attitudes regarding immigration legislation, illegal immigration,
>> and n
>> aturalization./"  , recursive = TRUE , showWarnings = FALSE )
>>
>>
>>
>>> sessionInfo()
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 10586)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ajdamico at gmail.com  Sat Jan  7 13:44:25 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 7 Jan 2017 07:44:25 -0500
Subject: [R] if i paste this into my windows 3.3.2 R console, it crashes
In-Reply-To: <57e4f197-c1ac-5628-cfb1-66ff5b56a937@gmail.com>
References: <CAOwvMDydcHZe=GozzN0Z9Nk9UHpp_rLM1kDw2L+Zy-JhvSoMWw@mail.gmail.com>
	<CA+8X3fWxFn8+UriH3NTF4qtVHH_0G7=RRTBffqczJumBJPn=1Q@mail.gmail.com>
	<57e4f197-c1ac-5628-cfb1-66ff5b56a937@gmail.com>
Message-ID: <CAOwvMDy0kWMpP6Ab=27Rra4vh4s0KwsOJN63zDDM6w7Y_ZLOfQ@mail.gmail.com>

thanks!  https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17206

On Sat, Jan 7, 2017 at 7:34 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 07/01/2017 5:51 AM, Jim Lemon wrote:
>
>> Hi Anthony,
>> I think you have included most of the forbidden characters in Windows
>> folder names and while I am too lazy to count the characters, you may
>> have exceeded the 259 character limit as well. Are there really
>> embedded EOLs as well? This is truly a masterpiece of computer
>> disobedience.
>>
>
> I haven't looked closely to see what goes wrong, but the problems you list
> should lead to an error message, not a crash.  So yes, Anthony should
> report this as a bug.  Anthony, if you don't have a bug reporting account
> you won't be able to do so; write to me privately and I'll create one for
> you (with your choice of associated email address).
>
> Duncan Murdoch
>
>
>
>> Jim
>>
>>
>> On Sat, Jan 7, 2017 at 8:31 PM, Anthony Damico <ajdamico at gmail.com>
>> wrote:
>>
>>> hi, should i file this on https://bugs.r-project.org/  ?  thanks
>>>
>>>
>>>
>>> # crash R with this command
>>> dir.create( "C:/My Directory/PEW/Hispanic Trends/2015/2013 Recontact
>>> Survey
>>> of Asian Ame
>>> ricans              Field dates: 10/16/13 - 10/31/13 Respondents:
>>> Nationally-rep
>>> resentative sample of 802 Asian Americans ages 18 and older. Margin of
>>> Error: +/
>>> - 5.0 percentage points at the 95% confidence interval. This survey
>>> focused
>>> on p
>>> olitics, attitudes regarding immigration legislation, illegal
>>> immigration,
>>> and n
>>> aturalization./"  , recursive = TRUE , showWarnings = FALSE )
>>>
>>>
>>>
>>> sessionInfo()
>>>>
>>> R version 3.3.2 (2016-10-31)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 10586)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Jan  7 15:28:21 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 07 Jan 2017 14:28:21 +0000
Subject: [R] What is c1 file and how to open it (.c1) in R program?
In-Reply-To: <SN2PR04MB2287B5544A11AF317E2175CAFD630@SN2PR04MB2287.namprd04.prod.outlook.com>
References: <SN2PR04MB2287B5544A11AF317E2175CAFD630@SN2PR04MB2287.namprd04.prod.outlook.com>
Message-ID: <5870FB05.9030600@sapo.pt>

Hello,

I believe you should google "c1 file extension". Apparently it has 
nothing to do with genetic data.

Hope this helps,

Rui Barradas

Em 06-01-2017 21:31, Jung, Su Yon escreveu:
> Hello,
>
> I have a set of genetic data in .c1 file.
> I plan to analyze using R.
> However, I am not sure how to open the c1 file in R program (what is the command?) in order to look at the data?
>
> Please, help.
>
> Thank you.
>
>
> Su Yon Jung, PhD, MPH
> Assistant Professor for Translational Sciences Section
> Jonsson Comprehensive Cancer Center
> UCLA School of Nursing
> 700 Tiverton Ave, Factor Bldg #3-264
> Los Angeles, CA 90095
> Phone: (310) 825-2840
> Fax: (310) 267-0413
> E-mail: sjung at sonnet.ucla.edu<mailto:sjung at sonnet.ucla.edu>; suyonj at ucla.edu
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Sat Jan  7 16:22:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 07 Jan 2017 07:22:52 -0800
Subject: [R] What is c1 file and how to open it (.c1) in R program?
In-Reply-To: <5870FB05.9030600@sapo.pt>
References: <SN2PR04MB2287B5544A11AF317E2175CAFD630@SN2PR04MB2287.namprd04.prod.outlook.com>
	<5870FB05.9030600@sapo.pt>
Message-ID: <FAB1CDD7-BF9C-4D2B-BCC2-E771886052C5@dcn.davis.ca.us>

There is no guarantee that a filename having a particular extension has any particular format inside it. You can make guesses and hope they are right, but the only dependable way to know what format is inside is to receive communication from the author about it or open it in a text or binary file viewer and compare what you see with the format documentation.

From a Bayesian perspective the information on the Internet about the file extension helps you narrow possibilities, but it still could be genetic data if the author had something else in mind when they named the file. In any event, without a sample of the data we cannot help, and if it really is genetic data then you would be better off asking this question in the bioconductor help forum and showing them the sample of data.
-- 
Sent from my phone. Please excuse my brevity.

On January 7, 2017 6:28:21 AM PST, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>I believe you should google "c1 file extension". Apparently it has 
>nothing to do with genetic data.
>
>Hope this helps,
>
>Rui Barradas
>
>Em 06-01-2017 21:31, Jung, Su Yon escreveu:
>> Hello,
>>
>> I have a set of genetic data in .c1 file.
>> I plan to analyze using R.
>> However, I am not sure how to open the c1 file in R program (what is
>the command?) in order to look at the data?
>>
>> Please, help.
>>
>> Thank you.
>>
>>
>> Su Yon Jung, PhD, MPH
>> Assistant Professor for Translational Sciences Section
>> Jonsson Comprehensive Cancer Center
>> UCLA School of Nursing
>> 700 Tiverton Ave, Factor Bldg #3-264
>> Los Angeles, CA 90095
>> Phone: (310) 825-2840
>> Fax: (310) 267-0413
>> E-mail: sjung at sonnet.ucla.edu<mailto:sjung at sonnet.ucla.edu>;
>suyonj at ucla.edu
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Sat Jan  7 18:15:37 2017
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 7 Jan 2017 12:15:37 -0500
Subject: [R] testing whether clusters in a PCA plot are significantly
 different from one another
In-Reply-To: <DB4PR06MB032C5A26C7F9186D0190FD3AF630@DB4PR06MB032.eurprd06.prod.outlook.com>
References: <DB4PR06MB032C5A26C7F9186D0190FD3AF630@DB4PR06MB032.eurprd06.prod.outlook.com>
Message-ID: <ec03be1d-2fd8-966f-bbeb-71e22e9bf9e5@yorku.ca>

Significance tests for group differences in a MANOVA of
lm(cbind(pc1, pc2) ~ group)

will get you what you want, but you are advised DON'T DO THIS, at least 
without a huge grain of salt and a slew of mea culpas.
Otherwise, you are committing p-value abuse and contributing to the 
notion that significance tests must be used to justify all conclusions.

The p-values will not be correct under standard normal theory of the
multivariate GLM because the pc1 and pc2 were chosen to optimize
the variance accounted for by their linear combinations and there
is no theory that can correct for this, AFAIK.  The cluster "group"
assignment was also chosen to optimize some (other) criterion.



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From dwinsemius at comcast.net  Sat Jan  7 19:27:17 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 7 Jan 2017 10:27:17 -0800
Subject: [R] What is c1 file and how to open it (.c1) in R program?
In-Reply-To: <FAB1CDD7-BF9C-4D2B-BCC2-E771886052C5@dcn.davis.ca.us>
References: <SN2PR04MB2287B5544A11AF317E2175CAFD630@SN2PR04MB2287.namprd04.prod.outlook.com>
	<5870FB05.9030600@sapo.pt>
	<FAB1CDD7-BF9C-4D2B-BCC2-E771886052C5@dcn.davis.ca.us>
Message-ID: <E151AAE6-7CFA-4150-9B67-2C107ECC19D2@comcast.net>


> On Jan 7, 2017, at 7:22 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> There is no guarantee that a filename having a particular extension has any particular format inside it. You can make guesses and hope they are right, but the only dependable way to know what format is inside is to receive communication from the author about it or open it in a text or binary file viewer and compare what you see with the format documentation.
> 
> From a Bayesian perspective the information on the Internet about the file extension helps you narrow possibilities, but it still could be genetic data if the author had something else in mind when they named the file.


That was a bit too long for a fortune nomination. Jeff, perhaps you can tighten it up a bit and resubmit?  I can observe that with my Bayesian wetware and Google, the highest posterior was for these files to be in the CEL format. However the best place to have posted this would have been on the Bioconductor support webpage.

Su Yon; When you do follow Jeff's sensible advice to post to the Bioc page at https://support.bioconductor.org/ be sure to follow the rest of his advice to offer more specifics, including a text representation of the first few lines or better details on the creator of these files.

( I tried a search on that website but '.c1' is just not narrow enough and adding "genetic" on  Bioconductor search string would have minimal narrowing consequences. )

-- 
David.


> In any event, without a sample of the data we cannot help, and if it really is genetic data then you would be better off asking this question in the bioconductor help forum and showing them the sample of data.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On January 7, 2017 6:28:21 AM PST, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>> 
>> I believe you should google "c1 file extension". Apparently it has 
>> nothing to do with genetic data.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 06-01-2017 21:31, Jung, Su Yon escreveu:
>>> Hello,
>>> 
>>> I have a set of genetic data in .c1 file.
>>> I plan to analyze using R.
>>> However, I am not sure how to open the c1 file in R program (what is
>> the command?) in order to look at the data?
>>> 
>>> Please, help.
>>> 
>>> Thank you.
>>> 
>>> 
>>> Su Yon Jung, PhD, MPH
>>> Assistant Professor for Translational Sciences Section
>>> Jonsson Comprehensive Cancer Center
>>> UCLA School of Nursing
>>> 700 Tiverton Ave, Factor Bldg #3-264
>>> Los Angeles, CA 90095
>>> Phone: (310) 825-2840
>>> Fax: (310) 267-0413
>>> E-mail: sjung at sonnet.ucla.edu<mailto:sjung at sonnet.ucla.edu>;
>> suyonj at ucla.edu
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ulrik.stervbo at gmail.com  Sat Jan  7 19:51:45 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 07 Jan 2017 18:51:45 +0000
Subject: [R] Error in doc_parse_file
In-Reply-To: <CANprgXvxVXj9LjgqKd3XD9+r7RtWWk2wPjNzri4iiF7FecVUzw@mail.gmail.com>
References: <CANprgXvxVXj9LjgqKd3XD9+r7RtWWk2wPjNzri4iiF7FecVUzw@mail.gmail.com>
Message-ID: <CAKVAULM=_13bjp32hvQw++TsJSSpDG=rCkdO5xVPpAar-uEOQg@mail.gmail.com>

Hi Maicel,

Please keep the list in CC.

I can't help with read_xml but perhaps someone on the list can.

Best,
Ulrik

On Fri, 6 Jan 2017, 19:03 Maicel Monzon, <maicel.monzon at gmail.com> wrote:

> Hi Ulrik,
>
>
>
> I meant 'read_xmlmap' was a bug. I did what you told me with all the set
> and the error message is:
>
>
>
>  ?Error in doc_parse_file(con, encoding = encoding, as_html = as_html,
> options = options) :    xmlParseEntityRef: no name [68]?
>
>
>
>
>
> keyword <-
>
>   muestra %>%
>
>   select(path) %>%  # I am attaching the all xml files..
>
>   unlist() %>%
>
>   map(.f = function(x) { read_xml(x) %>%
>
>        xml_find_all( ".//kwd") %>%
>
>        xml_text(trim=T) })
>
>
>
>
>
>
>
> I am attaching the xml files..
>
> Thank you
>
> Best regard
>
> Maicel
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Sat Jan  7 21:15:57 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Sat, 07 Jan 2017 20:15:57 +0000
Subject: [R] which parallel routine
Message-ID: <021cdb$5fm6gl@ironport10.mayo.edu>

I'm looking for advice on which of the parallel systems to use.

Context: maximize a likelihood, each evaluation is a sum over a large number of subjects (>5000) and each of those per subject terms is slow and complex.

If I were using optim the context would be
  fit <- optim(initial.values, myfun, ?.)
  myfun <- function(params) {
       ? Do some initial setup?
       temp <- apply-in-parallel(id,  per-subject-eval-fun, p=params)
       unlist(temp)
}

  The use of mcapply seems like there would be a lot of overhead starting and stopping threads.   But none of the tutorials I've found addresses this particular question.  Both direct answers and pointers to other docs would be welcome.

Terry T.



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jan  7 22:23:10 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 07 Jan 2017 13:23:10 -0800
Subject: [R] which parallel routine
In-Reply-To: <021cdb$5fm6gl@ironport10.mayo.edu>
References: <021cdb$5fm6gl@ironport10.mayo.edu>
Message-ID: <45F80186-5318-4A39-BF35-9FE0AFD66F6A@dcn.davis.ca.us>

There is always overhead in starting and stopping parallel processes, but the "per subject terms ... slow and complex" suggests to me that this is already a small price.

Mcapply tends to be good when you need to share a lot of the same data with all processes and have many processors with shared memory. Snow tends to be good when you really need lots of processors or lots of temporary memory and the common inputs are relatively small.

If you think the overhead is still hurting you, break your subjects into bigger groups to process in each pass. Try to avoid passing data into each process that you don't use to help reduce overhead. If you need more cores or processors and you don't have them, parallelizing won't help. Expecting the default parallel code in an algorithm-oriented library function to make these choices to fit your specific constraints is unreasonable. 
-- 
Sent from my phone. Please excuse my brevity.

On January 7, 2017 12:15:57 PM PST, "Therneau, Terry M., Ph.D." <therneau at mayo.edu> wrote:
>I'm looking for advice on which of the parallel systems to use.
>
>Context: maximize a likelihood, each evaluation is a sum over a large
>number of subjects (>5000) and each of those per subject terms is slow
>and complex.
>
>If I were using optim the context would be
>  fit <- optim(initial.values, myfun, ?.)
>  myfun <- function(params) {
>       ? Do some initial setup?
>       temp <- apply-in-parallel(id,  per-subject-eval-fun, p=params)
>       unlist(temp)
>}
>
>The use of mcapply seems like there would be a lot of overhead starting
>and stopping threads.   But none of the tutorials I've found addresses
>this particular question.  Both direct answers and pointers to other
>docs would be welcome.
>
>Terry T.
>
>
>
>	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Sat Jan  7 12:26:58 2017
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sat, 7 Jan 2017 16:56:58 +0530
Subject: [R] Linear optimization with quadratic constraints
In-Reply-To: <CAHVFrXHH7MY-hFOtKK4i9O3AtLTxfwmEVr8pawnD5CZod8_-5A@mail.gmail.com>
References: <CAHVFrXHH7MY-hFOtKK4i9O3AtLTxfwmEVr8pawnD5CZod8_-5A@mail.gmail.com>
Message-ID: <CAHVFrXHEXzQXzW51nF8MifqTwYeF6k=5F_py7+uHXR-GjOJj+Q@mail.gmail.com>

Hi Guys,
Any help with this,please?
Regards,
Preetam

On Thu, Jan 5, 2017 at 4:09 AM, Preetam Pal <lordpreetam at gmail.com> wrote:

> Hello guys,
>
> The context is ordinary multivariate regression with k (>1) regressors,
> i.e. *Y = XB + Error*, where
> Y = n X 1 vector of predicted variable,
> X = n X (k + 1) matrix of regressor variables(including ones in the first
> column)
> B = (k+1) vector of coefficients, including intercept.
>
> Say, I have already estimated B as B_hat = (X'X)^(-1) X'Y.
>
> I have to solve the following program:
>
> *minimize f(B) = LB*   ( L is a fixed vector 1 X (k+1)   )
> such that:
> *[(B-B_hat)' * X'X * (B-B_hat) ] / [ ( Y - XB_hat)' (Y - XB_hat) ] *  is
> less than a given value *c*.
>
> Note that this is a linear optimization program *with respect to B* with
> quadratic constraints.
>
> I don't understand how we can solve this optimization - I was going
> through some online resources, each of which involve manually computing
> gradients of the objective as well as constraint functions - which I want
> to avoid (at least manually doing this).
>
>
> Can you please help with solving this optimization problem? The inputs
> would be:
>
>    - X and Y
>    - B_hat
>    - L
>    - c
>
>
> Please let me know if any further information is required - the set-up is
> pretty general.
>
> Regards,
> Preetam
>



-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Jan  7 13:26:59 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 07 Jan 2017 12:26:59 +0000
Subject: [R] About populating a dataframe in a loop
In-Reply-To: <CAN5afy_PnSOtwAUy5v+gJQJVaR_DFam3NGD2SSEgpE=F4TLRfA@mail.gmail.com>
References: <CAN5afy9QKtxJQyCxtcGXOL=vPCX0PDMreG=sjRF2GggrL8GhCQ@mail.gmail.com>
	<586FDDFF.3000109@sapo.pt>
	<CAN5afy9WOBQxCKG45VbPFP6XiM9CZScx8DZZQ7_g_FXO_cGj8Q@mail.gmail.com>
	<CAGx1TMBQ72-UzJwASg+LVAd7ExZjpota6NFe=pBDYBkMpdgKjg@mail.gmail.com>
	<CAN5afy_PnSOtwAUy5v+gJQJVaR_DFam3NGD2SSEgpE=F4TLRfA@mail.gmail.com>
Message-ID: <5870DE93.2050103@sapo.pt>

Hello,

I believe you should follow Jeremiah's sugestion to first read all csv 
files into a list and then rbind them.
Something like the following.

file_list <- list.files(pattern = "*.csv")
df_list <- lapply(file_list, read.csv)
result <- do.call(rbind, df_list)

Hope this helps,

Rui Barradas

Em 07-01-2017 06:51, lily li escreveu:
> Thanks, Richard. But if the data cannot fill the constructed data frame,
> will there be NA values?
>
>
> On Fri, Jan 6, 2017 at 10:07 PM, Richard M. Heiberger <rmh at temple.edu
> <mailto:rmh at temple.edu>> wrote:
>
>     Incrementally increasing the size of an array is not efficient in R.
>     The recommended technique is to allocate as much space as you will
>     need, and then fill it.
>
>      > system.time({tmp <- 1:5 ; for (i in 1:1000) tmp <- rbind(tmp, 1:5)})
>         user  system elapsed
>        0.011   0.000   0.011
>      > dim(tmp)
>     [1] 1001    5
>      > system.time({tmp <- matrix(NA, 1001, 5); for (i in 1:1001)
>     tmp[i,] <- 1:5})
>         user  system elapsed
>        0.001   0.000   0.001
>      > dim(tmp)
>     [1] 1001    5
>
>     On Fri, Jan 6, 2017 at 11:46 PM, lily li <chocold12 at gmail.com
>     <mailto:chocold12 at gmail.com>> wrote:
>      > Hi Rui,
>      >
>      > Thanks for your reply. Yes, when I tried to rbind two dataframes,
>     it works.
>      > However, if there are more than 50, it got stuck for hours. When
>     I tried to
>      > terminate the process and open the csv file separately, it has
>     only one
>      > data frame. What is the problem? Thanks.
>      >
>      >
>      > On Fri, Jan 6, 2017 at 11:12 AM, Rui Barradas
>     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>      >
>      >> Hello,
>      >>
>      >> Works with me:
>      >>
>      >> set.seed(6574)
>      >>
>      >> pre.mat = data.frame()
>      >> for(i in 1:10){
>      >>     mat.temp = data.frame(x = rnorm(5), A = sample(LETTERS, 5,
>     TRUE))
>      >>     pre.mat = rbind(pre.mat, mat.temp)
>      >> }
>      >>
>      >> nrow(pre.mat)  # should be 50
>      >>
>      >>
>      >> Can you give us an example that doesn't work?
>      >>
>      >> Rui Barradas
>      >>
>      >>
>      >> Em 06-01-2017 18:00, lily li escreveu:
>      >>
>      >>> Hi R users,
>      >>>
>      >>> I have a question about filling a dataframe in R using a for loop.
>      >>>
>      >>> I created an empty dataframe first and then filled it, using
>     the code:
>      >>> pre.mat = data.frame()
>      >>> for(i in 1:10){
>      >>>      mat.temp = data.frame(some values filled in)
>      >>>      pre.mat = rbind(pre.mat, mat.temp)
>      >>> }
>      >>> However, the resulted dataframe has not all the rows that I
>     desired for.
>      >>> What is the problem and how to solve it? Thanks.
>      >>>
>      >>>         [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      >>> PLEASE do read the posting guide http://www.R-project.org/posti
>      >>> ng-guide.html
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>>
>      >>>
>      >
>      >         [[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      > and provide commented, minimal, self-contained, reproducible code.
>
>


From biottilicia at gmail.com  Sat Jan  7 23:53:35 2017
From: biottilicia at gmail.com (Licia Biotti)
Date: Sat, 7 Jan 2017 23:53:35 +0100
Subject: [R] recoding responses in a numeric variable
Message-ID: <CA+HfEmD79TMpx_b8pqC1biXUzS-2pec4sz__LexCkf9D8y2hAw@mail.gmail.com>

Hello,

I am working with a dataset in R studio, and I have created a numeric
variable which I have called fear by using a factor variable (called vn35).
Here is the piece of code:
fear<-gles_reduced$vn35
levels(fear)
table(fear, as.numeric(fear), exclude=NULL)

Then I have coded the levels "don't know" and "not specified" as NA
fear[fear=="not specified"]<-NA
fear[fear=="don't know"]<-NA

This is how the table looks like:

fear                          3    4    5    6    7 <NA>
  no entry                 0    0    0    0    0    0
  don't know             0    0    0    0    0    0
  a lot of fear           412    0    0    0    0    0
  big fear                   0  883    0    0    0    0
  medium fear           0    0  1350    0    0    0
  little fear                 0    0    0  920    0    0
  no fear at all           0    0    0    0  305    0
  <NA>                      0    0    0    0    0    41

I would like to code the remaining answers (a lot of fear, big fear, medium
fear, little fear and no fear at all) with values from 0 to 4 (so that
greater values indicate great concern)
I tried this piece of code:
fear[fear=="big fear"]<-1
But it is not working,
could you please help me?
Thanks,

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Jan  8 06:04:38 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 7 Jan 2017 21:04:38 -0800 (PST)
Subject: [R] recoding responses in a numeric variable
In-Reply-To: <CA+HfEmD79TMpx_b8pqC1biXUzS-2pec4sz__LexCkf9D8y2hAw@mail.gmail.com>
References: <CA+HfEmD79TMpx_b8pqC1biXUzS-2pec4sz__LexCkf9D8y2hAw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1701072043420.53694@pedal.dcn.davis.ca.us>

Please read the Posting Guide mentioned at the bottom of this and every 
message. In particular, send your email in plain text format so we get to 
see what you saw (the mailing list strips out HTML formatting in most 
cases). Also please work to make your examples reproducible... e.g. give 
all steps necessary to reproduce your output or error... otherwise 
we get to guess what you were doing wrong and if we guess wrong then our 
help is wasted. The code below should be reproducible for your benefit and 
for anyone else who reads this.

#### code follows
# make believe data as though it was in a file
inputdata <-
"vn35
no entry
no entry
don't know
don't know
don't know
a lot of fear
a lot of fear
a lot of fear
a lot of fear
big fear
big fear
big fear
big fear
big fear
medium fear
medium fear
medium fear
medium fear
medium fear
medium fear
little fear
little fear
little fear
little fear
little fear
little fear
little fear
no fear at all
no fear at all
no fear at all
no fear at all
no fear at all
no fear at all
no fear at all
no fear at all
"

# I am going to guess that you did something kind of like

gles_reduced <- read.csv( text=inputdata )

# before you did the steps you gave us:
fear <- gles_reduced$vn35
levels(fear)  # this doesn't change any of your data
table(fear, as.numeric(fear), exclude=NULL) # neither does this

# This now has a new level <NA> represented by a numeric value NA, and
# it is really not very useful to have both the value and the level be
# NA.

# In my opinion, the problem started when you let R automatically
# create a factor based on default settings. Lets try that again
# the right way:

# DONT let R automatically create a factor column
gles_reduced <- read.csv( text=inputdata, stringsAsFactors = FALSE )

fear <- gles_reduced$vn35
# now fear is a vector of character strings
# replace semantic unknowns with NA
fear[ fear %in% c( "no entry", "don't know" ) ] <- NA
# define the levels in the order you want them from small to large
fearlvls <- c( "no fear at all"
              , "little fear"
              , "medium fear"
              , "big fear"
              , "a lot of fear"
              )
# explicitly create the factor with comparability
fear <- ordered( fear, levels=fearlvls )
table(fear, as.numeric( fear ) )
sum( is.na( fear ) )
which( "big fear" < fear ) # indexes of the ones that have
                            # a lot of fear
fear[ which( "big fear" < fear ) ] # see them
#### end of code

Note that the levels go from 1 to 5, not 0 to 4, but factors don't work 
with zeroes.  Fortunately all the stats functions in R know this so you 
are better off not fighting the convention. If you absolutely must, then 
you need to deal with it in an integer or numeric vector:

fearnums <- as.integer( fear ) - 1L

On Sat, 7 Jan 2017, Licia Biotti wrote:

> Hello,
>
> I am working with a dataset in R studio, and I have created a numeric
> variable which I have called fear by using a factor variable (called vn35).
> Here is the piece of code:
> fear<-gles_reduced$vn35
> levels(fear)
> table(fear, as.numeric(fear), exclude=NULL)
>
> Then I have coded the levels "don't know" and "not specified" as NA
> fear[fear=="not specified"]<-NA
> fear[fear=="don't know"]<-NA
>
> This is how the table looks like:
>
> fear                          3    4    5    6    7 <NA>
>  no entry                 0    0    0    0    0    0
>  don't know             0    0    0    0    0    0
>  a lot of fear           412    0    0    0    0    0
>  big fear                   0  883    0    0    0    0
>  medium fear           0    0  1350    0    0    0
>  little fear                 0    0    0  920    0    0
>  no fear at all           0    0    0    0  305    0
>  <NA>                      0    0    0    0    0    41
>
> I would like to code the remaining answers (a lot of fear, big fear, medium
> fear, little fear and no fear at all) with values from 0 to 4 (so that
> greater values indicate great concern)
> I tried this piece of code:
> fear[fear=="big fear"]<-1
> But it is not working,
> could you please help me?
> Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Sun Jan  8 06:56:41 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 7 Jan 2017 21:56:41 -0800 (PST)
Subject: [R] Linear optimization with quadratic constraints
In-Reply-To: <CAHVFrXHEXzQXzW51nF8MifqTwYeF6k=5F_py7+uHXR-GjOJj+Q@mail.gmail.com>
References: <CAHVFrXHH7MY-hFOtKK4i9O3AtLTxfwmEVr8pawnD5CZod8_-5A@mail.gmail.com>
	<CAHVFrXHEXzQXzW51nF8MifqTwYeF6k=5F_py7+uHXR-GjOJj+Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1701072111300.53694@pedal.dcn.davis.ca.us>

I did't really feel like digging through your HTML-contaminated email [1] 
that has nothing concrete in it, most notably R code and input data, nor 
an expected result that the code should yield. (Before you protest that 
you are LOOKING for R code, please go read about reproducible R examples 
[2] since you CAN translate a sample problem of the type you want to solve 
into input data and expected results as dput() output. If you can't then 
you may not understand your own problem clearly yet and we are unlikely to 
understand what you want anyway.)

A quick skim leaves me wondering why you don't just use the lm function. I 
don't get why you have formulated this with a constraint at all... the 
B_hat complication seems counterproductive since there is no particular 
reason to think that a solution is even present meeting that constraint. 
(Then again, I am looking at corrupted HTML which may be contributing to 
the confusion.) Anyway, I am not a mathematician and this is not a theory 
discussion list, so you need make the problem more concrete and perhaps 
someone here can come up with a concrete solution.

When you say you found stuff on the web that didn't meet your needs, you 
should cite it and describe why not specifically so we don't find it and 
think "you should have found this yourself". The second hit that came up 
when I typed 'R linear optimization "quadratic constraint"' into Google 
was https://cran.r-project.org/web/packages/ROI/ROI.pdf, which seems 
relevant though I have never used that particular package and you have not 
explicitly said why the examples in that package are not useful to you.

[1] Read the Posting Guide at the footer of every email on this mailing 
list... the mailing list is explicitly for plain text email and usually 
damages HTML format so don't put it in there to begin with.
[2] Google "reproducible R example"

On Sat, 7 Jan 2017, Preetam Pal wrote:

> Hi Guys,
> Any help with this,please?
> Regards,
> Preetam
>
> On Thu, Jan 5, 2017 at 4:09 AM, Preetam Pal <lordpreetam at gmail.com> wrote:
>
>> Hello guys,
>>
>> The context is ordinary multivariate regression with k (>1) regressors,
>> i.e. *Y = XB + Error*, where
>> Y = n X 1 vector of predicted variable,
>> X = n X (k + 1) matrix of regressor variables(including ones in the first
>> column)
>> B = (k+1) vector of coefficients, including intercept.
>>
>> Say, I have already estimated B as B_hat = (X'X)^(-1) X'Y.
>>
>> I have to solve the following program:
>>
>> *minimize f(B) = LB*   ( L is a fixed vector 1 X (k+1)   )
>> such that:
>> *[(B-B_hat)' * X'X * (B-B_hat) ] / [ ( Y - XB_hat)' (Y - XB_hat) ] *  is
>> less than a given value *c*.
>>
>> Note that this is a linear optimization program *with respect to B* with
>> quadratic constraints.
>>
>> I don't understand how we can solve this optimization - I was going
>> through some online resources, each of which involve manually computing
>> gradients of the objective as well as constraint functions - which I want
>> to avoid (at least manually doing this).
>>
>>
>> Can you please help with solving this optimization problem? The inputs
>> would be:
>>
>>    - X and Y
>>    - B_hat
>>    - L
>>    - c
>>
>>
>> Please let me know if any further information is required - the set-up is
>> pretty general.
>>
>> Regards,
>> Preetam
>>
>
>
>
> -- 
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From profjcnash at gmail.com  Sun Jan  8 15:02:49 2017
From: profjcnash at gmail.com (ProfJCNash)
Date: Sun, 8 Jan 2017 09:02:49 -0500
Subject: [R] Linear optimization with quadratic constraints
In-Reply-To: <CAHVFrXHEXzQXzW51nF8MifqTwYeF6k=5F_py7+uHXR-GjOJj+Q@mail.gmail.com>
References: <CAHVFrXHH7MY-hFOtKK4i9O3AtLTxfwmEVr8pawnD5CZod8_-5A@mail.gmail.com>
	<CAHVFrXHEXzQXzW51nF8MifqTwYeF6k=5F_py7+uHXR-GjOJj+Q@mail.gmail.com>
Message-ID: <0ae711d8-e392-4e4a-a35e-696be94bf389@gmail.com>

Small example code to set up the problem?

JN

On 2017-01-07 06:26 AM, Preetam Pal wrote:
> Hi Guys,
> Any help with this,please?
> Regards,
> Preetam
> 
> On Thu, Jan 5, 2017 at 4:09 AM, Preetam Pal <lordpreetam at gmail.com> wrote:
> 
>> Hello guys,
>>
>> The context is ordinary multivariate regression with k (>1) regressors,
>> i.e. *Y = XB + Error*, where
>> Y = n X 1 vector of predicted variable,
>> X = n X (k + 1) matrix of regressor variables(including ones in the first
>> column)
>> B = (k+1) vector of coefficients, including intercept.
>>
>> Say, I have already estimated B as B_hat = (X'X)^(-1) X'Y.
>>
>> I have to solve the following program:
>>
>> *minimize f(B) = LB*   ( L is a fixed vector 1 X (k+1)   )
>> such that:
>> *[(B-B_hat)' * X'X * (B-B_hat) ] / [ ( Y - XB_hat)' (Y - XB_hat) ] *  is
>> less than a given value *c*.
>>
>> Note that this is a linear optimization program *with respect to B* with
>> quadratic constraints.
>>
>> I don't understand how we can solve this optimization - I was going
>> through some online resources, each of which involve manually computing
>> gradients of the objective as well as constraint functions - which I want
>> to avoid (at least manually doing this).
>>
>>
>> Can you please help with solving this optimization problem? The inputs
>> would be:
>>
>>    - X and Y
>>    - B_hat
>>    - L
>>    - c
>>
>>
>> Please let me know if any further information is required - the set-up is
>> pretty general.
>>
>> Regards,
>> Preetam
>>
> 
> 
>


From caciquesamurai at gmail.com  Mon Jan  9 06:21:45 2017
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Mon, 9 Jan 2017 03:21:45 -0200
Subject: [R] using if else function to complete a column in data frame
Message-ID: <CAGtwFe1abeMbWHSbLtM6p7-+616UUEXUvfahdV-FpDhywZ8Guw@mail.gmail.com>

Hello all!

I?m trying to complete the "movimento" column in dataframe based in
the values of "kmr" column in two sequential lines, as below:

data example (dput in the end of email):

         ID    kmr movimento
5    10.700 314.20        NA
1    10.700 278.74        NA
2    10.700 278.74        NA
3    10.700 278.74        NA
4    10.700 278.74        NA
494 100.700 269.94        NA
500 100.700 278.74        NA
499 100.700 314.20        NA
495 100.700 278.74        NA
498 100.700 278.74        NA
496 100.700 255.40        NA
497 100.700 255.10        NA

Once I have different IDs, I wrote this function:

move = function (x){

  for (j in x$ID){

    for (i in 2:length(x$kmr)-1){

      if (x$kmr[i+1]  < x$kmr[i]) {
        x$movimento[i+1] <- "jusante"
      } else if (x$kmr[i+1] > x$kmr[i]) {
        x$movimento[i+1] <- "montante"
      } else {
        x$movimento[i+1] <- "parado"
      }

    }

  }

  return (x)
}

Worked pretty well with just one ID, but with many IDs the function
didn?t detach different IDs.

         ID    kmr movimento
5    10.700 314.20      <NA>
1    10.700 278.74   jusante
2    10.700 278.74    parado
3    10.700 278.74    parado
4    10.700 278.74    parado
494 100.700 269.94   jusante <-- this should be <NA>
500 100.700 278.74  montante
499 100.700 314.20  montante
495 100.700 278.74   jusante
498 100.700 278.74    parado
496 100.700 255.40   jusante
497 100.700 255.10   jusante

I also tried remove the first If condition and pass this function
using lapply in the splitted original data-frame, but didn?t work as
well.

Some onde can help?

Thanks in advanced,

Raoni

structure(list(ID = c("10.700", "10.700", "10.700", "10.700",
"10.700", "100.700", "100.700", "100.700", "100.700", "100.700",
"100.700", "100.700"), kmr = c(314.2, 278.74, 278.74, 278.74,
278.74, 269.94, 278.74, 314.2, 278.74, 278.74, 255.4, 255.1),
    movimento = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
    NA)), .Names = c("ID", "kmr", "movimento"), row.names = c(5L,
1L, 2L, 3L, 4L, 494L, 500L, 499L, 495L, 498L, 496L, 497L), class = "data.frame")

-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From mazatlanmexico at yahoo.com  Mon Jan  9 07:06:57 2017
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Mon, 9 Jan 2017 06:06:57 +0000
Subject: [R] gridExtra-arrangeGrob
References: <65473706.838889.1483942017228.ref@mail.yahoo.com>
Message-ID: <65473706.838889.1483942017228@mail.yahoo.com>

?Hi;The code below used to work on my older version of gridExtra but doesn't work with the new version. Could someonegive me a hint on how to translate this code to the new version of gridExtra code? Thank you beforehand.
p1?<- ggplot(iris,aes(Sepal.Length,? Petal.Length, colour=Species)) +
geom_point() + theme_bw() + theme(legend.position='top')

?grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .33,.33), ncol=1), ncol=2)
?#Create 2 columns with different width using the 'widths' argument in the grid.arrange call
? grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .40,.27), ncol=1), ncol=2,widths=c(1.25,0.75))
p <- rectGrob()??
?grid.arrange(p, arrangeGrob(p,p,p, heights=c(0.33, .33,.33), ncol=1), ncol=2)

	[[alternative HTML version deleted]]


From chris.barker at barkerstats.com  Mon Jan  9 05:52:24 2017
From: chris.barker at barkerstats.com (Chris)
Date: Mon, 9 Jan 2017 04:52:24 +0000 (UTC)
Subject: [R] R install/libraries
References: <2046322896.798422.1483937544943.ref@mail.yahoo.com>
Message-ID: <2046322896.798422.1483937544943@mail.yahoo.com>

I'd appreciate a tip on (re-)installing libraries for R on my windows machine?
I have a windows (Windows 7) ?computer and a recent version of R installed (3.3.2). ?I discovered that when I install R libraries they install to the "my documents" folder rather than to "program files"This seems to also create problems installing the dependent libraries when a library installs.
I'm presuming that R libraries are not installing to "program files" due to some permission/administrator privilege problems.
I have tried manually copying files from my documents to program files which didn't seem to completely fix the problem.
I also installed "r studio" but that hasn't resolved the problem of libraries not finding other libraries it depends on.A specific example, typically I use Frank Harrel's HMISC, however in my current installation it doesn't find "openssl".?
installation tips appreciated.
?Chris Barker, Ph.D.
Adjunct Associate Professor of Biostatistics - UIC-SPH
and
President and Owner
Statistical Planning and Analysis Services, Inc.
www.barkerstats.com
415 609 7473 
skype: barkerstats


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Jan  9 08:35:22 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Jan 2017 07:35:22 +0000
Subject: [R] using if else function to complete a column in data frame
In-Reply-To: <CAGtwFe1abeMbWHSbLtM6p7-+616UUEXUvfahdV-FpDhywZ8Guw@mail.gmail.com>
References: <CAGtwFe1abeMbWHSbLtM6p7-+616UUEXUvfahdV-FpDhywZ8Guw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FCB7A@SRVEXCHCM301.precheza.cz>

Hi

Split option seems to me the most effective and ifelse is in this case not necessary.

You can use this function to estimate levels

fff <- function(x) sign(diff(x))
test.s <- split(test, test$ID)
for (i in 1:length(test.s)) test.s[[i]]$movimento[-1] <- fff(test.s[[i]][,2])
test <- do.call(rbind, test.s)
test[,3] <- factor(test[,3], levels=c(-1, 0, 1), labels=c("jusante", "parado", "montante"))
test

To avoid extension of row names you can use
library (plyr)
test<-ldply (test.s, data.frame)

instead of do.call.

I tried assigning factor within for cycle

fff<- function(x) factor(sign(diff(x)), levels=c(-1, 0, 1), labels=c("jusante", "parado", "montante"))
test.s <- split(test, test$ID)
for (i in 1:length(test.s)) test.s[[i]]$movimento[-1] <- fff(test.s[[i]][,2])
test <- do.call(rbind, test.s)
test

but assigned in this case is not factor but numeric vector, which seems to me strange. Maybe somebody could explain this behaviour

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cacique
> Samurai
> Sent: Monday, January 9, 2017 6:22 AM
> To: R help <r-help at r-project.org>
> Subject: [R] using if else function to complete a column in data frame
>
> Hello all!
>
> I?m trying to complete the "movimento" column in dataframe based in the
> values of "kmr" column in two sequential lines, as below:
>
> data example (dput in the end of email):
>
>          ID    kmr movimento
> 5    10.700 314.20        NA
> 1    10.700 278.74        NA
> 2    10.700 278.74        NA
> 3    10.700 278.74        NA
> 4    10.700 278.74        NA
> 494 100.700 269.94        NA
> 500 100.700 278.74        NA
> 499 100.700 314.20        NA
> 495 100.700 278.74        NA
> 498 100.700 278.74        NA
> 496 100.700 255.40        NA
> 497 100.700 255.10        NA
>
> Once I have different IDs, I wrote this function:
>
> move = function (x){
>
>   for (j in x$ID){
>
>     for (i in 2:length(x$kmr)-1){
>
>       if (x$kmr[i+1]  < x$kmr[i]) {
>         x$movimento[i+1] <- "jusante"
>       } else if (x$kmr[i+1] > x$kmr[i]) {
>         x$movimento[i+1] <- "montante"
>       } else {
>         x$movimento[i+1] <- "parado"
>       }
>
>     }
>
>   }
>
>   return (x)
> }
>
> Worked pretty well with just one ID, but with many IDs the function didn?t
> detach different IDs.
>
>          ID    kmr movimento
> 5    10.700 314.20      <NA>
> 1    10.700 278.74   jusante
> 2    10.700 278.74    parado
> 3    10.700 278.74    parado
> 4    10.700 278.74    parado
> 494 100.700 269.94   jusante <-- this should be <NA>
> 500 100.700 278.74  montante
> 499 100.700 314.20  montante
> 495 100.700 278.74   jusante
> 498 100.700 278.74    parado
> 496 100.700 255.40   jusante
> 497 100.700 255.10   jusante
>
> I also tried remove the first If condition and pass this function using lapply in
> the splitted original data-frame, but didn?t work as well.
>
> Some onde can help?
>
> Thanks in advanced,
>
> Raoni
>
> structure(list(ID = c("10.700", "10.700", "10.700", "10.700", "10.700",
> "100.700", "100.700", "100.700", "100.700", "100.700", "100.700", "100.700"),
> kmr = c(314.2, 278.74, 278.74, 278.74, 278.74, 269.94, 278.74, 314.2, 278.74,
> 278.74, 255.4, 255.1),
>     movimento = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>     NA)), .Names = c("ID", "kmr", "movimento"), row.names = c(5L, 1L, 2L, 3L,
> 4L, 494L, 500L, 499L, 495L, 498L, 496L, 497L), class = "data.frame")
>
> --
> Raoni Rosa Rodrigues
> Research Associate of Fish Transposition Center CTPeixes Universidade
> Federal de Minas Gerais - UFMG Brasil rodrigues.raoni at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dwinsemius at comcast.net  Mon Jan  9 08:36:34 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 8 Jan 2017 23:36:34 -0800
Subject: [R] using if else function to complete a column in data frame
In-Reply-To: <CAGtwFe1abeMbWHSbLtM6p7-+616UUEXUvfahdV-FpDhywZ8Guw@mail.gmail.com>
References: <CAGtwFe1abeMbWHSbLtM6p7-+616UUEXUvfahdV-FpDhywZ8Guw@mail.gmail.com>
Message-ID: <FF81F62B-E480-47D9-ACFB-27195A3CC34F@comcast.net>


> On Jan 8, 2017, at 9:21 PM, Cacique Samurai <caciquesamurai at gmail.com> wrote:
> 
> Hello all!
> 
> I?m trying to complete the "movimento" column in dataframe based in
> the values of "kmr" column in two sequential lines, as below:
> 
> data example (dput in the end of email):
> 
>         ID    kmr movimento
> 5    10.700 314.20        NA
> 1    10.700 278.74        NA
> 2    10.700 278.74        NA
> 3    10.700 278.74        NA
> 4    10.700 278.74        NA
> 494 100.700 269.94        NA
> 500 100.700 278.74        NA
> 499 100.700 314.20        NA
> 495 100.700 278.74        NA
> 498 100.700 278.74        NA
> 496 100.700 255.40        NA
> 497 100.700 255.10        NA
> 
> Once I have different IDs, I wrote this function:
> 
> move = function (x){
> 
>  for (j in x$ID){
> 
>    for (i in 2:length(x$kmr)-1){
> 
>      if (x$kmr[i+1]  < x$kmr[i]) {
>        x$movimento[i+1] <- "jusante"
>      } else if (x$kmr[i+1] > x$kmr[i]) {
>        x$movimento[i+1] <- "montante"
>      } else {
>        x$movimento[i+1] <- "parado"
>      }
> 
>    }
> 
>  }
> 
>  return (x)
> }
> 
> Worked pretty well with just one ID, but with many IDs the function
> didn?t detach different IDs.
> 
>         ID    kmr movimento
> 5    10.700 314.20      <NA>
> 1    10.700 278.74   jusante
> 2    10.700 278.74    parado
> 3    10.700 278.74    parado
> 4    10.700 278.74    parado
> 494 100.700 269.94   jusante <-- this should be <NA>

The inner loop was not "recognizing" (or more accurately you were not causing the code to account for the fact) that you wanted this to be done within values of ID. Each pass of the outer loop was doing the same process inside the inner loop.


> 500 100.700 278.74  montante
> 499 100.700 314.20  montante
> 495 100.700 278.74   jusante
> 498 100.700 278.74    parado
> 496 100.700 255.40   jusante
> 497 100.700 255.10   jusante
> 
> I also tried remove the first If condition and pass this function
> using lapply in the splitted original data-frame, but didn?t work as
> well.
> 
> Some onde can help?
> 
> Thanks in advanced,
> 
> Raoni
> 
> structure(list(ID = c("10.700", "10.700", "10.700", "10.700",
> "10.700", "100.700", "100.700", "100.700", "100.700", "100.700",
> "100.700", "100.700"), kmr = c(314.2, 278.74, 278.74, 278.74,
> 278.74, 269.94, 278.74, 314.2, 278.74, 278.74, 255.4, 255.1),
>    movimento = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>    NA)), .Names = c("ID", "kmr", "movimento"), row.names = c(5L,
> 1L, 2L, 3L, 4L, 494L, 500L, 499L, 495L, 498L, 496L, 497L), class = "data.frame")
> 
> -- 
> Raoni Rosa Rodrigues
> Research Associate of Fish Transposition Center CTPeixes
> Universidade Federal de Minas Gerais - UFMG
> Brasil
> rodrigues.raoni at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From j.marchesi at imperial.ac.uk  Mon Jan  9 09:18:23 2017
From: j.marchesi at imperial.ac.uk (Marchesi, Julian)
Date: Mon, 9 Jan 2017 08:18:23 +0000
Subject: [R] testing whether clusters in a PCA plot are significantly
 different from one another
In-Reply-To: <ec03be1d-2fd8-966f-bbeb-71e22e9bf9e5@yorku.ca>
References: <DB4PR06MB032C5A26C7F9186D0190FD3AF630@DB4PR06MB032.eurprd06.prod.outlook.com>,
	<ec03be1d-2fd8-966f-bbeb-71e22e9bf9e5@yorku.ca>
Message-ID: <DB4PR06MB032BB65A88AC767AF28DA48AF640@DB4PR06MB032.eurprd06.prod.outlook.com>

Dear Micheal

So I would be much better off just reporting the PCA as is and conclude what i can from plot

cheers

Julian

Julian R. Marchesi

Deputy Director and Professor of Clinical Microbiome Research at the  Centre for Digestive and Gut Health, Imperial College London, London W2 1NY Tel: +44 (0)20 331 26197

and

Professor of Human Microbiome Research at the School of Biosciences, Museum Avenue, Cardiff University, Cardiff, CF10 3AT, Tel: +44 (0)29 208 74188, Fax: +44 (0)29 20874305, Mobile 07885 569144




________________________________________
From: Michael Friendly <friendly at yorku.ca>
Sent: 07 January 2017 17:15
To: Marchesi, Julian; 'r-help at r-project.org'
Subject: Re: testing whether clusters in a PCA plot are significantly different from one another

Significance tests for group differences in a MANOVA of
lm(cbind(pc1, pc2) ~ group)

will get you what you want, but you are advised DON'T DO THIS, at least
without a huge grain of salt and a slew of mea culpas.
Otherwise, you are committing p-value abuse and contributing to the
notion that significance tests must be used to justify all conclusions.

The p-values will not be correct under standard normal theory of the
multivariate GLM because the pc1 and pc2 were chosen to optimize
the variance accounted for by their linear combinations and there
is no theory that can correct for this, AFAIK.  The cluster "group"
assignment was also chosen to optimize some (other) criterion.



--
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jdnewmil at dcn.davis.ca.us  Mon Jan  9 10:03:37 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 09 Jan 2017 01:03:37 -0800
Subject: [R] R install/libraries
In-Reply-To: <2046322896.798422.1483937544943@mail.yahoo.com>
References: <2046322896.798422.1483937544943.ref@mail.yahoo.com>
	<2046322896.798422.1483937544943@mail.yahoo.com>
Message-ID: <E90749AF-779D-4AA9-B0B1-856CD8FC1103@dcn.davis.ca.us>

You seem to have shafted yourself by thinking you need to run R as administrator... ever.

Use Run as Administrator to run the command line and delete your My Documents/R folder and then exit that command line and stay out of it and don't run R as administrator again, because by doing so you prevent yourself from using it as it is intended... non-administrator.

Don't make any effort to modify the system library. It is unnecessary and only causes trouble. If R doesn't re-create your personal library for you then you can re-create My Documents/R/win-library/3.3 yourself with File Explorer. 

https://stat.ethz.ch/pipermail/r-help//2013-March/349131.html

fortunes::fortune(337)

-- 
Sent from my phone. Please excuse my brevity.

On January 8, 2017 8:52:24 PM PST, Chris <chris.barker at barkerstats.com> wrote:
>I'd appreciate a tip on (re-)installing libraries for R on my windows
>machine?
>I have a windows (Windows 7) ?computer and a recent version of R
>installed (3.3.2). ?I discovered that when I install R libraries they
>install to the "my documents" folder rather than to "program files"This
>seems to also create problems installing the dependent libraries when a
>library installs.
>I'm presuming that R libraries are not installing to "program files"
>due to some permission/administrator privilege problems.
>I have tried manually copying files from my documents to program files
>which didn't seem to completely fix the problem.
>I also installed "r studio" but that hasn't resolved the problem of
>libraries not finding other libraries it depends on.A specific example,
>typically I use Frank Harrel's HMISC, however in my current
>installation it doesn't find "openssl".?
>installation tips appreciated.
>?Chris Barker, Ph.D.
>Adjunct Associate Professor of Biostatistics - UIC-SPH
>and
>President and Owner
>Statistical Planning and Analysis Services, Inc.
>www.barkerstats.com
>415 609 7473 
>skype: barkerstats
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Mon Jan  9 12:35:25 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 9 Jan 2017 11:35:25 +0000
Subject: [R] gridExtra-arrangeGrob
In-Reply-To: <65473706.838889.1483942017228@mail.yahoo.com>
References: <65473706.838889.1483942017228.ref@mail.yahoo.com>
	<65473706.838889.1483942017228@mail.yahoo.com>
Message-ID: <1699652495.1038553.1483961725633@mail.yahoo.com>

I'm not sure what the problem is but, if nothing else, it looks like you need to do 
library(grid)
It may be that an early version of ggplot2 or gridExtra was automatically loading grid and it no longer does.? 


 

    On Monday, January 9, 2017 1:08 AM, Felipe Carrillo via R-help <r-help at r-project.org> wrote:
 

 ?Hi;The code below used to work on my older version of gridExtra but doesn't work with the new version. Could someonegive me a hint on how to translate this code to the new version of gridExtra code? Thank you beforehand.
p1?<- ggplot(iris,aes(Sepal.Length,? Petal.Length, colour=Species)) +
geom_point() + theme_bw() + theme(legend.position='top')

?grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .33,.33), ncol=1), ncol=2)
?#Create 2 columns with different width using the 'widths' argument in the grid.arrange call
? grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .40,.27), ncol=1), ncol=2,widths=c(1.25,0.75))
p <- rectGrob()??
?grid.arrange(p, arrangeGrob(p,p,p, heights=c(0.33, .33,.33), ncol=1), ncol=2)

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Mon Jan  9 14:59:39 2017
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Mon, 9 Jan 2017 16:59:39 +0300
Subject: [R] Error in ReadInputs(dat1, constant1, stopmissing = c(40, 40, 10),
 timestep = "daily", : Missing data of Tmax.daily.
Message-ID: <CAGh51gQiO2V-88MoMBmgzpAMm+CWArKfA3Wdwdc5Dm3ckWg6EA@mail.gmail.com>

Dear All,

Could you please give me a hint on how to overcome this error?

Here is the code:


data("constants")
constant1<-constants
constant1$lat<-dat1$Latitude[1]
constant1$lat_rad<-0.10123

dat1<-omit(dat1)
# ReadInputs climate data
data <- ReadInputs(dat1, constant1,
                   stopmissing=c(40,40,10),
                   timestep="daily",
                   interp_missing_days = T,
                   interp_missing_entries = T,
                   interp_abnormal = T,
                   missing_method = "DoY average",
                   abnormal_method = "DoY average")
results <- ET.HargreavesSamani(data,constant1, ts="daily")


dput(head(dat1))structure(list(Year = structure(c(1L, 1L, 1L, 1L, 1L,
1L), .Label = c("1984",
"1985", "1986", "1987", "1988", "1989", "1990", "1991", "1992",
"1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000",
"2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008",
"2009"), class = "factor"), Month = structure(c(1L, 1L, 1L, 1L,
1L, 1L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
"10", "11", "12"), class = "factor"), Day = 1:6, WindSpeed = c(5L,
4L, 4L, 3L, 5L, 6L), Sunshine = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
), Tmax = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin = c(14.5,
16, 14.4, 14.8, 16.6, 15.4), Hmax = c(100L, 95L, 97L, 100L, 97L,
99L), Hmin = c(45L, 62L, 72L, 55L, 54L, 63L), Station.Name = structure(c(1L,
1L, 1L, 1L, 1L, 1L), .Label = "KIGALI AERO", class = "factor"),
    Elevation = c(1490L, 1490L, 1490L, 1490L, 1490L, 1490L),
    Longitude = c(30.11, 30.11, 30.11, 30.11, 30.11, 30.11),
    Latitude = c(-1.95, -1.95, -1.95, -1.95, -1.95, -1.95), Date =
structure(c(5113,
    5114, 5115, 5116, 5117, 5118), class = "Date")), .Names = c("Year",
"Month", "Day", "WindSpeed", "Sunshine", "Tmax", "Tmin", "Hmax",
"Hmin", "Station.Name", "Elevation", "Longitude", "Latitude",
"Date"), na.action = structure(c(257L, 325L, 326L, 393L, 424L,
425L, 428L, 436L, 564L, 632L, 635L, 636L, 647L, 747L, 778L, 790L,
822L, 823L, 852L, 853L, 884L, 886L, 910L, 911L, 912L, 913L, 914L,
915L, 927L, 945L, 999L, 1019L, 1054L, 1156L, 1398L, 1445L, 1468L,
1489L, 1667L, 1742L, 1754L, 1766L, 1819L, 1822L, 1973L, 2142L,
2162L, 2163L, 2164L, 2165L, 2166L, 2167L, 2168L, 2169L, 2170L,
2171L, 2172L, 2173L, 2174L, 2175L, 2176L, 2177L, 2178L, 2179L,
2180L, 2181L, 2182L, 2183L, 2184L, 2185L, 2186L, 2187L, 2188L,
2189L, 2190L, 2191L, 2192L, 2283L, 2316L, 2420L, 2469L, 2478L,
2484L, 2603L, 2627L, 2831L, 2832L, 2833L, 2834L, 2835L, 2836L,
2837L, 2838L, 2839L, 2840L, 2841L, 2842L, 2843L, 2844L, 2845L,
2846L, 2847L, 2848L, 2849L, 2850L, 2851L, 2852L, 2853L, 2854L,
2855L, 2856L, 2857L, 2858L, 2859L, 2860L, 2861L, 2862L, 2863L,
2864L, 2865L, 2866L, 2867L, 2868L, 2869L, 2870L, 2871L, 2872L,
2873L, 2874L, 2875L, 2876L, 2877L, 2878L, 2879L, 2880L, 2881L,
2882L, 2883L, 2884L, 2885L, 2886L, 2887L, 2888L, 2889L, 2890L,
2891L, 2892L, 2893L, 2894L, 2895L, 2896L, 2897L, 2898L, 2899L,
2900L, 2901L, 2902L, 2903L, 2904L, 2905L, 2906L, 2907L, 2908L,
2909L, 2910L, 2911L, 2912L, 2913L, 2914L, 2915L, 2916L, 2917L,
2918L, 2919L, 2920L, 2921L, 2922L, 2923L, 2924L, 2925L, 2926L,
2927L, 2928L, 2929L, 2930L, 2931L, 2932L, 2933L, 2934L, 2935L,
2936L, 2937L, 2938L, 2939L, 2940L, 2941L, 2942L, 2943L, 2944L,
2945L, 2946L, 2947L, 2948L, 2949L, 2950L, 2951L, 2952L, 2953L,
2954L, 2955L, 2956L, 2957L, 2958L, 2959L, 2960L, 2961L, 2962L,
2963L, 2964L, 2965L, 2966L, 2967L, 2968L, 2969L, 2970L, 2971L,
2972L, 2973L, 2974L, 2975L, 2976L, 2977L, 2978L, 2979L, 2980L,
2981L, 2982L, 2983L, 2984L, 2985L, 2986L, 2987L, 2988L, 2989L,
2990L, 2991L, 2992L, 2993L, 2994L, 2995L, 2996L, 2997L, 2998L,
2999L, 3000L, 3001L, 3002L, 3003L, 3004L, 3005L, 3006L, 3007L,
3008L, 3009L, 3010L, 3011L, 3012L, 3013L, 3014L, 3015L, 3016L,
3017L, 3018L, 3019L, 3020L, 3021L, 3022L, 3023L, 3024L, 3025L,
3026L, 3027L, 3028L, 3029L, 3030L, 3031L, 3032L, 3033L, 3034L,
3035L, 3036L, 3037L, 3038L, 3039L, 3040L, 3041L, 3042L, 3043L,
3044L, 3045L, 3046L, 3047L, 3048L, 3049L, 3050L, 3051L, 3052L,
3053L, 3054L, 3055L, 3056L, 3057L, 3058L, 3059L, 3060L, 3061L,
3062L, 3063L, 3064L, 3065L, 3066L, 3067L, 3068L, 3069L, 3070L,
3071L, 3072L, 3073L, 3074L, 3075L, 3076L, 3077L, 3078L, 3079L,
3080L, 3081L, 3082L, 3083L, 3084L, 3085L, 3086L, 3087L, 3088L,
3089L, 3090L, 3091L, 3092L, 3093L, 3094L, 3095L, 3096L, 3097L,
3098L, 3099L, 3100L, 3101L, 3102L, 3103L, 3104L, 3105L, 3106L,
3107L, 3108L, 3109L, 3110L, 3111L, 3112L, 3113L, 3114L, 3115L,
3116L, 3117L, 3118L, 3119L, 3120L, 3121L, 3122L, 3123L, 3124L,
3125L, 3126L, 3127L, 3128L, 3129L, 3130L, 3131L, 3132L, 3133L,
3134L, 3135L, 3136L, 3137L, 3138L, 3139L, 3140L, 3141L, 3142L,
3143L, 3144L, 3145L, 3146L, 3147L, 3148L, 3149L, 3150L, 3151L,
3152L, 3153L, 3154L, 3155L, 3156L, 3157L, 3158L, 3159L, 3160L,
3161L, 3162L, 3163L, 3164L, 3165L, 3166L, 3167L, 3168L, 3169L,
3170L, 3171L, 3172L, 3173L, 3174L, 3175L, 3176L, 3177L, 3178L,
3179L, 3180L, 3181L, 3182L, 3183L, 3184L, 3185L, 3186L, 3187L,
3188L, 3189L, 3190L, 3191L, 3192L, 3193L, 3194L, 3195L, 3196L,
3197L, 3198L, 3199L, 3200L, 3201L, 3202L, 3203L, 3204L, 3205L,
3206L, 3207L, 3208L, 3209L, 3210L, 3211L, 3212L, 3213L, 3214L,
3215L, 3216L, 3217L, 3218L, 3219L, 3220L, 3221L, 3222L, 3223L,
3224L, 3225L, 3226L, 3227L, 3228L, 3229L, 3230L, 3231L, 3232L,
3233L, 3234L, 3235L, 3236L, 3237L, 3238L, 3239L, 3240L, 3241L,
3242L, 3243L, 3244L, 3245L, 3246L, 3247L, 3248L, 3249L, 3250L,
3251L, 3252L, 3253L, 3254L, 3255L, 3256L, 3257L, 3258L, 3259L,
3260L, 3261L, 3262L, 3263L, 3264L, 3265L, 3266L, 3267L, 3268L,
3269L, 3270L, 3271L, 3272L, 3273L, 3274L, 3275L, 3276L, 3277L,
3278L, 3279L, 3280L, 3281L, 3282L, 3283L, 3284L, 3285L, 3286L,
3287L, 3288L, 3289L, 3290L, 3291L, 3292L, 3293L, 3294L, 3295L,
3296L, 3297L, 3298L, 3299L, 3300L, 3301L, 3302L, 3303L, 3304L,
3305L, 3306L, 3307L, 3308L, 3309L, 3310L, 3311L, 3312L, 3313L,
3314L, 3315L, 3316L, 3317L, 3318L, 3319L, 3532L, 3533L, 3534L,
3535L, 3536L, 3537L, 3538L, 3539L, 3540L, 3541L, 3542L, 3543L,
3544L, 3545L, 3546L, 3547L, 3548L, 3549L, 3550L, 3551L, 3552L,
3553L, 3554L, 3555L, 3556L, 3557L, 3558L, 3559L, 3560L, 3561L,
3562L, 3563L, 3564L, 3565L, 3566L, 3567L, 3568L, 3569L, 3570L,
3571L, 3572L, 3573L, 3574L, 3575L, 3576L, 3577L, 3578L, 3579L,
3580L, 3581L, 3582L, 3583L, 3584L, 3585L, 3586L, 3587L, 3588L,
3589L, 3590L, 3591L, 3592L, 3593L, 3594L, 3595L, 3596L, 3597L,
3598L, 3599L, 3600L, 3601L, 3602L, 3603L, 3604L, 3605L, 3606L,
3607L, 3608L, 3609L, 3610L, 3611L, 3612L, 3613L, 3614L, 3615L,
3616L, 3617L, 3618L, 3619L, 3620L, 3621L, 3622L, 3654L, 3655L,
3656L, 3657L, 3658L, 3659L, 3660L, 3661L, 3662L, 3663L, 3664L,
3665L, 3666L, 3667L, 3668L, 3669L, 3670L, 3671L, 3672L, 3673L,
3674L, 3675L, 3676L, 3677L, 3678L, 3679L, 3680L, 3681L, 3682L,
3683L, 3684L, 3685L, 3686L, 3687L, 3688L, 3689L, 3690L, 3691L,
3692L, 3693L, 3694L, 3695L, 3696L, 3697L, 3698L, 3699L, 3700L,
3701L, 3702L, 3703L, 3704L, 3705L, 3706L, 3707L, 3708L, 3709L,
3710L, 3711L, 3712L, 3713L, 3714L, 3715L, 3716L, 3717L, 3718L,
3719L, 3720L, 3721L, 3722L, 3723L, 3724L, 3725L, 3726L, 3727L,
3728L, 3729L, 3730L, 3731L, 3732L, 3733L, 3734L, 3735L, 3736L,
3737L, 3738L, 3739L, 3740L, 3741L, 3742L, 3743L, 3744L, 3745L,
3746L, 3747L, 3748L, 3749L, 3750L, 3751L, 3752L, 3753L, 3754L,
3755L, 3756L, 3757L, 3758L, 3759L, 3760L, 3761L, 3762L, 3763L,
3764L, 3765L, 3766L, 3767L, 3768L, 3769L, 3770L, 3771L, 3772L,
3773L, 3774L, 3775L, 3776L, 3777L, 3778L, 3779L, 3780L, 3781L,
3782L, 3783L, 3784L, 3785L, 3786L, 3787L, 3788L, 3789L, 3790L,
3791L, 3792L, 3793L, 3794L, 3795L, 3796L, 3797L, 3798L, 3799L,
3800L, 3801L, 3802L, 3803L, 3804L, 3805L, 3806L, 3807L, 3808L,
3809L, 3810L, 3811L, 3812L, 3813L, 3814L, 3815L, 3816L, 3817L,
3818L, 3819L, 3820L, 3821L, 3822L, 3823L, 3824L, 3825L, 3826L,
3827L, 3828L, 3829L, 3830L, 3831L, 3832L, 3833L, 3834L, 3835L,
3836L, 3837L, 3838L, 3839L, 3840L, 3841L, 3842L, 3843L, 3844L,
3845L, 3846L, 3847L, 3848L, 3849L, 3850L, 3851L, 3852L, 3853L,
3854L, 3855L, 3856L, 3857L, 3858L, 3859L, 3860L, 3861L, 3862L,
3863L, 3864L, 3865L, 3866L, 3867L, 3868L, 3869L, 3870L, 3871L,
3872L, 3873L, 3874L, 3875L, 3876L, 3877L, 3878L, 3879L, 3880L,
3881L, 3882L, 3883L, 3884L, 3885L, 3886L, 3887L, 3888L, 3889L,
3890L, 3891L, 3892L, 3893L, 3894L, 3895L, 3896L, 3897L, 3898L,
3899L, 3900L, 3901L, 3902L, 3903L, 3904L, 3905L, 3906L, 3907L,
3908L, 3909L, 3910L, 3911L, 3912L, 3913L, 3914L, 3915L, 3916L,
3917L, 3918L, 3919L, 3920L, 3921L, 3922L, 3923L, 3924L, 3925L,
3926L, 3927L, 3928L, 3929L, 3930L, 3931L, 3932L, 3933L, 3934L,
3935L, 3936L, 3937L, 3938L, 3939L, 3940L, 3941L, 3942L, 3943L,
3944L, 3945L, 3946L, 3947L, 3948L, 3949L, 3950L, 3951L, 3952L,
3953L, 3954L, 3955L, 3956L, 3957L, 3958L, 3959L, 3960L, 3961L,
3962L, 3963L, 3964L, 3965L, 3966L, 3967L, 3968L, 3969L, 3970L,
3971L, 3972L, 3973L, 3974L, 3975L, 3976L, 3977L, 3978L, 3979L,
3980L, 3981L, 3982L, 3983L, 3984L, 3985L, 3986L, 3987L, 3988L,
3989L, 3990L, 3991L, 3992L, 3993L, 3994L, 3995L, 3996L, 3997L,
3998L, 3999L, 4000L, 4001L, 4002L, 4003L, 4004L, 4005L, 4006L,
4007L, 4008L, 4009L, 4010L, 4011L, 4012L, 4013L, 4014L, 4015L,
4016L, 4017L, 4018L, 4145L, 4163L, 4559L, 4752L, 5115L, 5116L,
5117L, 5118L, 5119L, 5120L, 5121L, 5122L, 5123L, 5124L, 5125L,
5126L, 5127L, 5128L, 5129L, 5130L, 5131L, 5132L, 5133L, 5134L,
5135L, 5136L, 5137L, 5138L, 5139L, 5140L, 5141L, 5142L, 5143L,
5144L, 5145L, 5146L, 5147L, 5148L, 5149L, 5150L, 5151L, 5152L,
5153L, 5154L, 5155L, 5156L, 5157L, 5158L, 5159L, 5160L, 5161L,
5162L, 5163L, 5164L, 5165L, 5166L, 5167L, 5168L, 5169L, 5170L,
5171L, 5172L, 5173L, 5174L, 5175L, 5176L, 5177L, 5178L, 5179L,
5180L, 5181L, 5182L, 5183L, 5184L, 5185L, 5186L, 5187L, 5188L,
5189L, 5190L, 5191L, 5192L, 5193L, 5194L, 5195L, 5196L, 5197L,
5198L, 5199L, 5200L, 5201L, 5202L, 5203L, 5204L, 5205L, 5206L,
5207L, 5208L, 5209L, 5210L, 5211L, 5212L, 5213L, 5214L, 5215L,
5216L, 5217L, 5218L, 5219L, 5220L, 5221L, 5222L, 5223L, 5224L,
5225L, 5226L, 5227L, 5228L, 5229L, 5230L, 5231L, 5232L, 5233L,
5234L, 5235L, 5236L, 5237L, 5238L, 5239L, 5240L, 5241L, 5242L,
5243L, 5244L, 5245L, 5246L, 5247L, 5248L, 5249L, 5250L, 5251L,
5252L, 5253L, 5254L, 5255L, 5256L, 5257L, 5258L, 5259L, 5260L,
5261L, 5262L, 5263L, 5264L, 5265L, 5266L, 5267L, 5268L, 5269L,
5270L, 5271L, 5272L, 5273L, 5274L, 5275L, 5276L, 5277L, 5278L,
5279L, 5280L, 5281L, 5282L, 5283L, 5284L, 5285L, 5286L, 5287L,
5288L, 5289L, 5290L, 5291L, 5292L, 5293L, 5294L, 5295L, 5296L,
5297L, 5298L, 5299L, 5300L, 5301L, 5302L, 5303L, 5304L, 5305L,
5306L, 5307L, 5308L, 5309L, 5310L, 5311L, 5312L, 5313L, 5314L,
5315L, 5316L, 5317L, 5318L, 5319L, 5320L, 5321L, 5322L, 5323L,
5324L, 5325L, 5326L, 5327L, 5328L, 5329L, 5330L, 5331L, 5332L,
5333L, 5334L, 5335L, 5336L, 5337L, 5338L, 5339L, 5340L, 5341L,
5342L, 5343L, 5344L, 5345L, 5346L, 5347L, 5348L, 5349L, 5350L,
5351L, 5352L, 5353L, 5354L, 5355L, 5356L, 5357L, 5358L, 5359L,
5360L, 5361L, 5362L, 5363L, 5364L, 5365L, 5366L, 5367L, 5368L,
5369L, 5370L, 5371L, 5372L, 5373L, 5374L, 5375L, 5376L, 5377L,
5378L, 5379L, 5380L, 5381L, 5382L, 5383L, 5384L, 5385L, 5386L,
5387L, 5388L, 5389L, 5390L, 5391L, 5392L, 5393L, 5394L, 5395L,
5396L, 5397L, 5398L, 5399L, 5400L, 5401L, 5402L, 5403L, 5404L,
5405L, 5406L, 5407L, 5408L, 5409L, 5410L, 5411L, 5412L, 5413L,
5414L, 5415L, 5416L, 5417L, 5418L, 5419L, 5420L, 5421L, 5422L,
5423L, 5424L, 5425L, 5426L, 5427L, 5428L, 5429L, 5430L, 5431L,
5432L, 5433L, 5434L, 5435L, 5436L, 5437L, 5438L, 5439L, 5440L,
5441L, 5442L, 5443L, 5444L, 5445L, 5446L, 5447L, 5448L, 5449L,
5450L, 5451L, 5452L, 5453L, 5454L, 5455L, 5456L, 5457L, 5458L,
5459L, 5460L, 5461L, 5462L, 5463L, 5464L, 5465L, 5466L, 5467L,
5468L, 5469L, 5470L, 5471L, 5472L, 5473L, 5474L, 5475L, 5476L,
5477L, 5478L, 5479L, 5784L, 5832L, 5867L, 5892L, 6136L, 6140L,
6148L, 6213L, 6214L, 6461L, 6510L, 6761L, 6762L, 6763L, 6764L,
6765L, 6778L, 6779L, 6780L, 6781L, 6782L, 6783L, 6784L, 6785L,
6786L, 6787L, 6788L, 6789L, 6790L, 6791L, 6792L, 6793L, 6795L,
6797L, 6798L, 6799L, 6800L, 6801L, 6802L, 6803L, 6804L, 6806L,
6807L, 6808L, 6809L, 6810L, 6811L, 6812L, 6813L, 6814L, 6815L,
6816L, 6817L, 6818L, 6819L, 6820L, 6821L, 6822L, 6823L, 6824L,
6825L, 6826L, 6827L, 6828L, 6829L, 6830L, 6831L, 6832L, 6833L,
6834L, 6835L, 6836L, 6837L, 6838L, 6839L, 6840L, 6841L, 6842L,
6843L, 6844L, 6845L, 6846L, 6847L, 6848L, 6851L, 6855L, 6856L,
6857L, 6862L, 6864L, 6865L, 6866L, 6867L, 6873L, 6882L, 6910L,
6911L, 6912L, 6913L, 6914L, 6915L, 6916L, 6917L, 6918L, 6919L,
6920L, 6921L, 6922L, 6923L, 6924L, 6925L, 6926L, 6927L, 6928L,
6929L, 6930L, 6931L, 6932L, 6933L, 6934L, 6935L, 6936L, 6937L,
6938L, 6939L, 6940L, 6941L, 6942L, 6943L, 6944L, 6945L, 6946L,
6947L, 6948L, 6949L, 6950L, 6951L, 6952L, 6953L, 6954L, 6955L,
6956L, 6957L, 6958L, 6959L, 6960L, 6961L, 6962L, 6963L, 6964L,
6965L, 6966L, 6967L, 6968L, 6969L, 6970L, 6971L, 6972L, 6973L,
6974L, 6975L, 6976L, 6977L, 6978L, 6979L, 6980L, 6981L, 6982L,
6983L, 6984L, 6985L, 6986L, 6987L, 6988L, 6989L, 6990L, 6991L,
6993L, 6994L, 6995L, 6996L, 6997L, 6998L, 6999L, 7000L, 7001L,
7002L, 7003L, 7004L, 7005L, 7006L, 7007L, 7008L, 7009L, 7010L,
7011L, 7012L, 7013L, 7014L, 7015L, 7016L, 7017L, 7018L, 7019L,
7020L, 7021L, 7022L, 7023L, 7024L, 7025L, 7026L, 7027L, 7028L,
7029L, 7030L, 7031L, 7032L, 7033L, 7034L, 7035L, 7036L, 7037L,
7038L, 7039L, 7040L, 7041L, 7042L, 7043L, 7044L, 7045L, 7046L,
7047L, 7048L, 7049L, 7050L, 7051L, 7052L, 7053L, 7054L, 7055L,
7056L, 7057L, 7058L, 7059L, 7060L, 7061L, 7062L, 7063L, 7064L,
7065L, 7066L, 7067L, 7068L, 7069L, 7070L, 7071L, 7072L, 7073L,
7074L, 7075L, 7076L, 7077L, 7078L, 7079L, 7080L, 7081L, 7082L,
7083L, 7084L, 7085L, 7086L, 7087L, 7088L, 7089L, 7090L, 7091L,
7092L, 7093L, 7094L, 7095L, 7096L, 7097L, 7098L, 7099L, 7100L,
7101L, 7102L, 7103L, 7104L, 7105L, 7106L, 7107L, 7108L, 7109L,
7110L, 7111L, 7112L, 7113L, 7114L, 7115L, 7116L, 7117L, 7118L,
7119L, 7120L, 7121L, 7122L, 7123L, 7124L, 7125L, 7126L, 7127L,
7128L, 7129L, 7130L, 7131L, 7132L, 7133L, 7134L, 7135L, 7136L,
7137L, 7138L, 7139L, 7140L, 7141L, 7142L, 7143L, 7144L, 7145L,
7146L, 7147L, 7148L, 7149L, 7150L, 7151L, 7152L, 7153L, 7154L,
7155L, 7156L, 7157L, 7158L, 7159L, 7160L, 7161L, 7162L, 7163L,
7164L, 7165L, 7166L, 7167L, 7168L, 7169L, 7170L, 7171L, 7172L,
7173L, 7174L, 7175L, 7176L, 7177L, 7178L, 7179L, 7180L, 7181L,
7182L, 7183L, 7184L, 7185L, 7186L, 7187L, 7188L, 7189L, 7190L,
7191L, 7192L, 7193L, 7194L, 7195L, 7196L, 7197L, 7198L, 7199L,
7200L, 7201L, 7202L, 7203L, 7204L, 7205L, 7206L, 7207L, 7208L,
7209L, 7210L, 7211L, 7212L, 7213L, 7214L, 7215L, 7216L, 7217L,
7218L, 7219L, 7220L, 7221L, 7222L, 7223L, 7224L, 7225L, 7226L,
7227L, 7228L, 7229L, 7230L, 7231L, 7232L, 7233L, 7234L, 7235L,
7236L, 7237L, 7238L, 7239L, 7240L, 7241L, 7242L, 7243L, 7244L,
7245L, 7246L, 7247L, 7248L, 7249L, 7250L, 7251L, 7252L, 7253L,
7254L, 7255L, 7256L, 7257L, 7258L, 7259L, 7260L, 7261L, 7262L,
7263L, 7264L, 7265L, 7266L, 7267L, 7268L, 7269L, 7270L, 7271L,
7272L, 7273L, 7274L, 7275L, 7276L, 7277L, 7278L, 7279L, 7280L,
7281L, 7282L, 7283L, 7284L, 7285L, 7286L, 7287L, 7288L, 7289L,
7290L, 7291L, 7292L, 7293L, 7294L, 7295L, 7296L, 7297L, 7298L,
7299L, 7300L, 7301L, 7302L, 7303L, 7304L, 7305L, 7306L, 7307L,
7308L, 7309L, 7310L, 7311L, 7312L, 7313L, 7314L, 7315L, 7316L,
7317L, 7318L, 7319L, 7320L, 7321L, 7322L, 7323L, 7324L, 7325L,
7326L, 7327L, 7328L, 7329L, 7330L, 7331L, 7332L, 7333L, 7334L,
7335L, 7336L, 7337L, 7338L, 7339L, 7340L, 7341L, 7342L, 7343L,
7344L, 7345L, 7346L, 7347L, 7348L, 7349L, 7350L, 7351L, 7352L,
7353L, 7354L, 7355L, 7356L, 7357L, 7358L, 7359L, 7360L, 7361L,
7362L, 7363L, 7364L, 7365L, 7366L, 7367L, 7368L, 7369L, 7370L,
7371L, 7372L, 7373L, 7374L, 7375L, 7376L, 7377L, 7378L, 7379L,
7380L, 7381L, 7382L, 7383L, 7384L, 7385L, 7386L, 7387L, 7388L,
7389L, 7390L, 7391L, 7392L, 7393L, 7394L, 7395L, 7396L, 7397L,
7398L, 7399L, 7400L, 7401L, 7402L, 7403L, 7404L, 7405L, 7406L,
7407L, 7408L, 7409L, 7410L, 7411L, 7412L, 7413L, 7414L, 7415L,
7416L, 7417L, 7418L, 7419L, 7420L, 7421L, 7422L, 7423L, 7424L,
7425L, 7426L, 7427L, 7428L, 7429L, 7430L, 7431L, 7432L, 7433L,
7434L, 7435L, 7436L, 7437L, 7438L, 7439L, 7440L, 7441L, 7442L,
7443L, 7444L, 7445L, 7446L, 7447L, 7448L, 7449L, 7450L, 7451L,
7452L, 7453L, 7454L, 7455L, 7456L, 7457L, 7458L, 7459L, 7460L,
7461L, 7462L, 7463L, 7464L, 7465L, 7466L, 7467L, 7468L, 7469L,
7470L, 7471L, 7472L, 7473L, 7474L, 7475L, 7476L, 7477L, 7478L,
7479L, 7480L, 7481L, 7482L, 7483L, 7484L, 7485L, 7486L, 7487L,
7488L, 7489L, 7490L, 7491L, 7492L, 7493L, 7494L, 7495L, 7496L,
7497L, 7498L, 7499L, 7500L, 7501L, 7502L, 7503L, 7504L, 7505L,
7506L, 7507L, 7508L, 7509L, 7510L, 7511L, 7512L, 7513L, 7514L,
7515L, 7516L, 7517L, 7518L, 7519L, 7520L, 7521L, 7522L, 7523L,
7524L, 7525L, 7526L, 7527L, 7528L, 7529L, 7530L, 7531L, 7532L,
7533L, 7534L, 7535L, 7536L, 7537L, 7538L, 7539L, 7540L, 7541L,
7542L, 7543L, 7544L, 7545L, 7546L, 7547L, 7548L, 7549L, 7550L,
7551L, 7552L, 7553L, 7554L, 7555L, 7556L, 7557L, 7558L, 7559L,
7560L, 7561L, 7562L, 7563L, 7564L, 7565L, 7566L, 7567L, 7568L,
7569L, 7570L, 7571L, 7572L, 7573L, 7574L, 7575L, 7576L, 7577L,
7578L, 7579L, 7580L, 7581L, 7582L, 7583L, 7584L, 7585L, 7586L,
7587L, 7588L, 7589L, 7590L, 7591L, 7592L, 7593L, 7594L, 7595L,
7596L, 7597L, 7598L, 7599L, 7600L, 7601L, 7602L, 7603L, 7604L,
7605L, 7606L, 7607L, 7608L, 7609L, 7610L, 7611L, 7612L, 7613L,
7614L, 7615L, 7616L, 7617L, 7618L, 7619L, 7620L, 7621L, 7622L,
7623L, 7624L, 7625L, 7626L, 7627L, 7628L, 7629L, 7630L, 7631L,
7632L, 7633L, 7634L, 7635L, 7636L, 7637L, 7638L, 7639L, 7640L,
7641L, 7642L, 7643L, 7644L, 7645L, 7646L, 7647L, 7648L, 7649L,
7650L, 7651L, 7652L, 7653L, 7654L, 7655L, 7656L, 7657L, 7658L,
7659L, 7660L, 7661L, 7662L, 7663L, 7664L, 7665L, 7666L, 7667L,
7668L, 7669L, 7670L, 7671L, 7672L, 7673L, 7674L, 7675L, 7676L,
7677L, 7678L, 7679L, 7680L, 7681L, 7682L, 7683L, 7684L, 7685L,
7686L, 7687L, 7688L, 7689L, 7690L, 7691L, 7692L, 7693L, 7694L,
7695L, 7696L, 7697L, 7698L, 7699L, 7700L, 7701L, 7702L, 7703L,
7704L, 7705L, 7706L, 7707L, 7708L, 7709L, 7710L, 7711L, 7712L,
7713L, 7714L, 7715L, 7716L, 7717L, 7718L, 7719L, 7720L, 7721L,
7722L, 7723L, 7724L, 7725L, 7726L, 7727L, 7728L, 7729L, 7730L,
7731L, 7732L, 7733L, 7734L, 7735L, 7736L, 7737L, 7738L, 7739L,
7740L, 7741L, 7742L, 7743L, 7744L, 7745L, 7746L, 7747L, 7748L,
7749L, 7750L, 7751L, 7752L, 7753L, 7754L, 7755L, 7756L, 7757L,
7758L, 7759L, 7760L, 7761L, 7762L, 7763L, 7764L, 7765L, 7766L,
7767L, 7768L, 7769L, 7770L, 7771L, 7772L, 7773L, 7774L, 7775L,
7776L, 7777L, 7778L, 7779L, 7780L, 7781L, 7782L, 7783L, 7784L,
7785L, 7786L, 7787L, 7788L, 7789L, 7790L, 7791L, 7792L, 7793L,
7794L, 7795L, 7796L, 7797L, 7798L, 7799L, 7800L, 7801L, 7802L,
7803L, 7804L, 7805L, 7806L, 7807L, 7808L, 7809L, 7810L, 7811L,
7812L, 7813L, 7814L, 7815L, 7816L, 7817L, 7818L, 7819L, 7820L,
7821L, 7822L, 7823L, 7824L, 7825L, 7826L, 7827L, 7828L, 7829L,
7830L, 7831L, 7832L, 7833L, 7834L, 7835L, 7836L, 7837L, 7838L,
7839L, 7840L, 7841L, 7842L, 7843L, 7844L, 7845L, 7846L, 7847L,
7848L, 7849L, 7850L, 7851L, 7852L, 7853L, 7854L, 7855L, 7856L,
7857L, 7858L, 7859L, 7860L, 7861L, 7862L, 7863L, 7864L, 7865L,
7866L, 7867L, 7868L, 7869L, 7870L, 7871L, 7872L, 7873L, 7874L,
7875L, 7876L, 7877L, 7878L, 7879L, 7880L, 7881L, 7882L, 7883L,
7884L, 7885L, 7886L, 7887L, 7888L, 7889L, 7890L, 7891L, 7892L,
7893L, 7894L, 7895L, 7896L, 7897L, 7898L, 7899L, 7900L, 7901L,
7902L, 7903L, 7904L, 7905L, 7906L, 7907L, 7908L, 7909L, 7910L,
7911L, 7912L, 7913L, 7914L, 7915L, 7916L, 7917L, 7918L, 7919L,
7920L, 7921L, 7922L, 7923L, 7924L, 7925L, 7926L, 7927L, 7928L,
7929L, 7930L, 7931L, 7932L, 7933L, 7934L, 7935L, 7936L, 7937L,
7938L, 7939L, 7940L, 7941L, 7942L, 7943L, 7944L, 7945L, 7946L,
7947L, 7948L, 7949L, 7950L, 7951L, 7952L, 7953L, 7954L, 7955L,
7956L, 7957L, 7958L, 7959L, 7960L, 7961L, 7962L, 7963L, 7964L,
7965L, 7966L, 7967L, 7968L, 7969L, 7970L, 7971L, 7972L, 7973L,
7974L, 7975L, 7976L, 7977L, 7978L, 7979L, 7980L, 7981L, 7982L,
7983L, 7984L, 7985L, 7986L, 7987L, 7988L, 7989L, 7990L, 7991L,
7992L, 7993L, 7994L, 7995L, 7996L, 7997L, 7998L, 7999L, 8000L,
8001L, 8002L, 8003L, 8004L, 8005L, 8006L, 8007L, 8008L, 8009L,
8010L, 8011L, 8012L, 8013L, 8014L, 8015L, 8016L, 8017L, 8018L,
8019L, 8020L, 8021L, 8022L, 8023L, 8024L, 8025L, 8026L, 8027L,
8028L, 8029L, 8030L, 8031L, 8032L, 8033L, 8034L, 8035L, 8036L,
8037L, 8038L, 8039L, 8040L, 8041L, 8042L, 8043L, 8044L, 8045L,
8046L, 8047L, 8048L, 8049L, 8050L, 8051L, 8052L, 8053L, 8054L,
8055L, 8056L, 8057L, 8058L, 8059L, 8060L, 8061L, 8062L, 8063L,
8064L, 8065L, 8066L, 8067L, 8068L, 8069L, 8070L, 8071L, 8072L,
8073L, 8074L, 8075L, 8076L, 8077L, 8078L, 8079L, 8080L, 8081L,
8082L, 8083L, 8084L, 8085L, 8086L, 8087L, 8088L, 8089L, 8090L,
8091L, 8092L, 8093L, 8094L, 8095L, 8096L, 8097L, 8098L, 8099L,
8100L, 8101L, 8102L, 8103L, 8104L, 8105L, 8106L, 8107L, 8108L,
8109L, 8110L, 8111L, 8112L, 8113L, 8114L, 8115L, 8116L, 8117L,
8118L, 8119L, 8120L, 8121L, 8122L, 8123L, 8124L, 8125L, 8126L,
8127L, 8128L, 8129L, 8130L, 8131L, 8132L, 8133L, 8134L, 8135L,
8136L, 8137L, 8138L, 8139L, 8140L, 8141L, 8142L, 8143L, 8144L,
8145L, 8146L, 8147L, 8148L, 8149L, 8150L, 8151L, 8152L, 8153L,
8154L, 8155L, 8156L, 8157L, 8158L, 8159L, 8160L, 8161L, 8162L,
8163L, 8164L, 8165L, 8166L, 8167L, 8168L, 8169L, 8170L, 8171L,
8172L, 8173L, 8174L, 8175L, 8176L, 8177L, 8178L, 8179L, 8180L,
8181L, 8182L, 8183L, 8184L, 8185L, 8186L, 8187L, 8188L, 8189L,
8190L, 8191L, 8192L, 8193L, 8194L, 8195L, 8196L, 8197L, 8198L,
8199L, 8200L, 8201L, 8202L, 8203L, 8204L, 8205L, 8206L, 8207L,
8208L, 8209L, 8210L, 8211L, 8212L, 8213L, 8214L, 8215L, 8216L,
8217L, 8218L, 8219L, 8220L, 8221L, 8222L, 8223L, 8224L, 8225L,
8226L, 8227L, 8228L, 8229L, 8230L, 8231L, 8232L, 8233L, 8234L,
8235L, 8236L, 8237L, 8238L, 8239L, 8240L, 8241L, 8242L, 8243L,
8244L, 8245L, 8246L, 8247L, 8248L, 8461L, 8462L, 8463L, 8464L,
8465L, 8466L, 8467L, 8468L, 8469L, 8470L, 8471L, 8472L, 8473L,
8474L, 8475L, 8476L, 8477L, 8478L, 8479L, 8480L, 8481L, 8482L,
8483L, 8484L, 8485L, 8486L, 8487L, 8488L, 8489L, 8490L, 8491L,
8687L, 8688L, 8689L, 8690L, 8691L, 8692L, 8693L, 8694L, 8695L,
8696L, 8697L, 8698L, 8699L, 8700L, 8701L, 8702L, 8703L, 8704L,
8705L, 8706L, 8707L, 8708L, 8709L, 8710L, 8711L, 8712L, 8713L,
8714L, 8715L, 8716L, 8717L, 8718L, 8719L, 8720L, 8721L, 8722L,
8723L, 8724L, 8725L, 8726L, 8727L, 8728L, 8729L, 8730L, 8731L,
8732L, 8733L, 8734L, 8735L, 8736L, 8737L, 8738L, 8739L, 8740L,
8741L, 8742L, 8743L, 8744L, 8745L, 8746L, 8747L, 8748L, 8749L,
8750L, 8751L, 8752L, 8753L, 8754L, 8755L, 8756L, 8757L, 8758L,
8759L, 8760L, 8761L, 8762L, 8763L, 8764L, 8765L, 8766L, 8767L,
8768L, 8769L, 8770L, 8771L, 8772L, 8773L, 8774L, 8775L, 8776L,
8777L, 8778L, 8779L, 8780L, 8781L, 8782L, 8783L, 8784L, 8785L,
8786L, 8787L, 8788L, 8789L, 8790L, 8791L, 8792L, 8793L, 8794L,
8795L, 8796L, 8797L, 8798L, 8799L, 8800L, 8801L, 8802L, 8803L,
8804L, 8805L, 8806L, 8807L, 8808L, 8809L, 8810L, 8811L, 8812L,
8813L, 8814L, 8815L, 8816L, 8817L, 8818L, 8819L, 8820L, 8821L,
8822L, 8823L, 8824L, 8825L, 8826L, 8827L, 8828L, 8829L, 8830L,
8831L, 8832L, 8833L, 8834L, 8835L, 8836L, 8837L, 8838L, 8839L,
8840L, 8841L, 8842L, 8843L, 8844L, 8845L, 8846L, 8847L, 8848L,
8849L, 8850L, 8851L, 8852L, 8853L, 8854L, 8855L, 8856L, 8857L,
8858L, 8859L, 8860L, 8861L, 8862L, 8863L, 8864L, 8865L, 8866L,
8867L, 8868L, 8869L, 8870L, 8871L, 8872L, 8873L, 8874L, 8875L,
8876L, 8877L, 8878L, 8879L, 8880L, 8881L, 8882L, 8883L, 8884L,
8885L, 8886L, 8887L, 8888L, 8889L, 8890L, 8891L, 8892L, 8893L,
8894L, 8895L, 8896L, 8897L, 8898L, 8899L, 8900L, 8901L, 8902L,
8903L, 8904L, 8905L, 8906L, 8907L, 8908L, 8909L, 8910L, 8911L,
8912L, 8913L, 8914L, 8915L, 8916L, 8917L, 8918L, 8919L, 8920L,
8921L, 8922L, 8923L, 8924L, 8925L, 8926L, 8927L, 8928L, 8929L,
8930L, 8931L, 8932L, 8933L, 8934L, 8935L, 8936L, 8937L, 8938L,
8939L, 8940L, 8941L, 8942L, 8943L, 8944L, 8945L, 8946L, 8947L,
8948L, 8949L, 8950L, 8951L, 8952L, 8953L, 8954L, 8955L, 8956L,
8957L, 8958L, 8959L, 8960L, 8961L, 8962L, 8963L, 8964L, 8965L,
8966L, 8967L, 8968L, 8969L, 8970L, 8971L, 8972L, 8973L, 8974L,
8975L, 8976L, 8977L, 8978L, 8979L, 8980L, 8981L, 8982L, 8983L,
8984L, 8985L, 8986L, 8987L, 8988L, 8989L, 8990L, 8991L, 8992L,
8993L, 8994L, 8995L, 8996L, 8997L, 8998L, 8999L, 9000L, 9001L,
9002L, 9003L, 9004L, 9005L, 9006L, 9007L, 9008L, 9009L, 9010L,
9011L, 9012L, 9013L, 9014L, 9015L, 9016L, 9017L, 9018L, 9019L,
9020L, 9021L, 9022L, 9023L, 9024L, 9025L, 9026L, 9027L, 9028L,
9029L, 9030L, 9031L, 9032L, 9033L, 9034L, 9035L, 9036L, 9037L,
9038L, 9039L, 9040L, 9041L, 9042L, 9043L, 9044L, 9045L, 9046L,
9047L, 9048L, 9049L, 9050L, 9051L, 9052L, 9053L, 9054L, 9055L,
9056L, 9057L, 9058L, 9059L, 9060L, 9061L, 9062L, 9063L, 9064L,
9065L, 9066L, 9067L, 9068L, 9069L, 9070L, 9071L, 9072L, 9073L,
9074L, 9075L, 9076L, 9077L, 9078L, 9079L, 9080L, 9081L, 9082L,
9083L, 9084L, 9085L, 9086L, 9087L, 9088L, 9089L, 9090L, 9091L,
9092L, 9093L, 9094L, 9095L, 9096L, 9097L, 9098L, 9099L, 9100L,
9101L, 9102L, 9103L, 9104L, 9105L, 9106L, 9107L, 9108L, 9109L,
9110L, 9111L, 9112L, 9113L, 9114L, 9115L, 9116L, 9117L, 9118L,
9119L, 9120L, 9121L, 9122L, 9123L, 9124L, 9125L, 9126L, 9127L,
9128L, 9129L, 9130L, 9131L, 9132L, 9133L, 9134L, 9135L, 9136L,
9137L, 9138L, 9139L, 9140L, 9141L, 9142L, 9143L, 9144L, 9145L,
9146L, 9147L, 9148L, 9149L, 9150L, 9151L, 9152L, 9153L, 9154L,
9155L, 9156L, 9157L, 9158L, 9159L, 9160L, 9161L, 9162L, 9163L,
9164L, 9165L, 9166L, 9167L, 9168L, 9169L, 9170L, 9171L, 9172L,
9173L, 9174L, 9175L, 9176L, 9177L, 9178L, 9179L, 9180L, 9181L,
9182L, 9183L, 9184L, 9185L, 9186L, 9187L, 9188L, 9189L, 9190L,
9191L, 9192L, 9193L, 9194L, 9195L, 9196L, 9197L, 9198L, 9199L,
9200L, 9201L, 9202L, 9203L, 9204L, 9205L, 9206L, 9207L, 9208L,
9209L, 9210L, 9211L, 9212L, 9213L, 9214L, 9215L, 9216L, 9217L,
9218L, 9219L, 9220L, 9221L, 9222L, 9223L, 9224L, 9225L, 9226L,
9227L, 9228L, 9229L, 9230L, 9231L, 9232L, 9233L, 9234L, 9235L,
9236L, 9237L, 9238L, 9239L, 9240L, 9241L, 9242L, 9243L, 9244L,
9245L, 9246L, 9247L, 9248L, 9249L, 9250L, 9251L, 9252L, 9253L,
9254L, 9255L, 9256L, 9257L, 9258L, 9259L, 9260L, 9261L, 9262L,
9263L, 9264L, 9265L, 9266L, 9267L, 9268L, 9269L, 9270L, 9271L,
9272L, 9273L, 9274L, 9275L, 9276L, 9277L, 9278L, 9279L, 9280L,
9281L, 9282L, 9283L, 9284L, 9285L, 9286L, 9287L, 9288L, 9289L,
9290L, 9291L, 9292L, 9293L, 9294L, 9295L, 9296L, 9297L, 9298L,
9299L, 9300L, 9301L, 9302L, 9303L, 9304L, 9305L, 9306L, 9307L,
9308L, 9309L, 9310L, 9311L, 9312L, 9313L, 9314L, 9315L, 9316L,
9317L, 9318L, 9319L, 9320L, 9321L, 9322L, 9323L, 9324L, 9325L,
9326L, 9327L, 9328L, 9329L, 9330L, 9331L, 9332L, 9333L, 9334L,
9335L, 9336L, 9337L, 9338L, 9339L, 9340L, 9341L, 9342L, 9343L,
9344L, 9345L, 9346L, 9347L, 9348L, 9349L, 9350L, 9351L, 9352L,
9353L, 9354L, 9355L, 9356L, 9357L, 9358L, 9359L, 9360L, 9361L,
9362L, 9363L, 9364L, 9365L, 9366L, 9367L, 9368L, 9369L, 9370L,
9371L, 9372L, 9373L, 9374L, 9375L, 9376L, 9377L, 9378L, 9379L,
9380L, 9381L, 9382L, 9383L, 9384L, 9385L, 9386L, 9387L, 9388L,
9389L, 9390L, 9391L, 9392L, 9393L, 9394L, 9395L, 9396L, 9397L,
9398L, 9399L, 9400L, 9401L, 9402L, 9403L, 9404L, 9405L, 9406L,
9407L, 9408L, 9409L, 9410L, 9411L, 9412L, 9413L, 9414L, 9415L,
9416L, 9417L, 9418L, 9419L, 9420L, 9421L, 9422L, 9423L, 9424L,
9425L, 9426L, 9427L, 9428L, 9429L, 9430L, 9431L, 9432L, 9433L,
9434L, 9435L, 9436L, 9437L, 9438L, 9439L, 9440L, 9441L, 9442L,
9443L, 9444L, 9445L, 9446L, 9447L, 9448L, 9449L, 9450L, 9451L,
9452L, 9453L, 9454L, 9455L, 9456L, 9457L, 9458L, 9459L, 9460L,
9461L, 9462L, 9463L, 9464L, 9465L, 9466L, 9467L, 9468L, 9469L,
9470L, 9471L, 9472L, 9473L, 9474L, 9475L, 9476L, 9477L, 9478L,
9479L, 9480L, 9481L, 9482L, 9483L, 9484L, 9485L, 9486L, 9487L,
9488L, 9489L, 9490L, 9491L, 9492L, 9493L, 9494L, 9495L, 9496L,
9497L), .Names = c("257", "325", "326", "393", "424", "425",
"428", "436", "564", "632", "635", "636", "647", "747", "778",
"790", "822", "823", "852", "853", "884", "886", "910", "911",
"912", "913", "914", "915", "927", "945", "999", "1019", "1054",
"1156", "1398", "1445", "1468", "1489", "1667", "1742", "1754",
"1766", "1819", "1822", "1973", "2142", "2162", "2163", "2164",
"2165", "2166", "2167", "2168", "2169", "2170", "2171", "2172",
"2173", "2174", "2175", "2176", "2177", "2178", "2179", "2180",
"2181", "2182", "2183", "2184", "2185", "2186", "2187", "2188",
"2189", "2190", "2191", "2192", "2283", "2316", "2420", "2469",
"2478", "2484", "2603", "2627", "2831", "2832", "2833", "2834",
"2835", "2836", "2837", "2838", "2839", "2840", "2841", "2842",
"2843", "2844", "2845", "2846", "2847", "2848", "2849", "2850",
"2851", "2852", "2853", "2854", "2855", "2856", "2857", "2858",
"2859", "2860", "2861", "2862", "2863", "2864", "2865", "2866",
"2867", "2868", "2869", "2870", "2871", "2872", "2873", "2874",
"2875", "2876", "2877", "2878", "2879", "2880", "2881", "2882",
"2883", "2884", "2885", "2886", "2887", "2888", "2889", "2890",
"2891", "2892", "2893", "2894", "2895", "2896", "2897", "2898",
"2899", "2900", "2901", "2902", "2903", "2904", "2905", "2906",
"2907", "2908", "2909", "2910", "2911", "2912", "2913", "2914",
"2915", "2916", "2917", "2918", "2919", "2920", "2921", "2922",
"2923", "2924", "2925", "2926", "2927", "2928", "2929", "2930",
"2931", "2932", "2933", "2934", "2935", "2936", "2937", "2938",
"2939", "2940", "2941", "2942", "2943", "2944", "2945", "2946",
"2947", "2948", "2949", "2950", "2951", "2952", "2953", "2954",
"2955", "2956", "2957", "2958", "2959", "2960", "2961", "2962",
"2963", "2964", "2965", "2966", "2967", "2968", "2969", "2970",
"2971", "2972", "2973", "2974", "2975", "2976", "2977", "2978",
"2979", "2980", "2981", "2982", "2983", "2984", "2985", "2986",
"2987", "2988", "2989", "2990", "2991", "2992", "2993", "2994",
"2995", "2996", "2997", "2998", "2999", "3000", "3001", "3002",
"3003", "3004", "3005", "3006", "3007", "3008", "3009", "3010",
"3011", "3012", "3013", "3014", "3015", "3016", "3017", "3018",
"3019", "3020", "3021", "3022", "3023", "3024", "3025", "3026",
"3027", "3028", "3029", "3030", "3031", "3032", "3033", "3034",
"3035", "3036", "3037", "3038", "3039", "3040", "3041", "3042",
"3043", "3044", "3045", "3046", "3047", "3048", "3049", "3050",
"3051", "3052", "3053", "3054", "3055", "3056", "3057", "3058",
"3059", "3060", "3061", "3062", "3063", "3064", "3065", "3066",
"3067", "3068", "3069", "3070", "3071", "3072", "3073", "3074",
"3075", "3076", "3077", "3078", "3079", "3080", "3081", "3082",
"3083", "3084", "3085", "3086", "3087", "3088", "3089", "3090",
"3091", "3092", "3093", "3094", "3095", "3096", "3097", "3098",
"3099", "3100", "3101", "3102", "3103", "3104", "3105", "3106",
"3107", "3108", "3109", "3110", "3111", "3112", "3113", "3114",
"3115", "3116", "3117", "3118", "3119", "3120", "3121", "3122",
"3123", "3124", "3125", "3126", "3127", "3128", "3129", "3130",
"3131", "3132", "3133", "3134", "3135", "3136", "3137", "3138",
"3139", "3140", "3141", "3142", "3143", "3144", "3145", "3146",
"3147", "3148", "3149", "3150", "3151", "3152", "3153", "3154",
"3155", "3156", "3157", "3158", "3159", "3160", "3161", "3162",
"3163", "3164", "3165", "3166", "3167", "3168", "3169", "3170",
"3171", "3172", "3173", "3174", "3175", "3176", "3177", "3178",
"3179", "3180", "3181", "3182", "3183", "3184", "3185", "3186",
"3187", "3188", "3189", "3190", "3191", "3192", "3193", "3194",
"3195", "3196", "3197", "3198", "3199", "3200", "3201", "3202",
"3203", "3204", "3205", "3206", "3207", "3208", "3209", "3210",
"3211", "3212", "3213", "3214", "3215", "3216", "3217", "3218",
"3219", "3220", "3221", "3222", "3223", "3224", "3225", "3226",
"3227", "3228", "3229", "3230", "3231", "3232", "3233", "3234",
"3235", "3236", "3237", "3238", "3239", "3240", "3241", "3242",
"3243", "3244", "3245", "3246", "3247", "3248", "3249", "3250",
"3251", "3252", "3253", "3254", "3255", "3256", "3257", "3258",
"3259", "3260", "3261", "3262", "3263", "3264", "3265", "3266",
"3267", "3268", "3269", "3270", "3271", "3272", "3273", "3274",
"3275", "3276", "3277", "3278", "3279", "3280", "3281", "3282",
"3283", "3284", "3285", "3286", "3287", "3288", "3289", "3290",
"3291", "3292", "3293", "3294", "3295", "3296", "3297", "3298",
"3299", "3300", "3301", "3302", "3303", "3304", "3305", "3306",
"3307", "3308", "3309", "3310", "3311", "3312", "3313", "3314",
"3315", "3316", "3317", "3318", "3319", "3532", "3533", "3534",
"3535", "3536", "3537", "3538", "3539", "3540", "3541", "3542",
"3543", "3544", "3545", "3546", "3547", "3548", "3549", "3550",
"3551", "3552", "3553", "3554", "3555", "3556", "3557", "3558",
"3559", "3560", "3561", "3562", "3563", "3564", "3565", "3566",
"3567", "3568", "3569", "3570", "3571", "3572", "3573", "3574",
"3575", "3576", "3577", "3578", "3579", "3580", "3581", "3582",
"3583", "3584", "3585", "3586", "3587", "3588", "3589", "3590",
"3591", "3592", "3593", "3594", "3595", "3596", "3597", "3598",
"3599", "3600", "3601", "3602", "3603", "3604", "3605", "3606",
"3607", "3608", "3609", "3610", "3611", "3612", "3613", "3614",
"3615", "3616", "3617", "3618", "3619", "3620", "3621", "3622",
"3654", "3655", "3656", "3657", "3658", "3659", "3660", "3661",
"3662", "3663", "3664", "3665", "3666", "3667", "3668", "3669",
"3670", "3671", "3672", "3673", "3674", "3675", "3676", "3677",
"3678", "3679", "3680", "3681", "3682", "3683", "3684", "3685",
"3686", "3687", "3688", "3689", "3690", "3691", "3692", "3693",
"3694", "3695", "3696", "3697", "3698", "3699", "3700", "3701",
"3702", "3703", "3704", "3705", "3706", "3707", "3708", "3709",
"3710", "3711", "3712", "3713", "3714", "3715", "3716", "3717",
"3718", "3719", "3720", "3721", "3722", "3723", "3724", "3725",
"3726", "3727", "3728", "3729", "3730", "3731", "3732", "3733",
"3734", "3735", "3736", "3737", "3738", "3739", "3740", "3741",
"3742", "3743", "3744", "3745", "3746", "3747", "3748", "3749",
"3750", "3751", "3752", "3753", "3754", "3755", "3756", "3757",
"3758", "3759", "3760", "3761", "3762", "3763", "3764", "3765",
"3766", "3767", "3768", "3769", "3770", "3771", "3772", "3773",
"3774", "3775", "3776", "3777", "3778", "3779", "3780", "3781",
"3782", "3783", "3784", "3785", "3786", "3787", "3788", "3789",
"3790", "3791", "3792", "3793", "3794", "3795", "3796", "3797",
"3798", "3799", "3800", "3801", "3802", "3803", "3804", "3805",
"3806", "3807", "3808", "3809", "3810", "3811", "3812", "3813",
"3814", "3815", "3816", "3817", "3818", "3819", "3820", "3821",
"3822", "3823", "3824", "3825", "3826", "3827", "3828", "3829",
"3830", "3831", "3832", "3833", "3834", "3835", "3836", "3837",
"3838", "3839", "3840", "3841", "3842", "3843", "3844", "3845",
"3846", "3847", "3848", "3849", "3850", "3851", "3852", "3853",
"3854", "3855", "3856", "3857", "3858", "3859", "3860", "3861",
"3862", "3863", "3864", "3865", "3866", "3867", "3868", "3869",
"3870", "3871", "3872", "3873", "3874", "3875", "3876", "3877",
"3878", "3879", "3880", "3881", "3882", "3883", "3884", "3885",
"3886", "3887", "3888", "3889", "3890", "3891", "3892", "3893",
"3894", "3895", "3896", "3897", "3898", "3899", "3900", "3901",
"3902", "3903", "3904", "3905", "3906", "3907", "3908", "3909",
"3910", "3911", "3912", "3913", "3914", "3915", "3916", "3917",
"3918", "3919", "3920", "3921", "3922", "3923", "3924", "3925",
"3926", "3927", "3928", "3929", "3930", "3931", "3932", "3933",
"3934", "3935", "3936", "3937", "3938", "3939", "3940", "3941",
"3942", "3943", "3944", "3945", "3946", "3947", "3948", "3949",
"3950", "3951", "3952", "3953", "3954", "3955", "3956", "3957",
"3958", "3959", "3960", "3961", "3962", "3963", "3964", "3965",
"3966", "3967", "3968", "3969", "3970", "3971", "3972", "3973",
"3974", "3975", "3976", "3977", "3978", "3979", "3980", "3981",
"3982", "3983", "3984", "3985", "3986", "3987", "3988", "3989",
"3990", "3991", "3992", "3993", "3994", "3995", "3996", "3997",
"3998", "3999", "4000", "4001", "4002", "4003", "4004", "4005",
"4006", "4007", "4008", "4009", "4010", "4011", "4012", "4013",
"4014", "4015", "4016", "4017", "4018", "4145", "4163", "4559",
"4752", "5115", "5116", "5117", "5118", "5119", "5120", "5121",
"5122", "5123", "5124", "5125", "5126", "5127", "5128", "5129",
"5130", "5131", "5132", "5133", "5134", "5135", "5136", "5137",
"5138", "5139", "5140", "5141", "5142", "5143", "5144", "5145",
"5146", "5147", "5148", "5149", "5150", "5151", "5152", "5153",
"5154", "5155", "5156", "5157", "5158", "5159", "5160", "5161",
"5162", "5163", "5164", "5165", "5166", "5167", "5168", "5169",
"5170", "5171", "5172", "5173", "5174", "5175", "5176", "5177",
"5178", "5179", "5180", "5181", "5182", "5183", "5184", "5185",
"5186", "5187", "5188", "5189", "5190", "5191", "5192", "5193",
"5194", "5195", "5196", "5197", "5198", "5199", "5200", "5201",
"5202", "5203", "5204", "5205", "5206", "5207", "5208", "5209",
"5210", "5211", "5212", "5213", "5214", "5215", "5216", "5217",
"5218", "5219", "5220", "5221", "5222", "5223", "5224", "5225",
"5226", "5227", "5228", "5229", "5230", "5231", "5232", "5233",
"5234", "5235", "5236", "5237", "5238", "5239", "5240", "5241",
"5242", "5243", "5244", "5245", "5246", "5247", "5248", "5249",
"5250", "5251", "5252", "5253", "5254", "5255", "5256", "5257",
"5258", "5259", "5260", "5261", "5262", "5263", "5264", "5265",
"5266", "5267", "5268", "5269", "5270", "5271", "5272", "5273",
"5274", "5275", "5276", "5277", "5278", "5279", "5280", "5281",
"5282", "5283", "5284", "5285", "5286", "5287", "5288", "5289",
"5290", "5291", "5292", "5293", "5294", "5295", "5296", "5297",
"5298", "5299", "5300", "5301", "5302", "5303", "5304", "5305",
"5306", "5307", "5308", "5309", "5310", "5311", "5312", "5313",
"5314", "5315", "5316", "5317", "5318", "5319", "5320", "5321",
"5322", "5323", "5324", "5325", "5326", "5327", "5328", "5329",
"5330", "5331", "5332", "5333", "5334", "5335", "5336", "5337",
"5338", "5339", "5340", "5341", "5342", "5343", "5344", "5345",
"5346", "5347", "5348", "5349", "5350", "5351", "5352", "5353",
"5354", "5355", "5356", "5357", "5358", "5359", "5360", "5361",
"5362", "5363", "5364", "5365", "5366", "5367", "5368", "5369",
"5370", "5371", "5372", "5373", "5374", "5375", "5376", "5377",
"5378", "5379", "5380", "5381", "5382", "5383", "5384", "5385",
"5386", "5387", "5388", "5389", "5390", "5391", "5392", "5393",
"5394", "5395", "5396", "5397", "5398", "5399", "5400", "5401",
"5402", "5403", "5404", "5405", "5406", "5407", "5408", "5409",
"5410", "5411", "5412", "5413", "5414", "5415", "5416", "5417",
"5418", "5419", "5420", "5421", "5422", "5423", "5424", "5425",
"5426", "5427", "5428", "5429", "5430", "5431", "5432", "5433",
"5434", "5435", "5436", "5437", "5438", "5439", "5440", "5441",
"5442", "5443", "5444", "5445", "5446", "5447", "5448", "5449",
"5450", "5451", "5452", "5453", "5454", "5455", "5456", "5457",
"5458", "5459", "5460", "5461", "5462", "5463", "5464", "5465",
"5466", "5467", "5468", "5469", "5470", "5471", "5472", "5473",
"5474", "5475", "5476", "5477", "5478", "5479", "5784", "5832",
"5867", "5892", "6136", "6140", "6148", "6213", "6214", "6461",
"6510", "6761", "6762", "6763", "6764", "6765", "6778", "6779",
"6780", "6781", "6782", "6783", "6784", "6785", "6786", "6787",
"6788", "6789", "6790", "6791", "6792", "6793", "6795", "6797",
"6798", "6799", "6800", "6801", "6802", "6803", "6804", "6806",
"6807", "6808", "6809", "6810", "6811", "6812", "6813", "6814",
"6815", "6816", "6817", "6818", "6819", "6820", "6821", "6822",
"6823", "6824", "6825", "6826", "6827", "6828", "6829", "6830",
"6831", "6832", "6833", "6834", "6835", "6836", "6837", "6838",
"6839", "6840", "6841", "6842", "6843", "6844", "6845", "6846",
"6847", "6848", "6851", "6855", "6856", "6857", "6862", "6864",
"6865", "6866", "6867", "6873", "6882", "6910", "6911", "6912",
"6913", "6914", "6915", "6916", "6917", "6918", "6919", "6920",
"6921", "6922", "6923", "6924", "6925", "6926", "6927", "6928",
"6929", "6930", "6931", "6932", "6933", "6934", "6935", "6936",
"6937", "6938", "6939", "6940", "6941", "6942", "6943", "6944",
"6945", "6946", "6947", "6948", "6949", "6950", "6951", "6952",
"6953", "6954", "6955", "6956", "6957", "6958", "6959", "6960",
"6961", "6962", "6963", "6964", "6965", "6966", "6967", "6968",
"6969", "6970", "6971", "6972", "6973", "6974", "6975", "6976",
"6977", "6978", "6979", "6980", "6981", "6982", "6983", "6984",
"6985", "6986", "6987", "6988", "6989", "6990", "6991", "6993",
"6994", "6995", "6996", "6997", "6998", "6999", "7000", "7001",
"7002", "7003", "7004", "7005", "7006", "7007", "7008", "7009",
"7010", "7011", "7012", "7013", "7014", "7015", "7016", "7017",
"7018", "7019", "7020", "7021", "7022", "7023", "7024", "7025",
"7026", "7027", "7028", "7029", "7030", "7031", "7032", "7033",
"7034", "7035", "7036", "7037", "7038", "7039", "7040", "7041",
"7042", "7043", "7044", "7045", "7046", "7047", "7048", "7049",
"7050", "7051", "7052", "7053", "7054", "7055", "7056", "7057",
"7058", "7059", "7060", "7061", "7062", "7063", "7064", "7065",
"7066", "7067", "7068", "7069", "7070", "7071", "7072", "7073",
"7074", "7075", "7076", "7077", "7078", "7079", "7080", "7081",
"7082", "7083", "7084", "7085", "7086", "7087", "7088", "7089",
"7090", "7091", "7092", "7093", "7094", "7095", "7096", "7097",
"7098", "7099", "7100", "7101", "7102", "7103", "7104", "7105",
"7106", "7107", "7108", "7109", "7110", "7111", "7112", "7113",
"7114", "7115", "7116", "7117", "7118", "7119", "7120", "7121",
"7122", "7123", "7124", "7125", "7126", "7127", "7128", "7129",
"7130", "7131", "7132", "7133", "7134", "7135", "7136", "7137",
"7138", "7139", "7140", "7141", "7142", "7143", "7144", "7145",
"7146", "7147", "7148", "7149", "7150", "7151", "7152", "7153",
"7154", "7155", "7156", "7157", "7158", "7159", "7160", "7161",
"7162", "7163", "7164", "7165", "7166", "7167", "7168", "7169",
"7170", "7171", "7172", "7173", "7174", "7175", "7176", "7177",
"7178", "7179", "7180", "7181", "7182", "7183", "7184", "7185",
"7186", "7187", "7188", "7189", "7190", "7191", "7192", "7193",
"7194", "7195", "7196", "7197", "7198", "7199", "7200", "7201",
"7202", "7203", "7204", "7205", "7206", "7207", "7208", "7209",
"7210", "7211", "7212", "7213", "7214", "7215", "7216", "7217",
"7218", "7219", "7220", "7221", "7222", "7223", "7224", "7225",
"7226", "7227", "7228", "7229", "7230", "7231", "7232", "7233",
"7234", "7235", "7236", "7237", "7238", "7239", "7240", "7241",
"7242", "7243", "7244", "7245", "7246", "7247", "7248", "7249",
"7250", "7251", "7252", "7253", "7254", "7255", "7256", "7257",
"7258", "7259", "7260", "7261", "7262", "7263", "7264", "7265",
"7266", "7267", "7268", "7269", "7270", "7271", "7272", "7273",
"7274", "7275", "7276", "7277", "7278", "7279", "7280", "7281",
"7282", "7283", "7284", "7285", "7286", "7287", "7288", "7289",
"7290", "7291", "7292", "7293", "7294", "7295", "7296", "7297",
"7298", "7299", "7300", "7301", "7302", "7303", "7304", "7305",
"7306", "7307", "7308", "7309", "7310", "7311", "7312", "7313",
"7314", "7315", "7316", "7317", "7318", "7319", "7320", "7321",
"7322", "7323", "7324", "7325", "7326", "7327", "7328", "7329",
"7330", "7331", "7332", "7333", "7334", "7335", "7336", "7337",
"7338", "7339", "7340", "7341", "7342", "7343", "7344", "7345",
"7346", "7347", "7348", "7349", "7350", "7351", "7352", "7353",
"7354", "7355", "7356", "7357", "7358", "7359", "7360", "7361",
"7362", "7363", "7364", "7365", "7366", "7367", "7368", "7369",
"7370", "7371", "7372", "7373", "7374", "7375", "7376", "7377",
"7378", "7379", "7380", "7381", "7382", "7383", "7384", "7385",
"7386", "7387", "7388", "7389", "7390", "7391", "7392", "7393",
"7394", "7395", "7396", "7397", "7398", "7399", "7400", "7401",
"7402", "7403", "7404", "7405", "7406", "7407", "7408", "7409",
"7410", "7411", "7412", "7413", "7414", "7415", "7416", "7417",
"7418", "7419", "7420", "7421", "7422", "7423", "7424", "7425",
"7426", "7427", "7428", "7429", "7430", "7431", "7432", "7433",
"7434", "7435", "7436", "7437", "7438", "7439", "7440", "7441",
"7442", "7443", "7444", "7445", "7446", "7447", "7448", "7449",
"7450", "7451", "7452", "7453", "7454", "7455", "7456", "7457",
"7458", "7459", "7460", "7461", "7462", "7463", "7464", "7465",
"7466", "7467", "7468", "7469", "7470", "7471", "7472", "7473",
"7474", "7475", "7476", "7477", "7478", "7479", "7480", "7481",
"7482", "7483", "7484", "7485", "7486", "7487", "7488", "7489",
"7490", "7491", "7492", "7493", "7494", "7495", "7496", "7497",
"7498", "7499", "7500", "7501", "7502", "7503", "7504", "7505",
"7506", "7507", "7508", "7509", "7510", "7511", "7512", "7513",
"7514", "7515", "7516", "7517", "7518", "7519", "7520", "7521",
"7522", "7523", "7524", "7525", "7526", "7527", "7528", "7529",
"7530", "7531", "7532", "7533", "7534", "7535", "7536", "7537",
"7538", "7539", "7540", "7541", "7542", "7543", "7544", "7545",
"7546", "7547", "7548", "7549", "7550", "7551", "7552", "7553",
"7554", "7555", "7556", "7557", "7558", "7559", "7560", "7561",
"7562", "7563", "7564", "7565", "7566", "7567", "7568", "7569",
"7570", "7571", "7572", "7573", "7574", "7575", "7576", "7577",
"7578", "7579", "7580", "7581", "7582", "7583", "7584", "7585",
"7586", "7587", "7588", "7589", "7590", "7591", "7592", "7593",
"7594", "7595", "7596", "7597", "7598", "7599", "7600", "7601",
"7602", "7603", "7604", "7605", "7606", "7607", "7608", "7609",
"7610", "7611", "7612", "7613", "7614", "7615", "7616", "7617",
"7618", "7619", "7620", "7621", "7622", "7623", "7624", "7625",
"7626", "7627", "7628", "7629", "7630", "7631", "7632", "7633",
"7634", "7635", "7636", "7637", "7638", "7639", "7640", "7641",
"7642", "7643", "7644", "7645", "7646", "7647", "7648", "7649",
"7650", "7651", "7652", "7653", "7654", "7655", "7656", "7657",
"7658", "7659", "7660", "7661", "7662", "7663", "7664", "7665",
"7666", "7667", "7668", "7669", "7670", "7671", "7672", "7673",
"7674", "7675", "7676", "7677", "7678", "7679", "7680", "7681",
"7682", "7683", "7684", "7685", "7686", "7687", "7688", "7689",
"7690", "7691", "7692", "7693", "7694", "7695", "7696", "7697",
"7698", "7699", "7700", "7701", "7702", "7703", "7704", "7705",
"7706", "7707", "7708", "7709", "7710", "7711", "7712", "7713",
"7714", "7715", "7716", "7717", "7718", "7719", "7720", "7721",
"7722", "7723", "7724", "7725", "7726", "7727", "7728", "7729",
"7730", "7731", "7732", "7733", "7734", "7735", "7736", "7737",
"7738", "7739", "7740", "7741", "7742", "7743", "7744", "7745",
"7746", "7747", "7748", "7749", "7750", "7751", "7752", "7753",
"7754", "7755", "7756", "7757", "7758", "7759", "7760", "7761",
"7762", "7763", "7764", "7765", "7766", "7767", "7768", "7769",
"7770", "7771", "7772", "7773", "7774", "7775", "7776", "7777",
"7778", "7779", "7780", "7781", "7782", "7783", "7784", "7785",
"7786", "7787", "7788", "7789", "7790", "7791", "7792", "7793",
"7794", "7795", "7796", "7797", "7798", "7799", "7800", "7801",
"7802", "7803", "7804", "7805", "7806", "7807", "7808", "7809",
"7810", "7811", "7812", "7813", "7814", "7815", "7816", "7817",
"7818", "7819", "7820", "7821", "7822", "7823", "7824", "7825",
"7826", "7827", "7828", "7829", "7830", "7831", "7832", "7833",
"7834", "7835", "7836", "7837", "7838", "7839", "7840", "7841",
"7842", "7843", "7844", "7845", "7846", "7847", "7848", "7849",
"7850", "7851", "7852", "7853", "7854", "7855", "7856", "7857",
"7858", "7859", "7860", "7861", "7862", "7863", "7864", "7865",
"7866", "7867", "7868", "7869", "7870", "7871", "7872", "7873",
"7874", "7875", "7876", "7877", "7878", "7879", "7880", "7881",
"7882", "7883", "7884", "7885", "7886", "7887", "7888", "7889",
"7890", "7891", "7892", "7893", "7894", "7895", "7896", "7897",
"7898", "7899", "7900", "7901", "7902", "7903", "7904", "7905",
"7906", "7907", "7908", "7909", "7910", "7911", "7912", "7913",
"7914", "7915", "7916", "7917", "7918", "7919", "7920", "7921",
"7922", "7923", "7924", "7925", "7926", "7927", "7928", "7929",
"7930", "7931", "7932", "7933", "7934", "7935", "7936", "7937",
"7938", "7939", "7940", "7941", "7942", "7943", "7944", "7945",
"7946", "7947", "7948", "7949", "7950", "7951", "7952", "7953",
"7954", "7955", "7956", "7957", "7958", "7959", "7960", "7961",
"7962", "7963", "7964", "7965", "7966", "7967", "7968", "7969",
"7970", "7971", "7972", "7973", "7974", "7975", "7976", "7977",
"7978", "7979", "7980", "7981", "7982", "7983", "7984", "7985",
"7986", "7987", "7988", "7989", "7990", "7991", "7992", "7993",
"7994", "7995", "7996", "7997", "7998", "7999", "8000", "8001",
"8002", "8003", "8004", "8005", "8006", "8007", "8008", "8009",
"8010", "8011", "8012", "8013", "8014", "8015", "8016", "8017",
"8018", "8019", "8020", "8021", "8022", "8023", "8024", "8025",
"8026", "8027", "8028", "8029", "8030", "8031", "8032", "8033",
"8034", "8035", "8036", "8037", "8038", "8039", "8040", "8041",
"8042", "8043", "8044", "8045", "8046", "8047", "8048", "8049",
"8050", "8051", "8052", "8053", "8054", "8055", "8056", "8057",
"8058", "8059", "8060", "8061", "8062", "8063", "8064", "8065",
"8066", "8067", "8068", "8069", "8070", "8071", "8072", "8073",
"8074", "8075", "8076", "8077", "8078", "8079", "8080", "8081",
"8082", "8083", "8084", "8085", "8086", "8087", "8088", "8089",
"8090", "8091", "8092", "8093", "8094", "8095", "8096", "8097",
"8098", "8099", "8100", "8101", "8102", "8103", "8104", "8105",
"8106", "8107", "8108", "8109", "8110", "8111", "8112", "8113",
"8114", "8115", "8116", "8117", "8118", "8119", "8120", "8121",
"8122", "8123", "8124", "8125", "8126", "8127", "8128", "8129",
"8130", "8131", "8132", "8133", "8134", "8135", "8136", "8137",
"8138", "8139", "8140", "8141", "8142", "8143", "8144", "8145",
"8146", "8147", "8148", "8149", "8150", "8151", "8152", "8153",
"8154", "8155", "8156", "8157", "8158", "8159", "8160", "8161",
"8162", "8163", "8164", "8165", "8166", "8167", "8168", "8169",
"8170", "8171", "8172", "8173", "8174", "8175", "8176", "8177",
"8178", "8179", "8180", "8181", "8182", "8183", "8184", "8185",
"8186", "8187", "8188", "8189", "8190", "8191", "8192", "8193",
"8194", "8195", "8196", "8197", "8198", "8199", "8200", "8201",
"8202", "8203", "8204", "8205", "8206", "8207", "8208", "8209",
"8210", "8211", "8212", "8213", "8214", "8215", "8216", "8217",
"8218", "8219", "8220", "8221", "8222", "8223", "8224", "8225",
"8226", "8227", "8228", "8229", "8230", "8231", "8232", "8233",
"8234", "8235", "8236", "8237", "8238", "8239", "8240", "8241",
"8242", "8243", "8244", "8245", "8246", "8247", "8248", "8461",
"8462", "8463", "8464", "8465", "8466", "8467", "8468", "8469",
"8470", "8471", "8472", "8473", "8474", "8475", "8476", "8477",
"8478", "8479", "8480", "8481", "8482", "8483", "8484", "8485",
"8486", "8487", "8488", "8489", "8490", "8491", "8687", "8688",
"8689", "8690", "8691", "8692", "8693", "8694", "8695", "8696",
"8697", "8698", "8699", "8700", "8701", "8702", "8703", "8704",
"8705", "8706", "8707", "8708", "8709", "8710", "8711", "8712",
"8713", "8714", "8715", "8716", "8717", "8718", "8719", "8720",
"8721", "8722", "8723", "8724", "8725", "8726", "8727", "8728",
"8729", "8730", "8731", "8732", "8733", "8734", "8735", "8736",
"8737", "8738", "8739", "8740", "8741", "8742", "8743", "8744",
"8745", "8746", "8747", "8748", "8749", "8750", "8751", "8752",
"8753", "8754", "8755", "8756", "8757", "8758", "8759", "8760",
"8761", "8762", "8763", "8764", "8765", "8766", "8767", "8768",
"8769", "8770", "8771", "8772", "8773", "8774", "8775", "8776",
"8777", "8778", "8779", "8780", "8781", "8782", "8783", "8784",
"8785", "8786", "8787", "8788", "8789", "8790", "8791", "8792",
"8793", "8794", "8795", "8796", "8797", "8798", "8799", "8800",
"8801", "8802", "8803", "8804", "8805", "8806", "8807", "8808",
"8809", "8810", "8811", "8812", "8813", "8814", "8815", "8816",
"8817", "8818", "8819", "8820", "8821", "8822", "8823", "8824",
"8825", "8826", "8827", "8828", "8829", "8830", "8831", "8832",
"8833", "8834", "8835", "8836", "8837", "8838", "8839", "8840",
"8841", "8842", "8843", "8844", "8845", "8846", "8847", "8848",
"8849", "8850", "8851", "8852", "8853", "8854", "8855", "8856",
"8857", "8858", "8859", "8860", "8861", "8862", "8863", "8864",
"8865", "8866", "8867", "8868", "8869", "8870", "8871", "8872",
"8873", "8874", "8875", "8876", "8877", "8878", "8879", "8880",
"8881", "8882", "8883", "8884", "8885", "8886", "8887", "8888",
"8889", "8890", "8891", "8892", "8893", "8894", "8895", "8896",
"8897", "8898", "8899", "8900", "8901", "8902", "8903", "8904",
"8905", "8906", "8907", "8908", "8909", "8910", "8911", "8912",
"8913", "8914", "8915", "8916", "8917", "8918", "8919", "8920",
"8921", "8922", "8923", "8924", "8925", "8926", "8927", "8928",
"8929", "8930", "8931", "8932", "8933", "8934", "8935", "8936",
"8937", "8938", "8939", "8940", "8941", "8942", "8943", "8944",
"8945", "8946", "8947", "8948", "8949", "8950", "8951", "8952",
"8953", "8954", "8955", "8956", "8957", "8958", "8959", "8960",
"8961", "8962", "8963", "8964", "8965", "8966", "8967", "8968",
"8969", "8970", "8971", "8972", "8973", "8974", "8975", "8976",
"8977", "8978", "8979", "8980", "8981", "8982", "8983", "8984",
"8985", "8986", "8987", "8988", "8989", "8990", "8991", "8992",
"8993", "8994", "8995", "8996", "8997", "8998", "8999", "9000",
"9001", "9002", "9003", "9004", "9005", "9006", "9007", "9008",
"9009", "9010", "9011", "9012", "9013", "9014", "9015", "9016",
"9017", "9018", "9019", "9020", "9021", "9022", "9023", "9024",
"9025", "9026", "9027", "9028", "9029", "9030", "9031", "9032",
"9033", "9034", "9035", "9036", "9037", "9038", "9039", "9040",
"9041", "9042", "9043", "9044", "9045", "9046", "9047", "9048",
"9049", "9050", "9051", "9052", "9053", "9054", "9055", "9056",
"9057", "9058", "9059", "9060", "9061", "9062", "9063", "9064",
"9065", "9066", "9067", "9068", "9069", "9070", "9071", "9072",
"9073", "9074", "9075", "9076", "9077", "9078", "9079", "9080",
"9081", "9082", "9083", "9084", "9085", "9086", "9087", "9088",
"9089", "9090", "9091", "9092", "9093", "9094", "9095", "9096",
"9097", "9098", "9099", "9100", "9101", "9102", "9103", "9104",
"9105", "9106", "9107", "9108", "9109", "9110", "9111", "9112",
"9113", "9114", "9115", "9116", "9117", "9118", "9119", "9120",
"9121", "9122", "9123", "9124", "9125", "9126", "9127", "9128",
"9129", "9130", "9131", "9132", "9133", "9134", "9135", "9136",
"9137", "9138", "9139", "9140", "9141", "9142", "9143", "9144",
"9145", "9146", "9147", "9148", "9149", "9150", "9151", "9152",
"9153", "9154", "9155", "9156", "9157", "9158", "9159", "9160",
"9161", "9162", "9163", "9164", "9165", "9166", "9167", "9168",
"9169", "9170", "9171", "9172", "9173", "9174", "9175", "9176",
"9177", "9178", "9179", "9180", "9181", "9182", "9183", "9184",
"9185", "9186", "9187", "9188", "9189", "9190", "9191", "9192",
"9193", "9194", "9195", "9196", "9197", "9198", "9199", "9200",
"9201", "9202", "9203", "9204", "9205", "9206", "9207", "9208",
"9209", "9210", "9211", "9212", "9213", "9214", "9215", "9216",
"9217", "9218", "9219", "9220", "9221", "9222", "9223", "9224",
"9225", "9226", "9227", "9228", "9229", "9230", "9231", "9232",
"9233", "9234", "9235", "9236", "9237", "9238", "9239", "9240",
"9241", "9242", "9243", "9244", "9245", "9246", "9247", "9248",
"9249", "9250", "9251", "9252", "9253", "9254", "9255", "9256",
"9257", "9258", "9259", "9260", "9261", "9262", "9263", "9264",
"9265", "9266", "9267", "9268", "9269", "9270", "9271", "9272",
"9273", "9274", "9275", "9276", "9277", "9278", "9279", "9280",
"9281", "9282", "9283", "9284", "9285", "9286", "9287", "9288",
"9289", "9290", "9291", "9292", "9293", "9294", "9295", "9296",
"9297", "9298", "9299", "9300", "9301", "9302", "9303", "9304",
"9305", "9306", "9307", "9308", "9309", "9310", "9311", "9312",
"9313", "9314", "9315", "9316", "9317", "9318", "9319", "9320",
"9321", "9322", "9323", "9324", "9325", "9326", "9327", "9328",
"9329", "9330", "9331", "9332", "9333", "9334", "9335", "9336",
"9337", "9338", "9339", "9340", "9341", "9342", "9343", "9344",
"9345", "9346", "9347", "9348", "9349", "9350", "9351", "9352",
"9353", "9354", "9355", "9356", "9357", "9358", "9359", "9360",
"9361", "9362", "9363", "9364", "9365", "9366", "9367", "9368",
"9369", "9370", "9371", "9372", "9373", "9374", "9375", "9376",
"9377", "9378", "9379", "9380", "9381", "9382", "9383", "9384",
"9385", "9386", "9387", "9388", "9389", "9390", "9391", "9392",
"9393", "9394", "9395", "9396", "9397", "9398", "9399", "9400",
"9401", "9402", "9403", "9404", "9405", "9406", "9407", "9408",
"9409", "9410", "9411", "9412", "9413", "9414", "9415", "9416",
"9417", "9418", "9419", "9420", "9421", "9422", "9423", "9424",
"9425", "9426", "9427", "9428", "9429", "9430", "9431", "9432",
"9433", "9434", "9435", "9436", "9437", "9438", "9439", "9440",
"9441", "9442", "9443", "9444", "9445", "9446", "9447", "9448",
"9449", "9450", "9451", "9452", "9453", "9454", "9455", "9456",
"9457", "9458", "9459", "9460", "9461", "9462", "9463", "9464",
"9465", "9466", "9467", "9468", "9469", "9470", "9471", "9472",
"9473", "9474", "9475", "9476", "9477", "9478", "9479", "9480",
"9481", "9482", "9483", "9484", "9485", "9486", "9487", "9488",
"9489", "9490", "9491", "9492", "9493", "9494", "9495", "9496",
"9497"), class = "omit"), row.names = c(NA, 6L), class = "data.frame")


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Mon Jan  9 17:21:03 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 9 Jan 2017 17:21:03 +0100
Subject: [R] Source into a specified environment
Message-ID: <OF93B312E2.FBC8A0C4-ONC12580A3.0057FCC8-C12580A3.0059D230@lotus.hawesko.de>

Hi All,

I wish everyone a happy new year.

I have the following code:

-- cut --

modules <- c("t_calculate_RFM_model.R", "t_count_na.R", 
"t_export_table_2_xls.R",
             "t_find_duplicates_in_variable.R", 
"t_find_originals_and_duplicates.R",
             "t_frequencies.R", "t_inspect_dataset.R", 
"t_merge_variables.R",
             "t_openxlsx_shortcuts.r", "t_rename_variables.R", 
"t_select_chunks.R")

toolbox <- new.env(parent = emptyenv())

for (file in modules)
{
  source(file = file.path(
    c_path_full$modules,  # path to modules
    file),
    echo = TRUE)
}

-- cut --

I would like to know how I can source the modules into the newly created 
environment called "toolbox"?

I had a look at the help file for ?source but this function can read in 
only in the current environment or the global environment (= default).

I tried also the following

-- cut --

for (file in modules))
{
  do.call(
    what = "source",
    args = list(
      file = file.path(c_path_full$modules,
                       file),
      echo = TRUE
    ),
    envir = toolbox
  )
}

-- cut --

But this did not work, i. e. it did not load the modules into the 
environment "toolbox" but into the .GlobalEnv.

I also had a look at "assign", but assign() askes for a name of an object 
in quotes. This way I could not figure out how to use it in a loop or 
function to name the element in "toolbox" after the modules names:

assign("t_add_sheet", t_add_sheet, envir = toolbox)  # works
assign(quote(t_add_sheet), t_add_sheet, envir = toolbox)  # does NOT work
assign(as.name(t_add_sheet), t_add_sheet, envir = toolbix)  # does NOT 
work


Is there a way to load the modules directly into the "toolbox" 
environment?

Kind regards

Georg


From calandra at rgzm.de  Mon Jan  9 17:33:36 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Mon, 9 Jan 2017 17:33:36 +0100
Subject: [R] Source into a specified environment
In-Reply-To: <OF93B312E2.FBC8A0C4-ONC12580A3.0057FCC8-C12580A3.0059D230@lotus.hawesko.de>
References: <OF93B312E2.FBC8A0C4-ONC12580A3.0057FCC8-C12580A3.0059D230@lotus.hawesko.de>
Message-ID: <294c6eda-8b6b-38b2-996a-de359f931ffd@rgzm.de>

Hi Georg,

Not sure how it would work in your case, but the 'local' argument to 
source() is not only TRUE or FALSE; you can also specify an environment.

HTH,
Ivan

--
Ivan Calandra, PhD
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
calandra at rgzm.de
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra
https://rgzm.academia.edu/IvanCalandra
https://publons.com/author/705639/

Le 09/01/2017 ? 17:21, G.Maubach at weinwolf.de a ?crit :
> Hi All,
>
> I wish everyone a happy new year.
>
> I have the following code:
>
> -- cut --
>
> modules <- c("t_calculate_RFM_model.R", "t_count_na.R",
> "t_export_table_2_xls.R",
>               "t_find_duplicates_in_variable.R",
> "t_find_originals_and_duplicates.R",
>               "t_frequencies.R", "t_inspect_dataset.R",
> "t_merge_variables.R",
>               "t_openxlsx_shortcuts.r", "t_rename_variables.R",
> "t_select_chunks.R")
>
> toolbox <- new.env(parent = emptyenv())
>
> for (file in modules)
> {
>    source(file = file.path(
>      c_path_full$modules,  # path to modules
>      file),
>      echo = TRUE)
> }
>
> -- cut --
>
> I would like to know how I can source the modules into the newly created
> environment called "toolbox"?
>
> I had a look at the help file for ?source but this function can read in
> only in the current environment or the global environment (= default).
>
> I tried also the following
>
> -- cut --
>
> for (file in modules))
> {
>    do.call(
>      what = "source",
>      args = list(
>        file = file.path(c_path_full$modules,
>                         file),
>        echo = TRUE
>      ),
>      envir = toolbox
>    )
> }
>
> -- cut --
>
> But this did not work, i. e. it did not load the modules into the
> environment "toolbox" but into the .GlobalEnv.
>
> I also had a look at "assign", but assign() askes for a name of an object
> in quotes. This way I could not figure out how to use it in a loop or
> function to name the element in "toolbox" after the modules names:
>
> assign("t_add_sheet", t_add_sheet, envir = toolbox)  # works
> assign(quote(t_add_sheet), t_add_sheet, envir = toolbox)  # does NOT work
> assign(as.name(t_add_sheet), t_add_sheet, envir = toolbix)  # does NOT
> work
>
>
> Is there a way to load the modules directly into the "toolbox"
> environment?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From vodvos at zoho.com  Mon Jan  9 15:55:44 2017
From: vodvos at zoho.com (vod vos)
Date: Mon, 09 Jan 2017 06:55:44 -0800
Subject: [R] how to proof the trend of two columns of data?
Message-ID: <15983ba57a1.114810fdb22468.7903301582019536849@zoho.com>

Hello everyone,



If there are two columns, one is age (numeric, cut to several groups), the other is hair color type(factor: yellow, black, white). 



If the age column is not normal distributed, which statistic method should use to prove the trend relationship between them, for example, the older has more probability of white hair type? Are there any existed R package to figure out this situation?



Thank you.




	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Jan  9 18:27:36 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 09 Jan 2017 17:27:36 +0000
Subject: [R] how to proof the trend of two columns of data?
In-Reply-To: <15983ba57a1.114810fdb22468.7903301582019536849@zoho.com>
References: <15983ba57a1.114810fdb22468.7903301582019536849@zoho.com>
Message-ID: <5873C808.5080604@sapo.pt>

Hello,

Inline.

Em 09-01-2017 14:55, vod vos escreveu:
> Hello everyone,
>
>
>
> If there are two columns, one is age (numeric, cut to several groups), the other is hair color type(factor: yellow, black, white).
>
>
>
> If the age column is not normal distributed

If you use ?lm, it's the residuals that should be normally distributed, 
not age.
You can also use ?glm with a binomial link, in which case you should 
recode type as white/not white.

Hope this helps,

Rui Barradas

, which statistic method should use to prove the trend relationship 
between them, for example, the older has more probability of white hair 
type? Are there any existed R package to figure out this situation?
>
>
>
> Thank you.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Jan  9 18:51:13 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Jan 2017 09:51:13 -0800
Subject: [R] gridExtra-arrangeGrob
In-Reply-To: <1699652495.1038553.1483961725633@mail.yahoo.com>
References: <65473706.838889.1483942017228.ref@mail.yahoo.com>
	<65473706.838889.1483942017228@mail.yahoo.com>
	<1699652495.1038553.1483961725633@mail.yahoo.com>
Message-ID: <272527ED-F6D3-4FE2-9291-D8F4DC7D8A13@comcast.net>


> On Jan 9, 2017, at 3:35 AM, John Kane via R-help <r-help at r-project.org> wrote:
> 
> I'm not sure what the problem is but, if nothing else, it looks like you need to do 
> library(grid)
> It may be that an early version of ggplot2 or gridExtra was automatically loading grid and it no longer does.  
> 
> 
> 
> 
>    On Monday, January 9, 2017 1:08 AM, Felipe Carrillo via R-help <r-help at r-project.org> wrote:
> 
> 
>  Hi;The code below used to work on my older version of gridExtra but doesn't work with the new version. Could someonegive me a hint on how to translate this code to the new version of gridExtra code? Thank you beforehand.
> p1 <- ggplot(iris,aes(Sepal.Length,  Petal.Length, colour=Species)) +
> geom_point() + theme_bw() + theme(legend.position='top')
> 
>  grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .33,.33), ncol=1), ncol=2)
>  #Create 2 columns with different width using the 'widths' argument in the grid.arrange call
>   grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .40,.27), ncol=1), ncol=2,widths=c(1.25,0.75))
> p <- rectGrob()  
>  grid.arrange(p, arrangeGrob(p,p,p, heights=c(0.33, .33,.33), ncol=1), ncol=2)

The lattice library attaches the grid functions via a namespace mechanism but it does not actually load the package. That meant that attempts to use grid functions from the console would fail. Perhaps this is also the practice of the ggplot2 authors? In any event, the grid.arrange and arrangeGrob functions are not from grid, but rather from gridExtra, which I am not seeing being loaded.

-- 
David.


> 
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Mon Jan  9 19:12:14 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 9 Jan 2017 18:12:14 +0000
Subject: [R] how to proof the trend of two columns of data?
In-Reply-To: <5873C808.5080604@sapo.pt>
References: <15983ba57a1.114810fdb22468.7903301582019536849@zoho.com>
	<5873C808.5080604@sapo.pt>
Message-ID: <9267fa5ef8ae4f6fabfad5546c218c24@exch-2p-mbx-w2.ads.tamu.edu>

The list does not assist with homework problems. If this is not a class assignment, you should be more specific about what you have tried and provide a reproducible example (a sample of the real data or some made-up data that has the same columns and data types). In the meantime you could also try the following R command:

> ?kruskal.test

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Monday, January 9, 2017 11:28 AM
To: vod vos; r-help
Subject: Re: [R] how to proof the trend of two columns of data?

Hello,

Inline.

Em 09-01-2017 14:55, vod vos escreveu:
> Hello everyone,
>
>
>
> If there are two columns, one is age (numeric, cut to several groups), the other is hair color type(factor: yellow, black, white).
>
>
>
> If the age column is not normal distributed

If you use ?lm, it's the residuals that should be normally distributed, 
not age.
You can also use ?glm with a binomial link, in which case you should 
recode type as white/not white.

Hope this helps,

Rui Barradas

, which statistic method should use to prove the trend relationship 
between them, for example, the older has more probability of white hair 
type? Are there any existed R package to figure out this situation?
>
>
>
> Thank you.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mazatlanmexico at yahoo.com  Mon Jan  9 20:33:52 2017
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Mon, 9 Jan 2017 19:33:52 +0000
Subject: [R] gridExtra-arrangeGrob
In-Reply-To: <272527ED-F6D3-4FE2-9291-D8F4DC7D8A13@comcast.net>
References: <65473706.838889.1483942017228.ref@mail.yahoo.com>
	<65473706.838889.1483942017228@mail.yahoo.com>
	<1699652495.1038553.1483961725633@mail.yahoo.com>
	<272527ED-F6D3-4FE2-9291-D8F4DC7D8A13@comcast.net>
Message-ID: <1410638411.1255809.1483990432157@mail.yahoo.com>

I am not sure if something was wrong with my gridExtra installation or grid but after uninstall/re-install of the packages (and reboot) the code is working properly. Thank you all.?
 

    On Monday, January 9, 2017 9:51 AM, David Winsemius <dwinsemius at comcast.net> wrote:
 
 

 
> On Jan 9, 2017, at 3:35 AM, John Kane via R-help <r-help at r-project.org> wrote:
> 
> I'm not sure what the problem is but, if nothing else, it looks like you need to do 
> library(grid)
> It may be that an early version of ggplot2 or gridExtra was automatically loading grid and it no longer does.? 
> 
> 
> 
> 
>? ? On Monday, January 9, 2017 1:08 AM, Felipe Carrillo via R-help <r-help at r-project.org> wrote:
> 
> 
>? Hi;The code below used to work on my older version of gridExtra but doesn't work with the new version. Could someonegive me a hint on how to translate this code to the new version of gridExtra code? Thank you beforehand.
> p1 <- ggplot(iris,aes(Sepal.Length,? Petal.Length, colour=Species)) +
> geom_point() + theme_bw() + theme(legend.position='top')
> 
>? grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .33,.33), ncol=1), ncol=2)
>? #Create 2 columns with different width using the 'widths' argument in the grid.arrange call
>? grid.arrange(p1, arrangeGrob(p1,p1,p1, heights=c(0.33, .40,.27), ncol=1), ncol=2,widths=c(1.25,0.75))
> p <- rectGrob()? 
>? grid.arrange(p, arrangeGrob(p,p,p, heights=c(0.33, .33,.33), ncol=1), ncol=2)

The lattice library attaches the grid functions via a namespace mechanism but it does not actually load the package. That meant that attempts to use grid functions from the console would fail. Perhaps this is also the practice of the ggplot2 authors? In any event, the grid.arrange and arrangeGrob functions are not from grid, but rather from gridExtra, which I am not seeing being loaded.

-- 
David.


> 
>? ? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


 
   
	[[alternative HTML version deleted]]


From jholtman at gmail.com  Tue Jan 10 02:28:46 2017
From: jholtman at gmail.com (jim holtman)
Date: Mon, 9 Jan 2017 20:28:46 -0500
Subject: [R] Source into a specified environment
In-Reply-To: <OF93B312E2.FBC8A0C4-ONC12580A3.0057FCC8-C12580A3.0059D230@lotus.hawesko.de>
References: <OF93B312E2.FBC8A0C4-ONC12580A3.0057FCC8-C12580A3.0059D230@lotus.hawesko.de>
Message-ID: <CAAxdm-7FmD07DVtdGU71nFKKi=xjCeX0DNY_URcWix_x1yD08g@mail.gmail.com>

?sys.source

Here is an example of the way I use it:

# read my functions into a environment
.my.env.jph <- new.env()
.sys.source('~/C_Drive/perf/bin/perfmon.r', envir=.my.env.jph)
attach(.my.env.jph)


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Jan 9, 2017 at 11:21 AM, <G.Maubach at weinwolf.de> wrote:

> Hi All,
>
> I wish everyone a happy new year.
>
> I have the following code:
>
> -- cut --
>
> modules <- c("t_calculate_RFM_model.R", "t_count_na.R",
> "t_export_table_2_xls.R",
>              "t_find_duplicates_in_variable.R",
> "t_find_originals_and_duplicates.R",
>              "t_frequencies.R", "t_inspect_dataset.R",
> "t_merge_variables.R",
>              "t_openxlsx_shortcuts.r", "t_rename_variables.R",
> "t_select_chunks.R")
>
> toolbox <- new.env(parent = emptyenv())
>
> for (file in modules)
> {
>   source(file = file.path(
>     c_path_full$modules,  # path to modules
>     file),
>     echo = TRUE)
> }
>
> -- cut --
>
> I would like to know how I can source the modules into the newly created
> environment called "toolbox"?
>
> I had a look at the help file for ?source but this function can read in
> only in the current environment or the global environment (= default).
>
> I tried also the following
>
> -- cut --
>
> for (file in modules))
> {
>   do.call(
>     what = "source",
>     args = list(
>       file = file.path(c_path_full$modules,
>                        file),
>       echo = TRUE
>     ),
>     envir = toolbox
>   )
> }
>
> -- cut --
>
> But this did not work, i. e. it did not load the modules into the
> environment "toolbox" but into the .GlobalEnv.
>
> I also had a look at "assign", but assign() askes for a name of an object
> in quotes. This way I could not figure out how to use it in a loop or
> function to name the element in "toolbox" after the modules names:
>
> assign("t_add_sheet", t_add_sheet, envir = toolbox)  # works
> assign(quote(t_add_sheet), t_add_sheet, envir = toolbox)  # does NOT work
> assign(as.name(t_add_sheet), t_add_sheet, envir = toolbix)  # does NOT
> work
>
>
> Is there a way to load the modules directly into the "toolbox"
> environment?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Jan 10 02:52:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 09 Jan 2017 17:52:03 -0800
Subject: [R] R install/libraries
In-Reply-To: <1674730174.1453061.1484009236252@mail.yahoo.com>
References: <2046322896.798422.1483937544943.ref@mail.yahoo.com>
	<2046322896.798422.1483937544943@mail.yahoo.com>
	<E90749AF-779D-4AA9-B0B1-856CD8FC1103@dcn.davis.ca.us>
	<13112013.1327634.1483996990436@mail.yahoo.com>
	<A63BC48D-4A62-4BE1-9ECB-E0A7218EECEF@dcn.davis.ca.us>
	<1674730174.1453061.1484009236252@mail.yahoo.com>
Message-ID: <9B1425D1-4FEB-49C3-8751-65E9DB42BD11@dcn.davis.ca.us>

I have noticed a behavior where if I update a package with dependencies, sometimes it fails and the package that was outdated but installed is no longer installed. Once I run install.packages again, it usually seems to work just fine. I have not noticed that base packages are more susceptible to this than contributed packages. 
-- 
Sent from my phone. Please excuse my brevity.

On January 9, 2017 4:47:16 PM PST, Chris <chris.barker at barkerstats.com> wrote:
>thx. when I let R installed to "my documents" (which is basically world
>read/writable) not all dependent packages download/install with the
>library.?
>When R tells me it can't find the dependent librariies, I manually
>download and install.
>
>Is that typical behaviour for R??Chris Barker, Ph.D.
>Adjunct Associate Professor of Biostatistics - UIC-SPH
>and
>President and Owner
>Statistical Planning and Analysis Services, Inc.
>www.barkerstats.com
>415 609 7473 
>skype: barkerstats
>
> 
>
>On Monday, January 9, 2017 4:41 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
> 
>
>Your (updated) personal library should receive any updated versions of
>base packages that were originally installed with R. The outdated
>packages in the system library tend to become irrelevant over time with
>normal use. It is possible to update them but for most people fixing
>that is not worth the risk of breaking permissions on your personal
>library. 


From lucy.leigh at newcastle.edu.au  Tue Jan 10 05:46:40 2017
From: lucy.leigh at newcastle.edu.au (Lucy Leigh)
Date: Tue, 10 Jan 2017 04:46:40 +0000
Subject: [R] mstate with multiple initial states?
Message-ID: <SG2PR04MB1198A37C810FD5902597AC2AA8670@SG2PR04MB1198.apcprd04.prod.outlook.com>

Hi,

I have a multi-state model that I would like to estimate using the 'mstate' package - but I am not sure how best to approach it and was wondering

if anyone could provide some insight for me.

Basically, I have a group of kids who have been randomized to one of 2 treatments, A or B. If they do well on either of these, they

are discharged (A -->D or B--> D). If they do poorly, kids who were receiving treatment A are moved onto treatment B (A-->B), but kids

on B can't go to A, they go straight into ICU (A-->C). If the kids who went from A-->B do well they are discharged (A-->B-->D), and if they

do poorly they go to ICU (A-->B-->C), and then finally after ICU they are discharged (C-->D). There are also a small number of kids who were sent

straight to ICU (so...in fact there are 3 initial states). So the transition matrix looks like:


     A      B     C      D

A   NA   1    NA   1

B  NA   NA   1     1

C  NA   NA   NA  1

D  NA   NA  NA  NA


However, I am not sure whether I can do this in 'mstate', as there are three initial states? The program requires that we start with

a wide data set, in which  there is an event indicator for each state, and a time of entry into each state. If they don't enter a state, then

the time for that state is set to last follow-up (page 4 of https://www.jstatsoft.org/article/view/v038i07 ).


So, in the case where a kid starts in A, and goes to D; the data would look like:

           A.status  A.time    B.status   B.time   C.Status   C.Time  D.Status  D.time

                 1             0                0         Final           0            Final         1          Final


And I think this is OK in terms of what is specified for B, because technically the kid is at risk of transitioning into B

until they are discharged.


But what about a kid who starts in B and goes to D? The corresponding data would possibly be?:

       A.status  A.time    B.status   B.time   C.Status   C.Time  D.Status  D.time

                 0       Final            1       0                 0            Final         1          Final


However, this to me doesn't look right, as technically they are never at risk of going to A if they started in B.

I tried setting the A.time to 0 to reflect the fact that they are never at risk of going back to A, but the numbers I got

from the model  (events$model) were incorrect - basically all the events were going to A, and no one was in B.

And for the kids that started in C...similarly.



So, I was wondering, would it be valid to create a new initial state (e.g. P = pre-treatment), from which the child

then transitions immediately (at say, time  = 0.1) to either A or B (or C). So the matrix would be:


     P      A      B     C      D

P   NA   1      1      1     NA

A  NA   NA    1    NA    1

B  NA   NA   NA    1     1

C  NA   NA   NA  NA    1

D  NA   NA  NA  NA   NA


And then the data for someone who went from A--D would be


  A.status  A.time        B.status   B.time   C.Status   C.Time  D.Status  D.time

          1             0.1                0        0.1             0            Final         1          Final


And then the data for someone who went from B--D would be


       A.status  A.time      B.status   B.time          C.Status   C.Time  D.Status  D.time

                 0      0.1             1                 0 .1                0            Final         1          Final



When I code the model like this, then the number of events I get from the model is correct.


However, I am not sure whether adding this extra initial state is a valid option?



Thanks in advance for anyone who can help me out,

Lucy Leigh




mstate: An R Package for the Analysis of Competing Risks ...<https://www.jstatsoft.org/article/view/v038i07>
www.jstatsoft.org
Authors: Liesbeth C. de Wreede, Marta Fiocco, Hein Putter: Title: mstate: An R Package for the Analysis of Competing Risks and Multi-State Models



	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue Jan 10 08:25:26 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 10 Jan 2017 08:25:26 +0100
Subject: [R] SOLVED: Re:  Source into a specified environment
In-Reply-To: <CAAxdm-7FmD07DVtdGU71nFKKi=xjCeX0DNY_URcWix_x1yD08g@mail.gmail.com>
References: <OF93B312E2.FBC8A0C4-ONC12580A3.0057FCC8-C12580A3.0059D230@lotus.hawesko.de>
	<CAAxdm-7FmD07DVtdGU71nFKKi=xjCeX0DNY_URcWix_x1yD08g@mail.gmail.com>
Message-ID: <OFA7A3D18B.05F37BD9-ONC12580A4.0028B06C-C12580A4.0028C760@lotus.hawesko.de>

Hi Jim,

many thanks for your answer.

That's exactly what I need.

Many thanks again.

Kind regards

Georg




Von:    jim holtman <jholtman at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  R mailing list <r-help at r-project.org>
Datum:  10.01.2017 03:59
Betreff:        Re: [R] Source into a specified environment



?sys.source

Here is an example of the way I use it:

# read my functions into a environment
.my.env.jph <- new.env()
.sys.source('~/C_Drive/perf/bin/perfmon.r', envir=.my.env.jph)
attach(.my.env.jph)


Jim Holtman
Data Munger Guru
 
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Jan 9, 2017 at 11:21 AM, <G.Maubach at weinwolf.de> wrote:
Hi All,

I wish everyone a happy new year.

I have the following code:

-- cut --

modules <- c("t_calculate_RFM_model.R", "t_count_na.R",
"t_export_table_2_xls.R",
             "t_find_duplicates_in_variable.R",
"t_find_originals_and_duplicates.R",
             "t_frequencies.R", "t_inspect_dataset.R",
"t_merge_variables.R",
             "t_openxlsx_shortcuts.r", "t_rename_variables.R",
"t_select_chunks.R")

toolbox <- new.env(parent = emptyenv())

for (file in modules)
{
  source(file = file.path(
    c_path_full$modules,  # path to modules
    file),
    echo = TRUE)
}

-- cut --

I would like to know how I can source the modules into the newly created
environment called "toolbox"?

I had a look at the help file for ?source but this function can read in
only in the current environment or the global environment (= default).

I tried also the following

-- cut --

for (file in modules))
{
  do.call(
    what = "source",
    args = list(
      file = file.path(c_path_full$modules,
                       file),
      echo = TRUE
    ),
    envir = toolbox
  )
}

-- cut --

But this did not work, i. e. it did not load the modules into the
environment "toolbox" but into the .GlobalEnv.

I also had a look at "assign", but assign() askes for a name of an object
in quotes. This way I could not figure out how to use it in a loop or
function to name the element in "toolbox" after the modules names:

assign("t_add_sheet", t_add_sheet, envir = toolbox)  # works
assign(quote(t_add_sheet), t_add_sheet, envir = toolbox)  # does NOT work
assign(as.name(t_add_sheet), t_add_sheet, envir = toolbix)  # does NOT
work


Is there a way to load the modules directly into the "toolbox"
environment?

Kind regards

Georg

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Tue Jan 10 09:49:19 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 10 Jan 2017 09:49:19 +0100
Subject: [R] Assessing the name of an object within an argument
Message-ID: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>

Hi All,

I have a function like

my_func <- function(dataset)
{
  some operation
}

Now I would like not only to operate on the dataset (how this is done is 
obvious) but I would like to get the name of the dataset handed over as an 
argument.

Example:

my_func <- function(dataset = iris)
{
  print(dataset)  # here I do not want to print the dataset but the name 
of the object - iris in this case - instead
  # quote() does not do the trick cause it prints "dataset" instead of 
"iris"
  # as.name() gives an error saying that the object can not coerced to a 
symbol
}

Is there a way to do this?

Kind regards

Georg


From mailund at birc.au.dk  Tue Jan 10 10:02:25 2017
From: mailund at birc.au.dk (Thomas Mailund)
Date: Tue, 10 Jan 2017 09:02:25 +0000
Subject: [R] Assessing the name of an object within an argument
In-Reply-To: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>
References: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>
Message-ID: <etPan.5874a321.2ae297dd.11e64@birc.au.dk>

?
You can get that using `formals()`.  

my_func <- function(dataset = iris)  
{
? #print(dataset) # here I do not want to print the dataset but the name  
? # of the object - iris in this case - instead

? print(formals()$dataset) # this is what you want
}

This gives you what the arguments were as an alist. It won?t always be a name, of course, but when it is, as in this case, that will be a symbol you can print.

Cheers
	Thomas



On 10 January 2017 at 09:51:55, g.maubach at weinwolf.de (g.maubach at weinwolf.de(mailto:g.maubach at weinwolf.de)) wrote:

> Hi All,
>  
> I have a function like
>  
> my_func <- function(dataset)
> {
> some operation
> }
>  
> Now I would like not only to operate on the dataset (how this is done is
> obvious) but I would like to get the name of the dataset handed over as an
> argument.
>  
> Example:
>  
> my_func <- function(dataset = iris)
> {
> print(dataset) # here I do not want to print the dataset but the name
> of the object - iris in this case - instead
> # quote() does not do the trick cause it prints "dataset" instead of
> "iris"
> # as.name() gives an error saying that the object can not coerced to a
> symbol
> }
>  
> Is there a way to do this?
>  
> Kind regards
>  
> Georg
>  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Tue Jan 10 10:31:25 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 10 Jan 2017 01:31:25 -0800
Subject: [R] Assessing the name of an object within an argument
In-Reply-To: <etPan.5874a321.2ae297dd.11e64@birc.au.dk>
References: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>
	<etPan.5874a321.2ae297dd.11e64@birc.au.dk>
Message-ID: <CAGxFJbSo_uoDC-nAVBjiGWO-gKP6EZ65+SSojXih=-cZpVNc8w@mail.gmail.com>

This is false. formals() gives the FORMAL argument list of the function,
not the ACTUAL arguments supplied. That is obtained by the construction

deparse(substitute(dataset))

The OP should consult a good R tutorial for this and other uses of
substitute(), part of the "computing on the language" functionality of R.

Bert



On Jan 10, 2017 4:04 AM, "Thomas Mailund" <mailund at birc.au.dk> wrote:


You can get that using `formals()`.

my_func <- function(dataset = iris)
{
  #print(dataset) # here I do not want to print the dataset but the name
  # of the object - iris in this case - instead

  print(formals()$dataset) # this is what you want
}

This gives you what the arguments were as an alist. It won?t always be a
name, of course, but when it is, as in this case, that will be a symbol you
can print.

Cheers
        Thomas



On 10 January 2017 at 09:51:55, g.maubach at weinwolf.de (g.maubach at weinwolf.de
(mailto:g.maubach at weinwolf.de)) wrote:

> Hi All,
>
> I have a function like
>
> my_func <- function(dataset)
> {
> some operation
> }
>
> Now I would like not only to operate on the dataset (how this is done is
> obvious) but I would like to get the name of the dataset handed over as an
> argument.
>
> Example:
>
> my_func <- function(dataset = iris)
> {
> print(dataset) # here I do not want to print the dataset but the name
> of the object - iris in this case - instead
> # quote() does not do the trick cause it prints "dataset" instead of
> "iris"
> # as.name() gives an error saying that the object can not coerced to a
> symbol
> }
>
> Is there a way to do this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mailund at birc.au.dk  Tue Jan 10 10:33:32 2017
From: mailund at birc.au.dk (Thomas Mailund)
Date: Tue, 10 Jan 2017 09:33:32 +0000
Subject: [R] Assessing the name of an object within an argument
In-Reply-To: <CAGxFJbSo_uoDC-nAVBjiGWO-gKP6EZ65+SSojXih=-cZpVNc8w@mail.gmail.com>
References: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>
	<etPan.5874a321.2ae297dd.11e64@birc.au.dk>
	<CAGxFJbSo_uoDC-nAVBjiGWO-gKP6EZ65+SSojXih=-cZpVNc8w@mail.gmail.com>
Message-ID: <etPan.5874aa6c.7c18c9f5.11e64@birc.au.dk>

Yes, I was too fast there, sorry. I sent a correction right after but must have picked Reply instead of Replay All.

Cheers
Thomas



On 10 January 2017 at 10:31:30, Bert Gunter (bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>) wrote:

This is false. formals() gives the FORMAL argument list of the function, not the ACTUAL arguments supplied. That is obtained by the construction

deparse(substitute(dataset))

The OP should consult a good R tutorial for this and other uses of substitute(), part of the "computing on the language" functionality of R.

Bert



On Jan 10, 2017 4:04 AM, "Thomas Mailund" <mailund at birc.au.dk<mailto:mailund at birc.au.dk>> wrote:

You can get that using `formals()`.

my_func <- function(dataset = iris)
{
  #print(dataset) # here I do not want to print the dataset but the name
  # of the object - iris in this case - instead

  print(formals()$dataset) # this is what you want
}

This gives you what the arguments were as an alist. It won?t always be a name, of course, but when it is, as in this case, that will be a symbol you can print.

Cheers
        Thomas



On 10 January 2017 at 09:51:55, g.maubach at weinwolf.de<mailto:g.maubach at weinwolf.de> (g.maubach at weinwolf.de<mailto:g.maubach at weinwolf.de>(mailto:g.maubach at weinwolf.de<mailto:g.maubach at weinwolf.de>)) wrote:

> Hi All,
>
> I have a function like
>
> my_func <- function(dataset)
> {
> some operation
> }
>
> Now I would like not only to operate on the dataset (how this is done is
> obvious) but I would like to get the name of the dataset handed over as an
> argument.
>
> Example:
>
> my_func <- function(dataset = iris)
> {
> print(dataset) # here I do not want to print the dataset but the name
> of the object - iris in this case - instead
> # quote() does not do the trick cause it prints "dataset" instead of
> "iris"
> # as.name<http://as.name>() gives an error saying that the object can not coerced to a
> symbol
> }
>
> Is there a way to do this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Tue Jan 10 14:57:01 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Tue, 10 Jan 2017 19:27:01 +0530
Subject: [R] PNG File in R Markdown HTML
Message-ID: <CAB=p7SqVsTL5+fct-7ArbK=erkpcZ5hzjHFYidysr1b4f+2a_g@mail.gmail.com>

Hi Team,

I am successfully able to add the company logo to the R markdown file using
the code below:

```{r, fig.width=3, fig.height=15,echo=FALSE, warning=FALSE, message=FALSE}
library(png)
library(grid)
img <- readPNG("D:/Shivi/R Project/Name.png")
 grid.raster(img)
```
However the image gets displayed at the bottom of the html page. I have
tried deleting any empty space after this code but it does not help.

Request you to please advice.
Thanks, Shivi

	[[alternative HTML version deleted]]


From luojingqin at yahoo.com  Tue Jan 10 00:28:12 2017
From: luojingqin at yahoo.com (Jingqin luo)
Date: Mon, 9 Jan 2017 23:28:12 +0000 (UTC)
Subject: [R] error in an univariate integration involving a bivariate normal
 CDF
References: <1962352232.2248830.1484004492723.ref@mail.yahoo.com>
Message-ID: <1962352232.2248830.1484004492723@mail.yahoo.com>

R users,I encountered some error message when trying a univariate integration involving a bivariate normal CDF with mean MU and variance matrix Sigma. Below are my code:MU=c(1,3)
Sigma=matrix(c(1,0.5,0.5,1.5),2,2)
integrand=function(xx,y=1,MU=MU,Sigma=Sigma)
  {        
    dnorm(xx,mean=MU[1],sd=sqrt(Sigma[1,1]))*pmvnorm(lower=c(-Inf,-Inf),upper=c(xx,y),mean=MU,sigma=Sigma)

  }
  integrate(integrand,y=1,MU=MU,Sigma=Sigma,lower=-Inf,upper=Inf,subdivisions=1000)gave : Error in checkmvArgs(lower = lower, upper = upper, mean = mean, corr = corr, : ?diag(sigma)? and ?lower? are of different length.The error came from the pmvnorm() part. I will appreciate any hints to this error.> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux Server release 6.2 (Santiago)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] pbivnorm_0.6.0     ggplot2_1.0.0      pROC_1.8           copula_0.999-11   
 [5] mvtnorm_1.0-0      lcmix_0.3          nnls_1.4           MASS_7.3-45       
 [9] matrixStats_0.10.0 R.methodsS3_1.6.1  psych_1.6.9       

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.1      munsell_0.4.2    mnormt_1.5-1     ADGofTest_0.3   
 [5] colorspace_1.2-4 pspline_1.0-16   lattice_0.20-29  stringr_0.6.2   
 [9] plyr_1.8.1       tcltk_3.3.1      tools_3.3.1      parallel_3.3.1  
[13] grid_3.3.1       gtable_0.1.2     digest_0.6.4     Matrix_1.1-4    
[17] reshape2_1.4     labeling_0.3     scales_0.2.4     gsl_1.9-10      
[21] stats4_3.3.1     stabledist_0.6-6 foreign_0.8-66   proto_0.3-10    

	[[alternative HTML version deleted]]


From vodvos at zoho.com  Tue Jan 10 13:03:25 2017
From: vodvos at zoho.com (vod vos)
Date: Tue, 10 Jan 2017 04:03:25 -0800
Subject: [R] how to proof the trend of two columns of data?
In-Reply-To: <9267fa5ef8ae4f6fabfad5546c218c24@exch-2p-mbx-w2.ads.tamu.edu>
References: <15983ba57a1.114810fdb22468.7903301582019536849@zoho.com>
	<5873C808.5080604@sapo.pt>
	<9267fa5ef8ae4f6fabfad5546c218c24@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <1598842ef55.101f82e822686.1862894340827705399@zoho.com>

as far as I know,  ?kruskal.test will show us the differences between three or more groups. But it could show the trend. 




---- On ???, 09 ?? 2017 10:12:14 -0800 David L Carlson &lt;dcarlson at tamu.edu&gt; wrote ----




The list does not assist with homework problems. If this is not a class assignment, you should be more specific about what you have tried and provide a reproducible example (a sample of the real data or some made-up data that has the same columns and data types). In the meantime you could also try the following R command: 

 

&gt; ?kruskal.test 

 

------------------------------------- 

David L Carlson 

Department of Anthropology 

Texas A&amp;M University 

College Station, TX 77840-4352 



-----Original Message----- 

From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas 

Sent: Monday, January 9, 2017 11:28 AM 

To: vod vos; r-help 

Subject: Re: [R] how to proof the trend of two columns of data? 



Hello, 



Inline. 



Em 09-01-2017 14:55, vod vos escreveu: 

&gt; Hello everyone, 

&gt; 

&gt; 

&gt; 

&gt; If there are two columns, one is age (numeric, cut to several groups), the other is hair color type(factor: yellow, black, white). 

&gt; 

&gt; 

&gt; 

&gt; If the age column is not normal distributed 



If you use ?lm, it's the residuals that should be normally distributed, 

not age. 

You can also use ?glm with a binomial link, in which case you should 

recode type as white/not white. 



Hope this helps, 



Rui Barradas 



, which statistic method should use to prove the trend relationship 

between them, for example, the older has more probability of white hair 

type? Are there any existed R package to figure out this situation? 

&gt; 

&gt; 

&gt; 

&gt; Thank you. 

&gt; 

&gt; 

&gt; 

&gt; 

&gt;     [[alternative HTML version deleted]] 

&gt; 

&gt; ______________________________________________ 

&gt; R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 

&gt; https://stat.ethz.ch/mailman/listinfo/r-help 

&gt; PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 

&gt; and provide commented, minimal, self-contained, reproducible code. 

&gt; 



______________________________________________ 

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 

https://stat.ethz.ch/mailman/listinfo/r-help 

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 

and provide commented, minimal, self-contained, reproducible code. 



______________________________________________ 

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 

https://stat.ethz.ch/mailman/listinfo/r-help 

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 

and provide commented, minimal, self-contained, reproducible code. 











	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Jan 10 16:21:59 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Jan 2017 07:21:59 -0800
Subject: [R] error in an univariate integration involving a bivariate
 normal CDF
In-Reply-To: <1962352232.2248830.1484004492723@mail.yahoo.com>
References: <1962352232.2248830.1484004492723.ref@mail.yahoo.com>
	<1962352232.2248830.1484004492723@mail.yahoo.com>
Message-ID: <CAF8bMcYR66A9yStqXrvFcwgthYhDTakJcFHQCqJRwJb3XpUmUA@mail.gmail.com>

  integrand=function(xx,y=1,MU=MU,Sigma=Sigma)
    {
      dnorm(xx,mean=MU[1],sd=sqrt(Sigma[1,1]))*pmvnorm(lower=c(-Inf,-Inf),upper=c(xx,y),mean=MU,sigma=Sigma)

    }

The integrand must be a function that returns a vector the length of
its first argument (integrate will pass it a short vector of input
values).  It looks like your function expects 'xx' to be a scalar.
You can use the Vectorize function to fix things up.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Jan 9, 2017 at 3:28 PM, Jingqin luo via R-help
<r-help at r-project.org> wrote:
> R users,I encountered some error message when trying a univariate integration involving a bivariate normal CDF with mean MU and variance matrix Sigma. Below are my code:MU=c(1,3)
> Sigma=matrix(c(1,0.5,0.5,1.5),2,2)
> integrand=function(xx,y=1,MU=MU,Sigma=Sigma)
>   {
>     dnorm(xx,mean=MU[1],sd=sqrt(Sigma[1,1]))*pmvnorm(lower=c(-Inf,-Inf),upper=c(xx,y),mean=MU,sigma=Sigma)
>
>   }
>   integrate(integrand,y=1,MU=MU,Sigma=Sigma,lower=-Inf,upper=Inf,subdivisions=1000)gave : Error in checkmvArgs(lower = lower, upper = upper, mean = mean, corr = corr, : ?diag(sigma)? and ?lower? are of different length.The error came from the pmvnorm() part. I will appreciate any hints to this error.> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Running under: Red Hat Enterprise Linux Server release 6.2 (Santiago)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] pbivnorm_0.6.0     ggplot2_1.0.0      pROC_1.8           copula_0.999-11
>  [5] mvtnorm_1.0-0      lcmix_0.3          nnls_1.4           MASS_7.3-45
>  [9] matrixStats_0.10.0 R.methodsS3_1.6.1  psych_1.6.9
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.1      munsell_0.4.2    mnormt_1.5-1     ADGofTest_0.3
>  [5] colorspace_1.2-4 pspline_1.0-16   lattice_0.20-29  stringr_0.6.2
>  [9] plyr_1.8.1       tcltk_3.3.1      tools_3.3.1      parallel_3.3.1
> [13] grid_3.3.1       gtable_0.1.2     digest_0.6.4     Matrix_1.1-4
> [17] reshape2_1.4     labeling_0.3     scales_0.2.4     gsl_1.9-10
> [21] stats4_3.3.1     stabledist_0.6-6 foreign_0.8-66   proto_0.3-10
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Tue Jan 10 16:58:44 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 10 Jan 2017 09:58:44 -0600
Subject: [R] Assessing the name of an object within an argument
In-Reply-To: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>
References: <OF8337205C.B335F100-ONC12580A4.002F66E2-C12580A4.00307583@lotus.hawesko.de>
Message-ID: <CABdHhvFJP5ChRcxnXgKgJzpE45FK3KDdoHHRi0gnDmcjtcyKsQ@mail.gmail.com>

You might find http://adv-r.had.co.nz/Computing-on-the-language.html helpful.

Hadley

On Tue, Jan 10, 2017 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I have a function like
>
> my_func <- function(dataset)
> {
>   some operation
> }
>
> Now I would like not only to operate on the dataset (how this is done is
> obvious) but I would like to get the name of the dataset handed over as an
> argument.
>
> Example:
>
> my_func <- function(dataset = iris)
> {
>   print(dataset)  # here I do not want to print the dataset but the name
> of the object - iris in this case - instead
>   # quote() does not do the trick cause it prints "dataset" instead of
> "iris"
>   # as.name() gives an error saying that the object can not coerced to a
> symbol
> }
>
> Is there a way to do this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From dcarlson at tamu.edu  Tue Jan 10 17:03:52 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 10 Jan 2017 16:03:52 +0000
Subject: [R] how to proof the trend of two columns of data?
In-Reply-To: <1598842ef55.101f82e822686.1862894340827705399@zoho.com>
References: <15983ba57a1.114810fdb22468.7903301582019536849@zoho.com>
	<5873C808.5080604@sapo.pt>
	<9267fa5ef8ae4f6fabfad5546c218c24@exch-2p-mbx-w2.ads.tamu.edu>
	<1598842ef55.101f82e822686.1862894340827705399@zoho.com>
Message-ID: <d8819eb7b1f64fc5885065c0829a1609@exch-2p-mbx-w2.ads.tamu.edu>

As Rui noted, to get a trend you need to focus on percent gray vs age since hair color is not an ordinal/rank variable. Then use a measure of association designed for rank variables of which there are many: Spearman?s r, Kendall?s tau, gamma, tau-c, Somers-d. All of them are available in package DescTools.

David C

From: vod vos [mailto:vodvos at zoho.com]
Sent: Tuesday, January 10, 2017 6:03 AM
To: David L Carlson
Cc: Rui Barradas; r-help
Subject: Re: [R] how to proof the trend of two columns of data?

as far as I know,  ?kruskal.test will show us the differences between three or more groups. But it could show the trend.


---- On ???, 09 ?? 2017 10:12:14 -0800 David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote ----

The list does not assist with homework problems. If this is not a class assignment, you should be more specific about what you have tried and provide a reproducible example (a sample of the real data or some made-up data that has the same columns and data types). In the meantime you could also try the following R command:

> ?kruskal.test

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Rui Barradas
Sent: Monday, January 9, 2017 11:28 AM
To: vod vos; r-help
Subject: Re: [R] how to proof the trend of two columns of data?

Hello,

Inline.

Em 09-01-2017 14:55, vod vos escreveu:
> Hello everyone,
>
>
>
> If there are two columns, one is age (numeric, cut to several groups), the other is hair color type(factor: yellow, black, white).
>
>
>
> If the age column is not normal distributed

If you use ?lm, it's the residuals that should be normally distributed,
not age.
You can also use ?glm with a binomial link, in which case you should
recode type as white/not white.

Hope this helps,

Rui Barradas

, which statistic method should use to prove the trend relationship
between them, for example, the older has more probability of white hair
type? Are there any existed R package to figure out this situation?
>
>
>
> Thank you.
>
>
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=CwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=dYbJ1jQFhNgZSpX0dKdCO9D4cZWmkFMSAQSB3IC3bgY&s=U9wEEeg-qBbAGd3kjbAL6vlYC7cHatQHXWCc216ugVA&e=>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=CwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=dYbJ1jQFhNgZSpX0dKdCO9D4cZWmkFMSAQSB3IC3bgY&s=cvDboOH1gMUry-kXLtHgdlh4ICbrTPQE9fjNNO2xPho&e=>
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=CwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=dYbJ1jQFhNgZSpX0dKdCO9D4cZWmkFMSAQSB3IC3bgY&s=U9wEEeg-qBbAGd3kjbAL6vlYC7cHatQHXWCc216ugVA&e=>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=CwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=dYbJ1jQFhNgZSpX0dKdCO9D4cZWmkFMSAQSB3IC3bgY&s=cvDboOH1gMUry-kXLtHgdlh4ICbrTPQE9fjNNO2xPho&e=>
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=CwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=dYbJ1jQFhNgZSpX0dKdCO9D4cZWmkFMSAQSB3IC3bgY&s=U9wEEeg-qBbAGd3kjbAL6vlYC7cHatQHXWCc216ugVA&e=>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=CwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=dYbJ1jQFhNgZSpX0dKdCO9D4cZWmkFMSAQSB3IC3bgY&s=cvDboOH1gMUry-kXLtHgdlh4ICbrTPQE9fjNNO2xPho&e=>
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Jan 10 17:15:05 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 10 Jan 2017 08:15:05 -0800
Subject: [R] PNG File in R Markdown HTML
In-Reply-To: <CAB=p7SqVsTL5+fct-7ArbK=erkpcZ5hzjHFYidysr1b4f+2a_g@mail.gmail.com>
References: <CAB=p7SqVsTL5+fct-7ArbK=erkpcZ5hzjHFYidysr1b4f+2a_g@mail.gmail.com>
Message-ID: <15731C6D-4A73-4830-990F-8B4D68CC5EC8@dcn.davis.ca.us>

Someone here may have an answer for you,  but in general to solve this you need to use CSS which implies you also need to understand HTML, and neither of these subjects are on topic here (where the topic is the R language). Once you know what you want the output of knitr to look like then you need to learn how to get that code through knitr, which has its own mailing list. If you are lucky someone may have already made an rmarkdown template you could use or modify. You might try Googling "rmarkdown logo html".
-- 
Sent from my phone. Please excuse my brevity.

On January 10, 2017 5:57:01 AM PST, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>Hi Team,
>
>I am successfully able to add the company logo to the R markdown file
>using
>the code below:
>
>```{r, fig.width=3, fig.height=15,echo=FALSE, warning=FALSE,
>message=FALSE}
>library(png)
>library(grid)
>img <- readPNG("D:/Shivi/R Project/Name.png")
> grid.raster(img)
>```
>However the image gets displayed at the bottom of the html page. I have
>tried deleting any empty space after this code but it does not help.
>
>Request you to please advice.
>Thanks, Shivi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Pierre.Racine at sbf.ulaval.ca  Tue Jan 10 16:39:29 2017
From: Pierre.Racine at sbf.ulaval.ca (Pierre Racine)
Date: Tue, 10 Jan 2017 15:39:29 +0000
Subject: [R] =?iso-8859-1?q?Announcing_the_biggest_French-speaking_R_Confe?=
 =?iso-8859-1?q?rence_in_North_America_-_R_=E0_Qu=E9bec_2017?=
Message-ID: <fa6552b6b0934e00a8305ce764e87648@ul-exc-pr-mbx14.ulaval.ca>

We are posting this info here because most French-speaking R users in North America use this forum even if English is not their first language.

Le comit? scientifique du Colloque R ? Qu?bec 2017 (http://raquebec.ulaval.ca) recueille jusqu'au 15 janvier 2017 des propositions de conf?rences touchant, entre autres, aux th?mes suivants :

.        statistiques descriptives
.        analyse et traitement de donn?es
.        visualisation et graphiques
.        mod?lisation, optimisation et simulation
.        calcul haute performance
.        forage de donn?es
.        applications en recherche, en enseignement ou dans les secteurs public ou priv?

Dans une perspective d'interdisciplinarit?, l'accent de la conf?rence doit porter sur l'utilisation de R. Les pr?sentations se d?rouleront en fran?ais et elles seront d'une dur?e de 20 minutes. Il est possible que les auteurs de propositions de conf?rences non retenues soient invit?s ? pr?senter sous forme d'affiche. Les conf?renciers devront s'inscrire et payer leurs frais d'inscription.

La date limite pour soumettre une pr?sentation est le 15 janvier 2017.

R ? Qu?bec 2017 (raquebec.ulaval.ca) est un colloque interdisciplinaire rassemblant chercheurs, ?tudiants, praticiens et professionnels des milieux acad?miques, gouvernementaux et industriels. ? l'instar des conf?rences useR, ce premier colloque d'envergure au Qu?bec d?di? sp?cifiquement ? l'utilisation de R favorisera le transfert d'expertise entre les disciplines, l'avancement des pratiques et, pour certains, le passage vers l'environnement R. La premi?re journ?e sera consacr?e ? des ateliers de formation introductifs et avanc?s et la deuxi?me ? des conf?rences. Le colloque aura lieu les 25 et 26 mai 2017.

Comit? scientifique :

.        Alexandre Bureau - D?partement de m?decine sociale et pr?ventive, Universit? Laval
.        Anne-Sophie Charest - D?partement de math?matiques et statistique, Universit? Laval
.        Arnaud Droit - D?partement de m?decine mol?culaire, Universit? Laval
.        Vincent Goulet - ?cole d'actuariat, Universit? Laval
.        Charles Fleury - D?partement de sociologie, Universit? Laval

Pour toute information sur l'appel de conf?rence, contactez Vincent Goulet (Vincent.Goulet at act.ulaval.ca). Pour toute autre information sur R ? Qu?bec 2017, contactez Natacha Fontaine (raquebec at ulaval.ca) ou visitez notre site web : http://raquebec.ulaval.ca.


From zeeshan.lakshya at gmail.com  Tue Jan 10 18:33:17 2017
From: zeeshan.lakshya at gmail.com (Lakshya Agrawal)
Date: Tue, 10 Jan 2017 23:03:17 +0530
Subject: [R] Getting Started
Message-ID: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>

Hello,
 I would like to contribute to R i have gone over the development page but
could find anything on how to get started .Please can someone help me
getting started. Sorry if i have overlooked something.

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Tue Jan 10 20:51:07 2017
From: davidsmi at microsoft.com (David Smith)
Date: Tue, 10 Jan 2017 19:51:07 +0000
Subject: [R] Revolutions blog: December 2016 roundup
Message-ID: <CY1PR0301MB21058261C260A4DB7318352BC8670@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of December:

Power BI now has a gallery of custom visualizations built with R:
http://blog.revolutionanalytics.com/2016/12/power-bi-custom-visuals-based-on-r.html

Chicago's Department of Public Health uses R to prioritize health inspections at restaurants:
http://blog.revolutionanalytics.com/2016/12/food-inspection-forecasting.html

A beautiful map of Switzerland municipalities combined with a relief map of the mountains, created with R:
http://blog.revolutionanalytics.com/2016/12/swiss-map.html

Using the Azure Interface Tool to parallelize the problem of optimizing an R model across the hyperparameter space:
http://blog.revolutionanalytics.com/2016/12/azure-r-interface-tool.html

A primer on Bayesian Statistics: http://blog.revolutionanalytics.com/2016/12/bayesian-inference.html

Animating Voronoi tesselations in R to create a greeting card:
http://blog.revolutionanalytics.com/2016/12/merry-christmas.html

The Linux Data Science Virtual Machine, which includes several R-related components, is available for a free "test
drive" on Azure: http://blog.revolutionanalytics.com/2016/12/dsvm-test-drive.html

The new AzureSMR package lets you manage Azure virtual machines, clusters and storage from R:
http://blog.revolutionanalytics.com/2016/12/azuresmr.html

Interactive decision trees in Microsoft R Server:
http://blog.revolutionanalytics.com/2016/12/interactive-decision-trees-with-microsoft-r.html

The ompr package provides numerical optimization with mixed integer programming:
http://blog.revolutionanalytics.com/2016/12/mixed-integer-programming-in-r-with-the-ompr-package.html

Predicting flu deaths in China with R: http://blog.revolutionanalytics.com/2016/12/predicting-flu-deaths.html

Using the circlize package and Microsoft R Server's Spark interface to visualize millions of taxi trips:
http://blog.revolutionanalytics.com/2016/12/taxi-mrs-spark.html

The State of Indiana uses R to forecast employment:
http://blog.revolutionanalytics.com/2016/12/state-of-indiana-employment.html

"One Page R" is a free, multi-chapter tutorial on data science topics with R:
http://blog.revolutionanalytics.com/2016/12/one-page-r.html

The Deputy Chief Economist at Freddie Mac used R to animate the different rates of housing price increases around the
world: http://blog.revolutionanalytics.com/2016/12/housing-prices.html

I gave a talk about the value of ecosystems to open source projects, using R as an example:
http://blog.revolutionanalytics.com/2016/12/the-value-of-rs-open-source-ecosystem.html

A summary of some recent projects funded by the R Consortium:
http://blog.revolutionanalytics.com/2016/12/r-consortium-projects-update.html 

Microsoft R Server 9.0, featuring R 3.3.2 and support for Spark 2.0, is now available:
http://blog.revolutionanalytics.com/2016/12/microsoft-r-server-90-now-available.html

The dplyrXdf package has been updated with new features for managing XDF data sets in Microsoft R:
http://blog.revolutionanalytics.com/2016/12/dplyrxdf-090-now-available.html

A stylometric analysis of the speeches of the Prime Minister of Pakistan:
http://blog.revolutionanalytics.com/2016/12/stylometry.html

Using R and the d3heatmap package to visualize the emotional journey of characters in "War and Peace":
http://blog.revolutionanalytics.com/2016/12/war-and-peace.html#more

General interest stories (not related to R) in the past month included: the horrors of 2016
(http://blog.revolutionanalytics.com/2016/12/because-its-friday-goodbye-2016.html), a Machinima Christmas carol
(http://blog.revolutionanalytics.com/2016/12/because-its-friday-a-christmas-destiny.html), freezing bubbles
(http://blog.revolutionanalytics.com/2016/12/because-its-friday-im-forever-freezing-bubbles.html), dark comics
(http://blog.revolutionanalytics.com/2016/12/because-its-friday-angst-in-four-panels.html), and a virtual flight along
the US-Mexico border (http://blog.revolutionanalytics.com/2016/12/because-its-friday-border.html).

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From drjimlemon at gmail.com  Tue Jan 10 22:13:51 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 11 Jan 2017 08:13:51 +1100
Subject: [R] Getting Started
In-Reply-To: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>
References: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>
Message-ID: <CA+8X3fUotdgaa17EZybnLKR8PS6fzwWQibuMgTBZ38LvYJSpFA@mail.gmail.com>

Hi Lakshya,
One good way to contribute is to try to do something in R, and if you
see a way to do it better or more easily, you may have an improvement
that will find its way into R. This usually involves a lot of
discovering that someone else has already done it, but as your
knowledge of R expands, so do the opportunities to find something that
no one has yet accomplished.

Jim


On Wed, Jan 11, 2017 at 4:33 AM, Lakshya Agrawal
<zeeshan.lakshya at gmail.com> wrote:
> Hello,
>  I would like to contribute to R i have gone over the development page but
> could find anything on how to get started .Please can someone help me
> getting started. Sorry if i have overlooked something.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jan 10 23:09:55 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 10 Jan 2017 14:09:55 -0800
Subject: [R] Getting Started
In-Reply-To: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>
References: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>
Message-ID: <CAGxFJbRobt3vTcfs2Mn0iywdd3oNATWfS6giT4Xn+pYX4t5frg@mail.gmail.com>

You obviously know little about R or you would not have asked that
question. So heeding Jim's advice is clearly your first step. A second
would be to read the "Writing R extensions" manual to learn about R
packages. A third would be to check out the CRAN task views to get a sense
of what's available in the 3000 or more packages users have already
contributed.

Cheers,

Bert

On Jan 10, 2017 1:50 PM, "Lakshya Agrawal" <zeeshan.lakshya at gmail.com>
wrote:

> Hello,
>  I would like to contribute to R i have gone over the development page but
> could find anything on how to get started .Please can someone help me
> getting started. Sorry if i have overlooked something.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Tue Jan 10 23:36:28 2017
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Tue, 10 Jan 2017 14:36:28 -0800
Subject: [R] Getting Started
In-Reply-To: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>
References: <CAE0ivFzzJ8KN0VrEcTMqqv-VGL2AhUBPSYf0b1PMjjmBNwK7iA@mail.gmail.com>
Message-ID: <CAJeYpE-cE1fLA_ADX5E_Sgbqd-_4ED5DniRV7YTqSEx2z5=yNw@mail.gmail.com>

By "contribute", do you mean you have a package (or potential package) that
you'd like to share? Or do you have something else in mind?

-Dan

On Tue, Jan 10, 2017 at 9:33 AM, Lakshya Agrawal <zeeshan.lakshya at gmail.com>
wrote:

> Hello,
>  I would like to contribute to R i have gone over the development page but
> could find anything on how to get started .Please can someone help me
> getting started. Sorry if i have overlooked something.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From btyner at gmail.com  Wed Jan 11 11:12:43 2017
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 11 Jan 2017 05:12:43 -0500
Subject: [R] file.exists() on device files
Message-ID: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>

Hi,

On my linux machine (Ubuntu, and also tested on RHEL), I am curious to 
know what might be causing file.exists (and also normalizePath) to not 
see the final device file here:

    > list.files("/dev/fd", full.names = TRUE)
    [1] "/dev/fd/0" "/dev/fd/1" "/dev/fd/2" "/dev/fd/3"
    > file.exists(list.files("/dev/fd", full.names = TRUE))
    [1]  TRUE  TRUE  TRUE FALSE
    > normalizePath(list.files("/dev/fd", full.names = TRUE))
    [1] "/dev/pts/2" "/dev/pts/2" "/dev/pts/2" "/dev/fd/3"
    Warning message:
    In normalizePath(list.files("/dev/fd", full.names = TRUE)) :
      path[4]="/dev/fd/3": No such file or directory

    > sessionInfo()
    R version 3.2.5 (2016-04-14)
    Platform: x86_64-pc-linux-gnu (64-bit)
    Running under: Ubuntu 16.04.1 LTS

    locale:
     [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
     [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
     [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
     [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
     [9] LC_ADDRESS=C               LC_TELEPHONE=C
    [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods base

Regards
Ben


From aoife.m.doherty at gmail.com  Wed Jan 11 15:08:19 2017
From: aoife.m.doherty at gmail.com (aoife doherty)
Date: Wed, 11 Jan 2017 14:08:19 +0000
Subject: [R] qvalue package: checking I'm using the right output values.
Message-ID: <CAAsJanb4btomF5WsyA+qkyra_SWjnVxU1RTN8kq_qHo0US5yqg@mail.gmail.com>

Can I ask, when I run the below code:


library(qvalue)

pvals
<-c(0.01,0.02,0.03,0.10,0.67,0.08,0.55,0.10,0.81,0.08,0.94,0.10,0.81,0.08,0.72,0.10,0.22,0.08,0.72,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.01,0.02,0.03,0.10,0.67,0.08,0.55,0.10,0.81,0.08,0.94,0.10,0.81,0.089,0.72,0.10,0.22,0.08,0.72,0.01,0.02,0.03,0.04,0.05,0.06,0.07)

qobj <-qvalue(p=pvals)

pvals

qobj$qvalues

qobj$lfdr


the qobj$qvalues list is:

 [1] 0.03592311 0.03592311 0.03592311 0.03991457 0.22490992 0.03991457

 [7] 0.19757712 0.03991457 0.23278177 0.03991457 0.25975174 0.03991457

[13] 0.23278177 0.03991457 0.22490992 0.03991457 0.08319037 0.03991457

[19] 0.22490992 0.03592311 0.03592311 0.03592311 0.03991457 0.03991457

[25] 0.03991457 0.03991457 0.03592311 0.03592311 0.03592311 0.03991457

[31] 0.22490992 0.03991457 0.19757712 0.03991457 0.23278177 0.03991457

[37] 0.25975174 0.03991457 0.23278177 0.03991457 0.22490992 0.03991457

[43] 0.08319037 0.03991457 0.22490992 0.03592311 0.03592311 0.03592311

[49] 0.03991457 0.03991457 0.03991457 0.03991457


and the qobj$lfdr list is:

 [1] 0.03070397 0.04312982 0.05458114 0.13925884 0.79081046 0.11311424

 [7] 0.79081046 0.13925884 0.79081046 0.11311424 0.79081046 0.13925884

[13] 0.79081046 0.11311424 0.79081046 0.13925884 0.34265237 0.11311424

[19] 0.79081046 0.03070397 0.04312982 0.05458114 0.06583569 0.07718949

[25] 0.08879583 0.10074920 0.03070397 0.04312982 0.05458114 0.13925884

[31] 0.79081046 0.11311424 0.79081046 0.13925884 0.79081046 0.11311424

[37] 0.79081046 0.13925884 0.79081046 0.12463425 0.79081046 0.13925884

[43] 0.34265237 0.11311424 0.79081046 0.03070397 0.04312982 0.05458114

[49] 0.06583569 0.07718949 0.08879583 0.10074920


Can I check that the qobj$lfdr are the FDR Q values (i.e. the number of
expected false positives over the number of significant results) for each
gene?


Thanks

	[[alternative HTML version deleted]]


From tungakantarci at gmail.com  Tue Jan 10 22:39:48 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Tue, 10 Jan 2017 22:39:48 +0100
Subject: [R] Delete the first instances of the unique values of a vector in R
Message-ID: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>

Consider a data frame which I name as rwrdatafile. It includes several
variables stored in columns. For each variable there are 1000
observations and hence 1000 rows. The interest lies in the values of
the second column of this data frame, that is in rwrdatafile[,2]. What
I am trying to accomplish is to delete the rows of the data frame if
it is the first instance of a unique value in rwrdatafile[,2]. That
is, the values stored in rwrdatafile[,2] look like

1
4
4
4
4
4
4
6
6

and the routine should delete 1 (and the other values in that row),
the first 4 (and the other values in that row), and the first 6 (and
the other values in that row). I did an online search, and indeed
there are similar examples, but they did not help for what I am trying
to achieve. What is specific to what I am trying to achieve is that
the routine should use a for loop. I have written a routine that is
not using a for loop and it works fine and I paste it below
(Vector-oriented coding in R). I need to write a for loop that
accomplishes the same task. In fact, I have written this for loop but
it has a problem (Scalar-oriened coding in R pasted below). Note that
the data stored in rwrdatafile[,2] has three unique values (there are
more but for making the example that does not matter) which are 1, 4,
6. The for loop I have written first determines the number of unique
values in rwrdatafile[,2], with length(unique(rwrdatafile[,2])), and
uses that number in the sequence of the for loop. The length is 3 so
the sequence is 1:3. But there is a catch! When 1 is deleted (and
other values row wise), the length decreases to 2 but the for loop
attempts 3 and therefore it returns NULL at the end of the loop.
Therefore I subtract 1 from the length. But this is not good coding. I
wondered about the NULL result and it took me a while to figure out
the problem, and worse is that I could have never found the problem.
So the for loop here is not reliable because it requires that the user
knows that there are multiple instances of the unique values (so
multiple instances of 1). How can I fix the problem? The restriction I
have is that I need to keep the for loop and it should resemble the
for loop I have written for MATLAB (pasted below). The aim is to
translate the MATLAB routine as close as possible in R. So I do not
want to deviate (much) from the MATLAB version of the code because
otherwise I cannot compare the routines while I am teaching this. That
is, I need to use a function in the for loop in R that is as close as
possible to the find function (with the first option) of MATLAB.

# Scalar-oriented coding in R
length(unique(rwrdatafile[,2]))
for (i in 1:(.Last.value-1)){
  rwrdatafile = rwrdatafile[-(which(rwrdatafile[,2] ==
unique(rwrdatafile[,2])[i])[1]),]
}

# Vector-oriented coding in R
unique(rwrdatafile[,2])
tag = match(.Last.value,rwrdatafile[,2])
rwrdatafile = rwrdatafile[!row.names(rwrdatafile) %in% tag,]

# Scalar-oriented coding in MATLAB
unique(mwmatfile.data(:,2));
for i = ans'
    mwmatfile.data(find(mwmatfile.data(:,2) == i,1,'first'),:) = [];
end


From tungakantarci at gmail.com  Wed Jan 11 12:53:11 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Wed, 11 Jan 2017 12:53:11 +0100
Subject: [R] How to automatically create data frames from an existing one?
Message-ID: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>

I have a data frame that includes several columns representing
variables and variables names are indicated at the top row of the data
frame. That is, I had a csv file where variable names were stored in
the top row, and when I imported the csv file to R, R created a data
frame that appears with the name rwrdatafile (custom name I gave)
where I can see all the variables with their names on the top row in
RStudio. For example, one of the columns stores wage data and I can
create a stand alone data frame (shall I call it a vector data frame?)
for wage, but do this for all variables.

That is, I can execute the command

wage = rwrdatafile[,1,drop=FALSE]

which nicely creates wage and RStudio shows it as data in its
environment window and if I click on it, I can inspect it in a spread
sheet like view and work with that data say in regression analysis.

The problem is that there are many variables stored in the data frame
rwrdatafile, and it is very tedious to repeat the above mentioned
routine for each variable. Hence I attempted to write a for loop for
this but it helped to no avail.

In particular, I tried

for (i in 1:k){
  assign(names(rwrdatafile)[i],rwrdatafile[,i])
}

and in fact this nicely assigns each column in the data frame to a
name, but I do not see the variables as data in the environment
section. But what I need are variables that I can work with in matrix
operations.

I also tried

for(i in 1:k){
  names(rwrdatafile)[i] = rwrdatafile[,i,drop=FALSE]
}

thinking that this for loop would just repeat what I do for

wage = rwrdatafile[,1,drop=FALSE]

for all the variables in rwrdatafile.

Please note that I do need to use a for loop and in fact I need to
translate and imitate the MATLAB code below, which does the job in
MATLAB, as close as possible in R.

# MATLAB code generating variables from structure array rwrdatafile
[N,k] = size(rwrdatafile.data);
for i = 1:k
    eval([cell2mat(rwrdatafile.textdata(i)) '= rwrdatafile.data(:,i);'])
end


From sarah.goslee at gmail.com  Wed Jan 11 18:31:09 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Jan 2017 12:31:09 -0500
Subject: [R] How to automatically create data frames from an existing
	one?
In-Reply-To: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>
References: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>
Message-ID: <CAM_vjumZgFgk+j9yO7C=LG6O=qRT_7EsMPJG3sAt4krbtWfzqw@mail.gmail.com>

I do not understand why you want to take a perfectly good data frame
and split it into a whole bunch of single-column data frames instead
of working with it as-is. The latter seems like an awkward and
unnecessary thing to do.

If you explain what you're trying to do, we can help. Referencing
MATLAB code isn't useful, because R does not have the same underlying
way of working.

You can readily use columns of a data frame in other operations
without doing this.

Sarah

On Wed, Jan 11, 2017 at 6:53 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> I have a data frame that includes several columns representing
> variables and variables names are indicated at the top row of the data
> frame. That is, I had a csv file where variable names were stored in
> the top row, and when I imported the csv file to R, R created a data
> frame that appears with the name rwrdatafile (custom name I gave)
> where I can see all the variables with their names on the top row in
> RStudio. For example, one of the columns stores wage data and I can
> create a stand alone data frame (shall I call it a vector data frame?)
> for wage, but do this for all variables.
>
> That is, I can execute the command
>
> wage = rwrdatafile[,1,drop=FALSE]
>
> which nicely creates wage and RStudio shows it as data in its
> environment window and if I click on it, I can inspect it in a spread
> sheet like view and work with that data say in regression analysis.
>
> The problem is that there are many variables stored in the data frame
> rwrdatafile, and it is very tedious to repeat the above mentioned
> routine for each variable. Hence I attempted to write a for loop for
> this but it helped to no avail.
>
> In particular, I tried
>
> for (i in 1:k){
>   assign(names(rwrdatafile)[i],rwrdatafile[,i])
> }
>
> and in fact this nicely assigns each column in the data frame to a
> name, but I do not see the variables as data in the environment
> section. But what I need are variables that I can work with in matrix
> operations.
>
> I also tried
>
> for(i in 1:k){
>   names(rwrdatafile)[i] = rwrdatafile[,i,drop=FALSE]
> }
>
> thinking that this for loop would just repeat what I do for
>
> wage = rwrdatafile[,1,drop=FALSE]
>
> for all the variables in rwrdatafile.
>
> Please note that I do need to use a for loop and in fact I need to
> translate and imitate the MATLAB code below, which does the job in
> MATLAB, as close as possible in R.
>
> # MATLAB code generating variables from structure array rwrdatafile
> [N,k] = size(rwrdatafile.data);
> for i = 1:k
>     eval([cell2mat(rwrdatafile.textdata(i)) '= rwrdatafile.data(:,i);'])
> end
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From ruipbarradas at sapo.pt  Wed Jan 11 18:31:54 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 11 Jan 2017 17:31:54 +0000
Subject: [R] Delete the first instances of the unique values of a vector
 in R
In-Reply-To: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>
References: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>
Message-ID: <58766C0A.2010200@sapo.pt>

Hello,

Just see the following.

x <- scan(text = "
1
4
4
4
4
4
4
6
6")
dat <- data.frame(x, y = rnorm(length(x)))

dat[-which(c(TRUE, dat$x[-1] != dat$x[-length(dat$x)])), ]

And now instead of 'dat' call your dataset 'rwrdatafile', and the same 
for the column of interess.

Hope this helps,

Rui Barradas

Em 10-01-2017 21:39, Tunga Kantarc? escreveu:
> Consider a data frame which I name as rwrdatafile. It includes several
> variables stored in columns. For each variable there are 1000
> observations and hence 1000 rows. The interest lies in the values of
> the second column of this data frame, that is in rwrdatafile[,2]. What
> I am trying to accomplish is to delete the rows of the data frame if
> it is the first instance of a unique value in rwrdatafile[,2]. That
> is, the values stored in rwrdatafile[,2] look like
>
> 1
> 4
> 4
> 4
> 4
> 4
> 4
> 6
> 6
>
> and the routine should delete 1 (and the other values in that row),
> the first 4 (and the other values in that row), and the first 6 (and
> the other values in that row). I did an online search, and indeed
> there are similar examples, but they did not help for what I am trying
> to achieve. What is specific to what I am trying to achieve is that
> the routine should use a for loop. I have written a routine that is
> not using a for loop and it works fine and I paste it below
> (Vector-oriented coding in R). I need to write a for loop that
> accomplishes the same task. In fact, I have written this for loop but
> it has a problem (Scalar-oriened coding in R pasted below). Note that
> the data stored in rwrdatafile[,2] has three unique values (there are
> more but for making the example that does not matter) which are 1, 4,
> 6. The for loop I have written first determines the number of unique
> values in rwrdatafile[,2], with length(unique(rwrdatafile[,2])), and
> uses that number in the sequence of the for loop. The length is 3 so
> the sequence is 1:3. But there is a catch! When 1 is deleted (and
> other values row wise), the length decreases to 2 but the for loop
> attempts 3 and therefore it returns NULL at the end of the loop.
> Therefore I subtract 1 from the length. But this is not good coding. I
> wondered about the NULL result and it took me a while to figure out
> the problem, and worse is that I could have never found the problem.
> So the for loop here is not reliable because it requires that the user
> knows that there are multiple instances of the unique values (so
> multiple instances of 1). How can I fix the problem? The restriction I
> have is that I need to keep the for loop and it should resemble the
> for loop I have written for MATLAB (pasted below). The aim is to
> translate the MATLAB routine as close as possible in R. So I do not
> want to deviate (much) from the MATLAB version of the code because
> otherwise I cannot compare the routines while I am teaching this. That
> is, I need to use a function in the for loop in R that is as close as
> possible to the find function (with the first option) of MATLAB.
>
> # Scalar-oriented coding in R
> length(unique(rwrdatafile[,2]))
> for (i in 1:(.Last.value-1)){
>    rwrdatafile = rwrdatafile[-(which(rwrdatafile[,2] ==
> unique(rwrdatafile[,2])[i])[1]),]
> }
>
> # Vector-oriented coding in R
> unique(rwrdatafile[,2])
> tag = match(.Last.value,rwrdatafile[,2])
> rwrdatafile = rwrdatafile[!row.names(rwrdatafile) %in% tag,]
>
> # Scalar-oriented coding in MATLAB
> unique(mwmatfile.data(:,2));
> for i = ans'
>      mwmatfile.data(find(mwmatfile.data(:,2) == i,1,'first'),:) = [];
> end
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Wed Jan 11 18:33:54 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Jan 2017 12:33:54 -0500
Subject: [R] Delete the first instances of the unique values of a vector
 in R
In-Reply-To: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>
References: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>
Message-ID: <CAM_vju=XXrALPY=WUZ=vuG93_8Y3XwB1AY++V_DS1Y-SZjq4uw@mail.gmail.com>

I think you should probably go read some introductory material on R.
There are lots of good references out there. R does not work in the
same way as MATLAB.

You should probably also read the posting guide, and this article on
making good reproducible examples:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Meanwhile, it sounds like you might want this:

> vec <- c(1, 4, 4, 4, 4, 4, 6, 6)
> !duplicated(vec)
[1]  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE


On Tue, Jan 10, 2017 at 4:39 PM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> Consider a data frame which I name as rwrdatafile. It includes several
> variables stored in columns. For each variable there are 1000
> observations and hence 1000 rows. The interest lies in the values of
> the second column of this data frame, that is in rwrdatafile[,2]. What
> I am trying to accomplish is to delete the rows of the data frame if
> it is the first instance of a unique value in rwrdatafile[,2]. That
> is, the values stored in rwrdatafile[,2] look like
>
> 1
> 4
> 4
> 4
> 4
> 4
> 4
> 6
> 6
>
> and the routine should delete 1 (and the other values in that row),
> the first 4 (and the other values in that row), and the first 6 (and
> the other values in that row). I did an online search, and indeed
> there are similar examples, but they did not help for what I am trying
> to achieve. What is specific to what I am trying to achieve is that
> the routine should use a for loop. I have written a routine that is
> not using a for loop and it works fine and I paste it below
> (Vector-oriented coding in R). I need to write a for loop that
> accomplishes the same task. In fact, I have written this for loop but
> it has a problem (Scalar-oriened coding in R pasted below). Note that
> the data stored in rwrdatafile[,2] has three unique values (there are
> more but for making the example that does not matter) which are 1, 4,
> 6. The for loop I have written first determines the number of unique
> values in rwrdatafile[,2], with length(unique(rwrdatafile[,2])), and
> uses that number in the sequence of the for loop. The length is 3 so
> the sequence is 1:3. But there is a catch! When 1 is deleted (and
> other values row wise), the length decreases to 2 but the for loop
> attempts 3 and therefore it returns NULL at the end of the loop.
> Therefore I subtract 1 from the length. But this is not good coding. I
> wondered about the NULL result and it took me a while to figure out
> the problem, and worse is that I could have never found the problem.
> So the for loop here is not reliable because it requires that the user
> knows that there are multiple instances of the unique values (so
> multiple instances of 1). How can I fix the problem? The restriction I
> have is that I need to keep the for loop and it should resemble the
> for loop I have written for MATLAB (pasted below). The aim is to
> translate the MATLAB routine as close as possible in R. So I do not
> want to deviate (much) from the MATLAB version of the code because
> otherwise I cannot compare the routines while I am teaching this. That
> is, I need to use a function in the for loop in R that is as close as
> possible to the find function (with the first option) of MATLAB.
>
> # Scalar-oriented coding in R
> length(unique(rwrdatafile[,2]))
> for (i in 1:(.Last.value-1)){
>   rwrdatafile = rwrdatafile[-(which(rwrdatafile[,2] ==
> unique(rwrdatafile[,2])[i])[1]),]
> }
>
> # Vector-oriented coding in R
> unique(rwrdatafile[,2])
> tag = match(.Last.value,rwrdatafile[,2])
> rwrdatafile = rwrdatafile[!row.names(rwrdatafile) %in% tag,]
>
> # Scalar-oriented coding in MATLAB
> unique(mwmatfile.data(:,2));
> for i = ans'
>     mwmatfile.data(find(mwmatfile.data(:,2) == i,1,'first'),:) = [];
> end
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Wed Jan 11 18:36:38 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 11 Jan 2017 09:36:38 -0800
Subject: [R] How to automatically create data frames from an existing
	one?
In-Reply-To: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>
References: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>
Message-ID: <CAF8bMcZqey4pERGtV=9Dq+_tpoA+1sb4X-N8gh2gHMHcL=i=kQ@mail.gmail.com>

You can use the 'with' function or the 'data' argument to many functions
to use the variables in the data frame without copying them out to the
global environment.  Leaving them in the data.frame keeps them from
getting lost among the temporary variables in the global environment.

> Data <- read.csv(header=TRUE, text=
+ "Name,Education,Wage
+ Abe,PhD,105
+ Bob,MS,108
+ Chuck,BS,118
+ Dave,PhD,102")
> with(Data, tapply(Wage, Education, mean))
   BS    MS   PhD
118.0 108.0 103.5
> lm(data=Data, Wage ~ Education - 1)

Call:
lm(formula = Wage ~ Education - 1, data = Data)

Coefficients:
 EducationBS   EducationMS  EducationPhD
       118.0         108.0         103.5


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Jan 11, 2017 at 3:53 AM, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> I have a data frame that includes several columns representing
> variables and variables names are indicated at the top row of the data
> frame. That is, I had a csv file where variable names were stored in
> the top row, and when I imported the csv file to R, R created a data
> frame that appears with the name rwrdatafile (custom name I gave)
> where I can see all the variables with their names on the top row in
> RStudio. For example, one of the columns stores wage data and I can
> create a stand alone data frame (shall I call it a vector data frame?)
> for wage, but do this for all variables.
>
> That is, I can execute the command
>
> wage = rwrdatafile[,1,drop=FALSE]
>
> which nicely creates wage and RStudio shows it as data in its
> environment window and if I click on it, I can inspect it in a spread
> sheet like view and work with that data say in regression analysis.
>
> The problem is that there are many variables stored in the data frame
> rwrdatafile, and it is very tedious to repeat the above mentioned
> routine for each variable. Hence I attempted to write a for loop for
> this but it helped to no avail.
>
> In particular, I tried
>
> for (i in 1:k){
>   assign(names(rwrdatafile)[i],rwrdatafile[,i])
> }
>
> and in fact this nicely assigns each column in the data frame to a
> name, but I do not see the variables as data in the environment
> section. But what I need are variables that I can work with in matrix
> operations.
>
> I also tried
>
> for(i in 1:k){
>   names(rwrdatafile)[i] = rwrdatafile[,i,drop=FALSE]
> }
>
> thinking that this for loop would just repeat what I do for
>
> wage = rwrdatafile[,1,drop=FALSE]
>
> for all the variables in rwrdatafile.
>
> Please note that I do need to use a for loop and in fact I need to
> translate and imitate the MATLAB code below, which does the job in
> MATLAB, as close as possible in R.
>
> # MATLAB code generating variables from structure array rwrdatafile
> [N,k] = size(rwrdatafile.data);
> for i = 1:k
>     eval([cell2mat(rwrdatafile.textdata(i)) '= rwrdatafile.data(:,i);'])
> end
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jan 11 18:38:14 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 11 Jan 2017 17:38:14 +0000
Subject: [R] Delete the first instances of the unique values of a vector
 in R
In-Reply-To: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>
References: <CAMDpC=siie6t=O5uOs_FNgx4ShoFmcoxrGg1t8MU2zCMsNEOUQ@mail.gmail.com>
Message-ID: <58766D86.6060905@sapo.pt>

Hello again,

Sorry about my first answer, I hadn't read until the part you say you 
need a for loop. Why you need it seems strange to me but here it is.


delete <- c(TRUE, dat$x[-1] != dat$x[-length(dat$x)])
result <- data.frame()
for(i in seq_along(delete)){
	if(!delete[i])
		result <- rbind(result, dat[i, ])
}
result

Rui Barradas

Em 10-01-2017 21:39, Tunga Kantarc? escreveu:
> Consider a data frame which I name as rwrdatafile. It includes several
> variables stored in columns. For each variable there are 1000
> observations and hence 1000 rows. The interest lies in the values of
> the second column of this data frame, that is in rwrdatafile[,2]. What
> I am trying to accomplish is to delete the rows of the data frame if
> it is the first instance of a unique value in rwrdatafile[,2]. That
> is, the values stored in rwrdatafile[,2] look like
>
> 1
> 4
> 4
> 4
> 4
> 4
> 4
> 6
> 6
>
> and the routine should delete 1 (and the other values in that row),
> the first 4 (and the other values in that row), and the first 6 (and
> the other values in that row). I did an online search, and indeed
> there are similar examples, but they did not help for what I am trying
> to achieve. What is specific to what I am trying to achieve is that
> the routine should use a for loop. I have written a routine that is
> not using a for loop and it works fine and I paste it below
> (Vector-oriented coding in R). I need to write a for loop that
> accomplishes the same task. In fact, I have written this for loop but
> it has a problem (Scalar-oriened coding in R pasted below). Note that
> the data stored in rwrdatafile[,2] has three unique values (there are
> more but for making the example that does not matter) which are 1, 4,
> 6. The for loop I have written first determines the number of unique
> values in rwrdatafile[,2], with length(unique(rwrdatafile[,2])), and
> uses that number in the sequence of the for loop. The length is 3 so
> the sequence is 1:3. But there is a catch! When 1 is deleted (and
> other values row wise), the length decreases to 2 but the for loop
> attempts 3 and therefore it returns NULL at the end of the loop.
> Therefore I subtract 1 from the length. But this is not good coding. I
> wondered about the NULL result and it took me a while to figure out
> the problem, and worse is that I could have never found the problem.
> So the for loop here is not reliable because it requires that the user
> knows that there are multiple instances of the unique values (so
> multiple instances of 1). How can I fix the problem? The restriction I
> have is that I need to keep the for loop and it should resemble the
> for loop I have written for MATLAB (pasted below). The aim is to
> translate the MATLAB routine as close as possible in R. So I do not
> want to deviate (much) from the MATLAB version of the code because
> otherwise I cannot compare the routines while I am teaching this. That
> is, I need to use a function in the for loop in R that is as close as
> possible to the find function (with the first option) of MATLAB.
>
> # Scalar-oriented coding in R
> length(unique(rwrdatafile[,2]))
> for (i in 1:(.Last.value-1)){
>    rwrdatafile = rwrdatafile[-(which(rwrdatafile[,2] ==
> unique(rwrdatafile[,2])[i])[1]),]
> }
>
> # Vector-oriented coding in R
> unique(rwrdatafile[,2])
> tag = match(.Last.value,rwrdatafile[,2])
> rwrdatafile = rwrdatafile[!row.names(rwrdatafile) %in% tag,]
>
> # Scalar-oriented coding in MATLAB
> unique(mwmatfile.data(:,2));
> for i = ans'
>      mwmatfile.data(find(mwmatfile.data(:,2) == i,1,'first'),:) = [];
> end
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From weinerm at ccf.org  Wed Jan 11 19:54:24 2017
From: weinerm at ccf.org (Weiner, Michael)
Date: Wed, 11 Jan 2017 18:54:24 +0000
Subject: [R] installing rgl
Message-ID: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>

I have a Fedora linux 24 64bit workstation I am trying to install rgl on and I keep running into this error:

trying URL 'https://cran.cnr.berkeley.edu/src/contrib/rgl_0.97.0.tar.gz'
Content type 'application/x-gzip' length 2369444 bytes (2.3 MB)
==================================================
downloaded 2.3 MB

* installing *source* package 'rgl' ...
** package 'rgl' successfully unpacked and MD5 sums checked
checking for gcc... gcc -m64
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -m64 accepts -g... yes
checking for gcc -m64 option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -m64 -E
checking for gcc... (cached) gcc -m64
checking whether we are using the GNU C compiler... (cached) yes
checking whether gcc -m64 accepts -g... (cached) yes
checking for gcc -m64 option to accept ISO C89... (cached) none needed
checking whether __attribute__((visibility())) is supported... yes
checking whether gcc -m64 accepts -fvisibility... yes
checking whether  accepts -fvisibility... no
checking for libpng-config... yes
configure: using libpng-config
configure: using libpng dynamic linkage
checking for X... libraries , headers
checking GL/gl.h usability... yes
checking GL/gl.h presence... yes
checking for GL/gl.h... yes
checking GL/glu.h usability... yes
checking GL/glu.h presence... yes
checking for GL/glu.h... yes
checking for glEnd in -lGL... no
configure: error: missing required library GL
ERROR: configuration failed for package 'rgl'
* removing '/usr/lib64/R/library/rgl'

The downloaded source packages are in
        '/tmp/Rtmp0VF17F/downloaded_packages'
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("rgl") :
  installation of package 'rgl' had non-zero exit status

As you can see, it finds the GL headers, but fails on glEnd and then complains it cannot find the GL libraries. I have the mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel packages installed but I still get the errors.

Any thoughts?

Thank you in advance
Michael Weiner

===================================


 Please consider the environment before printing this e-mail

Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).  
Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.


Confidentiality Note:  This message is intended for use ...{{dropped:18}}


From dwinsemius at comcast.net  Wed Jan 11 20:41:51 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Jan 2017 11:41:51 -0800
Subject: [R] installing rgl
In-Reply-To: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
References: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
Message-ID: <BC283294-4E6F-46B2-A404-9D9A1F940A96@comcast.net>


> On Jan 11, 2017, at 10:54 AM, Weiner, Michael <weinerm at ccf.org> wrote:
> 
> I have a Fedora linux 24 64bit workstation I am trying to install rgl on and I keep running into this error:

I thin this is more appropriately directed to:

R-SIG-Fedora

https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

-- 
David.
> 
> trying URL 'https://cran.cnr.berkeley.edu/src/contrib/rgl_0.97.0.tar.gz'
> Content type 'application/x-gzip' length 2369444 bytes (2.3 MB)
> ==================================================
> downloaded 2.3 MB
> 
> * installing *source* package 'rgl' ...
> ** package 'rgl' successfully unpacked and MD5 sums checked
> checking for gcc... gcc -m64
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -m64 accepts -g... yes
> checking for gcc -m64 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -m64 -E
> checking for gcc... (cached) gcc -m64
> checking whether we are using the GNU C compiler... (cached) yes
> checking whether gcc -m64 accepts -g... (cached) yes
> checking for gcc -m64 option to accept ISO C89... (cached) none needed
> checking whether __attribute__((visibility())) is supported... yes
> checking whether gcc -m64 accepts -fvisibility... yes
> checking whether  accepts -fvisibility... no
> checking for libpng-config... yes
> configure: using libpng-config
> configure: using libpng dynamic linkage
> checking for X... libraries , headers
> checking GL/gl.h usability... yes
> checking GL/gl.h presence... yes
> checking for GL/gl.h... yes
> checking GL/glu.h usability... yes
> checking GL/glu.h presence... yes
> checking for GL/glu.h... yes
> checking for glEnd in -lGL... no
> configure: error: missing required library GL
> ERROR: configuration failed for package 'rgl'
> * removing '/usr/lib64/R/library/rgl'
> 
> The downloaded source packages are in
>        '/tmp/Rtmp0VF17F/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgl") :
>  installation of package 'rgl' had non-zero exit status
> 
> As you can see, it finds the GL headers, but fails on glEnd and then complains it cannot find the GL libraries. I have the mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel packages installed but I still get the errors.
> 
> Any thoughts?
> 
> Thank you in advance
> Michael Weiner
> 
> ===================================
> 
> 
> Please consider the environment before printing this e-mail
> 
> Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).  
> Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.
> 
> 
> Confidentiality Note:  This message is intended for use ...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From weinerm at ccf.org  Wed Jan 11 20:46:42 2017
From: weinerm at ccf.org (Weiner, Michael)
Date: Wed, 11 Jan 2017 19:46:42 +0000
Subject: [R] installing rgl
In-Reply-To: <BC283294-4E6F-46B2-A404-9D9A1F940A96@comcast.net>
References: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>,
	<BC283294-4E6F-46B2-A404-9D9A1F940A96@comcast.net>
Message-ID: <4A51D044-9264-4989-A2AC-5C453B8F5C33@ccf.org>

Thank you David

> On Jan 11, 2017, at 2:41 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jan 11, 2017, at 10:54 AM, Weiner, Michael <weinerm at ccf.org> wrote:
>> 
>> I have a Fedora linux 24 64bit workstation I am trying to install rgl on and I keep running into this error:
> 
> I thin this is more appropriately directed to:
> 
> R-SIG-Fedora
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
> 
> -- 
> David.
>> 
>> trying URL 'https://cran.cnr.berkeley.edu/src/contrib/rgl_0.97.0.tar.gz'
>> Content type 'application/x-gzip' length 2369444 bytes (2.3 MB)
>> ==================================================
>> downloaded 2.3 MB
>> 
>> * installing *source* package 'rgl' ...
>> ** package 'rgl' successfully unpacked and MD5 sums checked
>> checking for gcc... gcc -m64
>> checking whether the C compiler works... yes
>> checking for C compiler default output file name... a.out
>> checking for suffix of executables...
>> checking whether we are cross compiling... no
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc -m64 accepts -g... yes
>> checking for gcc -m64 option to accept ISO C89... none needed
>> checking how to run the C preprocessor... gcc -m64 -E
>> checking for gcc... (cached) gcc -m64
>> checking whether we are using the GNU C compiler... (cached) yes
>> checking whether gcc -m64 accepts -g... (cached) yes
>> checking for gcc -m64 option to accept ISO C89... (cached) none needed
>> checking whether __attribute__((visibility())) is supported... yes
>> checking whether gcc -m64 accepts -fvisibility... yes
>> checking whether  accepts -fvisibility... no
>> checking for libpng-config... yes
>> configure: using libpng-config
>> configure: using libpng dynamic linkage
>> checking for X... libraries , headers
>> checking GL/gl.h usability... yes
>> checking GL/gl.h presence... yes
>> checking for GL/gl.h... yes
>> checking GL/glu.h usability... yes
>> checking GL/glu.h presence... yes
>> checking for GL/glu.h... yes
>> checking for glEnd in -lGL... no
>> configure: error: missing required library GL
>> ERROR: configuration failed for package 'rgl'
>> * removing '/usr/lib64/R/library/rgl'
>> 
>> The downloaded source packages are in
>>       '/tmp/Rtmp0VF17F/downloaded_packages'
>> Updating HTML index of packages in '.Library'
>> Making 'packages.html' ... done
>> Warning message:
>> In install.packages("rgl") :
>> installation of package 'rgl' had non-zero exit status
>> 
>> As you can see, it finds the GL headers, but fails on glEnd and then complains it cannot find the GL libraries. I have the mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel packages installed but I still get the errors.
>> 
>> Any thoughts?
>> 
>> Thank you in advance
>> Michael Weiner
>> 
>> ===================================
>> 
>> 
>> Please consider the environment before printing this e-mail
>> 
>> Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).  
>> Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.
>> 
>> 
>> Confidentiality Note:  This message is intended for use ...{{dropped:18}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

===================================


 Please consider the environment before printing this e-mail

Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).  
Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.


Confidentiality Note:  This message is intended for use ...{{dropped:18}}


From murdoch.duncan at gmail.com  Wed Jan 11 20:55:14 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Jan 2017 14:55:14 -0500
Subject: [R] installing rgl
In-Reply-To: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
References: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
Message-ID: <1807ad96-3ec1-915c-9fdb-5e19c992a4e9@gmail.com>

On this page

http://forums.fedoraforum.org/showthread.php?t=294543

eventually it turned out that a similar problem was fixed by

yum install libpng-devel

For other readers, someone else posted that on OpenSUSE, this was the 
magic install:

sudo zypper in libpng16-devel

Duncan Murdoch

On 11/01/2017 1:54 PM, Weiner, Michael wrote:
> I have a Fedora linux 24 64bit workstation I am trying to install rgl on and I keep running into this error:
>
> trying URL 'https://cran.cnr.berkeley.edu/src/contrib/rgl_0.97.0.tar.gz'
> Content type 'application/x-gzip' length 2369444 bytes (2.3 MB)
> ==================================================
> downloaded 2.3 MB
>
> * installing *source* package 'rgl' ...
> ** package 'rgl' successfully unpacked and MD5 sums checked
> checking for gcc... gcc -m64
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -m64 accepts -g... yes
> checking for gcc -m64 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -m64 -E
> checking for gcc... (cached) gcc -m64
> checking whether we are using the GNU C compiler... (cached) yes
> checking whether gcc -m64 accepts -g... (cached) yes
> checking for gcc -m64 option to accept ISO C89... (cached) none needed
> checking whether __attribute__((visibility())) is supported... yes
> checking whether gcc -m64 accepts -fvisibility... yes
> checking whether  accepts -fvisibility... no
> checking for libpng-config... yes
> configure: using libpng-config
> configure: using libpng dynamic linkage
> checking for X... libraries , headers
> checking GL/gl.h usability... yes
> checking GL/gl.h presence... yes
> checking for GL/gl.h... yes
> checking GL/glu.h usability... yes
> checking GL/glu.h presence... yes
> checking for GL/glu.h... yes
> checking for glEnd in -lGL... no
> configure: error: missing required library GL
> ERROR: configuration failed for package 'rgl'
> * removing '/usr/lib64/R/library/rgl'
>
> The downloaded source packages are in
>         '/tmp/Rtmp0VF17F/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgl") :
>   installation of package 'rgl' had non-zero exit status
>
> As you can see, it finds the GL headers, but fails on glEnd and then complains it cannot find the GL libraries. I have the mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel packages installed but I still get the errors.
>
> Any thoughts?
>
> Thank you in advance
> Michael Weiner
>
> ===================================
>
>
>  Please consider the environment before printing this e-mail
>
> Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).
> Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.
>
>
> Confidentiality Note:  This message is intended for use ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From weinerm at ccf.org  Wed Jan 11 21:03:43 2017
From: weinerm at ccf.org (Weiner, Michael)
Date: Wed, 11 Jan 2017 20:03:43 +0000
Subject: [R] installing rgl
In-Reply-To: <1807ad96-3ec1-915c-9fdb-5e19c992a4e9@gmail.com>
References: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
	<1807ad96-3ec1-915c-9fdb-5e19c992a4e9@gmail.com>
Message-ID: <DC6306FFE044A644A9BEAE5A43DEA9250F75F0B5@CC-CLEXMB53.cc.ad.cchs.net>

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Wednesday, January 11, 2017 2:55 PM
To: Weiner, Michael <weinerm at ccf.org>; r-help at r-project.org
Subject: Re: [R] installing rgl

> On this page
>
>http://forums.fedoraforum.org/showthread.php?t=294543
>
>eventually it turned out that a similar problem was fixed by
>
>yum install libpng-devel

Thank you for your response Duncan, unfortunately that didn't help, though I do see in config.log:

configure:4429: checking for glEnd in -lGL
configure:4454: gcc -o conftest -g -O2  -DHAVE_PNG_H -I/usr/include/libpng16  conftest.c -lGL   -L/usr/lib64 -lpng16 -lX11 >&5
/usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/6.2.1/../../../libGL.so when searching for -lGL
/usr/bin/ld: skipping incompatible /lib/libGL.so when searching for -lGL
/usr/bin/ld: skipping incompatible /usr/lib/libGL.so when searching for -lGL
/usr/bin/ld: cannot find -lGL

So something else is up

Michael


===================================


 Please consider the environment before printing this e-mail

Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).  
Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.


Confidentiality Note:  This message is intended for use ...{{dropped:18}}


From murdoch.duncan at gmail.com  Wed Jan 11 21:14:12 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Jan 2017 15:14:12 -0500
Subject: [R] installing rgl
In-Reply-To: <DC6306FFE044A644A9BEAE5A43DEA9250F75F0B5@CC-CLEXMB53.cc.ad.cchs.net>
References: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
	<1807ad96-3ec1-915c-9fdb-5e19c992a4e9@gmail.com>
	<DC6306FFE044A644A9BEAE5A43DEA9250F75F0B5@CC-CLEXMB53.cc.ad.cchs.net>
Message-ID: <e4de19d7-12da-18f2-72fe-da64870b1b45@gmail.com>

On 11/01/2017 3:03 PM, Weiner, Michael wrote:
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Wednesday, January 11, 2017 2:55 PM
> To: Weiner, Michael <weinerm at ccf.org>; r-help at r-project.org
> Subject: Re: [R] installing rgl
>
>> On this page
>>
>> http://forums.fedoraforum.org/showthread.php?t=294543
>>
>> eventually it turned out that a similar problem was fixed by
>>
>> yum install libpng-devel
>
> Thank you for your response Duncan, unfortunately that didn't help, though I do see in config.log:
>
> configure:4429: checking for glEnd in -lGL
> configure:4454: gcc -o conftest -g -O2  -DHAVE_PNG_H -I/usr/include/libpng16  conftest.c -lGL   -L/usr/lib64 -lpng16 -lX11 >&5
> /usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-redhat-linux/6.2.1/../../../libGL.so when searching for -lGL
> /usr/bin/ld: skipping incompatible /lib/libGL.so when searching for -lGL
> /usr/bin/ld: skipping incompatible /usr/lib/libGL.so when searching for -lGL
> /usr/bin/ld: cannot find -lGL
>
> So something else is up
>

I don't know Fedora at all so I don't know what you'd need to do this, 
but I'd suggest asking to uninstall and reinstall mesa-libGL-devel and 
mesa-libGLU-devel (and maybe libpng-devel).

Duncan Murdoch

> Michael
>
>
> ===================================
>
>
>  Please consider the environment before printing this e-mail
>
> Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2015).
> Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.
>
>
> Confidentiality Note:  This message is intended for use ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pai1981 at gmail.com  Wed Jan 11 21:32:09 2017
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Wed, 11 Jan 2017 15:32:09 -0500
Subject: [R] Error in R_nc4_open
Message-ID: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>

Hi all,
I recently updated my Rstudio to the newer version (Version 1.0.136) and I
started to getting following error when I am trying to read netcdf files

Error in R_nc4_open: NetCDF: DAP server error

Any ideas?

with regards
-Deb

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed Jan 11 22:23:07 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 11 Jan 2017 21:23:07 +0000
Subject: [R] How to automatically create data frames from an existing
 one?
In-Reply-To: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>
References: <CAMDpC=skuuJG4KhCCz_yTRORkwWV5NSFjhU0LGxJJ85g5bKECA@mail.gmail.com>
Message-ID: <48F96C46-046B-40F2-A86B-65EC7C99AC87@llnl.gov>

I don't know what the matlab eval() function does, but this example might help you get started with the way R does things:

lapply( rwrdatafile, summary)

This will apply the summary() function to every column of the data frame.

As others have mentioned, it is bad R to create separate variables for each column of the data frame. Anything you want to do with your variable named wage you can do with rwdatafile$wage. Regression analysis even more you should NOT take the variables out of the data frame. Instead using things like
  lm( wage ~ year, data=rwdatafile)

But if you insist on it, then try this:

for (nm in names(rwrdatafile)) assign(nm, rwrdatafile[[nm]], '.GlobalEnv')

(assuming I got the parentheses matched correctly)

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 1/11/17, 3:53 AM, "R-help on behalf of Tunga Kantarc?" <r-help-bounces at r-project.org on behalf of tungakantarci at gmail.com> wrote:

    I have a data frame that includes several columns representing
    variables and variables names are indicated at the top row of the data
    frame. That is, I had a csv file where variable names were stored in
    the top row, and when I imported the csv file to R, R created a data
    frame that appears with the name rwrdatafile (custom name I gave)
    where I can see all the variables with their names on the top row in
    RStudio. For example, one of the columns stores wage data and I can
    create a stand alone data frame (shall I call it a vector data frame?)
    for wage, but do this for all variables.
    
    That is, I can execute the command
    
    wage = rwrdatafile[,1,drop=FALSE]
    
    which nicely creates wage and RStudio shows it as data in its
    environment window and if I click on it, I can inspect it in a spread
    sheet like view and work with that data say in regression analysis.
    
    The problem is that there are many variables stored in the data frame
    rwrdatafile, and it is very tedious to repeat the above mentioned
    routine for each variable. Hence I attempted to write a for loop for
    this but it helped to no avail.
    
    In particular, I tried
    
    for (i in 1:k){
      assign(names(rwrdatafile)[i],rwrdatafile[,i])
    }
    
    and in fact this nicely assigns each column in the data frame to a
    name, but I do not see the variables as data in the environment
    section. But what I need are variables that I can work with in matrix
    operations.
    
    I also tried
    
    for(i in 1:k){
      names(rwrdatafile)[i] = rwrdatafile[,i,drop=FALSE]
    }
    
    thinking that this for loop would just repeat what I do for
    
    wage = rwrdatafile[,1,drop=FALSE]
    
    for all the variables in rwrdatafile.
    
    Please note that I do need to use a for loop and in fact I need to
    translate and imitate the MATLAB code below, which does the job in
    MATLAB, as close as possible in R.
    
    # MATLAB code generating variables from structure array rwrdatafile
    [N,k] = size(rwrdatafile.data);
    for i = 1:k
        eval([cell2mat(rwrdatafile.textdata(i)) '= rwrdatafile.data(:,i);'])
    end
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewmil at dcn.davis.ca.us  Wed Jan 11 22:27:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 11 Jan 2017 13:27:03 -0800
Subject: [R] Error in R_nc4_open
In-Reply-To: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
Message-ID: <A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>

You will do yourself a favor if you pay attention to which software you are using.  When you use RStudio, the console window is a direct connection to R, which is NOT RStudio... it has a separate installer and a different support group (e.g. this mailing list). All of this means you have failed to tell us anything about the software that actually matters in your question... R, nor the CONTRIBUTED package (meaning NOT part of R or RStudio) containing the function you are having trouble with.

Go read the Posting Guide... carefully... and provide a reproducible example that leads to your error... and post in plain text rather than HTML email so your example doesn't get messed up in transit. The output of sessionInfo() after the error would probably be a good idea also. For good measure you should open R directly rather than through RStudio and confirm the results (if it doesn't happen in R then RStudio may be breaking R (rare, but it has happened) in which case you would have to ask them for help. 
-- 
Sent from my phone. Please excuse my brevity.

On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
>Hi all,
>I recently updated my Rstudio to the newer version (Version 1.0.136)
>and I
>started to getting following error when I am trying to read netcdf
>files
>
>Error in R_nc4_open: NetCDF: DAP server error
>
>Any ideas?
>
>with regards
>-Deb
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pai1981 at gmail.com  Wed Jan 11 22:46:23 2017
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Wed, 11 Jan 2017 16:46:23 -0500
Subject: [R] Error in R_nc4_open
In-Reply-To: <A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
Message-ID: <CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>

Hi Jeff,
Thanks for your detail response but I am really baffled by this sort of
response from a help group because I am also a part of a help group
(NCAR-Command Language).

Anyway I felt its R/Rstudio issue because my code was working properly
before..........but since the update it isn't working anymore

Here is few lines of my code

library("ncdf4")
gribfile<-"
http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
"
## open connection
nc <- nc_open(gribfile)

error-Error in R_nc4_open: NetCDF: DAP server error

I am getting the error message in nc_open.

Please excuse me if this not R issue. Please let me know which "*R HELP
GROUP*" I should post this message.

-Deb




On Wed, Jan 11, 2017 at 4:27 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You will do yourself a favor if you pay attention to which software you
> are using.  When you use RStudio, the console window is a direct connection
> to R, which is NOT RStudio... it has a separate installer and a different
> support group (e.g. this mailing list). All of this means you have failed
> to tell us anything about the software that actually matters in your
> question... R, nor the CONTRIBUTED package (meaning NOT part of R or
> RStudio) containing the function you are having trouble with.
>
> Go read the Posting Guide... carefully... and provide a reproducible
> example that leads to your error... and post in plain text rather than HTML
> email so your example doesn't get messed up in transit. The output of
> sessionInfo() after the error would probably be a good idea also. For good
> measure you should open R directly rather than through RStudio and confirm
> the results (if it doesn't happen in R then RStudio may be breaking R
> (rare, but it has happened) in which case you would have to ask them for
> help.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <
> pai1981 at gmail.com> wrote:
> >Hi all,
> >I recently updated my Rstudio to the newer version (Version 1.0.136)
> >and I
> >started to getting following error when I am trying to read netcdf
> >files
> >
> >Error in R_nc4_open: NetCDF: DAP server error
> >
> >Any ideas?
> >
> >with regards
> >-Deb
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed Jan 11 23:01:00 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 11 Jan 2017 17:01:00 -0500
Subject: [R] Error in R_nc4_open
In-Reply-To: <CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
	<CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
Message-ID: <BAD66AB8-E867-4AEB-8499-145694E9D22B@bigelow.org>

Hi,

> error-Error in R_nc4_open: NetCDF: DAP server error

Based upon the error above, the issue appears to be on the server side not your client end.  Perhaps the URL to the grib file is not correct?  I know that I recently switch NOMADS related URLS from http to https.

You also asked about mailing lists.  If you are working with geospatial data then you might like the r-sig-geo list here https://stat.ethz.ch/mailman/listinfo/r-sig-geo


Ben



> On Jan 11, 2017, at 4:46 PM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> 
> Hi Jeff,
> Thanks for your detail response but I am really baffled by this sort of
> response from a help group because I am also a part of a help group
> (NCAR-Command Language).
> 
> Anyway I felt its R/Rstudio issue because my code was working properly
> before..........but since the update it isn't working anymore
> 
> Here is few lines of my code
> 
> library("ncdf4")
> gribfile<-"
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
> "
> ## open connection
> nc <- nc_open(gribfile)
> 
> error-Error in R_nc4_open: NetCDF: DAP server error
> 
> I am getting the error message in nc_open.
> 
> Please excuse me if this not R issue. Please let me know which "*R HELP
> GROUP*" I should post this message.
> 
> -Deb
> 
> 
> 
> 
> On Wed, Jan 11, 2017 at 4:27 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> You will do yourself a favor if you pay attention to which software you
>> are using.  When you use RStudio, the console window is a direct connection
>> to R, which is NOT RStudio... it has a separate installer and a different
>> support group (e.g. this mailing list). All of this means you have failed
>> to tell us anything about the software that actually matters in your
>> question... R, nor the CONTRIBUTED package (meaning NOT part of R or
>> RStudio) containing the function you are having trouble with.
>> 
>> Go read the Posting Guide... carefully... and provide a reproducible
>> example that leads to your error... and post in plain text rather than HTML
>> email so your example doesn't get messed up in transit. The output of
>> sessionInfo() after the error would probably be a good idea also. For good
>> measure you should open R directly rather than through RStudio and confirm
>> the results (if it doesn't happen in R then RStudio may be breaking R
>> (rare, but it has happened) in which case you would have to ask them for
>> help.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <
>> pai1981 at gmail.com> wrote:
>>> Hi all,
>>> I recently updated my Rstudio to the newer version (Version 1.0.136)
>>> and I
>>> started to getting following error when I am trying to read netcdf
>>> files
>>> 
>>> Error in R_nc4_open: NetCDF: DAP server error
>>> 
>>> Any ideas?
>>> 
>>> with regards
>>> -Deb
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From sarah.goslee at gmail.com  Wed Jan 11 23:02:04 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Jan 2017 17:02:04 -0500
Subject: [R] Error in R_nc4_open
In-Reply-To: <CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
	<CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
Message-ID: <CAM_vjunfssNJ2qA1aP98Db4h-j4MfSqiLQ=VmPXAgqGdfxQB9w@mail.gmail.com>

Jeff's point was that R and RStudio are two entirely different things,
and if you think it's a problem with RStudio, you should pursue their
tech support.

If you think it's a problem with R, then you should prepare a
reproducible example and submit it to this list, as you've done.

I actually think it's neither: I think it's a DAP server error, just
as the error message says. If you try to download your grb file
directly, you will discover this is true.

It's always good practice to break down each part into small steps
when trying to solve a problem, so that you can tell where things go
wrong.

I'd walk back to
https://nomads.ncdc.noaa.gov/thredds/catalog.html
and make sure that the data path hasn't changed.


Sarah

On Wed, Jan 11, 2017 at 4:46 PM, Debasish Pai Mazumder
<pai1981 at gmail.com> wrote:
> Hi Jeff,
> Thanks for your detail response but I am really baffled by this sort of
> response from a help group because I am also a part of a help group
> (NCAR-Command Language).
>
> Anyway I felt its R/Rstudio issue because my code was working properly
> before..........but since the update it isn't working anymore
>
> Here is few lines of my code
>
> library("ncdf4")
> gribfile<-"
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
> "
> ## open connection
> nc <- nc_open(gribfile)
>
> error-Error in R_nc4_open: NetCDF: DAP server error
>
> I am getting the error message in nc_open.
>
> Please excuse me if this not R issue. Please let me know which "*R HELP
> GROUP*" I should post this message.
>
> -Deb
>
>
>
>
> On Wed, Jan 11, 2017 at 4:27 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> You will do yourself a favor if you pay attention to which software you
>> are using.  When you use RStudio, the console window is a direct connection
>> to R, which is NOT RStudio... it has a separate installer and a different
>> support group (e.g. this mailing list). All of this means you have failed
>> to tell us anything about the software that actually matters in your
>> question... R, nor the CONTRIBUTED package (meaning NOT part of R or
>> RStudio) containing the function you are having trouble with.
>>
>> Go read the Posting Guide... carefully... and provide a reproducible
>> example that leads to your error... and post in plain text rather than HTML
>> email so your example doesn't get messed up in transit. The output of
>> sessionInfo() after the error would probably be a good idea also. For good
>> measure you should open R directly rather than through RStudio and confirm
>> the results (if it doesn't happen in R then RStudio may be breaking R
>> (rare, but it has happened) in which case you would have to ask them for
>> help.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <
>> pai1981 at gmail.com> wrote:
>> >Hi all,
>> >I recently updated my Rstudio to the newer version (Version 1.0.136)
>> >and I
>> >started to getting following error when I am trying to read netcdf
>> >files
>> >
>> >Error in R_nc4_open: NetCDF: DAP server error
>> >
>> >Any ideas?
>> >
>> >with regards
>> >-Deb
>> >

-- 
Sarah Goslee
http://www.functionaldiversity.org


From roy.mendelssohn at noaa.gov  Wed Jan 11 23:04:31 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 11 Jan 2017 14:04:31 -0800
Subject: [R] Error in R_nc4_open
In-Reply-To: <CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
	<CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
Message-ID: <10ECA11F-F7EF-40E9-9C06-5F7A3F86E228@noaa.gov>

Try replacing http with https.

>  gribfile <- "https://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2"
> nc <- nc_open(gribfile)
> str(nc)
List of 14
 $ filename   : chr "https://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100."| __truncated__
 $ writable   : logi FALSE
 $ id         : int 65536
 $ safemode   : logi FALSE
 $ format     : chr "NC_FORMAT_64BIT"
 $ is_GMT     : logi FALSE
 $ groups     :List of 1
......

-Roy



> On Jan 11, 2017, at 1:46 PM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> 
> Hi Jeff,
> Thanks for your detail response but I am really baffled by this sort of
> response from a help group because I am also a part of a help group
> (NCAR-Command Language).
> 
> Anyway I felt its R/Rstudio issue because my code was working properly
> before..........but since the update it isn't working anymore
> 
> Here is few lines of my code
> 
> library("ncdf4")
> gribfile<-"
> http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
> "
> ## open connection
> nc <- nc_open(gribfile)
> 
> error-Error in R_nc4_open: NetCDF: DAP server error
> 
> I am getting the error message in nc_open.
> 
> Please excuse me if this not R issue. Please let me know which "*R HELP
> GROUP*" I should post this message.
> 
> -Deb
> 
> 
> 
> 
> On Wed, Jan 11, 2017 at 4:27 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> You will do yourself a favor if you pay attention to which software you
>> are using.  When you use RStudio, the console window is a direct connection
>> to R, which is NOT RStudio... it has a separate installer and a different
>> support group (e.g. this mailing list). All of this means you have failed
>> to tell us anything about the software that actually matters in your
>> question... R, nor the CONTRIBUTED package (meaning NOT part of R or
>> RStudio) containing the function you are having trouble with.
>> 
>> Go read the Posting Guide... carefully... and provide a reproducible
>> example that leads to your error... and post in plain text rather than HTML
>> email so your example doesn't get messed up in transit. The output of
>> sessionInfo() after the error would probably be a good idea also. For good
>> measure you should open R directly rather than through RStudio and confirm
>> the results (if it doesn't happen in R then RStudio may be breaking R
>> (rare, but it has happened) in which case you would have to ask them for
>> help.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <
>> pai1981 at gmail.com> wrote:
>>> Hi all,
>>> I recently updated my Rstudio to the newer version (Version 1.0.136)
>>> and I
>>> started to getting following error when I am trying to read netcdf
>>> files
>>> 
>>> Error in R_nc4_open: NetCDF: DAP server error
>>> 
>>> Any ideas?
>>> 
>>> with regards
>>> -Deb
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ed_isfahani at yahoo.com  Wed Jan 11 23:14:40 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Wed, 11 Jan 2017 22:14:40 +0000 (UTC)
Subject: [R] co-expression network of coding-noncoding genes
References: <614878929.2220375.1484172880081.ref@mail.yahoo.com>
Message-ID: <614878929.2220375.1484172880081@mail.yahoo.com>

hello all,

I have 9 experiments (human RNAseq data (control/treatment)),I did RNAseq analysis by CLC genomics,after normalization I calculated correlation, I have many pairs of coding and lncoding molecules that correlate according to their expression,I filtered them (> 0.9 and < -0.9). Additionally, I've considered the pairs that have p-values < 0.001,but they are many pairs yet.

now for more filtering I want to consider the pairs of coding-non coding, which are both deferentially expressed.?
how can I have DE for all treated vs all controls samples for coding and DE for all treated vs all controls samples for noncoding?


I should say that each experiment is effect of one drug on one cancer (drugs and cancers are different in each experiment ) but the platform is similar and all of them are Illumina HiSeq 2000 (Homo sapiens)

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jan 11 23:38:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 11 Jan 2017 14:38:10 -0800
Subject: [R] co-expression network of coding-noncoding genes
In-Reply-To: <614878929.2220375.1484172880081@mail.yahoo.com>
References: <614878929.2220375.1484172880081.ref@mail.yahoo.com>
	<614878929.2220375.1484172880081@mail.yahoo.com>
Message-ID: <CAGxFJbS5n1KgPSinvfi6_zYLPkPOHmqT9o7qeghOTvFTjWkkzg@mail.gmail.com>

Wrong list.

Post on the Bioconductor list.

-- Bert


On Jan 11, 2017 5:15 PM, "Elham - via R-help" <r-help at r-project.org> wrote:

hello all,

I have 9 experiments (human RNAseq data (control/treatment)),I did RNAseq
analysis by CLC genomics,after normalization I calculated correlation, I
have many pairs of coding and lncoding molecules that correlate according
to their expression,I filtered them (> 0.9 and < -0.9). Additionally, I've
considered the pairs that have p-values < 0.001,but they are many pairs yet.

now for more filtering I want to consider the pairs of coding-non coding,
which are both deferentially expressed.
how can I have DE for all treated vs all controls samples for coding and DE
for all treated vs all controls samples for noncoding?


I should say that each experiment is effect of one drug on one cancer
(drugs and cancers are different in each experiment ) but the platform is
similar and all of them are Illumina HiSeq 2000 (Homo sapiens)

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Jan 12 00:56:35 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 12 Jan 2017 12:56:35 +1300
Subject: [R] [FORGED]  file.exists() on device files
In-Reply-To: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>
References: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>
Message-ID: <556530f1-dca1-6962-526b-65302ff5fe24@auckland.ac.nz>

On 11/01/17 23:12, Benjamin Tyner wrote:
> Hi,
>
> On my linux machine (Ubuntu, and also tested on RHEL), I am curious to
> know what might be causing file.exists (and also normalizePath) to not
> see the final device file here:
>
>    > list.files("/dev/fd", full.names = TRUE)
>    [1] "/dev/fd/0" "/dev/fd/1" "/dev/fd/2" "/dev/fd/3"
>    > file.exists(list.files("/dev/fd", full.names = TRUE))
>    [1]  TRUE  TRUE  TRUE FALSE
>    > normalizePath(list.files("/dev/fd", full.names = TRUE))
>    [1] "/dev/pts/2" "/dev/pts/2" "/dev/pts/2" "/dev/fd/3"
>    Warning message:
>    In normalizePath(list.files("/dev/fd", full.names = TRUE)) :
>      path[4]="/dev/fd/3": No such file or directory

(a) Exactly the same thing happens to me (I am also running Ubuntu 16.04).

(b) Things get a bit confused because /dev/fd is actually a symbolic link:

> $ ls -l /dev/fd
> lrwxrwxrwx 1 root root 13 Jan  6 20:16 /dev/fd -> /proc/self/fd/

(c) But then doing

>> file.exists(list.files("/proc/self/fd", full.names = TRUE))

Gives the same result as before:

> [1]  TRUE  TRUE  TRUE FALSE

(d) It turns out that the four "files" in /proc/self/fd are again
symbolic links:

> $ ls -l /proc/self/fd
> total 0
> lrwx------ 1 rolf rolf 64 Jan 12 12:32 0 -> /dev/pts/3
> lrwx------ 1 rolf rolf 64 Jan 12 12:32 1 -> /dev/pts/3
> lrwx------ 1 rolf rolf 64 Jan 12 12:32 2 -> /dev/pts/3
> lr-x------ 1 rolf rolf 64 Jan 12 12:32 3 -> /proc/7150/fd/

(e) But now do it again!!!

> $ ls -l /proc/self/fd
> total 0
> lrwx------ 1 rolf rolf 64 Jan 12 12:32 0 -> /dev/pts/3
> lrwx------ 1 rolf rolf 64 Jan 12 12:32 1 -> /dev/pts/3
> lrwx------ 1 rolf rolf 64 Jan 12 12:32 2 -> /dev/pts/3
> lr-x------ 1 rolf rolf 64 Jan 12 12:32 3 -> /proc/7154/fd/

Different number; 7154 rather than 7150.

(f) The name "/proc" would seem to imply that this has something to do 
with processes; the directories "7150", "7154" etc. are being created 
and removed on the fly, as a result of some process (presumably the "ls"
process) starting and finishing.

I have no insight into what is being effected here, or what is really 
going on "deep down", but the foregoing is some sort of "explanation".
By the time file.exists() is invoked, the ls process called by 
list.files() has finished and the associated directory (e.g. "7150", 
"7154", ...) has ceased to be.

What you do with this "explanation" is up to you.  My advice would be to 
forget about it and go to the pub! :-)

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Thu Jan 12 01:37:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 11 Jan 2017 16:37:30 -0800
Subject: [R] Error in R_nc4_open
In-Reply-To: <CAM_vjunfssNJ2qA1aP98Db4h-j4MfSqiLQ=VmPXAgqGdfxQB9w@mail.gmail.com>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
	<CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
	<CAM_vjunfssNJ2qA1aP98Db4h-j4MfSqiLQ=VmPXAgqGdfxQB9w@mail.gmail.com>
Message-ID: <AA864301-F4E0-4F0A-8798-CE5CB6A8EA3C@dcn.davis.ca.us>

My real point was that all the relevant information was missing, and it was missing because Debasish was unaware of which software was actually responsible for generating that error, and we were in the dark on that until the example was provided. 
-- 
Sent from my phone. Please excuse my brevity.

On January 11, 2017 2:02:04 PM PST, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>Jeff's point was that R and RStudio are two entirely different things,
>and if you think it's a problem with RStudio, you should pursue their
>tech support.
>
>If you think it's a problem with R, then you should prepare a
>reproducible example and submit it to this list, as you've done.
>
>I actually think it's neither: I think it's a DAP server error, just
>as the error message says. If you try to download your grb file
>directly, you will discover this is true.
>
>It's always good practice to break down each part into small steps
>when trying to solve a problem, so that you can tell where things go
>wrong.
>
>I'd walk back to
>https://nomads.ncdc.noaa.gov/thredds/catalog.html
>and make sure that the data path hasn't changed.
>
>
>Sarah
>
>On Wed, Jan 11, 2017 at 4:46 PM, Debasish Pai Mazumder
><pai1981 at gmail.com> wrote:
>> Hi Jeff,
>> Thanks for your detail response but I am really baffled by this sort
>of
>> response from a help group because I am also a part of a help group
>> (NCAR-Command Language).
>>
>> Anyway I felt its R/Rstudio issue because my code was working
>properly
>> before..........but since the update it isn't working anymore
>>
>> Here is few lines of my code
>>
>> library("ncdf4")
>> gribfile<-"
>>
>http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
>> "
>> ## open connection
>> nc <- nc_open(gribfile)
>>
>> error-Error in R_nc4_open: NetCDF: DAP server error
>>
>> I am getting the error message in nc_open.
>>
>> Please excuse me if this not R issue. Please let me know which "*R
>HELP
>> GROUP*" I should post this message.
>>
>> -Deb
>>
>>
>>
>>
>> On Wed, Jan 11, 2017 at 4:27 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> You will do yourself a favor if you pay attention to which software
>you
>>> are using.  When you use RStudio, the console window is a direct
>connection
>>> to R, which is NOT RStudio... it has a separate installer and a
>different
>>> support group (e.g. this mailing list). All of this means you have
>failed
>>> to tell us anything about the software that actually matters in your
>>> question... R, nor the CONTRIBUTED package (meaning NOT part of R or
>>> RStudio) containing the function you are having trouble with.
>>>
>>> Go read the Posting Guide... carefully... and provide a reproducible
>>> example that leads to your error... and post in plain text rather
>than HTML
>>> email so your example doesn't get messed up in transit. The output
>of
>>> sessionInfo() after the error would probably be a good idea also.
>For good
>>> measure you should open R directly rather than through RStudio and
>confirm
>>> the results (if it doesn't happen in R then RStudio may be breaking
>R
>>> (rare, but it has happened) in which case you would have to ask them
>for
>>> help.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <
>>> pai1981 at gmail.com> wrote:
>>> >Hi all,
>>> >I recently updated my Rstudio to the newer version (Version
>1.0.136)
>>> >and I
>>> >started to getting following error when I am trying to read netcdf
>>> >files
>>> >
>>> >Error in R_nc4_open: NetCDF: DAP server error
>>> >
>>> >Any ideas?
>>> >
>>> >with regards
>>> >-Deb
>>> >


From henrik.bengtsson at gmail.com  Thu Jan 12 04:33:22 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 11 Jan 2017 19:33:22 -0800
Subject: [R] [FORGED] file.exists() on device files
In-Reply-To: <556530f1-dca1-6962-526b-65302ff5fe24@auckland.ac.nz>
References: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>
	<556530f1-dca1-6962-526b-65302ff5fe24@auckland.ac.nz>
Message-ID: <CAFDcVCSe52wXeJkQqX+V6vfbqjPV+QyUCPNBs_g1ZECvmw71dg@mail.gmail.com>

On Wed, Jan 11, 2017 at 3:56 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 11/01/17 23:12, Benjamin Tyner wrote:
>>
>> Hi,
>>
>> On my linux machine (Ubuntu, and also tested on RHEL), I am curious to
>> know what might be causing file.exists (and also normalizePath) to not
>> see the final device file here:
>>
>>    > list.files("/dev/fd", full.names = TRUE)
>>    [1] "/dev/fd/0" "/dev/fd/1" "/dev/fd/2" "/dev/fd/3"
>>    > file.exists(list.files("/dev/fd", full.names = TRUE))
>>    [1]  TRUE  TRUE  TRUE FALSE
>>    > normalizePath(list.files("/dev/fd", full.names = TRUE))
>>    [1] "/dev/pts/2" "/dev/pts/2" "/dev/pts/2" "/dev/fd/3"
>>    Warning message:
>>    In normalizePath(list.files("/dev/fd", full.names = TRUE)) :
>>      path[4]="/dev/fd/3": No such file or directory
>
>
> (a) Exactly the same thing happens to me (I am also running Ubuntu 16.04).
>
> (b) Things get a bit confused because /dev/fd is actually a symbolic link:
>
>> $ ls -l /dev/fd
>> lrwxrwxrwx 1 root root 13 Jan  6 20:16 /dev/fd -> /proc/self/fd/
>
>
> (c) But then doing
>
>>> file.exists(list.files("/proc/self/fd", full.names = TRUE))
>
>
> Gives the same result as before:
>
>> [1]  TRUE  TRUE  TRUE FALSE
>
>
> (d) It turns out that the four "files" in /proc/self/fd are again
> symbolic links:
>
>> $ ls -l /proc/self/fd
>> total 0
>> lrwx------ 1 rolf rolf 64 Jan 12 12:32 0 -> /dev/pts/3
>> lrwx------ 1 rolf rolf 64 Jan 12 12:32 1 -> /dev/pts/3
>> lrwx------ 1 rolf rolf 64 Jan 12 12:32 2 -> /dev/pts/3
>> lr-x------ 1 rolf rolf 64 Jan 12 12:32 3 -> /proc/7150/fd/
>
>
> (e) But now do it again!!!
>
>> $ ls -l /proc/self/fd
>> total 0
>> lrwx------ 1 rolf rolf 64 Jan 12 12:32 0 -> /dev/pts/3
>> lrwx------ 1 rolf rolf 64 Jan 12 12:32 1 -> /dev/pts/3
>> lrwx------ 1 rolf rolf 64 Jan 12 12:32 2 -> /dev/pts/3
>> lr-x------ 1 rolf rolf 64 Jan 12 12:32 3 -> /proc/7154/fd/
>
>
> Different number; 7154 rather than 7150.
>
> (f) The name "/proc" would seem to imply that this has something to do with
> processes; the directories "7150", "7154" etc. are being created and removed
> on the fly, as a result of some process (presumably the "ls"
> process) starting and finishing.

FYI, the /proc is there because Unix has something called the "proc
filesystem (procfs; https://en.wikipedia.org/wiki/Procfs) is a special
filesystem in Unix-like operating systems that presents information
about processes and other system information in a hierarchical
file-like structure".  For instance, you can query the uptime of the
machine by reading from /proc/uptime:

$ cat /proc/uptime
332826.96 661438.10

$ cat /proc/uptime
332871.40 661568.50


You can get all IDs (PIDs) of all processes currently running:

$ ls /proc/ | grep -E '^[0-9]+$'

and for each process you there are multiple attributes mapped as
files, e.g. if I start R as:

$ R --args -e "message('hello there')"

then I can query that process as:

$ pid=$(pidof R)
$ echo $pid
26323

$ cat /proc/26323/cmdline
/usr/lib/R/bin/exec/R--args-emessage('hello there')

Unix is neat

/Henrik

>
> I have no insight into what is being effected here, or what is really going
> on "deep down", but the foregoing is some sort of "explanation".
> By the time file.exists() is invoked, the ls process called by list.files()
> has finished and the associated directory (e.g. "7150", "7154", ...) has
> ceased to be.
>
> What you do with this "explanation" is up to you.  My advice would be to
> forget about it and go to the pub! :-)
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pai1981 at gmail.com  Thu Jan 12 05:39:09 2017
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Wed, 11 Jan 2017 23:39:09 -0500
Subject: [R] Error in R_nc4_open
In-Reply-To: <AA864301-F4E0-4F0A-8798-CE5CB6A8EA3C@dcn.davis.ca.us>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
	<CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
	<CAM_vjunfssNJ2qA1aP98Db4h-j4MfSqiLQ=VmPXAgqGdfxQB9w@mail.gmail.com>
	<AA864301-F4E0-4F0A-8798-CE5CB6A8EA3C@dcn.davis.ca.us>
Message-ID: <CAM9mbiBv56Fdopeq18-hFdjT9fpAG_hrf55CPO7G8KZYtbgeVA@mail.gmail.com>

Thanks so much Roy. It works.
Thanks Jeff for all your help.
As a part of NCAR Command Language help group, I was only concern about the
first response I received from this help group which will discourage new
user like me to post their problems in this forum.

I would like apologize if I caused any inconvenience to anyone.

with regards
-Deb

Debasish PaiMazumder, PhD
Associate Scientist
Capacity Center for Climate and Weather Extremes (C3WE)
Nation Center for Atmospheric Research (NCAR)
Boulder, CO

On Wed, Jan 11, 2017 at 7:37 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> My real point was that all the relevant information was missing, and it
> was missing because Debasish was unaware of which software was actually
> responsible for generating that error, and we were in the dark on that
> until the example was provided.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 11, 2017 2:02:04 PM PST, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> >Jeff's point was that R and RStudio are two entirely different things,
> >and if you think it's a problem with RStudio, you should pursue their
> >tech support.
> >
> >If you think it's a problem with R, then you should prepare a
> >reproducible example and submit it to this list, as you've done.
> >
> >I actually think it's neither: I think it's a DAP server error, just
> >as the error message says. If you try to download your grb file
> >directly, you will discover this is true.
> >
> >It's always good practice to break down each part into small steps
> >when trying to solve a problem, so that you can tell where things go
> >wrong.
> >
> >I'd walk back to
> >https://nomads.ncdc.noaa.gov/thredds/catalog.html
> >and make sure that the data path hasn't changed.
> >
> >
> >Sarah
> >
> >On Wed, Jan 11, 2017 at 4:46 PM, Debasish Pai Mazumder
> ><pai1981 at gmail.com> wrote:
> >> Hi Jeff,
> >> Thanks for your detail response but I am really baffled by this sort
> >of
> >> response from a help group because I am also a part of a help group
> >> (NCAR-Command Language).
> >>
> >> Anyway I felt its R/Rstudio issue because my code was working
> >properly
> >> before..........but since the update it isn't working anymore
> >>
> >> Here is few lines of my code
> >>
> >> library("ncdf4")
> >> gribfile<-"
> >>
> >http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
> forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.
> 2011040100.daily.grb2
> >> "
> >> ## open connection
> >> nc <- nc_open(gribfile)
> >>
> >> error-Error in R_nc4_open: NetCDF: DAP server error
> >>
> >> I am getting the error message in nc_open.
> >>
> >> Please excuse me if this not R issue. Please let me know which "*R
> >HELP
> >> GROUP*" I should post this message.
> >>
> >> -Deb
> >>
> >>
> >>
> >>
> >> On Wed, Jan 11, 2017 at 4:27 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >> wrote:
> >>
> >>> You will do yourself a favor if you pay attention to which software
> >you
> >>> are using.  When you use RStudio, the console window is a direct
> >connection
> >>> to R, which is NOT RStudio... it has a separate installer and a
> >different
> >>> support group (e.g. this mailing list). All of this means you have
> >failed
> >>> to tell us anything about the software that actually matters in your
> >>> question... R, nor the CONTRIBUTED package (meaning NOT part of R or
> >>> RStudio) containing the function you are having trouble with.
> >>>
> >>> Go read the Posting Guide... carefully... and provide a reproducible
> >>> example that leads to your error... and post in plain text rather
> >than HTML
> >>> email so your example doesn't get messed up in transit. The output
> >of
> >>> sessionInfo() after the error would probably be a good idea also.
> >For good
> >>> measure you should open R directly rather than through RStudio and
> >confirm
> >>> the results (if it doesn't happen in R then RStudio may be breaking
> >R
> >>> (rare, but it has happened) in which case you would have to ask them
> >for
> >>> help.
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>> On January 11, 2017 12:32:09 PM PST, Debasish Pai Mazumder <
> >>> pai1981 at gmail.com> wrote:
> >>> >Hi all,
> >>> >I recently updated my Rstudio to the newer version (Version
> >1.0.136)
> >>> >and I
> >>> >started to getting following error when I am trying to read netcdf
> >>> >files
> >>> >
> >>> >Error in R_nc4_open: NetCDF: DAP server error
> >>> >
> >>> >Any ideas?
> >>> >
> >>> >with regards
> >>> >-Deb
> >>> >
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Thu Jan 12 05:56:28 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 11 Jan 2017 20:56:28 -0800
Subject: [R] Error in R_nc4_open
In-Reply-To: <CAM9mbiBv56Fdopeq18-hFdjT9fpAG_hrf55CPO7G8KZYtbgeVA@mail.gmail.com>
References: <CAM9mbiBajn7tmdUvixMEZo4Cxn8M9zSXgUkXMiXBp3kUQw8RHg@mail.gmail.com>
	<A4925722-19B6-4947-BD35-547A9C2AAEDD@dcn.davis.ca.us>
	<CAM9mbiBzQxAek0DywGUQY6Ctz+5cpxouhN3963a9SZ6u3iDJcQ@mail.gmail.com>
	<CAM_vjunfssNJ2qA1aP98Db4h-j4MfSqiLQ=VmPXAgqGdfxQB9w@mail.gmail.com>
	<AA864301-F4E0-4F0A-8798-CE5CB6A8EA3C@dcn.davis.ca.us>
	<CAM9mbiBv56Fdopeq18-hFdjT9fpAG_hrf55CPO7G8KZYtbgeVA@mail.gmail.com>
Message-ID: <53927099-CBF4-4BC0-86D2-6F91DF81F389@noaa.gov>


> On Jan 11, 2017, at 8:39 PM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> 
> Thanks so much Roy. It works. 
> Thanks Jeff for all your help. 
> As a part of NCAR Command Language help group, I was only concern about the first response I received from this help group which will discourage new user like me to post their problems in this forum.
> 
> I would like apologize if I caused any inconvenience to anyone.
> 
> with regards
> -Deb

Your welcome.  The update to RStudio was just a coincidence.  It is the often sudden switch to https at many sites,  usually with http redirect that is causing a lot of problems.  Not every library handles the redirect cleanly. It is a decision made without much thought as to what might break.  Having https available is a good thing.  Forced re-direct without any testing of what will/will not work not so good.  We had a slew of python code break for the same reason.  And oddly enough versions of OS,  versions and suppliers of python, and versions of OpenSSL greatly affect whether things  work.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From floorrinse at gmail.com  Thu Jan 12 01:15:24 2017
From: floorrinse at gmail.com (Florence Lui)
Date: Thu, 12 Jan 2017 00:15:24 +0000
Subject: [R] Problem installing R 2.12.1 on Mac OS X Yosemite 10.10.5
Message-ID: <CA+TszVDkX-XAWWNbtKet3yu7m33p6Mgd-uaQLz92GazxSa5uFg@mail.gmail.com>

I'm trying to download version 2.12.1 of R in order for it to be compatible
with the version of SPSS I have on my computer (SPSS V. 20), so that I can
install the Essentials for R plugin for SPSS.

However, when I try to install this version of R, I get a popup saying it
can't be installed because it requires Mac OS X 10.5 or higher (see
attached). But I do have a higher operating system--Mac OS X Yosemite
10.10.5.

Any idea what might be wrong? Thanks for your help!
-- 
Florence Lui

	[[alternative HTML version deleted]]


From woolawson123 at gmail.com  Thu Jan 12 05:47:51 2017
From: woolawson123 at gmail.com (woo lawson)
Date: Wed, 11 Jan 2017 22:47:51 -0600
Subject: [R] (no subject)
Message-ID: <CA+25kR3zUBgZPpmabKR_a9O0mYx+rXKTOQbXWoUmcV5WkLu8bg@mail.gmail.com>

hello friends, i wanted to install miniCRAN as site-repository and once its
created wanted to push few packages to miniCRAN. I read some docs online
about minicran but didn't find good help so far and confuse about couple of
things. wanted to know,

-> is minicran package comes with any packages by default and we can add
more packages afterwards?

-> any solution to push package to minicran?


appreciate any help...

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jan 12 07:20:42 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Jan 2017 22:20:42 -0800
Subject: [R] Problem installing R 2.12.1 on Mac OS X Yosemite 10.10.5
In-Reply-To: <CA+TszVDkX-XAWWNbtKet3yu7m33p6Mgd-uaQLz92GazxSa5uFg@mail.gmail.com>
References: <CA+TszVDkX-XAWWNbtKet3yu7m33p6Mgd-uaQLz92GazxSa5uFg@mail.gmail.com>
Message-ID: <323276CE-757A-4F31-B03F-D99B5E2E564C@comcast.net>


> On Jan 11, 2017, at 4:15 PM, Florence Lui <floorrinse at gmail.com> wrote:
> 
> I'm trying to download version 2.12.1 of R in order for it to be compatible
> with the version of SPSS I have on my computer (SPSS V. 20), so that I can
> install the Essentials for R plugin for SPSS.
> 
> However, when I try to install this version of R, I get a popup saying it
> can't be installed because it requires Mac OS X 10.5 or higher (see
> attached).

I suspect that there is code that does a comparison of the character version of your numeric version of OSX and finds that it is less than "10.5" since if you do that comparison at your console you will see 

> "10.10" < "10.5"
[1] TRUE


> But I do have a higher operating system--Mac OS X Yosemite
> 10.10.5.
> 
> Any idea what might be wrong?

I suspect this has been discussed with in the past. Search the Archives of the R-SIG-Mac mailing list (which would have been the correct place to post this question in the first place.) I have vague memory that such a request appeared in the not so distant past.

-- 
David.




> Thanks for your help!
> -- 
> Florence Lui
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Thu Jan 12 07:42:51 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 12 Jan 2017 19:42:51 +1300
Subject: [R] [FORGED] file.exists() on device files
In-Reply-To: <CAFDcVCSe52wXeJkQqX+V6vfbqjPV+QyUCPNBs_g1ZECvmw71dg@mail.gmail.com>
References: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>
	<556530f1-dca1-6962-526b-65302ff5fe24@auckland.ac.nz>
	<CAFDcVCSe52wXeJkQqX+V6vfbqjPV+QyUCPNBs_g1ZECvmw71dg@mail.gmail.com>
Message-ID: <126ba0b3-aa2a-55c5-a119-f231d2127312@auckland.ac.nz>

On 12/01/17 16:33, Henrik Bengtsson wrote:

<SNIP>

> FYI, the /proc is there because Unix has something called the "proc
> filesystem (procfs; https://en.wikipedia.org/wiki/Procfs) is a special
> filesystem in Unix-like operating systems that presents information
> about processes and other system information in a hierarchical
> file-like structure".  For instance, you can query the uptime of the
> machine by reading from /proc/uptime:
>
> $ cat /proc/uptime
> 332826.96 661438.10
>
> $ cat /proc/uptime
> 332871.40 661568.50
>
>
> You can get all IDs (PIDs) of all processes currently running:
>
> $ ls /proc/ | grep -E '^[0-9]+$'
>
> and for each process you there are multiple attributes mapped as
> files, e.g. if I start R as:
>
> $ R --args -e "message('hello there')"
>
> then I can query that process as:
>
> $ pid=$(pidof R)
> $ echo $pid
> 26323
>
> $ cat /proc/26323/cmdline
> /usr/lib/R/bin/exec/R--args-emessage('hello there')
>
> Unix is neat

Indeed.  Couldn't agree more.  Thanks for the insight.

<SNIP>

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Thu Jan 12 07:45:38 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Jan 2017 22:45:38 -0800
Subject: [R] Problem installing R 2.12.1 on Mac OS X Yosemite 10.10.5
In-Reply-To: <323276CE-757A-4F31-B03F-D99B5E2E564C@comcast.net>
References: <CA+TszVDkX-XAWWNbtKet3yu7m33p6Mgd-uaQLz92GazxSa5uFg@mail.gmail.com>
	<323276CE-757A-4F31-B03F-D99B5E2E564C@comcast.net>
Message-ID: <965D9508-BE3E-4277-836A-CA3F3C839158@comcast.net>


> On Jan 11, 2017, at 10:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jan 11, 2017, at 4:15 PM, Florence Lui <floorrinse at gmail.com> wrote:
>> 
>> I'm trying to download version 2.12.1 of R in order for it to be compatible
>> with the version of SPSS I have on my computer (SPSS V. 20), so that I can
>> install the Essentials for R plugin for SPSS.
>> 
>> However, when I try to install this version of R, I get a popup saying it
>> can't be installed because it requires Mac OS X 10.5 or higher (see
>> attached).
> 
> I suspect that there is code that does a comparison of the character version of your numeric version of OSX and finds that it is less than "10.5" since if you do that comparison at your console you will see 
> 
>> "10.10" < "10.5"
> [1] TRUE
> 
> 
>> But I do have a higher operating system--Mac OS X Yosemite
>> 10.10.5.
>> 
>> Any idea what might be wrong?
> 
> I suspect this has been discussed with in the past. Search the Archives of the R-SIG-Mac mailing list (which would have been the correct place to post this question in the first place.) I have vague memory that such a request appeared in the not so distant past.

I think this is the message I remember, but probably encountered it during a different search since it cannot be called recent. Peter Dalgaard suggests temporarily setting your version to 10.9.

http://markmail.org/message/rl3ym7cjo45gpo5n?q=list:org%2Er-project+spss+version

http://markmail.org/search/?q=list%3Aorg.r-project+spss+version#query:list%3Aorg.r-project%20spss%20version+page:1+mid:rl3ym7cjo45gpo5n+state:results


Despite being a Mac user of long standing, I had no idea how one would do that, but thought a google-search would help:

http://justindaigle.com/blog/2010/02/tutorial-change-mac-os-x-system-version/

Perhaps the SPSS administration should distribute free copies of their software to all of the R-Core, since they seem to expect that R-help should be the unpaid support staff for a commercial product.



>> 
>> 	[[alternative HTML version deleted]]

And please do read the Posting Guide.
Best;
-- 

David Winsemius
Alameda, CA, USA


From vincent.goulet at me.com  Thu Jan 12 02:55:28 2017
From: vincent.goulet at me.com (Vincent Goulet)
Date: Wed, 11 Jan 2017 20:55:28 -0500
Subject: [R] [R-pkgs] Announcing new package expint
Message-ID: <7B91989A-3503-472A-BDE3-6BE51B182A43@me.com>

I am pleased to announce the immediate availability on CRAN of the new
package expint: https://cran.r-project.org/package=expint.

The exponential integral

  E_1(x) = int_x^\Inf exp(-t)/t dt,  x real

and the incomplete gamma function

  G(a, x) = \int_x^\Inf t^{a-1} exp(-t) dt, x > 0, a real

are two closely related functions that arise in various fields of
mathematics.

expint is a small package that intends to fill a gap in R's
support for mathematical functions by providing facilities to compute
the exponential integral and the incomplete gamma function.

Furthermore, and perhaps most conveniently for R package developers,
the package also gives easy access to the underlying C workhorses
through an API; see the exhaustive package vignette for details.

The C routines are derived from the GNU Scientific Library.

Best,

v.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From maechler at stat.math.ethz.ch  Thu Jan 12 11:41:45 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 12 Jan 2017 11:41:45 +0100
Subject: [R] Problem installing R 2.12.1 on Mac OS X Yosemite 10.10.5
In-Reply-To: <965D9508-BE3E-4277-836A-CA3F3C839158@comcast.net>
References: <CA+TszVDkX-XAWWNbtKet3yu7m33p6Mgd-uaQLz92GazxSa5uFg@mail.gmail.com>
	<323276CE-757A-4F31-B03F-D99B5E2E564C@comcast.net>
	<965D9508-BE3E-4277-836A-CA3F3C839158@comcast.net>
Message-ID: <22647.23913.523436.976901@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Wed, 11 Jan 2017 22:45:38 -0800 writes:

    >> On Jan 11, 2017, at 10:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
    >> 
    >> 
    >>> On Jan 11, 2017, at 4:15 PM, Florence Lui <floorrinse at gmail.com> wrote:
    >>> 
    >>> I'm trying to download version 2.12.1 of R in order for it to be compatible
    >>> with the version of SPSS I have on my computer (SPSS V. 20), so that I can
    >>> install the Essentials for R plugin for SPSS.
    >>> 
    >>> However, when I try to install this version of R, I get a popup saying it
    >>> can't be installed because it requires Mac OS X 10.5 or higher (see
    >>> attached).
    >> 
    >> I suspect that there is code that does a comparison of the character version of your numeric version of OSX and finds that it is less than "10.5" since if you do that comparison at your console you will see 
    >> 
    >>> "10.10" < "10.5"
    >> [1] TRUE
    >> 
    >> 
    >>> But I do have a higher operating system--Mac OS X Yosemite
    >>> 10.10.5.
    >>> 
    >>> Any idea what might be wrong?
    >> 
    >> I suspect this has been discussed with in the past. Search the Archives of the R-SIG-Mac mailing list (which would have been the correct place to post this question in the first place.) I have vague memory that such a request appeared in the not so distant past.

    > I think this is the message I remember, but probably encountered it during a different search since it cannot be called recent. Peter Dalgaard suggests temporarily setting your version to 10.9.

    > http://markmail.org/message/rl3ym7cjo45gpo5n?q=list:org%2Er-project+spss+version

    > http://markmail.org/search/?q=list%3Aorg.r-project+spss+version#query:list%3Aorg.r-project%20spss%20version+page:1+mid:rl3ym7cjo45gpo5n+state:results


    > Despite being a Mac user of long standing, I had no idea how one would do that, but thought a google-search would help:

    > http://justindaigle.com/blog/2010/02/tutorial-change-mac-os-x-system-version/

    > Perhaps the SPSS administration should distribute free copies of their software to all of the R-Core, since they seem to expect that R-help should be the unpaid support staff for a commercial product.

Well, but don't we all want to reduce unnecessary waste - thinking
of CO2 when burning all those CDs ?
Do you think R core would have any other use for such free copies
but to heat a bit during this cold (northern hemisphere) winter ?

;-)

Martin


From profjcnash at gmail.com  Thu Jan 12 14:25:27 2017
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 12 Jan 2017 08:25:27 -0500
Subject: [R] installing rgl
In-Reply-To: <e4de19d7-12da-18f2-72fe-da64870b1b45@gmail.com>
References: <DC6306FFE044A644A9BEAE5A43DEA9250F75E676@CC-CLEXMB53.cc.ad.cchs.net>
	<1807ad96-3ec1-915c-9fdb-5e19c992a4e9@gmail.com>
	<DC6306FFE044A644A9BEAE5A43DEA9250F75F0B5@CC-CLEXMB53.cc.ad.cchs.net>
	<e4de19d7-12da-18f2-72fe-da64870b1b45@gmail.com>
Message-ID: <481e5442-f225-dcfb-8ffb-fb13dde89872@gmail.com>

I had this problem this week in Linux Mint (debian/ubuntu based) and 
needed to install some libgl* and libglu* packages. A search for
"rgl  glu.h" and "rgl gl.h" found the appropriate suggestions, though I 
probably installed a couple of unnecessary packages too.

JN

On 2017-01-11 03:14 PM, Duncan Murdoch wrote:
> On 11/01/2017 3:03 PM, Weiner, Michael wrote:
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Wednesday, January 11, 2017 2:55 PM
>> To: Weiner, Michael <weinerm at ccf.org>; r-help at r-project.org
>> Subject: Re: [R] installing rgl
>>
>>> On this page
>>>
>>> http://forums.fedoraforum.org/showthread.php?t=294543
>>>
>>> eventually it turned out that a similar problem was fixed by
>>>
>>> yum install libpng-devel
>>
>> Thank you for your response Duncan, unfortunately that didn't help,
>> though I do see in config.log:
>>
>> configure:4429: checking for glEnd in -lGL
>> configure:4454: gcc -o conftest -g -O2  -DHAVE_PNG_H
>> -I/usr/include/libpng16  conftest.c -lGL   -L/usr/lib64 -lpng16 -lX11 >&5
>> /usr/bin/ld: skipping incompatible
>> /usr/lib/gcc/x86_64-redhat-linux/6.2.1/../../../libGL.so when
>> searching for -lGL
>> /usr/bin/ld: skipping incompatible /lib/libGL.so when searching for -lGL
>> /usr/bin/ld: skipping incompatible /usr/lib/libGL.so when searching
>> for -lGL
>> /usr/bin/ld: cannot find -lGL
>>
>> So something else is up
>>
>
> I don't know Fedora at all so I don't know what you'd need to do this,
> but I'd suggest asking to uninstall and reinstall mesa-libGL-devel and
> mesa-libGLU-devel (and maybe libpng-devel).
>
> Duncan Murdoch
>
>> Michael
>>
>>
>> ===================================
>>
>>
>>  Please consider the environment before printing this e-mail
>>
>> Cleveland Clinic is ranked as one of the top hospitals in America by
>> U.S.News & World Report (2015).
>> Visit us online at http://www.clevelandclinic.org for a complete
>> listing of our services, staff and locations.
>>
>>
>> Confidentiality Note:  This message is intended for use ...{{dropped:18}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From janko.thyson at gmail.com  Thu Jan 12 17:14:02 2017
From: janko.thyson at gmail.com (Janko Thyson)
Date: Thu, 12 Jan 2017 17:14:02 +0100
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year numbers on
 Windows with German locale
Message-ID: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>

Dear list,

I'm experiencing problems with converting strings of the format
"YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates which (I
think) I need in order to retrieve the month-of-the-year number.

Simpler put: I'd like to match week-of-the-year numbers to
month-of-the-year numbers. Ideally, the week-of-the-year number would
follow the ISO 8601 convention (i.e. format argument "%V") instead of the
US (format argument "%U") or UK (format argument "%W") convention.

After posting this to Stackoverflow, I have strong reasons to believe that
the issue is caused by Windows:
http://stackoverflow.com/questions/41616407/match-iso-8601-week-numbers-to-month-of-year-on-windows-with-german-locale/41617215?noredirect=1#comment70436768_41617215

Example:

# ISO 8601 convention:

(yw <- format(posix, "%Y-%V"))# [1] "2015-52" "2015-53" "2016-53" "2016-01"
ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))# [1]
"2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
-> utterly wrong!!!

# US convention:
(yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00" "2016-01"
ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
"2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
-> NA problem for week 00A fellow R user tested this on both macOS and
Ubuntu and he didn't encounter the issue:

some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
"2016-01-08"))
(year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
"2016 00" "2016 01"
(year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
52 1" "2016 00 1" "2016 01 1"
(as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"

My session info:

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

locale:[1] LC_COLLATE=German_Germany.1252
LC_CTYPE=German_Germany.1252       LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C                       LC_TIME=English_United
States.1252

attached base packages:[1] stats     graphics  grDevices utils
datasets  methods   base

other attached packages:
 [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
plyr_1.8.4      magrittr_1.5
 [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
crayon_1.3.2    withr_1.0.2
 [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
tools_3.3.2     stringr_1.1.0  [13] tibble_1.2

Any idea on how to workaround this issue on Windows?

Thanks and best regards,

Janko Thyson

	[[alternative HTML version deleted]]


From Sinnwell.Jason at mayo.edu  Wed Jan 11 20:24:11 2017
From: Sinnwell.Jason at mayo.edu (Sinnwell, Jason P.)
Date: Wed, 11 Jan 2017 19:24:11 +0000
Subject: [R] [R-pkgs] new package: arsenal
Message-ID: <021cdb$5h5q0m@ironport10.mayo.edu>

Dear useRs,



We are pleased to announce a new package that has recently appeared on CRAN, called "arsenal" (version 0.1.2: https://CRAN.R-project.org/package=arsenal<https://cran.r-project.org/package=arsenal>).
The package is a toolkit for statistical summaries, and is streamlined to work with the latest reporting tools in R and RStudio. The primary functions use a formula-driven approach to creating tables of summary statistics and univariate models. A set of common summary statistics is provided, or user-defined statistics can be used instead.  Model families supported include Binomial, Gaussian, Poisson, and Survival. More details are in the vignettes, which are listed below.
+ tableby(): a Table-1-like summary of multiple variable types 'by' the levels of a categorical variable
https://cran.r-project.org/web/packages/arsenal/vignettes/tableby.html
+ modelsum(): performs simple model fits on the same endpoint for many variables (univariate or adjusted for standard covariates)
https://cran.r-project.org/web/packages/arsenal/vignettes/modelsum.html
+ freqlist(): a powerful frequency table across many categorical variables
https://cran.r-project.org/web/packages/arsenal/vignettes/freqlist.pdf

Suggestions and contributions are welcome.



Best,

Jason Sinnwell

Ethan Heinzen



--

Jason Sinnwell and Ethan Heinzen

Mayo Clinic

Department of Health Sciences Research

Division of Biomedical Statistics and Informatics


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From tombernardryan at gmail.com  Thu Jan 12 18:12:17 2017
From: tombernardryan at gmail.com (Thomas Ryan)
Date: Thu, 12 Jan 2017 17:12:17 +0000
Subject: [R] Qvalue package: I am getting back 1,
	000 q values when I only want 1 q value.
Message-ID: <CANvF3ck-O6hy031HCRWH+3dhVguMFBszSEXQh1mNvs4tknjGWQ@mail.gmail.com>

Hi all, I'm wondering if someone could put me on the right path to using
the "qvalue" package correctly.

I have an original p value from an analysis, and I've done 1,000
randomisations of the data set. So I now have an original P value and 1,000
random p values. I want to work out the false discovery rate (FDR) (Q; as
described by Storey and Tibshriani in 2003) for my original p value,
defined as the number of expected false positives over the number of
significant results for my original P value.

So, for my original P value, I want one Q value, that has been calculated
as described above based on the 1,000 random p values.

I wrote this code:

pvals <- c(list_of_p_values_obtained_from_randomisations)
qobj <-qvalue(p=pvals)
r_output1 <- qobj$pvalue
r_output2 <- qobj$qvalue

r_output1 is the list of 1,000 p values that I put in, and r_output2 is a q
value for each of those p values (i.e. so there are 1,000 q values).

The problem is I don't want there to be 1,000 Q values (i.e one for each
random p value). The Q value should be the false discovery rate (FDR) (Q),
defined as the number of expected false positives over the number of
significant results. So I want one Q value for my original P value, and to
calculate that one Q value using the 1,000 random P values I have generated.

Could someone please tell me where I'm going wrong.

Thanks
Tom

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jan 12 20:37:14 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Jan 2017 11:37:14 -0800
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
	numbers on Windows with German locale
In-Reply-To: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
Message-ID: <DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>


> On Jan 12, 2017, at 8:14 AM, Janko Thyson <janko.thyson at gmail.com> wrote:
> 
> Dear list,
> 
> I'm experiencing problems with converting strings of the format
> "YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates which (I
> think) I need in order to retrieve the month-of-the-year number.
> 
> Simpler put: I'd like to match week-of-the-year numbers to
> month-of-the-year numbers. Ideally, the week-of-the-year number would
> follow the ISO 8601 convention (i.e. format argument "%V") instead of the
> US (format argument "%U") or UK (format argument "%W") convention.
> 
> After posting this to Stackoverflow, I have strong reasons to believe that
> the issue is caused by Windows:
> http://stackoverflow.com/questions/41616407/match-iso-8601-week-numbers-to-month-of-year-on-windows-with-german-locale/41617215?noredirect=1#comment70436768_41617215
> 
> Example:
> 
> # ISO 8601 convention:
> 
> (yw <- format(posix, "%Y-%V"))

The documentation for R datetime format parameters ?strptime says %V is ignored on input.


> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))

The documentation for R datetime format parameters ( = ?strptime) says %V is ignored on input.

You should leartn to post plain text to r-help.

-- 
David.


> # [1]
> "2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
> -> utterly wrong!!!
> 
> # US convention:
> (yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00" "2016-01"
> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
> "2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
> -> NA problem for week 00A fellow R user tested this on both macOS and
> Ubuntu and he didn't encounter the issue:
> 
> some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
> "2016-01-08"))
> (year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
> "2016 00" "2016 01"
> (year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
> 52 1" "2016 00 1" "2016 01 1"
> (as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
> EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
> 
> My session info:
> 
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> locale:[1] LC_COLLATE=German_Germany.1252
> LC_CTYPE=German_Germany.1252       LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                       LC_TIME=English_United
> States.1252
> 
> attached base packages:[1] stats     graphics  grDevices utils
> datasets  methods   base
> 
> other attached packages:
> [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
> plyr_1.8.4      magrittr_1.5
> [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0
> 
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
> crayon_1.3.2    withr_1.0.2
> [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
> tools_3.3.2     stringr_1.1.0  [13] tibble_1.2
> 
> Any idea on how to workaround this issue on Windows?
> 
> Thanks and best regards,
> 
> Janko Thyson
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bob at rud.is  Thu Jan 12 21:41:02 2017
From: bob at rud.is (Bob Rudis)
Date: Thu, 12 Jan 2017 15:41:02 -0500
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
 numbers on Windows with German locale
In-Reply-To: <DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
Message-ID: <CAA-FpKXp4EDrJ=JdqyxP1O+vXYy7uVFBCuJ88OgZKfOuKvRADA@mail.gmail.com>

Aye, but this:

  some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
"2016-01-08"))

  (year_week <- format(some_dates, "%Y-%U"))
  ## [1] "2015-51" "2015-52" "2016-00" "2016-01"

  (year_week_day <- sprintf("%s-1", year_week))
  ## [1] "2015-51-1" "2015-52-1" "2016-00-1" "2016-01-1"

  (as.POSIXct(year_week_day, format = "%Y-%U-%u"))
  ## [1] "2015-12-21 EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"

works fine on macOS & Linux (Ubuntu, anyway), but it fails on Windows
(10, 64bit, R 3.3.2):

  (as.POSIXct(year_week_day, format = "%Y-%U-%u"))
  ## [1] "2015-12-21 PST" "2015-12-28 PST" NA               "2016-01-04 PST"

On 1/12/17, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Jan 12, 2017, at 8:14 AM, Janko Thyson <janko.thyson at gmail.com> wrote:
>>
>> Dear list,
>>
>> I'm experiencing problems with converting strings of the format
>> "YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates which
>> (I
>> think) I need in order to retrieve the month-of-the-year number.
>>
>> Simpler put: I'd like to match week-of-the-year numbers to
>> month-of-the-year numbers. Ideally, the week-of-the-year number would
>> follow the ISO 8601 convention (i.e. format argument "%V") instead of the
>> US (format argument "%U") or UK (format argument "%W") convention.
>>
>> After posting this to Stackoverflow, I have strong reasons to believe
>> that
>> the issue is caused by Windows:
>> http://stackoverflow.com/questions/41616407/match-iso-8601-week-numbers-to-month-of-year-on-windows-with-german-locale/41617215?noredirect=1#comment70436768_41617215
>>
>> Example:
>>
>> # ISO 8601 convention:
>>
>> (yw <- format(posix, "%Y-%V"))
>
> The documentation for R datetime format parameters ?strptime says %V is
> ignored on input.
>
>
>> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))
>
> The documentation for R datetime format parameters ( = ?strptime) says %V is
> ignored on input.
>
> You should leartn to post plain text to r-help.
>
> --
> David.
>
>
>> # [1]
>> "2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
>> -> utterly wrong!!!
>>
>> # US convention:
>> (yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00"
>> "2016-01"
>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
>> "2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
>> -> NA problem for week 00A fellow R user tested this on both macOS and
>> Ubuntu and he didn't encounter the issue:
>>
>> some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
>> "2016-01-08"))
>> (year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
>> "2016 00" "2016 01"
>> (year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
>> 52 1" "2016 00 1" "2016 01 1"
>> (as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
>> EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
>>
>> My session info:
>>
>>> sessionInfo()
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> locale:[1] LC_COLLATE=German_Germany.1252
>> LC_CTYPE=German_Germany.1252       LC_MONETARY=German_Germany.1252
>> [4] LC_NUMERIC=C                       LC_TIME=English_United
>> States.1252
>>
>> attached base packages:[1] stats     graphics  grDevices utils
>> datasets  methods   base
>>
>> other attached packages:
>> [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
>> plyr_1.8.4      magrittr_1.5
>> [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0
>>
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
>> crayon_1.3.2    withr_1.0.2
>> [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
>> tools_3.3.2     stringr_1.1.0  [13] tibble_1.2
>>
>> Any idea on how to workaround this issue on Windows?
>>
>> Thanks and best regards,
>>
>> Janko Thyson
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From NordlDJ at dshs.wa.gov  Thu Jan 12 22:20:42 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 12 Jan 2017 21:20:42 +0000
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
 numbers on Windows with German locale
In-Reply-To: <CAA-FpKXp4EDrJ=JdqyxP1O+vXYy7uVFBCuJ88OgZKfOuKvRADA@mail.gmail.com>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
	<CAA-FpKXp4EDrJ=JdqyxP1O+vXYy7uVFBCuJ88OgZKfOuKvRADA@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E7D04E@WAXMXOLYMB025.WAX.wa.lcl>

See comments inline.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bob Rudis
> Sent: Thursday, January 12, 2017 12:41 PM
> To: David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] Match ISO 8601 week-of-year numbers to month-of-year
> numbers on Windows with German locale
> 
> Aye, but this:
> 
>   some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
> "2016-01-08"))
> 
>   (year_week <- format(some_dates, "%Y-%U"))
>   ## [1] "2015-51" "2015-52" "2016-00" "2016-01"
> 
>   (year_week_day <- sprintf("%s-1", year_week))
>   ## [1] "2015-51-1" "2015-52-1" "2016-00-1" "2016-01-1"
> 
>   (as.POSIXct(year_week_day, format = "%Y-%U-%u"))
>   ## [1] "2015-12-21 EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
> 
> works fine on macOS & Linux (Ubuntu, anyway), but it fails on Windows (10,
> 64bit, R 3.3.2):
> 
>   (as.POSIXct(year_week_day, format = "%Y-%U-%u"))
>   ## [1] "2015-12-21 PST" "2015-12-28 PST" NA               "2016-01-04 PST"

Why do you say it works fine on Ubuntu?  The date "2016-01-01" is in week 0 of 2016.  There is no Monday in week 0.  So I would argue the return  value of NA from Windows is more appropriate than returning the date of Monday in week 1 of 2016 like Ubuntu does.

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> 
> On 1/12/17, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> >> On Jan 12, 2017, at 8:14 AM, Janko Thyson <janko.thyson at gmail.com>
> wrote:
> >>
> >> Dear list,
> >>
> >> I'm experiencing problems with converting strings of the format
> >> "YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates
> >> which (I
> >> think) I need in order to retrieve the month-of-the-year number.
> >>
> >> Simpler put: I'd like to match week-of-the-year numbers to
> >> month-of-the-year numbers. Ideally, the week-of-the-year number
> would
> >> follow the ISO 8601 convention (i.e. format argument "%V") instead of
> >> the US (format argument "%U") or UK (format argument "%W")
> convention.
> >>
> >> After posting this to Stackoverflow, I have strong reasons to believe
> >> that the issue is caused by Windows:
> >> http://stackoverflow.com/questions/41616407/match-iso-8601-week-
> numbe
> >> rs-to-month-of-year-on-windows-with-german-
> locale/41617215?noredirect
> >> =1#comment70436768_41617215
> >>
> >> Example:
> >>
> >> # ISO 8601 convention:
> >>
> >> (yw <- format(posix, "%Y-%V"))
> >
> > The documentation for R datetime format parameters ?strptime says %V
> > is ignored on input.
> >
> >
> >> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
> >> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))
> >
> > The documentation for R datetime format parameters ( = ?strptime) says
> > %V is ignored on input.
> >
> > You should leartn to post plain text to r-help.
> >
> > --
> > David.
> >
> >
> >> # [1]
> >> "2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
> >> -> utterly wrong!!!
> >>
> >> # US convention:
> >> (yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00"
> >> "2016-01"
> >> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
> >> "2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
> >> -> NA problem for week 00A fellow R user tested this on both macOS
> >> -> and
> >> Ubuntu and he didn't encounter the issue:
> >>
> >> some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
> >> "2016-01-08"))
> >> (year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
> >> "2016 00" "2016 01"
> >> (year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
> >> 52 1" "2016 00 1" "2016 01 1"
> >> (as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
> >> EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
> >>
> >> My session info:
> >>
> >>> sessionInfo()
> >> R version 3.3.2 (2016-10-31)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >=
> 8
> >> x64 (build 9200)
> >>
> >> locale:[1] LC_COLLATE=German_Germany.1252
> >> LC_CTYPE=German_Germany.1252
> LC_MONETARY=German_Germany.1252
> >> [4] LC_NUMERIC=C                       LC_TIME=English_United
> >> States.1252
> >>
> >> attached base packages:[1] stats     graphics  grDevices utils
> >> datasets  methods   base
> >>
> >> other attached packages:
> >> [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
> >> plyr_1.8.4      magrittr_1.5
> >> [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0
> >>
> >> loaded via a namespace (and not attached):
> >> [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
> >> crayon_1.3.2    withr_1.0.2
> >> [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
> >> tools_3.3.2     stringr_1.1.0  [13] tibble_1.2
> >>
> >> Any idea on how to workaround this issue on Windows?
> >>
> >> Thanks and best regards,
> >>
> >> Janko Thyson
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 


From drjimlemon at gmail.com  Thu Jan 12 22:27:21 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 13 Jan 2017 08:27:21 +1100
Subject: [R] Qvalue package: I am getting back 1,
 000 q values when I only want 1 q value.
In-Reply-To: <CANvF3ck-O6hy031HCRWH+3dhVguMFBszSEXQh1mNvs4tknjGWQ@mail.gmail.com>
References: <CANvF3ck-O6hy031HCRWH+3dhVguMFBszSEXQh1mNvs4tknjGWQ@mail.gmail.com>
Message-ID: <CA+8X3fW7HO8E5D5VJsWwGSB74e-A_Sy0qy9QkSb4DQQHNso_zg@mail.gmail.com>

Hi Tom,
>From a quick scan of the docs, I think you are looking for qobj$pi0.
The vector qobj$qvalue seems to be the local false discovery rate for
each of your randomizations. Note that the manual implies that the p
values are those of multiple comparisons within a data set, not
randomizations of the data, so I'm not sure that your usage is valid
for the function..

Jim


On Fri, Jan 13, 2017 at 4:12 AM, Thomas Ryan <tombernardryan at gmail.com> wrote:
> Hi all, I'm wondering if someone could put me on the right path to using
> the "qvalue" package correctly.
>
> I have an original p value from an analysis, and I've done 1,000
> randomisations of the data set. So I now have an original P value and 1,000
> random p values. I want to work out the false discovery rate (FDR) (Q; as
> described by Storey and Tibshriani in 2003) for my original p value,
> defined as the number of expected false positives over the number of
> significant results for my original P value.
>
> So, for my original P value, I want one Q value, that has been calculated
> as described above based on the 1,000 random p values.
>
> I wrote this code:
>
> pvals <- c(list_of_p_values_obtained_from_randomisations)
> qobj <-qvalue(p=pvals)
> r_output1 <- qobj$pvalue
> r_output2 <- qobj$qvalue
>
> r_output1 is the list of 1,000 p values that I put in, and r_output2 is a q
> value for each of those p values (i.e. so there are 1,000 q values).
>
> The problem is I don't want there to be 1,000 Q values (i.e one for each
> random p value). The Q value should be the false discovery rate (FDR) (Q),
> defined as the number of expected false positives over the number of
> significant results. So I want one Q value for my original P value, and to
> calculate that one Q value using the 1,000 random P values I have generated.
>
> Could someone please tell me where I'm going wrong.
>
> Thanks
> Tom
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jennifer.sheng2002 at gmail.com  Thu Jan 12 22:44:03 2017
From: jennifer.sheng2002 at gmail.com (Jennifer Sheng)
Date: Thu, 12 Jan 2017 16:44:03 -0500
Subject: [R] for loop in R
Message-ID: <CALvAKXJVhGCRWf1y5Vt1CEC9x_dQmeiwkV7oufhOPEqKM2iCHQ@mail.gmail.com>

Dear friends,  I am working on a double loop using for.  One level of loop
is to predict N times for each subject, and the second level is to predict
M times for the every subject, one subject after one subject.   Please note
every subject have different N or M rows of data.   Any advice?  Thank you
so much!

Below is the current code:

set.seed (123)   ## for consistent result;

ND <- S004Cmin[S004Cmin$ID %in% c(1:10),]   # define the first 10 subjects

predSurv <- vector("list", nrow(ND))

for (i in 1:nrow(ND)) {

  set.seed(123)

  predSurv[[i]] <- survfitJM(fitJOINT.NULL, newdata = ND[1:i, ],
idVar="USUBJID")

  }



Thank you very much!

Jenny

	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Thu Jan 12 23:23:43 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 12 Jan 2017 23:23:43 +0100
Subject: [R] Question about Cubist Model
Message-ID: <20170112222343.GA2894@chicca>

Dear All,
I am fine tuning a Cubist model (see
https://cran.r-project.org/web/packages/Cubist/index.html).
I am a bit puzzled by its output. On a dataset which contains 275
cases, I get non mutually exclusive rules.
E.g., in the output below, rules 2 and 3 cover all the 275 cases of
the data set and rule 1 overlaps partially.
Am I misunderstanding something?
Many thanks

Lorenzo




Cubist [Release 2.07 GPL Edition]  Thu Jan 12 23:10:40 2017
---------------------------------

    Target attribute `outcome'

Read 275 cases (21 attributes) from undefined.data

Model:

  Rule 1: [204 cases, mean 0.5393324, range 0 to 2.285714, est err
  0.2598495]

    if
	home_copub_after_all <= 0.7142857
        host_copub_after_all <= 1.833333
		 then
	     outcome = 0.1666667 + 0.9 home_copub_after_all
		          + 0.11 home_copub_before_all

  Rule 2: [259 cases, mean 0.7445303, range 0 to 3.166667, est err
  0.1866440]

    if
	host_copub_after_all <= 1.833333
	    then
		outcome = 0.0433333 + 0.75 home_copub_after_all
			          + 0.33 host_copub_after_all + 0.37
	top_10_after_all

  Rule 3: [16 cases, mean 4.4285712, range 2.142857 to 8.857142, est
  err 1.0346190]

    if
	host_copub_after_all > 1.833333
	    then
		outcome = 1.595 + 1.03 top_10_after_all + 0.45
	home_copub_after_all


Evaluation on training data (275 cases):

    Average  |error|          0.2678023
        Relative |error|               0.38
	    Correlation coefficient        0.94


	    Attribute usage:
	    	        Conds  Model

			  100%    54%    host_copub_after_all
			  	     43%   100%
			  	     home_copub_after_all
					          57%
			  	     top_10_after_all
					          43%
			  	     home_copub_before_all


Time: 0.0 secs
>


From lorenzo.isella at gmail.com  Thu Jan 12 23:37:37 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 12 Jan 2017 23:37:37 +0100
Subject: [R] Question about Cubist Model
Message-ID: <20170112223737.GB2894@chicca>

Dear All,
I am fine tuning a Cubist model (see
https://cran.r-project.org/web/packages/Cubist/index.html).
I am a bit puzzled by its output. On a dataset which contains 275
cases, I get non mutually exclusive rules.
E.g., in the output below, rules 2 and 3 cover all the 275 cases of
the data set and rule 1 overlaps partially.
Am I misunderstanding something?
Many thanks

Lorenzo




Cubist [Release 2.07 GPL Edition]  Thu Jan 12 23:10:40 2017
---------------------------------

    Target attribute `outcome'

Read 275 cases (21 attributes) from undefined.data

Model:

  Rule 1: [204 cases, mean 0.5393324, range 0 to 2.285714, est err
  0.2598495]

    if
	home_copub_after_all <= 0.7142857
        host_copub_after_all <= 1.833333
		 then
	     outcome = 0.1666667 + 0.9 home_copub_after_all
		          + 0.11 home_copub_before_all

  Rule 2: [259 cases, mean 0.7445303, range 0 to 3.166667, est err
  0.1866440]

    if
	host_copub_after_all <= 1.833333
	    then
		outcome = 0.0433333 + 0.75 home_copub_after_all
			          + 0.33 host_copub_after_all + 0.37
	top_10_after_all

  Rule 3: [16 cases, mean 4.4285712, range 2.142857 to 8.857142, est
  err 1.0346190]

    if
	host_copub_after_all > 1.833333
	    then
		outcome = 1.595 + 1.03 top_10_after_all + 0.45
	home_copub_after_all


Evaluation on training data (275 cases):

    Average  |error|          0.2678023
        Relative |error|               0.38
	    Correlation coefficient        0.94


	    Attribute usage:
	    	        Conds  Model

			  100%    54%    host_copub_after_all
			  	     43%   100%
			  	     home_copub_after_all
					          57%
			  	     top_10_after_all
					          43%
			  	     home_copub_before_all


Time: 0.0 secs
>


From rsherry8 at comcast.net  Thu Jan 12 22:49:17 2017
From: rsherry8 at comcast.net (Robert Sherry)
Date: Thu, 12 Jan 2017 16:49:17 -0500
Subject: [R] for loop in R
In-Reply-To: <CALvAKXJVhGCRWf1y5Vt1CEC9x_dQmeiwkV7oufhOPEqKM2iCHQ@mail.gmail.com>
References: <CALvAKXJVhGCRWf1y5Vt1CEC9x_dQmeiwkV7oufhOPEqKM2iCHQ@mail.gmail.com>
Message-ID: <a9f2843a-9f83-58f7-b8f6-63699b11c353@comcast.net>

I only see one for loop in your code. I am wondering if you want a 
second for loop based upon the length of newdata.

I would also think that you do not need the second call to set.seed.

Bob

On 1/12/2017 4:44 PM, Jennifer Sheng wrote:
> Dear friends,  I am working on a double loop using for.  One level of loop
> is to predict N times for each subject, and the second level is to predict
> M times for the every subject, one subject after one subject.   Please note
> every subject have different N or M rows of data.   Any advice?  Thank you
> so much!
>
> Below is the current code:
>
> set.seed (123)   ## for consistent result;
>
> ND <- S004Cmin[S004Cmin$ID %in% c(1:10),]   # define the first 10 subjects
>
> predSurv <- vector("list", nrow(ND))
>
> for (i in 1:nrow(ND)) {
>
>    set.seed(123)
>
>    predSurv[[i]] <- survfitJM(fitJOINT.NULL, newdata = ND[1:i, ],
> idVar="USUBJID")
>
>    }
>
>
>
> Thank you very much!
>
> Jenny
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jennifer.sheng2002 at gmail.com  Fri Jan 13 00:36:35 2017
From: jennifer.sheng2002 at gmail.com (jennifer.sheng2002 at gmail.com)
Date: Thu, 12 Jan 2017 18:36:35 -0500
Subject: [R] for loop in R
In-Reply-To: <a9f2843a-9f83-58f7-b8f6-63699b11c353@comcast.net>
References: <CALvAKXJVhGCRWf1y5Vt1CEC9x_dQmeiwkV7oufhOPEqKM2iCHQ@mail.gmail.com>
	<a9f2843a-9f83-58f7-b8f6-63699b11c353@comcast.net>
Message-ID: <EBEA218F-7790-447C-97A1-F64BEB2FFCFF@gmail.com>

That is right, Bob.  Only one loop for now, since I do not know how to set up the 2nd loop.  Any advice from the community?  Thank you!

Sent from my iPhone

> On Jan 12, 2017, at 4:49 PM, Robert Sherry <rsherry8 at comcast.net> wrote:
> 
> I only see one for loop in your code. I am wondering if you want a second for loop based upon the length of newdata.
> 
> I would also think that you do not need the second call to set.seed.
> 
> Bob
> 
>> On 1/12/2017 4:44 PM, Jennifer Sheng wrote:
>> Dear friends,  I am working on a double loop using for.  One level of loop
>> is to predict N times for each subject, and the second level is to predict
>> M times for the every subject, one subject after one subject.   Please note
>> every subject have different N or M rows of data.   Any advice?  Thank you
>> so much!
>> 
>> Below is the current code:
>> 
>> set.seed (123)   ## for consistent result;
>> 
>> ND <- S004Cmin[S004Cmin$ID %in% c(1:10),]   # define the first 10 subjects
>> 
>> predSurv <- vector("list", nrow(ND))
>> 
>> for (i in 1:nrow(ND)) {
>> 
>>   set.seed(123)
>> 
>>   predSurv[[i]] <- survfitJM(fitJOINT.NULL, newdata = ND[1:i, ],
>> idVar="USUBJID")
>> 
>>   }
>> 
>> 
>> 
>> Thank you very much!
>> 
>> Jenny
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mxkuhn at gmail.com  Fri Jan 13 00:04:29 2017
From: mxkuhn at gmail.com (Mxkuhn)
Date: Thu, 12 Jan 2017 18:04:29 -0500
Subject: [R] Question about Cubist Model
In-Reply-To: <20170112223737.GB2894@chicca>
References: <20170112223737.GB2894@chicca>
Message-ID: <2D0BA9FF-2963-4E32-939C-F5458FA4EC48@gmail.com>



> On Jan 12, 2017, at 5:37 PM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
> Dear All,
> I am fine tuning a Cubist model (see
> https://cran.r-project.org/web/packages/Cubist/index.html).
> I am a bit puzzled by its output. On a dataset which contains 275
> cases, I get non mutually exclusive rules.
> E.g., in the output below, rules 2 and 3 cover all the 275 cases of
> the data set and rule 1 overlaps partially.
> Am I misunderstanding something?

It is doing the right thing. The rules are first derived from a regression tree and, in the process of pruning the rules, they can produce overlapping sets. When the rules overlap, the regression output is average across the active rules. 

Thanks,

Max

> Many thanks
> 
> Lorenzo
> 
> 
> 
> 
> Cubist [Release 2.07 GPL Edition]  Thu Jan 12 23:10:40 2017
> ---------------------------------
> 
>   Target attribute `outcome'
> 
> Read 275 cases (21 attributes) from undefined.data
> 
> Model:
> 
> Rule 1: [204 cases, mean 0.5393324, range 0 to 2.285714, est err
> 0.2598495]
> 
>   if
>    home_copub_after_all <= 0.7142857
>       host_copub_after_all <= 1.833333
>         then
>         outcome = 0.1666667 + 0.9 home_copub_after_all
>                  + 0.11 home_copub_before_all
> 
> Rule 2: [259 cases, mean 0.7445303, range 0 to 3.166667, est err
> 0.1866440]
> 
>   if
>    host_copub_after_all <= 1.833333
>        then
>        outcome = 0.0433333 + 0.75 home_copub_after_all
>                      + 0.33 host_copub_after_all + 0.37
>    top_10_after_all
> 
> Rule 3: [16 cases, mean 4.4285712, range 2.142857 to 8.857142, est
> err 1.0346190]
> 
>   if
>    host_copub_after_all > 1.833333
>        then
>        outcome = 1.595 + 1.03 top_10_after_all + 0.45
>    home_copub_after_all
> 
> 
> Evaluation on training data (275 cases):
> 
>   Average  |error|          0.2678023
>       Relative |error|               0.38
>        Correlation coefficient        0.94
> 
> 
>        Attribute usage:
>                    Conds  Model
> 
>              100%    54%    host_copub_after_all
>                       43%   100%
>                       home_copub_after_all
>                              57%
>                       top_10_after_all
>                              43%
>                       home_copub_before_all
> 
> 
> Time: 0.0 secs
>> 


From rmh at temple.edu  Fri Jan 13 06:46:59 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 13 Jan 2017 00:46:59 -0500
Subject: [R] what is f_eval? It has broken the HH package
Message-ID: <CAGx1TMCZDhB5+A5Bx3H78+Z4B1sH3YPha8bButgLqy5dLV9fng@mail.gmail.com>

I am preparing for the new semester and have downloaded and installed
R-3.3.2 for Macintosh and Windows, and then the HH package and its
dependencies for both.
Everything fresh off CRAN.

All works correctly on the Macintosh.
On the Windows 10 I am getting an error

> library(HH)
Loading required package: lattice
Loading required package: grid
Loading required package: latticeExtra
Loading required package: RColorBrewer
Loading required package: multcomp
Loading required package: mvtnorm
Loading required package: survival
Loading required package: TH.data
Loading required package: MASS

Attaching package: 'TH.data'

The following object is masked from 'package:MASS':

    geyser

Loading required package: gridExtra
Error : object 'f_eval' is not exported by 'namespace:lazyeval'
Error: package or namespace load failed for 'HH'



I can't find f_eval

> lazyeval::f_eval
Error: 'f_eval' is not an exported object from 'namespace:lazyeval'
> lazyeval:::f_eval
Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
  object 'f_eval' not found
>



Just to check I backed up to R-3.3.1 on Windows.  That is now also broken
> library(HH)
Loading required package: lattice
Loading required package: grid
Loading required package: latticeExtra
Loading required package: RColorBrewer
Loading required package: multcomp
Loading required package: mvtnorm
Loading required package: survival
Loading required package: TH.data
Loading required package: MASS

Attaching package: 'TH.data'

The following object is masked from 'package:MASS':

    geyser

Loading required package: gridExtra
Error : object 'f_eval' is not exported by 'namespace:lazyeval'
In addition: Warning messages:
1: package 'HH' was built under R version 3.3.2
2: package 'gridExtra' was built under R version 3.3.2
Error: package or namespace load failed for 'HH'
>




I backed up one more time to R-3.2.4revised on Windows
 R version 3.2.4 Revised (2016-03-16 r70336)
Here HH still loads correctly.


I was planning a new release of HH this weekend, but it has now become urgent.
Can someone enlighten me on what f_eval is and how I need to work with it?
Also, why is this Windows only, and not also a Macintosh problem?

Thanks
Rich


From soni.archit1989 at gmail.com  Fri Jan 13 10:12:34 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Fri, 13 Jan 2017 14:42:34 +0530
Subject: [R] JSON data in data frame
Message-ID: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>

Hi All,

Warm greetings, I am stuck at an issue to convert incoming json response to
data frame.

I am using below code to get the data

library(jsonlite)
d1 <- fromJSON('
http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
')

d2 <- as.data.frame(d1)
?
typeof(d2)
list

can you please guide me how can i get this data into pure data.frame
format. The list in d1 has nested data.frame objects.

Note: If you are unable to get data from api then can use below json string
to test it out:

JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":{"type":1,"id":7323,"message":0.193,"country":"RU","sunrise":1484286631,"sunset":1484313983},"weather":[{"id":600,"main":"Snow","description":"light
snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"humidity":86,"temp_min":-4,"temp_max":-3},"visibility":8000,"wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":1484290800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.52,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"country":"UA","sunrise":1484286787,"sunset":1484317236},"weather":[{"id":804,"main":"Clouds","description":"overcast
clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"humidity":92,"temp_min":-2,"temp_max":-2},"visibility":9000,"wind":{"speed":4,"deg":250,"var_beg":210,"var_end":270},"clouds":{"all":90},"dt":1484290800,"id":703448,"name":"Kiev"},{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"id":5187,"message":0.1973,"country":"GB","sunrise":1484294413,"sunset":1484324321},"weather":[{"id":802,"main":"Clouds","description":"scattered
clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"temp_min":0,"temp_max":2,"humidity":98},"visibility":10000,"wind":{"speed":6.2,"deg":270},"clouds":{"all":40},"dt":1484290200,"id":2643743,"name":"London"}]}

Any help is appreciated.

-- 
Regards
Archit

	[[alternative HTML version deleted]]


From janko.thyson at gmail.com  Fri Jan 13 12:20:31 2017
From: janko.thyson at gmail.com (Janko Thyson)
Date: Fri, 13 Jan 2017 12:20:31 +0100
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
 numbers on Windows with German locale
In-Reply-To: <DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
Message-ID: <CAGmpuejra4=+PCpUs3eAWuzkgMc4HP-WVXpmbj0XGYmBtErKoA@mail.gmail.com>

Hi David,

thanks for replying and sorry about the HTML/non-plain-text email (I
forgot to change that, shouldn't have happened).

Might just be me, but reading "The documentation for R datetime format
parameters ?strptime says %V is ignored on input." in the
documentation doesn't really tell me all that much. As a user, I would
read that, not completely understand what this means and thus try to
understand it better by applying it in actual code:

(yw <- format(posix, "%Y-%V"))
> # [1] "2015-52" "2015-53" "2016-53" "2016-01"

Which, after checking back with a calendar, would give me reason to
believe that it using %V does in fact seem to work: it's an input to
`format()` and R doesn't seem to ignore it as the correct week numbers
(following ISO 8601) are returned.

Not wanting to stress this particular aspect any further, though, I
would slightly rephrase my original question: is it possible to use
the ISO 8601 convention for weeknumbers at all (on Windows, using a
German locale setting) and if so, how would I link ISO 8601
weeknumbers to the correct month of the year?

Thanks for help,
Janko

On Thu, Jan 12, 2017 at 8:37 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Jan 12, 2017, at 8:14 AM, Janko Thyson <janko.thyson at gmail.com> wrote:
>>
>> Dear list,
>>
>> I'm experiencing problems with converting strings of the format
>> "YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates which (I
>> think) I need in order to retrieve the month-of-the-year number.
>>
>> Simpler put: I'd like to match week-of-the-year numbers to
>> month-of-the-year numbers. Ideally, the week-of-the-year number would
>> follow the ISO 8601 convention (i.e. format argument "%V") instead of the
>> US (format argument "%U") or UK (format argument "%W") convention.
>>
>> After posting this to Stackoverflow, I have strong reasons to believe that
>> the issue is caused by Windows:
>> http://stackoverflow.com/questions/41616407/match-iso-8601-week-numbers-to-month-of-year-on-windows-with-german-locale/41617215?noredirect=1#comment70436768_41617215
>>
>> Example:
>>
>> # ISO 8601 convention:
>>
>> (yw <- format(posix, "%Y-%V"))
>
> The documentation for R datetime format parameters ?strptime says %V is ignored on input.
>
>
>> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))
>
> The documentation for R datetime format parameters ( = ?strptime) says %V is ignored on input.
>
> You should leartn to post plain text to r-help.
>
> --
> David.
>
>
>> # [1]
>> "2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
>> -> utterly wrong!!!
>>
>> # US convention:
>> (yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00" "2016-01"
>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
>> "2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
>> -> NA problem for week 00A fellow R user tested this on both macOS and
>> Ubuntu and he didn't encounter the issue:
>>
>> some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
>> "2016-01-08"))
>> (year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
>> "2016 00" "2016 01"
>> (year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
>> 52 1" "2016 00 1" "2016 01 1"
>> (as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
>> EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
>>
>> My session info:
>>
>>> sessionInfo()
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> locale:[1] LC_COLLATE=German_Germany.1252
>> LC_CTYPE=German_Germany.1252       LC_MONETARY=German_Germany.1252
>> [4] LC_NUMERIC=C                       LC_TIME=English_United
>> States.1252
>>
>> attached base packages:[1] stats     graphics  grDevices utils
>> datasets  methods   base
>>
>> other attached packages:
>> [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
>> plyr_1.8.4      magrittr_1.5
>> [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0
>>
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
>> crayon_1.3.2    withr_1.0.2
>> [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
>> tools_3.3.2     stringr_1.1.0  [13] tibble_1.2
>>
>> Any idea on how to workaround this issue on Windows?
>>
>> Thanks and best regards,
>>
>> Janko Thyson
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From murdoch.duncan at gmail.com  Fri Jan 13 12:27:42 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Jan 2017 06:27:42 -0500
Subject: [R] what is f_eval? It has broken the HH package
In-Reply-To: <CAGx1TMCZDhB5+A5Bx3H78+Z4B1sH3YPha8bButgLqy5dLV9fng@mail.gmail.com>
References: <CAGx1TMCZDhB5+A5Bx3H78+Z4B1sH3YPha8bButgLqy5dLV9fng@mail.gmail.com>
Message-ID: <2b95484a-6289-65b9-ba4d-1802b6b1351b@gmail.com>

On 13/01/2017 12:46 AM, Richard M. Heiberger wrote:
> I am preparing for the new semester and have downloaded and installed
> R-3.3.2 for Macintosh and Windows, and then the HH package and its
> dependencies for both.
> Everything fresh off CRAN.
>
> All works correctly on the Macintosh.
> On the Windows 10 I am getting an error
>
>> library(HH)
> Loading required package: lattice
> Loading required package: grid
> Loading required package: latticeExtra
> Loading required package: RColorBrewer
> Loading required package: multcomp
> Loading required package: mvtnorm
> Loading required package: survival
> Loading required package: TH.data
> Loading required package: MASS
>
> Attaching package: 'TH.data'
>
> The following object is masked from 'package:MASS':
>
>     geyser
>
> Loading required package: gridExtra
> Error : object 'f_eval' is not exported by 'namespace:lazyeval'
> Error: package or namespace load failed for 'HH'
>

What version of lazyeval do you have there?  f_eval is exported by the 
current version 0.2.0, which isn't very new:  it's from June, 2016.

I'd try re-installing it.

Duncan Murdoch

>
>
> I can't find f_eval
>
>> lazyeval::f_eval
> Error: 'f_eval' is not an exported object from 'namespace:lazyeval'
>> lazyeval:::f_eval
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>   object 'f_eval' not found
>>
>
>
>
> Just to check I backed up to R-3.3.1 on Windows.  That is now also broken
>> library(HH)
> Loading required package: lattice
> Loading required package: grid
> Loading required package: latticeExtra
> Loading required package: RColorBrewer
> Loading required package: multcomp
> Loading required package: mvtnorm
> Loading required package: survival
> Loading required package: TH.data
> Loading required package: MASS
>
> Attaching package: 'TH.data'
>
> The following object is masked from 'package:MASS':
>
>     geyser
>
> Loading required package: gridExtra
> Error : object 'f_eval' is not exported by 'namespace:lazyeval'
> In addition: Warning messages:
> 1: package 'HH' was built under R version 3.3.2
> 2: package 'gridExtra' was built under R version 3.3.2
> Error: package or namespace load failed for 'HH'
>>
>
>
>
>
> I backed up one more time to R-3.2.4revised on Windows
>  R version 3.2.4 Revised (2016-03-16 r70336)
> Here HH still loads correctly.
>
>
> I was planning a new release of HH this weekend, but it has now become urgent.
> Can someone enlighten me on what f_eval is and how I need to work with it?
> Also, why is this Windows only, and not also a Macintosh problem?
>
> Thanks
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From btyner at gmail.com  Fri Jan 13 12:54:35 2017
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 13 Jan 2017 06:54:35 -0500
Subject: [R] [FORGED] file.exists() on device files
In-Reply-To: <126ba0b3-aa2a-55c5-a119-f231d2127312@auckland.ac.nz>
References: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>
	<556530f1-dca1-6962-526b-65302ff5fe24@auckland.ac.nz>
	<CAFDcVCSe52wXeJkQqX+V6vfbqjPV+QyUCPNBs_g1ZECvmw71dg@mail.gmail.com>
	<126ba0b3-aa2a-55c5-a119-f231d2127312@auckland.ac.nz>
Message-ID: <6b61f4ab-a089-eb6c-7540-b6860397a803@gmail.com>

Thank you for the insights, Rolf and Henrik.

To give another example, this time in non-interactive mode,

    Rscript -e "file.exists(commandArgs(TRUE))" <(echo "Hi")

    [1] TRUE

versus

    Rscript -e "normalizePath(commandArgs(TRUE))" <(echo "Hi")
    [1] "/dev/fd/63"
    Warning message:
    In normalizePath(commandArgs(TRUE)) :
      path[1]="/dev/fd/63": No such file or directory

It almost seems like file.exists and normalizePath use separate criteria 
for determining existence?

Regards

Ben

On 01/12/2017 01:42 AM, Rolf Turner wrote:
> On 12/01/17 16:33, Henrik Bengtsson wrote:
>
> <SNIP>
>
>> FYI, the /proc is there because Unix has something called the "proc
>> filesystem (procfs; https://en.wikipedia.org/wiki/Procfs) is a special
>> filesystem in Unix-like operating systems that presents information
>> about processes and other system information in a hierarchical
>> file-like structure".  For instance, you can query the uptime of the
>> machine by reading from /proc/uptime:
>>
>> $ cat /proc/uptime
>> 332826.96 661438.10
>>
>> $ cat /proc/uptime
>> 332871.40 661568.50
>>
>>
>> You can get all IDs (PIDs) of all processes currently running:
>>
>> $ ls /proc/ | grep -E '^[0-9]+$'
>>
>> and for each process you there are multiple attributes mapped as
>> files, e.g. if I start R as:
>>
>> $ R --args -e "message('hello there')"
>>
>> then I can query that process as:
>>
>> $ pid=$(pidof R)
>> $ echo $pid
>> 26323
>>
>> $ cat /proc/26323/cmdline
>> /usr/lib/R/bin/exec/R--args-emessage('hello there')
>>
>> Unix is neat
>
> Indeed.  Couldn't agree more.  Thanks for the insight.
>
> <SNIP>
>
> cheers,
>
> Rolf
>


From bob at rud.is  Thu Jan 12 12:28:08 2017
From: bob at rud.is (Bob Rudis)
Date: Thu, 12 Jan 2017 06:28:08 -0500
Subject: [R] [R-pkgs] New package: epidata
Message-ID: <CAA-FpKXCUe-HMO3QAsF0LAytz8kPX=jCpBOwaPQyCoUQHQpa+w@mail.gmail.com>

Hey folks,

epidata ? https://cran.r-project.org/package=epidata ? hit CRAN a few
days ago. It provides tools to retrieve Economic Policy Institute data
library extracts from their "hidden"-but-well-conceived API, returning
pristine data frames.

EPI <http://www.epi.org/> provides researchers, media, and the public
with easily accessible, up-to-date, and comprehensive historical data
on the American labor force. It is compiled from Economic Policy
Institute analysis of [U.S.] government data sources.

It has data on wages, unemployment, inequality, and other economic
indicators over time and among demographic groups. Their data is
usually updated monthly.

Code (with extended examples in the README) is at:
https://github.com/hrbrmstr/epidata

Issues, enhancements (etc) are ? as always ? welcome.

-Bob

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From rmh at temple.edu  Fri Jan 13 15:20:21 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 13 Jan 2017 09:20:21 -0500
Subject: [R] what is f_eval? It has broken the HH package
In-Reply-To: <2b95484a-6289-65b9-ba4d-1802b6b1351b@gmail.com>
References: <CAGx1TMCZDhB5+A5Bx3H78+Z4B1sH3YPha8bButgLqy5dLV9fng@mail.gmail.com>
	<2b95484a-6289-65b9-ba4d-1802b6b1351b@gmail.com>
Message-ID: <CAGx1TMA81nW+LhaZ5mNSLfzah_xbwhhSKAJbTRDz1XxnTHRL0g@mail.gmail.com>

That solved it.  Thank you.


On Fri, Jan 13, 2017 at 6:27 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13/01/2017 12:46 AM, Richard M. Heiberger wrote:
>>
>> I am preparing for the new semester and have downloaded and installed
>> R-3.3.2 for Macintosh and Windows, and then the HH package and its
>> dependencies for both.
>> Everything fresh off CRAN.
>>
>> All works correctly on the Macintosh.
>> On the Windows 10 I am getting an error
>>
>>> library(HH)
>>
>> Loading required package: lattice
>> Loading required package: grid
>> Loading required package: latticeExtra
>> Loading required package: RColorBrewer
>> Loading required package: multcomp
>> Loading required package: mvtnorm
>> Loading required package: survival
>> Loading required package: TH.data
>> Loading required package: MASS
>>
>> Attaching package: 'TH.data'
>>
>> The following object is masked from 'package:MASS':
>>
>>     geyser
>>
>> Loading required package: gridExtra
>> Error : object 'f_eval' is not exported by 'namespace:lazyeval'
>> Error: package or namespace load failed for 'HH'
>>
>
> What version of lazyeval do you have there?  f_eval is exported by the
> current version 0.2.0, which isn't very new:  it's from June, 2016.
>
> I'd try re-installing it.
>
> Duncan Murdoch
>
>>
>>
>> I can't find f_eval
>>
>>> lazyeval::f_eval
>>
>> Error: 'f_eval' is not an exported object from 'namespace:lazyeval'
>>>
>>> lazyeval:::f_eval
>>
>> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>>   object 'f_eval' not found
>>>
>>>
>>
>>
>>
>> Just to check I backed up to R-3.3.1 on Windows.  That is now also broken
>>>
>>> library(HH)
>>
>> Loading required package: lattice
>> Loading required package: grid
>> Loading required package: latticeExtra
>> Loading required package: RColorBrewer
>> Loading required package: multcomp
>> Loading required package: mvtnorm
>> Loading required package: survival
>> Loading required package: TH.data
>> Loading required package: MASS
>>
>> Attaching package: 'TH.data'
>>
>> The following object is masked from 'package:MASS':
>>
>>     geyser
>>
>> Loading required package: gridExtra
>> Error : object 'f_eval' is not exported by 'namespace:lazyeval'
>> In addition: Warning messages:
>> 1: package 'HH' was built under R version 3.3.2
>> 2: package 'gridExtra' was built under R version 3.3.2
>> Error: package or namespace load failed for 'HH'
>>>
>>>
>>
>>
>>
>>
>> I backed up one more time to R-3.2.4revised on Windows
>>  R version 3.2.4 Revised (2016-03-16 r70336)
>> Here HH still loads correctly.
>>
>>
>> I was planning a new release of HH this weekend, but it has now become
>> urgent.
>> Can someone enlighten me on what f_eval is and how I need to work with it?
>> Also, why is this Windows only, and not also a Macintosh problem?
>>
>> Thanks
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From jdnewmil at dcn.davis.ca.us  Fri Jan 13 17:43:14 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 13 Jan 2017 08:43:14 -0800
Subject: [R] [FORGED] file.exists() on device files
In-Reply-To: <6b61f4ab-a089-eb6c-7540-b6860397a803@gmail.com>
References: <4a51f1e1-df5f-6fa9-514f-89cdb86a123d@gmail.com>
	<556530f1-dca1-6962-526b-65302ff5fe24@auckland.ac.nz>
	<CAFDcVCSe52wXeJkQqX+V6vfbqjPV+QyUCPNBs_g1ZECvmw71dg@mail.gmail.com>
	<126ba0b3-aa2a-55c5-a119-f231d2127312@auckland.ac.nz>
	<6b61f4ab-a089-eb6c-7540-b6860397a803@gmail.com>
Message-ID: <08BED64B-A3EF-4C58-9E59-EDBD70169D9F@dcn.davis.ca.us>

Of course they have separate criteria for determining existence... they do different things, and therefore have different requirements for access permissions.
-- 
Sent from my phone. Please excuse my brevity.

On January 13, 2017 3:54:35 AM PST, Benjamin Tyner <btyner at gmail.com> wrote:
>Thank you for the insights, Rolf and Henrik.
>
>To give another example, this time in non-interactive mode,
>
>    Rscript -e "file.exists(commandArgs(TRUE))" <(echo "Hi")
>
>    [1] TRUE
>
>versus
>
>    Rscript -e "normalizePath(commandArgs(TRUE))" <(echo "Hi")
>    [1] "/dev/fd/63"
>    Warning message:
>    In normalizePath(commandArgs(TRUE)) :
>      path[1]="/dev/fd/63": No such file or directory
>
>It almost seems like file.exists and normalizePath use separate
>criteria 
>for determining existence?
>
>Regards
>
>Ben
>
>On 01/12/2017 01:42 AM, Rolf Turner wrote:
>> On 12/01/17 16:33, Henrik Bengtsson wrote:
>>
>> <SNIP>
>>
>>> FYI, the /proc is there because Unix has something called the "proc
>>> filesystem (procfs; https://en.wikipedia.org/wiki/Procfs) is a
>special
>>> filesystem in Unix-like operating systems that presents information
>>> about processes and other system information in a hierarchical
>>> file-like structure".  For instance, you can query the uptime of the
>>> machine by reading from /proc/uptime:
>>>
>>> $ cat /proc/uptime
>>> 332826.96 661438.10
>>>
>>> $ cat /proc/uptime
>>> 332871.40 661568.50
>>>
>>>
>>> You can get all IDs (PIDs) of all processes currently running:
>>>
>>> $ ls /proc/ | grep -E '^[0-9]+$'
>>>
>>> and for each process you there are multiple attributes mapped as
>>> files, e.g. if I start R as:
>>>
>>> $ R --args -e "message('hello there')"
>>>
>>> then I can query that process as:
>>>
>>> $ pid=$(pidof R)
>>> $ echo $pid
>>> 26323
>>>
>>> $ cat /proc/26323/cmdline
>>> /usr/lib/R/bin/exec/R--args-emessage('hello there')
>>>
>>> Unix is neat
>>
>> Indeed.  Couldn't agree more.  Thanks for the insight.
>>
>> <SNIP>
>>
>> cheers,
>>
>> Rolf
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From roundsjeremiah at gmail.com  Fri Jan 13 18:53:20 2017
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Fri, 13 Jan 2017 09:53:20 -0800
Subject: [R] JSON data in data frame
In-Reply-To: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
Message-ID: <CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>

I TAd a course in R computing and the first thing I told students was
"inspect. inspect. inspect."
d1 <- fromJSON('
http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
')
names(d1)
str(d1)
d1
d1$list
your_data = d1$list

On Fri, Jan 13, 2017 at 1:12 AM, Archit Soni <soni.archit1989 at gmail.com>
wrote:

> Hi All,
>
> Warm greetings, I am stuck at an issue to convert incoming json response to
> data frame.
>
> I am using below code to get the data
>
> library(jsonlite)
> d1 <- fromJSON('
> http://api.openweathermap.org/data/2.5/group?id=524901,
> 703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
> ')
>
> d2 <- as.data.frame(d1)
> ?
> typeof(d2)
> list
>
> can you please guide me how can i get this data into pure data.frame
> format. The list in d1 has nested data.frame objects.
>
> Note: If you are unable to get data from api then can use below json string
> to test it out:
>
> JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":
> {"type":1,"id":7323,"message":0.193,"country":"RU","sunrise"
> :1484286631,"sunset":1484313983},"weather":[{"id":600,"main":"Snow","
> description":"light
> snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"
> humidity":86,"temp_min":-4,"temp_max":-3},"visibility":
> 8000,"wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":
> 1484290800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.
> 52,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"
> country":"UA","sunrise":1484286787,"sunset":1484317236},"weather":[{"id":
> 804,"main":"Clouds","description":"overcast
> clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"
> humidity":92,"temp_min":-2,"temp_max":-2},"visibility":
> 9000,"wind":{"speed":4,"deg":250,"var_beg":210,"var_end":
> 270},"clouds":{"all":90},"dt":1484290800,"id":703448,"name":
> "Kiev"},{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"
> id":5187,"message":0.1973,"country":"GB","sunrise":1484294413,"sunset":
> 1484324321},"weather":[{"id":802,"main":"Clouds","description":"scattered
> clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"
> temp_min":0,"temp_max":2,"humidity":98},"visibility":
> 10000,"wind":{"speed":6.2,"deg":270},"clouds":{"all":40},
> "dt":1484290200,"id":2643743,"name":"London"}]}
>
> Any help is appreciated.
>
> --
> Regards
> Archit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Fri Jan 13 19:11:51 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Fri, 13 Jan 2017 23:41:51 +0530
Subject: [R] JSON data in data frame
In-Reply-To: <CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
Message-ID: <CAJ7HxByP+_j4x54GB1JBHBtzm013rwVRBOsuGTYb-aN56WtrpQ@mail.gmail.com>

Thanks Jeremiah,  I'll try this.

On Jan 13, 2017 11:23 PM, "jeremiah rounds" <roundsjeremiah at gmail.com>
wrote:

I TAd a course in R computing and the first thing I told students was
"inspect. inspect. inspect."
d1 <- fromJSON('http://api.openweathermap.org/data/2.5/
group?id=524901,703448,2643743&units=metric&appid=
ec0313a918fa729d4372555ada5fb1f8')
names(d1)
str(d1)
d1
d1$list
your_data = d1$list

On Fri, Jan 13, 2017 at 1:12 AM, Archit Soni <soni.archit1989 at gmail.com>
wrote:

> Hi All,
>
> Warm greetings, I am stuck at an issue to convert incoming json response to
> data frame.
>
> I am using below code to get the data
>
> library(jsonlite)
> d1 <- fromJSON('
> http://api.openweathermap.org/data/2.5/group?id=524901,70344
> 8,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
> ')
>
> d2 <- as.data.frame(d1)
> ?
> typeof(d2)
> list
>
> can you please guide me how can i get this data into pure data.frame
> format. The list in d1 has nested data.frame objects.
>
> Note: If you are unable to get data from api then can use below json string
> to test it out:
>
> JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":{"
> type":1,"id":7323,"message":0.193,"country":"RU","sunrise":
> 1484286631,"sunset":1484313983},"weather":[{"id":600,"main":
> "Snow","description":"light
> snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"h
> umidity":86,"temp_min":-4,"temp_max":-3},"visibility":8000,"
> wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":148429
> 0800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.52
> ,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"co
> untry":"UA","sunrise":1484286787,"sunset":1484317236},"
> weather":[{"id":804,"main":"Clouds","description":"overcast
> clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"hu
> midity":92,"temp_min":-2,"temp_max":-2},"visibility":9000,"
> wind":{"speed":4,"deg":250,"var_beg":210,"var_end":270},"
> clouds":{"all":90},"dt":1484290800,"id":703448,"name":"Kiev"
> },{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"id":
> 5187,"message":0.1973,"country":"GB","sunrise":1484294413,"
> sunset":1484324321},"weather":[{"id":802,"main":"Clouds","de
> scription":"scattered
> clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"t
> emp_min":0,"temp_max":2,"humidity":98},"visibility":10000,"
> wind":{"speed":6.2,"deg":270},"clouds":{"all":40},"dt":
> 1484290200,"id":2643743,"name":"London"}]}
>
> Any help is appreciated.
>
> --
> Regards
> Archit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jan 13 22:33:17 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Jan 2017 13:33:17 -0800
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
	numbers on Windows with German locale
In-Reply-To: <CAGmpuejra4=+PCpUs3eAWuzkgMc4HP-WVXpmbj0XGYmBtErKoA@mail.gmail.com>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
	<CAGmpuejra4=+PCpUs3eAWuzkgMc4HP-WVXpmbj0XGYmBtErKoA@mail.gmail.com>
Message-ID: <5F53F040-E6C3-4302-AC32-853839F5FD2C@comcast.net>


> On Jan 13, 2017, at 3:20 AM, Janko Thyson <janko.thyson at gmail.com> wrote:
> 
> Hi David,
> 
> thanks for replying and sorry about the HTML/non-plain-text email (I
> forgot to change that, shouldn't have happened).
> 
> Might just be me, but reading "The documentation for R datetime format
> parameters ?strptime says %V is ignored on input." in the
> documentation doesn't really tell me all that much. As a user, I would
> read that, not completely understand what this means and thus try to
> understand it better by applying it in actual code:
> 
> (yw <- format(posix, "%Y-%V"))
>> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
> 
> Which, after checking back with a calendar, would give me reason to
> believe that it using %V does in fact seem to work: it's an input to
> `format()` and R doesn't seem to ignore it as the correct week numbers
> (following ISO 8601) are returned.
> 
> Not wanting to stress this particular aspect any further, though, I
> would slightly rephrase my original question: is it possible to use
> the ISO 8601 convention for weeknumbers at all (on Windows, using a
> German locale setting) and if so, how would I link ISO 8601
> weeknumbers to the correct month of the year?

You are using an undocumented behavior of R's implementation on Windows. If you have a date, it's unambiguous what month and dates should be returned, but I don't think it's quite so easy to say in which month an unspecified day of the week in a particular numbered week might lie.


-- 
David.

> 
> Thanks for help,
> Janko
> 
> On Thu, Jan 12, 2017 at 8:37 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Jan 12, 2017, at 8:14 AM, Janko Thyson <janko.thyson at gmail.com> wrote:
>>> 
>>> Dear list,
>>> 
>>> I'm experiencing problems with converting strings of the format
>>> "YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates which (I
>>> think) I need in order to retrieve the month-of-the-year number.
>>> 
>>> Simpler put: I'd like to match week-of-the-year numbers to
>>> month-of-the-year numbers. Ideally, the week-of-the-year number would
>>> follow the ISO 8601 convention (i.e. format argument "%V") instead of the
>>> US (format argument "%U") or UK (format argument "%W") convention.
>>> 
>>> After posting this to Stackoverflow, I have strong reasons to believe that
>>> the issue is caused by Windows:
>>> http://stackoverflow.com/questions/41616407/match-iso-8601-week-numbers-to-month-of-year-on-windows-with-german-locale/41617215?noredirect=1#comment70436768_41617215
>>> 
>>> Example:
>>> 
>>> # ISO 8601 convention:
>>> 
>>> (yw <- format(posix, "%Y-%V"))
>> 
>> The documentation for R datetime format parameters ?strptime says %V is ignored on input.
>> 
>> 
>>> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
>>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))
>> 
>> The documentation for R datetime format parameters ( = ?strptime) says %V is ignored on input.
>> 
>> You should leartn to post plain text to r-help.
>> 
>> --
>> David.
>> 
>> 
>>> # [1]
>>> "2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
>>> -> utterly wrong!!!
>>> 
>>> # US convention:
>>> (yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00" "2016-01"
>>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
>>> "2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
>>> -> NA problem for week 00A fellow R user tested this on both macOS and
>>> Ubuntu and he didn't encounter the issue:
>>> 
>>> some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
>>> "2016-01-08"))
>>> (year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
>>> "2016 00" "2016 01"
>>> (year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
>>> 52 1" "2016 00 1" "2016 01 1"
>>> (as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
>>> EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
>>> 
>>> My session info:
>>> 
>>>> sessionInfo()
>>> R version 3.3.2 (2016-10-31)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows >= 8 x64 (build 9200)
>>> 
>>> locale:[1] LC_COLLATE=German_Germany.1252
>>> LC_CTYPE=German_Germany.1252       LC_MONETARY=German_Germany.1252
>>> [4] LC_NUMERIC=C                       LC_TIME=English_United
>>> States.1252
>>> 
>>> attached base packages:[1] stats     graphics  grDevices utils
>>> datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
>>> plyr_1.8.4      magrittr_1.5
>>> [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
>>> crayon_1.3.2    withr_1.0.2
>>> [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
>>> tools_3.3.2     stringr_1.1.0  [13] tibble_1.2
>>> 
>>> Any idea on how to workaround this issue on Windows?
>>> 
>>> Thanks and best regards,
>>> 
>>> Janko Thyson
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From jspark4 at uic.edu  Fri Jan 13 22:57:51 2017
From: jspark4 at uic.edu (Sparks, John James)
Date: Fri, 13 Jan 2017 15:57:51 -0600
Subject: [R] cforest Single Tree Output for Categorical Variable
Message-ID: <7118bec067ff4209802b572650539a1b.squirrel@webmail.uic.edu>

Hello R Helpers,

I am building a random forest using the cforest method in the party
package.  I then want to have a look at the characteristics of a few of
the trees.  I get the output for one of the trees by executing

pt <- party:::prettytree(cforest at ensemble[[3]],
names(cforest at data@get("input")))
pt

The first splitting variable is a categorical variable (here named cat,
which contains value 0 through 9 and is a factor), but the output does not
specify which values went into which part of the tree:

1) cat == {}; criterion = 1, statistic = 32.792

Can anyone help me to get the detail on this splitting variable to appear
in the output?

I regret that I cannot send a reproducible example because the data is
proprietary.  I will try to work up an example with a public data set that
has the same problem.

Any help would be much appreciated.

Best wishes,
--John J. Sparks, Ph.D.


From pdalgd at gmail.com  Sat Jan 14 10:17:11 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 14 Jan 2017 10:17:11 +0100
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
	numbers on Windows with German locale
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276643E7D04E@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
	<CAA-FpKXp4EDrJ=JdqyxP1O+vXYy7uVFBCuJ88OgZKfOuKvRADA@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA276643E7D04E@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <B8B30BE9-6E87-4047-87D5-030DB4FD4486@gmail.com>


> On 12 Jan 2017, at 22:20 , Nordlund, Dan (DSHS/RDA) <NordlDJ at dshs.wa.gov> wrote:
> 
> See comments inline.
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bob Rudis
>> Sent: Thursday, January 12, 2017 12:41 PM
>> To: David Winsemius
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Match ISO 8601 week-of-year numbers to month-of-year
>> numbers on Windows with German locale
>> 
>> Aye, but this:
>> 
>>  some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
>> "2016-01-08"))
>> 
>>  (year_week <- format(some_dates, "%Y-%U"))
>>  ## [1] "2015-51" "2015-52" "2016-00" "2016-01"
>> 
>>  (year_week_day <- sprintf("%s-1", year_week))
>>  ## [1] "2015-51-1" "2015-52-1" "2016-00-1" "2016-01-1"
>> 
>>  (as.POSIXct(year_week_day, format = "%Y-%U-%u"))
>>  ## [1] "2015-12-21 EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
>> 
>> works fine on macOS & Linux (Ubuntu, anyway), but it fails on Windows (10,
>> 64bit, R 3.3.2):
>> 
>>  (as.POSIXct(year_week_day, format = "%Y-%U-%u"))
>>  ## [1] "2015-12-21 PST" "2015-12-28 PST" NA               "2016-01-04 PST"
> 
> Why do you say it works fine on Ubuntu?  The date "2016-01-01" is in week 0 of 2016.  There is no Monday in week 0.  So I would argue the return  value of NA from Windows is more appropriate than returning the date of Monday in week 1 of 2016 like Ubuntu does.

Yes, the Ubuntu output suggests that Jan 4 is Monday of both w1 and w0...! 

But I'm puzzled: Around here, we actually use week numbers (for planning), but they are never zero: 

2016-01-01 was Friday, week 53 (of 2015)
2014-12-31 was Wednesday, week 1 (still 2015).

So it would seem that any logic that converts dates to/from week numbers would need to be rather more careful than to try and use %Y for the year...

-pd

> 
> Dan
> 
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
> 
>> 
>> On 1/12/17, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>> On Jan 12, 2017, at 8:14 AM, Janko Thyson <janko.thyson at gmail.com>
>> wrote:
>>>> 
>>>> Dear list,
>>>> 
>>>> I'm experiencing problems with converting strings of the format
>>>> "YYYY-<weekofyear>" (e.g. 2016-01, 2016-52) to proper POSIX dates
>>>> which (I
>>>> think) I need in order to retrieve the month-of-the-year number.
>>>> 
>>>> Simpler put: I'd like to match week-of-the-year numbers to
>>>> month-of-the-year numbers. Ideally, the week-of-the-year number
>> would
>>>> follow the ISO 8601 convention (i.e. format argument "%V") instead of
>>>> the US (format argument "%U") or UK (format argument "%W")
>> convention.
>>>> 
>>>> After posting this to Stackoverflow, I have strong reasons to believe
>>>> that the issue is caused by Windows:
>>>> http://stackoverflow.com/questions/41616407/match-iso-8601-week-
>> numbe
>>>> rs-to-month-of-year-on-windows-with-german-
>> locale/41617215?noredirect
>>>> =1#comment70436768_41617215
>>>> 
>>>> Example:
>>>> 
>>>> # ISO 8601 convention:
>>>> 
>>>> (yw <- format(posix, "%Y-%V"))
>>> 
>>> The documentation for R datetime format parameters ?strptime says %V
>>> is ignored on input.
>>> 
>>> 
>>>> # [1] "2015-52" "2015-53" "2016-53" "2016-01"
>>>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%V-%u"))
>>> 
>>> The documentation for R datetime format parameters ( = ?strptime) says
>>> %V is ignored on input.
>>> 
>>> You should leartn to post plain text to r-help.
>>> 
>>> --
>>> David.
>>> 
>>> 
>>>> # [1]
>>>> "2015-01-12 CET" "2015-01-12 CET" "2016-01-12 CET" "2016-01-12 CET"#
>>>> -> utterly wrong!!!
>>>> 
>>>> # US convention:
>>>> (yw <- format(posix, "%Y-%U"))# [1] "2015-51" "2015-52" "2016-00"
>>>> "2016-01"
>>>> ywd <- sprintf("%s-1", yw)(as.POSIXct(ywd, format = "%Y-%U-%u"))# [1]
>>>> "2015-12-21 CET" "2015-12-28 CET" NA               "2016-01-04 CET"#
>>>> -> NA problem for week 00A fellow R user tested this on both macOS
>>>> -> and
>>>> Ubuntu and he didn't encounter the issue:
>>>> 
>>>> some_dates <- as.POSIXct(c("2015-12-24", "2015-12-31", "2016-01-01",
>>>> "2016-01-08"))
>>>> (year_week <- format(some_dates, "%Y %U"))## [1] "2015 51" "2015 52"
>>>> "2016 00" "2016 01"
>>>> (year_week_day <- sprintf("%s 1", year_week))## [1] "2015 51 1" "2015
>>>> 52 1" "2016 00 1" "2016 01 1"
>>>> (as.POSIXct(year_week_day, format = "%Y %U %u"))## [1] "2015-12-21
>>>> EST" "2015-12-28 EST" "2016-01-04 EST" "2016-01-04 EST"
>>>> 
>>>> My session info:
>>>> 
>>>>> sessionInfo()
>>>> R version 3.3.2 (2016-10-31)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >=
>> 8
>>>> x64 (build 9200)
>>>> 
>>>> locale:[1] LC_COLLATE=German_Germany.1252
>>>> LC_CTYPE=German_Germany.1252
>> LC_MONETARY=German_Germany.1252
>>>> [4] LC_NUMERIC=C                       LC_TIME=English_United
>>>> States.1252
>>>> 
>>>> attached base packages:[1] stats     graphics  grDevices utils
>>>> datasets  methods   base
>>>> 
>>>> other attached packages:
>>>> [1] fva_0.1.0       digest_0.6.10   readxl_0.1.1    dplyr_0.5.0
>>>> plyr_1.8.4      magrittr_1.5
>>>> [7] memoise_1.0.0   testthat_1.0.2  roxygen2_5.0.1  devtools_1.12.0
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] Rcpp_0.12.8     lubridate_1.6.0 assertthat_0.1  packrat_0.4.8-1
>>>> crayon_1.3.2    withr_1.0.2
>>>> [7] R6_2.2.0        DBI_0.5-1       stringi_1.1.2   rstudioapi_0.6
>>>> tools_3.3.2     stringr_1.1.0  [13] tibble_1.2
>>>> 
>>>> Any idea on how to workaround this issue on Windows?
>>>> 
>>>> Thanks and best regards,
>>>> 
>>>> Janko Thyson
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From soni.archit1989 at gmail.com  Sat Jan 14 10:25:14 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Sat, 14 Jan 2017 14:55:14 +0530
Subject: [R] JSON data in data frame
In-Reply-To: <CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
Message-ID: <CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>

Hi Jermiah,

When i ran this code in Spotfire, my aim is to get output as a data table.
I am getting the same error:

TIBCO Enterprise Runtime for R returned an error: 'Error in
.cleanDataForExport(value, output.name) : Output data 'tab$coord' has
illegal type: 'data.frame''.


Code that I used:

library(jsonlite)

dat<- fromJSON('
http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
')


tab <- dat$list

tab is my output variable that will give me results in table format.

Could you please suggest what we can do to resolve this error.

Many Thanks,
Archit

On Fri, Jan 13, 2017 at 11:23 PM, jeremiah rounds <roundsjeremiah at gmail.com>
wrote:

> I TAd a course in R computing and the first thing I told students was
> "inspect. inspect. inspect."
> d1 <- fromJSON('http://api.openweathermap.org/data/2.5/
> group?id=524901,703448,2643743&units=metric&appid=
> ec0313a918fa729d4372555ada5fb1f8')
> names(d1)
> str(d1)
> d1
> d1$list
> your_data = d1$list
>
> On Fri, Jan 13, 2017 at 1:12 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
>
>> Hi All,
>>
>> Warm greetings, I am stuck at an issue to convert incoming json response
>> to
>> data frame.
>>
>> I am using below code to get the data
>>
>> library(jsonlite)
>> d1 <- fromJSON('
>> http://api.openweathermap.org/data/2.5/group?id=524901,70344
>> 8,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
>> ')
>>
>> d2 <- as.data.frame(d1)
>> ?
>> typeof(d2)
>> list
>>
>> can you please guide me how can i get this data into pure data.frame
>> format. The list in d1 has nested data.frame objects.
>>
>> Note: If you are unable to get data from api then can use below json
>> string
>> to test it out:
>>
>> JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":{"
>> type":1,"id":7323,"message":0.193,"country":"RU","sunrise":
>> 1484286631,"sunset":1484313983},"weather":[{"id":600,"main":
>> "Snow","description":"light
>> snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"h
>> umidity":86,"temp_min":-4,"temp_max":-3},"visibility":8000,"
>> wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":148429
>> 0800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.52
>> ,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"co
>> untry":"UA","sunrise":1484286787,"sunset":1484317236},"
>> weather":[{"id":804,"main":"Clouds","description":"overcast
>> clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"hu
>> midity":92,"temp_min":-2,"temp_max":-2},"visibility":9000,"
>> wind":{"speed":4,"deg":250,"var_beg":210,"var_end":270},"
>> clouds":{"all":90},"dt":1484290800,"id":703448,"name":"Kiev"
>> },{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"id":
>> 5187,"message":0.1973,"country":"GB","sunrise":1484294413,"
>> sunset":1484324321},"weather":[{"id":802,"main":"Clouds","de
>> scription":"scattered
>> clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"t
>> emp_min":0,"temp_max":2,"humidity":98},"visibility":10000,"
>> wind":{"speed":6.2,"deg":270},"clouds":{"all":40},"dt":
>> 1484290200,"id":2643743,"name":"London"}]}
>>
>> Any help is appreciated.
>>
>> --
>> Regards
>> Archit
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Regards
Archit

	[[alternative HTML version deleted]]


From tombernardryan at gmail.com  Fri Jan 13 13:08:12 2017
From: tombernardryan at gmail.com (Thomas Ryan)
Date: Fri, 13 Jan 2017 12:08:12 +0000
Subject: [R] Qvalue package: I am getting back 1,
 000 q values when I only want 1 q value.
In-Reply-To: <CA+8X3fW7HO8E5D5VJsWwGSB74e-A_Sy0qy9QkSb4DQQHNso_zg@mail.gmail.com>
References: <CANvF3ck-O6hy031HCRWH+3dhVguMFBszSEXQh1mNvs4tknjGWQ@mail.gmail.com>
	<CA+8X3fW7HO8E5D5VJsWwGSB74e-A_Sy0qy9QkSb4DQQHNso_zg@mail.gmail.com>
Message-ID: <CANvF3c=fkTrrMLPWvum3nXMZ_HqS_JV03FOrQO-atY4xUf_+ig@mail.gmail.com>

Jim,

Thanks for the reply. Yes I'm just playing around with the data at the
minute, but regardless of where the p values actually come from, I can't
seem to get a Q value that makes sense.

For example, in one case, I have an actual P value of 0.05.  I have a list
of 1,000 randomised p values: range of these randomised p values is 0.002
to 0.795, average of the randomised p values is 0.399 and the median of the
randomised p values is 0.45.

So I thought it would be reasonable to expect the FDR Q Value (i.e the
number of expected false positives over the number of significant results) to
be at least over 0.05, given that 869 of the randomised p values are >
0.05?

When I run the code:

library(qvalue)
list1 <-scan("ListOfPValues")

qobj <-qvalue(p=list1)

qobj$pi0


The answer is 0.0062. That's why I thought qobj$pi0 isn't the right
variable to be looking at? So my problem (or my mis-understanding) is that
I have an actual P value of 0.05, but then a Q value that is lower, 0.006?


Thanks again for your help,

Tom








On Thu, Jan 12, 2017 at 9:27 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Tom,
> From a quick scan of the docs, I think you are looking for qobj$pi0.
> The vector qobj$qvalue seems to be the local false discovery rate for
> each of your randomizations. Note that the manual implies that the p
> values are those of multiple comparisons within a data set, not
> randomizations of the data, so I'm not sure that your usage is valid
> for the function..
>
> Jim
>
>
> On Fri, Jan 13, 2017 at 4:12 AM, Thomas Ryan <tombernardryan at gmail.com>
> wrote:
> > Hi all, I'm wondering if someone could put me on the right path to using
> > the "qvalue" package correctly.
> >
> > I have an original p value from an analysis, and I've done 1,000
> > randomisations of the data set. So I now have an original P value and
> 1,000
> > random p values. I want to work out the false discovery rate (FDR) (Q; as
> > described by Storey and Tibshriani in 2003) for my original p value,
> > defined as the number of expected false positives over the number of
> > significant results for my original P value.
> >
> > So, for my original P value, I want one Q value, that has been calculated
> > as described above based on the 1,000 random p values.
> >
> > I wrote this code:
> >
> > pvals <- c(list_of_p_values_obtained_from_randomisations)
> > qobj <-qvalue(p=pvals)
> > r_output1 <- qobj$pvalue
> > r_output2 <- qobj$qvalue
> >
> > r_output1 is the list of 1,000 p values that I put in, and r_output2 is
> a q
> > value for each of those p values (i.e. so there are 1,000 q values).
> >
> > The problem is I don't want there to be 1,000 Q values (i.e one for each
> > random p value). The Q value should be the false discovery rate (FDR)
> (Q),
> > defined as the number of expected false positives over the number of
> > significant results. So I want one Q value for my original P value, and
> to
> > calculate that one Q value using the 1,000 random P values I have
> generated.
> >
> > Could someone please tell me where I'm going wrong.
> >
> > Thanks
> > Tom
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Paul.Ossenbruggen at unh.edu  Fri Jan 13 22:21:11 2017
From: Paul.Ossenbruggen at unh.edu (Ossenbruggen, Paul)
Date: Fri, 13 Jan 2017 21:21:11 +0000
Subject: [R] rgdal functions: spTransform and CRS not working
Message-ID: <3C6E19E8-B0CA-4889-8C51-A8E3F9A81B21@unh.edu>

The following are examples from the rgdal library help file. 

Neither functions operate properly. 

Help is appreciated.
Paul

Example 1
> EPSG <- make_EPSG()
Error in make_EPSG() : Error opening epsg file
> EPSG[grep("Oslo", EPSG$note), 1:2]
Error: object 'EPSG' not found
> EPSG[1925:1927, 3]
Error: object 'EPSG' not found


Example 2
> data(meuse)
> coordinates(meuse) <- c("x", "y")
> proj4string(meuse) <- CRS(paste("+init=epsg:28992",
+  "+towgs84=565.237,50.0087,465.658,-0.406857,0.350733,-1.87035,4.0812"))
NOTE: rgdal::checkCRSArgs: no proj_defs.dat in PROJ.4 shared files
Error in CRS(paste("+init=epsg:28992", "+towgs84=565.237,50.0087,465.658,-0.406857,0.350733,-1.87035,4.0812")) : 
  no system list, errno: 2
> # see http://trac.osgeo.org/gdal/ticket/1987
> summary(meuse)
Object of class SpatialPointsDataFrame
Coordinates:
     min    max
x 178605 181390
y 329714 333611
Is projected: NA 
proj4string : [NA]
Number of points: 155
Data attributes:
    cadmium           copper            lead            zinc       
 Min.   : 0.200   Min.   : 14.00   Min.   : 37.0   Min.   : 113.0  
 1st Qu.: 0.800   1st Qu.: 23.00   1st Qu.: 72.5   1st Qu.: 198.0  
 Median : 2.100   Median : 31.00   Median :123.0   Median : 326.0  
 Mean   : 3.246   Mean   : 40.32   Mean   :153.4   Mean   : 469.7  
 3rd Qu.: 3.850   3rd Qu.: 49.50   3rd Qu.:207.0   3rd Qu.: 674.5  
 Max.   :18.100   Max.   :128.00   Max.   :654.0   Max.   :1839.0  
                                                                   
      elev             dist               om         ffreq  soil   lime   
 Min.   : 5.180   Min.   :0.00000   Min.   : 1.000   1:84   1:97   0:111  
 1st Qu.: 7.546   1st Qu.:0.07569   1st Qu.: 5.300   2:48   2:46   1: 44  
 Median : 8.180   Median :0.21184   Median : 6.900   3:23   3:12          
 Mean   : 8.165   Mean   :0.24002   Mean   : 7.478                        
 3rd Qu.: 8.955   3rd Qu.:0.36407   3rd Qu.: 9.000                        
 Max.   :10.520   Max.   :0.88039   Max.   :17.000                        
                                    NA's   :2                             
    landuse       dist.m      
 W      :50   Min.   :  10.0  
 Ah     :39   1st Qu.:  80.0  
 Am     :22   Median : 270.0  
 Fw     :10   Mean   : 290.3  
 Ab     : 8   3rd Qu.: 450.0  
 (Other):25   Max.   :1000.0  
 NA's   : 1                   
> meuse.utm <- spTransform(meuse, CRS("+proj=utm +zone=32 +datum=WGS84"))
NOTE: rgdal::checkCRSArgs: no proj_defs.dat in PROJ.4 shared files
Error in spTransform(xSP, CRSobj, ...) : 
  No transformation possible from NA reference system
> summary(meuse.utm)
Error in summary(meuse.utm) : object 'meuse.utm' not found
> 

From alaios at yahoo.com  Sat Jan 14 11:24:53 2017
From: alaios at yahoo.com (Alaios)
Date: Sat, 14 Jan 2017 10:24:53 +0000 (UTC)
Subject: [R] How these Plots are called? Which package
References: <1419887563.2990899.1484389493861.ref@mail.yahoo.com>
Message-ID: <1419887563.2990899.1484389493861@mail.yahoo.com>

Hello,how I can try something like that in R (in the attachment I am providing a sketch).Which packages would you try to use?I would like to thank you in advance for your helpRegardsAlex

From jrkrideau at yahoo.ca  Sat Jan 14 11:57:02 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 14 Jan 2017 10:57:02 +0000 (UTC)
Subject: [R] How these Plots are called? Which package
In-Reply-To: <1419887563.2990899.1484389493861@mail.yahoo.com>
References: <1419887563.2990899.1484389493861.ref@mail.yahoo.com>
	<1419887563.2990899.1484389493861@mail.yahoo.com>
Message-ID: <2063223482.3195867.1484391422101@mail.yahoo.com>

No sign of attachment. 
 

    On Saturday, January 14, 2017 5:42 AM, Alaios via R-help <r-help at r-project.org> wrote:
 

 Hello,how I can try something like that in R (in the attachment I am providing a sketch).Which packages would you try to use?I would like to thank you in advance for your helpRegardsAlex
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Sat Jan 14 16:44:51 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Sat, 14 Jan 2017 21:14:51 +0530
Subject: [R] JSON data in data frame
In-Reply-To: <406bf5f9-eeec-aedb-8fda-a333042c5550@gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
	<CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>
	<406bf5f9-eeec-aedb-8fda-a333042c5550@gmail.com>
Message-ID: <CAJ7HxBxvLRbVNUamCEacaYWw0dwi=8hj1GRTA+q2d4gOCXJFUQ@mail.gmail.com>

Hey Rob,

Thanks for replying but what i see after i run str(tab$list) is that it has
nested data.frame. And for some weird reason Spotfire is discarding and
stating as illegal data type.

On Jan 14, 2017 20:15, "Rob Baer" <rwbaer at gmail.com> wrote:

> I just tried after fixing what I thoug were email wrapping errors and it
> seemed to work:
>
> library(jsonlite)
> dat<- fromJSON('http://api.openweathermap.org/data/2.5/group?id=
> 524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
> ')
> tab <- dat$list
>
> Avoid the line breaks in your string
>
>
> On 1/14/2017 3:25 AM, Archit Soni wrote:
>
>> library(jsonlite)
>>
>> dat<- fromJSON('
>> http://api.openweathermap.org/data/2.5/group?id=524901,70344
>> 8,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
>> ')
>>
>>
>> tab <- dat$list
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jan 14 17:48:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 14 Jan 2017 08:48:30 -0800
Subject: [R] How these Plots are called? Which package
In-Reply-To: <2063223482.3195867.1484391422101@mail.yahoo.com>
References: <1419887563.2990899.1484389493861.ref@mail.yahoo.com>
	<1419887563.2990899.1484389493861@mail.yahoo.com>
	<2063223482.3195867.1484391422101@mail.yahoo.com>
Message-ID: <73D064D1-06A9-4103-A67B-DBA75783456F@dcn.davis.ca.us>

... which means Alaios desperately needs to read the Posting Guide... carefully. 
-- 
Sent from my phone. Please excuse my brevity.

On January 14, 2017 2:57:02 AM PST, John Kane via R-help <r-help at r-project.org> wrote:
>No sign of attachment. 
> 
>
>On Saturday, January 14, 2017 5:42 AM, Alaios via R-help
><r-help at r-project.org> wrote:
> 
>
>Hello,how I can try something like that in R (in the attachment I am
>providing a sketch).Which packages would you try to use?I would like to
>thank you in advance for your helpRegardsAlex
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>   
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Jan 14 18:27:37 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 14 Jan 2017 09:27:37 -0800
Subject: [R] JSON data in data frame
In-Reply-To: <CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
	<CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>
Message-ID: <CAF8bMcbsvXRy+y6cUiftpVz_ey6E5H6jUwGTzGHANhDmgbpytA@mail.gmail.com>

This is a question concerning the interface between the TIBCO products
Spotfire and TERR so most people on this mailing list won't have a
clue.  You will have better luck with TIBCO support or asking in the
Q&A section of https://community.tibco.com.

It does sound like you might have a data.frame nested within a
data.frame on the R/TERR side and Spotfire cannot deal with such a
structure - its data table columns must be simple vectors.  Try
unpacking the columns of the inner data frame and putting them one by
one into the outer one.

(I cannot say for sure because that URL gives me a 502 error.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Jan 14, 2017 at 1:25 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> Hi Jermiah,
>
> When i ran this code in Spotfire, my aim is to get output as a data table.
> I am getting the same error:
>
> TIBCO Enterprise Runtime for R returned an error: 'Error in
> .cleanDataForExport(value, output.name) : Output data 'tab$coord' has
> illegal type: 'data.frame''.
>
>
> Code that I used:
>
> library(jsonlite)
>
> dat<- fromJSON('
> http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
> ')
>
>
> tab <- dat$list
>
> tab is my output variable that will give me results in table format.
>
> Could you please suggest what we can do to resolve this error.
>
> Many Thanks,
> Archit
>
> On Fri, Jan 13, 2017 at 11:23 PM, jeremiah rounds <roundsjeremiah at gmail.com>
> wrote:
>
>> I TAd a course in R computing and the first thing I told students was
>> "inspect. inspect. inspect."
>> d1 <- fromJSON('http://api.openweathermap.org/data/2.5/
>> group?id=524901,703448,2643743&units=metric&appid=
>> ec0313a918fa729d4372555ada5fb1f8')
>> names(d1)
>> str(d1)
>> d1
>> d1$list
>> your_data = d1$list
>>
>> On Fri, Jan 13, 2017 at 1:12 AM, Archit Soni <soni.archit1989 at gmail.com>
>> wrote:
>>
>>> Hi All,
>>>
>>> Warm greetings, I am stuck at an issue to convert incoming json response
>>> to
>>> data frame.
>>>
>>> I am using below code to get the data
>>>
>>> library(jsonlite)
>>> d1 <- fromJSON('
>>> http://api.openweathermap.org/data/2.5/group?id=524901,70344
>>> 8,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
>>> ')
>>>
>>> d2 <- as.data.frame(d1)
>>>
>>> typeof(d2)
>>> list
>>>
>>> can you please guide me how can i get this data into pure data.frame
>>> format. The list in d1 has nested data.frame objects.
>>>
>>> Note: If you are unable to get data from api then can use below json
>>> string
>>> to test it out:
>>>
>>> JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":{"
>>> type":1,"id":7323,"message":0.193,"country":"RU","sunrise":
>>> 1484286631,"sunset":1484313983},"weather":[{"id":600,"main":
>>> "Snow","description":"light
>>> snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"h
>>> umidity":86,"temp_min":-4,"temp_max":-3},"visibility":8000,"
>>> wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":148429
>>> 0800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.52
>>> ,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"co
>>> untry":"UA","sunrise":1484286787,"sunset":1484317236},"
>>> weather":[{"id":804,"main":"Clouds","description":"overcast
>>> clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"hu
>>> midity":92,"temp_min":-2,"temp_max":-2},"visibility":9000,"
>>> wind":{"speed":4,"deg":250,"var_beg":210,"var_end":270},"
>>> clouds":{"all":90},"dt":1484290800,"id":703448,"name":"Kiev"
>>> },{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"id":
>>> 5187,"message":0.1973,"country":"GB","sunrise":1484294413,"
>>> sunset":1484324321},"weather":[{"id":802,"main":"Clouds","de
>>> scription":"scattered
>>> clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"t
>>> emp_min":0,"temp_max":2,"humidity":98},"visibility":10000,"
>>> wind":{"speed":6.2,"deg":270},"clouds":{"all":40},"dt":
>>> 1484290200,"id":2643743,"name":"London"}]}
>>>
>>> Any help is appreciated.
>>>
>>> --
>>> Regards
>>> Archit
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>
> --
> Regards
> Archit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Jan 14 19:28:47 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Jan 2017 10:28:47 -0800
Subject: [R] OS X solution... was Re: rgdal functions: spTransform and CRS
	not working
In-Reply-To: <3C6E19E8-B0CA-4889-8C51-A8E3F9A81B21@unh.edu>
References: <3C6E19E8-B0CA-4889-8C51-A8E3F9A81B21@unh.edu>
Message-ID: <0E4D1C59-DA8A-404A-A560-22F706EC70E4@comcast.net>


> On Jan 13, 2017, at 1:21 PM, Ossenbruggen, Paul <Paul.Ossenbruggen at unh.edu> wrote:
> 
> The following are examples from the rgdal library help file. 
> 
> Neither functions operate properly. 
> 
> Help is appreciated.
> Paul
> 
> Example 1
>> EPSG <- make_EPSG()
> Error in make_EPSG() : Error opening epsg file

I get the same error. Using OSX:

Built: R 3.3.2; x86_64-apple-darwin13.4.0; 2016-12-17 14:34:29 UTC; unix

.... with recently updated rgdal but did not update either GDAL or PROJ4

Loaded GDAL runtime: GDAL 2.1.2, released 2016/10/24
 Path to GDAL shared files: 
 Loaded PROJ.4 runtime: Rel. 4.9.1, 04 March 2015, 

which I am seeing some documented problems with

... when I search on the warning message:

WARNING: no proj_defs.dat in PROJ.4 shared files

...  I got when loading rgdal:

https://github.com/OSGeo/proj.4/issues/351

So I'm wondering what OS you have and what version of GDAL and PROJ4 you are using. I'm quitting my session so I can update my system structure. I've had success in hte past with the KingChaos disk images:

GDAL 2.1 Complete
http://www.kyngchaos.com/files/software/frameworks/GDAL_Complete-2.1.dmg

Used the disk image from Finder.app

That failed to resolve the warning or the error from rgdal::make_EPSG. Tried (re-)installing rgdal from current source tar.gz file using install.packages. Got an error relating to missing gdal-config

So based on a stackOverflow solution from Fran Villamil: http://stackoverflow.com/questions/34333624/trouble-installing-rgdal/37829420#37829420, I tried (from the R console):

install.packages('rgdal', type = "source", configure.args=c(
'--with-gdal-config=/Library/Frameworks/GDAL.framework/Programs/gdal-config', 
'--with-proj-include=/Library/Frameworks/PROJ.framework/Headers', 
'--with-proj-lib=/Library/Frameworks/PROJ.framework/unix/lib'))


reloaded R and ... no warnings or errors

I'm a somewhat clueless, albeit noisy user of R. I don't really have the development skills to figure out how to construct the code to tie together all these compiled bits, but I do find that searching is often sufficient to solve problems. If this is not an exact match to your situation,  then you should first read the posting guide and include sufficient information about _your_ OS, your system tools,  and versions of external-to-R packages to support a more focussed discussion.

Best;
David.


>> EPSG[grep("Oslo", EPSG$note), 1:2]
> Error: object 'EPSG' not found
>> EPSG[1925:1927, 3]
> Error: object 'EPSG' not found
> 
> 
> Example 2
>> data(meuse)
>> coordinates(meuse) <- c("x", "y")
>> proj4string(meuse) <- CRS(paste("+init=epsg:28992",
> +  "+towgs84=565.237,50.0087,465.658,-0.406857,0.350733,-1.87035,4.0812"))
> NOTE: rgdal::checkCRSArgs: no proj_defs.dat in PROJ.4 shared files
> Error in CRS(paste("+init=epsg:28992", "+towgs84=565.237,50.0087,465.658,-0.406857,0.350733,-1.87035,4.0812")) : 
>  no system list, errno: 2
>> # see http://trac.osgeo.org/gdal/ticket/1987
>> summary(meuse)
> Object of class SpatialPointsDataFrame
> Coordinates:
>     min    max
> x 178605 181390
> y 329714 333611
> Is projected: NA 
> proj4string : [NA]
> Number of points: 155
> Data attributes:
>    cadmium           copper            lead            zinc       
> Min.   : 0.200   Min.   : 14.00   Min.   : 37.0   Min.   : 113.0  
> 1st Qu.: 0.800   1st Qu.: 23.00   1st Qu.: 72.5   1st Qu.: 198.0  
> Median : 2.100   Median : 31.00   Median :123.0   Median : 326.0  
> Mean   : 3.246   Mean   : 40.32   Mean   :153.4   Mean   : 469.7  
> 3rd Qu.: 3.850   3rd Qu.: 49.50   3rd Qu.:207.0   3rd Qu.: 674.5  
> Max.   :18.100   Max.   :128.00   Max.   :654.0   Max.   :1839.0  
> 
>      elev             dist               om         ffreq  soil   lime   
> Min.   : 5.180   Min.   :0.00000   Min.   : 1.000   1:84   1:97   0:111  
> 1st Qu.: 7.546   1st Qu.:0.07569   1st Qu.: 5.300   2:48   2:46   1: 44  
> Median : 8.180   Median :0.21184   Median : 6.900   3:23   3:12          
> Mean   : 8.165   Mean   :0.24002   Mean   : 7.478                        
> 3rd Qu.: 8.955   3rd Qu.:0.36407   3rd Qu.: 9.000                        
> Max.   :10.520   Max.   :0.88039   Max.   :17.000                        
>                                    NA's   :2                             
>    landuse       dist.m      
> W      :50   Min.   :  10.0  
> Ah     :39   1st Qu.:  80.0  
> Am     :22   Median : 270.0  
> Fw     :10   Mean   : 290.3  
> Ab     : 8   3rd Qu.: 450.0  
> (Other):25   Max.   :1000.0  
> NA's   : 1                   
>> meuse.utm <- spTransform(meuse, CRS("+proj=utm +zone=32 +datum=WGS84"))
> NOTE: rgdal::checkCRSArgs: no proj_defs.dat in PROJ.4 shared files
> Error in spTransform(xSP, CRSobj, ...) : 
>  No transformation possible from NA reference system
>> summary(meuse.utm)
> Error in summary(meuse.utm) : object 'meuse.utm' not found
>> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Jan 14 20:05:15 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Jan 2017 11:05:15 -0800
Subject: [R] JSON data in data frame
In-Reply-To: <CAF8bMcbsvXRy+y6cUiftpVz_ey6E5H6jUwGTzGHANhDmgbpytA@mail.gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
	<CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>
	<CAF8bMcbsvXRy+y6cUiftpVz_ey6E5H6jUwGTzGHANhDmgbpytA@mail.gmail.com>
Message-ID: <EEE51D22-0C4B-4B84-98D8-C047721B71E0@comcast.net>


> On Jan 14, 2017, at 9:27 AM, William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> This is a question concerning the interface between the TIBCO products
> Spotfire and TERR so most people on this mailing list won't have a
> clue.  You will have better luck with TIBCO support or asking in the
> Q&A section of https://community.tibco.com.
> 
> It does sound like you might have a data.frame nested within a
> data.frame on the R/TERR side and Spotfire cannot deal with such a
> structure - its data table columns must be simple vectors.  Try
> unpacking the columns of the inner data frame and putting them one by
> one into the outer one.
> 
> (I cannot say for sure because that URL gives me a 502 error.)
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com

The R as.dataframe includes that embeded dataframe as:

                                 list.weather
1           620, Snow, light shower snow, 13n
2 520, Rain, light intensity shower rain, 09n
3               800, Clear, Sky is Clear, 01n


An R solution for extraction might be:

 do.call(rbind, d1$list$weather)
#---------
   id  main                 description icon
1 620  Snow           light shower snow  13n
2 520  Rain light intensity shower rain  09n
3 800 Clear                Sky is Clear  01n


cbind( as.data.frame( d1$list[ !names(d1$list) %in% "weather"]), do.call(rbind, d1$list$weather) )
#----------
  coord.lon coord.lat sys.type sys.id sys.message sys.country sys.sunrise
1     37.62     55.75        1   7323      0.2075          RU  1484372967
2     30.52     50.43        1   7358      0.1982          UA  1484373141
3     -0.13     51.51        1   5091      0.2218          GB  1484380764
  sys.sunset main.temp main.pressure main.humidity main.temp_min main.temp_max
1 1484400490     -1.50          1009            80            -2            -1
2 1484403724      2.66           999            93             2             3
3 1484410813      2.46          1021            80             1             5
  visibility wind.speed wind.deg wind.var_beg wind.var_end all         dt      id
1       9000        6.0      150          120          190  90 1484416800  524901
2       9000        4.0      190           90          230  90 1484416800  703448
3      10000        5.1      280           NA           NA   0 1484418000 2643743
    name  id  main                 description icon
1 Moscow 620  Snow           light shower snow  13n
2   Kiev 520  Rain light intensity shower rain  09n
3 London 800 Clear                Sky is Clear  01n

-- 
David.

> 
> 
> On Sat, Jan 14, 2017 at 1:25 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
>> Hi Jermiah,
>> 
>> When i ran this code in Spotfire, my aim is to get output as a data table.
>> I am getting the same error:
>> 
>> TIBCO Enterprise Runtime for R returned an error: 'Error in
>> .cleanDataForExport(value, output.name) : Output data 'tab$coord' has
>> illegal type: 'data.frame''.
>> 
>> 
>> Code that I used:
>> 
>> library(jsonlite)
>> 
>> dat<- fromJSON('
>> http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
>> ')
>> 
>> 
>> tab <- dat$list
>> 
>> tab is my output variable that will give me results in table format.
>> 
>> Could you please suggest what we can do to resolve this error.
>> 
>> Many Thanks,
>> Archit
>> 
>> On Fri, Jan 13, 2017 at 11:23 PM, jeremiah rounds <roundsjeremiah at gmail.com>
>> wrote:
>> 
>>> I TAd a course in R computing and the first thing I told students was
>>> "inspect. inspect. inspect."
>>> d1 <- fromJSON('http://api.openweathermap.org/data/2.5/
>>> group?id=524901,703448,2643743&units=metric&appid=
>>> ec0313a918fa729d4372555ada5fb1f8')
>>> names(d1)
>>> str(d1)
>>> d1
>>> d1$list
>>> your_data = d1$list
>>> 
>>> On Fri, Jan 13, 2017 at 1:12 AM, Archit Soni <soni.archit1989 at gmail.com>
>>> wrote:
>>> 
>>>> Hi All,
>>>> 
>>>> Warm greetings, I am stuck at an issue to convert incoming json response
>>>> to
>>>> data frame.
>>>> 
>>>> I am using below code to get the data
>>>> 
>>>> library(jsonlite)
>>>> d1 <- fromJSON('
>>>> http://api.openweathermap.org/data/2.5/group?id=524901,70344
>>>> 8,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
>>>> ')
>>>> 
>>>> d2 <- as.data.frame(d1)
>>>> 
>>>> typeof(d2)
>>>> list
>>>> 
>>>> can you please guide me how can i get this data into pure data.frame
>>>> format. The list in d1 has nested data.frame objects.
>>>> 
>>>> Note: If you are unable to get data from api then can use below json
>>>> string
>>>> to test it out:
>>>> 
>>>> JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":{"
>>>> type":1,"id":7323,"message":0.193,"country":"RU","sunrise":
>>>> 1484286631,"sunset":1484313983},"weather":[{"id":600,"main":
>>>> "Snow","description":"light
>>>> snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"h
>>>> umidity":86,"temp_min":-4,"temp_max":-3},"visibility":8000,"
>>>> wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":148429
>>>> 0800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.52
>>>> ,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"co
>>>> untry":"UA","sunrise":1484286787,"sunset":1484317236},"
>>>> weather":[{"id":804,"main":"Clouds","description":"overcast
>>>> clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"hu
>>>> midity":92,"temp_min":-2,"temp_max":-2},"visibility":9000,"
>>>> wind":{"speed":4,"deg":250,"var_beg":210,"var_end":270},"
>>>> clouds":{"all":90},"dt":1484290800,"id":703448,"name":"Kiev"
>>>> },{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"id":
>>>> 5187,"message":0.1973,"country":"GB","sunrise":1484294413,"
>>>> sunset":1484324321},"weather":[{"id":802,"main":"Clouds","de
>>>> scription":"scattered
>>>> clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"t
>>>> emp_min":0,"temp_max":2,"humidity":98},"visibility":10000,"
>>>> wind":{"speed":6.2,"deg":270},"clouds":{"all":40},"dt":
>>>> 1484290200,"id":2643743,"name":"London"}]}
>>>> 
>>>> Any help is appreciated.
>>>> 
>>>> --
>>>> Regards
>>>> Archit
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>> 
>> 
>> --
>> Regards
>> Archit
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From alaios at yahoo.com  Sat Jan 14 21:04:52 2017
From: alaios at yahoo.com (Alaios)
Date: Sat, 14 Jan 2017 20:04:52 +0000 (UTC)
Subject: [R] How these Plots are called? Which package
In-Reply-To: <2063223482.3195867.1484391422101@mail.yahoo.com>
References: <1419887563.2990899.1484389493861.ref@mail.yahoo.com>
	<1419887563.2990899.1484389493861@mail.yahoo.com>
	<2063223482.3195867.1484391422101@mail.yahoo.com>
Message-ID: <1594153961.3099488.1484424292154@mail.yahoo.com>

can you see it now? I have uploaded it on my dropbox
https://www.dropbox.com/s/9eikpabu6xflasa/Figure.jpg?dl=0
 

    On Saturday, January 14, 2017 12:57 PM, John Kane <jrkrideau at yahoo.ca> wrote:
 

 No sign of attachment. 
 

    On Saturday, January 14, 2017 5:42 AM, Alaios via R-help <r-help at r-project.org> wrote:
 

 Hello,how I can try something like that in R (in the attachment I am providing a sketch).Which packages would you try to use?I would like to thank you in advance for your helpRegardsAlex
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   

   
	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Sat Jan 14 21:17:32 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Sun, 15 Jan 2017 01:47:32 +0530
Subject: [R] JSON data in data frame
In-Reply-To: <EEE51D22-0C4B-4B84-98D8-C047721B71E0@comcast.net>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
	<CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>
	<CAF8bMcbsvXRy+y6cUiftpVz_ey6E5H6jUwGTzGHANhDmgbpytA@mail.gmail.com>
	<EEE51D22-0C4B-4B84-98D8-C047721B71E0@comcast.net>
Message-ID: <CAJ7HxBx_q8YLqkxATrq0VKk+SvJPO8vVyCdkioG94T1XtvXLUw@mail.gmail.com>

Hey David,

A big big thank you..!!

Your code worked like a charm and with little tweaks i extracted each item
from other nested data frames. Now i got a single data frame


My final code: dat2 <- cbind(as.data.frame(dat1$list[!names(dat1$list) %in%
c("coord","weather","sys","main","wind","clouds")]), do.call(cbind,
dat1$list$coord),do.call(rbind, dat1$list$weather),do.call(cbind,
dat1$list$sys),do.call(cbind,
dat1$list$main),do.call(cbind,dat1$list$wind),do.call(cbind,dat1$list$clouds))

Spotfire is accepting it too.. :)

Thanks again,
Archit

On Sun, Jan 15, 2017 at 12:35 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jan 14, 2017, at 9:27 AM, William Dunlap via R-help <
> r-help at r-project.org> wrote:
> >
> > This is a question concerning the interface between the TIBCO products
> > Spotfire and TERR so most people on this mailing list won't have a
> > clue.  You will have better luck with TIBCO support or asking in the
> > Q&A section of https://community.tibco.com.
> >
> > It does sound like you might have a data.frame nested within a
> > data.frame on the R/TERR side and Spotfire cannot deal with such a
> > structure - its data table columns must be simple vectors.  Try
> > unpacking the columns of the inner data frame and putting them one by
> > one into the outer one.
> >
> > (I cannot say for sure because that URL gives me a 502 error.)
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
>
> The R as.dataframe includes that embeded dataframe as:
>
>                                  list.weather
> 1           620, Snow, light shower snow, 13n
> 2 520, Rain, light intensity shower rain, 09n
> 3               800, Clear, Sky is Clear, 01n
>
>
> An R solution for extraction might be:
>
>  do.call(rbind, d1$list$weather)
> #---------
>    id  main                 description icon
> 1 620  Snow           light shower snow  13n
> 2 520  Rain light intensity shower rain  09n
> 3 800 Clear                Sky is Clear  01n
>
>
> cbind( as.data.frame( d1$list[ !names(d1$list) %in% "weather"]),
> do.call(rbind, d1$list$weather) )
> #----------
>   coord.lon coord.lat sys.type sys.id sys.message sys.country sys.sunrise
> 1     37.62     55.75        1   7323      0.2075          RU  1484372967
> 2     30.52     50.43        1   7358      0.1982          UA  1484373141
> 3     -0.13     51.51        1   5091      0.2218          GB  1484380764
>   sys.sunset main.temp main.pressure main.humidity main.temp_min
> main.temp_max
> 1 1484400490     -1.50          1009            80            -2
>   -1
> 2 1484403724      2.66           999            93             2
>    3
> 3 1484410813      2.46          1021            80             1
>    5
>   visibility wind.speed wind.deg wind.var_beg wind.var_end all         dt
>     id
> 1       9000        6.0      150          120          190  90 1484416800
> 524901
> 2       9000        4.0      190           90          230  90 1484416800
> 703448
> 3      10000        5.1      280           NA           NA   0 1484418000
> 2643743
>     name  id  main                 description icon
> 1 Moscow 620  Snow           light shower snow  13n
> 2   Kiev 520  Rain light intensity shower rain  09n
> 3 London 800 Clear                Sky is Clear  01n
>
> --
> David.
>
> >
> >
> > On Sat, Jan 14, 2017 at 1:25 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> >> Hi Jermiah,
> >>
> >> When i ran this code in Spotfire, my aim is to get output as a data
> table.
> >> I am getting the same error:
> >>
> >> TIBCO Enterprise Runtime for R returned an error: 'Error in
> >> .cleanDataForExport(value, output.name) : Output data 'tab$coord' has
> >> illegal type: 'data.frame''.
> >>
> >>
> >> Code that I used:
> >>
> >> library(jsonlite)
> >>
> >> dat<- fromJSON('
> >> http://api.openweathermap.org/data/2.5/group?id=524901,
> 703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
> >> ')
> >>
> >>
> >> tab <- dat$list
> >>
> >> tab is my output variable that will give me results in table format.
> >>
> >> Could you please suggest what we can do to resolve this error.
> >>
> >> Many Thanks,
> >> Archit
> >>
> >> On Fri, Jan 13, 2017 at 11:23 PM, jeremiah rounds <
> roundsjeremiah at gmail.com>
> >> wrote:
> >>
> >>> I TAd a course in R computing and the first thing I told students was
> >>> "inspect. inspect. inspect."
> >>> d1 <- fromJSON('http://api.openweathermap.org/data/2.5/
> >>> group?id=524901,703448,2643743&units=metric&appid=
> >>> ec0313a918fa729d4372555ada5fb1f8')
> >>> names(d1)
> >>> str(d1)
> >>> d1
> >>> d1$list
> >>> your_data = d1$list
> >>>
> >>> On Fri, Jan 13, 2017 at 1:12 AM, Archit Soni <
> soni.archit1989 at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi All,
> >>>>
> >>>> Warm greetings, I am stuck at an issue to convert incoming json
> response
> >>>> to
> >>>> data frame.
> >>>>
> >>>> I am using below code to get the data
> >>>>
> >>>> library(jsonlite)
> >>>> d1 <- fromJSON('
> >>>> http://api.openweathermap.org/data/2.5/group?id=524901,70344
> >>>> 8,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8
> >>>> ')
> >>>>
> >>>> d2 <- as.data.frame(d1)
> >>>>
> >>>> typeof(d2)
> >>>> list
> >>>>
> >>>> can you please guide me how can i get this data into pure data.frame
> >>>> format. The list in d1 has nested data.frame objects.
> >>>>
> >>>> Note: If you are unable to get data from api then can use below json
> >>>> string
> >>>> to test it out:
> >>>>
> >>>> JSON: {"cnt":3,"list":[{"coord":{"lon":37.62,"lat":55.75},"sys":{"
> >>>> type":1,"id":7323,"message":0.193,"country":"RU","sunrise":
> >>>> 1484286631,"sunset":1484313983},"weather":[{"id":600,"main":
> >>>> "Snow","description":"light
> >>>> snow","icon":"13d"}],"main":{"temp":-3.75,"pressure":1005,"h
> >>>> umidity":86,"temp_min":-4,"temp_max":-3},"visibility":8000,"
> >>>> wind":{"speed":4,"deg":170},"clouds":{"all":90},"dt":148429
> >>>> 0800,"id":524901,"name":"Moscow"},{"coord":{"lon":30.52
> >>>> ,"lat":50.43},"sys":{"type":1,"id":7358,"message":0.1885,"co
> >>>> untry":"UA","sunrise":1484286787,"sunset":1484317236},"
> >>>> weather":[{"id":804,"main":"Clouds","description":"overcast
> >>>> clouds","icon":"04d"}],"main":{"temp":-2,"pressure":1009,"hu
> >>>> midity":92,"temp_min":-2,"temp_max":-2},"visibility":9000,"
> >>>> wind":{"speed":4,"deg":250,"var_beg":210,"var_end":270},"
> >>>> clouds":{"all":90},"dt":1484290800,"id":703448,"name":"Kiev"
> >>>> },{"coord":{"lon":-0.13,"lat":51.51},"sys":{"type":1,"id":
> >>>> 5187,"message":0.1973,"country":"GB","sunrise":1484294413,"
> >>>> sunset":1484324321},"weather":[{"id":802,"main":"Clouds","de
> >>>> scription":"scattered
> >>>> clouds","icon":"03n"}],"main":{"temp":0.7,"pressure":1002,"t
> >>>> emp_min":0,"temp_max":2,"humidity":98},"visibility":10000,"
> >>>> wind":{"speed":6.2,"deg":270},"clouds":{"all":40},"dt":
> >>>> 1484290200,"id":2643743,"name":"London"}]}
> >>>>
> >>>> Any help is appreciated.
> >>>>
> >>>> --
> >>>> Regards
> >>>> Archit
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>>> ng-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>>
> >>
> >>
> >> --
> >> Regards
> >> Archit
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Regards
Archit

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Jan 14 21:53:39 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Jan 2017 21:53:39 +0100
Subject: [R] How these Plots are called? Which package
In-Reply-To: <1594153961.3099488.1484424292154@mail.yahoo.com>
References: <1419887563.2990899.1484389493861.ref@mail.yahoo.com>
	<1419887563.2990899.1484389493861@mail.yahoo.com>
	<2063223482.3195867.1484391422101@mail.yahoo.com>
	<1594153961.3099488.1484424292154@mail.yahoo.com>
Message-ID: <3c23be77-9fee-f6b7-752e-277aecf92111@statistik.tu-dortmund.de>



On 14.01.2017 21:04, Alaios via R-help wrote:
> can you see it now? I have uploaded it on my dropbox
> https://www.dropbox.com/s/9eikpabu6xflasa/Figure.jpg?dl=0

This is called spectogram and there are several packages that can do it, 
depending on your application.

Best,
Uwe Ligges


>
>
>     On Saturday, January 14, 2017 12:57 PM, John Kane <jrkrideau at yahoo.ca> wrote:
>
>
>  No sign of attachment.
>
>
>     On Saturday, January 14, 2017 5:42 AM, Alaios via R-help <r-help at r-project.org> wrote:
>
>
>  Hello,how I can try something like that in R (in the attachment I am providing a sketch).Which packages would you try to use?I would like to thank you in advance for your helpRegardsAlex
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rwbaer at gmail.com  Sat Jan 14 19:27:40 2017
From: rwbaer at gmail.com (Rob Baer)
Date: Sat, 14 Jan 2017 12:27:40 -0600
Subject: [R] JSON data in data frame
In-Reply-To: <CAJ7HxBxvLRbVNUamCEacaYWw0dwi=8hj1GRTA+q2d4gOCXJFUQ@mail.gmail.com>
References: <CAJ7HxByNx-T-8xzYRC_WchDz-QmK_sZNx_NrKB=0vzPVWBAcPg@mail.gmail.com>
	<CAOjnRsavac5FTu=YsNzX2U0XsD9NNHVB1nkOYS=hkwavCTiy4w@mail.gmail.com>
	<CAJ7HxByv_xTf4c052fCxEYNdPa6LWjfwENpOAMexaoTkeh6NwQ@mail.gmail.com>
	<406bf5f9-eeec-aedb-8fda-a333042c5550@gmail.com>
	<CAJ7HxBxvLRbVNUamCEacaYWw0dwi=8hj1GRTA+q2d4gOCXJFUQ@mail.gmail.com>
Message-ID: <0212d085-c80c-8b40-badc-2befbc18affb@gmail.com>

Try this:

# get weather data
library(jsonlite)
dat<- 
fromJSON('http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8')
tab <- dat$list

#look at what we get
class(tab)
names(tab)
ncol(tab)
nrow(tab)
tab[,c("clouds","wind","name")]
tab$wind$speed
tab$wind[,c("speed", "deg")]

Here's my output.  Is this what you get/want?  If not, what do you hope 
for?  As an aside are you working in standard R if you get an error?

 > # get weather data
 > library(jsonlite)
 > dat<- 
fromJSON('http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8')
 > tab <- dat$list
 >
 > #look at what we get
 > class(tab)
[1] "data.frame"
 > names(tab)
  [1] "coord"      "sys"        "weather"    "main"
  [5] "visibility" "wind"       "clouds"     "dt"
  [9] "id"         "name"
 > ncol(tab)
[1] 10
 > nrow(tab)
[1] 3
 > tab[,c("clouds","wind","name")]
   all wind.speed wind.deg wind.var_beg wind.var_end   name
1  90        6.0      150          120          190 Moscow
2  90        4.0      190           90          230   Kiev
3   0        3.6      280           NA           NA London
 > tab$wind$speed
[1] 6.0 4.0 3.6
 > tab$wind[,c("speed", "deg")]
   speed deg
1   6.0 150
2   4.0 190
3   3.6 280
 >






4/2017 9:44 AM, Archit Soni wrote:
>
> library(jsonlite)
> dat<- 
> fromJSON('http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8 
> <http://api.openweathermap.org/data/2.5/group?id=524901,703448,2643743&units=metric&appid=ec0313a918fa729d4372555ada5fb1f8>')
> tab <- dat$list


	[[alternative HTML version deleted]]


From jSmith.Coursera at outlook.com  Sun Jan 15 13:32:43 2017
From: jSmith.Coursera at outlook.com (John Smith)
Date: Sun, 15 Jan 2017 12:32:43 +0000
Subject: [R] Running Omega in R
Message-ID: <AM2PR09MB0372398D1A24E270EAFD8503FD7A0@AM2PR09MB0372.eurprd09.prod.outlook.com>

Hi,

I opened a question on stack overflow I?m hoping this mailing list can help with.
I have a dataset below (this is made up but produces the same error I am getting)

structure(list(Q1 = c(4, 5, 3, 5, 4, 5, 3, 5, 5, 5, 6,
3, 5, 4, 6, 5, 5, 6, 7, 4, 5, 5, 3, 4, 4, 5, 4, 3, 5, 4, 5, 5,
6, 6, 3, 6, 3, 4, 4, 4, 6, 5, 3, 2, 6, 6, 4, 5, 4, 3, 6, 4, 4,
5, 6, 2, 4, 3, 4, 6, 4, 6, 4, 5, 5, 6, 4, 6, 5, 5, 4, 5, 6, 6,
2, 5, 4, 3, 4, 4, 4, 6, 3, 3, 5, 4, 4, 4, 5, 5, 5, 3, 6, 6, 6,
6, 5, 4, 3, 5), Q2 = c(7, 4, 4, 4, 4, 6, 6, 6, 7, 6, 5,
6, 5, 4, 5, 6, 6, 6, 7, 5, 4, 4, 6, 6, 4, 4, 6, 2, 6, 5, 4, 6,
4, 6, 6, 6, 5, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 6, 2, 6, 6, 5, 4,
6, 6, 4, 4, 7, 6, 5, 5, 5, 5, 6, 5, 5, 4, 5, 5, 5, 4, 6, 7, 5,
5, 5, 6, 5, 6, 5, 6, 7, 2, 6, 5, 7, 3, 5, 5, 3, 3, 3, 7, 4, 5,
6, 6, 6, 5, 7), Q3 = c(5, 4, 5, 6, 4, 4, 5, 4, 2, 6, 5,
5, 5, 5, 7, 5, 5, 6, 7, 6, 3, 6, 6, 6, 5, 6, 6, 5, 5, 4, 5, 5,
6, 6, 5, 6, 5, 5, 4, 4, 6, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4,
3, 5, 4, 5, 6, 6, 6, 4, 5, 5, 5, 6, 4, 5, 5, 7, 4, 5, 6, 6, 5,
5, 3, 3, 5, 4, 6, 5, 5, 1, 3, 5, 3, 2, 5, 4, 6, 6, 6, 6, 4, 6,
3, 6, 6, 6, 5), Q4 = c(6, 6, 4, 7, 4, 6, 7, 6, 7, 6, 6,
6, 5, 7, 7, 6, 6, 5, 7, 7, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 5, 6,
7, 5, 4, 6, 4, 3, 6, 4, 6, 6, 6, 3, 5, 7, 5, 6, 4, 6, 7, 6, 7,
4, 6, 3, 5, 7, 5, 4, 6, 6, 4, 6, 5, 5, 5, 5, 7, 7, 7, 6, 6, 6,
5, 6, 6, 4, 5, 7, 6, 7, 3, 5, 6, 5, 6, 5, 5, 7, 7, 6, 6, 2, 7,
6, 6, 7, 7, 5)), .Names = c("Q1", "Q2", "Q3",
"Q4"), row.names = c(NA, 100L), class = "data.frame")


When i run Cronbach Alpha with R i get a result

psych::alpha(construct,
         na.rm = TRUE,
         title = 'myscale',
         n.iter = 1000)


When i run Omega using R i get the following error message

"Error in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : I am sorry: missing values (NAs) in the correlation matrix do not allow me to continue.
Please drop those variables and try again. In addition: There were 50 or more warnings (use warnings() to see the first 50)"

psych::omega(m = construct,
      nfactors = 1, fm = "pa", n.iter = 1000, p = 0.05,
      title = "Omega", plot = FALSE, n.obs = 100)


Stackoverflow Link: http://stackoverflow.com/questions/41533231/running-omega-with-psych-library-in-r?noredirect=1#comment70278453_41533231

If I have the wrong mailing list, could you direct me to the appropriate one (I?m aware it might not be an R issue but more of a stats question)



Thank you for your time



	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Jan 15 20:57:24 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 15 Jan 2017 19:57:24 +0000
Subject: [R] Running Omega in R
In-Reply-To: <AM2PR09MB0372398D1A24E270EAFD8503FD7A0@AM2PR09MB0372.eurprd09.prod.outlook.com>
References: <AM2PR09MB0372398D1A24E270EAFD8503FD7A0@AM2PR09MB0372.eurprd09.prod.outlook.com>
Message-ID: <587BD424.2090603@sapo.pt>

Hello,

I no nothing about package psych so if you ask whether this is the wrong 
list you can always try

maintainer("psych")
[1] "William Revelle <revelle at northwestern.edu>"

Hope this helps,

Rui Barradas

Em 15-01-2017 12:32, John Smith escreveu:
> Hi,
>
> I opened a question on stack overflow I?m hoping this mailing list can help with.
> I have a dataset below (this is made up but produces the same error I am getting)
>
> structure(list(Q1 = c(4, 5, 3, 5, 4, 5, 3, 5, 5, 5, 6,
> 3, 5, 4, 6, 5, 5, 6, 7, 4, 5, 5, 3, 4, 4, 5, 4, 3, 5, 4, 5, 5,
> 6, 6, 3, 6, 3, 4, 4, 4, 6, 5, 3, 2, 6, 6, 4, 5, 4, 3, 6, 4, 4,
> 5, 6, 2, 4, 3, 4, 6, 4, 6, 4, 5, 5, 6, 4, 6, 5, 5, 4, 5, 6, 6,
> 2, 5, 4, 3, 4, 4, 4, 6, 3, 3, 5, 4, 4, 4, 5, 5, 5, 3, 6, 6, 6,
> 6, 5, 4, 3, 5), Q2 = c(7, 4, 4, 4, 4, 6, 6, 6, 7, 6, 5,
> 6, 5, 4, 5, 6, 6, 6, 7, 5, 4, 4, 6, 6, 4, 4, 6, 2, 6, 5, 4, 6,
> 4, 6, 6, 6, 5, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 6, 2, 6, 6, 5, 4,
> 6, 6, 4, 4, 7, 6, 5, 5, 5, 5, 6, 5, 5, 4, 5, 5, 5, 4, 6, 7, 5,
> 5, 5, 6, 5, 6, 5, 6, 7, 2, 6, 5, 7, 3, 5, 5, 3, 3, 3, 7, 4, 5,
> 6, 6, 6, 5, 7), Q3 = c(5, 4, 5, 6, 4, 4, 5, 4, 2, 6, 5,
> 5, 5, 5, 7, 5, 5, 6, 7, 6, 3, 6, 6, 6, 5, 6, 6, 5, 5, 4, 5, 5,
> 6, 6, 5, 6, 5, 5, 4, 4, 6, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4,
> 3, 5, 4, 5, 6, 6, 6, 4, 5, 5, 5, 6, 4, 5, 5, 7, 4, 5, 6, 6, 5,
> 5, 3, 3, 5, 4, 6, 5, 5, 1, 3, 5, 3, 2, 5, 4, 6, 6, 6, 6, 4, 6,
> 3, 6, 6, 6, 5), Q4 = c(6, 6, 4, 7, 4, 6, 7, 6, 7, 6, 6,
> 6, 5, 7, 7, 6, 6, 5, 7, 7, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 5, 6,
> 7, 5, 4, 6, 4, 3, 6, 4, 6, 6, 6, 3, 5, 7, 5, 6, 4, 6, 7, 6, 7,
> 4, 6, 3, 5, 7, 5, 4, 6, 6, 4, 6, 5, 5, 5, 5, 7, 7, 7, 6, 6, 6,
> 5, 6, 6, 4, 5, 7, 6, 7, 3, 5, 6, 5, 6, 5, 5, 7, 7, 6, 6, 2, 7,
> 6, 6, 7, 7, 5)), .Names = c("Q1", "Q2", "Q3",
> "Q4"), row.names = c(NA, 100L), class = "data.frame")
>
>
> When i run Cronbach Alpha with R i get a result
>
> psych::alpha(construct,
>           na.rm = TRUE,
>           title = 'myscale',
>           n.iter = 1000)
>
>
> When i run Omega using R i get the following error message
>
> "Error in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : I am sorry: missing values (NAs) in the correlation matrix do not allow me to continue.
> Please drop those variables and try again. In addition: There were 50 or more warnings (use warnings() to see the first 50)"
>
> psych::omega(m = construct,
>        nfactors = 1, fm = "pa", n.iter = 1000, p = 0.05,
>        title = "Omega", plot = FALSE, n.obs = 100)
>
>
> Stackoverflow Link: http://stackoverflow.com/questions/41533231/running-omega-with-psych-library-in-r?noredirect=1#comment70278453_41533231
>
> If I have the wrong mailing list, could you direct me to the appropriate one (I?m aware it might not be an R issue but more of a stats question)
>
>
>
> Thank you for your time
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Sun Jan 15 21:26:44 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 15 Jan 2017 21:26:44 +0100
Subject: [R] Running Omega in R
In-Reply-To: <587BD424.2090603@sapo.pt>
References: <AM2PR09MB0372398D1A24E270EAFD8503FD7A0@AM2PR09MB0372.eurprd09.prod.outlook.com>
	<587BD424.2090603@sapo.pt>
Message-ID: <E406C5A2-7F5D-4719-8E17-829DA45DFDA8@gmail.com>


> On 15 Jan 2017, at 20:57 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> I no nothing about package psych so if you ask whether this is the wrong list you can always try
> 
> maintainer("psych")
> [1] "William Revelle <revelle at northwestern.edu>"

...although publishing a package is not the same as issuing a blank cheque for free support, so you may want to dig a little deeper first. 

I'd check the documentation for whether the data are in the right format. In particular, can "m" be a data frame? If it wants a matrix, you probably need to give it one (m=as.matrix(construct) should do it).

-pd

> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 15-01-2017 12:32, John Smith escreveu:
>> Hi,
>> 
>> I opened a question on stack overflow I?m hoping this mailing list can help with.
>> I have a dataset below (this is made up but produces the same error I am getting)
>> 
>> structure(list(Q1 = c(4, 5, 3, 5, 4, 5, 3, 5, 5, 5, 6,
>> 3, 5, 4, 6, 5, 5, 6, 7, 4, 5, 5, 3, 4, 4, 5, 4, 3, 5, 4, 5, 5,
>> 6, 6, 3, 6, 3, 4, 4, 4, 6, 5, 3, 2, 6, 6, 4, 5, 4, 3, 6, 4, 4,
>> 5, 6, 2, 4, 3, 4, 6, 4, 6, 4, 5, 5, 6, 4, 6, 5, 5, 4, 5, 6, 6,
>> 2, 5, 4, 3, 4, 4, 4, 6, 3, 3, 5, 4, 4, 4, 5, 5, 5, 3, 6, 6, 6,
>> 6, 5, 4, 3, 5), Q2 = c(7, 4, 4, 4, 4, 6, 6, 6, 7, 6, 5,
>> 6, 5, 4, 5, 6, 6, 6, 7, 5, 4, 4, 6, 6, 4, 4, 6, 2, 6, 5, 4, 6,
>> 4, 6, 6, 6, 5, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 6, 2, 6, 6, 5, 4,
>> 6, 6, 4, 4, 7, 6, 5, 5, 5, 5, 6, 5, 5, 4, 5, 5, 5, 4, 6, 7, 5,
>> 5, 5, 6, 5, 6, 5, 6, 7, 2, 6, 5, 7, 3, 5, 5, 3, 3, 3, 7, 4, 5,
>> 6, 6, 6, 5, 7), Q3 = c(5, 4, 5, 6, 4, 4, 5, 4, 2, 6, 5,
>> 5, 5, 5, 7, 5, 5, 6, 7, 6, 3, 6, 6, 6, 5, 6, 6, 5, 5, 4, 5, 5,
>> 6, 6, 5, 6, 5, 5, 4, 4, 6, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4,
>> 3, 5, 4, 5, 6, 6, 6, 4, 5, 5, 5, 6, 4, 5, 5, 7, 4, 5, 6, 6, 5,
>> 5, 3, 3, 5, 4, 6, 5, 5, 1, 3, 5, 3, 2, 5, 4, 6, 6, 6, 6, 4, 6,
>> 3, 6, 6, 6, 5), Q4 = c(6, 6, 4, 7, 4, 6, 7, 6, 7, 6, 6,
>> 6, 5, 7, 7, 6, 6, 5, 7, 7, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 5, 6,
>> 7, 5, 4, 6, 4, 3, 6, 4, 6, 6, 6, 3, 5, 7, 5, 6, 4, 6, 7, 6, 7,
>> 4, 6, 3, 5, 7, 5, 4, 6, 6, 4, 6, 5, 5, 5, 5, 7, 7, 7, 6, 6, 6,
>> 5, 6, 6, 4, 5, 7, 6, 7, 3, 5, 6, 5, 6, 5, 5, 7, 7, 6, 6, 2, 7,
>> 6, 6, 7, 7, 5)), .Names = c("Q1", "Q2", "Q3",
>> "Q4"), row.names = c(NA, 100L), class = "data.frame")
>> 
>> 
>> When i run Cronbach Alpha with R i get a result
>> 
>> psych::alpha(construct,
>>          na.rm = TRUE,
>>          title = 'myscale',
>>          n.iter = 1000)
>> 
>> 
>> When i run Omega using R i get the following error message
>> 
>> "Error in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : I am sorry: missing values (NAs) in the correlation matrix do not allow me to continue.
>> Please drop those variables and try again. In addition: There were 50 or more warnings (use warnings() to see the first 50)"
>> 
>> psych::omega(m = construct,
>>       nfactors = 1, fm = "pa", n.iter = 1000, p = 0.05,
>>       title = "Omega", plot = FALSE, n.obs = 100)
>> 
>> 
>> Stackoverflow Link: http://stackoverflow.com/questions/41533231/running-omega-with-psych-library-in-r?noredirect=1#comment70278453_41533231
>> 
>> If I have the wrong mailing list, could you direct me to the appropriate one (I?m aware it might not be an R issue but more of a stats question)
>> 
>> 
>> 
>> Thank you for your time
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Roger.Bivand at nhh.no  Mon Jan 16 11:02:30 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 16 Jan 2017 11:02:30 +0100
Subject: [R] Re: OS X solution... was Re: rgdal functions: spTransform and
 CRS not working
Message-ID: <alpine.LFD.2.20.1701161050001.2785@reclus.nhh.no>

I apologise for not following up in-thread, as I used to use Gmane to 
reply to postings read digested before its (hopefully temporary) demise.

The problem is that the CRAN OSX binaries for rgdal are shipping without 
two key folders, proj/ and gdal/. Until we get it fixed, please see if you 
can download the equivalent Windows binary package:

https://cran.r-project.org/bin/windows/contrib/3.3/rgdal_1.2-5.zip

unzip it (do not install it), and copy the proj/ and gdal/ folders with
their contents to the folder shown (in R) by:

system.file("", package="rgdal")

For OSX-specific questions like this, you could try R-sig-mac, for spatial 
data R-sig-geo. Always show the output of sessionInfo() when reporting 
issues.

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From Paul.Ossenbruggen at unh.edu  Mon Jan 16 11:52:05 2017
From: Paul.Ossenbruggen at unh.edu (Ossenbruggen, Paul)
Date: Mon, 16 Jan 2017 10:52:05 +0000
Subject: [R] OS X solution... was Re: rgdal functions: spTransform and
 CRS not working
In-Reply-To: <alpine.LFD.2.20.1701161050001.2785@reclus.nhh.no>
References: <alpine.LFD.2.20.1701161050001.2785@reclus.nhh.no>
Message-ID: <F5EBD384-525C-4DCF-B2E2-BCD43E6C7A9F@unh.edu>

Thank you for your assistance.

David Winsemius gave me a work around solution that addresses the issue. 

I thank both of you.

Paul

Sent from my iPad

> On Jan 16, 2017, at 5:02 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
> I apologise for not following up in-thread, as I used to use Gmane to reply to postings read digested before its (hopefully temporary) demise.
> 
> The problem is that the CRAN OSX binaries for rgdal are shipping without two key folders, proj/ and gdal/. Until we get it fixed, please see if you can download the equivalent Windows binary package:
> 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_bin_windows_contrib_3.3_rgdal-5F1.2-2D5.zip&d=DwIBAg&c=c6MrceVCY5m5A_KAUkrdoA&r=WDD4_Yg52kDcV1-aTnZGuPa5XvnE9sRyJLzwnTtaEa4&m=dgU0yI25qorGYcBVyZbsn1WJw773Uh-jx0lQHACi8t0&s=wnPJ31FbUqePLKa2rQgFFPi0-GvGKY8XFGUZQHoEmGY&e= 
> unzip it (do not install it), and copy the proj/ and gdal/ folders with
> their contents to the folder shown (in R) by:
> 
> system.file("", package="rgdal")
> 
> For OSX-specific questions like this, you could try R-sig-mac, for spatial data R-sig-geo. Always show the output of sessionInfo() when reporting issues.
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> https://urldefense.proofpoint.com/v2/url?u=http-3A__orcid.org_0000-2D0003-2D2392-2D6140&d=DwIBAg&c=c6MrceVCY5m5A_KAUkrdoA&r=WDD4_Yg52kDcV1-aTnZGuPa5XvnE9sRyJLzwnTtaEa4&m=dgU0yI25qorGYcBVyZbsn1WJw773Uh-jx0lQHACi8t0&s=vkKFU5pFCkqarbvnL7h3LHTf2FOeqRHz5kXzN-LepwE&e= https://urldefense.proofpoint.com/v2/url?u=https-3A__scholar.google.no_citations-3Fuser-3DAWeghB0AAAAJ-26hl-3Den&d=DwIBAg&c=c6MrceVCY5m5A_KAUkrdoA&r=WDD4_Yg52kDcV1-aTnZGuPa5XvnE9sRyJLzwnTtaEa4&m=dgU0yI25qorGYcBVyZbsn1WJw773Uh-jx0lQHACi8t0&s=BzwpcCxeGE8YMisKdas7VFF6YDAXFoMyLygD2PI5XGU&e= https://urldefense.proofpoint.com/v2/url?u=http-3A__depsy.org_person_434412&d=DwIBAg&c=c6MrceVCY5m5A_KAUkrdoA&r=WDD4_Yg52kDcV1-aTnZGuPa5XvnE9sRyJLzwnTtaEa4&m=dgU0yI25qorGYcBVyZbsn1WJw773Uh-jx0lQHACi8t0&s=vDry50VlCgUoz7ZoJu5j2rg-DBKK2fPQ9jjWxOLNoIc&e= 


From dcarlson at tamu.edu  Mon Jan 16 16:43:38 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Jan 2017 15:43:38 +0000
Subject: [R] Running Omega in R
In-Reply-To: <E406C5A2-7F5D-4719-8E17-829DA45DFDA8@gmail.com>
References: <AM2PR09MB0372398D1A24E270EAFD8503FD7A0@AM2PR09MB0372.eurprd09.prod.outlook.com>
	<587BD424.2090603@sapo.pt>
	<E406C5A2-7F5D-4719-8E17-829DA45DFDA8@gmail.com>
Message-ID: <7b1e673521c14c37a95941f64081ca0a@exch-2p-mbx-w2.ads.tamu.edu>

I get an additional error message when I run your example so perhaps your version is not the current (1.6.12) one? 

Loading required namespace: GPArotation
Failed with error:  ?there is no package called ?GPArotation??
Error in omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip,  : 
  I am sorry, you need to have the  GPArotation package installed

Then I get a great deal of error output followed by the one you list. The first error is 

"Omega_h for 1 factor is not meaningful, just omega_t" (repeated 174 times). I'm copying the package maintainer as this seems like overkill.

Your problem is addressed in the first line of the manual page for omega:

"McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test. One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. "

You cannot rotate a single factor so you cannot compute omega.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter dalgaard
Sent: Sunday, January 15, 2017 2:27 PM
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: John Smith <jSmith.Coursera at outlook.com>; r-help at r-project.org
Subject: Re: [R] Running Omega in R


> On 15 Jan 2017, at 20:57 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> I no nothing about package psych so if you ask whether this is the wrong list you can always try
> 
> maintainer("psych")
> [1] "William Revelle <revelle at northwestern.edu>"

...although publishing a package is not the same as issuing a blank cheque for free support, so you may want to dig a little deeper first. 

I'd check the documentation for whether the data are in the right format. In particular, can "m" be a data frame? If it wants a matrix, you probably need to give it one (m=as.matrix(construct) should do it).

-pd

> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 15-01-2017 12:32, John Smith escreveu:
>> Hi,
>> 
>> I opened a question on stack overflow I?m hoping this mailing list can help with.
>> I have a dataset below (this is made up but produces the same error I am getting)
>> 
>> structure(list(Q1 = c(4, 5, 3, 5, 4, 5, 3, 5, 5, 5, 6,
>> 3, 5, 4, 6, 5, 5, 6, 7, 4, 5, 5, 3, 4, 4, 5, 4, 3, 5, 4, 5, 5,
>> 6, 6, 3, 6, 3, 4, 4, 4, 6, 5, 3, 2, 6, 6, 4, 5, 4, 3, 6, 4, 4,
>> 5, 6, 2, 4, 3, 4, 6, 4, 6, 4, 5, 5, 6, 4, 6, 5, 5, 4, 5, 6, 6,
>> 2, 5, 4, 3, 4, 4, 4, 6, 3, 3, 5, 4, 4, 4, 5, 5, 5, 3, 6, 6, 6,
>> 6, 5, 4, 3, 5), Q2 = c(7, 4, 4, 4, 4, 6, 6, 6, 7, 6, 5,
>> 6, 5, 4, 5, 6, 6, 6, 7, 5, 4, 4, 6, 6, 4, 4, 6, 2, 6, 5, 4, 6,
>> 4, 6, 6, 6, 5, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 6, 2, 6, 6, 5, 4,
>> 6, 6, 4, 4, 7, 6, 5, 5, 5, 5, 6, 5, 5, 4, 5, 5, 5, 4, 6, 7, 5,
>> 5, 5, 6, 5, 6, 5, 6, 7, 2, 6, 5, 7, 3, 5, 5, 3, 3, 3, 7, 4, 5,
>> 6, 6, 6, 5, 7), Q3 = c(5, 4, 5, 6, 4, 4, 5, 4, 2, 6, 5,
>> 5, 5, 5, 7, 5, 5, 6, 7, 6, 3, 6, 6, 6, 5, 6, 6, 5, 5, 4, 5, 5,
>> 6, 6, 5, 6, 5, 5, 4, 4, 6, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4,
>> 3, 5, 4, 5, 6, 6, 6, 4, 5, 5, 5, 6, 4, 5, 5, 7, 4, 5, 6, 6, 5,
>> 5, 3, 3, 5, 4, 6, 5, 5, 1, 3, 5, 3, 2, 5, 4, 6, 6, 6, 6, 4, 6,
>> 3, 6, 6, 6, 5), Q4 = c(6, 6, 4, 7, 4, 6, 7, 6, 7, 6, 6,
>> 6, 5, 7, 7, 6, 6, 5, 7, 7, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 5, 6,
>> 7, 5, 4, 6, 4, 3, 6, 4, 6, 6, 6, 3, 5, 7, 5, 6, 4, 6, 7, 6, 7,
>> 4, 6, 3, 5, 7, 5, 4, 6, 6, 4, 6, 5, 5, 5, 5, 7, 7, 7, 6, 6, 6,
>> 5, 6, 6, 4, 5, 7, 6, 7, 3, 5, 6, 5, 6, 5, 5, 7, 7, 6, 6, 2, 7,
>> 6, 6, 7, 7, 5)), .Names = c("Q1", "Q2", "Q3",
>> "Q4"), row.names = c(NA, 100L), class = "data.frame")
>> 
>> 
>> When i run Cronbach Alpha with R i get a result
>> 
>> psych::alpha(construct,
>>          na.rm = TRUE,
>>          title = 'myscale',
>>          n.iter = 1000)
>> 
>> 
>> When i run Omega using R i get the following error message
>> 
>> "Error in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : I am sorry: missing values (NAs) in the correlation matrix do not allow me to continue.
>> Please drop those variables and try again. In addition: There were 50 or more warnings (use warnings() to see the first 50)"
>> 
>> psych::omega(m = construct,
>>       nfactors = 1, fm = "pa", n.iter = 1000, p = 0.05,
>>       title = "Omega", plot = FALSE, n.obs = 100)
>> 
>> 
>> Stackoverflow Link: http://stackoverflow.com/questions/41533231/running-omega-with-psych-library-in-r?noredirect=1#comment70278453_41533231
>> 
>> If I have the wrong mailing list, could you direct me to the appropriate one (I?m aware it might not be an R issue but more of a stats question)
>> 
>> 
>> 
>> Thank you for your time
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jsorkin at grecc.umaryland.edu  Mon Jan 16 17:58:21 2017
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 16 Jan 2017 11:58:21 -0500
Subject: [R] R studio server vs R server and Small computer to run R
Message-ID: <587CB567020000CB0016CEC3@smtp.medicine.umaryland.edu>

I am looking for a small computer low power that I make available on the web that will run R studio server or R server
1) can anyone recommend a computer?
2) can anyone let me know the advantages and disadvantages of R studio server and R server?
Thank you
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jSmith.Coursera at outlook.com  Mon Jan 16 18:38:14 2017
From: jSmith.Coursera at outlook.com (John Smith)
Date: Mon, 16 Jan 2017 17:38:14 +0000
Subject: [R] Running Omega in R
Message-ID: <AM2PR09MB03723470A6B31917F2E95026FD7D0@AM2PR09MB0372.eurprd09.prod.outlook.com>

Hi David

Thank you for your feedback
I didn?t realise you couldn?t implement omega on a single factor
This definitely makes sense the more I read on it

Thank you all very much for your time 


From: David L Carlson
Sent: Monday 16 January 2017 16:43
To: peter dalgaard; Rui Barradas
Cc: John Smith; r-help at r-project.org; revelle at northwestern.edu
Subject: RE: [R] Running Omega in R

I get an additional error message when I run your example so perhaps your version is not the current (1.6.12) one? 

Loading required namespace: GPArotation
Failed with error:  ?there is no package called ?GPArotation??
Error in omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip,  : 
  I am sorry, you need to have the  GPArotation package installed

Then I get a great deal of error output followed by the one you list. The first error is 

"Omega_h for 1 factor is not meaningful, just omega_t" (repeated 174 times). I'm copying the package maintainer as this seems like overkill.

Your problem is addressed in the first line of the manual page for omega:

"McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test. One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. "

You cannot rotate a single factor so you cannot compute omega.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter dalgaard
Sent: Sunday, January 15, 2017 2:27 PM
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: John Smith <jSmith.Coursera at outlook.com>; r-help at r-project.org
Subject: Re: [R] Running Omega in R


> On 15 Jan 2017, at 20:57 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> I no nothing about package psych so if you ask whether this is the wrong list you can always try
> 
> maintainer("psych")
> [1] "William Revelle <revelle at northwestern.edu>"

...although publishing a package is not the same as issuing a blank cheque for free support, so you may want to dig a little deeper first. 

I'd check the documentation for whether the data are in the right format. In particular, can "m" be a data frame? If it wants a matrix, you probably need to give it one (m=as.matrix(construct) should do it).

-pd

> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 15-01-2017 12:32, John Smith escreveu:
>> Hi,
>> 
>> I opened a question on stack overflow I?m hoping this mailing list can help with.
>> I have a dataset below (this is made up but produces the same error I am getting)
>> 
>> structure(list(Q1 = c(4, 5, 3, 5, 4, 5, 3, 5, 5, 5, 6,
>> 3, 5, 4, 6, 5, 5, 6, 7, 4, 5, 5, 3, 4, 4, 5, 4, 3, 5, 4, 5, 5,
>> 6, 6, 3, 6, 3, 4, 4, 4, 6, 5, 3, 2, 6, 6, 4, 5, 4, 3, 6, 4, 4,
>> 5, 6, 2, 4, 3, 4, 6, 4, 6, 4, 5, 5, 6, 4, 6, 5, 5, 4, 5, 6, 6,
>> 2, 5, 4, 3, 4, 4, 4, 6, 3, 3, 5, 4, 4, 4, 5, 5, 5, 3, 6, 6, 6,
>> 6, 5, 4, 3, 5), Q2 = c(7, 4, 4, 4, 4, 6, 6, 6, 7, 6, 5,
>> 6, 5, 4, 5, 6, 6, 6, 7, 5, 4, 4, 6, 6, 4, 4, 6, 2, 6, 5, 4, 6,
>> 4, 6, 6, 6, 5, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 6, 2, 6, 6, 5, 4,
>> 6, 6, 4, 4, 7, 6, 5, 5, 5, 5, 6, 5, 5, 4, 5, 5, 5, 4, 6, 7, 5,
>> 5, 5, 6, 5, 6, 5, 6, 7, 2, 6, 5, 7, 3, 5, 5, 3, 3, 3, 7, 4, 5,
>> 6, 6, 6, 5, 7), Q3 = c(5, 4, 5, 6, 4, 4, 5, 4, 2, 6, 5,
>> 5, 5, 5, 7, 5, 5, 6, 7, 6, 3, 6, 6, 6, 5, 6, 6, 5, 5, 4, 5, 5,
>> 6, 6, 5, 6, 5, 5, 4, 4, 6, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4,
>> 3, 5, 4, 5, 6, 6, 6, 4, 5, 5, 5, 6, 4, 5, 5, 7, 4, 5, 6, 6, 5,
>> 5, 3, 3, 5, 4, 6, 5, 5, 1, 3, 5, 3, 2, 5, 4, 6, 6, 6, 6, 4, 6,
>> 3, 6, 6, 6, 5), Q4 = c(6, 6, 4, 7, 4, 6, 7, 6, 7, 6, 6,
>> 6, 5, 7, 7, 6, 6, 5, 7, 7, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 5, 6,
>> 7, 5, 4, 6, 4, 3, 6, 4, 6, 6, 6, 3, 5, 7, 5, 6, 4, 6, 7, 6, 7,
>> 4, 6, 3, 5, 7, 5, 4, 6, 6, 4, 6, 5, 5, 5, 5, 7, 7, 7, 6, 6, 6,
>> 5, 6, 6, 4, 5, 7, 6, 7, 3, 5, 6, 5, 6, 5, 5, 7, 7, 6, 6, 2, 7,
>> 6, 6, 7, 7, 5)), .Names = c("Q1", "Q2", "Q3",
>> "Q4"), row.names = c(NA, 100L), class = "data.frame")
>> 
>> 
>> When i run Cronbach Alpha with R i get a result
>> 
>> psych::alpha(construct,
>>          na.rm = TRUE,
>>          title = 'myscale',
>>          n.iter = 1000)
>> 
>> 
>> When i run Omega using R i get the following error message
>> 
>> "Error in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : I am sorry: missing values (NAs) in the correlation matrix do not allow me to continue.
>> Please drop those variables and try again. In addition: There were 50 or more warnings (use warnings() to see the first 50)"
>> 
>> psych::omega(m = construct,
>>       nfactors = 1, fm = "pa", n.iter = 1000, p = 0.05,
>>       title = "Omega", plot = FALSE, n.obs = 100)
>> 
>> 
>> Stackoverflow Link: http://stackoverflow.com/questions/41533231/running-omega-with-psych-library-in-r?noredirect=1#comment70278453_41533231
>> 
>> If I have the wrong mailing list, could you direct me to the appropriate one (I?m aware it might not be an R issue but more of a stats question)
>> 
>> 
>> 
>> Thank you for your time
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From therneau at mayo.edu  Tue Jan 17 03:19:48 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 17 Jan 2017 02:19:48 +0000
Subject: [R] Parallel package guidance needed
Message-ID: <021cdb$5j2s2p@ironport10.mayo.edu>

I have a process that I need to parallelize, and have a question about two
different ways to proceed.  It is essentially an MCMC exploration where
the likelihood is a sum over subjects (6000 of them), and the per-subject
computation is the slow part.

Here is a rough schematic of the code using one approach:

mymc <- function(formula, data, subset, na.action,  id, etc) {
     # lots of setup, long but computationally quick

     hlog <- function(thisid, param) {
        # compute the loglik for this subject
       ...
       }

    uid <- unique(id)  # multiple data rows for each subject

    for (i in 1:burnin) {
       param <- get_next_proposal()
       loglist <- mclapply(uid, hlog, param=param)
       loglik <- sum(unlist(loglist))
       # process result
       }

   # Now the non-burnin MCMC iterations
  ?
}

The second approach is to put cluster formation outside the loop, e.g.,

 ...
 clust <- makeForkCluster()
 for (i in 1:burnin) {
     param <- get_next_proposal()
     loglist <- parLapply(clust, uid, hlog, param=param)
     loglik <- sum(unlist(loglist))
     # process result
     }

   # rest of the code

   stopCluster(clust)

------------------

On the face of it, the second looks like it "could" be more efficient since it
only starts and stops the subprocesses once.  A short trial on one of our
cluster servers seems to say the opposite.  The load average on a quiet machine
never gets much over 5-6  using method 2, and in the 20s for method 1
(detectCores() =80 on the box, we used mc.cores=50).  Wall time for method 2
is looking to be several hours.

Any pointers to documentation/discussion at this level would be much appreciated.  I'm going to be fitting a lot of models.

Terry T.


	[[alternative HTML version deleted]]


From robert.piliero at gmail.com  Mon Jan 16 19:27:46 2017
From: robert.piliero at gmail.com (Robert Piliero)
Date: Mon, 16 Jan 2017 13:27:46 -0500
Subject: [R] Test
Message-ID: <CALNVFWm_-_JEC6Vo6D4kThw4e5F+9ntLd82vny5=a63bUSn_HA@mail.gmail.com>

-- 

Robert J. Piliero

Cell: (617) 283 1020
38 Linnaean St. #6
Cambridge, MA, 02138
USA

	[[alternative HTML version deleted]]


From robert.piliero at gmail.com  Mon Jan 16 21:10:12 2017
From: robert.piliero at gmail.com (Robert Piliero)
Date: Mon, 16 Jan 2017 15:10:12 -0500
Subject: [R] Receiving NaN message
Message-ID: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>

Hello,

I am working on a Coursera assignment and have combined 332 files into a
single data frame called "dat". The dataframe has 4 columns,

1. Date
2. Sulfate (numerical values)
3. Nitrate  (numerical  values)
4. ID # (numerical values).

Our assignment is to write a function pollutantmean <- function(directory,
pollutant, ID). whereby we can calculate the mean by inputting the
pollutant name and ID #.

I have reached the stage of subsetting the date e.g. by ID # 1-10, however
when I do so and then calculate the mean of this subset I receive the NaN
message (even though I have instructed R to disregard the "NA"'s).


*Beginning Code: *
getwd()
read.csv(specdata)
specdata <- ("C:/Users/rober/specdata")
list.files(specdata)
files_full <- list.files(specdata, full.names=TRUE)
files_full
dat <- data.frame()
for (i in 1:332){
  dat <- rbind(dat,read.csv(files_full[i]))
}
str(dat)
mean(dat$sulfate, na.rm=TRUE)

*Code which generated the NaN message. *
dat1_10 <- dat[which(dat[,ID] ==1:10),]
mean(dat1_10$sulfate, na.rm=TRUE)

Am I making a mistake in subsetting the rows with ID's 1:10? Any advice
would be appreciated.

Thank you,

Robert

Robert J. Piliero

Cell: (617) 283 1020
38 Linnaean St. #6
Cambridge, MA, 02138
USA

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Jan 17 05:14:20 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 17 Jan 2017 15:14:20 +1100
Subject: [R] Receiving NaN message
In-Reply-To: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>
References: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>
Message-ID: <CA+8X3fX8_-6jkpJBNgMqx=XCSO=QvNP3D7Nq6YmRMW4eOnKacw@mail.gmail.com>

Hi Robert,
There is a policy of not doing people's homework for them on the list.
Nevertheless, I would advise you to read up on how to use the
comparison operator (==). Good luck.

Jim


On Tue, Jan 17, 2017 at 7:10 AM, Robert Piliero
<robert.piliero at gmail.com> wrote:
> Hello,
>
> I am working on a Coursera assignment and have combined 332 files into a
> single data frame called "dat". The dataframe has 4 columns,
>
> 1. Date
> 2. Sulfate (numerical values)
> 3. Nitrate  (numerical  values)
> 4. ID # (numerical values).
>
> Our assignment is to write a function pollutantmean <- function(directory,
> pollutant, ID). whereby we can calculate the mean by inputting the
> pollutant name and ID #.
>
> I have reached the stage of subsetting the date e.g. by ID # 1-10, however
> when I do so and then calculate the mean of this subset I receive the NaN
> message (even though I have instructed R to disregard the "NA"'s).
>
>
> *Beginning Code: *
> getwd()
> read.csv(specdata)
> specdata <- ("C:/Users/rober/specdata")
> list.files(specdata)
> files_full <- list.files(specdata, full.names=TRUE)
> files_full
> dat <- data.frame()
> for (i in 1:332){
>   dat <- rbind(dat,read.csv(files_full[i]))
> }
> str(dat)
> mean(dat$sulfate, na.rm=TRUE)
>
> *Code which generated the NaN message. *
> dat1_10 <- dat[which(dat[,ID] ==1:10),]
> mean(dat1_10$sulfate, na.rm=TRUE)
>
> Am I making a mistake in subsetting the rows with ID's 1:10? Any advice
> would be appreciated.
>
> Thank you,
>
> Robert
>
> Robert J. Piliero
>
> Cell: (617) 283 1020
> 38 Linnaean St. #6
> Cambridge, MA, 02138
> USA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Jan 17 11:50:35 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 17 Jan 2017 10:50:35 +0000
Subject: [R] Receiving NaN message
In-Reply-To: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>
References: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE30A@SRVEXCHCM301.precheza.cz>

Hi

And above what Jim adviced you should look also at
?match

help page.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert
> Piliero
> Sent: Monday, January 16, 2017 9:10 PM
> To: r-help at r-project.org
> Subject: [R] Receiving NaN message
>
> Hello,
>
> I am working on a Coursera assignment and have combined 332 files into a
> single data frame called "dat". The dataframe has 4 columns,
>
> 1. Date
> 2. Sulfate (numerical values)
> 3. Nitrate  (numerical  values)
> 4. ID # (numerical values).
>
> Our assignment is to write a function pollutantmean <- function(directory,
> pollutant, ID). whereby we can calculate the mean by inputting the pollutant
> name and ID #.
>
> I have reached the stage of subsetting the date e.g. by ID # 1-10, however
> when I do so and then calculate the mean of this subset I receive the NaN
> message (even though I have instructed R to disregard the "NA"'s).
>
>
> *Beginning Code: *
> getwd()
> read.csv(specdata)
> specdata <- ("C:/Users/rober/specdata")
> list.files(specdata)
> files_full <- list.files(specdata, full.names=TRUE) files_full dat <- data.frame()
> for (i in 1:332){
>   dat <- rbind(dat,read.csv(files_full[i]))
> }
> str(dat)
> mean(dat$sulfate, na.rm=TRUE)
>
> *Code which generated the NaN message. *
> dat1_10 <- dat[which(dat[,ID] ==1:10),]
> mean(dat1_10$sulfate, na.rm=TRUE)
>
> Am I making a mistake in subsetting the rows with ID's 1:10? Any advice
> would be appreciated.
>
> Thank you,
>
> Robert
>
> Robert J. Piliero
>
> Cell: (617) 283 1020
> 38 Linnaean St. #6
> Cambridge, MA, 02138
> USA
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ruipbarradas at sapo.pt  Tue Jan 17 12:51:20 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 17 Jan 2017 11:51:20 +0000
Subject: [R] Receiving NaN message
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE30A@SRVEXCHCM301.precheza.cz>
References: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE30A@SRVEXCHCM301.precheza.cz>
Message-ID: <587E0538.30900@sapo.pt>

Hello,

And in addition to what Jim and Petr said, take a look at ?%in%.

Rui Barradas

Em 17-01-2017 10:50, PIKAL Petr escreveu:
> Hi
>
> And above what Jim adviced you should look also at
> ?match
>
> help page.
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert
>> Piliero
>> Sent: Monday, January 16, 2017 9:10 PM
>> To: r-help at r-project.org
>> Subject: [R] Receiving NaN message
>>
>> Hello,
>>
>> I am working on a Coursera assignment and have combined 332 files into a
>> single data frame called "dat". The dataframe has 4 columns,
>>
>> 1. Date
>> 2. Sulfate (numerical values)
>> 3. Nitrate  (numerical  values)
>> 4. ID # (numerical values).
>>
>> Our assignment is to write a function pollutantmean <- function(directory,
>> pollutant, ID). whereby we can calculate the mean by inputting the pollutant
>> name and ID #.
>>
>> I have reached the stage of subsetting the date e.g. by ID # 1-10, however
>> when I do so and then calculate the mean of this subset I receive the NaN
>> message (even though I have instructed R to disregard the "NA"'s).
>>
>>
>> *Beginning Code: *
>> getwd()
>> read.csv(specdata)
>> specdata <- ("C:/Users/rober/specdata")
>> list.files(specdata)
>> files_full <- list.files(specdata, full.names=TRUE) files_full dat <- data.frame()
>> for (i in 1:332){
>>    dat <- rbind(dat,read.csv(files_full[i]))
>> }
>> str(dat)
>> mean(dat$sulfate, na.rm=TRUE)
>>
>> *Code which generated the NaN message. *
>> dat1_10 <- dat[which(dat[,ID] ==1:10),]
>> mean(dat1_10$sulfate, na.rm=TRUE)
>>
>> Am I making a mistake in subsetting the rows with ID's 1:10? Any advice
>> would be appreciated.
>>
>> Thank you,
>>
>> Robert
>>
>> Robert J. Piliero
>>
>> Cell: (617) 283 1020
>> 38 Linnaean St. #6
>> Cambridge, MA, 02138
>> USA
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Tue Jan 17 14:42:25 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 17 Jan 2017 13:42:25 +0000
Subject: [R] Receiving NaN message
In-Reply-To: <587E0538.30900@sapo.pt>
References: <CALNVFWmd2JD_EnvgQi8ce+oVxHC5Y+rh_ooXF9AYP4g34K_5tw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE30A@SRVEXCHCM301.precheza.cz>
	<587E0538.30900@sapo.pt>
Message-ID: <75354b1b845f4225abbc4549380bb24b@exch-2p-mbx-w2.ads.tamu.edu>

And (re: "dat[,ID]"), the page on "Extract or Replace Parts of an Object":

? Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Tuesday, January 17, 2017 5:51 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; Robert Piliero <robert.piliero at gmail.com>; r-help at r-project.org
Subject: Re: [R] Receiving NaN message

Hello,

And in addition to what Jim and Petr said, take a look at ?%in%.

Rui Barradas

Em 17-01-2017 10:50, PIKAL Petr escreveu:
> Hi
>
> And above what Jim adviced you should look also at
> ?match
>
> help page.
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert
>> Piliero
>> Sent: Monday, January 16, 2017 9:10 PM
>> To: r-help at r-project.org
>> Subject: [R] Receiving NaN message
>>
>> Hello,
>>
>> I am working on a Coursera assignment and have combined 332 files into a
>> single data frame called "dat". The dataframe has 4 columns,
>>
>> 1. Date
>> 2. Sulfate (numerical values)
>> 3. Nitrate  (numerical  values)
>> 4. ID # (numerical values).
>>
>> Our assignment is to write a function pollutantmean <- function(directory,
>> pollutant, ID). whereby we can calculate the mean by inputting the pollutant
>> name and ID #.
>>
>> I have reached the stage of subsetting the date e.g. by ID # 1-10, however
>> when I do so and then calculate the mean of this subset I receive the NaN
>> message (even though I have instructed R to disregard the "NA"'s).
>>
>>
>> *Beginning Code: *
>> getwd()
>> read.csv(specdata)
>> specdata <- ("C:/Users/rober/specdata")
>> list.files(specdata)
>> files_full <- list.files(specdata, full.names=TRUE) files_full dat <- data.frame()
>> for (i in 1:332){
>>    dat <- rbind(dat,read.csv(files_full[i]))
>> }
>> str(dat)
>> mean(dat$sulfate, na.rm=TRUE)
>>
>> *Code which generated the NaN message. *
>> dat1_10 <- dat[which(dat[,ID] ==1:10),]
>> mean(dat1_10$sulfate, na.rm=TRUE)
>>
>> Am I making a mistake in subsetting the rows with ID's 1:10? Any advice
>> would be appreciated.
>>
>> Thank you,
>>
>> Robert
>>
>> Robert J. Piliero
>>
>> Cell: (617) 283 1020
>> 38 Linnaean St. #6
>> Cambridge, MA, 02138
>> USA
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jim.silverton at gmail.com  Tue Jan 17 17:45:10 2017
From: jim.silverton at gmail.com (Jim Silverton)
Date: Tue, 17 Jan 2017 12:45:10 -0400
Subject: [R] Cronbach's Alpha
Message-ID: <CAGPwjHyddZxVF0yZPV9nKwqcDpEuGdSw0bp9buNEuzhRJWQ==A@mail.gmail.com>

Dear all,

I have 12 companies and I am developing a scale for innovation. I want to
check the reliability of my scale. I delivered it to different (engineers,
managers etc) people in each company and an unequal number of values.
For example:
Company 1    2 engineers      2 managers
Company 2    4 engineers     10 managers
etc.

My question is can I use 'ordinary Cronbach's alpha or do I need a modified
weighted cronbach's alpha. If so, does such a thing exist in R?

-- 
Thanks,
Jim.

	[[alternative HTML version deleted]]


From jstudyvin at west-inc.com  Tue Jan 17 14:56:29 2017
From: jstudyvin at west-inc.com (Jared Studyvin)
Date: Tue, 17 Jan 2017 06:56:29 -0700
Subject: [R] Current R terminal width
Message-ID: <CADmTk9EF5LLNtEinBGT7AfsVWJLeKtJpCufM9bVEtgE7Hxro1A@mail.gmail.com>

Hello,

I have found when using R in a unix environment that Sys.getenv("COLUMNS")
will return the current R terminal width. This does not work on a Window
OS. How can this be done?

I'm looking for the Windows OS equivalent of options(width=Sys.getenv("
COLUMNS"))

Thanks,

*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}


From jay.tanzman at gmail.com  Tue Jan 17 10:05:34 2017
From: jay.tanzman at gmail.com (Jay Tanzman)
Date: Mon, 16 Jan 2017 23:05:34 -1000
Subject: [R] Qvalue package: I am getting back 1,
 000 q values when I only want 1 q value.
In-Reply-To: <CANvF3c=fkTrrMLPWvum3nXMZ_HqS_JV03FOrQO-atY4xUf_+ig@mail.gmail.com>
References: <CANvF3ck-O6hy031HCRWH+3dhVguMFBszSEXQh1mNvs4tknjGWQ@mail.gmail.com>
	<CA+8X3fW7HO8E5D5VJsWwGSB74e-A_Sy0qy9QkSb4DQQHNso_zg@mail.gmail.com>
	<CANvF3c=fkTrrMLPWvum3nXMZ_HqS_JV03FOrQO-atY4xUf_+ig@mail.gmail.com>
Message-ID: <CAAZ2zPqt5GkKmYYJK3MdarL1KXKcyC86QMRkh30B1XE3ZtVYBA@mail.gmail.com>

What you're doing makes no sense.  Given p-values p_i, i=1...n, resulting
from hypothesis tests t_i, i=1...n, the q-value of p_i is the expected
proportion of false positives among all n tests if the significance level
of each test is ?=p_i. Thus a q-value is only defined for an observed
p-value.  Assuming that you have stored n observed p-values in an R vector
P, and the ith p-value P[i]==.05, then the R syntax to obtain the q-value
for P[i] is qvalue(P)$qvalues[i].

If, instead (as I suspect), that .05 is not among your observed p-values,
but you want to know what the FDR would be, given your sequence of
p-values, if the significance level of every test were .05, then the R
syntax would be
max(qvalue(P)$qvalues[P<=.05]).

On Fri, Jan 13, 2017 at 2:08 AM, Thomas Ryan <tombernardryan at gmail.com>
wrote:

> Jim,
>
> Thanks for the reply. Yes I'm just playing around with the data at the
> minute, but regardless of where the p values actually come from, I can't
> seem to get a Q value that makes sense.
>
> For example, in one case, I have an actual P value of 0.05.  I have a list
> of 1,000 randomised p values: range of these randomised p values is 0.002
> to 0.795, average of the randomised p values is 0.399 and the median of the
> randomised p values is 0.45.
>
> So I thought it would be reasonable to expect the FDR Q Value (i.e the
> number of expected false positives over the number of significant results)
> to
> be at least over 0.05, given that 869 of the randomised p values are >
> 0.05?
>
> When I run the code:
>
> library(qvalue)
> list1 <-scan("ListOfPValues")
>
> qobj <-qvalue(p=list1)
>
> qobj$pi0
>
>
> The answer is 0.0062. That's why I thought qobj$pi0 isn't the right
> variable to be looking at? So my problem (or my mis-understanding) is that
> I have an actual P value of 0.05, but then a Q value that is lower, 0.006?
>
>
> Thanks again for your help,
>
> Tom
>
>
>
>
>
>
>
>
> On Thu, Jan 12, 2017 at 9:27 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Tom,
> > From a quick scan of the docs, I think you are looking for qobj$pi0.
> > The vector qobj$qvalue seems to be the local false discovery rate for
> > each of your randomizations. Note that the manual implies that the p
> > values are those of multiple comparisons within a data set, not
> > randomizations of the data, so I'm not sure that your usage is valid
> > for the function..
> >
> > Jim
> >
> >
> > On Fri, Jan 13, 2017 at 4:12 AM, Thomas Ryan <tombernardryan at gmail.com>
> > wrote:
> > > Hi all, I'm wondering if someone could put me on the right path to
> using
> > > the "qvalue" package correctly.
> > >
> > > I have an original p value from an analysis, and I've done 1,000
> > > randomisations of the data set. So I now have an original P value and
> > 1,000
> > > random p values. I want to work out the false discovery rate (FDR) (Q;
> as
> > > described by Storey and Tibshriani in 2003) for my original p value,
> > > defined as the number of expected false positives over the number of
> > > significant results for my original P value.
> > >
> > > So, for my original P value, I want one Q value, that has been
> calculated
> > > as described above based on the 1,000 random p values.
> > >
> > > I wrote this code:
> > >
> > > pvals <- c(list_of_p_values_obtained_from_randomisations)
> > > qobj <-qvalue(p=pvals)
> > > r_output1 <- qobj$pvalue
> > > r_output2 <- qobj$qvalue
> > >
> > > r_output1 is the list of 1,000 p values that I put in, and r_output2 is
> > a q
> > > value for each of those p values (i.e. so there are 1,000 q values).
> > >
> > > The problem is I don't want there to be 1,000 Q values (i.e one for
> each
> > > random p value). The Q value should be the false discovery rate (FDR)
> > (Q),
> > > defined as the number of expected false positives over the number of
> > > significant results. So I want one Q value for my original P value, and
> > to
> > > calculate that one Q value using the 1,000 random P values I have
> > generated.
> > >
> > > Could someone please tell me where I'm going wrong.
> > >
> > > Thanks
> > > Tom
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From crm.maia at gmail.com  Tue Jan 17 11:20:34 2017
From: crm.maia at gmail.com (Carlos R. Moreira Maia)
Date: Tue, 17 Jan 2017 08:20:34 -0200
Subject: [R] Meta-regression
Message-ID: <CAFh+_DyhuMvVKU182GFUtFJbx+GobhSK5GKXMjPXEffgx0OkRg@mail.gmail.com>

Dear all,

I'm running a meta-regression but, as a newbie, I'm facing few problems to
interpret the outputs from metareg.

I wonder if you can inform some literature where I can find how to
understand and interpret the meta-regression analysis from R.

These are the books/papers I have, but they are not very helpful:

*Introduction to Meta-Analysis [Borenstein]
*Meta-Analysis with R [Guido Schwarzer]
*How should meta-regression analyses be undertaken and interpreted?
[Thompson and Higgins]
*Conducting Meta-Analyses in R with the metafor Package [Wolfgang
Viechtbauer]

Do you have anything different, with examples?

Thank you in advance!

BW

Carlos.

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Tue Jan 17 21:36:42 2017
From: valkremk at gmail.com (Val)
Date: Tue, 17 Jan 2017 14:36:42 -0600
Subject: [R] output
In-Reply-To: <CAJOiR6b1jpiGyjpZYew666BOUG5=OA_MttbogCv5oe_UmBfazg@mail.gmail.com>
References: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
	<25E7578F-967F-49AE-B257-4241DDDC4958@me.com>
	<CAJOiR6b1jpiGyjpZYew666BOUG5=OA_MttbogCv5oe_UmBfazg@mail.gmail.com>
Message-ID: <CAJOiR6a_X+QMosvX2USs_7Nmo+hs0HmGOB8odr--4k-WfEjNxg@mail.gmail.com>

Hi Marc and all,

Last time you suggest me to use  WriteXLS  function to write more than
65,000  row in excel.  Creating the file worked fine.  Now I wanted to
read it using the WriteXLS   function but have a problem,. The file
has more than  one sheets.  Here is the script and the error message.

datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
dat <-data.frame(datx(110000,10,2))
WriteXLS(dat, "test5.xlsx", row.names=FALSE)
 I created several sheets  by copying the first sheet

t1<- read.xls("Test6.xlsx",2, stringsAsFactors=FALSE)

I am getting an error message of
Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
  no lines available in input

Thank you in advance


On Tue, Dec 13, 2016 at 5:07 PM, Val <valkremk at gmail.com> wrote:
> Marc,
> Thank you so much! That was helpful comment.
>
>
> On Mon, Dec 12, 2016 at 10:09 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> Hi,
>>
>> With the WriteXLS() function, from the package of the same name, if you specify '.xlsx' for the file name extension, the function will create an Excel 2007 compatible file, which can handle worksheets of up to 1,048,576 rows by 16,384 columns.
>>
>> Thus:
>>
>>   WriteXLS(dat, "test4.xlsx", row.names = FALSE)
>>
>> That is all described in the help file for the function.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>> On Dec 12, 2016, at 6:51 PM, Val <valkremk at gmail.com> wrote:
>>>
>>> Hi all,
>>>
>>> I have a data frame with more than 100,000 rows.
>>>
>>> datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
>>> dat <- datx(110000,10,2)
>>>
>>> 1)
>>> WriteXLS(dat, "test4.xls", row.names=FALSE)
>>> Error in WriteXLS(dat, "test4.xls", row.names = FALSE) :
>>>  One or more of the data frames named in 'x' exceeds 65,535 rows or 256 columns
>>>
>>> I noticed that *.xls has  row and column limitations.
>>>
>>> How can I take the excess row to the next sheet?
>>>
>>> 2) I also tried to use xlsx and have a problem
>>>
>>> write.xlsx(dat, "test3.xlsx",sheetName="sheet1", row.names=FALSE)
>>> Error in .jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook") :
>>>  java.lang.OutOfMemoryError: Java heap
>>> space.jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook")<S4 object of
>>> class "jobjRef">
>>>
>>> Any help ?
>>> Thank you in advance
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From marc_schwartz at me.com  Tue Jan 17 22:28:57 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 17 Jan 2017 15:28:57 -0600
Subject: [R] output
In-Reply-To: <CAJOiR6a_X+QMosvX2USs_7Nmo+hs0HmGOB8odr--4k-WfEjNxg@mail.gmail.com>
References: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
	<25E7578F-967F-49AE-B257-4241DDDC4958@me.com>
	<CAJOiR6b1jpiGyjpZYew666BOUG5=OA_MttbogCv5oe_UmBfazg@mail.gmail.com>
	<CAJOiR6a_X+QMosvX2USs_7Nmo+hs0HmGOB8odr--4k-WfEjNxg@mail.gmail.com>
Message-ID: <EE2ACA88-206F-4994-B6C1-61D9B100896A@me.com>

Hi Val,

Presuming that the Excel file that you are trying to read has a second worksheet, which is what the read.xls() command you are using is trying to do, the problem may be that XLSX file support has not been installed for the gdata package, which is what I presume you are using. You do not explicitly indicate that, so I am guessing here.

In case there is any misunderstanding, I do not have any support for reading Excel files in WriteXLS.

If you look at the help for ?read.xls in Greg's gdata package, there is a reference to using ?xlsFormats, which tests as to whether or not you have support for XLSX formats installed for that package. If that latter function only returns "XLS" and not both "XLS" and "XLSX", then you need to use ?installXLSXsupport to install additional Perl modules so that Greg's functions can read XLSX format files.

Alternatively, there are other Excel file I/O packages available on CRAN if you would prefer to consider other options as well. They will typically require Java being installed, rather than Perl, as I and Greg do.

Regards,

Marc


> On Jan 17, 2017, at 2:36 PM, Val <valkremk at gmail.com> wrote:
> 
> Hi Marc and all,
> 
> Last time you suggest me to use  WriteXLS  function to write more than
> 65,000  row in excel.  Creating the file worked fine.  Now I wanted to
> read it using the WriteXLS   function but have a problem,. The file
> has more than  one sheets.  Here is the script and the error message.
> 
> datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
> dat <-data.frame(datx(110000,10,2))
> WriteXLS(dat, "test5.xlsx", row.names=FALSE)
> I created several sheets  by copying the first sheet
> 
> t1<- read.xls("Test6.xlsx",2, stringsAsFactors=FALSE)
> 
> I am getting an error message of
> Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
>  no lines available in input
> 
> Thank you in advance
> 
> 
> On Tue, Dec 13, 2016 at 5:07 PM, Val <valkremk at gmail.com> wrote:
>> Marc,
>> Thank you so much! That was helpful comment.
>> 
>> 
>> On Mon, Dec 12, 2016 at 10:09 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>> Hi,
>>> 
>>> With the WriteXLS() function, from the package of the same name, if you specify '.xlsx' for the file name extension, the function will create an Excel 2007 compatible file, which can handle worksheets of up to 1,048,576 rows by 16,384 columns.
>>> 
>>> Thus:
>>> 
>>>  WriteXLS(dat, "test4.xlsx", row.names = FALSE)
>>> 
>>> That is all described in the help file for the function.
>>> 
>>> Regards,
>>> 
>>> Marc Schwartz
>>> 
>>> 
>>>> On Dec 12, 2016, at 6:51 PM, Val <valkremk at gmail.com> wrote:
>>>> 
>>>> Hi all,
>>>> 
>>>> I have a data frame with more than 100,000 rows.
>>>> 
>>>> datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
>>>> dat <- datx(110000,10,2)
>>>> 
>>>> 1)
>>>> WriteXLS(dat, "test4.xls", row.names=FALSE)
>>>> Error in WriteXLS(dat, "test4.xls", row.names = FALSE) :
>>>> One or more of the data frames named in 'x' exceeds 65,535 rows or 256 columns
>>>> 
>>>> I noticed that *.xls has  row and column limitations.
>>>> 
>>>> How can I take the excess row to the next sheet?
>>>> 
>>>> 2) I also tried to use xlsx and have a problem
>>>> 
>>>> write.xlsx(dat, "test3.xlsx",sheetName="sheet1", row.names=FALSE)
>>>> Error in .jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook") :
>>>> java.lang.OutOfMemoryError: Java heap
>>>> space.jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook")<S4 object of
>>>> class "jobjRef">
>>>> 
>>>> Any help ?
>>>> Thank you in advance
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 


From jwd at surewest.net  Tue Jan 17 22:37:17 2017
From: jwd at surewest.net (John Dougherty)
Date: Tue, 17 Jan 2017 13:37:17 -0800
Subject: [R] Cronbach's Alpha
In-Reply-To: <CAGPwjHyddZxVF0yZPV9nKwqcDpEuGdSw0bp9buNEuzhRJWQ==A@mail.gmail.com>
References: <CAGPwjHyddZxVF0yZPV9nKwqcDpEuGdSw0bp9buNEuzhRJWQ==A@mail.gmail.com>
Message-ID: <20170117133717.14ca8ed4@draco.site>

On Tue, 17 Jan 2017 12:45:10 -0400
Jim Silverton <jim.silverton at gmail.com> wrote:

> Dear all,
> 
> I have 12 companies and I am developing a scale for innovation. I
> want to check the reliability of my scale. I delivered it to
> different (engineers, managers etc) people in each company and an
> unequal number of values. For example:
> Company 1    2 engineers      2 managers
> Company 2    4 engineers     10 managers
> etc.
> 
> My question is can I use 'ordinary Cronbach's alpha or do I need a
> modified weighted cronbach's alpha. If so, does such a thing exist in
> R?
> 

More a statistical question than an R question.  You might want to
search sites that deal with specifically statistical aspects.

-- 

John


From r.turner at auckland.ac.nz  Tue Jan 17 23:16:02 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Jan 2017 11:16:02 +1300
Subject: [R] [FORGED] Re:  output
In-Reply-To: <EE2ACA88-206F-4994-B6C1-61D9B100896A@me.com>
References: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
	<25E7578F-967F-49AE-B257-4241DDDC4958@me.com>
	<CAJOiR6b1jpiGyjpZYew666BOUG5=OA_MttbogCv5oe_UmBfazg@mail.gmail.com>
	<CAJOiR6a_X+QMosvX2USs_7Nmo+hs0HmGOB8odr--4k-WfEjNxg@mail.gmail.com>
	<EE2ACA88-206F-4994-B6C1-61D9B100896A@me.com>
Message-ID: <ccc04258-3413-d0c7-06c2-b681b2cc7ac7@auckland.ac.nz>

On 18/01/17 10:28, Marc Schwartz wrote:
> Hi Val,

<SNIP>

> Alternatively, there are other Excel file I/O packages available on
> CRAN if you would prefer to consider other options as well. They will
> typically require Java being installed, rather than Perl, as I and
> Greg do.

The read_excel() function from the "readxl" package has an argument 
"sheet" which should facilitate what Val wants to do.

In my experience the read_excel() function (which is, as you indicate, 
Java rather than Perl based) is quite a bit faster than the Perl based 
alternatives.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From neverstop at hotmail.it  Tue Jan 17 23:17:05 2017
From: neverstop at hotmail.it (Neverstop .)
Date: Tue, 17 Jan 2017 22:17:05 +0000
Subject: [R] Dimensionality reduction with proDenICA
Message-ID: <AM2PR04MB08526DB96D84804519219994C17C0@AM2PR04MB0852.eurprd04.prod.outlook.com>

Hello,

I have a dataset with many variables and I'd like to do dimensionality 
reduction with Independent Component Analysis. There are many 
statistical methods to estimate the latent variables of the ICA model. 
I'm trying the R package "proDenICA" that implements the penalized 
maximum likelihood method proposed by Hastie, Tibshirani and Friedman in 
Section 14.7.4 of the book "Elements of Statistical Learning". The 
documentation of the proDenICA function says that the argument "k" is 
the "Number of components required, less than or equal to the number of 
columns of x". If I choose a value of k less than the number of colomns 
of x, I get an error message. It seems to me that I'm not using the 
function proDenICA() as it is meant to be used. Am I missing something?

I've reproduced the problem with a smaller dataset here:

 > library(MASS)
 > data(crabs)
 > str(crabs)
'data.frame':    200 obs. of  8 variables:
  $ sp   : Factor w/ 2 levels "B","O": 1 1 1 1 1 1 1 1 1 1 ...
  $ sex  : Factor w/ 2 levels "F","M": 2 2 2 2 2 2 2 2 2 2 ...
  $ index: int  1 2 3 4 5 6 7 8 9 10 ...
  $ FL   : num  8.1 8.8 9.2 9.6 9.8 10.8 11.1 11.6 11.8 11.8 ...
  $ RW   : num  6.7 7.7 7.8 7.9 8 9 9.9 9.1 9.6 10.5 ...
  $ CL   : num  16.1 18.1 19 20.1 20.3 23 23.8 24.5 24.2 25.2 ...
  $ CW   : num  19 20.8 22.4 23.1 23 26.5 27.1 28.4 27.8 29.3 ...
  $ BD   : num  7 7.4 7.7 8.2 8.2 9.8 9.8 10.4 9.7 10.3 ...
 > X=crabs[,4:8]
 > X=as.matrix(X)
 > library(ProDenICA)
 > out.proDen = ProDenICA(X, k = 2, whiten = TRUE, maxit = 20, trace=T)
Error in solve.default(V, W) : 'a' (5 x 2) must be square

I get the error with k = 1,2,3,4. The function works with k=5.

Thank you.


From r.turner at auckland.ac.nz  Wed Jan 18 00:08:42 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Jan 2017 12:08:42 +1300
Subject: [R] Dimensionality reduction with ProDenICA
In-Reply-To: <AM2PR04MB08526DB96D84804519219994C17C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
References: <AM2PR04MB08526DB96D84804519219994C17C0@AM2PR04MB0852.eurprd04.prod.outlook.com>
Message-ID: <05e5be07-56e6-0e23-57e3-b3247865f227@auckland.ac.nz>

On 18/01/17 11:17, Neverstop . wrote:
> Hello,
>
> I have a dataset with many variables and I'd like to do dimensionality
> reduction with Independent Component Analysis. There are many
> statistical methods to estimate the latent variables of the ICA model.
> I'm trying the R package "ProDenICA" that implements the penalized
> maximum likelihood method proposed by Hastie, Tibshirani and Friedman in
> Section 14.7.4 of the book "Elements of Statistical Learning". The
> documentation of the ProDenICA function says that the argument "k" is
> the "Number of components required, less than or equal to the number of
> columns of x". If I choose a value of k less than the number of colomns
> of x, I get an error message. It seems to me that I'm not using the
> function proDenICA() as it is meant to be used. Am I missing something?
>
> I've reproduced the problem with a smaller dataset here:
>
>  > library(MASS)
>  > data(crabs)
>  > str(crabs)
> 'data.frame':    200 obs. of  8 variables:
>   $ sp   : Factor w/ 2 levels "B","O": 1 1 1 1 1 1 1 1 1 1 ...
>   $ sex  : Factor w/ 2 levels "F","M": 2 2 2 2 2 2 2 2 2 2 ...
>   $ index: int  1 2 3 4 5 6 7 8 9 10 ...
>   $ FL   : num  8.1 8.8 9.2 9.6 9.8 10.8 11.1 11.6 11.8 11.8 ...
>   $ RW   : num  6.7 7.7 7.8 7.9 8 9 9.9 9.1 9.6 10.5 ...
>   $ CL   : num  16.1 18.1 19 20.1 20.3 23 23.8 24.5 24.2 25.2 ...
>   $ CW   : num  19 20.8 22.4 23.1 23 26.5 27.1 28.4 27.8 29.3 ...
>   $ BD   : num  7 7.4 7.7 8.2 8.2 9.8 9.8 10.4 9.7 10.3 ...
>  > X=crabs[,4:8]
>  > X=as.matrix(X)
>  > library(ProDenICA)
>  > out.proDen = ProDenICA(X, k = 2, whiten = TRUE, maxit = 20, trace=T)
> Error in solve.default(V, W) : 'a' (5 x 2) must be square
>
> I get the error with k = 1,2,3,4. The function works with k=5.

I have no idea how to help you --- sorry!!! --- but I would like to 
compliment you on the clarity of your extremely well structured 
question, complete with reproducible example.

My gut feeling is that there must be something wrong with the 
ProDenICA() function, but such is my ignorance that this gut feeling is 
not worth the paper it's written on! :-)

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Wed Jan 18 00:21:31 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Jan 2017 10:21:31 +1100
Subject: [R] turning the output of cut into a waffle plot
Message-ID: <CA+8X3fXcMWEBfw3JtDPY8L7urwx4RabcqrO2how-FJSbmpA2_A@mail.gmail.com>

Hi all,
A few days ago I offered a suggestion on how to display the initial
values that were cut into a factor as a waffle plot. As Rolf Turner
noted, a major problem for users would be constructing the matrix that
was fed to the color2D.matplot function. Here is a fairly general
purpose function for that with an example from the initial post.

egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
           161,162,165,164,179,173,173,182,180,185,180,197,190)

cut2matrix<-function(x,breaks,ncol,nrow,right=TRUE) {
 xcut<-as.numeric(cut(x,breaks=breaks,right=right))
 if(missing(ncol)) ncol<-length(breaks)-1
 if(missing(nrow)) nrow<-max(table(xcut))
 xlist<-vector("list",ncol)
 for(xind in 1:ncol) xlist[[xind]]<-rev(x[xcut==xind])
 xdf<-as.data.frame(lapply(xlist,function(x) x[1:nrow]))
 names(xdf)<-paste("V",1:ncol,sep="")
 return(as.matrix(sapply(xdf,rev)))
}

egmat<-cut2matrix(egdat,seq(120,210,by=10),9,8,FALSE)
library(plotrix)
color2D.matplot(egmat,show.values=TRUE)

Jim


From jake.andrae at adelaide.edu.au  Wed Jan 18 02:04:51 2017
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Wed, 18 Jan 2017 01:04:51 +0000
Subject: [R] Adding regression line to each individual plot in a window with
 multiple plots
Message-ID: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>

Hi Everyone,



I've constructed a script that adds multiple plots to the plot window, but I'm having a bit of trouble adding a regression line to each individual plot. Of course, the regression lines will vary depending on the variables plotted against one another. I've attached the script.


#Growing season
#Construction of plots
# 12 figures arranged in 3 rows and 4 columns
attach(mtcars)
par(mfrow=c(3,4), mar = c(.6,.5,.6,1), oma = c(15,4,2,2), xpd = NA)
#Concentration
plot(Growing_season_precipitation, Concentration, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,500), xlab = NA, ylab = "Concentration", xaxt='n', pch=21,  bg='black', abline(lm(Growing_season_precipitation~Concentration)))
plot(Growing_season_VPD, Concentration, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n')
plot(Growing_season_Rhmax, Concentration, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n')
plot(Growing_season_temperature, Concentration, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n')
#ACL
plot(Growing_season_precipitation, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(28,32), xlab = "", ylab = "ACL", xaxt='n',  pch=21,  bg='black')
plot(Growing_season_VPD, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
plot(Growing_season_Rhmax, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
plot(Growing_season_temperature, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
#CPI
plot(Growing_season_precipitation, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,30), xlab = "Total precipitation (mm)", ylab = "CPI",  pch=21,  bg='black')
plot(Growing_season_VPD, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(0,30), xlab = "Average daily VPD (kpa)", ylab = "",  pch=21,  bg='black', yaxt='n')
plot(Growing_season_Rhmax, CPITotal, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(0,30), xlab = "Average daily RHmax (%)", ylab = "",  pch=21,  bg='black', yaxt='n')
plot(Growing_season_temperature, CPITotal, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(0,30), xlab = "Average daily temperature (oC)", ylab = "",  pch=21,  bg='black', yaxt='n')
#Plot main title
title(main="Growing season (June-November, inclusive)",outer=T)

Any help would be greatly appreciated!



	[[alternative HTML version deleted]]


From alaasindi at gmail.com  Tue Jan 17 19:53:30 2017
From: alaasindi at gmail.com (Alaa Sindi)
Date: Tue, 17 Jan 2017 13:53:30 -0500
Subject: [R] the difference between R and other statistical software when
	using maxilla package
Message-ID: <E9333F92-0F47-42D7-8047-977673A4D961@gmail.com>

Hi all,

Is  there any differences in estimation results when using maxlik package in R and other statistical software? 

Thanks 
Alaa

From drjimlemon at gmail.com  Wed Jan 18 03:36:26 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Jan 2017 13:36:26 +1100
Subject: [R] Adding regression line to each individual plot in a window
 with multiple plots
In-Reply-To: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
References: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
Message-ID: <CA+8X3fWFjCmOFNpfOysR0fkiKxcmosncjxfOHCMHV6q2km44mQ@mail.gmail.com>

Hi Jake,
As I don't have your data set, try this:

attach(mtcars)
plot(mpg~disp,xaxs="i",yaxs="i")
abline(lm(mpg~disp))

Jim

On Wed, Jan 18, 2017 at 12:04 PM, Jake William Andrae
<jake.andrae at adelaide.edu.au> wrote:
> Hi Everyone,
>
>
>
> I've constructed a script that adds multiple plots to the plot window, but I'm having a bit of trouble adding a regression line to each individual plot. Of course, the regression lines will vary depending on the variables plotted against one another. I've attached the script.
>
>
> #Growing season
> #Construction of plots
> # 12 figures arranged in 3 rows and 4 columns
> attach(mtcars)
> par(mfrow=c(3,4), mar = c(.6,.5,.6,1), oma = c(15,4,2,2), xpd = NA)
> #Concentration
> plot(Growing_season_precipitation, Concentration, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,500), xlab = NA, ylab = "Concentration", xaxt='n', pch=21,  bg='black', abline(lm(Growing_season_precipitation~Concentration)))
> plot(Growing_season_VPD, Concentration, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n')
> plot(Growing_season_Rhmax, Concentration, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n')
> plot(Growing_season_temperature, Concentration, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n')
> #ACL
> plot(Growing_season_precipitation, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(28,32), xlab = "", ylab = "ACL", xaxt='n',  pch=21,  bg='black')
> plot(Growing_season_VPD, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
> plot(Growing_season_Rhmax, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
> plot(Growing_season_temperature, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
> #CPI
> plot(Growing_season_precipitation, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,30), xlab = "Total precipitation (mm)", ylab = "CPI",  pch=21,  bg='black')
> plot(Growing_season_VPD, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(0,30), xlab = "Average daily VPD (kpa)", ylab = "",  pch=21,  bg='black', yaxt='n')
> plot(Growing_season_Rhmax, CPITotal, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(0,30), xlab = "Average daily RHmax (%)", ylab = "",  pch=21,  bg='black', yaxt='n')
> plot(Growing_season_temperature, CPITotal, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(0,30), xlab = "Average daily temperature (oC)", ylab = "",  pch=21,  bg='black', yaxt='n')
> #Plot main title
> title(main="Growing season (June-November, inclusive)",outer=T)
>
> Any help would be greatly appreciated!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jan 18 04:10:11 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Jan 2017 14:10:11 +1100
Subject: [R] Adding regression line to each individual plot in a window
 with multiple plots
In-Reply-To: <SY3PR01MB2074150EFF82792ABDB1B065A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
References: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
	<CA+8X3fWFjCmOFNpfOysR0fkiKxcmosncjxfOHCMHV6q2km44mQ@mail.gmail.com>
	<SY3PR01MB2074150EFF82792ABDB1B065A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
Message-ID: <CA+8X3fW5Q7Wokci5OB1mUFjwKNF0Okp_mGX90cH4akqcma5AAg@mail.gmail.com>

Hi Jake,
In the second line of your script, you set xpd=NA. That means that
abline will draw a line across the entire display region rather than
restricting it to the plot region. If you must set this at the
beginning, then add these lines:

par(xpd=TRUE)
abline(lm(...))
par(xpd=NA)

for each regression line you display.

Jim


On Wed, Jan 18, 2017 at 1:41 PM, Jake William Andrae
<jake.andrae at adelaide.edu.au> wrote:
> Hi Jim, that works but this is what it then looks like.
>
> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com]
> Sent: Wednesday, 18 January 2017 1:06 PM
> To: Jake William Andrae <jake.andrae at adelaide.edu.au>
> Cc: r-help at r-project.org
> Subject: Re: [R] Adding regression line to each individual plot in a window with multiple plots
>
> Hi Jake,
> As I don't have your data set, try this:
>
> attach(mtcars)
> plot(mpg~disp,xaxs="i",yaxs="i")
> abline(lm(mpg~disp))
>
> Jim
>
> On Wed, Jan 18, 2017 at 12:04 PM, Jake William Andrae <jake.andrae at adelaide.edu.au> wrote:
>> Hi Everyone,
>>
>>
>>
>> I've constructed a script that adds multiple plots to the plot window, but I'm having a bit of trouble adding a regression line to each individual plot. Of course, the regression lines will vary depending on the variables plotted against one another. I've attached the script.
>>
>>
>> #Growing season
>> #Construction of plots
>> # 12 figures arranged in 3 rows and 4 columns
>> attach(mtcars)
>> par(mfrow=c(3,4), mar = c(.6,.5,.6,1), oma = c(15,4,2,2), xpd = NA)
>> #Concentration plot(Growing_season_precipitation, Concentration, xaxs
>> = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,500), xlab = NA, ylab
>> = "Concentration", xaxt='n', pch=21,  bg='black',
>> abline(lm(Growing_season_precipitation~Concentration)))
>> plot(Growing_season_VPD, Concentration, xaxs = "i", yaxs = "i", xlim =
>> c(0.6, 1.8), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,
>> bg='black', yaxt='n') plot(Growing_season_Rhmax, Concentration, xaxs =
>> "i", yaxs = "i", xlim = c(35, 60), ylim = c(0,500), xlab = NA, ylab =
>> "", xaxt='n', pch=21,  bg='black', yaxt='n')
>> plot(Growing_season_temperature, Concentration, xaxs = "i", yaxs =
>> "i", xlim = c(20,34), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n',
>> pch=21,  bg='black', yaxt='n') #ACL plot(Growing_season_precipitation,
>> ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(28,32),
>> xlab = "", ylab = "ACL", xaxt='n',  pch=21,  bg='black')
>> plot(Growing_season_VPD, ACLTotal, xaxs = "i", yaxs = "i", xlim =
>> c(0.6, 1.8), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,
>> bg='black', yaxt='n') plot(Growing_season_Rhmax, ACLTotal, xaxs = "i",
>> yaxs = "i", xlim = c(35, 60), ylim = c(28,32), xlab = "", ylab = "",
>> xaxt='n',  pch=21,  bg='black', yaxt='n')
>> plot(Growing_season_temperature, ACLTotal, xaxs = "i", yaxs = "i",
>> xlim = c(20,34), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',
>> pch=21,  bg='black', yaxt='n') #CPI plot(Growing_season_precipitation,
>> CPITotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,30),
>> xlab = "Total precipitation (mm)", ylab = "CPI",  pch=21,  bg='black')
>> plot(Growing_season_VPD, CPITotal, xaxs = "i", yaxs = "i", xlim =
>> c(0.6, 1.8), ylim = c(0,30), xlab = "Average daily VPD (kpa)", ylab =
>> "",  pch=21,  bg='black', yaxt='n') plot(Growing_season_Rhmax,
>> CPITotal, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(0,30),
>> xlab = "Average daily RHmax (%)", ylab = "",  pch=21,  bg='black',
>> yaxt='n') plot(Growing_season_temperature, CPITotal, xaxs = "i", yaxs
>> = "i", xlim = c(20,34), ylim = c(0,30), xlab = "Average daily
>> temperature (oC)", ylab = "",  pch=21,  bg='black', yaxt='n') #Plot
>> main title title(main="Growing season (June-November,
>> inclusive)",outer=T)
>>
>> Any help would be greatly appreciated!
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jan 18 04:34:16 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Jan 2017 14:34:16 +1100
Subject: [R] Adding regression line to each individual plot in a window
 with multiple plots
In-Reply-To: <SY3PR01MB20743CCD131BD34815FB5EDEA97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
References: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
	<CA+8X3fWFjCmOFNpfOysR0fkiKxcmosncjxfOHCMHV6q2km44mQ@mail.gmail.com>
	<SY3PR01MB2074150EFF82792ABDB1B065A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
	<CA+8X3fW5Q7Wokci5OB1mUFjwKNF0Okp_mGX90cH4akqcma5AAg@mail.gmail.com>
	<SY3PR01MB20743CCD131BD34815FB5EDEA97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
Message-ID: <CA+8X3fUWpBk-ygPBkAeFPmt+2aBqK=VZKLAwPX1dXznX1iNf0Q@mail.gmail.com>

Hi Jake,
My mistake, that should be:

par(xpd=FALSE)
abline(lm(...))
par(xpd=NA)

I suspect that the odd looking regression lines are due to points off
the plot as you have specified xlim and ylim for your plots.

Jim


On Wed, Jan 18, 2017 at 2:22 PM, Jake William Andrae
<jake.andrae at adelaide.edu.au> wrote:
> If I run the script like this, with the commands you suggested, it looks like the figure attached. Scratching my head, the regression lines shouldn?t look like this.
>
> #Growing season
> #Construction of plots (without Rhmax)
> # 12 figures arranged in 3 rows and 3 columns
> attach(mtcars)
> par(mfrow=c(3,3), mar = c(.6,.5,.6,1), oma = c(5,4,2,2), xpd = NA)
> #Concentration
> plot(Growing_season_precipitation, Concentration, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,500), xlab = NA, ylab = "Concentration", xaxt='n', pch=21,  bg='black', rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_precipitation~Concentration))
> par(xpd=NA)
> plot(Growing_season_VPD, Concentration, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n', rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_VPD~Concentration))
> par(xpd=NA)
> plot(Growing_season_temperature, Concentration, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black', yaxt='n', rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_temperature~Concentration))
> par(xpd=NA)
> #ACL
> plot(Growing_season_precipitation, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(28,32), xlab = "", ylab = "ACL", xaxt='n',  pch=21,  bg='black',  rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_precipitation~ACLTotal))
> par(xpd=NA)
> plot(Growing_season_VPD, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n' ,rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_VPD~ACLTotal))
> par(xpd=NA)
> plot(Growing_season_temperature, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n', rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_temperature~ACLTotal))
> par(xpd=NA)
> #CPI
> plot(Growing_season_precipitation, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,30), xlab = "Total precipitation (mm)", ylab = "CPI",  pch=21,  bg='black', rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_precipitation~CPITotal))
> par(xpd=NA)
> plot(Growing_season_VPD, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0.6, 1.8), ylim = c(0,30), xlab = "Average daily VPD (kPa)", ylab = "",  pch=21,  bg='black', yaxt='n' ,rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_VPD~CPITotal))
> par(xpd=NA)
> plot(Growing_season_temperature, CPITotal, xaxs = "i", yaxs = "i", xlim = c(20,34), ylim = c(0,30), xlab = "Average daily temperature (oC)", ylab = "",  pch=21,  bg='black', yaxt='n', rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white"))
> par(xpd=TRUE)
> abline(lm(Growing_season_temperature~CPITotal))
> par(xpd=NA)
> #Plot main title
> title(main="Growing season (June-November, inclusive)",outer=T)
>
> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com]
> Sent: Wednesday, 18 January 2017 1:40 PM
> To: Jake William Andrae <jake.andrae at adelaide.edu.au>; r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Adding regression line to each individual plot in a window with multiple plots
>
> Hi Jake,
> In the second line of your script, you set xpd=NA. That means that abline will draw a line across the entire display region rather than restricting it to the plot region. If you must set this at the beginning, then add these lines:
>
> par(xpd=TRUE)
> abline(lm(...))
> par(xpd=NA)
>
> for each regression line you display.
>
> Jim
>
>
> On Wed, Jan 18, 2017 at 1:41 PM, Jake William Andrae <jake.andrae at adelaide.edu.au> wrote:
>> Hi Jim, that works but this is what it then looks like.
>>
>> -----Original Message-----
>> From: Jim Lemon [mailto:drjimlemon at gmail.com]
>> Sent: Wednesday, 18 January 2017 1:06 PM
>> To: Jake William Andrae <jake.andrae at adelaide.edu.au>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Adding regression line to each individual plot in a
>> window with multiple plots
>>
>> Hi Jake,
>> As I don't have your data set, try this:
>>
>> attach(mtcars)
>> plot(mpg~disp,xaxs="i",yaxs="i")
>> abline(lm(mpg~disp))
>>
>> Jim
>>
>> On Wed, Jan 18, 2017 at 12:04 PM, Jake William Andrae <jake.andrae at adelaide.edu.au> wrote:
>>> Hi Everyone,
>>>
>>>
>>>
>>> I've constructed a script that adds multiple plots to the plot window, but I'm having a bit of trouble adding a regression line to each individual plot. Of course, the regression lines will vary depending on the variables plotted against one another. I've attached the script.
>>>
>>>
>>> #Growing season
>>> #Construction of plots
>>> # 12 figures arranged in 3 rows and 4 columns
>>> attach(mtcars)
>>> par(mfrow=c(3,4), mar = c(.6,.5,.6,1), oma = c(15,4,2,2), xpd = NA)
>>> #Concentration plot(Growing_season_precipitation, Concentration, xaxs
>>> = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,500), xlab = NA, ylab
>>> = "Concentration", xaxt='n', pch=21,  bg='black',
>>> abline(lm(Growing_season_precipitation~Concentration)))
>>> plot(Growing_season_VPD, Concentration, xaxs = "i", yaxs = "i", xlim
>>> = c(0.6, 1.8), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n',
>>> pch=21, bg='black', yaxt='n') plot(Growing_season_Rhmax,
>>> Concentration, xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim =
>>> c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,  bg='black',
>>> yaxt='n') plot(Growing_season_temperature, Concentration, xaxs = "i",
>>> yaxs = "i", xlim = c(20,34), ylim = c(0,500), xlab = NA, ylab = "",
>>> xaxt='n', pch=21,  bg='black', yaxt='n') #ACL
>>> plot(Growing_season_precipitation,
>>> ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(28,32),
>>> xlab = "", ylab = "ACL", xaxt='n',  pch=21,  bg='black')
>>> plot(Growing_season_VPD, ACLTotal, xaxs = "i", yaxs = "i", xlim =
>>> c(0.6, 1.8), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',
>>> pch=21, bg='black', yaxt='n') plot(Growing_season_Rhmax, ACLTotal,
>>> xaxs = "i", yaxs = "i", xlim = c(35, 60), ylim = c(28,32), xlab = "",
>>> ylab = "", xaxt='n',  pch=21,  bg='black', yaxt='n')
>>> plot(Growing_season_temperature, ACLTotal, xaxs = "i", yaxs = "i",
>>> xlim = c(20,34), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',
>>> pch=21,  bg='black', yaxt='n') #CPI
>>> plot(Growing_season_precipitation,
>>> CPITotal, xaxs = "i", yaxs = "i", xlim = c(0, 700), ylim = c(0,30),
>>> xlab = "Total precipitation (mm)", ylab = "CPI",  pch=21,
>>> bg='black') plot(Growing_season_VPD, CPITotal, xaxs = "i", yaxs =
>>> "i", xlim = c(0.6, 1.8), ylim = c(0,30), xlab = "Average daily VPD
>>> (kpa)", ylab = "",  pch=21,  bg='black', yaxt='n')
>>> plot(Growing_season_Rhmax, CPITotal, xaxs = "i", yaxs = "i", xlim =
>>> c(35, 60), ylim = c(0,30), xlab = "Average daily RHmax (%)", ylab =
>>> "",  pch=21,  bg='black',
>>> yaxt='n') plot(Growing_season_temperature, CPITotal, xaxs = "i", yaxs
>>> = "i", xlim = c(20,34), ylim = c(0,30), xlab = "Average daily
>>> temperature (oC)", ylab = "",  pch=21,  bg='black', yaxt='n') #Plot
>>> main title title(main="Growing season (June-November,
>>> inclusive)",outer=T)
>>>
>>> Any help would be greatly appreciated!
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Jan 18 07:37:31 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Jan 2017 19:37:31 +1300
Subject: [R] [FORGED]  turning the output of cut into a waffle plot
In-Reply-To: <CA+8X3fXcMWEBfw3JtDPY8L7urwx4RabcqrO2how-FJSbmpA2_A@mail.gmail.com>
References: <CA+8X3fXcMWEBfw3JtDPY8L7urwx4RabcqrO2how-FJSbmpA2_A@mail.gmail.com>
Message-ID: <4c8330b2-6cea-d1c5-c093-32126cfaa3bb@auckland.ac.nz>

On 18/01/17 12:21, Jim Lemon wrote:
> Hi all,
> A few days ago I offered a suggestion on how to display the initial
> values that were cut into a factor as a waffle plot. As Rolf Turner
> noted, a major problem for users would be constructing the matrix that
> was fed to the color2D.matplot function. Here is a fairly general
> purpose function for that with an example from the initial post.
>
> egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
>            161,162,165,164,179,173,173,182,180,185,180,197,190)
>
> cut2matrix<-function(x,breaks,ncol,nrow,right=TRUE) {
>  xcut<-as.numeric(cut(x,breaks=breaks,right=right))
>  if(missing(ncol)) ncol<-length(breaks)-1
>  if(missing(nrow)) nrow<-max(table(xcut))
>  xlist<-vector("list",ncol)
>  for(xind in 1:ncol) xlist[[xind]]<-rev(x[xcut==xind])
>  xdf<-as.data.frame(lapply(xlist,function(x) x[1:nrow]))
>  names(xdf)<-paste("V",1:ncol,sep="")
>  return(as.matrix(sapply(xdf,rev)))
> }
>
> egmat<-cut2matrix(egdat,seq(120,210,by=10),9,8,FALSE)
> library(plotrix)
> color2D.matplot(egmat,show.values=TRUE)

Nice work Jim.  Will the cut2matrix() function now be added to the 
plotrix package?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thierry.onkelinx at inbo.be  Wed Jan 18 09:46:14 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 18 Jan 2017 09:46:14 +0100
Subject: [R] Adding regression line to each individual plot in a window
 with multiple plots
In-Reply-To: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
References: <SY3PR01MB20745B1467237858E3F4F186A97F0@SY3PR01MB2074.ausprd01.prod.outlook.com>
Message-ID: <CAJuCY5wmgn5XGhU+GCa1Ugv43AD20XLnhdOzXUsO_Snw5uRRhw@mail.gmail.com>

Hi Jake,

You could consider switching to ggplot2

# create a dummy dataset
dataset <- data.frame(
  XA = rnorm(100),
  XB = rnorm(100, mean = 10),
  YA = rnorm(100),
  YB = rnorm(100, mean = -10)
)
# convert it to long format
library(tidyr)
long <- dataset %>%
  gather("Xcat", "Xvalue", XA:XB) %>%
  gather("Ycat", "Yvalue", YA:YB)
# create the plot
library(ggplot2)
ggplot(long, aes(x = Xvalue, y = Yvalue)) +
  geom_smooth(method = "lm") +
  geom_point() +
  facet_grid(Ycat ~ Xcat, scales = "free")

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-18 2:04 GMT+01:00 Jake William Andrae <jake.andrae at adelaide.edu.au>:

> Hi Everyone,
>
>
>
> I've constructed a script that adds multiple plots to the plot window, but
> I'm having a bit of trouble adding a regression line to each individual
> plot. Of course, the regression lines will vary depending on the variables
> plotted against one another. I've attached the script.
>
>
> #Growing season
> #Construction of plots
> # 12 figures arranged in 3 rows and 4 columns
> attach(mtcars)
> par(mfrow=c(3,4), mar = c(.6,.5,.6,1), oma = c(15,4,2,2), xpd = NA)
> #Concentration
> plot(Growing_season_precipitation, Concentration, xaxs = "i", yaxs = "i",
> xlim = c(0, 700), ylim = c(0,500), xlab = NA, ylab = "Concentration",
> xaxt='n', pch=21,  bg='black', abline(lm(Growing_season_
> precipitation~Concentration)))
> plot(Growing_season_VPD, Concentration, xaxs = "i", yaxs = "i", xlim =
> c(0.6, 1.8), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,
> bg='black', yaxt='n')
> plot(Growing_season_Rhmax, Concentration, xaxs = "i", yaxs = "i", xlim =
> c(35, 60), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,
> bg='black', yaxt='n')
> plot(Growing_season_temperature, Concentration, xaxs = "i", yaxs = "i",
> xlim = c(20,34), ylim = c(0,500), xlab = NA, ylab = "", xaxt='n', pch=21,
> bg='black', yaxt='n')
> #ACL
> plot(Growing_season_precipitation, ACLTotal, xaxs = "i", yaxs = "i", xlim
> = c(0, 700), ylim = c(28,32), xlab = "", ylab = "ACL", xaxt='n',  pch=21,
> bg='black')
> plot(Growing_season_VPD, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(0.6,
> 1.8), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,
> bg='black', yaxt='n')
> plot(Growing_season_Rhmax, ACLTotal, xaxs = "i", yaxs = "i", xlim = c(35,
> 60), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,  bg='black',
> yaxt='n')
> plot(Growing_season_temperature, ACLTotal, xaxs = "i", yaxs = "i", xlim =
> c(20,34), ylim = c(28,32), xlab = "", ylab = "", xaxt='n',  pch=21,
> bg='black', yaxt='n')
> #CPI
> plot(Growing_season_precipitation, CPITotal, xaxs = "i", yaxs = "i", xlim
> = c(0, 700), ylim = c(0,30), xlab = "Total precipitation (mm)", ylab =
> "CPI",  pch=21,  bg='black')
> plot(Growing_season_VPD, CPITotal, xaxs = "i", yaxs = "i", xlim = c(0.6,
> 1.8), ylim = c(0,30), xlab = "Average daily VPD (kpa)", ylab = "",
> pch=21,  bg='black', yaxt='n')
> plot(Growing_season_Rhmax, CPITotal, xaxs = "i", yaxs = "i", xlim = c(35,
> 60), ylim = c(0,30), xlab = "Average daily RHmax (%)", ylab = "",  pch=21,
> bg='black', yaxt='n')
> plot(Growing_season_temperature, CPITotal, xaxs = "i", yaxs = "i", xlim =
> c(20,34), ylim = c(0,30), xlab = "Average daily temperature (oC)", ylab =
> "",  pch=21,  bg='black', yaxt='n')
> #Plot main title
> title(main="Growing season (June-November, inclusive)",outer=T)
>
> Any help would be greatly appreciated!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jan 18 10:25:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Jan 2017 20:25:24 +1100
Subject: [R] [FORGED]  turning the output of cut into a waffle plot
In-Reply-To: <4c8330b2-6cea-d1c5-c093-32126cfaa3bb@auckland.ac.nz>
References: <CA+8X3fXcMWEBfw3JtDPY8L7urwx4RabcqrO2how-FJSbmpA2_A@mail.gmail.com>
	<4c8330b2-6cea-d1c5-c093-32126cfaa3bb@auckland.ac.nz>
Message-ID: <CA+8X3fXXJ7n8Y8K0rwN759vyhbxrHsLUB2nW+sZyO-rNH1eYOA@mail.gmail.com>

Hi Rolf,
About the only reason I would hesitate is package bloat. There are now
167 functions listed in the package. I posted the cut2matrix function
for the benefit of those who had been following the thread, but it
seems like a very peculiar way of displaying data. While I encourage
trying things out, as there is a lot left to discover, I would like to
be sure that more than one person sees a use for it.

Jim


On Wed, Jan 18, 2017 at 5:37 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 18/01/17 12:21, Jim Lemon wrote:
>>
>> Hi all,
>> A few days ago I offered a suggestion on how to display the initial
>> values that were cut into a factor as a waffle plot. As Rolf Turner
>> noted, a major problem for users would be constructing the matrix that
>> was fed to the color2D.matplot function. Here is a fairly general
>> purpose function for that with an example from the initial post.
>>
>> egdat <- c(137,135,144,149,150,152,159,157,154,163,164,164,
>>            161,162,165,164,179,173,173,182,180,185,180,197,190)
>>
>> cut2matrix<-function(x,breaks,ncol,nrow,right=TRUE) {
>>  xcut<-as.numeric(cut(x,breaks=breaks,right=right))
>>  if(missing(ncol)) ncol<-length(breaks)-1
>>  if(missing(nrow)) nrow<-max(table(xcut))
>>  xlist<-vector("list",ncol)
>>  for(xind in 1:ncol) xlist[[xind]]<-rev(x[xcut==xind])
>>  xdf<-as.data.frame(lapply(xlist,function(x) x[1:nrow]))
>>  names(xdf)<-paste("V",1:ncol,sep="")
>>  return(as.matrix(sapply(xdf,rev)))
>> }
>>
>> egmat<-cut2matrix(egdat,seq(120,210,by=10),9,8,FALSE)
>> library(plotrix)
>> color2D.matplot(egmat,show.values=TRUE)
>
>
> Nice work Jim.  Will the cut2matrix() function now be added to the plotrix
> package?
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From pnsinha68 at gmail.com  Wed Jan 18 12:13:45 2017
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Wed, 18 Jan 2017 16:43:45 +0530
Subject: [R] Error on using Rweka package
Message-ID: <CADcgpJeCrh7EGtaLH6wQd7471e-_K8gy2yhe3a448Fq9njnvrw@mail.gmail.com>

I am using R version 3.3.2 (64 bit) on ubuntu version 14. I am trying to
install Rweka but getting the following error.
Can someone please help me with this error ?
Regards
Parth


Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object
'/home/puja/R/x86_64-pc-linux-gnu-library/3.3/rJava/libs/rJava.so':
  /home/puja/R/x86_64-pc-linux-gnu-library/3.3/rJava/libs/rJava.so: invalid
ELF header
Error: package or namespace load failed for ?RWeka?

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Jan 18 13:35:38 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 18 Jan 2017 12:35:38 +0000
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
 numbers on Windows with German locale
In-Reply-To: <CAGmpuejra4=+PCpUs3eAWuzkgMc4HP-WVXpmbj0XGYmBtErKoA@mail.gmail.com>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
	<CAGmpuejra4=+PCpUs3eAWuzkgMc4HP-WVXpmbj0XGYmBtErKoA@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672404E3A709D8@GBTEDVPEXCMB04.corp.lgc-group.com>



> -----Original Message-----
> (yw <- format(posix, "%Y-%V"))
> > # [1] "2015-52" "2015-53" "2016-53" "2016-01"
> 
> Which, after checking back with a calendar, would give me reason to believe
> that it using %V does in fact seem to work: it's an input to `format()` and R
> doesn't seem to ignore it as the correct week numbers (following ISO 8601)
> are returned.

Unfortunately it does _not_ work as an input to strptime() or as.Date(). Try
strptime(sprintf("2016-%02d", 1:52), "%Y-%V")

which all return the same (rather arbitrary-looking) date. (R 3.3.1 on Windows 7)

So you can easily extract the week number from a date, but you can't extract the month number from a week number using base R.

What you _could_ do is assign an appropriate weekday in each week and use that day to assign a month. Using the 8601 rules, Thursday seems sensible as that is the weekday used to define the week number. The following crude implementation (which allows some variation in the input string and a custom weekday defaulting to Thursday) seems to work in my UK locale, though I've not spent a lot of time debugging. You should be able to get it to work with minimal tweaking in another locale:

yw.to.month <- function(yw, yearformat="%Y", separator="-", monthformat="%m", weekday=4) {
	# yw  is a character vector assumed to be in %Y-%W" or "%y-%W"
	#     form (or with another separator specified by separator)
	# yearformat is a character string used by as.Date to convert the year.
	# separator is the year-week separator string in yw
	# monthformat is the output format, passed to format.Date
	# weekday is the (numerica) day of the week to be used to place the week 
	#         in a specific month. The default, 4, takes the Thursday.
	
	
	#Get the year as a character vector
	Y <- format(as.Date(yw, yearformat), "%Y")
	
	#Get the date of the first thursday in each year
	Jan01 <- as.Date(sprintf("%s-01-01", Y), "%Y-%m-%d") #constructs 1st Jan for each year
	J1.w <- as.numeric( format(Jan01, "%w") ) #numerical day of week for jan 1st
	date.increment <- ifelse(J1.w > weekday, 7 + weekday - J1.w, weekday - J1.w) #How far to first thursday?
	Thursday1 <- as.Date( Jan01 + date.increment ) #date for first thursday
		
	#Add the week number in yw to get the corresponding Thursday's date
	wknum <- as.numeric( gsub(sprintf(".+%s(.+)", separator), "\\1", yw) )
	Thursdays <- Thursday1 + 7 * (wknum - 1)

	#... and convert each Thursday date to month number 
	# using supplied monthformat
	
	format( Thursdays, monthformat )
}

#Examples
#Construct a collection of "YYYY-WW" strings:
yw <- sprintf("%4d-%02d", rep(2015:2017, each=53), rep(1:53, 3))
	#NB: Week 53 does not exist in all years. e.g 'week 53' of 2016 is week 1 of 2017. 
	#But the week number is just used as an offset from the first specified weekday,
	#so the function does returns a valid year and month if the week number is 
	#after the year end. 
	
yw.to.month(yw)

yw.to.month(yw, monthformat="%Y-%m")

#Use the month in which the Monday falls:
yw.to.month(yw, monthformat="%Y-%m", weekday=1)



Steve E








*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From highstat at highstat.com  Wed Jan 18 14:20:05 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 18 Jan 2017 13:20:05 +0000
Subject: [R] Stats course on Crete
Message-ID: <e98a825a-a92e-2b34-5e68-19311e08373e@highstat.com>


We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with R

Where:  HCMR, Crete, Greece

When:   24-28 April 2017

Course website: http://www.highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_04Crete_RGG.pdf


Kind regards,

Alain Zuur


Other open courses in 2017:

Introduction to Regression Models with Spatial and Temporal Correlation. 
8-12 May 2017. Genoa, Italy.
Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian 
approaches. 9-13 October 2017. Trondheim, Norway.
Introduction to Regression Models with Spatial and Temporal Correlation. 
23-27 October 2017. Southampton, UK
Data exploration, regression, GLM & GAM with introduction to R. 18-22 
September 2017. Edmonton, Canada.
Introduction to Regression Models with Spatial and Temporal Correlation. 
4-8 December 2017. Banff, Canada.


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From payneb at post.bgu.ac.il  Wed Jan 18 10:57:10 2017
From: payneb at post.bgu.ac.il (Brandon Payne)
Date: Wed, 18 Jan 2017 11:57:10 +0200
Subject: [R] can this be simplified with purrr:map or mapply?
Message-ID: <CAN4m+BKxY1CjW+J6svZcsTusd-K7ATRScZpu1y5XDngi8pBuuw@mail.gmail.com>

I can't get my head around the *apply family of functions,
surely there's a better way than what I have.
I've tried using paste0 on the years, but then I have lists of strings, not
data frames.

`realList<-paste0("exp",as.character(2004:2014),"s")`

I can't seem to convert these lists of strings to references to data frames.

years<-c(2004:2014)
framesEXP<-list(exp2004s,exp2005s,exp2006s,exp2007s,exp2008s,exp2009s,exp2011s,exp2010s,exp2012s,exp2013s,exp2014s)

framesFAM<-list(fam2004s,fam2005s,fam2006s,fam2007s,fam2008s,fam2009s,fam2011s,fam2010s,fam2012s,fam2013s,fam2014s)

data2004<<-merge(exp2004s,fam2004s, by="HHNUM")
data2005<<-merge(exp2005s,fam2005s, by="HHNUM")
data2006<<-merge(exp2006s,fam2006s, by="HHNUM")
data2007<<-merge(exp2007s,fam2007s, by="HHNUM")
data2008<<-merge(exp2008s,fam2008s, by="HHNUM")
data2009<<-merge(exp2009s,fam2009s, by="HHNUM")
data2010<<-merge(exp2010s,fam2010s, by="HHNUM")
data2011<<-merge(exp2011s,fam2011s, by="HHNUM")
data2012<<-merge(exp2012s,fam2012s, by="HHNUM")
data2013<<-merge(exp2013s,fam2013s, by="HHNUM")
data2014<<-merge(exp2014s,fam2014s, by="HHNUM")

dput(data2004, file="../dataframes/data2004.txt")
dput(data2005, file="../dataframes/data2005.txt")
dput(data2006, file="../dataframes/data2006.txt")
dput(data2007, file="../dataframes/data2007.txt")
dput(data2008, file="../dataframes/data2008.txt")
dput(data2009, file="../dataframes/data2009.txt")
dput(data2010, file="../dataframes/data2010.txt")
dput(data2011, file="../dataframes/data2011.txt")
dput(data2012, file="../dataframes/data2012.txt")
dput(data2013, file="../dataframes/data2013.txt")
dput(data2014, file="../dataframes/data2014.txt")

	[[alternative HTML version deleted]]


From tamildee at gmail.com  Wed Jan 18 09:09:48 2017
From: tamildee at gmail.com (Edward Tamil)
Date: Wed, 18 Jan 2017 13:39:48 +0530
Subject: [R] Fwd: Need help in exporting R apriori rules to Excel
In-Reply-To: <CAAdgFSrHZur6ywhL2Oh2KhJaVXn7C4usUic68NyY11aWWSjpNg@mail.gmail.com>
References: <CAAdgFSrHZur6ywhL2Oh2KhJaVXn7C4usUic68NyY11aWWSjpNg@mail.gmail.com>
Message-ID: <CAAdgFSrP_=OyMxGtRbjNh7qsScquzQzFbUgcjisDcUXRr5Zy5A@mail.gmail.com>

Hi Sir,


Need help in exporting R apriori rules to Excel. i tried write.csv
write.table write.csv2

only exporting less than 500 rules.

unable to export Large Data.


" No Error Msg" File size is "0"

-- 

*Edward *






-- 
-- 
*Regards * *:)*

*Edward Tamil.S *

	[[alternative HTML version deleted]]


From tgramer at z.zgs.de  Wed Jan 18 10:57:49 2017
From: tgramer at z.zgs.de (tgramer at z.zgs.de)
Date: Wed, 18 Jan 2017 10:57:49 +0100
Subject: [R] Smoothing a Time Series
Message-ID: <3A1D5ABD-85BD-423E-9B08-B13AD30AA5D0@z.zgs.de>

Dear R-Team,

i only want to smooth a time series with a Kalmen Filter in R (KFAS).

I found code in the Internet, which I had to change a little bit.

Now I get the following error-message. I don?t know what I have

to do now.

Fehler in is.SSModel(do.call(updatefn, args = c(list(inits, model), update_args)),  : 
  Storage mode of some of the model attributes 'p', 'k', 'm', 'n', 'tv' is not integer.

Thank you very much.

Sincerely

Tobias Gramer




 library(KFAS)
 library(tseries)

 library(timeSeries)

 library(timeDate)
 library(zoo)

 library(quantmod)
 library(xts)
 library(TTR)
 
getDailyPrices=function(tickerSym,startDate,endDate)
{
  prices=c(1318,518,2320,6528,10831,5135,2700,687,7499,790,4524,3686,1677,809,9153,2032,3558,1880,2266,7230,3641,7429,3361,3803,2215,2066,709,1695,4061,150,1555,508,6497,563,1944,1600,4428,3325,10971,3253,1274,2915,1128,588,1600,5837,1760,4196,2103,3658,1600,1288)
  prices.ts=ts(prices)
  return(prices.ts) 	
  
}

kalmanFilter=function(x)
{
   t=x
   if (class(t)!="ts") {
     t=ts(t)
   }
   
   ssModel=structSSM(y=t,distribution=?Gaussian")

   ssFit=fitSSM(inits=c(0.5*log(var(t)),0.5*log(var(t))),model=ssModel)
   kfs=KFS(ssFit$model,smoothing="state",nsim=length(t))
   vals=kfs$a
   lastVal=vals[length(vals)]
   return(lastVal)
}


 Start="2011-01-01"
 End=  "2012-12-31"
 SandP="^GSPC"
 windowWidth=20
 tsLength=52
 SAndP.ts=getDailyPrices(SandP,Start,End)

 SAndP.smoothed=rollapply(data=SAndP.ts,width=windowWidth,FUN=kalmanFilter)
 
 par(mfrow=c(1,1))
 prices=coredata(SAndP.ts[windowWidth:length(SAndP.ts)])
 plot(prices,col="blue",type="l")
 lines(coredata(SAndP.smoothed),col="magenta")
 par(mfrow=c(1,1))
 
 
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Jan 18 15:14:04 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 18 Jan 2017 09:14:04 -0500
Subject: [R] Fwd: Need help in exporting R apriori rules to Excel
In-Reply-To: <CAAdgFSrP_=OyMxGtRbjNh7qsScquzQzFbUgcjisDcUXRr5Zy5A@mail.gmail.com>
References: <CAAdgFSrHZur6ywhL2Oh2KhJaVXn7C4usUic68NyY11aWWSjpNg@mail.gmail.com>
	<CAAdgFSrP_=OyMxGtRbjNh7qsScquzQzFbUgcjisDcUXRr5Zy5A@mail.gmail.com>
Message-ID: <CAM_vju=F9y-YVaqTAN66pbwi-wm3D+FUjG85A+4cf5rmE176dg@mail.gmail.com>

I believe you need to convert them to a data frame before you can use
any data frame export functions to save them to disk. See ?as

I'm assuming that you are using the arules package; your question is incomplete.

I've never used arules myself; I googled "rhelp export apriori rules"

Sarah

On Wed, Jan 18, 2017 at 3:09 AM, Edward Tamil <tamildee at gmail.com> wrote:
> Hi Sir,
>
>
> Need help in exporting R apriori rules to Excel. i tried write.csv
> write.table write.csv2
>
> only exporting less than 500 rules.
>
> unable to export Large Data.
>
>
> " No Error Msg" File size is "0"
>
> --
>
> *Edward *
>
>
>
>
>


From erich.subs at neuwirth.priv.at  Wed Jan 18 15:19:13 2017
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Wed, 18 Jan 2017 15:19:13 +0100
Subject: [R] can this be simplified with purrr:map or mapply?
In-Reply-To: <CAN4m+BKxY1CjW+J6svZcsTusd-K7ATRScZpu1y5XDngi8pBuuw@mail.gmail.com>
References: <CAN4m+BKxY1CjW+J6svZcsTusd-K7ATRScZpu1y5XDngi8pBuuw@mail.gmail.com>
Message-ID: <F4CB8090-A99E-4570-A29F-885D519E43F8@neuwirth.priv.at>

Look up get and mget in the docs.

> On 18 Jan 2017, at 10:57, Brandon Payne <payneb at post.bgu.ac.il> wrote:
> 
> I can't get my head around the *apply family of functions,
> surely there's a better way than what I have.
> I've tried using paste0 on the years, but then I have lists of strings, not
> data frames.
> 
> `realList<-paste0("exp",as.character(2004:2014),"s")`
> 
> I can't seem to convert these lists of strings to references to data frames.
> 
> years<-c(2004:2014)
> framesEXP<-list(exp2004s,exp2005s,exp2006s,exp2007s,exp2008s,exp2009s,exp2011s,exp2010s,exp2012s,exp2013s,exp2014s)
> 
> framesFAM<-list(fam2004s,fam2005s,fam2006s,fam2007s,fam2008s,fam2009s,fam2011s,fam2010s,fam2012s,fam2013s,fam2014s)
> 
> data2004<<-merge(exp2004s,fam2004s, by="HHNUM")
> data2005<<-merge(exp2005s,fam2005s, by="HHNUM")
> data2006<<-merge(exp2006s,fam2006s, by="HHNUM")
> data2007<<-merge(exp2007s,fam2007s, by="HHNUM")
> data2008<<-merge(exp2008s,fam2008s, by="HHNUM")
> data2009<<-merge(exp2009s,fam2009s, by="HHNUM")
> data2010<<-merge(exp2010s,fam2010s, by="HHNUM")
> data2011<<-merge(exp2011s,fam2011s, by="HHNUM")
> data2012<<-merge(exp2012s,fam2012s, by="HHNUM")
> data2013<<-merge(exp2013s,fam2013s, by="HHNUM")
> data2014<<-merge(exp2014s,fam2014s, by="HHNUM")
> 
> dput(data2004, file="../dataframes/data2004.txt")
> dput(data2005, file="../dataframes/data2005.txt")
> dput(data2006, file="../dataframes/data2006.txt")
> dput(data2007, file="../dataframes/data2007.txt")
> dput(data2008, file="../dataframes/data2008.txt")
> dput(data2009, file="../dataframes/data2009.txt")
> dput(data2010, file="../dataframes/data2010.txt")
> dput(data2011, file="../dataframes/data2011.txt")
> dput(data2012, file="../dataframes/data2012.txt")
> dput(data2013, file="../dataframes/data2013.txt")
> dput(data2014, file="../dataframes/data2014.txt")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Jan 18 16:07:11 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 18 Jan 2017 15:07:11 +0000
Subject: [R] can this be simplified with purrr:map or mapply?
In-Reply-To: <CAN4m+BKxY1CjW+J6svZcsTusd-K7ATRScZpu1y5XDngi8pBuuw@mail.gmail.com>
References: <CAN4m+BKxY1CjW+J6svZcsTusd-K7ATRScZpu1y5XDngi8pBuuw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE672@SRVEXCHCM301.precheza.cz>

Hi

Let me make some assumptions. Your data are stored as *txt files somewhere.

I would start with vector of file names

fil<-paste0("data",2004:2014,".txt")
> fil
 [1] "data2004.txt" "data2005.txt" "data2006.txt" "data2007.txt" "data2008.txt"
 [6] "data2009.txt" "data2010.txt" "data2011.txt" "data2012.txt" "data2013.txt"
[11] "data2014.txt"

than I would read my files into predefined list

mylist<-vector(length=11, mode="list")

You can add names to this list by
names(mylist) <- fil

Than simple cycle

for (i in seq_along(fil)) {

mylist[[i]] <- read.table(fil[i])

... you could also do some polishing of single files here
}

Now you have list of data frames and you can do many operations on this whole list instead on separate data frames.

Further operations depend on structure of your data frames and your exact intention what do you want to do with them.

I wonder why merge is appropriate if you have separate data for each year. Why not to use rbind followed by aggregate.

But here I am fishing in really murky water.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brandon
> Payne
> Sent: Wednesday, January 18, 2017 10:57 AM
> To: r-help at r-project.org
> Subject: [R] can this be simplified with purrr:map or mapply?
>
> I can't get my head around the *apply family of functions,
> surely there's a better way than what I have.
> I've tried using paste0 on the years, but then I have lists of strings, not
> data frames.
>
> `realList<-paste0("exp",as.character(2004:2014),"s")`
>
> I can't seem to convert these lists of strings to references to data frames.
>
> years<-c(2004:2014)
> framesEXP<-
> list(exp2004s,exp2005s,exp2006s,exp2007s,exp2008s,exp2009s,exp2011s,ex
> p2010s,exp2012s,exp2013s,exp2014s)
>
> framesFAM<-
> list(fam2004s,fam2005s,fam2006s,fam2007s,fam2008s,fam2009s,fam2011s,fa
> m2010s,fam2012s,fam2013s,fam2014s)
>
> data2004<<-merge(exp2004s,fam2004s, by="HHNUM")
> data2005<<-merge(exp2005s,fam2005s, by="HHNUM")
> data2006<<-merge(exp2006s,fam2006s, by="HHNUM")
> data2007<<-merge(exp2007s,fam2007s, by="HHNUM")
> data2008<<-merge(exp2008s,fam2008s, by="HHNUM")
> data2009<<-merge(exp2009s,fam2009s, by="HHNUM")
> data2010<<-merge(exp2010s,fam2010s, by="HHNUM")
> data2011<<-merge(exp2011s,fam2011s, by="HHNUM")
> data2012<<-merge(exp2012s,fam2012s, by="HHNUM")
> data2013<<-merge(exp2013s,fam2013s, by="HHNUM")
> data2014<<-merge(exp2014s,fam2014s, by="HHNUM")
>
> dput(data2004, file="../dataframes/data2004.txt")
> dput(data2005, file="../dataframes/data2005.txt")
> dput(data2006, file="../dataframes/data2006.txt")
> dput(data2007, file="../dataframes/data2007.txt")
> dput(data2008, file="../dataframes/data2008.txt")
> dput(data2009, file="../dataframes/data2009.txt")
> dput(data2010, file="../dataframes/data2010.txt")
> dput(data2011, file="../dataframes/data2011.txt")
> dput(data2012, file="../dataframes/data2012.txt")
> dput(data2013, file="../dataframes/data2013.txt")
> dput(data2014, file="../dataframes/data2014.txt")
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From michael.eisenring at agroscope.admin.ch  Wed Jan 18 18:00:08 2017
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Wed, 18 Jan 2017 17:00:08 +0000
Subject: [R] non-parametric manova with post-hoc test
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD0513EF96@SB00112A.adb.intra.admin.ch>

Good day,
I am looking for a way to perform a non parametric manova and to analyze the result using post-hoc tests (an equivalent of the kruskal wallis test for anova)

In my book (discovering statistic using R) two tests are described Munzel and Brunners method (mulrank) and Choi and Mardens test (cmanova). Both are from the package WRS which unfortunately does not exist anymore (and WRS2 is not containing these tests). Furthermore the test do to my knowledge not allow post-hoc analyses-

I would be grateful for your help

Best,
Mike

Eisenring Michael, Msc.
PhD Student

Federal Department of Economic Affairs, Education and Research
EAER
Agroecology and Environment
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 44 37 77181
Fax +41 44 37 77201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Wed Jan 18 18:03:40 2017
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 18 Jan 2017 12:03:40 -0500
Subject: [R] R studio server vs R server and Small computer to run R
Message-ID: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>

Please forgive my resending this help request. I sent it two days ago. To date I have not received any responses.
Thank you,
John
 
 
I am looking for a small computer low power that I make available on the web that will run R studio server or R server

1) can anyone recommend a computer?

2) can anyone let me know the advantages and disadvantages of R studio server and R server?

Thank you

John


John David Sorkin M.D., Ph.D.

Professor of Medicine

Chief, Biostatistics and Informatics


University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine


Baltimore VA Medical Center


10 North Greene Street


GRECC (BT/18/GR)


Baltimore, MD 21201-1524


(Phone) 410-605-7119

(Fax) 410-605-7913 (Please call phone number above prior to faxing)
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From marc_schwartz at me.com  Wed Jan 18 18:11:52 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 18 Jan 2017 11:11:52 -0600
Subject: [R] R studio server vs R server and Small computer to run R
In-Reply-To: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>
References: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>
Message-ID: <D65F7756-3EA5-4E0B-A67B-4DBCA9C308F0@me.com>


> On Jan 18, 2017, at 11:03 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> Please forgive my resending this help request. I sent it two days ago. To date I have not received any responses.
> Thank you,
> John
> 
> 
> I am looking for a small computer low power that I make available on the web that will run R studio server or R server
> 
> 1) can anyone recommend a computer?
> 
> 2) can anyone let me know the advantages and disadvantages of R studio server and R server?
> 
> Thank you
> 
> John
> 


John,

I missed your first post on this, but I suspect that the lack of replies here is due to R Studio having their own support venue:
 
  https://support.rstudio.com/hc/en-us

and that your query is likely best posted directly to them, since this is not strictly an R question, per se, thus technically off-topic for R-Help.

Regards,

Marc Schwartz


From cadeb at usgs.gov  Wed Jan 18 18:20:05 2017
From: cadeb at usgs.gov (Cade, Brian)
Date: Wed, 18 Jan 2017 10:20:05 -0700
Subject: [R] non-parametric manova with post-hoc test
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD0513EF96@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD0513EF96@SB00112A.adb.intra.admin.ch>
Message-ID: <CAM5M9BQEthYSTtQWW3fgKAztb22oiC=YAJtBQVSUoit6V3oFNQ@mail.gmail.com>

You could try a multi-response permutation procedure (MRPP) for
multivariate hypothesis testing (null is groups come from a common
distribution) without resorting to ranks.  There are no automated multiple
comparison procedures, but one could either look at pairwise contrasts of
group (if that is what you are implying by post-hoc testing) with some sort
of correction procedure for multiple comparisons (e.g., Holm's sequential
procedure).  Or similarly, comparisons with different subsets of the
multivariate outcome variables (again, adjusting for multiple comparisons)
across the grouping structure.  There are several R packages that I think
implement MRPP but the Blossom package might be one of the better
implementations in terms of alternatives provided (including permutation
version of Hotelling's test).

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Wed, Jan 18, 2017 at 10:00 AM, <michael.eisenring at agroscope.admin.ch>
wrote:

> Good day,
> I am looking for a way to perform a non parametric manova and to analyze
> the result using post-hoc tests (an equivalent of the kruskal wallis test
> for anova)
>
> In my book (discovering statistic using R) two tests are described Munzel
> and Brunners method (mulrank) and Choi and Mardens test (cmanova). Both are
> from the package WRS which unfortunately does not exist anymore (and WRS2
> is not containing these tests). Furthermore the test do to my knowledge not
> allow post-hoc analyses-
>
> I would be grateful for your help
>
> Best,
> Mike
>
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Agroecology and Environment
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:michael.
> eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Jan 18 18:32:54 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 18 Jan 2017 17:32:54 +0000
Subject: [R] can this be simplified with purrr:map or mapply?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE672@SRVEXCHCM301.precheza.cz>
References: <CAN4m+BKxY1CjW+J6svZcsTusd-K7ATRScZpu1y5XDngi8pBuuw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FE672@SRVEXCHCM301.precheza.cz>
Message-ID: <CAKVAULNMLRrS7TLE4SQBAvLz-pk-=YTvjnFGvXwqiKV3DjbXvw@mail.gmail.com>

If you want to use purrr, you could do

fil <- paste0("data",2004:2014,".txt")
map_df(fil, read.table, .id = "fil")

to get everything in one data frame (I assume all files have the same
structure)

HTH
Ulrik

On Wed, 18 Jan 2017 at 16:10 PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Let me make some assumptions. Your data are stored as *txt files somewhere.
>
> I would start with vector of file names
>
> fil<-paste0("data",2004:2014,".txt")
> > fil
>  [1] "data2004.txt" "data2005.txt" "data2006.txt" "data2007.txt"
> "data2008.txt"
>  [6] "data2009.txt" "data2010.txt" "data2011.txt" "data2012.txt"
> "data2013.txt"
> [11] "data2014.txt"
>
> than I would read my files into predefined list
>
> mylist<-vector(length=11, mode="list")
>
> You can add names to this list by
> names(mylist) <- fil
>
> Than simple cycle
>
> for (i in seq_along(fil)) {
>
> mylist[[i]] <- read.table(fil[i])
>
> ... you could also do some polishing of single files here
> }
>
> Now you have list of data frames and you can do many operations on this
> whole list instead on separate data frames.
>
> Further operations depend on structure of your data frames and your exact
> intention what do you want to do with them.
>
> I wonder why merge is appropriate if you have separate data for each year.
> Why not to use rbind followed by aggregate.
>
> But here I am fishing in really murky water.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brandon
> > Payne
> > Sent: Wednesday, January 18, 2017 10:57 AM
> > To: r-help at r-project.org
> > Subject: [R] can this be simplified with purrr:map or mapply?
> >
> > I can't get my head around the *apply family of functions,
> > surely there's a better way than what I have.
> > I've tried using paste0 on the years, but then I have lists of strings,
> not
> > data frames.
> >
> > `realList<-paste0("exp",as.character(2004:2014),"s")`
> >
> > I can't seem to convert these lists of strings to references to data
> frames.
> >
> > years<-c(2004:2014)
> > framesEXP<-
> > list(exp2004s,exp2005s,exp2006s,exp2007s,exp2008s,exp2009s,exp2011s,ex
> > p2010s,exp2012s,exp2013s,exp2014s)
> >
> > framesFAM<-
> > list(fam2004s,fam2005s,fam2006s,fam2007s,fam2008s,fam2009s,fam2011s,fa
> > m2010s,fam2012s,fam2013s,fam2014s)
> >
> > data2004<<-merge(exp2004s,fam2004s, by="HHNUM")
> > data2005<<-merge(exp2005s,fam2005s, by="HHNUM")
> > data2006<<-merge(exp2006s,fam2006s, by="HHNUM")
> > data2007<<-merge(exp2007s,fam2007s, by="HHNUM")
> > data2008<<-merge(exp2008s,fam2008s, by="HHNUM")
> > data2009<<-merge(exp2009s,fam2009s, by="HHNUM")
> > data2010<<-merge(exp2010s,fam2010s, by="HHNUM")
> > data2011<<-merge(exp2011s,fam2011s, by="HHNUM")
> > data2012<<-merge(exp2012s,fam2012s, by="HHNUM")
> > data2013<<-merge(exp2013s,fam2013s, by="HHNUM")
> > data2014<<-merge(exp2014s,fam2014s, by="HHNUM")
> >
> > dput(data2004, file="../dataframes/data2004.txt")
> > dput(data2005, file="../dataframes/data2005.txt")
> > dput(data2006, file="../dataframes/data2006.txt")
> > dput(data2007, file="../dataframes/data2007.txt")
> > dput(data2008, file="../dataframes/data2008.txt")
> > dput(data2009, file="../dataframes/data2009.txt")
> > dput(data2010, file="../dataframes/data2010.txt")
> > dput(data2011, file="../dataframes/data2011.txt")
> > dput(data2012, file="../dataframes/data2012.txt")
> > dput(data2013, file="../dataframes/data2013.txt")
> > dput(data2014, file="../dataframes/data2014.txt")
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From janko.thyson at gmail.com  Wed Jan 18 19:28:33 2017
From: janko.thyson at gmail.com (Janko Thyson)
Date: Wed, 18 Jan 2017 19:28:33 +0100
Subject: [R] Match ISO 8601 week-of-year numbers to month-of-year
 numbers on Windows with German locale
In-Reply-To: <1A8C1289955EF649A09086A153E2672404E3A709D8@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAGmpueijhCKbmrNx=Vs-x+39a5pJmfH1Z4mvxh0TSm1qeFZ=fw@mail.gmail.com>
	<DC2EFBD8-3419-4719-BA6D-B6704C3023B1@comcast.net>
	<CAGmpuejra4=+PCpUs3eAWuzkgMc4HP-WVXpmbj0XGYmBtErKoA@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672404E3A709D8@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAGmpuehonXLHTnPAT0o4BKDN-oQXCHsSTzh4qEv4cR7Z7PJYVg@mail.gmail.com>

Hi Steve,

and thanks so much for taking the time to draft your solution! After
running through it looks like it's EXACTLY what I was looking/hoping
for!

For those interested: I also tried to get this in as a feature request
for the lubridate package >>
https://github.com/hadley/lubridate/issues/506

Here's to open source, social coding and our active user community! :-)

Janko

On Wed, Jan 18, 2017 at 1:35 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
>
>> -----Original Message-----
>> (yw <- format(posix, "%Y-%V"))
>> > # [1] "2015-52" "2015-53" "2016-53" "2016-01"
>>
>> Which, after checking back with a calendar, would give me reason to believe
>> that it using %V does in fact seem to work: it's an input to `format()` and R
>> doesn't seem to ignore it as the correct week numbers (following ISO 8601)
>> are returned.
>
> Unfortunately it does _not_ work as an input to strptime() or as.Date(). Try
> strptime(sprintf("2016-%02d", 1:52), "%Y-%V")
>
> which all return the same (rather arbitrary-looking) date. (R 3.3.1 on Windows 7)
>
> So you can easily extract the week number from a date, but you can't extract the month number from a week number using base R.
>
> What you _could_ do is assign an appropriate weekday in each week and use that day to assign a month. Using the 8601 rules, Thursday seems sensible as that is the weekday used to define the week number. The following crude implementation (which allows some variation in the input string and a custom weekday defaulting to Thursday) seems to work in my UK locale, though I've not spent a lot of time debugging. You should be able to get it to work with minimal tweaking in another locale:
>
> yw.to.month <- function(yw, yearformat="%Y", separator="-", monthformat="%m", weekday=4) {
>         # yw  is a character vector assumed to be in %Y-%W" or "%y-%W"
>         #     form (or with another separator specified by separator)
>         # yearformat is a character string used by as.Date to convert the year.
>         # separator is the year-week separator string in yw
>         # monthformat is the output format, passed to format.Date
>         # weekday is the (numerica) day of the week to be used to place the week
>         #         in a specific month. The default, 4, takes the Thursday.
>
>
>         #Get the year as a character vector
>         Y <- format(as.Date(yw, yearformat), "%Y")
>
>         #Get the date of the first thursday in each year
>         Jan01 <- as.Date(sprintf("%s-01-01", Y), "%Y-%m-%d") #constructs 1st Jan for each year
>         J1.w <- as.numeric( format(Jan01, "%w") ) #numerical day of week for jan 1st
>         date.increment <- ifelse(J1.w > weekday, 7 + weekday - J1.w, weekday - J1.w) #How far to first thursday?
>         Thursday1 <- as.Date( Jan01 + date.increment ) #date for first thursday
>
>         #Add the week number in yw to get the corresponding Thursday's date
>         wknum <- as.numeric( gsub(sprintf(".+%s(.+)", separator), "\\1", yw) )
>         Thursdays <- Thursday1 + 7 * (wknum - 1)
>
>         #... and convert each Thursday date to month number
>         # using supplied monthformat
>
>         format( Thursdays, monthformat )
> }
>
> #Examples
> #Construct a collection of "YYYY-WW" strings:
> yw <- sprintf("%4d-%02d", rep(2015:2017, each=53), rep(1:53, 3))
>         #NB: Week 53 does not exist in all years. e.g 'week 53' of 2016 is week 1 of 2017.
>         #But the week number is just used as an offset from the first specified weekday,
>         #so the function does returns a valid year and month if the week number is
>         #after the year end.
>
> yw.to.month(yw)
>
> yw.to.month(yw, monthformat="%Y-%m")
>
> #Use the month in which the Monday falls:
> yw.to.month(yw, monthformat="%Y-%m", weekday=1)
>
>
>
> Steve E
>
>
>
>
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From agingadvice at gmail.com  Wed Jan 18 19:35:31 2017
From: agingadvice at gmail.com (Josh Mitteldorf)
Date: Wed, 18 Jan 2017 13:35:31 -0500
Subject: [R] PCA in Q- and R-modes
Message-ID: <CAMVOpmPEoxKFn-Xmx01gWr0yqi3ubmbm75WstENM_7ot3ACSew@mail.gmail.com>

I'm working with proteomic data, helping a student who knows biology and
has done analysis in R without understanding it in depth.

We have 3000 protein levels for 6 ages.  I can treat this as 6 vectors in
3000-dimensional space, diagonalize a 6x6 covariance matrix and find 5
principal components, one zero eigenvalue.  My student has worked with R in
"Q mode" and he enters the transposed matrix as 3000 vectors in
6-dimensional space.  In just a few seconds, R diagonalizes a 3000x3000
matrix!  I can't imagine what that means, to diagonalize a 3000x3000
matrix.  But, of course, there are only 5 degrees of freedom in the data,
so only 5 of the eigenvalues are non-zero, and the other 2995 vectors are
junk.

   Questions:  a) Is there a relationship between the principal components
of the 3000*6 matrix and the principal components of the transposed 6*3000
matrix?
                     b) Is there a way to find the 5 meaningful
eigenvectors without carrying the baggage of diagonalizing the huge
3000-dimensional matrix?
                     c) The big question is which version to analyze and
publish? My student tells me the transposed matrix is the common
procedure.  The two yield very different-looking plots.

Thanks for your help.
- Josh Mitteldorf

	[[alternative HTML version deleted]]


From jake.andrae at adelaide.edu.au  Thu Jan 19 01:44:36 2017
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Thu, 19 Jan 2017 00:44:36 +0000
Subject: [R] Superscript in graph text
Message-ID: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>

Hello,


I've added some statistical information as text to some graphs, but I'm having a really hard time making the 2 in the R2 label superscript. Does anyone have any suggestions?


mtext(paste("R2 = ", R2), adj=0, line=1, col="black", cex=0.7)


Kind regards


Jake Andrae
PhD Candidate
Geology & Geophysics - Sprigg Geobiology Centre
Department of Earth Science
School of Physical Sciences
The University of Adelaide, AUSTRALIA 5005
Phone: 0407701565
Email: jake.andrae at adelaide.edu.au


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jan 19 01:59:25 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 18 Jan 2017 16:59:25 -0800
Subject: [R] Superscript in graph text
In-Reply-To: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>
References: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>
Message-ID: <CAGxFJbQnyAjwWf=26Wro0Vz=V=oUN8osJZG946bxDbvZCzvXXg@mail.gmail.com>

?plotmath

Yes, you will have to put in some effort if you want to use these
sorts of latex-like math expressions as labels in your graphs.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 18, 2017 at 4:44 PM, Jake William Andrae
<jake.andrae at adelaide.edu.au> wrote:
> Hello,
>
>
> I've added some statistical information as text to some graphs, but I'm having a really hard time making the 2 in the R2 label superscript. Does anyone have any suggestions?
>
>
> mtext(paste("R2 = ", R2), adj=0, line=1, col="black", cex=0.7)
>
>
> Kind regards
>
>
> Jake Andrae
> PhD Candidate
> Geology & Geophysics - Sprigg Geobiology Centre
> Department of Earth Science
> School of Physical Sciences
> The University of Adelaide, AUSTRALIA 5005
> Phone: 0407701565
> Email: jake.andrae at adelaide.edu.au
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Thu Jan 19 02:00:13 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 18 Jan 2017 20:00:13 -0500
Subject: [R] Superscript in graph text
In-Reply-To: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>
References: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>
Message-ID: <CAGx1TMDwUawM_csqDM8i4QHopfoJA_VvKfmAH=3v8Cx7AVsvnA@mail.gmail.com>

?plotmath


plot(1:10, main=expression(R^2))

plot(1:10, main=bquote(R^2 * "=" * .(x)))

On Wed, Jan 18, 2017 at 7:44 PM, Jake William Andrae
<jake.andrae at adelaide.edu.au> wrote:
> Hello,
>
>
> I've added some statistical information as text to some graphs, but I'm having a really hard time making the 2 in the R2 label superscript. Does anyone have any suggestions?
>
>
> mtext(paste("R2 = ", R2), adj=0, line=1, col="black", cex=0.7)
>
>
> Kind regards
>
>
> Jake Andrae
> PhD Candidate
> Geology & Geophysics - Sprigg Geobiology Centre
> Department of Earth Science
> School of Physical Sciences
> The University of Adelaide, AUSTRALIA 5005
> Phone: 0407701565
> Email: jake.andrae at adelaide.edu.au
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Thu Jan 19 02:00:38 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 18 Jan 2017 20:00:38 -0500
Subject: [R] Superscript in graph text
In-Reply-To: <CAGx1TMDwUawM_csqDM8i4QHopfoJA_VvKfmAH=3v8Cx7AVsvnA@mail.gmail.com>
References: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>
	<CAGx1TMDwUawM_csqDM8i4QHopfoJA_VvKfmAH=3v8Cx7AVsvnA@mail.gmail.com>
Message-ID: <CAGx1TMCsXEmp_CCwK8NUsnngMqyB2GY_h7foxgz+Yxx7P9eHOQ@mail.gmail.com>

x <- 10
plot(1:10, main=bquote(R^2 * "=" * .(x)))

On Wed, Jan 18, 2017 at 8:00 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> ?plotmath
>
>
> plot(1:10, main=expression(R^2))
>
> plot(1:10, main=bquote(R^2 * "=" * .(x)))
>
> On Wed, Jan 18, 2017 at 7:44 PM, Jake William Andrae
> <jake.andrae at adelaide.edu.au> wrote:
>> Hello,
>>
>>
>> I've added some statistical information as text to some graphs, but I'm having a really hard time making the 2 in the R2 label superscript. Does anyone have any suggestions?
>>
>>
>> mtext(paste("R2 = ", R2), adj=0, line=1, col="black", cex=0.7)
>>
>>
>> Kind regards
>>
>>
>> Jake Andrae
>> PhD Candidate
>> Geology & Geophysics - Sprigg Geobiology Centre
>> Department of Earth Science
>> School of Physical Sciences
>> The University of Adelaide, AUSTRALIA 5005
>> Phone: 0407701565
>> Email: jake.andrae at adelaide.edu.au
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jan 19 02:02:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 18 Jan 2017 17:02:26 -0800
Subject: [R] PCA in Q- and R-modes
In-Reply-To: <CAMVOpmPEoxKFn-Xmx01gWr0yqi3ubmbm75WstENM_7ot3ACSew@mail.gmail.com>
References: <CAMVOpmPEoxKFn-Xmx01gWr0yqi3ubmbm75WstENM_7ot3ACSew@mail.gmail.com>
Message-ID: <CAGxFJbTk+_1DrbN5o+mqaWoGdxiNr41kDF6sukvc=p1nHZY4RQ@mail.gmail.com>

Off topic for this list.

Post on stats.stackexchange.com or similar for statistics questions.

Post on Bioconductor list for biology-related (e.g. proteomics) data
anaysis questions.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 18, 2017 at 10:35 AM, Josh Mitteldorf <agingadvice at gmail.com> wrote:
> I'm working with proteomic data, helping a student who knows biology and
> has done analysis in R without understanding it in depth.
>
> We have 3000 protein levels for 6 ages.  I can treat this as 6 vectors in
> 3000-dimensional space, diagonalize a 6x6 covariance matrix and find 5
> principal components, one zero eigenvalue.  My student has worked with R in
> "Q mode" and he enters the transposed matrix as 3000 vectors in
> 6-dimensional space.  In just a few seconds, R diagonalizes a 3000x3000
> matrix!  I can't imagine what that means, to diagonalize a 3000x3000
> matrix.  But, of course, there are only 5 degrees of freedom in the data,
> so only 5 of the eigenvalues are non-zero, and the other 2995 vectors are
> junk.
>
>    Questions:  a) Is there a relationship between the principal components
> of the 3000*6 matrix and the principal components of the transposed 6*3000
> matrix?
>                      b) Is there a way to find the 5 meaningful
> eigenvectors without carrying the baggage of diagonalizing the huge
> 3000-dimensional matrix?
>                      c) The big question is which version to analyze and
> publish? My student tells me the transposed matrix is the common
> procedure.  The two yield very different-looking plots.
>
> Thanks for your help.
> - Josh Mitteldorf
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jake.andrae at adelaide.edu.au  Thu Jan 19 03:48:06 2017
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Thu, 19 Jan 2017 02:48:06 +0000
Subject: [R] Superscript in graph text
In-Reply-To: <CAGx1TMB_zqa-d8f=Og1L0+C8FJbFEou002-50_bWxvkLFw0V-A@mail.gmail.com>
References: <SY3PR01MB20749CB185EC08C3860C326BA97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>
	<CAGx1TMDwUawM_csqDM8i4QHopfoJA_VvKfmAH=3v8Cx7AVsvnA@mail.gmail.com>
	<CAGx1TMCsXEmp_CCwK8NUsnngMqyB2GY_h7foxgz+Yxx7P9eHOQ@mail.gmail.com>
	<SY3PR01MB2074207E7A27F300DAC13F80A97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>,
	<CAGx1TMB_zqa-d8f=Og1L0+C8FJbFEou002-50_bWxvkLFw0V-A@mail.gmail.com>
Message-ID: <SY3PR01MB2074D8AB9B980E70AAB633F9A97E0@SY3PR01MB2074.ausprd01.prod.outlook.com>

Thank you, your suggestions are very helpful. As I said, I'm a novice to R and this list, and it's hard for me to decipher exactly what is required; I was really hoping for some basic script formatting guidance (which was given and appreciated).


Jake Andrae
PhD Candidate
Geology & Geophysics ? Sprigg Geobiology Centre
Department of Earth Science
School of Physical Sciences
The University of Adelaide, AUSTRALIA 5005
Phone: 0407701565
Email: jake.andrae at adelaide.edu.au



________________________________
From: Richard M. Heiberger <rmh at temple.edu>
Sent: Thursday, 19 January 2017 12:58 PM
To: Jake William Andrae
Subject: Re: [R] Superscript in graph text

your example is not reproducible because I don't have your dataset.
Please re-read the notes
at the bottom of every R-help email
   PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
   and provide commented, minimal, self-contained, reproducible code.

The convention on this email list is to always stay on the list.  It
is not good form to
write only to the person who replies to you and the list.

For base graphics, you can use an expression or bquote in any of the
annotation arguments or functions.
I showed you a use in main=.  It works the same for all others.



plot(1:10)
p <- .4
R2 <- .9876
mtext(bquote(p * " = " * .(p)), adj=0, line=0.1, col="black", cex=0.7)
mtext(bquote(R^2 * " =" * .(R2)), adj=0, line=1, col="black", cex=0.7)

## Using mtext doesn't look like a good idea.
## use sub or main or some other keywords

title(main=bquote(p * " = " * .(p)),
      sub=bquote(R^2 * "/" * p * " = " * .(R2/p)))

## Or do it all together
p <- .4
R2 <- .9876
plot(1:10,
     main=bquote(p * " = " * .(p)),
     sub=bquote(R^2 * "/" * p * " = " * .(R2/p)),
     xlab=bquote(R^2 * " = " * .(R2)),
     ylab=expression(e^(-z^2))
     )

## at some point, soon I recommend, you should learn either lattice or ggplot.
## you might also want to look at the archives of R-SIG-Geo,start with
https://www.r-project.org/mail.html

## Please Keep the list in further emails

On Wed, Jan 18, 2017 at 8:09 PM, Jake William Andrae
<jake.andrae at adelaide.edu.au> wrote:
> Hi Richard,
>
>
> If I want to use the ?plotmath function, how would I go about writing that
> into the script I have for my graphs?
>
> I've just pasted the whole script here, with the summary label section
> higlighted. Sorry to be a burden like this, I'm a real novice to R haha.
>
>
> #Concentration
> plot(Annual_precipitation, Concentration, xaxs = "i", yaxs = "i", xlim =
> c(1000, 2400), ylim = c(0,500), xlab = NA, ylab = "Concentration", xaxt='n',
> pch=21,  bg='black',
> rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "gray"))
> par(xpd=FALSE)
> abline(lm(Concentration~Annual_precipitation))
> par(xpd=NA)
> AnnualPrecipitationConcentration <- lm(Concentration~Annual_precipitation)
>         #Summary labels
>         R2 <- round(summary(AnnualPrecipitationConcentration)$r.squared, 2)
>         p <- anova(AnnualPrecipitationConcentration)[1,5]
>         if(p <= 0.001){
>         p <- "< 0.001"
>         }else{p <- round(p, 3)}
>         x <- 10
>         mtext(paste("R2 = ", R2), adj=0, line=1, col="black", cex=0.7)
>         mtext(paste("p = ", p), adj=0, line=0.1, col="black", cex=0.7)
>
>
> Kind regards,
>
> Jake
>
>
>
> Jake Andrae
> PhD Candidate
> Geology & Geophysics ? Sprigg Geobiology Centre
> Department of Earth Science
> School of Physical Sciences
> The University of Adelaide, AUSTRALIA 5005
> Phone: 0407701565
> Email: jake.andrae at adelaide.edu.au
>
> ________________________________
> From: Richard M. Heiberger <rmh at temple.edu>
> Sent: Thursday, 19 January 2017 11:30:38 AM
> To: Jake William Andrae
> Cc: r-help at r-project.org
> Subject: Re: [R] Superscript in graph text
>
> x <- 10
> plot(1:10, main=bquote(R^2 * "=" * .(x)))
>
> On Wed, Jan 18, 2017 at 8:00 PM, Richard M. Heiberger <rmh at temple.edu>
> wrote:
>> ?plotmath
>>
>>
>> plot(1:10, main=expression(R^2))
>>
>> plot(1:10, main=bquote(R^2 * "=" * .(x)))
>>
>> On Wed, Jan 18, 2017 at 7:44 PM, Jake William Andrae
>> <jake.andrae at adelaide.edu.au> wrote:
>>> Hello,
>>>
>>>
>>> I've added some statistical information as text to some graphs, but I'm
>>> having a really hard time making the 2 in the R2 label superscript. Does
>>> anyone have any suggestions?
>>>
>>>
>>> mtext(paste("R2 = ", R2), adj=0, line=1, col="black", cex=0.7)
>>>
>>>
>>> Kind regards
>>>
>>>
>>> Jake Andrae
>>> PhD Candidate
>>> Geology & Geophysics - Sprigg Geobiology Centre
>>> Department of Earth Science
>>> School of Physical Sciences
>>> The University of Adelaide, AUSTRALIA 5005
>>> Phone: 0407701565
>>> Email: jake.andrae at adelaide.edu.au
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
R-help Info Page - Homepage - SfS ? Seminar for Statistics<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...


>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From yui.nishizawa at gmail.com  Wed Jan 18 23:52:40 2017
From: yui.nishizawa at gmail.com (yui nishizawa)
Date: Thu, 19 Jan 2017 07:52:40 +0900
Subject: [R] grepRaw() not matching fixed pattern at the tail
Message-ID: <CABtF06nNQ+iD+tb_P6wb+JwpKLUsupqW8fb9gdzWmrgPY7pkCg@mail.gmail.com>

Hello

This is my first time posting a question.

I am having trouble getting grepRaw() to match a fixed pattern at the
tail of a raw vector.

Here is an example:

# Returns integer(0), expected 2.
grepRaw(pattern = charToRaw('abcd'), x = charToRaw('0abcd'), fixed=T)
# Consequently, the pattern won't match itself either. Returns integer(0).
grepRaw(pattern = charToRaw('abcd'), x = charToRaw('abcd'), fixed=T)


After some experiments, I noticed that these all work as expected:

# x doesn't end with the pattern. Returns 2 as expected.
grepRaw(pattern = charToRaw('abcd'), x = charToRaw('0abcd0'), fixed=T)

# A shorter pattern. length < 4?
grepRaw(pattern = charToRaw('abc'), x = charToRaw('0abc'), fixed=T)

# non-fixed.
grepRaw(pattern = charToRaw('abcd'), x = charToRaw('0abcd'), fixed=F)


However, I still need to get something like the top example to work.
Am I missing something?

Just in case, my sessionInfo() is:
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.2


Any help is appreciated. Thank you.

Yui Nishizawa


From michael.eisenring at agroscope.admin.ch  Thu Jan 19 08:19:44 2017
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Thu, 19 Jan 2017 07:19:44 +0000
Subject: [R] non-parametric manova with post-hoc test
In-Reply-To: <CAM5M9BQEthYSTtQWW3fgKAztb22oiC=YAJtBQVSUoit6V3oFNQ@mail.gmail.com>
References: <6D5C009FB51EBD41BEE57F4C002350FD0513EF96@SB00112A.adb.intra.admin.ch>
	<CAM5M9BQEthYSTtQWW3fgKAztb22oiC=YAJtBQVSUoit6V3oFNQ@mail.gmail.com>
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD0513F001@SB00112A.adb.intra.admin.ch>

Dear Brian,
Thank you for your answer.
Another thing that came to my mind: Would it be possible just to separately rank-transform my 3 dependent  variables and then to conduct a normal MANOVA on this data?


Thanks,
Mike
Eisenring Michael, Msc.
PhD Student

Federal Department of Economic Affairs, Education and Research
EAER
Agroecology and Environment
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 44 37 77181
Fax +41 44 37 77201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>

Von: Cade, Brian [mailto:cadeb at usgs.gov]
Gesendet: Mittwoch, 18. Januar 2017 18:20
An: Eisenring Michael Agroscope <michael.eisenring at agroscope.admin.ch>
Cc: r-help at r-project.org
Betreff: Re: [R] non-parametric manova with post-hoc test

You could try a multi-response permutation procedure (MRPP) for multivariate hypothesis testing (null is groups come from a common distribution) without resorting to ranks.  There are no automated multiple comparison procedures, but one could either look at pairwise contrasts of group (if that is what you are implying by post-hoc testing) with some sort of correction procedure for multiple comparisons (e.g., Holm's sequential procedure).  Or similarly, comparisons with different subsets of the multivariate outcome variables (again, adjusting for multiple comparisons) across the grouping structure.  There are several R packages that I think implement MRPP but the Blossom package might be one of the better implementations in terms of alternatives provided (including permutation version of Hotelling's test).

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
tel:  970 226-9326


On Wed, Jan 18, 2017 at 10:00 AM, <michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>> wrote:
Good day,
I am looking for a way to perform a non parametric manova and to analyze the result using post-hoc tests (an equivalent of the kruskal wallis test for anova)

In my book (discovering statistic using R) two tests are described Munzel and Brunners method (mulrank) and Choi and Mardens test (cmanova). Both are from the package WRS which unfortunately does not exist anymore (and WRS2 is not containing these tests). Furthermore the test do to my knowledge not allow post-hoc analyses-

I would be grateful for your help

Best,
Mike

Eisenring Michael, Msc.
PhD Student

Federal Department of Economic Affairs, Education and Research
EAER
Agroecology and Environment
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 44 37 77181
Fax +41 44 37 77201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch><mailto:michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>>
www.agroscope.ch<http://www.agroscope.ch><http://www.agroscope.ch/>


        [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From bruno.rproject at gmail.com  Thu Jan 19 15:31:56 2017
From: bruno.rproject at gmail.com (Bruno C)
Date: Thu, 19 Jan 2017 14:31:56 +0000
Subject: [R] non-parametric manova with post-hoc test
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD0513F001@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD0513EF96@SB00112A.adb.intra.admin.ch>
	<CAM5M9BQEthYSTtQWW3fgKAztb22oiC=YAJtBQVSUoit6V3oFNQ@mail.gmail.com>
	<6D5C009FB51EBD41BEE57F4C002350FD0513F001@SB00112A.adb.intra.admin.ch>
Message-ID: <CADnerV9+TdpAB96395t__j++t6RuYD88FghOdyrK9YyjR=dHwg@mail.gmail.com>

Bruno.rproject at gmail.com

Em qui, 19 de jan de 2017 05:22, <michael.eisenring at agroscope.admin.ch>
escreveu:

> Dear Brian,
> Thank you for your answer.
> Another thing that came to my mind: Would it be possible just to
> separately rank-transform my 3 dependent  variables and then to conduct a
> normal MANOVA on this data?
>
>
> Thanks,
> Mike
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Agroecology and Environment
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:
> michael.eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
> Von: Cade, Brian [mailto:cadeb at usgs.gov]
> Gesendet: Mittwoch, 18. Januar 2017 18:20
> An: Eisenring Michael Agroscope <michael.eisenring at agroscope.admin.ch>
> Cc: r-help at r-project.org
> Betreff: Re: [R] non-parametric manova with post-hoc test
>
> You could try a multi-response permutation procedure (MRPP) for
> multivariate hypothesis testing (null is groups come from a common
> distribution) without resorting to ranks.  There are no automated multiple
> comparison procedures, but one could either look at pairwise contrasts of
> group (if that is what you are implying by post-hoc testing) with some sort
> of correction procedure for multiple comparisons (e.g., Holm's sequential
> procedure).  Or similarly, comparisons with different subsets of the
> multivariate outcome variables (again, adjusting for multiple comparisons)
> across the grouping structure.  There are several R packages that I think
> implement MRPP but the Blossom package might be one of the better
> implementations in terms of alternatives provided (including permutation
> version of Hotelling's test).
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
> On Wed, Jan 18, 2017 at 10:00 AM, <michael.eisenring at agroscope.admin.ch
> <mailto:michael.eisenring at agroscope.admin.ch>> wrote:
> Good day,
> I am looking for a way to perform a non parametric manova and to analyze
> the result using post-hoc tests (an equivalent of the kruskal wallis test
> for anova)
>
> In my book (discovering statistic using R) two tests are described Munzel
> and Brunners method (mulrank) and Choi and Mardens test (cmanova). Both are
> from the package WRS which unfortunately does not exist anymore (and WRS2
> is not containing these tests). Furthermore the test do to my knowledge not
> allow post-hoc analyses-
>
> I would be grateful for your help
>
> Best,
> Mike
>
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Agroecology and Environment
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:
> michael.eisenring at agroscope.admin.ch><mailto:
> michael.eisenring at agroscope.admin.ch<mailto:
> michael.eisenring at agroscope.admin.ch>>
> www.agroscope.ch<http://www.agroscope.ch><http://www.agroscope.ch/>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jan 19 15:42:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 19 Jan 2017 06:42:57 -0800
Subject: [R] non-parametric manova with post-hoc test
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD0513F001@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD0513EF96@SB00112A.adb.intra.admin.ch>
	<CAM5M9BQEthYSTtQWW3fgKAztb22oiC=YAJtBQVSUoit6V3oFNQ@mail.gmail.com>
	<6D5C009FB51EBD41BEE57F4C002350FD0513F001@SB00112A.adb.intra.admin.ch>
Message-ID: <CAGxFJbQWawzDL0NioD5QOPp6=f-d14R=PLT-NvmBDnCBVaBYdw@mail.gmail.com>

You really need to go to the literature. The analysis of rank
transformed data has a long history going back to the 1970's/80's, at
least. See, e.g.

https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjDg_uGuM7RAhWmrVQKHaYRDb0QFggcMAA&url=http%3A%2F%2Fpeople.umass.edu%2Fbioep740%2Ftopics%2Famstat-1985-iman.pdf&usg=AFQjCNHcbe_1R6vRtMSBrMW9YIeFQxjb1Q&sig2=9JeOaP1f61m7REfmScefVg

There is even a Wikipedia entry for "Anova on Ranks".
So you really really should do some homework.

Moreover, statistical discussions are largely OT here.
stats.stackexchange.com is a more appropriate list if you wish to
continue online.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 18, 2017 at 11:19 PM,  <michael.eisenring at agroscope.admin.ch> wrote:
> Dear Brian,
> Thank you for your answer.
> Another thing that came to my mind: Would it be possible just to separately rank-transform my 3 dependent  variables and then to conduct a normal MANOVA on this data?
>
>
> Thanks,
> Mike
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Agroecology and Environment
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
> Von: Cade, Brian [mailto:cadeb at usgs.gov]
> Gesendet: Mittwoch, 18. Januar 2017 18:20
> An: Eisenring Michael Agroscope <michael.eisenring at agroscope.admin.ch>
> Cc: r-help at r-project.org
> Betreff: Re: [R] non-parametric manova with post-hoc test
>
> You could try a multi-response permutation procedure (MRPP) for multivariate hypothesis testing (null is groups come from a common distribution) without resorting to ranks.  There are no automated multiple comparison procedures, but one could either look at pairwise contrasts of group (if that is what you are implying by post-hoc testing) with some sort of correction procedure for multiple comparisons (e.g., Holm's sequential procedure).  Or similarly, comparisons with different subsets of the multivariate outcome variables (again, adjusting for multiple comparisons) across the grouping structure.  There are several R packages that I think implement MRPP but the Blossom package might be one of the better implementations in terms of alternatives provided (including permutation version of Hotelling's test).
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
> On Wed, Jan 18, 2017 at 10:00 AM, <michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>> wrote:
> Good day,
> I am looking for a way to perform a non parametric manova and to analyze the result using post-hoc tests (an equivalent of the kruskal wallis test for anova)
>
> In my book (discovering statistic using R) two tests are described Munzel and Brunners method (mulrank) and Choi and Mardens test (cmanova). Both are from the package WRS which unfortunately does not exist anymore (and WRS2 is not containing these tests). Furthermore the test do to my knowledge not allow post-hoc analyses-
>
> I would be grateful for your help
>
> Best,
> Mike
>
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Agroecology and Environment
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch><mailto:michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>>
> www.agroscope.ch<http://www.agroscope.ch><http://www.agroscope.ch/>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Thu Jan 19 17:19:32 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 19 Jan 2017 11:19:32 -0500
Subject: [R] Fwd: Need help in exporting R apriori rules to Excel
In-Reply-To: <CAAdgFSrmJqwVWCocGjG7B296sn+prN87YPdQK374--tCkiL8Mg@mail.gmail.com>
References: <CAAdgFSrHZur6ywhL2Oh2KhJaVXn7C4usUic68NyY11aWWSjpNg@mail.gmail.com>
	<CAAdgFSrP_=OyMxGtRbjNh7qsScquzQzFbUgcjisDcUXRr5Zy5A@mail.gmail.com>
	<CAM_vju=F9y-YVaqTAN66pbwi-wm3D+FUjG85A+4cf5rmE176dg@mail.gmail.com>
	<CAAdgFSrmJqwVWCocGjG7B296sn+prN87YPdQK374--tCkiL8Mg@mail.gmail.com>
Message-ID: <CAM_vjunC34YBUu_F12y1h8Ocf0tgd5oRzTXHOMkqJy_Bdkns8w@mail.gmail.com>

Hi,

You need to reply to the list as well as to me; I can't provide private R help.

I don't know what more help you need: I told you what function to use,
and what google search I used to find the answer.

If you have additional problems you need to be more specific in your
question. This link might help:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah

On Thu, Jan 19, 2017 at 1:35 AM, Edward Tamil <tamildee at gmail.com> wrote:
> hi
>
> Thanks for your reply.
>
> Im new to R. started learning from Web tutorials.below is the code. please
> help me.....
>
> rm(list=ls())
> setwd("D:/POSable/Mahimm sir/Market Basket Analysis")
> tr <- read.csv("Noodles.csv")
> options(max.print=10000000)
> str(tr)
> tr
> i <- split(tr$item, tr$id)
> head(i)
> library("arules")
> txn <- as(i, "transactions")
> basket_rules <- apriori(txn, parameter = list(sup = 0.001, conf = 0.01,
> target="rules"))
> DT <- data.frame(inspect(sort(basket_rules, by="support")))
> write.table(file = "Noodle_rules.csv",DT,sep = ",", col.names = NA,
>             qmethod = "double")
>
>
>
>
> On Wed, Jan 18, 2017 at 7:44 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> I believe you need to convert them to a data frame before you can use
>> any data frame export functions to save them to disk. See ?as
>>
>> I'm assuming that you are using the arules package; your question is
>> incomplete.
>>
>> I've never used arules myself; I googled "rhelp export apriori rules"
>>
>> Sarah
>>
>> On Wed, Jan 18, 2017 at 3:09 AM, Edward Tamil <tamildee at gmail.com> wrote:
>> > Hi Sir,
>> >
>> >
>> > Need help in exporting R apriori rules to Excel. i tried write.csv
>> > write.table write.csv2
>> >
>> > only exporting less than 500 rules.
>> >
>> > unable to export Large Data.
>> >
>> >
>> > " No Error Msg" File size is "0"
>> >
>> > --
>> >
>> > *Edward *
>> >
>> >
>> >
>> >
>> >
>
>
>


From pauljohn32 at gmail.com  Thu Jan 19 17:52:16 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 19 Jan 2017 10:52:16 -0600
Subject: [R] xvfb? cron job updates R packages, fails on some requiring X11
Message-ID: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>

In Centos 7 systems, I wrote a script that runs on the cron and I
notice some package updates and installs fail like this:


Error : .onLoad failed in loadNamespace() for 'iplots', details:
  call: .jnew("org/rosuda/iplots/Framework")
  error: java.awt.HeadlessException:
No X11 DISPLAY variable was set, but this program performed an
operation which requires it.
Error: loading failed
Execution halted
ERROR: loading failed
* removing ?/usr/share/R/library/iplots?
* restoring previous ?/usr/share/R/library/iplots?


I can log in interactively and run  the same install successfully.

I understand I need something like xvfb to simulate an X11 session,
but I don't understand how to make it work.  Can one of you give me an
idiot's guide on what to do?

pj


-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From murdoch.duncan at gmail.com  Thu Jan 19 18:01:21 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Jan 2017 12:01:21 -0500
Subject: [R] xvfb? cron job updates R packages,
 fails on some requiring X11
In-Reply-To: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>
References: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>
Message-ID: <73e3c214-cafd-c1f9-abe6-ec1703d8666e@gmail.com>

On 19/01/2017 11:52 AM, Paul Johnson wrote:
> In Centos 7 systems, I wrote a script that runs on the cron and I
> notice some package updates and installs fail like this:
>
>
> Error : .onLoad failed in loadNamespace() for 'iplots', details:
>   call: .jnew("org/rosuda/iplots/Framework")
>   error: java.awt.HeadlessException:
> No X11 DISPLAY variable was set, but this program performed an
> operation which requires it.
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing ?/usr/share/R/library/iplots?
> * restoring previous ?/usr/share/R/library/iplots?
>
>
> I can log in interactively and run  the same install successfully.
>
> I understand I need something like xvfb to simulate an X11 session,
> but I don't understand how to make it work.  Can one of you give me an
> idiot's guide on what to do?
>
> pj
>
>

I don't know if iplots offers this, but a package should be able to work 
in a non-X11 environment.  rgl does it by checking the RGL_USE_NULL 
environment variable.

Duncan Murdoch


From edd at debian.org  Thu Jan 19 18:22:31 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 19 Jan 2017 11:22:31 -0600
Subject: [R] xvfb? cron job updates R packages,
	fails on some requiring X11
In-Reply-To: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>
References: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>
Message-ID: <22656.62935.469624.377721@max.nulle.part>


Paul,

Just prefix the command as you would with, say, /usr/bin/time.  An example is here:

  https://github.com/RcppCore/rcpp-logs/blob/master/scripts/runRcppDepends.r#L140L-L142

from the script I use to test all Rcpp dependencies -- now over 900 -- unattended.

Some packages also need OpenGL which the default does not give you. But the
r-cran.mk script building several hundred r-cran-* package for the Debian and
Ubuntu distros -- as well as several _thousand_ r-cran-* packages via Michael
Rutter's repos for Ubuntu, and included in every installation, does this:


  ## xvfb-run with GL extension and default resolution
  xvfbSrvArgs 	= -screen 0 1024x768x24 -ac +extension GLX +render -noreset

  [...]

		if test -f /usr/bin/xvfb-run; then 			\
			$(makeFlagsCall) xvfb-run -a -n 20              \
                                                  -s "${xvfbSrvArgs}"   \
				R CMD INSTALL -l $(debRlib) --clean     \
					$(extraInstallFlags) .   	\
					$(builttimeStamp)   	        \
					;                               \


I guess you can piece the rest together.  Now, if you just used Ubuntu LTS
instead of insisting on CentOS you wouldn't even have to compile them
locally.  Might be worth a consideration or test deployment.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From glennmschultz at me.com  Thu Jan 19 17:39:50 2017
From: glennmschultz at me.com (Glenn Schultz)
Date: Thu, 19 Jan 2017 16:39:50 +0000 (GMT)
Subject: [R] help using tryCatch
Message-ID: <be20fa7d-224c-460f-b8a0-e3b42a88e706@me.com>

All,
I have ?a function that I would like to return 0 or NA on unit root error but I cannot figure out how to get tryCatch to work. ?I have followed the examples in the R documentation as well as some online but I am missing something. ?If I added the tryCatch code I only get the error value. ?Any help is appreciated

Glenn

FindATOMSPrice <- function(StartPrice,
TBAPrice,
PriceInterval,
CurrFactor,
PrevFactor,
CarryAdj,
PDReturn,
CPNReturn,
MTDReturn){
ATOMSReturn <- function(ClosePrice,
StartPrice,
CurrFactor,
PrevFactor,
PDReturn, 
CPNReturn, 
MTDReturn){
SurvivalFactor = CurrFactor/PrevFactor
PrxReturn = ((ClosePrice - StartPrice)/StartPrice) * SurvivalFactor
ATOMSReturn = sum(PrxReturn, PDReturn, CPNReturn)
return(ATOMSReturn - MTDReturn)
}
TBALow = TBAPrice - PriceInterval
TBAHigh = TBAPrice + PriceInterval

CleanPrice = 
#tryCatch({
uniroot(ATOMSReturn,
interval = c(TBALow, TBAHigh),
tol = .000000001,
StartPrice = StartPrice,
CurrFactor = CurrFactor,
PrevFactor = PrevFactor,
PDReturn = PDReturn,
CPNReturn = CPNReturn,
MTDReturn = MTDReturn)$root
#}, error = return(TBAPrice))
return(CleanPrice - CarryAdj)
}

From ebs15242 at gmail.com  Thu Jan 19 19:20:41 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 19 Jan 2017 12:20:41 -0600
Subject: [R] T tests on multiple groups
Message-ID: <CALRb-ofRneWTpqCnC33jad2uPVimtt16AUxZGCgeCP6D8S2LRQ@mail.gmail.com>

I have a data set with observations on groups with multiple variables.
Let's call them GENO and AGE.  I have control and test genotypes
and two different ages.  It is only meaningful to compare control and
test within the same age.

I'd like to get the p value for each group compared back to control
of the appropriate age.  T-test requires that the grouping factor has
exactly two levels.   How can I do this efficiently?

I was hoping something like ttest(OBS ~ GENO * AGE, mydata) would work.
Is there something I can do with tapply() or aggregate() to do this?
I'd like to end up with a table that looks like this:

GENO    Age    OBS    p.val
control    10    1.1    1
control    10    0.9    1
control    20    2.1    1
control    20    1.9    1
A    10    11    0.01224066
A    10    9    0.01224066
A    20    21    0.003102783
A    20    19    0.003102783
B    10    4    0.057714305
B    10    6    0.057714305
B    20    14    0.005923285
B    20    16    0.005923285
AB    10    1    0.698488655
AB    10    1.1    0.698488655
AB    20    2    0.552786405
AB    20    2.2    0.552786405


From wdunlap at tibco.com  Thu Jan 19 19:30:08 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Jan 2017 10:30:08 -0800
Subject: [R] help using tryCatch
In-Reply-To: <be20fa7d-224c-460f-b8a0-e3b42a88e706@me.com>
References: <be20fa7d-224c-460f-b8a0-e3b42a88e706@me.com>
Message-ID: <CAF8bMca3sMWWnjmZZ6p3XAtypUHdzg5oDa_dGkDk9C_hqn5tWQ@mail.gmail.com>

The 'error' argument to tryCatch must be a function (of one argument,
the exception).  Its return value will be the return value of tryCatch
if there is an error.  Hence you should change the present
    error = return(TBAPrice)
to
    error = function(exception) TBAPrice

You can use
    error = function(exception) return(TBAPrice)
if you prefer to use explicit return statements.

You could also examine conditionMessage(exception) or class(exception)
to see if it is the error you expect.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 19, 2017 at 8:39 AM, Glenn Schultz <glennmschultz at me.com> wrote:
> All,
> I have  a function that I would like to return 0 or NA on unit root error
> but I cannot figure out how to get tryCatch to work.  I have followed the
> examples in the R documentation as well as some online but I am missing
> something.  If I added the tryCatch code I only get the error value.  Any
> help is appreciated
>
> Glenn
>
> FindATOMSPrice <- function(StartPrice,
> TBAPrice,
> PriceInterval,
> CurrFactor,
> PrevFactor,
> CarryAdj,
> PDReturn,
> CPNReturn,
> MTDReturn){
> ATOMSReturn <- function(ClosePrice,
> StartPrice,
> CurrFactor,
> PrevFactor,
> PDReturn, CPNReturn, MTDReturn){
> SurvivalFactor = CurrFactor/PrevFactor
> PrxReturn = ((ClosePrice - StartPrice)/StartPrice) * SurvivalFactor
> ATOMSReturn = sum(PrxReturn, PDReturn, CPNReturn)
> return(ATOMSReturn - MTDReturn)
> }
> TBALow = TBAPrice - PriceInterval
> TBAHigh = TBAPrice + PriceInterval
>
> CleanPrice = #tryCatch({
> uniroot(ATOMSReturn,
> interval = c(TBALow, TBAHigh),
> tol = .000000001,
> StartPrice = StartPrice,
> CurrFactor = CurrFactor,
> PrevFactor = PrevFactor,
> PDReturn = PDReturn,
> CPNReturn = CPNReturn,
> MTDReturn = MTDReturn)$root
> #}, error = return(TBAPrice))
> return(CleanPrice - CarryAdj)
> }
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Thu Jan 19 19:53:20 2017
From: chocold12 at gmail.com (lily li)
Date: Thu, 19 Jan 2017 11:53:20 -0700
Subject: [R] reading data
Message-ID: <CAN5afy9OpdmFRn=JWjx8+MUhi=PRfntQj=4=SqEsdboqkgvMsw@mail.gmail.com>

Hi R users,

I'm trying to open netcdf files in R. Each nc file has daily climate
measurements for a whole year, covering the whole US. How to limit the file
to a specific rectangle? Thanks.

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Jan 19 20:38:14 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 19 Jan 2017 19:38:14 +0000
Subject: [R] reading data
In-Reply-To: <CAN5afy9OpdmFRn=JWjx8+MUhi=PRfntQj=4=SqEsdboqkgvMsw@mail.gmail.com>
References: <CAN5afy9OpdmFRn=JWjx8+MUhi=PRfntQj=4=SqEsdboqkgvMsw@mail.gmail.com>
Message-ID: <72A81B28-7C21-4987-B170-382146FDE716@llnl.gov>

Try asking on R-sig-geo mailing list

Also, state what package(s) you are using, and include what you have already tried.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 1/19/17, 10:53 AM, "R-help on behalf of lily li" <r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:

    Hi R users,
    
    I'm trying to open netcdf files in R. Each nc file has daily climate
    measurements for a whole year, covering the whole US. How to limit the file
    to a specific rectangle? Thanks.
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From john.archie.mckown at gmail.com  Thu Jan 19 20:46:42 2017
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 19 Jan 2017 13:46:42 -0600
Subject: [R] R studio server vs R server and Small computer to run R
In-Reply-To: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>
References: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>
Message-ID: <CAAJSdjhPnS5Aa7po3sFQOwGGH_CYyvKpMu6+5G9wFPhG5hiXaw@mail.gmail.com>

On Wed, Jan 18, 2017 at 11:03 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Please forgive my resending this help request. I sent it two days ago. To
> date I have not received any responses.
> Thank you,
> John
>
>
> I am looking for a small computer low power that I make available on the
> web that will run R studio server or R server
>
> 1) can anyone recommend a computer?
>

The Raspberry Pi 3 runs a version of Debian. It is quite small. Mine runs a
BCM2709 processor. That's a
?64 bit ARM processor. HOWEVER! The Debian that I have to run is only 32
bit.  It has 1 GiB of RAM and 32 GiB of flash memory which is the disk. It
runs 1.2 Ghz. It has 4 USB ports so you could plug in a USB connected disk,
if you need more local disk space.


https://www.raspberrypi.org/products/raspberry-pi-3-model-b/



>
> 2) can anyone let me know the advantages and disadvantages of R studio
> server and R server?
>

?Sorry, I only use the basic R.



>
> Thank you
>
> John
>
> John David Sorkin M.D., Ph.D.
>
>
>


-- 
There?s no obfuscated Perl contest because it?s pointless.

?Jeff Polk

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Thu Jan 19 21:21:31 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 19 Jan 2017 14:21:31 -0600
Subject: [R] Hyperbola formula
Message-ID: <021cdb$5kgu3q@ironport10.mayo.edu>

This simple form of a hyperbola is not well known.  I find it useful for change point 
models: since the derivative is continuous it often behaves better in a maximizer.

h1 <- function(x, b, k=3)  .5 * b * (x + sqrt(x^2 + k^2))

Function h1() has asymptotes of y=0 to the left of 0 and y=x to the right of 0.  The 
parameter k controls how tightly the curve bends at zero.

A generalization is
h2 <- function (x, b, k=3) {
     z <- x - b[4]
     b[1] + b[2]*z + .5*b[3]* (z + sqrt(z^2 + k^2))
}
b[1] and b[2] are the intercept and slope of the left portion of the curve, b[4] is the 
inflection point, and b[3] is the change in slope at the inflection point.

The main downside is that k is arbitrary. I simply choose it to "look right", though it 
too could be part of an optimization.

Terry Therneau


From drjimlemon at gmail.com  Thu Jan 19 22:48:51 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 20 Jan 2017 08:48:51 +1100
Subject: [R] T tests on multiple groups
In-Reply-To: <CALRb-ofRneWTpqCnC33jad2uPVimtt16AUxZGCgeCP6D8S2LRQ@mail.gmail.com>
References: <CALRb-ofRneWTpqCnC33jad2uPVimtt16AUxZGCgeCP6D8S2LRQ@mail.gmail.com>
Message-ID: <CA+8X3fXwis-k7uD7Yqni4G_Q+35jw8_7RmOfih-Xp8hoUX38jg@mail.gmail.com>

Hi Ed,
It's little hard to work out exactly what you want, but here's a guess:

esdf<-data.frame(GENO=rep(c("control","A","B","AB"),each=20),
 age=rep(c(10,20),40),OBS=runif(80,1,21))
for(age in c(10,20)) {
 for(geno in c("A","B","AB"))
  print(t.test(OBS~GENO,esdf[esdf$age==age &
   esdf$GENO %in% c("control",geno),]))
}

Note that this is not a good way to use t.test, nor a good way to
analyze data like this. Look at defining sensible contrasts and using
ANOVA or a similar approach.

Jim

On Fri, Jan 20, 2017 at 5:20 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I have a data set with observations on groups with multiple variables.
> Let's call them GENO and AGE.  I have control and test genotypes
> and two different ages.  It is only meaningful to compare control and
> test within the same age.
>
> I'd like to get the p value for each group compared back to control
> of the appropriate age.  T-test requires that the grouping factor has
> exactly two levels.   How can I do this efficiently?
>
> I was hoping something like ttest(OBS ~ GENO * AGE, mydata) would work.
> Is there something I can do with tapply() or aggregate() to do this?
> I'd like to end up with a table that looks like this:
>
> GENO    Age    OBS    p.val
> control    10    1.1    1
> control    10    0.9    1
> control    20    2.1    1
> control    20    1.9    1
> A    10    11    0.01224066
> A    10    9    0.01224066
> A    20    21    0.003102783
> A    20    19    0.003102783
> B    10    4    0.057714305
> B    10    6    0.057714305
> B    20    14    0.005923285
> B    20    16    0.005923285
> AB    10    1    0.698488655
> AB    10    1.1    0.698488655
> AB    20    2    0.552786405
> AB    20    2.2    0.552786405
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Jan 19 23:13:54 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 19 Jan 2017 17:13:54 -0500
Subject: [R] R studio server vs R server and Small computer to run R
In-Reply-To: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>
References: <587F599C020000CB0016D289@smtp.medicine.umaryland.edu>
Message-ID: <CA+vqiLHn23fX7wg282m1RGwvz7HqY_eic5Zo+mrGtyewFTBBRg@mail.gmail.com>

Hi John,

I don't think this is the right place to find information about
RStudio or Microsoft products. If you re-phrase the question in terms
of what you want to accomplish rather than whether RStudio or
Microsoft is better perhaps people here will give you some
suggestions.

Best,
Ista

On Wed, Jan 18, 2017 at 12:03 PM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> Please forgive my resending this help request. I sent it two days ago. To date I have not received any responses.
> Thank you,
> John
>
>
> I am looking for a small computer low power that I make available on the web that will run R studio server or R server
>
> 1) can anyone recommend a computer?
>
> 2) can anyone let me know the advantages and disadvantages of R studio server and R server?
>
> Thank you
>
> John
>
>
> John David Sorkin M.D., Ph.D.
>
> Professor of Medicine
>
> Chief, Biostatistics and Informatics
>
>
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>
>
> Baltimore VA Medical Center
>
>
> 10 North Greene Street
>
>
> GRECC (BT/18/GR)
>
>
> Baltimore, MD 21201-1524
>
>
> (Phone) 410-605-7119
>
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From george.trojan at noaa.gov  Thu Jan 19 23:25:54 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Thu, 19 Jan 2017 22:25:54 +0000
Subject: [R] rgl does not plot
Message-ID: <CABie7_r0fAKLdF5g2euytnxjL5dEynBv+SRWXiz44g-5mo0+cQ@mail.gmail.com>

I have installed package rgl without any problems. I can load the library,
issue commands from console without any errors showing up, however I can't
get anything plotted. Example session:

> library(rgl)
> plot3d(rnorm(100), rnorm(100), rnorm(100))
> rgl.quit()
> library(rgl)
> .check3d()
glX
 1
> plot3d(rnorm(100), rnorm(100), rnorm(100))
> > open3d()
glX
 2
> plot3d(rnorm(100), rnorm(100), rnorm(100))
> rgl.quit()

.check3d() and open3d() open a small window ~8x8 cm, copying desktop
background under it, which stays there when the window is moved. plot3d()
does not do anything. rgl.quit() closes the windows, as expected.

I am running Fedora 24 Scientific, NVIDIA video card with NVIDIA
proprietory driver that supports GLX. Any idea where to look for a solution?

George

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Jan 19 23:58:44 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 19 Jan 2017 16:58:44 -0600
Subject: [R] Aggregate data to lower resolution
In-Reply-To: <CAMLwc7PGO4UPgHdu4JqrzGyzM1ycJ2gksUjqtc6F7MCN0EZ-LQ@mail.gmail.com>
References: <CAMLwc7O1nWa7Akou2RA8S1Rt=FWzTzUrBjfZFaFz8wTXDckEFg@mail.gmail.com>
	<CAN5YmCGiejFeenv8bJV525Tm+jhCoqHbEyS6TPrY5ePhPHaeLw@mail.gmail.com>
	<CAMLwc7PGO4UPgHdu4JqrzGyzM1ycJ2gksUjqtc6F7MCN0EZ-LQ@mail.gmail.com>
Message-ID: <CAN5YmCHG3e0st3bvDZ9EeGum9GYE5W-8fuAvMhNDkqnhvabdag@mail.gmail.com>

Milu,

To get the quickest help and keep everyone in the loop, you should cc the
help list.

I don't understand your question.  If you want the mean GDP use the mean
function, if you want the sum of the GDP use the sum function.

Jean

On Fri, Jan 13, 2017 at 5:33 PM, Miluji Sb <milujisb at gmail.com> wrote:

> Dear Jean,
>
> Greetings of the new year. Hope you are doing well.
>
> I apologise for writing to you off-list but this might be a really silly
> question and I wanted to clarify without bothering everyone. Would kindly
> help me out? Hope this is not too much of a bother.
>
> My original question was regarding aggregating data to 1 degree x 1
> degree. You had kindly provided the following solution:
>
> temp$long1 <- floor(temp$longitude)
> temp$lat1 <- floor(temp$latitude)
> temp1 <- aggregate(GDP ~ long1 + lat1, temp, mean)
>
> Everything works well, my only question (and confusion) is that for
> aggregating from 0.5 degree by 0.5 degree to 1 degree by 1 degree, should
> we use sum instead of mean?
>
> temp1 <- aggregate(GDP ~ long1 + lat1, temp, sum)
>
> I really hope I'm not bothering you too much. Thanks again.
>
> Sincerely,
>
> Milu
>
> On Fri, Jul 22, 2016 at 3:06 PM, Adams, Jean <jvadams at usgs.gov> wrote:
>
>> Milu,
>>
>> Perhaps an approach like this would work.  In the example below, I
>> calculate the mean GDP for each 1 degree by 1 degree.
>>
>> temp$long1 <- floor(temp$longitude)
>> temp$lat1 <- floor(temp$latitude)
>> temp1 <- aggregate(GDP ~ long1 + lat1, temp, mean)
>>
>>   long1 lat1        GDP
>> 1   -69  -55 0.90268640
>> 2   -68  -55 0.09831317
>> 3   -72  -54 0.22379000
>> 4   -71  -54 0.14067290
>> 5   -70  -54 0.00300380
>> 6   -69  -54 0.00574220
>>
>> Jean
>>
>> On Thu, Jul 21, 2016 at 3:57 PM, Miluji Sb <milujisb at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> I have the following GDP data by latitude and longitude at 0.5 degree by
>>> 0.5 degree.
>>>
>>> temp <- dput(head(ptsDF,10))
>>> structure(list(longitude = c(-68.25, -67.75, -67.25, -68.25,
>>> -67.75, -67.25, -71.25, -70.75, -69.25, -68.75), latitude = c(-54.75,
>>> -54.75, -54.75, -54.25, -54.25, -54.25, -53.75, -53.75, -53.75,
>>> -53.75), GDP = c(1.683046, 0.3212307, 0.0486207, 0.1223268, 0.0171909,
>>> 0.0062104, 0.22379, 0.1406729, 0.0030038, 0.0057422)), .Names =
>>> c("longitude",
>>> "latitude", "GDP"), row.names = c(4L, 17L, 30L, 43L, 56L, 69L,
>>> 82L, 95L, 108L, 121L), class = "data.frame")
>>>
>>> I would like to aggregate the data 1 degree by 1 degree. I understand
>>> that
>>> the first step is to convert to raster. I have tried:
>>>
>>> rasterDF <- rasterFromXYZ(temp)
>>> r <- aggregate(rasterDF,fact=2, fun=sum)
>>>
>>> But this does not seem to work. Could anyone help me out please? Thank
>>> you
>>> in advance.
>>>
>>> Sincerely,
>>>
>>> Milu
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Fri Jan 20 14:29:19 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 20 Jan 2017 08:29:19 -0500
Subject: [R] Fitting arima Models with Exogenous Variables
Message-ID: <CAMOcQfPK=1UZvFN5mS=Q6jH8T1qt1MMmNvoSQeh6MO9Rp9gcuA@mail.gmail.com>

Dear friends,

I have 5 exogenous variables which I?d like to incorporate into my
auto.arima model.

I was able to incorporate the xreg, and I understand that newxreg should be
the forecast of my exogenous variables, but I have not been able to get it
to work.

Newxreg should only have one column? Should newxreg have the same number of
rows of the training data?

This is the error I keep getting but I don?t quite understand:

Error in forecast.Arima(ModelAfit, h = 12, newxreg = NewXreg) :
  No regressors provided
In addition: Warning message:
In forecast.Arima(ModelAfit, h = 12, newxreg = NewXreg) :
  The non-existent newxreg arguments will be ignored.

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From jstudyvin at west-inc.com  Fri Jan 20 15:58:18 2017
From: jstudyvin at west-inc.com (Jared Studyvin)
Date: Fri, 20 Jan 2017 07:58:18 -0700
Subject: [R] Current Terminal (console) width
Message-ID: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>

Hello,

On a non Windows OS the following command: Sys.getenv("COLUMNS")
Will return the current width of the R terminal (console) but this does not
work on a Windows OS.

Does anyone know equivelant R code when install on a Windows OS?

I'm using WIndows 10 Pro Version: 1607; R 3.3.2

Thanks,

*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}


From btupper at bigelow.org  Fri Jan 20 16:48:56 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 20 Jan 2017 10:48:56 -0500
Subject: [R] Current Terminal (console) width
In-Reply-To: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
Message-ID: <FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>

Hi,

Have you looked at 

> > options("width")
> $width
> [1] 80

and does that get at what you need?

Ben




> On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com> wrote:
> 
> Hello,
> 
> On a non Windows OS the following command: Sys.getenv("COLUMNS")
> Will return the current width of the R terminal (console) but this does not
> work on a Windows OS.
> 
> Does anyone know equivelant R code when install on a Windows OS?
> 
> I'm using WIndows 10 Pro Version: 1607; R 3.3.2
> 
> Thanks,
> 
> *Jared Studyvin, PhD *
> *Statistician*
> 
> 
> Environmental & Statistical Consultants
> 200 S. Second Street
> Laramie, WY 82070
> (307) 721-3179
> jstudyvin at west-inc.com
> www.west-inc.com
> 
> *Follow WEST: *Facebook
> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> 
> CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From jstudyvin at west-inc.com  Fri Jan 20 17:17:45 2017
From: jstudyvin at west-inc.com (Jared Studyvin)
Date: Fri, 20 Jan 2017 09:17:45 -0700
Subject: [R] Current Terminal (console) width
In-Reply-To: <FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
Message-ID: <CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>

Ben,

That options control is about the size of what is printed. I'm looking for
the actual size of the window in real time.

options('width') ## returns 80
resize the terminal window
options('width') ## returns 80

Sys.getenv('COLUMNS') ## returns current window width
resize the terminal window
Sys.getenv('COLUMNS') ## returns a different value

This however does not work on a Windows OS.

Thanks,




*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanying communications
are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
2510-2521, and contain information that is privileged, confidential or
otherwise protected from disclosure.  If you are not the intended recipient
or an agent responsible for delivering the communication to the intended
recipient, you are hereby notified that you have received this
communication in error.  Dissemination, distribution or copying of this
e-mail or the information herein by anyone other than the intended
recipient, or an employee or agent responsible for delivering the message
to the intended recipient, is prohibited.  If you have received this
communication in error, please notify us immediately by e-mail and delete
the original message.  Thank you.

P Please consider the environment before printing.


On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> Have you looked at
>
> > > options("width")
> > $width
> > [1] 80
>
> and does that get at what you need?
>
> Ben
>
>
>
>
> > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com>
> wrote:
> >
> > Hello,
> >
> > On a non Windows OS the following command: Sys.getenv("COLUMNS")
> > Will return the current width of the R terminal (console) but this does
> not
> > work on a Windows OS.
> >
> > Does anyone know equivelant R code when install on a Windows OS?
> >
> > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
> >
> > Thanks,
> >
> > *Jared Studyvin, PhD *
> > *Statistician*
> >
> >
> > Environmental & Statistical Consultants
> > 200 S. Second Street
> > Laramie, WY 82070
> > (307) 721-3179
> > jstudyvin at west-inc.com
> > www.west-inc.com
> >
> > *Follow WEST: *Facebook
> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> 90Technology%E2%80%90WESTInc/125604770807646>
> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >
> > CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Jan 20 17:29:39 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 20 Jan 2017 16:29:39 +0000
Subject: [R] Current Terminal (console) width
In-Reply-To: <CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
Message-ID: <1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>

I cannot replicate that on Windows 8 (64 bit or 32 bit):

> options('width') 
$width
[1] 90

# Drag the window to resize, then:

> options('width') 
$width
[1] 124

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jared Studyvin
Sent: Friday, January 20, 2017 10:18 AM
To: Ben Tupper <btupper at bigelow.org>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Current Terminal (console) width

Ben,

That options control is about the size of what is printed. I'm looking for
the actual size of the window in real time.

options('width') ## returns 80
resize the terminal window
options('width') ## returns 80

Sys.getenv('COLUMNS') ## returns current window width
resize the terminal window
Sys.getenv('COLUMNS') ## returns a different value

This however does not work on a Windows OS.

Thanks,




*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanying communications
are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
2510-2521, and contain information that is privileged, confidential or
otherwise protected from disclosure.  If you are not the intended recipient
or an agent responsible for delivering the communication to the intended
recipient, you are hereby notified that you have received this
communication in error.  Dissemination, distribution or copying of this
e-mail or the information herein by anyone other than the intended
recipient, or an employee or agent responsible for delivering the message
to the intended recipient, is prohibited.  If you have received this
communication in error, please notify us immediately by e-mail and delete
the original message.  Thank you.

P Please consider the environment before printing.


On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> Have you looked at
>
> > > options("width")
> > $width
> > [1] 80
>
> and does that get at what you need?
>
> Ben
>
>
>
>
> > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com>
> wrote:
> >
> > Hello,
> >
> > On a non Windows OS the following command: Sys.getenv("COLUMNS")
> > Will return the current width of the R terminal (console) but this does
> not
> > work on a Windows OS.
> >
> > Does anyone know equivelant R code when install on a Windows OS?
> >
> > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
> >
> > Thanks,
> >
> > *Jared Studyvin, PhD *
> > *Statistician*
> >
> >
> > Environmental & Statistical Consultants
> > 200 S. Second Street
> > Laramie, WY 82070
> > (307) 721-3179
> > jstudyvin at west-inc.com
> > www.west-inc.com
> >
> > *Follow WEST: *Facebook
> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> 90Technology%E2%80%90WESTInc/125604770807646>
> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >
> > CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jstudyvin at west-inc.com  Fri Jan 20 17:52:29 2017
From: jstudyvin at west-inc.com (Jared Studyvin)
Date: Fri, 20 Jan 2017 09:52:29 -0700
Subject: [R] Current Terminal (console) width
In-Reply-To: <1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
	<1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CADmTk9GjL8V8=8z37T4Ycm8YyZ8cYnn5+C5gNNYrU+cvKfpLfw@mail.gmail.com>

David,

When using native R GUI that does work because the option is checked to do
that. See Edit -> GUI Preferences...

I'm looking for the R code that will do that same thing so when R is not
being run in the native GUI I can ensure that same behavior.

Thanks,


*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanying communications
are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
2510-2521, and contain information that is privileged, confidential or
otherwise protected from disclosure.  If you are not the intended recipient
or an agent responsible for delivering the communication to the intended
recipient, you are hereby notified that you have received this
communication in error.  Dissemination, distribution or copying of this
e-mail or the information herein by anyone other than the intended
recipient, or an employee or agent responsible for delivering the message
to the intended recipient, is prohibited.  If you have received this
communication in error, please notify us immediately by e-mail and delete
the original message.  Thank you.

P Please consider the environment before printing.


On Fri, Jan 20, 2017 at 9:29 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> I cannot replicate that on Windows 8 (64 bit or 32 bit):
>
> > options('width')
> $width
> [1] 90
>
> # Drag the window to resize, then:
>
> > options('width')
> $width
> [1] 124
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jared
> Studyvin
> Sent: Friday, January 20, 2017 10:18 AM
> To: Ben Tupper <btupper at bigelow.org>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Current Terminal (console) width
>
> Ben,
>
> That options control is about the size of what is printed. I'm looking for
> the actual size of the window in real time.
>
> options('width') ## returns 80
> resize the terminal window
> options('width') ## returns 80
>
> Sys.getenv('COLUMNS') ## returns current window width
> resize the terminal window
> Sys.getenv('COLUMNS') ## returns a different value
>
> This however does not work on a Windows OS.
>
> Thanks,
>
>
>
>
> *Jared Studyvin, PhD *
> *Statistician*
>
>
> Environmental & Statistical Consultants
> 200 S. Second Street
> Laramie, WY 82070
> (307) 721-3179
> jstudyvin at west-inc.com
> www.west-inc.com
>
> *Follow WEST: *Facebook
> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> 90Technology%E2%80%90WESTInc/125604770807646>
> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>
> CONFIDENTIALITY NOTICE:  This message and any accompanying communications
> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> 2510-2521, and contain information that is privileged, confidential or
> otherwise protected from disclosure.  If you are not the intended recipient
> or an agent responsible for delivering the communication to the intended
> recipient, you are hereby notified that you have received this
> communication in error.  Dissemination, distribution or copying of this
> e-mail or the information herein by anyone other than the intended
> recipient, or an employee or agent responsible for delivering the message
> to the intended recipient, is prohibited.  If you have received this
> communication in error, please notify us immediately by e-mail and delete
> the original message.  Thank you.
>
> P Please consider the environment before printing.
>
>
> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:
>
> > Hi,
> >
> > Have you looked at
> >
> > > > options("width")
> > > $width
> > > [1] 80
> >
> > and does that get at what you need?
> >
> > Ben
> >
> >
> >
> >
> > > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com>
> > wrote:
> > >
> > > Hello,
> > >
> > > On a non Windows OS the following command: Sys.getenv("COLUMNS")
> > > Will return the current width of the R terminal (console) but this does
> > not
> > > work on a Windows OS.
> > >
> > > Does anyone know equivelant R code when install on a Windows OS?
> > >
> > > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
> > >
> > > Thanks,
> > >
> > > *Jared Studyvin, PhD *
> > > *Statistician*
> > >
> > >
> > > Environmental & Statistical Consultants
> > > 200 S. Second Street
> > > Laramie, WY 82070
> > > (307) 721-3179
> > > jstudyvin at west-inc.com
> > > www.west-inc.com
> > >
> > > *Follow WEST: *Facebook
> > > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> > 90Technology%E2%80%90WESTInc/125604770807646>
> > > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> > > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> > > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> > 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> > >
> > > CONFIDENTIALITY NOTICE:  This message and any
> accompanyi...{{dropped:19}}
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > Ben Tupper
> > Bigelow Laboratory for Ocean Sciences
> > 60 Bigelow Drive, P.O. Box 380
> > East Boothbay, Maine 04544
> > http://www.bigelow.org
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jan 20 18:02:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 20 Jan 2017 09:02:52 -0800
Subject: [R] Current Terminal (console) width
In-Reply-To: <1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
	<1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAGxFJbSK8BUmTTQtQ7ec+weDVjFm_R9oKwu7Pa6B2bOz5L-aaw@mail.gmail.com>

David et al:

from ?options

"width:
controls the maximum number of columns on a line used in printing
vectors, matrices and arrays, and when filling by cat.

[as Jared said]

...
Some R consoles automatically change the value when they are resized."

So this behavior depends on the unstated by both of you console in
which R is running.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jan 20, 2017 at 8:29 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> I cannot replicate that on Windows 8 (64 bit or 32 bit):
>
>> options('width')
> $width
> [1] 90
>
> # Drag the window to resize, then:
>
>> options('width')
> $width
> [1] 124
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jared Studyvin
> Sent: Friday, January 20, 2017 10:18 AM
> To: Ben Tupper <btupper at bigelow.org>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Current Terminal (console) width
>
> Ben,
>
> That options control is about the size of what is printed. I'm looking for
> the actual size of the window in real time.
>
> options('width') ## returns 80
> resize the terminal window
> options('width') ## returns 80
>
> Sys.getenv('COLUMNS') ## returns current window width
> resize the terminal window
> Sys.getenv('COLUMNS') ## returns a different value
>
> This however does not work on a Windows OS.
>
> Thanks,
>
>
>
>
> *Jared Studyvin, PhD *
> *Statistician*
>
>
> Environmental & Statistical Consultants
> 200 S. Second Street
> Laramie, WY 82070
> (307) 721-3179
> jstudyvin at west-inc.com
> www.west-inc.com
>
> *Follow WEST: *Facebook
> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>
> CONFIDENTIALITY NOTICE:  This message and any accompanying communications
> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> 2510-2521, and contain information that is privileged, confidential or
> otherwise protected from disclosure.  If you are not the intended recipient
> or an agent responsible for delivering the communication to the intended
> recipient, you are hereby notified that you have received this
> communication in error.  Dissemination, distribution or copying of this
> e-mail or the information herein by anyone other than the intended
> recipient, or an employee or agent responsible for delivering the message
> to the intended recipient, is prohibited.  If you have received this
> communication in error, please notify us immediately by e-mail and delete
> the original message.  Thank you.
>
> P Please consider the environment before printing.
>
>
> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:
>
>> Hi,
>>
>> Have you looked at
>>
>> > > options("width")
>> > $width
>> > [1] 80
>>
>> and does that get at what you need?
>>
>> Ben
>>
>>
>>
>>
>> > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com>
>> wrote:
>> >
>> > Hello,
>> >
>> > On a non Windows OS the following command: Sys.getenv("COLUMNS")
>> > Will return the current width of the R terminal (console) but this does
>> not
>> > work on a Windows OS.
>> >
>> > Does anyone know equivelant R code when install on a Windows OS?
>> >
>> > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
>> >
>> > Thanks,
>> >
>> > *Jared Studyvin, PhD *
>> > *Statistician*
>> >
>> >
>> > Environmental & Statistical Consultants
>> > 200 S. Second Street
>> > Laramie, WY 82070
>> > (307) 721-3179
>> > jstudyvin at west-inc.com
>> > www.west-inc.com
>> >
>> > *Follow WEST: *Facebook
>> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
>> 90Technology%E2%80%90WESTInc/125604770807646>
>> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
>> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
>> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>> >
>> > CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>>
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Jan 20 18:04:53 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Jan 2017 09:04:53 -0800
Subject: [R] Current Terminal (console) width
In-Reply-To: <CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
Message-ID: <CAF8bMcYyJfGpr1xNQoEUp_A0YJ_ZHVZc77BjEBb=7AJOUxXaSA@mail.gmail.com>

The answer is UI-specific.

In the supplied-by-R-core Windows GUI for R, options("width") is the
current width of the command window.  If you run R in a cmd.exe window
instead of the GUI you can get the width of the cmd window by doing
some string manipulations on the output of shell("mode con",
intern=TRUE).  E.g.,
as.integer(sub("^.* ", "", grep(value=TRUE, "Columns:", shell("mode
con", intern=TRUE))))

(Setting options(width=120) when using the cmd window does not seem to
affect the input echoing - it seems to always be 80 characters.)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jan 20, 2017 at 8:17 AM, Jared Studyvin <jstudyvin at west-inc.com> wrote:
> Ben,
>
> That options control is about the size of what is printed. I'm looking for
> the actual size of the window in real time.
>
> options('width') ## returns 80
> resize the terminal window
> options('width') ## returns 80
>
> Sys.getenv('COLUMNS') ## returns current window width
> resize the terminal window
> Sys.getenv('COLUMNS') ## returns a different value
>
> This however does not work on a Windows OS.
>
> Thanks,
>
>
>
>
> *Jared Studyvin, PhD *
> *Statistician*
>
>
> Environmental & Statistical Consultants
> 200 S. Second Street
> Laramie, WY 82070
> (307) 721-3179
> jstudyvin at west-inc.com
> www.west-inc.com
>
> *Follow WEST: *Facebook
> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>
> CONFIDENTIALITY NOTICE:  This message and any accompanying communications
> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> 2510-2521, and contain information that is privileged, confidential or
> otherwise protected from disclosure.  If you are not the intended recipient
> or an agent responsible for delivering the communication to the intended
> recipient, you are hereby notified that you have received this
> communication in error.  Dissemination, distribution or copying of this
> e-mail or the information herein by anyone other than the intended
> recipient, or an employee or agent responsible for delivering the message
> to the intended recipient, is prohibited.  If you have received this
> communication in error, please notify us immediately by e-mail and delete
> the original message.  Thank you.
>
> P Please consider the environment before printing.
>
>
> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:
>
>> Hi,
>>
>> Have you looked at
>>
>> > > options("width")
>> > $width
>> > [1] 80
>>
>> and does that get at what you need?
>>
>> Ben
>>
>>
>>
>>
>> > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com>
>> wrote:
>> >
>> > Hello,
>> >
>> > On a non Windows OS the following command: Sys.getenv("COLUMNS")
>> > Will return the current width of the R terminal (console) but this does
>> not
>> > work on a Windows OS.
>> >
>> > Does anyone know equivelant R code when install on a Windows OS?
>> >
>> > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
>> >
>> > Thanks,
>> >
>> > *Jared Studyvin, PhD *
>> > *Statistician*
>> >
>> >
>> > Environmental & Statistical Consultants
>> > 200 S. Second Street
>> > Laramie, WY 82070
>> > (307) 721-3179
>> > jstudyvin at west-inc.com
>> > www.west-inc.com
>> >
>> > *Follow WEST: *Facebook
>> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
>> 90Technology%E2%80%90WESTInc/125604770807646>
>> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
>> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
>> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>> >
>> > CONFIDENTIALITY NOTICE:  This message and any accompanyi...{{dropped:19}}
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>>
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Fri Jan 20 18:29:54 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 20 Jan 2017 12:29:54 -0500
Subject: [R] Current Terminal (console) width
In-Reply-To: <CADmTk9GjL8V8=8z37T4Ycm8YyZ8cYnn5+C5gNNYrU+cvKfpLfw@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
	<1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
	<CADmTk9GjL8V8=8z37T4Ycm8YyZ8cYnn5+C5gNNYrU+cvKfpLfw@mail.gmail.com>
Message-ID: <CA+vqiLFavXO1v0L1QVcAktaJqe7yvY9Y3eA8-ixZh11qrGFyyQ@mail.gmail.com>

On Fri, Jan 20, 2017 at 11:52 AM, Jared Studyvin <jstudyvin at west-inc.com> wrot:
> David,
>
> When using native R GUI that does work because the option is checked to do
> that. See Edit -> GUI Preferences...
>
> I'm looking for the R code that will do that same thing so when R is not
> being run in the native GUI I can ensure that same behavior.

You still have not told use where it IS being run. That might be
useful information.

Best,
Ista

>
> Thanks,
>
>
> *Jared Studyvin, PhD *
> *Statistician*
>
>
> Environmental & Statistical Consultants
> 200 S. Second Street
> Laramie, WY 82070
> (307) 721-3179
> jstudyvin at west-inc.com
> www.west-inc.com
>
> *Follow WEST: *Facebook
> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>
> CONFIDENTIALITY NOTICE:  This message and any accompanying communications
> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> 2510-2521, and contain information that is privileged, confidential or
> otherwise protected from disclosure.  If you are not the intended recipient
> or an agent responsible for delivering the communication to the intended
> recipient, you are hereby notified that you have received this
> communication in error.  Dissemination, distribution or copying of this
> e-mail or the information herein by anyone other than the intended
> recipient, or an employee or agent responsible for delivering the message
> to the intended recipient, is prohibited.  If you have received this
> communication in error, please notify us immediately by e-mail and delete
> the original message.  Thank you.
>
> P Please consider the environment before printing.
>
>
> On Fri, Jan 20, 2017 at 9:29 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>
>> I cannot replicate that on Windows 8 (64 bit or 32 bit):
>>
>> > options('width')
>> $width
>> [1] 90
>>
>> # Drag the window to resize, then:
>>
>> > options('width')
>> $width
>> [1] 124
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jared
>> Studyvin
>> Sent: Friday, January 20, 2017 10:18 AM
>> To: Ben Tupper <btupper at bigelow.org>
>> Cc: r-help mailing list <r-help at r-project.org>
>> Subject: Re: [R] Current Terminal (console) width
>>
>> Ben,
>>
>> That options control is about the size of what is printed. I'm looking for
>> the actual size of the window in real time.
>>
>> options('width') ## returns 80
>> resize the terminal window
>> options('width') ## returns 80
>>
>> Sys.getenv('COLUMNS') ## returns current window width
>> resize the terminal window
>> Sys.getenv('COLUMNS') ## returns a different value
>>
>> This however does not work on a Windows OS.
>>
>> Thanks,
>>
>>
>>
>>
>> *Jared Studyvin, PhD *
>> *Statistician*
>>
>>
>> Environmental & Statistical Consultants
>> 200 S. Second Street
>> Laramie, WY 82070
>> (307) 721-3179
>> jstudyvin at west-inc.com
>> www.west-inc.com
>>
>> *Follow WEST: *Facebook
>> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
>> 90Technology%E2%80%90WESTInc/125604770807646>
>> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> <http://www.linkedin.com/company/1458419>, Join our Mailing list
>> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
>> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>>
>> CONFIDENTIALITY NOTICE:  This message and any accompanying communications
>> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
>> 2510-2521, and contain information that is privileged, confidential or
>> otherwise protected from disclosure.  If you are not the intended recipient
>> or an agent responsible for delivering the communication to the intended
>> recipient, you are hereby notified that you have received this
>> communication in error.  Dissemination, distribution or copying of this
>> e-mail or the information herein by anyone other than the intended
>> recipient, or an employee or agent responsible for delivering the message
>> to the intended recipient, is prohibited.  If you have received this
>> communication in error, please notify us immediately by e-mail and delete
>> the original message.  Thank you.
>>
>> P Please consider the environment before printing.
>>
>>
>> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:
>>
>> > Hi,
>> >
>> > Have you looked at
>> >
>> > > > options("width")
>> > > $width
>> > > [1] 80
>> >
>> > and does that get at what you need?
>> >
>> > Ben
>> >
>> >
>> >
>> >
>> > > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com>
>> > wrote:
>> > >
>> > > Hello,
>> > >
>> > > On a non Windows OS the following command: Sys.getenv("COLUMNS")
>> > > Will return the current width of the R terminal (console) but this does
>> > not
>> > > work on a Windows OS.
>> > >
>> > > Does anyone know equivelant R code when install on a Windows OS?
>> > >
>> > > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
>> > >
>> > > Thanks,
>> > >
>> > > *Jared Studyvin, PhD *
>> > > *Statistician*
>> > >
>> > >
>> > > Environmental & Statistical Consultants
>> > > 200 S. Second Street
>> > > Laramie, WY 82070
>> > > (307) 721-3179
>> > > jstudyvin at west-inc.com
>> > > www.west-inc.com
>> > >
>> > > *Follow WEST: *Facebook
>> > > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
>> > 90Technology%E2%80%90WESTInc/125604770807646>
>> > > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> > > <http://www.linkedin.com/company/1458419>, Join our Mailing list
>> > > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
>> > 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>> > >
>> > > CONFIDENTIALITY NOTICE:  This message and any
>> accompanyi...{{dropped:19}}
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > Ben Tupper
>> > Bigelow Laboratory for Ocean Sciences
>> > 60 Bigelow Drive, P.O. Box 380
>> > East Boothbay, Maine 04544
>> > http://www.bigelow.org
>> >
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jstudyvin at west-inc.com  Fri Jan 20 19:36:24 2017
From: jstudyvin at west-inc.com (Jared Studyvin)
Date: Fri, 20 Jan 2017 11:36:24 -0700
Subject: [R] Current Terminal (console) width
In-Reply-To: <CA+vqiLFavXO1v0L1QVcAktaJqe7yvY9Y3eA8-ixZh11qrGFyyQ@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
	<1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
	<CADmTk9GjL8V8=8z37T4Ycm8YyZ8cYnn5+C5gNNYrU+cvKfpLfw@mail.gmail.com>
	<CA+vqiLFavXO1v0L1QVcAktaJqe7yvY9Y3eA8-ixZh11qrGFyyQ@mail.gmail.com>
Message-ID: <CADmTk9HypgS6m7wMqS7OT+TZhesw3PNLWzYCm6RNcMbai5Nitw@mail.gmail.com>

Ista,

I use R through Emacs. I'm trying to get this to work there. At a more
basic level I'm disappointed that when I use R on my Mac I can get this
information but when I use R on Windows I can not.

Thanks,

*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanying communications
are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
2510-2521, and contain information that is privileged, confidential or
otherwise protected from disclosure.  If you are not the intended recipient
or an agent responsible for delivering the communication to the intended
recipient, you are hereby notified that you have received this
communication in error.  Dissemination, distribution or copying of this
e-mail or the information herein by anyone other than the intended
recipient, or an employee or agent responsible for delivering the message
to the intended recipient, is prohibited.  If you have received this
communication in error, please notify us immediately by e-mail and delete
the original message.  Thank you.

P Please consider the environment before printing.


On Fri, Jan 20, 2017 at 10:29 AM, Ista Zahn <istazahn at gmail.com> wrote:

> On Fri, Jan 20, 2017 at 11:52 AM, Jared Studyvin <jstudyvin at west-inc.com>
> wrot:
> > David,
> >
> > When using native R GUI that does work because the option is checked to
> do
> > that. See Edit -> GUI Preferences...
> >
> > I'm looking for the R code that will do that same thing so when R is not
> > being run in the native GUI I can ensure that same behavior.
>
> You still have not told use where it IS being run. That might be
> useful information.
>
> Best,
> Ista
>
> >
> > Thanks,
> >
> >
> > *Jared Studyvin, PhD *
> > *Statistician*
> >
> >
> > Environmental & Statistical Consultants
> > 200 S. Second Street
> > Laramie, WY 82070
> > (307) 721-3179
> > jstudyvin at west-inc.com
> > www.west-inc.com
> >
> > *Follow WEST: *Facebook
> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> 90Technology%E2%80%90WESTInc/125604770807646>
> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >
> > CONFIDENTIALITY NOTICE:  This message and any accompanying communications
> > are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> > 2510-2521, and contain information that is privileged, confidential or
> > otherwise protected from disclosure.  If you are not the intended
> recipient
> > or an agent responsible for delivering the communication to the intended
> > recipient, you are hereby notified that you have received this
> > communication in error.  Dissemination, distribution or copying of this
> > e-mail or the information herein by anyone other than the intended
> > recipient, or an employee or agent responsible for delivering the message
> > to the intended recipient, is prohibited.  If you have received this
> > communication in error, please notify us immediately by e-mail and delete
> > the original message.  Thank you.
> >
> > P Please consider the environment before printing.
> >
> >
> > On Fri, Jan 20, 2017 at 9:29 AM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> >
> >> I cannot replicate that on Windows 8 (64 bit or 32 bit):
> >>
> >> > options('width')
> >> $width
> >> [1] 90
> >>
> >> # Drag the window to resize, then:
> >>
> >> > options('width')
> >> $width
> >> [1] 124
> >>
> >> -------------------------------------
> >> David L Carlson
> >> Department of Anthropology
> >> Texas A&M University
> >> College Station, TX 77840-4352
> >>
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jared
> >> Studyvin
> >> Sent: Friday, January 20, 2017 10:18 AM
> >> To: Ben Tupper <btupper at bigelow.org>
> >> Cc: r-help mailing list <r-help at r-project.org>
> >> Subject: Re: [R] Current Terminal (console) width
> >>
> >> Ben,
> >>
> >> That options control is about the size of what is printed. I'm looking
> for
> >> the actual size of the window in real time.
> >>
> >> options('width') ## returns 80
> >> resize the terminal window
> >> options('width') ## returns 80
> >>
> >> Sys.getenv('COLUMNS') ## returns current window width
> >> resize the terminal window
> >> Sys.getenv('COLUMNS') ## returns a different value
> >>
> >> This however does not work on a Windows OS.
> >>
> >> Thanks,
> >>
> >>
> >>
> >>
> >> *Jared Studyvin, PhD *
> >> *Statistician*
> >>
> >>
> >> Environmental & Statistical Consultants
> >> 200 S. Second Street
> >> Laramie, WY 82070
> >> (307) 721-3179
> >> jstudyvin at west-inc.com
> >> www.west-inc.com
> >>
> >> *Follow WEST: *Facebook
> >> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> >> 90Technology%E2%80%90WESTInc/125604770807646>
> >> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> >> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> >> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> >> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >>
> >> CONFIDENTIALITY NOTICE:  This message and any accompanying
> communications
> >> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> >> 2510-2521, and contain information that is privileged, confidential or
> >> otherwise protected from disclosure.  If you are not the intended
> recipient
> >> or an agent responsible for delivering the communication to the intended
> >> recipient, you are hereby notified that you have received this
> >> communication in error.  Dissemination, distribution or copying of this
> >> e-mail or the information herein by anyone other than the intended
> >> recipient, or an employee or agent responsible for delivering the
> message
> >> to the intended recipient, is prohibited.  If you have received this
> >> communication in error, please notify us immediately by e-mail and
> delete
> >> the original message.  Thank you.
> >>
> >> P Please consider the environment before printing.
> >>
> >>
> >> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org>
> wrote:
> >>
> >> > Hi,
> >> >
> >> > Have you looked at
> >> >
> >> > > > options("width")
> >> > > $width
> >> > > [1] 80
> >> >
> >> > and does that get at what you need?
> >> >
> >> > Ben
> >> >
> >> >
> >> >
> >> >
> >> > > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com
> >
> >> > wrote:
> >> > >
> >> > > Hello,
> >> > >
> >> > > On a non Windows OS the following command: Sys.getenv("COLUMNS")
> >> > > Will return the current width of the R terminal (console) but this
> does
> >> > not
> >> > > work on a Windows OS.
> >> > >
> >> > > Does anyone know equivelant R code when install on a Windows OS?
> >> > >
> >> > > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
> >> > >
> >> > > Thanks,
> >> > >
> >> > > *Jared Studyvin, PhD *
> >> > > *Statistician*
> >> > >
> >> > >
> >> > > Environmental & Statistical Consultants
> >> > > 200 S. Second Street
> >> > > Laramie, WY 82070
> >> > > (307) 721-3179
> >> > > jstudyvin at west-inc.com
> >> > > www.west-inc.com
> >> > >
> >> > > *Follow WEST: *Facebook
> >> > > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> >> > 90Technology%E2%80%90WESTInc/125604770807646>
> >> > > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> >> > > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> >> > > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> >> > 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >> > >
> >> > > CONFIDENTIALITY NOTICE:  This message and any
> >> accompanyi...{{dropped:19}}
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide http://www.R-project.org/
> >> > posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > Ben Tupper
> >> > Bigelow Laboratory for Ocean Sciences
> >> > 60 Bigelow Drive, P.O. Box 380
> >> > East Boothbay, Maine 04544
> >> > http://www.bigelow.org
> >> >
> >> >
> >> >
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Fri Jan 20 22:40:38 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 20 Jan 2017 16:40:38 -0500
Subject: [R] Current Terminal (console) width
In-Reply-To: <CADmTk9HypgS6m7wMqS7OT+TZhesw3PNLWzYCm6RNcMbai5Nitw@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
	<1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
	<CADmTk9GjL8V8=8z37T4Ycm8YyZ8cYnn5+C5gNNYrU+cvKfpLfw@mail.gmail.com>
	<CA+vqiLFavXO1v0L1QVcAktaJqe7yvY9Y3eA8-ixZh11qrGFyyQ@mail.gmail.com>
	<CADmTk9HypgS6m7wMqS7OT+TZhesw3PNLWzYCm6RNcMbai5Nitw@mail.gmail.com>
Message-ID: <CA+vqiLEveQL_WTxLiBYkQpoFUvdLapvf=5+sRsg7b=eUkp6f6A@mail.gmail.com>

Hi Jared,

On Jan 20, 2017 1:36 PM, "Jared Studyvin" <jstudyvin at west-inc.com> wrote:

Ista,

I use R through Emacs. I'm trying to get this to work there.


Here is how ESS calculates the width of the comint buffer:

https://github.com/emacs-ess/ESS/blob/e21af4d2a09c6cb6061e8cd9f0f5cacadedcccc3/lisp/ess-inf.el#L2449

This works cross-platform.

At a more basic level I'm disappointed that when I use R on my Mac I can
get this information but when I use R on Windows I can not.


Sounds like an issue that should be taken up with microsoft.


Thanks,

*Jared Studyvin, PhD *
*Statistician*


Environmental & Statistical Consultants
200 S. Second Street
Laramie, WY 82070
(307) 721-3179
jstudyvin at west-inc.com
www.west-inc.com

*Follow WEST: *Facebook
<http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
, Twitter <http://twitter.com/WestEcoSystems>, Linked In
<http://www.linkedin.com/company/1458419>, Join our Mailing list
<http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>

CONFIDENTIALITY NOTICE:  This message and any accompanying communications
are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
2510-2521, and contain information that is privileged, confidential or
otherwise protected from disclosure.  If you are not the intended recipient
or an agent responsible for delivering the communication to the intended
recipient, you are hereby notified that you have received this
communication in error.  Dissemination, distribution or copying of this
e-mail or the information herein by anyone other than the intended
recipient, or an employee or agent responsible for delivering the message
to the intended recipient, is prohibited.  If you have received this
communication in error, please notify us immediately by e-mail and delete
the original message.  Thank you.

P Please consider the environment before printing.


On Fri, Jan 20, 2017 at 10:29 AM, Ista Zahn <istazahn at gmail.com> wrote:

> On Fri, Jan 20, 2017 at 11:52 AM, Jared Studyvin <jstudyvin at west-inc.com>
> wrot:
> > David,
> >
> > When using native R GUI that does work because the option is checked to
> do
> > that. See Edit -> GUI Preferences...
> >
> > I'm looking for the R code that will do that same thing so when R is not
> > being run in the native GUI I can ensure that same behavior.
>
> You still have not told use where it IS being run. That might be
> useful information.
>
> Best,
> Ista
>
> >
> > Thanks,
> >
> >
> > *Jared Studyvin, PhD *
> > *Statistician*
> >
> >
> > Environmental & Statistical Consultants
> > 200 S. Second Street
> > Laramie, WY 82070
> > (307) 721-3179
> > jstudyvin at west-inc.com
> > www.west-inc.com
> >
> > *Follow WEST: *Facebook
> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2
> %80%90Technology%E2%80%90WESTInc/125604770807646>
> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=00
> 1qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >
> > CONFIDENTIALITY NOTICE:  This message and any accompanying communications
> > are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> > 2510-2521, and contain information that is privileged, confidential or
> > otherwise protected from disclosure.  If you are not the intended
> recipient
> > or an agent responsible for delivering the communication to the intended
> > recipient, you are hereby notified that you have received this
> > communication in error.  Dissemination, distribution or copying of this
> > e-mail or the information herein by anyone other than the intended
> > recipient, or an employee or agent responsible for delivering the message
> > to the intended recipient, is prohibited.  If you have received this
> > communication in error, please notify us immediately by e-mail and delete
> > the original message.  Thank you.
> >
> > P Please consider the environment before printing.
> >
> >
> > On Fri, Jan 20, 2017 at 9:29 AM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> >
> >> I cannot replicate that on Windows 8 (64 bit or 32 bit):
> >>
> >> > options('width')
> >> $width
> >> [1] 90
> >>
> >> # Drag the window to resize, then:
> >>
> >> > options('width')
> >> $width
> >> [1] 124
> >>
> >> -------------------------------------
> >> David L Carlson
> >> Department of Anthropology
> >> Texas A&M University
> >> College Station, TX 77840-4352
> >>
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jared
> >> Studyvin
> >> Sent: Friday, January 20, 2017 10:18 AM
> >> To: Ben Tupper <btupper at bigelow.org>
> >> Cc: r-help mailing list <r-help at r-project.org>
> >> Subject: Re: [R] Current Terminal (console) width
> >>
> >> Ben,
> >>
> >> That options control is about the size of what is printed. I'm looking
> for
> >> the actual size of the window in real time.
> >>
> >> options('width') ## returns 80
> >> resize the terminal window
> >> options('width') ## returns 80
> >>
> >> Sys.getenv('COLUMNS') ## returns current window width
> >> resize the terminal window
> >> Sys.getenv('COLUMNS') ## returns a different value
> >>
> >> This however does not work on a Windows OS.
> >>
> >> Thanks,
> >>
> >>
> >>
> >>
> >> *Jared Studyvin, PhD *
> >> *Statistician*
> >>
> >>
> >> Environmental & Statistical Consultants
> >> 200 S. Second Street
> >> Laramie, WY 82070
> >> (307) 721-3179
> >> jstudyvin at west-inc.com
> >> www.west-inc.com
> >>
> >> *Follow WEST: *Facebook
> >> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> >> 90Technology%E2%80%90WESTInc/125604770807646>
> >> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> >> <http://www.linkedin.com/company/1458419>, Join our Mailing list
> >> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> >> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >>
> >> CONFIDENTIALITY NOTICE:  This message and any accompanying
> communications
> >> are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
> >> 2510-2521, and contain information that is privileged, confidential or
> >> otherwise protected from disclosure.  If you are not the intended
> recipient
> >> or an agent responsible for delivering the communication to the intended
> >> recipient, you are hereby notified that you have received this
> >> communication in error.  Dissemination, distribution or copying of this
> >> e-mail or the information herein by anyone other than the intended
> >> recipient, or an employee or agent responsible for delivering the
> message
> >> to the intended recipient, is prohibited.  If you have received this
> >> communication in error, please notify us immediately by e-mail and
> delete
> >> the original message.  Thank you.
> >>
> >> P Please consider the environment before printing.
> >>
> >>
> >> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org>
> wrote:
> >>
> >> > Hi,
> >> >
> >> > Have you looked at
> >> >
> >> > > > options("width")
> >> > > $width
> >> > > [1] 80
> >> >
> >> > and does that get at what you need?
> >> >
> >> > Ben
> >> >
> >> >
> >> >
> >> >
> >> > > On Jan 20, 2017, at 9:58 AM, Jared Studyvin <jstudyvin at west-inc.com
> >
> >> > wrote:
> >> > >
> >> > > Hello,
> >> > >
> >> > > On a non Windows OS the following command: Sys.getenv("COLUMNS")
> >> > > Will return the current width of the R terminal (console) but this
> does
> >> > not
> >> > > work on a Windows OS.
> >> > >
> >> > > Does anyone know equivelant R code when install on a Windows OS?
> >> > >
> >> > > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
> >> > >
> >> > > Thanks,
> >> > >
> >> > > *Jared Studyvin, PhD *
> >> > > *Statistician*
> >> > >
> >> > >
> >> > > Environmental & Statistical Consultants
> >> > > 200 S. Second Street
> >> > > Laramie, WY 82070
> >> > > (307) 721-3179
> >> > > jstudyvin at west-inc.com
> >> > > www.west-inc.com
> >> > >
> >> > > *Follow WEST: *Facebook
> >> > > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
> >> > 90Technology%E2%80%90WESTInc/125604770807646>
> >> > > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
> >> > > <http://www.linkedin.com/company/1458419>, Join our Mailing list
> >> > > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
> >> > 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
> >> > >
> >> > > CONFIDENTIALITY NOTICE:  This message and any
> >> accompanyi...{{dropped:19}}
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide http://www.R-project.org/
> >> > posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > Ben Tupper
> >> > Bigelow Laboratory for Ocean Sciences
> >> > 60 Bigelow Drive, P.O. Box 380
> >> > East Boothbay, Maine 04544
> >> > http://www.bigelow.org
> >> >
> >> >
> >> >
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Jan 20 22:41:27 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 21 Jan 2017 10:41:27 +1300
Subject: [R] [FORGED]  Fitting arima Models with Exogenous Variables
In-Reply-To: <CAMOcQfPK=1UZvFN5mS=Q6jH8T1qt1MMmNvoSQeh6MO9Rp9gcuA@mail.gmail.com>
References: <CAMOcQfPK=1UZvFN5mS=Q6jH8T1qt1MMmNvoSQeh6MO9Rp9gcuA@mail.gmail.com>
Message-ID: <ce0a0a41-0bb3-9c85-4ac0-50d3e570e2b2@auckland.ac.nz>

On 21/01/17 02:29, Paul Bernal wrote:
> Dear friends,
>
> I have 5 exogenous variables which I?d like to incorporate into my
> auto.arima model.
>
> I was able to incorporate the xreg, and I understand that newxreg should be
> the forecast of my exogenous variables, but I have not been able to get it
> to work.
>
> Newxreg should only have one column? Should newxreg have the same number of
> rows of the training data?
>
> This is the error I keep getting but I don?t quite understand:
>
> Error in forecast.Arima(ModelAfit, h = 12, newxreg = NewXreg) :
>   No regressors provided
> In addition: Warning message:
> In forecast.Arima(ModelAfit, h = 12, newxreg = NewXreg) :
>   The non-existent newxreg arguments will be ignored.
>
> Any help will be greatly appreciated,

You need to provide a *reproducible example*.  (Including data --- 
built-in data set, dput output, or simulation recipe with a seed set --- 
and an indication of what *packages* you are using.)

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Fri Jan 20 23:08:33 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 20 Jan 2017 14:08:33 -0800
Subject: [R] Current Terminal (console) width
In-Reply-To: <CA+vqiLEveQL_WTxLiBYkQpoFUvdLapvf=5+sRsg7b=eUkp6f6A@mail.gmail.com>
References: <CADmTk9E18sdS4EzrKBRJh25NO7YgT_3SyFD4PC9Q5wk-xenwNw@mail.gmail.com>
	<FFDFE1D4-8641-410B-A1EF-5C94D4E3EDE1@bigelow.org>
	<CADmTk9HMy7Q8wXb-qWnLwWdcD8AA25TzfN-L42iq6DECB-=S6g@mail.gmail.com>
	<1a96528cab584523b8960b71fa586e29@exch-2p-mbx-w2.ads.tamu.edu>
	<CADmTk9GjL8V8=8z37T4Ycm8YyZ8cYnn5+C5gNNYrU+cvKfpLfw@mail.gmail.com>
	<CA+vqiLFavXO1v0L1QVcAktaJqe7yvY9Y3eA8-ixZh11qrGFyyQ@mail.gmail.com>
	<CADmTk9HypgS6m7wMqS7OT+TZhesw3PNLWzYCm6RNcMbai5Nitw@mail.gmail.com>
	<CA+vqiLEveQL_WTxLiBYkQpoFUvdLapvf=5+sRsg7b=eUkp6f6A@mail.gmail.com>
Message-ID: <23BAAD35-BFF1-4A81-BD05-AADA59D3EF56@dcn.davis.ca.us>

For clarity, maintenance of the COLUMNS environment variable is a feature of certain terminal drivers, and is therefore an operating system feature, not an R feature. 
-- 
Sent from my phone. Please excuse my brevity.

On January 20, 2017 1:40:38 PM PST, Ista Zahn <istazahn at gmail.com> wrote:
>Hi Jared,
>
>On Jan 20, 2017 1:36 PM, "Jared Studyvin" <jstudyvin at west-inc.com>
>wrote:
>
>Ista,
>
>I use R through Emacs. I'm trying to get this to work there.
>
>
>Here is how ESS calculates the width of the comint buffer:
>
>https://github.com/emacs-ess/ESS/blob/e21af4d2a09c6cb6061e8cd9f0f5cacadedcccc3/lisp/ess-inf.el#L2449
>
>This works cross-platform.
>
>At a more basic level I'm disappointed that when I use R on my Mac I
>can
>get this information but when I use R on Windows I can not.
>
>
>Sounds like an issue that should be taken up with microsoft.
>
>
>Thanks,
>
>*Jared Studyvin, PhD *
>*Statistician*
>
>
>Environmental & Statistical Consultants
>200 S. Second Street
>Laramie, WY 82070
>(307) 721-3179
>jstudyvin at west-inc.com
>www.west-inc.com
>
>*Follow WEST: *Facebook
><http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%90Technology%E2%80%90WESTInc/125604770807646>
>, Twitter <http://twitter.com/WestEcoSystems>, Linked In
><http://www.linkedin.com/company/1458419>, Join our Mailing list
><http://visitor.r20.constantcontact.com/manage/optin/ea?v=001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>
>CONFIDENTIALITY NOTICE:  This message and any accompanying
>communications
>are covered by the Electronic Communications Privacy Act, 18 U.S.C. ??
>2510-2521, and contain information that is privileged, confidential or
>otherwise protected from disclosure.  If you are not the intended
>recipient
>or an agent responsible for delivering the communication to the
>intended
>recipient, you are hereby notified that you have received this
>communication in error.  Dissemination, distribution or copying of this
>e-mail or the information herein by anyone other than the intended
>recipient, or an employee or agent responsible for delivering the
>message
>to the intended recipient, is prohibited.  If you have received this
>communication in error, please notify us immediately by e-mail and
>delete
>the original message.  Thank you.
>
>P Please consider the environment before printing.
>
>
>On Fri, Jan 20, 2017 at 10:29 AM, Ista Zahn <istazahn at gmail.com> wrote:
>
>> On Fri, Jan 20, 2017 at 11:52 AM, Jared Studyvin
><jstudyvin at west-inc.com>
>> wrot:
>> > David,
>> >
>> > When using native R GUI that does work because the option is
>checked to
>> do
>> > that. See Edit -> GUI Preferences...
>> >
>> > I'm looking for the R code that will do that same thing so when R
>is not
>> > being run in the native GUI I can ensure that same behavior.
>>
>> You still have not told use where it IS being run. That might be
>> useful information.
>>
>> Best,
>> Ista
>>
>> >
>> > Thanks,
>> >
>> >
>> > *Jared Studyvin, PhD *
>> > *Statistician*
>> >
>> >
>> > Environmental & Statistical Consultants
>> > 200 S. Second Street
>> > Laramie, WY 82070
>> > (307) 721-3179
>> > jstudyvin at west-inc.com
>> > www.west-inc.com
>> >
>> > *Follow WEST: *Facebook
>> > <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2
>> %80%90Technology%E2%80%90WESTInc/125604770807646>
>> > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> > <http://www.linkedin.com/company/1458419>, Join our Mailing list
>> > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=00
>> 1qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>> >
>> > CONFIDENTIALITY NOTICE:  This message and any accompanying
>communications
>> > are covered by the Electronic Communications Privacy Act, 18 U.S.C.
>??
>> > 2510-2521, and contain information that is privileged, confidential
>or
>> > otherwise protected from disclosure.  If you are not the intended
>> recipient
>> > or an agent responsible for delivering the communication to the
>intended
>> > recipient, you are hereby notified that you have received this
>> > communication in error.  Dissemination, distribution or copying of
>this
>> > e-mail or the information herein by anyone other than the intended
>> > recipient, or an employee or agent responsible for delivering the
>message
>> > to the intended recipient, is prohibited.  If you have received
>this
>> > communication in error, please notify us immediately by e-mail and
>delete
>> > the original message.  Thank you.
>> >
>> > P Please consider the environment before printing.
>> >
>> >
>> > On Fri, Jan 20, 2017 at 9:29 AM, David L Carlson
><dcarlson at tamu.edu>
>> wrote:
>> >
>> >> I cannot replicate that on Windows 8 (64 bit or 32 bit):
>> >>
>> >> > options('width')
>> >> $width
>> >> [1] 90
>> >>
>> >> # Drag the window to resize, then:
>> >>
>> >> > options('width')
>> >> $width
>> >> [1] 124
>> >>
>> >> -------------------------------------
>> >> David L Carlson
>> >> Department of Anthropology
>> >> Texas A&M University
>> >> College Station, TX 77840-4352
>> >>
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Jared
>> >> Studyvin
>> >> Sent: Friday, January 20, 2017 10:18 AM
>> >> To: Ben Tupper <btupper at bigelow.org>
>> >> Cc: r-help mailing list <r-help at r-project.org>
>> >> Subject: Re: [R] Current Terminal (console) width
>> >>
>> >> Ben,
>> >>
>> >> That options control is about the size of what is printed. I'm
>looking
>> for
>> >> the actual size of the window in real time.
>> >>
>> >> options('width') ## returns 80
>> >> resize the terminal window
>> >> options('width') ## returns 80
>> >>
>> >> Sys.getenv('COLUMNS') ## returns current window width
>> >> resize the terminal window
>> >> Sys.getenv('COLUMNS') ## returns a different value
>> >>
>> >> This however does not work on a Windows OS.
>> >>
>> >> Thanks,
>> >>
>> >>
>> >>
>> >>
>> >> *Jared Studyvin, PhD *
>> >> *Statistician*
>> >>
>> >>
>> >> Environmental & Statistical Consultants
>> >> 200 S. Second Street
>> >> Laramie, WY 82070
>> >> (307) 721-3179
>> >> jstudyvin at west-inc.com
>> >> www.west-inc.com
>> >>
>> >> *Follow WEST: *Facebook
>> >> <http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
>> >> 90Technology%E2%80%90WESTInc/125604770807646>
>> >> , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> >> <http://www.linkedin.com/company/1458419>, Join our Mailing list
>> >> <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
>> >> 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>> >>
>> >> CONFIDENTIALITY NOTICE:  This message and any accompanying
>> communications
>> >> are covered by the Electronic Communications Privacy Act, 18
>U.S.C. ??
>> >> 2510-2521, and contain information that is privileged,
>confidential or
>> >> otherwise protected from disclosure.  If you are not the intended
>> recipient
>> >> or an agent responsible for delivering the communication to the
>intended
>> >> recipient, you are hereby notified that you have received this
>> >> communication in error.  Dissemination, distribution or copying of
>this
>> >> e-mail or the information herein by anyone other than the intended
>> >> recipient, or an employee or agent responsible for delivering the
>> message
>> >> to the intended recipient, is prohibited.  If you have received
>this
>> >> communication in error, please notify us immediately by e-mail and
>> delete
>> >> the original message.  Thank you.
>> >>
>> >> P Please consider the environment before printing.
>> >>
>> >>
>> >> On Fri, Jan 20, 2017 at 8:48 AM, Ben Tupper <btupper at bigelow.org>
>> wrote:
>> >>
>> >> > Hi,
>> >> >
>> >> > Have you looked at
>> >> >
>> >> > > > options("width")
>> >> > > $width
>> >> > > [1] 80
>> >> >
>> >> > and does that get at what you need?
>> >> >
>> >> > Ben
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > > On Jan 20, 2017, at 9:58 AM, Jared Studyvin
><jstudyvin at west-inc.com
>> >
>> >> > wrote:
>> >> > >
>> >> > > Hello,
>> >> > >
>> >> > > On a non Windows OS the following command:
>Sys.getenv("COLUMNS")
>> >> > > Will return the current width of the R terminal (console) but
>this
>> does
>> >> > not
>> >> > > work on a Windows OS.
>> >> > >
>> >> > > Does anyone know equivelant R code when install on a Windows
>OS?
>> >> > >
>> >> > > I'm using WIndows 10 Pro Version: 1607; R 3.3.2
>> >> > >
>> >> > > Thanks,
>> >> > >
>> >> > > *Jared Studyvin, PhD *
>> >> > > *Statistician*
>> >> > >
>> >> > >
>> >> > > Environmental & Statistical Consultants
>> >> > > 200 S. Second Street
>> >> > > Laramie, WY 82070
>> >> > > (307) 721-3179
>> >> > > jstudyvin at west-inc.com
>> >> > > www.west-inc.com
>> >> > >
>> >> > > *Follow WEST: *Facebook
>> >> > >
><http://www.facebook.com/pages/Western%E2%80%90EcoSystems%E2%80%
>> >> > 90Technology%E2%80%90WESTInc/125604770807646>
>> >> > > , Twitter <http://twitter.com/WestEcoSystems>, Linked In
>> >> > > <http://www.linkedin.com/company/1458419>, Join our Mailing
>list
>> >> > > <http://visitor.r20.constantcontact.com/manage/optin/ea?v=
>> >> > 001qrD4A3S5xJ5KgMyelH9jyw%3D%3D>
>> >> > >
>> >> > > CONFIDENTIALITY NOTICE:  This message and any
>> >> accompanyi...{{dropped:19}}
>> >> > >
>> >> > > ______________________________________________
>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > PLEASE do read the posting guide http://www.R-project.org/
>> >> > posting-guide.html
>> >> > > and provide commented, minimal, self-contained, reproducible
>code.
>> >> >
>> >> > Ben Tupper
>> >> > Bigelow Laboratory for Ocean Sciences
>> >> > 60 Bigelow Drive, P.O. Box 380
>> >> > East Boothbay, Maine 04544
>> >> > http://www.bigelow.org
>> >> >
>> >> >
>> >> >
>> >> >
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rob.vech87 at gmail.com  Thu Jan 19 20:18:12 2017
From: rob.vech87 at gmail.com (rob vech)
Date: Thu, 19 Jan 2017 20:18:12 +0100
Subject: [R] order list of date (bug?)
Message-ID: <6f286496-383e-a849-903c-973778fae196@gmail.com>

Hi list,
I'd like to submit the following problem that seems a bug but it is so 
strange that it could be my mind ... so
I would like to sort a list of date time items like in this script:

df = data.frame(DateTime = c(
'2016-12-21 10:34:54',
'2016-12-21 11:04:54',
'2016-12-21 11:34:54',
'2016-03-27 02:05:50',
'2016-03-27 02:35:50',
'2016-12-21 12:04:54',
'2016-12-21 12:34:54'
))

df$DateTime = as.POSIXlt(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S'))

ord = order(as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S')))

df.ord = df[ord,1]
df.ord

I have the following results:

"2016-12-21 10:34:54 CET"
"2016-12-21 11:04:54 CET"
"2016-12-21 11:34:54 CET"
"2016-12-21 12:04:54 CET"
"2016-12-21 12:34:54 CET"
"2016-03-27 02:05:50"
"2016-03-27 02:35:50"

the last two terms should be before (note that CET is missing).

if I change "2016-03-27 02:05:50" and "2016-03-27 02:35:50" to something 
like "2016-03-27 01:05:50" and "2016-03-27 01:35:50"
it seems to work. It seems to have problem with 02 hours. Any ideas?
I'm using R-3.1.2 on Win
Thank you
rob

	[[alternative HTML version deleted]]


From polidan19 at hotmail.com  Thu Jan 19 23:11:14 2017
From: polidan19 at hotmail.com (El Polidan)
Date: Thu, 19 Jan 2017 22:11:14 +0000
Subject: [R] Coverting HTML data into CSV
Message-ID: <HE1PR0601MB21561F7BF42B8CD314EFE65DB67E0@HE1PR0601MB2156.eurprd06.prod.outlook.com>

Good evening,


I need to convert and HTML data file into a CSV file.


I managed to read the html files in R. Any pointers on how to convert  into a readable data frame or csv?


Thank you.


Sent from Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From sergio.ferreira-cardoso at umontpellier.fr  Fri Jan 20 14:36:23 2017
From: sergio.ferreira-cardoso at umontpellier.fr (Sergio Ferreira Cardoso)
Date: Fri, 20 Jan 2017 14:36:23 +0100 (CET)
Subject: [R] Chi-square test
Message-ID: <646731128.10390242.1484919383326.JavaMail.zimbra@umontpellier.fr>

Dear all, 

Anova() for .car package retrieves Chi-square statistics when I'm testing a model the significance of a multivariate .gls model gls(x~1+2+3+x,corBrownian(phy=tree), ...). 
Is this Chi-square a two-sided test? 

Thank you. 

Best, 
S?rgio. 

	[[alternative HTML version deleted]]


From sff.cardoso at campus.fct.unl.pt  Fri Jan 20 14:39:10 2017
From: sff.cardoso at campus.fct.unl.pt (Sergio Ferreira Cardoso)
Date: Fri, 20 Jan 2017 14:39:10 +0100
Subject: [R] Anova() Chi-square test
Message-ID: <CAKPGrLz_8Zh22uRgdOnR8kOTUJrkVpfJdJg5SEXtAHqtdUANDQ@mail.gmail.com>

Dear all,

Anova() for .car package retrieves Chi-square statistics when I'm testing a
model the significance of a multivariate .gls model
gls(x~1+2+3+x,corBrownian(phy=tree), ...).
Is this Chi-square a two-sided test?

Thank you.

Best,
S?rgio.

-- 
Com os melhores cumprimentos,
S?rgio Ferreira Cardoso.

--------------------

Best regards,
S?rgio Ferreira Cardoso




MSc. Paleontology
Museu da Lourinh?, GEAL.
LATR/IST/CTN - Campus Tecnol?gico e Nuclear.

Lisboa, Portugal

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Fri Jan 20 16:09:47 2017
From: glennmschultz at me.com (Glenn Schultz)
Date: Fri, 20 Jan 2017 15:09:47 +0000 (GMT)
Subject: [R] Zip Files
Message-ID: <d03ad9a4-1e9e-4fd7-a1f0-1fd9ab58ff7a@me.com>

All,
I have a zip that was downloaded with HTTR. ? I had to use HTTR because I need to login and post to the website. ?The files download and by double clicking the file on my MAC the .zip file is inflated and a .txt is appears which I can then parse as needed. ?However, when I use unzip either at the terminal or in an R session the file does not open but I get the following message

Archive:? ar170106.zip
replace ar170106.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename:?

So it seems the MAC archive utility can open the file but unzip cannot. ?I have searched about for answers but no luck does anyone have an idea as to the possible cause of this behavior?

Best Regards,
Glenn

From elise.likiliki at gmail.com  Fri Jan 20 17:02:54 2017
From: elise.likiliki at gmail.com (Elise LIKILIKI)
Date: Fri, 20 Jan 2017 17:02:54 +0100
Subject: [R] Subset()
Message-ID: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>

Hello,

I have a dataset containing Date Time, Air Temperature, PPFD, Sol
Temperature...
The first data are false so I would like to extract the other ones.
I've tried :
>data1<-subset(data,DateTime>=as.POSIXct("2017-01-10
11:00:00",format="%Y-%m-%d
%H:%M:%S"),select=c(DateTime,PPFD_Avg,Air_Temp_Avg,RH_Avg,Soil_Temp_Avg))
But I still have 4 rows with data from 2017-01-10 10:00:00 to 2017-01-10
10:45:00 and I don't understand why.

Does anyone could help me please.

Thanks,

Elise LIKILIKI

	[[alternative HTML version deleted]]


From zcatav at gmail.com  Fri Jan 20 18:18:13 2017
From: zcatav at gmail.com (=?UTF-8?Q?Zeki_=C3=87ATAV?=)
Date: Fri, 20 Jan 2017 20:18:13 +0300
Subject: [R] non-numeric argument to binary operator
Message-ID: <CAP6VsRKzRMXpdubphjb9W-zSLjgJMp1O_fJZg8zGKz=fNxBotQ@mail.gmail.com>

Hi,
I'm working on following dataset.


> dput(uu5)
structure(list(grup = structure(c(1L, 1L, 2L, 2L), .Label = c("1",
"2"), class = "factor"), bw_grp = structure(c(1L, 2L, 1L, 2L), .Label =
c("0-999",
"1000+"), class = "factor"), deaths = c(6L, 13L, 1L, 2L), pop = c(26L,
67L, 41L, 93L), bw = c(500L, 1500L, 500L, 1500L), rates =
c(23.0769230769231,
19.4029850746269, 2.4390243902439, 2.1505376344086), pct =
c(0.279569892473118,
0.720430107526882, 0.305970149253731, 0.694029850746269), logexpo =
c(3.25809653802148,
4.20469261939097, 3.71357206670431, 4.53259949315326), grup1 = c(1,
1, 0, 0)), .Names = c("grup", "bw_grp", "deaths", "pop", "bw",
"rates", "pct", "logexpo", "grup1"), class = c("grouped_df",
"tbl_df", "tbl", "data.frame"), row.names = c(NA, -4L), vars = list(
    grup), labels = structure(list(grup = structure(1:2, .Label = c("1",
"2"), class = "factor")), row.names = c(NA, -2L), class = "data.frame",
vars = list(
    grup), drop = TRUE, .Names = "grup"), indices = list(0:1,
    2:3), drop = TRUE, group_sizes = c(2L, 2L), biggest_group_size = 2L)

When I try;
uu4 <- mutate(uu4, logexpo = log(pop), grup1 = as.numeric(group == 1 ))
fit <- glm(deaths ~ agegrp + grup1 + offset(log(pop)), data = uu4, family =
poisson)
coef(summary(fit))
exp(coef(fit)["grup1"])
data.frame(deviance(fit), df=fit$df.residual)
deviance(fit)/(fit$null.deviance ~ deviance(fit))
this code, I get an error related to last line:

Error in deviance(fit)/(fit$null.deviance ~ deviance(fit)) :
  non-numeric argument to binary operator

What's wrong? How can I correct this problem?
Thanks in advance.

PS: R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"

-- 
Zeki ?atav
http://zekicatav.com <http://zekicatav.tyih.gov.tr>
twitter.com/zcatav

	[[alternative HTML version deleted]]


From patzelt at g.harvard.edu  Fri Jan 20 19:46:30 2017
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Fri, 20 Jan 2017 13:46:30 -0500
Subject: [R] Estimated Marginal Means from PSCL Object
Message-ID: <CAB9UfhS+kjJXBAt-w55yRx0Xycut9EMtw2JuheFMji_Tu-otNw@mail.gmail.com>

Hi R-Help,

I have a pscl zero-inflated poisson regression object from which I am
trying to extract the estimated marginal means by category (e.g. GROUPA), I
can't figure out what I'm doing wrong with the lsmeans package:

FU1NSSI<-zeroinfl(W8_PAST4WEEKS_NSSI ~ GROUPA,
                na.action="na.exclude",data = FHB, dist = "poisson")

and

lsmeans(FU1NSSI, GROUPA)
Error in ref.grid(object = <S4 object of class "ref.grid">) :
  Can't handle an object of class  ?ref.grid?
 Use help("models", package = "lsmeans") for information on supported
models.

Thanks! Edward



-- 
Edward H Patzelt | Clinical Science PhD Student
Psychology | Harvard University
*Computational Cognitive Neuroscience Laboratory
<http://gershmanlab.webfactional.com/>*

	[[alternative HTML version deleted]]


From rxprtgama at gmail.com  Thu Jan 19 09:18:17 2017
From: rxprtgama at gmail.com (Joseph Gama)
Date: Thu, 19 Jan 2017 10:18:17 +0200
Subject: [R] No reply from CRAN Task View: Graphic Displays & Dynamic
 Graphics & Graphic Devices & Visualization
In-Reply-To: <1466457650.959487.643395241.4D327A50@webmail.messagingengine.com>
References: <CAEHfrcGHtBWw91F4Mqn2f8B38fG-Wj=3ddtdgBKPe00PnRiOvA@mail.gmail.com>
	<alpine.DEB.2.20.1606202152310.32217@paninaro>
	<1466457650.959487.643395241.4D327A50@webmail.messagingengine.com>
Message-ID: <CAEHfrcGdqkusY87VXb4A4N_UNqvcRktKnHGfOuDAEfr4QXu74w@mail.gmail.com>

It's already Winter and nothing has changed. Maybe you should let someone
else be in charge of something that you can't handle.

On Tue, Jun 21, 2016 at 12:20 AM, Nicholas Lewin-Koh <nikko at hailmail.net>
wrote:

> Yes, it needs a major re-write, and yes I got the suggestion, and it
> actually fits in the task view so I will include your package. I am
> planning a rewrite this summer.
>
> I usually urge people to have their package that does a particular plot
> in the appropriate task view, eg dendrograms in the phylogeny task view,
> etc.
>
> Nicholas
>
> On Mon, Jun 20, 2016, at 12:53, Achim Zeileis wrote:
> > On Mon, 20 Jun 2016, Joseph Gama wrote:
> >
> > > Hi all,
> > >
> > > I emailed a suggestion to Nicholas Lewin-Koh, the maintainer of the
> CRAN
> > > Task View: Graphic Displays & Dynamic Graphics & Graphic Devices &
> > > Visualization. I got no reply, so I wonder, is he still maintaining
> that
> > > view? If not, then who else does or will maintain it?
> >
> > To the best of my knowledge he is still maintaining it. I cc'ed Nicholas
> > in this reply.
> >
> > > BR,
> > >
> > > Jos? Gama
> > >
> > >     [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Sat Jan 21 03:25:18 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 20 Jan 2017 21:25:18 -0500
Subject: [R] non-numeric argument to binary operator
In-Reply-To: <CAP6VsRKzRMXpdubphjb9W-zSLjgJMp1O_fJZg8zGKz=fNxBotQ@mail.gmail.com>
References: <CAP6VsRKzRMXpdubphjb9W-zSLjgJMp1O_fJZg8zGKz=fNxBotQ@mail.gmail.com>
Message-ID: <CAGx1TMAee5fOv31KNTReA0oW2dfVAG9gEYetnDzamoYDvQ+QnQ@mail.gmail.com>

It looks like you are attempting to divide a number by a formula.

> 5 / (a ~ b)
Error in 5/(a ~ b) : non-numeric argument to binary operator


On Fri, Jan 20, 2017 at 12:18 PM, Zeki ?ATAV <zcatav at gmail.com> wrote:

> Hi,
> I'm working on following dataset.
>
>
> > dput(uu5)
> structure(list(grup = structure(c(1L, 1L, 2L, 2L), .Label = c("1",
> "2"), class = "factor"), bw_grp = structure(c(1L, 2L, 1L, 2L), .Label =
> c("0-999",
> "1000+"), class = "factor"), deaths = c(6L, 13L, 1L, 2L), pop = c(26L,
> 67L, 41L, 93L), bw = c(500L, 1500L, 500L, 1500L), rates =
> c(23.0769230769231,
> 19.4029850746269, 2.4390243902439, 2.1505376344086), pct =
> c(0.279569892473118,
> 0.720430107526882, 0.305970149253731, 0.694029850746269), logexpo =
> c(3.25809653802148,
> 4.20469261939097, 3.71357206670431, 4.53259949315326), grup1 = c(1,
> 1, 0, 0)), .Names = c("grup", "bw_grp", "deaths", "pop", "bw",
> "rates", "pct", "logexpo", "grup1"), class = c("grouped_df",
> "tbl_df", "tbl", "data.frame"), row.names = c(NA, -4L), vars = list(
>     grup), labels = structure(list(grup = structure(1:2, .Label = c("1",
> "2"), class = "factor")), row.names = c(NA, -2L), class = "data.frame",
> vars = list(
>     grup), drop = TRUE, .Names = "grup"), indices = list(0:1,
>     2:3), drop = TRUE, group_sizes = c(2L, 2L), biggest_group_size = 2L)
>
> When I try;
> uu4 <- mutate(uu4, logexpo = log(pop), grup1 = as.numeric(group == 1 ))
> fit <- glm(deaths ~ agegrp + grup1 + offset(log(pop)), data = uu4, family =
> poisson)
> coef(summary(fit))
> exp(coef(fit)["grup1"])
> data.frame(deviance(fit), df=fit$df.residual)
> deviance(fit)/(fit$null.deviance ~ deviance(fit))
> this code, I get an error related to last line:
>
> Error in deviance(fit)/(fit$null.deviance ~ deviance(fit)) :
>   non-numeric argument to binary operator
>
> What's wrong? How can I correct this problem?
> Thanks in advance.
>
> PS: R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
>
> --
> Zeki ?atav
> http://zekicatav.com <http://zekicatav.tyih.gov.tr>
> twitter.com/zcatav
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Jan 21 06:09:22 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 21 Jan 2017 05:09:22 +0000
Subject: [R] Chi-square test
In-Reply-To: <646731128.10390242.1484919383326.JavaMail.zimbra@umontpellier.fr>
References: <646731128.10390242.1484919383326.JavaMail.zimbra@umontpellier.fr>
Message-ID: <2C59CD56-B455-4941-BD1B-7B7D3A12ACF4@mcmaster.ca>

Dear Sergio,

You appear to have asked this question twice on r-help.

Anova() has no specific method for ?gls? models (I assume, though you don?t say so, that the model is fit by gls() in the nlme package), but the default method works and provides Wald chi-square tests for terms in the model. I don?t understand the model formula x ~ 1 + 2 + 3 + x, however, and so I have no idea what gls() would do with this model, other than report an error. Perhaps you can show us the output ? or, better yet, provide a reproducible example.

As a general matter, for 1-df terms in an additive model, the 1-df chi-square values reported by Anova() will simply be the squares of the corresponding Wald statistics (labelled ?t? I believe) reported in the summary of the model. Although the p-value is from the upper tail of the chi-square distribution, the test is inherently two-sided.

Best,
 John

-------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: http::/socserv.mcmaster.ca/jfox

> On Jan 20, 2017, at 8:36 AM, Sergio Ferreira Cardoso <sergio.ferreira-cardoso at umontpellier.fr> wrote:
> 
> Dear all, 
> 
> Anova() for .car package retrieves Chi-square statistics when I'm testing a model the significance of a multivariate .gls model gls(x~1+2+3+x,corBrownian(phy=tree), ...). 
> Is this Chi-square a two-sided test? 
> 
> Thank you. 
> 
> Best, 
> S?rgio. 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Jan 21 06:10:36 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Jan 2017 21:10:36 -0800
Subject: [R] order list of date (bug?)
In-Reply-To: <6f286496-383e-a849-903c-973778fae196@gmail.com>
References: <6f286496-383e-a849-903c-973778fae196@gmail.com>
Message-ID: <CAF8bMcb=DgwRLS+=xZ5Oze2jCTAuwu2Y_pkEbbO4y7t6F6FF5w@mail.gmail.com>

When did the switch between 'summer time'/'winter time' (or 'daylight
savings'/'standard') happen in CET last year?  (Did 2:35 exist on
March 27, 2016?)

At the R level, what is
  as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S'))
with your time zone settings?
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 19, 2017 at 11:18 AM, rob vech <rob.vech87 at gmail.com> wrote:
> Hi list,
> I'd like to submit the following problem that seems a bug but it is so
> strange that it could be my mind ... so
> I would like to sort a list of date time items like in this script:
>
> df = data.frame(DateTime = c(
> '2016-12-21 10:34:54',
> '2016-12-21 11:04:54',
> '2016-12-21 11:34:54',
> '2016-03-27 02:05:50',
> '2016-03-27 02:35:50',
> '2016-12-21 12:04:54',
> '2016-12-21 12:34:54'
> ))
>
> df$DateTime = as.POSIXlt(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S'))
>
> ord = order(as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S')))
>
> df.ord = df[ord,1]
> df.ord
>
> I have the following results:
>
> "2016-12-21 10:34:54 CET"
> "2016-12-21 11:04:54 CET"
> "2016-12-21 11:34:54 CET"
> "2016-12-21 12:04:54 CET"
> "2016-12-21 12:34:54 CET"
> "2016-03-27 02:05:50"
> "2016-03-27 02:35:50"
>
> the last two terms should be before (note that CET is missing).
>
> if I change "2016-03-27 02:05:50" and "2016-03-27 02:35:50" to something
> like "2016-03-27 01:05:50" and "2016-03-27 01:35:50"
> it seems to work. It seems to have problem with 02 hours. Any ideas?
> I'm using R-3.1.2 on Win
> Thank you
> rob
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Jan 21 06:25:08 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Jan 2017 23:25:08 -0600
Subject: [R] Subset()
In-Reply-To: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>
References: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>
Message-ID: <5AF73B7B-C617-4CA0-BAB3-D024160522F7@comcast.net>

How are we supposed to help you if you don?t read the Posting Guide and don?t provide any information about the classes of columns in `data`.?

? David.



> On Jan 20, 2017, at 10:02 AM, Elise LIKILIKI <elise.likiliki at gmail.com> wrote:
> 
> Hello,
> 
> I have a dataset containing Date Time, Air Temperature, PPFD, Sol
> Temperature...
> The first data are false so I would like to extract the other ones.
> I've tried :
>> data1<-subset(data,DateTime>=as.POSIXct("2017-01-10
> 11:00:00",format="%Y-%m-%d
> %H:%M:%S"),select=c(DateTime,PPFD_Avg,Air_Temp_Avg,RH_Avg,Soil_Temp_Avg))
> But I still have 4 rows with data from 2017-01-10 10:00:00 to 2017-01-10
> 10:45:00 and I don't understand why.
> 
> Does anyone could help me please.
> 
> Thanks,
> 
> Elise LIKILIKI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Jan 21 06:31:28 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Jan 2017 23:31:28 -0600
Subject: [R] Chi-square test
In-Reply-To: <646731128.10390242.1484919383326.JavaMail.zimbra@umontpellier.fr>
References: <646731128.10390242.1484919383326.JavaMail.zimbra@umontpellier.fr>
Message-ID: <8C58EAFA-1ECF-4255-88A7-2741522F90FD@comcast.net>


> On Jan 20, 2017, at 7:36 AM, Sergio Ferreira Cardoso <sergio.ferreira-cardoso at umontpellier.fr> wrote:
> 
> Dear all, 
> 
> Anova() for .car package retrieves Chi-square statistics when I'm testing a model the significance of a multivariate .gls model gls(x~1+2+3+x,corBrownian(phy=tree), ...). 
> Is this Chi-square a two-sided test? 
that
If you explain what you mean by a "2-sided test" we might be able to help. It?s unlikely that the author set up the test so that it would fail when the fit was so good that the chi-square statistic was very small, but it?s also likely that departures from the implicit hypothesis of all the coefficients being identity 0 would have raised the chi-square statistic away from zero.

? 
David.
> 
> Thank you. 
> 
> Best, 
> S?rgio. 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From msharp at txbiomed.org  Sat Jan 21 07:14:38 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Sat, 21 Jan 2017 06:14:38 +0000
Subject: [R] Coverting HTML data into CSV
In-Reply-To: <HE1PR0601MB21561F7BF42B8CD314EFE65DB67E0@HE1PR0601MB2156.eurprd06.prod.outlook.com>
References: <HE1PR0601MB21561F7BF42B8CD314EFE65DB67E0@HE1PR0601MB2156.eurprd06.prod.outlook.com>
Message-ID: <F873A98E-6585-4858-90B7-A958FD1B773A@txbiomed.org>

An example of your data will be very helpful. Saying that you have contents of an HTML file is not sufficiently descriptive. Note that the instructions recommend commented, minimal, self-contained, reproducible code. In leu of the HTML data file and code used to read it, you can use dput() with its argument being the object containing the HTML data.

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Jan 19, 2017, at 4:11 PM, El Polidan <polidan19 at hotmail.com> wrote:
>
> Good evening,
>
>
> I need to convert and HTML data file into a CSV file.
>
>
> I managed to read the html files in R. Any pointers on how to convert  into a readable data frame or csv?
>
>
> Thank you.
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From Berwin.Turlach at gmail.com  Sat Jan 21 07:43:03 2017
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Sat, 21 Jan 2017 14:43:03 +0800
Subject: [R] xvfb? cron job updates R packages,
 fails on some requiring X11
In-Reply-To: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>
References: <CAErODj8K8gbM6HxQvtQuaL6ypKhtC90d6_H+oAEfdE1U8kkWtw@mail.gmail.com>
Message-ID: <20170121144303.7ef91ba6@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Paul,

On Thu, 19 Jan 2017 10:52:16 -0600
Paul Johnson <pauljohn32 at gmail.com> wrote:

> In Centos 7 systems, I wrote a script that runs on the cron and I
> notice some package updates and installs fail like this:
> 
> [....]
> 
> I understand I need something like xvfb to simulate an X11 session,
> but I don't understand how to make it work.  Can one of you give me an
> idiot's guide on what to do?

I do not know about Centos (i.e. how to install the necessary
software), but on my Ubuntu machines I have since years the following
in my crontab:

44 4 * * * cd /opt/src ; /usr/bin/xvfb-run ./R-devel-Doit
44 5 * * * cd /opt/src ; /usr/bin/xvfb-run ./R-aop-Doit

Those scripts update the R source code (development version and patched
version of latest official release, respectively), compile and install
from scratch, and update (if necessary) some contributed packages for
these R versions.  

I do not have iplots among the packages that I need for these R
versions, but I do have rgl and upgrades of the latter work (without
the need of setting any environment variables).

Hope this helps.

Cheers,
	
	Berwin


From G.Maubach at gmx.de  Sat Jan 21 11:19:44 2017
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Sat, 21 Jan 2017 11:19:44 +0100
Subject: [R] Authentication and Web Site Scraping
Message-ID: <trinity-d2e1e7dd-b61c-401d-b1a9-b756ad2d8f3a-1484993984544@3capp-gmx-bs54>

Hi All,

I would like to learn how to scrape a web site which is password protected. I do my training with my Delicious web site. I will obey all rules and legislation existent.

The delicious export api was shut down. I assume that the web site will be shut down in the foreseeable future. In my Coursera Course I learned that it is possible to scrape web sites and extract the information in it. I would like to use this possibility to download the bookmark pages and extract the bookmarks with its accompanying tags as an alternative to the non-existant export api.

I started with

-- cut --
url_base <- "https://del.icio.us/gmaubach?&page="

data_created <- as.character(Sys.Date())
filename_base <-
  paste0(
    data_created,
    "_Delicious_Page_")

page_start <- 1
page_end <- 670

for (page in seq_along(page_start:page_end))
{
  download.file(
    url = paste0(
      url_base,
      as.character(page)),
    destfile = paste0(
      filename_base,
      as.character(page)))
}
-- cut --

This way approx. 1000 bookmarks are not loaded cause only the public bookmarks are shown. I know that it is possible to authenticate using something like

-- cut --
page <- GET("https://del.icio.us",
           authenticate("user", "password"))
-- cut --

To not have to authenticate over and over again, it is possible to use handles like

-- cut --
delicious <- handle("https://del.icio.us")
-- cut --

I do not know how I have to put it all together. What would be a statement sequence in getting all stored booksmarks on the pages 1..670 using authentication?

Kind regards

Georg


From drjimlemon at gmail.com  Sat Jan 21 11:36:05 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 21 Jan 2017 21:36:05 +1100
Subject: [R] Zip Files
In-Reply-To: <d03ad9a4-1e9e-4fd7-a1f0-1fd9ab58ff7a@me.com>
References: <d03ad9a4-1e9e-4fd7-a1f0-1fd9ab58ff7a@me.com>
Message-ID: <CA+8X3fU-Y3eRRHea3p=3DBJu+TRdrqVz3NVPhUvOhvN9TTMZwQ@mail.gmail.com>

Hi Glenn,
I would try the "rename" option which should allow you to give the
output another name.

Jim


On Sat, Jan 21, 2017 at 2:09 AM, Glenn Schultz <glennmschultz at me.com> wrote:
> All,
> I have a zip that was downloaded with HTTR.   I had to use HTTR because I
> need to login and post to the website.  The files download and by double
> clicking the file on my MAC the .zip file is inflated and a .txt is appears
> which I can then parse as needed.  However, when I use unzip either at the
> terminal or in an R session the file does not open but I get the following
> message
>
> Archive:  ar170106.zip
> replace ar170106.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename:
>
> So it seems the MAC archive utility can open the file but unzip cannot.  I
> have searched about for answers but no luck does anyone have an idea as to
> the possible cause of this behavior?
>
> Best Regards,
> Glenn
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Jan 21 11:41:16 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 21 Jan 2017 21:41:16 +1100
Subject: [R] Subset()
In-Reply-To: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>
References: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>
Message-ID: <CA+8X3fUX9qZhSJy+i2Se7M_9o_c_1Swj9YSf6uodvGM2dF9Kjg@mail.gmail.com>

Hi Elise,.
I would ask:

class(data$DateTime)

and see if it returns:

"POSIXct" "POSIXt"

Jim


On Sat, Jan 21, 2017 at 3:02 AM, Elise LIKILIKI
<elise.likiliki at gmail.com> wrote:
> Hello,
>
> I have a dataset containing Date Time, Air Temperature, PPFD, Sol
> Temperature...
> The first data are false so I would like to extract the other ones.
> I've tried :
>>data1<-subset(data,DateTime>=as.POSIXct("2017-01-10
> 11:00:00",format="%Y-%m-%d
> %H:%M:%S"),select=c(DateTime,PPFD_Avg,Air_Temp_Avg,RH_Avg,Soil_Temp_Avg))
> But I still have 4 rows with data from 2017-01-10 10:00:00 to 2017-01-10
> 10:45:00 and I don't understand why.
>
> Does anyone could help me please.
>
> Thanks,
>
> Elise LIKILIKI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Jan 21 13:59:12 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 21 Jan 2017 12:59:12 +0000
Subject: [R] Coverting HTML data into CSV
In-Reply-To: <HE1PR0601MB21561F7BF42B8CD314EFE65DB67E0@HE1PR0601MB2156.eurprd06.prod.outlook.com>
References: <HE1PR0601MB21561F7BF42B8CD314EFE65DB67E0@HE1PR0601MB2156.eurprd06.prod.outlook.com>
Message-ID: <58835B20.9060600@sapo.pt>

Hello,

You could give us an example of what html you are trying to read.
Follow this example:

install.packages("XML")

library(XML)

url <- 
"http://www.databaseolympics.com/sport/sportevent.htm?enum=110&sp=ATH"
dat <- readHTMLTable(readLines(url), which=2, header=TRUE, 
stringsAsFactors = FALSE)
str(dat)


Hope this helps,

Rui Barradas

Em 19-01-2017 22:11, El Polidan escreveu:
> Good evening,
>
>
> I need to convert and HTML data file into a CSV file.
>
>
> I managed to read the html files in R. Any pointers on how to convert  into a readable data frame or csv?
>
>
> Thank you.
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Sat Jan 21 17:25:55 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 21 Jan 2017 08:25:55 -0800
Subject: [R] order list of date (bug?)
In-Reply-To: <CAF8bMcb=DgwRLS+=xZ5Oze2jCTAuwu2Y_pkEbbO4y7t6F6FF5w@mail.gmail.com>
References: <6f286496-383e-a849-903c-973778fae196@gmail.com>
	<CAF8bMcb=DgwRLS+=xZ5Oze2jCTAuwu2Y_pkEbbO4y7t6F6FF5w@mail.gmail.com>
Message-ID: <CAF8bMcb=aNC1hW-UXzsT++e5J5-=OGycjWrpM2yCsGEJ2awd9A@mail.gmail.com>

It does look like "2016-03-27 02:35:00 CET" is a non-existent time
since the time sprang from 02:00-epsilon to 0:300 on that date.  The
POSIXlt entry for it is a missing value (per is.na()) and order() puts
missing values at the end, hence your problem.

It seems like a bug that POSIXlt entries with such invalid time print
oddly instead printing an NA.  is.na() says that they are
missing/invalid values.

> txt <- sprintf("2016-03-27 %02d:30:00", 1:4)
> txt
[1] "2016-03-27 01:30:00" "2016-03-27 02:30:00" "2016-03-27 03:30:00"
"2016-03-27 04:30:00"
> tim <- strptime(txt, format="%Y-%m-%d %H:%M:%S", tz="CET")
> tim
[1] "2016-03-27 01:30:00 CET"  "2016-03-27 02:30:00"      "2016-03-27
03:30:00 CEST" "2016-03-27 04:30:00 CEST"
> is.na(tim)
[1] FALSE  TRUE FALSE FALSE
> diff(tim)
Time differences in hours
[1] NA NA  1
> tim[3]-tim[1]
Time difference of 1 hours
> as.numeric(tim)
[1] 1459038600         NA 1459042200 1459045800

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jan 20, 2017 at 9:10 PM, William Dunlap <wdunlap at tibco.com> wrote:
> When did the switch between 'summer time'/'winter time' (or 'daylight
> savings'/'standard') happen in CET last year?  (Did 2:35 exist on
> March 27, 2016?)
>
> At the R level, what is
>   as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S'))
> with your time zone settings?
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Jan 19, 2017 at 11:18 AM, rob vech <rob.vech87 at gmail.com> wrote:
>> Hi list,
>> I'd like to submit the following problem that seems a bug but it is so
>> strange that it could be my mind ... so
>> I would like to sort a list of date time items like in this script:
>>
>> df = data.frame(DateTime = c(
>> '2016-12-21 10:34:54',
>> '2016-12-21 11:04:54',
>> '2016-12-21 11:34:54',
>> '2016-03-27 02:05:50',
>> '2016-03-27 02:35:50',
>> '2016-12-21 12:04:54',
>> '2016-12-21 12:34:54'
>> ))
>>
>> df$DateTime = as.POSIXlt(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S'))
>>
>> ord = order(as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S')))
>>
>> df.ord = df[ord,1]
>> df.ord
>>
>> I have the following results:
>>
>> "2016-12-21 10:34:54 CET"
>> "2016-12-21 11:04:54 CET"
>> "2016-12-21 11:34:54 CET"
>> "2016-12-21 12:04:54 CET"
>> "2016-12-21 12:34:54 CET"
>> "2016-03-27 02:05:50"
>> "2016-03-27 02:35:50"
>>
>> the last two terms should be before (note that CET is missing).
>>
>> if I change "2016-03-27 02:05:50" and "2016-03-27 02:35:50" to something
>> like "2016-03-27 01:05:50" and "2016-03-27 01:35:50"
>> it seems to work. It seems to have problem with 02 hours. Any ideas?
>> I'm using R-3.1.2 on Win
>> Thank you
>> rob
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Jan 21 23:32:49 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 22 Jan 2017 09:32:49 +1100
Subject: [R] Subset()
In-Reply-To: <CAFjJzakQpiJpFUTcM2YJKqdDCT6LAEE7HX0BqOSPc2RexeuGEQ@mail.gmail.com>
References: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>
	<CA+8X3fUX9qZhSJy+i2Se7M_9o_c_1Swj9YSf6uodvGM2dF9Kjg@mail.gmail.com>
	<CAFjJzakQpiJpFUTcM2YJKqdDCT6LAEE7HX0BqOSPc2RexeuGEQ@mail.gmail.com>
Message-ID: <CA+8X3fUKCndpCdWAkEWRK0tRNhUO0RM0hZdmV2im8xJ-WuRvKQ@mail.gmail.com>

Hi Elise,
If I create a CSV file like your example and read it into a data frame:

eldf<-read.csv("el.csv")

Then convert the first field to POSIXt dates:

eldf$DateTime<-strptime(eldf$DateTime,"%Y-%m-%d %H:%M:%S")
class(eldf$DateTime)
[1] "POSIXlt" "POSIXt"

I can subset the file like this:

time_after<-strptime("2017-01-09 18:00:00","%Y-%m-%d %H:%M:%S")
> time_after
[1] "2017-01-09 18:00:00 AEDT"
> eldf[eldf$DateTime >= time_after,]
            DateTime RECORD PTemp PPFD_Avg Air_Temp_Avg RH_avg Soil_Temp
7  2017-01-09 18:00:00      6 21.26   -48.83       -38.49 -0.415        79
8  2017-01-09 18:15:00      7 21.21   -52.23       -39.00 -0.642        79
9  2017-01-09 18:30:00      8 21.12   -54.68       -39.41 -0.805        79
10 2017-01-09 18:45:00      9 21.04   -56.44       .39.74 -0.939        79
11 2017-01-09 19:00:00     10 20.99   -57.71       -40.01 -1.046        79
12 2017-01-09 19:15:00     11 20.91   -58.66       -40.25 -1.137        79
13 2017-01-09 19:30:00     12 21.83   -59.39       -40.46 -1.208        79

Perhaps this will do what you want.

No need to apologize for your English, I could not make myself
understood in French.

Jim

On Sun, Jan 22, 2017 at 4:15 AM, Elise LIKILIKI
<elise.likiliki at gmail.com> wrote:
> Hi Jim,
>
> Yes exactly it returns "POSIXct" "POSIXt"
> Find attached a screenshot showing my data in "data" object.
> I don't need the data before 2017-01-10 11:00:00 nor columns : Records and
> Ptemp.
> I've tried with subset() and with [ ] but I still have some rows containing
> data before 2017-01-10 11:00:00.
>
> I'm french so I am really sorry about my english
>
> 2017-01-21 11:41 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Elise,.
>> I would ask:
>>
>> class(data$DateTime)
>>
>> and see if it returns:
>>
>> "POSIXct" "POSIXt"
>>
>> Jim
>>
>>
>> On Sat, Jan 21, 2017 at 3:02 AM, Elise LIKILIKI
>> <elise.likiliki at gmail.com> wrote:
>> > Hello,
>> >
>> > I have a dataset containing Date Time, Air Temperature, PPFD, Sol
>> > Temperature...
>> > The first data are false so I would like to extract the other ones.
>> > I've tried :
>> >>data1<-subset(data,DateTime>=as.POSIXct("2017-01-10
>> > 11:00:00",format="%Y-%m-%d
>> >
>> > %H:%M:%S"),select=c(DateTime,PPFD_Avg,Air_Temp_Avg,RH_Avg,Soil_Temp_Avg))
>> > But I still have 4 rows with data from 2017-01-10 10:00:00 to 2017-01-10
>> > 10:45:00 and I don't understand why.
>> >
>> > Does anyone could help me please.
>> >
>> > Thanks,
>> >
>> > Elise LIKILIKI
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Sun Jan 22 05:18:40 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 22 Jan 2017 15:18:40 +1100
Subject: [R] Subset()
In-Reply-To: <CAFjJza=0n6mYPbTxUUbsHefPJD2aOXb7FUn3Ztijxd1Fxk_uEQ@mail.gmail.com>
References: <CAFjJzakyevFhtG75YgtXrEd9+w-EfYPVkmhnh_tZ_hcQOpSQPg@mail.gmail.com>
	<CA+8X3fUX9qZhSJy+i2Se7M_9o_c_1Swj9YSf6uodvGM2dF9Kjg@mail.gmail.com>
	<CAFjJzakQpiJpFUTcM2YJKqdDCT6LAEE7HX0BqOSPc2RexeuGEQ@mail.gmail.com>
	<CA+8X3fUKCndpCdWAkEWRK0tRNhUO0RM0hZdmV2im8xJ-WuRvKQ@mail.gmail.com>
	<CAFjJzamZo1Ov3p=xBEONJsAd4UihB03t3r-PhwUwvXknC-od9A@mail.gmail.com>
	<CAFjJza=0n6mYPbTxUUbsHefPJD2aOXb7FUn3Ztijxd1Fxk_uEQ@mail.gmail.com>
Message-ID: <CA+8X3fXUE2JdTpJKLpmnVjYaDC=Dfy6ca1x1N6pRBhn0fhWwMg@mail.gmail.com>

Hi Elise,
One of the quirks of POSIXt time values is that they are lists. This
should give you the plot:

plot(Soil_Temp~as.numeric(DateTime),eldf,xaxt="n",xlab="DateTime")

and this the x axis:

axis.POSIXct(1,eldf$DateTime)

If you want a different format for the date values on the axis, look
at the "format" argument.

Jim


On Sun, Jan 22, 2017 at 2:32 PM, Elise LIKILIKI
<elise.likiliki at gmail.com> wrote:
> Hi Jim,
>
> I'm really sorry to bother you, but finally I have another problem, then
> when I try to make a plot
>>plot(Soil_Temp_Avg~DateTime,eldf2)
>
> I have an error message saying :
> Error in (function (formula, data = NULL, subset = NULL, na.action =
> na.fail, : invalid type (list) for variable 'DateTime'
>
>
> 2017-01-22 3:42 GMT+01:00 Elise LIKILIKI <elise.likiliki at gmail.com>:
>>
>> Hi Jim,
>>
>> Thank you so much, it works with your method !! I'm going to be able to
>> process my data, thanks again !
>>
>> Regards,
>>
>> Elise
>>
>> 2017-01-21 23:32 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:
>>>
>>> Hi Elise,
>>> If I create a CSV file like your example and read it into a data frame:
>>>
>>> eldf<-read.csv("el.csv")
>>>
>>> Then convert the first field to POSIXt dates:
>>>
>>> eldf$DateTime<-strptime(eldf$DateTime,"%Y-%m-%d %H:%M:%S")
>>> class(eldf$DateTime)
>>> [1] "POSIXlt" "POSIXt"
>>>
>>> I can subset the file like this:
>>>
>>> time_after<-strptime("2017-01-09 18:00:00","%Y-%m-%d %H:%M:%S")
>>> > time_after
>>> [1] "2017-01-09 18:00:00 AEDT"
>>> > eldf[eldf$DateTime >= time_after,]
>>>             DateTime RECORD PTemp PPFD_Avg Air_Temp_Avg RH_avg Soil_Temp
>>> 7  2017-01-09 18:00:00      6 21.26   -48.83       -38.49 -0.415
>>> 79
>>> 8  2017-01-09 18:15:00      7 21.21   -52.23       -39.00 -0.642
>>> 79
>>> 9  2017-01-09 18:30:00      8 21.12   -54.68       -39.41 -0.805
>>> 79
>>> 10 2017-01-09 18:45:00      9 21.04   -56.44       .39.74 -0.939
>>> 79
>>> 11 2017-01-09 19:00:00     10 20.99   -57.71       -40.01 -1.046
>>> 79
>>> 12 2017-01-09 19:15:00     11 20.91   -58.66       -40.25 -1.137
>>> 79
>>> 13 2017-01-09 19:30:00     12 21.83   -59.39       -40.46 -1.208
>>> 79
>>>
>>> Perhaps this will do what you want.
>>>
>>> No need to apologize for your English, I could not make myself
>>> understood in French.
>>>
>>> Jim
>>>
>>> On Sun, Jan 22, 2017 at 4:15 AM, Elise LIKILIKI
>>> <elise.likiliki at gmail.com> wrote:
>>> > Hi Jim,
>>> >
>>> > Yes exactly it returns "POSIXct" "POSIXt"
>>> > Find attached a screenshot showing my data in "data" object.
>>> > I don't need the data before 2017-01-10 11:00:00 nor columns : Records
>>> > and
>>> > Ptemp.
>>> > I've tried with subset() and with [ ] but I still have some rows
>>> > containing
>>> > data before 2017-01-10 11:00:00.
>>> >
>>> > I'm french so I am really sorry about my english
>>> >
>>> > 2017-01-21 11:41 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:
>>> >>
>>> >> Hi Elise,.
>>> >> I would ask:
>>> >>
>>> >> class(data$DateTime)
>>> >>
>>> >> and see if it returns:
>>> >>
>>> >> "POSIXct" "POSIXt"
>>> >>
>>> >> Jim
>>> >>
>>> >>
>>> >> On Sat, Jan 21, 2017 at 3:02 AM, Elise LIKILIKI
>>> >> <elise.likiliki at gmail.com> wrote:
>>> >> > Hello,
>>> >> >
>>> >> > I have a dataset containing Date Time, Air Temperature, PPFD, Sol
>>> >> > Temperature...
>>> >> > The first data are false so I would like to extract the other ones.
>>> >> > I've tried :
>>> >> >>data1<-subset(data,DateTime>=as.POSIXct("2017-01-10
>>> >> > 11:00:00",format="%Y-%m-%d
>>> >> >
>>> >> >
>>> >> > %H:%M:%S"),select=c(DateTime,PPFD_Avg,Air_Temp_Avg,RH_Avg,Soil_Temp_Avg))
>>> >> > But I still have 4 rows with data from 2017-01-10 10:00:00 to
>>> >> > 2017-01-10
>>> >> > 10:45:00 and I don't understand why.
>>> >> >
>>> >> > Does anyone could help me please.
>>> >> >
>>> >> > Thanks,
>>> >> >
>>> >> > Elise LIKILIKI
>>> >> >
>>> >> >         [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide
>>> >> > http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>
>>
>


From tr206 at kent.ac.uk  Sun Jan 22 14:11:19 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 22 Jan 2017 13:11:19 +0000
Subject: [R] Granger-causality test using vars package
Message-ID: <1485090697003.33648@kent.ac.uk>

Dear R-users,

I am trying to compute the test statistics for Granger-causality for a VAR(p) model using the "vars" package. I simply used the example proposed by the vars vignette and added the code for the Granger-causality. The code looks as follows



library(vars)

Canada<-Canada[, c("prod", "e", "U", "rw")]
p1ct<-VAR(Canada, p=1, type = "both")

causality(p1ct, cause = c("prod","e","U","rw"))



Unfortunately I get the error

Error in `[<-`(`*tmp*`, i, w[i], value = 1) : subscript out of bounds



Does any body know what is wrong with the code? I would like to create a matrix containing the F-values and the corresponding significance. How can I do that?

	[[alternative HTML version deleted]]


From fromnorden at gmail.com  Sun Jan 22 17:30:33 2017
From: fromnorden at gmail.com (Andreu Ferrero)
Date: Sun, 22 Jan 2017 17:30:33 +0100
Subject: [R] Can mice() handle crr()? Fine-Gray model,
	Object has no vcov() method.
Message-ID: <CAH2QH=e0xuk7KaGBR8DEX--PtusrDK3gdSw-pwM6hpV6GYXdZg@mail.gmail.com>

Here is an example:


# example

library(survival)
library(mice)
library(cmprsk)

test1 <- as.data.frame(list(time=c(4,3,1,1,2,2,3,5,2,4,5,1,
4,3,1,1,2,2,3,5,2,4,5,1),
                            status=c(1,1,1,0,2,2,0,0,1,1,2,0,
1,1,1,0,2,2,0,0,1,1,2,0),
                            x=c(0,2,1,1,NA,NA,0,1,1,2,0,1,
0,2,1,1,NA,NA,0,1,1,2,0,1),
                            sex=c(0,0,0,NA,1,1,1,1,NA,1,0,0,
0,0,0,NA,1,1,1,1,NA,1,0,0)))

dat <- mice(test1,m=10)

#Cox regression: cause 1

models.cox1 <- with(dat,coxph(Surv(time, status==1) ~ x +sex
))

summary(pool(models.cox1))

#Cox regression: cause 1 or 2

models.cox <- with(dat,coxph(Surv(time, status==1 | status==2) ~ x +sex
))
models.cox
summary(pool(models.cox))


# crr()

#Fine-Gray model

models.FG<- with(dat,crr(ftime=time, fstatus=status,  cov1=test1[,c(
"x","sex")], failcode=1, cencode=0, variance=TRUE))

summary(pool(models.FG))

#Error in pool(models.FG) : Object has no vcov() method.

models.FG




-- 
Andreu Ferrero Gregori

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Jan 23 06:49:59 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Jan 2017 23:49:59 -0600
Subject: [R] Can mice() handle crr()? Fine-Gray model,
	Object has no vcov() method.
In-Reply-To: <CAH2QH=e0xuk7KaGBR8DEX--PtusrDK3gdSw-pwM6hpV6GYXdZg@mail.gmail.com>
References: <CAH2QH=e0xuk7KaGBR8DEX--PtusrDK3gdSw-pwM6hpV6GYXdZg@mail.gmail.com>
Message-ID: <D2A18CDD-42B6-48F6-BF57-4A73B7CD9911@comcast.net>


> On Jan 22, 2017, at 10:30 AM, Andreu Ferrero <fromnorden at gmail.com> wrote:
> 
> Here is an example:
> 

Crossposting to stackoverflow and rhelp is deprecated. Read the Posting Guide. (And) Learn to ask the maintainer.

? 
David.
> 
> # example
> 
> library(survival)
> library(mice)
> library(cmprsk)
> 
> test1 <- as.data.frame(list(time=c(4,3,1,1,2,2,3,5,2,4,5,1,
> 4,3,1,1,2,2,3,5,2,4,5,1),
>                            status=c(1,1,1,0,2,2,0,0,1,1,2,0,
> 1,1,1,0,2,2,0,0,1,1,2,0),
>                            x=c(0,2,1,1,NA,NA,0,1,1,2,0,1,
> 0,2,1,1,NA,NA,0,1,1,2,0,1),
>                            sex=c(0,0,0,NA,1,1,1,1,NA,1,0,0,
> 0,0,0,NA,1,1,1,1,NA,1,0,0)))
> 
> dat <- mice(test1,m=10)
> 
> #Cox regression: cause 1
> 
> models.cox1 <- with(dat,coxph(Surv(time, status==1) ~ x +sex
> ))
> 
> summary(pool(models.cox1))
> 
> #Cox regression: cause 1 or 2
> 
> models.cox <- with(dat,coxph(Surv(time, status==1 | status==2) ~ x +sex
> ))
> models.cox
> summary(pool(models.cox))
> 
> 
> # crr()
> 
> #Fine-Gray model
> 
> models.FG<- with(dat,crr(ftime=time, fstatus=status,  cov1=test1[,c(
> "x","sex")], failcode=1, cencode=0, variance=TRUE))
> 
> summary(pool(models.FG))
> 
> #Error in pool(models.FG) : Object has no vcov() method.
> 
> models.FG
> 
> 
> 
> 
> -- 
> Andreu Ferrero Gregori
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From maechler at stat.math.ethz.ch  Mon Jan 23 09:08:39 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 Jan 2017 09:08:39 +0100
Subject: [R] runmed {stat}
In-Reply-To: <aada707d-fe01-a89c-30b2-e06adce14104@iit.edu>
References: <d99e81a3-7a2b-adbe-acb2-b2f1b6fffb42@iit.edu>
	<aada707d-fe01-a89c-30b2-e06adce14104@iit.edu>
Message-ID: <22661.47623.514325.473151@stat.math.ethz.ch>

>>>>> <someone>  on Sun, 22 Jan 2017 10:26:24 -0600 writes:

    > Dear Dr M?chler, I am using runmed from R's stat
    > package. I understand that you are the author of this package.

not of the package - but of function runmed().

I'm reply to R-help, so this answer maybe available to future
web searches.

    > I am using the function with even length k=40 and the
    > function forces it to be odd as k=41. I am sure there must
    > be reason behind this overriding behavior. May I ask if
    > you could enlighten me on this? Thank you in advance.

The help page - which one should really read (!) - says that k must be odd.

Why?  The median of an *odd* number of observations is "the
middle".  That's not the case with an even number, but a very
desirable property, which is kept even when iterating running
medians.
(Further, mathematically there are as many odd numbers as integers, so
 odd numbers should be sufficient ;-) ;-))

Martin Maechler
ETH Zurich


From Bernhard_Pfaff at fra.invesco.com  Mon Jan 23 10:12:04 2017
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Mon, 23 Jan 2017 09:12:04 +0000
Subject: [R] Granger-causality test using vars package
In-Reply-To: <1485090697003.33648@kent.ac.uk>
References: <1485090697003.33648@kent.ac.uk>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C712E962BFA@GBLONXMB13.corp.amvescap.net>

Dear T.Riedle,

you cannot assign *all* variables as a cause at once. Incidentally, in your example, you missed a 'data(Canada)'.
Having said this, you can loop over the variables names and extract the statistic/p-values. These are contained as named list elements 'statistic' and 'p.value' in the returned list object 'Granger' which is of informal class 'htest'.

Best wishes,
Bernhard

-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von T.Riedle
Gesendet: Sonntag, 22. Januar 2017 14:11
An: R-help at r-project.org
Betreff: [EXT] [R] Granger-causality test using vars package

Dear R-users,

I am trying to compute the test statistics for Granger-causality for a VAR(p) model using the "vars" package. I simply used the example proposed by the vars vignette and added the code for the Granger-causality. The code looks as follows



library(vars)

Canada<-Canada[, c("prod", "e", "U", "rw")] p1ct<-VAR(Canada, p=1, type = "both")

causality(p1ct, cause = c("prod","e","U","rw"))



Unfortunately I get the error

Error in `[<-`(`*tmp*`, i, w[i], value = 1) : subscript out of bounds



Does any body know what is wrong with the code? I would like to create a matrix containing the F-values and the corresponding significance. How can I do that?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From tr206 at kent.ac.uk  Mon Jan 23 13:25:33 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 23 Jan 2017 12:25:33 +0000
Subject: [R] Granger-causality test using vars package
In-Reply-To: <FCD9A33C859ACC469587CB09DD5C6C712E962BFA@GBLONXMB13.corp.amvescap.net>
References: <1485090697003.33648@kent.ac.uk>,
	<FCD9A33C859ACC469587CB09DD5C6C712E962BFA@GBLONXMB13.corp.amvescap.net>
Message-ID: <1485174352341.50944@kent.ac.uk>

Thank you for your reply. The code follows the example in the vignette and I changed it only a little as shown below.

library(vars)
data(Canada)
summary(Canada)
stat.desc(Canada,basic=FALSE)
plot(Canada, nc=2, xlab="")

# Testing for unit roots using ADF
adf1<-adf.test(Canada[,"prod"])
adf1
adf2<-adf.test(Canada[,"e"])
adf2
adf3<-adf.test(Canada[,"U"])
adf3
adf4<-adf.test(Canada[,"rw"])
adf4

# Use VAR to create a list of class varest
Canada<-Canada[, c("prod", "e", "U", "rw")]
p1ct<-VAR(Canada, p=1, type = "both")
p1ct
summary(p1ct, equation="e")
plot(p1ct, names = "e")

#Run Granger-causality test
causality(p1ct)

The Granger-causality test returns following output
$Granger

	Granger causality H0: prod do not Granger-cause e U rw

data:  VAR object p1ct
F-Test = 11.956, df1 = 3, df2 = 308, p-value = 1.998e-07


$Instant

	H0: No instantaneous causality between: prod and e U rw

data:  VAR object p1ct
Chi-squared = 3.7351, df = 3, p-value = 0.2915


Warning message:
In causality(p1ct) : 
Argument 'cause' has not been specified;
using first variable in 'x$y' (prod) as cause variable.

I am struggling with the result as it is not clear to me whether the variable prod Granger-causes e or U or rw. H0 is that prod does not Granger-cause e U rw. What does that mean? How can I find out if prod Granger-causes e, U and rw, respectively i.e. how can I determine that prod Granger-causes e, U and rw?

Thanks for your support in advance.
________________________________________
From: Pfaff, Bernhard Dr. <Bernhard_Pfaff at fra.invesco.com>
Sent: 23 January 2017 09:12
To: T.Riedle; R-help at r-project.org
Subject: AW:  [R] Granger-causality test using vars package

Dear T.Riedle,

you cannot assign *all* variables as a cause at once. Incidentally, in your example, you missed a 'data(Canada)'.
Having said this, you can loop over the variables names and extract the statistic/p-values. These are contained as named list elements 'statistic' and 'p.value' in the returned list object 'Granger' which is of informal class 'htest'.

Best wishes,
Bernhard

-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von T.Riedle
Gesendet: Sonntag, 22. Januar 2017 14:11
An: R-help at r-project.org
Betreff: [EXT] [R] Granger-causality test using vars package

Dear R-users,

I am trying to compute the test statistics for Granger-causality for a VAR(p) model using the "vars" package. I simply used the example proposed by the vars vignette and added the code for the Granger-causality. The code looks as follows



library(vars)

Canada<-Canada[, c("prod", "e", "U", "rw")] p1ct<-VAR(Canada, p=1, type = "both")

causality(p1ct, cause = c("prod","e","U","rw"))



Unfortunately I get the error

Error in `[<-`(`*tmp*`, i, w[i], value = 1) : subscript out of bounds



Does any body know what is wrong with the code? I would like to create a matrix containing the F-values and the corresponding significance. How can I do that?

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:11}}


From abhinabaroy09 at gmail.com  Mon Jan 23 13:29:55 2017
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Mon, 23 Jan 2017 17:59:55 +0530
Subject: [R] Extracting first number after * in a character vector
Message-ID: <CANtKHPUX-YN8k1N7ooEFJy8CRyRi2mZWL-iN7iQ-VU1bbjkB9g@mail.gmail.com>

Hi,

How do I extract the first number after '*' in a vector?

The vector is given below

> dput(out[1:10])
c("     1 X[0,SMITH]   *              0             0             1 ",
"     2 X[0,JOHNSON] *              0             0             1 ",
"     3 X[0,WILLIAMS]", "                    *              1             0
            1 ",
"     4 X[0,JONES]   *              0             0             1 ",
"     5 X[0,BROWN]   *              0             0             1 ",
"     6 X[0,DAVIS]   *              0             0             1 ",
"     7 X[0,MILLER]  *              0             0             1 ",
"     8 X[0,WILSON]  *              0             0             1 ",
"     9 X[0,MOORE]   *              0             0             1 "
)

I want a vector with the first number after the asterisk.

So the output would give me, a vector (0,0,1,0,0,0,0,0,0,0)

How can I do it in R?

Best,
Abhinaba

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Mon Jan 23 14:02:33 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 23 Jan 2017 14:02:33 +0100
Subject: [R] Extracting first number after * in a character vector
In-Reply-To: <CANtKHPUX-YN8k1N7ooEFJy8CRyRi2mZWL-iN7iQ-VU1bbjkB9g@mail.gmail.com>
References: <CANtKHPUX-YN8k1N7ooEFJy8CRyRi2mZWL-iN7iQ-VU1bbjkB9g@mail.gmail.com>
Message-ID: <0701b5a3-b900-e4b4-a627-ebd3ce2d0a7f@statistik.tu-dortmund.de>



On 23.01.2017 13:29, Abhinaba Roy wrote:
> Hi,
>
> How do I extract the first number after '*' in a vector?
>
> The vector is given below
>
>> dput(out[1:10])
> c("     1 X[0,SMITH]   *              0             0             1 ",
> "     2 X[0,JOHNSON] *              0             0             1 ",
> "     3 X[0,WILLIAMS]", "                    *              1             0
>             1 ",
> "     4 X[0,JONES]   *              0             0             1 ",
> "     5 X[0,BROWN]   *              0             0             1 ",
> "     6 X[0,DAVIS]   *              0             0             1 ",
> "     7 X[0,MILLER]  *              0             0             1 ",
> "     8 X[0,WILSON]  *              0             0             1 ",
> "     9 X[0,MOORE]   *              0             0             1 "
> )
>
> I want a vector with the first number after the asterisk.
>
> So the output would give me, a vector (0,0,1,0,0,0,0,0,0,0)
>
> How can I do it in R?

You know that your vector (called x below) contains an element without 
an asterisk?
If that happened by accident, use
  gsub(".+\\* *([[:digit:]]+).*", "\\1", x)
and if it could happen to have elements without an asterisk or number 
that follows, you can set these results to NA in a seperate step.

Best,
Uwe Ligges







>
> Best,
> Abhinaba
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From justanotherdigression at gmail.com  Mon Jan 23 13:28:17 2017
From: justanotherdigression at gmail.com (Luanna Dixson)
Date: Mon, 23 Jan 2017 13:28:17 +0100
Subject: [R] Suggestions for vectorizing/double loop
Message-ID: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>

I need to rename a bunch of files, by searching for string matches in a
list. Each list element containings a character with the old filename that
I want to match to, and the new file name that I want to rename by.

For instance, here filename '1001.xls' should match to list[[1]]$oldname
and I want to rename it to 'newa.xls' from list[[1]]$newname.

The actual new file names I have will feature a random alphanumeric number
and the list will have a length of ~600.


# files I want to rename

files with old file name =c('1001.xls', '1002.xls')

# list with old file names and new file names

oldnames=c('1001', '1002', '1003')

newnames=c('newa', 'newb', 'newc')

df=data.frame(oldnames,newnames)

list <- split(df, rownames(df))


# turn list elements in character

for(i in 1:length(list)) list[[i]]$oldnames=as.character(list[[i]]$oldnames)

for(i in 1:length(list)) list[[i]]$newnames=as.character(list[[i]]$newnames)


I heard that it would be better to vectorize this than trying to do a
double loop so if someone could give me a hint about how to do this I would
be very grateful!

	[[alternative HTML version deleted]]


From sergio.ferreira-cardoso at umontpellier.fr  Mon Jan 23 13:02:03 2017
From: sergio.ferreira-cardoso at umontpellier.fr (Sergio Ferreira Cardoso)
Date: Mon, 23 Jan 2017 13:02:03 +0100 (CET)
Subject: [R] Chi-square test
In-Reply-To: <2C59CD56-B455-4941-BD1B-7B7D3A12ACF4@mcmaster.ca>
References: <646731128.10390242.1484919383326.JavaMail.zimbra@umontpellier.fr>
	<2C59CD56-B455-4941-BD1B-7B7D3A12ACF4@mcmaster.ca>
Message-ID: <213918227.11644999.1485172923189.JavaMail.zimbra@umontpellier.fr>

Dear David and John,

Thank you for your replies. Indeed I'm using ape and nlme packages. Here it is:

> fit<-gls(fcl~mass+activity+agility,correlation=corBrownian(phy=tree),data=df,method="ML",weights=varFixed(~vf))
> Anova(fit)
Analysis of Deviance Table (Type II tests)

Response: fcl
         Df  Chisq Pr(>Chisq)
mass      1 0.1756     0.6752
activity  2 0.5549     0.7577
agility   4 3.2903     0.5105

Anyway, I have the help I was looking for. Thank you vey much.

Best regards,
S?rgio.

----- Mensagem original -----
> De: "Fox, John" <jfox at mcmaster.ca>
> Para: "Sergio Ferreira Cardoso" <sergio.ferreira-cardoso at umontpellier.fr>
> Cc: "R-help list" <r-help at r-project.org>
> Enviadas: S?bado, 21 De Janeiro de 2017 6:09:22
> Assunto: Re: [R] Chi-square test

> Dear Sergio,
> 
> You appear to have asked this question twice on r-help.
> 
> Anova() has no specific method for ?gls? models (I assume, though you don?t say
> so, that the model is fit by gls() in the nlme package), but the default method
> works and provides Wald chi-square tests for terms in the model. I don?t
> understand the model formula x ~ 1 + 2 + 3 + x, however, and so I have no idea
> what gls() would do with this model, other than report an error. Perhaps you
> can show us the output ? or, better yet, provide a reproducible example.
> 
> As a general matter, for 1-df terms in an additive model, the 1-df chi-square
> values reported by Anova() will simply be the squares of the corresponding Wald
> statistics (labelled ?t? I believe) reported in the summary of the model.
> Although the p-value is from the upper tail of the chi-square distribution, the
> test is inherently two-sided.
> 
> Best,
> John
> 
> -------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> Web: http::/socserv.mcmaster.ca/jfox
> 
>> On Jan 20, 2017, at 8:36 AM, Sergio Ferreira Cardoso
>> <sergio.ferreira-cardoso at umontpellier.fr> wrote:
>> 
>> Dear all,
>> 
>> Anova() for .car package retrieves Chi-square statistics when I'm testing a
>> model the significance of a multivariate .gls model
>> gls(x~1+2+3+x,corBrownian(phy=tree), ...).
>> Is this Chi-square a two-sided test?
>> 
>> Thank you.
>> 
>> Best,
>> S?rgio.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Mon Jan 23 14:12:44 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 Jan 2017 14:12:44 +0100
Subject: [R] Suggestions for vectorizing/double loop
In-Reply-To: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
References: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
Message-ID: <CAJuCY5xLJv9NV_qme2WCf6eCnRzLKW88UX0A_6=36UEJrw7Mkw@mail.gmail.com>

Dear Luanna,

Assuming that oldnames and newnames are character (and not factor), the
just use stringsAsFactors = FALSE. That will save you from having to
convert the factors back to character.

data.frame(oldnames, newnames, stringsAsFactor = FALSE)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-23 13:28 GMT+01:00 Luanna Dixson <justanotherdigression at gmail.com>:

> I need to rename a bunch of files, by searching for string matches in a
> list. Each list element containings a character with the old filename that
> I want to match to, and the new file name that I want to rename by.
>
> For instance, here filename '1001.xls' should match to list[[1]]$oldname
> and I want to rename it to 'newa.xls' from list[[1]]$newname.
>
> The actual new file names I have will feature a random alphanumeric number
> and the list will have a length of ~600.
>
>
> # files I want to rename
>
> files with old file name =c('1001.xls', '1002.xls')
>
> # list with old file names and new file names
>
> oldnames=c('1001', '1002', '1003')
>
> newnames=c('newa', 'newb', 'newc')
>
> df=data.frame(oldnames,newnames)
>
> list <- split(df, rownames(df))
>
>
> # turn list elements in character
>
> for(i in 1:length(list)) list[[i]]$oldnames=as.
> character(list[[i]]$oldnames)
>
> for(i in 1:length(list)) list[[i]]$newnames=as.
> character(list[[i]]$newnames)
>
>
> I heard that it would be better to vectorize this than trying to do a
> double loop so if someone could give me a hint about how to do this I would
> be very grateful!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Jan 23 14:21:59 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 23 Jan 2017 13:21:59 +0000
Subject: [R] Suggestions for vectorizing/double loop
In-Reply-To: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
References: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
Message-ID: <acce06d5-156f-de77-5987-2f6849125d01@dewey.myzen.co.uk>

Dear Luanna

It is not compulsory to avoid for loops but see below

On 23/01/2017 12:28, Luanna Dixson wrote:
> I need to rename a bunch of files, by searching for string matches in a
> list. Each list element containings a character with the old filename that
> I want to match to, and the new file name that I want to rename by.
>
> For instance, here filename '1001.xls' should match to list[[1]]$oldname
> and I want to rename it to 'newa.xls' from list[[1]]$newname.
>
> The actual new file names I have will feature a random alphanumeric number
> and the list will have a length of ~600.
>
>
> # files I want to rename
>
> files with old file name =c('1001.xls', '1002.xls')
>
> # list with old file names and new file names
>
> oldnames=c('1001', '1002', '1003')
>
> newnames=c('newa', 'newb', 'newc')
>
> df=data.frame(oldnames,newnames)
>
> list <- split(df, rownames(df))
>

Both df and list are already in existience and you are overwriting them. 
It is best practice not to do that.
>
> # turn list elements in character
>
> for(i in 1:length(list)) list[[i]]$oldnames=as.character(list[[i]]$oldnames)
>

Something like

lapply(list, function(x) x$oldnames <- as.character(x$oldnames))

would probably work.
You might want sapply instead of lapply

> for(i in 1:length(list)) list[[i]]$newnames=as.character(list[[i]]$newnames)
>
>
> I heard that it would be better to vectorize this than trying to do a
> double loop so if someone could give me a hint about how to do this I would
> be very grateful!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From petr.pikal at precheza.cz  Mon Jan 23 14:22:39 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Jan 2017 13:22:39 +0000
Subject: [R] Suggestions for vectorizing/double loop
In-Reply-To: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
References: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FF0D4@SRVEXCHCM301.precheza.cz>

Hi

In your case if you want to rename abot 600 items and your doble loop works it is not worth to vectorize it. However if you want to repeat such task often and you expect much bigger number of files vectorizing can speed things up and make them cleaner.

Although I must admit that I do not understand what your commands should actually do. AFAICU the list is the same before and after your "double" loop.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luanna
> Dixson
> Sent: Monday, January 23, 2017 1:28 PM
> To: r-help at r-project.org
> Subject: [R] Suggestions for vectorizing/double loop
>
> I need to rename a bunch of files, by searching for string matches in a list.
> Each list element containings a character with the old filename that I want to
> match to, and the new file name that I want to rename by.
>
> For instance, here filename '1001.xls' should match to list[[1]]$oldname and I
> want to rename it to 'newa.xls' from list[[1]]$newname.
>
> The actual new file names I have will feature a random alphanumeric number
> and the list will have a length of ~600.
>
>
> # files I want to rename
>
> files with old file name =c('1001.xls', '1002.xls')
>
> # list with old file names and new file names
>
> oldnames=c('1001', '1002', '1003')
>
> newnames=c('newa', 'newb', 'newc')
>
> df=data.frame(oldnames,newnames)
>
> list <- split(df, rownames(df))
>
>
> # turn list elements in character
>
> for(i in 1:length(list)) list[[i]]$oldnames=as.character(list[[i]]$oldnames)
>
> for(i in 1:length(list)) list[[i]]$newnames=as.character(list[[i]]$newnames)
>
>
> I heard that it would be better to vectorize this than trying to do a double
> loop so if someone could give me a hint about how to do this I would be very
> grateful!
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From andrew.halford at gmail.com  Mon Jan 23 15:42:28 2017
From: andrew.halford at gmail.com (Andrew Halford)
Date: Mon, 23 Jan 2017 22:42:28 +0800
Subject: [R] spatial analysis using quickPCNM
Message-ID: <CAJrFtqKXBg8Jpc0Xebk3pKb3Qx-Lsb0QhNuMwFTpoz=GFk=V6A@mail.gmail.com>

Hi Listers,

I posted this message to the R-sig-ecology group last Friday but have not
had a response hence my post here.

I have been trying to run spatial analyses on a fish community dataset.

My fish dataset has 114 species(variables) x 45 sites
My spatial dataset has the Lat and Long values for each site, converted to
cartesian coordinates



> fish <- read.table(file.choose())> latlong <- read.table(file.choose()) > fish.h <- decostand (fish, "hellinger")> fish.PCNM.quick <- quickPCNM(fish.h,latlong)

Truncation level = 639.5348
Time to compute PCNMs = 0.820000  sec Error in if (temp2.test[1, 5] <=
alpha) { : argument is of length zeroTiming stopped at: 1.06 0.05 1.19

I do not understand the error message coming up and would appreciate
some advice.

Andy


-- 
Andrew Halford Ph.D
Research Scientist (Kimberley Marine Parks)
Dept. Parks and Wildlife
Western Australia

Ph: +61 8 9219 9795
Mobile: +61 (0) 468 419 473

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Mon Jan 23 15:46:31 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 23 Jan 2017 08:46:31 -0600
Subject: [R] Can mice() handle crr()? Fine-Gray model
In-Reply-To: <mailman.1.1485169202.3239.r-help@r-project.org>
References: <mailman.1.1485169202.3239.r-help@r-project.org>
Message-ID: <021cdb$5lj4rt@ironport10.mayo.edu>

Look at the finegray command within the survival package; the competing risks vignette has 
coverage of it.  The command creates an expanded data set with case weights, such that 
coxph() on the new data set = the Fine Gray model for the original data.  Anything that 
works with coxph is valid on the new data.  Caveat -- I don't know mice() well at all: the 
dat1 data set below has multiple observations per subject, should the mice() command be 
cognizant of this?

Terry Therneau


library(survival)
library(mice)

test1 <- data.frame (time=c(4,3,1,1,2,2,3,5,2,4,5,1,
                             4,3,1,1,2,2,3,5,2,4,5,1),
                      status=c(1,1,1,0,2,2,0,0,1,1,2,0,
                               1,1,1,0,2,2,0,0,1,1,2,0),
                      x=c(0,2,1,1,NA,NA,0,1,1,2,0,1,
                          0,2,1,1,NA,NA,0,1,1,2,0,1),
                      sex=c(0,0,0,NA,1,1,1,1,NA,1,0,0,
                            0,0,0,NA,1,1,1,1,NA,1,0,0)))

# Endpoint 1, simple, then with mice
fit0 <- copxh(Surv(time, status==1) ~ sex + x, test1)
dat0 <- mice(test1, m=10)
mfit0 <- with(dat0, coxph(Surv(time, status==1) ~ sex + x))
summary(pool(mfit0))

# Endpoint 1, Fine-Gray model
fg1 <- finegray(Surv(time, factor(status)) ~ ., data=test1, etype=1)
fit1 <- coxph(Surv(fgstart, fgstop, fgstatus) ~ sex + x, data=fg1,
               weight= fgwt)

dat1 <- mice(fg1, m=10)
mfit1 <- with(dat1, coxph(Surv(fgstart, fgstop, fgstatus) ~ sex + x,
                          weight=fgwt))


On 01/23/2017 05:00 AM, r-help-request at r-project.org wrote:
> Here is an example:
>
>
> # example
>
> library(survival)
> library(mice)
> library(cmprsk)
>
> test1 <- as.data.frame(list(time=c(4,3,1,1,2,2,3,5,2,4,5,1,
> 4,3,1,1,2,2,3,5,2,4,5,1),
>                              status=c(1,1,1,0,2,2,0,0,1,1,2,0,
> 1,1,1,0,2,2,0,0,1,1,2,0),
>                              x=c(0,2,1,1,NA,NA,0,1,1,2,0,1,
> 0,2,1,1,NA,NA,0,1,1,2,0,1),
>                              sex=c(0,0,0,NA,1,1,1,1,NA,1,0,0,
> 0,0,0,NA,1,1,1,1,NA,1,0,0)))
>
> dat <- mice(test1,m=10)
>
> #Cox regression: cause 1
>
> models.cox1 <- with(dat,coxph(Surv(time, status==1) ~ x +sex
> ))
>
> summary(pool(models.cox1))
>
> #Cox regression: cause 1 or 2
>
> models.cox <- with(dat,coxph(Surv(time, status==1 | status==2) ~ x +sex
> ))
> models.cox
> summary(pool(models.cox))
>
>
> # crr()
>
> #Fine-Gray model
>
> models.FG<- with(dat,crr(ftime=time, fstatus=status,  cov1=test1[,c(
> "x","sex")], failcode=1, cencode=0, variance=TRUE))
>
> summary(pool(models.FG))
>
> #Error in pool(models.FG) : Object has no vcov() method.
>
> models.FG
>
>
>
>
> -- Andreu Ferrero Gregori


From Bernhard_Pfaff at fra.invesco.com  Mon Jan 23 16:55:55 2017
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Mon, 23 Jan 2017 15:55:55 +0000
Subject: [R] Granger-causality test using vars package
In-Reply-To: <1485174352341.50944@kent.ac.uk>
References: <1485090697003.33648@kent.ac.uk>,
	<FCD9A33C859ACC469587CB09DD5C6C712E962BFA@GBLONXMB13.corp.amvescap.net>
	<1485174352341.50944@kent.ac.uk>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C712E966D88@GBLONXMB13.corp.amvescap.net>

Dear T.Riedle,

it is a 'combined' test, see ?causality for a formal description of the test statistic. 
If you would like results on an 'equation' by equation' approach, you could employ anova() on restricted and unrestricted lm-objects.

Best wishes,
Bernhard


-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von T.Riedle
Gesendet: Montag, 23. Januar 2017 13:26
An: R-help at r-project.org
Betreff: [EXT] Re: [R] Granger-causality test using vars package

Thank you for your reply. The code follows the example in the vignette and I changed it only a little as shown below.

library(vars)
data(Canada)
summary(Canada)
stat.desc(Canada,basic=FALSE)
plot(Canada, nc=2, xlab="")

# Testing for unit roots using ADF
adf1<-adf.test(Canada[,"prod"])
adf1
adf2<-adf.test(Canada[,"e"])
adf2
adf3<-adf.test(Canada[,"U"])
adf3
adf4<-adf.test(Canada[,"rw"])
adf4

# Use VAR to create a list of class varest Canada<-Canada[, c("prod", "e", "U", "rw")] p1ct<-VAR(Canada, p=1, type = "both") p1ct summary(p1ct, equation="e") plot(p1ct, names = "e")

#Run Granger-causality test
causality(p1ct)

The Granger-causality test returns following output $Granger

	Granger causality H0: prod do not Granger-cause e U rw

data:  VAR object p1ct
F-Test = 11.956, df1 = 3, df2 = 308, p-value = 1.998e-07


$Instant

	H0: No instantaneous causality between: prod and e U rw

data:  VAR object p1ct
Chi-squared = 3.7351, df = 3, p-value = 0.2915


Warning message:
In causality(p1ct) : 
Argument 'cause' has not been specified; using first variable in 'x$y' (prod) as cause variable.

I am struggling with the result as it is not clear to me whether the variable prod Granger-causes e or U or rw. H0 is that prod does not Granger-cause e U rw. What does that mean? How can I find out if prod Granger-causes e, U and rw, respectively i.e. how can I determine that prod Granger-causes e, U and rw?

Thanks for your support in advance.
________________________________________
From: Pfaff, Bernhard Dr. <Bernhard_Pfaff at fra.invesco.com>
Sent: 23 January 2017 09:12
To: T.Riedle; R-help at r-project.org
Subject: AW:  [R] Granger-causality test using vars package

Dear T.Riedle,

you cannot assign *all* variables as a cause at once. Incidentally, in your example, you missed a 'data(Canada)'.
Having said this, you can loop over the variables names and extract the statistic/p-values. These are contained as named list elements 'statistic' and 'p.value' in the returned list object 'Granger' which is of informal class 'htest'.

Best wishes,
Bernhard

-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von T.Riedle
Gesendet: Sonntag, 22. Januar 2017 14:11
An: R-help at r-project.org
Betreff: [EXT] [R] Granger-causality test using vars package

Dear R-users,

I am trying to compute the test statistics for Granger-causality for a VAR(p) model using the "vars" package. I simply used the example proposed by the vars vignette and added the code for the Granger-causality. The code looks as follows



library(vars)

Canada<-Canada[, c("prod", "e", "U", "rw")] p1ct<-VAR(Canada, p=1, type = "both")

causality(p1ct, cause = c("prod","e","U","rw"))



Unfortunately I get the error

Error in `[<-`(`*tmp*`, i, w[i], value = 1) : subscript out of bounds



Does any body know what is wrong with the code? I would like to create a matrix containing the F-values and the corresponding significance. How can I do that?

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:9}}


From justanotherdigression at gmail.com  Mon Jan 23 18:38:42 2017
From: justanotherdigression at gmail.com (Luanna Dixson)
Date: Mon, 23 Jan 2017 18:38:42 +0100
Subject: [R] Suggestions for vectorizing/double loop
In-Reply-To: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
References: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
Message-ID: <CAAAKMC=+-tcrtZ91hL4WJA=PXbpOwQORaPhVUcumS1LzTG5=-Q@mail.gmail.com>

Hi all,

Thanks very much for your help! You are correct in thinking the list is the
same as before, actually, my question was more about how to do the next
steps, where I needed to match the filenames of the files in my directory
with old (i.e current) and new file name prefixes in my list. For each
match I then wanted to rename the original file using the corresponding new
filename prefix from the list.

Sorry for being a bit confusing, I didn't post my first attempt to do this
at first as my code just didn't work at all, but I have had another go
using a matrix instead and I think this does the job.

old_path="./old/"
new_path="./new/"

old_names <- list.files(old_path)
head(old_names)

oldnames=c('1002', '1003')
newnames=c('1002_new', '1003_new')
mapping=cbind(oldnames,newnames)
head(mapping)

for (i in old_names){
    temp <- unlist(strsplit(i, "[.]"))[1]
    n <- which(is.element(mapping,temp))
    if(length(n)>0) {
        #copy the file to the new folder
        #re name it and the name is paste(mapping[n,2], '.xls', sep="")
        print(paste(mapping[n,2], '.xls', sep=""))
        newnames <- paste(mapping[n,2], '.xls', sep="")
        file.copy(from = paste(old_path, i, sep=""),
                  to = paste(new_path, newnames))
    }
}


On 23 January 2017 at 13:28, Luanna Dixson <justanotherdigression at gmail.com>
wrote:

> I need to rename a bunch of files, by searching for string matches in a
> list. Each list element containings a character with the old filename that
> I want to match to, and the new file name that I want to rename by.
>
> For instance, here filename '1001.xls' should match to list[[1]]$oldname
> and I want to rename it to 'newa.xls' from list[[1]]$newname.
>
> The actual new file names I have will feature a random alphanumeric number
> and the list will have a length of ~600.
>
>
> # files I want to rename
>
> files with old file name =c('1001.xls', '1002.xls')
>
> # list with old file names and new file names
>
> oldnames=c('1001', '1002', '1003')
>
> newnames=c('newa', 'newb', 'newc')
>
> df=data.frame(oldnames,newnames)
>
> list <- split(df, rownames(df))
>
>
> # turn list elements in character
>
> for(i in 1:length(list)) list[[i]]$oldnames=as.
> character(list[[i]]$oldnames)
>
> for(i in 1:length(list)) list[[i]]$newnames=as.
> character(list[[i]]$newnames)
>
>
> I heard that it would be better to vectorize this than trying to do a
> double loop so if someone could give me a hint about how to do this I would
> be very grateful!
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan 23 19:08:27 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 Jan 2017 10:08:27 -0800
Subject: [R] spatial analysis using quickPCNM
In-Reply-To: <CAJrFtqKXBg8Jpc0Xebk3pKb3Qx-Lsb0QhNuMwFTpoz=GFk=V6A@mail.gmail.com>
References: <CAJrFtqKXBg8Jpc0Xebk3pKb3Qx-Lsb0QhNuMwFTpoz=GFk=V6A@mail.gmail.com>
Message-ID: <E9F17BC7-3690-4176-BE70-48F626AADE65@dcn.davis.ca.us>

I don't know if I will be able to help solve your problem, but failure to follow the recommendations in the Posting Guide was probably getting you off in the wrong foot when you posted on the other (more appropriate?) mailing list, as it is here. 

A) Code is garbled. Post using plain text format... this is a setting you have to choose in your email program. 

B) Code is not reproducible. We cannot run your code to get your error due to missing library statements and no data. The Posting Guide and Google have suggestions for how you can make your example reproducible. 

C) Assuming you are using the PCNM package, the documentation found by Google (which you can probably read using ?quickPCNM) says quickPCNM expects a matrix, but it looks like you are giving it a data frame. Read your introductory R training materials (e.g. the Introduction to R document that ships with R) to understand the distinction.  But I have never used this function so this could be a red herring. 

Please go read the Posting Guide. 
-- 
Sent from my phone. Please excuse my brevity.

On January 23, 2017 6:42:28 AM PST, Andrew Halford <andrew.halford at gmail.com> wrote:
>Hi Listers,
>
>I posted this message to the R-sig-ecology group last Friday but have
>not
>had a response hence my post here.
>
>I have been trying to run spatial analyses on a fish community dataset.
>
>My fish dataset has 114 species(variables) x 45 sites
>My spatial dataset has the Lat and Long values for each site, converted
>to
>cartesian coordinates
>
>
>
>> fish <- read.table(file.choose())> latlong <-
>read.table(file.choose()) > fish.h <- decostand (fish, "hellinger")>
>fish.PCNM.quick <- quickPCNM(fish.h,latlong)
>
>Truncation level = 639.5348
>Time to compute PCNMs = 0.820000  sec Error in if (temp2.test[1, 5] <=
>alpha) { : argument is of length zeroTiming stopped at: 1.06 0.05 1.19
>
>I do not understand the error message coming up and would appreciate
>some advice.
>
>Andy


From jacksonmrodrigues at gmail.com  Mon Jan 23 19:19:02 2017
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Mon, 23 Jan 2017 15:19:02 -0300
Subject: [R] R Graphics: Device 2 (Active)
Message-ID: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>

Hi,

after updating R and RStudio I am no longer able to see my plots in the
plot pane. Instead a new window opens called: R Graphics: Device 2 (Active).

I tried to use dev.off(), reinstalling, update again and etc but it does
not help.

I've checked this discussion list but I could not find any solution.

The following are some info about my R version

> sessionInfo()

R version 3.3.2 (2016-10-31)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows >= 8 x64 (build 9200)

locale:

[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252

[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C

[5] LC_TIME=Portuguese_Brazil.1252


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:

 [1] RColorBrewer_1.1-2 labdsv_1.8-0       cluster_2.0.5      MASS_7.3-45


 [5] mgcv_1.8-15        nlme_3.1-128       analogue_0.17-0    vegan_2.4-1


 [9] lattice_0.20-34    permute_0.9-4

loaded via a namespace (and not attached):

[1] Matrix_1.2-7.1   parallel_3.3.2   tools_3.3.2      brglm_0.5-9

[5] grid_3.3.2       princurve_1.1-12


$version

[1] ?0.99.441?


Any help are very welcome.

Thanks

Jackson

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Jan 23 19:47:16 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 23 Jan 2017 18:47:16 +0000
Subject: [R] R Graphics: Device 2 (Active)
In-Reply-To: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
References: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
Message-ID: <58864FB4.2060801@sapo.pt>

Hello,

That's a question for R Studio, ask here: https://support.rstudio.com

Hope this helps,

Rui Barradas


Em 23-01-2017 18:19, Jackson Rodrigues escreveu:
> Hi,
>
> after updating R and RStudio I am no longer able to see my plots in the
> plot pane. Instead a new window opens called: R Graphics: Device 2 (Active).
>
> I tried to use dev.off(), reinstalling, update again and etc but it does
> not help.
>
> I've checked this discussion list but I could not find any solution.
>
> The following are some info about my R version
>
>> sessionInfo()
>
> R version 3.3.2 (2016-10-31)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Running under: Windows >= 8 x64 (build 9200)
>
> locale:
>
> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>
> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
>
> [5] LC_TIME=Portuguese_Brazil.1252
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>
>   [1] RColorBrewer_1.1-2 labdsv_1.8-0       cluster_2.0.5      MASS_7.3-45
>
>
>   [5] mgcv_1.8-15        nlme_3.1-128       analogue_0.17-0    vegan_2.4-1
>
>
>   [9] lattice_0.20-34    permute_0.9-4
>
> loaded via a namespace (and not attached):
>
> [1] Matrix_1.2-7.1   parallel_3.3.2   tools_3.3.2      brglm_0.5-9
>
> [5] grid_3.3.2       princurve_1.1-12
>
>
> $version
>
> [1] ?0.99.441?
>
>
> Any help are very welcome.
>
> Thanks
>
> Jackson
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Mon Jan 23 19:56:32 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 Jan 2017 10:56:32 -0800
Subject: [R] R Graphics: Device 2 (Active)
In-Reply-To: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
References: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
Message-ID: <DD257874-1E56-469F-9DDA-9A3FAC936C33@dcn.davis.ca.us>

You need to be clear in your own mind about the distinction between RStudio and R before you can communicate clearly about it.  Specifically, we don't know how to debug problems with RStudio here, and what you describe sounds completely normal for the R Gui program that ships with R.

It sounds to me like you need to communicate with RStudio support, but providing a reproducible example here, run from R Gui rather than RStudio, could make the issue more clear.
-- 
Sent from my phone. Please excuse my brevity.

On January 23, 2017 10:19:02 AM PST, Jackson Rodrigues <jacksonmrodrigues at gmail.com> wrote:
>Hi,
>
>after updating R and RStudio I am no longer able to see my plots in the
>plot pane. Instead a new window opens called: R Graphics: Device 2
>(Active).
>
>I tried to use dev.off(), reinstalling, update again and etc but it
>does
>not help.
>
>I've checked this discussion list but I could not find any solution.
>
>The following are some info about my R version
>
>> sessionInfo()
>
>R version 3.3.2 (2016-10-31)
>
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>Running under: Windows >= 8 x64 (build 9200)
>
>locale:
>
>[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>
>[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
>
>[5] LC_TIME=Portuguese_Brazil.1252
>
>
>attached base packages:
>
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>
>[1] RColorBrewer_1.1-2 labdsv_1.8-0       cluster_2.0.5     
>MASS_7.3-45
>
>
>[5] mgcv_1.8-15        nlme_3.1-128       analogue_0.17-0   
>vegan_2.4-1
>
>
> [9] lattice_0.20-34    permute_0.9-4
>
>loaded via a namespace (and not attached):
>
>[1] Matrix_1.2-7.1   parallel_3.3.2   tools_3.3.2      brglm_0.5-9
>
>[5] grid_3.3.2       princurve_1.1-12
>
>
>$version
>
>[1] ?0.99.441?
>
>
>Any help are very welcome.
>
>Thanks
>
>Jackson
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From xuelimizzou at hotmail.com  Mon Jan 23 16:09:30 2017
From: xuelimizzou at hotmail.com (Xue Li)
Date: Mon, 23 Jan 2017 15:09:30 +0000
Subject: [R] Replicate Christensen, Dib (2008) using BMR package
Message-ID: <SG2PR06MB174130F040AEA7C67E61B2E3BC720@SG2PR06MB1741.apcprd06.prod.outlook.com>

Dear all,


I am trying to replicate Christensen, Dib (2008)'s estimation results using "EDSGE" function in BMR package. Attached are my R code, the data I collected and preprocessed, and the paper.


I set the priors following the literature (e.g., Smets and Wouters, 2007). However, when I ran the code, R reported error messages like:


Beginning MCMC run, Mon Jan 23 22:42:03 2017.
Error in chol.default(CovM) :
  the leading minor of order 2 is not positive definite
In addition: Warning message:
In sqrt(parModeHessian) : NaNs produced

I also found that the estimation is sensitive to initial values and/or prior settings. I am struggling with debugging the code and hope someone could help me out. Thanks!


Best,

April
-------------- next part --------------
A non-text attachment was scrubbed...
Name: The financial accelerator in an estimated New Keynesian model_Christensen, Dib (2008 RED).pdf
Type: application/pdf
Size: 2680535 bytes
Desc: The financial accelerator in an estimated New Keynesian model_Christensen, Dib (2008 RED).pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170123/1d3e2958/attachment-0001.pdf>

From jacobkap at sas.upenn.edu  Sun Jan 22 07:06:00 2017
From: jacobkap at sas.upenn.edu (Jacob Kaplan)
Date: Sun, 22 Jan 2017 01:06:00 -0500
Subject: [R] [R-pkgs] Announcing caesar
Message-ID: <CAPVd8g+MWj++w5ONLBfz90A06bXU0TqQ9C3+djCwjSfJtDFN8Q@mail.gmail.com>

Dear R users,

I am happy to announce that the package caesar is now on CRAN (
https://cran.r-project.org/web/packages/caesar/index.html).

The caesar package lets you encrypt and decrypt strings using the common
Caesar cipher or a more secure pseudorandom number generator method.

If you would like to know more please visit the repository on GitHub (
https://github.com/jacobkap/caesar).

Best,
Jacob

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bgunter.4567 at gmail.com  Mon Jan 23 20:17:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 23 Jan 2017 11:17:11 -0800
Subject: [R] R Graphics: Device 2 (Active)
In-Reply-To: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
References: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
Message-ID: <CAGxFJbRiBhgtZHM3M_R9HhM5gJj_AvRRoMHoZHriRHBKVym-0Q@mail.gmail.com>

This sounds like an RStudio issue to me (just a not-so-informed guess,
though). Did you reinstall that, too? Did you look/post on RStudio's
site?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 23, 2017 at 10:19 AM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi,
>
> after updating R and RStudio I am no longer able to see my plots in the
> plot pane. Instead a new window opens called: R Graphics: Device 2 (Active).
>
> I tried to use dev.off(), reinstalling, update again and etc but it does
> not help.
>
> I've checked this discussion list but I could not find any solution.
>
> The following are some info about my R version
>
>> sessionInfo()
>
> R version 3.3.2 (2016-10-31)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Running under: Windows >= 8 x64 (build 9200)
>
> locale:
>
> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>
> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
>
> [5] LC_TIME=Portuguese_Brazil.1252
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>
>  [1] RColorBrewer_1.1-2 labdsv_1.8-0       cluster_2.0.5      MASS_7.3-45
>
>
>  [5] mgcv_1.8-15        nlme_3.1-128       analogue_0.17-0    vegan_2.4-1
>
>
>  [9] lattice_0.20-34    permute_0.9-4
>
> loaded via a namespace (and not attached):
>
> [1] Matrix_1.2-7.1   parallel_3.3.2   tools_3.3.2      brglm_0.5-9
>
> [5] grid_3.3.2       princurve_1.1-12
>
>
> $version
>
> [1] ?0.99.441?
>
>
> Any help are very welcome.
>
> Thanks
>
> Jackson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Jan 23 20:23:20 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 Jan 2017 11:23:20 -0800
Subject: [R] Replicate Christensen, Dib (2008) using BMR package
In-Reply-To: <SG2PR06MB174130F040AEA7C67E61B2E3BC720@SG2PR06MB1741.apcprd06.prod.outlook.com>
References: <SG2PR06MB174130F040AEA7C67E61B2E3BC720@SG2PR06MB1741.apcprd06.prod.outlook.com>
Message-ID: <0373A9B2-7C5A-4512-B19B-221B3CF0A491@dcn.davis.ca.us>

Only your pdf attachment made it through. You would need to follow the Posting Guide regarding file types to achieve successful transmission. 

I will say that open-ended debugging of your code does not fit the Posting Guide recommendations either... this is an R language mailing list, not a research assistance mailing list. It might fit in better at stats.stackexchange.com, but even they want a focused question rather than general assistance requests. 
-- 
Sent from my phone. Please excuse my brevity.

On January 23, 2017 7:09:30 AM PST, Xue Li <xuelimizzou at hotmail.com> wrote:
>Dear all,
>
>
>I am trying to replicate Christensen, Dib (2008)'s estimation results
>using "EDSGE" function in BMR package. Attached are my R code, the data
>I collected and preprocessed, and the paper.
>
>
>I set the priors following the literature (e.g., Smets and Wouters,
>2007). However, when I ran the code, R reported error messages like:
>
>
>Beginning MCMC run, Mon Jan 23 22:42:03 2017.
>Error in chol.default(CovM) :
>  the leading minor of order 2 is not positive definite
>In addition: Warning message:
>In sqrt(parModeHessian) : NaNs produced
>
>I also found that the estimation is sensitive to initial values and/or
>prior settings. I am struggling with debugging the code and hope
>someone could help me out. Thanks!
>
>
>Best,
>
>April


From dkrstajic at hotmail.com  Mon Jan 23 21:48:48 2017
From: dkrstajic at hotmail.com (Damjan Krstajic)
Date: Mon, 23 Jan 2017 20:48:48 +0000
Subject: [R] removing dropouts from survival analysis
Message-ID: <HE1PR0802MB2188B3100E4E9E2F7A5A0674B4720@HE1PR0802MB2188.eurprd08.prod.outlook.com>

Dear All.


Apologies for posting a question regarding survival analysis, and not R, to the R-help list. In the past I received the best advices from the R community.


The random censorship model (the censoring times independent of the failure times and vice versa) is one of the fundamental assumptions in the survival analysis. In the medical studies we have random entry to study and study end which is a censoring mechanism independent of the failure times. However, in reality we may have dropout subjects, lost to follow-up, which are censored by a different mechanism which may not be independent of the failure times. The inclusion of dropout subjects in the survival analysis may break the random censorship model and include bias in our estimates of survival with KM. I have studied papers on this subject (e.g. double sampling, copula approach for dependent censoring), but I have not found any research paper which examines the removal of dropout subjects from the survival analysis.


I am alone in my research and would be grateful to hear thoughts on this subject. Thank you in advance and apologies for using the R-help list for my research question.


DK

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Mon Jan 23 22:10:42 2017
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 23 Jan 2017 14:10:42 -0700
Subject: [R] R Graphics: Device 2 (Active)
In-Reply-To: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
References: <CAPL76w9Q2M-Nj0jrhjR-cNhZcz_RDoLCCVNUVdMxELBDfSUzOA@mail.gmail.com>
Message-ID: <CAFEqCdxugk6XHFvDu9CxRvFEicKTHV7rg6URG9oO7eGkmi2m9A@mail.gmail.com>

What is the result of running:

getOption("device")

?

It should be something like: "RStudioGD".  It sounds like this has
been changed to something else, if that is the case it is a matter of
either changing it back, or figuring out where the change is being
made and fixing that.

On Mon, Jan 23, 2017 at 11:19 AM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi,
>
> after updating R and RStudio I am no longer able to see my plots in the
> plot pane. Instead a new window opens called: R Graphics: Device 2 (Active).
>
> I tried to use dev.off(), reinstalling, update again and etc but it does
> not help.
>
> I've checked this discussion list but I could not find any solution.
>
> The following are some info about my R version
>
>> sessionInfo()
>
> R version 3.3.2 (2016-10-31)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Running under: Windows >= 8 x64 (build 9200)
>
> locale:
>
> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>
> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
>
> [5] LC_TIME=Portuguese_Brazil.1252
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>
>  [1] RColorBrewer_1.1-2 labdsv_1.8-0       cluster_2.0.5      MASS_7.3-45
>
>
>  [5] mgcv_1.8-15        nlme_3.1-128       analogue_0.17-0    vegan_2.4-1
>
>
>  [9] lattice_0.20-34    permute_0.9-4
>
> loaded via a namespace (and not attached):
>
> [1] Matrix_1.2-7.1   parallel_3.3.2   tools_3.3.2      brglm_0.5-9
>
> [5] grid_3.3.2       princurve_1.1-12
>
>
> $version
>
> [1] ?0.99.441?
>
>
> Any help are very welcome.
>
> Thanks
>
> Jackson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From drjimlemon at gmail.com  Mon Jan 23 22:27:22 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 24 Jan 2017 08:27:22 +1100
Subject: [R] Extracting first number after * in a character vector
In-Reply-To: <CANtKHPUX-YN8k1N7ooEFJy8CRyRi2mZWL-iN7iQ-VU1bbjkB9g@mail.gmail.com>
References: <CANtKHPUX-YN8k1N7ooEFJy8CRyRi2mZWL-iN7iQ-VU1bbjkB9g@mail.gmail.com>
Message-ID: <CA+8X3fWmsOcA6NsvsVHL6hmxFes=eQcugN7q-w8-MTAeiT6qcw@mail.gmail.com>

Hi Abhinaba,
I'm sure that someone will post a terrifyingly elegant regular
expression that does this, but:

 ardat<-
 c([1] "     1 X[0,SMITH]   *              0             0             1 ",
 ...
numpoststar<-function(x) {
 xsplit<-unlist(strsplit(x,""))
 starpos<-which(xsplit=="*")
 # watch out for a missing asterisk, they cause an infinite loop
 if(length(starpos)) {
  digits<-c("0","1","2","3","4","5","6","7","8","9")
  while(!any(digits %in% xsplit[starpos])) starpos<-starpos+1
  return(as.numeric(xsplit[starpos]))
 }
 return(NA)
}

for(i in 1:length(ardat)) print(numpoststar(ardat[i]))

The observant will wonder why I didn't use sapply. Because for some
reason it returned the original strings rather than the numbers. I
dunno.

Jim

On Mon, Jan 23, 2017 at 11:29 PM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi,
>
> How do I extract the first number after '*' in a vector?
>
> The vector is given below
>
>> dput(out[1:10])
> c("     1 X[0,SMITH]   *              0             0             1 ",
> "     2 X[0,JOHNSON] *              0             0             1 ",
> "     3 X[0,WILLIAMS]", "                    *              1             0
>             1 ",
> "     4 X[0,JONES]   *              0             0             1 ",
> "     5 X[0,BROWN]   *              0             0             1 ",
> "     6 X[0,DAVIS]   *              0             0             1 ",
> "     7 X[0,MILLER]  *              0             0             1 ",
> "     8 X[0,WILSON]  *              0             0             1 ",
> "     9 X[0,MOORE]   *              0             0             1 "
> )
>
> I want a vector with the first number after the asterisk.
>
> So the output would give me, a vector (0,0,1,0,0,0,0,0,0,0)
>
> How can I do it in R?
>
> Best,
> Abhinaba
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Mon Jan 23 22:35:46 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 24 Jan 2017 10:35:46 +1300
Subject: [R] [FORGED]  Fitting arima Models with Exogenous Variables
In-Reply-To: <CAMOcQfMMyqURzc2aHGrkNGjy_a2++5-S=Wo-OgTQSGzEG+BL2Q@mail.gmail.com>
References: <CAMOcQfPK=1UZvFN5mS=Q6jH8T1qt1MMmNvoSQeh6MO9Rp9gcuA@mail.gmail.com>
	<ce0a0a41-0bb3-9c85-4ac0-50d3e570e2b2@auckland.ac.nz>
	<CAMOcQfMMyqURzc2aHGrkNGjy_a2++5-S=Wo-OgTQSGzEG+BL2Q@mail.gmail.com>
Message-ID: <e59677cb-a472-75e5-145c-8e6b809687d5@auckland.ac.nz>


This should have been sent to the R-help mailing list, not to me 
personally.  I am not an expert on this sort of time series modelling
and cannot thereby provide any useful advice.  My reply to you was of a 
"generic" nature --- when making an enquiry, provide a reproducible 
example!!!

I am cc-ing this email to the R-help list, since someone on that list 
*may* be able to answer your question.  I have (re-) attached the data 
sets that you sent to me.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 24/01/17 04:36, Paul Bernal wrote:
> Hello Rolf,
>
> Thank you for your kind reply. I am attaching two datasets, one with the
> historical data that I used to train the model, and the other one with
> the exogenous variables.
>
> The R code that I used is as follows:
>
>>library(forecast)
>>library(tseries)
>>library(TSA)
>>library(stats)
>>library(stats4)
>> TrainingDat<-read.csv("Training Data.csv")
>>
>> ExogVars<-read.csv("ExogenousVariables5.csv")
>> #The file ExogVars contains 5 columns, one column for each regressor
>> Model1<-auto.arima(TrainingDat[,5], xreg=ExogVars)
>>#In Model1 I was able to incorporate xreg without any trouble
>>#The problem comes when trying to incorporate newxreg
>> Model2<-auto.arima(ExoVars[1:5])
> Error in as.ts(x) : object 'ExoVars' not found
>>
>> Model2<-auto.arima(ExogVars[1:5])
>
> Error in auto.arima(ExogVars[1:5]) : No suitable ARIMA model found
>>
>> Model2<-auto.arima(ExogVars[,1])
>>
>> NewXReg<-forecast(Model2, h=12)
>>
>> Forec<-forecast(Model1, newxreg=NewXReg)
> Error in forecast.Arima(Model1, newxreg = NewXReg) :
>   No regressors provided
> In addition: Warning message:
> In forecast.Arima(Model1, newxreg = NewXReg) :
>   The non-existent newxreg arguments will be ignored.
>>
>> Forec<-forecast(Model1, newxreg=NewXReg$mean)
> Error in forecast.Arima(Model1, newxreg = NewXReg$mean) :
>   No regressors provided
> In addition: Warning message:
> In forecast.Arima(Model1, newxreg = NewXReg$mean) :
>   The non-existent newxreg arguments will be ignored.
>
> I would like to generate the forecasts for all 4 variables included in
> the Training set, along with all 5 regressors, but it seems like I can
> only chose one training variable at a time, and one regressor at a time.
>
> Please let me know if you can work this out,



From bgunter.4567 at gmail.com  Mon Jan 23 22:45:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 23 Jan 2017 13:45:14 -0800
Subject: [R] removing dropouts from survival analysis
In-Reply-To: <HE1PR0802MB2188B3100E4E9E2F7A5A0674B4720@HE1PR0802MB2188.eurprd08.prod.outlook.com>
References: <HE1PR0802MB2188B3100E4E9E2F7A5A0674B4720@HE1PR0802MB2188.eurprd08.prod.outlook.com>
Message-ID: <CAGxFJbTGSzsZQkz1uruHkhO-m+Yfg0mOqxdvFVFrdWL4LRZVvw@mail.gmail.com>

Sorry. You may get private replies, but this *is* way OT on this list.
Try stats.stackexchange.com instead for statistical queries. Or,
better yet, find local consulting help. Non-random dropouts are a
difficult issue.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 23, 2017 at 12:48 PM, Damjan Krstajic <dkrstajic at hotmail.com> wrote:
> Dear All.
>
>
> Apologies for posting a question regarding survival analysis, and not R, to the R-help list. In the past I received the best advices from the R community.
>
>
> The random censorship model (the censoring times independent of the failure times and vice versa) is one of the fundamental assumptions in the survival analysis. In the medical studies we have random entry to study and study end which is a censoring mechanism independent of the failure times. However, in reality we may have dropout subjects, lost to follow-up, which are censored by a different mechanism which may not be independent of the failure times. The inclusion of dropout subjects in the survival analysis may break the random censorship model and include bias in our estimates of survival with KM. I have studied papers on this subject (e.g. double sampling, copula approach for dependent censoring), but I have not found any research paper which examines the removal of dropout subjects from the survival analysis.
>
>
> I am alone in my research and would be grateful to hear thoughts on this subject. Thank you in advance and apologies for using the R-help list for my research question.
>
>
> DK
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thpe at simecol.de  Mon Jan 23 23:32:47 2017
From: thpe at simecol.de (Thomas Petzoldt)
Date: Mon, 23 Jan 2017 23:32:47 +0100
Subject: [R] separate mixture of gamma and normal (with mixtools or ??)
Message-ID: <21f59d8e-b88a-20c5-65a5-75148f3b436b@simecol.de>

Dear friends,

I am trying to separate bi- (and sometimes tri-) modal univariate 
mixtures of biological data, where the first component is left bounded 
(e.g. exponential or gamma) and the other(s) approximately Gaussian.

After checking several packages, I'm not really clear what to do. Here 
is an example with "mixtools" that already works quite good, however, 
the left component is not Gaussian (and not symmetric).

Any idea about a more adequate function or package for this problem?

Thanks a lot!

Thomas



library(mixtools)
set.seed(123)

lambda <- c(0.25, 0.75)
N      <- 200

## dist1 ~ gamma (or exponential as a special case)
#dist1 <- rexp(lambda[1]*N, 1)
dist1 <- rgamma(lambda[1]*N, 1, 1)

## dist2 ~ normal
dist2 <- rnorm(lambda[2]*N, 12, 2)

## mixture
x <- c(dist1, dist2)

mix <-  spEMsymloc(x, mu0=2, eps=1e-3, verbose=TRUE)
plot(mix, xlim=c(0, 25))
summary(mix)


--
Thomas Petzoldt
TU Dresden, Institute of Hydrobiology
http://www.tu-dresden.de/Members/thomas.petzoldt


From bgunter.4567 at gmail.com  Tue Jan 24 00:34:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 23 Jan 2017 15:34:33 -0800
Subject: [R] separate mixture of gamma and normal (with mixtools or ??)
In-Reply-To: <21f59d8e-b88a-20c5-65a5-75148f3b436b@simecol.de>
References: <21f59d8e-b88a-20c5-65a5-75148f3b436b@simecol.de>
Message-ID: <CAGxFJbSQnrH8_gqRwkZ4tyWc76+c8e+A8tqPYrDab1BZwn8MxQ@mail.gmail.com>

Fitting multicomponent mixtures distributions -- and 3 is already a
lot of components -- is inherently ill-conditioned. You may need to
reassess your strategy. You might wish to post on stackexchange
instead to discuss such statistical issues.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 23, 2017 at 2:32 PM, Thomas Petzoldt <thpe at simecol.de> wrote:
> Dear friends,
>
> I am trying to separate bi- (and sometimes tri-) modal univariate mixtures
> of biological data, where the first component is left bounded (e.g.
> exponential or gamma) and the other(s) approximately Gaussian.
>
> After checking several packages, I'm not really clear what to do. Here is an
> example with "mixtools" that already works quite good, however, the left
> component is not Gaussian (and not symmetric).
>
> Any idea about a more adequate function or package for this problem?
>
> Thanks a lot!
>
> Thomas
>
>
>
> library(mixtools)
> set.seed(123)
>
> lambda <- c(0.25, 0.75)
> N      <- 200
>
> ## dist1 ~ gamma (or exponential as a special case)
> #dist1 <- rexp(lambda[1]*N, 1)
> dist1 <- rgamma(lambda[1]*N, 1, 1)
>
> ## dist2 ~ normal
> dist2 <- rnorm(lambda[2]*N, 12, 2)
>
> ## mixture
> x <- c(dist1, dist2)
>
> mix <-  spEMsymloc(x, mu0=2, eps=1e-3, verbose=TRUE)
> plot(mix, xlim=c(0, 25))
> summary(mix)
>
>
> --
> Thomas Petzoldt
> TU Dresden, Institute of Hydrobiology
> http://www.tu-dresden.de/Members/thomas.petzoldt
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Tue Jan 24 01:20:29 2017
From: tmrsg11 at gmail.com (C W)
Date: Mon, 23 Jan 2017 19:20:29 -0500
Subject: [R] Can R markdown do beamer palo alto theme?
Message-ID: <CAE2FW2kiHe0YdRknO52KOeuifLHQ7PBLDKjgC7nuKGTHkp22sw@mail.gmail.com>

Hi R list,

Is it possible to use R markdown with beamer palo alto theme?  Are they
compatible?

I copy pasted my LaTex code over to R, I get the following error message:

! LaTeX Error: Can be used only in preamble.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...

l.89 \end{frame}

pandoc: Error producing PDF
Error: pandoc document conversion failed with error 43
Execution halted

Thanks for your help in advance!

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Tue Jan 24 01:33:23 2017
From: tmrsg11 at gmail.com (C W)
Date: Mon, 23 Jan 2017 19:33:23 -0500
Subject: [R] Can R markdown do beamer palo alto theme?
In-Reply-To: <CAE2FW2kiHe0YdRknO52KOeuifLHQ7PBLDKjgC7nuKGTHkp22sw@mail.gmail.com>
References: <CAE2FW2kiHe0YdRknO52KOeuifLHQ7PBLDKjgC7nuKGTHkp22sw@mail.gmail.com>
Message-ID: <CAE2FW2=vfjruJ5pu-hSjZUWcFDjGLu=RT0bQFS=93u-y1th9BQ@mail.gmail.com>

Actually, I figured out that you can, but the syntax is different.

You don't declare using \usedocument{beamer} \usetheme{PaloAlto}, instead,
title and output are the correct syntax.

Is there a full conversion list from Latex Beamer to Markdown Beamer?

Thanks!

On Mon, Jan 23, 2017 at 7:20 PM, C W <tmrsg11 at gmail.com> wrote:

> Hi R list,
>
> Is it possible to use R markdown with beamer palo alto theme?  Are they
> compatible?
>
> I copy pasted my LaTex code over to R, I get the following error message:
>
> ! LaTeX Error: Can be used only in preamble.
>
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help.
>  ...
>
> l.89 \end{frame}
>
> pandoc: Error producing PDF
> Error: pandoc document conversion failed with error 43
> Execution halted
>
> Thanks for your help in advance!
>

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Tue Jan 24 03:31:59 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 23 Jan 2017 18:31:59 -0800
Subject: [R] Extracting first number after * in a character vector
In-Reply-To: <CA+8X3fWmsOcA6NsvsVHL6hmxFes=eQcugN7q-w8-MTAeiT6qcw@mail.gmail.com>
References: <CANtKHPUX-YN8k1N7ooEFJy8CRyRi2mZWL-iN7iQ-VU1bbjkB9g@mail.gmail.com>
	<CA+8X3fWmsOcA6NsvsVHL6hmxFes=eQcugN7q-w8-MTAeiT6qcw@mail.gmail.com>
Message-ID: <CACdH2ZaOxh1sr9S+zhqpoa1nAFCnRKdku9QYins8q50U5y01Yw@mail.gmail.com>

Elegant I don't know, but I think the appended does the trick.

-- Mike

> foo <- c("     1 X[0,SMITH]   *              0             0             1 ",
+  "     2 X[0,JOHNSON] *              0             0             1 ",
+  "     3 X[0,WILLIAMS]              *              1             0 1 ",
+  "     4 X[0,JONES]   *              0             0             1 ",
+  .... [TRUNCATED]

> as.numeric(gsub("^[^*]+[*][^0-9]+([01]).*$", "\\1", foo))
[1] 0 0 1 0 0 0 0 0 0
>

On Mon, Jan 23, 2017 at 1:27 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Abhinaba,
> I'm sure that someone will post a terrifyingly elegant regular
> expression that does this, but:
>
>  ardat<-
>  c([1] "     1 X[0,SMITH]   *              0             0             1 ",
>  ...
> numpoststar<-function(x) {
>  xsplit<-unlist(strsplit(x,""))
>  starpos<-which(xsplit=="*")
>  # watch out for a missing asterisk, they cause an infinite loop
>  if(length(starpos)) {
>   digits<-c("0","1","2","3","4","5","6","7","8","9")
>   while(!any(digits %in% xsplit[starpos])) starpos<-starpos+1
>   return(as.numeric(xsplit[starpos]))
>  }
>  return(NA)
> }
>
> for(i in 1:length(ardat)) print(numpoststar(ardat[i]))
>
> The observant will wonder why I didn't use sapply. Because for some
> reason it returned the original strings rather than the numbers. I
> dunno.
>
> Jim
>
> On Mon, Jan 23, 2017 at 11:29 PM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
>> Hi,
>>
>> How do I extract the first number after '*' in a vector?
>>
>> The vector is given below
>>
>>> dput(out[1:10])
>> c("     1 X[0,SMITH]   *              0             0             1 ",
>> "     2 X[0,JOHNSON] *              0             0             1 ",
>> "     3 X[0,WILLIAMS]", "                    *              1             0
>>             1 ",
>> "     4 X[0,JONES]   *              0             0             1 ",
>> "     5 X[0,BROWN]   *              0             0             1 ",
>> "     6 X[0,DAVIS]   *              0             0             1 ",
>> "     7 X[0,MILLER]  *              0             0             1 ",
>> "     8 X[0,WILSON]  *              0             0             1 ",
>> "     9 X[0,MOORE]   *              0             0             1 "
>> )
>>
>> I want a vector with the first number after the asterisk.
>>
>> So the output would give me, a vector (0,0,1,0,0,0,0,0,0,0)
>>
>> How can I do it in R?
>>
>> Best,
>> Abhinaba
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thpe at simecol.de  Tue Jan 24 08:47:16 2017
From: thpe at simecol.de (Thomas Petzoldt)
Date: Tue, 24 Jan 2017 08:47:16 +0100
Subject: [R] separate mixture of gamma and normal (with mixtools or ??)
In-Reply-To: <CAGxFJbSQnrH8_gqRwkZ4tyWc76+c8e+A8tqPYrDab1BZwn8MxQ@mail.gmail.com>
References: <21f59d8e-b88a-20c5-65a5-75148f3b436b@simecol.de>
	<CAGxFJbSQnrH8_gqRwkZ4tyWc76+c8e+A8tqPYrDab1BZwn8MxQ@mail.gmail.com>
Message-ID: <1c3441cc-4554-5e40-8457-1974df70bd2e@simecol.de>

Dear Bert,

thank you very much for your suggestion. You are right, ill-conditioning 
was sometimes a problem for 3 components, but not in the two-component 
case. The modes are well separated, and the sample size is high.

My main problem is (1) the shape of the distributions and (2) the 
diversity of available packages and approaches to this topic.

In the mean time I made some progress in this matter by treating the 
data as a mixture of gamma distributions (package mixdist, see below), 
so what I want to know is the purely R technical question ;-)

Has someone else has ever stumbled across something like this and can 
make a suggestion which package to use?

Thanks, Thomas


## Approximate an Exponential+Gaussian mixture with
##   a mixture of Gammas

library("mixdist")
set.seed(123)
lambda <- c(0.25, 0.75)
N <- 2000
x <- c(rexp(lambda[1]*N, 1), rnorm(lambda[2]*N, 20, 4))

xx <- mixgroup(x, breaks=0:40)
pp <- mixparam(mu=c(1, 8), sigma=c(1, 3), pi=c(0.2, 0.5))
mix <-  mix(xx, pp, dist="gamma", emsteps=10)

summary(mix)
p <- coef(mix)
beta <- with(p, sigma^2/mu)
alpha <- with(p, mu /beta)
lambda <- p$pi

plot(mix, xlim=c(0, 35))
x1 <- seq(0, 35, 0.1)
lines(x1, lambda[1]*dgamma(x1, alpha[1], 1/beta[1]),
   col="orange", lwd=2)
lines(x1, lambda[2]*dgamma(x1, alpha[2], 1/beta[2]),
   col="magenta", lwd=2)



Am 24.01.2017 um 00:34 schrieb Bert Gunter:
> Fitting multicomponent mixtures distributions -- and 3 is already a
> lot of components -- is inherently ill-conditioned. You may need to
> reassess your strategy. You might wish to post on stackexchange
> instead to discuss such statistical issues.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jan 23, 2017 at 2:32 PM, Thomas Petzoldt <thpe at simecol.de> wrote:
>> Dear friends,
>>
>> I am trying to separate bi- (and sometimes tri-) modal univariate mixtures
>> of biological data, where the first component is left bounded (e.g.
>> exponential or gamma) and the other(s) approximately Gaussian.
>>
>> After checking several packages, I'm not really clear what to do. Here is an
>> example with "mixtools" that already works quite good, however, the left
>> component is not Gaussian (and not symmetric).
>>
>> Any idea about a more adequate function or package for this problem?
>>
>> Thanks a lot!
>>
>> Thomas
>>
>>
>>
>> library(mixtools)
>> set.seed(123)
>>
>> lambda <- c(0.25, 0.75)
>> N      <- 200
>>
>> ## dist1 ~ gamma (or exponential as a special case)
>> #dist1 <- rexp(lambda[1]*N, 1)
>> dist1 <- rgamma(lambda[1]*N, 1, 1)
>>
>> ## dist2 ~ normal
>> dist2 <- rnorm(lambda[2]*N, 12, 2)
>>
>> ## mixture
>> x <- c(dist1, dist2)
>>
>> mix <-  spEMsymloc(x, mu0=2, eps=1e-3, verbose=TRUE)
>> plot(mix, xlim=c(0, 25))
>> summary(mix)
>>
>>
>> --
>> Thomas Petzoldt
>> TU Dresden, Institute of Hydrobiology
>> http://www.tu-dresden.de/Members/thomas.petzoldt
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Jan 24 08:51:22 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 24 Jan 2017 07:51:22 +0000
Subject: [R] Suggestions for vectorizing/double loop
In-Reply-To: <CAAAKMC=+-tcrtZ91hL4WJA=PXbpOwQORaPhVUcumS1LzTG5=-Q@mail.gmail.com>
References: <CAAAKMCm5nqxKhC2aFV6=hLRr_ySfuZvLO2Ls2kLrAnT=WC_42w@mail.gmail.com>
	<CAAAKMC=+-tcrtZ91hL4WJA=PXbpOwQORaPhVUcumS1LzTG5=-Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FF3CE@SRVEXCHCM301.precheza.cz>

Well, your second post is rather confusing too, as is your not reproducible code.

If I understand correctly, you just want to change names of files in a directory according to some rules, which you did not clerly specify.

First I am not sure if R is the best tool for it. Nevertheless, you do not change a contents of any file, just change the name.

I found this with simple answer questioning internet.
http://stackoverflow.com/questions/10758965/how-do-i-rename-files-using-r

Is this what you want?

Here is another possibility
https://www.r-bloggers.com/operating-on-files-with-r-copy-and-rename/

Anyway the concept I would use is.

#read old names

old_names <- list.files(old_path)

#setting new names (you did not explain how do you want to do this)
new_names <- some vector of new names

If order of names is correct
file.rename(old_names, new_names)

othervise it would be needed correctly order both vectors before file.rename.

The crucial information is how do you want set the new names vector. You shold specify it by reproducible way if you want more precise answer.

Copying files is in this case best done by OS itself.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luanna
> Dixson
> Sent: Monday, January 23, 2017 6:39 PM
> To: r-help at r-project.org
> Subject: Re: [R] Suggestions for vectorizing/double loop
>
> Hi all,
>
> Thanks very much for your help! You are correct in thinking the list is the
> same as before, actually, my question was more about how to do the next
> steps, where I needed to match the filenames of the files in my directory
> with old (i.e current) and new file name prefixes in my list. For each match I
> then wanted to rename the original file using the corresponding new
> filename prefix from the list.
>
> Sorry for being a bit confusing, I didn't post my first attempt to do this at first
> as my code just didn't work at all, but I have had another go using a matrix
> instead and I think this does the job.
>
> old_path="./old/"
> new_path="./new/"
>
> old_names <- list.files(old_path)
> head(old_names)
>
> oldnames=c('1002', '1003')
> newnames=c('1002_new', '1003_new')
> mapping=cbind(oldnames,newnames)
> head(mapping)
>
> for (i in old_names){
>     temp <- unlist(strsplit(i, "[.]"))[1]
>     n <- which(is.element(mapping,temp))
>     if(length(n)>0) {
>         #copy the file to the new folder
>         #re name it and the name is paste(mapping[n,2], '.xls', sep="")
>         print(paste(mapping[n,2], '.xls', sep=""))
>         newnames <- paste(mapping[n,2], '.xls', sep="")
>         file.copy(from = paste(old_path, i, sep=""),
>                   to = paste(new_path, newnames))
>     }
> }
>
>
> On 23 January 2017 at 13:28, Luanna Dixson
> <justanotherdigression at gmail.com>
> wrote:
>
> > I need to rename a bunch of files, by searching for string matches in
> > a list. Each list element containings a character with the old
> > filename that I want to match to, and the new file name that I want to
> rename by.
> >
> > For instance, here filename '1001.xls' should match to
> > list[[1]]$oldname and I want to rename it to 'newa.xls' from
> list[[1]]$newname.
> >
> > The actual new file names I have will feature a random alphanumeric
> > number and the list will have a length of ~600.
> >
> >
> > # files I want to rename
> >
> > files with old file name =c('1001.xls', '1002.xls')
> >
> > # list with old file names and new file names
> >
> > oldnames=c('1001', '1002', '1003')
> >
> > newnames=c('newa', 'newb', 'newc')
> >
> > df=data.frame(oldnames,newnames)
> >
> > list <- split(df, rownames(df))
> >
> >
> > # turn list elements in character
> >
> > for(i in 1:length(list)) list[[i]]$oldnames=as.
> > character(list[[i]]$oldnames)
> >
> > for(i in 1:length(list)) list[[i]]$newnames=as.
> > character(list[[i]]$newnames)
> >
> >
> > I heard that it would be better to vectorize this than trying to do a
> > double loop so if someone could give me a hint about how to do this I
> > would be very grateful!
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From tr206 at kent.ac.uk  Tue Jan 24 13:08:39 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 24 Jan 2017 12:08:39 +0000
Subject: [R] Cannot open MTS package
Message-ID: <1485259740186.48057@kent.ac.uk>

Dear all,

I am trying to download MTS package but when I call it using library() I get the error below. I have already installed the Rcpp package. What is wrong? What must I do to open the MTS package?



Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'Rcpp'
Error: package or namespace load failed for 'MTS'





	[[alternative HTML version deleted]]


From sathiaraj_sp at yahoo.com  Tue Jan 24 11:26:20 2017
From: sathiaraj_sp at yahoo.com (Sathiaraj S P)
Date: Tue, 24 Jan 2017 10:26:20 +0000 (UTC)
Subject: [R] Extract input and filter data using extracted value.
References: <719227861.2891301.1485253580527.ref@mail.yahoo.com>
Message-ID: <719227861.2891301.1485253580527@mail.yahoo.com>

Hi,

I raised this question @ stack overflow and got below partial answer. Hope this mailing list can help on rest to complete.

library(dplyr)
library(tidyr)

input <- "1.8 - versicolor"

temp <- data.frame(input = input) %>%

          tidyr::separate(input, c("Petal.Width", "Species"),sep = " - ", convert = TRUE)
filtered <- dplyr::filter(iris, iris$Petal.Width %in% temp$Petal.Width)

This work fine but my input is "A001 - Description1" and I get "Error: operations are possible only for numeric, logical or complex types". even I tried with convert as FALSE.

Any suggestion? Is there any alternative package for the solution?

Thanks


From petr.pikal at precheza.cz  Tue Jan 24 14:42:22 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 24 Jan 2017 13:42:22 +0000
Subject: [R] Extract input and filter data using extracted value.
In-Reply-To: <719227861.2891301.1485253580527@mail.yahoo.com>
References: <719227861.2891301.1485253580527.ref@mail.yahoo.com>
	<719227861.2891301.1485253580527@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FF4D8@SRVEXCHCM301.precheza.cz>

Hi

see in line
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sathiaraj S
> P via R-help
> Sent: Tuesday, January 24, 2017 11:26 AM
> To: r-help at r-project.org
> Subject: [R] Extract input and filter data using extracted value.
>
> Hi,
>
> I raised this question @ stack overflow and got below partial answer. Hope
> this mailing list can help on rest to complete.
>
> library(dplyr)
> library(tidyr)
>
> input <- "1.8 - versicolor"
>
> temp <- data.frame(input = input) %>%
>
>           tidyr::separate(input, c("Petal.Width", "Species"),sep = " - ", convert =
> TRUE)
> filtered <- dplyr::filter(iris, iris$Petal.Width %in% temp$Petal.Width)
>
> This work fine but my input is "A001 - Description1" and I get "Error:
> operations are possible only for numeric, logical or complex types". even I
> tried with convert as FALSE.

I can not reproduce your error

input <- "A001 - versicolor"
temp <- data.frame(input = input) %>% separate(input, c("Petal.Width", "Species"),sep = " - ", convert = TRUE)
temp
  Petal.Width    Species
1        A001 versicolor

> filtered <- dplyr::filter(iris, iris$Petal.Width %in% temp$Petal.Width)
> filtered
[1] Sepal.Length Sepal.Width  Petal.Length Petal.Width  Species
<0 rows> (or 0-length row.names)

seems to work without error.

Cheers
Petr

>
> Any suggestion? Is there any alternative package for the solution?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From xuelimizzou at hotmail.com  Tue Jan 24 15:21:47 2017
From: xuelimizzou at hotmail.com (Xue Li)
Date: Tue, 24 Jan 2017 14:21:47 +0000
Subject: [R] Plot IRFs for class EDSGE using BMR package
Message-ID: <SG2PR06MB1741BBE7E4E52BCFB978EE97BC750@SG2PR06MB1741.apcprd06.prod.outlook.com>

Dear all,


After estimating a DSGE model using "EDSGE" function in BMR package, I planned to plot IRFs using the following code:


IRF(NKFFest,ObservableIRFs=T,varnames=varnames,percentiles=c(0.05,0.50,0.95),save=F)


But R reported an error message:


You have too many IRFs to plot!


There are 16 endogenous variables and 5 exogenous shocks in the DSGE model, and I used 5 observable series to implement the estimation. I would like to plot the IRFs of selected endogenous variables to each of the five shocks. However, I could not find any option to do that in the BMR manual. Does any one know how to do that? Thanks!


Best,

April

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Tue Jan 24 18:40:41 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Tue, 24 Jan 2017 23:10:41 +0530
Subject: [R] Error in FUN(content(x),
 ...) : invalid input in 'utf8towcs' in Twitter Analysis using TM
 package
Message-ID: <CAB=p7SpNYB_QQW0kDZqE5vHyVBY17qmi+-epU1OpPVTvc7xhJA@mail.gmail.com>

Hi All,
I am working on a twitter analysis using the TM package. Below are some
codes:

1- Here i am creating a data frame of the data collected from twitter
chennai=as.data.frame(cbind(tweet=jallitext,date=jallidate,lat=jallilat,lon=jallilon,
                         isretweet=isretweet,retweeted=retweeted,
retweetcount=retweetcount,favorite=favoritesCount,
                         favorited=favorited))

2- corpus<- Corpus(VectorSource(chennai$tweet)) The output gives me:
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 6000

However while changing the text to lower using the tm package i get this
error:

Error in FUN(content(x), ...) :
  invalid input 'RT @Aariactor: Officially #jallikattu protest is over
yesterday we won ? ????? ???? thx to government ? ??? ? ????' in
'utf8towcs'.

After researching a lot i am using this code:-
tryTolower = function(x)
{
  # create missing value
  # this is where the returned value will be
  y = NA
  # tryCatch error
  try_error = tryCatch(tolower(x), error = function(e) e)
  # if not an error
  if (!inherits(try_error, "error"))
    y = tolower(x)
  return(y)
}
corpus<- sapply(corpus, function(x) tryTolower(x))
This makes the tweets case sensitive but  when i create a document term
matrix i get this error:

Jalli<- DocumentTermMatrix(corpus)
Error in UseMethod("TermDocumentMatrix", x) :
  no applicable method for 'TermDocumentMatrix' applied to an object of
class "character"

Request you to please assist with this error. Thank you.

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Tue Jan 24 22:53:53 2017
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Tue, 24 Jan 2017 21:53:53 +0000
Subject: [R] HELP lme4 & lmerTest INSTALLATION
Message-ID: <1485294834325.31820@unine.ch>

Dear colleagues,


I am having trouble installing lme4 package and this leads me to problems installing lmerTest, when I try to do I got this Error messages:

>install.packages("lme4")
Installing package into 'C:/Users/Hp/Documents/R/win-library/3.3'
(as 'lib' is unspecified)
probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lme4_1.1-12.zip'
Content type 'application/zip' length 4745943 bytes (4.5 MB)
downloaded 4.5 MB

package 'lme4' successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package 'lme4'

The downloaded binary packages are in
        C:\Users\Hp\AppData\Local\Temp\RtmpWKmMgm\downloaded_packages
> library(lme4)
Error in library(lme4) : there is no package called 'lme4'
> install.packages("lmerTest")
Installing package into 'C:/Users/Hp/Documents/R/win-library/3.3'
(as 'lib' is unspecified)
also installing the dependency 'lme4'

probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lme4_1.1-12.zip'
Content type 'application/zip' length 4745943 bytes (4.5 MB)
downloaded 4.5 MB

probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lmerTest_2.0-33.zip'
Content type 'application/zip' length 1149636 bytes (1.1 MB)
downloaded 1.1 MB

package 'lme4' successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package 'lme4'
package 'lmerTest' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\Hp\AppData\Local\Temp\RtmpWKmMgm\downloaded_packages
> library(lmerTest)
Loading required package: Matrix
Error: package 'lme4' required by 'lmerTest' could not be found
Adem?s: Warning message:
In read.dcf(file.path(p, "DESCRIPTION"), c("Package", "Version")) :
  cannot open compressed file 'C:/Users/Hp/Documents/R/win-library/3.3/lme4/DESCRIPTION', probable reason 'No such file or directory'



Could yo please help me?

What to do? I am using latest version : R 3.3.2.


Thank you very much,

Xavier


	[[alternative HTML version deleted]]


From marine.regis at hotmail.fr  Wed Jan 25 02:32:59 2017
From: marine.regis at hotmail.fr (Marine Regis)
Date: Wed, 25 Jan 2017 01:32:59 +0000
Subject: [R] Adding x and y axis labels with the function plot.sensFun
 (package FME)
Message-ID: <AM5PR0701MB23381A40C4C54E5EB42B7D5AE2740@AM5PR0701MB2338.eurprd07.prod.outlook.com>

Hello,


How can I add x and y axis labels for a plot that is built from the function plot.sensFun (package FME) ? I tested xlab ="Time" and ylab="Population size" but this doesn't work for me.


Here is a code to generate the plot:


pars <- list(gmax = 0.5, eff = 0.5,
             ks = 0.5, rB = 0.01, dB = 0.01)

solveBact <- function(pars) {
  derivs <- function(t, state, pars) { # returns rate of change
    with (as.list(c(state, pars)), {
      dBact <-  gmax * eff * Sub/(Sub + ks) * Bact - dB * Bact - rB * Bact
      dSub  <- -gmax       * Sub/(Sub + ks) * Bact + dB * Bact
      return(list(c(dBact, dSub)))
    })
  }
  state   <- c(Bact = 0.1, Sub = 100)
  tout    <- seq(0, 50, by = 0.5)
  ## ode solves the model by integration ...
  return(as.data.frame(ode(y = state, times = tout, func = derivs,
                           parms = pars)))
}

## sensitivity functions
SF <- sensFun(func = solveBact, parms = pars,
              sensvar = c("Bact", "Sub"), varscale = 1)
par(mfrow = c(1,2))
plot(SF, which = c("Sub", "Bact"), mfrow = NULL, xlab="Time", ylab="Population size")

Thanks a lot for your time.
Marine


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Jan 25 11:45:26 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 25 Jan 2017 10:45:26 +0000
Subject: [R] HELP lme4 & lmerTest INSTALLATION
In-Reply-To: <1485294834325.31820@unine.ch>
References: <1485294834325.31820@unine.ch>
Message-ID: <588881C6.6000400@sapo.pt>

Hello,

You don't need to install lme4, it comes with base R.
As for package lmerTest, I've just did

 > install.packages("lmerTest")
--- Please select a CRAN mirror for use in this session ---
also installing the dependencies ?checkmate?, ?survival?, ?Formula?, 
?latticeExtra?, ?acepack?, ?gridExtra?, ?data.table?, ?htmlTable?, 
?viridis?, ?Hmisc?

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/checkmate_1.8.2.zip'
Content type 'application/zip' length 554040 bytes (541 KB)
downloaded 541 KB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/survival_2.40-1.zip'
Content type 'application/zip' length 5108708 bytes (4.9 MB)
downloaded 4.9 MB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/Formula_1.2-1.zip'
Content type 'application/zip' length 163536 bytes (159 KB)
downloaded 159 KB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/latticeExtra_0.6-28.zip'
Content type 'application/zip' length 2069570 bytes (2.0 MB)
downloaded 2.0 MB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/acepack_1.4.1.zip'
Content type 'application/zip' length 90515 bytes (88 KB)
downloaded 88 KB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/gridExtra_2.2.1.zip'
Content type 'application/zip' length 483236 bytes (471 KB)
downloaded 471 KB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/data.table_1.10.0.zip'
Content type 'application/zip' length 1508659 bytes (1.4 MB)
downloaded 1.4 MB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/htmlTable_1.8.zip'
Content type 'application/zip' length 179208 bytes (175 KB)
downloaded 175 KB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/viridis_0.3.4.zip'
Content type 'application/zip' length 1746408 bytes (1.7 MB)
downloaded 1.7 MB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/Hmisc_4.0-2.zip'
Content type 'application/zip' length 1785840 bytes (1.7 MB)
downloaded 1.7 MB

trying URL 
'https://cloud.r-project.org/bin/windows/contrib/3.3/lmerTest_2.0-33.zip'
Content type 'application/zip' length 1149547 bytes (1.1 MB)
downloaded 1.1 MB

package ?checkmate? successfully unpacked and MD5 sums checked
package ?survival? successfully unpacked and MD5 sums checked
package ?Formula? successfully unpacked and MD5 sums checked
package ?latticeExtra? successfully unpacked and MD5 sums checked
package ?acepack? successfully unpacked and MD5 sums checked
package ?gridExtra? successfully unpacked and MD5 sums checked
package ?data.table? successfully unpacked and MD5 sums checked
package ?htmlTable? successfully unpacked and MD5 sums checked
package ?viridis? successfully unpacked and MD5 sums checked
package ?Hmisc? successfully unpacked and MD5 sums checked
package ?lmerTest? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
 
C:\Users\Convidado\AppData\Local\Temp\RtmpEpipqW\downloaded_packages

 > library(lmerTest)

Attaching package: ?lmerTest?

The following object is masked from ?package:lme4?:

     lmer

The following object is masked from ?package:stats?:

     step


So there was no problem. And my output of install.packages() is quite 
different from yours.

If you're having a problem with lme4, maybe as an extreme mesure you 
could reinstall R.
And by the way, what is your OS? What is the output of

 > sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lmerTest_2.0-33 lme4_1.1-12     Matrix_1.2-7.1

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.8         Formula_1.2-1       knitr_1.15.1
  [4] magrittr_1.5        cluster_2.0.5       splines_3.3.2
  [7] MASS_7.3-45         munsell_0.4.3       colorspace_1.3-1
[10] lattice_0.20-34     minqa_1.2.4         stringr_1.1.0
[13] plyr_1.8.4          tools_3.3.2         nnet_7.3-12
[16] grid_3.3.2          data.table_1.10.0   checkmate_1.8.2
[19] htmlTable_1.8       gtable_0.2.0        nlme_3.1-128
[22] latticeExtra_0.6-28 htmltools_0.3.5     digest_0.6.10
[25] survival_2.40-1     lazyeval_0.2.0      assertthat_0.1
[28] tibble_1.2          gridExtra_2.2.1     RColorBrewer_1.1-2
[31] nloptr_1.0.4        ggplot2_2.2.0       base64enc_0.1-3
[34] acepack_1.4.1       rpart_4.1-10        stringi_1.1.2
[37] backports_1.0.4     scales_0.4.1        Hmisc_4.0-2
[40] foreign_0.8-67

Hope this helps,

Rui Barradas


Em 24-01-2017 21:53, CHIRIBOGA Xavier escreveu:
> Dear colleagues,
>
>
> I am having trouble installing lme4 package and this leads me to problems installing lmerTest, when I try to do I got this Error messages:
>
>> install.packages("lme4")
> Installing package into 'C:/Users/Hp/Documents/R/win-library/3.3'
> (as 'lib' is unspecified)
> probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lme4_1.1-12.zip'
> Content type 'application/zip' length 4745943 bytes (4.5 MB)
> downloaded 4.5 MB
>
> package 'lme4' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'lme4'
>
> The downloaded binary packages are in
>          C:\Users\Hp\AppData\Local\Temp\RtmpWKmMgm\downloaded_packages
>> library(lme4)
> Error in library(lme4) : there is no package called 'lme4'
>> install.packages("lmerTest")
> Installing package into 'C:/Users/Hp/Documents/R/win-library/3.3'
> (as 'lib' is unspecified)
> also installing the dependency 'lme4'
>
> probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lme4_1.1-12.zip'
> Content type 'application/zip' length 4745943 bytes (4.5 MB)
> downloaded 4.5 MB
>
> probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lmerTest_2.0-33.zip'
> Content type 'application/zip' length 1149636 bytes (1.1 MB)
> downloaded 1.1 MB
>
> package 'lme4' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'lme4'
> package 'lmerTest' successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>          C:\Users\Hp\AppData\Local\Temp\RtmpWKmMgm\downloaded_packages
>> library(lmerTest)
> Loading required package: Matrix
> Error: package 'lme4' required by 'lmerTest' could not be found
> Adem?s: Warning message:
> In read.dcf(file.path(p, "DESCRIPTION"), c("Package", "Version")) :
>    cannot open compressed file 'C:/Users/Hp/Documents/R/win-library/3.3/lme4/DESCRIPTION', probable reason 'No such file or directory'
>
>
>
> Could yo please help me?
>
> What to do? I am using latest version : R 3.3.2.
>
>
> Thank you very much,
>
> Xavier
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thierry.onkelinx at inbo.be  Wed Jan 25 12:42:24 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Jan 2017 12:42:24 +0100
Subject: [R] HELP lme4 & lmerTest INSTALLATION
In-Reply-To: <588881C6.6000400@sapo.pt>
References: <1485294834325.31820@unine.ch> <588881C6.6000400@sapo.pt>
Message-ID: <CAJuCY5x4HfeSedv7U9etCzs05bE7-+LQ8Zf2KTcSGx=LLtj=gg@mail.gmail.com>

Dear Rui,

nlme is a recommended package, lme4 is (currently) not. You need to install
it.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-01-25 11:45 GMT+01:00 Rui Barradas <ruipbarradas at sapo.pt>:

>
> You don't need to install lme4, it comes with base R.
>

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Wed Jan 25 12:49:09 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 25 Jan 2017 11:49:09 +0000
Subject: [R] Cannot open MTS package
In-Reply-To: <1485259740186.48057@kent.ac.uk>
References: <1485259740186.48057@kent.ac.uk>
Message-ID: <1485344972009.90814@kent.ac.uk>

Dear all,

I am trying to download MTS package but when I call it using library() I get the error below. I have already installed the Rcpp package. What is wrong? What must I do to open the MTS package?



Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'Rcpp'
Error: package or namespace load failed for 'MTS'





	[[alternative HTML version deleted]]


From alachanc at bates.edu  Wed Jan 25 15:12:05 2017
From: alachanc at bates.edu (Andrew Lachance)
Date: Wed, 25 Jan 2017 09:12:05 -0500
Subject: [R] XML to CSV
In-Reply-To: <69D768435B870B498704129A048CDB190F41F34C@nermbxs08.nervianoms.com>
References: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>
	<B41EB1BE-2E3F-4315-9D72-F434D8DB353E@bigelow.org>
	<CAMgrDmOKQbmc0pP8dsORvF7gfcQMAcis_CVBfC7QRLc+jHA89g@mail.gmail.com>
	<C8399CB8-5E8A-40A1-9295-15F77EBD6643@bigelow.org>
	<EFA2748B-6A6D-4152-9454-A40ADF077805@dcn.davis.ca.us>
	<69D768435B870B498704129A048CDB190F41F34C@nermbxs08.nervianoms.com>
Message-ID: <CAMgrDmO9JbOqvRSY8CTseVW9iKqjGWjsqAzk961Sn5607maWpA@mail.gmail.com>

Hello all,

Thank you for the extremely helpful information. As a follow up, some of
the nested elements are of the form below:
-<DischargeMedication>
    <Medication MedAdmin="0" MedID="10"/>
    <Medication MedAdmin="0" MedID="11"/>

I've been having trouble extracting this information and was wondering if
anyone had any suggestions.

Thank you,
Andrew

On Thu, Jan 5, 2017 at 7:39 AM, Franzini, Gabriele [Nervianoms] <
Gabriele.Franzini at nervianoms.com> wrote:

> Hello Andrew,
>
> as you are "clean slate" anyway in handling XML files, you could take a
> look to XSLT processing -- also an off-topic area.
> There are free tools available around, and many examples of "XML to CSV
> XSLT" on StackOverflow.
>
> HTH,
> Gabriele
>
> -----Original Message-----
>
> On January 4, 2017 12:45:08 PM PST, Ben Tupper <btupper at bigelow.org>
> wrote:
> >Hi,
> >
> >You should keep replies on the list - you never know when someone will
> >swoop in with the right answer to make your life easier.
> >
> >Below is a simple example that uses xpath syntax to identify (and in
> >this case retrieve) children that match your xpath expression.  xpath
> >epxressions are sort of like /a/directory/structure/description so you
> >can visualize elements of XML like nested folders or subdirectories.
> >
> >Hopefully this will get you started.  A lot more on xpath here
> >http://www.w3schools.com/xml/xml_xpath.asp  There are other extraction
> >tools in xml2 - just type ?xml2 at the command prompt to see more.
> >
> >Since you have more deeply nested elements you'll need to play with
> >this a bit first.
> >
> >library(xml2)
> >uri = 'http://www.w3schools.com/xml/simple.xml'
> >x = read_xml(uri)
> >
> >name_nodes = xml_find_all(x, "//name")
> >name = xml_text(name_nodes)
> >
> >price_nodes = xml_find_all(x, "//price")
> >price = xml_text(price_nodes)
> >
> >calories_nodes = xml_find_all(x, "//calories")
> >calories = xml_double(calories_nodes)
> >
> >X = data.frame(name, price, calories, stringsAsFactors = FALSE)
> >write.csv(X, file = 'foo.csv')
> >
> >Cheers,
> >Ben
> >
> >> On Jan 4, 2017, at 2:13 PM, Andrew Lachance <alachanc at bates.edu>
> >wrote:
> >>
> >> Hello Ben,
> >>
> >> Thank you for the advice. I am extremely new to any sort of coding so
> >I have learned a lot already. Essentially, I was given an XML file and
> >was told to convert all of it to a csv so that it could be uploaded
> >into a database. Unfortunately the information I am working with is
> >medical information and can't really share it. I initially tried to
> >convert it using online programs, however that ended up with a large
> >amount of blank spaces that wasn't useful for uploading into the
> >database.
> >>
> >> So essentially, my goal is to parse all the data in the XML to a
> >coherent, succinct CSV that could be uploaded. In the document, there
> >are 361 patient files with 13 subcategories for each patient which
> >further branches off to around 150 categories total. Since I am so new,
> >I have been having a hard time seeing the bigger picture or knowing if
> >there are any intermediary steps that will prevent all the blank spaces
> >that the online conversion programs created.
> >>
> >> I will look through the information on the xml2 package. Any advice
> >or recommendations would be greatly appreciated as I have felt fairly
> >stuck. Once again, thank you very much for your help.
> >>
> >> Best,
> >> Andrew
> >>
> >> On Tue, Jan 3, 2017 at 2:29 PM, Ben Tupper <btupper at bigelow.org
> ><mailto:btupper at bigelow.org>> wrote:
> >> Hi,
> >>
> >> It's hard to know what to advise - much depends upon the XML data you
> >have and what you want to extract from it. Without knowing about those
> >two things there is little anyone could do to help.  Can you post to
> >the internet a to example data and provide the link here?  Then state
> >explicitly what you want to have in hand at the end.
> >>
> >> If you are just starting out I suggest that you try xml2 package (
> >https://cran.r-project.org/web/packages/xml2/
> ><https://cran.r-project.org/web/packages/xml2/> ) rather than XML
> >package ( https://cran.r-project.org/web/packages/XML/
> ><https://cran.r-project.org/web/packages/XML/> ). I have been using it
> >much more since the authors added the ability to create xml nodes
> >(rather than just extracting data from existing xml nodes).
> >>
> >> Cheers,
> >> Ben
> >>
> >> P.S.  Hello to my niece Olivia S on the Bates EMS team.
> >>
> >>
> >> > On Jan 3, 2017, at 11:27 AM, Andrew Lachance <alachanc at bates.edu
> ><mailto:alachanc at bates.edu>> wrote:
> >> >
> >> > up votdown votefavorite
> >> >
> ><http://stats.stackexchange.com/questions/254328/how-to-
> convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#
> ><http://stats.stackexchange.com/questions/254328/how-to-
> convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>>
> >> >
> >> > I am completely new to R and have tried to use several functions
> >within the
> >> > xml packages to convert an XML to a csv and have had little
> >success. Since
> >> > I am so new, I am not sure what the necessary steps are to complete
> >this
> >> > conversion without a lot of NA.
> >> >
> >> > --
> >> > Andrew D. Lachance
> >> > Chief of Service, Bates Emergency Medical Service
> >> > Residence Coordinator, Hopkins House
> >> > Bates College Class of 2017
> >> > alachanc at bates.edu <mailto:alachanc at bates.edu> <wcurley at bates.edu
> ><mailto:wcurley at bates.edu>>
> >> > (207) 620-4854
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> ><https://stat.ethz.ch/mailman/listinfo/r-help>
> >> > PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> ><http://www.r-project.org/posting-guide.html>
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> Ben Tupper
> >> Bigelow Laboratory for Ocean Sciences
> >> 60 Bigelow Drive, P.O. Box 380
> >> East Boothbay, Maine 04544
> >> http://www.bigelow.org <http://www.bigelow.org/>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >> Andrew D. Lachance
> >> Chief of Service, Bates Emergency Medical Service
> >> Residence Coordinator, Hopkins House
> >> Bates College Class of 2017
> >> alachanc at bates.edu <mailto:wcurley at bates.edu>
> >> (207) 620-4854
> >
> >Ben Tupper
> >Bigelow Laboratory for Ocean Sciences
> >60 Bigelow Drive, P.O. Box 380
> >East Boothbay, Maine 04544
> >http://www.bigelow.org
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Andrew D. Lachance
Chief of Service, Bates Emergency Medical Service
Residence Coordinator, Hopkins House
Bates College Class of 2017
alachanc at bates.edu <wcurley at bates.edu>
(207) 620-4854

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Jan 25 15:20:54 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 25 Jan 2017 14:20:54 +0000
Subject: [R] HELP lme4 & lmerTest INSTALLATION
In-Reply-To: <CAJuCY5x4HfeSedv7U9etCzs05bE7-+LQ8Zf2KTcSGx=LLtj=gg@mail.gmail.com>
References: <1485294834325.31820@unine.ch> <588881C6.6000400@sapo.pt>
	<CAJuCY5x4HfeSedv7U9etCzs05bE7-+LQ8Zf2KTcSGx=LLtj=gg@mail.gmail.com>
Message-ID: <5888B446.7070006@sapo.pt>

Oh, so sorry then, I thought I hadn't installed it and when I did 
library(lme4) it ran without error.
Thanks for the correction.

Rui Barradas

Em 25-01-2017 11:42, Thierry Onkelinx escreveu:
> Dear Rui,
>
> nlme is a recommended package, lme4 is (currently) not. You need to
> install it.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
>
> 2017-01-25 11:45 GMT+01:00 Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>>:
>
>
>     You don't need to install lme4, it comes with base R.
>


From Gabriele.Franzini at nervianoms.com  Wed Jan 25 15:43:00 2017
From: Gabriele.Franzini at nervianoms.com (Franzini, Gabriele [Nervianoms])
Date: Wed, 25 Jan 2017 15:43:00 +0100
Subject: [R] XML to CSV
In-Reply-To: <CAMgrDmO9JbOqvRSY8CTseVW9iKqjGWjsqAzk961Sn5607maWpA@mail.gmail.com>
References: <CAMgrDmMi_21jpCUeoaNjfN0KR2pLd-C--rbdVVSQ+_jFSR+5Ww@mail.gmail.com>
	<B41EB1BE-2E3F-4315-9D72-F434D8DB353E@bigelow.org>
	<CAMgrDmOKQbmc0pP8dsORvF7gfcQMAcis_CVBfC7QRLc+jHA89g@mail.gmail.com>
	<C8399CB8-5E8A-40A1-9295-15F77EBD6643@bigelow.org>
	<EFA2748B-6A6D-4152-9454-A40ADF077805@dcn.davis.ca.us>
	<69D768435B870B498704129A048CDB190F41F34C@nermbxs08.nervianoms.com>
	<CAMgrDmO9JbOqvRSY8CTseVW9iKqjGWjsqAzk961Sn5607maWpA@mail.gmail.com>
Message-ID: <69D768435B870B498704129A048CDB190F59EE45@nermbxs08.nervianoms.com>

They are attributes, not nodes so, if I understood the question:

"//DischargeMedication/Medication/@MedAdmin"
"//DischargeMedication/Medication/@MedID"

should do.
HTH, 
Gabriele


From: Andrew Lachance [mailto:alachanc at bates.edu] 
Sent: Wednesday, January 25, 2017 3:12 PM
To: Franzini, Gabriele [Nervianoms]
Cc: r-help at r-project.org
Subject: Re: [R] XML to CSV

Hello all,

Thank you for the extremely helpful information. As a follow up, some of the nested elements are of the form below:
-<DischargeMedication>
? ? <Medication MedAdmin="0" MedID="10"/>
? ? <Medication MedAdmin="0" MedID="11"/>

I've been having trouble extracting this information and was wondering if anyone had any suggestions.

Thank you,
Andrew

On Thu, Jan 5, 2017 at 7:39 AM, Franzini, Gabriele [Nervianoms] <Gabriele.Franzini at nervianoms.com> wrote:
Hello Andrew,

as you are "clean slate" anyway in handling XML files, you could take a look to XSLT processing -- also an off-topic area.
There are free tools available around, and many examples of "XML to CSV XSLT" on StackOverflow.

HTH,
Gabriele

-----Original Message-----

On January 4, 2017 12:45:08 PM PST, Ben Tupper <btupper at bigelow.org> wrote:
>Hi,
>
>You should keep replies on the list - you never know when someone will
>swoop in with the right answer to make your life easier.
>
>Below is a simple example that uses xpath syntax to identify (and in
>this case retrieve) children that match your xpath expression.? xpath
>epxressions are sort of like /a/directory/structure/description so you
>can visualize elements of XML like nested folders or subdirectories.
>
>Hopefully this will get you started.? A lot more on xpath here
>http://www.w3schools.com/xml/xml_xpath.asp? There are other extraction
>tools in xml2 - just type ?xml2 at the command prompt to see more.
>
>Since you have more deeply nested elements you'll need to play with
>this a bit first.
>
>library(xml2)
>uri = 'http://www.w3schools.com/xml/simple.xml'
>x = read_xml(uri)
>
>name_nodes = xml_find_all(x, "//name")
>name = xml_text(name_nodes)
>
>price_nodes = xml_find_all(x, "//price")
>price = xml_text(price_nodes)
>
>calories_nodes = xml_find_all(x, "//calories")
>calories = xml_double(calories_nodes)
>
>X = data.frame(name, price, calories, stringsAsFactors = FALSE)
>write.csv(X, file = 'foo.csv')
>
>Cheers,
>Ben
>
>> On Jan 4, 2017, at 2:13 PM, Andrew Lachance <alachanc at bates.edu>
>wrote:
>>
>> Hello Ben,
>>
>> Thank you for the advice. I am extremely new to any sort of coding so
>I have learned a lot already. Essentially, I was given an XML file and
>was told to convert all of it to a csv so that it could be uploaded
>into a database. Unfortunately the information I am working with is
>medical information and can't really share it. I initially tried to
>convert it using online programs, however that ended up with a large
>amount of blank spaces that wasn't useful for uploading into the
>database.
>>
>> So essentially, my goal is to parse all the data in the XML to a
>coherent, succinct CSV that could be uploaded. In the document, there
>are 361 patient files with 13 subcategories for each patient which
>further branches off to around 150 categories total. Since I am so new,
>I have been having a hard time seeing the bigger picture or knowing if
>there are any intermediary steps that will prevent all the blank spaces
>that the online conversion programs created.
>>
>> I will look through the information on the xml2 package. Any advice
>or recommendations would be greatly appreciated as I have felt fairly
>stuck. Once again, thank you very much for your help.
>>
>> Best,
>> Andrew
>>
>> On Tue, Jan 3, 2017 at 2:29 PM, Ben Tupper <btupper at bigelow.org
><mailto:btupper at bigelow.org>> wrote:
>> Hi,
>>
>> It's hard to know what to advise - much depends upon the XML data you
>have and what you want to extract from it. Without knowing about those
>two things there is little anyone could do to help.? Can you post to
>the internet a to example data and provide the link here?? Then state
>explicitly what you want to have in hand at the end.
>>
>> If you are just starting out I suggest that you try xml2 package (
>https://cran.r-project.org/web/packages/xml2/
><https://cran.r-project.org/web/packages/xml2/> ) rather than XML
>package ( https://cran.r-project.org/web/packages/XML/
><https://cran.r-project.org/web/packages/XML/> ). I have been using it
>much more since the authors added the ability to create xml nodes
>(rather than just extracting data from existing xml nodes).
>>
>> Cheers,
>> Ben
>>
>> P.S.? Hello to my niece Olivia S on the Bates EMS team.
>>
>>
>> > On Jan 3, 2017, at 11:27 AM, Andrew Lachance <alachanc at bates.edu
><mailto:alachanc at bates.edu>> wrote:
>> >
>> > up votdown votefavorite
>> >
><http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#
><http://stats.stackexchange.com/questions/254328/how-to-convert-a-large-xml-file-to-a-csv-file-using-r?noredirect=1#>>
>> >
>> > I am completely new to R and have tried to use several functions
>within the
>> > xml packages to convert an XML to a csv and have had little
>success. Since
>> > I am so new, I am not sure what the necessary steps are to complete
>this
>> > conversion without a lot of NA.
>> >
>> > --
>> > Andrew D. Lachance
>> > Chief of Service, Bates Emergency Medical Service
>> > Residence Coordinator, Hopkins House
>> > Bates College Class of 2017
>> > alachanc at bates.edu <mailto:alachanc at bates.edu> <wcurley at bates.edu
><mailto:wcurley at bates.edu>>
>> > (207) 620-4854
>> >
>> >? ? ? ?[[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
><http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org <http://www.bigelow.org/>
>>
>>
>>
>>
>>
>>
>> --
>> Andrew D. Lachance
>> Chief of Service, Bates Emergency Medical Service
>> Residence Coordinator, Hopkins House
>> Bates College Class of 2017
>> alachanc at bates.edu <mailto:wcurley at bates.edu>
>> (207) 620-4854
>
>Ben Tupper
>Bigelow Laboratory for Ocean Sciences
>60 Bigelow Drive, P.O. Box 380
>East Boothbay, Maine 04544
>http://www.bigelow.org
>
>
>
>
>? ? ? ?[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.





-- 
Andrew D. Lachance
Chief of Service, Bates Emergency Medical Service
Residence Coordinator, Hopkins House
Bates College Class of 2017
alachanc at bates.edu
(207) 620-4854

From istazahn at gmail.com  Wed Jan 25 16:25:46 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 25 Jan 2017 10:25:46 -0500
Subject: [R] Cannot open MTS package
In-Reply-To: <1485344972009.90814@kent.ac.uk>
References: <1485259740186.48057@kent.ac.uk> <1485344972009.90814@kent.ac.uk>
Message-ID: <CA+vqiLFFTeZEitMj+DRR37+gzrN7Ef39DUihuJW6EcrtmJ1CHQ@mail.gmail.com>

"there is no package called 'Rcpp'" is a pretty clear error message.
Did you try installing the Rcpp package?

Best,
Ista

On Wed, Jan 25, 2017 at 6:49 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> Dear all,
>
> I am trying to download MTS package but when I call it using library() I get the error below. I have already installed the Rcpp package. What is wrong? What must I do to open the MTS package?
>
>
>
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>   there is no package called 'Rcpp'
> Error: package or namespace load failed for 'MTS'
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From xavier.chiriboga at unine.ch  Wed Jan 25 16:46:28 2017
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Wed, 25 Jan 2017 15:46:28 +0000
Subject: [R] HELP lme4 & lmerTest INSTALLATION
In-Reply-To: <CAJuCY5x4HfeSedv7U9etCzs05bE7-+LQ8Zf2KTcSGx=LLtj=gg@mail.gmail.com>
References: <1485294834325.31820@unine.ch> <588881C6.6000400@sapo.pt>,
	<CAJuCY5x4HfeSedv7U9etCzs05bE7-+LQ8Zf2KTcSGx=LLtj=gg@mail.gmail.com>
Message-ID: <1485359191349.33562@unine.ch>

Dear Thierry,


So, does it mean that I have to install "nlme" instead of "lme4"? or first "nlme" and after "lme4"???


I also need"lmerTest" and when I installed it, I got the following message:


install.packages("lmerTest")
Installing package into 'C:/Users/Hp/Documents/R/win-library/3.3'
(as 'lib' is unspecified)
probando la URL 'http://cran.espol.edu.ec/bin/windows/contrib/3.3/lmerTest_2.0-33.zip'
Content type 'application/zip' length 1149547 bytes (1.1 MB)
downloaded 1.1 MB

package 'lmerTest' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\Hp\AppData\Local\Temp\Rtmp6D0iIu\downloaded_packages
> library(lmerTest)
Loading required package: Matrix
Loading required package: lme4

Attaching package: 'lme4'

The following object is masked from 'package:nlme':

    lmList


Attaching package: 'lmerTest'

The following object is masked from 'package:lme4':

    lmer


THANK YOU FOR YOUR REPLY,


Xavier

________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: Wednesday, January 25, 2017 12:42 PM
To: Rui Barradas
Cc: CHIRIBOGA Xavier; r-help at r-project.org
Subject: Re: [R] HELP lme4 & lmerTest INSTALLATION

Dear Rui,

nlme is a recommended package, lme4 is (currently) not. You need to install it.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2017-01-25 11:45 GMT+01:00 Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>:

You don't need to install lme4, it comes with base R.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jan 25 18:20:27 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 25 Jan 2017 09:20:27 -0800
Subject: [R] Cannot open MTS package
In-Reply-To: <CA+vqiLFFTeZEitMj+DRR37+gzrN7Ef39DUihuJW6EcrtmJ1CHQ@mail.gmail.com>
References: <1485259740186.48057@kent.ac.uk> <1485344972009.90814@kent.ac.uk>
	<CA+vqiLFFTeZEitMj+DRR37+gzrN7Ef39DUihuJW6EcrtmJ1CHQ@mail.gmail.com>
Message-ID: <CAGxFJbT0s+WaRCKnYnXhXtYDDTHJughqES9R1t=jqbTU52Vg-A@mail.gmail.com>

Ista:

See below. He states that he did. Maybe the question is where? -- in
the lib.loc in .libPaths() or somewhere where R cannot find it?

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 25, 2017 at 7:25 AM, Ista Zahn <istazahn at gmail.com> wrote:
> "there is no package called 'Rcpp'" is a pretty clear error message.
> Did you try installing the Rcpp package?
>
> Best,
> Ista
>
> On Wed, Jan 25, 2017 at 6:49 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
>> Dear all,
>>
>> I am trying to download MTS package but when I call it using library() I get the error below. I have already installed the Rcpp package. What is wrong? What must I do to open the MTS package?
>>
>>
>>
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>>   there is no package called 'Rcpp'
>> Error: package or namespace load failed for 'MTS'
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roger.bos at rothschild.com  Wed Jan 25 18:44:59 2017
From: roger.bos at rothschild.com (Bos, Roger)
Date: Wed, 25 Jan 2017 17:44:59 +0000
Subject: [R] selecting colors to be used in a plot
Message-ID: <0765308CD028654885F30322557308D8667D59AC@NYCSM0208.rth.ad.rothschild.com>

My specific question relates to function charts.PerformanceSummary in package PerformanceAnalytics, but the underlying problem is probably with base plot.

In this sample code we see a chart with 10 groupings.  Apparently 10 groupings is bigger than the number of default colors (8), so red and black are recycled, but in my case groups 1 and 2 are the worst and groups 9 and 10 are the best, so if the same red and black colors are used for both it gets confusing:

Minimal working example with recycled colors:

dates <- as.Date(c('1970-01-02','1970-01-03','1970-01-04','1970-01-05','1970-01-06','1970-01-07','1970-01-08','1970-01-09','1970-01-10','1970-01-11'), format="%Y-%m-%d")
x <- as.xts(matrix(runif(100),10,10), order.by=dates)
names(x) <- paste("Group", 1:10)
charts.PerformanceSummary(x, geometric=FALSE, ylog=TRUE, main='Log Return by Column')

Since the documentation says you can pass other variables to plot, I try to use ?col? to set my own colors:

colors <- c("#A6CEE3","#1F78B4","#B2DF8A","#33A02C","#FB9A99","#E31A1C","#FDBF6F","#FF7F00","#CAB2D6","#6A3D9A")
charts.PerformanceSummary(x, geometric=FALSE, ylog=TRUE, col = colors, main='Log Return by Column')

Error in plot.xy(xy.coords(x, y), type = type, ...) :
  formal argument "col" matched by multiple actual arguments

I am sure it is possible to produce a plot using more than 8 colors.  Would someone please point out what I am doing wrong?  Thanks in advance.



This message and any attachments are for the intended recipient?s use only. This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies. You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.





From rmh at temple.edu  Wed Jan 25 18:58:06 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 25 Jan 2017 12:58:06 -0500
Subject: [R] selecting colors to be used in a plot
In-Reply-To: <0765308CD028654885F30322557308D8667D59AC@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D8667D59AC@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAGx1TMC3m=GRzWuvXBeV7+CGvAD42xE2b3nGF=S8_q5e=jmBhQ@mail.gmail.com>

This package uses a nonstandard name colorset.
This is based on the help example for
?charts.PerformanceSummary

>      data(edhec)
>      charts.PerformanceSummary(edhec[,c(1,13)])
>      charts.PerformanceSummary(edhec[,c(1,13)], colorset=c("red","blue"))
>

On Wed, Jan 25, 2017 at 12:44 PM, Bos, Roger <roger.bos at rothschild.com> wrote:
> My specific question relates to function charts.PerformanceSummary in package PerformanceAnalytics, but the underlying problem is probably with base plot.
>
> In this sample code we see a chart with 10 groupings.  Apparently 10 groupings is bigger than the number of default colors (8), so red and black are recycled, but in my case groups 1 and 2 are the worst and groups 9 and 10 are the best, so if the same red and black colors are used for both it gets confusing:
>
> Minimal working example with recycled colors:
>
> dates <- as.Date(c('1970-01-02','1970-01-03','1970-01-04','1970-01-05','1970-01-06','1970-01-07','1970-01-08','1970-01-09','1970-01-10','1970-01-11'), format="%Y-%m-%d")
> x <- as.xts(matrix(runif(100),10,10), order.by=dates)
> names(x) <- paste("Group", 1:10)
> charts.PerformanceSummary(x, geometric=FALSE, ylog=TRUE, main='Log Return by Column')
>
> Since the documentation says you can pass other variables to plot, I try to use ?col? to set my own colors:
>
> colors <- c("#A6CEE3","#1F78B4","#B2DF8A","#33A02C","#FB9A99","#E31A1C","#FDBF6F","#FF7F00","#CAB2D6","#6A3D9A")
> charts.PerformanceSummary(x, geometric=FALSE, ylog=TRUE, col = colors, main='Log Return by Column')
>
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
>   formal argument "col" matched by multiple actual arguments
>
> I am sure it is possible to produce a plot using more than 8 colors.  Would someone please point out what I am doing wrong?  Thanks in advance.
>
>
>
> This message and any attachments are for the intended recipient?s use only. This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies. You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roger.bos at rothschild.com  Wed Jan 25 19:17:05 2017
From: roger.bos at rothschild.com (Bos, Roger)
Date: Wed, 25 Jan 2017 18:17:05 +0000
Subject: [R] selecting colors to be used in a plot
In-Reply-To: <CAGx1TMC3m=GRzWuvXBeV7+CGvAD42xE2b3nGF=S8_q5e=jmBhQ@mail.gmail.com>
References: <0765308CD028654885F30322557308D8667D59AC@NYCSM0208.rth.ad.rothschild.com>
	<CAGx1TMC3m=GRzWuvXBeV7+CGvAD42xE2b3nGF=S8_q5e=jmBhQ@mail.gmail.com>
Message-ID: <0765308CD028654885F30322557308D8667D59DC@NYCSM0208.rth.ad.rothschild.com>

Thanks Richard.  That worked beautifully!


-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu]
Sent: Wednesday, January 25, 2017 12:58 PM
To: Bos, Roger
Cc: R Help R
Subject: Re: [R] selecting colors to be used in a plot

This package uses a nonstandard name colorset.
This is based on the help example for
?charts.PerformanceSummary

>      data(edhec)
>      charts.PerformanceSummary(edhec[,c(1,13)])
>      charts.PerformanceSummary(edhec[,c(1,13)],
> colorset=c("red","blue"))
>

On Wed, Jan 25, 2017 at 12:44 PM, Bos, Roger <roger.bos at rothschild.com> wrote:
> My specific question relates to function charts.PerformanceSummary in package PerformanceAnalytics, but the underlying problem is probably with base plot.
>
> In this sample code we see a chart with 10 groupings.  Apparently 10 groupings is bigger than the number of default colors (8), so red and black are recycled, but in my case groups 1 and 2 are the worst and groups 9 and 10 are the best, so if the same red and black colors are used for both it gets confusing:
>
> Minimal working example with recycled colors:
>
> dates <-
> as.Date(c('1970-01-02','1970-01-03','1970-01-04','1970-01-05','1970-01
> -06','1970-01-07','1970-01-08','1970-01-09','1970-01-10','1970-01-11')
> , format="%Y-%m-%d") x <- as.xts(matrix(runif(100),10,10),
> order.by=dates)
> names(x) <- paste("Group", 1:10)
> charts.PerformanceSummary(x, geometric=FALSE, ylog=TRUE, main='Log
> Return by Column')
>
> Since the documentation says you can pass other variables to plot, I try to use ?col? to set my own colors:
>
> colors <-
> c("#A6CEE3","#1F78B4","#B2DF8A","#33A02C","#FB9A99","#E31A1C","#FDBF6F
> ","#FF7F00","#CAB2D6","#6A3D9A") charts.PerformanceSummary(x,
> geometric=FALSE, ylog=TRUE, col = colors, main='Log Return by Column')
>
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
>   formal argument "col" matched by multiple actual arguments
>
> I am sure it is possible to produce a plot using more than 8 colors.  Would someone please point out what I am doing wrong?  Thanks in advance.
>
>
>
> This message and any attachments are for the intended recipient?s use only. This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies. You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



This message and any attachments are for the intended recipient?s use only. This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies. You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.





From thpe at simecol.de  Thu Jan 26 01:02:15 2017
From: thpe at simecol.de (Thomas Petzoldt)
Date: Thu, 26 Jan 2017 01:02:15 +0100
Subject: [R] Adding x and y axis labels with the function plot.sensFun
 (package FME)
In-Reply-To: <AM5PR0701MB23381A40C4C54E5EB42B7D5AE2740@AM5PR0701MB2338.eurprd07.prod.outlook.com>
References: <AM5PR0701MB23381A40C4C54E5EB42B7D5AE2740@AM5PR0701MB2338.eurprd07.prod.outlook.com>
Message-ID: <d0c05ce5-ab0d-667d-4b92-e2a90a1a1e27@simecol.de>

Hi,

I reproduced your example and it worked for me with "Time" and 
"Population size" as axis labels. Are you using the most recent version?

Thomas



Am 25.01.2017 um 02:32 schrieb Marine Regis:
> Hello,
>
>
> How can I add x and y axis labels for a plot that is built from the function plot.sensFun (package FME) ? I tested xlab ="Time" and ylab="Population size" but this doesn't work for me.
>
>
> Here is a code to generate the plot:
>
>
> pars <- list(gmax = 0.5, eff = 0.5,
>              ks = 0.5, rB = 0.01, dB = 0.01)
>
> solveBact <- function(pars) {
>   derivs <- function(t, state, pars) { # returns rate of change
>     with (as.list(c(state, pars)), {
>       dBact <-  gmax * eff * Sub/(Sub + ks) * Bact - dB * Bact - rB * Bact
>       dSub  <- -gmax       * Sub/(Sub + ks) * Bact + dB * Bact
>       return(list(c(dBact, dSub)))
>     })
>   }
>   state   <- c(Bact = 0.1, Sub = 100)
>   tout    <- seq(0, 50, by = 0.5)
>   ## ode solves the model by integration ...
>   return(as.data.frame(ode(y = state, times = tout, func = derivs,
>                            parms = pars)))
> }
>
> ## sensitivity functions
> SF <- sensFun(func = solveBact, parms = pars,
>               sensvar = c("Bact", "Sub"), varscale = 1)
> par(mfrow = c(1,2))
> plot(SF, which = c("Sub", "Bact"), mfrow = NULL, xlab="Time", ylab="Population size")
>
> Thanks a lot for your time.
> Marine
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lists at dewey.myzen.co.uk  Wed Jan 25 17:10:28 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 25 Jan 2017 16:10:28 +0000
Subject: [R] [R-pkgs] Update of package metap now on CRAN
Message-ID: <f7f0ffc1-c3cf-537d-4bd0-8a8d4804cb2a@dewey.myzen.co.uk>

I have uploaded version 0.8 of this package for meta-analysis of 
significance values. In the nearly three years since I last posted here 
about it there have been some additions (see the NEWS) but the most 
important change is an extended vignette which not only describes the 
function but also gives some information about choice between them.

I would be very interested to hear comments. In particular I am 
searching for published worked examples of (a) methods involving 
weighting except for Stouffer's method (b) methods for correlated 
significance values. I only include methods where I can check my coding 
against a published example.

Disclaimer: meta-analysis of significance values is a last resort and if 
you have effect sizes you should not use this package.

-- 
Michael
http://www.dewey.myzen.co.uk/home.html

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dr.vinay.muc at gmail.com  Thu Jan 26 14:20:02 2017
From: dr.vinay.muc at gmail.com (Dr.Vinay Pitchika)
Date: Thu, 26 Jan 2017 14:20:02 +0100
Subject: [R] Categorize subjects using PCA
Message-ID: <CACR65sEcsjb21w3KPcRuwHKPY2pX74u9gXuwjCOGJAGbhRJCPw@mail.gmail.com>

Hello everyone,

I have been analyzing dietary pattern data obtained via FFQ. We performed
Principal Component Analysis and decided to extract 3 dimensions (healthy,
unhealthy and mixed diet) and to adjust this in linear regression model
along with various other variables. However, our statistician was not happy
with the approach because the 3 dimensions we adjust do not have a measure.

So, I would like to classify the patients in our dataset using the PCA
results. Is it possible to classify all the patients into one of the 3
groups mentioned above?

Thank you
Vinay

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu Jan 26 14:39:42 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 26 Jan 2017 13:39:42 +0000
Subject: [R] Categorize subjects using PCA
In-Reply-To: <CACR65sEcsjb21w3KPcRuwHKPY2pX74u9gXuwjCOGJAGbhRJCPw@mail.gmail.com>
References: <CACR65sEcsjb21w3KPcRuwHKPY2pX74u9gXuwjCOGJAGbhRJCPw@mail.gmail.com>
Message-ID: <9e961572-f0dc-713a-351d-b66035c8946d@dewey.myzen.co.uk>

If you want to discover groupings in your data-set I would have thought 
latent class analysis was a more principled solution. There are several 
packages for doing this.

If you want more detail about this you might be better asking on 
stats.stackexchange.com for statistical help. When you do be sure to 
define what you mean by 'do not have a measure' as it is not, to me at 
least, clear what s/he means.

On 26/01/2017 13:20, Dr.Vinay Pitchika wrote:
> Hello everyone,
>
> I have been analyzing dietary pattern data obtained via FFQ. We performed
> Principal Component Analysis and decided to extract 3 dimensions (healthy,
> unhealthy and mixed diet) and to adjust this in linear regression model
> along with various other variables. However, our statistician was not happy
> with the approach because the 3 dimensions we adjust do not have a measure.
>
> So, I would like to classify the patients in our dataset using the PCA
> results. Is it possible to classify all the patients into one of the 3
> groups mentioned above?
>
> Thank you
> Vinay
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From kylecovington1 at gmail.com  Wed Jan 25 23:01:25 2017
From: kylecovington1 at gmail.com (Kyle Covington)
Date: Wed, 25 Jan 2017 16:01:25 -0600
Subject: [R]  Sweave and optional document sections
Message-ID: <839C75BF-C359-48EC-BD80-EF05869AF1CE@gmail.com>

I was just trying to do this and I think I have a reasonable solution that seems to be working well.

In the main document you can include a chunk with a logical section:

<<optnsa, echo=F, results=tex>>=
if(T){
  {sink("/dev/null"); Sweave(?subsection.Rnw'); sink(); } 
  cat('\\input{subsection.tex}')
}
@

Then you can put your subsection logic into subsection.Rnw, just make sure to remove all of the default latex header stuff, just put in the blocks that you want to process:


This comes from a subsection.

<<ssb1>>=
cat(?I?m in a  subsection?)
@

This worked for me

Kyle

From jeff.hughes at gmail.com  Thu Jan 26 00:23:27 2017
From: jeff.hughes at gmail.com (Jeff Hughes)
Date: Wed, 25 Jan 2017 18:23:27 -0500
Subject: [R] Error with "compiler" and "caret" packages
Message-ID: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>

Hi there,

I have been getting an irritating error when trying to use the "caret"
package on one of my machines. Whenever I train any model whatsoever, it
comes back with this error:

Warning: namespace ?compiler? is not available and has been replaced
by .GlobalEnv when processing object ?sep?
Error in comp(expr, env = envir, options = list(suppressUndefined = TRUE))
:
  could not find function "makeCenv"

As a result, the model does not work, and I am unable to use the caret
package. As an example, here is some code that causes the error, though it
has happened in every case I have tried:

library(caret)
fit.knn <- train(Species ~ ., data=iris, method="knn")

I have tried reinstalling the caret package; I have tried reinstalling R; I
have tried updating all of my packages; nothing has worked. What's more,
this machine is running Windows 10, and I have successfully run the same
code on two other machines running the same version of Windows, the same
version of R, and the same version of the caret package. I have also only
run into it when using caret, but I don't think the error lies within that
package itself.

Here is my sessionInfo() after running the above code in a new R session:

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2      MASS_7.3-45
     munsell_0.4.3      colorspace_1.3-2
 [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0      car_2.1-4
     plyr_1.8.4         tools_3.3.2
[13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6     grid_3.3.2
      gtable_0.2.0       nlme_3.1-128
[19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7        class_7.3-14
      MatrixModels_0.4-1 iterators_1.0.8
[25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1     tibble_1.2
      Matrix_1.2-7.1     nloptr_1.0.4
[31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15   stringi_1.1.2
     scales_0.4.1       stats4_3.3.2
[37] SparseM_1.74

Note that the "compiler" package is not loaded for some reason, which I
think it should be (the other machines on which this runs successfully have
it loaded). But the compiler package is built-in, so I can't seem to find a
way to load it manually.

This one has really stumped me, and there are very few relevant hits on
Google. Any help would be much appreciated!

Jeff

	[[alternative HTML version deleted]]


From mariapilar.gonzalez at ehu.eus  Thu Jan 26 12:58:17 2017
From: mariapilar.gonzalez at ehu.eus (=?utf-8?b?TcKq?= Pilar Gonzalez Casimiro)
Date: Thu, 26 Jan 2017 12:58:17 +0100
Subject: [R] testing in spatial sure models
Message-ID: <20170126125817.Horde.2L2YtkEITNsaGTrzcTS8bGF@webposta.ehu.eus>


Good afternoon,

I would like to know how to test for homogeneity in spatial sure models.

Thank you,

Pilar


  Pilar Gonz?lez Casimiro
  Facultad de Ciencias Econ?micas y Empresariales
  Avda. Lehendakari Aguirre, 83 48015 Bilbao
  tfno: 94 601 3730


From mtb_dave at yahoo.ca  Thu Jan 26 15:37:05 2017
From: mtb_dave at yahoo.ca (David Hutchinson)
Date: Thu, 26 Jan 2017 06:37:05 -0800
Subject: [R] Passing database connections to functions
Message-ID: <3359373c-de03-fcfe-e178-ee5a182352b4@yahoo.ca>

Hi,

I have a series of functions which query various tables of a sqlite 
database. The database was developed by a government agency and is 
downloaded to a local users computer (it is relatively large - 1 GB). 
These functions I have developed typically take the form of:

getData <- function(con, id) {
     sqlString <- sprintf("SELECT * FROM TABLE WHERE STATION = \'%s'\", id)
     qryResult <- dbGetQuery(con, sqlString)
     return(qryResult)
}

where 'con' represents an open database connection derived from:

db.path <- "~/Documents/mydatabase.sqlite3" # this path is user-dependent
con <- dbConnect(RSQLite::SQLite(), db.path)

I would like to expose these functions through an R package. I have two 
questions:
1. Is there a better way to handle passing of database connections to 
functions? By opening the database connection first, users can access 
one or more of the functions to return data by passing in 'con' as an 
argument. I've had a hard time finding resources on best practices.
2. Any documented examples for the eventual package will have to be 
wrapped with \donotrun{} since I cannot guarantee where the database may 
reside on the users computer. What is the R-communities take on 
developing a package for CRAN where documented methods have no working 
examples? I wish the underlying data were available through an http 
request, but they are not.

Thanks in advance,
Dave


From bgunter.4567 at gmail.com  Thu Jan 26 19:22:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 26 Jan 2017 10:22:50 -0800
Subject: [R] testing in spatial sure models
In-Reply-To: <20170126125817.Horde.2L2YtkEITNsaGTrzcTS8bGF@webposta.ehu.eus>
References: <20170126125817.Horde.2L2YtkEITNsaGTrzcTS8bGF@webposta.ehu.eus>
Message-ID: <CAGxFJbQjkK_22fL0HG_99iXuKBbhn-iba9r2UpYUsPcWmOLWYA@mail.gmail.com>

Wrong list.

For statistical questions (which this is), post to
stats.stackexchange.com. I suspect you will have to frame your query
more coherently (context, model, etc.) to get a response even there.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 26, 2017 at 3:58 AM, M? Pilar Gonzalez Casimiro
<mariapilar.gonzalez at ehu.eus> wrote:
>
> Good afternoon,
>
> I would like to know how to test for homogeneity in spatial sure models.
>
> Thank you,
>
> Pilar
>
>
>  Pilar Gonz?lez Casimiro
>  Facultad de Ciencias Econ?micas y Empresariales
>  Avda. Lehendakari Aguirre, 83 48015 Bilbao
>  tfno: 94 601 3730
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jan 26 19:24:19 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 26 Jan 2017 10:24:19 -0800
Subject: [R] Cannot open MTS package
In-Reply-To: <1485259740186.48057@kent.ac.uk>
References: <1485259740186.48057@kent.ac.uk>
Message-ID: <224234E9-7FB9-4CD3-AF4D-E188C334E37E@comcast.net>


> On Jan 24, 2017, at 4:08 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Dear all,
> 
> I am trying to download MTS package but when I call it using library()

Did you install it? If so, how?


> I get the error below. I have already installed the Rcpp package. What is wrong? What must I do to open the MTS package?
> 
> 
> 
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>  there is no package called 'Rcpp'
> Error: package or namespace load failed for 'MTS'

It appears your installation of Rcpp was also flawed. You should describe your setup, including the results of .libPaths(), say how you installed Rcpp, and show the code you used for all these steps.

> 	[[alternative HTML version deleted]]

And try to post in plain text. It's not a problem with this posting but as soon as you tryo post actual code, its liekly to be mangled by the HTML scrubbing that the listserver performs.
> 

And as always ...........
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Thu Jan 26 19:25:38 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 26 Jan 2017 10:25:38 -0800
Subject: [R] Error with "compiler" and "caret" packages
In-Reply-To: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
References: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
Message-ID: <CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>

Check your permissions? They may be denying your process access.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 25, 2017 at 3:23 PM, Jeff Hughes <jeff.hughes at gmail.com> wrote:
> Hi there,
>
> I have been getting an irritating error when trying to use the "caret"
> package on one of my machines. Whenever I train any model whatsoever, it
> comes back with this error:
>
> Warning: namespace ?compiler? is not available and has been replaced
> by .GlobalEnv when processing object ?sep?
> Error in comp(expr, env = envir, options = list(suppressUndefined = TRUE))
> :
>   could not find function "makeCenv"
>
> As a result, the model does not work, and I am unable to use the caret
> package. As an example, here is some code that causes the error, though it
> has happened in every case I have tried:
>
> library(caret)
> fit.knn <- train(Species ~ ., data=iris, method="knn")
>
> I have tried reinstalling the caret package; I have tried reinstalling R; I
> have tried updating all of my packages; nothing has worked. What's more,
> this machine is running Windows 10, and I have successfully run the same
> code on two other machines running the same version of Windows, the same
> version of R, and the same version of the caret package. I have also only
> run into it when using caret, but I don't think the error lies within that
> package itself.
>
> Here is my sessionInfo() after running the above code in a new R session:
>
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2      MASS_7.3-45
>      munsell_0.4.3      colorspace_1.3-2
>  [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0      car_2.1-4
>      plyr_1.8.4         tools_3.3.2
> [13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6     grid_3.3.2
>       gtable_0.2.0       nlme_3.1-128
> [19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7        class_7.3-14
>       MatrixModels_0.4-1 iterators_1.0.8
> [25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1     tibble_1.2
>       Matrix_1.2-7.1     nloptr_1.0.4
> [31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15   stringi_1.1.2
>      scales_0.4.1       stats4_3.3.2
> [37] SparseM_1.74
>
> Note that the "compiler" package is not loaded for some reason, which I
> think it should be (the other machines on which this runs successfully have
> it loaded). But the compiler package is built-in, so I can't seem to find a
> way to load it manually.
>
> This one has really stumped me, and there are very few relevant hits on
> Google. Any help would be much appreciated!
>
> Jeff
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rob.vech87 at gmail.com  Thu Jan 26 19:46:33 2017
From: rob.vech87 at gmail.com (rob vech)
Date: Thu, 26 Jan 2017 19:46:33 +0100
Subject: [R] order list of date (bug?)
In-Reply-To: <CAF8bMcb=aNC1hW-UXzsT++e5J5-=OGycjWrpM2yCsGEJ2awd9A@mail.gmail.com>
References: <6f286496-383e-a849-903c-973778fae196@gmail.com>
	<CAF8bMcb=DgwRLS+=xZ5Oze2jCTAuwu2Y_pkEbbO4y7t6F6FF5w@mail.gmail.com>
	<CAF8bMcb=aNC1hW-UXzsT++e5J5-=OGycjWrpM2yCsGEJ2awd9A@mail.gmail.com>
Message-ID: <b37ba77c-bd51-1cdc-60ef-0ac9d266023c@gmail.com>

Hi William,
asking to the r-devel list I resolved the problem! It depends from the 
timezone (tz param) that I didn't specified and so R automatically uses 
my local time and considers also the daylight saving time (that comes at 
2:00 at my position).
As my dates are in solar time, I specified the time zone as "GMT" and it 
works!
Here a simple example:

df = data.frame(DateTime = c(
   '2016-12-21 10:34:54',
   '2016-12-21 11:04:54',
   '2016-12-21 11:34:54',
   '2016-03-27 02:05:50',
   '2016-03-27 02:35:50',
   '2016-12-21 12:04:54',
   '2016-12-21 12:34:54'
))


df$DateTime = as.POSIXlt(strptime(df$DateTime,
                                   format='%Y-%m-%d %H:%M:%S',
                                   tz='GMT'))

ord = order(as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S', 
tz='GMT')))

df.ord = df[ord,1]
df.ord


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Jan 26 20:22:47 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Jan 2017 11:22:47 -0800
Subject: [R] order list of date (bug?)
In-Reply-To: <b37ba77c-bd51-1cdc-60ef-0ac9d266023c@gmail.com>
References: <6f286496-383e-a849-903c-973778fae196@gmail.com>
	<CAF8bMcb=DgwRLS+=xZ5Oze2jCTAuwu2Y_pkEbbO4y7t6F6FF5w@mail.gmail.com>
	<CAF8bMcb=aNC1hW-UXzsT++e5J5-=OGycjWrpM2yCsGEJ2awd9A@mail.gmail.com>
	<b37ba77c-bd51-1cdc-60ef-0ac9d266023c@gmail.com>
Message-ID: <CAF8bMcbJvrdfZDq-cMW8a4-+zoRnYA1EbvN_z2yEgZ7C=AR=nA@mail.gmail.com>

The R bug I mentioned was not that
   as.POSIXlt("2016-03-27 02:30", format="%Y-%m-%d %H:%M", tz="CET")
returned an NA.  That seems reasonable since there was no such time.

The bug is that the POSIXlt object prints in an odd format (leaving
off the time zone/daylight/standard time string) instead of printing
an NA.  This made it hard for you to see the problem.

Using tz="GMT" or "UTC" will give 'solar' time England.
tz="Etc/GMT-1" will give 'solar' time in central Europe.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 26, 2017 at 10:46 AM, rob vech <rob.vech87 at gmail.com> wrote:
> Hi William,
> asking to the r-devel list I resolved the problem! It depends from the
> timezone (tz param) that I didn't specified and so R automatically uses my
> local time and considers also the daylight saving time (that comes at 2:00
> at my position).
> As my dates are in solar time, I specified the time zone as "GMT" and it
> works!
> Here a simple example:
>
> df = data.frame(DateTime = c(
>   '2016-12-21 10:34:54',
>   '2016-12-21 11:04:54',
>   '2016-12-21 11:34:54',
>   '2016-03-27 02:05:50',
>   '2016-03-27 02:35:50',
>   '2016-12-21 12:04:54',
>   '2016-12-21 12:34:54'
> ))
>
>
> df$DateTime = as.POSIXlt(strptime(df$DateTime,
>                                   format='%Y-%m-%d %H:%M:%S',
>                                   tz='GMT'))
>
> ord = order(as.numeric(strptime(df$DateTime, format='%Y-%m-%d %H:%M:%S',
> tz='GMT')))
>
> df.ord = df[ord,1]
> df.ord
>


From r.turner at auckland.ac.nz  Thu Jan 26 20:49:41 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 27 Jan 2017 08:49:41 +1300
Subject: [R] [FORGED]  Fitting arima Models with Exogenous Variables
In-Reply-To: <e59677cb-a472-75e5-145c-8e6b809687d5@auckland.ac.nz>
References: <CAMOcQfPK=1UZvFN5mS=Q6jH8T1qt1MMmNvoSQeh6MO9Rp9gcuA@mail.gmail.com>
	<ce0a0a41-0bb3-9c85-4ac0-50d3e570e2b2@auckland.ac.nz>
	<CAMOcQfMMyqURzc2aHGrkNGjy_a2++5-S=Wo-OgTQSGzEG+BL2Q@mail.gmail.com>
	<e59677cb-a472-75e5-145c-8e6b809687d5@auckland.ac.nz>
Message-ID: <501ddc45-4222-c91e-f0db-040d4e6852ea@auckland.ac.nz>


I am re-sending this since I have been told that the attachments that I 
made did not get through.  So I am trying again with *.dput attachments.

You will need to read them in using dget().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 24/01/17 10:35, Rolf Turner wrote:
>
> This should have been sent to the R-help mailing list, not to me
> personally.  I am not an expert on this sort of time series modelling
> and cannot thereby provide any useful advice.  My reply to you was of a
> "generic" nature --- when making an enquiry, provide a reproducible
> example!!!
>
> I am cc-ing this email to the R-help list, since someone on that list
> *may* be able to answer your question.  I have (re-) attached the data
> sets that you sent to me.
>
> cheers,
>
> Rolf Turner
>
> On 24/01/17 04:36, Paul Bernal wrote:
>> Hello Rolf,
>>
>> Thank you for your kind reply. I am attaching two datasets, one with the
>> historical data that I used to train the model, and the other one with
>> the exogenous variables.
>>
>> The R code that I used is as follows:
>>
>>> library(forecast)
>>> library(tseries)
>>> library(TSA)
>>> library(stats)
>>> library(stats4)
>>> TrainingDat<-read.csv("Training Data.csv")
>>>
>>> ExogVars<-read.csv("ExogenousVariables5.csv")
>>> #The file ExogVars contains 5 columns, one column for each regressor
>>> Model1<-auto.arima(TrainingDat[,5], xreg=ExogVars)
>>> #In Model1 I was able to incorporate xreg without any trouble
>>> #The problem comes when trying to incorporate newxreg
>>> Model2<-auto.arima(ExoVars[1:5])
>> Error in as.ts(x) : object 'ExoVars' not found
>>>
>>> Model2<-auto.arima(ExogVars[1:5])
>>
>> Error in auto.arima(ExogVars[1:5]) : No suitable ARIMA model found
>>>
>>> Model2<-auto.arima(ExogVars[,1])
>>>
>>> NewXReg<-forecast(Model2, h=12)
>>>
>>> Forec<-forecast(Model1, newxreg=NewXReg)
>> Error in forecast.Arima(Model1, newxreg = NewXReg) :
>>   No regressors provided
>> In addition: Warning message:
>> In forecast.Arima(Model1, newxreg = NewXReg) :
>>   The non-existent newxreg arguments will be ignored.
>>>
>>> Forec<-forecast(Model1, newxreg=NewXReg$mean)
>> Error in forecast.Arima(Model1, newxreg = NewXReg$mean) :
>>   No regressors provided
>> In addition: Warning message:
>> In forecast.Arima(Model1, newxreg = NewXReg$mean) :
>>   The non-existent newxreg arguments will be ignored.
>>
>> I would like to generate the forecasts for all 4 variables included in
>> the Training set, along with all 5 regressors, but it seems like I can
>> only chose one training variable at a time, and one regressor at a time.
>>
>> Please let me know if you can work this out,




-------------- next part --------------
structure(list(date = c("1994/Oct", "1994/Nov", "1994/Dec", "1995/Jan", 
"1995/Feb", "1995/Mar", "1995/Apr", "1995/May", "1995/Jun", "1995/Jul", 
"1995/Aug", "1995/Sep", "1995/Oct", "1995/Nov", "1995/Dec", "1996/Jan", 
"1996/Feb", "1996/Mar", "1996/Apr", "1996/May", "1996/Jun", "1996/Jul", 
"1996/Aug", "1996/Sep", "1996/Oct", "1996/Nov", "1996/Dec", "1997/Jan", 
"1997/Feb", "1997/Mar", "1997/Apr", "1997/May", "1997/Jun", "1997/Jul", 
"1997/Aug", "1997/Sep", "1997/Oct", "1997/Nov", "1997/Dec", "1998/Jan", 
"1998/Feb", "1998/Mar", "1998/Apr", "1998/May", "1998/Jun", "1998/Jul", 
"1998/Aug", "1998/Sep", "1998/Oct", "1998/Nov", "1998/Dec", "1999/Jan", 
"1999/Feb", "1999/Mar", "1999/Apr", "1999/May", "1999/Jun", "1999/Jul", 
"1999/Aug", "1999/Sep", "1999/Oct", "1999/Nov", "1999/Dec", "2000/Jan", 
"2000/Feb", "2000/Mar", "2000/Apr", "2000/May", "2000/Jun", "2000/Jul", 
"2000/Aug", "2000/Sep", "2000/Oct", "2000/Nov", "2000/Dec", "2001/Jan", 
"2001/Feb", "2001/Mar", "2001/Apr", "2001/May", "2001/Jun", "2001/Jul", 
"2001/Aug", "2001/Sep", "2001/Oct", "2001/Nov", "2001/Dec", "2002/Jan", 
"2002/Feb", "2002/Mar", "2002/Apr", "2002/May", "2002/Jun", "2002/Jul", 
"2002/Aug", "2002/Sep", "2002/Oct", "2002/Nov", "2002/Dec", "2003/Jan", 
"2003/Feb", "2003/Mar", "2003/Apr", "2003/May", "2003/Jun", "2003/Jul", 
"2003/Aug", "2003/Sep", "2003/Oct", "2003/Nov", "2003/Dec", "2004/Jan", 
"2004/Feb", "2004/Mar", "2004/Apr", "2004/May", "2004/Jun", "2004/Jul", 
"2004/Aug", "2004/Sep", "2004/Oct", "2004/Nov", "2004/Dec", "2005/Jan", 
"2005/Feb", "2005/Mar", "2005/Apr", "2005/May", "2005/Jun", "2005/Jul", 
"2005/Aug", "2005/Sep", "2005/Oct", "2005/Nov", "2005/Dec", "2006/Jan", 
"2006/Feb", "2006/Mar", "2006/Apr", "2006/May", "2006/Jun", "2006/Jul", 
"2006/Aug", "2006/Sep", "2006/Oct", "2006/Nov", "2006/Dec", "2007/Jan", 
"2007/Feb", "2007/Mar", "2007/Apr", "2007/May", "2007/Jun", "2007/Jul", 
"2007/Aug", "2007/Sep", "2007/Oct", "2007/Nov", "2007/Dec", "2008/Jan", 
"2008/Feb", "2008/Mar", "2008/Apr", "2008/May", "2008/Jun", "2008/Jul", 
"2008/Aug", "2008/Sep", "2008/Oct", "2008/Nov", "2008/Dec", "2009/Jan", 
"2009/Feb", "2009/Mar", "2009/Apr", "2009/May", "2009/Jun", "2009/Jul", 
"2009/Aug", "2009/Sep", "2009/Oct", "2009/Nov", "2009/Dec", "2010/Jan", 
"2010/Feb", "2010/Mar", "2010/Apr", "2010/May", "2010/Jun", "2010/Jul", 
"2010/Aug", "2010/Sep", "2010/Oct", "2010/Nov", "2010/Dec", "2011/Jan", 
"2011/Feb", "2011/Mar", "2011/Apr", "2011/May", "2011/Jun", "2011/Jul", 
"2011/Aug", "2011/Sep", "2011/Oct", "2011/Nov", "2011/Dec", "2012/Jan", 
"2012/Feb", "2012/Mar", "2012/Apr", "2012/May", "2012/Jun", "2012/Jul", 
"2012/Aug", "2012/Sep", "2012/Oct", "2012/Nov", "2012/Dec", "2013/Jan", 
"2013/Feb", "2013/Mar", "2013/Apr", "2013/May", "2013/Jun", "2013/Jul", 
"2013/Aug", "2013/Sep", "2013/Oct", "2013/Nov", "2013/Dec", "2014/Jan", 
"2014/Feb", "2014/Mar", "2014/Apr", "2014/May", "2014/Jun", "2014/Jul", 
"2014/Aug", "2014/Sep", "2014/Oct", "2014/Nov", "2014/Dec", "2015/Jan", 
"2015/Feb", "2015/Mar", "2015/Apr", "2015/May", "2015/Jun", "2015/Jul", 
"2015/Aug", "2015/Sep", "2015/Oct", "2015/Nov", "2015/Dec"), 
    Transits.Class.A = c(22L, 18L, 19L, 18L, 18L, 19L, 21L, 22L, 
    17L, 17L, 17L, 16L, 16L, 17L, 18L, 15L, 17L, 19L, 19L, 19L, 
    13L, 11L, 11L, 6L, 7L, 6L, 11L, 7L, 9L, 8L, 7L, 11L, 14L, 
    17L, 16L, 12L, 14L, 12L, 13L, 11L, 11L, 15L, 11L, 11L, 12L, 
    17L, 13L, 11L, 11L, 12L, 11L, 11L, 10L, 4L, 5L, 4L, 5L, 7L, 
    5L, 2L, 5L, 6L, 9L, 8L, 11L, 4L, 2L, 2L, 2L, 3L, 3L, 6L, 
    3L, 4L, 1L, 7L, 6L, 7L, 10L, 4L, 4L, 8L, 12L, 12L, 10L, 10L, 
    7L, 12L, 7L, 7L, 8L, 12L, 12L, 13L, 13L, 9L, 10L, 10L, 6L, 
    7L, 11L, 17L, 16L, 14L, 13L, 14L, 13L, 16L, 14L, 12L, 13L, 
    12L, 11L, 12L, 14L, 14L, 15L, 14L, 12L, 12L, 15L, 11L, 15L, 
    13L, 11L, 14L, 14L, 14L, 15L, 12L, 14L, 10L, 5L, 6L, 4L, 
    3L, 3L, 5L, 9L, 6L, 5L, 5L, 2L, 3L, 5L, 4L, 3L, 6L, 3L, 7L, 
    4L, 3L, 2L, 1L, 3L, 5L, 3L, 3L, 6L, 7L, 10L, 10L, 13L, 10L, 
    6L, 7L, 4L, 5L, 6L, 4L, 5L, 3L, 6L, 9L, 3L, 3L, 6L, 7L, 8L, 
    6L, 6L, 6L, 7L, 8L, 4L, 8L, 8L, 6L, 5L, 5L, 7L, 4L, 5L, 6L, 
    5L, 8L, 9L, 12L, 10L, 10L, 7L, 4L, 4L, 4L, 7L, 6L, 7L, 6L, 
    7L, 4L, 5L, 7L, 2L, 4L, 4L, 4L, 3L, 2L, 3L, 3L, 1L, 5L, 2L, 
    3L, 3L, 2L, 2L, 3L, 1L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 4L, 
    2L, 2L, 2L, 2L, 2L, 4L, 5L, 5L, 5L, 8L, 7L, 5L, 3L, 3L, 2L, 
    2L, 5L), Transits.Class.B = c(15L, 15L, 14L, 14L, 14L, 15L, 
    16L, 15L, 18L, 21L, 18L, 17L, 21L, 18L, 19L, 19L, 18L, 21L, 
    22L, 25L, 23L, 28L, 25L, 25L, 25L, 21L, 28L, 21L, 22L, 23L, 
    20L, 24L, 22L, 26L, 24L, 24L, 28L, 31L, 34L, 36L, 33L, 29L, 
    34L, 33L, 33L, 31L, 33L, 29L, 32L, 26L, 24L, 30L, 27L, 31L, 
    23L, 23L, 21L, 21L, 18L, 21L, 19L, 19L, 16L, 14L, 22L, 24L, 
    28L, 26L, 29L, 23L, 28L, 21L, 17L, 17L, 14L, 12L, 14L, 10L, 
    12L, 13L, 14L, 15L, 21L, 10L, 15L, 12L, 15L, 16L, 17L, 14L, 
    14L, 12L, 7L, 8L, 8L, 11L, 9L, 12L, 11L, 6L, 8L, 11L, 7L, 
    8L, 14L, 9L, 11L, 8L, 8L, 6L, 3L, 4L, 4L, 5L, 4L, 3L, 3L, 
    5L, 8L, 6L, 8L, 6L, 7L, 14L, 14L, 15L, 13L, 16L, 18L, 20L, 
    21L, 18L, 19L, 24L, 27L, 26L, 18L, 28L, 21L, 22L, 25L, 29L, 
    26L, 22L, 22L, 14L, 18L, 18L, 13L, 15L, 16L, 19L, 9L, 14L, 
    11L, 9L, 14L, 16L, 11L, 13L, 11L, 16L, 16L, 20L, 17L, 19L, 
    18L, 24L, 19L, 19L, 15L, 21L, 21L, 24L, 28L, 14L, 20L, 15L, 
    24L, 18L, 24L, 24L, 25L, 21L, 24L, 27L, 28L, 27L, 26L, 29L, 
    25L, 24L, 25L, 28L, 23L, 30L, 23L, 29L, 26L, 31L, 33L, 40L, 
    36L, 39L, 36L, 34L, 32L, 32L, 30L, 27L, 32L, 30L, 31L, 26L, 
    31L, 29L, 26L, 28L, 24L, 22L, 11L, 15L, 17L, 12L, 13L, 14L, 
    9L, 12L, 11L, 17L, 9L, 8L, 7L, 11L, 8L, 15L, 8L, 10L, 13L, 
    12L, 13L, 12L, 12L, 19L, 21L, 18L, 20L, 21L, 20L, 22L, 19L, 
    21L, 20L, 21L, 18L), Transits.Class.C = c(15L, 12L, 15L, 
    14L, 13L, 17L, 15L, 12L, 18L, 15L, 11L, 16L, 13L, 14L, 16L, 
    14L, 12L, 15L, 13L, 12L, 14L, 13L, 12L, 14L, 11L, 15L, 13L, 
    14L, 14L, 14L, 15L, 13L, 17L, 14L, 15L, 13L, 18L, 16L, 19L, 
    19L, 14L, 18L, 20L, 13L, 19L, 17L, 23L, 21L, 23L, 19L, 25L, 
    24L, 21L, 23L, 24L, 28L, 27L, 29L, 28L, 23L, 27L, 26L, 26L, 
    24L, 20L, 23L, 21L, 28L, 24L, 29L, 28L, 32L, 26L, 36L, 25L, 
    28L, 24L, 26L, 28L, 29L, 24L, 24L, 28L, 21L, 23L, 23L, 24L, 
    21L, 27L, 23L, 22L, 27L, 26L, 24L, 28L, 24L, 27L, 27L, 34L, 
    26L, 27L, 23L, 27L, 23L, 30L, 35L, 34L, 31L, 33L, 31L, 34L, 
    37L, 29L, 37L, 29L, 32L, 26L, 33L, 28L, 27L, 29L, 26L, 29L, 
    30L, 29L, 34L, 38L, 31L, 37L, 33L, 34L, 32L, 33L, 27L, 28L, 
    30L, 32L, 35L, 32L, 37L, 36L, 41L, 43L, 39L, 41L, 40L, 49L, 
    56L, 55L, 64L, 73L, 68L, 64L, 58L, 69L, 51L, 64L, 57L, 67L, 
    70L, 65L, 65L, 60L, 66L, 56L, 48L, 58L, 56L, 64L, 58L, 53L, 
    55L, 56L, 64L, 53L, 69L, 60L, 59L, 51L, 54L, 56L, 49L, 48L, 
    50L, 45L, 50L, 56L, 54L, 47L, 52L, 46L, 46L, 45L, 48L, 41L, 
    43L, 38L, 45L, 46L, 41L, 40L, 37L, 30L, 31L, 42L, 34L, 37L, 
    39L, 44L, 40L, 44L, 43L, 26L, 32L, 24L, 25L, 30L, 27L, 28L, 
    26L, 25L, 27L, 32L, 29L, 23L, 25L, 25L, 22L, 22L, 19L, 21L, 
    18L, 17L, 17L, 15L, 19L, 15L, 18L, 13L, 14L, 14L, 14L, 15L, 
    14L, 12L, 18L, 15L, 16L, 15L, 18L, 15L, 15L, 14L, 13L, 19L
    ), Transits.Class.D = c(58L, 55L, 53L, 60L, 54L, 60L, 62L, 
    63L, 60L, 67L, 59L, 62L, 64L, 62L, 65L, 67L, 61L, 65L, 64L, 
    64L, 68L, 65L, 73L, 66L, 71L, 65L, 69L, 67L, 61L, 71L, 63L, 
    71L, 67L, 66L, 71L, 68L, 67L, 69L, 66L, 72L, 62L, 70L, 69L, 
    79L, 80L, 87L, 86L, 85L, 89L, 81L, 81L, 81L, 65L, 75L, 71L, 
    82L, 80L, 86L, 81L, 80L, 83L, 78L, 87L, 88L, 79L, 87L, 79L, 
    96L, 95L, 98L, 102L, 93L, 108L, 97L, 98L, 102L, 93L, 101L, 
    96L, 106L, 98L, 104L, 107L, 105L, 109L, 107L, 107L, 117L, 
    106L, 112L, 122L, 117L, 134L, 143L, 141L, 141L, 138L, 136L, 
    151L, 152L, 129L, 146L, 137L, 150L, 147L, 160L, 161L, 157L, 
    165L, 162L, 171L, 151L, 152L, 154L, 158L, 168L, 167L, 160L, 
    176L, 161L, 172L, 163L, 168L, 175L, 166L, 179L, 176L, 200L, 
    182L, 195L, 200L, 191L, 207L, 204L, 207L, 215L, 183L, 202L, 
    201L, 211L, 210L, 225L, 232L, 237L, 250L, 236L, 238L, 228L, 
    198L, 217L, 209L, 228L, 207L, 238L, 222L, 239L, 227L, 222L, 
    211L, 204L, 195L, 189L, 198L, 217L, 197L, 222L, 227L, 222L, 
    219L, 206L, 213L, 211L, 178L, 187L, 195L, 200L, 198L, 186L, 
    188L, 181L, 180L, 164L, 162L, 158L, 135L, 164L, 145L, 180L, 
    179L, 190L, 199L, 195L, 207L, 182L, 201L, 189L, 181L, 186L, 
    189L, 205L, 186L, 202L, 196L, 196L, 197L, 197L, 188L, 191L, 
    172L, 198L, 202L, 208L, 216L, 239L, 233L, 225L, 228L, 204L, 
    210L, 218L, 197L, 204L, 210L, 218L, 210L, 215L, 219L, 216L, 
    219L, 194L, 201L, 206L, 190L, 214L, 207L, 225L, 211L, 220L, 
    214L, 224L, 222L, 202L, 211L, 217L, 188L, 226L, 205L, 218L, 
    219L, 241L, 244L, 226L, 238L, 214L, 218L)), .Names = c("date", 
"Transits.Class.A", "Transits.Class.B", "Transits.Class.C", "Transits.Class.D"
), class = "data.frame", row.names = c(NA, -255L))
-------------- next part --------------
structure(list(MGOFujairah = c(183.75, 185, 185, 185, 185, 185, 
185.25, 186.25, 188.5, 188.63, 184.13, 183.3, 182.5, 182.5, 193, 
205.25, 206.63, 211.9, 211.25, 214.5, 209.5, 205, 205.5, 220, 
231.5, 236.25, 247.5, 230.6, 220, 220, 220, 216.2, 210.5, 207.5, 
212.62, 212.74, 215, 214.75, 201.25, 175.3, 172.25, 172.63, 177.75, 
172.7, 165.25, 152, 146.75, 153.38, 147.8, 142.25, 132.5, 133.75, 
119.5, 129.13, 140.4, 142.75, 144, 153.2, 178.75, 190.75, 201, 
204.25, 201.9, 209.38, 226.25, 269.3, 254.38, 255, 253, 254.5, 
281.25, 323.6, 327.25, 305.63, 279.4, 274, 256, 252, 260, 258.75, 
254.7, 252.75, 251.7, 258.75, 242.75, 228.7, 215.38, 211.25, 
207, 206.3, 219.63, 222.1, 221.88, 223.75, 227, 245.25, 253.75, 
249, 244.38, 260.5, 302.5, 319.38, 298.75, 275.5, 255.63, 245.63, 
249, 249.63, 254.2, 259.38, 270.63, 307.1, 317.5, 311.38, 314.2, 
338.13, 335.63, 349.4, 390.63, 398.13, 434.5, 441.25, 431, 424.38, 
425, 470, 511.5, 505, 510.63, 517, 523.75, 552.8, 557.5, 546.25, 
534, 533.75, 541.25, 548.5, 624.38, 646.88, 646.9, 680.88, 692.63, 
672.5, 634.38, 613.75, 590, 581.88, 586, 592.5, 615, 618.75, 
633.9, 672.5, 698, 707.5, 717.5, 807.5, 812.94, 833.13, 843, 
923.75, 1010, 1204.5, 1274.38, 1353.25, 1296, 1105, 928.5, 778.13, 
680.63, 653.5, 543.75, 477.5, 503.13, 545.3, 614.38, 610, 644.38, 
626.88, 634, 646.88, 645, 658, 660.63, 668.13, 697.9, 720, 720, 
727, 731.88, 732, 739, 752.5, 791.4, 870, 959.63, 990, 1028.2, 
1036.25, 1035, 1065.6, 1078.75, 1061, 1047.5, 1050, 1043.1, 1060.5, 
1055.88, 1058.8, 1043.38, 1055, 1024, 1017.25, 1028, 1035, 1028.75, 
1026.5, 1016.88, 999.38, 1007.5, 1016.5, 1016.25, 1001.5, 995, 
991.88, 1002.5, 999.38, 1000.63, 1000.5, 991.25, 986.1, 981.25, 
981.25, 979.25, 978.5, 975.13, 972.13, 979.8, 991.25, 939.5, 
887.25, 873.25, 779.3, 775.75, 746.88, 730, 732.5, 744.38, 715, 
680, 634.38, 599.8, 612.75, 556.75), MGORotterdam = c(150.5, 
150, 141.8, 141, 140, 144, 156, 155.25, 153, 145, 148, 154.3, 
146.75, 149.5, 165.2, 168.38, 176.13, 189.3, 194.63, 169.2, 163.13, 
174.88, 182.6, 218.75, 234.6, 218.75, 217.5, 219.5, 186.25, 167.13, 
159.88, 169.2, 164.38, 162.88, 186.54, 163.5, 178, 176.75, 162, 
144.3, 139.5, 129.5, 132.63, 130.2, 118.25, 114.8, 104.25, 114.5, 
117.5, 106.63, 98.9, 100.38, 97.5, 110.63, 125.9, 122.88, 120.25, 
145.3, 165.13, 178.5, 183.8, 194.5, 209, 217, 225.38, 230.7, 
216.25, 224.5, 236.5, 244.25, 263.75, 315.9, 298, 297.5, 265.4, 
255, 230.5, 223, 227.5, 225, 227.7, 219.38, 223.3, 228.38, 203.13, 
182.3, 168.88, 170.13, 166.38, 191.5, 207.38, 207.3, 199.75, 
210.25, 220.7, 239.25, 241.88, 215.2, 248.88, 270.3, 309.5, 304.13, 
237.5, 226.9, 231.88, 234.63, 245, 233, 245, 262.38, 272.88, 
281.9, 263.38, 297.13, 299.9, 326.88, 321.63, 347.6, 381.75, 
391.13, 475, 445.75, 398, 391.63, 413.75, 493.13, 494.7, 448.75, 
508.88, 532, 567.5, 620.5, 593.38, 515.13, 502, 535.63, 521.88, 
549.5, 610.88, 611.25, 619, 630, 639.38, 575, 530.13, 524.75, 
535.5, 484.38, 506.88, 537.6, 574.25, 579.38, 602.1, 637.13, 
609.7, 673.63, 696.88, 814.5, 815, 810, 838.5, 961.88, 1023.13, 
1178.8, 1225, 1234.5, 1040.5, 927.5, 749.9, 577.88, 453.13, 450.3, 
404.5, 407.25, 452.75, 477.8, 575, 536.9, 613.75, 574.88, 609.5, 
635, 608.75, 640.44, 620, 668.75, 719.5, 665.38, 660, 648.5, 
661.25, 666.5, 728.8, 741.25, 772.4, 813.88, 898.75, 973.75, 
1016.5, 951.25, 955, 964.9, 946.13, 955, 936, 981.63, 941.2, 
968, 993.63, 1023, 1007.75, 961.25, 848.3, 891, 959.6, 975.63, 
980.63, 929.5, 925.63, 940, 990, 905.5, 851.25, 838.4, 861.25, 
897.5, 920.7, 926.75, 912.84, 893.7, 907.5, 891.5, 885, 866.38, 
874.25, 879.2, 880.75, 863.75, 847.5, 815.75, 743.5, 693.5, 558.25, 
479.5, 551.13, 537.5, 530.5, 580.3, 559.75, 494.1, 433, 442.75, 
424.5, 401.88, 319.88), X380CSTFujairah = c(85.5, 92.25, 88.4, 
96.25, 98.38, 102.3, 104.38, 103.63, 94.1, 83.13, 84, 83.9, 87.75, 
91.88, 105.8, 109.88, 99.38, 103.2, 107.75, 96.3, 88.13, 92.88, 
97.5, 111.88, 115.2, 116.13, 115, 105.8, 94, 96.5, 95.63, 96.4, 
97.38, 96.63, 117.55, 107.75, 110.1, 104.75, 89.75, 67.4, 59.38, 
70.63, 77.75, 75.9, 62.25, 62.4, 59.38, 76.88, 82.7, 73.5, 62.4, 
62, 55.13, 60.25, 74.7, 83.13, 83.63, 96, 115.13, 127.88, 138, 
143.25, 142.9, 135.88, 139.63, 170.4, 153.88, 165.13, 166.6, 
147.63, 147.25, 164.8, 177.13, 163.63, 131.5, 126.5, 126.63, 
129.9, 135.88, 146.38, 132, 127.25, 137.3, 149.13, 126.25, 106.1, 
112.5, 109.63, 119.38, 129.9, 144.25, 151.1, 149.13, 153, 160.7, 
172.25, 162.13, 144, 155.38, 176.8, 200.13, 176.63, 148.88, 159.3, 
162.88, 173.88, 166.8, 156.75, 159.4, 158.25, 156.25, 162.3, 
169.63, 163.13, 172.9, 187.75, 179.5, 179.6, 185.13, 178, 193.1, 
177.75, 171.8, 184.63, 196.88, 210.63, 247.6, 256.88, 257.75, 
264.9, 275, 312.6, 301.38, 293.25, 277.6, 297, 319.25, 330.4, 
345.75, 342.88, 323.8, 337, 326.5, 282.9, 282.5, 272, 270.6, 
264.25, 302, 314.8, 343.63, 344, 349.5, 379.25, 381.3, 404.38, 
428.75, 500.6, 472.5, 484.13, 476.6, 507.38, 531.38, 582.35, 
628.5, 715.25, 703.6, 595, 418.7, 242.63, 226.75, 254.6, 258.75, 
243.88, 284.13, 339.8, 406.75, 406.8, 454.38, 456.75, 441.5, 
466.75, 459.25, 481.8, 465.25, 472.25, 481.2, 460.38, 443.25, 
442.2, 453.5, 445.5, 473.1, 492.63, 507, 543.5, 631.5, 638.5, 
672.7, 651, 659, 674.5, 671.5, 661.9, 659.75, 690.5, 680.8, 725.75, 
731.88, 745.2, 729.13, 683.63, 604.4, 620.38, 668.2, 665.25, 
638.5, 604.8, 605, 619.5, 653.5, 637.4, 617.25, 608.8, 614.5, 
593.13, 605.8, 608.25, 616.75, 618.9, 607.75, 617.4, 605.5, 601.75, 
596, 596.5, 608.63, 602.75, 602.5, 590.63, 505.9, 454.88, 358.75, 
295.3, 354.75, 335.63, 337.88, 379.8, 348.63, 311.8, 250.25, 
238.88, 245.7, 226.25, 178.75), X380CSTRotterdam = c(89.13, 102.88, 
96.1, 108.5, 103.38, 106.2, 105.19, 107.88, 93.6, 81.38, 83.25, 
87.5, 85.88, 85.5, 102.8, 103.63, 95.5, 106.6, 115.38, 99.6, 
88.63, 88.13, 97.4, 114.5, 122.5, 116.5, 120.38, 110.2, 96.38, 
89.75, 86.13, 84.6, 86.63, 89.38, 108.69, 97.5, 104.6, 107.5, 
88.69, 73.5, 69, 67.25, 79.75, 73.2, 67.38, 66.7, 62.63, 66.25, 
69.5, 60.5, 55.8, 64.5, 57.75, 61.88, 72.8, 71.88, 80.75, 95.7, 
112.88, 117.75, 127.7, 130, 127.3, 127.5, 133.88, 147.3, 125.5, 
126.5, 144.3, 132.88, 132.5, 154.5, 159.88, 149.75, 126.7, 117.9, 
121.5, 119.8, 116.75, 122, 121.6, 118, 125.4, 130.13, 110.63, 
101.9, 103.75, 104.5, 103.25, 120.5, 136.13, 140.8, 135, 142.75, 
145.9, 161.38, 154, 125.7, 134.38, 173.5, 175.13, 148.25, 126.38, 
137.9, 147.5, 170.5, 159.7, 147.75, 151.9, 154.75, 141, 141.4, 
139, 144.5, 152.6, 170.63, 159.5, 162.9, 167, 161.75, 173.9, 
146.5, 143.5, 157.5, 171.25, 203, 231.9, 230.13, 232.25, 248.9, 
261.75, 288.4, 270.5, 256.38, 255.8, 282.88, 294.75, 300.3, 320.13, 
324.63, 301.4, 316.5, 311, 280.5, 266.13, 262.38, 255.9, 229.13, 
251.5, 272.7, 312, 325.88, 325.9, 359.88, 353.7, 374, 412.5, 
476.1, 447.5, 447.75, 436.9, 477.38, 494.88, 542.9, 593.76, 679.5, 
635.6, 544.13, 398, 217.63, 194.5, 225.7, 239.13, 244.5, 276.25, 
327.5, 384.25, 382.8, 429.38, 412.38, 423.1, 462, 438.75, 457.2, 
445.5, 453.25, 467, 437.38, 424.38, 423.7, 439.63, 431.5, 458.6, 
476, 488.6, 514.75, 575.25, 606.38, 641.6, 621.75, 631.25, 647.5, 
634.38, 640.5, 633, 645.13, 623.8, 682.38, 694.63, 712.6, 697, 
651.5, 572.4, 597.13, 640.5, 640, 616.75, 588, 582.75, 608.75, 
634.5, 605.6, 584, 580.2, 580, 596.75, 601.6, 597.5, 588.5, 575.9, 
584.25, 570.4, 580, 574.5, 578.75, 576.4, 590.25, 575, 563.4, 
547.5, 481.6, 420, 327.88, 250.1, 304.63, 301.88, 307.25, 343.7, 
328.5, 292.7, 233.75, 226.63, 222.5, 201, 157.13), X380CSTHouston = c(91, 
94.25, 89.2, 90, 96.75, 97.05, 100.19, 106.75, 101.5, 85.5, 83.5, 
84.7, 86.5, 86.75, 99.2, 99.75, 99.13, 102.7, 107.38, 101.4, 
96.75, 93.5, 96.1, 111.38, 130.3, 119.75, 112, 106.3, 90.5, 90.75, 
93.38, 96.4, 94.88, 95.38, 107.55, 99.63, 109, 108.63, 86.88, 
74.4, 72.75, 59, 78.13, 72.1, 67.88, 68.4, 62.63, 65.13, 68.9, 
63.38, 53.3, 56.13, 52, 63, 82.2, 81, 81.88, 92.2, 114.5, 119.13, 
125.5, 126.5, 125.8, 128, 135.63, 141.1, 123.75, 132, 145.6, 
133.25, 128.88, 148.5, 152.88, 142, 120.1, 116.4, 129.5, 120.9, 
104.13, 114.38, 111.1, 113.5, 117, 128.75, 105.75, 93.8, 98.38, 
99.5, 97.75, 117.9, 139.25, 142, 139, 141.75, 148.6, 158.88, 
153, 128.4, 142.5, 195, 186.25, 160.25, 134.88, 139.9, 152, 167.75, 
172.1, 149.13, 157.7, 158, 150, 148.9, 153.5, 151.13, 160.1, 
181.13, 167.5, 164.5, 170.38, 171.13, 213.3, 152.88, 173.4, 182.63, 
177, 200.25, 247, 255.13, 253.63, 253.5, 264.63, 305.3, 294.63, 
269.13, 276.4, 300, 310.25, 309.4, 330.68, 334.13, 309.4, 326.13, 
331.38, 284.9, 269, 263.38, 267.5, 247.75, 267.25, 272.7, 305.75, 
334.75, 348.3, 359.88, 366.4, 376.38, 403.25, 482, 457, 458.5, 
454.6, 486.13, 498.13, 568.4, 629.5, 721.25, 661.5, 592, 420.5, 
242, 229.5, 256.9, 265.13, 247.38, 275.88, 328.4, 389, 388, 422.38, 
416.25, 425.2, 466.5, 447.75, 458.5, 450.13, 449.75, 464, 439.25, 
424.75, 427.1, 432.88, 433.38, 456.1, 468.25, 487.9, 511.38, 
572.75, 629.75, 656.3, 633.88, 651.75, 653.4, 631.25, 635.1, 
647.25, 657.25, 628.1, 669, 700.25, 722.1, 709.38, 661.5, 577.9, 
587, 644.3, 647.5, 625, 603.9, 611.13, 624.25, 645.63, 612, 591, 
584.2, 581.63, 584.75, 597.9, 620.75, 600.38, 589.5, 600, 591.7, 
598, 592.25, 591.75, 598.5, 601, 584.13, 574.1, 558.13, 492.7, 
424.25, 340, 277.4, 326.88, 312.38, 315.63, 345.82, 338.5, 296.1, 
235, 224.88, 221.1, 205.63, 152.75), ContainerTCRIndex = c(101L, 
103L, 102L, 104L, 105L, 103L, 106L, 106L, 110L, 109L, 110L, 111L, 
114L, 107L, 109L, 109L, 110L, 110L, 110L, 110L, 110L, 109L, 108L, 
104L, 103L, 101L, 100L, 97L, 98L, 96L, 91L, 89L, 89L, 89L, 86L, 
85L, 84L, 83L, 84L, 83L, 81L, 80L, 80L, 78L, 75L, 72L, 69L, 66L, 
65L, 65L, 63L, 58L, 58L, 59L, 61L, 61L, 64L, 67L, 72L, 74L, 74L, 
71L, 68L, 71L, 78L, 81L, 86L, 90L, 91L, 91L, 90L, 90L, 90L, 85L, 
83L, 81L, 82L, 83L, 82L, 79L, 76L, 72L, 66L, 59L, 55L, 49L, 47L, 
48L, 49L, 51L, 56L, 57L, 57L, 59L, 64L, 62L, 63L, 62L, 59L, 62L, 
71L, 75L, 79L, 85L, 88L, 93L, 95L, 97L, 95L, 95L, 94L, 104L, 
113L, 120L, 124L, 126L, 128L, 131L, 136L, 142L, 146L, 154L, 163L, 
169L, 171L, 172L, 172L, 170L, 164L, 159L, 150L, 142L, 124L, 114L, 
116L, 111L, 107L, 107L, 111L, 113L, 112L, 112L, 108L, 105L, 99L, 
94L, 91L, 96L, 100L, 102L, 103L, 105L, 107L, 109L, 112L, 116L, 
116L, 114L, 114L, 113L, 113L, 113L, 111L, 108L, 101L, 97L, 92L, 
87L, 65L, 58L, 47L, 45L, 40L, 37L, 35L, 35L, 34L, 34L, 34L, 33L, 
33L, 32L, 32L, 32L, 34L, 36L, 41L, 47L, 58L, 61L, 64L, 64L, 61L, 
57L, 59L, 66L, 71L, 76L, 75L, 75L, 73L, 65L, 61L, 55L, 48L, 46L, 
42L, 40L, 41L, 42L, 43L, 45L, 45L, 44L, 44L, 44L, 43L, 42L, 42L, 
42L, 43L, 43L, 45L, 46L, 47L, 47L, 48L, 47L, 48L, 47L, 47L, 47L, 
47L, 47L, 47L, 47L, 47L, 47L, 47L, 47L, 47L, 47L, 47L, 48L, 50L, 
52L, 59L, 63L, 62L, 60L, 55L, 51L, 46L, 45L, 43L), USAInterestRates = c(0.08, 
0.08, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 
0.09, 0.09, 0.09, 0.09, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 
0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.09, 0.09, 0.09, 0.09, 
0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 
0.09, 0.09, 0.09, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 
0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.09, 0.09, 0.09, 0.09, 0.09, 
0.09, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.09, 0.09, 0.08, 0.08, 
0.07, 0.07, 0.07, 0.07, 0.06, 0.06, 0.05, 0.05, 0.05, 0.05, 0.05, 
0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04, 
0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 
0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.05, 0.05, 0.05, 0.05, 
0.05, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.07, 0.07, 0.07, 
0.07, 0.07, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 
0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 
0.08, 0.08, 0.07, 0.07, 0.06, 0.06, 0.05, 0.05, 0.05, 0.05, 0.05, 
0.05, 0.05, 0.04, 0.04, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 
0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03
)), .Names = c("MGOFujairah", "MGORotterdam", "X380CSTFujairah", 
"X380CSTRotterdam", "X380CSTHouston", "ContainerTCRIndex", "USAInterestRates"
), class = "data.frame", row.names = c(NA, -255L))

From dwinsemius at comcast.net  Thu Jan 26 21:26:57 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 26 Jan 2017 12:26:57 -0800
Subject: [R] separate mixture of gamma and normal (with mixtools or ??)
In-Reply-To: <1c3441cc-4554-5e40-8457-1974df70bd2e@simecol.de>
References: <21f59d8e-b88a-20c5-65a5-75148f3b436b@simecol.de>
	<CAGxFJbSQnrH8_gqRwkZ4tyWc76+c8e+A8tqPYrDab1BZwn8MxQ@mail.gmail.com>
	<1c3441cc-4554-5e40-8457-1974df70bd2e@simecol.de>
Message-ID: <DE0E172F-45A1-4DE0-BB12-32D41E2F578C@comcast.net>


> On Jan 23, 2017, at 11:47 PM, Thomas Petzoldt <thpe at simecol.de> wrote:
> 
> Dear Bert,
> 
> thank you very much for your suggestion. You are right, ill-conditioning was sometimes a problem for 3 components, but not in the two-component case. The modes are well separated, and the sample size is high.
> 
> My main problem is (1) the shape of the distributions and (2) the diversity of available packages and approaches to this topic.
> 
> In the mean time I made some progress in this matter by treating the data as a mixture of gamma distributions (package mixdist, see below), so what I want to know is the purely R technical question ;-)
> 
> Has someone else has ever stumbled across something like this and can make a suggestion which package to use?

In survival analysis of cancer cases, the question of cure comes up often. Physicians sometimes have a naive notion of survival to 5 years after definitive treatment with no evident recurrence being equivalent to 'cure', despite the fact that there is great heterogeneity in the recurrence and survival distribution of different cancer types. I have see papers in the medical statistical literature that used mixtures of Weibull variates to model this problem. The cancer-specific survival is often exponential (mu=1) or "sub-exponential" (shape < 1) whereas non-cancer survival times are "super-exponential" (shape >> 1). When I ran your second simulation with dist='weibull' I get:

> library("mixdist")
> set.seed(123)
> lambda <- c(0.25, 0.75)
> N <- 2000
> x <- c(rexp(lambda[1]*N, 1), rnorm(lambda[2]*N, 20, 4))
> xx <- mixgroup(x, breaks=0:40)
> pp <- mixparam(mu=c(.5, 8), sigma=c(1, 10), pi=c(0.2, 0.5))
> mix <-  mix(xx, pp, dist="weibull", emsteps=10)
> 
> summary(mix)

Parameters:
      pi     mu  sigma
1 0.2492  1.016 0.8702
2 0.7508 20.079 4.2328

Standard Errors:
     pi.se   mu.se sigma.se
1 0.009683 0.04249  0.05137
2 0.009683 0.10972  0.06802


Analysis of Variance Table

          Df  Chisq Pr(>Chisq)    
Residuals 29 80.407   1.01e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


> p <- coef(mix)
> p
         pi        mu     sigma
1 0.2492477  1.016319 0.8702055
2 0.7507523 20.079093 4.2327769

So the exponential parameter at least is well-estimated. I believe that Weibull variates with  shape >> 1 are approximately normal, but I know that your mathematical sophistication exceeds mine by quite a bit, so consider this only a dilettante's comment.

-- 
David.


> 
> Thanks, Thomas
> 
> 
> ## Approximate an Exponential+Gaussian mixture with
> ##   a mixture of Gammas
> 
> library("mixdist")
> set.seed(123)
> lambda <- c(0.25, 0.75)
> N <- 2000
> x <- c(rexp(lambda[1]*N, 1), rnorm(lambda[2]*N, 20, 4))
> 
> xx <- mixgroup(x, breaks=0:40)
> pp <- mixparam(mu=c(1, 8), sigma=c(1, 3), pi=c(0.2, 0.5))
> mix <-  mix(xx, pp, dist="gamma", emsteps=10)
> 
> summary(mix)
> p <- coef(mix)
> beta <- with(p, sigma^2/mu)
> alpha <- with(p, mu /beta)
> lambda <- p$pi
> 
> plot(mix, xlim=c(0, 35))
> x1 <- seq(0, 35, 0.1)
> lines(x1, lambda[1]*dgamma(x1, alpha[1], 1/beta[1]),
>  col="orange", lwd=2)
> lines(x1, lambda[2]*dgamma(x1, alpha[2], 1/beta[2]),
>  col="magenta", lwd=2)
> 
> 
> 
> Am 24.01.2017 um 00:34 schrieb Bert Gunter:
>> Fitting multicomponent mixtures distributions -- and 3 is already a
>> lot of components -- is inherently ill-conditioned. You may need to
>> reassess your strategy. You might wish to post on stackexchange
>> instead to discuss such statistical issues.
>> 
>> Cheers,
>> Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Mon, Jan 23, 2017 at 2:32 PM, Thomas Petzoldt <thpe at simecol.de> wrote:
>>> Dear friends,
>>> 
>>> I am trying to separate bi- (and sometimes tri-) modal univariate mixtures
>>> of biological data, where the first component is left bounded (e.g.
>>> exponential or gamma) and the other(s) approximately Gaussian.
>>> 
>>> After checking several packages, I'm not really clear what to do. Here is an
>>> example with "mixtools" that already works quite good, however, the left
>>> component is not Gaussian (and not symmetric).
>>> 
>>> Any idea about a more adequate function or package for this problem?
>>> 
>>> Thanks a lot!
>>> 
>>> Thomas
>>> 
>>> 
>>> 
>>> library(mixtools)
>>> set.seed(123)
>>> 
>>> lambda <- c(0.25, 0.75)
>>> N      <- 200
>>> 
>>> ## dist1 ~ gamma (or exponential as a special case)
>>> #dist1 <- rexp(lambda[1]*N, 1)
>>> dist1 <- rgamma(lambda[1]*N, 1, 1)
>>> 
>>> ## dist2 ~ normal
>>> dist2 <- rnorm(lambda[2]*N, 12, 2)
>>> 
>>> ## mixture
>>> x <- c(dist1, dist2)
>>> 
>>> mix <-  spEMsymloc(x, mu0=2, eps=1e-3, verbose=TRUE)
>>> plot(mix, xlim=c(0, 25))
>>> summary(mix)
>>> 
>>> 
>>> --
>>> Thomas Petzoldt
>>> TU Dresden, Institute of Hydrobiology
>>> http://www.tu-dresden.de/Members/thomas.petzoldt
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu Jan 26 21:30:19 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 26 Jan 2017 12:30:19 -0800
Subject: [R] order list of date (bug?)
In-Reply-To: <CAF8bMcbJvrdfZDq-cMW8a4-+zoRnYA1EbvN_z2yEgZ7C=AR=nA@mail.gmail.com>
References: <6f286496-383e-a849-903c-973778fae196@gmail.com>
	<CAF8bMcb=DgwRLS+=xZ5Oze2jCTAuwu2Y_pkEbbO4y7t6F6FF5w@mail.gmail.com>
	<CAF8bMcb=aNC1hW-UXzsT++e5J5-=OGycjWrpM2yCsGEJ2awd9A@mail.gmail.com>
	<b37ba77c-bd51-1cdc-60ef-0ac9d266023c@gmail.com>
	<CAF8bMcbJvrdfZDq-cMW8a4-+zoRnYA1EbvN_z2yEgZ7C=AR=nA@mail.gmail.com>
Message-ID: <CA4D7664-AC65-4AA4-9345-528E2011A3A3@dcn.davis.ca.us>

The Etc timezones are nice and simple, but I am grateful for the other ones since they help make handling local time conventions used by other people tolerable. 

In the TL;DR department,  Local Standard Time is accessible using Olson "Etc/GMT.*" time zone strings,  but that is not the same thing as "solar" time, for which noon occurs when the sun is highest in the sky. As the earth follows an elliptical orbit it speeds up and slows down throughout the year so solar noon shifts back and forth relative to local standard time. 
-- 
Sent from my phone. Please excuse my brevity.

On January 26, 2017 11:22:47 AM PST, William Dunlap via R-help <r-help at r-project.org> wrote:
>The R bug I mentioned was not that
>   as.POSIXlt("2016-03-27 02:30", format="%Y-%m-%d %H:%M", tz="CET")
>returned an NA.  That seems reasonable since there was no such time.
>
>The bug is that the POSIXlt object prints in an odd format (leaving
>off the time zone/daylight/standard time string) instead of printing
>an NA.  This made it hard for you to see the problem.
>
>Using tz="GMT" or "UTC" will give 'solar' time England.
>tz="Etc/GMT-1" will give 'solar' time in central Europe.
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Thu, Jan 26, 2017 at 10:46 AM, rob vech <rob.vech87 at gmail.com>
>wrote:
>> Hi William,
>> asking to the r-devel list I resolved the problem! It depends from
>the
>> timezone (tz param) that I didn't specified and so R automatically
>uses my
>> local time and considers also the daylight saving time (that comes at
>2:00
>> at my position).
>> As my dates are in solar time, I specified the time zone as "GMT" and
>it
>> works!
>> Here a simple example:
>>
>> df = data.frame(DateTime = c(
>>   '2016-12-21 10:34:54',
>>   '2016-12-21 11:04:54',
>>   '2016-12-21 11:34:54',
>>   '2016-03-27 02:05:50',
>>   '2016-03-27 02:35:50',
>>   '2016-12-21 12:04:54',
>>   '2016-12-21 12:34:54'
>> ))
>>
>>
>> df$DateTime = as.POSIXlt(strptime(df$DateTime,
>>                                   format='%Y-%m-%d %H:%M:%S',
>>                                   tz='GMT'))
>>
>> ord = order(as.numeric(strptime(df$DateTime, format='%Y-%m-%d
>%H:%M:%S',
>> tz='GMT')))
>>
>> df.ord = df[ord,1]
>> df.ord
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From george.trojan at noaa.gov  Thu Jan 26 21:51:26 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Thu, 26 Jan 2017 20:51:26 +0000
Subject: [R] R2Cube integration errors
Message-ID: <CABie7_pWPTZp7ar0nJ1CgBS-bqM5Pz3gK0g68FJ7ks4svdkitg@mail.gmail.com>

Why this happens?

> library("R2Cuba")
> f <- function(x) 0
> cuhre(ndim=1, ncomp=1, f)
Iteration 1:  11 integrand evaluations so far
[1] 0 +- 0      chisq 0 (0 df)
Iteration 2:  33 integrand evaluations so far
[1] 0 +- 0      chisq 0 (1 df)
integral: 0 (+-0)
nregions: 2; number of evaluations:  33; probability:  0
> vegas(ndim=1, ncomp=1, f)
Iteration 1:  1000 integrand evaluations so far
[1] 0 +- 7.02518e-18    chisq 0 (0 df)
. . .
Iteration 13:  52000 integrand evaluations so far
[1] 0 +- 2.65413e-18    chisq 0 (12 df)
integral: 0 (+-2.7e-18)
number of evaluations:  52000; probability:  0
failed with message  ?Dimension out of range?
> suave(ndim=1, ncomp=1, f)
. . .
[1] 0 +- 7.02462e-17    chisq 0 (411 df)
integral: 0 (+-7e-17)
nregions: 50; number of evaluations:  50000; probability:  0
failed with message  ?Dimension out of range?

Is this a bug?

George

	[[alternative HTML version deleted]]


From Zhao.Liu at fmglobal.com  Thu Jan 26 20:41:32 2017
From: Zhao.Liu at fmglobal.com (Liu, Zhao)
Date: Thu, 26 Jan 2017 19:41:32 +0000
Subject: [R] proportional odds logistic regression with non-negative
 constraint for several coefficients
Message-ID: <CY1PR0401MB17879350EBD1E12EA3692B3FF7770@CY1PR0401MB1787.namprd04.prod.outlook.com>

Hi,

I am  working on proportional odds logistic regression, and trying to figure out how to specify the constraint for several predictors.  Those non-negative constraints for some predictors are for practical purpose.

I have seen some one posted passing box constraint with L-BFGS-B with logistic regression.

What I did not is to use polr() to solve the proportional odds, and modify the source code for polr() by passing the lower bounds to the optim() and change the method to L-BFGS-B.

Then I realized that polr() generate a start value for all coefficients with glm.fit, which can still start from negative.

So my question is that does the start value having negative while the optimization has a lower bound as 0.00001. Does it matter?

Or is there another way of implementation to solve proportional odds while forcing some coefficients  as non-negative.

Thanks so much!

Zhao

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jan 26 23:45:31 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 26 Jan 2017 14:45:31 -0800
Subject: [R] R2Cube integration errors
In-Reply-To: <CABie7_pWPTZp7ar0nJ1CgBS-bqM5Pz3gK0g68FJ7ks4svdkitg@mail.gmail.com>
References: <CABie7_pWPTZp7ar0nJ1CgBS-bqM5Pz3gK0g68FJ7ks4svdkitg@mail.gmail.com>
Message-ID: <6AC9D0CB-DE0A-44DF-A55C-9893C3EE6A09@comcast.net>


> On Jan 26, 2017, at 12:51 PM, George Trojan - NOAA Federal <george.trojan at noaa.gov> wrote:
> 
> Why this happens?
> 
>> library("R2Cuba")
>> f <- function(x) 0
>> cuhre(ndim=1, ncomp=1, f)
> Iteration 1:  11 integrand evaluations so far
> [1] 0 +- 0      chisq 0 (0 df)
> Iteration 2:  33 integrand evaluations so far
> [1] 0 +- 0      chisq 0 (1 df)
> integral: 0 (+-0)
> nregions: 2; number of evaluations:  33; probability:  0
>> vegas(ndim=1, ncomp=1, f)
> Iteration 1:  1000 integrand evaluations so far
> [1] 0 +- 7.02518e-18    chisq 0 (0 df)
> . . .
> Iteration 13:  52000 integrand evaluations so far
> [1] 0 +- 2.65413e-18    chisq 0 (12 df)
> integral: 0 (+-2.7e-18)
> number of evaluations:  52000; probability:  0
> failed with message  ?Dimension out of range?
>> suave(ndim=1, ncomp=1, f)
> . . .
> [1] 0 +- 7.02462e-17    chisq 0 (411 df)
> integral: 0 (+-7e-17)
> nregions: 50; number of evaluations:  50000; probability:  0
> failed with message  ?Dimension out of range?
> 
> Is this a bug?

If you look at the code you will see that the delivered message does not actually match what the documentation says should be delivered when 'ifail' is (positive) 1. Appears the package maintainer has not put in code to warn of failure to reach "the accuracy goal was not met within the allowed maximum number of integrand evaluations." That message is only supposed to be delivered when 'ifail' is -1.

> maintainer("R2Cuba")
[1] "Annie Bouvier <Annie.Bouvier at jouy.inra.fr>"



> 
> George
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jeff.hughes at gmail.com  Fri Jan 27 00:10:21 2017
From: jeff.hughes at gmail.com (Jeff Hughes)
Date: Thu, 26 Jan 2017 18:10:21 -0500
Subject: [R] Error with "compiler" and "caret" packages
In-Reply-To: <CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>
References: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
	<CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>
Message-ID: <CAKV=rG-bLDHWZ-DtUSgPjmSM-+uxMGJOGeCtyqdMw_Wst1L3Ag@mail.gmail.com>

That sounds like a good thing to check, but what permissions should I be
checking? I'm not very familiar with how the compiler works -- is it
creating temp files somewhere that I should check? If you have a suggestion
for a directory or two that seem like good candidates, I can play around
with the permissions, but I don't really want to start messing around with
my entire C: drive or whatever.

Thanks,
Jeff


On Thu, Jan 26, 2017 at 1:25 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Check your permissions? They may be denying your process access.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Jan 25, 2017 at 3:23 PM, Jeff Hughes <jeff.hughes at gmail.com>
> wrote:
> > Hi there,
> >
> > I have been getting an irritating error when trying to use the "caret"
> > package on one of my machines. Whenever I train any model whatsoever, it
> > comes back with this error:
> >
> > Warning: namespace ?compiler? is not available and has been replaced
> > by .GlobalEnv when processing object ?sep?
> > Error in comp(expr, env = envir, options = list(suppressUndefined =
> TRUE))
> > :
> >   could not find function "makeCenv"
> >
> > As a result, the model does not work, and I am unable to use the caret
> > package. As an example, here is some code that causes the error, though
> it
> > has happened in every case I have tried:
> >
> > library(caret)
> > fit.knn <- train(Species ~ ., data=iris, method="knn")
> >
> > I have tried reinstalling the caret package; I have tried reinstalling
> R; I
> > have tried updating all of my packages; nothing has worked. What's more,
> > this machine is running Windows 10, and I have successfully run the same
> > code on two other machines running the same version of Windows, the same
> > version of R, and the same version of the caret package. I have also only
> > run into it when using caret, but I don't think the error lies within
> that
> > package itself.
> >
> > Here is my sessionInfo() after running the above code in a new R session:
> >
> > R version 3.3.2 (2016-10-31)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows >= 8 x64 (build 9200)
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> > States.1252    LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C                           LC_TIME=English_United
> > States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34
> >
> > loaded via a namespace (and not attached):
> >  [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2      MASS_7.3-45
> >      munsell_0.4.3      colorspace_1.3-2
> >  [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0      car_2.1-4
> >      plyr_1.8.4         tools_3.3.2
> > [13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6     grid_3.3.2
> >       gtable_0.2.0       nlme_3.1-128
> > [19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7
> class_7.3-14
> >       MatrixModels_0.4-1 iterators_1.0.8
> > [25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1     tibble_1.2
> >       Matrix_1.2-7.1     nloptr_1.0.4
> > [31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15
>  stringi_1.1.2
> >      scales_0.4.1       stats4_3.3.2
> > [37] SparseM_1.74
> >
> > Note that the "compiler" package is not loaded for some reason, which I
> > think it should be (the other machines on which this runs successfully
> have
> > it loaded). But the compiler package is built-in, so I can't seem to
> find a
> > way to load it manually.
> >
> > This one has really stumped me, and there are very few relevant hits on
> > Google. Any help would be much appreciated!
> >
> > Jeff
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jan 27 01:11:54 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 26 Jan 2017 16:11:54 -0800
Subject: [R] Error with "compiler" and "caret" packages
In-Reply-To: <CAKV=rG-bLDHWZ-DtUSgPjmSM-+uxMGJOGeCtyqdMw_Wst1L3Ag@mail.gmail.com>
References: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
	<CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>
	<CAKV=rG-bLDHWZ-DtUSgPjmSM-+uxMGJOGeCtyqdMw_Wst1L3Ag@mail.gmail.com>
Message-ID: <CAGxFJbS0zjhsQZMPhb3pbgW0fose32+KAy7yjEALvFhGKgo_Gw@mail.gmail.com>

Perfectly reasonable questions: I don't have a clue. Perhaps someone
runnig Windows can answer.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 26, 2017 at 3:10 PM, Jeff Hughes <jeff.hughes at gmail.com> wrote:
> That sounds like a good thing to check, but what permissions should I be
> checking? I'm not very familiar with how the compiler works -- is it
> creating temp files somewhere that I should check? If you have a suggestion
> for a directory or two that seem like good candidates, I can play around
> with the permissions, but I don't really want to start messing around with
> my entire C: drive or whatever.
>
> Thanks,
> Jeff
>
>
> On Thu, Jan 26, 2017 at 1:25 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Check your permissions? They may be denying your process access.
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Jan 25, 2017 at 3:23 PM, Jeff Hughes <jeff.hughes at gmail.com>
>> wrote:
>> > Hi there,
>> >
>> > I have been getting an irritating error when trying to use the "caret"
>> > package on one of my machines. Whenever I train any model whatsoever, it
>> > comes back with this error:
>> >
>> > Warning: namespace ?compiler? is not available and has been replaced
>> > by .GlobalEnv when processing object ?sep?
>> > Error in comp(expr, env = envir, options = list(suppressUndefined =
>> > TRUE))
>> > :
>> >   could not find function "makeCenv"
>> >
>> > As a result, the model does not work, and I am unable to use the caret
>> > package. As an example, here is some code that causes the error, though
>> > it
>> > has happened in every case I have tried:
>> >
>> > library(caret)
>> > fit.knn <- train(Species ~ ., data=iris, method="knn")
>> >
>> > I have tried reinstalling the caret package; I have tried reinstalling
>> > R; I
>> > have tried updating all of my packages; nothing has worked. What's more,
>> > this machine is running Windows 10, and I have successfully run the same
>> > code on two other machines running the same version of Windows, the same
>> > version of R, and the same version of the caret package. I have also
>> > only
>> > run into it when using caret, but I don't think the error lies within
>> > that
>> > package itself.
>> >
>> > Here is my sessionInfo() after running the above code in a new R
>> > session:
>> >
>> > R version 3.3.2 (2016-10-31)
>> > Platform: x86_64-w64-mingw32/x64 (64-bit)
>> > Running under: Windows >= 8 x64 (build 9200)
>> >
>> > locale:
>> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> > States.1252    LC_MONETARY=English_United States.1252
>> > [4] LC_NUMERIC=C                           LC_TIME=English_United
>> > States.1252
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> > other attached packages:
>> > [1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34
>> >
>> > loaded via a namespace (and not attached):
>> >  [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2
>> > MASS_7.3-45
>> >      munsell_0.4.3      colorspace_1.3-2
>> >  [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0      car_2.1-4
>> >      plyr_1.8.4         tools_3.3.2
>> > [13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6     grid_3.3.2
>> >       gtable_0.2.0       nlme_3.1-128
>> > [19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7
>> > class_7.3-14
>> >       MatrixModels_0.4-1 iterators_1.0.8
>> > [25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1     tibble_1.2
>> >       Matrix_1.2-7.1     nloptr_1.0.4
>> > [31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15
>> > stringi_1.1.2
>> >      scales_0.4.1       stats4_3.3.2
>> > [37] SparseM_1.74
>> >
>> > Note that the "compiler" package is not loaded for some reason, which I
>> > think it should be (the other machines on which this runs successfully
>> > have
>> > it loaded). But the compiler package is built-in, so I can't seem to
>> > find a
>> > way to load it manually.
>> >
>> > This one has really stumped me, and there are very few relevant hits on
>> > Google. Any help would be much appreciated!
>> >
>> > Jeff
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Fri Jan 27 01:39:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 26 Jan 2017 16:39:52 -0800
Subject: [R] Error with "compiler" and "caret" packages
In-Reply-To: <CAGxFJbS0zjhsQZMPhb3pbgW0fose32+KAy7yjEALvFhGKgo_Gw@mail.gmail.com>
References: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
	<CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>
	<CAKV=rG-bLDHWZ-DtUSgPjmSM-+uxMGJOGeCtyqdMw_Wst1L3Ag@mail.gmail.com>
	<CAGxFJbS0zjhsQZMPhb3pbgW0fose32+KAy7yjEALvFhGKgo_Gw@mail.gmail.com>
Message-ID: <B1B93C1E-D2F1-477A-B060-8FB0FAE2A27F@dcn.davis.ca.us>

Running Windows and user of caret.

BTW permissions problems can begin with installation if you use "Run As Administrator..." mode instead of just letting the install program prompt you for permission to install. But I know nothing about caret.
-- 
Sent from my phone. Please excuse my brevity.

On January 26, 2017 4:11:54 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Perfectly reasonable questions: I don't have a clue. Perhaps someone
>runnig Windows can answer.
>
>-- Bert
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Jan 26, 2017 at 3:10 PM, Jeff Hughes <jeff.hughes at gmail.com>
>wrote:
>> That sounds like a good thing to check, but what permissions should I
>be
>> checking? I'm not very familiar with how the compiler works -- is it
>> creating temp files somewhere that I should check? If you have a
>suggestion
>> for a directory or two that seem like good candidates, I can play
>around
>> with the permissions, but I don't really want to start messing around
>with
>> my entire C: drive or whatever.
>>
>> Thanks,
>> Jeff
>>
>>
>> On Thu, Jan 26, 2017 at 1:25 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>>>
>>> Check your permissions? They may be denying your process access.
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming
>along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, Jan 25, 2017 at 3:23 PM, Jeff Hughes <jeff.hughes at gmail.com>
>>> wrote:
>>> > Hi there,
>>> >
>>> > I have been getting an irritating error when trying to use the
>"caret"
>>> > package on one of my machines. Whenever I train any model
>whatsoever, it
>>> > comes back with this error:
>>> >
>>> > Warning: namespace ?compiler? is not available and has been
>replaced
>>> > by .GlobalEnv when processing object ?sep?
>>> > Error in comp(expr, env = envir, options = list(suppressUndefined
>=
>>> > TRUE))
>>> > :
>>> >   could not find function "makeCenv"
>>> >
>>> > As a result, the model does not work, and I am unable to use the
>caret
>>> > package. As an example, here is some code that causes the error,
>though
>>> > it
>>> > has happened in every case I have tried:
>>> >
>>> > library(caret)
>>> > fit.knn <- train(Species ~ ., data=iris, method="knn")
>>> >
>>> > I have tried reinstalling the caret package; I have tried
>reinstalling
>>> > R; I
>>> > have tried updating all of my packages; nothing has worked. What's
>more,
>>> > this machine is running Windows 10, and I have successfully run
>the same
>>> > code on two other machines running the same version of Windows,
>the same
>>> > version of R, and the same version of the caret package. I have
>also
>>> > only
>>> > run into it when using caret, but I don't think the error lies
>within
>>> > that
>>> > package itself.
>>> >
>>> > Here is my sessionInfo() after running the above code in a new R
>>> > session:
>>> >
>>> > R version 3.3.2 (2016-10-31)
>>> > Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> > Running under: Windows >= 8 x64 (build 9200)
>>> >
>>> > locale:
>>> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> > States.1252    LC_MONETARY=English_United States.1252
>>> > [4] LC_NUMERIC=C                           LC_TIME=English_United
>>> > States.1252
>>> >
>>> > attached base packages:
>>> > [1] stats     graphics  grDevices utils     datasets  methods  
>base
>>> >
>>> > other attached packages:
>>> > [1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34
>>> >
>>> > loaded via a namespace (and not attached):
>>> >  [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2
>>> > MASS_7.3-45
>>> >      munsell_0.4.3      colorspace_1.3-2
>>> >  [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0     
>car_2.1-4
>>> >      plyr_1.8.4         tools_3.3.2
>>> > [13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6    
>grid_3.3.2
>>> >       gtable_0.2.0       nlme_3.1-128
>>> > [19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7
>>> > class_7.3-14
>>> >       MatrixModels_0.4-1 iterators_1.0.8
>>> > [25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1    
>tibble_1.2
>>> >       Matrix_1.2-7.1     nloptr_1.0.4
>>> > [31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15
>>> > stringi_1.1.2
>>> >      scales_0.4.1       stats4_3.3.2
>>> > [37] SparseM_1.74
>>> >
>>> > Note that the "compiler" package is not loaded for some reason,
>which I
>>> > think it should be (the other machines on which this runs
>successfully
>>> > have
>>> > it loaded). But the compiler package is built-in, so I can't seem
>to
>>> > find a
>>> > way to load it manually.
>>> >
>>> > This one has really stumped me, and there are very few relevant
>hits on
>>> > Google. Any help would be much appreciated!
>>> >
>>> > Jeff
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Fri Jan 27 02:32:05 2017
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Fri, 27 Jan 2017 01:32:05 +0000
Subject: [R] Error with "compiler" and "caret" packages
In-Reply-To: <CAGxFJbS0zjhsQZMPhb3pbgW0fose32+KAy7yjEALvFhGKgo_Gw@mail.gmail.com>
References: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
	<CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>
	<CAKV=rG-bLDHWZ-DtUSgPjmSM-+uxMGJOGeCtyqdMw_Wst1L3Ag@mail.gmail.com>
	<CAGxFJbS0zjhsQZMPhb3pbgW0fose32+KAy7yjEALvFhGKgo_Gw@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E8FB85@WAXMXOLYMB025.WAX.wa.lcl>

The compiler package may be installed on your computer, but did you load it with

library(compiler)


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
> Gunter
> Sent: Thursday, January 26, 2017 4:12 PM
> To: Jeff Hughes
> Cc: R-help
> Subject: Re: [R] Error with "compiler" and "caret" packages
> 
> Perfectly reasonable questions: I don't have a clue. Perhaps someone runnig
> Windows can answer.
> 
> -- Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jan 26, 2017 at 3:10 PM, Jeff Hughes <jeff.hughes at gmail.com>
> wrote:
> > That sounds like a good thing to check, but what permissions should I
> > be checking? I'm not very familiar with how the compiler works -- is
> > it creating temp files somewhere that I should check? If you have a
> > suggestion for a directory or two that seem like good candidates, I
> > can play around with the permissions, but I don't really want to start
> > messing around with my entire C: drive or whatever.
> >
> > Thanks,
> > Jeff
> >
> >
> > On Thu, Jan 26, 2017 at 1:25 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> Check your permissions? They may be denying your process access.
> >>
> >> Cheers,
> >> Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming
> >> along and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Jan 25, 2017 at 3:23 PM, Jeff Hughes <jeff.hughes at gmail.com>
> >> wrote:
> >> > Hi there,
> >> >
> >> > I have been getting an irritating error when trying to use the "caret"
> >> > package on one of my machines. Whenever I train any model
> >> > whatsoever, it comes back with this error:
> >> >
> >> > Warning: namespace ?compiler? is not available and has been
> >> > replaced by .GlobalEnv when processing object ?sep?
> >> > Error in comp(expr, env = envir, options = list(suppressUndefined =
> >> > TRUE))
> >> > :
> >> >   could not find function "makeCenv"
> >> >
> >> > As a result, the model does not work, and I am unable to use the
> >> > caret package. As an example, here is some code that causes the
> >> > error, though it has happened in every case I have tried:
> >> >
> >> > library(caret)
> >> > fit.knn <- train(Species ~ ., data=iris, method="knn")
> >> >
> >> > I have tried reinstalling the caret package; I have tried
> >> > reinstalling R; I have tried updating all of my packages; nothing
> >> > has worked. What's more, this machine is running Windows 10, and I
> >> > have successfully run the same code on two other machines running
> >> > the same version of Windows, the same version of R, and the same
> >> > version of the caret package. I have also only run into it when
> >> > using caret, but I don't think the error lies within that package
> >> > itself.
> >> >
> >> > Here is my sessionInfo() after running the above code in a new R
> >> > session:
> >> >
> >> > R version 3.3.2 (2016-10-31)
> >> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows
> >=
> >> > 8 x64 (build 9200)
> >> >
> >> > locale:
> >> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >> > States.1252    LC_MONETARY=English_United States.1252
> >> > [4] LC_NUMERIC=C                           LC_TIME=English_United
> >> > States.1252
> >> >
> >> > attached base packages:
> >> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >> >
> >> > other attached packages:
> >> > [1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34
> >> >
> >> > loaded via a namespace (and not attached):
> >> >  [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2
> >> > MASS_7.3-45
> >> >      munsell_0.4.3      colorspace_1.3-2
> >> >  [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0      car_2.1-4
> >> >      plyr_1.8.4         tools_3.3.2
> >> > [13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6     grid_3.3.2
> >> >       gtable_0.2.0       nlme_3.1-128
> >> > [19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7
> >> > class_7.3-14
> >> >       MatrixModels_0.4-1 iterators_1.0.8
> >> > [25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1     tibble_1.2
> >> >       Matrix_1.2-7.1     nloptr_1.0.4
> >> > [31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15
> >> > stringi_1.1.2
> >> >      scales_0.4.1       stats4_3.3.2
> >> > [37] SparseM_1.74
> >> >
> >> > Note that the "compiler" package is not loaded for some reason,
> >> > which I think it should be (the other machines on which this runs
> >> > successfully have it loaded). But the compiler package is built-in,
> >> > so I can't seem to find a way to load it manually.
> >> >
> >> > This one has really stumped me, and there are very few relevant
> >> > hits on Google. Any help would be much appreciated!
> >> >
> >> > Jeff
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Fri Jan 27 02:56:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 26 Jan 2017 17:56:20 -0800
Subject: [R] Error with "compiler" and "caret" packages
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276643E8FB85@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAKV=rG8P-9y6g=PjDVK_Q_wV+R0rjrJrtehoP6p7erXg7TdMtA@mail.gmail.com>
	<CAGxFJbRW94i+C9Om4E1TWB814-P81bzEa6LGatYXLhUYhZ5F-g@mail.gmail.com>
	<CAKV=rG-bLDHWZ-DtUSgPjmSM-+uxMGJOGeCtyqdMw_Wst1L3Ag@mail.gmail.com>
	<CAGxFJbS0zjhsQZMPhb3pbgW0fose32+KAy7yjEALvFhGKgo_Gw@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA276643E8FB85@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <CAGxFJbRwHz7E3ekSQxk4YgSMtn3wJ1PdLq56HZNf-5LEGJRffQ@mail.gmail.com>

Dan:

Strictly speaking library() does not just "load" it -- it "attaches"
it and loads compiler's namespace. I would have presumed that if
needed, the compiler paclage  would have been loaded as part of
caret's Namespace import directives, but perhaps that's wrong and the
source of the difficulties.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jan 26, 2017 at 5:32 PM, Nordlund, Dan (DSHS/RDA)
<NordlDJ at dshs.wa.gov> wrote:
> The compiler package may be installed on your computer, but did you load it with
>
> library(compiler)
>
>
> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
>> Gunter
>> Sent: Thursday, January 26, 2017 4:12 PM
>> To: Jeff Hughes
>> Cc: R-help
>> Subject: Re: [R] Error with "compiler" and "caret" packages
>>
>> Perfectly reasonable questions: I don't have a clue. Perhaps someone runnig
>> Windows can answer.
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jan 26, 2017 at 3:10 PM, Jeff Hughes <jeff.hughes at gmail.com>
>> wrote:
>> > That sounds like a good thing to check, but what permissions should I
>> > be checking? I'm not very familiar with how the compiler works -- is
>> > it creating temp files somewhere that I should check? If you have a
>> > suggestion for a directory or two that seem like good candidates, I
>> > can play around with the permissions, but I don't really want to start
>> > messing around with my entire C: drive or whatever.
>> >
>> > Thanks,
>> > Jeff
>> >
>> >
>> > On Thu, Jan 26, 2017 at 1:25 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >>
>> >> Check your permissions? They may be denying your process access.
>> >>
>> >> Cheers,
>> >> Bert
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming
>> >> along and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Wed, Jan 25, 2017 at 3:23 PM, Jeff Hughes <jeff.hughes at gmail.com>
>> >> wrote:
>> >> > Hi there,
>> >> >
>> >> > I have been getting an irritating error when trying to use the "caret"
>> >> > package on one of my machines. Whenever I train any model
>> >> > whatsoever, it comes back with this error:
>> >> >
>> >> > Warning: namespace ?compiler? is not available and has been
>> >> > replaced by .GlobalEnv when processing object ?sep?
>> >> > Error in comp(expr, env = envir, options = list(suppressUndefined =
>> >> > TRUE))
>> >> > :
>> >> >   could not find function "makeCenv"
>> >> >
>> >> > As a result, the model does not work, and I am unable to use the
>> >> > caret package. As an example, here is some code that causes the
>> >> > error, though it has happened in every case I have tried:
>> >> >
>> >> > library(caret)
>> >> > fit.knn <- train(Species ~ ., data=iris, method="knn")
>> >> >
>> >> > I have tried reinstalling the caret package; I have tried
>> >> > reinstalling R; I have tried updating all of my packages; nothing
>> >> > has worked. What's more, this machine is running Windows 10, and I
>> >> > have successfully run the same code on two other machines running
>> >> > the same version of Windows, the same version of R, and the same
>> >> > version of the caret package. I have also only run into it when
>> >> > using caret, but I don't think the error lies within that package
>> >> > itself.
>> >> >
>> >> > Here is my sessionInfo() after running the above code in a new R
>> >> > session:
>> >> >
>> >> > R version 3.3.2 (2016-10-31)
>> >> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows
>> >=
>> >> > 8 x64 (build 9200)
>> >> >
>> >> > locale:
>> >> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> >> > States.1252    LC_MONETARY=English_United States.1252
>> >> > [4] LC_NUMERIC=C                           LC_TIME=English_United
>> >> > States.1252
>> >> >
>> >> > attached base packages:
>> >> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >> >
>> >> > other attached packages:
>> >> > [1] caret_6.0-73    ggplot2_2.2.1   lattice_0.20-34
>> >> >
>> >> > loaded via a namespace (and not attached):
>> >> >  [1] Rcpp_0.12.8        magrittr_1.5       splines_3.3.2
>> >> > MASS_7.3-45
>> >> >      munsell_0.4.3      colorspace_1.3-2
>> >> >  [7] foreach_1.4.3      minqa_1.2.4        stringr_1.1.0      car_2.1-4
>> >> >      plyr_1.8.4         tools_3.3.2
>> >> > [13] parallel_3.3.2     nnet_7.3-12        pbkrtest_0.4-6     grid_3.3.2
>> >> >       gtable_0.2.0       nlme_3.1-128
>> >> > [19] mgcv_1.8-16        quantreg_5.29      e1071_1.6-7
>> >> > class_7.3-14
>> >> >       MatrixModels_0.4-1 iterators_1.0.8
>> >> > [25] lme4_1.1-12        lazyeval_0.2.0     assertthat_0.1     tibble_1.2
>> >> >       Matrix_1.2-7.1     nloptr_1.0.4
>> >> > [31] reshape2_1.4.2     ModelMetrics_1.1.0 codetools_0.2-15
>> >> > stringi_1.1.2
>> >> >      scales_0.4.1       stats4_3.3.2
>> >> > [37] SparseM_1.74
>> >> >
>> >> > Note that the "compiler" package is not loaded for some reason,
>> >> > which I think it should be (the other machines on which this runs
>> >> > successfully have it loaded). But the compiler package is built-in,
>> >> > so I can't seem to find a way to load it manually.
>> >> >
>> >> > This one has really stumped me, and there are very few relevant
>> >> > hits on Google. Any help would be much appreciated!
>> >> >
>> >> > Jeff
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nicholas.wray at ntlworld.com  Fri Jan 27 13:06:43 2017
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Fri, 27 Jan 2017 12:06:43 +0000 (GMT)
Subject: [R] reading file labels into R
Message-ID: <506514419.1559074.1485518803690.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>

Hello R-ren   I have a list of csv files in a folder which are labelled
essentially in this way (actual data has scores of files)

F010116, F020116, F030116

G020116, G030116, G040116, G 050116

H020116, H030116

where F G and H are engines I've got data from and the numbers are the dates. I
can manually make a "register" to create a paste label of each engine and the
dates for which I have data, which, as in the example, are not the same for each
engine, but I am wondering whether there's any way of getting R to read the
labels from the folder so that it can then loop through successive engines and
dates without being explicitly told what labels it will need to upload each csv
file in turn

If anyone has ideas I'd be grateful

Thanks,Nick
	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Fri Jan 27 13:22:26 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Fri, 27 Jan 2017 17:52:26 +0530
Subject: [R] Request body format is wrong. Make sure the json request is
 serialized correctly and there are no null members"- Text Mining With
 Cognitive API
Message-ID: <CAB=p7SrdVvfr1WSxM6r=Q=javf300VPn295kJcBRCBkY2tZCGA@mail.gmail.com>

Hi Team,

I am building a sentiment and text mining model with R and Cognitive API. I
am getting the error as mentioned in the subject:

Request body format is wrong. Make sure the json request is serialized
correctly and there are no null members. Can you please advice what is
incorrect i am doing in the code below:

modi_df["language"] = "en"
modi_df["id"] = seq.int(nrow(modi_df))
request_body_modi = modi_df[c(2,3,1)]

# Converting tweets dataframe into JSON
request_body_json_modi = toJSON(list(documents = request_body_modi))
# Calling text analytics API


result_modi = POST("
https://westus.api.cognitive.microsoft.com/text/analytics/v2.0/sentiment",
                    body = request_body_json_modi,
                    add_headers(.headers =
c("Content-Type"="application/json","Ocp-Apim-Subscription-Key"="bc8c8427fd74412ea51967373e418681")))

Output = content(result_modi)
Thank You!.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jan 27 13:23:57 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 27 Jan 2017 12:23:57 +0000
Subject: [R] reading file labels into R
In-Reply-To: <506514419.1559074.1485518803690.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
References: <506514419.1559074.1485518803690.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FFFCB@SRVEXCHCM301.precheza.cz>

Hi

Did you try

?list.files

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of WRAY
> NICHOLAS
> Sent: Friday, January 27, 2017 1:07 PM
> To: r-help <r-help at r-project.org>; r-help-request <r-help-request at r-
> project.org>
> Subject: [R] reading file labels into R
>
> Hello R-ren   I have a list of csv files in a folder which are labelled
> essentially in this way (actual data has scores of files)
>
> F010116, F020116, F030116
>
> G020116, G030116, G040116, G 050116
>
> H020116, H030116
>
> where F G and H are engines I've got data from and the numbers are the
> dates. I can manually make a "register" to create a paste label of each engine
> and the dates for which I have data, which, as in the example, are not the
> same for each engine, but I am wondering whether there's any way of
> getting R to read the labels from the folder so that it can then loop through
> successive engines and dates without being explicitly told what labels it will
> need to upload each csv file in turn
>
> If anyone has ideas I'd be grateful
>
> Thanks,Nick
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From eaglek2011 at gmail.com  Thu Jan 26 23:21:07 2017
From: eaglek2011 at gmail.com (ken eagle)
Date: Thu, 26 Jan 2017 16:21:07 -0600
Subject: [R] R matrix multiplication slowdown
Message-ID: <CAEtNUHmopf+Xz92G1u-4gvQgnuJvHE3OJak9vPH_vC90vHmUiA@mail.gmail.com>

Hi all.  A question about performance of matrix multiplication.



I have two relatively large matrices:



A is 100x3072, all integers 0-255, not sparse

B is 1016x3072, all integers 0-255, not sparse



The command z<-B %*% t(A) works fine and takes roughly 0.2 seconds .  If I
add one row to B, the same command takes 2.4 seconds; at 1050 rows in B,
the command is up to almost 4 seconds.  Just trying to understand why the
big slowdown is occurring, especially since the matrices I actually want to
multiply have 1000 and 5000 rows, not 100 and 1017.



Thanks,

Ken



(Macbook Pro running 10.11.6, 16Gb, R v 3.3.1)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Jan 27 15:29:54 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 27 Jan 2017 06:29:54 -0800
Subject: [R] R matrix multiplication slowdown
In-Reply-To: <CAEtNUHmopf+Xz92G1u-4gvQgnuJvHE3OJak9vPH_vC90vHmUiA@mail.gmail.com>
References: <CAEtNUHmopf+Xz92G1u-4gvQgnuJvHE3OJak9vPH_vC90vHmUiA@mail.gmail.com>
Message-ID: <45336D3A-80F9-4BA8-ACBF-41CB80FE7E89@dcn.davis.ca.us>

You are asked by the Posting Guide to provide a reproducible example and to post in plain text (because HTML gets mangled).  I would guess your problem has nothing to do with multiplication, but without the code there is no way to say for sure. 
-- 
Sent from my phone. Please excuse my brevity.

On January 26, 2017 2:21:07 PM PST, ken eagle <eaglek2011 at gmail.com> wrote:
>Hi all.  A question about performance of matrix multiplication.
>
>
>
>I have two relatively large matrices:
>
>
>
>A is 100x3072, all integers 0-255, not sparse
>
>B is 1016x3072, all integers 0-255, not sparse
>
>
>
>The command z<-B %*% t(A) works fine and takes roughly 0.2 seconds . 
>If I
>add one row to B, the same command takes 2.4 seconds; at 1050 rows in
>B,
>the command is up to almost 4 seconds.  Just trying to understand why
>the
>big slowdown is occurring, especially since the matrices I actually
>want to
>multiply have 1000 and 5000 rows, not 100 and 1017.
>
>
>
>Thanks,
>
>Ken
>
>
>
>(Macbook Pro running 10.11.6, 16Gb, R v 3.3.1)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jamilnaser79 at gmail.com  Fri Jan 27 16:43:55 2017
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Fri, 27 Jan 2017 21:43:55 +0600
Subject: [R] No visible binding for global variable
Message-ID: <CAJK=5Ykk2Upxg-YwHjVGT=ch6sgepJhWGhcmBeWy1ugV0=zgqA@mail.gmail.com>

Dear R-users,
I would like to seek your suggestion. I have the following code which runs
smoothly. But when I compile the function (lf1.c), it shows "no visible
binding for global variable" for some of the arguments.

###################################

library(compiler)


psi0<-function(theta1,theta2,theta3,theta4,x){
z1<-exp(theta1+theta2*x)
z2<-exp(theta3+theta4*x)
1/((1+z1)*(1+z2))
                                             }

psi1<-function(theta1,theta2,theta3,theta4,x){
z1<-exp(theta1+theta2*x)
z2<-exp(theta3+theta4*x)
z1/((1+z1)*(1+z2))
                                             }
psi2<-function(theta3,theta4,x) {
z2<-exp(theta3+theta4*x)
z2/(1+z2)
                                }



lf1<-function(w) {
   v<-1
   w1<-w[1]
   w2<-w[2]
   w3<-w[3]
   w4<-w[4]
   for (i in 1:length(alloc.dose)) {
       dose.i<-alloc.dose[i]
       r0.i<-r0[i]
       r1.i<-r1[i]
       r2.i<-r2[i]
       z1<-exp(w1+w2*dose.i)
       z2<-exp(w3+w4*dose.i)
       psi0<-1/((1+z1)*(1+z2))
       psi1<-z1*psi0
       v<-v*(psi0^r0.i)*(psi1^r1.i)*((1-psi0-psi1)^r2.i)
                                   }
   return(v)
                  }


lf1.c<-cmpfun(lf1)

###############################

May I know how to avoid this message? If I leave the code as it is, will
that affect the result anyway?

Thanks in advance.


Regards,
Jamil.

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Jan 27 17:58:48 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 27 Jan 2017 16:58:48 +0000
Subject: [R] testing in spatial sure models
In-Reply-To: <20170126125817.Horde.2L2YtkEITNsaGTrzcTS8bGF@webposta.ehu.eus>
References: <20170126125817.Horde.2L2YtkEITNsaGTrzcTS8bGF@webposta.ehu.eus>
Message-ID: <2B8F56F8-2267-4B1D-A531-7E428871B7D6@llnl.gov>

You could start by going to the CRAN website, clicking on the "Task Views" item on the left, then clicking on "Spatial". This will bring you to a page with extensive information about doing things with spatial data in R. It includes some brief descriptions of the purposes/capabilities of many spatial-related packages in R. Beyond that, when you have the name of a test method, the folks at R-sig-geo should be able to help identify which packages might have it.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 1/26/17, 3:58 AM, "R-help on behalf of M? Pilar Gonzalez Casimiro" <r-help-bounces at r-project.org on behalf of mariapilar.gonzalez at ehu.eus> wrote:

    
    Good afternoon,
    
    I would like to know how to test for homogeneity in spatial sure models.
    
    Thank you,
    
    Pilar
    
    
      Pilar Gonz?lez Casimiro
      Facultad de Ciencias Econ?micas y Empresariales
      Avda. Lehendakari Aguirre, 83 48015 Bilbao
      tfno: 94 601 3730
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri Jan 27 19:27:28 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 27 Jan 2017 18:27:28 +0000
Subject: [R] No visible binding for global variable
In-Reply-To: <CAJK=5Ykk2Upxg-YwHjVGT=ch6sgepJhWGhcmBeWy1ugV0=zgqA@mail.gmail.com>
References: <CAJK=5Ykk2Upxg-YwHjVGT=ch6sgepJhWGhcmBeWy1ugV0=zgqA@mail.gmail.com>
Message-ID: <96A36311-8F09-4971-AE67-38DE0B2046CA@mcmaster.ca>

Dear Jamil,

Presumably, the variables alloc.dose, r0, r1, and r2 will exist in the global environment when you call the compiled function lf1.c(), but didn?t exist when you compiled the function. If so, then lf1.c() should work properly despite the notes (not errors, or even warnings) that was printed.

On the other hand, relying on global data in a function is poor programming style ? it would be better to make alloc.dose, etc., arguments to the function. As well, if you?re compiling the function to improve efficiency, then you probably also want to compile psi0(), etc.

I hope that this helps,
 John

John Fox
Sen. William McMaster Professor of Social Statistics
McMaster University
Hamilton, Ontario, Canada
Web: http::/socserv.mcmaster.ca/jfox

> On Jan 27, 2017, at 10:43 AM, Naser Jamil <jamilnaser79 at gmail.com> wrote:
> 
> Dear R-users,
> I would like to seek your suggestion. I have the following code which runs
> smoothly. But when I compile the function (lf1.c), it shows "no visible
> binding for global variable" for some of the arguments.
> 
> ###################################
> 
> library(compiler)
> 
> 
> psi0<-function(theta1,theta2,theta3,theta4,x){
> z1<-exp(theta1+theta2*x)
> z2<-exp(theta3+theta4*x)
> 1/((1+z1)*(1+z2))
>                                             }
> 
> psi1<-function(theta1,theta2,theta3,theta4,x){
> z1<-exp(theta1+theta2*x)
> z2<-exp(theta3+theta4*x)
> z1/((1+z1)*(1+z2))
>                                             }
> psi2<-function(theta3,theta4,x) {
> z2<-exp(theta3+theta4*x)
> z2/(1+z2)
>                                }
> 
> 
> 
> lf1<-function(w) {
>   v<-1
>   w1<-w[1]
>   w2<-w[2]
>   w3<-w[3]
>   w4<-w[4]
>   for (i in 1:length(alloc.dose)) {
>       dose.i<-alloc.dose[i]
>       r0.i<-r0[i]
>       r1.i<-r1[i]
>       r2.i<-r2[i]
>       z1<-exp(w1+w2*dose.i)
>       z2<-exp(w3+w4*dose.i)
>       psi0<-1/((1+z1)*(1+z2))
>       psi1<-z1*psi0
>       v<-v*(psi0^r0.i)*(psi1^r1.i)*((1-psi0-psi1)^r2.i)
>                                   }
>   return(v)
>                  }
> 
> 
> lf1.c<-cmpfun(lf1)
> 
> ###############################
> 
> May I know how to avoid this message? If I leave the code as it is, will
> that affect the result anyway?
> 
> Thanks in advance.
> 
> 
> Regards,
> Jamil.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.






From eaglek2011 at gmail.com  Fri Jan 27 20:51:47 2017
From: eaglek2011 at gmail.com (ken eagle)
Date: Fri, 27 Jan 2017 13:51:47 -0600
Subject: [R] R matrix multiplication slowdown
In-Reply-To: <45336D3A-80F9-4BA8-ACBF-41CB80FE7E89@dcn.davis.ca.us>
References: <CAEtNUHmopf+Xz92G1u-4gvQgnuJvHE3OJak9vPH_vC90vHmUiA@mail.gmail.com>
	<45336D3A-80F9-4BA8-ACBF-41CB80FE7E89@dcn.davis.ca.us>
Message-ID: <CAEtNUHnhy10-G4gXKrfjN52N67ggXa0PF5Eam665q63A+BCc+g@mail.gmail.com>

I've done more searching and found a problem with the data in one of the
matrices that was corrupting the calculation.  Data now fixed and problem
is solved.  Apologies if anyone wasted time on this.

Ken

On Fri, Jan 27, 2017 at 8:29 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You are asked by the Posting Guide to provide a reproducible example and
> to post in plain text (because HTML gets mangled).  I would guess your
> problem has nothing to do with multiplication, but without the code there
> is no way to say for sure.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 26, 2017 2:21:07 PM PST, ken eagle <eaglek2011 at gmail.com>
> wrote:
> >Hi all.  A question about performance of matrix multiplication.
> >
> >
> >
> >I have two relatively large matrices:
> >
> >
> >
> >A is 100x3072, all integers 0-255, not sparse
> >
> >B is 1016x3072, all integers 0-255, not sparse
> >
> >
> >
> >The command z<-B %*% t(A) works fine and takes roughly 0.2 seconds .
> >If I
> >add one row to B, the same command takes 2.4 seconds; at 1050 rows in
> >B,
> >the command is up to almost 4 seconds.  Just trying to understand why
> >the
> >big slowdown is occurring, especially since the matrices I actually
> >want to
> >multiply have 1000 and 5000 rows, not 100 and 1017.
> >
> >
> >
> >Thanks,
> >
> >Ken
> >
> >
> >
> >(Macbook Pro running 10.11.6, 16Gb, R v 3.3.1)
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Sat Jan 28 11:36:32 2017
From: rune.haubo at gmail.com (Rune Haubo)
Date: Sat, 28 Jan 2017 11:36:32 +0100
Subject: [R] proportional odds logistic regression with non-negative
 constraint for several coefficients
In-Reply-To: <CY1PR0401MB17879350EBD1E12EA3692B3FF7770@CY1PR0401MB1787.namprd04.prod.outlook.com>
References: <CY1PR0401MB17879350EBD1E12EA3692B3FF7770@CY1PR0401MB1787.namprd04.prod.outlook.com>
Message-ID: <CAG_uk92+UVG9LV5k0hQU0GwZw6DqN6KJGOGqH8eFgEXUex+wNg@mail.gmail.com>

Hi Zhao,

This is not a direct answer to your question, but a suggestion for a
different approach. The ordinal package was designed to cope with
issues like this (parameter constraints in ordinal regression models)
- try the following:

> library(ordinal)
> data(wine, package="ordinal")
> ## Fit model for reference:
> fm1 <- clm(rating ~ temp + contact, data=wine)
> # summary(fm1)
> coef(fm1)
       1|2        2|3        3|4        4|5   tempwarm contactyes
 -1.344383   1.250809   3.466887   5.006404   2.503102   1.527798
>
> ## Now fit the same model by manually optimizing a clm-environment:
> env <- clm(rating ~ temp + contact, data=wine, doFit=FALSE)
> # ls.str(env) ## view contents of env
> ## Define negative log-likelihood function:
> nll <- function(par, envir) {
+   envir$par <- par
+   envir$clm.nll(envir)
+ }
> ## optimize with nlminb:
> nlminb(start=env$par, objective=nll, envir=env)$par
[1] -1.344385  1.250812  3.466887  5.006404  2.503102  1.527798
>
> # Now optimize under parameter constraints:
> nlminb(start=env$par, objective=nll, envir=env,
+        upper = c(Inf, Inf, Inf, Inf, 2, 1),
+        lower = rep(-Inf, 6))$par
[1] -1.6124363  0.8060461  2.8052591  4.2401832  2.0000000  1.0000000
>

Cheers
Rune

On 26 January 2017 at 20:41, Liu, Zhao <Zhao.Liu at fmglobal.com> wrote:
> Hi,
>
> I am  working on proportional odds logistic regression, and trying to figure out how to specify the constraint for several predictors.  Those non-negative constraints for some predictors are for practical purpose.
>
> I have seen some one posted passing box constraint with L-BFGS-B with logistic regression.
>
> What I did not is to use polr() to solve the proportional odds, and modify the source code for polr() by passing the lower bounds to the optim() and change the method to L-BFGS-B.
>
> Then I realized that polr() generate a start value for all coefficients with glm.fit, which can still start from negative.
>
> So my question is that does the start value having negative while the optimization has a lower bound as 0.00001. Does it matter?
>
> Or is there another way of implementation to solve proportional odds while forcing some coefficients  as non-negative.
>
> Thanks so much!
>
> Zhao
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Sun Jan 29 00:03:04 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 28 Jan 2017 18:03:04 -0500
Subject: [R] graphical behavior of a table of numbers
Message-ID: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>

## This example is from R-intro.pdf page 21 (R-3.3.2)

d <- outer(0:9, 0:9)
fr <- table(outer(d, d, "-"))
plot(as.numeric(names(fr)), fr, type="h",
            xlab="Determinant", ylab="Frequency")
## The y-axis tick marks are at c(-21,24,65).
## This seems to be because class(fr) == "table"

## Switching the class to array gives the more appropriate
## y-axis ticks at seq(0,500,100) .

fr.array <- fr
class(fr.array) <- "array"
plot(as.numeric(names(fr)), fr.array, type="h",
            xlab="Determinant", ylab="Frequency")


## I have a question and a recommendation.
## Question:
## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
##
## Recommendation:
## Changed the example on page 21 to show the ticks at seq(0,500,100)?

## Rich


From bgunter.4567 at gmail.com  Sun Jan 29 01:19:37 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 28 Jan 2017 16:19:37 -0800
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
Message-ID: <CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>

Rich:

Simpler: Just lose the "table" class.

plot(as.numeric(names(fr)), as.vector(fr),  type="h",
            xlab="Determinant", ylab="Frequency")


However, I'm no less puzzled by the "strange" behavior than you.

In addition, it's probably worth noting that xyplot in lattice (and no
doubt ggplot,too) does not have this problem (as I'm sure you know):

xyplot(fr ~ as.numeric(names(fr)),  type="h",
            xlab="Determinant", ylab="Frequency")


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> ## This example is from R-intro.pdf page 21 (R-3.3.2)
>
> d <- outer(0:9, 0:9)
> fr <- table(outer(d, d, "-"))
> plot(as.numeric(names(fr)), fr, type="h",
>             xlab="Determinant", ylab="Frequency")
> ## The y-axis tick marks are at c(-21,24,65).
> ## This seems to be because class(fr) == "table"
>
> ## Switching the class to array gives the more appropriate
> ## y-axis ticks at seq(0,500,100) .
>
> fr.array <- fr
> class(fr.array) <- "array"
> plot(as.numeric(names(fr)), fr.array, type="h",
>             xlab="Determinant", ylab="Frequency")
>
>
> ## I have a question and a recommendation.
> ## Question:
> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
> ##
> ## Recommendation:
> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
>
> ## Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Jan 29 06:05:15 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 29 Jan 2017 16:05:15 +1100
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
	<CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
Message-ID: <CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>

Hi Richard,
I think there may be something amiss in the plot.table function. As
you note, changing the class of fr to array produces a more sensible
plot, as does Bert's "as.vector". Yet inside plot.table we find:

plot(x0, unclass(x), ...

and that should produce an array:

class(unclass(fr))
[1] "array"

The plot.table function looks like it should produce the plot you
want, but it doesn't. I think (therefore I am probably wrong) that a
1D table is handled in the same way as  multiD table rather than being
squeezed into a vector.

Jim


On Sun, Jan 29, 2017 at 11:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Rich:
>
> Simpler: Just lose the "table" class.
>
> plot(as.numeric(names(fr)), as.vector(fr),  type="h",
>             xlab="Determinant", ylab="Frequency")
>
>
> However, I'm no less puzzled by the "strange" behavior than you.
>
> In addition, it's probably worth noting that xyplot in lattice (and no
> doubt ggplot,too) does not have this problem (as I'm sure you know):
>
> xyplot(fr ~ as.numeric(names(fr)),  type="h",
>             xlab="Determinant", ylab="Frequency")
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> ## This example is from R-intro.pdf page 21 (R-3.3.2)
>>
>> d <- outer(0:9, 0:9)
>> fr <- table(outer(d, d, "-"))
>> plot(as.numeric(names(fr)), fr, type="h",
>>             xlab="Determinant", ylab="Frequency")
>> ## The y-axis tick marks are at c(-21,24,65).
>> ## This seems to be because class(fr) == "table"
>>
>> ## Switching the class to array gives the more appropriate
>> ## y-axis ticks at seq(0,500,100) .
>>
>> fr.array <- fr
>> class(fr.array) <- "array"
>> plot(as.numeric(names(fr)), fr.array, type="h",
>>             xlab="Determinant", ylab="Frequency")
>>
>>
>> ## I have a question and a recommendation.
>> ## Question:
>> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
>> ##
>> ## Recommendation:
>> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
>>
>> ## Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Jan 29 12:32:27 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 29 Jan 2017 06:32:27 -0500
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
	<CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
	<CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>
Message-ID: <4388a051-200f-9bbb-d02e-c6cab734019b@gmail.com>

On 29/01/2017 12:05 AM, Jim Lemon wrote:
> Hi Richard,
> I think there may be something amiss in the plot.table function. As
> you note, changing the class of fr to array produces a more sensible
> plot, as does Bert's "as.vector". Yet inside plot.table we find:
>
> plot(x0, unclass(x), ...
>
> and that should produce an array:
>
> class(unclass(fr))
> [1] "array"
>
> The plot.table function looks like it should produce the plot you
> want, but it doesn't. I think (therefore I am probably wrong) that a
> 1D table is handled in the same way as  multiD table rather than being
> squeezed into a vector.

I think the issue is that Axis() is called without removing the class.
Axis.table sets ticks based on the names of the table.

Duncan Murdoch

>
> Jim
>
>
> On Sun, Jan 29, 2017 at 11:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Rich:
>>
>> Simpler: Just lose the "table" class.
>>
>> plot(as.numeric(names(fr)), as.vector(fr),  type="h",
>>             xlab="Determinant", ylab="Frequency")
>>
>>
>> However, I'm no less puzzled by the "strange" behavior than you.
>>
>> In addition, it's probably worth noting that xyplot in lattice (and no
>> doubt ggplot,too) does not have this problem (as I'm sure you know):
>>
>> xyplot(fr ~ as.numeric(names(fr)),  type="h",
>>             xlab="Determinant", ylab="Frequency")
>>
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>> ## This example is from R-intro.pdf page 21 (R-3.3.2)
>>>
>>> d <- outer(0:9, 0:9)
>>> fr <- table(outer(d, d, "-"))
>>> plot(as.numeric(names(fr)), fr, type="h",
>>>             xlab="Determinant", ylab="Frequency")
>>> ## The y-axis tick marks are at c(-21,24,65).
>>> ## This seems to be because class(fr) == "table"
>>>
>>> ## Switching the class to array gives the more appropriate
>>> ## y-axis ticks at seq(0,500,100) .
>>>
>>> fr.array <- fr
>>> class(fr.array) <- "array"
>>> plot(as.numeric(names(fr)), fr.array, type="h",
>>>             xlab="Determinant", ylab="Frequency")
>>>
>>>
>>> ## I have a question and a recommendation.
>>> ## Question:
>>> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
>>> ##
>>> ## Recommendation:
>>> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
>>>
>>> ## Rich
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jamilnaser79 at gmail.com  Sat Jan 28 10:03:21 2017
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Sat, 28 Jan 2017 15:03:21 +0600
Subject: [R] No visible binding for global variable
In-Reply-To: <96A36311-8F09-4971-AE67-38DE0B2046CA@mcmaster.ca>
References: <CAJK=5Ykk2Upxg-YwHjVGT=ch6sgepJhWGhcmBeWy1ugV0=zgqA@mail.gmail.com>
	<96A36311-8F09-4971-AE67-38DE0B2046CA@mcmaster.ca>
Message-ID: <CAJK=5YmU31LPsqWkHmYiRBM1eEy5HvxuKLgvYExg307SAcAt8w@mail.gmail.com>

Dear Prof John,
I have got the points now. Many thanks for your suggestions.

Regards,
Jamil.

On 28 January 2017 at 00:27, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Jamil,
>
> Presumably, the variables alloc.dose, r0, r1, and r2 will exist in the
> global environment when you call the compiled function lf1.c(), but didn?t
> exist when you compiled the function. If so, then lf1.c() should work
> properly despite the notes (not errors, or even warnings) that was printed.
>
> On the other hand, relying on global data in a function is poor
> programming style ? it would be better to make alloc.dose, etc., arguments
> to the function. As well, if you?re compiling the function to improve
> efficiency, then you probably also want to compile psi0(), etc.
>
> I hope that this helps,
>  John
>
> John Fox
> Sen. William McMaster Professor of Social Statistics
> McMaster University
> Hamilton, Ontario, Canada
> Web: http::/socserv.mcmaster.ca/jfox
>
> > On Jan 27, 2017, at 10:43 AM, Naser Jamil <jamilnaser79 at gmail.com>
> wrote:
> >
> > Dear R-users,
> > I would like to seek your suggestion. I have the following code which
> runs
> > smoothly. But when I compile the function (lf1.c), it shows "no visible
> > binding for global variable" for some of the arguments.
> >
> > ###################################
> >
> > library(compiler)
> >
> >
> > psi0<-function(theta1,theta2,theta3,theta4,x){
> > z1<-exp(theta1+theta2*x)
> > z2<-exp(theta3+theta4*x)
> > 1/((1+z1)*(1+z2))
> >                                             }
> >
> > psi1<-function(theta1,theta2,theta3,theta4,x){
> > z1<-exp(theta1+theta2*x)
> > z2<-exp(theta3+theta4*x)
> > z1/((1+z1)*(1+z2))
> >                                             }
> > psi2<-function(theta3,theta4,x) {
> > z2<-exp(theta3+theta4*x)
> > z2/(1+z2)
> >                                }
> >
> >
> >
> > lf1<-function(w) {
> >   v<-1
> >   w1<-w[1]
> >   w2<-w[2]
> >   w3<-w[3]
> >   w4<-w[4]
> >   for (i in 1:length(alloc.dose)) {
> >       dose.i<-alloc.dose[i]
> >       r0.i<-r0[i]
> >       r1.i<-r1[i]
> >       r2.i<-r2[i]
> >       z1<-exp(w1+w2*dose.i)
> >       z2<-exp(w3+w4*dose.i)
> >       psi0<-1/((1+z1)*(1+z2))
> >       psi1<-z1*psi0
> >       v<-v*(psi0^r0.i)*(psi1^r1.i)*((1-psi0-psi1)^r2.i)
> >                                   }
> >   return(v)
> >                  }
> >
> >
> > lf1.c<-cmpfun(lf1)
> >
> > ###############################
> >
> > May I know how to avoid this message? If I leave the code as it is, will
> > that affect the result anyway?
> >
> > Thanks in advance.
> >
> >
> > Regards,
> > Jamil.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Sun Jan 29 10:31:54 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Sun, 29 Jan 2017 09:31:54 +0000 (UTC)
Subject: [R] princomp() output loadings component missing
In-Reply-To: <825389587.741141.1481055296512@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
Message-ID: <1718993451.2837139.1485682314808@mail.yahoo.com>

Hello, there,
I did a test run for this princomp() function using USArrests data. The R document says that the output loadings contain the eigenvector matrix. When I looked at this matrix, I found that a missing item for Comp.4 

   > p3=princomp(USArrests, cor=TRUE )> p3$loadings
Loadings:?? ? ? ? Comp.1 Comp.2 Comp.3 Comp.4Murder ? -0.536? 0.418 -0.341? 0.649Assault? -0.583? 0.188 -0.268 -0.743UrbanPop -0.278 -0.873 -0.378? 0.134Rape ? ? -0.543 -0.167? 0.818? ? ? ?
?? ? ? ? ? ? ? Comp.1 Comp.2 Comp.3 Comp.4SS loadings? ? ? 1.00 ? 1.00 ? 1.00 ? 1.00Proportion Var ? 0.25 ? 0.25 ? 0.25 ? 0.25Cumulative Var ? 0.25 ? 0.50 ? 0.75 ? 1.00
How should I explain this?
Thanks.
Ace

   
	[[alternative HTML version deleted]]


From btupper at bigelow.org  Sun Jan 29 22:12:59 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 29 Jan 2017 16:12:59 -0500
Subject: [R] princomp() output loadings component missing
In-Reply-To: <1718993451.2837139.1485682314808@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
Message-ID: <DA148A68-253E-4975-9337-8EF3AD42C531@bigelow.org>

Hi,

Check out the detailed explanation in the 'Value' section of ?princomp - in particular for 'loadings'.  It will send you to ?loadings where it explains why that one element appears to be missing.

If you really want to see the missing value try...

p3$loadings['Rape', 'Comp.4']

... or even ...

unclass(p3$loadings)

Don't forget that this email list works best when messages are send in plain text, and it works poorly for html or rich text.  Check the settings in your email client.  In case others are interested here is what the loadings print to...

Loadings:
         Comp.1 Comp.2 Comp.3 Comp.4
Murder   -0.536  0.418 -0.341  0.649
Assault  -0.583  0.188 -0.268 -0.743
UrbanPop -0.278 -0.873 -0.378  0.134
Rape     -0.543 -0.167  0.818       

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00 

Cheers,
Ben

> On Jan 29, 2017, at 4:31 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Hello, there,
> I did a test run for this princomp() function using USArrests data. The R document says that the output loadings contain the eigenvector matrix. When I looked at this matrix, I found that a missing item for Comp.4 
> 
>> p3=princomp(USArrests, cor=TRUE )> p3$loadings
> Loadings:         Comp.1 Comp.2 Comp.3 Comp.4Murder   -0.536  0.418 -0.341  0.649Assault  -0.583  0.188 -0.268 -0.743UrbanPop -0.278 -0.873 -0.378  0.134Rape     -0.543 -0.167  0.818       
>                Comp.1 Comp.2 Comp.3 Comp.4SS loadings      1.00   1.00   1.00   1.00Proportion Var   0.25   0.25   0.25   0.25Cumulative Var   0.25   0.50   0.75   1.00
> How should I explain this?
> Thanks.
> Ace
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From draga at ualberta.ca  Mon Jan 30 08:09:36 2017
From: draga at ualberta.ca (Miya Draga)
Date: Mon, 30 Jan 2017 00:09:36 -0700
Subject: [R] RQDA issue
Message-ID: <CAK5=ESdFzLhztwW5w0JTceY8nBtP2ir-vSEHjABT9MZ0qF3JNg@mail.gmail.com>

Hello,

Sincerest apologies if I am emailing the wrong person/people, but I had a
hard time finding contact information that seemed relevant to the issue
that I'm having. I hope someone can answer my question.

I would like to download RQDA to use for my research, but the RQDA Project
website seems to be down. Any idea whether/how long it will take for it to
be back up?

Cheers,

-- 
*Miya Draga*
MA Candidate
Department of Sociology
University of Alberta

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Jan 30 11:38:26 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 30 Jan 2017 11:38:26 +0100
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <4388a051-200f-9bbb-d02e-c6cab734019b@gmail.com>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
	<CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
	<CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>
	<4388a051-200f-9bbb-d02e-c6cab734019b@gmail.com>
Message-ID: <22671.6050.750658.33001@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Sun, 29 Jan 2017 06:32:27 -0500 writes:

    > On 29/01/2017 12:05 AM, Jim Lemon wrote:
    >> Hi Richard, I think there may be something amiss in the
    >> plot.table function. As you note, changing the class of
    >> fr to array produces a more sensible plot, as does Bert's
    >> "as.vector". Yet inside plot.table we find:
    >> 
    >> plot(x0, unclass(x), ...
    >> 
    >> and that should produce an array:
    >> 
    >> class(unclass(fr)) [1] "array"
    >> 
    >> The plot.table function looks like it should produce the
    >> plot you want, but it doesn't. I think (therefore I am
    >> probably wrong) that a 1D table is handled in the same
    >> way as multiD table rather than being squeezed into a
    >> vector.

    > I think the issue is that Axis() is called without
    > removing the class.  Axis.table sets ticks based on the
    > names of the table.

    > Duncan Murdoch

yes indeed!  So this answers Rich Heiberger's question.

The example stems from a time long before there was
a plot.table() method, and even longer before plot.default() had
started using  Axis() and its methods.

So a much nicer example for the R-intro -- committed a few
minutes ago -- is making use of the  plot.table() S3 method :

  d <- outer(0:9, 0:9)
  fr <- table(outer(d, d, "-"))
  plot(fr, type="h", xlab="Determinant", ylab="Frequency")

So this fulfills Rich's recommendation.

Martin


    >> On Sun, Jan 29, 2017 at 11:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >>> Rich:
    >>> 
    >>> Simpler: Just lose the "table" class.
    >>> 
    >>> plot(as.numeric(names(fr)), as.vector(fr),  type="h",
    >>>      xlab="Determinant", ylab="Frequency")
    >>> 
    >>> However, I'm no less puzzled by the "strange" behavior than you.
    >>> 
    >>> In addition, it's probably worth noting that xyplot in lattice (and no
    >>> doubt ggplot,too) does not have this problem (as I'm sure you know):
    >>> 
    >>> xyplot(fr ~ as.numeric(names(fr)),  type="h",
    >>>        xlab="Determinant", ylab="Frequency")
    >>> 
    >>> 
    >>> Cheers,
    >>> Bert
    >>> Bert Gunter
    >>> 
    >>> "The trouble with having an open mind is that people keep coming along
    >>> and sticking things into it."
    >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    >>> 
    >>> 
    >>> On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
    >>>> ## This example is from R-intro.pdf page 21 (R-3.3.2)
    >>>> 
    >>>> d <- outer(0:9, 0:9)
    >>>> fr <- table(outer(d, d, "-"))
    >>>> plot(as.numeric(names(fr)), fr, type="h",
    >>>>      xlab="Determinant", ylab="Frequency")
    >>>> ## The y-axis tick marks are at c(-21,24,65).
    >>>> ## This seems to be because class(fr) == "table"
    >>>> 
    >>>> ## Switching the class to array gives the more appropriate
    >>>> ## y-axis ticks at seq(0,500,100) .
    >>>> 
    >>>> fr.array <- fr
    >>>> class(fr.array) <- "array"
    >>>> plot(as.numeric(names(fr)), fr.array, type="h",
    >>>>      xlab="Determinant", ylab="Frequency")
    >>>> 
    >>>> 
    >>>> ## I have a question and a recommendation.
    >>>> ## Question:
    >>>> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
    >>>> ##
    >>>> ## Recommendation:
    >>>> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
    >>>> 
    >>>> ## Rich
    >>>>


From starskykwesi at gmail.com  Mon Jan 30 13:53:34 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Mon, 30 Jan 2017 14:53:34 +0200
Subject: [R] Challenge extracting months
Message-ID: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>

Hello, I have a data with two variables nodes and index, I want to extract
3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
OND. Was wondering how to go about it. Kindly find attached the data as csv.
Any help will be appreciated.

Regards,
?Kwesi?

-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

From pdalgd at gmail.com  Mon Jan 30 14:59:51 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 30 Jan 2017 14:59:51 +0100
Subject: [R] RQDA issue
In-Reply-To: <CAK5=ESdFzLhztwW5w0JTceY8nBtP2ir-vSEHjABT9MZ0qF3JNg@mail.gmail.com>
References: <CAK5=ESdFzLhztwW5w0JTceY8nBtP2ir-vSEHjABT9MZ0qF3JNg@mail.gmail.com>
Message-ID: <66AF59E2-5C34-49CB-AD36-CF3910089054@gmail.com>

That would be http://rqda.r-forge.r-project.org? It appears that the entire r-forge site is offline just now, but it is hosted at WU-Vienna, so they are the ones that have the hard facts about what has happened.

Peter D.

On 30 Jan 2017, at 08:09 , Miya Draga <draga at ualberta.ca> wrote:

> Hello,
> 
> Sincerest apologies if I am emailing the wrong person/people, but I had a
> hard time finding contact information that seemed relevant to the issue
> that I'm having. I hope someone can answer my question.
> 
> I would like to download RQDA to use for my research, but the RQDA Project
> website seems to be down. Any idea whether/how long it will take for it to
> be back up?
> 
> Cheers,
> 
> -- 
> *Miya Draga*
> MA Candidate
> Department of Sociology
> University of Alberta
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From starskykwesi at gmail.com  Mon Jan 30 15:11:48 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Mon, 30 Jan 2017 16:11:48 +0200
Subject: [R] (no subject)
Message-ID: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>

Hello, I have a data with two variables nodes and index, I want to extract
3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
OND. Was wondering how to go about it. Kindly find data sample below, data
is in csv format.
Any help will be appreciated.

My data sample;

      era...1.    Node_freq           MEI
1   1980-01-01 -0.389855332  0.3394196488
2   1980-02-01 -0.728019153  0.2483738232
3   1980-03-01 -1.992457784  0.3516954904
4   1980-04-01  0.222760284  0.5736836269
5   1980-05-01  0.972601798  0.6289249144
6   1980-06-01  0.570725954  0.5736836269
7   1980-07-01 -0.977966324  0.4120517119
8   1980-08-01  0.056128836 -0.0104418383
9   1980-09-01  0.987304573 -0.0687520861
10  1980-10-01  1.188242495 -0.1403611624
11  1980-11-01  1.693037763 -0.0963727298
12  1980-12-01  1.173539720 -0.2539126977
13  1981-01-01  0.423698206 -0.6140040528
14  1981-02-01 -2.208098481 -0.5209122536
15  1981-03-01 -0.786830252  0.1133395650
16  1981-04-01 -0.110502611  0.3302127675
17  1981-05-01 -1.272021820 -0.1894645290
18  1981-06-01  0.394292656 -0.3736021538
19  1981-07-01  1.452892441 -0.4032687711
20  1981-08-01  0.698150002 -0.4441882433
21  1981-09-01  0.997106423 -0.1720737534
22  1981-10-01  0.247264908 -0.2436828296
23  1981-11-01  0.771663876 -0.3909929295
24  1981-12-01 -0.316341458 -0.4943145967

Regards,
?Kwesi?

-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From rsherry8 at comcast.net  Mon Jan 30 15:23:16 2017
From: rsherry8 at comcast.net (Robert Sherry)
Date: Mon, 30 Jan 2017 09:23:16 -0500
Subject: [R] (no subject)
In-Reply-To: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
Message-ID: <6c0fd124-4dcb-08e4-2a1c-2acbf34f1f55@comcast.net>

Here is one thought. Assign each month a value of 0, 1 or 2. Then do a 
simple linear regression analysis where the value of the month
is the independent variable. You can also do multiple linear regression 
with the value you assigned to the month plus the other factors that
you believe are causing a change to your data. Time is the one that 
comes to my mind. You can do this with the standard R function lm.

I hope this helps.

Bob

On 1/30/2017 9:11 AM, Kwesi Quagraine wrote:
> Hello, I have a data with two variables nodes and index, I want to extract
> 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
> OND. Was wondering how to go about it. Kindly find data sample below, data
> is in csv format.
> Any help will be appreciated.
>
> My data sample;
>
>        era...1.    Node_freq           MEI
> 1   1980-01-01 -0.389855332  0.3394196488
> 2   1980-02-01 -0.728019153  0.2483738232
> 3   1980-03-01 -1.992457784  0.3516954904
> 4   1980-04-01  0.222760284  0.5736836269
> 5   1980-05-01  0.972601798  0.6289249144
> 6   1980-06-01  0.570725954  0.5736836269
> 7   1980-07-01 -0.977966324  0.4120517119
> 8   1980-08-01  0.056128836 -0.0104418383
> 9   1980-09-01  0.987304573 -0.0687520861
> 10  1980-10-01  1.188242495 -0.1403611624
> 11  1980-11-01  1.693037763 -0.0963727298
> 12  1980-12-01  1.173539720 -0.2539126977
> 13  1981-01-01  0.423698206 -0.6140040528
> 14  1981-02-01 -2.208098481 -0.5209122536
> 15  1981-03-01 -0.786830252  0.1133395650
> 16  1981-04-01 -0.110502611  0.3302127675
> 17  1981-05-01 -1.272021820 -0.1894645290
> 18  1981-06-01  0.394292656 -0.3736021538
> 19  1981-07-01  1.452892441 -0.4032687711
> 20  1981-08-01  0.698150002 -0.4441882433
> 21  1981-09-01  0.997106423 -0.1720737534
> 22  1981-10-01  0.247264908 -0.2436828296
> 23  1981-11-01  0.771663876 -0.3909929295
> 24  1981-12-01 -0.316341458 -0.4943145967
>
> Regards,
> ?Kwesi?
>


From mak.hholly at gmail.com  Mon Jan 30 15:23:44 2017
From: mak.hholly at gmail.com (greg holly)
Date: Mon, 30 Jan 2017 09:23:44 -0500
Subject: [R] lines those not started with "rs"
Message-ID: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>

Hi all;

I have a file which has about 3.000.000 lines. Most of the lines at first
column start with "rs", for example, rs10000056, rs10000076 and so on. I
would like to get the lines which do not start with "rs" . Your helps
highly appreciated.

Regards,

Greg

	[[alternative HTML version deleted]]


From rsherry8 at comcast.net  Mon Jan 30 15:36:45 2017
From: rsherry8 at comcast.net (Robert Sherry)
Date: Mon, 30 Jan 2017 09:36:45 -0500
Subject: [R] lines those not started with "rs"
In-Reply-To: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
References: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
Message-ID: <79629de8-e92b-b04b-a17b-61c7275b6290@comcast.net>

Greg,

I am assuming that your data is in a text file. R is a good tool but not 
the tool I would use for this job. The tool I would
use is grep. The following command should get you want you want:
          grep -v "^rs" <data file name>

Bob

On 1/30/2017 9:23 AM, greg holly wrote:
> Hi all;
>
> I have a file which has about 3.000.000 lines. Most of the lines at first
> column start with "rs", for example, rs10000056, rs10000076 and so on. I
> would like to get the lines which do not start with "rs" . Your helps
> highly appreciated.
>
> Regards,
>
> Greg
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mak.hholly at gmail.com  Mon Jan 30 15:44:50 2017
From: mak.hholly at gmail.com (greg holly)
Date: Mon, 30 Jan 2017 09:44:50 -0500
Subject: [R] lines those not started with "rs"
In-Reply-To: <79629de8-e92b-b04b-a17b-61c7275b6290@comcast.net>
References: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
	<79629de8-e92b-b04b-a17b-61c7275b6290@comcast.net>
Message-ID: <CAM9Qe4gTUtuPDNFyAQ=nMC1z_W4BWXJw-MfLDcubOj=g2yzXCg@mail.gmail.com>

Hi Robert;

I do appreciate your advice. Only the first column of the data is text. The
rest columns are numeric.

Regards,

Greg

On Mon, Jan 30, 2017 at 9:36 AM, Robert Sherry <rsherry8 at comcast.net> wrote:

> Greg,
>
> I am assuming that your data is in a text file. R is a good tool but not
> the tool I would use for this job. The tool I would
> use is grep. The following command should get you want you want:
>          grep -v "^rs" <data file name>
>
> Bob
>
>
> On 1/30/2017 9:23 AM, greg holly wrote:
>
>> Hi all;
>>
>> I have a file which has about 3.000.000 lines. Most of the lines at first
>> column start with "rs", for example, rs10000056, rs10000076 and so on. I
>> would like to get the lines which do not start with "rs" . Your helps
>> highly appreciated.
>>
>> Regards,
>>
>> Greg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rsherry8 at comcast.net  Mon Jan 30 15:46:51 2017
From: rsherry8 at comcast.net (Robert Sherry)
Date: Mon, 30 Jan 2017 09:46:51 -0500
Subject: [R] lines those not started with "rs"
In-Reply-To: <CAM9Qe4gTUtuPDNFyAQ=nMC1z_W4BWXJw-MfLDcubOj=g2yzXCg@mail.gmail.com>
References: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
	<79629de8-e92b-b04b-a17b-61c7275b6290@comcast.net>
	<CAM9Qe4gTUtuPDNFyAQ=nMC1z_W4BWXJw-MfLDcubOj=g2yzXCg@mail.gmail.com>
Message-ID: <37749e35-3644-1505-3208-1698010da21e@comcast.net>

then my solution should work.

Bob
On 1/30/2017 9:44 AM, greg holly wrote:
> Hi Robert;
>
> I do appreciate your advice. Only the first column of the data is 
> text. The rest columns are numeric.
>
> Regards,
>
> Greg
>
> On Mon, Jan 30, 2017 at 9:36 AM, Robert Sherry <rsherry8 at comcast.net 
> <mailto:rsherry8 at comcast.net>> wrote:
>
>     Greg,
>
>     I am assuming that your data is in a text file. R is a good tool
>     but not the tool I would use for this job. The tool I would
>     use is grep. The following command should get you want you want:
>              grep -v "^rs" <data file name>
>
>     Bob
>
>
>     On 1/30/2017 9:23 AM, greg holly wrote:
>
>         Hi all;
>
>         I have a file which has about 3.000.000 lines. Most of the
>         lines at first
>         column start with "rs", for example, rs10000056, rs10000076
>         and so on. I
>         would like to get the lines which do not start with "rs" .
>         Your helps
>         highly appreciated.
>
>         Regards,
>
>         Greg
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan 30 16:19:06 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 Jan 2017 07:19:06 -0800
Subject: [R] (no subject)
In-Reply-To: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
Message-ID: <1F7C867A-BC3F-4F1E-B8B1-28DE056BE7C7@dcn.davis.ca.us>

How you proceed depends on how consistent the data are and on what you want to do with those sets of three months after you have identified them.

One approach is to create a matrix where each row contains the values corresponding to the "second previous", "previous", and "current" months data, respectively using the embed() function. The first two rows would be incomplete because the earlier data are missing there:

d3 <- embed( dta$MEI )

with which you could compute whatever metric you wanted. For example you could compute rolling means:

dta$MEImeans <- rowMeans( d3 )

If your data have missing rows you might need to use the aggregate or merge functions instead. 

For specific layouts of data or metrics you can find specialized functions in various packages. You might want to search using the R "sos" package or Google for your analysis method of choice. 
-- 
Sent from my phone. Please excuse my brevity.

On January 30, 2017 6:11:48 AM PST, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
>Hello, I have a data with two variables nodes and index, I want to
>extract
>3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc
>to
>OND. Was wondering how to go about it. Kindly find data sample below,
>data
>is in csv format.
>Any help will be appreciated.
>
>My data sample;
>
>      era...1.    Node_freq           MEI
>1   1980-01-01 -0.389855332  0.3394196488
>2   1980-02-01 -0.728019153  0.2483738232
>3   1980-03-01 -1.992457784  0.3516954904
>4   1980-04-01  0.222760284  0.5736836269
>5   1980-05-01  0.972601798  0.6289249144
>6   1980-06-01  0.570725954  0.5736836269
>7   1980-07-01 -0.977966324  0.4120517119
>8   1980-08-01  0.056128836 -0.0104418383
>9   1980-09-01  0.987304573 -0.0687520861
>10  1980-10-01  1.188242495 -0.1403611624
>11  1980-11-01  1.693037763 -0.0963727298
>12  1980-12-01  1.173539720 -0.2539126977
>13  1981-01-01  0.423698206 -0.6140040528
>14  1981-02-01 -2.208098481 -0.5209122536
>15  1981-03-01 -0.786830252  0.1133395650
>16  1981-04-01 -0.110502611  0.3302127675
>17  1981-05-01 -1.272021820 -0.1894645290
>18  1981-06-01  0.394292656 -0.3736021538
>19  1981-07-01  1.452892441 -0.4032687711
>20  1981-08-01  0.698150002 -0.4441882433
>21  1981-09-01  0.997106423 -0.1720737534
>22  1981-10-01  0.247264908 -0.2436828296
>23  1981-11-01  0.771663876 -0.3909929295
>24  1981-12-01 -0.316341458 -0.4943145967
>
>Regards,
>?Kwesi?
>
>-- 
>Try not to become a man of success but rather a man of value-Albert
>Einstein
>
>University of Cape Coast|College of Agriculture and Natural
>Sciences|Department
>of Physics|
>Team Leader|Recycle Up! Ghana|Technology Without Borders|
>Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>Mobile: +233266173582
>Skype: quagraine_cwasi
>Twitter: @Pkdilly
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Mon Jan 30 16:19:53 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 30 Jan 2017 10:19:53 -0500
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <22671.6050.750658.33001@stat.math.ethz.ch>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
	<CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
	<CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>
	<4388a051-200f-9bbb-d02e-c6cab734019b@gmail.com>
	<22671.6050.750658.33001@stat.math.ethz.ch>
Message-ID: <CAGx1TMAR6c_vZvtHciRJvgZQDs6cvSESxkeLQWseX=6Biq2CDg@mail.gmail.com>

Duncan, thank you for locating the problem.
Martin, thank you for explaining the behavior and for the first pass
at fixing it.
With the fix, now the x-axis has ticks at all integers, and tick labels at
c(-81,-67,-53,-39,-25,-11,0,9,19,31,43,55,67,79)
This is with R-3.3.2, as I interpret your fix to be to only the
R-intro.pdf manual with no change
to the code of any of the functions.
More work has to be done to repair the example.

I recommend
plot(as.numeric(fr) ~ as.numeric(names(fr)), type="h",
xlab="Determinant", ylab="Frequency")

The slightly more obvious solution doesn't work
> plot(fr ~ as.numeric(names(fr)), type="h", xlab="Determinant", ylab="Frequency")
Error in plot.table(c(-81, -80, -79, -78, -77, -76, -75, -74, -73, -72,  :
  invalid table 'x'

## It is possible to change graphics:::Axis.table to
if (is.num) axis(side, ...)
## and that would make the x-axis for the determinant example
plot(fr, type="h", xlab="Determinant", ylab="Frequency")
## look sensible, but would
## be less appropriate for the following example.

## The current behavior of Axis.table makes sense in this example
tt <- as.table(array(c(10,20,30), dimnames=list(c(100, 120, 200))))
tt
plot(tt)

On Mon, Jan 30, 2017 at 5:38 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Sun, 29 Jan 2017 06:32:27 -0500 writes:
>
>     > On 29/01/2017 12:05 AM, Jim Lemon wrote:
>     >> Hi Richard, I think there may be something amiss in the
>     >> plot.table function. As you note, changing the class of
>     >> fr to array produces a more sensible plot, as does Bert's
>     >> "as.vector". Yet inside plot.table we find:
>     >>
>     >> plot(x0, unclass(x), ...
>     >>
>     >> and that should produce an array:
>     >>
>     >> class(unclass(fr)) [1] "array"
>     >>
>     >> The plot.table function looks like it should produce the
>     >> plot you want, but it doesn't. I think (therefore I am
>     >> probably wrong) that a 1D table is handled in the same
>     >> way as multiD table rather than being squeezed into a
>     >> vector.
>
>     > I think the issue is that Axis() is called without
>     > removing the class.  Axis.table sets ticks based on the
>     > names of the table.
>
>     > Duncan Murdoch
>
> yes indeed!  So this answers Rich Heiberger's question.
>
> The example stems from a time long before there was
> a plot.table() method, and even longer before plot.default() had
> started using  Axis() and its methods.
>
> So a much nicer example for the R-intro -- committed a few
> minutes ago -- is making use of the  plot.table() S3 method :
>
>   d <- outer(0:9, 0:9)
>   fr <- table(outer(d, d, "-"))
>   plot(fr, type="h", xlab="Determinant", ylab="Frequency")
>
> So this fulfills Rich's recommendation.
>
> Martin
>
>
>     >> On Sun, Jan 29, 2017 at 11:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>     >>> Rich:
>     >>>
>     >>> Simpler: Just lose the "table" class.
>     >>>
>     >>> plot(as.numeric(names(fr)), as.vector(fr),  type="h",
>     >>>      xlab="Determinant", ylab="Frequency")
>     >>>
>     >>> However, I'm no less puzzled by the "strange" behavior than you.
>     >>>
>     >>> In addition, it's probably worth noting that xyplot in lattice (and no
>     >>> doubt ggplot,too) does not have this problem (as I'm sure you know):
>     >>>
>     >>> xyplot(fr ~ as.numeric(names(fr)),  type="h",
>     >>>        xlab="Determinant", ylab="Frequency")
>     >>>
>     >>>
>     >>> Cheers,
>     >>> Bert
>     >>> Bert Gunter
>     >>>
>     >>> "The trouble with having an open mind is that people keep coming along
>     >>> and sticking things into it."
>     >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>     >>>
>     >>>
>     >>> On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>     >>>> ## This example is from R-intro.pdf page 21 (R-3.3.2)
>     >>>>
>     >>>> d <- outer(0:9, 0:9)
>     >>>> fr <- table(outer(d, d, "-"))
>     >>>> plot(as.numeric(names(fr)), fr, type="h",
>     >>>>      xlab="Determinant", ylab="Frequency")
>     >>>> ## The y-axis tick marks are at c(-21,24,65).
>     >>>> ## This seems to be because class(fr) == "table"
>     >>>>
>     >>>> ## Switching the class to array gives the more appropriate
>     >>>> ## y-axis ticks at seq(0,500,100) .
>     >>>>
>     >>>> fr.array <- fr
>     >>>> class(fr.array) <- "array"
>     >>>> plot(as.numeric(names(fr)), fr.array, type="h",
>     >>>>      xlab="Determinant", ylab="Frequency")
>     >>>>
>     >>>>
>     >>>> ## I have a question and a recommendation.
>     >>>> ## Question:
>     >>>> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
>     >>>> ##
>     >>>> ## Recommendation:
>     >>>> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
>     >>>>
>     >>>> ## Rich
>     >>>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Jan 30 16:37:55 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 30 Jan 2017 15:37:55 +0000
Subject: [R] (no subject)
In-Reply-To: <1F7C867A-BC3F-4F1E-B8B1-28DE056BE7C7@dcn.davis.ca.us>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
	<1F7C867A-BC3F-4F1E-B8B1-28DE056BE7C7@dcn.davis.ca.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A13AB8@SRVEXCHCM301.precheza.cz>

Hi

Probably just a small correction.

d3 <- embed( dta$MEI, 3)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> Newmiller
> Sent: Monday, January 30, 2017 4:19 PM
> To: r-help at r-project.org; Kwesi Quagraine <starskykwesi at gmail.com>
> Subject: Re: [R] (no subject)
>
> How you proceed depends on how consistent the data are and on what you
> want to do with those sets of three months after you have identified them.
>
> One approach is to create a matrix where each row contains the values
> corresponding to the "second previous", "previous", and "current" months
> data, respectively using the embed() function. The first two rows would be
> incomplete because the earlier data are missing there:
>
> d3 <- embed( dta$MEI )
>
> with which you could compute whatever metric you wanted. For example
> you could compute rolling means:
>
> dta$MEImeans <- rowMeans( d3 )
>
> If your data have missing rows you might need to use the aggregate or
> merge functions instead.
>
> For specific layouts of data or metrics you can find specialized functions in
> various packages. You might want to search using the R "sos" package or
> Google for your analysis method of choice.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 30, 2017 6:11:48 AM PST, Kwesi Quagraine
> <starskykwesi at gmail.com> wrote:
> >Hello, I have a data with two variables nodes and index, I want to
> >extract
> >3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc
> >to OND. Was wondering how to go about it. Kindly find data sample
> >below, data is in csv format.
> >Any help will be appreciated.
> >
> >My data sample;
> >
> >      era...1.    Node_freq           MEI
> >1   1980-01-01 -0.389855332  0.3394196488
> >2   1980-02-01 -0.728019153  0.2483738232
> >3   1980-03-01 -1.992457784  0.3516954904
> >4   1980-04-01  0.222760284  0.5736836269
> >5   1980-05-01  0.972601798  0.6289249144
> >6   1980-06-01  0.570725954  0.5736836269
> >7   1980-07-01 -0.977966324  0.4120517119
> >8   1980-08-01  0.056128836 -0.0104418383
> >9   1980-09-01  0.987304573 -0.0687520861
> >10  1980-10-01  1.188242495 -0.1403611624
> >11  1980-11-01  1.693037763 -0.0963727298
> >12  1980-12-01  1.173539720 -0.2539126977
> >13  1981-01-01  0.423698206 -0.6140040528
> >14  1981-02-01 -2.208098481 -0.5209122536
> >15  1981-03-01 -0.786830252  0.1133395650
> >16  1981-04-01 -0.110502611  0.3302127675
> >17  1981-05-01 -1.272021820 -0.1894645290
> >18  1981-06-01  0.394292656 -0.3736021538
> >19  1981-07-01  1.452892441 -0.4032687711
> >20  1981-08-01  0.698150002 -0.4441882433
> >21  1981-09-01  0.997106423 -0.1720737534
> >22  1981-10-01  0.247264908 -0.2436828296
> >23  1981-11-01  0.771663876 -0.3909929295
> >24  1981-12-01 -0.316341458 -0.4943145967
> >
> >Regards,
> >?Kwesi?
> >
> >--
> >Try not to become a man of success but rather a man of value-Albert
> >Einstein
> >
> >University of Cape Coast|College of Agriculture and Natural
> >Sciences|Department
> >of Physics|
> >Team Leader|Recycle Up! Ghana|Technology Without Borders| Other
> emails:
> >kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> >Mobile: +233266173582
> >Skype: quagraine_cwasi
> >Twitter: @Pkdilly
> >
> >     [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dwinsemius at comcast.net  Mon Jan 30 16:52:46 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Jan 2017 07:52:46 -0800
Subject: [R] Challenge extracting months
In-Reply-To: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
Message-ID: <25F2ED69-5767-4BBB-BEEE-95506FC31357@comcast.net>


> On Jan 30, 2017, at 4:53 AM, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
> 
> Hello, I have a data with two variables nodes and index, I want to extract
> 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
> OND. Was wondering how to go about it. Kindly find attached the data as csv.
> Any help will be appreciated.

When you desired for csv files to be distributed to the list you need to rename the file so it has a txt extension. Then you mail client will lable in a manner that the mailserver recognizes as MIME-text.

-- 
David.
> 
> Regards,
> ?Kwesi?
> 
> -- 
> 


David Winsemius
Alameda, CA, USA


From maechler at stat.math.ethz.ch  Mon Jan 30 16:59:33 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 30 Jan 2017 16:59:33 +0100
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <CAGx1TMAR6c_vZvtHciRJvgZQDs6cvSESxkeLQWseX=6Biq2CDg@mail.gmail.com>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
	<CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
	<CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>
	<4388a051-200f-9bbb-d02e-c6cab734019b@gmail.com>
	<22671.6050.750658.33001@stat.math.ethz.ch>
	<CAGx1TMAR6c_vZvtHciRJvgZQDs6cvSESxkeLQWseX=6Biq2CDg@mail.gmail.com>
Message-ID: <22671.25317.335078.641793@stat.math.ethz.ch>

>>>>> Richard M Heiberger <rmh at temple.edu>
>>>>>     on Mon, 30 Jan 2017 10:19:53 -0500 writes:

    > Duncan, thank you for locating the problem.
    > Martin, thank you for explaining the behavior and for the first pass
    > at fixing it.


    > With the fix, now the x-axis has ticks at all integers, and tick labels at
    > c(-81,-67,-53,-39,-25,-11,0,9,19,31,43,55,67,79)

Note that *which* tick labels are shown depends quite a bit
on your graphics window width, your font sizes etc !

    > This is with R-3.3.2, as I interpret your fix to be to only the
    > R-intro.pdf manual with no change
    > to the code of any of the functions.

That's correct.  If this is about improving any of
the base graphics functions,  there's the  R-devel mailing list
and the bugzilla repository for "wishes"... rather than the
R-help list.

    > More work has to be done to repair the example.

I strongly disagree:
The example (which does not even need a 'type = "h"', and no longer
uses it) now mentions that the plot.factor method is used.
... and I do like its graphics output, given the simplicity of
the plot() function call.

Code as the one below may be preferable in some cases, but not
there in the   "Introduction to R".


    > I recommend
    > plot(as.numeric(fr) ~ as.numeric(names(fr)), type="h",
    > xlab="Determinant", ylab="Frequency")

    > The slightly more obvious solution doesn't work
    >> plot(fr ~ as.numeric(names(fr)), type="h", xlab="Determinant", ylab="Frequency")
    > Error in plot.table(c(-81, -80, -79, -78, -77, -76, -75, -74, -73, -72,  :
    > invalid table 'x'

    > ## It is possible to change graphics:::Axis.table to
    > if (is.num) axis(side, ...)
    > ## and that would make the x-axis for the determinant example
    > plot(fr, type="h", xlab="Determinant", ylab="Frequency")
    > ## look sensible, but would
    > ## be less appropriate for the following example.

    > ## The current behavior of Axis.table makes sense in this example
    > tt <- as.table(array(c(10,20,30), dimnames=list(c(100, 120, 200))))
    > tt
    > plot(tt)

Indeed.  I doubt we would want to change Axis.table()
just because of examples like the determinant one....
(and then again: such considerations would be part of a new thread on R-devel...)

Martin Maechler


    > On Mon, Jan 30, 2017 at 5:38 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
    >>>>>>> on Sun, 29 Jan 2017 06:32:27 -0500 writes:
    >> 
    >> > On 29/01/2017 12:05 AM, Jim Lemon wrote:
    >> >> Hi Richard, I think there may be something amiss in the
    >> >> plot.table function. As you note, changing the class of
    >> >> fr to array produces a more sensible plot, as does Bert's
    >> >> "as.vector". Yet inside plot.table we find:
    >> >>
    >> >> plot(x0, unclass(x), ...
    >> >>
    >> >> and that should produce an array:
    >> >>
    >> >> class(unclass(fr)) [1] "array"
    >> >>
    >> >> The plot.table function looks like it should produce the
    >> >> plot you want, but it doesn't. I think (therefore I am
    >> >> probably wrong) that a 1D table is handled in the same
    >> >> way as multiD table rather than being squeezed into a
    >> >> vector.
    >> 
    >> > I think the issue is that Axis() is called without
    >> > removing the class.  Axis.table sets ticks based on the
    >> > names of the table.
    >> 
    >> > Duncan Murdoch
    >> 
    >> yes indeed!  So this answers Rich Heiberger's question.
    >> 
    >> The example stems from a time long before there was
    >> a plot.table() method, and even longer before plot.default() had
    >> started using  Axis() and its methods.
    >> 
    >> So a much nicer example for the R-intro -- committed a few
    >> minutes ago -- is making use of the  plot.table() S3 method :
    >> 
    >> d <- outer(0:9, 0:9)
    >> fr <- table(outer(d, d, "-"))
    >> plot(fr, type="h", xlab="Determinant", ylab="Frequency")
    >> 
    >> So this fulfills Rich's recommendation.
    >> 
    >> Martin
    >> 
    >> 
    >> >> On Sun, Jan 29, 2017 at 11:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >> >>> Rich:
    >> >>>
    >> >>> Simpler: Just lose the "table" class.
    >> >>>
    >> >>> plot(as.numeric(names(fr)), as.vector(fr),  type="h",
    >> >>>      xlab="Determinant", ylab="Frequency")
    >> >>>
    >> >>> However, I'm no less puzzled by the "strange" behavior than you.
    >> >>>
    >> >>> In addition, it's probably worth noting that xyplot in lattice (and no
    >> >>> doubt ggplot,too) does not have this problem (as I'm sure you know):
    >> >>>
    >> >>> xyplot(fr ~ as.numeric(names(fr)),  type="h",
    >> >>>        xlab="Determinant", ylab="Frequency")
    >> >>>
    >> >>>
    >> >>> Cheers,
    >> >>> Bert
    >> >>> Bert Gunter
    >> >>>
    >> >>> "The trouble with having an open mind is that people keep coming along
    >> >>> and sticking things into it."
    >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    >> >>>
    >> >>>
    >> >>> On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
    >> >>>> ## This example is from R-intro.pdf page 21 (R-3.3.2)
    >> >>>>
    >> >>>> d <- outer(0:9, 0:9)
    >> >>>> fr <- table(outer(d, d, "-"))
    >> >>>> plot(as.numeric(names(fr)), fr, type="h",
    >> >>>>      xlab="Determinant", ylab="Frequency")
    >> >>>> ## The y-axis tick marks are at c(-21,24,65).
    >> >>>> ## This seems to be because class(fr) == "table"
    >> >>>>
    >> >>>> ## Switching the class to array gives the more appropriate
    >> >>>> ## y-axis ticks at seq(0,500,100) .
    >> >>>>
    >> >>>> fr.array <- fr
    >> >>>> class(fr.array) <- "array"
    >> >>>> plot(as.numeric(names(fr)), fr.array, type="h",
    >> >>>>      xlab="Determinant", ylab="Frequency")
    >> >>>>
    >> >>>>
    >> >>>> ## I have a question and a recommendation.
    >> >>>> ## Question:
    >> >>>> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
    >> >>>> ##
    >> >>>> ## Recommendation:
    >> >>>> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
    >> >>>>
    >> >>>> ## Rich
    >> >>>>
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.


From erich.subs at neuwirth.priv.at  Mon Jan 30 17:01:29 2017
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Mon, 30 Jan 2017 17:01:29 +0100
Subject: [R] (no subject)
In-Reply-To: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
Message-ID: <82783029-476C-4825-93C3-6CBD97AB0776@neuwirth.priv.at>

Using dplyr and magrittr you could do the following


-=-=-=-=-
library(dplyr)
library(magrittr)

mydata  <- read.table(text="
     era...1.    Node_freq           MEI
1   1980-01-01 -0.389855332  0.3394196488
2   1980-02-01 -0.728019153  0.2483738232
3   1980-03-01 -1.992457784  0.3516954904
4   1980-04-01  0.222760284  0.5736836269
5   1980-05-01  0.972601798  0.6289249144
6   1980-06-01  0.570725954  0.5736836269
7   1980-07-01 -0.977966324  0.4120517119
8   1980-08-01  0.056128836 -0.0104418383
9   1980-09-01  0.987304573 -0.0687520861
10  1980-10-01  1.188242495 -0.1403611624
11  1980-11-01  1.693037763 -0.0963727298
12  1980-12-01  1.173539720 -0.2539126977
13  1981-01-01  0.423698206 -0.6140040528
14  1981-02-01 -2.208098481 -0.5209122536
15  1981-03-01 -0.786830252  0.1133395650
16  1981-04-01 -0.110502611  0.3302127675
17  1981-05-01 -1.272021820 -0.1894645290
18  1981-06-01  0.394292656 -0.3736021538
19  1981-07-01  1.452892441 -0.4032687711
20  1981-08-01  0.698150002 -0.4441882433
21  1981-09-01  0.997106423 -0.1720737534
22  1981-10-01  0.247264908 -0.2436828296
23  1981-11-01  0.771663876 -0.3909929295
24  1981-12-01 -0.316341458 -0.4943145967
") 

mydata %<>% mutate(Node_freq2=lead(Node_freq,1),Node_freq3=lead(Node_freq,2),MEI1=lead(MEI,1),MEI2=lead(MEI,3)) %>%
  select(1,2,4,5,3,6,7)

-=-==-=

check if mydata ist what you want


From marc_grt at yahoo.fr  Mon Jan 30 18:19:02 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 30 Jan 2017 18:19:02 +0100
Subject: [R] g parameter for deltaMethod() as a function
Message-ID: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>

Hi everyone,

I try to use the Default S3 method DeltaMethod() from car package, but I 
have some problems when I try to use a function as the "g" parameter. I 
don't know if it is possible anyway. I hope that you could tell me:

Here an example from the help of deltaMethod(). It works and I 
understand well (I think at least !).

library(car)
m1 <- lm(time ~ t1 + t2, data = Transact)
deltaMethod(coef(m1), "t1/t2", vcov.=vcov(m1))

###############

I would like do the same with a function instead of "t1/t2":

try_g <- function(...) {
   par <- list(...)
   return(par$t1/par$t2)
}

try_g(t1=1, t2=2)
deltaMethod(coef(m1), "try_g", vcov.=vcov(m1))

But I get an error:

Error in as.data.frame.default(x[[i]], optional = TRUE) :
   cannot coerce class ""function"" to a data.frame

If someone could give me the solution... or tell me if it is impossible !

Thanks

Marc

PS. In fine I would like using deltaMethod() to produce a confidence 
interval after fitting a model using ML with optim.


From starskykwesi at gmail.com  Mon Jan 30 18:26:22 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Mon, 30 Jan 2017 19:26:22 +0200
Subject: [R] (no subject)
In-Reply-To: <82783029-476C-4825-93C3-6CBD97AB0776@neuwirth.priv.at>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
	<82783029-476C-4825-93C3-6CBD97AB0776@neuwirth.priv.at>
Message-ID: <CAGD2cKfH8qOuFa99mz-K527nMEr2f5BNYR4r7-yMrW0R5AFurQ@mail.gmail.com>

Hello Eric, thanks for the code, it seems to do something closer to what I
want. I generate JFM, FMA and so on, but it does not create the DJF at the
beginning. Any thoughts on that?

Kwesi

On Mon, Jan 30, 2017 at 6:01 PM, Erich Subscriptions <
erich.subs at neuwirth.priv.at> wrote:

> Using dplyr and magrittr you could do the following
>
>
> -=-=-=-=-
> library(dplyr)
> library(magrittr)
>
> mydata  <- read.table(text="
>      era...1.    Node_freq           MEI
> 1   1980-01-01 -0.389855332  0.3394196488
> 2 1980-02-01 -0.728019153  0.2483738232
> 3   1980-03-01 -1.992457784  0.3516954904
> 4   1980-04-01  0.222760284  0.5736836269
> 5   1980-05-01  0.972601798  0.6289249144
> 6   1980-06-01  0.570725954  0.5736836269
> 7   1980-07-01 -0.977966324  0.4120517119
> 8   1980-08-01  0.056128836 -0.0104418383
> 9   1980-09-01  0.987304573 -0.0687520861
> 10  1980-10-01  1.188242495 -0.1403611624
> 11  1980-11-01  1.693037763 -0.0963727298
> 12  1980-12-01  1.173539720 -0.2539126977
> 13  1981-01-01  0.423698206 -0.6140040528
> 14  1981-02-01 -2.208098481 -0.5209122536
> 15  1981-03-01 -0.786830252  0.1133395650
> 16  1981-04-01 -0.110502611  0.3302127675
> 17  1981-05-01 -1.272021820 -0.1894645290
> 18  1981-06-01  0.394292656 -0.3736021538
> 19  1981-07-01  1.452892441 -0.4032687711
> 20  1981-08-01  0.698150002 -0.4441882433
> 21  1981-09-01  0.997106423 -0.1720737534
> 22  1981-10-01  0.247264908 -0.2436828296
> 23  1981-11-01  0.771663876 -0.3909929295
> 24  1981-12-01 -0.316341458 -0.4943145967
> ")
>
> mydata %<>% mutate(Node_freq2=lead(Node_freq,1),Node_freq3=lead(Node_
> freq,2),MEI1=lead(MEI,1),MEI2=lead(MEI,3)) %>%
>   select(1,2,4,5,3,6,7)
>
> -=-==-=
>
> check if mydata ist what you want
>
>
>
>
>
>


-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Mon Jan 30 18:28:52 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Mon, 30 Jan 2017 19:28:52 +0200
Subject: [R] (no subject)
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A13AB8@SRVEXCHCM301.precheza.cz>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
	<1F7C867A-BC3F-4F1E-B8B1-28DE056BE7C7@dcn.davis.ca.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A13AB8@SRVEXCHCM301.precheza.cz>
Message-ID: <CAGD2cKdWCmEeSRZ-oP8V-458YxUi90anx_xFpYGxJAYakDxrsQ@mail.gmail.com>

Upon trying this method, I get an error ;

Error in `$<-.data.frame`(`*tmp*`, "MEImeans", value =
c(0.313162987462034,  :
  replacement has 442 rows, data has 444

Any thoughts?

Kwesi

On Mon, Jan 30, 2017 at 5:37 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Probably just a small correction.
>
> d3 <- embed( dta$MEI, 3)
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> > Newmiller
> > Sent: Monday, January 30, 2017 4:19 PM
> > To: r-help at r-project.org; Kwesi Quagraine <starskykwesi at gmail.com>
> > Subject: Re: [R] (no subject)
> >
> > How you proceed depends on how consistent the data are and on what you
> > want to do with those sets of three months after you have identified
> them.
> >
> > One approach is to create a matrix where each row contains the values
> > corresponding to the "second previous", "previous", and "current" months
> > data, respectively using the embed() function. The first two rows would
> be
> > incomplete because the earlier data are missing there:
> >
> > d3 <- embed( dta$MEI )
> >
> > with which you could compute whatever metric you wanted. For example
> > you could compute rolling means:
> >
> > dta$MEImeans <- rowMeans( d3 )
> >
> > If your data have missing rows you might need to use the aggregate or
> > merge functions instead.
> >
> > For specific layouts of data or metrics you can find specialized
> functions in
> > various packages. You might want to search using the R "sos" package or
> > Google for your analysis method of choice.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On January 30, 2017 6:11:48 AM PST, Kwesi Quagraine
> > <starskykwesi at gmail.com> wrote:
> > >Hello, I have a data with two variables nodes and index, I want to
> > >extract
> > >3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc
> > >to OND. Was wondering how to go about it. Kindly find data sample
> > >below, data is in csv format.
> > >Any help will be appreciated.
> > >
> > >My data sample;
> > >
> > >      era...1.    Node_freq           MEI
> > >1   1980-01-01 -0.389855332  0.3394196488
> > >2 1980-02-01 -0.728019153  0.2483738232
> > >3   1980-03-01 -1.992457784  0.3516954904
> > >4   1980-04-01  0.222760284  0.5736836269
> > >5   1980-05-01  0.972601798  0.6289249144
> > >6   1980-06-01  0.570725954  0.5736836269
> > >7   1980-07-01 -0.977966324  0.4120517119
> > >8   1980-08-01  0.056128836 -0.0104418383
> > >9   1980-09-01  0.987304573 -0.0687520861
> > >10  1980-10-01  1.188242495 -0.1403611624
> > >11  1980-11-01  1.693037763 -0.0963727298
> > >12  1980-12-01  1.173539720 -0.2539126977
> > >13  1981-01-01  0.423698206 -0.6140040528
> > >14  1981-02-01 -2.208098481 -0.5209122536
> > >15  1981-03-01 -0.786830252  0.1133395650
> > >16  1981-04-01 -0.110502611  0.3302127675
> > >17  1981-05-01 -1.272021820 -0.1894645290
> > >18  1981-06-01  0.394292656 -0.3736021538
> > >19  1981-07-01  1.452892441 -0.4032687711
> > >20  1981-08-01  0.698150002 -0.4441882433
> > >21  1981-09-01  0.997106423 -0.1720737534
> > >22  1981-10-01  0.247264908 -0.2436828296
> > >23  1981-11-01  0.771663876 -0.3909929295
> > >24  1981-12-01 -0.316341458 -0.4943145967
> > >
> > >Regards,
> > >?Kwesi?
> > >
> > >--
> > >Try not to become a man of success but rather a man of value-Albert
> > >Einstein
> > >
> > >University of Cape Coast|College of Agriculture and Natural
> > >Sciences|Department
> > >of Physics|
> > >Team Leader|Recycle Up! Ghana|Technology Without Borders| Other
> > emails:
> > >kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> > >Mobile: +233266173582
> > >Skype: quagraine_cwasi
> > >Twitter: @Pkdilly
> > >
> > >     [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Mon Jan 30 18:37:27 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Mon, 30 Jan 2017 19:37:27 +0200
Subject: [R] (no subject)
In-Reply-To: <6c0fd124-4dcb-08e4-2a1c-2acbf34f1f55@comcast.net>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
	<6c0fd124-4dcb-08e4-2a1c-2acbf34f1f55@comcast.net>
Message-ID: <CAGD2cKe6p-=C3YTn5hePmU1BJy2nCvhjAgdrMv=W5iNaJ21gUQ@mail.gmail.com>

Thanks for your suggestion. I am much grateful.

Kwesi

On Mon, Jan 30, 2017 at 4:23 PM, Robert Sherry <rsherry8 at comcast.net> wrote:

> Here is one thought. Assign each month a value of 0, 1 or 2. Then do a
> simple linear regression analysis where the value of the month
> is the independent variable. You can also do multiple linear regression
> with the value you assigned to the month plus the other factors that
> you believe are causing a change to your data. Time is the one that comes
> to my mind. You can do this with the standard R function lm.
>
> I hope this helps.
>
> Bob
>
>
> On 1/30/2017 9:11 AM, Kwesi Quagraine wrote:
>
>> Hello, I have a data with two variables nodes and index, I want to extract
>> 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
>> OND. Was wondering how to go about it. Kindly find data sample below, data
>> is in csv format.
>> Any help will be appreciated.
>>
>> My data sample;
>>
>>        era...1.    Node_freq           MEI
>> 1   1980-01-01 -0.389855332  0.3394196488
>> 2 1980-02-01 -0.728019153  0.2483738232
>> 3 1980-03-01 -1.992457784  0.3516954904
>> 4 1980-04-01 0.222760284  0.5736836269
>> 5 1980-05-01 0.972601798 0.6289249144
>> 6 1980-06-01 0.570725954 0.5736836269
>> 7 1980-07-01 -0.977966324  0.4120517119
>> 8 1980-08-01 0.056128836 -0.0104418383
>> 9 1980-09-01 0.987304573 -0.0687520861
>> 10  1980-10-01  1.188242495 -0.1403611624
>> 11  1980-11-01  1.693037763 -0.0963727298
>> 12 1980-12-01 1.173539720 -0.2539126977
>> 13 1981-01-01 0.423698206 -0.6140040528
>> 14 1981-02-01 -2.208098481 -0.5209122536
>> 15 1981-03-01 -0.786830252 0.1133395650
>> 16 1981-04-01 -0.110502611  0.3302127675
>> 17 1981-05-01 -1.272021820 -0.1894645290
>> 18 1981-06-01 0.394292656 -0.3736021538
>> 19 1981-07-01 1.452892441 -0.4032687711
>> 20  1981-08-01  0.698150002 -0.4441882433
>> 21  1981-09-01  0.997106423 -0.1720737534
>> 22  1981-10-01  0.247264908 -0.2436828296
>> 23  1981-11-01  0.771663876 -0.3909929295
>> 24  1981-12-01 -0.316341458 -0.4943145967
>>
>> Regards,
>> ?Kwesi?
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Mon Jan 30 18:39:58 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Mon, 30 Jan 2017 19:39:58 +0200
Subject: [R] Challenge extracting months
In-Reply-To: <25F2ED69-5767-4BBB-BEEE-95506FC31357@comcast.net>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<25F2ED69-5767-4BBB-BEEE-95506FC31357@comcast.net>
Message-ID: <CAGD2cKd76GYPXwbf3juhTU+jHZ=4nykjTqLguopJ=6JiWL_OKQ@mail.gmail.com>

Well noted David. Thanks

Kwesi

On Mon, Jan 30, 2017 at 5:52 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jan 30, 2017, at 4:53 AM, Kwesi Quagraine <starskykwesi at gmail.com>
> wrote:
> >
> > Hello, I have a data with two variables nodes and index, I want to
> extract
> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
> > OND. Was wondering how to go about it. Kindly find attached the data as
> csv.
> > Any help will be appreciated.
>
> When you desired for csv files to be distributed to the list you need to
> rename the file so it has a txt extension. Then you mail client will lable
> in a manner that the mailserver recognizes as MIME-text.
>
> --
> David.
> >
> > Regards,
> > ?Kwesi?
> >
> > --
> >
>
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Jan 30 19:04:38 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 30 Jan 2017 18:04:38 +0000
Subject: [R] g parameter for deltaMethod() as a function
In-Reply-To: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>
References: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365E1F70@FHSDB2D11-2.csu.mcmaster.ca>

Dear Marc,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
> Girondot via R-help
> Sent: Monday, January 30, 2017 12:19 PM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] g parameter for deltaMethod() as a function
> 
> Hi everyone,
> 
> I try to use the Default S3 method DeltaMethod() from car package, but I
> have some problems when I try to use a function as the "g" parameter. I
> don't know if it is possible anyway. I hope that you could tell me:

I don't see how that would work. From ?deltaMethod: "g [the second argument]: A quoted string that is the function of the parameter estimates to be evaluated; see the details below."

A possible solution would be to write a wrapper function that prepares a proper call to deltaMethod().

I hope this helps,
 John

--------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox


> 
> Here an example from the help of deltaMethod(). It works and I
> understand well (I think at least !).
> 
> library(car)
> m1 <- lm(time ~ t1 + t2, data = Transact) deltaMethod(coef(m1), "t1/t2",
> vcov.=vcov(m1))
> 
> ###############
> 
> I would like do the same with a function instead of "t1/t2":
> 
> try_g <- function(...) {
>    par <- list(...)
>    return(par$t1/par$t2)
> }
> 
> try_g(t1=1, t2=2)
> deltaMethod(coef(m1), "try_g", vcov.=vcov(m1))
> 
> But I get an error:
> 
> Error in as.data.frame.default(x[[i]], optional = TRUE) :
>    cannot coerce class ""function"" to a data.frame
> 
> If someone could give me the solution... or tell me if it is impossible
> !
> 
> Thanks
> 
> Marc
> 
> PS. In fine I would like using deltaMethod() to produce a confidence
> interval after fitting a model using ML with optim.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Mon Jan 30 19:30:43 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 30 Jan 2017 19:30:43 +0100
Subject: [R] g parameter for deltaMethod() as a function
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365E1F70@FHSDB2D11-2.csu.mcmaster.ca>
References: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>
	<ACD1644AA6C67E4FBD0C350625508EC8365E1F70@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <b512a5c6-6fa4-59ee-f843-eb1fe8d5c674@yahoo.fr>

Le 30/01/2017 ? 19:04, Fox, John a ?crit :
>> Hi everyone,
>>
>> I try to use the Default S3 method DeltaMethod() from car package, but I
>> have some problems when I try to use a function as the "g" parameter. I
>> don't know if it is possible anyway. I hope that you could tell me:
> I don't see how that would work. From ?deltaMethod: "g [the second argument]: A quoted string that is the function of the parameter estimates to be evaluated; see the details below."
>
> A possible solution would be to write a wrapper function that prepares a proper call to deltaMethod().

Hi John,

This is exactly what I try to do: a wrapper (I forget that name in 
English !).

I have made some progress to do a wrapper function:

try_g <- function(...) {
   par <- list(...)
   return(par$t1/par$t2)
}

try_g(t1=1, t2=2)
deltaMethod(coef(m1), "try_g(t1, t2)", vcov.=vcov(m1))

The wrapper function try_g is accepted now, but I get an error because 
deltaMethod() tried to do symbolic derivative:

 > deltaMethod(coef(m1), "try_g(t1, t2)", vcov.=vcov(m1))
Error in D(g, names(para)[i]) :
   La fonction 'try_g' n'est pas dans la table des d?riv?es 
(translation: The function 'try_g' is not in the table of derivative 
functions).

I was hopping that numeric approximation of derivative (example 
numDeriv::grad() or deriv() ) could be used, but it is not the case.

Thanks

Marc


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan 30 19:35:02 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 Jan 2017 10:35:02 -0800
Subject: [R] (no subject)
In-Reply-To: <CAGD2cKdWCmEeSRZ-oP8V-458YxUi90anx_xFpYGxJAYakDxrsQ@mail.gmail.com>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
	<1F7C867A-BC3F-4F1E-B8B1-28DE056BE7C7@dcn.davis.ca.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A13AB8@SRVEXCHCM301.precheza.cz>
	<CAGD2cKdWCmEeSRZ-oP8V-458YxUi90anx_xFpYGxJAYakDxrsQ@mail.gmail.com>
Message-ID: <5D009706-C2CD-4095-A098-84806A06818B@dcn.davis.ca.us>

Try

d3 <- embed( c( NA, NA, dta$MEI ), 3)

-- 
Sent from my phone. Please excuse my brevity.

On January 30, 2017 9:28:52 AM PST, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
>Upon trying this method, I get an error ;
>
>Error in `$<-.data.frame`(`*tmp*`, "MEImeans", value =
>c(0.313162987462034,  :
>  replacement has 442 rows, data has 444
>
>Any thoughts?
>
>Kwesi
>
>On Mon, Jan 30, 2017 at 5:37 PM, PIKAL Petr <petr.pikal at precheza.cz>
>wrote:
>
>> Hi
>>
>> Probably just a small correction.
>>
>> d3 <- embed( dta$MEI, 3)
>>
>> Cheers
>> Petr
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Jeff
>> > Newmiller
>> > Sent: Monday, January 30, 2017 4:19 PM
>> > To: r-help at r-project.org; Kwesi Quagraine <starskykwesi at gmail.com>
>> > Subject: Re: [R] (no subject)
>> >
>> > How you proceed depends on how consistent the data are and on what
>you
>> > want to do with those sets of three months after you have
>identified
>> them.
>> >
>> > One approach is to create a matrix where each row contains the
>values
>> > corresponding to the "second previous", "previous", and "current"
>months
>> > data, respectively using the embed() function. The first two rows
>would
>> be
>> > incomplete because the earlier data are missing there:
>> >
>> > d3 <- embed( dta$MEI )
>> >
>> > with which you could compute whatever metric you wanted. For
>example
>> > you could compute rolling means:
>> >
>> > dta$MEImeans <- rowMeans( d3 )
>> >
>> > If your data have missing rows you might need to use the aggregate
>or
>> > merge functions instead.
>> >
>> > For specific layouts of data or metrics you can find specialized
>> functions in
>> > various packages. You might want to search using the R "sos"
>package or
>> > Google for your analysis method of choice.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On January 30, 2017 6:11:48 AM PST, Kwesi Quagraine
>> > <starskykwesi at gmail.com> wrote:
>> > >Hello, I have a data with two variables nodes and index, I want to
>> > >extract
>> > >3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA
>etc
>> > >to OND. Was wondering how to go about it. Kindly find data sample
>> > >below, data is in csv format.
>> > >Any help will be appreciated.
>> > >
>> > >My data sample;
>> > >
>> > >      era...1.    Node_freq           MEI
>> > >1   1980-01-01 -0.389855332  0.3394196488
>> > >2 1980-02-01 -0.728019153  0.2483738232
>> > >3   1980-03-01 -1.992457784  0.3516954904
>> > >4   1980-04-01  0.222760284  0.5736836269
>> > >5   1980-05-01  0.972601798  0.6289249144
>> > >6   1980-06-01  0.570725954  0.5736836269
>> > >7   1980-07-01 -0.977966324  0.4120517119
>> > >8   1980-08-01  0.056128836 -0.0104418383
>> > >9   1980-09-01  0.987304573 -0.0687520861
>> > >10  1980-10-01  1.188242495 -0.1403611624
>> > >11  1980-11-01  1.693037763 -0.0963727298
>> > >12  1980-12-01  1.173539720 -0.2539126977
>> > >13  1981-01-01  0.423698206 -0.6140040528
>> > >14  1981-02-01 -2.208098481 -0.5209122536
>> > >15  1981-03-01 -0.786830252  0.1133395650
>> > >16  1981-04-01 -0.110502611  0.3302127675
>> > >17  1981-05-01 -1.272021820 -0.1894645290
>> > >18  1981-06-01  0.394292656 -0.3736021538
>> > >19  1981-07-01  1.452892441 -0.4032687711
>> > >20  1981-08-01  0.698150002 -0.4441882433
>> > >21  1981-09-01  0.997106423 -0.1720737534
>> > >22  1981-10-01  0.247264908 -0.2436828296
>> > >23  1981-11-01  0.771663876 -0.3909929295
>> > >24  1981-12-01 -0.316341458 -0.4943145967
>> > >
>> > >Regards,
>> > >?Kwesi?
>> > >
>> > >--
>> > >Try not to become a man of success but rather a man of
>value-Albert
>> > >Einstein
>> > >
>> > >University of Cape Coast|College of Agriculture and Natural
>> > >Sciences|Department
>> > >of Physics|
>> > >Team Leader|Recycle Up! Ghana|Technology Without Borders| Other
>> > emails:
>> > >kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> > >Mobile: +233266173582
>> > >Skype: quagraine_cwasi
>> > >Twitter: @Pkdilly
>> > >
>> > >     [[alternative HTML version deleted]]
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and
>are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and
>its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of
>the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering
>into a
>> contract in any time, for any reason, and without stating any
>reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer)
>excludes
>> any acceptance of the offer on the part of the recipient containing
>any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded
>only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such
>authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization
>is
>> known to the recipient of the person represented by the recipient.
>>


From duncanlj at mcmaster.ca  Mon Jan 30 18:18:03 2017
From: duncanlj at mcmaster.ca (Duncan, Laura)
Date: Mon, 30 Jan 2017 17:18:03 +0000
Subject: [R] metafor rma.mv weights questions
Message-ID: <31A98C8B8E62D84982441B63A46937D76CEDCF95@FHSDB2D11-1.csu.mcmaster.ca>

Hi there, 

Question:
Does the rma.mv command in metafor automically adjust the weights to account for multiple effect sizes within study or do these weights need to manually calculated and applied?

Details:
In setting up a multilevel meta-analysis and meta-regression with multiple effect sizes within studies, I have seen the suggestion to adjust the weights according to Hedges, Tipton, & Johnson (suggestion made at 24.33mins in this tutorial https://www.youtube.com/watch?v=rJjeRRf23L8) using:
 Wij=1/Kj*mean V.j
I am wondering if the data is structured hierarchically and the random effects for each level specified correctly, does the rma.mv command automatically adjust the weights in this way? Another way to ask this question is - what are the default weights used by rma.mv when there are multiple estimates within studies? 

Thanks
Laura

Laura Duncan, M.A.
Research Coordinator
Offord Centre for Child Studies 
McMaster University

Tel: 905 525 9140 x21504
Fax: 905 574 6665
duncanlj at mcmaster.ca
ontariochildhealthstudy.ca
offordcentre.com

Mailing Address ????????????????????????????????????????????? Courier Address
1280 Main St. W. MIP 201A?????????????????????????? 175 Longwood Rd. S. MIP 201A
Hamilton, Ontario L8S 4K1 ??????????????????????????? Hamilton, Ontario L8P 0A1


From m.bickis at sasktel.net  Mon Jan 30 18:29:08 2017
From: m.bickis at sasktel.net (Mik Bickis)
Date: Mon, 30 Jan 2017 11:29:08 -0600
Subject: [R] Strange display of saved functions
Message-ID: <05785E4B-A69C-46BF-96FA-813CF71FD5D9@sasktel.net>

Hello:

I recently upgraded to R version 3.3.2 (2016-10-31)

Now I find that functions that I load from an older .RData file give a strange display:

---------------------------------------------------------------------------------------------------------------------------
> payments
function (a, n, tol = 1e-10) 
{
    p <- a/(1 - (1 + a)^(-n))
    p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
    p
}
attr(,"source")
[1] "function(a,n,tol=1E-10){# required proportion of principal required to "
[2] "\t# pay off loan in n installments at interest rate a"                  
[3] "\tp<-a/(1-(1+a)^(-n))"                                                  
[4] "\t# linear approximation for small rates"                               
[5] "\tp[a<tol]<-1/n+(n+1)*a[a<tol]/(2*n)"                                   
[6] "\tp}"                                                
------------------------------------------------------------------------------------------------------------------------------

In addition to the usual function definition it also prints the function contents as an attribute "source", including strange escape characters at the beginning of the lines.  Note that the comment only appears in this latter display.
This same display happens if I use the "edit" function.

However, if I copy and paste the definition into a new function, then it displays as expected:

----------------------------------------------------------------------------------------------------------------------------
> puments<-function (a, n, tol = 1e-10) 
+ {
+     p <- a/(1 - (1 + a)^(-n))
+     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
+     p
+ }
> 
> puments
function (a, n, tol = 1e-10) 
{
    p <- a/(1 - (1 + a)^(-n))
    p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
    p
}
--------------------------------------------------------------------------------------------------------------------------------

And I can successfully insert a comment right in the definition, as one would like

-------------------------------------------------------------------------------------------------------------------------------------------
> puments
function (a, n, tol = 1e-10) 
{# required proportion of principal required to 
# pay off loan in n installments at interest rate a 
    p <- a/(1 - (1 + a)^(-n))
    p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
    p
}
-------------------------------------------------------------------------------------------------------------------------------------------

What is happening to the displays of my function definitions?   I have never witnessed such behaviour before.   Is there some option I have to set (globally) to suppress this redundancy?

Mik Bickis
Department of Mathematics and Statistics
University of Saskatchewan

From ruipbarradas at sapo.pt  Mon Jan 30 17:59:02 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 30 Jan 2017 16:59:02 +0000
Subject: [R] lines those not started with "rs"
In-Reply-To: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
References: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
Message-ID: <588F70D6.1050109@sapo.pt>

Hello,

Try to study the following example.

A <- c("rs10000056", "rs10000076", "ab1234567")
x <- 1:3
dat <- data.frame(A, x)

inx <- grepl("^rs", dat$A)
dat[!inx, ]


Hope this helps,

Rui Barradas

Em 30-01-2017 14:23, greg holly escreveu:
> Hi all;
>
> I have a file which has about 3.000.000 lines. Most of the lines at first
> column start with "rs", for example, rs10000056, rs10000076 and so on. I
> would like to get the lines which do not start with "rs" . Your helps
> highly appreciated.
>
> Regards,
>
> Greg
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Mon Jan 30 20:03:31 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 30 Jan 2017 19:03:31 +0000
Subject: [R] g parameter for deltaMethod() as a function
In-Reply-To: <b512a5c6-6fa4-59ee-f843-eb1fe8d5c674@yahoo.fr>
References: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>
	<ACD1644AA6C67E4FBD0C350625508EC8365E1F70@FHSDB2D11-2.csu.mcmaster.ca>
	<b512a5c6-6fa4-59ee-f843-eb1fe8d5c674@yahoo.fr>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365E1FE4@FHSDB2D11-2.csu.mcmaster.ca>

Dear Marc,

A "wrapper function" *calls* deltaMethod(). Your function try_g() is intended to be *called by* try_g(). Actually, you just pass to deltaMethod() a character string that would evaluate to the function call, and deltaMethod() doesn't know what to do with that.

The description of the g (second) argument in ?deltaMethod seems perfectly clear to me; beyond what I quoted, in "Details" you'll find, "The argument g must be a quoted character string that gives the function [of the coefficients] of interest. For example, if you set m2 <- lm(Y ~ X1 + X2 + X1:X2), then deltaMethod(m2,"X1/X2") applies the delta method to the ratio of the coefficient estimates for X1 and X2. The argument g can consist of constants and names associated with the elements of the vector of coefficient estimates. Etc."

Try writing a function that calls deltaMethod() and does what you want.

John

> -----Original Message-----
> From: Marc Girondot [mailto:marc_grt at yahoo.fr]
> Sent: Monday, January 30, 2017 1:31 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] g parameter for deltaMethod() as a function
> 
> Le 30/01/2017 ? 19:04, Fox, John a ?crit :
> 
> 
> 		Hi everyone,
> 
> 		I try to use the Default S3 method DeltaMethod() from car
> package, but I
> 		have some problems when I try to use a function as the "g"
> parameter. I
> 		don't know if it is possible anyway. I hope that you could
> tell me:
> 
> 	I don't see how that would work. From ?deltaMethod: "g [the second
> argument]: A quoted string that is the function of the parameter
> estimates to be evaluated; see the details below."
> 
> 	A possible solution would be to write a wrapper function that
> prepares a proper call to deltaMethod().
> 
> Hi John,
> 
> This is exactly what I try to do: a wrapper (I forget that name in
> English !).
> 
> I have made some progress to do a wrapper function:
> 
> try_g <- function(...) {
>   par <- list(...)
>   return(par$t1/par$t2)
> }
> 
> try_g(t1=1, t2=2)
> deltaMethod(coef(m1), "try_g(t1, t2)", vcov.=vcov(m1))
> 
> The wrapper function try_g is accepted now, but I get an error because
> deltaMethod() tried to do symbolic derivative:
> 
> > deltaMethod(coef(m1), "try_g(t1, t2)", vcov.=vcov(m1))
> Error in D(g, names(para)[i]) :
>   La fonction 'try_g' n'est pas dans la table des d?riv?es (translation:
> The function 'try_g' is not in the table of derivative functions).
> 
> I was hopping that numeric approximation of derivative (example
> numDeriv::grad() or deriv() ) could be used, but it is not the case.
> 
> Thanks
> 
> Marc
> 


From wdunlap at tibco.com  Mon Jan 30 20:17:37 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 30 Jan 2017 11:17:37 -0800
Subject: [R] Strange display of saved functions
In-Reply-To: <05785E4B-A69C-46BF-96FA-813CF71FD5D9@sasktel.net>
References: <05785E4B-A69C-46BF-96FA-813CF71FD5D9@sasktel.net>
Message-ID: <CAF8bMcYRP+jDRJGDhQmqNeh1byppgZP5k4uKv+8XyvwyScowUw@mail.gmail.com>

This must be a pretty old RData file (pre-2.14.0).  news() says:

Changes in version 2.14.0:

NEW FEATURES

    o   The "source" attribute on functions created with keep.source=TRUE
        has been replaced with a "srcref" attribute.  The "srcref"
        attribute references an in-memory copy of the source file using the
        "srcfilecopy" class or the new "srcfilealias" class.

        *NB:* This means that functions sourced with keep.source = TRUE and
        saved (e.g., by save() or readRDS()) in earlier versions of R will
        no longer show the original sources (including comments).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Jan 30, 2017 at 9:29 AM, Mik Bickis <m.bickis at sasktel.net> wrote:
> Hello:
>
> I recently upgraded to R version 3.3.2 (2016-10-31)
>
> Now I find that functions that I load from an older .RData file give a strange display:
>
> ---------------------------------------------------------------------------------------------------------------------------
>> payments
> function (a, n, tol = 1e-10)
> {
>     p <- a/(1 - (1 + a)^(-n))
>     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>     p
> }
> attr(,"source")
> [1] "function(a,n,tol=1E-10){# required proportion of principal required to "
> [2] "\t# pay off loan in n installments at interest rate a"
> [3] "\tp<-a/(1-(1+a)^(-n))"
> [4] "\t# linear approximation for small rates"
> [5] "\tp[a<tol]<-1/n+(n+1)*a[a<tol]/(2*n)"
> [6] "\tp}"
> ------------------------------------------------------------------------------------------------------------------------------
>
> In addition to the usual function definition it also prints the function contents as an attribute "source", including strange escape characters at the beginning of the lines.  Note that the comment only appears in this latter display.
> This same display happens if I use the "edit" function.
>
> However, if I copy and paste the definition into a new function, then it displays as expected:
>
> ----------------------------------------------------------------------------------------------------------------------------
>> puments<-function (a, n, tol = 1e-10)
> + {
> +     p <- a/(1 - (1 + a)^(-n))
> +     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
> +     p
> + }
>>
>> puments
> function (a, n, tol = 1e-10)
> {
>     p <- a/(1 - (1 + a)^(-n))
>     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>     p
> }
> --------------------------------------------------------------------------------------------------------------------------------
>
> And I can successfully insert a comment right in the definition, as one would like
>
> -------------------------------------------------------------------------------------------------------------------------------------------
>> puments
> function (a, n, tol = 1e-10)
> {# required proportion of principal required to
> # pay off loan in n installments at interest rate a
>     p <- a/(1 - (1 + a)^(-n))
>     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>     p
> }
> -------------------------------------------------------------------------------------------------------------------------------------------
>
> What is happening to the displays of my function definitions?   I have never witnessed such behaviour before.   Is there some option I have to set (globally) to suppress this redundancy?
>
> Mik Bickis
> Department of Mathematics and Statistics
> University of Saskatchewan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jan 30 20:18:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 30 Jan 2017 11:18:36 -0800
Subject: [R] lines those not started with "rs"
In-Reply-To: <588F70D6.1050109@sapo.pt>
References: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
	<588F70D6.1050109@sapo.pt>
Message-ID: <CAGxFJbSqG1JYg4SqAqpKD1=-iK-nG7gZy_1_ZoMAJcW1n673ZA@mail.gmail.com>

Rui, et. al.:

**IF** the data set can be read into R (3e6 lines x ?bytes/line ??) ,
then I think for a completely specified regular pattern such as that
described by the OP, grep would be a bit inefficient. If x is a vector
of strings, and you wish to remove all those that don't begin with
"rs" then:

 x[!substring(x,1,2) == "rs"]

took about 1/2 the time on my computer as the grepl() version for a
vector,x, of length 1e6.

To be fair, I suspect this may be a negigible difference, as most of
the time would probably be taken in extracting and replacing rows from
the data frame. Nevertheless, it seems worthwhile to highlight the use
of simple, efficient, albeit limited, tools when they *can* be used.

All, of course, assuming I have understood the query correctly.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 30, 2017 at 8:59 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Try to study the following example.
>
> A <- c("rs10000056", "rs10000076", "ab1234567")
> x <- 1:3
> dat <- data.frame(A, x)
>
> inx <- grepl("^rs", dat$A)
> dat[!inx, ]
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 30-01-2017 14:23, greg holly escreveu:
>>
>> Hi all;
>>
>> I have a file which has about 3.000.000 lines. Most of the lines at first
>> column start with "rs", for example, rs10000056, rs10000076 and so on. I
>> would like to get the lines which do not start with "rs" . Your helps
>> highly appreciated.
>>
>> Regards,
>>
>> Greg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jan 30 20:22:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 30 Jan 2017 11:22:33 -0800
Subject: [R] lines those not started with "rs"
In-Reply-To: <CAGxFJbSqG1JYg4SqAqpKD1=-iK-nG7gZy_1_ZoMAJcW1n673ZA@mail.gmail.com>
References: <CAM9Qe4hdUw=WrBPVyRiANCgaev--zxosP3YBuZTEewG7+Bf1vA@mail.gmail.com>
	<588F70D6.1050109@sapo.pt>
	<CAGxFJbSqG1JYg4SqAqpKD1=-iK-nG7gZy_1_ZoMAJcW1n673ZA@mail.gmail.com>
Message-ID: <CAGxFJbRdRYObK3Qs5_RnK=NgsFqik_JuS92P+g7JkNwKyxT_RA@mail.gmail.com>

... heh, heh and even simpler (but maybe not much faster)

 x[substring(x,1,2) != "rs"]


(DUHHH!)

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jan 30, 2017 at 11:18 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Rui, et. al.:
>
> **IF** the data set can be read into R (3e6 lines x ?bytes/line ??) ,
> then I think for a completely specified regular pattern such as that
> described by the OP, grep would be a bit inefficient. If x is a vector
> of strings, and you wish to remove all those that don't begin with
> "rs" then:
>
>  x[!substring(x,1,2) == "rs"]
>
> took about 1/2 the time on my computer as the grepl() version for a
> vector,x, of length 1e6.
>
> To be fair, I suspect this may be a negigible difference, as most of
> the time would probably be taken in extracting and replacing rows from
> the data frame. Nevertheless, it seems worthwhile to highlight the use
> of simple, efficient, albeit limited, tools when they *can* be used.
>
> All, of course, assuming I have understood the query correctly.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jan 30, 2017 at 8:59 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Try to study the following example.
>>
>> A <- c("rs10000056", "rs10000076", "ab1234567")
>> x <- 1:3
>> dat <- data.frame(A, x)
>>
>> inx <- grepl("^rs", dat$A)
>> dat[!inx, ]
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 30-01-2017 14:23, greg holly escreveu:
>>>
>>> Hi all;
>>>
>>> I have a file which has about 3.000.000 lines. Most of the lines at first
>>> column start with "rs", for example, rs10000056, rs10000076 and so on. I
>>> would like to get the lines which do not start with "rs" . Your helps
>>> highly appreciated.
>>>
>>> Regards,
>>>
>>> Greg
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ed_isfahani at yahoo.com  Mon Jan 30 20:40:05 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Mon, 30 Jan 2017 19:40:05 +0000 (UTC)
Subject: [R] caculate correlation
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
Message-ID: <379992977.4826084.1485805205593@mail.yahoo.com>

for calculating correlation between?coding and noncoding,first I transposed data?,(rows become columns) so row is control&treatment and columns are gene names.(so I have 2 matrix with same row and different column),I use these function for calculating correlation but all of spearman correlation are NA,why?


control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method= "spearman")






?
tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1], ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")

	[[alternative HTML version deleted]]


From rmh at temple.edu  Mon Jan 30 21:04:23 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 30 Jan 2017 15:04:23 -0500
Subject: [R] graphical behavior of a table of numbers
In-Reply-To: <22671.25317.335078.641793@stat.math.ethz.ch>
References: <CAGx1TMC8ZjD6HypPhNR7fDOjr2Npfa+3Z6eStzKMFiDdiFc79A@mail.gmail.com>
	<CAGxFJbRAn30qoifs5s2HSgySSva_b3ta09LZMGENxAB8hoo3=w@mail.gmail.com>
	<CA+8X3fV5ziYOCc4=RatnhZ-0LR-YTRc4zPDMG7EKhNXvNUvOaQ@mail.gmail.com>
	<4388a051-200f-9bbb-d02e-c6cab734019b@gmail.com>
	<22671.6050.750658.33001@stat.math.ethz.ch>
	<CAGx1TMAR6c_vZvtHciRJvgZQDs6cvSESxkeLQWseX=6Biq2CDg@mail.gmail.com>
	<22671.25317.335078.641793@stat.math.ethz.ch>
Message-ID: <CAGx1TMC=cU4w90FCLKxHen4LXsXHrUK6UjaGBrEu-FbnChWGYg@mail.gmail.com>

I still think

plot(fr, xlab="Determinant", ylab="Frequency")

has a totally non-intuitive x-axis.

I recommend that the example in R-intro.pdf include an additional
sentence and option.


## In this example, where the x-axis is the entire set of integers -81:81,
## displaying them as an ordinary numeric axis might be preferable, in
which case use
   plot(fr, xlab="Determinant", ylab="Frequency", xaxt="n")
   axis(1)


While thinking on this, I looked at ?plot.table
The example
     plot(table(state.division))
doesn't display most of the labels, and I think it therefore not a good example.
I recommend revising it, perhaps to
    old.oma <- par(oma=c(6,1,0,1));
    plot(table(state.division), las=2, mgp=c(.5,2,0))
    par(old.oma)
I agree the code for the legible labels is difficult to read.

Rich

On Mon, Jan 30, 2017 at 10:59 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Richard M Heiberger <rmh at temple.edu>
>>>>>>     on Mon, 30 Jan 2017 10:19:53 -0500 writes:
>
>     > Duncan, thank you for locating the problem.
>     > Martin, thank you for explaining the behavior and for the first pass
>     > at fixing it.
>
>
>     > With the fix, now the x-axis has ticks at all integers, and tick labels at
>     > c(-81,-67,-53,-39,-25,-11,0,9,19,31,43,55,67,79)
>
> Note that *which* tick labels are shown depends quite a bit
> on your graphics window width, your font sizes etc !
>
>     > This is with R-3.3.2, as I interpret your fix to be to only the
>     > R-intro.pdf manual with no change
>     > to the code of any of the functions.
>
> That's correct.  If this is about improving any of
> the base graphics functions,  there's the  R-devel mailing list
> and the bugzilla repository for "wishes"... rather than the
> R-help list.
>
>     > More work has to be done to repair the example.
>
> I strongly disagree:
> The example (which does not even need a 'type = "h"', and no longer
> uses it) now mentions that the plot.factor method is used.
> ... and I do like its graphics output, given the simplicity of
> the plot() function call.
>
> Code as the one below may be preferable in some cases, but not
> there in the   "Introduction to R".
>
>
>     > I recommend
>     > plot(as.numeric(fr) ~ as.numeric(names(fr)), type="h",
>     > xlab="Determinant", ylab="Frequency")
>
>     > The slightly more obvious solution doesn't work
>     >> plot(fr ~ as.numeric(names(fr)), type="h", xlab="Determinant", ylab="Frequency")
>     > Error in plot.table(c(-81, -80, -79, -78, -77, -76, -75, -74, -73, -72,  :
>     > invalid table 'x'
>
>     > ## It is possible to change graphics:::Axis.table to
>     > if (is.num) axis(side, ...)
>     > ## and that would make the x-axis for the determinant example
>     > plot(fr, type="h", xlab="Determinant", ylab="Frequency")
>     > ## look sensible, but would
>     > ## be less appropriate for the following example.
>
>     > ## The current behavior of Axis.table makes sense in this example
>     > tt <- as.table(array(c(10,20,30), dimnames=list(c(100, 120, 200))))
>     > tt
>     > plot(tt)
>
> Indeed.  I doubt we would want to change Axis.table()
> just because of examples like the determinant one....
> (and then again: such considerations would be part of a new thread on R-devel...)
>
> Martin Maechler
>
>
>     > On Mon, Jan 30, 2017 at 5:38 AM, Martin Maechler
>     > <maechler at stat.math.ethz.ch> wrote:
>     >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>     >>>>>>> on Sun, 29 Jan 2017 06:32:27 -0500 writes:
>     >>
>     >> > On 29/01/2017 12:05 AM, Jim Lemon wrote:
>     >> >> Hi Richard, I think there may be something amiss in the
>     >> >> plot.table function. As you note, changing the class of
>     >> >> fr to array produces a more sensible plot, as does Bert's
>     >> >> "as.vector". Yet inside plot.table we find:
>     >> >>
>     >> >> plot(x0, unclass(x), ...
>     >> >>
>     >> >> and that should produce an array:
>     >> >>
>     >> >> class(unclass(fr)) [1] "array"
>     >> >>
>     >> >> The plot.table function looks like it should produce the
>     >> >> plot you want, but it doesn't. I think (therefore I am
>     >> >> probably wrong) that a 1D table is handled in the same
>     >> >> way as multiD table rather than being squeezed into a
>     >> >> vector.
>     >>
>     >> > I think the issue is that Axis() is called without
>     >> > removing the class.  Axis.table sets ticks based on the
>     >> > names of the table.
>     >>
>     >> > Duncan Murdoch
>     >>
>     >> yes indeed!  So this answers Rich Heiberger's question.
>     >>
>     >> The example stems from a time long before there was
>     >> a plot.table() method, and even longer before plot.default() had
>     >> started using  Axis() and its methods.
>     >>
>     >> So a much nicer example for the R-intro -- committed a few
>     >> minutes ago -- is making use of the  plot.table() S3 method :
>     >>
>     >> d <- outer(0:9, 0:9)
>     >> fr <- table(outer(d, d, "-"))
>     >> plot(fr, type="h", xlab="Determinant", ylab="Frequency")
>     >>
>     >> So this fulfills Rich's recommendation.
>     >>
>     >> Martin
>     >>
>     >>
>     >> >> On Sun, Jan 29, 2017 at 11:19 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>     >> >>> Rich:
>     >> >>>
>     >> >>> Simpler: Just lose the "table" class.
>     >> >>>
>     >> >>> plot(as.numeric(names(fr)), as.vector(fr),  type="h",
>     >> >>>      xlab="Determinant", ylab="Frequency")
>     >> >>>
>     >> >>> However, I'm no less puzzled by the "strange" behavior than you.
>     >> >>>
>     >> >>> In addition, it's probably worth noting that xyplot in lattice (and no
>     >> >>> doubt ggplot,too) does not have this problem (as I'm sure you know):
>     >> >>>
>     >> >>> xyplot(fr ~ as.numeric(names(fr)),  type="h",
>     >> >>>        xlab="Determinant", ylab="Frequency")
>     >> >>>
>     >> >>>
>     >> >>> Cheers,
>     >> >>> Bert
>     >> >>> Bert Gunter
>     >> >>>
>     >> >>> "The trouble with having an open mind is that people keep coming along
>     >> >>> and sticking things into it."
>     >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>     >> >>>
>     >> >>>
>     >> >>> On Sat, Jan 28, 2017 at 3:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>     >> >>>> ## This example is from R-intro.pdf page 21 (R-3.3.2)
>     >> >>>>
>     >> >>>> d <- outer(0:9, 0:9)
>     >> >>>> fr <- table(outer(d, d, "-"))
>     >> >>>> plot(as.numeric(names(fr)), fr, type="h",
>     >> >>>>      xlab="Determinant", ylab="Frequency")
>     >> >>>> ## The y-axis tick marks are at c(-21,24,65).
>     >> >>>> ## This seems to be because class(fr) == "table"
>     >> >>>>
>     >> >>>> ## Switching the class to array gives the more appropriate
>     >> >>>> ## y-axis ticks at seq(0,500,100) .
>     >> >>>>
>     >> >>>> fr.array <- fr
>     >> >>>> class(fr.array) <- "array"
>     >> >>>> plot(as.numeric(names(fr)), fr.array, type="h",
>     >> >>>>      xlab="Determinant", ylab="Frequency")
>     >> >>>>
>     >> >>>>
>     >> >>>> ## I have a question and a recommendation.
>     >> >>>> ## Question:
>     >> >>>> ## Why are the y-axis ticks for the table defaulted to c(-21,24,65).
>     >> >>>> ##
>     >> >>>> ## Recommendation:
>     >> >>>> ## Changed the example on page 21 to show the ticks at seq(0,500,100)?
>     >> >>>>
>     >> >>>> ## Rich
>     >> >>>>
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Jan 30 21:08:03 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Jan 2017 15:08:03 -0500
Subject: [R] Strange display of saved functions
In-Reply-To: <CAF8bMcYRP+jDRJGDhQmqNeh1byppgZP5k4uKv+8XyvwyScowUw@mail.gmail.com>
References: <05785E4B-A69C-46BF-96FA-813CF71FD5D9@sasktel.net>
	<CAF8bMcYRP+jDRJGDhQmqNeh1byppgZP5k4uKv+8XyvwyScowUw@mail.gmail.com>
Message-ID: <ab4dcad6-fca9-0101-e89d-d9ce3927558a@gmail.com>

On 30/01/2017 2:17 PM, William Dunlap via R-help wrote:
> This must be a pretty old RData file (pre-2.14.0).  news() says:
>
> Changes in version 2.14.0:
>
> NEW FEATURES
>
>     o   The "source" attribute on functions created with keep.source=TRUE
>         has been replaced with a "srcref" attribute.  The "srcref"
>         attribute references an in-memory copy of the source file using the
>         "srcfilecopy" class or the new "srcfilealias" class.
>
>         *NB:* This means that functions sourced with keep.source = TRUE and
>         saved (e.g., by save() or readRDS()) in earlier versions of R will
>         no longer show the original sources (including comments).

Yes, indeed.  Mik, if you do want the original formatting and comments, 
something like

cat(attr(payments, "source"), sep = "\n")

should display it.

Duncan Murdoch


>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Jan 30, 2017 at 9:29 AM, Mik Bickis <m.bickis at sasktel.net> wrote:
>> Hello:
>>
>> I recently upgraded to R version 3.3.2 (2016-10-31)
>>
>> Now I find that functions that I load from an older .RData file give a strange display:
>>
>> ---------------------------------------------------------------------------------------------------------------------------
>>> payments
>> function (a, n, tol = 1e-10)
>> {
>>     p <- a/(1 - (1 + a)^(-n))
>>     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>>     p
>> }
>> attr(,"source")
>> [1] "function(a,n,tol=1E-10){# required proportion of principal required to "
>> [2] "\t# pay off loan in n installments at interest rate a"
>> [3] "\tp<-a/(1-(1+a)^(-n))"
>> [4] "\t# linear approximation for small rates"
>> [5] "\tp[a<tol]<-1/n+(n+1)*a[a<tol]/(2*n)"
>> [6] "\tp}"
>> ------------------------------------------------------------------------------------------------------------------------------
>>
>> In addition to the usual function definition it also prints the function contents as an attribute "source", including strange escape characters at the beginning of the lines.  Note that the comment only appears in this latter display.
>> This same display happens if I use the "edit" function.
>>
>> However, if I copy and paste the definition into a new function, then it displays as expected:
>>
>> ----------------------------------------------------------------------------------------------------------------------------
>>> puments<-function (a, n, tol = 1e-10)
>> + {
>> +     p <- a/(1 - (1 + a)^(-n))
>> +     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>> +     p
>> + }
>>>
>>> puments
>> function (a, n, tol = 1e-10)
>> {
>>     p <- a/(1 - (1 + a)^(-n))
>>     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>>     p
>> }
>> --------------------------------------------------------------------------------------------------------------------------------
>>
>> And I can successfully insert a comment right in the definition, as one would like
>>
>> -------------------------------------------------------------------------------------------------------------------------------------------
>>> puments
>> function (a, n, tol = 1e-10)
>> {# required proportion of principal required to
>> # pay off loan in n installments at interest rate a
>>     p <- a/(1 - (1 + a)^(-n))
>>     p[a < tol] <- 1/n + (n + 1) * a[a < tol]/(2 * n)
>>     p
>> }
>> -------------------------------------------------------------------------------------------------------------------------------------------
>>
>> What is happening to the displays of my function definitions?   I have never witnessed such behaviour before.   Is there some option I have to set (globally) to suppress this redundancy?
>>
>> Mik Bickis
>> Department of Mathematics and Statistics
>> University of Saskatchewan
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Mon Jan 30 22:36:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 08:36:24 +1100
Subject: [R] caculate correlation
In-Reply-To: <379992977.4826084.1485805205593@mail.yahoo.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
Message-ID: <CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>

Hi Elham,
Without knowing much about what coding.rpkm and ncoding.rkpm look
like, it is difficult to say. Have you tried to subset these matrices
as you do in the "cor" function and see what is returned?

Jim

On Tue, Jan 31, 2017 at 6:40 AM, Elham - via R-help
<r-help at r-project.org> wrote:
> for calculating correlation between coding and noncoding,first I transposed data ,(rows become columns) so row is control&treatment and columns are gene names.(so I have 2 matrix with same row and different column),I use these function for calculating correlation but all of spearman correlation are NA,why?
>
>
> control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method= "spearman")
>
>
>
>
>
>
>
> tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1], ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ed_isfahani at yahoo.com  Mon Jan 30 22:45:23 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Mon, 30 Jan 2017 21:45:23 +0000 (UTC)
Subject: [R] caculate correlation
In-Reply-To: <CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
Message-ID: <1908713206.125008.1485812723647@mail.yahoo.com>

I have 9 experiments control/treatment that I analysed coding and lncoding, after that I normalize expression value.as you know we have different known number of coding and non -coding genes,so for calculating correlation first I transposed data ,(rows become columns)so row is control&treatment and columns are gene names.(so I have 2 matrix with same row and different column).This information is enough? ?
 

    On Tuesday, January 31, 2017 1:06 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Elham,
Without knowing much about what coding.rpkm and ncoding.rkpm look
like, it is difficult to say. Have you tried to subset these matrices
as you do in the "cor" function and see what is returned?

Jim

On Tue, Jan 31, 2017 at 6:40 AM, Elham - via R-help
<r-help at r-project.org> wrote:
> for calculating correlation between coding and noncoding,first I transposed data ,(rows become columns) so row is control&treatment and columns are gene names.(so I have 2 matrix with same row and different column),I use these function for calculating correlation but all of spearman correlation are NA,why?
>
>
> control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method= "spearman")
>
>
>
>
>
>
>
> tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1], ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Jan 30 22:47:55 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 30 Jan 2017 21:47:55 +0000
Subject: [R] g parameter for deltaMethod() as a function
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365E1FE4@FHSDB2D11-2.csu.mcmaster.ca>
References: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>
	<ACD1644AA6C67E4FBD0C350625508EC8365E1F70@FHSDB2D11-2.csu.mcmaster.ca>
	<b512a5c6-6fa4-59ee-f843-eb1fe8d5c674@yahoo.fr>
	<ACD1644AA6C67E4FBD0C350625508EC8365E1FE4@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <E047408E-94B0-424D-8E66-40604520AAD6@mcmaster.ca>

Dear Mark,

I realized that there was a typo in my last response, which is corrected below:

> On Jan 30, 2017, at 2:03 PM, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Marc,
> 
> A "wrapper function" *calls* deltaMethod().
> Your function try_g() is intended to be *called by* try_g().

Actually this should say, "Your function try_g() is intended to be *called by* deltaMethod().?

Sorry if that was confusing,
 John


> Actually, you just pass to deltaMethod() a character string that would evaluate to the function call, and deltaMethod() doesn't know what to do with that.
> 
> The description of the g (second) argument in ?deltaMethod seems perfectly clear to me; beyond what I quoted, in "Details" you'll find, "The argument g must be a quoted character string that gives the function [of the coefficients] of interest. For example, if you set m2 <- lm(Y ~ X1 + X2 + X1:X2), then deltaMethod(m2,"X1/X2") applies the delta method to the ratio of the coefficient estimates for X1 and X2. The argument g can consist of constants and names associated with the elements of the vector of coefficient estimates. Etc."
> 
> Try writing a function that calls deltaMethod() and does what you want.
> 
> John
> 
>> -----Original Message-----
>> From: Marc Girondot [mailto:marc_grt at yahoo.fr]
>> Sent: Monday, January 30, 2017 1:31 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] g parameter for deltaMethod() as a function
>> 
>> Le 30/01/2017 ? 19:04, Fox, John a ?crit :
>> 
>> 
>> 		Hi everyone,
>> 
>> 		I try to use the Default S3 method DeltaMethod() from car
>> package, but I
>> 		have some problems when I try to use a function as the "g"
>> parameter. I
>> 		don't know if it is possible anyway. I hope that you could
>> tell me:
>> 
>> 	I don't see how that would work. From ?deltaMethod: "g [the second
>> argument]: A quoted string that is the function of the parameter
>> estimates to be evaluated; see the details below."
>> 
>> 	A possible solution would be to write a wrapper function that
>> prepares a proper call to deltaMethod().
>> 
>> Hi John,
>> 
>> This is exactly what I try to do: a wrapper (I forget that name in
>> English !).
>> 
>> I have made some progress to do a wrapper function:
>> 
>> try_g <- function(...) {
>>  par <- list(...)
>>  return(par$t1/par$t2)
>> }
>> 
>> try_g(t1=1, t2=2)
>> deltaMethod(coef(m1), "try_g(t1, t2)", vcov.=vcov(m1))
>> 
>> The wrapper function try_g is accepted now, but I get an error because
>> deltaMethod() tried to do symbolic derivative:
>> 
>>> deltaMethod(coef(m1), "try_g(t1, t2)", vcov.=vcov(m1))
>> Error in D(g, names(para)[i]) :
>>  La fonction 'try_g' n'est pas dans la table des d?riv?es (translation:
>> The function 'try_g' is not in the table of derivative functions).
>> 
>> I was hopping that numeric approximation of derivative (example
>> numDeriv::grad() or deriv() ) could be used, but it is not the case.
>> 
>> Thanks
>> 
>> Marc
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Mon Jan 30 21:26:21 2017
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 30 Jan 2017 20:26:21 +0000 (UTC)
Subject: [R] Save a generated .txt (or .csv) file on the desktop
References: <368947391.7257542.1485807981734.ref@mail.yahoo.com>
Message-ID: <368947391.7257542.1485807981734@mail.yahoo.com>

Dear R-Experts,

I have generated a data.frame. Now I would like to get it (the generated data.frame) saved on my desktop (desktop of my computer) in a .csv or .txt file. How can I proceed ?

Many thanks.

Here is the reproducible example :



# G?n?ration al?atoire des colonnes
Individu<-1:50
Genre<-sample(c("H","F"),50,replace=T)
Age<-sample(18:45,50,replace=T)
Pratique<-sample(c("PI","I","TI"),50,replace=T)
Statut<-sample(c("C","M","D"),50, replace=T)

# G?n?ration du Data.frame "tableau" contenant les colonnes pr?c?dentes
tableau <- data.frame(Individu,Genre,Age,Pratique,Statut)

# Exportation du data.frame dans un fichier csv
write.csv(tableau,row.names=FALSE)



# Sauvegarder...save(tableau, file = "saveddf.txt") 


From drjimlemon at gmail.com  Mon Jan 30 22:53:07 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 08:53:07 +1100
Subject: [R] Challenge extracting months
In-Reply-To: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
Message-ID: <CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>

Hi Kwesi,
Even without the data, it seems clear that you want something like a
rolling mean. Here is a simple function that will apply a function
like "mean" to successive bits of a vector of numbers:

collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
 jump<-span-1
 newx<-rep(NA,length(x)-jump)
 for(i in 1:length(newx))
  newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
 return(newx)
}

test<-1:12
names(test)<-month.abb
test
collapse_values(test,3)
 [1]  2  3  4  5  6  7  8  9 10 11

Jim



On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
<starskykwesi at gmail.com> wrote:
> Hello, I have a data with two variables nodes and index, I want to extract
> 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
> OND. Was wondering how to go about it. Kindly find attached the data as csv.
> Any help will be appreciated.
>
> Regards,
> Kwesi
>
> --
> Try not to become a man of success but rather a man of value-Albert Einstein
>
> University of Cape Coast|College of Agriculture and Natural Sciences|Department
> of Physics|
> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> Mobile: +233266173582
> Skype: quagraine_cwasi
> Twitter: @Pkdilly
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Jan 30 22:57:39 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 08:57:39 +1100
Subject: [R] caculate correlation
In-Reply-To: <1908713206.125008.1485812723647@mail.yahoo.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
	<1908713206.125008.1485812723647@mail.yahoo.com>
Message-ID: <CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>

Hi Elham,
This is about the same as your first message. What I meant was, what
do these two expressions return? Is whatever is returned suitable
input for the "cor" function?

coding.rpkm[grep("23.C",coding.rpkm$name),-1]

ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1]

Jim


On Tue, Jan 31, 2017 at 8:45 AM, Elham - <ed_isfahani at yahoo.com> wrote:
> I have 9 experiments control/treatment that I analysed coding and lncoding,
> after that I normalize expression value.as you know we have different known
> number of coding and non -coding genes,so for calculating correlation first
> I transposed data ,(rows become columns)so row is control&treatment and
> columns are gene names.(so I have 2 matrix with same row and different
> column).This information is enough?
>
>
>
>
> On Tuesday, January 31, 2017 1:06 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Elham,
> Without knowing much about what coding.rpkm and ncoding.rkpm look
> like, it is difficult to say. Have you tried to subset these matrices
> as you do in the "cor" function and see what is returned?
>
> Jim
>
> On Tue, Jan 31, 2017 at 6:40 AM, Elham - via R-help
> <r-help at r-project.org> wrote:
>> for calculating correlation between coding and noncoding,first I
>> transposed data ,(rows become columns) so row is control&treatment and
>> columns are gene names.(so I have 2 matrix with same row and different
>> column),I use these function for calculating correlation but all of spearman
>> correlation are NA,why?
>>
>>
>>
>> control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method=
>> "spearman")
>>
>>
>>
>>
>>
>>
>>
>> tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1],
>> ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From msharp at txbiomed.org  Mon Jan 30 23:04:44 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 30 Jan 2017 22:04:44 +0000
Subject: [R] Save a generated .txt (or .csv) file on the desktop
In-Reply-To: <368947391.7257542.1485807981734@mail.yahoo.com>
References: <368947391.7257542.1485807981734.ref@mail.yahoo.com>
	<368947391.7257542.1485807981734@mail.yahoo.com>
Message-ID: <26263B1E-9C10-469F-A1FF-FB05E74C7C4F@TxBiomed.org>

You can define the "file" argument in your call to write.csv()

## This will write out a file named "test_file.csv" to your working directory
write.csv(tableau,file = "test_file.csv", row.names=FALSE)


R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Jan 30, 2017, at 2:26 PM, varin sacha <varinsacha at yahoo.fr> wrote:
>
> Dear R-Experts,
>
> I have generated a data.frame. Now I would like to get it (the generated data.frame) saved on my desktop (desktop of my computer) in a .csv or .txt file. How can I proceed ?
>
> Many thanks.
>
> Here is the reproducible example :
>
>
>
> # G?n?ration al?atoire des colonnes
> Individu<-1:50
> Genre<-sample(c("H","F"),50,replace=T)
> Age<-sample(18:45,50,replace=T)
> Pratique<-sample(c("PI","I","TI"),50,replace=T)
> Statut<-sample(c("C","M","D"),50, replace=T)
>
> # G?n?ration du Data.frame "tableau" contenant les colonnes pr?c?dentes
> tableau <- data.frame(Individu,Genre,Age,Pratique,Statut)
>
> # Exportation du data.frame dans un fichier csv
> write.csv(tableau,row.names=FALSE)
>
>
>
> # Sauvegarder...save(tableau, file = "saveddf.txt")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From ed_isfahani at yahoo.com  Mon Jan 30 23:17:47 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Mon, 30 Jan 2017 22:17:47 +0000 (UTC)
Subject: [R] caculate correlation
In-Reply-To: <CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
	<1908713206.125008.1485812723647@mail.yahoo.com>
	<CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>
Message-ID: <579290005.175382.1485814667600@mail.yahoo.com>

this script automatically recognizes what is control among cod and lnc. Note that this script contains a?piece of text that is "grep(".C",cod$name)". This text select - among all column names - those that contain ".C". in my files, I named C1, C2, C3, etc all columns that correspond to controls. In the same manner, I get controls among the lnc, with the text: "grep(".C",lnc$name)"
I`m so sorry,maybe I do not understand you again.

    On Tuesday, January 31, 2017 1:27 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Elham,
This is about the same as your first message. What I meant was, what
do these two expressions return? Is whatever is returned suitable
input for the "cor" function?

coding.rpkm[grep("23.C",coding.rpkm$name),-1]

ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1]

Jim


On Tue, Jan 31, 2017 at 8:45 AM, Elham - <ed_isfahani at yahoo.com> wrote:
> I have 9 experiments control/treatment that I analysed coding and lncoding,
> after that I normalize expression value.as you know we have different known
> number of coding and non -coding genes,so for calculating correlation first
> I transposed data ,(rows become columns)so row is control&treatment and
> columns are gene names.(so I have 2 matrix with same row and different
> column).This information is enough?
>
>
>
>
> On Tuesday, January 31, 2017 1:06 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Elham,
> Without knowing much about what coding.rpkm and ncoding.rkpm look
> like, it is difficult to say. Have you tried to subset these matrices
> as you do in the "cor" function and see what is returned?
>
> Jim
>
> On Tue, Jan 31, 2017 at 6:40 AM, Elham - via R-help
> <r-help at r-project.org> wrote:
>> for calculating correlation between coding and noncoding,first I
>> transposed data ,(rows become columns) so row is control&treatment and
>> columns are gene names.(so I have 2 matrix with same row and different
>> column),I use these function for calculating correlation but all of spearman
>> correlation are NA,why?
>>
>>
>>
>> control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method=
>> "spearman")
>>
>>
>>
>>
>>
>>
>>
>> tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1],
>> ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")
>>
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


   
	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Mon Jan 30 23:50:06 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Tue, 31 Jan 2017 00:50:06 +0200
Subject: [R] Challenge extracting months
In-Reply-To: <CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
Message-ID: <CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>

Hello Jim,this is my script now; I am having this error when I called the
function;" In mean.default(list(era...1. = 1:444, Node_freq =
c(-0.389855332400718,  :  argument is not numeric or logical: returning NA"
Any help will be much appreciated.

Kwesi

rm(list = ls())
setwd('/home/kwesi/Documents/700hpa/soms/')
# Reading the data

era       <- read.csv(file="som_freq.csv",header = TRUE, sep = ",",dec =
".")
era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
era.sta<-data.frame(era[,1],era.scaled)
era.sta

collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
  jump<-span-1
  newx<-rep(NA,length(x)-jump)
  for(i in 1:length(newx))
    newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
  return(newx)
}

#test<-1:12
names(era.sta)<-month.abb
collapse_values(era.sta,3)
era.sta


On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kwesi,
> Even without the data, it seems clear that you want something like a
> rolling mean. Here is a simple function that will apply a function
> like "mean" to successive bits of a vector of numbers:
>
> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>  jump<-span-1
>  newx<-rep(NA,length(x)-jump)
>  for(i in 1:length(newx))
>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>  return(newx)
> }
>
> test<-1:12
> names(test)<-month.abb
> test
> collapse_values(test,3)
>  [1]  2  3  4  5  6  7  8  9 10 11
>
> Jim
>
>
>
> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
> <starskykwesi at gmail.com> wrote:
> > Hello, I have a data with two variables nodes and index, I want to
> extract
> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
> > OND. Was wondering how to go about it. Kindly find attached the data as
> csv.
> > Any help will be appreciated.
> >
> > Regards,
> > Kwesi
> >
> > --
> > Try not to become a man of success but rather a man of value-Albert
> Einstein
> >
> > University of Cape Coast|College of Agriculture and Natural
> Sciences|Department
> > of Physics|
> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> > Mobile: +233266173582
> > Skype: quagraine_cwasi
> > Twitter: @Pkdilly
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Jan 31 00:32:33 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 10:32:33 +1100
Subject: [R] Challenge extracting months
In-Reply-To: <CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
Message-ID: <CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>

Hi Kwesi,
The function collapse_values will only work on a vector of numbers
with FUN="mean". era.sta looks like a data frame with at least two
elements. As the second of these elements seems to be numeric, perhaps
this will work:

era.sta[,2]<-collapse.values(era.sta[,2],3)

Don't try to apply the names to era.sta, that was just something to
make the example easier to understand. If you want to collapse more
than one column of era.sta do each one at a time and assign them to a
new data frame. In particular, if era[,1] is a vector of month names,
you will have to create a new vector of quarter (three month) names.
If there are very many of these, the collapse_values function can be
modified to do it automatically.

Jim



On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
> Hello Jim,this is my script now; I am having this error when I called the
> function;" In mean.default(list(era...1. = 1:444, Node_freq =
> c(-0.389855332400718,  :  argument is not numeric or logical: returning NA"
> Any help will be much appreciated.
>
> Kwesi
>
> rm(list = ls())
> setwd('/home/kwesi/Documents/700hpa/soms/')
> # Reading the data
>
> era       <- read.csv(file="som_freq.csv",header = TRUE, sep = ",",dec =
> ".")
> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
> era.sta<-data.frame(era[,1],era.scaled)
> era.sta
>
> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>   jump<-span-1
>   newx<-rep(NA,length(x)-jump)
>   for(i in 1:length(newx))
>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>   return(newx)
> }
>
> #test<-1:12
> names(era.sta)<-month.abb
> collapse_values(era.sta,3)
> era.sta
>
>
> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Kwesi,
>> Even without the data, it seems clear that you want something like a
>> rolling mean. Here is a simple function that will apply a function
>> like "mean" to successive bits of a vector of numbers:
>>
>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>>  jump<-span-1
>>  newx<-rep(NA,length(x)-jump)
>>  for(i in 1:length(newx))
>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>>  return(newx)
>> }
>>
>> test<-1:12
>> names(test)<-month.abb
>> test
>> collapse_values(test,3)
>>  [1]  2  3  4  5  6  7  8  9 10 11
>>
>> Jim
>>
>>
>>
>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
>> <starskykwesi at gmail.com> wrote:
>> > Hello, I have a data with two variables nodes and index, I want to
>> > extract
>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
>> > OND. Was wondering how to go about it. Kindly find attached the data as
>> > csv.
>> > Any help will be appreciated.
>> >
>> > Regards,
>> > Kwesi
>> >
>> > --
>> > Try not to become a man of success but rather a man of value-Albert
>> > Einstein
>> >
>> > University of Cape Coast|College of Agriculture and Natural
>> > Sciences|Department
>> > of Physics|
>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> > Mobile: +233266173582
>> > Skype: quagraine_cwasi
>> > Twitter: @Pkdilly
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Try not to become a man of success but rather a man of value-Albert Einstein
>
> University of Cape Coast|College of Agriculture and Natural
> Sciences|Department of Physics|
> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> Mobile: +233266173582
> Skype: quagraine_cwasi
> Twitter: @Pkdilly
>


From drjimlemon at gmail.com  Tue Jan 31 00:37:44 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 10:37:44 +1100
Subject: [R] caculate correlation
In-Reply-To: <579290005.175382.1485814667600@mail.yahoo.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
	<1908713206.125008.1485812723647@mail.yahoo.com>
	<CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>
	<579290005.175382.1485814667600@mail.yahoo.com>
Message-ID: <CA+8X3fXsqP=zwHGODvzUujE4v8YsQy7kZ797B_eDq-qXK+qOKA@mail.gmail.com>

Hi Elham,
What I meant is to simply copy these two expressions into the R command line:

coding.rpkm[grep("23.C",coding.rpkm$name),-1]

ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1]

and see what comes out. If both return a vector of numbers of the same
length with no NA values, my guess was wrong. If there are NA values,
try adding the argument use=pairwise.complete.obs to the "cor"
statement.

Jim


On Tue, Jan 31, 2017 at 9:17 AM, Elham - <ed_isfahani at yahoo.com> wrote:
> this script automatically recognizes what is control among cod and lnc. Note
> that this script contains a piece of text that is "grep(".C",cod$name)".
> This text select - among all column names - those that contain ".C". in my
> files, I named C1, C2, C3, etc all columns that correspond to controls. In
> the same manner, I get controls among the lnc, with the text:
> "grep(".C",lnc$name)"
>
> I`m so sorry,maybe I do not understand you again.
>
>
> On Tuesday, January 31, 2017 1:27 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Elham,
> This is about the same as your first message. What I meant was, what
> do these two expressions return? Is whatever is returned suitable
> input for the "cor" function?
>
> coding.rpkm[grep("23.C",coding.rpkm$name),-1]
>
> ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1]
>
> Jim
>
>
> On Tue, Jan 31, 2017 at 8:45 AM, Elham - <ed_isfahani at yahoo.com> wrote:
>> I have 9 experiments control/treatment that I analysed coding and
>> lncoding,
>> after that I normalize expression value.as you know we have different
>> known
>> number of coding and non -coding genes,so for calculating correlation
>> first
>> I transposed data ,(rows become columns)so row is control&treatment and
>> columns are gene names.(so I have 2 matrix with same row and different
>> column).This information is enough?
>>
>>
>>
>>
>> On Tuesday, January 31, 2017 1:06 AM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>
>>
>> Hi Elham,
>> Without knowing much about what coding.rpkm and ncoding.rkpm look
>> like, it is difficult to say. Have you tried to subset these matrices
>> as you do in the "cor" function and see what is returned?
>>
>> Jim
>>
>> On Tue, Jan 31, 2017 at 6:40 AM, Elham - via R-help
>> <r-help at r-project.org> wrote:
>>> for calculating correlation between coding and noncoding,first I
>>> transposed data ,(rows become columns) so row is control&treatment and
>>> columns are gene names.(so I have 2 matrix with same row and different
>>> column),I use these function for calculating correlation but all of
>>> spearman
>>> correlation are NA,why?
>>>
>>>
>>>
>>>
>>> control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method=
>>> "spearman")
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1],
>>> ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>


From xavier.chiriboga at unine.ch  Tue Jan 31 01:18:40 2017
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Tue, 31 Jan 2017 00:18:40 +0000
Subject: [R] HELP GLM
Message-ID: <1485821921225.45014@unine.ch>

Dear colleagues,


I am trying to perform GLM but I got the following message.


 m2<-glm(induction~time+plant,data=b)
Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
  NA/NaN/Inf in 'y'
Adem?s: Warning messages:
1: In Ops.factor(y, mu) : '-' not meaningful for factors
2: In Ops.factor(eta, offset) : '-' not meaningful for factors
3: In Ops.factor(y, mu) : '-' not meaningful for factors


Do you know why it is not working?


Thank you for your help,


Xavier

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Jan 31 03:09:18 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 13:09:18 +1100
Subject: [R] HELP GLM
In-Reply-To: <1485821921225.45014@unine.ch>
References: <1485821921225.45014@unine.ch>
Message-ID: <CA+8X3fVxGu2RhmWDO1ZHQzFwUKa7TWE78DxhE__JYcuRRoeEYA@mail.gmail.com>

After scrupulous textual analysis, I conclude that you have at least
one NA/NaN/Inf in b$induction. There is also a hint that you should
acquaint yourself with family="binomial".

Sherlock

On Tue, Jan 31, 2017 at 11:18 AM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Dear colleagues,
>
>
> I am trying to perform GLM but I got the following message.
>
>
>  m2<-glm(induction~time+plant,data=b)
> Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
>   NA/NaN/Inf in 'y'
> Adem?s: Warning messages:
> 1: In Ops.factor(y, mu) : '-' not meaningful for factors
> 2: In Ops.factor(eta, offset) : '-' not meaningful for factors
> 3: In Ops.factor(y, mu) : '-' not meaningful for factors
>
>
> Do you know why it is not working?
>
>
> Thank you for your help,
>
>
> Xavier
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Jan 31 04:23:29 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 14:23:29 +1100
Subject: [R] Challenge extracting months
In-Reply-To: <CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
	<CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
Message-ID: <CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>

Hi Kwesi,
A mistake in the last email. Don't try to replace the column in
era.sta as the result will be a different length. Try this:

newera.sta2<-collapse.values(era.sta[,2],3)

Jim

On Tue, Jan 31, 2017 at 10:32 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Kwesi,
> The function collapse_values will only work on a vector of numbers
> with FUN="mean". era.sta looks like a data frame with at least two
> elements. As the second of these elements seems to be numeric, perhaps
> this will work:
>
> era.sta[,2]<-collapse.values(era.sta[,2],3)
>
> Don't try to apply the names to era.sta, that was just something to
> make the example easier to understand. If you want to collapse more
> than one column of era.sta do each one at a time and assign them to a
> new data frame. In particular, if era[,1] is a vector of month names,
> you will have to create a new vector of quarter (three month) names.
> If there are very many of these, the collapse_values function can be
> modified to do it automatically.
>
> Jim
>
>
>
> On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
>> Hello Jim,this is my script now; I am having this error when I called the
>> function;" In mean.default(list(era...1. = 1:444, Node_freq =
>> c(-0.389855332400718,  :  argument is not numeric or logical: returning NA"
>> Any help will be much appreciated.
>>
>> Kwesi
>>
>> rm(list = ls())
>> setwd('/home/kwesi/Documents/700hpa/soms/')
>> # Reading the data
>>
>> era       <- read.csv(file="som_freq.csv",header = TRUE, sep = ",",dec =
>> ".")
>> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
>> era.sta<-data.frame(era[,1],era.scaled)
>> era.sta
>>
>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>>   jump<-span-1
>>   newx<-rep(NA,length(x)-jump)
>>   for(i in 1:length(newx))
>>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>>   return(newx)
>> }
>>
>> #test<-1:12
>> names(era.sta)<-month.abb
>> collapse_values(era.sta,3)
>> era.sta
>>
>>
>> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Kwesi,
>>> Even without the data, it seems clear that you want something like a
>>> rolling mean. Here is a simple function that will apply a function
>>> like "mean" to successive bits of a vector of numbers:
>>>
>>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>>>  jump<-span-1
>>>  newx<-rep(NA,length(x)-jump)
>>>  for(i in 1:length(newx))
>>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>>>  return(newx)
>>> }
>>>
>>> test<-1:12
>>> names(test)<-month.abb
>>> test
>>> collapse_values(test,3)
>>>  [1]  2  3  4  5  6  7  8  9 10 11
>>>
>>> Jim
>>>
>>>
>>>
>>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
>>> <starskykwesi at gmail.com> wrote:
>>> > Hello, I have a data with two variables nodes and index, I want to
>>> > extract
>>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc to
>>> > OND. Was wondering how to go about it. Kindly find attached the data as
>>> > csv.
>>> > Any help will be appreciated.
>>> >
>>> > Regards,
>>> > Kwesi
>>> >
>>> > --
>>> > Try not to become a man of success but rather a man of value-Albert
>>> > Einstein
>>> >
>>> > University of Cape Coast|College of Agriculture and Natural
>>> > Sciences|Department
>>> > of Physics|
>>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>>> > Mobile: +233266173582
>>> > Skype: quagraine_cwasi
>>> > Twitter: @Pkdilly
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>> --
>> Try not to become a man of success but rather a man of value-Albert Einstein
>>
>> University of Cape Coast|College of Agriculture and Natural
>> Sciences|Department of Physics|
>> Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> Mobile: +233266173582
>> Skype: quagraine_cwasi
>> Twitter: @Pkdilly
>>


From sigbert at wiwi.hu-berlin.de  Tue Jan 31 08:54:11 2017
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Tue, 31 Jan 2017 08:54:11 +0100
Subject: [R] Misleading error message: XML content does not seem to be XML
Message-ID: <8267d201-2787-00dc-a9ba-07e284ef031d@wiwi.hu-berlin.de>

Hi,

using the XML package reading an XML file

library("XML")
doc  <- xmlParse(file='abc.xml')

I got the above error message. The problem was that the file was located 
at a different directory. So the file was not found rather than 
containing invalid XML.

Best Sigbert

-- 
http://u.hu-berlin.de/sk


From drjimlemon at gmail.com  Tue Jan 31 09:50:38 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Jan 2017 19:50:38 +1100
Subject: [R] caculate correlation
In-Reply-To: <705924209.578370.1485851300485@mail.yahoo.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
	<1908713206.125008.1485812723647@mail.yahoo.com>
	<CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>
	<579290005.175382.1485814667600@mail.yahoo.com>
	<CA+8X3fXsqP=zwHGODvzUujE4v8YsQy7kZ797B_eDq-qXK+qOKA@mail.gmail.com>
	<705924209.578370.1485851300485@mail.yahoo.com>
Message-ID: <CA+8X3fVV5Q4bbjHjN2SrTdEnyaTyesmNvbUSuTY4nSPHHDpvwA@mail.gmail.com>

Hi Elham,

On Tue, Jan 31, 2017 at 7:28 PM, Elham - <ed_isfahani at yahoo.com> wrote:
> Hi Dear Jim,
>
> I did it, both return a vector of name of the genes with different length,as
> I said before I have list of coding and noncoding so the length are not
> same.
>
> where is number?!
>
Not in the values you are extracting from the data frame. As you are
aware, you can only perform the "cor" operation on numbers. As the
value returned refers to the correlation of _pairs_ of values, the
vectors of numbers should be the same length and there should be some
meaningful relationship between those pairs. Are you just trying to
correlate any old numbers because they are numbers?

> and at the end of print there is this error :
>
> <0 rows> (or 0-length row.names)
>
This is probably not an error, just R telling you that something that
was requested didn't have anything in it. Maybe one day we will find
out what is in:

coding.rpkm
ncoding.rpkm

and we can provide more informed advice.

Jim


From marc_grt at yahoo.fr  Tue Jan 31 11:59:48 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 31 Jan 2017 11:59:48 +0100
Subject: [R] g parameter for deltaMethod() as a function
In-Reply-To: <E047408E-94B0-424D-8E66-40604520AAD6@mcmaster.ca>
References: <ae5442f2-6867-5a10-bb58-d19b64022ba1@yahoo.fr>
	<ACD1644AA6C67E4FBD0C350625508EC8365E1F70@FHSDB2D11-2.csu.mcmaster.ca>
	<b512a5c6-6fa4-59ee-f843-eb1fe8d5c674@yahoo.fr>
	<ACD1644AA6C67E4FBD0C350625508EC8365E1FE4@FHSDB2D11-2.csu.mcmaster.ca>
	<E047408E-94B0-424D-8E66-40604520AAD6@mcmaster.ca>
Message-ID: <474d15ae-0fa2-7d90-6514-fa84d1270f6b@yahoo.fr>

Dear John and list members,

I have found a solution using the package nlWaldTest. I post the 
solution in case someone else will have this problem.

Here is a summary of the problem:
I would like use the delta method for a function for which no derivative 
using D() can be calculated. I would like rather use numerical derivative.

Here is the solution. In the two first examples, symbolic derivative is 
used.

library(car)
m1 <- lm(time ~ t1 + t2, data = Transact)
deltaMethod(coef(m1), "t1/t2", vcov.=vcov(m1))

library("nlWaldTest")
nlConfint(obj = NULL, texts="b[2]/b[3]", level = 0.95, coeff = coef(m1),
           Vcov = vcov(m1), df2 = TRUE, x = NULL)

############# Now numerical derivative is used. The result is the same.

try_g <- function(...) {
   par <- list(...)
   return(par[[1]]/par[[2]])
}

nlConfint(obj = NULL, texts="try_g(b[2], b[3])", level = 0.95, coeff = 
coef(m1),
           Vcov = vcov(m1), df2 = TRUE, x = NULL)

Marc


From petr.pikal at precheza.cz  Tue Jan 31 15:18:26 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 31 Jan 2017 14:18:26 +0000
Subject: [R] (no subject)
In-Reply-To: <CAGD2cKdWCmEeSRZ-oP8V-458YxUi90anx_xFpYGxJAYakDxrsQ@mail.gmail.com>
References: <CAGD2cKdsAeLORnWj4ANFc4763R2839g8QHC6d92yDi4fZ4CBaA@mail.gmail.com>
	<1F7C867A-BC3F-4F1E-B8B1-28DE056BE7C7@dcn.davis.ca.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A13AB8@SRVEXCHCM301.precheza.cz>
	<CAGD2cKdWCmEeSRZ-oP8V-458YxUi90anx_xFpYGxJAYakDxrsQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A13EF6@SRVEXCHCM301.precheza.cz>

Hi

Of course you have fewer values than in original data.

> x<-1:21

> length(rowSums(embed(x,3)))
[1] 19
> length(x)
[1] 21

> embed(x,3)
      [,1] [,2] [,3]
[1,]    3    2    1
[2,]    4    3    2
[3,]    5    4    3
[4,]    6    5    4
[5,]    7    6    5
[6,]    8    7    6
[7,]    9    8    7
[8,]   10    9    8
[9,]   11   10    9
[10,]   12   11   10
[11,]   13   12   11
[12,]   14   13   12
[13,]   15   14   13
[14,]   16   15   14
[15,]   17   16   15
[16,]   18   17   16
[17,]   19   18   17
[18,]   20   19   18
[19,]   21   20   19

You need to prepend or append 2 NA values if you want to add newly computed values to old data.

or extend your original vector by 2 values

length(rowSums(embed(c(NA, NA, x),3), na.rm=T))
[1] 21

Cheers
Petr


From: Kwesi Quagraine [mailto:starskykwesi at gmail.com]
Sent: Monday, January 30, 2017 6:29 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
Subject: Re: [R] (no subject)

Upon trying this method, I get an error ;

Error in `$<-.data.frame`(`*tmp*`, "MEImeans", value = c(0.313162987462034,  :
  replacement has 442 rows, data has 444
Any thoughts?
Kwesi

On Mon, Jan 30, 2017 at 5:37 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Probably just a small correction.

d3 <- embed( dta$MEI, 3)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Jeff
> Newmiller
> Sent: Monday, January 30, 2017 4:19 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>; Kwesi Quagraine <starskykwesi at gmail.com<mailto:starskykwesi at gmail.com>>
> Subject: Re: [R] (no subject)
>
> How you proceed depends on how consistent the data are and on what you
> want to do with those sets of three months after you have identified them.
>
> One approach is to create a matrix where each row contains the values
> corresponding to the "second previous", "previous", and "current" months
> data, respectively using the embed() function. The first two rows would be
> incomplete because the earlier data are missing there:
>
> d3 <- embed( dta$MEI )
>
> with which you could compute whatever metric you wanted. For example
> you could compute rolling means:
>
> dta$MEImeans <- rowMeans( d3 )
>
> If your data have missing rows you might need to use the aggregate or
> merge functions instead.
>
> For specific layouts of data or metrics you can find specialized functions in
> various packages. You might want to search using the R "sos" package or
> Google for your analysis method of choice.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 30, 2017 6:11:48 AM PST, Kwesi Quagraine
> <starskykwesi at gmail.com<mailto:starskykwesi at gmail.com>> wrote:
> >Hello, I have a data with two variables nodes and index, I want to
> >extract
> >3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA etc
> >to OND. Was wondering how to go about it. Kindly find data sample
> >below, data is in csv format.
> >Any help will be appreciated.
> >
> >My data sample;
> >
> >      era...1.    Node_freq           MEI
> >1   1980-01-01 -0.389855332  0.3394196488<tel:3394196488>
> >2 1980-02-01 -0<tel:2%20%20%201980-02-01%20-0>.728019153  0.2483738232<tel:2483738232>
> >3   1980-03-01 -1.992457784  0.3516954904
> >4   1980-04-01  0.222760284  0.5736836269
> >5   1980-05-01  0.972601798  0.6289249144
> >6   1980-06-01  0.570725954  0.5736836269
> >7   1980-07-01 -0.977966324  0.4120517119
> >8   1980-08-01  0.056128836 -0.0104418383
> >9   1980-09-01  0.987304573 -0.0687520861
> >10  1980-10-01  1.188242495 -0.1403611624
> >11  1980-11-01  1.693037763 -0.0963727298
> >12  1980-12-01  1.173539720 -0.2539126977
> >13  1981-01-01  0.423698206 -0.6140040528
> >14  1981-02-01 -2.208098481 -0.5209122536
> >15  1981-03-01 -0.786830252  0.1133395650
> >16  1981-04-01 -0.110502611  0.3302127675
> >17  1981-05-01 -1.272021820 -0.1894645290
> >18  1981-06-01  0.394292656 -0.3736021538
> >19  1981-07-01  1.452892441 -0.4032687711
> >20  1981-08-01  0.698150002 -0.4441882433
> >21  1981-09-01  0.997106423 -0.1720737534
> >22  1981-10-01  0.247264908 -0.2436828296
> >23  1981-11-01  0.771663876 -0.3909929295
> >24  1981-12-01 -0.316341458 -0.4943145967
> >
> >Regards,
> >?Kwesi?
> >
> >--
> >Try not to become a man of success but rather a man of value-Albert
> >Einstein
> >
> >University of Cape Coast|College of Agriculture and Natural
> >Sciences|Department
> >of Physics|
> >Team Leader|Recycle Up! Ghana|Technology Without Borders| Other
> emails:
> >kwesi.quagraine at ucc.edu.gh<mailto:kwesi.quagraine at ucc.edu.gh>|kwesi.quagraine at teog.de<mailto:kwesi.quagraine at teog.de>|
> >Mobile: +233266173582<tel:%2B233266173582>
> >Skype: quagraine_cwasi
> >Twitter: @Pkdilly
> >
> >     [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



--
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh<mailto:kwesi.quagraine at ucc.edu.gh>|kwesi.quagraine at teog.de<mailto:kwesi.quagraine at teog.de>|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Tue Jan 31 16:43:16 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 31 Jan 2017 15:43:16 +0000
Subject: [R] Failure to understand namespaces in XML::getNodeSet
Message-ID: <C93BCEFF-3EB2-4422-8BDF-9B305E393424@txbiomed.org>

I am trying to read a series of XML files that use a namespace and I have failed, thus far, to discover the proper syntax. I have a reproducible example below. I have two XML character strings defined: one without a namespace and one with. I show that I can successfully extract the node using the XML string without the namespace and fail when using the XML string with the namespace.

Mark
PS I am having the same problem with the xml2 package and am hoping understanding one with help with the other.

##
library(XML)
## The first XML text (no_ns_xml) does not have a namespace defined
no_ns_xml <- c("<?xml version=\"1.0\" ?>", "<WorkSet>",
               "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
               "</WorkSet>")
l_no_ns_xml <-xmlTreeParse(no_ns_xml, asText = TRUE, getDTD = FALSE,
                           useInternalNodes = TRUE)
## The node is found
getNodeSet(l_no_ns_xml, "/WorkSet//Description")

## The second XML text (with_ns_xml) has a namespace defined
with_ns_xml <- c("<?xml version=\"1.0\" ?>",
                 "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
                 "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
                 "</WorkSet>")

l_with_ns_xml <-xmlTreeParse(with_ns_xml, asText = TRUE, getDTD = FALSE,
                               useInternalNodes = TRUE)
## The node is not found
getNodeSet(l_with_ns_xml, "/WorkSet//Description")
## I attempt to provide the namespace, but fail.
ns <-  "http://labkey.org/etl/xml"
names(ns)[1] <- "xmlns"
getNodeSet(l_with_ns_xml, "/WorkSet//Description", namespaces = ns)

R. Mark Sharp, Ph.D.
Director of Data Science Core
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org









CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From ed_isfahani at yahoo.com  Tue Jan 31 09:28:20 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Tue, 31 Jan 2017 08:28:20 +0000 (UTC)
Subject: [R] caculate correlation
In-Reply-To: <CA+8X3fXsqP=zwHGODvzUujE4v8YsQy7kZ797B_eDq-qXK+qOKA@mail.gmail.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
	<1908713206.125008.1485812723647@mail.yahoo.com>
	<CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>
	<579290005.175382.1485814667600@mail.yahoo.com>
	<CA+8X3fXsqP=zwHGODvzUujE4v8YsQy7kZ797B_eDq-qXK+qOKA@mail.gmail.com>
Message-ID: <705924209.578370.1485851300485@mail.yahoo.com>

Hi Dear Jim,

I did it, both return a vector of name of the genes with different?length,as I said before I have list of coding and noncoding so the length are not same.
where is number?!

and at the end of print there is this error :

<0 rows> (or 0-length row.names)
 

    On Tuesday, January 31, 2017 3:07 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Elham,
What I meant is to simply copy these two expressions into the R command line:

coding.rpkm[grep("23.C",coding.rpkm$name),-1]

ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1]

and see what comes out. If both return a vector of numbers of the same
length with no NA values, my guess was wrong. If there are NA values,
try adding the argument use=pairwise.complete.obs to the "cor"
statement.

Jim


On Tue, Jan 31, 2017 at 9:17 AM, Elham - <ed_isfahani at yahoo.com> wrote:
> this script automatically recognizes what is control among cod and lnc. Note
> that this script contains a piece of text that is "grep(".C",cod$name)".
> This text select - among all column names - those that contain ".C". in my
> files, I named C1, C2, C3, etc all columns that correspond to controls. In
> the same manner, I get controls among the lnc, with the text:
> "grep(".C",lnc$name)"
>
> I`m so sorry,maybe I do not understand you again.
>
>
> On Tuesday, January 31, 2017 1:27 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Elham,
> This is about the same as your first message. What I meant was, what
> do these two expressions return? Is whatever is returned suitable
> input for the "cor" function?
>
> coding.rpkm[grep("23.C",coding.rpkm$name),-1]
>
> ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1]
>
> Jim
>
>
> On Tue, Jan 31, 2017 at 8:45 AM, Elham - <ed_isfahani at yahoo.com> wrote:
>> I have 9 experiments control/treatment that I analysed coding and
>> lncoding,
>> after that I normalize expression value.as you know we have different
>> known
>> number of coding and non -coding genes,so for calculating correlation
>> first
>> I transposed data ,(rows become columns)so row is control&treatment and
>> columns are gene names.(so I have 2 matrix with same row and different
>> column).This information is enough?
>>
>>
>>
>>
>> On Tuesday, January 31, 2017 1:06 AM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>
>>
>> Hi Elham,
>> Without knowing much about what coding.rpkm and ncoding.rkpm look
>> like, it is difficult to say. Have you tried to subset these matrices
>> as you do in the "cor" function and see what is returned?
>>
>> Jim
>>
>> On Tue, Jan 31, 2017 at 6:40 AM, Elham - via R-help
>> <r-help at r-project.org> wrote:
>>> for calculating correlation between coding and noncoding,first I
>>> transposed data ,(rows become columns) so row is control&treatment and
>>> columns are gene names.(so I have 2 matrix with same row and different
>>> column),I use these function for calculating correlation but all of
>>> spearman
>>> correlation are NA,why?
>>>
>>>
>>>
>>>
>>> control.corr=cor(coding.rpkm[grep("23.C",coding.rpkm$name),-1],ncoding.rpkm[grep("23.C",ncoding.rpkm$name),-1],method=
>>> "spearman")
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> tumor.corr=cor(coding.rpkm [grep("27.T", coding.rpkm $name),-1],
>>> ncoding.rpkm [grep("27.T", ncoding.rpkm $name),-1],method = "spearman")
>>>
>>>? ? ? ? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>


   
	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Tue Jan 31 11:04:29 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Tue, 31 Jan 2017 12:04:29 +0200
Subject: [R] Challenge extracting months
In-Reply-To: <CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
	<CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
	<CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>
Message-ID: <CAGD2cKe-M=v7qpfbnmwV2VOZ1qFGRC2ABv+=CtsqoQ=mFOA43Q@mail.gmail.com>

Hello Jim, thanks for the code. But I come to you once again, I am not
looking to do a rolling mean, but to select JFM,FMA,MAM etc from the data
attached. Below is my sample code which actually selects these months. I
will rather be glad if I can have a function that does the selection for
all these 3 months selected for each year as shown in my last two lines of
code; Taking into accounts years with 29 days in February etc.

rm(list = ls())
library(zoo)
library(PCICt)
library(lattice)
library(RColorBrewer)

setwd('/home/kwesi/Documents/700hpa/soms/')
# Reading the data

era       <- read.table(file="SAfr_700hpa_5x4II.txt",header = FALSE, sep =
"",skip=1,dec = ".")
era.nodes      <- paste(era[,1],era[,2],sep=".")

era.nodes      <-as.numeric(era.nodes)
era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-
01"),end=as.Date("2016-12-31"))

era.nodes.days.t1<-window(era.nodes.days,start=as.Date("
1980-01-01"),end=as.Date("2016-12-31"))

mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
seas.t1 <-as.numeric(format(index(era.nodes.days.t1),"%Y"))
era.nodes.days.t1<-cbind(era.nodes.days.t1,mon.t1,seas.t1)
era.nodes.days.t1
jfm80<-era.nodes.days.t1[1:91,1:3[era.nodes.days.t1[1:91,2]=
=1|era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3]
fma80<-era.nodes.days.t1[32:(91+30),1:3 [era.nodes.days.t1[1:91,2]==2|
era.nodes.days.t1[1:91,2]==3|era.nodes.days.t1[1:91,2]==4]

On Tue, Jan 31, 2017 at 5:23 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kwesi,
> A mistake in the last email. Don't try to replace the column in
> era.sta as the result will be a different length. Try this:
>
> newera.sta2<-collapse.values(era.sta[,2],3)
>
> Jim
>
> On Tue, Jan 31, 2017 at 10:32 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi Kwesi,
> > The function collapse_values will only work on a vector of numbers
> > with FUN="mean". era.sta looks like a data frame with at least two
> > elements. As the second of these elements seems to be numeric, perhaps
> > this will work:
> >
> > era.sta[,2]<-collapse.values(era.sta[,2],3)
> >
> > Don't try to apply the names to era.sta, that was just something to
> > make the example easier to understand. If you want to collapse more
> > than one column of era.sta do each one at a time and assign them to a
> > new data frame. In particular, if era[,1] is a vector of month names,
> > you will have to create a new vector of quarter (three month) names.
> > If there are very many of these, the collapse_values function can be
> > modified to do it automatically.
> >
> > Jim
> >
> >
> >
> > On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine <starskykwesi at gmail.com>
> wrote:
> >> Hello Jim,this is my script now; I am having this error when I called
> the
> >> function;" In mean.default(list(era...1. = 1:444, Node_freq =
> >> c(-0.389855332400718,  :  argument is not numeric or logical: returning
> NA"
> >> Any help will be much appreciated.
> >>
> >> Kwesi
> >>
> >> rm(list = ls())
> >> setwd('/home/kwesi/Documents/700hpa/soms/')
> >> # Reading the data
> >>
> >> era       <- read.csv(file="som_freq.csv",header = TRUE, sep = ",",dec
> =
> >> ".")
> >> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
> >> era.sta<-data.frame(era[,1],era.scaled)
> >> era.sta
> >>
> >> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
> >>   jump<-span-1
> >>   newx<-rep(NA,length(x)-jump)
> >>   for(i in 1:length(newx))
> >>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
> >>   return(newx)
> >> }
> >>
> >> #test<-1:12
> >> names(era.sta)<-month.abb
> >> collapse_values(era.sta,3)
> >> era.sta
> >>
> >>
> >> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>
> >>> Hi Kwesi,
> >>> Even without the data, it seems clear that you want something like a
> >>> rolling mean. Here is a simple function that will apply a function
> >>> like "mean" to successive bits of a vector of numbers:
> >>>
> >>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
> >>>  jump<-span-1
> >>>  newx<-rep(NA,length(x)-jump)
> >>>  for(i in 1:length(newx))
> >>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
> >>>  return(newx)
> >>> }
> >>>
> >>> test<-1:12
> >>> names(test)<-month.abb
> >>> test
> >>> collapse_values(test,3)
> >>>  [1]  2  3  4  5  6  7  8  9 10 11
> >>>
> >>> Jim
> >>>
> >>>
> >>>
> >>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
> >>> <starskykwesi at gmail.com> wrote:
> >>> > Hello, I have a data with two variables nodes and index, I want to
> >>> > extract
> >>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA
> etc to
> >>> > OND. Was wondering how to go about it. Kindly find attached the data
> as
> >>> > csv.
> >>> > Any help will be appreciated.
> >>> >
> >>> > Regards,
> >>> > Kwesi
> >>> >
> >>> > --
> >>> > Try not to become a man of success but rather a man of value-Albert
> >>> > Einstein
> >>> >
> >>> > University of Cape Coast|College of Agriculture and Natural
> >>> > Sciences|Department
> >>> > of Physics|
> >>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
> >>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> >>> > Mobile: +233266173582
> >>> > Skype: quagraine_cwasi
> >>> > Twitter: @Pkdilly
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >>> > http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >> --
> >> Try not to become a man of success but rather a man of value-Albert
> Einstein
> >>
> >> University of Cape Coast|College of Agriculture and Natural
> >> Sciences|Department of Physics|
> >> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> >> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> >> Mobile: +233266173582
> >> Skype: quagraine_cwasi
> >> Twitter: @Pkdilly
> >>
>



-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly
-------------- next part --------------
3 rect 7 5 bubble
5 3 262.743 
6 3 359.22 
6 2 312.448 
6 2 354.72 
5 3 314.867 
4 4 357.216 
3 3 400.566 
1 2 231.919 
1 2 235.411 
1 2 239.103 
1 2 464.147 
4 1 466.655 
3 3 402.066 
1 1 382.157 
1 0 303.911 
0 0 470.562 
1 0 513.253 
2 0 421.147 
1 0 308.818 
1 0 264.989 
1 1 286.063 
0 3 315.745 
0 4 313.184 
0 4 366.756 
0 4 400.392 
2 4 534.889 
3 4 437.125 
4 4 413.559 
3 4 408.606 
3 4 401.4 
4 4 369.529 
2 3 352.949 
1 3 376.416 
0 4 326.168 
0 4 393.977 
0 1 368.409 
0 2 404.687 
4 1 455.278 
4 1 416.604 
5 1 427.605 
6 2 572.357 
5 3 442.566 
4 4 301.639 
5 4 476.283 
5 3 462.514 
5 2 463.576 
3 3 323.803 
2 1 258.793 
1 0 312.374 
0 0 316.876 
0 0 311.801 
1 1 278.954 
3 0 351.28 
3 0 310.807 
3 0 393.349 
3 0 397.366 
4 0 489.916 
4 0 509.192 
1 1 300.306 
0 1 393.326 
0 2 469.11 
1 2 334.395 
1 2 306.296 
1 1 298.577 
1 1 270.184 
3 0 414.842 
4 0 430.052 
4 1 418.762 
1 1 407.965 
0 4 463.342 
0 4 482.931 
0 0 570.422 
0 1 479.212 
0 1 384.128 
1 2 329.899 
3 4 569.741 
4 4 647.495 
0 4 301.806 
0 0 337.595 
0 0 313.357 
0 0 283.128 
0 0 337.221 
1 0 324.405 
1 0 250.863 
2 0 310.858 
2 0 218.516 
2 0 307.276 
2 0 281.828 
2 1 226.371 
2 0 286.091 
2 1 338.935 
1 0 426.228 
1 0 321.939 
3 0 262.425 
6 0 400.465 
6 1 337.543 
5 2 186.789 
4 2 276.876 
5 1 288.933 
5 1 329.775 
4 2 416.436 
4 3 489.321 
4 3 369.539 
4 2 373.39 
6 4 423.206 
6 4 340.209 
6 3 457.823 
5 4 561.557 
4 4 502.644 
3 4 518.399 
2 2 447.769 
2 3 498.375 
1 2 362.989 
1 2 319.798 
1 2 367.224 
1 3 204.403 
1 0 232.86 
1 0 257.377 
2 0 505.885 
2 0 583.042 
2 0 407.602 
3 0 401.506 
4 0 396.104 
3 1 436.173 
6 0 418.79 
5 0 315.67 
5 0 353.223 
5 2 427.816 
4 3 416.294 
3 2 492.841 
5 1 364.616 
5 1 385.404 
5 1 200.477 
6 1 326.151 
6 2 421.589 
6 0 639.7 
6 0 733.992 
5 1 503.622 
3 2 239.735 
2 1 387.641 
1 0 498.019 
2 0 566.835 
2 0 339.611 
5 0 286.868 
6 2 534.988 
6 2 404.129 
6 2 290.965 
3 2 419.852 
1 2 381.364 
4 1 439.474 
2 4 317.164 
1 3 352.197 
4 1 274.574 
3 1 307.977 
1 3 364.437 
1 4 470.65 
2 4 430.455 
2 4 366.58 
2 3 228.209 
1 2 229.555 
3 1 197.486 
2 2 240.976 
1 1 371.263 
3 0 361.302 
4 0 230.01 
3 2 265.395 
3 3 379.501 
4 4 676.61 
2 4 912.576 
0 1 460.657 
3 0 320.051 
5 0 351.297 
4 1 538.373 
5 3 528.858 
5 2 396.559 
5 3 358.29 
6 0 464.554 
6 1 424.088 
6 2 539.966 
5 4 748.059 
5 4 960.802 
4 4 867.488 
3 4 407.092 
2 4 254.101 
2 4 350.995 
2 3 343.393 
2 2 298.684 
2 2 276.426 
1 3 350.707 
2 0 199.987 
2 1 266.151 
2 1 392.663 
3 0 534.302 
6 0 394.356 
3 2 477.207 
2 2 395.206 
2 3 370.538 
2 4 543.846 
0 4 539.861 
2 0 458.614 
1 1 318.511 
1 0 355.77 
3 0 471.225 
3 0 343.465 
2 3 395.058 
2 3 545.167 
1 0 506.524 
2 0 427.646 
3 0 508.042 
5 0 509.807 
5 0 615.281 
0 2 710.295 
0 3 475.28 
0 4 415.144 
0 0 462.638 
2 4 356.336 
0 0 538.845 
2 0 607.157 
3 0 656.647 
3 1 418 
3 2 356.616 
2 3 291.511 
2 3 342.111 
3 1 334.593 
5 0 400.327 
4 3 686.315 
4 4 507.919 
3 4 580.53 
1 3 430.062 
0 0 394.535 
1 0 293.688 
2 2 356.105 
2 3 336.5 
2 1 528.197 
6 0 592.808 
6 0 444.662 
5 3 452.835 
4 2 511.203 
5 1 420.435 
5 4 502.96 
3 2 534.749 
2 1 629.854 
3 2 609.083 
6 1 400.764 
5 2 479.639 
6 0 388.745 
6 1 400.18 
5 1 449.991 
4 2 424.278 
4 4 380.328 
1 4 428.515 
0 0 445.493 
2 0 497.266 
4 1 367.741 
5 2 287.039 
6 4 354.892 
5 4 354.925 
3 4 510.337 
3 2 312.229 
6 4 408.687 
6 4 482.591 
6 4 591.504 
4 4 578.875 
5 1 421.524 
4 2 426.709 
3 4 359.145 
0 4 447.868 
0 0 483.066 
0 0 295.196 
0 2 261.278 
4 2 395.285 
5 4 446.672 
4 3 503.587 
3 2 562.566 
6 1 433.691 
6 3 506.974 
6 4 416.788 
5 2 395.472 
5 3 410.669 
3 2 473.222 
3 4 725.679 
2 3 541.647 
2 3 386.923 
2 0 436.131 
2 1 371.198 
2 3 366.096 
3 1 255.869 
5 2 285.216 
5 3 268.967 
4 2 334.209 
4 3 271.483 
4 3 342.448 
4 4 258.993 
4 3 468.642 
5 1 410.339 
5 3 451.818 
4 4 366.251 
4 4 389.09 
4 4 354.185 
3 3 396.865 
2 3 476.671 
2 3 445.639 
2 4 399.486 
2 4 472.009 
1 4 375.332 
1 4 474.112 
1 4 484.074 
2 3 394.342 
3 2 248.658 
5 3 363.161 
6 3 557.864 
5 3 465.915 
5 4 312.968 
6 4 449.254 
6 3 531.065 
6 2 708.805 
6 2 751.658 
6 3 440.598 
6 4 508.023 
6 4 482.457 
6 2 369.579 
6 2 513.147 
5 2 797.132 
5 2 584.889 
5 4 357.411 
5 3 321.471 
5 4 406.062 
4 4 426.051 
3 4 233.142 
3 3 258.578 
4 4 374.431 
3 4 504.076 
2 4 592.089 
0 4 654.3 
0 3 373.351 
0 3 373.489 
0 2 353.079 
3 4 500.409 
1 2 485.249 
3 1 474.234 
4 0 379.303 
4 1 389.678 
3 3 320.803 
3 4 405.729 
3 4 393.768 
3 3 256.145 
3 3 278.824 
2 3 276.567 
1 3 236.65 
3 1 305.551 
4 2 273.982 
5 3 259.489 
6 4 484.862 
6 3 814.385 
6 1 848.907 
6 2 279.55 
6 2 488.471 
6 1 478.352 
4 1 380.706 
2 1 359.574 
3 0 324.762 
3 2 338.389 
4 3 295.673 
4 3 355.551 
5 4 395.277 
5 3 499.143 
5 2 317.61 
5 1 271.015 
4 1 328.031 
3 3 467.143 
2 4 373.893 
1 3 342.16 
3 3 315.511 
4 4 342.645 
2 4 291.991 
3 4 273.733 
5 3 249.283 
4 2 239.317 
5 2 332.764 
5 2 312.789 
4 2 192.517 
4 2 259.638 
4 3 384.876 
3 4 399.474 
4 1 481.513 
4 1 288.379 
2 2 311.402 
3 2 300.996 
4 2 486.271 
0 3 605.289 
0 4 899.76 
0 0 903.059 
0 4 486.886 
0 4 223.096 
1 3 228.621 
3 4 361.636 
3 4 303.829 
1 4 364.491 
0 0 395.271 
0 0 361.766 
0 1 324.592 
1 3 390.797 
1 4 329.884 
0 4 261.54 
0 1 425.867 
4 0 475.05 
4 1 345.539 
4 2 380.17 
1 3 380.245 
1 3 294.534 
0 0 319.079 
0 0 430.652 
0 0 492.976 
0 0 532.427 
0 0 432.117 
0 1 370.294 
0 1 363.36 
0 3 333.25 
0 2 431.057 
0 2 538.727 
0 1 296.13 
0 1 259.626 
1 1 199.639 
3 0 305.06 
2 1 292.084 
3 0 261.694 
4 1 517.644 
4 4 426.074 
1 4 418.587 
0 4 515.296 
0 4 414.527 
0 4 249.535 
1 4 250.253 
2 4 260.561 
2 4 204.256 
2 3 237.205 
2 3 269.452 
1 4 227.701 
2 3 276.409 
3 4 458.677 
3 4 430.37 
3 4 330.219 
3 4 354.522 
2 2 333.737 
2 1 322.34 
2 2 265.147 
4 0 363.227 
6 0 659.849 
4 0 671.87 
0 1 474.031 
0 3 393.179 
0 1 426.138 
0 2 379.528 
3 4 351.342 
2 4 505.36 
2 1 334.882 
4 1 308.58 
3 2 330.746 
3 2 357.819 
3 2 510.881 
3 2 392.382 
4 2 335.528 
5 2 373.836 
5 4 319.404 
3 4 420.605 
3 1 475.82 
5 2 402.47 
5 3 423.075 
5 2 489.035 
3 2 501.121 
3 0 381.928 
1 1 394.841 
0 4 367.014 
0 0 302.5 
1 0 279.463 
1 4 351.411 
1 0 300.761 
3 0 262.04 
4 0 363.343 
0 2 217.808 
0 2 367.528 
0 2 646.198 
0 2 771.068 
4 3 402.135 
3 3 267.107 
2 2 356.479 
4 2 328.479 
4 4 280.826 
2 2 368.244 
0 2 394.552 
4 3 405.695 
0 3 323.91 
0 3 424.609 
0 2 671.691 
4 0 742.723 
4 0 615.067 
4 0 612.744 
0 2 495.551 
0 2 462.628 
0 0 304.756 
0 0 393.563 
0 0 436.226 
2 0 534.232 
1 0 446.313 
1 0 497.419 
1 0 307.619 
2 3 356.08 
1 4 374.114 
0 0 370.987 
2 0 343.116 
4 0 262.006 
4 1 376.609 
0 2 381.61 
0 3 396.148 
0 2 441.525 
0 2 454.915 
0 2 323.193 
0 1 458.928 
4 0 688.072 
5 0 531.809 
4 1 532.013 
5 3 555.114 
5 4 586.997 
2 4 668.203 
0 4 603.67 
1 1 459.907 
2 3 314.426 
2 2 397.788 
2 1 364.298 
1 0 353.816 
2 1 222.521 
4 3 318.189 
3 3 477.153 
3 2 491.601 
4 1 345.8 
5 0 375.409 
6 0 428.793 
5 2 390.826 
4 2 452.999 
4 0 276.13 
5 0 253.901 
4 2 311.129 
6 3 443.517 
6 4 660.42 
6 4 652.26 
5 3 492.447 
4 3 349.803 
4 4 240.775 
3 4 440.814 
2 4 370.527 
2 3 408.604 
5 2 448.561 
6 2 598.815 
6 3 655.333 
5 4 485.166 
5 0 537.696 
6 0 618.368 
6 1 761.159 
6 1 691.321 
5 2 252.372 
4 3 246.716 
4 3 360.568 
5 2 651.225 
5 1 467.363 
6 0 374.835 
6 1 395.367 
5 2 317.958 
5 0 341.805 
5 1 306.429 
4 2 316.365 
2 4 270.639 
1 0 542.426 
4 0 626.526 
6 0 494.959 
6 0 410.021 
3 0 270.807 
2 0 556.68 
4 0 456.657 
5 0 454.532 
6 0 653.619 
6 0 646.539 
4 2 490.985 
4 0 570.094 
5 0 479.516 
6 0 454.6 
6 0 338.965 
6 0 554.311 
6 0 504.71 
6 3 385.353 
5 4 267.205 
4 4 500 
3 4 760.626 
3 4 556.693 
4 4 633.163 
4 4 974.89 
2 4 528.428 
3 4 346.579 
2 4 535.746 
0 4 526.083 
0 4 519.976 
0 2 585.324 
0 2 502.865 
4 1 528.015 
6 2 492.787 
5 4 684.388 
0 3 838.161 
0 4 561.348 
0 3 393.292 
3 4 614.278 
0 4 714.286 
0 4 486.638 
0 0 388.056 
0 0 297.096 
1 0 497.447 
4 0 558.731 
5 0 577.867 
5 3 500.542 
3 4 416.397 
2 4 365.869 
1 1 289.513 
2 0 375.272 
5 0 623.278 
6 0 953.889 
6 1 989.821 
6 0 759.156 
6 1 718.735 
6 2 502.557 
6 2 350.277 
5 3 282.461 
3 2 505.803 
3 2 621.41 
3 3 581.197 
3 2 418.917 
5 1 377.988 
5 2 282.014 
5 3 252.671 
6 4 236.057 
5 4 260.119 
4 4 293.019 
6 4 391.028 
6 4 574.708 
5 4 675.385 
6 4 534.541 
5 4 979.075 
4 4 729.378 
4 4 620.67 
4 4 509.563 
3 4 243.997 
1 4 491.838 
0 4 424.968 
1 0 284.525 
2 0 310.202 
3 0 295.677 
4 0 341.139 
0 2 525.133 
4 3 439.877 
1 4 370.007 
0 4 501.644 
0 0 436.161 
3 0 499.648 
4 0 369.039 
4 3 454.386 
3 4 319.289 
1 2 563.357 
4 1 456.19 
4 1 434.182 
5 0 420.022 
5 2 345.481 
4 2 274.433 
4 2 291.973 
2 2 373.549 
2 1 418.22 
2 2 427.645 
3 2 402.05 
3 3 359.125 
3 3 295.594 
3 2 304.227 
4 4 251.609 
3 4 339.75 
1 2 203.684 
3 3 272.523 
3 3 421.261 
1 2 587.38 
4 0 439.539 
4 0 334.079 
4 0 359.633 
4 2 375.952 
4 2 288.426 
4 3 340.2 
3 1 330.91 
6 0 340.966 
6 2 480.631 
5 4 433.622 
1 3 370.909 
0 2 392.849 
4 1 425.422 
4 1 316.791 
5 1 365.104 
5 2 701.058 
4 3 531.671 
1 2 361.993 
0 4 291.657 
0 4 282.152 
0 4 273.29 
0 4 323.346 
0 0 420.068 
1 3 451.76 
2 4 480.223 
1 4 287.767 
0 4 279.655 
4 0 306.339 
4 0 248.632 
1 1 306.149 
1 1 288.498 
4 2 304.978 
4 3 275.694 
1 2 255.405 
3 0 261.632 
4 0 288.21 
4 1 358.519 
2 2 334.35 
1 2 281.769 
0 1 363.912 
1 2 342.319 
4 4 334.044 
4 4 519.599 
4 4 292.17 
4 3 357.679 
5 3 341.788 
5 4 329.377 
5 2 345.075 
6 3 582.391 
5 4 569.389 
4 4 438.651 
1 3 404.65 
1 2 491.939 
5 3 479.105 
6 3 396.014 
5 3 271.974 
3 2 202.847 
3 1 289.557 
4 1 269.728 
4 1 241.12 
4 1 252.883 
5 1 378.981 
6 1 464.117 
5 1 394.695 
4 2 276.085 
3 1 308.726 
5 0 354.367 
5 1 413.968 
4 3 442.771 
1 2 432.446 
4 0 341.913 
1 1 512.099 
2 4 564.188 
1 4 515.943 
1 4 360.796 
0 4 257.67 
0 1 297.699 
1 0 216.047 
1 0 260.205 
2 0 329.503 
3 1 412.052 
3 0 331.603 
4 1 389.074 
4 2 467.847 
2 4 420.264 
0 3 321.586 
0 1 301.719 
4 0 311.519 
4 2 394.652 
3 2 335.489 
3 0 348.095 
3 1 407.353 
2 1 264.158 
3 0 370.973 
4 2 517.317 
1 3 436.549 
0 3 386.491 
0 3 295.476 
0 4 283.179 
0 1 338.36 
1 3 392.318 
1 3 300.688 
1 2 374.555 
3 4 364.422 
2 2 289.956 
3 1 374.164 
1 0 249.409 
1 0 340.417 
1 0 348.544 
0 3 398.507 
0 4 359.76 
1 4 304.593 
1 4 392.405 
2 4 367.308 
1 4 242.824 
1 1 293.945 
3 0 377.403 
2 0 418.776 
1 1 394.151 
1 4 405.96 
1 3 251.307 
2 3 241.928 
1 2 200.16 
1 2 242.504 
1 2 224.77 
1 2 385.651 
0 3 373.076 
0 4 403.786 
0 0 418.612 
0 1 347.417 
0 2 445.635 
0 2 599.567 
4 0 576.788 
4 0 508.792 
3 1 323.383 
1 1 415.586 
0 0 544.975 
1 4 417.632 
2 4 303.082 
0 4 357.607 
0 0 739.059 
0 0 830.719 
0 0 489.721 
1 0 385.979 
0 1 337.585 
1 2 308.566 
0 3 356.097 
0 1 351.578 
4 3 556.421 
4 4 235.742 
4 2 381.409 
4 1 358.606 
4 1 250.446 
4 1 385.317 
4 3 801.69 
0 2 905.721 
0 2 727.317 
0 3 362.06 
0 4 342.825 
0 4 531.556 
0 4 525.053 
0 0 350.638 
0 0 469.852 
0 1 505.331 
0 2 372.152 
0 3 504.449 
0 2 705.554 
0 2 564.432 
3 3 301.487 
2 3 445.158 
1 1 375.139 
0 0 287.171 
1 0 294.73 
1 0 279.948 
1 0 401.686 
1 0 314.321 
2 1 266.58 
4 1 312.184 
5 2 273.752 
5 1 334.213 
6 0 327.889 
5 0 313.312 
5 0 305.335 
6 0 391.588 
5 2 288.223 
4 3 435.473 
5 0 304.58 
6 0 490.035 
6 2 496.754 
5 3 499.24 
5 2 412.872 
5 3 362.574 
5 4 277.684 
3 4 242.123 
2 4 299.822 
4 1 334.884 
4 3 293.504 
3 4 223.51 
2 4 386.221 
2 1 448.781 
1 0 372.482 
2 0 438.373 
3 0 656.061 
5 0 464.236 
4 1 375.143 
4 0 457.828 
3 0 439.015 
4 0 699.125 
5 0 480.964 
4 1 438.465 
3 0 442.282 
4 1 443.585 
4 2 409.359 
5 1 424.464 
6 2 427.535 
5 3 488.483 
2 4 348.26 
1 0 392.049 
3 0 264.84 
5 1 485.823 
6 3 504.583 
6 2 574.297 
5 1 537.813 
5 0 549.921 
3 1 423.042 
2 1 301.168 
3 0 235.247 
3 0 547.369 
4 0 628.875 
0 2 666.35 
3 4 546.66 
2 4 450.007 
2 4 481.517 
2 4 520.493 
2 3 380.203 
2 3 355.674 
2 3 382.586 
2 3 312.145 
2 4 376.7 
3 2 225.885 
4 4 362.539 
2 4 553.906 
3 0 433.948 
2 1 413.861 
2 0 459.988 
2 1 328.62 
3 1 285.389 
6 0 350.927 
6 0 557.621 
5 0 626.895 
5 1 615.73 
4 3 527.824 
3 2 374.583 
3 3 413.068 
2 2 444.764 
4 1 387.722 
5 0 447.404 
4 2 503.544 
3 3 549.123 
3 4 614.913 
3 4 651.003 
1 2 556.439 
5 2 466.732 
5 4 388.451 
5 4 324.335 
3 4 339.785 
2 2 441.967 
3 0 276.714 
5 1 310.137 
6 2 325.109 
5 3 466.658 
2 2 508.947 
2 0 446.648 
3 0 559.677 
3 1 581.922 
3 1 519.278 
3 2 455.616 
3 2 390.351 
3 1 349.34 
4 2 399.776 
4 4 301.683 
2 4 412.586 
1 4 471.971 
0 4 492.271 
0 0 341.436 
0 1 286.032 
0 1 341.969 
4 1 396.043 
5 1 345.354 
6 0 269.615 
4 1 395.658 
2 2 380.28 
3 3 479.595 
4 4 377.347 
3 4 584.146 
2 4 554.708 
1 4 345.25 
1 4 374.829 
1 4 297.937 
2 1 362.944 
5 0 442.843 
6 0 409.21 
5 0 417.212 
3 1 424.617 
3 0 459.474 
3 1 420.844 
3 0 461.863 
2 0 451.603 
3 0 585.527 
5 0 565.574 
5 1 647.324 
3 3 564.667 
1 4 630.383 
1 4 509.866 
1 4 429.754 
1 4 449.022 
1 4 471.627 
2 2 358.927 
1 0 279.654 
1 0 465.947 
1 0 567.245 
1 0 579.032 
2 3 479.206 
1 4 453.297 
1 3 412.718 
3 1 502.134 
6 0 349.833 
6 2 434.632 
5 4 472.124 
3 4 505.945 
0 4 438.606 
0 4 485.003 
0 2 607.653 
0 2 552.988 
0 2 542.162 
4 4 354.35 
2 4 285.326 
3 3 298.029 
3 3 356.842 
3 2 257.536 
4 4 429.762 
3 4 710.551 
0 2 561.992 
3 0 359.72 
3 0 292.953 
4 1 366.596 
4 3 273.733 
2 4 301.094 
0 4 366.835 
0 0 346.107 
1 2 439.043 
4 4 537.68 
3 4 644.117 
2 4 493.385 
1 2 331.059 
4 3 382.128 
0 2 504.744 
4 0 457.593 
5 0 300.796 
5 1 266.441 
5 4 235.13 
5 3 381.944 
6 4 260.106 
5 4 352.936 
3 4 254.744 
2 4 292.654 
0 4 353.251 
0 4 385.56 
1 1 332.934 
4 1 224.219 
4 2 245.034 
6 4 428.526 
5 4 457.05 
5 4 303.002 
4 2 238.379 
4 2 294.433 
4 3 373.31 
4 4 417.053 
4 4 480.002 
4 3 200.794 
3 3 183.727 
2 2 241.005 
2 1 309.836 
2 1 307.783 
2 2 328.695 
4 1 429.585 
6 1 385.8 
6 1 357.235 
5 2 251.346 
5 4 278.738 
5 4 347.923 
5 4 332.147 
5 4 673.702 
6 2 635.348 
5 3 273.012 
3 3 392.438 
3 1 459.175 
6 2 412.946 
6 2 480.879 
5 2 251.675 
2 0 233.848 
2 0 358.298 
3 1 380.734 
6 2 380.669 
5 3 250.74 
4 2 265.139 
5 2 245.426 
6 2 314.449 
6 2 405.798 
5 3 496.505 
5 1 530.745 
3 2 338.824 
4 3 329.275 
4 2 396.522 
5 2 385.939 
5 1 424.481 
5 2 432.261 
3 2 355.642 
3 3 465.044 
2 0 431.165 
2 1 406.741 
2 2 438.392 
3 1 590.846 
6 3 500.221 
4 3 435.16 
2 4 208.077 
1 3 300.469 
2 0 282.081 
2 1 346.143 
2 1 288.279 
2 1 235.394 
2 2 262.254 
3 2 256.512 
4 2 276.339 
4 4 360.022 
3 3 277.602 
3 2 285.361 
3 0 268.416 
2 0 274.447 
2 0 280.184 
2 1 357.413 
2 2 294.141 
2 1 384.674 
2 0 278.548 
6 0 391.392 
5 1 431.729 
6 1 468.421 
4 2 360.003 
3 2 306.663 
4 1 233.83 
3 2 198.589 
2 2 323.469 
3 1 396.157 
6 1 413.413 
6 1 547.843 
5 2 528.936 
3 4 418.198 
0 4 316.794 
0 0 445.872 
0 0 387.972 
0 0 331.798 
0 0 470.183 
0 4 486.238 
0 4 389.101 
0 1 401.074 
1 1 446.693 
2 1 402.929 
2 1 301.374 
2 1 287.613 
2 0 410.117 
1 3 625.495 
1 4 592.17 
0 0 575.795 
1 1 427.042 
3 3 406.998 
4 2 398.949 
5 3 337.574 
5 2 300.321 
5 0 460.454 
4 1 555.131 
1 3 382.932 
1 4 442.744 
0 0 560.514 
0 4 466.819 
0 0 408.51 
0 4 493.319 
0 4 567.955 
1 4 441.031 
2 2 288.965 
5 3 445.316 
5 3 257.888 
5 2 289.422 
4 2 345.411 
4 3 365.904 
5 4 335.98 
3 3 370.762 
2 1 206.993 
2 1 175.882 
1 0 241.188 
1 0 310.95 
1 0 373.897 
1 0 382.119 
1 1 368.845 
2 4 350.947 
2 4 364.265 
2 3 350.656 
3 3 312.462 
3 3 328.659 
1 4 311.851 
2 4 351.066 
1 4 344.19 
2 3 369.368 
1 3 209.384 
1 1 312.569 
2 0 235.078 
3 0 274.572 
3 0 247.232 
0 1 441.894 
0 0 516.008 
0 3 425.55 
3 4 428.045 
2 4 407.188 
2 3 455.658 
3 1 393.776 
4 0 324.119 
0 1 354.684 
1 0 263.3 
0 0 470.141 
1 0 340.228 
3 0 279.415 
2 1 320.208 
4 0 307.773 
4 0 300.093 
2 0 390.508 
1 0 543.34 
1 0 317.176 
1 0 392.017 
2 0 408.916 
2 2 387.067 
2 3 223.501 
2 1 238.439 
3 1 321.08 
5 3 415.99 
3 4 321.431 
2 1 328.489 
5 0 443.289 
5 0 662.647 
5 3 704.584 
5 4 424.489 
4 3 629.877 
5 0 704.682 
6 0 918.082 
6 1 798.342 
6 3 650.899 
5 3 560.912 
4 3 566.716 
5 3 573.574 
5 3 512.542 
4 2 397.618 
4 0 426.942 
5 0 252.898 
5 1 341.702 
6 2 421.819 
6 2 390.039 
3 1 396.504 
5 1 411.206 
5 3 371.875 
3 2 570.631 
5 2 359.085 
4 3 326.861 
3 3 343.55 
3 2 300.659 
5 4 430.264 
3 4 386.204 
1 3 242.031 
0 1 368.683 
0 0 363.613 
2 0 524.98 
3 0 453.975 
3 0 475.86 
3 1 374.773 
2 2 311.127 
2 2 402.942 
3 0 448.083 
6 0 569.422 
6 0 780.765 
6 1 819.939 
6 1 717.553 
6 2 407.451 
6 3 367.838 
6 4 394.185 
4 4 308.867 
3 3 266.505 
2 3 180.727 
1 4 343.231 
1 0 463.361 
2 0 308.945 
6 0 276.836 
6 3 450.936 
5 4 319.857 
4 2 330.573 
5 3 321.823 
6 3 363.678 
6 3 306.286 
6 3 255.549 
6 2 289.881 
6 1 516.978 
6 2 541.798 
6 4 341.627 
4 4 453.099 
2 4 223.122 
2 3 314.129 
2 2 445.515 
5 0 349.597 
6 1 504.15 
6 3 468.362 
3 4 338.212 
0 4 359.089 
0 0 534.791 
0 0 532.609 
0 1 505.995 
1 4 401.424 
1 4 460.406 
1 4 420.707 
2 1 496.267 
3 1 465.307 
6 1 481.876 
6 3 366.54 
6 1 541.509 
6 2 708.111 
6 4 735.63 
4 4 475.302 
0 3 352.266 
1 3 452.831 
1 4 456.306 
2 3 313.781 
2 2 374.988 
3 1 428.491 
3 2 545.253 
2 4 340.442 
0 3 389.179 
0 3 316.302 
1 4 380.329 
2 0 497.529 
5 1 426.832 
6 4 279.764 
4 4 292.734 
1 0 524.129 
2 0 491.263 
3 0 496.536 
6 2 283.008 
6 2 296.55 
6 3 411.678 
6 4 393.76 
6 0 610.873 
6 0 451.552 
6 0 653.728 
6 0 580.56 
6 1 398.883 
5 2 354.338 
5 0 512.267 
6 0 214.96 
5 2 382.289 
2 3 386.121 
2 4 392.853 
2 3 452.348 
5 1 432.349 
6 2 289.93 
6 3 396.732 
6 3 794.642 
6 0 587.781 
6 1 408.796 
5 2 438.725 
5 2 381.534 
6 0 446.193 
6 0 406.868 
0 2 751.268 
0 2 699.383 
0 2 626.672 
0 2 534.479 
3 3 501.578 
4 1 481.013 
5 1 453.751 
5 1 477.769 
6 1 582.698 
6 0 503.322 
5 0 609.797 
1 2 495.379 
1 2 407.33 
2 4 269.377 
1 4 316.743 
0 4 462.013 
0 4 307.455 
0 1 269.862 
0 2 229.677 
0 1 208.148 
0 0 200.036 
0 1 267.543 
3 0 309.127 
4 1 313.311 
3 3 308.389 
3 1 556.109 
4 1 255.231 
3 3 244.225 
3 3 369.602 
4 1 514.281 
0 2 370.506 
0 1 386.253 
4 1 461.809 
4 4 301.623 
2 4 327.003 
1 1 505.392 
1 0 391.391 
2 0 182.651 
4 1 359.16 
5 2 314.937 
3 3 267.975 
1 2 391.943 
2 0 321.476 
1 0 466.381 
2 0 452.953 
1 3 400.659 
2 4 287.51 
1 3 270.733 
3 3 315.598 
4 3 232.893 
4 3 318.629 
5 4 263.405 
5 4 299.484 
3 3 284.546 
2 3 246.64 
1 2 312.827 
3 0 269.228 
3 0 283.837 
0 1 394.624 
0 2 368.588 
0 2 314.918 
0 2 368.753 
4 0 466.943 
4 0 481.46 
3 0 584.347 
1 0 490.881 
1 3 234.774 
2 4 174.978 
1 4 401.866 
0 3 290.793 
1 2 247.194 
3 1 180.413 
3 2 363.407 
2 3 330.05 
2 3 243.853 
3 2 222.152 
4 1 247.276 
4 2 172.045 
4 2 203.532 
4 2 268.696 
4 2 231.37 
2 2 242.341 
2 2 305.267 
3 1 345.484 
3 1 320.526 
5 0 329.974 
6 1 326.003 
4 3 247.813 
1 2 359.582 
1 1 334.346 
2 0 279.45 
0 0 221.933 
0 1 191.154 
0 2 342.652 
5 0 424.861 
5 1 338.277 
3 2 280.895 
2 2 420.488 
1 1 343.167 
1 1 210.506 
1 3 194.876 
2 1 298.969 
4 0 176.761 
3 1 208.029 
2 0 316.771 
2 1 308.889 
1 3 354.412 
1 2 325.747 
0 1 270.328 
0 0 303.164 
0 0 417.482 
4 0 443.411 
4 2 469.923 
3 4 421.209 
0 3 375.6 
0 1 314.261 
0 1 268.743 
1 3 388.22 
3 0 429.258 
1 2 459.42 
4 3 493.065 
4 3 537.377 
3 3 472.555 
3 3 601.142 
1 2 621.736 
1 2 611.901 
1 2 528.16 
1 2 602.808 
4 1 439.67 
4 1 434.953 
5 1 410.058 
5 1 526.159 
4 3 435.109 
4 2 449.393 
4 4 466.099 
3 4 510.92 
1 2 381.642 
4 0 548.944 
5 0 570.025 
5 0 575.854 
5 3 684.049 
3 3 476.104 
1 1 411.36 
1 1 449.694 
1 1 424.088 
0 0 376.614 
1 0 413.402 
0 0 364.353 
1 0 508.324 
0 1 481.664 
0 1 402.683 
0 3 328.37 
1 4 307.617 
0 4 291.73 
0 1 279.907 
1 2 339.911 
0 3 348.372 
0 2 404.486 
3 0 534.252 
3 0 502.133 
2 0 487.001 
3 0 424.292 
4 0 396.095 
3 0 367.574 
2 2 313.219 
2 2 272.06 
2 1 297.036 
2 2 366.385 
3 4 456.109 
1 4 489.083 
0 4 489.394 
0 4 325.929 
1 1 223.871 
1 2 395.811 
1 4 327.175 
1 4 546.238 
0 0 515.253 
0 0 465.352 
1 0 404.502 
1 1 381.699 
2 2 360.884 
4 2 382.856 
3 3 315.216 
3 4 312.586 
1 3 433.284 
2 0 314.234 
5 0 378.854 
4 1 402.487 
1 2 307.228 
0 4 348.478 
0 0 317.329 
0 0 202.547 
0 4 374.289 
1 4 489.813 
1 4 578.416 
1 3 478.874 
2 2 421.836 
4 0 289.752 
6 0 431.865 
5 0 464.087 
4 2 375.641 
1 3 261.388 
0 1 307.783 
0 1 322.316 
4 0 497.749 
4 1 502.348 
4 1 442.119 
4 1 353.774 
4 1 374.813 
4 2 407.776 
2 3 366.293 
2 3 460.342 
2 2 487.398 
1 1 436.698 
1 0 307.48 
1 0 360.206 
2 0 393.781 
5 0 529.332 
5 2 531.361 
5 4 362.345 
4 3 310.782 
2 2 245.337 
3 0 212.887 
4 0 281.348 
4 1 331.091 
4 1 302.098 
4 0 352.621 
6 0 337.729 
6 2 461.076 
6 3 372.953 
4 2 304.227 
4 3 246.908 
5 3 301.72 
6 2 443.763 
6 3 554.299 
6 3 703.544 
6 2 1017.21 
6 2 1272.46 
6 2 1559.39 
6 2 738.096 
6 3 276.217 
4 2 387.083 
5 1 202.692 
3 2 176.643 
2 0 192.037 
2 0 333.947 
4 0 388.988 
4 0 338.189 
4 1 285.12 
4 3 238.527 
3 4 384.676 
1 4 501.266 
0 0 576.467 
1 0 733.247 
1 0 375.044 
4 4 273.115 
6 4 472.344 
6 2 250.82 
6 4 427.216 
3 2 543.44 
2 1 410.133 
2 1 281.977 
3 1 243.048 
6 3 354.906 
6 4 291.553 
5 4 410.68 
3 4 526.044 
0 4 415.165 
0 4 527.091 
0 0 316.775 
4 0 317.862 
5 0 297.648 
1 2 376.273 
0 4 468.24 
1 0 348.345 
1 1 292.618 
2 0 282.748 
2 0 347.278 
2 2 265.503 
3 0 350.287 
3 0 640.455 
6 0 708.225 
6 0 418.092 
6 1 337.499 
6 2 354.737 
6 4 363.846 
6 4 344.736 
6 4 439.872 
6 4 479.56 
5 4 493.977 
3 3 345.725 
2 1 334.359 
1 0 409.886 
0 0 518.563 
3 0 836.959 
6 0 672.142 
6 0 376.762 
5 2 397.686 
3 3 384.722 
3 1 423.246 
5 0 308.802 
4 2 343.197 
3 3 338.708 
0 3 324.667 
0 1 610.856 
3 0 593.17 
1 1 360.143 
1 0 417.921 
2 1 363.693 
5 2 347.605 
4 3 364.389 
4 4 342.539 
0 3 404.913 
2 4 406.746 
0 4 561.006 
2 0 544.859 
5 0 478.016 
6 0 259.133 
6 1 261.173 
6 3 413.337 
5 4 520.895 
3 4 302.132 
4 2 275.441 
4 1 239.366 
3 0 355.655 
3 0 373.69 
3 0 422.399 
3 0 294.293 
2 1 261.969 
2 2 343.823 
2 4 392.859 
2 3 451.637 
2 2 389.641 
5 3 656.419 
6 3 576.1 
5 4 573.397 
6 3 491.145 
6 2 411.904 
6 3 394.041 
5 4 526.925 
5 4 469.473 
5 4 946.917 
5 4 912.566 
3 4 645.406 
0 2 572.997 
4 0 560.34 
6 0 365.055 
6 1 423.393 
6 1 806.418 
6 3 804.035 
6 3 708.138 
6 3 659.873 
6 3 599.865 
6 2 405.434 
5 3 324.318 
4 1 447.133 
6 0 333.373 
4 1 286.413 
0 2 379.98 
4 3 553.981 
5 2 532.777 
5 2 299.418 
5 2 322.114 
6 0 350.81 
6 2 272.406 
5 2 347.384 
3 2 368.339 
2 3 411.533 
2 4 379.947 
2 3 502.421 
3 3 665.582 
0 4 513.778 
0 0 406.917 
1 0 355.737 
2 0 358.256 
3 0 401.45 
4 0 292.734 
5 0 382.526 
6 0 457.435 
6 1 622.301 
6 2 537.769 
4 3 551.323 
0 4 465.58 
0 4 627.542 
0 4 624.73 
0 4 643.884 
0 1 521.446 
4 2 449.017 
5 3 227.207 
4 3 332.872 
3 4 472.687 
1 4 478.715 
1 0 337.818 
3 0 291.397 
2 2 401.77 
2 3 240.976 
3 2 217.716 
3 3 200.303 
1 1 170.558 
1 0 297.888 
0 0 340.466 
1 0 350.894 
5 0 293.432 
5 1 403.413 
4 0 474.316 
4 0 343.126 
5 0 295.021 
5 3 323.804 
3 4 299.647 
2 1 287.173 
2 2 272.314 
2 3 260.832 
1 0 379.077 
0 0 298.683 
1 0 289.823 
1 2 424.332 
1 3 342.833 
1 4 299.63 
1 4 514.046 
0 4 547.725 
0 4 451.136 
0 1 434.417 
0 2 402.571 
3 4 421.033 
4 4 599.574 
3 4 440.098 
1 3 489.248 
1 2 511.036 
5 2 487.364 
4 2 486.887 
4 3 478.257 
3 4 340.031 
2 3 252.718 
2 2 237.996 
2 3 315.851 
2 4 302.766 
2 2 295.881 
4 1 212.163 
5 2 264.999 
6 2 384.47 
6 2 524.461 
6 4 549.768 
5 4 591.862 
4 4 362.283 
4 3 420.189 
6 4 462.025 
6 4 444.558 
5 2 451.533 
5 1 319.689 
5 1 324.545 
4 2 303.245 
4 3 333.021 
4 2 580.774 
6 0 672.39 
6 0 513.549 
5 1 431.731 
4 1 441.836 
4 2 612.44 
5 3 599.901 
6 4 614.94 
6 4 886.815 
6 4 780.313 
5 4 580.668 
5 4 472.304 
5 4 395.729 
4 4 586.602 
2 3 433.714 
2 2 450.618 
2 1 395.155 
3 0 416.667 
3 1 405.171 
4 3 292.701 
3 2 514.009 
6 0 279.115 
5 1 266.646 
2 1 200.662 
1 1 233.747 
1 3 202.616 
1 2 237.903 
1 2 366.286 
1 3 334.579 
0 3 348.052 
3 4 382.906 
0 2 443.64 
4 0 342.057 
4 1 413.885 
1 3 252.665 
1 1 286.372 
4 0 331.928 
5 0 358.082 
4 1 296.874 
3 3 269.925 
2 2 339.17 
1 2 459.113 
1 2 459.551 
3 0 385.902 
4 0 310.813 
4 1 371.073 
4 0 415.442 
4 0 366.796 
1 2 350.879 
1 2 341.226 
3 1 404.016 
1 2 388.534 
0 2 451.946 
0 3 519.128 
0 4 762.012 
0 4 893.096 
0 1 626.422 
0 1 437.35 
1 3 385.148 
0 2 384.564 
0 2 365.923 
4 0 388.203 
4 0 373.334 
4 0 428.347 
4 1 562.792 
1 3 376.672 
0 1 328.182 
0 2 386.233 
0 2 365.309 
0 2 506.009 
4 1 448.538 
1 2 278.733 
1 1 306.339 
1 1 331.77 
4 0 348.529 
4 1 688.071 
0 2 764.882 
4 2 700.485 
5 4 434.356 
4 4 289.434 
1 3 312.279 
1 2 305.759 
1 3 349.439 
0 0 388.24 
1 0 267.936 
4 0 410.364 
4 0 368.862 
4 0 411.288 
5 0 601.182 
6 0 744.449 
5 0 527.812 
4 1 354.533 
1 2 478.204 
4 3 431.407 
5 4 325.188 
4 4 302.918 
3 2 303.984 
4 2 273.078 
3 3 271.269 
2 1 290.002 
1 4 341.572 
0 4 430.902 
0 4 475.452 
1 4 287.839 
0 0 499.672 
0 0 409.695 
0 0 413.756 
0 0 390.391 
1 0 368.64 
4 1 369.391 
6 0 431.146 
6 1 405.945 
4 3 666.961 
5 3 506.176 
5 4 300.316 
2 3 412.148 
1 0 360.92 
0 0 582.829 
0 0 471.937 
0 0 380.218 
0 1 221.364 
3 0 337.955 
4 0 511.621 
4 0 703.607 
4 0 722.34 
4 0 764.061 
4 0 766.148 
4 1 611.315 
4 3 624.883 
0 2 559.65 
0 2 489.436 
0 1 452.314 
1 1 479.043 
5 2 498.459 
6 3 458.163 
6 3 395.418 
5 4 406.019 
2 3 367.041 
2 3 343.753 
2 1 212.437 
2 2 253.612 
3 3 251.946 
1 2 302.771 
1 3 409.697 
4 4 566.237 
4 4 840.886 
4 4 929.496 
4 4 672.086 
0 4 503.909 
0 4 432.586 
0 3 351.418 
3 3 343.454 
3 3 313.492 
4 2 389.299 
6 1 398.484 
5 1 721.847 
5 0 574.436 
5 1 425.41 
5 3 386.463 
4 4 466.04 
2 3 517.815 
3 0 384.292 
4 0 458.37 
1 1 412.13 
1 1 369.821 
1 3 364.171 
2 4 444.057 
0 4 605.047 
0 1 613.393 
1 2 464.404 
2 3 444.012 
2 4 344.845 
2 4 425.77 
3 3 455.531 
6 4 370.169 
6 3 325.778 
6 2 409.372 
6 2 387.809 
6 2 402.808 
6 3 323.219 
5 3 563.354 
5 1 291.784 
3 1 292.235 
3 0 374.525 
5 0 448.943 
5 2 356.876 
5 2 538.217 
6 0 499.509 
3 2 483.904 
0 4 389.591 
0 0 700.154 
0 0 738.391 
0 0 665.719 
2 0 563.93 
2 0 256.752 
2 0 316.719 
1 0 521.494 
2 0 488.056 
3 0 372.747 
3 1 469.923 
6 1 328.149 
6 3 386.366 
5 3 500.302 
5 2 389.576 
6 2 375.97 
5 2 430.288 
6 1 305.357 
5 3 475.425 
2 4 592.612 
1 4 520.504 
1 3 451.591 
1 1 305.368 
1 0 183.637 
1 0 216.849 
0 1 236.839 
0 2 210.368 
4 1 484.465 
4 2 607.333 
4 4 503.138 
3 3 619.648 
4 0 528.26 
3 0 430.479 
4 3 352.854 
4 3 383.686 
3 2 395.169 
3 1 489.002 
6 0 483.454 
6 0 370.624 
6 0 320.048 
6 1 405.195 
6 3 372.927 
6 1 577.211 
6 0 652.433 
6 1 516.972 
6 2 281.71 
6 1 343.779 
6 2 339.425 
3 2 580.125 
3 1 463.951 
3 2 300.218 
3 0 292.469 
4 1 322.49 
3 2 335.856 
3 0 550.162 
3 0 764.609 
3 0 739.73 
3 0 465.003 
2 1 375.018 
3 0 469.951 
5 1 389.28 
5 2 354.712 
3 3 434.521 
1 4 515.079 
1 4 591.839 
1 0 493.774 
3 1 185.529 
4 2 387.146 
1 3 464.003 
1 0 358.519 
3 0 258.413 
5 0 291.148 
4 1 373.038 
3 0 328.82 
3 0 208.845 
2 2 359.182 
1 0 287.188 
1 1 271.222 
5 0 429.489 
6 0 247.023 
6 2 405.081 
6 4 577.398 
4 4 239.191 
1 2 277.225 
1 3 257.313 
0 0 252.257 
3 0 361.162 
5 0 296.819 
5 2 325.156 
4 4 222.079 
2 2 523.69 
6 0 532.859 
6 0 447.363 
5 2 428.461 
4 3 370.856 
3 2 304.776 
3 1 345.638 
5 0 446.269 
6 0 239.632 
5 1 434.549 
5 1 463.079 
3 1 546.182 
2 2 515.234 
3 1 335.685 
3 3 292.416 
2 1 385.352 
3 1 353.653 
2 3 375.389 
1 4 414.925 
1 0 619.204 
2 0 609.812 
3 0 393.992 
0 2 354.166 
0 2 440.71 
3 0 405.743 
1 1 257.815 
1 0 237.612 
1 1 279.517 
1 2 353.535 
0 1 360.885 
2 0 456.703 
3 0 643.826 
6 0 502.799 
6 0 534.463 
3 1 500.911 
2 2 416.859 
3 3 317.655 
4 3 364.871 
4 4 453.599 
0 3 620.551 
0 3 607.579 
0 1 464.953 
0 1 451.955 
0 1 447.962 
3 0 431.27 
5 0 400.468 
4 1 364.024 
4 2 471.709 
0 2 357.825 
0 1 481.514 
1 2 411.991 
2 3 244.092 
1 0 295.352 
1 0 359.991 
1 0 368.803 
2 0 403.856 
1 0 572.231 
1 0 682.019 
1 4 763.715 
0 0 685.767 
0 0 342.938 
0 1 302.066 
0 2 287.8 
0 1 305.999 
1 1 206.82 
0 4 318.913 
0 4 458.398 
0 0 472.538 
0 4 347.766 
0 4 339.413 
0 0 394.138 
0 1 301.982 
0 3 402.176 
0 3 653.129 
0 1 496.87 
2 0 375.836 
3 1 250.796 
3 1 278.349 
5 0 287.836 
5 1 261.968 
4 2 336.331 
3 3 382.484 
2 2 367.386 
4 2 354.411 
3 4 349.38 
1 4 256.932 
1 4 230.296 
0 4 265.434 
0 4 404.703 
0 1 422.029 
0 2 539.142 
0 2 590.472 
0 3 412.402 
4 3 352.518 
4 3 376.816 
4 3 198.936 
3 3 271.529 
5 3 305.15 
6 3 423.751 
6 2 477.58 
6 4 437.056 
5 4 390.247 
3 3 388.074 
3 2 383.97 
1 2 363.578 
1 2 363.84 
4 1 540.687 
5 2 573.649 
4 3 334.887 
3 2 360.417 
3 1 340.307 
2 1 283.171 
2 2 219.732 
4 2 423.987 
5 0 511.622 
6 0 385.426 
3 2 389.433 
1 3 288.428 
1 4 281.229 
0 0 327.975 
1 0 407.335 
1 0 405.647 
1 1 520.118 
1 4 345.239 
1 4 188.296 
0 1 239.655 
1 0 330.095 
1 0 259.405 
1 1 219.299 
4 2 450.577 
4 4 431.006 
2 2 254.628 
1 2 431.183 
1 3 318.983 
0 4 307.344 
0 0 229.251 
0 1 328.789 
0 2 280.398 
1 2 226.336 
3 0 318.601 
4 2 413.768 
5 3 385.686 
4 3 380.609 
4 3 363.762 
5 4 306.214 
3 4 326.872 
1 1 351.422 
2 0 296.963 
1 1 308.743 
1 1 325.972 
2 0 388.229 
3 0 488.819 
5 0 507.343 
4 1 579.264 
0 2 458.679 
0 2 467.617 
0 3 591.037 
0 3 575.059 
0 3 495.992 
0 2 388.792 
1 2 354.7 
2 2 335.572 
4 3 483.799 
3 3 411.475 
2 3 328.923 
2 3 411.055 
1 3 440.232 
1 0 340.372 
2 0 404.968 
2 2 337.168 
3 2 355.598 
1 2 361.826 
1 2 314.829 
4 1 327.769 
5 1 269.011 
6 0 412.215 
5 2 490.113 
4 1 442.769 
4 1 434.401 
1 2 267.83 
1 1 373.291 
4 0 411.362 
5 0 396.249 
4 2 561.342 
0 4 457.084 
0 3 379.447 
0 1 256.388 
2 0 164.645 
3 1 499.776 
5 1 343.912 
5 2 608.422 
1 1 314.44 
1 0 386.489 
0 4 491.94 
0 0 354.265 
0 1 395.837 
3 0 303.27 
3 0 206.929 
3 1 305.298 
1 2 455.08 
0 2 513.439 
1 2 473.249 
1 3 333.78 
0 0 385.436 
0 1 498.615 
4 1 491 
4 1 345.044 
5 1 472.438 
6 3 488.434 
6 3 444.879 
4 3 476.38 
3 4 518.043 
3 4 516.566 
1 3 321.245 
1 3 274.772 
1 4 368.774 
1 0 342.778 
2 0 581.234 
2 0 336.594 
2 0 294.108 
3 1 340.069 
3 2 294.166 
2 2 282.278 
2 3 267.397 
3 4 387.349 
0 4 597.768 
0 3 509.756 
1 2 529.109 
5 3 462.05 
6 3 482.473 
6 3 390.83 
6 2 375.273 
6 2 399.369 
6 3 596.426 
6 2 470.85 
6 3 327.744 
6 4 406.599 
6 4 360.994 
3 3 410.577 
2 1 415.859 
2 0 382.639 
2 0 319.397 
2 0 314.535 
3 2 232.655 
3 2 288.68 
3 3 257.669 
2 3 364.193 
3 0 649.294 
5 0 697.529 
5 0 646.944 
4 0 486.389 
4 2 545.06 
4 2 866.666 
6 0 776.709 
5 0 824.149 
0 2 767.75 
0 2 590.296 
4 4 616.451 
0 4 592.705 
0 4 423.044 
1 1 482.656 
5 0 564.549 
6 0 343.317 
6 1 249.119 
6 2 365.426 
6 4 552.796 
5 4 747.125 
4 0 465.272 
6 0 401.438 
6 1 478.933 
6 2 297.998 
6 0 233.811 
5 1 295.118 
5 4 268.817 
3 4 435.416 
3 3 328.202 
5 4 420.321 
3 4 529.417 
2 4 473.265 
2 1 596.429 
5 0 348.288 
6 0 243.066 
6 0 349.156 
4 1 528.507 
1 2 537.788 
0 3 448.111 
0 3 404.3 
2 4 355.419 
0 4 472.451 
1 0 428.178 
3 0 329.971 
5 0 322.64 
6 1 294.82 
5 2 357.911 
3 1 683.994 
5 0 595.024 
6 0 366.349 
6 2 371.116 
6 1 611.154 
6 1 352.064 
5 2 586.294 
3 2 476.843 
3 1 710.489 
3 0 386.088 
3 1 342.066 
2 0 380.462 
3 0 378.192 
2 2 342.632 
2 3 365.634 
2 2 403.711 
2 3 280.528 
2 4 328.361 
3 4 497.99 
2 4 344.682 
1 4 367.31 
0 1 434.082 
4 0 560.874 
0 2 667.984 
0 2 482.274 
0 2 373.919 
0 2 517.662 
4 0 749.515 
4 0 605.92 
4 0 427.736 
3 0 424.451 
4 0 601.996 
4 0 728.293 
4 0 458.387 
4 1 354.678 
4 2 317.875 
1 2 352.557 
4 1 389.995 
2 1 303.73 
1 0 313.866 
2 0 262.943 
4 1 276.122 
4 2 329.525 
4 2 335.226 
5 2 400.569 
5 3 575.635 
5 4 548.831 
3 4 578.408 
0 3 460.899 
0 1 396.672 
4 3 459.334 
3 3 439.189 
3 4 462.347 
2 2 376.817 
3 1 520.132 
3 2 496.584 
6 3 375.832 
6 4 462.929 
5 4 504.497 
3 3 280.404 
3 2 375.365 
4 1 390.388 
3 1 415.7 
3 0 402.783 
5 0 354.491 
6 1 291.992 
6 4 307.359 
3 2 472.89 
2 1 421.518 
2 0 467.31 
3 0 524.58 
6 0 363.109 
5 2 278.542 
4 3 277.506 
3 4 386.47 
0 4 360.429 
0 4 327.661 
0 0 381.899 
0 0 452.246 
1 0 437.711 
2 1 298.698 
1 3 328.946 
0 4 455.903 
0 0 450.316 
0 2 433.532 
0 2 523.875 
0 2 522.917 
0 2 533.035 
4 4 548.774 
4 3 491.549 
4 2 552.611 
4 0 458.609 
5 0 331.533 
4 1 311.702 
4 1 376.949 
1 2 277.556 
1 1 342.921 
2 1 255.941 
2 2 380.099 
3 1 321.873 
3 1 512.256 
3 1 499.867 
2 1 355.202 
4 1 243.102 
4 3 313.512 
3 3 309.279 
3 2 281.546 
3 4 339.646 
0 2 475.483 
4 0 404.425 
4 0 401.213 
0 2 407.867 
4 1 433.592 
5 0 392.873 
5 2 417.533 
5 4 333.67 
2 2 323.69 
2 1 263.026 
4 2 382.216 
4 3 390.624 
5 4 362.791 
4 4 291.771 
2 3 461.347 
3 4 589.715 
5 4 567.495 
5 4 332.214 
3 4 252.959 
1 0 376.801 
2 0 259.924 
3 0 316.905 
1 3 338.937 
0 4 299.425 
0 1 290.047 
0 2 273.446 
0 1 270.96 
0 0 252.563 
0 0 299.515 
3 0 449.115 
4 1 390.993 
4 3 224.25 
4 2 255.849 
5 2 368.66 
6 2 511.814 
6 2 398.62 
4 1 264.192 
3 0 303.002 
3 1 246.041 
4 3 354.218 
2 2 358.102 
1 2 290.844 
2 4 322.157 
1 4 306.358 
1 4 384.284 
2 4 445.435 
1 4 483.729 
1 4 358.559 
2 2 281.698 
4 3 465.285 
2 4 270.088 
1 4 376.294 
1 4 373.955 
0 0 467.718 
1 0 302.626 
1 1 302.129 
1 2 293.259 
4 1 242.291 
3 1 191.854 
3 1 290.432 
3 2 381.12 
3 2 310.09 
4 2 361.482 
5 4 413.041 
5 1 372.507 
4 1 331.316 
1 3 310.589 
1 2 322.033 
3 0 401.599 
4 0 356.323 
4 1 428.952 
1 2 305.016 
2 4 262.571 
2 4 396.297 
1 2 188.528 
1 2 238.488 
2 2 249.812 
2 2 302.102 
2 2 206.428 
3 1 222.122 
2 0 216.164 
2 0 290.369 
2 2 255.6 
4 2 326.659 
6 3 431.561 
6 4 366.807 
6 4 423.875 
6 3 314.941 
6 4 288.857 
4 3 303.569 
3 2 354.576 
3 1 283.502 
2 1 342.286 
3 1 303.423 
3 2 250.07 
3 1 372.139 
5 0 502.621 
3 0 459.959 
5 1 532.192 
3 2 334.376 
3 1 304.747 
3 2 353.273 
2 1 345.026 
3 0 376.607 
3 0 392.225 
1 2 415.75 
1 4 422.443 
1 4 339.729 
1 2 191.28 
3 0 257.796 
3 0 291.911 
1 1 256.739 
1 1 290.587 
1 3 353.015 
3 2 329.835 
4 2 194.313 
3 2 226.698 
5 1 509.664 
5 2 465.041 
2 1 405.916 
2 0 401.571 
1 0 354.134 
1 0 280.431 
2 0 334.448 
1 0 282.684 
1 0 456.62 
1 4 399.135 
2 4 321.568 
1 4 352.457 
1 3 366.658 
3 2 394.03 
4 2 406.874 
4 3 431.988 
4 4 531.596 
1 2 449.574 
4 1 406.033 
5 0 352.401 
5 0 423.702 
4 1 350.025 
1 2 282.107 
2 2 243.036 
2 2 222.34 
3 2 262.332 
3 3 266.529 
1 3 232.781 
0 1 220.553 
0 1 212.869 
0 3 337.677 
1 3 477.492 
0 4 361.024 
1 3 306.777 
1 2 346.921 
4 1 240.023 
3 1 224.176 
3 1 165.268 
4 1 271.935 
2 1 314.269 
2 2 389.272 
3 3 483.265 
3 3 297.002 
3 1 249.594 
3 2 297.338 
3 1 263.508 
3 1 362.871 
3 2 434.54 
2 3 293.27 
3 1 265.335 
4 1 332.72 
0 2 471.095 
0 2 462.842 
2 3 434.319 
2 0 375.272 
2 0 319.864 
2 0 318.747 
3 0 367.405 
4 0 377.942 
5 0 342.92 
4 2 388.621 
3 2 298.779 
1 1 205.769 
2 0 242.265 
3 0 343.496 
1 1 260.792 
2 1 271.088 
2 1 359.388 
2 0 294.638 
2 0 267.344 
2 0 286.89 
5 0 270.109 
6 2 262.901 
6 3 424.789 
6 4 340.063 
3 3 451.706 
2 2 462.823 
3 0 366.412 
4 0 540.336 
5 0 568.877 
6 0 512.872 
6 2 494.099 
6 3 556.839 
6 3 540.166 
6 3 556.301 
6 3 633.006 
6 4 369.236 
3 4 346.967 
2 4 376.468 
1 0 439.214 
1 1 262.897 
2 1 371.029 
3 1 221.727 
2 3 271.892 
2 3 453.512 
2 4 559.305 
2 4 649.745 
2 2 644.281 
5 0 526.825 
6 1 329.576 
5 2 285.994 
5 2 353.538 
6 2 653.799 
6 4 689.941 
5 4 535.896 
2 2 346.839 
3 1 315.806 
5 1 323.028 
4 3 269.168 
2 4 303.631 
1 0 346.502 
2 1 308.693 
3 2 522.07 
6 3 591.096 
6 3 461.556 
5 4 514.925 
3 4 622.762 
0 4 646.566 
1 4 740.841 
0 0 778.677 
1 0 485.424 
3 0 459.5 
5 1 421.388 
1 2 478.547 
1 3 460.209 
2 4 386.665 
1 0 437.967 
2 0 462.324 
3 0 636.388 
5 0 330.832 
4 1 462.895 
0 2 363.775 
1 1 421.117 
3 1 355.289 
2 4 376.672 
1 4 460.699 
0 4 458.317 
0 1 326.706 
4 2 403.35 
6 4 316.69 
6 4 239.947 
6 4 296.551 
5 4 431.393 
2 4 316.699 
2 0 360.834 
5 0 662.345 
6 0 937.688 
5 0 803.031 
5 1 679.804 
4 2 474.9 
1 3 453.478 
1 0 395.376 
2 0 527.556 
6 0 431.927 
6 2 422.039 
6 2 447.808 
6 3 437.795 
5 3 368.834 
3 1 370.453 
3 1 411.797 
3 2 458.931 
3 3 504.564 
4 4 324.102 
3 4 446.209 
2 4 427.409 
1 3 367.406 
2 0 422.857 
3 0 452.603 
6 0 597.979 
6 0 582.262 
6 1 489.391 
5 3 385.825 
3 4 239.407 
3 2 432.582 
4 1 285.016 
5 1 385.714 
5 1 291.266 
5 2 333.962 
3 3 535.719 
2 0 572.433 
3 1 623.721 
5 2 367.225 
5 3 418.017 
1 3 370.139 
0 0 440.452 
2 0 360.666 
3 1 426.362 
3 3 388.3 
6 0 355.565 
6 1 451.71 
6 2 377.601 
4 2 317.041 
3 2 443.974 
5 4 386.803 
4 4 250.36 
3 4 222.2 
2 3 375.572 
1 2 347.519 
1 2 260.154 
2 2 283.852 
2 2 376.073 
3 1 578.816 
6 0 355.776 
6 2 367.932 
6 2 372.03 
5 3 365.085 
3 3 298.257 
2 4 278.406 
1 1 387.941 
4 0 258.494 
4 2 402.7 
1 4 480.454 
0 0 521.932 
5 1 491.033 
6 3 296.844 
4 3 311.018 
1 4 393.221 
0 4 609.629 
0 0 478.266 
0 2 492.257 
5 2 451.975 
5 4 368.252 
2 4 350.381 
1 4 592.791 
2 3 499.51 
2 3 321.398 
2 3 209.279 
2 3 199.633 
3 2 344.056 
5 1 237.73 
6 1 256.6 
6 3 277.145 
4 3 224.177 
1 2 243.026 
0 2 293.339 
0 4 334.025 
1 0 530.362 
3 0 629.064 
3 0 479.916 
0 3 314.62 
0 4 373.791 
0 1 332.342 
4 0 328.649 
3 1 259.995 
1 1 368.867 
1 2 345.803 
2 2 380.707 
4 0 468.528 
4 1 402.815 
2 2 331.613 
2 1 286.872 
2 1 247.762 
3 2 244.768 
3 1 406.836 
5 2 469.205 
5 2 487.998 
3 3 538.878 
3 3 355.884 
2 1 412.537 
3 0 314.4 
2 1 479.802 
1 4 455.353 
0 4 545.406 
0 0 596.92 
0 0 422.682 
4 0 220.005 
5 1 299.37 
4 2 269.924 
4 2 220.689 
5 1 321.177 
5 2 377.491 
5 4 442.858 
2 3 307.932 
2 1 403.368 
1 0 384.705 
3 1 263.225 
6 3 231.103 
6 3 247.627 
4 3 286.408 
1 1 379.051 
1 0 458.903 
1 2 348.079 
1 2 276.638 
3 1 246.632 
3 2 204.069 
3 1 284.644 
5 1 325.434 
6 0 246.285 
6 1 273.746 
6 2 380.437 
5 2 366.709 
6 3 378.304 
5 2 471.913 
4 3 387.613 
1 3 335.27 
0 3 305.92 
1 3 305.196 
2 4 310.304 
3 2 423.902 
4 1 353.241 
3 3 296.117 
3 4 536.656 
2 4 427.607 
2 2 294.875 
4 3 190.347 
4 2 336.068 
6 3 499.882 
6 2 431.624 
6 4 632.538 
5 4 289.677 
3 2 225.971 
2 2 220.446 
2 1 312.471 
2 1 304.329 
2 1 342.052 
2 2 369.431 
3 2 399.341 
5 2 497.733 
4 2 317.013 
3 3 313.415 
4 4 414.938 
4 4 723.654 
2 4 413.938 
1 3 291.912 
2 0 176.617 
2 0 257.268 
3 1 226.59 
3 1 198.151 
3 2 193.705 
3 2 258.004 
4 2 286.215 
4 2 395.641 
3 2 361.214 
4 3 365.214 
4 4 432.559 
4 2 505.868 
4 2 459.267 
4 2 343.653 
4 3 375.663 
3 3 346.934 
1 2 430.631 
4 1 540.089 
4 1 567.906 
1 2 440.211 
2 3 367.82 
3 3 466.55 
4 3 505.925 
3 2 317.589 
2 2 331.912 
1 3 357.15 
1 4 332.72 
0 4 476.596 
0 0 352.577 
0 0 262.919 
0 1 305.593 
0 4 315.676 
0 0 242.03 
1 1 354.107 
1 2 304.978 
1 2 361.833 
0 0 372.158 
2 0 342.462 
1 1 393.397 
1 2 373.796 
1 0 329.298 
1 0 330.515 
0 1 338.374 
0 3 336.502 
0 4 374.764 
0 0 295.147 
0 1 410.354 
1 2 296.539 
1 2 249.216 
1 3 382.29 
0 4 264.128 
0 0 190.33 
1 1 239.965 
0 1 353.086 
0 4 274.97 
0 4 359.761 
0 4 339.392 
0 4 497.471 
0 4 511.706 
0 1 343.009 
0 2 357.174 
0 2 309.91 
4 0 366.021 
5 0 233.206 
4 1 223.142 
3 0 350.041 
5 0 463.242 
4 2 354.933 
3 2 252.536 
3 2 164.776 
3 2 283.664 
3 2 362.513 
2 1 367.791 
3 0 302.053 
2 1 430.02 
2 0 461.787 
3 0 392.805 
3 1 371.549 
3 1 378.422 
3 1 379.524 
3 3 337.976 
0 3 383.683 
0 4 560.297 
0 4 623.49 
0 2 405.251 
5 2 532.102 
4 3 529.899 
4 4 460.941 
2 4 327.13 
2 4 493.097 
2 4 621.076 
2 4 639.847 
0 4 453.439 
0 0 316.46 
0 0 372.517 
0 0 526.483 
0 0 601.411 
0 1 415.173 
0 2 678.446 
5 1 834.651 
5 2 482.175 
6 2 241.822 
6 0 255.3 
5 1 517.444 
5 3 695.818 
5 4 509.452 
5 4 704.773 
3 4 519.266 
1 4 404.812 
1 0 347.042 
1 4 384.771 
2 0 381.053 
2 2 481.389 
2 4 478.205 
1 4 381.412 
2 4 375.376 
2 2 377.888 
3 1 274.385 
3 2 252.768 
2 2 347.624 
1 0 396.148 
1 0 427.131 
2 0 270.052 
3 1 169.939 
4 0 325.353 
5 1 263.025 
6 2 318 
6 2 244.269 
6 3 206.635 
6 3 430.385 
6 1 401.036 
6 2 464.491 
6 2 293.731 
6 3 416.582 
5 1 614.821 
5 1 475.416 
5 3 499.901 
5 2 487.458 
5 2 372.854 
4 3 243.032 
2 2 326.111 
3 1 339.006 
6 1 308.228 
6 1 638.075 
6 2 853.006 
6 2 482.092 
6 2 551.722 
4 3 594.535 
4 4 634.19 
0 3 514.928 
0 1 458.723 
0 2 588.754 
0 2 562.414 
4 0 472.24 
5 2 379.585 
3 3 359.908 
3 3 477.823 
3 3 604.486 
3 2 470.933 
5 2 413.285 
6 3 419.083 
5 4 503.557 
4 4 346.499 
3 4 508.812 
2 4 504.987 
0 2 525.873 
0 2 344.867 
0 3 305.562 
0 0 471.182 
0 1 469.275 
4 0 286.816 
4 2 364.788 
4 2 443.258 
5 1 397.513 
6 2 465.988 
6 3 527.093 
6 2 567.166 
6 3 387.224 
6 1 357.449 
6 2 588.92 
4 2 413.51 
3 2 406.242 
5 3 474.93 
5 4 452.732 
5 2 592.626 
5 2 704.888 
6 2 671.384 
6 3 465.76 
6 2 380.492 
6 1 488.707 
6 1 526.966 
6 3 420.084 
5 3 404.488 
4 3 212.469 
1 2 312.715 
1 2 276.034 
1 3 189.908 
1 4 306.767 
2 3 339.482 
4 4 378.466 
6 4 368.98 
6 4 617.407 
6 4 470.969 
6 4 548.259 
5 3 413.202 
5 2 386.47 
6 1 386.079 
5 2 362.355 
5 1 378.284 
4 2 320.457 
3 3 370.436 
3 3 484.37 
3 2 462.439 
3 2 668.651 
6 4 678.122 
3 2 585.232 
5 3 633.582 
3 2 480.913 
3 4 586.535 
1 4 646.311 
0 3 603.245 
5 0 531.41 
5 0 279.675 
4 1 237.832 
1 3 414.692 
1 1 446.171 
4 0 436.565 
4 3 611.141 
4 4 717.409 
4 4 767.364 
6 2 638.374 
6 1 586.647 
5 2 472.107 
2 4 394.814 
1 4 463.973 
1 3 311.94 
2 2 403.821 
3 2 299.272 
5 2 560.419 
6 3 376.81 
6 3 455.242 
6 2 382.588 
6 3 728.684 
6 4 408.284 
5 4 400.674 
3 3 472.536 
5 1 469.594 
5 2 491.331 
5 4 583.897 
5 4 678.55 
4 1 771.645 
6 0 455.456 
3 1 546.742 
3 2 438.749 
2 3 304.096 
2 2 394.396 
4 0 351.207 
6 1 338.775 
6 3 438.961 
6 4 489.95 
5 0 424.727 
5 0 326.808 
5 1 375.578 
5 3 306.223 
5 2 362.315 
6 1 400.223 
6 3 410.7 
4 2 439.511 
4 1 451.798 
4 2 504.891 
4 3 655.111 
1 2 570.279 
3 4 444.328 
3 4 467.518 
2 4 440.075 
1 4 428.473 
1 1 397.775 
4 0 277.433 
5 1 267.193 
5 3 360.493 
5 4 596.755 
4 4 410.682 
3 3 372.665 
5 1 306.165 
6 2 397.484 
6 3 372.816 
5 2 357.235 
5 3 440.796 
5 4 356.612 
6 2 362.217 
6 2 502.019 
6 4 268.438 
5 2 378.235 
5 1 352.092 
3 1 289.167 
5 1 350.033 
5 3 333.492 
6 4 278.919 
4 4 320.662 
2 3 217.077 
3 1 259.964 
4 1 332.792 
3 3 372.807 
2 4 378.393 
2 4 415.841 
1 4 379.206 
1 0 370.592 
2 3 373.321 
2 4 558.375 
0 4 494.606 
0 4 398.312 
0 1 411.846 
1 1 348.302 
1 3 318.542 
1 3 273.069 
1 1 453.271 
4 0 290.296 
4 0 271.695 
3 1 213.758 
2 2 232.951 
2 2 292.873 
4 4 486.588 
4 4 526.739 
4 4 503.211 
4 4 571.122 
4 4 510.653 
3 4 262.845 
3 4 355.687 
3 4 503.369 
2 4 614.186 
0 4 442.104 
0 1 488.251 
0 1 507.997 
4 0 560.662 
1 2 431.935 
4 2 214.104 
4 2 287.772 
4 2 313.531 
4 4 385.401 
3 4 488.759 
3 4 427.856 
0 3 485.41 
0 2 526.38 
4 1 439.12 
3 3 383.654 
4 4 497.459 
5 4 702.55 
4 2 552.275 
1 2 430.545 
2 4 292.527 
1 4 304.407 
1 1 276.255 
1 2 358.864 
0 4 297.654 
0 4 369.217 
0 1 225.753 
0 2 298.577 
1 3 330.786 
2 2 304.634 
1 2 333.336 
0 2 462.217 
0 2 528.502 
0 2 562.865 
0 2 596.38 
4 0 575.101 
4 1 578.363 
0 2 431.794 
0 1 501.005 
0 1 395.037 
0 1 457.743 
0 2 443.754 
0 3 386.149 
0 1 349.086 
4 0 477.305 
4 1 481.019 
1 2 445.026 
1 2 441.113 
4 3 416.109 
3 4 435.413 
2 4 390.495 
1 3 360.21 
1 2 316.468 
1 1 317.558 
3 0 403.42 
3 0 519.966 
4 0 535.482 
5 1 439.997 
4 2 458.606 
0 3 429.305 
0 0 426.553 
0 4 458.954 
0 4 431.293 
0 0 351.024 
0 1 265.814 
1 3 358.442 
0 3 319.315 
0 1 335.478 
0 2 462.492 
0 2 462.335 
0 3 335.404 
0 3 402.675 
0 3 533.819 
0 0 495.904 
0 1 355.525 
0 2 256.792 
4 0 341.944 
1 2 249.151 
0 2 269.304 
4 0 393.211 
4 1 414.188 
0 2 443.179 
0 1 571.844 
0 1 539.693 
4 0 583.333 
4 0 576.518 
0 2 520.627 
0 2 352.212 
0 2 395.649 
1 2 431.829 
0 3 429.127 
0 1 449.698 
0 0 411.497 
1 1 361.334 
1 2 354.923 
3 3 352.231 
2 1 427.694 
0 1 370.455 
0 2 378.957 
0 2 382.6 
4 0 362.247 
2 1 311.666 
1 1 321.494 
1 1 339.561 
1 2 349.843 
1 2 331.403 
1 3 330.583 
1 3 372.088 
1 4 370.438 
0 4 395.752 
0 0 281.77 
1 0 331.475 
2 0 474.176 
4 0 582.485 
4 1 812.169 
5 4 458.941 
4 4 403.094 
3 2 237.028 
4 2 350.039 
3 2 396.37 
3 3 455.24 
2 3 356.441 
0 0 401.099 
0 0 303.412 
0 0 250.612 
0 1 309.094 
1 1 306.235 
1 2 354.275 
2 1 381.401 
1 2 344.47 
0 4 279.392 
0 4 414.861 
0 4 374.095 
0 1 346.004 
4 0 438.897 
4 1 588.12 
0 2 693.621 
3 3 544.801 
0 3 320.435 
0 0 403.248 
1 4 332.884 
1 1 265.988 
4 3 374.032 
3 4 376.253 
1 4 269.424 
1 4 323.927 
1 3 232.453 
3 4 414.248 
0 2 498.495 
4 0 390.081 
1 1 359.593 
0 0 249.495 
1 0 539.873 
3 0 604.857 
4 0 463.482 
6 0 379.474 
6 2 393.078 
6 4 434.201 
5 4 262.83 
3 2 236.039 
1 0 329.144 
1 0 486.719 
5 0 655.469 
5 1 423.248 
2 2 513.549 
1 4 573.447 
0 0 418.203 
1 0 328.912 
1 1 327.863 
2 2 247.491 
3 3 195.28 
4 4 193.579 
4 4 395.394 
3 2 283.2 
5 2 350.993 
6 1 261.605 
6 0 381.534 
5 1 585.824 
5 4 482.752 
4 4 310.497 
4 4 528.31 
4 4 596.834 
3 4 531.608 
4 3 403.358 
3 4 305.807 
2 3 359.574 
2 2 269 
2 4 372.516 
2 3 419.459 
2 2 456.996 
2 3 374.01 
1 0 506.516 
1 0 475.391 
2 0 362.561 
4 1 438.205 
3 2 360.323 
1 3 365.241 
1 3 380.616 
0 3 334.355 
0 2 289.827 
5 0 454.127 
6 1 540.074 
6 2 413.635 
6 2 289.092 
6 1 290.168 
5 2 317.214 
4 3 340.713 
4 2 299.027 
6 2 305.249 
6 3 210.589 
6 2 333.986 
6 4 340.191 
3 4 404.523 
2 2 270.059 
5 0 425.312 
6 0 353.059 
6 0 238.032 
5 2 218.854 
3 1 277.865 
3 1 307.552 
6 0 639.593 
6 0 536.216 
5 2 456.783 
5 2 439.949 
5 4 515.621 
3 4 573.922 
1 0 497.377 
2 0 419.181 
1 0 328.467 
4 0 263.275 
5 0 310.725 
4 1 518.268 
0 2 379.358 
4 3 360.296 
3 3 429.868 
3 1 378.858 
6 2 323.063 
6 4 313.146 
5 2 423.056 
4 2 434.612 
1 2 351.189 
1 0 417.674 
1 0 327.04 
2 2 349.801 
2 3 336.528 
2 1 421.79 
6 0 241.806 
6 1 343.563 
6 0 361.222 
5 2 411.523 
1 2 398.211 
5 0 495.48 
6 1 513.299 
6 2 312.514 
3 0 429.709 
3 0 429.282 
1 2 534.698 
4 1 388.726 
5 2 451.373 
3 1 523.772 
5 0 589.33 
6 1 336.318 
6 2 787.78 
6 2 542.002 
6 3 456.12 
6 3 604.578 
6 2 585.721 
6 4 641.335 
6 3 655.073 
6 1 489.626 
6 1 611.573 
6 1 989.252 
6 2 774.418 
6 4 572.509 
5 4 525.498 
3 4 677.379 
2 4 566.868 
2 3 402.412 
3 3 527.76 
4 0 322.107 
0 2 446.034 
3 0 614.539 
3 0 602.607 
5 0 501.953 
5 0 322.715 
6 0 311.383 
6 2 476.257 
6 4 388.884 
6 3 331.609 
6 4 805.121 
5 4 839.855 
4 3 424.609 
3 3 438.157 
0 2 400.763 
1 1 478.338 
2 2 359.617 
3 2 410.226 
6 2 416.732 
5 2 372.058 
4 2 402.628 
0 2 420.604 
4 0 630.593 
5 2 398.222 
5 3 320.528 
5 3 521.554 
5 2 233.587 
6 3 401.1 
5 4 424.31 
3 4 262.901 
2 3 203.948 
1 3 255.983 
1 1 377.54 
5 0 308.944 
5 2 385.931 
3 2 341.89 
3 1 152.732 
3 3 309.098 
3 4 357.137 
3 0 425.683 
4 1 446.132 
5 3 324.375 
3 3 241.927 
1 1 263.99 
3 0 224.727 
5 0 438.62 
5 1 306.052 
1 3 388.108 
0 4 392.295 
0 4 253.702 
0 2 342.637 
3 4 320.047 
3 4 309.038 
3 3 377.682 
3 3 401.388 
2 4 334.388 
3 4 335.709 
3 4 383.018 
1 2 438.584 
5 3 389.511 
4 4 304.144 
2 3 418.21 
1 2 400.24 
4 0 332.781 
4 1 447.954 
0 2 827.677 
4 1 834.251 
5 2 386.844 
4 3 293.9 
2 4 295.146 
2 2 300.731 
2 1 346.027 
2 0 290.531 
2 0 251.606 
1 3 370.867 
1 0 339.275 
1 0 258.208 
0 2 240.719 
0 2 337.74 
0 1 358.653 
0 0 250.415 
0 1 148.4 
4 1 352.471 
5 1 296.41 
5 2 261.147 
4 3 368.688 
3 4 232.75 
2 4 225.818 
1 4 211.304 
1 3 278.462 
1 1 278.996 
0 1 198.789 
1 1 391.784 
4 0 313.082 
1 2 311.073 
1 3 332.804 
1 4 375.081 
1 1 417.387 
4 0 273.16 
5 2 376.707 
6 4 439.423 
6 4 292.096 
4 1 366.432 
4 0 329.103 
3 2 446.268 
2 1 347.032 
2 0 306.679 
4 1 396.423 
5 2 439.733 
5 1 368.218 
4 3 412.4 
3 3 413.016 
4 0 379.024 
1 1 472.039 
1 1 442.547 
1 1 419.493 
3 1 394.275 
4 2 451.265 
3 4 258.274 
2 2 328.336 
1 1 284.028 
1 2 405.189 
1 1 436.81 
0 1 375.638 
0 2 278.297 
1 2 331.915 
1 1 316.999 
0 1 272.984 
2 0 340.972 
4 0 371.538 
4 1 489.667 
4 3 513.636 
2 3 267.47 
1 2 214.855 
3 3 272.937 
2 3 258.913 
2 2 201.323 
3 2 499.076 
3 4 394.347 
2 3 381.896 
1 0 348.168 
2 0 571.836 
2 0 582.516 
1 0 466.343 
1 0 443.661 
0 0 547.5 
0 0 500.928 
0 0 469.369 
0 0 513.953 
0 0 503.887 
0 0 426.173 
0 3 516.806 
0 3 517.526 
0 3 527.858 
3 4 363.822 
2 4 269.865 
1 1 372.865 
4 1 459.182 
4 1 499.167 
4 1 292.002 
4 1 339.531 
0 2 478.928 
0 3 530.304 
0 3 576.428 
0 3 647.684 
0 3 464.931 
4 3 452.243 
1 3 347.774 
0 4 285.902 
0 0 330.654 
0 1 451.643 
4 0 430.743 
5 0 439.544 
1 1 396.268 
1 4 212.741 
0 4 297.619 
0 3 382.783 
0 3 271.569 
0 0 276.816 
0 0 385.129 
1 4 448.268 
2 4 419.617 
1 4 354.772 
1 1 222.885 
0 4 444.177 
0 4 561.921 
0 0 431.365 
0 4 292.153 
0 4 277.697 
0 0 339.166 
0 0 277.103 
0 1 315.28 
0 1 267.114 
2 3 298.993 
1 4 275.792 
0 4 297.285 
0 1 291.531 
1 3 602.473 
3 4 519.003 
3 4 332.268 
3 3 342.663 
1 2 378.832 
3 4 380.621 
3 4 403.767 
3 4 386.013 
1 4 280.747 
1 1 236.875 
4 1 202.442 
4 1 192.369 
3 0 201.537 
3 0 246.011 
5 0 459.226 
5 0 356.798 
0 1 426.337 
0 0 492.967 
0 1 413.693 
1 1 358.789 
1 1 280.135 
3 0 333.666 
0 2 480.346 
0 1 384.988 
0 0 733.591 
0 0 627.658 
0 1 565.179 
4 0 374.621 
4 0 356.576 
5 0 434.862 
6 1 667.158 
6 1 680.737 
6 1 465.065 
5 2 537.228 
6 3 668.165 
6 3 707.854 
6 3 732.158 
6 4 673.018 
6 4 540.942 
5 4 440.384 
4 3 441.215 
3 2 217.239 
3 3 193.836 
4 4 225.627 
4 4 461.347 
3 3 533.575 
3 2 235.172 
3 4 454.781 
2 3 493.671 
1 0 558.249 
2 0 442.893 
5 0 459.459 
3 1 398.883 
6 0 815.951 
6 1 685.517 
6 3 458.985 
4 3 318.169 
2 4 223.543 
2 4 464.381 
3 4 479.161 
2 2 289.611 
2 1 287.884 
2 0 223.629 
3 1 308.082 
3 2 389.878 
3 1 370.338 
5 0 403.45 
5 0 401.207 
6 0 545.478 
5 1 614.3 
5 3 395.877 
5 3 513.019 
5 2 534.112 
5 3 519.961 
6 3 575.219 
6 3 517.564 
5 4 521.77 
2 3 590.237 
2 2 652.872 
3 2 458.254 
3 1 373.733 
5 3 454.143 
5 4 418.922 
2 4 465.694 
1 4 510.071 
3 2 328.337 
5 4 386.777 
4 4 505.879 
4 3 357.576 
4 3 276.019 
4 3 250.871 
6 4 361.895 
6 4 435.314 
6 4 666.341 
6 4 765.29 
3 4 533.755 
2 2 469.532 
5 0 278.821 
6 1 458.931 
5 2 247.951 
5 1 299.608 
5 0 322.608 
5 0 358.006 
5 0 593.612 
6 0 431.317 
6 0 279.405 
6 0 416.707 
6 1 566.793 
6 4 324.577 
6 3 705.553 
6 0 242.45 
6 0 344.176 
6 0 381.692 
6 1 408.538 
6 3 416.699 
4 4 321.479 
3 4 281.455 
3 2 447.502 
6 1 652.514 
5 2 667.238 
3 1 546.76 
3 1 549.475 
2 2 430.643 
5 0 496.728 
6 1 539.696 
6 2 697.545 
6 3 696.93 
5 3 503.639 
3 2 260.774 
4 3 304.478 
2 3 188.032 
1 0 300.51 
1 0 236.993 
3 0 564.566 
6 0 741.554 
6 0 793.108 
6 1 683.48 
4 3 584.122 
1 4 525.987 
0 0 578.625 
1 0 247.096 
2 1 291.594 
2 1 314.712 
3 1 310.869 
4 3 345.979 
4 4 407.725 
0 4 279.236 
1 1 379.343 
1 1 514.4 
3 0 507.567 
2 1 415.375 
2 1 315.397 
3 1 376.151 
5 2 391.441 
3 3 448.703 
2 4 521.227 
3 4 778.425 
4 4 970.2 
3 4 498.943 
1 3 332.688 
2 4 348.776 
0 4 472.27 
0 0 450.328 
2 0 395.297 
4 1 253.642 
5 3 229.385 
3 2 278.67 
3 1 414.363 
5 1 580.492 
4 4 483.631 
3 4 408.799 
3 4 271.136 
4 2 283.697 
6 3 200.834 
5 4 304.564 
2 4 432.478 
0 0 481.476 
1 0 299.921 
2 0 274.158 
1 1 275.909 
1 3 361.221 
1 0 406.716 
1 4 470.906 
1 0 274.329 
3 1 228.776 
5 2 417.512 
3 3 544.54 
2 3 411.396 
2 3 461.209 
1 3 428.449 
1 3 334.679 
1 2 387.234 
4 2 374.592 
4 2 312.423 
5 2 418.571 
3 1 466.641 
3 1 367.551 
4 2 350.209 
4 2 377.45 
5 1 324.504 
5 2 269.744 
6 3 268.8 
6 4 610.002 
4 4 621.773 
4 4 536.596 
0 3 701.763 
0 4 609.206 
0 0 389.518 
4 0 447.045 
4 1 291.845 
4 3 231.041 
4 4 390.617 
3 4 680.493 
2 4 564.784 
2 4 482.431 
3 0 337.216 
3 1 264.856 
2 2 319.054 
1 1 280.265 
3 0 286.005 
3 0 268.572 
3 1 263.009 
5 3 303.948 
4 4 527.064 
3 4 509.959 
2 4 431.607 
3 0 382.537 
3 0 322.062 
3 0 376.023 
5 0 368.463 
5 1 292.301 
5 2 475.634 
4 3 641.675 
3 4 417.362 
0 2 334.232 
1 1 347.774 
2 1 313.825 
3 3 311.723 
4 4 345.721 
4 4 514.292 
4 2 433.665 
5 2 453.585 
5 4 390.234 
3 4 408.067 
2 4 320.936 
1 3 247.276 
0 3 298.568 
1 2 331.356 
5 2 409.568 
6 3 484.035 
3 4 415.501 
1 0 403.396 
1 4 385.404 
2 4 483.784 
0 3 542.478 
1 2 325.41 
3 3 307.409 
2 4 382.607 
1 4 551.722 
0 1 409.536 
4 0 260.021 
5 1 304.828 
5 2 257.045 
5 3 223.73 
4 2 295.843 
5 3 454.408 
6 4 417.043 
4 4 232.451 
3 2 352.846 
3 1 323.103 
5 1 397.004 
5 1 369.871 
4 2 283.495 
0 2 257.9 
0 3 387.313 
0 1 415.566 
1 1 489.096 
4 2 432.099 
5 4 443.689 
6 4 551.307 
5 4 606.164 
3 2 329.725 
3 2 352.435 
1 2 389.459 
1 1 327.323 
1 2 294.3 
4 2 335.7 
4 3 448.49 
3 3 359.41 
2 2 303.747 
2 2 280.423 
2 2 317.989 
3 0 259.404 
3 0 426.63 
3 0 514.322 
3 1 498.92 
2 3 364.153 
2 2 301.072 
3 3 360.516 
3 2 327.578 
3 2 292.05 
3 2 287.957 
3 3 354.891 
3 4 439.332 
2 4 378.054 
1 3 236.331 
1 1 281.047 
3 0 277.136 
3 1 305.976 
3 0 336.736 
1 2 429.277 
1 2 278.682 
4 0 330.434 
4 1 328.707 
2 1 275.816 
2 1 255.02 
2 1 268.88 
1 2 237.428 
1 3 206.535 
1 1 252.149 
1 0 297.735 
1 0 294.821 
4 0 401.983 
4 1 427.272 
1 2 464.513 
0 2 322.86 
4 0 574.175 
5 1 696.408 
4 1 502.711 
4 0 469.692 
4 1 500.521 
4 1 371.818 
1 1 237.482 
1 0 375.065 
2 2 400.664 
2 3 264.174 
2 2 345.385 
1 1 394.09 
1 1 369.541 
2 2 301.488 
4 0 205.803 
5 0 402.695 
3 2 397.695 
2 2 535.446 
1 0 431.826 
2 0 343.687 
1 1 370.864 
1 1 246.386 
1 2 379.397 
1 4 396.729 
1 4 387.734 
1 3 224.359 
0 4 199.99 
0 4 427.683 
0 4 453.534 
0 4 346.051 
0 1 276.863 
3 0 316.246 
5 0 184.753 
4 1 412.54 
3 2 436.107 
3 4 403.957 
1 4 394.848 
0 4 557.82 
0 4 505.232 
1 4 452.458 
2 4 481.225 
2 3 331.184 
1 2 274.853 
3 0 316.638 
2 0 301.098 
2 0 339.436 
1 0 318.069 
2 0 264.623 
3 0 349.971 
4 2 523.42 
4 4 394.531 
2 3 409.691 
3 1 338.614 
3 2 343.418 
1 3 304.509 
1 2 299.3 
3 0 241.997 
3 1 279.766 
3 1 287.132 
3 2 312.712 
3 3 330.597 
2 1 381.693 
3 0 337.709 
4 1 439.564 
3 3 371.166 
2 3 387.416 
2 0 343.951 
3 0 352.591 
3 0 253.992 
3 0 407.256 
3 0 262.964 
3 2 273.301 
3 2 319.489 
3 1 268.494 
4 1 266.35 
5 2 263.97 
3 3 276.416 
2 1 246.914 
3 3 300.723 
2 4 223.659 
2 3 245.801 
1 1 286.12 
1 4 303.979 
0 4 333.894 
0 4 448.04 
0 4 505.615 
0 0 299.085 
1 0 203.873 
2 1 254.55 
3 0 233.714 
3 0 605.734 
4 0 524.179 
5 0 636.696 
6 0 413.839 
6 0 401.301 
6 0 356.193 
6 2 453.195 
6 2 913.425 
6 4 671.711 
6 4 366.973 
3 4 425.887 
0 2 409.849 
4 0 340.721 
4 0 426.643 
0 2 380.742 
0 1 269.224 
0 0 262.479 
1 2 354.859 
4 0 574.002 
5 0 725.633 
4 0 761.395 
0 1 682.314 
1 2 545.408 
2 3 441.62 
2 4 339.021 
2 4 365.294 
4 4 412.235 
4 4 733.09 
3 4 1019.3 
0 4 882.593 
0 3 745.715 
0 2 625.469 
4 0 497.789 
0 1 394.525 
3 0 443.316 
5 0 417.63 
6 1 400.203 
6 2 624.312 
6 2 680.581 
5 3 531.403 
1 2 545.537 
0 0 356.864 
3 0 510.535 
5 0 542.87 
5 0 339.045 
1 2 475.852 
1 1 450.047 
2 3 424.839 
4 0 547.136 
4 1 521.586 
4 2 332.732 
3 3 235.576 
2 1 417.312 
3 0 317.632 
0 2 341.871 
0 2 315.069 
1 2 343.98 
2 4 359.374 
2 2 522.13 
2 4 471.418 
2 4 616.285 
2 3 636.047 
2 1 517.932 
3 2 567.944 
5 1 583.229 
5 2 444.324 
6 1 345.354 
6 2 520.281 
6 2 624.279 
6 1 674.685 
6 3 427.139 
3 3 335.102 
2 1 304.471 
5 0 518.173 
6 0 374.094 
6 2 690.967 
6 3 463.603 
6 3 634.845 
5 4 643.338 
3 4 689.917 
3 3 416.605 
5 4 376.243 
3 4 209.486 
2 3 258.585 
4 2 383.307 
4 4 341.788 
2 4 571.966 
1 4 499.443 
2 0 342.969 
3 0 520.772 
6 1 624.39 
5 2 447.857 
4 2 237.509 
4 2 333.113 
5 1 346.655 
5 3 325.855 
4 4 388.192 
2 2 461.738 
2 1 358.188 
3 1 420.648 
4 3 363.218 
3 1 379.098 
3 0 496.75 
5 0 579.121 
6 2 418.601 
5 3 349.508 
3 3 223.289 
1 0 485.894 
1 0 402.046 
3 1 319.384 
6 1 428.208 
6 1 385.232 
6 0 566.438 
6 1 713.693 
6 2 587.95 
5 2 389.276 
2 1 386.944 
2 1 396.238 
2 1 289.077 
3 3 276.329 
4 3 466.91 
6 1 476.682 
6 2 486.523 
6 3 689.046 
6 2 537.327 
6 3 405.056 
3 2 348.362 
3 3 454.026 
3 2 399.632 
4 2 327.863 
3 4 333.977 
2 4 449.484 
2 3 556.568 
4 2 400.449 
4 4 230.64 
1 3 349.286 
1 0 540.177 
3 0 558.824 
0 2 471.016 
4 3 406.985 
5 4 543.375 
3 3 392.714 
3 2 476.693 
4 1 288.968 
4 2 374.595 
3 1 632.195 
3 0 404.956 
3 1 243.833 
1 3 235.514 
1 3 261.355 
4 0 278.343 
5 3 323.95 
3 0 302.778 
5 0 396.945 
5 1 361.248 
4 3 520.448 
0 3 370.989 
0 3 469.951 
0 0 388.788 
1 4 259.466 
1 4 203.362 
0 3 211.58 
1 2 253.152 
1 2 308.023 
1 3 331.971 
0 3 266.507 
0 2 271.86 
0 3 308.95 
1 4 264.192 
2 1 331.604 
2 2 230.865 
2 2 202.702 
3 2 355.703 
3 0 457.582 
5 0 455.089 
3 1 248.402 
3 0 325.809 
4 1 295.969 
2 2 260.94 
3 3 305.849 
4 3 225.23 
4 4 214.846 
4 3 239.062 
4 4 215.834 
3 4 369.709 
4 1 341.01 
6 1 175.907 
6 3 359.954 
4 4 315.868 
1 4 361.367 
1 3 295.81 
3 3 298.926 
3 4 155.194 
1 3 365.381 
2 0 222.034 
3 1 258.372 
3 3 260.771 
2 3 375.683 
3 1 240.529 
2 2 241.895 
2 2 280.439 
3 4 172.12 
2 3 408.318 
3 1 263.722 
5 1 279.209 
4 2 272.505 
4 3 245.828 
3 2 350.931 
3 1 240.844 
3 1 323.1 
3 0 256.186 
3 0 244.887 
4 1 268.682 
1 2 451.45 
4 0 577.113 
3 0 600.176 
0 1 458.018 
0 2 320.558 
1 3 330.692 
2 3 449.925 
3 3 389.728 
3 2 702.26 
4 1 602.401 
3 3 538.114 
4 3 549.212 
4 2 558.507 
3 1 311.776 
2 0 252.802 
2 0 376.707 
1 0 268.851 
1 4 378.459 
1 4 479.999 
1 0 353.054 
3 0 219.007 
3 1 298.609 
3 2 393.24 
3 2 587.532 
3 3 526.138 
2 4 424.137 
2 3 286.372 
4 2 300.399 
4 3 396.789 
1 2 264.901 
4 2 326.661 
4 3 443.685 
4 4 469.086 
4 4 623.878 
3 4 396.065 
3 4 385.92 
4 4 284.302 
4 4 216.33 
3 3 197.087 
2 2 281.606 
2 0 413.136 
2 0 418.061 
1 1 319.561 
1 1 307.197 
2 2 299.925 
3 3 261.978 
3 2 266.764 
5 0 288.167 
3 0 209.901 
2 0 407.709 
3 0 385.498 
2 1 345.448 
3 0 252.533 
3 0 264.099 
3 0 447.412 
3 0 367.887 
3 0 585.272 
2 0 633.261 
3 0 461.144 
4 1 405.308 
4 2 273.812 
2 1 191.458 
1 1 316.773 
1 1 242.121 
1 1 268.653 
0 0 240.79 
0 0 288.092 
0 0 281.916 
0 0 265.665 
3 0 465.946 
4 0 394.821 
6 0 378.988 
4 2 418.938 
0 1 352.099 
0 1 376.729 
4 1 369.07 
4 3 590.245 
1 4 598.959 
0 4 517.751 
0 0 521.655 
0 0 632.72 
0 0 564.849 
0 1 422.012 
1 0 268.677 
1 1 228.118 
2 1 238.354 
3 1 346.345 
2 1 475.373 
1 4 531.202 
0 0 482.723 
1 0 397.069 
1 0 393.725 
2 0 397.15 
1 1 359.776 
0 2 284.075 
0 2 248.69 
0 1 275.012 
0 3 271.26 
0 3 390.773 
2 4 350.515 
1 3 305.816 
0 3 214.093 
0 1 439.062 
0 2 482.586 
0 2 394.866 
4 1 389.525 
5 1 351.788 
4 2 325.927 
3 2 413.326 
3 1 349.75 
3 1 313.673 
3 1 345.958 
2 2 289.197 
2 1 353.138 
2 0 377.184 
5 0 534.913 
5 0 448.951 
4 1 353.304 
0 2 304.668 
0 1 281.425 
0 1 552.677 
5 0 401.697 
5 1 261.676 
3 1 378.812 
4 0 372.649 
4 2 384.461 
3 1 276.226 
2 0 313.39 
2 0 488.301 
3 0 330.91 
4 0 265.36 
3 0 280.888 
5 0 315.676 
5 2 486.76 
4 3 397.545 
4 4 251.784 
3 3 277.209 
6 2 336.101 
6 3 735.457 
6 4 930.126 
6 4 1080.27 
6 4 547.98 
6 2 532.129 
6 1 437.208 
6 1 545.899 
3 1 519.215 
2 0 631.679 
1 0 555.982 
2 0 324.542 
3 0 360.488 
5 0 522.925 
5 0 242.664 
3 1 381.409 
3 1 369.277 
4 3 290.277 
5 3 379.368 
6 4 434.372 
5 4 453.787 
4 3 711.649 
5 2 351.689 
5 3 319.214 
5 4 494.416 
6 4 473.166 
6 4 562.395 
6 4 451.738 
5 3 455.68 
6 2 264.218 
6 2 387.424 
6 1 515.916 
6 2 243.956 
5 3 240.443 
4 2 359.494 
5 4 420.671 
2 4 578.3 
2 2 473.699 
2 3 490.85 
3 0 625.313 
5 0 416.924 
3 0 373.971 
2 1 466.328 
3 2 463.337 
3 2 362.95 
3 3 384.977 
3 2 314.567 
6 1 292.155 
6 3 302.304 
5 1 691.812 
6 0 339.394 
6 1 490.348 
6 2 664.133 
6 3 746.96 
6 3 665.822 
6 4 361.923 
5 3 512.948 
5 2 192.107 
6 3 174.286 
5 4 393.309 
5 4 645.829 
4 4 554.446 
3 4 696.866 
2 4 700.211 
3 1 308.676 
6 1 447.344 
6 1 472.001 
6 2 350.802 
6 3 570.248 
6 2 817.799 
6 2 424.806 
5 3 442.423 
5 0 436.082 
5 0 429.305 
6 0 493.706 
6 1 547.385 
3 2 828.174 
6 0 898.01 
3 1 686.981 
3 1 537.473 
5 0 465.555 
4 2 555.422 
3 3 455.424 
2 2 376.924 
3 2 344.022 
3 2 547.081 
5 3 727.338 
6 4 549.534 
6 4 309.302 
5 4 691.288 
2 4 301.883 
2 0 365.618 
1 0 342.374 
1 0 386.585 
3 1 402.735 
3 1 353.578 
3 0 552.661 
5 0 345.985 
5 2 270.368 
4 4 414.947 
2 4 493.297 
0 4 616.458 
0 4 492.335 
0 0 455.176 
2 2 365.378 
4 3 272.096 
3 3 356.268 
2 2 303.655 
2 4 348.951 
2 4 411.705 
2 3 361.256 
3 1 364.337 
5 1 427.492 
6 2 408.855 
6 3 577.504 
6 3 684.026 
5 4 481.775 
2 4 371.584 
2 3 400.386 
1 0 381.342 
0 0 578.313 
0 0 372.922 
4 0 332.375 
4 1 199.776 
6 1 203.243 
6 2 209.687 
6 1 325.216 
5 2 376.121 
4 2 310.033 
1 2 430.371 
0 2 421.648 
1 2 358.94 
3 1 234.314 
3 2 265.136 
4 4 336.067 
3 3 455.847 
3 1 330.081 
2 2 446.256 
2 4 441.468 
2 3 442.205 
4 1 412.585 
5 2 364.202 
6 2 420.17 
6 4 556.566 
4 4 318.045 
2 2 328.746 
5 3 448.968 
5 4 521.11 
5 4 720.783 
4 4 778.67 
2 3 492.471 
3 2 224.481 
3 3 193.1 
2 2 258.836 
2 2 164.391 
2 4 251.395 
1 4 295.061 
1 0 285.189 
4 0 288.152 
3 3 487.432 
1 4 396.377 
0 4 493.219 
0 1 478.657 
4 2 427.836 
5 2 485.253 
5 1 305.474 
4 3 400.32 
1 3 442.033 
0 3 425.268 
0 2 571.949 
5 0 703.92 
6 1 718.665 
6 1 646.777 
6 2 351.663 
6 2 445.984 
4 2 686.713 
0 2 713.197 
0 3 468.078 
0 3 410.353 
3 3 435.419 
4 2 413.878 
5 4 480.354 
4 4 469.755 
4 4 443.628 
2 3 408.257 
1 2 303.061 
3 3 398.97 
1 2 348.561 
4 3 431.042 
5 3 537.099 
5 4 484.319 
1 2 348.949 
0 2 497.847 
1 2 413.498 
0 1 319.165 
0 1 197.196 
0 1 275.502 
4 0 410.906 
5 2 436.552 
6 4 465.669 
5 4 338.185 
4 1 377.845 
5 1 365.439 
5 2 529.186 
5 4 389.613 
5 3 396.897 
5 2 338.349 
5 3 322.957 
4 4 434.263 
2 4 600.019 
1 4 479.268 
1 4 349.896 
2 1 479.054 
2 2 366.949 
3 2 287.066 
4 2 325.46 
6 2 366.375 
6 2 289.928 
6 2 321.829 
5 3 311.47 
3 2 257.494 
3 2 237.813 
4 2 304.544 
4 3 291.542 
4 3 235.619 
4 2 403.111 
5 0 409.922 
5 1 384.968 
6 3 346.564 
5 3 192.019 
5 2 251.793 
3 2 239.715 
5 1 248.199 
4 2 335.286 
4 2 393.134 
4 2 350.125 
4 4 354.655 
3 4 397.725 
3 4 490.161 
1 2 380.378 
4 2 445.478 
5 2 413.711 
5 2 295.133 
4 3 223.289 
3 2 231.99 
2 2 225.785 
1 0 456.143 
1 4 484.767 
1 3 463.156 
2 2 372.967 
2 3 372.284 
3 2 343.34 
5 4 352.156 
4 3 312.497 
4 3 335.701 
4 4 627.063 
4 3 593.336 
3 3 387.689 
2 3 317.739 
2 2 396.784 
2 1 366.422 
3 3 403.33 
5 4 408.074 
5 4 411.156 
6 4 582.484 
6 4 546.105 
4 2 281.947 
4 2 305.303 
3 3 363.948 
0 4 258.413 
0 0 342.005 
0 0 302.638 
0 1 374.427 
0 1 491.346 
0 2 398.583 
0 2 423.36 
0 2 436.5 
4 0 527.337 
4 2 381.191 
2 2 221.77 
2 1 176.936 
4 0 240.639 
4 1 377.15 
1 1 310.919 
1 0 261.341 
0 1 488.017 
0 1 451.87 
0 1 559.629 
0 1 491.822 
4 0 534.946 
0 2 619.437 
4 3 475.591 
0 2 462.877 
0 1 555.445 
2 0 590.92 
1 0 432.729 
0 1 330.108 
0 3 310.832 
0 3 343.842 
0 1 367.09 
0 1 395.381 
0 0 390.333 
1 0 537.845 
1 0 513.659 
1 0 414.447 
0 0 398.646 
1 2 402.296 
1 2 363.899 
1 2 354.358 
1 3 430.657 
1 3 343.299 
2 0 251.296 
1 1 376.852 
1 0 329.833 
2 1 300.177 
3 2 273.802 
3 2 221.18 
2 2 255.466 
1 3 271.214 
0 4 382.4 
0 0 293.61 
0 0 339.004 
0 0 269.666 
1 0 199.23 
1 2 440.609 
3 4 493.196 
0 4 611.12 
0 4 686.631 
0 0 543.182 
0 0 440.502 
0 1 408.061 
0 3 312.978 
3 0 618.422 
4 0 503.78 
4 1 436.202 
4 1 267.574 
1 2 301.475 
0 2 271.083 
0 4 298.683 
0 0 411.94 
3 0 375.173 
4 1 188.614 
5 0 221.913 
5 2 238.081 
5 1 360.376 
0 2 827.324 
0 2 861.204 
4 1 733.401 
4 0 348.006 
3 0 435.537 
4 0 517.113 
4 0 460.759 
0 1 374.366 
0 0 427.999 
0 0 320.206 
1 0 296.703 
2 0 250.205 
2 0 318.954 
1 1 311.056 
1 2 228.669 
4 1 264.014 
4 3 403.873 
4 4 346.664 
4 4 525.162 
4 4 736.712 
3 4 440.465 
1 2 376.766 
0 2 308.26 
4 0 334.817 
5 1 225.119 
4 2 318.225 
5 4 365.075 
5 4 378.28 
5 3 301.307 
5 3 538.678 
5 0 549.25 
5 0 366.967 
5 0 286.388 
3 1 299.478 
2 1 416.197 
2 3 452.268 
2 2 476.679 
2 1 284.031 
1 1 258.072 
1 1 228.686 
4 2 227.932 
5 1 380.556 
5 0 254.596 
6 1 488.77 
6 2 777.146 
6 3 983.647 
6 4 855.25 
6 4 384.353 
4 4 420.176 
5 4 535.616 
3 4 639.182 
2 3 452.618 
5 2 309.295 
6 4 664.765 
4 4 603.564 
2 3 319.564 
3 4 442.846 
3 4 448.521 
3 3 686.94 
5 0 587.84 
5 0 474.664 
0 2 568.869 
0 1 594.892 
0 0 637.877 
0 0 458.415 
2 0 352.442 
4 2 240.178 
5 3 282.98 
3 2 362.725 
3 2 414.912 
5 4 544.324 
5 4 628.727 
3 3 475.806 
3 3 354.158 
1 4 476.579 
2 0 427.491 
3 0 466.943 
1 1 564.218 
4 0 427.271 
2 2 449.092 
1 4 679.46 
1 4 643.185 
1 4 628.862 
1 0 477.19 
1 0 369.827 
2 0 592.801 
5 0 962.018 
6 0 721.85 
6 1 640.332 
6 2 438.535 
6 2 427.078 
6 2 313.695 
6 1 519.227 
5 2 730.89 
3 2 573.363 
3 1 508.476 
6 0 525.885 
4 1 617.506 
1 2 427.112 
2 1 309.748 
1 3 292.462 
1 4 343.171 
0 0 513.708 
0 0 556.342 
2 0 394.585 
6 0 543.772 
6 1 666.437 
6 2 444.068 
6 4 322.632 
3 3 393.258 
3 2 345.569 
5 0 476.274 
6 0 426.367 
6 0 606.446 
6 0 601.758 
4 1 383.739 
4 2 200.738 
5 2 157.776 
5 4 310.067 
4 3 542.77 
5 0 527.722 
5 1 364.759 
3 3 304.204 
1 4 481.39 
1 4 665.368 
2 3 718.233 
2 2 636.782 
3 3 613.655 
3 3 403.062 
2 2 257.984 
3 2 292.268 
5 3 376.657 
4 4 441.753 
0 4 478.026 
0 0 317.985 
1 0 464.499 
2 0 486.438 
4 0 388.698 
3 1 263.842 
1 3 294.818 
1 4 342.976 
0 0 306.03 
2 0 361.769 
2 0 326.974 
2 0 546.721 
3 0 548.875 
6 0 454.208 
3 2 252.207 
2 0 502.974 
2 1 501.677 
3 2 473.777 
6 0 632.684 
6 1 363.522 
5 3 345.013 
3 2 412.305 
3 1 370.174 
3 2 488.641 
3 3 629.121 
3 3 514.666 
2 2 452.728 
2 1 293.544 
3 0 364.518 
3 1 362.2 
3 3 336.999 
0 4 397.768 
0 0 588.661 
0 1 513.506 
3 1 284.733 
3 1 180.227 
3 2 233.556 
3 3 299.594 
4 4 432.226 
3 4 455.75 
0 3 605.88 
0 1 441.474 
1 1 254.433 
1 1 312.409 
1 3 282.609 
1 4 236.004 
2 0 341.534 
5 0 473.874 
5 2 556.059 
3 3 452.397 
2 1 292.395 
3 1 228.616 
3 2 332.866 
2 3 331.255 
5 0 378.967 
6 0 333.424 
3 2 312.428 
1 1 259.519 
2 2 279.747 
2 1 249.519 
1 1 227.64 
2 0 287.229 
2 0 320.878 
1 3 298.467 
2 2 341.433 
3 0 299.453 
4 0 377.684 
4 2 333.672 
5 3 567.435 
6 4 482.722 
5 4 621.443 
3 4 500.087 
2 3 373.022 
3 4 375.7 
2 3 333.673 
3 4 400.523 
0 3 350.641 
0 1 444.528 
4 0 352.024 
4 0 371.821 
4 2 537.285 
4 4 531.44 
0 2 374.448 
0 2 491.827 
4 0 571.005 
5 0 335.538 
3 1 329.829 
4 0 347.529 
4 0 354.143 
1 1 494.868 
3 0 541.693 
5 0 607.763 
6 1 523.935 
4 3 372.953 
0 3 267.534 
0 1 317.032 
0 1 329.121 
1 2 319.501 
4 3 362.276 
4 2 249.821 
5 1 261.519 
5 2 382.316 
4 3 551.055 
0 3 409.704 
0 4 309.726 
3 0 363.049 
5 2 347.242 
5 2 396.546 
5 3 355.619 
4 3 285.216 
3 4 236.06 
2 4 295.944 
2 4 325.894 
1 1 367.392 
1 1 366.319 
1 0 424.259 
1 0 250.806 
3 1 275.816 
4 3 314.846 
4 4 457.956 
3 4 300.402 
2 3 301.622 
2 4 342.65 
1 4 452.742 
2 0 219.089 
4 1 250.974 
4 1 240.338 
2 2 236.265 
3 2 306.505 
4 3 421.576 
1 2 398.818 
3 2 289.077 
4 3 274.636 
4 4 285.833 
3 4 445.688 
1 4 385.908 
1 4 339.261 
0 2 431.517 
4 0 476.325 
1 2 435.646 
1 2 299.407 
1 2 446.143 
4 1 459.462 
5 1 432.47 
5 3 351.12 
3 3 293.977 
3 3 441.483 
3 4 561.059 
0 3 482.358 
0 1 303.126 
0 0 265.238 
4 0 428.935 
5 1 481.543 
4 2 456.011 
1 3 448.638 
1 4 361.273 
1 3 279.612 
1 3 291.195 
1 2 237.718 
2 3 286.332 
2 3 350.644 
4 1 400.298 
4 0 508.781 
4 0 506.562 
1 2 489.666 
0 2 536.872 
0 2 614.437 
0 2 549.016 
0 2 628.558 
1 4 589.956 
0 4 290.292 
0 1 270.053 
3 0 461.494 
0 2 423.65 
0 3 371.035 
0 1 440.432 
0 0 352.717 
0 0 250.468 
3 0 443.966 
1 1 442.23 
1 2 382.671 
0 3 585.779 
0 4 557.703 
0 4 347.212 
0 4 305.859 
0 0 351.471 
0 0 387.966 
0 0 381.905 
1 0 381.128 
1 0 371.056 
3 0 430.603 
1 1 454.694 
0 4 458.965 
0 4 469.875 
0 4 678.906 
0 0 457.05 
0 1 388.659 
0 2 317.62 
0 2 295.217 
1 1 328.96 
0 1 323.874 
1 1 254.708 
0 1 225.617 
0 3 350.465 
0 4 411.27 
0 0 350.988 
0 0 388.015 
0 1 376.804 
0 0 396.026 
0 0 417.097 
0 0 413.448 
1 0 532.676 
3 0 451.051 
2 0 348.553 
2 0 278.041 
2 1 253.139 
3 0 461.076 
2 3 447.515 
2 4 375.756 
2 4 399.44 
1 3 324.821 
1 1 185.265 
1 1 413.886 
1 4 363.783 
1 4 377.719 
1 3 393.314 
1 1 377.983 
1 4 357.614 
2 3 318.473 
3 1 429.83 
2 2 394.092 
1 4 334.225 
0 0 344.35 
0 0 418.075 
0 0 429.383 
0 3 497.067 
0 3 539.092 
1 2 522.323 
0 2 493.003 
4 0 463.215 
0 2 499.76 
0 2 350.516 
0 2 314.664 
0 2 345.991 
4 4 464.18 
2 4 556.314 
1 4 523.256 
1 1 435.177 
4 0 320.465 
4 3 404.448 
2 4 243.326 
0 4 316.015 
0 1 279.18 
0 1 259.861 
1 1 266.772 
1 2 419.922 
1 1 447.84 
2 4 254.243 
1 4 285.679 
3 0 344.732 
3 0 302.938 
3 0 350.167 
3 2 325.586 
2 3 257.315 
2 0 305.388 
2 0 419.36 
2 0 327.643 
3 0 403.078 
3 0 589.092 
3 0 447.623 
4 0 460.822 
4 1 329.517 
4 2 399.009 
3 4 365.917 
4 4 355.007 
4 3 651.717 
4 0 523.798 
5 0 420.368 
4 2 631.691 
4 4 651.858 
4 4 602.864 
5 4 891.405 
3 4 799.481 
2 3 547.535 
3 0 222.085 
4 1 372.969 
4 2 322.791 
4 2 314.449 
5 4 345.246 
4 3 414.511 
4 4 480.748 
3 4 672.148 
2 4 585.907 
2 4 394.898 
2 2 300.984 
3 2 287.568 
2 1 265.262 
2 0 339.569 
6 0 327.265 
6 1 667.25 
6 3 623.098 
6 3 858.634 
6 2 1077.12 
6 3 656.267 
6 2 577.087 
6 1 464.924 
6 2 603.474 
6 3 742.867 
6 2 859.178 
6 2 1079.43 
6 3 949.288 
5 4 701.92 
3 4 430.795 
0 0 467.199 
2 0 413.189 
3 0 293.585 
4 1 270.668 
5 3 352.53 
3 2 549.542 
5 2 564.242 
5 2 395.162 
5 3 308.098 
3 4 569.136 
2 4 793.755 
2 3 537.018 
3 2 492.338 
5 3 509.866 
3 3 395.245 
3 3 185.143 
3 3 325.519 
4 0 248.389 
3 1 259.166 
4 1 340.915 
5 2 268.75 
6 2 420.472 
6 2 681.867 
6 3 793.623 
4 3 529.027 
5 4 505.995 
3 4 676.702 
2 4 406.624 
1 0 423.625 
2 0 387.855 
3 0 398.39 
3 1 313.781 
1 3 272.258 
1 4 293.889 
1 4 395.18 
1 4 271.188 
4 2 340.623 
5 3 380.781 
5 2 306.126 
6 3 260.902 
5 3 145.262 
5 3 330.718 
3 4 460.693 
5 4 419.464 
5 4 677.803 
4 4 309.638 
4 1 433.595 
4 0 325.239 
4 1 284.138 
4 3 366.482 
4 4 426.492 
1 4 431.594 
1 1 383.049 
3 0 325.004 
3 1 377.473 
3 2 489.599 
2 2 539.726 
2 2 436.991 
3 4 491.231 
2 3 354.854 
3 2 313.563 
3 3 436.915 
3 0 459.03 
5 0 381.394 
3 1 547.768 
2 0 569.582 
1 4 623.325 
1 0 527.001 
4 3 442.251 
2 4 573.076 
1 4 818.755 
0 0 444.011 
3 2 274.914 
4 3 249.725 
4 4 321.783 
4 4 290.567 
5 4 529.049 
5 2 790.029 
6 1 431.043 
6 4 356.065 
3 3 500.648 
3 3 266.562 
2 3 369.738 
3 1 503.453 
5 0 374.174 
5 1 588.447 
5 0 614.164 
6 0 669.064 
6 1 312.31 
6 4 490.832 
4 4 436.44 
5 3 368.279 
4 3 277.187 
4 3 266.452 
4 4 295.829 
3 4 331.849 
0 4 295.262 
0 0 222.338 
0 1 265.11 
0 2 337.495 
4 2 419.656 
4 3 395.116 
4 3 432.352 
1 2 411.947 
0 1 242.834 
0 0 389.945 
0 0 470.728 
1 0 357.002 
2 1 301.46 
4 1 325.067 
5 1 390.009 
6 1 349.23 
5 3 326.504 
2 3 256.7 
2 1 276.262 
3 2 383.495 
4 2 444.073 
5 2 358.641 
5 2 270.942 
4 3 290.461 
3 2 242.631 
3 3 282.025 
2 1 409.854 
2 1 486.823 
2 0 400.361 
3 0 340.871 
3 2 234.556 
3 2 223.897 
4 2 207.765 
3 2 349.765 
5 1 513.945 
6 4 645.187 
5 3 689.225 
4 1 403.809 
5 0 281.828 
5 1 289.888 
5 2 274.832 
6 4 318.794 
5 3 389.616 
5 2 326.223 
5 2 268.627 
6 3 306.392 
6 4 341.015 
6 4 227.449 
6 4 283.704 
5 4 357.492 
4 3 352.671 
4 3 354.13 
5 3 411.033 
5 4 358.948 
0 4 548.808 
0 4 447.475 
0 1 451.981 
4 0 376.611 
4 2 286.943 
3 2 287.481 
4 0 323.972 
5 0 606.073 
3 1 550.89 
3 0 440.411 
3 0 405.932 
1 2 405.467 
0 4 352.698 
0 4 408.588 
0 0 413.501 
1 3 454.561 
2 4 336.619 
1 1 403.476 
1 0 245.061 
2 2 266.121 
3 2 311.311 
3 1 265.522 
3 2 450.678 
5 2 490.651 
5 3 333.095 
4 3 367.075 
0 3 369.92 
0 3 294.886 
0 3 245.143 
0 1 413.09 
0 1 314.214 
0 3 217.034 
0 2 396.282 
4 1 293.817 
5 1 318.494 
3 1 271.015 
2 1 366.359 
2 1 406.045 
2 0 377.151 
2 0 362.753 
1 2 372.984 
1 4 390.897 
0 4 473.206 
0 2 353.22 
0 2 286.454 
1 1 307.103 
1 1 283.301 
0 1 227.039 
0 0 217.578 
0 1 275.232 
0 3 250.22 
0 3 320.672 
1 3 333.973 
2 4 285.604 
1 3 365.909 
1 1 257.121 
1 0 313.222 
3 0 428.693 
3 0 372.8 
4 1 248.262 
5 0 509.636 
6 0 445.939 
3 2 281.485 
3 2 295.793 
5 1 310.061 
5 3 366.335 
2 3 253.481 
1 1 425.451 
2 4 357.44 
2 4 290.397 
2 2 305.174 
3 3 322.428 
1 4 291.575 
1 0 376.522 
1 1 342.543 
1 1 358.577 
2 1 253.317 
2 0 219.665 
4 0 323.376 
1 2 378.585 
1 3 410.031 
0 4 421.862 
0 0 241.62 
3 0 353.798 
4 1 412.224 
4 3 374.894 
1 2 335.356 
1 0 329.59 
0 0 347.569 
0 0 294.221 
1 1 299.38 
3 0 327.823 
1 2 315.386 
0 4 321.032 
1 1 342.26 
1 0 308.935 
2 0 362.637 
2 0 340.365 
1 1 394.743 
1 1 355.494 
1 1 425.318 
0 4 352.179 
0 0 407.991 
0 1 627.961 
0 1 459.76 
0 3 432.444 
0 4 376.767 
0 4 396.517 
2 0 321.625 
2 0 304.226 
1 0 407.24 
0 4 418.963 
1 4 380.054 
2 4 421.607 
3 4 378.025 
3 4 479.196 
0 3 420.502 
0 3 369.55 
0 3 437.096 
3 4 490.865 
0 4 312.166 
1 3 307.293 
4 3 420.273 
3 4 286.304 
1 4 350.616 
1 1 270.722 
1 2 328.611 
2 3 252.741 
2 2 291.362 
1 1 349.73 
2 0 260.919 
1 2 429.12 
0 4 416.874 
0 4 622.058 
0 4 638.647 
0 4 518.191 
1 2 460.316 
4 1 316.368 
5 3 307.214 
3 3 276.32 
3 3 228.747 
4 3 272.044 
4 4 448.782 
4 4 502.901 
4 4 577.19 
4 2 508.137 
4 2 481.868 
5 1 537.904 
6 2 443.319 
6 3 356.237 
5 4 348.974 
4 4 393.026 
2 4 416.407 
0 1 384.274 
0 1 330.816 
0 0 321.749 
0 0 456.327 
0 0 611.265 
0 2 681.186 
0 2 713.812 
0 2 557.163 
3 1 504.059 
2 2 416.332 
2 3 369.243 
2 3 284.471 
1 3 319.775 
1 0 272.228 
2 0 237.483 
3 0 269.906 
2 1 391.034 
1 0 393.531 
0 0 423.09 
4 1 470.469 
6 2 578.057 
6 4 674.725 
5 4 492.895 
4 4 633.482 
2 4 338.561 
1 4 190.613 
1 4 163.965 
0 4 378.446 
0 0 334.707 
2 1 214.203 
3 3 315.435 
0 3 562.39 
0 2 576.805 
2 2 482.245 
5 0 281.495 
6 1 311.225 
5 3 470.493 
4 4 219.048 
3 1 490.766 
6 0 354.955 
6 2 400.767 
6 2 423.383 
6 3 298.627 
4 1 545.762 
5 0 475.967 
5 1 510.404 
0 2 660.604 
0 3 508.198 
0 4 492.072 
0 0 478.8 
1 0 377.384 
3 1 231.822 
4 2 363.1 
6 3 371.681 
6 4 378.064 
5 4 500.207 
4 4 635.159 
3 4 519.098 
2 4 480.104 
5 4 440.598 
6 3 417.557 
6 4 180.653 
4 4 538.962 
5 2 428.543 
5 3 400.937 
5 2 290.878 
6 4 440.782 
5 2 719.992 
6 1 469.603 
6 2 475.698 
6 2 346.9 
6 4 293.771 
4 4 279.407 
0 4 276.686 
1 4 205.12 
1 1 350.076 
4 0 303.829 
6 1 496.467 
6 2 489.238 
6 4 331.618 
6 3 590.406 
6 2 402.589 
6 2 689.359 
6 3 488.855 
5 2 345.684 
5 2 420.075 
6 1 380.949 
6 2 674.584 
6 3 423.041 
6 3 268.261 
6 3 286.332 
6 3 527.897 
6 3 660.777 
6 0 608.372 
6 0 643.201 
6 0 462.119 
6 1 787.931 
6 2 696.624 
6 2 400.631 
6 2 568.987 
6 1 599.738 
6 3 430.069 
5 4 376.351 
3 3 409.707 
1 1 422.97 
3 0 552.813 
2 0 528.757 
0 0 724.266 
0 0 642.696 
2 0 251.03 
5 0 428.288 
5 0 365.059 
4 0 394.34 
4 1 665.672 
5 4 637.719 
5 4 552.647 
4 3 775.904 
4 0 562.223 
5 0 447.765 
4 2 356.115 
3 2 293.668 
2 1 347.62 
4 1 352.058 
3 2 431.868 
6 0 339.182 
5 2 401.526 
4 3 379.624 
3 4 553.596 
2 2 480.758 
3 2 337.813 
3 2 467.183 
6 0 355.257 
6 1 446.398 
5 2 407.056 
5 2 333.886 
4 3 347.798 
1 0 229.879 
1 0 454.135 
1 0 340.47 
1 0 293.999 
3 3 428.824 
3 4 323.038 
3 3 415.18 
4 2 374.22 
0 4 429.967 
1 0 499.517 
2 0 351.041 
2 1 256.628 
3 1 474.406 
5 0 455.089 
6 1 458.264 
3 2 539.062 
0 1 466.087 
0 1 336.244 
0 2 443.39 
3 1 324.365 
4 2 177.116 
5 2 358.685 
6 1 456.663 
6 2 323.314 
5 2 273.329 
5 2 191.474 
5 2 268.152 
5 1 395.35 
6 1 776.007 
6 2 951.276 
5 3 434.294 
1 3 321.612 
0 3 252.567 
0 2 567.098 
0 2 697.03 
0 2 511.324 
4 3 549.496 
5 2 535.99 
5 3 339.762 
4 2 315.815 
4 2 418.293 
6 3 591.543 
6 4 798.932 
6 4 611.216 
6 4 416.486 
5 4 645.49 
3 4 519.454 
0 4 401.086 
0 0 469.089 
2 0 224.348 
4 2 207.267 
4 1 228.516 
4 2 303.742 
3 3 408.675 
2 2 326.534 
3 1 256.33 
3 2 301.245 
4 3 394.234 
3 2 439.011 
2 2 290.322 
2 3 341.606 
2 2 275.907 
2 1 284.508 
3 1 291.784 
3 3 262.617 
3 4 234.774 
0 4 227.242 
0 3 363.913 
0 2 367.375 
0 1 356.233 
1 2 325.667 
5 4 321.604 
5 4 509.92 
5 4 748.861 
4 4 471.592 
3 4 277.844 
4 3 343.547 
4 4 674.593 
4 4 510.766 
3 4 407.629 
1 2 325.984 
0 3 265.184 
0 0 243.592 
0 1 274.235 
0 3 286.982 
3 4 459.628 
3 4 454.931 
0 3 411.199 
3 4 476.207 
1 4 605.144 
0 4 437.495 
0 0 248.597 
0 2 343.531 
4 3 470.11 
0 4 363.902 
0 4 504.6 
0 3 453.834 
0 4 364.807 
0 4 323.837 
3 4 576.268 
0 3 710.515 
0 3 669.883 
0 4 628.069 
0 3 618.214 
0 3 469.831 
0 1 347.319 
0 1 272.431 
0 1 280.418 
1 1 440.6 
1 2 435.665 
0 1 265.661 
1 1 243.934 
1 0 264.839 
3 0 348.849 
4 0 421.295 
4 1 327.438 
5 2 394.468 
6 3 344.999 
5 2 356.083 
5 3 412.107 
4 3 487.786 
1 2 627.544 
1 2 437.298 
3 3 569.294 
4 3 582.617 
4 4 515.947 
1 3 495.009 
0 3 554.514 
0 3 407.013 
3 4 588.92 
1 2 704.696 
4 0 400.807 
5 0 433.086 
4 1 381.854 
4 1 457.472 
0 2 572.643 
4 4 706.325 
0 2 631.487 
0 2 555.956 
0 2 629.793 
0 2 532.625 
0 2 468.296 
0 2 607.27 
5 4 510.882 
4 3 562.862 
3 3 561.802 
1 1 412.878 
1 1 423.667 
3 0 431.419 
3 0 371.734 
1 2 336.103 
1 2 344.285 
5 0 447.474 
5 1 653.274 
0 2 501.28 
0 0 597.571 
0 0 569.629 
0 1 496.713 
0 1 322.414 
1 1 345.804 
4 0 359.726 
5 0 400.969 
5 0 523.845 
4 1 482.59 
0 0 498.233 
0 4 574.548 
0 4 526.731 
0 4 533.198 
0 3 386.964 
0 3 283.306 
0 1 225.628 
1 2 534.334 
4 4 492.429 
0 3 367.99 
0 1 320.402 
4 0 501.401 
5 0 468.403 
4 0 260.968 
2 0 216.434 
3 0 232.052 
5 1 426.014 
4 3 556.002 
0 3 479.184 
0 3 310.42 
0 1 280.236 
0 3 339.897 
0 4 477.323 
0 0 398.324 
0 0 418.188 
0 4 423.856 
0 0 469.473 
0 2 337.415 
4 3 384.52 
5 4 449.083 
4 2 537.069 
5 0 254.122 
3 1 486.588 
1 4 489.672 
1 4 385.044 
0 3 295.993 
1 3 277.457 
1 3 340.034 
0 3 361.487 
0 0 357.933 
0 0 398.524 
0 0 380.361 
3 0 534.74 
3 0 479.72 
4 1 383.209 
1 3 565.782 
0 4 371.435 
0 4 508.505 
0 3 580.784 
0 1 498.594 
4 0 574.541 
4 0 362.242 
1 2 389.715 
4 0 384.687 
5 1 440.096 
4 2 515.948 
4 2 481.387 
3 3 443.254 
2 3 272.045 
2 3 195.03 
2 3 144.339 
1 3 202.63 
1 3 283.303 
0 0 254.608 
0 0 409.923 
1 0 516.199 
1 0 462.653 
1 0 408.361 
0 2 305.883 
4 1 333.457 
4 2 339.748 
4 3 336.761 
4 1 414.145 
3 2 297.754 
2 0 363.103 
2 0 234.007 
5 0 259.043 
5 1 246.48 
6 0 313.743 
5 1 365.302 
4 1 288.428 
1 2 244.127 
0 0 259.702 
0 0 313.619 
0 0 147.356 
1 1 260.368 
1 1 406.701 
1 0 430.434 
0 1 358.897 
0 3 392.13 
0 3 507.503 
0 4 379.559 
0 0 356.223 
0 0 454.832 
3 0 657.732 
4 0 472.091 
6 0 585.484 
6 2 590.346 
6 4 431.207 
5 4 335.045 
5 3 266.361 
3 4 447.987 
3 2 435.167 
6 0 390.471 
6 1 565.026 
6 3 361.117 
4 3 330.348 
4 2 446.399 
6 0 328.259 
6 1 413.573 
6 1 777.141 
6 1 743.591 
6 2 1089.81 
6 2 968.731 
6 3 630.263 
5 4 461.88 
2 2 360.359 
2 3 481.05 
1 0 655.497 
2 0 581.056 
5 0 463.845 
4 1 239.204 
4 3 362.872 
4 2 467.172 
4 3 437.706 
3 3 768.995 
3 1 680.538 
6 0 477.531 
6 2 276.412 
6 1 645.356 
6 1 767.949 
6 2 442.652 
5 4 539.925 
2 4 616.043 
0 1 459.02 
0 1 349.224 
0 1 370.256 
2 0 499.998 
4 0 648.647 
5 0 518.631 
5 0 372.359 
6 2 426.026 
6 4 326.327 
4 4 375.093 
2 3 450.873 
2 0 402.909 
2 2 328.294 
2 4 230.381 
1 4 228.97 
0 4 473.838 
0 4 727.378 
0 0 748.066 
0 1 512.933 
5 0 336.797 
5 1 268.26 
5 2 321.791 
5 4 403.219 
5 4 342.121 
6 3 418.992 
6 3 635.728 
6 4 445.442 
3 4 624.485 
0 3 641.925 
0 2 585.004 
0 2 659.02 
4 1 704.471 
5 0 600.078 
6 0 385.999 
5 2 285.551 
5 1 386.291 
6 0 418.351 
6 3 440.78 
5 4 359.373 
3 2 426.393 
6 3 355.779 
6 4 295.668 
5 4 417.521 
4 4 581.681 
0 3 585.592 
0 3 579.23 
0 1 610.108 
5 0 616.167 
6 1 500.674 
6 1 853.599 
6 1 899.39 
6 2 387.486 
4 2 340.333 
3 2 372.551 
4 0 319.9 
5 1 342.09 
6 0 437.674 
5 1 265.044 
6 3 413.163 
6 3 561.593 
6 2 841.433 
6 3 1083.03 
6 3 942.162 
6 3 876.83 
6 3 631.606 
6 1 538.847 
5 1 678.751 
5 3 886.08 
6 4 851.972 
5 3 753.496 
5 0 667.405 
5 0 575.579 
5 1 534.065 
5 4 424.143 
2 2 524.079 
4 0 403.379 
4 1 402.098 
2 3 290.061 
1 2 460.99 
6 0 494.536 
6 2 686.249 
6 4 376.902 
3 3 611.375 
3 0 472.035 
3 0 385.712 
6 1 405.805 
6 3 304.808 
5 4 298.389 
4 2 383.245 
4 0 330.301 
5 0 376.167 
5 0 313.283 
3 2 394.654 
2 3 443.187 
0 4 379.544 
0 1 541.612 
5 1 645.624 
5 1 378.078 
4 1 314.601 
1 2 399.309 
2 4 382.442 
0 4 462.071 
0 1 309.454 
1 2 237.455 
4 2 408.92 
4 4 431.803 
0 3 514.016 
0 4 453.531 
0 0 456.166 
1 1 378.718 
2 3 319.283 
2 1 287.625 
4 3 256.667 
4 3 213.788 
1 2 237.837 
1 2 278.608 
4 2 407.524 
6 3 428.585 
6 3 474.102 
6 1 496.085 
5 2 502.418 
4 3 438.867 
0 3 560.771 
0 3 623.074 
5 1 549.081 
6 3 449.007 
6 0 413.313 
5 0 401.633 
1 2 457.723 
3 4 440.914 
4 4 549.906 
4 3 521.401 
4 4 497.442 
4 3 649.918 
5 1 587.718 
5 1 571.41 
0 2 629.016 
0 2 437.275 
0 2 467.047 
4 2 410.026 
5 1 357.183 
5 2 557.486 
3 4 415.061 
0 1 392.98 
4 0 326.366 
5 1 470.337 
5 1 526.301 
6 0 362.384 
6 2 311.359 
6 3 294.427 
3 3 298.319 
2 2 279.005 
3 2 349.052 
2 2 322.911 
2 2 294.41 
4 3 336.128 
5 1 479.846 
4 2 246.133 
3 3 208.19 
3 4 312.754 
3 3 335.364 
3 3 398.04 
4 1 460.958 
4 1 579.498 
4 4 594.277 
3 4 333.479 
1 2 257.971 
4 4 316.866 
3 3 256.225 
1 2 276.071 
3 1 228.733 
2 0 260.531 
2 0 292.335 
1 1 396.182 
0 3 465.19 
0 3 779.593 
0 2 661.179 
0 2 522.555 
4 3 339.95 
4 4 335.049 
2 4 403.978 
0 4 314.34 
0 0 382.832 
0 1 323.973 
1 1 404.152 
4 0 439.743 
5 2 524.429 
5 4 375.311 
4 3 336.31 
1 3 344.31 
1 1 244.141 
1 1 302.715 
4 0 363.392 
4 1 495.006 
1 3 420.802 
2 0 382.557 
3 0 419.922 
1 2 412.537 
4 1 375.705 
4 1 372.293 
4 1 440.042 
4 1 469.84 
4 0 493.036 
4 1 700.624 
0 2 473.198 
0 2 432.638 
0 2 542.856 
4 0 575.154 
6 1 692.189 
5 2 552.104 
4 1 436.944 
3 0 419.234 
4 0 440.997 
4 0 398.844 
4 0 444.424 
3 0 501.808 
0 0 448.042 
0 0 449.683 
0 1 469.847 
4 1 481.104 
4 2 609.215 
0 3 506.615 
0 2 419.816 
4 2 511.025 
4 1 495.937 
1 3 310.364 
2 3 271.328 
2 3 262.829 
2 2 346.74 
2 2 425.349 
3 3 609.176 
2 4 248.173 
1 1 343.52 
0 3 443.193 
0 3 534.691 
3 4 487.016 
1 4 396.422 
0 0 336.082 
0 1 357.828 
4 1 275.769 
4 1 288.301 
3 0 329.334 
3 0 329.207 
3 0 307.044 
3 0 264.223 
3 0 234.676 
5 1 344.116 
4 3 249.403 
1 3 362.654 
0 4 411.031 
0 4 513.568 
0 4 605.674 
0 4 579.033 
0 4 532.324 
0 3 350.02 
0 2 529.646 
4 4 385.967 
4 3 334.113 
3 2 271.855 
3 2 350.971 
3 3 366.247 
1 2 368.118 
1 4 305.696 
1 4 311.236 
0 3 200.545 
4 1 398.788 
4 3 443.009 
3 3 448.784 
0 3 317.834 
0 1 496.3 
0 1 487.448 
4 0 466.864 
4 1 535.155 
4 4 707.195 
0 4 583.339 
0 4 352.618 
1 4 278.575 
1 4 251.798 
1 4 301.752 
0 4 243.95 
0 4 244.59 
0 4 279.609 
1 3 261.221 
1 2 313.538 
4 2 309.009 
4 1 321.74 
4 1 258.649 
3 0 291.918 
4 0 382.211 
0 2 533.713 
4 1 617.073 
4 2 514.12 
5 1 397.925 
5 2 249.68 
4 2 392.903 
2 4 489.549 
0 3 523.136 
0 2 512.924 
3 3 332.066 
3 4 286.97 
3 4 280.956 
2 4 374.487 
0 4 284.304 
0 0 370.657 
0 4 385.908 
0 0 394.697 
0 0 363.063 
0 0 336.11 
0 1 332.437 
0 1 347.592 
1 2 413.022 
4 3 431.639 
4 4 449.848 
4 2 423.298 
5 1 441.311 
6 0 276.263 
6 0 373.334 
6 0 424.646 
5 1 358.394 
4 1 336.233 
5 0 459.269 
5 0 875.264 
0 2 671.643 
4 1 509.209 
5 4 686.317 
2 4 551.804 
0 4 545.448 
0 0 619.867 
0 0 409.401 
0 2 447.287 
4 3 271.393 
4 2 331.203 
5 2 283.594 
5 1 286.383 
5 2 266.95 
6 1 554.912 
6 1 747.047 
6 3 347.632 
4 3 353.621 
0 3 440.703 
0 3 684.696 
0 0 823.882 
0 1 662.215 
0 2 614.561 
6 1 454.383 
6 2 291.021 
3 2 344.596 
3 2 268.305 
3 3 402.87 
6 0 678.549 
6 1 917.233 
6 1 666.413 
6 1 836.032 
6 2 696.341 
6 2 702.168 
6 1 823.461 
6 2 794.802 
5 3 544.188 
1 2 445.27 
2 0 366.376 
2 1 376.28 
3 2 393.405 
5 4 379.658 
3 4 655.697 
1 4 640.95 
1 0 616.335 
1 0 345.712 
1 0 498.597 
2 0 502.06 
1 0 414.264 
1 4 558.084 
1 4 652.702 
1 0 605.339 
2 0 350.774 
4 2 381.329 
3 4 375.144 
0 4 372.164 
1 3 443.177 
2 2 348.071 
4 1 344.549 
5 1 403.526 
6 1 385.488 
6 2 329.934 
6 4 318.311 
5 3 401.075 
5 4 353.72 
4 4 336.665 
2 4 392.358 
1 0 398.616 
1 0 445.319 
3 0 561.759 
5 1 561.796 
5 2 436.528 
5 3 397.638 
4 1 536.679 
5 2 597.109 
5 3 507.801 
5 2 547.421 
3 2 606.854 
5 3 512.982 
5 2 388.897 
5 2 474.826 
3 2 442.514 
3 3 364.155 
3 2 330.402 
3 2 330.402 
5 2 400.799 
6 2 617.019 
5 2 305.436 
5 3 474.858 
6 3 480.484 
6 4 520.211 
5 4 578.859 
3 0 335.111 
3 1 453.289 
1 3 493.776 
0 4 480.123 
0 4 639.302 
0 2 650.309 
0 2 558.383 
0 2 433.525 
4 0 466.927 
5 0 304.779 
5 2 234.299 
4 2 410.03 
4 1 333.514 
5 2 295.232 
4 3 308.491 
3 4 335.136 
3 3 319.754 
1 2 241.528 
1 0 339.046 
0 0 460.844 
0 0 525.366 
1 0 430 
0 4 434.983 
0 4 423.038 
0 3 496.286 
0 1 411.775 
1 2 537.485 
1 2 564.337 
1 2 509.882 
4 3 537.446 
3 2 528.433 
3 1 440.167 
2 1 361.204 
2 0 422.963 
3 1 530.92 
3 1 638.229 
2 3 735.867 
2 1 707.053 
2 3 584.203 
3 1 499.292 
6 0 760.416 
6 1 777.109 
6 2 517.148 
6 3 376.287 
5 4 379.72 
2 4 304.927 
2 3 214.107 
5 1 194.086 
6 3 363.062 
3 3 255.062 
1 2 247.197 
0 4 253.932 
0 4 431.032 
0 4 613.429 
0 0 472.768 
0 0 302.289 
2 0 308.742 
4 0 355.402 
5 1 299.586 
4 2 289.771 
5 3 195.191 
4 3 204.384 
3 2 309.983 
4 3 363.487 
3 4 297.431 
2 1 397.405 
3 0 292.493 
2 1 237.717 
2 0 158.886 
3 0 309.776 
3 0 329.52 
2 2 378.152 
2 0 518.958 
3 0 381.054 
3 2 244.071 
4 2 466.158 
3 2 432.671 
4 4 354.301 
4 4 329.666 
3 3 348.433 
3 3 403.153 
0 2 488.229 
5 0 624.218 
5 0 853.181 
5 0 919.812 
5 1 767.527 
4 1 436.749 
4 3 515.995 
6 3 669.297 
6 3 813.574 
6 4 719.9 
6 4 500.889 
5 4 599.337 
4 4 756.839 
0 3 636.898 
0 4 533.337 
0 4 594.557 
0 4 554.607 
0 3 580.033 
5 2 451.39 
6 3 402.232 
5 4 221.04 
4 2 342.794 
4 1 221.675 
4 1 215.308 
3 2 286.164 
3 1 357.835 
4 1 322.07 
3 3 265.631 
2 3 247.906 
2 1 330.892 
4 1 360.376 
3 3 291.576 
2 1 278.722 
5 2 353.798 
5 4 486.278 
3 4 380.749 
1 4 261.901 
1 1 230.026 
1 3 404.327 
1 4 271.509 
1 0 328.269 
3 0 227.543 
4 2 279.183 
3 1 289.975 
1 1 246.469 
1 2 299.961 
2 3 293.344 
2 2 266.772 
4 2 295.698 
2 3 333.401 
0 0 414.757 
0 0 480.327 
0 0 505.089 
0 0 256.107 
0 2 374.588 
5 1 574.46 
5 1 568.526 
5 2 617.075 
5 4 424.741 
3 2 320.344 
3 0 201.324 
4 1 451.654 
2 1 274.216 
3 0 300.247 
3 1 317.358 
3 1 276.13 
4 1 367.512 
4 3 399.299 
5 3 444.78 
5 4 316.265 
4 2 221.704 
5 4 324.164 
5 4 308.212 
1 2 323.904 
2 2 336.339 
2 2 283.755 
2 2 340.865 
2 2 365.836 
2 2 407.425 
2 2 378.558 
3 2 371.111 
4 2 362.179 
5 3 444.854 
5 3 444.401 
2 2 399.691 
2 1 363.98 
2 1 392.29 
1 1 380.487 
1 4 374.03 
0 4 480.92 
0 4 502.666 
0 0 427.404 
1 0 480.156 
1 4 469.781 
1 4 386.057 
0 4 413.387 
0 4 548.214 
0 0 539.701 
0 0 258.03 
0 0 357.368 
1 0 361.86 
1 1 343.723 
1 3 319.141 
2 4 252.003 
1 3 289.994 
1 2 265.914 
2 2 241.835 
3 3 295.841 
1 3 311.364 
0 1 367.52 
2 0 390.143 
1 0 285.071 
3 0 263.785 
4 0 322.852 
1 2 219.16 
3 0 356.309 
4 2 367.294 
5 3 277.575 
4 3 534.766 
3 4 440.577 
2 4 268.585 
1 0 315.793 
1 1 191.636 
4 0 278.843 
3 1 366.415 
1 4 341.213 
1 0 370.975 
2 2 241.57 
3 1 202.229 
2 2 392.121 
1 1 315.547 
1 2 320.737 
1 3 383.146 
1 4 332.826 
0 4 361.062 
1 4 250.953 
1 4 296.823 
3 0 213.112 
3 1 259.583 
2 2 318.122 
2 3 384.616 
2 2 335.556 
5 2 462.443 
6 4 537.943 
6 3 468.807 
5 2 563.926 
3 3 414.734 
2 1 299.353 
1 2 308.888 
0 4 271.553 
0 0 309.143 
1 2 212.178 
2 4 266.696 
0 0 373.762 
0 0 591.335 
1 0 610.811 
2 0 621.217 
2 0 638.186 
3 0 648.476 
4 0 597.869 
0 3 448.278 
0 0 500.997 
0 0 384.478 
3 0 425.68 
3 0 329.073 
3 1 275.945 
2 1 257.068 
2 0 364.011 
2 1 308.251 
3 1 356.984 
5 1 254.924 
5 1 347.034 
4 2 311.135 
4 2 326.225 
5 1 523.88 
5 2 603.8 
5 3 717.431 
5 4 884.152 
5 4 1093.95 
4 4 1055.75 
4 4 924.996 
0 3 574.461 
0 3 457.764 
0 1 537.709 
0 0 473.539 
2 0 691.778 
3 0 656.943 
3 1 342.81 
3 1 298.292 
2 0 276.501 
2 0 396.298 
1 1 319.119 
1 1 425.936 
3 0 484.078 
3 1 459.043 
5 0 292.045 
3 1 470.08 
3 1 453.143 
3 1 357.531 
2 1 321.496 
2 1 328.95 
3 2 275.983 
6 0 435.204 
6 1 327.553 
6 1 381.93 
6 3 559.101 
6 4 722.241 
5 4 502.832 
3 2 529.828 
2 1 392.772 
3 1 345.93 
3 0 436.466 
3 1 424.464 
5 2 467.486 
5 3 503.084 
2 2 502.85 
2 1 454.383 
3 2 444.384 
6 3 305.431 
5 3 459.66 
5 2 469.875 
5 3 574.97 
3 2 586.754 
3 2 454.433 
2 1 474.587 
4 1 467.46 
5 4 484.484 
3 4 594.109 
2 0 431.423 
3 0 397.322 
5 0 441.681 
4 1 290.942 
5 3 391.567 
6 4 300.553 
6 4 308.916 
6 1 354.014 
6 2 441.047 
6 3 383.794 
5 4 344.435 
2 4 338.748 
1 4 370.425 
1 3 251.943 
2 1 271.278 
5 0 339.1 
6 0 605.943 
6 1 450.876 
5 3 390.443 
3 1 282.258 
1 2 428.183 
0 2 550.105 
0 2 494.324 
3 4 450.849 
2 4 392.023 
2 4 404.341 
2 2 278.145 
3 2 230.477 
5 0 448.941 
6 1 381.919 
3 3 222.57 
1 4 424.484 
0 0 511.872 
1 0 354.035 
3 0 416.821 
6 0 311.702 
5 1 405.775 
3 3 464.245 
1 1 469.973 
3 2 385.261 
2 2 352.607 
3 2 429.985 
3 2 489.116 
3 1 485.796 
4 2 401.614 
6 2 311.272 
6 4 598.816 
6 4 637.125 
4 4 493.136 
4 3 321.77 
4 2 433.405 
3 0 327.346 
4 0 359.283 
4 2 436.699 
4 4 497.083 
0 3 619.704 
0 3 577.876 
2 4 346.922 
1 4 343.649 
2 0 350.049 
3 0 427.081 
3 1 408.485 
2 3 273.152 
3 1 240.682 
4 3 217.038 
5 2 553.245 
6 1 281.353 
5 2 262.181 
4 1 323.515 
3 1 323.372 
3 2 287.926 
5 3 372.816 
4 3 369.59 
5 4 499.529 
4 4 635.324 
4 4 524.049 
4 2 335.094 
3 4 382.046 
2 3 356.133 
2 2 203.755 
3 3 300.907 
3 4 277.221 
2 3 348.986 
2 2 322.771 
5 0 385.046 
6 1 488.55 
6 1 436.767 
6 2 432.357 
6 3 414.527 
4 2 311.988 
5 3 394.37 
4 4 316.45 
4 1 420.54 
4 1 291.992 
4 2 370.938 
4 2 355.929 
3 2 323.454 
5 1 394.683 
6 1 245.715 
6 3 298.656 
4 4 336.971 
1 4 317.667 
1 1 307.081 
3 0 280.997 
4 1 192.951 
5 1 319.338 
5 2 318.382 
5 2 247.564 
4 4 280.472 
1 4 236.169 
1 0 480.124 
1 0 396.813 
3 1 272.055 
5 3 314.18 
3 4 344.523 
3 3 275.489 
3 3 357.257 
4 2 352.83 
3 4 502.821 
0 4 445.557 
0 3 349.979 
0 2 371.408 
4 2 399.127 
3 3 365.541 
2 4 289.079 
2 4 324.523 
5 2 259.754 
6 3 351.433 
6 3 347.457 
6 2 423.788 
5 4 413.793 
1 3 347.778 
1 1 291.135 
2 0 287.053 
2 0 321.884 
2 1 288.097 
2 1 392.57 
3 1 308.634 
6 3 329.649 
5 2 359.294 
4 1 300.597 
1 2 436.142 
0 3 405.049 
0 1 421.663 
0 1 328.126 
1 2 220.716 
2 2 323.632 
5 2 250.382 
5 3 321.022 
4 2 407.387 
0 2 467.998 
0 2 259.129 
1 2 312.545 
3 2 313.46 
4 3 361.005 
3 4 449.656 
0 4 557.185 
0 4 473.16 
0 4 579.58 
0 0 308.024 
0 1 424.245 
0 2 534.826 
1 2 415.652 
1 2 256.447 
0 3 261.022 
0 0 239.905 
0 0 271.68 
0 1 340.855 
0 1 269.305 
0 1 348.382 
0 2 299.045 
1 3 296.867 
1 2 308.672 
4 1 243.785 
5 3 414.194 
6 3 561.995 
5 4 415.443 
3 3 364.903 
3 1 293.254 
4 1 294.337 
4 3 306.431 
4 3 396.28 
1 2 292.086 
1 3 213.234 
1 2 323.425 
5 1 437.437 
6 2 493.78 
4 2 416.834 
4 3 468.996 
4 3 620.51 
0 2 591.723 
4 3 631.918 
3 4 375.052 
1 1 340.008 
4 0 513.089 
0 2 719.478 
0 2 628.498 
0 2 511.011 
3 0 387.004 
1 2 420.423 
1 2 285.882 
1 2 228.12 
1 2 280.868 
1 2 328.54 
3 3 383.088 
1 3 254.789 
0 4 290.975 
0 0 290.122 
0 0 359.005 
0 1 390.301 
1 1 383.979 
1 1 380.507 
1 1 464.225 
3 0 408.906 
1 1 309.095 
0 1 266.626 
0 2 396.905 
4 1 526.643 
4 2 537.501 
4 3 422.269 
4 2 445.193 
4 1 357.403 
5 3 523.287 
3 4 401.47 
2 4 322.252 
1 4 316.083 
1 3 354.547 
4 4 393.695 
4 4 418.62 
2 4 434.665 
2 4 338.562 
1 4 318.28 
0 4 451.922 
1 4 414.37 
1 3 327.948 
2 4 361.956 
2 4 323.936 
0 2 195.975 
0 0 224.927 
0 0 334.743 
1 0 331.817 
2 0 429.273 
4 0 375.514 
4 0 317.381 
5 0 376.514 
5 0 407.563 
3 1 352.974 
3 0 446.827 
4 0 612.67 
4 0 561.277 
1 2 592.513 
3 0 579.807 
1 1 491.927 
1 1 430.317 
0 0 381.238 
1 1 363.906 
1 2 397.516 
1 3 336.023 
1 3 311.493 
1 3 325.902 
1 3 392.913 
0 2 444.805 
0 2 455.638 
4 0 361.522 
4 0 359.154 
3 0 372.941 
4 1 346.037 
4 3 369.227 
3 3 403.188 
3 1 372.404 
2 2 395.612 
1 4 626.409 
1 4 661.025 
0 4 622.055 
0 0 484.169 
1 0 518.374 
1 0 473.85 
0 0 370.387 
0 0 226.894 
1 0 235.627 
1 0 357.249 
1 0 601.369 
1 4 398.143 
0 4 251.86 
0 4 172.796 
1 4 275.748 
1 4 524.627 
1 0 670.917 
1 0 471.782 
3 0 305.503 
3 2 301.52 
4 3 380.173 
3 4 524.632 
0 3 524.398 
5 2 529.336 
6 2 714.172 
6 2 436.933 
3 2 396.741 
5 3 298.697 
4 3 263.42 
1 4 281.164 
0 0 632.316 
0 0 782.354 
0 0 678.501 
1 0 493.869 
1 1 346.807 
4 1 331.118 
5 0 338.054 
6 1 218.365 
5 3 298.979 
4 4 316.509 
1 3 357.415 
1 3 218.89 
1 3 347.268 
3 4 357.731 
3 4 628.071 
3 3 400.149 
4 2 240.736 
2 3 159.119 
1 2 231.127 
3 4 438.615 
0 1 561.068 
0 1 508.494 
0 1 440.242 
0 2 444.701 
4 1 420.697 
6 0 423.551 
6 1 351.378 
6 3 295.01 
3 3 528.029 
5 3 546.417 
6 3 351.247 
4 3 435.878 
3 1 525.302 
1 2 393.625 
0 2 346.294 
0 2 394.408 
2 4 416.194 
1 0 459.874 
2 0 323.296 
1 2 257.386 
1 2 272.676 
1 3 359.751 
1 3 401.973 
2 3 357.498 
3 2 534.072 
5 1 316.517 
5 2 400.585 
5 2 489.273 
5 3 489.691 
6 3 367.33 
6 4 313.731 
6 4 424.194 
6 2 826.649 
6 2 603.607 
5 1 385.061 
4 0 426.959 
5 0 465.554 
5 0 504.633 
6 0 441.821 
6 1 297.143 
4 2 189.979 
2 2 309.32 
2 1 399.379 
3 0 624.458 
6 0 374.354 
6 0 533.36 
6 2 414.434 
5 2 470.607 
3 1 429.272 
2 1 451.132 
1 0 638.072 
3 0 509.373 
3 0 365.813 
3 0 428.737 
3 1 410.742 
5 3 337.295 
3 4 471.169 
5 0 470.308 
6 1 362.745 
6 1 401.416 
6 2 458.841 
6 2 660.122 
6 3 333.233 
4 4 356.402 
1 4 404.582 
2 0 369.428 
5 0 651.221 
6 0 500.973 
5 0 381.879 
3 0 336.453 
3 0 344.891 
2 1 320.268 
1 1 318.774 
0 1 416.348 
0 1 359.678 
0 2 381.051 
4 0 518.667 
6 0 763.703 
6 0 644.741 
6 2 506.215 
6 3 373.414 
5 4 312.514 
3 1 516.197 
6 0 337.161 
5 2 318.566 
6 4 393.29 
5 4 456.548 
3 4 335.285 
4 0 379.785 
6 0 460.021 
6 1 489.642 
3 2 686.25 
2 3 783.03 
2 3 687.551 
3 0 539.982 
5 0 581.204 
5 0 469.529 
5 0 270.294 
6 1 591.607 
5 3 426.376 
3 4 305.792 
0 4 359.645 
0 0 342.454 
0 1 454.34 
0 1 441.396 
0 2 537.052 
4 0 522.954 
4 3 327.44 
3 4 208.072 
1 3 302.483 
3 0 328.762 
3 1 425.321 
3 1 354.065 
3 0 403.981 
5 0 336.17 
6 0 602.099 
5 1 753.605 
5 2 703.572 
6 4 675.464 
5 4 873.805 
5 4 491.892 
5 2 448.842 
5 1 330.584 
6 1 300.273 
6 4 388.377 
4 4 365.676 
3 3 364.095 
5 1 273.511 
5 3 244.131 
5 3 360.116 
5 2 345.682 
6 1 461.854 
6 2 792.653 
6 3 711.971 
4 2 594.902 
1 3 353.74 
0 4 308.575 
0 3 259.234 
0 3 368.27 
0 1 407.922 
0 1 408.616 
0 1 451.036 
2 1 327.722 
2 4 508.401 
1 4 516.768 
2 0 359.433 
3 0 343.075 
3 1 393.315 
4 2 343.275 
3 4 173.131 
2 1 284.993 
3 1 297.473 
5 3 353.74 
3 4 292.178 
1 3 259.077 
2 4 299.715 
0 4 349.508 
0 3 332.19 
4 1 337.179 
4 2 246.544 
4 4 255.926 
3 4 368 
0 3 284.435 
0 2 288.765 
4 2 437.957 
4 3 358.438 
3 3 278.194 
1 0 320.844 
1 0 338.991 
2 2 320.856 
2 3 330.812 
3 2 456.759 
5 3 292.629 
5 4 249.497 
3 3 354.955 
5 1 351.078 
5 2 225.632 
5 1 345.148 
2 2 287.465 
2 1 569.255 
1 0 539.656 
1 4 438.189 
1 3 250.359 
3 4 233.208 
2 2 336.617 
5 1 267.596 
6 1 271.592 
5 2 381.559 
4 1 360.874 
4 1 395.372 
5 2 413.931 
5 2 448.972 
4 1 503.962 
5 0 479.819 
5 0 391.62 
5 1 301.12 
4 2 363.753 
2 4 224.275 
0 4 286.568 
1 0 213.523 
1 1 168.959 
2 1 262.885 
2 2 245.575 
5 3 409.766 
6 4 431.847 
3 4 317.649 
1 3 397.454 
1 4 274.474 
0 1 208.185 
0 3 307.56 
0 4 262.028 
0 0 402.097 
0 3 390.11 
1 3 499.18 
1 3 482.206 
0 2 458.81 
4 1 530.656 
5 2 646.453 
4 4 618.363 
0 3 487.304 
0 4 423.713 
1 3 412.578 
4 3 389.365 
3 3 320.68 
2 3 354.261 
2 4 317.83 
0 4 291.285 
1 1 289.163 
5 1 377.147 
5 3 470.874 
0 2 573.168 
0 3 436.813 
0 1 464.955 
0 1 562.641 
4 0 499.716 
4 0 499.128 
5 0 662.798 
0 2 701.278 
5 1 698.802 
4 1 695.514 
0 2 557.758 
4 4 670.742 
0 3 598.761 
0 3 564.299 
0 3 542.416 
0 4 571.912 
0 4 633.472 
0 4 537.111 
0 4 366.356 
0 4 456.447 
1 3 367.051 
1 3 428.809 
1 3 380.412 
1 3 290.472 
2 2 261.829 
4 3 268.938 
4 3 409.295 
0 2 601.183 
4 1 570.559 
5 2 370.068 
5 2 266.85 
4 2 248.93 
2 3 305.346 
1 1 286.654 
2 0 392.544 
2 1 488.077 
2 1 413.175 
1 1 450.733 
1 3 370.044 
1 2 378.301 
0 1 350.436 
3 0 469.773 
4 1 508.41 
1 2 450.925 
4 1 491.814 
5 3 631.957 
3 4 473.113 
0 4 470.229 
0 0 553.003 
0 1 564.811 
1 1 479.036 
3 0 481.762 
4 1 511.935 
0 2 553.794 
0 1 445.723 
0 0 402.114 
1 1 430.914 
1 2 370.192 
3 0 463.312 
3 0 449.007 
0 3 415.512 
0 3 367.496 
0 1 350.581 
0 0 295.209 
0 0 278.369 
0 3 360.777 
1 3 346.573 
1 3 339.455 
1 1 320.273 
4 2 317.271 
4 1 354.554 
3 1 322.146 
4 1 320.029 
5 1 478.579 
4 1 481.34 
4 1 424.915 
4 1 439.096 
1 2 368.552 
1 3 476.957 
1 4 406.999 
0 0 312.29 
1 0 317.368 
2 0 369.925 
1 1 363.609 
1 3 411.35 
1 4 400.563 
0 3 474.672 
0 4 430.662 
0 4 275.876 
2 4 404.936 
3 4 403.279 
0 3 432.612 
0 1 431.522 
1 2 454.335 
0 4 426.781 
0 0 559.89 
0 1 306.064 
0 1 274.406 
1 1 345.036 
1 3 264.554 
1 3 268.683 
0 1 220.686 
1 2 228.677 
1 2 245.569 
1 2 253.324 
1 3 230.982 
0 3 223.334 
0 3 200.793 
0 4 291.472 
0 0 429.032 
0 0 375.779 
3 0 535.847 
4 0 310.571 
5 1 330.185 
5 2 235.366 
5 3 305.763 
5 4 393.173 
3 4 415.55 
2 4 410.954 
0 0 267.272 
1 0 418.226 
0 2 541.472 
0 2 552.525 
1 2 373.643 
1 2 340.303 
4 1 430.388 
1 2 257.604 
1 1 240.173 
1 2 276.359 
1 3 276.53 
1 4 371.521 
0 4 479.485 
0 4 686.023 
0 0 605.832 
0 4 386.704 
0 4 327.89 
0 1 233.335 
2 2 305.677 
2 3 236.78 
2 0 313.392 
4 0 255.444 
4 1 281.891 
5 3 314 
4 4 281.27 
4 4 523.296 
4 1 639.414 
4 0 538.043 
5 0 578.738 
6 2 647.968 
6 3 587.7 
6 4 397.873 
5 4 356.4 
4 3 398.975 
1 2 317.391 
1 2 311.872 
0 0 361.467 
1 0 539.013 
1 0 405.153 
1 0 411.591 
1 2 461.836 
3 0 547.585 
6 0 552.504 
6 1 362.384 
4 2 357.716 
3 1 509.154 
4 1 304.446 
4 1 281.854 
5 2 339.091 
5 3 422.133 
3 4 549.009 
2 2 398.697 
4 0 316.86 
6 0 351.126 
6 2 407.531 
6 2 290.302 
5 3 351.643 
5 3 494.459 
3 2 479.066 
2 0 284.773 
2 1 269.184 
1 0 315.278 
3 0 578.621 
3 0 588.645 
2 1 480.983 
2 0 406.623 
0 1 550.427 
1 4 503.967 
0 4 584.098 
0 0 476.691 
2 0 550.764 
3 0 532.67 
5 0 475.69 
3 1 438.942 
6 0 441.439 
6 0 366.486 
6 1 842.079 
6 2 825.357 
6 3 419.209 
6 2 372.18 
6 2 676.467 
6 3 1100.35 
6 4 780.559 
6 4 605.176 
3 4 460.415 
0 4 343.634 
1 2 287.092 
3 3 303.936 
2 3 409.673 
2 2 351.054 
3 2 309.574 
4 3 325.398 
4 3 309.209 
4 3 491.104 
6 0 591.358 
6 0 679.207 
6 2 404.019 
6 4 384.286 
5 4 535.687 
3 4 575.614 
3 3 397.586 
2 2 280.329 
2 2 251.415 
1 1 326.852 
3 2 418.095 
3 3 414.819 
2 4 461.297 
2 4 482.481 
2 1 456.814 
3 2 386.434 
3 3 237.11 
3 4 322.574 
2 3 418.429 
1 1 309.431 
3 0 361.229 
3 0 286.388 
2 0 245.887 
2 0 268.433 
2 0 260.85 
2 1 247.387 
2 1 325.388 
3 2 451.162 
5 3 358.37 
6 3 267.441 
6 3 741.582 
6 3 787.77 
6 2 708.548 
6 2 764.038 
6 3 428.492 
6 3 415.265 
6 4 525.453 
6 4 550.592 
6 3 635.829 
6 2 423.836 
6 3 346.329 
6 3 526.956 
6 1 437.23 
6 3 668.456 
4 4 517.86 
2 3 421.902 
5 2 265.227 
5 3 366.271 
2 4 360.239 
0 4 430.38 
1 4 349.358 
1 3 323.03 
2 0 430.079 
4 0 397.239 
5 0 257.871 
6 2 333.374 
5 3 359.548 
6 3 537.57 
6 3 494.863 
4 3 452.809 
2 2 406.123 
1 2 320.779 
1 1 389.104 
4 0 314.426 
5 1 246.201 
5 2 198.159 
5 2 245.093 
3 2 326.073 
5 0 266.059 
6 2 257.005 
5 4 332.224 
1 4 379.53 
2 0 388.558 
2 1 317.138 
2 3 487.033 
1 1 528.844 
2 0 339.938 
2 1 333.142 
2 2 281.318 
2 3 208.279 
1 3 201.088 
0 4 296.972 
0 0 235.696 
0 2 427.042 
4 4 601.273 
0 2 473.026 
1 3 398.777 
1 3 425.175 
1 1 297.518 
0 3 497.242 
0 4 694.898 
0 4 919.852 
0 4 934.671 
0 2 758.077 
0 2 688.986 
0 2 534.335 
1 2 334.494 
1 2 320.011 
0 2 381.578 
0 2 349.227 
1 2 460.863 
4 1 463.896 
4 1 409.351 
4 1 479.571 
0 2 516.265 
0 2 508.36 
0 1 511.471 
0 1 701.058 
0 2 733.864 
4 0 803.467 
4 0 764.462 
4 1 569.056 
1 2 466.005 
2 2 305.442 
5 0 235.943 
5 2 230.61 
4 2 180.197 
3 3 258.752 
3 3 319.964 
4 3 312.921 
4 3 307.48 
3 3 237.419 
3 2 287.051 
3 2 340.242 
5 3 306.389 
5 3 369.424 
4 3 312.409 
3 2 219.98 
4 3 365.25 
3 3 324.672 
3 3 292.243 
4 4 286.459 
5 4 340.463 
5 4 589.908 
5 4 464.807 
5 4 367.921 
3 3 314.22 
4 2 359.293 
5 2 404.493 
6 3 529.57 
6 4 542.247 
5 4 333.896 
3 4 267.264 
2 4 210.126 
1 2 414.007 
5 3 437.344 
5 4 411.13 
4 3 442.037 
5 1 302.996 
5 2 344.804 
6 3 364.621 
6 3 346.831 
5 3 349.786 
4 4 598.725 
0 4 459.715 
0 4 341.091 
0 3 321.89 
0 1 386.809 
1 1 441.818 
0 1 351.888 
0 1 392.529 
4 0 457.7 
6 1 472.623 
5 1 358.517 
5 0 473.882 
4 0 508.459 
0 2 525.675 
0 1 574.926 
1 2 490.975 
1 2 297.067 
4 0 317.928 
4 1 371.777 
4 2 455.601 
3 3 343.977 
2 2 388.256 
4 0 391.686 
1 2 366.876 
0 0 383.861 
0 0 297.48 
0 0 336.251 
0 2 361.727 
4 1 423.796 
4 2 443.094 
5 4 430.54 
6 3 544.167 
6 2 715.459 
5 3 636.346 
1 2 333.16 
0 1 327.08 
1 3 336.739 
0 3 371.498 
2 4 551.506 
0 4 453.089 
0 4 469.061 
0 0 386.162 
2 0 539.254 
0 2 510.197 
0 2 327.022 
0 0 346.498 
0 1 346.248 
1 2 290.407 
1 2 314.603 
0 2 422.947 
0 3 350.029 
0 0 254.041 
1 1 308.501 
0 2 350.846 
1 3 327.414 
0 4 348.33 
0 0 341.151 
0 0 380.82 
0 1 321.886 
0 1 297.411 
1 1 249.427 
2 2 285.557 
3 2 267.77 
2 2 224.003 
3 2 314.441 
3 2 339.589 
4 2 454.706 
4 2 358.697 
4 2 339.025 
4 1 465.671 
4 3 460.78 
2 4 354.152 
1 0 539.014 
1 0 548.673 
1 0 389.425 
1 3 356.449 
0 3 428.578 
0 3 288.411 
1 4 433.16 
2 4 350.893 
1 2 358.507 
1 1 393.3 
2 0 416.059 
0 1 392.463 
4 0 392.688 
2 1 296.058 
2 0 257.945 
2 0 241.038 
4 0 293.214 
4 1 435.374 
1 1 314.697 
1 1 287.343 
4 3 363.652 
1 4 393.64 
0 4 598.931 
0 0 441.057 
0 1 489.736 
0 1 504.869 
0 1 423.387 
0 1 458.986 
0 0 478.604 
0 0 426.526 
0 4 438.782 
0 4 393.61 
1 3 286.22 
1 3 238.037 
1 4 233.431 
1 1 308.179 
1 0 199.067 
0 0 289.075 
1 0 441.801 
4 1 413.129 
5 1 414.041 
4 1 617.837 
4 3 599.711 
3 3 548.615 
4 1 647.379 
0 2 553.255 
0 2 441.53 
0 3 344.863 
0 0 396.776 
0 0 504.323 
4 0 635.637 
5 0 696.411 
5 2 718.767 
6 4 611.745 
6 4 612.8 
6 2 407.342 
6 2 340.007 
3 2 279.468 
2 0 433.84 
1 0 548.999 
2 0 459.757 
2 1 297.001 
2 1 276.013 
3 1 279.308 
3 1 369.37 
5 0 551.735 
6 0 412.991 
6 2 294.199 
6 3 162.306 
6 4 314.029 
5 4 470.807 
6 0 543.021 
6 1 765.517 
6 3 705.621 
3 3 553.747 
2 1 585.442 
3 1 390.427 
5 1 275.45 
6 1 291.633 
6 2 257.951 
6 2 250.372 
6 1 413.88 
5 2 443.86 
3 1 731.291 
4 0 567.639 
4 0 512.32 
3 1 461.551 
3 1 307.259 
2 2 376.233 
3 2 292.068 
3 2 343.25 
3 1 484 
5 2 436.267 
3 2 488.67 
4 3 518.459 
5 3 723.34 
4 2 549.965 
1 2 460.42 
1 0 339.371 
1 2 300.637 
0 4 288.384 
0 4 405.477 
0 0 378.209 
0 0 415.759 
1 0 439.908 
3 0 484.802 
4 0 484.289 
5 0 339.369 
5 2 298.614 
5 1 420.057 
6 0 451.831 
6 0 370.683 
5 1 683.923 
5 4 534.929 
1 4 458.995 
0 0 705.468 
4 0 580.956 
6 1 299.386 
6 2 301.601 
3 2 422.398 
1 2 296.78 
2 4 398.947 
2 4 516.385 
1 2 443.148 
4 1 516.999 
6 0 593.249 
6 2 756.96 
6 4 954.767 
5 4 793.5 
1 2 544.666 
4 3 590.636 
0 4 669.442 
1 4 573.309 
0 4 469.044 
3 0 542.684 
4 0 463.55 
1 1 375.546 
0 0 570.919 
1 0 570.026 
2 0 724.078 
2 0 777.596 
2 1 519.686 
1 3 440.26 
0 4 333.713 
0 0 426.446 
1 0 553.851 
1 0 342.271 
2 1 234.896 
4 1 376.957 
4 3 570.71 
0 3 537.949 
0 2 576.069 
5 2 539.795 
6 3 280.2 
6 3 340.412 
6 3 579.692 
6 3 754.8 
6 3 494.252 
6 1 482.258 
6 2 523.474 
6 2 709.42 
6 3 570.236 
6 2 506.861 
6 2 391.37 
6 2 399.475 
6 2 401.71 
5 2 472.564 
6 0 398.426 
5 2 710.745 
4 2 566.456 
4 2 427.154 
6 3 340.055 
6 3 409.056 
6 2 478.952 
6 2 567.901 
6 2 593.164 
4 3 626.109 
3 3 573.087 
6 0 406.435 
6 1 666.256 
6 2 740.27 
6 4 497.735 
3 4 521.24 
0 4 660.811 
0 4 611.543 
0 0 491.336 
0 1 410.049 
0 3 430.13 
0 2 404.226 
1 2 368.423 
2 2 426.707 
3 3 363.028 
4 3 344.968 
4 2 370.466 
4 2 363.154 
4 2 469.65 
5 3 366.439 
3 3 317.837 
3 1 298.12 
2 1 293.945 
3 0 533.911 
3 2 481.182 
2 3 412.68 
2 1 389.887 
3 0 413.677 
5 1 304.417 
5 2 293.245 
3 2 321.434 
2 1 320.731 
2 0 356.731 
2 1 339.528 
2 1 287.018 
2 3 442.671 
2 4 307.308 
2 3 339.027 
3 3 432.296 
1 3 538.393 
1 2 415.861 
6 4 276.42 
4 4 314.555 
0 4 360.583 
0 3 310.988 
4 0 409.104 
4 0 392.125 
0 2 424.111 
0 3 484.634 
3 4 643.856 
0 3 598.863 
0 2 425.641 
0 2 490.609 
4 0 472.981 
4 0 276.258 
3 0 240.593 
1 1 308.963 
4 1 286.629 
5 2 310.825 
5 2 372.842 
5 2 405.465 
4 3 451.898 
2 4 279.193 
0 0 458.828 
0 0 499.346 
0 0 603.418 
0 4 400.792 
0 3 302.537 
3 4 326.018 
2 4 361.376 
0 4 266.341 
1 1 255.157 
0 2 366.862 
0 3 380.669 
0 2 373.809 
1 2 362.774 
3 3 281.353 
2 2 271.176 
2 3 237.265 
1 2 232.718 
4 3 355.483 
3 4 293.533 
1 3 246.426 
4 2 297.872 
5 3 347.196 
4 2 410.989 
4 3 491.102 
4 4 399.555 
0 2 310.882 
4 1 424.621 
3 2 264.495 
4 3 408.15 
5 1 538.512 
5 0 377.815 
4 1 283.89 
4 4 160.637 
3 4 388.622 
1 2 288.162 
1 2 282.529 
3 0 264.318 
4 2 294.585 
2 2 243.368 
1 2 218.768 
3 3 360.513 
4 4 327.097 
5 4 339.03 
4 4 221.371 
4 1 271.652 
5 0 345.977 
5 1 456.919 
5 3 268.71 
2 3 198.863 
2 3 408.628 
2 2 286.284 
3 1 270.601 
3 1 214.971 
4 2 345.087 
2 3 227.443 
2 0 316.44 
3 0 449.909 
4 0 410.881 
5 0 468.627 
4 2 555.448 
1 2 299.601 
3 0 186.387 
4 0 318.41 
5 0 476.594 
5 2 475.478 
4 3 377.578 
4 1 560.944 
4 0 391.763 
4 0 585.699 
0 2 620.724 
0 2 519.316 
4 2 385.887 
4 0 349.075 
3 2 308.901 
3 1 298.68 
3 3 403.323 
2 4 352.214 
0 4 290.235 
0 0 334.464 
0 1 303.268 
0 1 259.36 
0 1 309.643 
0 3 316.738 
0 4 239.378 
0 4 317.446 
0 0 398.651 
1 3 415.939 
3 4 406.242 
5 3 324.097 
4 3 370.893 
0 4 205.186 
0 0 282.622 
0 0 313.575 
0 1 520.642 
0 2 537.344 
4 3 240.744 
5 1 290.008 
5 1 314.513 
4 2 547.597 
2 4 407.201 
2 4 452.06 
1 4 406.62 
0 0 548.037 
0 0 519.432 
0 0 304.415 
0 0 236.644 
0 0 452.253 
1 4 425.761 
2 4 504.675 
2 4 397.72 
1 3 406.596 
2 0 278.324 
2 0 295.762 
2 0 373.923 
1 3 423.521 
1 3 350.773 
1 1 338.827 
1 1 336.152 
1 4 298.19 
0 0 433.177 
0 0 304.373 
1 0 317.936 
1 1 366.496 
1 1 402.23 
4 0 308.601 
4 1 345.198 
1 1 227.596 
1 1 314.192 
2 1 384.886 
3 1 334.88 
3 2 342.588 
3 3 360.367 
3 2 512.701 
5 4 568.297 
2 4 468.276 
2 0 535.797 
2 0 320.162 
3 0 242.431 
4 2 529.231 
4 3 421.186 
3 3 341.705 
2 3 228.385 
2 4 286.1 
3 0 406.15 
3 0 673.703 
3 0 847.702 
3 0 628.154 
0 2 569.235 
0 2 438.335 
3 3 555.56 
5 1 549.278 
6 1 419.051 
4 1 468.828 
3 0 477.861 
1 2 341.743 
1 3 288.182 
0 3 275.781 
0 3 455.483 
0 0 442.731 
0 3 421.935 
0 3 376.295 
0 2 348.288 
1 2 318.187 
3 0 363.54 
0 2 386.332 
0 1 401.235 
0 1 502.069 
4 0 420.051 
4 0 432.529 
5 0 568.751 
5 0 382.721 
4 1 319.218 
1 2 225.215 
3 0 313.748 
4 1 302.961 
3 2 219.221 
3 0 210.272 
4 1 428.42 
0 2 680.972 
4 4 728.2 
4 4 487.152 
3 4 351.133 
2 3 307.742 
3 2 205.567 
3 2 203.991 
4 3 283.38 
3 4 314.812 
2 1 545.692 
5 1 374.801 
3 2 482.897 
2 3 432.521 
2 0 402.585 
3 0 412.674 
4 0 558.858 
5 0 461.604 
6 2 691.3 
6 2 951.791 
6 3 607.816 
5 3 233.283 
5 1 449.058 
6 1 447.716 
6 1 452.726 
4 2 386.139 
5 2 401.764 
5 4 387.471 
4 3 301.395 
3 4 321.436 
3 4 544.855 
5 0 455.372 
5 1 289.668 
5 1 232.278 
4 1 435.12 
5 2 365.611 
5 1 345.111 
4 0 567.088 
0 1 737.519 
0 1 563.976 
3 1 434.013 
3 1 391.445 
4 2 502.187 
6 1 588.67 
6 3 387.843 
4 4 442.621 
1 4 471.731 
1 0 436.069 
1 3 404 
0 3 459.831 
2 3 526.12 
3 2 493.584 
6 2 367.766 
6 3 327.871 
6 3 344.839 
4 3 461.363 
2 4 447.573 
1 1 471.243 
2 1 371.116 
2 1 327.916 
2 1 260.904 
4 1 259.461 
5 0 317.815 
5 1 288.689 
5 1 284.465 
5 3 592.759 
5 4 727.658 
5 4 514.38 
5 4 305.802 
5 0 389.159 
6 1 361.788 
5 2 438.681 
4 4 633.023 
0 4 546.396 
0 4 475.298 
0 0 546.192 
0 0 548.396 
0 1 609.711 
6 0 535.829 
6 1 428.499 
6 2 630.107 
6 3 663.935 
6 1 633.256 
6 1 970.968 
6 2 747.066 
6 2 719.308 
6 4 287.99 
3 2 356.712 
6 0 593.81 
6 2 611.896 
4 4 426.608 
0 3 336.383 
1 0 417.587 
2 1 372.507 
2 3 422.566 
1 0 483.79 
2 0 444.76 
2 0 396.745 
5 0 654.036 
6 1 650.173 
5 3 544.15 
3 4 501.976 
0 4 581.23 
0 0 683.875 
0 0 511.483 
0 0 343.445 
0 0 274.041 
1 0 432.387 
2 0 437.252 
2 1 359.848 
3 1 290.935 
4 2 381.608 
3 2 393.656 
4 0 329.66 
5 0 313.674 
6 0 548.609 
6 0 649.849 
6 0 427.955 
6 1 399.848 
3 2 463.468 
3 2 437.339 
4 3 290.968 
4 4 272.48 
2 4 310.327 
1 3 285.137 
3 0 355.591 
6 0 408.411 
5 2 760.617 
4 4 735.823 
0 2 697.525 
2 4 507.987 
1 4 608.274 
2 0 483.286 
2 0 387.381 
2 0 616.131 
1 0 534.757 
2 0 322.913 
2 1 374.946 
2 3 407.804 
2 4 438.907 
3 4 495.675 
5 4 560.212 
5 4 637.56 
4 4 515.179 
2 2 478.507 
4 0 346.091 
4 1 302.04 
3 2 297.356 
5 0 338.062 
6 2 534.248 
6 2 449.437 
6 3 379.483 
5 3 616.788 
5 1 304.641 
5 3 260.868 
4 4 235.169 
3 4 537.376 
1 3 591.861 
3 0 414.959 
3 0 483.08 
2 0 456.85 
3 0 497.409 
3 0 270.149 
3 0 412.403 
6 0 616.037 
6 0 471.787 
6 1 420.854 
5 3 266.38 
3 2 457.49 
3 1 443.525 
5 0 583.098 
5 1 450.451 
5 4 258.953 
5 4 382.717 
4 3 257.042 
5 3 238.227 
6 2 244.202 
6 4 321.035 
3 3 258.089 
2 2 256.826 
3 2 335.679 
5 1 241.442 
6 2 506.677 
6 4 573.224 
4 4 444.681 
2 4 252.972 
2 2 360.317 
5 3 367.067 
5 4 204.633 
3 4 218.667 
2 3 332.745 
3 1 219.169 
3 2 329.961 
4 3 225.545 
5 1 370.375 
5 2 318.402 
3 2 292.85 
3 1 394.669 
6 0 399.911 
5 1 465.19 
3 1 432.043 
3 1 437.031 
1 2 435.223 
0 4 448.639 
0 4 440.73 
1 4 345.835 
2 1 294.013 
4 2 414.814 
3 4 291.916 
2 4 431.563 
2 2 276.752 
2 2 218.597 
1 0 269.63 
0 0 406.805 
1 4 336.207 
0 4 356.436 
1 0 350.046 
1 2 297.944 
1 4 285.058 
0 4 282.109 
0 0 302.307 
1 0 379.907 
2 0 356.036 
3 1 328.587 
4 2 324.839 
6 0 300.578 
5 2 320.518 
3 3 277.318 
1 4 290.198 
1 4 170.189 
1 4 303.38 
1 3 321.574 
1 3 244.385 
3 4 238.394 
3 4 288.274 
3 4 319.511 
4 4 260.651 
4 3 385.443 
3 1 231.856 
2 1 311.537 
2 2 440.78 
2 1 357.574 
3 1 322.081 
2 3 338.611 
2 4 279.794 
2 2 266.523 
3 2 247.784 
2 2 311.807 
1 2 428.793 
3 4 261.753 
1 3 293.841 
1 1 282.133 
1 1 338.984 
4 2 404.21 
5 3 331.185 
6 2 356.243 
5 2 299.838 
5 1 385.941 
5 0 432.321 
5 0 411.129 
5 2 377.982 
4 3 284.448 
3 3 389.114 
1 3 206.039 
1 2 315.573 
4 2 360.875 
4 3 300.765 
2 3 266.776 
2 3 288.725 
3 1 349.611 
5 3 439.064 
4 2 422.046 
3 2 316.12 
3 1 186.284 
2 0 252.977 
2 0 237.873 
2 0 256.116 
2 0 188.142 
1 1 317.17 
1 2 393.673 
1 4 393.845 
0 1 425.55 
0 0 322.215 
0 1 351.42 
1 2 351.602 
5 0 490.324 
6 0 554.534 
6 0 396.732 
3 0 468.926 
3 0 552.255 
4 0 452.113 
5 1 440.592 
5 1 326.17 
1 2 261.548 
1 2 309.958 
3 3 336.255 
2 3 413.074 
1 1 365.389 
2 0 238.488 
2 1 359.98 
2 2 269.2 
2 1 233.415 
1 1 269.635 
1 3 263.824 
0 2 286.809 
4 0 496.032 
1 2 453.426 
1 1 478.129 
1 2 350.633 
1 1 273.197 
1 0 348.842 
2 0 490.618 
4 0 429.151 
5 2 503.437 
6 4 407.617 
5 4 273.837 
3 1 211.351 
1 3 440.776 
0 4 511.499 
0 0 574.332 
0 1 371.63 
0 2 626.151 
0 3 690.759 
0 3 648.745 
0 2 459.79 
0 2 342.36 
2 2 233.393 
1 0 285.066 
3 0 204.87 
2 1 368.51 
0 0 306.962 
1 0 244.703 
2 0 244.901 
2 1 324.746 
1 4 376.804 
1 0 368.9 
2 0 378.771 
3 0 386.249 
4 1 384.225 
5 3 339.098 
4 3 445.772 
6 0 340.548 
2 0 455.157 
0 0 494.773 
0 0 407.898 
0 0 339.132 
0 0 416.393 
0 0 446.289 
0 0 314.939 
1 0 361.092 
3 0 358.708 
4 0 358.878 
4 0 373.215 
4 0 376.138 
4 1 265.141 
3 1 295.986 
2 2 323.05 
2 4 276.256 
1 3 375.064 
1 1 228.095 
1 2 384.289 
1 2 446.123 
3 3 386.595 
3 2 225.451 
4 3 275.25 
5 4 314.187 
3 2 440.206 
2 1 242.207 
3 0 231.347 
4 2 321.213 
0 3 320.023 
0 1 491.296 
4 0 435.058 
2 3 230.054 
0 0 505.383 
1 0 519.817 
2 0 376.941 
1 3 411.06 
1 1 342.189 
1 0 295.682 
1 0 296.298 
1 0 370.041 
1 0 390.328 
0 1 360.477 
4 0 593.172 
4 0 730.671 
0 2 768.685 
4 4 598.064 
5 4 420.975 
3 3 338.233 
2 3 324.489 
2 1 354.689 
3 1 243.459 
5 2 319.315 
5 4 372.599 
3 4 503.781 
0 3 357.831 
0 2 449.649 
4 1 517.897 
5 4 408.927 
3 4 568.306 
3 4 526.066 
3 2 344.495 
5 1 363.51 
5 2 366.577 
5 3 466.983 
3 3 462.22 
4 1 302.127 
3 3 307.196 
2 4 249.512 
1 4 369.361 
2 0 285.735 
3 0 392.561 
3 1 468.689 
2 2 436.226 
1 4 266.616 
0 4 363.642 
0 4 429.175 
0 4 562.194 
0 0 562.488 
1 0 387.18 
2 1 287.034 
4 3 284.743 
5 4 275.069 
4 4 577.285 
3 4 735.56 
2 4 509.419 
1 0 422.195 
2 0 297.717 
3 1 246.515 
5 0 312.037 
5 1 451.066 
3 3 486.121 
2 4 427.671 
2 4 543.86 
2 4 429.668 
2 2 386.644 
3 1 344.006 
5 1 438.748 
5 2 431.017 
6 4 424.723 
3 4 382.127 
2 4 388.442 
2 4 337.72 
2 2 311.911 
4 2 362.199 
5 2 421.556 
5 2 535.644 
6 2 650.109 
6 3 500.422 
5 0 839.86 
6 0 603.857 
5 0 635.25 
3 0 474.036 
1 1 399.064 
2 2 354.527 
5 4 230.24 
3 4 237.482 
2 0 418.506 
6 0 766.466 
6 0 632.74 
5 0 551.402 
5 2 628.2 
5 2 690.21 
5 1 800.29 
5 3 518.312 
4 2 368.992 
4 2 362.456 
5 3 205.942 
6 2 359.358 
6 1 804.398 
6 3 867.813 
5 4 502.535 
3 3 464.216 
5 0 471.905 
6 0 338.713 
6 2 411.655 
6 3 574.99 
6 4 442.374 
6 4 710.521 
6 3 620.884 
5 3 523.97 
3 2 522.579 
6 0 358.215 
6 1 607.686 
6 1 382.997 
5 2 353.537 
4 2 383.105 
3 3 300.781 
2 2 367.718 
4 1 340.327 
5 2 366.798 
6 3 363.273 
6 4 388.061 
6 3 423.517 
5 4 411.474 
2 4 316.559 
0 4 363.593 
0 4 397.341 
0 0 302.845 
4 0 341.953 
6 0 374.572 
6 1 237.941 
5 2 301.175 
4 3 234.309 
4 3 217.576 
3 3 286.245 
3 2 273.851 
4 3 393.145 
5 1 565.417 
6 0 348.2 
5 3 423.861 
2 2 476.679 
3 0 418.575 
5 1 233.465 
6 3 302.233 
5 3 509.269 
4 1 583.715 
3 3 535.951 
3 4 366.26 
1 4 290.75 
0 3 357.554 
4 1 403.227 
2 3 460.28 
1 4 441.285 
1 3 481.835 
4 1 459.336 
5 2 362.049 
6 2 259.878 
6 4 398.485 
4 4 345.496 
0 3 309.027 
0 4 401.788 
0 0 409.387 
3 0 332.664 
3 1 314.46 
3 1 269.956 
6 0 218.155 
6 1 529.104 
5 4 382.2 
3 4 489.955 
1 3 446.122 
1 1 460.838 
3 0 324.324 
4 0 207.98 
4 3 315.023 
3 4 282.74 
3 4 332.247 
5 4 337.352 
6 4 418.507 
5 4 419.825 
3 2 441.146 
3 1 376.079 
5 1 388.919 
5 2 213.573 
4 3 218.711 
3 4 243.383 
2 1 375.325 
5 1 306.56 
5 3 332.943 
3 2 387.378 
3 2 345.769 
3 2 398.84 
3 2 281.033 
5 0 378.365 
0 2 717.253 
0 0 791.392 
0 0 575.379 
3 1 365.754 
4 2 274.214 
5 3 208.631 
5 3 311.304 
5 3 450.575 
3 4 253.502 
4 3 442.908 
3 4 372.944 
2 3 214.664 
2 4 233.063 
1 3 202.191 
2 3 252.356 
2 3 202.654 
4 1 221.826 
5 2 241.5 
5 4 319.848 
5 0 452.243 
6 1 363.507 
6 2 335.506 
6 2 278.626 
5 3 258.146 
4 2 416.057 
4 0 292.028 
3 1 446.025 
3 2 341.648 
3 2 337.043 
3 2 333.046 
3 3 176.895 
2 3 226.696 
3 1 219.299 
6 0 334.036 
5 1 535.518 
4 3 491.373 
4 3 387.29 
5 3 428.51 
5 3 328.886 
4 2 283.853 
3 3 454.957 
3 3 314.406 
4 4 369.73 
2 4 362.839 
1 4 329.404 
1 1 350.119 
3 1 347.537 
1 2 281.253 
3 0 314.648 
4 1 194.79 
3 2 238.247 
1 1 269.851 
1 0 405.317 
0 4 378.741 
0 2 310.43 
4 4 493.997 
3 4 419.287 
3 4 305.67 
3 4 304.043 
1 2 304.306 
0 3 239.87 
0 1 269.51 
0 2 380.378 
0 3 303.476 
0 2 398.456 
4 0 505.532 
4 0 349.822 
4 0 370.298 
4 2 512.851 
0 2 426.743 
0 1 335.048 
0 0 425.429 
1 2 570.716 
1 2 644.525 
1 2 669.824 
1 2 572.251 
3 4 499.781 
0 3 367.318 
0 0 427.239 
0 0 562.971 
0 0 397.957 
2 0 226.262 
2 0 343.901 
0 3 233.462 
0 1 227.65 
3 0 337.093 
4 0 238.141 
2 0 304.541 
1 0 559.368 
1 4 408.645 
1 3 339.207 
0 0 262.552 
1 1 314.166 
1 2 348.097 
4 2 442.35 
4 1 328.39 
1 1 219.329 
1 0 229.324 
3 0 338.905 
4 1 378.284 
4 3 365.544 
6 2 359.765 
5 2 391.791 
3 1 304.044 
4 1 495.032 
1 3 475.775 
0 4 313.94 
1 0 427.408 
1 0 483.73 
0 1 434.902 
1 2 474.109 
3 4 510.591 
1 4 545.398 
1 4 520.684 
1 4 337.248 
1 1 300.098 
2 2 224.111 
3 2 298.454 
4 0 250.755 
4 0 406.564 
3 1 262.254 
4 1 236.003 
4 2 241.741 
1 2 252.381 
2 0 332.336 
2 2 256.289 
4 1 283.132 
5 1 375.951 
5 1 300.343 
4 1 276.844 
1 1 302.532 
0 0 378.367 
0 0 399.624 
2 0 410.12 
4 0 291.385 
4 0 357.406 
3 1 327.345 
2 0 235.637 
1 0 439.564 
1 0 511.418 
4 1 372.444 
5 3 424.816 
3 3 324.157 
1 4 481.555 
1 0 320.916 
4 0 380.767 
4 0 330.493 
4 0 562.196 
5 1 512.501 
5 1 366.257 
4 1 325.955 
3 0 434.074 
5 2 436.764 
6 4 306.892 
5 2 529.902 
6 0 455.347 
3 2 479.285 
2 4 395.13 
1 4 517.487 
2 4 431.155 
2 3 297.469 
3 1 273.96 
1 2 365.11 
1 4 254.275 
1 4 441.785 
1 3 355.16 
1 1 339.601 
2 0 321.393 
2 0 330.624 
1 3 393.489 
1 3 445.346 
0 3 455.255 
0 2 378.944 
0 2 334.458 
4 4 395.859 
3 4 299.882 
1 3 315.698 
3 4 396.692 
1 3 267.948 
2 2 304.054 
2 3 321.433 
2 2 333.595 
3 2 394.466 
3 1 641.17 
3 1 710.694 
3 2 504.429 
2 3 457.475 
2 0 479.791 
3 0 448.328 
4 2 663.948 
3 4 668.353 
1 4 506.841 
1 4 390.212 
0 4 416.885 
1 0 399.112 
2 0 391.235 
3 0 401.548 
6 0 378.286 
6 1 511.548 
5 2 503.091 
4 3 407.479 
2 1 497.102 
1 0 434.744 
2 1 319.362 
5 0 340.472 
5 1 349.709 
5 2 316.875 
5 2 464.92 
5 4 538.614 
2 3 459.004 
2 0 368.923 
1 1 440.613 
1 0 310.587 
1 0 264.566 
3 0 614.296 
3 0 546.888 
3 0 470.877 
3 0 624.115 
4 0 620.333 
2 2 417.7 
3 1 317.743 
4 2 329.249 
3 2 269.07 
4 1 376.327 
6 1 410.131 
6 3 343.679 
3 4 311.114 
1 4 573.663 
0 4 729.726 
0 4 545.042 
0 4 304.956 
1 3 347.938 
3 4 422.092 
3 4 411.755 
4 4 488.46 
3 4 676.899 
0 4 421.108 
1 0 260.133 
1 1 283.703 
2 2 221.714 
2 2 247.685 
2 1 238.218 
4 1 266.308 
5 2 257.943 
5 2 262.058 
6 2 310.813 
6 3 343.627 
5 3 412.024 
4 3 485.959 
1 3 380.613 
2 0 348.685 
5 0 395.301 
6 3 555.438 
6 4 323.238 
4 3 389.407 
4 1 397.198 
6 0 292.129 
6 1 358.846 
6 2 363.267 
6 2 347.793 
6 2 341.773 
6 3 356.032 
5 4 425.691 
2 4 437.154 
1 0 515.23 
3 1 304.444 
6 1 484.493 
6 2 413.868 
6 3 370.432 
6 3 375.424 
5 3 589.274 
2 1 574.261 
1 0 516.891 
2 0 321.373 
3 0 307.602 
4 0 296.489 
4 1 300.969 
3 2 294.041 
3 2 353.856 
3 4 306.964 
2 3 306.125 
2 0 264.662 
2 0 199.644 
2 0 295.344 
2 2 349.041 
4 3 408.081 
3 4 619.771 
1 2 469.839 
4 2 330.821 
4 4 363.449 
0 2 546.825 
4 3 444.078 
4 4 399.112 
0 3 439.515 
1 1 399.639 
2 2 414.299 
3 4 451.066 
3 1 481.754 
3 1 583.984 
4 2 470.68 
5 0 316.5 
6 0 270.519 
5 2 504.089 
4 4 236.486 
2 4 321.601 
2 2 370.446 
3 1 276.743 
5 0 335.977 
4 2 462.182 
0 3 431.632 
0 3 359.388 
1 3 399.816 
2 3 250.805 
2 4 387.459 
1 4 265.347 
0 4 366.613 
1 0 283.179 
3 1 194.783 
5 1 252.012 
5 1 409.13 
4 1 518.11 
4 3 475.806 
5 2 441.348 
5 4 344.812 
3 4 307.986 
2 4 304.62 
1 3 228.134 
1 2 251.96 
3 0 251.087 
3 0 484.198 
5 0 507.429 
4 1 418.693 
1 3 453.271 
0 0 462.813 
0 1 409.82 
1 2 381.423 
1 3 236.059 
1 3 301.153 
2 2 278.931 
4 3 379.899 
5 4 354.513 
4 3 287.632 
6 3 330.045 
6 4 298.218 
3 4 282.279 
2 2 254.554 
2 1 277.369 
2 1 284.653 
2 1 237.042 
3 0 269.974 
3 1 312.582 
3 1 297.746 
4 2 327.875 
5 3 324.494 
5 4 345.194 
3 4 293.967 
1 3 311.379 
1 2 238.17 
2 1 253.075 
2 2 301.536 
2 2 396.034 
2 3 389.156 
2 1 377.915 
2 2 305.276 
3 1 367.055 
5 1 398.97 
6 2 248.013 
6 3 276.888 
6 4 193.674 
6 2 292.915 
5 2 253.842 
4 3 334.262 
3 2 339.945 
3 1 273.478 
4 1 256.802 
4 1 373.199 
6 1 351.628 
5 1 321.746 
3 0 372.925 
3 0 443.95 
4 0 424.093 
4 1 327.705 
1 2 320.785 
3 3 233.803 
1 2 325.849 
1 2 248.608 
2 2 417.182 
4 1 275.626 
4 1 205.966 
4 2 287.774 
4 4 317.714 
3 2 421.015 
4 1 231.899 
3 2 287.384 
3 2 271.87 
4 3 240.685 
1 3 322.79 
0 3 218.731 
0 2 351.655 
0 2 543.163 
4 0 346.404 
4 0 285.534 
4 1 216.119 
2 2 354.476 
4 0 299.129 
4 1 330.059 
3 2 270.81 
1 3 347.174 
1 3 351.925 
1 2 319.24 
3 0 258.831 
2 0 256.027 
3 0 328.899 
4 0 422.797 
4 2 346.333 
2 3 312.004 
2 3 236.899 
2 3 350.07 
2 4 223.664 
1 3 216.441 
1 4 237.394 
3 4 340.587 
2 4 394.145 
1 4 259.657 
1 4 428.972 
1 4 347.48 
1 3 459.018 
4 3 445.788 
5 3 304.842 
5 4 209.982 
5 4 186.402 
5 4 327.167 
4 4 226.927 
4 3 389.692 
0 3 606.143 
0 3 608.548 
0 2 495.844 
4 1 453.269 
1 2 445.89 
3 0 454.108 
3 0 398.219 
1 4 430.485 
1 4 412.201 
1 4 390.853 
1 0 401.57 
0 4 328.427 
0 1 282.88 
2 2 294.912 
2 3 235.102 
2 1 328.992 
3 1 311.378 
3 1 334.332 
2 2 264.701 
2 1 268.403 
2 0 295.96 
3 1 379.667 
1 1 349.872 
0 1 225.321 
0 1 195.701 
0 1 311.685 
1 2 333.706 
5 2 348.479 
4 2 255.833 
1 1 283.051 
1 4 477.082 
1 4 371.537 
2 4 291.779 
2 4 365.369 
1 4 511.98 
1 4 446.788 
2 3 361.219 
3 1 284.332 
4 3 363.338 
4 2 479.066 
4 1 385.413 
3 3 440.499 
1 4 390.5 
1 4 315.821 
1 4 240.815 
0 4 177.983 
0 0 321.852 
0 0 446.015 
0 0 402.975 
0 0 453.72 
1 0 533.89 
3 0 460.374 
1 1 347.492 
0 0 363.524 
0 0 375.305 
0 1 357.66 
0 2 311.3 
0 2 462.918 
4 1 431.519 
4 3 234.465 
4 2 231.823 
5 3 269.758 
5 3 294.143 
3 4 350.366 
1 4 267.478 
1 3 344.285 
1 4 328.774 
1 0 331.287 
2 0 421.326 
2 0 420.009 
0 0 326.012 
0 0 309.933 
0 3 301.919 
0 3 254.945 
0 2 225.491 
1 3 290.563 
1 0 366.78 
1 0 290.986 
1 1 300.265 
4 0 296.213 
6 0 321.215 
5 0 571.701 
4 1 543.523 
4 3 328.797 
4 3 410.766 
0 2 528.47 
4 3 440.948 
4 4 259.998 
3 4 192.976 
2 4 255.688 
1 4 454.518 
0 4 635.185 
0 1 662.931 
0 2 486.559 
2 3 306.947 
3 3 363.425 
3 2 313.348 
5 0 304.366 
5 1 395.151 
5 2 429.017 
3 2 524.3 
3 2 548.274 
3 1 464.105 
3 0 399.042 
5 0 401.699 
5 2 368.278 
3 1 369.877 
5 0 384.615 
6 1 559.275 
6 1 587.045 
5 2 331.74 
3 3 220.998 
2 0 380.688 
3 0 502.07 
4 0 517.65 
4 1 491.927 
3 4 370.391 
2 3 276.696 
4 1 361.346 
4 2 583.397 
0 3 622.512 
0 2 512.304 
4 1 385.052 
6 1 409.274 
6 1 515.963 
6 1 361.347 
4 2 354.222 
2 3 308.588 
4 2 383.689 
6 1 422.581 
6 1 366.78 
6 3 462.161 
6 4 221.88 
6 4 358.775 
5 2 514.716 
6 1 334.768 
6 3 560.727 
6 4 612.05 
6 4 387.014 
6 4 568.494 
3 2 361.75 
3 0 338.136 
3 1 382.943 
2 3 312.014 
0 4 466.84 
0 0 625.503 
1 0 393.4 
3 1 311.893 
5 0 302.515 
5 1 357.364 
4 2 339.761 
3 2 444.687 
3 2 356.677 
4 4 295.473 
3 4 411.655 
3 4 698.095 
1 4 559.022 
0 0 311.402 
1 0 411.777 
1 0 697.694 
1 0 682.929 
1 0 623.442 
1 0 566.71 
2 1 590.557 
2 2 633.932 
2 1 505.122 
3 2 390.149 
3 2 366.245 
1 3 506.978 
2 0 528.255 
5 0 397.7 
6 0 389.623 
6 2 372.812 
6 3 345.351 
6 3 525.156 
6 4 612.53 
5 2 699.722 
3 2 724.486 
3 2 619.267 
6 4 558.771 
5 4 714.092 
2 3 504.068 
2 1 284.215 
3 1 262.5 
3 2 308.792 
5 1 393.289 
5 2 392.556 
5 3 429.994 
6 0 512.829 
6 0 447.353 
6 0 527.643 
6 0 615.587 
4 1 454.968 
3 1 380.043 
3 1 342.122 
5 2 295.949 
5 2 294.531 
6 2 292.602 
6 1 294.358 
6 4 296.271 
6 3 359.513 
6 2 577.392 
6 3 746.24 
6 3 612.627 
4 4 672.499 
2 4 639.534 
4 1 599.889 
4 1 432.992 
5 1 261.997 
6 1 432.942 
6 2 762.906 
6 4 429.729 
5 2 514.698 
6 0 497.331 
3 1 481.132 
4 2 395.734 
6 2 416.125 
6 2 494.351 
6 1 290.837 
6 1 244.131 
6 2 281.845 
4 3 418.039 
3 1 413.816 
3 1 507.902 
3 2 692.458 
2 2 584.932 
2 2 400.379 
2 3 489.619 
1 4 735.538 
2 0 565.164 
2 1 296.849 
2 1 304.058 
3 1 321.091 
2 3 503.766 
2 2 466.67 
5 2 274.677 
6 3 246.355 
4 2 355.591 
3 1 422.174 
6 0 379.275 
6 2 548.813 
6 2 468.312 
4 2 492.444 
2 3 367.756 
1 1 347.387 
1 2 412.411 
4 0 402.959 
5 1 270.231 
5 2 228.619 
5 3 315.142 
2 4 321.774 
1 3 308.185 
3 0 377.725 
4 1 610.81 
3 2 390.167 
3 1 392.339 
6 0 280.822 
5 2 311.605 
3 3 319.914 
2 3 275.029 
1 1 324.816 
0 0 273.743 
1 0 432.515 
2 0 404.92 
3 0 253.551 
4 2 434.872 
6 4 441.251 
5 2 619.96 
6 1 513.416 
6 2 379.791 
5 4 287.511 
2 2 505.039 
3 0 305.02 
2 2 285.377 
2 1 463.858 
3 0 387.67 
3 0 599.525 
6 0 518.697 
6 1 503.97 
5 3 465.952 
1 2 458.352 
0 2 426.941 
0 3 396.125 
0 4 445.622 
0 4 647.001 
0 4 589.484 
0 4 556.619 
0 3 488.632 
0 2 406.111 
0 2 318.811 
4 3 319.332 
5 4 371.069 
4 4 415.932 
0 2 328.839 
0 0 320.528 
2 0 290.398 
3 0 256.596 
4 1 206.169 
5 3 305.529 
4 3 336.403 
3 2 269.285 
5 1 366.306 
5 3 386.863 
3 3 366.684 
3 3 299.812 
3 0 194.719 
5 1 338.819 
6 2 452.5 
5 3 390.064 
2 3 328.833 
3 3 402.342 
6 4 488.679 
6 4 545.613 
6 4 405.735 
5 4 625.872 
4 4 519.054 
5 4 410.78 
6 4 726.131 
5 4 848.119 
5 4 531.792 
4 3 457.334 
5 1 305.47 
5 1 211.216 
4 3 292.232 
4 3 234.503 
6 4 418.836 
6 4 510.892 
5 3 415.154 
3 3 301.459 
4 3 238.312 
4 4 350.873 
3 4 413.534 
3 4 403.179 
4 4 623.824 
4 4 718.999 
3 4 441.805 
1 3 293.024 
2 1 268.561 
2 0 314.822 
2 0 302.711 
1 2 351.853 
0 2 346.008 
1 2 403.835 
4 1 374.085 
4 2 379.044 
4 3 402.936 
0 2 352.344 
3 3 385.591 
4 1 383.022 
4 0 281.835 
5 0 349.459 
5 0 384.602 
3 1 334.256 
2 0 363.452 
3 0 452.702 
1 2 444.357 
4 4 370.188 
3 3 355.909 
4 1 266.917 
5 1 259.887 
3 3 319.783 
2 2 269.265 
3 3 396.481 
3 4 317.817 
3 3 180.5 
4 3 228.616 
3 3 235.17 
1 3 294.14 
0 4 312.648 
0 4 352.463 
0 1 320.496 
0 3 289.045 
1 2 347.827 
3 4 360.048 
1 2 334.776 
1 1 346.182 
1 2 473.116 
2 2 409.187 
1 3 399.001 
1 0 313.892 
3 0 257.953 
3 0 320.435 
4 0 298.584 
2 3 350.9 
2 3 267.391 
1 3 222.944 
1 1 279.356 
4 1 186.607 
5 2 244.807 
4 2 240.969 
2 2 223.965 
2 2 267.088 
2 2 286.599 
3 2 339.193 
4 1 404.485 
5 0 426.211 
5 0 335.101 
6 0 316.089 
5 2 472.691 
3 4 470.816 
0 4 356.664 
0 0 589.726 
0 0 518.245 
1 1 361.01 
3 3 441.615 
3 3 379.538 
3 3 273.712 
5 3 216.573 
5 4 434.13 
3 3 346.04 
2 2 331.252 
3 0 402.991 
2 2 323.095 
1 2 255.585 
3 0 221.987 
4 1 347.998 
3 2 334.619 
2 2 382.159 
2 4 456.461 
2 4 308.286 
1 3 259.924 
1 1 236.81 
1 2 479.276 
2 4 648.337 
0 4 414.416 
0 4 389.306 
0 0 294.819 
0 1 404.647 
1 3 402.513 
1 4 446.437 
0 0 458.635 
1 1 254.369 
2 0 232.533 
3 0 273.722 
1 2 408.649 
1 3 348.826 
3 4 460.129 
1 2 396.292 
0 2 194.127 
0 2 309.295 
5 1 540.304 
4 3 340.3 
2 3 310.804 
2 2 360.206 
4 4 405.353 
2 4 349.455 
1 3 421.382 
3 1 327.974 
6 0 383.817 
5 2 566.128 
5 3 461.73 
2 4 346.518 
1 3 330.777 
2 3 258.251 
2 3 377.44 
2 2 310.716 
3 4 338.004 
0 4 434.654 
0 4 486.515 
0 1 384.553 
4 1 326.533 
6 2 407.731 
6 1 550.275 
5 2 478.275 
0 3 321.16 
0 0 522.072 
0 0 581.571 
0 1 484.271 
0 1 447.334 
4 0 462.769 
4 0 444.695 
0 2 390.829 
4 1 311.453 
5 2 398.876 
5 2 537.992 
5 2 801.162 
5 4 1002.45 
5 4 1054.88 
4 4 668.041 
4 4 452.986 
0 4 496.52 
0 4 348.405 
4 2 391.073 
6 2 357.225 
6 3 412.219 
5 4 404.951 
3 2 367.406 
3 1 354.935 
3 1 503.969 
3 1 607.094 
3 3 377.023 
1 3 358.001 
2 0 371.141 
2 1 372.058 
2 1 398.077 
2 3 398.828 
2 3 360.424 
1 2 423.753 
5 2 653.515 
6 2 845.257 
5 2 801.663 
5 3 543.617 
4 4 336.763 
2 2 318.424 
1 3 261.956 
1 3 331.067 
1 0 401.084 
1 0 507.162 
2 1 414.644 
5 3 464.566 
3 4 456.862 
3 4 488.683 
3 4 515.301 
3 4 756.605 
1 0 653.909 
2 0 448.429 
1 0 565.961 
1 4 598.026 
2 3 521.225 
3 1 389.279 
5 2 446.684 
6 4 386.258 
5 4 473.576 
5 2 553.499 
5 3 451.187 
3 4 473.947 
2 3 474.696 
2 2 584.683 
3 0 558.31 
6 0 613.026 
4 2 643.194 
1 3 579.605 
0 3 524.696 
0 4 550.356 
0 0 508.5 
0 1 352.92 
1 2 318.936 
1 2 334.127 
4 0 283.019 
5 1 463.396 
0 2 550.491 
0 2 686.486 
5 0 498.692 
6 0 446.463 
6 0 685.302 
2 0 559.704 
2 0 313.742 
3 0 491.961 
4 1 477.949 
0 2 645.097 
0 2 699.673 
0 2 860.691 
0 2 1051.97 
4 4 900.767 
5 4 656.498 
5 3 621.879 
6 1 582.596 
6 2 235.786 
3 2 308.137 
5 0 494.737 
6 1 426.443 
6 4 314.061 
5 1 644.027 
5 1 423.248 
4 1 463.938 
4 2 417.931 
5 1 552.874 
5 2 395.436 
4 2 256.062 
1 2 429.199 
0 1 444.142 
0 4 521.004 
0 4 494.314 
1 3 402.258 
0 3 443.418 
1 0 451.443 
3 0 565.911 
6 0 491.341 
6 4 567.388 
3 4 597.216 
1 4 473.794 
1 3 316.113 
4 3 375.291 
2 4 305.879 
0 4 596.704 
1 4 435.882 
0 4 549.685 
0 0 515.438 
2 0 354.944 
3 1 377.517 
3 2 377.302 
3 2 348.246 
3 4 343.16 
1 3 381.073 
2 1 293.156 
5 2 259.549 
6 3 340.53 
5 3 470.242 
5 3 508.575 
6 4 480.819 
5 4 718.029 
3 4 603.75 
3 3 371.661 
5 3 342.036 
5 3 434.875 
3 4 399.797 
0 4 461.699 
1 0 347.392 
2 0 260.429 
2 1 400.106 
3 1 380.866 
5 3 433.936 
5 4 512.957 
4 4 501.134 
1 1 389.256 
2 0 390.57 
3 0 680.945 
6 0 962.92 
5 0 796.274 
1 0 643.524 
1 0 461.708 
1 4 222.63 
1 1 250.945 
2 0 289.591 
2 1 310.128 
3 1 300.648 
1 2 294.28 
1 4 343.895 
0 4 281.576 
0 0 365.715 
0 1 265.632 
1 1 325.83 
2 1 353.073 
3 2 407.513 
5 3 448.076 
3 2 333.844 
2 2 372.764 
2 1 442.572 
2 0 295.78 
6 1 298.657 
6 2 472.59 
4 2 610.756 
1 2 551.434 
5 1 463.256 
6 3 488.829 
5 4 336.231 
0 4 375.106 
0 4 454.158 
2 4 322.837 
2 4 238.821 
3 3 367.123 
3 4 342.454 
4 4 540.938 
3 4 482.908 
4 0 536.56 
6 0 473.928 
6 0 316.056 
5 1 355.944 
4 2 341.759 
2 4 271.452 
1 4 263.93 
1 1 269.592 
2 2 281.067 
4 3 266.705 
4 2 327.201 
4 2 291.934 
3 3 202.634 
3 2 188.615 
3 1 314.739 
3 2 392.826 
3 1 342.575 
4 2 321.664 
4 3 249.035 
4 3 249.374 
5 3 421.468 
1 2 489.716 
2 2 461.581 
3 1 303.644 
5 1 256.503 
5 3 268.185 
4 3 256.476 
3 4 293.602 
2 4 244.638 
2 3 228.773 
3 2 200.9 
3 2 269.545 
3 3 293.174 
3 3 203.983 
3 2 201.356 
4 1 240.386 
4 2 194.756 
2 2 263.45 
2 0 288.417 
3 1 206.147 
3 1 204.891 
3 1 313.901 
4 1 271.307 
4 1 255.052 
4 2 304.687 
6 2 324.808 
6 2 346.377 
6 2 424.242 
5 4 383.55 
2 3 226.968 
1 1 305.554 
1 0 263.216 
2 1 247.273 
3 0 358.672 
3 1 371.656 
3 3 465.895 
4 4 381.959 
3 4 290.965 
2 3 210.726 
2 1 220.398 
3 1 301.296 
4 2 246.102 
4 1 208.913 
4 2 279.588 
4 3 268.409 
4 3 200.432 
3 2 333.66 
3 4 494.016 
2 4 389.739 
2 3 254.659 
2 2 284.371 
2 4 486.679 
2 4 426.298 
2 2 282.924 
3 1 203.583 
2 2 276.67 
1 0 381.184 
2 1 368.214 
1 2 313.787 
3 0 377.934 
1 2 403.874 
2 2 269.768 
2 2 244.816 
1 3 289.614 
1 1 340.146 
1 1 365.427 
3 0 443.116 
4 0 568.875 
4 0 656.279 
0 2 585.197 
0 2 695.519 
4 4 862.304 
4 4 702.638 
4 3 630.064 
4 1 400.334 
4 2 332.568 
3 2 305.715 
1 2 349.306 
2 1 347.561 
3 2 385.152 
4 2 474.495 
3 3 355.209 
1 2 320.696 
3 0 423.627 
1 1 443.725 
0 0 352.981 
1 1 439.952 
1 2 469.539 
3 1 474.228 
4 0 382.802 
5 0 420.417 
0 2 428.201 
0 1 376.746 
0 4 434.019 
1 4 274.107 
0 0 448.151 
0 0 622.543 
0 0 609.192 
1 0 446.755 
2 2 280.107 
3 3 222.261 
2 3 221.998 
1 2 255.525 
1 2 307.828 
1 3 474.928 
0 4 676.451 
0 1 835.291 
0 2 602.359 
0 2 512.956 
0 2 494.923 
3 2 416.139 
3 3 255.151 
4 3 343.111 
4 3 363.525 
3 4 500.8 
1 4 368.839 
1 4 378.028 
0 4 314.169 
1 1 254.515 
1 4 339.678 
0 0 306.041 
0 0 264.729 
2 0 359.89 
1 1 316.39 
1 4 325.173 
0 4 444.605 
0 0 398.127 
0 0 359.909 
2 0 463.446 
4 1 515.784 
5 3 326.922 
3 2 305.127 
3 1 511.888 
3 2 322.553 
4 1 303.322 
3 1 320.854 
2 1 301.496 
1 0 249.048 
2 0 267.56 
3 0 256.444 
2 1 276.562 
1 1 246.035 
4 0 445.073 
5 0 479.181 
5 0 555.251 
5 2 525.155 
5 4 480.658 
6 4 450.782 
6 4 463.061 
2 2 263.688 
2 0 184.995 
2 1 262.863 
2 2 331.374 
2 0 392.322 
2 1 324.206 
3 0 381.49 
3 1 511.459 
6 2 678.683 
6 4 772.391 
3 3 766.82 
5 4 797.124 
3 3 508.456 
4 1 411.054 
5 3 263.099 
4 2 395.566 
5 3 384.476 
5 3 534.869 
6 2 648.937 
6 4 785.194 
4 4 1040.42 
4 4 924.728 
0 2 703.1 
4 4 413.159 
4 4 479.262 
5 4 494.372 
3 4 494.86 
3 3 326.771 
3 3 421.742 
0 2 453.798 
0 3 418.549 
0 0 518.76 
1 0 634.685 
0 1 693.395 
0 2 721.377 
0 2 754.547 
0 2 751.025 
0 2 963.18 
0 2 1029.17 
5 2 884.362 
5 2 514.676 
5 3 309.3 
5 3 286.664 
5 3 266.034 
5 3 207.839 
5 4 336.627 
3 2 522.243 
6 0 422.862 
5 4 451.056 
2 3 371.584 
2 1 279.134 
2 2 577.255 
5 0 523.709 
6 0 520.024 
6 0 448.179 
6 0 646.501 
4 2 652.911 
0 2 456.527 
1 0 440.228 
3 0 346.834 
3 3 391.554 
3 4 499.451 
2 4 432.537 
1 4 455.132 
1 0 441.903 
3 0 293.941 
4 2 307.965 
5 3 238.558 
5 4 340.251 
3 2 623.294 
6 2 575.419 
6 1 369.399 
5 3 430.825 
2 2 628.879 
2 2 406.936 
2 1 304.524 
2 1 294.997 
2 2 317.366 
3 1 228.607 
4 2 329.927 
5 1 338.007 
5 3 376.563 
5 2 509.545 
6 1 576.406 
6 2 362.007 
5 2 400.862 
6 1 859.445 
6 3 1295.19 
6 3 1193.62 
6 4 833.306 
6 4 601.101 
6 4 777.29 
6 3 632.418 
6 2 413.308 
6 3 318.626 
4 4 459.17 
3 0 597.146 
6 0 331.044 
4 2 317.485 
3 0 413.842 
5 0 497.921 
6 0 385.098 
6 2 288.799 
6 3 576.436 
5 2 761.354 
4 4 758.399 
4 4 626.531 
4 4 642.57 
3 4 424.694 
2 2 346.359 
5 0 324.716 
6 0 467.438 
6 1 547.335 
5 2 360.94 
5 2 272.571 
5 4 258.704 
3 2 410.65 
5 1 368.593 
5 4 457.469 
4 3 698.439 
4 1 520.921 
5 0 433.11 
6 0 250.818 
6 0 346.991 
3 2 473.6 
3 1 462.57 
6 1 333.144 
5 2 318.18 
5 3 460.296 
3 2 361.865 
5 1 348.798 
6 0 253.467 
6 0 344.449 
6 0 499.175 
6 2 488.951 
5 3 479.667 
3 2 297.098 
5 1 320.457 
3 2 458.235 
2 2 373.043 
2 1 448.555 
2 1 474.611 
3 1 581.187 
5 2 519.843 
6 3 339.916 
6 4 306.833 
5 4 453.881 
3 4 514.246 
1 2 454.67 
4 0 502.692 
6 1 407.312 
4 2 393.778 
2 4 339.088 
0 4 314.822 
4 1 322.385 
5 2 505.946 
5 3 315.104 
5 3 287.465 
6 3 327.239 
5 4 592.878 
4 4 514.599 
3 4 480.678 
1 4 254.565 
1 2 279.054 
3 1 274.603 
3 0 233.795 
4 1 251.943 
2 2 164.821 
2 0 304.045 
2 3 455.417 
2 4 304.197 
2 4 345.099 
2 4 459.54 
0 3 465.457 
0 1 390.611 
0 2 463.526 
4 4 469.406 
2 4 453.527 
1 1 317.199 
1 1 300.626 
1 1 249.666 
1 2 219.15 
1 3 367.095 
0 2 281.885 
0 1 268.684 
0 1 497.392 
5 0 679.957 
6 0 700.441 
6 2 612.221 
6 3 400.83 
6 3 577.128 
6 3 550.618 
6 3 300.325 
6 4 348.354 
6 3 488.04 
6 3 432.797 
6 3 620.115 
6 4 537.213 
5 3 326.774 
3 3 316.313 
3 4 426.748 
5 3 437.378 
5 3 307.495 
3 3 445.594 
0 3 459.03 
0 3 513.68 
0 3 434.767 
2 4 332.562 
3 3 333.658 
4 3 339.086 
4 4 390.992 
3 4 283.923 
1 3 329.52 
1 2 309.8 
3 1 292.083 
5 1 241.311 
5 2 280.467 
5 2 285.521 
4 3 344.292 
2 4 296.213 
0 4 195.901 
0 3 234.301 
4 0 327.36 
5 1 272.741 
3 2 445.803 
0 4 354.815 
0 4 302.397 
0 2 308.357 
0 2 525.187 
4 1 569.432 
4 3 486.165 
3 4 451.664 
0 4 296.166 
0 1 231.551 
0 1 228.793 
1 0 314.656 
0 1 400.616 
0 1 307.788 
0 2 525.338 
0 2 619.029 
4 0 502.532 
1 2 329.614 
1 1 372.353 
2 0 477.726 
3 0 511.718 
3 0 370.502 
4 1 393.397 
1 3 372.142 
0 2 334.703 
0 1 440.944 
0 2 462.156 
0 2 578.749 
3 4 504.981 
3 4 333.119 
1 2 290.778 
3 1 300.949 
4 1 329.678 
1 3 471.171 
0 4 368.792 
0 2 360.44 
4 3 283.159 
2 3 329.06 
3 4 375.716 
3 4 335.402 
3 3 355.874 
2 3 255.74 
3 2 373.563 
4 3 381.764 
1 3 321.655 
0 1 346.812 
0 4 469.804 
1 3 429.809 
3 3 496.204 
1 2 445.552 
2 3 332.873 
1 3 364.346 
1 3 396.265 
4 2 388.43 
5 2 426.086 
3 3 420.436 
2 3 447.468 
2 4 616.213 
2 4 516.614 
0 4 386.09 
0 4 498.583 
0 0 345.752 
0 3 371.271 
0 3 345.374 
0 2 262.513 
3 0 342.686 
1 1 321.727 
1 1 280.243 
1 1 264.531 
2 1 370.366 
2 3 415.771 
1 3 417.211 
1 1 430.541 
0 1 424.774 
0 1 381.197 
0 4 361.047 
0 0 475.485 
0 0 399.655 
0 1 272.842 
2 2 261.989 
2 1 199.001 
3 0 385.412 
2 1 412.299 
2 0 579.447 
1 0 543.69 
0 0 364.36 
0 0 358.364 
0 0 350.831 
0 0 244.438 
2 0 431.522 
4 0 426.767 
0 1 444.978 
0 1 534.079 
0 2 394.046 
0 3 376.313 
1 4 519.419 
1 4 545.373 
0 4 292.321 
0 0 230.447 
2 0 336.504 
1 2 350.028 
1 3 241.081 
1 3 345.111 
1 4 245.321 
1 4 347.575 
3 4 375.26 
3 4 362.768 
3 4 354.052 
3 4 352.973 
2 4 393.238 
1 4 328.233 
1 4 535.89 
1 4 681.234 
0 0 578.065 
0 0 407.283 
0 2 418.35 
5 2 304.541 
5 2 482.008 
4 4 364.936 
2 3 227.564 
1 2 194.883 
0 2 180.804 
0 2 260.999 
0 2 326.966 
1 3 367.489 
2 3 388.167 
4 2 435.505 
5 4 430.162 
5 4 470.104 
5 3 347.096 
4 3 315.112 
0 3 438.636 
0 3 420.546 
0 3 357.787 
2 4 485.614 
3 1 522.438 
4 2 282.217 
5 4 282.509 
3 4 131.778 
0 4 280.034 
0 3 415.674 
3 4 444.92 
3 4 541.053 
2 4 575.395 
4 3 666.597 
5 1 545.055 
6 0 531.275 
6 0 489.481 
5 1 383.115 
5 1 348.102 
6 2 274.277 
6 3 305.036 
6 3 344.6 
6 4 345.904 
5 4 647.953 
3 1 699.298 
5 1 521.735 
3 1 469.095 
1 0 463.669 
1 0 458.331 
2 0 678.02 
0 1 686.445 
4 0 570.573 
4 0 553.458 
0 1 439.803 
0 1 434.799 
0 1 292.369 
0 1 533.31 
4 0 589.297 
5 0 409.955 
5 0 453.891 
4 3 548.057 
0 3 531.907 
0 3 602.487 
0 2 677.414 
0 2 489.201 
0 1 463.532 
3 0 443.616 
4 0 355.027 
4 3 402.697 
1 4 384.277 
0 4 531.824 
3 0 540.214 
6 0 363.022 
6 1 282.179 
5 1 415.902 
5 0 464.23 
5 1 429.364 
2 3 574.39 
0 4 673.073 
0 0 863.128 
0 1 636.449 
0 2 485.656 
0 2 397.549 
4 1 348.075 
3 1 238.368 
2 2 392.289 
2 0 401.069 
2 1 354.75 
3 3 353.483 
3 4 329.022 
2 4 276.429 
0 3 384.696 
0 2 559.307 
5 0 764.434 
5 0 932.062 
5 1 932.459 
5 1 784.221 
6 2 552.728 
6 2 554.4 
6 2 669.853 
6 4 689.59 
3 4 588.05 
0 4 457.314 
0 4 328.359 
1 2 260.881 
3 0 210.289 
6 0 346.888 
5 3 409.462 
1 1 368.929 
2 0 328.483 
3 0 429.762 
3 0 402.859 
5 0 541.054 
5 0 499.33 
5 0 699.31 
6 0 885.73 
4 0 533.659 
4 0 384.473 
4 2 432.512 
4 3 296.815 
5 1 439.421 
6 2 368.284 
6 3 355.139 
5 3 336.425 
3 4 362.811 
0 4 303.553 
0 4 266.77 
2 3 229.385 
4 3 394.169 
6 4 279.16 
5 3 402.582 
5 4 593.068 
2 4 575.811 
3 2 409.926 
6 2 378.515 
6 2 470.534 
4 3 607.976 
0 2 337.143 
4 4 399.606 
0 4 308.834 
0 4 308.319 
3 4 467.619 
0 2 479.455 
4 0 452.254 
5 0 436.582 
5 0 422.609 
4 1 456.327 
4 3 697.554 
5 3 553.94 
6 1 728.182 
6 1 601.565 
6 1 565.971 
6 1 1334.73 
6 3 1415.73 
6 3 738.854 
6 2 590.911 
6 3 413.331 
6 2 376.563 
5 3 418.94 
3 1 732.967 
6 0 668.952 
6 1 615.565 
6 1 414.432 
5 2 414.564 
3 3 325.72 
2 2 350.323 
5 0 489.103 
6 0 556.791 
6 2 494.677 
5 3 320.765 
5 2 398.874 
6 2 341.262 
6 4 271.518 
1 2 422.728 
2 0 552.177 
5 0 643.539 
6 2 648.667 
6 3 483.952 
6 2 413.489 
6 3 376.254 
5 4 324.21 
6 0 421.098 
6 0 371.352 
6 1 325.953 
6 1 396.212 
6 2 368.049 
6 4 365.877 
4 4 444.55 
2 4 488.222 
0 4 537.982 
0 0 430.4 
0 2 452.873 
4 2 553.19 
3 3 471.975 
3 2 430.753 
3 2 404.878 
5 3 253.017 
3 3 264.668 
1 3 401.762 
1 1 378.943 
1 2 229.952 
3 1 309.765 
5 0 366.668 
5 1 322.415 
5 1 241.208 
4 3 226.257 
3 2 305.139 
3 4 440.568 
1 4 397.006 
2 1 233.851 
3 2 349.885 
2 4 441.527 
2 1 449.783 
3 2 316.069 
4 3 512.841 
5 1 448.791 
5 1 311.424 
5 4 300.663 
4 4 526.247 
2 2 518.369 
4 0 393.254 
0 2 502.949 
2 4 252.347 
1 2 234.318 
0 2 424.384 
3 4 494.529 
0 4 442.309 
0 3 299.8 
1 2 263.004 
3 2 356.35 
4 2 399.566 
5 4 362.085 
4 4 429.063 
3 4 279.696 
2 4 319.348 
1 1 383.23 
4 3 273.974 
5 3 206.638 
4 3 313.475 
2 3 303.756 
2 3 398.512 
4 1 163.789 
5 1 208.852 
5 1 248.509 
2 2 305.202 
2 1 297.352 
2 1 253.575 
2 2 161.315 
1 2 281.171 
2 3 321.25 
1 4 530.25 
1 4 482.83 
2 4 338.509 
2 4 193.893 
1 3 188.8 
2 3 210.624 
3 3 230.805 
5 2 333.168 
4 2 223.718 
1 2 296.533 
1 1 294.532 
1 1 330.112 
1 2 267.461 
4 0 271.35 
4 1 305.79 
5 1 299.97 
6 2 233.751 
6 3 531.495 
6 4 406.847 
5 4 332.766 
4 4 279.08 
3 4 568.956 
0 2 709.964 
4 3 804.828 
4 4 683.066 
3 4 638.862 
3 4 675.34 
0 3 473.61 
0 3 384.644 
0 4 345.461 
0 3 260.346 
0 2 254.741 
0 2 594.296 
4 0 491.901 
3 0 493.745 
0 3 221.818 
0 1 203.182 
0 1 281.178 
0 1 216.57 
1 2 271.982 
1 2 246.648 
3 3 289.598 
5 4 338.857 
4 4 428.685 
3 4 391.978 
3 4 437.564 
3 4 404.963 
1 2 311.611 
4 3 427.597 
1 2 391.674 
2 2 304.053 
3 0 362.647 
3 2 421.387 
1 3 221.965 
1 1 209.348 
1 2 172.695 
1 2 176.87 
3 2 255.579 
4 2 313.504 
5 4 386.889 
2 4 257.121 
0 4 450.728 
0 0 656.68 
0 4 424.915 
0 1 280.483 
1 1 269.013 
1 3 366.647 
1 4 327.795 
0 0 300.53 
0 1 433.961 
0 3 514.318 
0 4 473.028 
0 1 399.212 
1 1 332.162 
4 0 244.056 
4 2 349.59 
3 1 332.586 
4 1 485.108 
3 3 477.204 
0 4 382.817 
0 0 369.55 
0 0 316.095 
1 1 190.574 
1 2 228.909 
1 3 170.308 
0 0 310.681 
1 0 303.107 
1 1 348.847 
0 4 360.98 
0 0 577.93 
0 0 657.159 
0 0 547.579 
0 4 516.405 
0 4 372.841 
1 3 336.57 
0 2 243.099 
4 0 406.226 
1 2 400.983 
0 1 303.506 
0 0 197.363 
0 2 508.711 
4 4 588.948 
4 4 507.248 
4 4 383.392 
4 4 265.248 
2 4 203.138 
2 2 240.67 
3 3 248.597 
3 2 348.11 
1 2 267.295 
1 2 211.533 
4 0 211.728 
3 1 356.703 
2 1 325.048 
2 1 431.835 
2 4 365.492 
1 4 282.564 
2 4 380.316 
1 4 431.307 
2 0 260.064 
3 0 294.437 
2 2 437.269 
2 1 465.692 
2 1 323.914 
1 3 344.644 
1 4 325.086 
2 4 467.396 
3 4 576.155 
2 4 504.036 
1 0 341.743 
0 0 521.312 
0 0 678.923 
1 0 222.925 
4 1 205.74 
5 3 374.398 
2 4 424.036 
0 4 490.46 
0 4 409.237 
0 3 387.392 
0 3 336.481 
0 2 261.432 
0 2 387.413 
4 3 500.281 
5 0 600.702 
4 0 424.703 
4 2 396.272 
5 4 566.363 
4 4 682.022 
0 3 617.944 
0 1 546.393 
0 1 485.787 
4 0 405.578 
0 2 412.189 
0 3 382.115 
0 4 364.63 
0 3 428.41 
3 3 652.319 
0 1 513.962 
0 0 509.937 
0 1 409.99 
5 0 394.592 
6 1 600.655 
6 3 547.034 
6 4 358.44 
4 4 430.201 
1 4 427.389 
2 0 328.604 
3 0 325.641 
2 2 413.29 
4 0 441.82 
4 0 450.541 
0 2 529.229 
0 1 676.043 
4 0 761.879 
5 1 803.536 
6 3 727.531 
6 4 610.131 
6 4 716.572 
5 3 636.577 
5 1 388.133 
5 2 428.365 
5 2 451.788 
5 3 301.864 
4 4 350.323 
1 4 364.124 
1 0 558.28 
1 0 428.462 
1 2 361.303 
0 2 362.807 
4 0 431.733 
5 0 395.673 
6 0 248.591 
6 1 351.3 
4 2 345.609 
1 3 303.418 
2 0 279.391 
4 0 395.674 
4 0 542.796 
6 0 508.296 
6 2 938.48 
6 3 1072.64 
6 4 789.959 
4 4 696.23 
3 4 565.06 
3 4 721.099 
1 4 620.639 
1 0 333.19 
2 0 415.728 
3 0 548.868 
1 1 447.344 
1 0 286.639 
1 0 327.303 
1 2 335.054 
2 3 209.184 
3 2 334.785 
4 2 573.795 
4 2 590.793 
5 1 337.642 
5 2 322.026 
5 3 461.372 
4 3 447.898 
2 4 468.716 
1 4 535.72 
1 4 552.058 
1 4 412.65 
0 0 522.428 
1 0 366.132 
2 2 330.963 
4 3 479.768 
4 4 626.74 
1 4 518.28 
2 4 513.542 
2 4 481.963 
1 4 423.354 
1 2 565.003 
4 1 547.886 
4 0 528.557 
0 1 546.937 
1 1 499.557 
2 0 373.912 
3 0 384.086 
6 0 383.303 
6 1 494.088 
3 2 393.349 
2 0 343.777 
2 0 256.612 
3 0 526.465 
6 0 391.731 
6 1 310.338 
5 2 370.567 
5 4 467.712 
5 0 622.92 
3 0 306.647 
3 0 552.369 
5 0 804.517 
6 0 733.366 
5 0 637.104 
5 1 561.745 
5 3 255.471 
4 3 306.078 
3 4 206.521 
1 2 415.355 
4 0 294.511 
4 2 368.773 
1 2 320.311 
2 0 448.473 
3 0 451.156 
3 1 320.328 
3 0 508.473 
6 0 712.814 
6 0 562.905 
6 2 588.731 
6 0 682.863 
3 1 857.965 
6 0 650.952 
6 2 458.551 
4 3 494.914 
1 3 381.427 
3 3 389.722 
4 3 353.642 
5 2 443.413 
6 1 334.807 
6 1 400.816 
6 1 303.884 
6 2 300.189 
6 3 221.045 
6 4 246.151 
5 4 485.867 
4 3 400.369 
4 4 309.211 
3 4 415.446 
3 4 538.475 
4 1 504.634 
6 0 373.721 
6 1 365.539 
3 2 440.953 
2 4 409.077 
1 4 339.389 
1 4 360.187 
0 4 341.377 
1 4 286.057 
1 3 385.01 
3 3 500.161 
1 2 597.966 
5 0 243.858 
6 2 383.178 
6 4 359.747 
4 4 428.428 
2 4 441.434 
0 3 458.175 
0 2 468.042 
0 2 599.94 
4 0 635.379 
5 0 472.303 
4 1 465.168 
2 3 355.045 
1 4 277.63 
0 4 358.768 
1 4 299.488 
2 4 363.831 
1 4 392.115 
1 1 407.558 
3 2 280.531 
3 4 430.566 
0 4 615.47 
0 0 625.939 
1 2 541.96 
4 4 209.989 
3 3 362.131 
1 2 211.134 
1 2 202.153 
0 3 258.82 
0 1 337.408 
3 0 576.821 
5 0 552.511 
6 0 778.4 
6 0 901.673 
6 0 693.494 
5 0 465.352 
6 1 537.275 
6 1 726.891 
6 1 396.856 
6 2 317.452 
5 4 294.765 
4 4 414.512 
2 4 584.405 
0 4 363.687 
1 4 413.086 
0 4 535.077 
0 0 273.182 
2 0 362.631 
2 3 338.655 
1 4 387.623 
2 0 334.706 
2 0 364.989 
2 3 515.176 
2 4 403.512 
0 3 533.603 
0 2 535.52 
4 4 300.116 
4 4 361.061 
4 4 338.81 
4 4 435.509 
3 4 434.627 
2 4 498.26 
3 4 602.3 
0 3 600.178 
0 2 383.176 
0 2 272.099 
0 3 282.121 
0 3 405.069 
1 3 380.594 
2 4 387.802 
3 4 367.96 
4 3 314.203 
4 2 408.966 
5 2 304.305 
4 2 209.367 
4 2 229.683 
2 2 288.715 
3 1 333.56 
3 1 454.907 
5 2 296.766 
5 3 252.103 
3 2 222.609 
4 2 259.526 
5 4 253.081 
5 3 237.133 
4 3 221.848 
2 2 235.871 
1 3 208.766 
2 3 227.469 
3 3 314.407 
3 2 264.789 
2 3 216.709 
1 1 362.967 
3 0 410.512 
3 2 385.844 
3 3 311.8 
2 2 338.685 
3 0 258.137 
1 1 282.911 
1 1 228.916 
2 0 283.04 
3 0 402.838 
2 2 502.164 
2 3 447.982 
2 3 405.735 
2 1 210.597 
3 1 367.434 
1 1 280.369 
1 0 249.899 
3 1 301.538 
3 1 257.795 
4 1 324.582 
1 2 247.682 
0 3 130.145 
0 3 213.903 
0 3 375.168 
0 3 337.642 
1 2 393.914 
4 1 348.064 
4 3 295.351 
4 3 425.344 
4 2 410.369 
2 2 431.058 
4 0 431.743 
6 0 396.531 
5 0 362.508 
2 0 360.546 
2 0 513.211 
3 0 435.872 
3 1 232.617 
4 1 295.687 
2 2 250.956 
2 1 205.284 
4 0 240.915 
4 1 340.187 
3 2 376.337 
2 2 413.919 
2 4 474.276 
2 1 365.115 
1 1 328.339 
0 4 425.809 
0 0 542.646 
0 0 348.652 
0 1 382.187 
0 4 432.685 
1 4 470.82 
1 4 457.352 
2 4 412.798 
2 4 587.819 
1 4 324.727 
0 0 344.754 
0 0 332.114 
0 0 606.266 
0 0 605.987 
1 0 426.434 
2 0 368.676 
1 0 337.101 
1 0 312.707 
2 0 281.384 
2 3 418.417 
1 4 281.24 
1 4 276.705 
2 4 447.267 
3 4 559.26 
3 4 470.605 
3 4 309.466 
1 3 323.379 
0 0 305.711 
0 0 430.028 
0 2 190.392 
0 2 445.292 
0 2 471.873 
0 1 439.024 
3 1 413.833 
3 2 216.576 
2 1 322.1 
2 3 290.174 
2 3 299.542 
2 1 239.362 
2 1 305.056 
4 2 356.873 
3 3 339.221 
2 3 309.347 
3 2 293.353 
5 3 220.414 
6 1 592.948 
5 2 508.511 
3 4 306.26 
2 3 207.45 
1 0 472.456 
1 0 418.217 
2 1 256.172 
2 3 327.205 
1 2 354.2 
4 1 361.751 
5 1 420.748 
5 2 401.302 
5 3 288.87 
5 3 311 
4 4 488.252 
2 4 568.144 
1 4 404.283 
2 2 323.875 
3 2 292.527 
2 1 387.066 
1 3 399.251 
1 4 249.776 
2 4 346.547 
3 4 454.842 
4 4 375.647 
6 4 338.945 
6 2 575.604 
6 2 525.606 
6 1 399.38 
6 2 237.807 
6 1 513.19 
6 1 741.267 
6 2 874.824 
6 4 670.875 
6 1 692.869 
6 0 685.742 
6 0 522.634 
2 0 275.455 
1 0 385.052 
2 0 378.885 
2 0 339.868 
1 1 291.822 
1 0 374.886 
1 4 328.496 
1 1 317.563 
4 0 265.138 
4 1 280.736 
4 1 179.157 
5 0 269.209 
6 0 377.78 
5 2 427.508 
3 4 322.063 
0 4 244.845 
0 0 492.225 
0 4 550.416 
0 4 561.596 
0 4 448.143 
2 1 382.771 
3 3 472.972 
5 2 606.479 
5 2 471.852 
4 3 534.71 
2 4 439.783 
0 0 433.454 
1 0 352.609 
4 1 367.033 
6 2 325.965 
6 3 620.143 
5 4 508.995 
3 4 434.954 
1 4 257.077 
2 1 310.261 
3 1 242.793 
3 1 342.636 
2 1 239.16 
1 1 290.901 
2 0 366.525 
3 0 460.242 
3 2 430.796 
3 4 428.846 
1 4 370.962 
2 0 392.733 
6 0 416.495 
3 2 341.452 
1 0 288.527 
1 0 311.844 
2 0 294.443 
2 0 260.72 
3 0 357.118 
4 1 403.636 
2 2 300.158 
2 0 280.565 
5 0 251.225 
5 2 491.143 
5 3 469.388 
4 2 455.304 
5 0 275.419 
5 1 479.465 
4 3 423.481 
5 3 335.911 
5 3 423.302 
2 1 417.915 
2 1 438.547 
1 4 364.594 
1 0 330.035 
3 0 352.623 
4 2 415.679 
3 3 283.311 
3 1 292.797 
3 1 272.896 
2 3 334.448 
2 4 342.28 
3 4 589.802 
1 3 437.364 
1 3 356.565 
0 3 380.151 
0 4 478.172 
1 4 352.172 
1 1 245.422 
3 2 158.405 
2 1 420.266 
3 0 482.095 
5 2 525.64 
5 4 415.179 
2 4 394.284 
1 0 702.416 
1 0 553.896 
2 3 543.39 
3 3 464.638 
3 3 409.2 
1 3 448.832 
2 0 275.202 
4 3 404.529 
4 4 406.703 
4 0 457.762 
6 0 308.378 
6 2 373.501 
5 3 307.928 
2 3 364.604 
1 0 406.755 
4 0 353.34 
5 0 346.752 
5 1 224.439 
3 1 598.847 
2 0 706.66 
4 0 538.467 
4 2 391.532 
3 4 298.052 
1 2 500.312 
4 0 478.601 
4 0 488.44 
1 3 481.081 
2 4 435.903 
0 3 513.047 
1 2 407.962 
3 4 317.447 
3 2 486.173 
3 3 438.161 
3 2 416.937 
6 3 378.164 
6 3 694.632 
6 4 676.703 
3 4 487.34 
2 4 541.615 
0 3 610.27 
0 2 526.989 
0 2 537.715 
5 2 507.414 
5 1 422.777 
3 3 374.728 
3 2 348.065 
4 2 301.012 
3 4 397.323 
2 2 301.739 
3 1 306.275 
3 1 334.583 
4 2 238.689 
4 2 320.984 
1 2 377.385 
1 3 407.516 
0 1 529.071 
2 0 576.142 
3 0 559.537 
3 1 474.204 
5 1 545.846 
6 1 579.736 
6 3 579.118 
5 4 457.75 
3 4 410.043 
4 4 378.809 
4 4 359.39 
1 2 365.885 
0 1 352.02 
0 1 339.918 
4 0 406.611 
6 0 456.708 
6 1 428.875 
5 2 528.109 
0 2 587.185 
0 2 517.324 
0 3 536.165 
3 4 444.062 
3 4 364.353 
1 2 303.04 
4 2 279.785 
4 3 314.97 
2 3 342.197 
3 3 242.729 
5 2 403.884 
6 1 462.277 
6 1 446.914 
6 1 329.485 
4 2 300.726 
4 1 328.505 
6 2 514.753 
5 3 416.036 
2 2 384.258 
5 1 341.788 
6 4 410.82 
6 4 561.378 
2 4 331.304 
1 4 536.655 
2 4 240.98 
3 4 437.293 
4 0 527.503 
5 0 289.166 
5 1 372.854 
5 1 488.262 
4 2 564.077 
4 3 505.297 
1 4 368.441 
0 4 302.336 
0 3 224.123 
1 2 208.707 
4 3 238.77 
4 4 251.621 
4 3 268.015 
4 3 457.473 
0 2 487.434 
0 2 424.412 
4 2 415.156 
4 4 391.845 
4 4 638.837 
4 4 508.797 
3 4 405.443 
1 3 229.596 
1 2 322.738 
3 4 474.786 
4 4 479.583 
4 4 428.408 
2 4 530.905 
3 4 574.887 
4 4 711.128 
4 3 607.315 
1 2 324.265 
0 3 320.162 
0 4 399.164 
0 3 306.359 
0 2 536.129 
0 2 650.975 
0 3 277.945 
0 4 254.07 
0 3 232.055 
0 3 308.22 
0 3 328.006 
0 3 206.005 
0 3 235.103 
0 1 385.647 
0 1 540.402 
0 2 513.711 
0 4 472.48 
0 0 546.102 
0 0 643.856 
0 0 571.183 
0 1 432.42 
0 2 558.547 
4 1 492.905 
4 2 353.194 
1 3 195.131 
1 2 239.218 
1 2 302.994 
4 2 415.312 
4 1 372.517 
4 2 369.946 
1 2 350.721 
3 0 451.089 
4 0 480.145 
0 2 482.008 
0 2 421.233 
0 2 495.688 
0 3 382.496 
0 3 356.893 
0 2 407.282 
0 2 556.571 
0 2 540.353 
1 3 311.922 
1 1 328.493 
1 2 416.973 
0 1 290.522 
0 4 357.167 
0 4 351.912 
0 4 603.908 
0 0 511.491 
0 0 460.075 
0 1 372.416 
0 1 263.988 
0 3 328.526 
1 4 466.711 
0 3 443.738 
0 1 275.378 
2 0 359.527 
1 0 307.469 
1 0 390.835 
1 0 653.436 
0 0 584.661 
0 0 790.461 
0 1 577.49 
0 2 402.268 
0 2 237.748 
0 3 238.426 
0 1 278.662 
0 1 261.98 
0 0 379.686 
0 1 409.828 
0 1 404.869 
0 4 367.339 
0 4 343.049 
0 3 377.61 
0 2 251.053 
0 3 240.652 
0 0 242.709 
0 0 262.373 
0 1 215.414 
0 1 257.181 
1 1 333.938 
1 2 303.456 
1 1 223.252 
1 2 249.349 
4 2 293.646 
5 2 339.812 
3 2 429.159 
2 3 360.055 
1 3 246.24 
0 3 289.58 
0 4 368.205 
0 0 308.962 
0 1 431.29 
0 2 472.764 
0 3 385.836 
0 2 295.23 
4 2 279.613 
4 3 340.297 
5 4 456.959 
2 3 330.311 
2 2 268.02 
2 3 307.849 
2 2 367.738 
1 2 362.363 
0 2 373.121 
1 2 344.097 
4 3 313.179 
3 4 286.932 
1 4 256.894 
1 2 375.493 
2 4 391.051 
1 4 406.896 
1 4 568.225 
0 4 439.815 
0 0 238.146 
0 1 378.37 
0 1 378.649 
0 1 348.411 
0 3 412.87 
0 3 445.253 
0 4 426.186 
0 3 345.081 
4 2 479.727 
5 1 431.792 
4 2 460.44 
1 2 401.832 
5 0 404.874 
6 1 384.738 
6 1 424.468 
6 2 642.17 
5 4 637.392 
5 4 499.732 
4 4 456.147 
3 4 421.218 
0 0 413.653 
0 0 405.006 
0 4 333.076 
0 4 319.938 
1 1 352.941 
0 3 353.302 
0 4 441.641 
0 4 602.039 
0 4 538.801 
0 3 431.228 
0 3 469.842 
0 3 444.37 
0 3 459.642 
0 2 462.945 
0 2 545.141 
0 2 546.807 
0 2 495.566 
5 4 298.994 
4 4 357.918 
4 4 366.312 
4 4 553.978 
5 1 454.779 
6 2 430.445 
4 3 518.874 
0 3 597.369 
0 3 520.221 
0 2 625.13 
5 2 617.31 
6 2 667.181 
6 2 841.104 
6 4 451.51 
6 4 354.433 
6 4 378.056 
5 3 309.592 
4 4 405.063 
0 2 432.78 
0 3 539.528 
0 3 575.57 
0 3 553.086 
0 3 569.752 
0 2 540.972 
0 2 437.496 
1 3 470.558 
2 3 381.875 
3 3 525.535 
6 1 466.916 
6 3 585.099 
5 4 611.791 
5 0 541.367 
6 1 290.812 
4 3 402.406 
4 0 740.505 
4 0 749.814 
5 1 858.025 
4 3 828.236 
4 4 795.258 
4 4 740.12 
5 4 663.418 
5 4 645.525 
4 3 542.722 
4 4 591.264 
5 4 934.623 
6 4 987.587 
4 4 880.937 
0 4 502.479 
2 4 514.947 
2 4 767.23 
2 4 693.007 
1 4 404.961 
1 4 488.406 
0 0 505.105 
1 0 301.598 
0 0 321.224 
0 0 219.026 
0 1 287.179 
0 0 361.248 
0 0 378.731 
0 1 363.458 
0 3 392.237 
0 2 414.305 
0 2 515.686 
4 2 431.441 
2 3 330.549 
2 3 411.526 
3 4 461.798 
0 3 713.558 
0 2 494.055 
5 0 529.007 
5 1 532.581 
5 3 404.387 
2 3 234.12 
2 4 303.46 
3 4 475.272 
1 2 439.443 
4 0 293.486 
6 0 359.404 
4 2 421.553 
1 1 360.465 
1 0 263.666 
0 1 339.938 
0 1 524.33 
0 1 669.479 
4 0 507.834 
6 0 485.925 
5 3 587.526 
4 4 342.768 
1 4 299.032 
0 0 346.772 
0 0 628.562 
4 0 641.315 
4 0 428.095 
5 0 519.729 
6 0 543.37 
4 0 742.171 
0 1 606.461 
3 0 505.365 
4 0 465.779 
3 2 352.97 
2 4 306.274 
2 4 385.356 
2 1 454.426 
5 0 433.202 
5 2 389.07 
6 1 279.074 
6 3 564.751 
6 4 768.164 
6 4 769.841 
5 4 710.207 
3 4 697.903 
2 4 518.556 
3 2 647.531 
5 1 368.662 
3 1 462.862 
3 1 509.65 
5 1 300.787 
5 1 309.061 
5 2 185.397 
5 4 336.016 
4 4 593.828 
5 3 581.574 
6 3 466.372 
6 4 549.521 
5 4 337.262 
3 3 331.742 
2 2 348.116 
2 4 362.372 
2 4 400.18 
2 0 319.277 
3 1 528.005 
5 3 486.533 
5 2 562.559 
5 2 224.075 
4 3 309.629 
4 3 372.907 
4 3 456.45 
4 3 408.61 
4 3 373.053 
4 4 355.431 
2 3 575.225 
2 2 274.648 
2 1 247.486 
2 0 341.739 
3 0 465.029 
3 1 332.059 
1 2 457.017 
0 2 624.604 
4 0 532.265 
4 2 463.839 
3 4 327.259 
0 2 602.773 
0 2 809.846 
5 1 742.97 
5 3 398.864 
5 2 578.444 
6 1 474.874 
5 2 472.848 
6 4 539.774 
6 4 726.347 
6 3 794.531 
6 2 565.089 
6 2 403.238 
6 2 474.506 
6 3 406.656 
6 4 598.259 
4 4 659.229 
4 4 481.636 
6 3 359.907 
6 3 675.4 
6 4 734.687 
6 4 351.456 
6 1 545.782 
6 1 473.783 
6 3 396.116 
6 4 412.283 
5 3 324.358 
5 2 256.068 
4 4 412.999 
5 4 307.455 
5 4 245.984 
5 4 311.503 
3 4 247.492 
2 4 179.612 
1 2 441.267 
4 0 230.972 
4 2 370.557 
4 2 307.419 
4 3 527.885 
0 3 297.425 
1 2 322.654 
4 3 423.711 
0 3 194.343 
0 1 175.758 
1 1 174.501 
1 2 259.676 
0 3 253.68 
1 3 351.246 
3 4 451.055 
1 2 397.414 
4 0 219.618 
4 0 284.78 
4 0 366.117 
0 2 438.944 
0 2 331.536 
0 2 406.654 
0 2 390.503 
4 0 570.929 
5 0 605.436 
5 0 594.45 
5 1 294.72 
3 1 173.211 
3 0 340.809 
3 0 412.257 
3 0 432.357 
4 1 342.068 
5 1 252.103 
5 2 361.643 
4 3 213.391 
2 3 259.352 
0 3 335.532 
0 0 429.429 
0 0 314.121 
1 3 238.981 
2 3 372.277 
4 3 294.351 
4 3 269.545 
5 2 389.735 
6 2 427.481 
5 2 397.413 
5 2 422.513 
3 2 261.835 
2 2 329.209 
2 3 332.108 
2 3 295.063 
2 2 292.981 
3 2 268.931 
4 0 328.399 
6 0 385.04 
5 0 456.97 
2 2 373.147 
1 3 402.202 
0 1 374.698 
0 1 389.158 
0 0 395.82 
0 0 393.501 
0 1 370.417 
0 2 394.661 
0 2 400.911 
0 2 324.59 
0 2 372.199 
0 2 474.185 
0 3 393.202 
0 3 339.579 
0 2 356.422 
1 2 567.463 
4 1 416.95 
4 0 341.576 
1 2 401.725 
0 3 287.015 
0 4 325.671 
0 0 241.557 
0 3 299.84 
0 1 397.148 
0 1 371.516 
0 2 306.021 
4 3 386.774 
4 4 640.395 
5 3 657.409 
5 4 333.638 
5 3 305.412 
4 2 266.088 
4 2 273.024 
4 3 316.344 
4 4 330.787 
3 4 367.094 
1 2 308.749 
1 1 236.551 
4 1 265.138 
6 2 475.621 
6 4 448.179 
5 4 436.995 
4 3 359.163 
3 2 414.512 
3 0 432.361 
4 0 485.073 
4 1 496.001 
4 0 465.289 
3 0 543.992 
4 0 645.416 
4 0 497.09 
4 3 414.932 
2 3 331.16 
1 2 268.081 
1 1 236.225 
1 0 214.641 
0 0 496.1 
0 0 459.533 
0 0 342.319 
0 4 230.301 
0 0 344.391 
0 1 409.209 
0 2 435.844 
4 3 398.128 
4 3 251.932 
4 4 278.805 
3 3 386.661 
2 2 229.398 
2 2 278.683 
1 4 362.77 
0 4 552.458 
0 0 380.597 
1 1 246.434 
3 2 346.638 
3 1 338.87 
4 1 431.409 
4 2 630.463 
0 3 486.484 
1 4 380.667 
1 4 379.262 
1 1 328.62 
1 3 431.281 
2 3 211.322 
4 0 252.482 
5 0 620.001 
4 2 889.205 
0 2 648.993 
3 4 583.18 
2 4 598.958 
0 4 435.804 
0 0 492.796 
4 0 647.042 
5 1 419.28 
3 1 312.131 
1 1 377.162 
1 4 326.669 
2 4 391.585 
2 4 253.508 
1 3 443.217 
4 4 754.68 
3 4 613.345 
0 4 504.613 
0 4 465.775 
0 1 361.416 
4 1 270.732 
5 1 246.274 
6 0 324.731 
6 0 294.507 
5 1 346.496 
6 0 323.109 
6 1 321.655 
6 1 327.074 
4 2 346.052 
2 1 369.928 
1 4 464.188 
2 0 366.283 
4 0 346.022 
2 1 281.345 
1 0 382.162 
1 1 198.718 
0 2 292.832 
1 2 382.568 
2 2 338.228 
2 2 312.95 
6 2 378.606 
6 3 442.525 
6 4 351.862 
5 4 426.845 
4 4 334.802 
5 1 371.892 
5 2 474.632 
4 1 635.215 
4 0 374.632 
2 1 380.345 
2 1 355.934 
3 0 322.999 
5 1 476.705 
3 3 461.313 
2 3 398.155 
2 4 374.817 
2 4 519.437 
2 4 603.707 
3 3 454.944 
4 2 409.872 
5 3 299.049 
6 3 648.053 
6 4 907.064 
5 4 743.474 
3 4 499.608 
3 3 541.21 
4 4 495.09 
3 4 280.962 
1 2 255.139 
1 2 320.292 
0 2 368.915 
4 2 421.619 
2 3 398.605 
2 2 463.045 
1 4 340.985 
0 3 296.265 
0 2 413.826 
4 2 594.988 
5 2 652.525 
6 3 493.307 
6 2 460.392 
3 2 474.468 
3 1 467.913 
6 2 353.907 
6 3 302.473 
6 3 328.867 
5 2 249.31 
6 1 234.389 
6 3 279.693 
6 1 473.928 
6 0 257.642 
5 1 377.801 
6 4 417.807 
6 4 577.613 
6 3 475.815 
5 4 350.833 
3 3 360.973 
0 3 608.802 
0 3 591.726 
4 4 698.785 
3 4 721.683 
1 4 518.476 
1 0 311.282 
4 0 279.534 
6 0 291.462 
5 2 401.99 
4 3 491.069 
4 3 400.321 
3 1 278.961 
2 1 384.671 
2 1 360.989 
0 4 416.017 
0 3 516.62 
0 3 544.347 
1 2 490.133 
4 3 434.851 
4 4 400.111 
3 1 568.618 
3 0 347.745 
4 0 216.111 
4 1 349.945 
4 4 774.306 
0 3 846.254 
0 1 818.923 
4 0 640.094 
6 1 603.527 
6 2 722.933 
6 3 508.163 
6 1 576.329 
6 1 733.521 
6 1 488.293 
6 3 377.152 
3 2 432.937 
6 0 284.811 
6 0 254.544 
6 1 312.93 
5 2 382.532 
3 2 437.691 
3 0 446.042 
4 1 543.382 
6 1 382.551 
5 3 543.509 
3 3 483.401 
3 1 385.761 
5 1 331.673 
6 0 402.706 
6 1 408.277 
6 4 325.672 
5 3 471.555 
5 4 563.632 
4 4 562.959 
1 3 450.522 
0 0 534.819 
2 0 365.218 
4 1 352.746 
6 1 278.714 
6 4 326.105 
3 2 323.942 
3 1 321.413 
3 2 442.97 
1 4 273.053 
0 0 462.051 
1 0 562.947 
2 0 527.16 
4 0 391.887 
6 2 363.325 
6 1 385.151 
6 1 309.226 
5 2 301.118 
6 3 370.39 
5 4 496.102 
5 3 404.11 
4 2 473.713 
4 3 705.151 
4 1 593.759 
5 3 434.716 
5 2 521.965 
5 2 588.773 
3 2 522.083 
6 2 470.355 
6 3 368.655 
6 3 301.592 
6 2 295.341 
5 4 481.745 
2 4 371.286 
3 3 320.574 
4 3 212.822 
3 3 304.668 
2 2 262.22 
3 3 259.361 
2 3 246.317 
1 3 249.16 
0 4 348.667 
0 1 352.906 
0 2 574.571 
0 3 719.534 
0 4 594.831 
0 4 430.561 
3 4 365.271 
2 4 426.81 
0 1 315.04 
4 0 353.005 
4 2 451.969 
3 3 246.405 
1 3 230.246 
0 4 284.091 
0 4 484.367 
0 4 586.285 
0 4 651.343 
0 4 613.073 
0 3 432.167 
1 2 358.372 
2 2 443.019 
1 2 364.998 
2 4 395.877 
3 4 355.263 
4 3 421.653 
3 2 329.106 
3 1 236.911 
3 2 256.768 
2 2 240.004 
2 1 264.222 
3 0 277.292 
4 1 308.278 
4 3 327.07 
3 3 455.115 
3 1 484.583 
5 2 430.641 
4 3 274.645 
4 2 181.135 
5 1 197.496 
6 2 460.076 
5 4 288.701 
3 4 356.199 
2 4 331.766 
2 4 268.097 
3 4 312.795 
0 4 381.917 
0 4 435.304 
0 1 335.876 
4 1 319.504 
4 2 329.877 
4 3 382.462 
1 1 297.894 
1 1 239.804 
2 2 209.178 
1 3 301.962 
0 3 414.248 
0 3 342.395 
1 4 290.61 
1 4 337.812 
1 3 285.488 
1 3 294.984 
2 3 403.89 
0 2 306.287 
1 2 304.069 
2 2 347.682 
3 3 305.705 
1 2 372.462 
2 1 306.483 
2 2 335.65 
2 2 377.634 
1 3 226.9 
1 1 394.546 
5 0 362.339 
5 1 500.436 
6 2 509.483 
3 2 397.404 
4 2 324.553 
4 3 262.918 
4 2 405.053 
6 3 501.708 
5 4 466.653 
4 4 397.274 
3 3 189.836 
2 1 226.197 
3 1 314.606 
5 2 366.398 
5 3 399.106 
4 4 380.535 
1 3 290.771 
1 1 335.356 
0 2 368.398 
0 4 287.984 
0 0 416.259 
0 0 288.154 
1 3 308.457 
1 2 299.705 
4 2 429.63 
3 3 430.65 
3 3 456.687 
3 3 526.475 
5 3 502.394 
4 4 436.7 
3 4 424.948 
3 4 498.768 
2 4 476.603 
0 4 449.623 
0 0 350.859 
0 0 382.37 
0 0 323.854 
0 2 421.867 
0 2 536.29 
3 4 507.248 
1 4 371.289 
1 4 328.997 
1 3 268.224 
1 3 312.869 
0 1 243.163 
0 1 316.679 
0 1 325.154 
0 1 361.844 
3 0 363 
4 1 367.925 
1 2 332.582 
0 0 327.793 
0 1 311.235 
4 0 426.693 
4 1 472.716 
1 2 501.832 
3 3 414.615 
3 3 399.709 
3 3 384.064 
3 3 343.517 
2 2 324.768 
2 1 365.083 
3 0 439.804 
2 2 478.458 
1 2 364.45 
1 3 379.846 
1 4 391.827 
1 0 415.943 
2 1 275.969 
3 1 416.889 
5 1 333.432 
5 2 457.156 
2 3 384.551 
0 4 433.992 
0 0 584.201 
0 0 634.725 
0 4 606.19 
0 4 553.313 
0 1 319.71 
1 1 399.671 
3 1 386.274 
3 2 353.241 
4 3 373.109 
3 2 397.689 
2 1 212.182 
3 0 230.961 
4 1 446.644 
2 3 398.353 
0 4 259.518 
0 0 387.46 
2 0 534.671 
3 0 521.758 
0 0 463.858 
0 4 436.107 
0 0 613.777 
0 0 533.441 
0 3 511.924 
1 4 383.201 
2 3 303.709 
2 2 345.775 
3 2 414.539 
6 2 366.567 
6 2 327.074 
4 3 591.418 
1 4 520.911 
1 4 386.333 
2 4 320.913 
1 4 224.092 
1 3 340.263 
3 1 352.179 
6 0 353.856 
6 1 485.669 
4 3 557.47 
0 2 341.41 
0 1 325.569 
0 3 403.965 
3 4 434.214 
3 4 492.301 
1 1 368.89 
1 0 445.897 
1 0 295.168 
2 0 163.897 
3 2 233.944 
2 3 197.953 
2 1 514.743 
3 0 455.186 
4 1 387.418 
1 2 350.662 
1 3 308.136 
1 4 347.061 
2 1 452.504 
3 1 336.046 
4 2 366.334 
5 4 334.397 
3 4 420.407 
2 3 368.265 
2 1 298.995 
2 2 436.757 
2 1 346.097 
4 1 355.027 
4 3 358.071 
3 4 341.778 
1 4 364.835 
1 3 295.986 
1 2 231.074 
2 2 340.201 
3 3 400.163 
2 2 320.114 
2 2 396.469 
3 1 387.883 
6 2 338.211 
6 4 480.944 
6 4 563.487 
5 3 666.189 
5 2 493.748 
6 0 433.188 
6 0 661.068 
6 1 839.672 
6 3 467.737 
6 4 381.433 
4 4 503.084 
3 4 652.045 
6 4 520.803 
6 4 503.274 
3 4 377.73 
2 2 354.753 
3 2 373.946 
5 2 412.269 
6 2 224.212 
6 3 256.8 
4 4 324.53 
2 4 418.774 
2 4 468.978 
5 0 417.854 
6 1 300.16 
5 1 401.332 
6 0 488.162 
3 2 495.584 
5 0 550.434 
6 0 506.465 
6 2 580.337 
5 4 506.199 
0 3 507.505 
0 2 291.142 
4 2 319.035 
4 3 338.382 
4 4 280.001 
4 3 347.762 
4 4 474.192 
0 3 430.479 
4 0 590.675 
6 0 588.902 
4 0 426.504 
2 0 328.458 
1 0 339.839 
0 0 352.877 
1 0 306.024 
3 0 379.592 
4 1 368.517 
3 3 365.789 
4 1 457.097 
4 3 571.656 
0 4 688.496 
0 3 611.38 
4 2 435.772 
5 4 359.192 
3 3 388.662 
5 1 298.836 
6 2 454.266 
5 2 293.154 
3 2 663.881 
6 2 564.772 
6 3 575.508 
6 3 249.639 
3 4 557.036 
2 4 537.776 
1 0 573.829 
1 0 410.005 
2 0 488.733 
1 0 428.552 
2 0 476.599 
2 0 381.014 
0 2 475.78 
0 2 598.246 
0 2 561.94 
0 2 520.422 
4 0 546.218 
5 0 503.379 
6 1 491.576 
6 2 643.575 
6 3 634.497 
6 3 444.249 
6 2 613.124 
6 3 793.74 
6 4 635.81 
5 4 703.214 
5 1 415.953 
6 3 307.493 
6 4 265.984 
5 2 389.676 
4 3 352.386 
3 1 410.925 
6 0 477.384 
6 1 545.659 
6 0 407.621 
5 1 680.784 
5 1 954.208 
5 3 843.28 
6 3 539.128 
6 2 520.457 
5 2 329.526 
3 2 374.328 
5 4 557.753 
5 4 565.065 
5 3 490.171 
6 3 364.159 
6 4 406.189 
5 3 317.466 
5 4 274.456 
6 4 452.423 
6 1 548.173 
6 2 578.058 
6 2 575.406 
6 2 520.693 
6 2 553.76 
6 2 353.741 
6 1 616.94 
6 2 684.612 
5 3 285.875 
3 2 308.298 
4 2 300.678 
5 3 384.235 
5 3 468.356 
6 3 572.565 
6 3 952.029 
6 4 506.952 
3 4 364.903 
1 0 518.669 
2 0 210.867 
3 1 392.858 
3 1 466.423 
3 1 356.634 
2 1 356.087 
2 3 312.518 
2 3 229.725 
3 2 286.695 
3 3 363.107 
3 2 419.053 
5 3 490.217 
6 4 429.565 
5 4 432.535 
3 3 476.585 
3 1 456.864 
3 2 477.2 
3 4 352.436 
0 3 282.34 
0 3 351.291 
4 4 455.086 
4 4 478.93 
4 4 406.218 
3 4 457.987 
0 4 293.882 
0 4 264.05 
0 4 404.726 
0 0 493.885 
0 0 443.453 
0 1 369.447 
0 2 586.48 
4 4 788.79 
0 3 730.007 
0 3 495.971 
2 3 329.279 
3 2 213.132 
3 2 462.563 
4 2 560.448 
4 2 381.355 
5 4 265.07 
4 4 247.799 
3 4 260.755 
3 4 371.288 
4 3 384.71 
4 1 317.264 
4 2 402.502 
0 3 449.532 
0 3 409.56 
0 3 387.48 
3 4 487.009 
4 1 494.918 
5 2 430.422 
4 3 327.43 
3 2 289.645 
2 3 282.301 
1 3 372.191 
4 0 320.537 
4 1 323.223 
3 3 261.376 
1 3 233.449 
1 2 285.63 
4 4 346.031 
2 4 290.17 
1 0 327.251 
2 1 360.426 
4 3 441.28 
4 4 515.975 
3 4 636.218 
2 4 516.028 
1 4 433.646 
0 4 347.653 
0 4 365.326 
0 4 446.776 
0 3 355.431 
0 2 267.724 
4 3 385.927 
4 4 396.425 
3 4 304.964 
3 4 286.428 
3 4 308.192 
1 3 361.776 
1 2 314.463 
1 1 249.334 
2 1 269.195 
2 2 157.135 
3 1 247.025 
3 1 213.274 
3 1 234.174 
4 0 324.028 
4 1 310.821 
2 0 273.938 
1 1 349.289 
1 1 293.885 
3 0 435.242 
3 1 450.784 
3 0 392.08 
0 1 666.155 
0 2 814.442 
0 2 662.02 
0 3 548.55 
0 2 491.318 
0 2 479.479 
0 2 431.422 
3 2 235.915 
2 3 432.342 
2 4 270.743 
2 2 259.38 
2 0 234.385 
2 0 337.88 
2 2 439.488 
2 3 267.435 
1 3 331.323 
1 3 405.096 
1 3 356.656 
2 0 147.318 
4 0 232.066 
4 1 261.665 
3 3 284.73 
1 2 221.985 
1 1 279.805 
0 1 325.247 
0 1 373.712 
0 1 291.63 
0 1 232.318 
0 1 369.806 
0 2 319.848 
1 2 352.557 
4 0 455.404 
0 2 505.665 
0 2 514.242 
4 0 533.764 
4 0 511.309 
4 1 437.542 
4 1 362.382 
3 1 370.104 
4 0 465.676 
1 1 390.93 
0 0 418.666 
0 0 473.649 
1 3 409.963 
1 1 220.671 
1 3 321.621 
1 2 263.191 
4 2 470.375 
0 3 316.188 
0 0 248.37 
0 4 336.581 
0 4 305.441 
0 3 292.88 
0 3 289.532 
0 1 292.309 
0 2 438.453 
5 1 309.276 
5 1 259.539 
1 2 349.326 
1 1 338.272 
0 0 252.256 
1 1 292.705 
3 1 307.577 
4 2 380.183 
1 3 353.355 
1 3 274.906 
4 3 384.571 
4 4 329.762 
2 3 270.29 
3 3 223.432 
2 3 185.72 
1 3 237.492 
3 4 244.735 
3 2 312.348 
6 3 417.324 
4 3 365.735 
3 1 257.737 
4 0 349.379 
0 0 662.228 
0 0 690.553 
0 0 503.395 
1 2 525.706 
1 2 239.558 
1 1 251.018 
4 1 362.407 
4 2 298.132 
4 1 274.507 
4 1 423.573 
0 2 512.855 
0 3 504.389 
0 4 556.23 
0 4 506.385 
0 4 524.479 
0 0 560.005 
0 0 704.571 
0 0 770.269 
0 0 704.698 
0 0 563.402 
1 0 462.366 
1 0 287.093 
1 3 450.311 
1 4 371.436 
0 4 228.044 
0 1 234.48 
0 1 311.682 
0 4 383.696 
1 4 260.555 
4 3 259.377 
4 3 316.453 
3 4 425.157 
0 2 358.342 
4 1 384.524 
3 4 295.152 
2 3 380.821 
3 3 491.966 
5 4 426.363 
5 4 265.861 
3 2 244.356 
3 0 318.136 
3 0 550.738 
4 0 474.027 
1 3 293.174 
1 0 272.386 
3 0 482.335 
5 0 388.775 
5 1 435.342 
5 3 326.907 
5 4 244.565 
4 4 612.065 
2 3 616.169 
2 3 397.261 
4 3 581.86 
4 4 475.343 
3 4 454.829 
1 4 376.723 
2 3 351.527 
5 3 194.088 
5 4 396.162 
3 1 346.244 
3 0 414.444 
3 0 629.599 
4 2 440.729 
5 3 706.706 
6 0 705.842 
6 1 514.308 
6 2 231.701 
6 3 314.543 
6 2 683.134 
6 3 604.976 
6 3 602.255 
6 2 866.493 
6 2 885.518 
6 3 596.357 
4 3 465.087 
5 0 373.715 
6 0 338.719 
5 1 511.785 
3 2 312.508 
3 2 353.794 
3 2 367.782 
5 2 396.01 
6 2 466.002 
6 3 528.573 
6 4 392.236 
4 2 389.636 
5 2 357.912 
5 4 520.026 
3 4 813.526 
2 4 650.872 
2 2 608.829 
3 2 609.001 
3 2 531.629 
5 2 329.361 
6 3 322.074 
4 4 344.029 
2 1 335.043 
3 1 340.083 
3 1 505.685 
6 0 430.8 
3 0 639.495 
5 0 597.316 
5 0 535.328 
6 2 592.629 
5 4 420.849 
2 3 448.694 
3 4 486.822 
2 4 522.553 
1 4 435.681 
0 4 459.899 
1 2 408.832 
3 3 320.578 
3 4 479.877 
3 3 344.51 
5 1 525.039 
6 2 742.028 
6 3 836.655 
6 4 518.417 
3 4 560.658 
2 4 516.378 
2 3 390.171 
2 0 415.013 
5 0 455.842 
6 1 396.371 
6 3 328.445 
3 4 440.323 
2 4 497.2 
2 4 508.23 
2 2 360.539 
3 3 400.958 
3 4 504.79 
4 0 529.057 
5 0 418.451 
4 2 514.483 
0 2 477.114 
0 2 383.138 
0 4 385.756 
0 0 505.089 
1 4 351.738 
0 4 345.733 
0 0 227.888 
0 1 364.302 
3 0 423.694 
3 2 314.479 
1 4 326.676 
0 0 538.405 
1 0 271.763 
4 0 383.019 
5 1 513.893 
5 2 553.167 
5 3 596.504 
4 4 715.39 
4 4 917.711 
4 4 1038.16 
6 0 964.618 
6 0 498.953 
6 1 442.622 
6 3 566.966 
0 3 675.889 
0 4 606.924 
0 4 623.715 
0 0 459.069 
1 0 271.795 
2 0 216.505 
2 0 352.098 
3 0 612.827 
3 1 523.644 
3 2 573.871 
3 3 695.154 
3 3 531.297 
5 4 368.238 
4 2 378.069 
5 2 491.144 
3 2 534.356 
3 1 574.116 
3 1 631.955 
3 2 522.782 
5 1 613.78 
6 2 517.587 
5 4 384.119 
3 4 367.208 
2 4 308.695 
1 1 475.873 
0 0 385.962 
3 0 487.678 
4 0 380.73 
1 2 479.386 
0 2 401.605 
0 3 486.15 
0 3 505.934 
0 3 404.675 
0 4 443.967 
0 4 506.639 
1 4 471.415 
1 4 402.268 
1 3 385.331 
2 1 258.75 
5 3 352.345 
6 4 385.023 
6 4 352.934 
3 4 439.711 
0 4 498.258 
0 4 461.702 
0 4 430.156 
0 3 540.4 
3 3 521.916 
4 4 593.373 
0 3 622.589 
0 1 510.494 
0 3 451.424 
0 4 430.343 
0 0 383.088 
0 0 406.736 
1 1 372.948 
1 3 369.857 
1 4 304.785 
0 0 363.69 
0 0 227.854 
1 1 256.196 
3 0 267.583 
4 1 290.812 
3 3 364.213 
3 4 471.849 
1 3 418.588 
2 1 403.434 
3 2 384.505 
2 4 311.014 
1 4 394.937 
0 4 374.894 
0 2 334.388 
4 3 415.837 
3 4 512.336 
0 3 571.995 
4 1 459.075 
6 3 260.46 
4 2 423.7 
4 4 724.437 
3 4 720.146 
2 4 612.278 
1 4 473.602 
3 4 484.288 
5 4 535.582 
4 4 431.469 
3 4 316.974 
3 3 287.305 
0 3 296.682 
0 4 322.338 
0 2 412.277 
0 2 506.428 
1 2 411.922 
1 3 355.552 
1 1 474.081 
1 1 369.386 
0 2 305.726 
0 2 267.447 
1 1 309.073 
1 4 289.693 
0 0 245.655 
0 0 199.01 
0 1 274.957 
0 1 377.072 
1 1 288.394 
3 0 321.752 
4 2 332.614 
3 2 214.573 
3 2 315.385 
1 3 319.813 
1 3 378.255 
3 2 394.317 
5 3 304.505 
4 3 261.187 
5 3 272.857 
5 4 223.576 
4 4 258.216 
5 3 330.915 
6 3 528.651 
6 3 427.502 
5 3 196.845 
4 2 292.357 
1 2 216.461 
0 3 251.357 
0 3 346.828 
0 2 348.989 
4 0 360.427 
4 1 243.261 
4 1 333.016 
4 2 451.279 
6 4 437.971 
5 4 366.106 
2 2 361.227 
2 2 254.904 
2 2 293.878 
2 1 362.919 
2 1 283.576 
3 0 330.482 
1 2 287.528 
0 1 276.624 
4 0 539.253 
5 1 656.507 
4 1 573.171 
0 2 497.112 
2 4 429.898 
1 3 269.937 
1 4 276.223 
0 0 606.533 
1 1 462.38 
3 1 288.388 
4 0 272.721 
3 1 347.638 
1 2 276.784 
1 3 173.409 
1 1 345.545 
3 0 489.383 
0 1 518.304 
0 1 443.672 
0 1 493.982 
0 2 442.001 
0 2 426.911 
0 2 398.698 
0 2 410.971 
4 0 388.471 
4 0 448.721 
0 1 475.437 
1 0 337.91 
1 0 409.761 
0 0 478.752 
0 1 448.665 
0 3 569.95 
1 4 623.464 
0 4 351.652 
0 3 298.645 
1 2 321.283 
1 2 301.038 
4 2 260.491 
1 2 434.013 
1 3 198.294 
1 0 298.657 
0 0 327.217 
0 2 251.353 
0 2 226.481 
0 3 209.798 
0 4 251.086 
0 4 480.783 
0 4 495.219 
1 4 416.842 
1 1 254.115 
1 1 287.936 
1 1 217.788 
2 1 313.494 
1 3 294.747 
1 1 275.278 
1 1 367.926 
1 0 281.128 
1 1 278.709 
0 1 245.078 
1 0 304.568 
1 0 350.154 
1 3 509.699 
0 4 295.286 
0 2 410.602 
1 2 400.047 
2 2 332.695 
1 2 405.367 
1 4 323.062 
1 4 293.167 
1 1 298.671 
3 1 286.982 
2 2 347.19 
0 4 315.224 
0 3 401.497 
0 3 239.973 
0 3 347.422 
2 0 376.38 
1 1 335.108 
1 2 312.411 
1 3 405.64 
3 4 513.008 
0 3 400.427 
0 4 264.973 
0 4 247.361 
1 4 348.718 
1 4 325.528 
0 0 337.928 
1 1 256.933 
2 0 270.943 
2 1 320.301 
4 3 377.243 
4 4 438.027 
0 4 518.612 
0 4 794.505 
0 0 591.778 
0 2 368.726 
3 4 351.307 
2 4 201.369 
2 3 383.443 
1 4 345.288 
0 0 485.97 
0 0 491.692 
0 0 466.568 
0 1 384.471 
0 2 403.356 
0 2 441.505 
4 3 485.533 
4 3 325.891 
4 3 264.082 
3 3 396.668 
3 3 534.231 
5 4 498.364 
4 4 681.052 
2 4 379.228 
1 4 538.725 
0 4 408.714 
0 4 365.891 
0 0 487.665 
0 0 509.863 
4 0 425.912 
5 2 326.906 
6 1 295.033 
4 2 427.358 
3 2 370.185 
5 0 372.513 
4 2 470.204 
3 0 385.515 
2 1 440.06 
2 0 553.754 
3 0 472.632 
5 1 401.697 
5 2 286.951 
6 2 322.269 
4 3 396.708 
5 1 436.589 
6 1 546.836 
6 2 379.435 
4 2 410.833 
0 3 425.893 
0 1 481.279 
0 2 615.457 
4 4 696.227 
4 4 701.949 
0 3 380.8 
0 2 254.077 
0 2 308.83 
0 3 371.088 
0 0 308.002 
1 1 311.653 
2 1 352.855 
5 2 564.496 
6 3 485.086 
6 3 323.02 
5 3 434.508 
5 4 564.929 
4 2 370.727 
2 3 269.333 
2 1 496.42 
2 2 548.384 
2 1 438.451 
5 0 382.283 
5 2 591.199 
3 4 513.841 
2 3 453.572 
2 1 359.851 
3 2 386.22 
3 3 411.851 
2 3 309.67 
2 4 265.759 
2 4 355.185 
2 4 351.16 
2 3 349.781 
2 3 446.495 
0 4 540.67 
1 0 472.713 
2 3 392.809 
2 4 264.611 
2 1 342.007 
6 0 367.047 
5 3 536.639 
3 3 474.358 
1 2 431.306 
4 0 494.06 
5 1 405.12 
6 2 442.243 
5 2 383.926 
4 1 414.581 
2 2 474.382 
1 4 434.04 
0 4 412.171 
0 2 583.732 
0 3 599.495 
0 3 445.286 
1 2 460.698 
4 2 338.993 
5 2 278.517 
6 1 410.452 
6 3 544.567 
6 4 396.901 
3 3 464.492 
3 2 344.543 
4 1 547.695 
6 1 354.612 
5 3 476.93 
3 1 526.019 
3 0 386.034 
3 1 354.907 
5 4 457.155 
4 4 385.233 
3 3 291.383 
6 1 342.858 
6 2 579.271 
6 2 444.724 
6 0 510.951 
2 2 549.277 
2 3 469.436 
2 2 296.641 
0 3 281.95 
0 3 287.276 
1 3 374.04 
1 3 338.331 
0 0 402.201 
0 0 462.816 
0 0 545.36 
1 0 430.124 
3 0 307.88 
5 0 325.239 
3 1 371.371 
1 3 510.221 
0 3 499.105 
0 3 507.762 
0 4 515.534 
1 4 495.189 
0 0 616.238 
1 0 379.484 
3 0 427.807 
5 1 390.673 
5 1 341.204 
6 1 295.477 
4 3 540.476 
1 4 579.258 
1 4 492.201 
1 4 629.192 
1 0 561.223 
2 2 369.078 
4 3 313.436 
4 4 393.195 
2 4 456.157 
1 4 473.992 
2 0 425.148 
4 0 427.827 
5 1 449.758 
5 0 547.261 
3 0 536.253 
3 0 502.268 
3 1 390.668 
1 1 438.372 
5 0 503.308 
5 0 290.254 
4 1 378.946 
4 1 394.276 
5 1 344.817 
5 2 362.109 
3 1 593.128 
3 2 613.227 
3 2 741.46 
3 2 731.242 
5 3 750.174 
3 3 634.5 
4 3 465.404 
3 2 481.875 
5 1 489.124 
5 1 415.399 
4 1 349.199 
4 2 324.906 
3 2 404.534 
3 0 297.234 
2 0 341.237 
1 0 551.958 
1 0 427.894 
2 3 338.731 
2 4 268.818 
2 4 260.216 
2 1 369.342 
2 1 277.643 
1 4 524.272 
0 0 630.667 
1 0 481.651 
2 0 371.663 
1 2 309.036 
4 3 327.418 
4 4 435.823 
3 4 609.346 
2 4 533.267 
0 0 464.697 
1 0 421.376 
1 0 365.104 
4 0 344.133 
3 1 330.329 
3 2 391.041 
3 2 369.977 
5 3 233.441 
5 2 346.589 
5 2 328.881 
5 4 293.481 
5 4 292.299 
4 3 343.416 
5 3 284.625 
5 4 295.926 
5 1 334.151 
5 2 448.617 
5 3 607.891 
5 4 433.444 
3 4 435.355 
3 4 431.729 
5 4 324.211 
4 4 465.433 
0 3 413.943 
1 4 286.057 
1 4 420.027 
2 1 429.956 
2 2 313.97 
2 3 309.627 
1 4 339.787 
1 4 355.853 
1 4 419.296 
1 1 450.751 
1 1 314.696 
2 1 278.356 
3 2 301.676 
3 2 426.933 
3 3 413.462 
4 4 288.337 
4 4 379.58 
4 3 350.462 
5 2 328.098 
5 3 212.002 
3 2 256.507 
3 2 332.151 
2 2 333.834 
3 2 374.271 
5 3 416.761 
5 4 458.945 
3 2 461.631 
3 2 402.796 
2 3 345.583 
2 2 302.286 
2 1 277.902 
1 0 409.226 
0 0 683.856 
1 0 488.994 
1 0 299.382 
1 0 386.612 
2 1 508.921 
2 1 446.549 
1 0 567.388 
2 1 563.881 
2 2 387.534 
2 3 341.188 
1 4 461.337 
1 4 455.755 
1 4 303.123 
0 4 309.791 
0 0 328.237 
0 1 291.774 
1 3 421.656 
1 4 344.351 
0 4 444.558 
0 4 483.788 
0 4 299.072 
1 4 280.273 
0 4 254.451 
1 4 299.804 
1 3 350.425 
2 2 281.627 
4 2 332.218 
4 4 344.416 
3 1 340.159 
3 1 465.608 
2 2 458.562 
1 0 453.772 
1 0 517.355 
0 0 549.01 
1 0 447.687 
1 1 377.496 
0 2 288.196 
0 3 345.084 
0 0 434.919 
0 0 461.457 
0 4 667.208 
0 0 732.27 
0 0 595.682 
0 0 508.121 
0 3 445.722 
0 4 375.085 
0 3 368.903 
0 2 420.747 
1 2 534.309 
0 4 499.313 
0 4 702.344 
0 0 364.863 
0 2 425.097 
3 3 472.253 
3 3 288.709 
3 3 282.184 
3 1 278.046 
3 0 256.509 
3 0 243.822 
1 2 480.311 
3 3 333.247 
2 3 213.094 
2 0 453.532 
2 1 564.451 
2 3 333.565 
1 3 303.307 
1 0 309.153 
2 0 413.975 
1 1 415.215 
1 2 403.721 
1 2 341.335 
2 2 281.032 
0 3 333.657 
0 4 365.746 
1 0 292.539 
1 3 466.387 
1 4 336.401 
1 4 368.421 
0 4 392.178 
1 1 369.369 
3 1 345.327 
5 3 443.406 
5 4 475.058 
2 4 481.232 
0 4 333.428 
0 3 355.28 
0 3 322.968 
1 0 325.233 
5 0 454.678 
5 1 579.045 
4 2 512.303 
5 1 464.042 
5 1 391.345 
4 1 330.281 
5 2 291.311 
5 3 335.009 
2 3 395.328 
1 0 478.008 
2 4 360.081 
0 4 665.867 
0 4 873.315 
0 4 712.25 
1 4 383.76 
1 4 407.646 
2 0 317.031 
2 1 410.173 
2 1 319.702 
2 0 276.115 
2 0 462.707 
2 0 534.898 
1 4 548.162 
1 4 507.278 
2 2 330.46 
4 1 484.743 
6 1 270.516 
6 1 343.61 
5 2 308.551 
5 0 435.291 
4 1 401.756 
3 2 440.993 
5 3 687.833 
6 3 530.826 
6 4 532.089 
4 4 267.771 
3 3 388.599 
4 4 302.52 
3 4 469.295 
3 4 565.222 
2 4 412.837 
1 4 477.39 
0 4 561.087 
0 0 681.167 
0 0 501.306 
1 0 410.33 
2 0 356.262 
0 1 465.17 
0 1 389.531 
2 0 342.499 
2 1 576.399 
2 4 449.894 
2 0 510.615 
3 0 517.987 
2 1 525.644 
1 0 455.325 
1 0 399.115 
2 0 422.374 
2 1 583.77 
1 3 599.466 
1 4 563.12 
2 3 482.526 
2 3 474.398 
2 0 357.286 
3 0 344.528 
3 0 394.769 
4 0 582.512 
3 0 543.295 
2 0 387.387 
1 1 345.332 
1 4 284.931 
1 4 379.22 
1 4 499.878 
2 3 590.386 
2 0 504.849 
5 1 550.671 
5 3 386.772 
3 4 443.438 
2 3 566.373 
3 0 405.051 
6 0 536.962 
6 1 562.504 
5 2 392.656 
5 1 345.411 
5 1 312.142 
5 1 322.368 
4 2 340.354 
2 3 370.73 
1 0 438.697 
2 0 460.43 
2 0 330.057 
3 0 329.303 
5 0 572.65 
5 2 541.81 
5 3 447.293 
5 1 527.096 
6 1 500.444 
6 3 476.915 
2 4 336.552 
1 0 468.017 
2 0 371.689 
6 0 415.748 
4 2 395.24 
3 2 353.124 
2 3 517.555 
2 4 567.628 
1 0 691.753 
2 0 459.717 
1 0 470.414 
2 0 485.905 
5 0 369.423 
5 1 337.551 
3 2 246.472 
3 0 286.845 
3 0 482.397 
5 2 523.204 
5 2 347.111 
5 3 322.326 
5 3 359.52 
5 4 385.251 
3 4 531.635 
0 4 699.32 
0 0 919.854 
0 1 875.817 
0 2 717.509 
0 3 682.333 
0 3 644.573 
0 1 526.769 
2 0 540.573 
3 0 396.45 
4 2 497.692 
4 2 636.85 
3 2 592.264 
3 3 431.244 
2 2 413.645 
2 1 514.997 
2 1 622.402 
2 3 499.46 
3 0 564.102 
6 0 292.936 
6 0 285.7 
6 2 382.227 
3 2 479.762 
1 4 591.917 
1 4 506.495 
2 3 331.85 
4 3 274.812 
3 3 484.574 
5 1 339.647 
5 2 441.865 
3 2 667.232 
3 3 644.561 
3 3 490.88 
2 3 516.302 
2 0 483.486 
2 0 560.597 
2 1 585.432 
3 0 747.159 
6 0 730.475 
2 1 631.566 
1 4 502.919 
1 4 268.061 
2 1 248.24 
6 0 369.358 
5 1 428.202 
4 2 451.247 
5 2 456.706 
4 3 552.501 
1 4 563.586 
0 0 584.854 
1 1 449.004 
2 3 379 
2 0 352.222 
5 0 428.633 
5 2 633 
2 3 416.059 
1 0 450.166 
2 0 331.287 
3 2 253.472 
5 2 305.847 
5 3 387.883 
4 3 439.633 
5 4 338.663 
5 4 621.637 
6 1 344.476 
6 2 336.469 
6 3 379.188 
6 4 528.787 
5 4 396.971 
3 4 478.1 
0 3 551.345 
0 0 676.651 
0 0 651.435 
4 0 644.044 
5 3 637.84 
6 4 410.528 
5 3 378.479 
5 2 376.324 
6 0 505.456 
6 2 488.991 
3 3 532.341 
2 4 435.865 
2 1 401.006 
4 2 464.013 
4 4 463.282 
3 4 486.504 
1 3 330.39 
1 1 334.984 
3 0 391.029 
4 0 309.588 
1 1 531.062 
1 1 528.875 
3 0 425.204 
3 0 370.54 
4 0 405.692 
2 1 279.913 
2 2 373.431 
3 2 428.35 
6 4 347.05 
5 4 467.973 
3 4 418.412 
3 1 552.775 
5 0 395.535 
3 1 572.787 
3 3 458.335 
2 2 403.352 
2 2 356.793 
2 3 402.795 
3 3 358.041 
3 4 238.252 
4 4 320.614 
5 4 455.606 
5 4 601.579 
3 4 537.783 
2 4 299.376 
3 3 369.497 
4 4 343.827 
3 4 572.83 
4 4 751.366 
4 4 344.068 
4 4 365.593 
3 4 390.874 
1 1 428.928 
2 2 326.028 
3 3 212.745 
1 2 324.327 
3 1 309.437 
3 2 181.829 
3 2 217.748 
3 3 365.62 
3 4 414.621 
3 3 324.896 
3 1 363.88 
3 2 320.809 
2 3 307.065 
3 1 232.829 
3 1 426.32 
5 1 500.472 
5 3 345.142 
4 4 228.921 
2 3 194.438 
2 2 211.799 
2 3 192.72 
3 2 239.856 
4 2 356.93 
3 3 388.566 
3 2 361.674 
3 1 278.056 
4 1 255.244 
5 2 267.929 
6 1 254.571 
6 1 295.571 
6 2 288.031 
6 4 291.766 
3 3 301.846 
2 2 208.231 
1 1 206.652 
1 2 238.341 
2 1 291.671 
2 0 265.166 
2 0 262.26 

From samimist at live.com  Tue Jan 31 17:48:11 2017
From: samimist at live.com (Md Sami Bin Shokrana)
Date: Tue, 31 Jan 2017 16:48:11 +0000
Subject: [R] sub-setting rows based on dates in R
Message-ID: <KL1PR01MB0999FC07E36B092AFAD82C44B64A0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>

Hello guys, I am trying to solve a problem in R. I have 2 data frames which look like this:
df1 <-
  Date    Rainfall_Duration
6/14/2016       10
6/15/2016       20
6/17/2016       10
8/16/2016       30
8/19/2016       40

df2 <-
  Date    Removal.Rate
6/17/2016    64.7
6/30/2016    22.63
7/14/2016    18.18
8/19/2016    27.87

I want to look up the dates from df2 in df1 and their corresponding Rainfall_Duration data. For example, I want to look for the 1st date of df2 in df1 and subset rows in df1 for that specific date and 7 days prior to that. additionally, for example: for 6/30/2016 (in df2) there is no dates available in df1 within it's 7 days range. So, in this case I just want to extract the results same as it's previous date (6/17/2016) in df2. Same logic goes for 7/14/2016(df2).
The output should look like this:

df3<-

Rate.Removal.Date      Date             Rainfall_Duration
6/17/2016              6/14/2016              10
6/17/2016              6/15/2016              20
6/17/2016              6/17/2016              10
6/30/2016              6/14/2016              10
6/30/2016              6/15/2016              20
6/30/2016              6/17/2016              10
7/14/2016              6/14/2016              10
7/14/2016              6/15/2016              20
7/14/2016              6/17/2016              10
8/19/2016              8/16/2016              30
8/19/2016              8/19/2016              40

I could subset data for the 7 days range. But could not do it when no dates are available in that range. I have the following code:
library(plyr)
library (dplyr)
df1$Date <- as.Date(df1$Date,format = "%m/%d/%Y")
df2$Date <- as.Date(df2$Date,format = "%m/%d/%Y")

df3 <- lapply(df2$Date, function(x){
  filter(df1, between(Date, x-7, x))
})

names(df3) <- as.character(df2$Date)
bind_rows(df3, .id = "Rate.Removal.Date")
df3 <- ldply (df3, data.frame, .id = "Rate.Removal.Date")

I hope I could explain my problem properly. I would highly appreciate if someone can help me out with this code or a new one. Thanks in advance.




	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Tue Jan 31 22:34:24 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Tue, 31 Jan 2017 21:34:24 +0000 (UTC)
Subject: [R] filter correlation data
References: <1267128747.1264722.1485898464009.ref@mail.yahoo.com>
Message-ID: <1267128747.1264722.1485898464009@mail.yahoo.com>

hello everybody,I have a very very huge table in R from calculating correlation,how can I filter it per spearman correlation and p-value before export it,I mean what is the function that I use?I want to select the pairs for value (r), , greater than 0.9 (directly correlated) and less than -0.9 (inversely corerlated), and a p-value < 0.001


I should say that I?transformed the big matrix in a table by library(reshape).
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jan 31 23:04:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 Jan 2017 14:04:58 -0800
Subject: [R] filter correlation data
In-Reply-To: <1267128747.1264722.1485898464009@mail.yahoo.com>
References: <1267128747.1264722.1485898464009.ref@mail.yahoo.com>
	<1267128747.1264722.1485898464009@mail.yahoo.com>
Message-ID: <CAGxFJbQJXDeEkFdWunyObtR-i3Fe6nyzvMZmtUh8xD0kEjsFWA@mail.gmail.com>

... And why did you not do a web search on "correlation coefficient in
R", which would have led you almost imediately to ?cor and friends?

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 31, 2017 at 1:34 PM, Elham - via R-help
<r-help at r-project.org> wrote:
> hello everybody,I have a very very huge table in R from calculating correlation,how can I filter it per spearman correlation and p-value before export it,I mean what is the function that I use?I want to select the pairs for value (r), , greater than 0.9 (directly correlated) and less than -0.9 (inversely corerlated), and a p-value < 0.001
>
>
> I should say that I transformed the big matrix in a table by library(reshape).
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Tue Jan 31 23:27:25 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 31 Jan 2017 16:27:25 -0600
Subject: [R] Failure to understand namespaces in XML::getNodeSet
In-Reply-To: <C93BCEFF-3EB2-4422-8BDF-9B305E393424@txbiomed.org>
References: <C93BCEFF-3EB2-4422-8BDF-9B305E393424@txbiomed.org>
Message-ID: <CABdHhvHNcQBE+YLq-V6PP9AYhBAB1Wo8DbcmELpTZovFonsCgw@mail.gmail.com>

See the last example in ?xml2::xml_find_all or use xml2::xml2::xml_ns_strip()

Hadley

On Tue, Jan 31, 2017 at 9:43 AM, Mark Sharp <msharp at txbiomed.org> wrote:
> I am trying to read a series of XML files that use a namespace and I have failed, thus far, to discover the proper syntax. I have a reproducible example below. I have two XML character strings defined: one without a namespace and one with. I show that I can successfully extract the node using the XML string without the namespace and fail when using the XML string with the namespace.
>
> Mark
> PS I am having the same problem with the xml2 package and am hoping understanding one with help with the other.
>
> ##
> library(XML)
> ## The first XML text (no_ns_xml) does not have a namespace defined
> no_ns_xml <- c("<?xml version=\"1.0\" ?>", "<WorkSet>",
>                "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>                "</WorkSet>")
> l_no_ns_xml <-xmlTreeParse(no_ns_xml, asText = TRUE, getDTD = FALSE,
>                            useInternalNodes = TRUE)
> ## The node is found
> getNodeSet(l_no_ns_xml, "/WorkSet//Description")
>
> ## The second XML text (with_ns_xml) has a namespace defined
> with_ns_xml <- c("<?xml version=\"1.0\" ?>",
>                  "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
>                  "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>                  "</WorkSet>")
>
> l_with_ns_xml <-xmlTreeParse(with_ns_xml, asText = TRUE, getDTD = FALSE,
>                                useInternalNodes = TRUE)
> ## The node is not found
> getNodeSet(l_with_ns_xml, "/WorkSet//Description")
> ## I attempt to provide the namespace, but fail.
> ns <-  "http://labkey.org/etl/xml"
> names(ns)[1] <- "xmlns"
> getNodeSet(l_with_ns_xml, "/WorkSet//Description", namespaces = ns)
>
> R. Mark Sharp, Ph.D.
> Director of Data Science Core
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
>
>
>
>
>
>
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From ed_isfahani at yahoo.com  Tue Jan 31 23:36:22 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Tue, 31 Jan 2017 22:36:22 +0000 (UTC)
Subject: [R] filter correlation data
In-Reply-To: <CAGxFJbQJXDeEkFdWunyObtR-i3Fe6nyzvMZmtUh8xD0kEjsFWA@mail.gmail.com>
References: <1267128747.1264722.1485898464009.ref@mail.yahoo.com>
	<1267128747.1264722.1485898464009@mail.yahoo.com>
	<CAGxFJbQJXDeEkFdWunyObtR-i3Fe6nyzvMZmtUh8xD0kEjsFWA@mail.gmail.com>
Message-ID: <2118252427.118818.1485902182421@mail.yahoo.com>

actually,First I searched in net,after that I sent my question, because I couldn't find the function. 

    On Wednesday, February 1, 2017 1:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 ... And why did you not do a web search on "correlation coefficient in
R", which would have led you almost imediately to ?cor and friends?

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 31, 2017 at 1:34 PM, Elham - via R-help
<r-help at r-project.org> wrote:
> hello everybody,I have a very very huge table in R from calculating correlation,how can I filter it per spearman correlation and p-value before export it,I mean what is the function that I use?I want to select the pairs for value (r), , greater than 0.9 (directly correlated) and less than -0.9 (inversely corerlated), and a p-value < 0.001
>
>
> I should say that I transformed the big matrix in a table by library(reshape).
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Jan 31 23:47:12 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 1 Feb 2017 11:47:12 +1300
Subject: [R] [FORGED]  filter correlation data
In-Reply-To: <1267128747.1264722.1485898464009@mail.yahoo.com>
References: <1267128747.1264722.1485898464009.ref@mail.yahoo.com>
	<1267128747.1264722.1485898464009@mail.yahoo.com>
Message-ID: <01bed5b7-1e39-c310-2c7a-dd1ee74b7262@auckland.ac.nz>


On 01/02/17 10:34, Elham - via R-help wrote:

> hello everybody,I have a very very huge table in R from calculating
> correlation,how can I filter it per spearman correlation and p-value
> before export it,I mean what is the function that I use?I want to
> select the pairs for value (r), , greater than 0.9 (directly
> correlated) and less than -0.9 (inversely corerlated), and a p-value
> < 0.001
>
>
> I should say that I transformed the big matrix in a table by
> library(reshape).

(a) In this instance it doesn't really matter, but *PLEASE* stop posting 
in HTML.

(b) It's not at all clear what the structure of your (table? matrix? 
data frame) is.  Please learn to be precise and explicit, otherwise it 
is difficult-to-impossible to provide useful advice.  (I.e. don't expect 
us to be mind-readers.)

Let us suppose (for the sake of saying *something* that might be 
helpful) that your correlations and p-values are stored in a data frame 
"X" as columns named "r" and "pval".

Then assign

ok <- with(X, (r < -0.9 | r > 0.9) & pval < 0.001)
Y  <- X[ok,]

Then export Y.

Really, if you are going to use R you should learn something about R.

cheers,

Rolf Turner

P.S.  Note that your p-value < 0.001 condition is redundant for any 
sample size greater than or equal to 7.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From steffen.moritz10 at gmail.com  Tue Jan 31 19:16:39 2017
From: steffen.moritz10 at gmail.com (Steffen Moritz)
Date: Tue, 31 Jan 2017 19:16:39 +0100
Subject: [R] [R-pkgs] Announcing imputeTS 1.8
Message-ID: <CAAwsjPiDYg4X0kdg3zCaOQSEq_cn1QSfQC68jHA9jGCRPrFO2A@mail.gmail.com>

imputeTS:
Imputation (replacement) of missing values in univariate time series.

Dear R users,

I would like to announce version 1.8 of the imputeTS package.
( https://cran.r-project.org/package=imputeTS )

Since I did not introduce the package here before, let me give you a short
wrap up:

The package

- Focuses on missing value replacement in (univariate) time series

- Offers several simple and very fast imputation algorithms
  ( e.g. mean, last observation carried forward, linear interpolation )

- Offers several advanced (but slower) imputation algorithms
   ( like e.g. kalman smoothing on structural time series models )

- Additionally provides functions for plotting the distribution of missing
values
  in a time series

The latest (version 1.8) update includes significant speed improvements for
some of the imputation functions.

I am always happy about feedback!
( either per mail or via https://github.com/SteffenMoritz/imputeTS )

Best regards,

Steffen

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


