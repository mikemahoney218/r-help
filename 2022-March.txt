From e||z@_botto @end|ng |rom out|ook@com  Tue Mar  1 04:47:00 2022
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 1 Mar 2022 03:47:00 +0000
Subject: [R] setting zeros for the missing interval in data
Message-ID: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Dear useRs,

I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.

> dput(YY)

structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,

between

30 2021 2021/05/02 10:00:00 PM      0.2

and

30 2021 2021/05/02 10:55:00 PM      0.2

the values of rainfall depth for following "time stamps" are missing because they were "zero"

30 2021 2021/05/02 10:05:00 PM      0.0

30 2021 2021/05/02 10:10:00 PM      0.0

30 2021 2021/05/02 10:15:00 PM      0.0

30 2021 2021/05/02 10:20:00 PM      0.0

30 2021 2021/05/02 10:25:00 PM      0.0

30 2021 2021/05/02 10:30:00 PM      0.0

30 2021 2021/05/02 10:35:00 PM      0.0

30 2021 2021/05/02 10:40:00 PM      0.0

30 2021 2021/05/02 10:45:00 PM      0.0

30 2021 2021/05/02 10:50:00 PM      0.0

So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.

Thank You very much in advance,

Eliza



[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

	[[alternative HTML version deleted]]


From e||z@_botto @end|ng |rom out|ook@com  Tue Mar  1 04:52:47 2022
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 1 Mar 2022 03:52:47 +0000
Subject: [R] setting zeros for missing interval in data
Message-ID: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

[The data setting in the last email might be faulty]

Dear useRs,

I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.

> dput(YY)

structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,

between

30 2021 2021/05/02 10:00:00 PM      0.2

and

30 2021 2021/05/02 10:55:00 PM      0.2

the values of rainfall depth for following "time stamps" are missing because they were "zero"

30 2021 2021/05/02 10:05:00 PM      0.0

30 2021 2021/05/02 10:10:00 PM      0.0

30 2021 2021/05/02 10:15:00 PM      0.0

30 2021 2021/05/02 10:20:00 PM      0.0

30 2021 2021/05/02 10:25:00 PM      0.0

30 2021 2021/05/02 10:30:00 PM      0.0

30 2021 2021/05/02 10:35:00 PM      0.0

30 2021 2021/05/02 10:40:00 PM      0.0

30 2021 2021/05/02 10:45:00 PM      0.0

30 2021 2021/05/02 10:50:00 PM      0.0

So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.

Thank You very much in advance,

Eliza

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar  1 05:35:14 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 1 Mar 2022 15:35:14 +1100
Subject: [R] setting zeros for the missing interval in data
In-Reply-To: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>

Hi Eliza,
Your data wouldn't read for me, so I had to do some quick hacking to
get something to work with. It's a bit long, so I've attached what may
be a solution as an R source file.

Jim

On Tue, Mar 1, 2022 at 2:47 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
> > dput(YY)
>
> structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")
>
> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
> between
>
> 30 2021 2021/05/02 10:00:00 PM      0.2
>
> and
>
> 30 2021 2021/05/02 10:55:00 PM      0.2
>
> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
> 30 2021 2021/05/02 10:05:00 PM      0.0
>
> 30 2021 2021/05/02 10:10:00 PM      0.0
>
> 30 2021 2021/05/02 10:15:00 PM      0.0
>
> 30 2021 2021/05/02 10:20:00 PM      0.0
>
> 30 2021 2021/05/02 10:25:00 PM      0.0
>
> 30 2021 2021/05/02 10:30:00 PM      0.0
>
> 30 2021 2021/05/02 10:35:00 PM      0.0
>
> 30 2021 2021/05/02 10:40:00 PM      0.0
>
> 30 2021 2021/05/02 10:45:00 PM      0.0
>
> 30 2021 2021/05/02 10:50:00 PM      0.0
>
> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
> Thank You very much in advance,
>
> Eliza
>
>
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  1 05:46:34 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Feb 2022 20:46:34 -0800
Subject: [R] setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <E00A5313-DF88-480D-AA00-A4033CBBBD2F@dcn.davis.ca.us>

There are quite a variety of approaches implemented in various contributed packages, but here is a base R approach based on merge:

Sys.setenv(TZ = "UTC" ) # or other non-DST zone unless you need it
YY$TIMESTAMP <- as.POSIXct( YY$TIMESTAMP, format = "%Y/%m/%d %I:%M:%S %p" )
tlims <- as.POSIXct( c( "2021-05-02", "2021-05-10" ) )
tdiff <- as.difftime( 5, units="mins" )
aa <- seq( tlims[1], tlims[2], by = tdiff )
AA <- expand.grid( CHANNEL = 30, TIMESTAMP = aa )
yy <- merge( AA, YY[ , c( "CHANNEL", "TIMESTAMP", "RAINFALL" ) ], by = c( "CHANNEL", "TIMESTAMP" ), all.x = TRUE )
yy$RAINFALL[ is.na( yy$RAINFALL ) ] <- 0
yy


On February 28, 2022 7:52:47 PM PST, Eliza Botto <eliza_botto at outlook.com> wrote:
>[The data setting in the last email might be faulty]
>
>Dear useRs,
>
>I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
>> dput(YY)
>
>structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
>"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
>"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
>"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
>"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
>"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
>"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
>"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
>"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
>"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
>"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
>"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
>"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
>"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
>"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
>"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
>"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
>"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
>"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
>"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
>"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
>"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
>"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
>"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
>"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
>"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
>"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
>"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
>"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
>"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
>"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
>"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
>"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
>"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
>), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
>)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
>996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
>1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
>1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
>1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
>2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
>2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
>3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
>3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
>3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
>3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
>3932L, 3933L), class = "data.frame")
>
>You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
>between
>
>30 2021 2021/05/02 10:00:00 PM      0.2
>
>and
>
>30 2021 2021/05/02 10:55:00 PM      0.2
>
>the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
>30 2021 2021/05/02 10:05:00 PM      0.0
>
>30 2021 2021/05/02 10:10:00 PM      0.0
>
>30 2021 2021/05/02 10:15:00 PM      0.0
>
>30 2021 2021/05/02 10:20:00 PM      0.0
>
>30 2021 2021/05/02 10:25:00 PM      0.0
>
>30 2021 2021/05/02 10:30:00 PM      0.0
>
>30 2021 2021/05/02 10:35:00 PM      0.0
>
>30 2021 2021/05/02 10:40:00 PM      0.0
>
>30 2021 2021/05/02 10:45:00 PM      0.0
>
>30 2021 2021/05/02 10:50:00 PM      0.0
>
>So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
>Thank You very much in advance,
>
>Eliza
>
>[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar  1 05:59:43 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 1 Mar 2022 15:59:43 +1100
Subject: [R] setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fU1iWgDXczB6KBhBBAw018rN3O+kXxXfJYq+A6JG5ySmg@mail.gmail.com>

Hi Eliza,
It sure was:

YY$datetime<-strptime(YY$TIMESTAMP,"%Y/%m/%d %I:%M:%S %p")
dt5min<-seq(ISOdate(2021,5,1,0,5),ISOdate(2021,5,31,12,55),by="5 min")
newdt<-data.frame(datetime=dt5min)
newyy<-merge(newdt,YY,by="datetime",all=TRUE)
newyy$RAINFALL[is.na(newyy$RAINFALL)]<-0
plot(newyy$datetime,newyy$RAINFALL)

Jim

On Tue, Mar 1, 2022 at 2:57 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> [The data setting in the last email might be faulty]
>
> Dear useRs,
>
> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
> > dput(YY)
>
> structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")
>
> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
> between
>
> 30 2021 2021/05/02 10:00:00 PM      0.2
>
> and
>
> 30 2021 2021/05/02 10:55:00 PM      0.2
>
> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
> 30 2021 2021/05/02 10:05:00 PM      0.0
>
> 30 2021 2021/05/02 10:10:00 PM      0.0
>
> 30 2021 2021/05/02 10:15:00 PM      0.0
>
> 30 2021 2021/05/02 10:20:00 PM      0.0
>
> 30 2021 2021/05/02 10:25:00 PM      0.0
>
> 30 2021 2021/05/02 10:30:00 PM      0.0
>
> 30 2021 2021/05/02 10:35:00 PM      0.0
>
> 30 2021 2021/05/02 10:40:00 PM      0.0
>
> 30 2021 2021/05/02 10:45:00 PM      0.0
>
> 30 2021 2021/05/02 10:50:00 PM      0.0
>
> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
> Thank You very much in advance,
>
> Eliza
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Tue Mar  1 06:18:53 2022
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 1 Mar 2022 05:18:53 +0000
Subject: [R] [External]  setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <D92EAEA4-8181-4B87-81FB-5EF6FB61A19F@temple.edu>

I believe this is what you are looking for.
The idea is to set up the full range of interest and then subset into it with the values that you have observed.
I illustrate here with three days, you will need the full five months.


Start <- strptime("2021/05/02 10:00:00 PM", format="%Y/%m/%d %H:%M:%S", tz="GMT")
CompleteTimeSet <- Start + (0:(288*3))*5*60  ## 288 5min intervals per day, 3 days, 5*60=300 seconds per 5 minutes

YY <-
structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

CompleteData <- data.frame(TIMESTAMP=CompleteTimeSet, RAINFALL=0)
YYTIME <- strptime(YY$TIMESTAMP, format="%Y/%m/%d %H:%M:%S", tz="GMT")

CompleteData[CompleteData$TIMESTAMP %in% YYTIME[1:4], "RAINFALL"] <- YY$RAINFALL[1:4]
CompleteData


## output
> CompleteData[1:14,]
              TIMESTAMP RAINFALL
1   2021-05-02 10:00:00      0.2
2   2021-05-02 10:05:00      0.0
3   2021-05-02 10:10:00      0.0
4   2021-05-02 10:15:00      0.0
5   2021-05-02 10:20:00      0.0
6   2021-05-02 10:25:00      0.0
7   2021-05-02 10:30:00      0.0
8   2021-05-02 10:35:00      0.0
9   2021-05-02 10:40:00      0.0
10  2021-05-02 10:45:00      0.0
11  2021-05-02 10:50:00      0.0
12  2021-05-02 10:55:00      0.2
13  2021-05-02 11:00:00      0.0
14  2021-05-02 11:05:00      0.0


> On Feb 28, 2022, at 22:52, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
> structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Mar  1 06:49:19 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Mar 2022 05:49:19 +0000 (UTC)
Subject: [R] setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <1296919232.1562114.1646113759202@mail.yahoo.com>

In base R, I wish the question below had been explained better. It is nice that an example was given, albeit misleading for me.

The data shown is not flawed and has nothing inside it that reflects being missing as it first sounded like.

What sounds like it is missing is specific dates entirely. The column called Channel seems irrelevant as it is always 30. Rain fall is always 0.2 or 0.4. The YEAR is always 2021. So the ONLY interesting thing here seems to be TIMESTAMP.

But I am NOT convinced they are missing because the times are all over the place. I mean 10 PM and 5:40 PM  and 5:20 AM and so on. There are multiple rows for the same day.

Yes, there is no info for May 1 and May 6 and 7. I have no idea why but How and why are we supposed to guess that it means no rain versus some other reason? Towards the end, what I think is the real message is shown. The suggestion is there should be data for every five minute period interpolated here

Fair enough. Can I suggest that the data offered to us has the TIMESTAMP field as character, rather than some form of DATE/TIME that can be used in Python?

Converting it or extracting some info into temporary columns might be useful here.

You could then create some kind of data that loops over times starting with your start time, say midnight on the 1st and for every 5 minute interval makes a timestamp that looks like what you need and COMPARE to what is in the data shown. For any that are nor present, you can create a similar row with a zero in it for the RAINFALL field. There are oodles of ways to do that, including some more straightforward than others. Or, you may just make the sequence or all, and later in some kind of merge, only keep ones from the original data if there is a duplicate. Again, many ways, even in base R.

If my analysis is right, and clearly it may not be, a much better way to ask this question might be to say you have timestamped data about rainfall where the readings for every 5 minute interval with no rainfall have been omitted. How do you create records for all 5-minute intervals that are not present and merge that info with the records shown?

As a hint, you can make a sequence like below, with your own adjustments for starting and ending dates.

> seq(from=as.POSIXct("2020-05-01 00:00"),to=as.POSIXct("2020-05-01 01:00"),by="5 min")
 [1] "2020-05-01 00:00:00 EDT" "2020-05-01 00:05:00 EDT" "2020-05-01 00:10:00 EDT"
 [4] "2020-05-01 00:15:00 EDT" "2020-05-01 00:20:00 EDT" "2020-05-01 00:25:00 EDT"
 [7] "2020-05-01 00:30:00 EDT" "2020-05-01 00:35:00 EDT" "2020-05-01 00:40:00 EDT"
[10] "2020-05-01 00:45:00 EDT" "2020-05-01 00:50:00 EDT" "2020-05-01 00:55:00 EDT"
[13] "2020-05-01 01:00:00 EDT"

Of course you may want to know WHY you need the missing data interpolated. Some graphics programs, if properly supplied with actual dates, not character strings, may simply skip missing records and leave room between others. The missing ones might be treated as zero, depending what you are doing.


-----Original Message-----
From: Eliza Botto <eliza_botto at outlook.com>
To: R-help at r-project.org <R-help at r-project.org>
Sent: Mon, Feb 28, 2022 10:52 pm
Subject: [R] setting zeros for missing interval in data

[The data setting in the last email might be faulty]

Dear useRs,

I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.

> dput(YY)

structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,

between

30 2021 2021/05/02 10:00:00 PM? ? ? 0.2

and

30 2021 2021/05/02 10:55:00 PM? ? ? 0.2

the values of rainfall depth for following "time stamps" are missing because they were "zero"

30 2021 2021/05/02 10:05:00 PM? ? ? 0.0

30 2021 2021/05/02 10:10:00 PM? ? ? 0.0

30 2021 2021/05/02 10:15:00 PM? ? ? 0.0

30 2021 2021/05/02 10:20:00 PM? ? ? 0.0

30 2021 2021/05/02 10:25:00 PM? ? ? 0.0

30 2021 2021/05/02 10:30:00 PM? ? ? 0.0

30 2021 2021/05/02 10:35:00 PM? ? ? 0.0

30 2021 2021/05/02 10:40:00 PM? ? ? 0.0

30 2021 2021/05/02 10:45:00 PM? ? ? 0.0

30 2021 2021/05/02 10:50:00 PM? ? ? 0.0

So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.

Thank You very much in advance,

Eliza

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>? ?  Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Mar  1 06:52:54 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Mar 2022 05:52:54 +0000 (UTC)
Subject: [R] setting zeros for the missing interval in data
In-Reply-To: <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>
References: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>
Message-ID: <1903735100.1560703.1646113974624@mail.yahoo.com>

Hi Jim,

Just FYI, your reply to Eliza likely included your attachment but the copy to this list has it stripped.

I suspect the world would just work better if forums like this moved from text-only email to something like groups.io that allow richer text and attachments, albeit they do make images fuzzier to save on space. 

Regardless,

Avi


-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com>
To: Eliza Botto <eliza_botto at outlook.com>
Cc: R-help at r-project.org <R-help at r-project.org>
Sent: Mon, Feb 28, 2022 11:35 pm
Subject: Re: [R] setting zeros for the missing interval in data


Hi Eliza,
Your data wouldn't read for me, so I had to do some quick hacking to
get something to work with. It's a bit long, so I've attached what may
be a solution as an R source file.

Jim

On Tue, Mar 1, 2022 at 2:47 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
> > dput(YY)
>
> structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")
>
> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
> between
>
> 30 2021 2021/05/02 10:00:00 PM? ? ? 0.2
>
> and
>
> 30 2021 2021/05/02 10:55:00 PM? ? ? 0.2
>
> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
> 30 2021 2021/05/02 10:05:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:10:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:15:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:20:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:25:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:30:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:35:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:40:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:45:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:50:00 PM? ? ? 0.0
>
> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
> Thank You very much in advance,
>
> Eliza
>
>
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>? ?  Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  1 07:42:33 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Feb 2022 22:42:33 -0800
Subject: [R] setting zeros for the missing interval in data
In-Reply-To: <1903735100.1560703.1646113974624@mail.yahoo.com>
References: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>
 <1903735100.1560703.1646113974624@mail.yahoo.com>
Message-ID: <7195DBAF-8679-459E-BABC-4253EF4345B7@dcn.davis.ca.us>

Walled gardens are single points of failure. There are many of those out there already.

There are drawbacks to mailing lists also... there is room for both... but eliminating one in favor of the other is not necessary.

On February 28, 2022 9:52:54 PM PST, Avi Gross via R-help <r-help at r-project.org> wrote:
>Hi Jim,
>
>Just FYI, your reply to Eliza likely included your attachment but the copy to this list has it stripped.
>
>I suspect the world would just work better if forums like this moved from text-only email to something like groups.io that allow richer text and attachments, albeit they do make images fuzzier to save on space. 
>
>Regardless,
>
>Avi
>
>
>-----Original Message-----
>From: Jim Lemon <drjimlemon at gmail.com>
>To: Eliza Botto <eliza_botto at outlook.com>
>Cc: R-help at r-project.org <R-help at r-project.org>
>Sent: Mon, Feb 28, 2022 11:35 pm
>Subject: Re: [R] setting zeros for the missing interval in data
>
>
>Hi Eliza,
>Your data wouldn't read for me, so I had to do some quick hacking to
>get something to work with. It's a bit long, so I've attached what may
>be a solution as an R source file.
>
>Jim
>
>On Tue, Mar 1, 2022 at 2:47 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>>
>> Dear useRs,
>>
>> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>>
>> > dput(YY)
>>
>> structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
>> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
>> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
>> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
>> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
>> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
>> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
>> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
>> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
>> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
>> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
>> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
>> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
>> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
>> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
>> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
>> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
>> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
>> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
>> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
>> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
>> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
>> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
>> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
>> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
>> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
>> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
>> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
>> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
>> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
>> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
>> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
>> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
>> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
>> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
>> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
>> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
>> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
>> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
>> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
>> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
>> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
>> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
>> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
>> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
>> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
>> 3932L, 3933L), class = "data.frame")
>>
>> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>>
>> between
>>
>> 30 2021 2021/05/02 10:00:00 PM? ? ? 0.2
>>
>> and
>>
>> 30 2021 2021/05/02 10:55:00 PM? ? ? 0.2
>>
>> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>>
>> 30 2021 2021/05/02 10:05:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:10:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:15:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:20:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:25:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:30:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:35:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:40:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:45:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:50:00 PM? ? ? 0.0
>>
>> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>>
>> Thank You very much in advance,
>>
>> Eliza
>>
>>
>>
>> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>? ?  Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>
>>? ? ? ?  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Tue Mar  1 08:10:33 2022
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Tue, 1 Mar 2022 07:10:33 +0000
Subject: [R] plain passwords in reminder mail
Message-ID: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>

Dear list,

The list membership reminder mail includes a plain password!

Regards, Eduard


-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20220301/762e0aac/attachment.sig>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  1 08:41:10 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Feb 2022 23:41:10 -0800
Subject: [R] plain passwords in reminder mail
In-Reply-To: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
References: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
Message-ID: <37325DE9-C565-4F75-9579-6C422A8F1206@dcn.davis.ca.us>

https://www.urbandictionary.com/define.php?term=news%20at%2011&amp=true&defid=1443637

If there were problems associated with this behavior that were worse than the problems with not having it, it probably would have been changed after decades of being this way.

On February 28, 2022 11:10:33 PM PST, Eduard Drenth <edrenth at fryske-akademy.nl> wrote:
>Dear list,
>
>The list membership reminder mail includes a plain password!
>
>Regards, Eduard
>
>

-- 
Sent from my phone. Please excuse my brevity.


From m|n@h@|| @end|ng |rom um|ch@edu  Tue Mar  1 15:13:56 2022
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Tue, 01 Mar 2022 06:13:56 -0800
Subject: [R] plain passwords in reminder mail
In-Reply-To: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
References: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
Message-ID: <4055256.1646144036@apollo2.minshall.org>

Eduard,

> The list membership reminder mail includes a plain password!

this is very typical for, at least, mailman-supported, e-mail lists.
the password is of low intrinsic value, as it only allows you to change
your membership and options on the list.

cheers, Greg


From Ro@@@Boy|@n @end|ng |rom uc@|@edu  Wed Mar  2 02:51:04 2022
From: Ro@@@Boy|@n @end|ng |rom uc@|@edu (Boylan, Ross)
Date: Wed, 2 Mar 2022 01:51:04 +0000
Subject: [R] Time Zone problems: midnight goes in; 8am comes out
Message-ID: <BY3PR05MB811676D913B9117776364CDE87039@BY3PR05MB8116.namprd05.prod.outlook.com>

I'm having problems with timezones using lubridate, but it's not clear to me the difficulty is in lubridate.
---------------------------------
> r2 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz="PST")
> r2
[1] "1970-01-01 08:01:00 PST"  ## Oops: midnight has turned in 8am
> as.numeric(r2)
[1] 28860
> 8*3600 # seconds in 8 hours
[1] 28800
------------------------------------
lubridate accepts PST as the time zone, and the result prints "PST" for timezone.  Further, lubridate seems to be using the tz properly since it gets the 8 hour offset from UTC correct.

The problem is the value that is printed gives a UTC time of 08:01 despite having the PST suffix.  So the time appears to have jumped 8 hours ahead from the value parsed.

PST appears not to be a legal timezone (in spite of lubridate inferring the correct offset from it):
---------------------------------------------------
> Sys.timezone()
[1] "America/Los_Angeles"

> (grep("PST", OlsonNames(), value=TRUE))
[1] "PST8PDT"         "SystemV/PST8"    "SystemV/PST8PDT"
-------------------------------------
https://www.r-bloggers.com/2018/07/a-tour-of-timezones-troubles-in-r/ says lubridate will complain if given an invalid tz, though I don't see that explicitly in the current man page https://lubridate.tidyverse.org/reference/parse_date_time.html.  As shown above, parse_date_time() does not complain about the timezone, and does use it to get the correct offset.

Using America/Los_Angeles produces the expected results:
---------------------------------------
> r4 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz=Sys.timezone())
> r4
[1] "1970-01-01 00:01:00 PST"  # still prints PST.  This time it's true!
> as.numeric(r4)
[1] 28860
----------------------------------------------------

I suppose I can just use "America/Los_Angeles" as the time zone; this would have the advantage of making all my timezones the same, which apparently what R requires for a vector of datetimes.  But the behavior seems odd, and the "fix" also requires me to ignore the time zone specified in my inputs, which look like "2022-03-01 15:54:30 PST" or PDT, depending on time of year.

1. Why this strange behavior in which PST or PDT is used to construct the proper offset from UTC, and then kind of forgotten on output?
2. Is this a bug in lubridate or base POSIXct, particularly its print routine?

My theory on 1 is that lubridate understands PST and constructs an appropriate UTC time.  POSIXct time does not understand a tz of "PST" and so prints out the UTC value for the time, "decorating" it with the not understood tz value.  

For 2, on one hand, lubridate is constructing POSIXct dates with invalid tz values; lubridate probably shouldn't.  On the other hand, POSIXct is printing a UTC time but labeling it with a tz it doesn't understand, so it looks if it's in that local time even though it isn't.  In the context above that seems like a bug, but it's possible a lot of code that depends on it.

Under these theories, the problems only arise because the set of tz values understood by lubridate differs from the tz value understood by POSIXct.

Versions:
R 3.5.2
lubridate 1.7.4
Debian GNU/Linux 10 aka buster (amd64 flavor)

Thanks.
Ross Boylan

From @kw@|mmo @end|ng |rom gm@||@com  Wed Mar  2 03:50:31 2022
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 1 Mar 2022 21:50:31 -0500
Subject: [R] Time Zone problems: midnight goes in; 8am comes out
In-Reply-To: <BY3PR05MB811676D913B9117776364CDE87039@BY3PR05MB8116.namprd05.prod.outlook.com>
References: <BY3PR05MB811676D913B9117776364CDE87039@BY3PR05MB8116.namprd05.prod.outlook.com>
Message-ID: <CAPcHnpTELPUMZ8FB9O86VwJWwc5=d+ERS=ct2YXvxfnfFG_=mw@mail.gmail.com>

It seems like the current version of lubridate is 1.8.0, which does
raise a warning for an invalid timezone, just like as.POSIXct. This is
what I tried:


print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd
HMS"          , tz = "PST"))
print(as.POSIXct                ("1970-01-01 00:01:00", format =
"%Y-%m-%d %H:%M:%S", tz = "PST"))


outputs:


> print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd HMS"          , tz = "PST"))
[1] "1970-01-01 08:01:00 GMT"
Warning message:
In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
> print(as.POSIXct                ("1970-01-01 00:01:00", format = "%Y-%m-%d %H:%M:%S", tz = "PST"))
[1] "1970-01-01 00:01:00 GMT"
Warning messages:
1: In strptime(x, format, tz = tz) : unknown timezone 'PST'
2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'PST'
3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
>


But I don't see the same problem when using `tz =
"America/Los_Angeles"` or `tz = "PST8PDT"`.


print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd
HMS"          , tz = "PST8PDT"))
print(as.POSIXct                ("1970-01-01 00:01:00", format =
"%Y-%m-%d %H:%M:%S", tz = "PST8PDT"))


outputs:


> print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd HMS"          , tz = "PST8PDT"))
[1] "1970-01-01 00:01:00 PST"
> print(as.POSIXct                ("1970-01-01 00:01:00", format = "%Y-%m-%d %H:%M:%S", tz = "PST8PDT"))
[1] "1970-01-01 00:01:00 PST"
>


I would hesitate to use `tz = Sys.timezone()` because someone from
another province/state might not be able to use your code. Depends on
whether this work is being shared with other people though, up to you.

On Tue, Mar 1, 2022 at 8:51 PM Boylan, Ross via R-help
<r-help at r-project.org> wrote:
>
> I'm having problems with timezones using lubridate, but it's not clear to me the difficulty is in lubridate.
> ---------------------------------
> > r2 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz="PST")
> > r2
> [1] "1970-01-01 08:01:00 PST"  ## Oops: midnight has turned in 8am
> > as.numeric(r2)
> [1] 28860
> > 8*3600 # seconds in 8 hours
> [1] 28800
> ------------------------------------
> lubridate accepts PST as the time zone, and the result prints "PST" for timezone.  Further, lubridate seems to be using the tz properly since it gets the 8 hour offset from UTC correct.
>
> The problem is the value that is printed gives a UTC time of 08:01 despite having the PST suffix.  So the time appears to have jumped 8 hours ahead from the value parsed.
>
> PST appears not to be a legal timezone (in spite of lubridate inferring the correct offset from it):
> ---------------------------------------------------
> > Sys.timezone()
> [1] "America/Los_Angeles"
>
> > (grep("PST", OlsonNames(), value=TRUE))
> [1] "PST8PDT"         "SystemV/PST8"    "SystemV/PST8PDT"
> -------------------------------------
> https://www.r-bloggers.com/2018/07/a-tour-of-timezones-troubles-in-r/ says lubridate will complain if given an invalid tz, though I don't see that explicitly in the current man page https://lubridate.tidyverse.org/reference/parse_date_time.html.  As shown above, parse_date_time() does not complain about the timezone, and does use it to get the correct offset.
>
> Using America/Los_Angeles produces the expected results:
> ---------------------------------------
> > r4 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz=Sys.timezone())
> > r4
> [1] "1970-01-01 00:01:00 PST"  # still prints PST.  This time it's true!
> > as.numeric(r4)
> [1] 28860
> ----------------------------------------------------
>
> I suppose I can just use "America/Los_Angeles" as the time zone; this would have the advantage of making all my timezones the same, which apparently what R requires for a vector of datetimes.  But the behavior seems odd, and the "fix" also requires me to ignore the time zone specified in my inputs, which look like "2022-03-01 15:54:30 PST" or PDT, depending on time of year.
>
> 1. Why this strange behavior in which PST or PDT is used to construct the proper offset from UTC, and then kind of forgotten on output?
> 2. Is this a bug in lubridate or base POSIXct, particularly its print routine?
>
> My theory on 1 is that lubridate understands PST and constructs an appropriate UTC time.  POSIXct time does not understand a tz of "PST" and so prints out the UTC value for the time, "decorating" it with the not understood tz value.
>
> For 2, on one hand, lubridate is constructing POSIXct dates with invalid tz values; lubridate probably shouldn't.  On the other hand, POSIXct is printing a UTC time but labeling it with a tz it doesn't understand, so it looks if it's in that local time even though it isn't.  In the context above that seems like a bug, but it's possible a lot of code that depends on it.
>
> Under these theories, the problems only arise because the set of tz values understood by lubridate differs from the tz value understood by POSIXct.
>
> Versions:
> R 3.5.2
> lubridate 1.7.4
> Debian GNU/Linux 10 aka buster (amd64 flavor)
>
> Thanks.
> Ross Boylan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mtenneke@ @end|ng |rom gm@||@com  Wed Mar  2 10:52:04 2022
From: mtenneke@ @end|ng |rom gm@||@com (Martijn Tennekes)
Date: Wed, 2 Mar 2022 10:52:04 +0100
Subject: [R] dev.size() does not return correct size on 4K screen
Message-ID: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>

dev.size() does not return the correct screen size when using a 4K 
screen. With the R console and a x11() device, it seems to overestimate 
with factor 1.5, and in RStudio underestimate with factor 2.

See also https://github.com/rstudio/rstudio/issues/10723

Is this a bug, or is there something I can do?

Best,

Martijn Tennekes

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Mar  2 23:11:57 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 2 Mar 2022 23:11:57 +0100
Subject: [R] dev.size() does not return correct size on 4K screen
In-Reply-To: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>
References: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>
Message-ID: <D4C3DCA2-A3F3-4B4F-BDF1-F0E1C1E16514@gmail.com>

I don't know about RStudio, but in X11 this sort of thing can happen due to misconfiguration of the display itself, i.e. not in R as such. Basically, it relies on getting the correct dots-per-inch value from the display, and may otherwise use some standard value. 

What happens if you run xdpyinfo in a terminal window?

With XQuartz on an MB Air, I see

...
screen #0:
  dimensions:    1440x876 pixels (381x232 millimeters)
  resolution:    96x96 dots per inch
...

which is a multi-way lie! It is a 2560x1600 retina display, the resolution is way higher than 96x96, and it is 13.3", whereas the stated dimensions corresponds to a 17" diagonal. 

However, systems may be "lying in the users best interest", since e.g. the default for an X11() plot window is 7in square, which might not fit on a small laptop. You are somewhat more likely to want the same relative size across different laptops.  

- pd

> On 2 Mar 2022, at 10:52 , Martijn Tennekes <mtennekes at gmail.com> wrote:
> 
> dev.size() does not return the correct screen size when using a 4K 
> screen. With the R console and a x11() device, it seems to overestimate 
> with factor 1.5, and in RStudio underestimate with factor 2.
> 
> See also https://github.com/rstudio/rstudio/issues/10723
> 
> Is this a bug, or is there something I can do?
> 
> Best,
> 
> Martijn Tennekes
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Mar  2 23:54:43 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 2 Mar 2022 17:54:43 -0500
Subject: [R] How to automatically set R to read the files from a specific
 location
Message-ID: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>

Dear friends,

I am working on an assignment using R, and I would like to set my R code so
that R automatically recognizes where the files that need to be read are
without having to use the absolute path?
The idea is that when I send my .R script and my professor receives it, he
can just execute the code without running into any issues.

Thanks, beforehand, for your valuable feedback.

Cheers,
Paul

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Mar  3 00:07:17 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 2 Mar 2022 15:07:17 -0800
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
Message-ID: <CAGxFJbRpjVNjO07+qWu=w_rOiHg0+DK5E5n3ECDMzHPpfSnkTg@mail.gmail.com>

I may well be wrong, but I believe you will need to give more info on
where the files are located (e.g. on a remote server, on a website, a
local machine, ...), whether they consist only of data or whether
there are packages with functions that need to be used, etc.

A better approach might be to combine data and files into a package,
put the package where you all have access, and then give your prof the
code to download it from there.

Others may have better ideas, so do wait for more responses.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 2, 2022 at 2:55 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> I am working on an assignment using R, and I would like to set my R code so
> that R automatically recognizes where the files that need to be read are
> without having to use the absolute path?
> The idea is that when I send my .R script and my professor receives it, he
> can just execute the code without running into any issues.
>
> Thanks, beforehand, for your valuable feedback.
>
> Cheers,
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Mar  3 00:27:58 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Mar 2022 15:27:58 -0800
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
Message-ID: <B1EB47AE-AC31-43B3-AF6F-E498D11B717D@dcn.davis.ca.us>

1) make a working directory. Put all related files (including your R file(s) in that directory or in subdirectories.
2) Set your working directory as "current" before starting R. If you or anyone who wants to use your code does this, no actions will be needed in the script to "change" the directory. This is straightforward at the shell using "cd", and GUI file managers will normally do this automatically for you if you "open" a file using an action that triggers starting R from there. RStudio uses the .Rproj file to serve this purpose, so if you use RStudio then always create a Project for each separate "project" you work on.
3) Use relative paths in your code. You can access a csv file in your working directory as "filename.csv" or in a subdirectory data_dir of your working directory using "data_dir/filename.csv".
4) Send a zip archive of your "project" directory/contents to the recipient so the relative locations of files is maintained. Or consider using GitHub (e.g. [1]) to share and track changes.

Note that sometimes you may not want to include the data in your project directory because switching data sets will be common. In that case you cannot achieve this goal, but you can use a global variable to specify your data directory path and use file.path( dtadir, fname ) wherever your specify a file for input. The recipient then only needs to alter one line of your code.

[1] https://happygitwithr.com/

On March 2, 2022 2:54:43 PM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>I am working on an assignment using R, and I would like to set my R code so
>that R automatically recognizes where the files that need to be read are
>without having to use the absolute path?
>The idea is that when I send my .R script and my professor receives it, he
>can just execute the code without running into any issues.
>
>Thanks, beforehand, for your valuable feedback.
>
>Cheers,
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Mar  3 02:02:03 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 3 Mar 2022 01:02:03 +0000 (UTC)
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAGxFJbRpjVNjO07+qWu=w_rOiHg0+DK5E5n3ECDMzHPpfSnkTg@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
 <CAGxFJbRpjVNjO07+qWu=w_rOiHg0+DK5E5n3ECDMzHPpfSnkTg@mail.gmail.com>
Message-ID: <1505692023.226581.1646269323492@mail.yahoo.com>

All reasonable answers so far to the question but what is missing here is what the ASSIGNMENT is. Are the student(s) and professors/teachers sharing an environment on a multi-tasking machine or some networked situation or each is alone?
If I were teaching a class, I might be supplying the data files to be used and hence have a local copy on my machine in a designated area. This same issue comes up when someone asks me to do some analysis for them, sometimes without my having a copy of the data file, just knowing details about what it contains, such as column headers in a CSV.
So it is possibly something the teacher should have taught and set up. For example, they can tell you the file is in /usr/tmp (or whatever shared area) or a networked alternative where you are asked to copy the file into some local directory and setwd() into that directory and the? program is to be run from THAT directory. That makes it simple as each user can place the file anywhere they wish.
An alternative, as pointed out, is to ask the person to edit one line of? the R script being supplied such as:
WHERE <- "C:/..."setwd(WHERE)
Or, as pointed out, R has utilities to easily splice together a filename, as simple as:
FILE <- "xyz.csv"FULL_NAME <- paste(WHERE, "/", FILE)
and in operations on the file, use FULL_NAME.
Whatever method is used can be implemented best if you get instructions. If the Professor wants to see your program, the above and variants should work. If they just want to see the output file for correctness, and do not plan on running the R script, then attaching the output results in an email might do.
NOTE, I used slash notation for directory structures above as it is most portable. Of course, if everyone is on something like MS Windows, you have the option of doubled backslashes and so on. Some R utilities handle this better and might be preferable to what I show as a SIMPLE example using base R.

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com>
To: Paul Bernal <paulbernal07 at gmail.com>
Cc: R <r-help at r-project.org>
Sent: Wed, Mar 2, 2022 6:07 pm
Subject: Re: [R] How to automatically set R to read the files from a specific location

I may well be wrong, but I believe you will need to give more info on
where the files are located (e.g. on a remote server, on a website, a
local machine, ...), whether they consist only of data or whether
there are packages with functions that need to be used, etc.

A better approach might be to combine data and files into a package,
put the package where you all have access, and then give your prof the
code to download it from there.

Others may have better ideas, so do wait for more responses.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 2, 2022 at 2:55 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> I am working on an assignment using R, and I would like to set my R code so
> that R automatically recognizes where the files that need to be read are
> without having to use the absolute path?
> The idea is that when I send my .R script and my professor receives it, he
> can just execute the code without running into any issues.
>
> Thanks, beforehand, for your valuable feedback.
>
> Cheers,
> Paul
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Mar  3 02:08:10 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 3 Mar 2022 01:08:10 +0000 (UTC)
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
Message-ID: <456822666.230862.1646269690844@mail.yahoo.com>


Just a silly? thought, Paul. If this is really for a class and the file(s) being used are small enough, you can play a game where the data is already in the R program and is simply written into a file at the start in the current directory or a designated area. If that succeeds, you can then have the program start as if from scratch and read it back in and continue.?
An alternative if the file is not local but in a known place that can be reached, is code that copies it here ...
Of course in real life with existing huge files, not so much a good idea. But many programming assignments to students use smaller data sets. Some require having loaded a package and then have an access method to make the data visible and loaded. As long as the professor and others all have the same package, ...

-----Original Message-----
From: Paul Bernal <paulbernal07 at gmail.com>
To: R <r-help at r-project.org>
Sent: Wed, Mar 2, 2022 5:54 pm
Subject: [R] How to automatically set R to read the files from a specific location

Dear friends,

I am working on an assignment using R, and I would like to set my R code so
that R automatically recognizes where the files that need to be read are
without having to use the absolute path?
The idea is that when I send my .R script and my professor receives it, he
can just execute the code without running into any issues.

Thanks, beforehand, for your valuable feedback.

Cheers,
Paul

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Mar  3 07:50:58 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 3 Mar 2022 08:50:58 +0200
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <456822666.230862.1646269690844@mail.yahoo.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
 <456822666.230862.1646269690844@mail.yahoo.com>
Message-ID: <CAGgJW75-jaTK3jTf1yKqycsXx4PE9QE43v+=NthpgKAkC7CeZg@mail.gmail.com>

YAA (Yet Another Approach)
If the data is part of the assignment then the instructor presumably has a
copy of the data file(s).
Your script could get the location of these files via an environment
variable using Sys.getenv().
The instructor would need to set the environment variable prior to running
your script.
Your script should issue an error if the environment variable has not been
set.


On Thu, Mar 3, 2022 at 3:12 AM Avi Gross via R-help <r-help at r-project.org>
wrote:

>
> Just a silly  thought, Paul. If this is really for a class and the file(s)
> being used are small enough, you can play a game where the data is already
> in the R program and is simply written into a file at the start in the
> current directory or a designated area. If that succeeds, you can then have
> the program start as if from scratch and read it back in and continue.
> An alternative if the file is not local but in a known place that can be
> reached, is code that copies it here ...
> Of course in real life with existing huge files, not so much a good idea.
> But many programming assignments to students use smaller data sets. Some
> require having loaded a package and then have an access method to make the
> data visible and loaded. As long as the professor and others all have the
> same package, ...
>
> -----Original Message-----
> From: Paul Bernal <paulbernal07 at gmail.com>
> To: R <r-help at r-project.org>
> Sent: Wed, Mar 2, 2022 5:54 pm
> Subject: [R] How to automatically set R to read the files from a specific
> location
>
> Dear friends,
>
> I am working on an assignment using R, and I would like to set my R code so
> that R automatically recognizes where the files that need to be read are
> without having to use the absolute path?
> The idea is that when I send my .R script and my professor receives it, he
> can just execute the code without running into any issues.
>
> Thanks, beforehand, for your valuable feedback.
>
> Cheers,
> Paul
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @tch|rume @end|ng |rom gm@||@com  Thu Mar  3 08:43:32 2022
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Thu, 3 Mar 2022 09:43:32 +0200
Subject: [R] Applying HP and BP filters to calculate potential GDP
 (de-trending)
In-Reply-To: <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
Message-ID: <CAFfFd+vJ4pN0LSvFMvgC7TDD86d0VFuneaUDpAMonFm8sGkv9w@mail.gmail.com>

Goodday, i hope i find you well. Kindly assist me on how to apply the HP
and BP filetrs to the following data set.

Thank you in advance.

Admire

From mtenneke@ @end|ng |rom gm@||@com  Thu Mar  3 11:03:44 2022
From: mtenneke@ @end|ng |rom gm@||@com (Martijn Tennekes)
Date: Thu, 3 Mar 2022 11:03:44 +0100
Subject: [R] dev.size() does not return correct size on 4K screen
In-Reply-To: <D4C3DCA2-A3F3-4B4F-BDF1-F0E1C1E16514@gmail.com>
References: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>
 <D4C3DCA2-A3F3-4B4F-BDF1-F0E1C1E16514@gmail.com>
Message-ID: <aa8bd759-abdc-a821-147f-fb5530e1c893@gmail.com>

Thank you, Peter!


 From xdpyinfo I got

screen #0:
 ? dimensions:??? 5120x2880 pixels (903x508 millimeters)
 ? resolution:??? 144x144 dots per inch

According to these specs my screen should have a sqrt((5120/144)^2 + 
(2880/144)^2) = 40.8" diagonal.

However, in practice it is 27", so that perfectly explains the 1.5 
factor difference.


In RStudio, dev.size() is not equal to par("fin"), which caused the 
problem for me. I the R terminal, these two are equal. I'll post this in 
the RStudio issue list.


Best,

Martijn



On 3/2/22 23:11, peter dalgaard wrote:
> I don't know about RStudio, but in X11 this sort of thing can happen due to misconfiguration of the display itself, i.e. not in R as such. Basically, it relies on getting the correct dots-per-inch value from the display, and may otherwise use some standard value.
>
> What happens if you run xdpyinfo in a terminal window?
>
> With XQuartz on an MB Air, I see
>
> ...
> screen #0:
>    dimensions:    1440x876 pixels (381x232 millimeters)
>    resolution:    96x96 dots per inch
> ...
>
> which is a multi-way lie! It is a 2560x1600 retina display, the resolution is way higher than 96x96, and it is 13.3", whereas the stated dimensions corresponds to a 17" diagonal.
>
> However, systems may be "lying in the users best interest", since e.g. the default for an X11() plot window is 7in square, which might not fit on a small laptop. You are somewhat more likely to want the same relative size across different laptops.
>
> - pd
>
>> On 2 Mar 2022, at 10:52 , Martijn Tennekes <mtennekes at gmail.com> wrote:
>>
>> dev.size() does not return the correct screen size when using a 4K
>> screen. With the R console and a x11() device, it seems to overestimate
>> with factor 1.5, and in RStudio underestimate with factor 2.
>>
>> See also https://github.com/rstudio/rstudio/issues/10723
>>
>> Is this a bug, or is there something I can do?
>>
>> Best,
>>
>> Martijn Tennekes
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From n@d|ne@@|o|@b| @end|ng |rom gm@||@com  Thu Mar  3 13:15:35 2022
From: n@d|ne@@|o|@b| @end|ng |rom gm@||@com (Nadine Afolabi)
Date: Thu, 3 Mar 2022 13:15:35 +0100
Subject: [R] Error: `[.data.frame`(crossloadings, , c("name", "block",
 colnames(xloads))) : undefined columns
Message-ID: <CADG3JTyZdefXa6Vcr5QKRATxoApvYVKixUeuANavHO_-CR1__A@mail.gmail.com>

Hello,

I am trying to analyse a SEM with R and got the following error. I do not
know what I?ve done worng as it always worked in my previous projects. I
need your help please. Thank you.

> blocks = list(1:26, 27:47, 48:51, 52:75)
> library(plspm)
> r1= c(0,0,0,0)
> r2= c(1,0,0,0)
> r3= c(1,0,0,0)
> r4= c(1,0,0,0)
> path = rbind(r1, r2, r3, r4)
> rownames(path)= c("Leadership", "Work Values","Employee Motivation",
"Commitment")
> colnames(path)= rownames(path)
> innerplot(path)
> t(colnames(newsurvey))
> blocks = list(1:26, 27:47, 48:51, 52:75)
> modes=rep("A",4)
> pls= plspm(newsurvey, path, blocks, modes = modes)
Fehler in `[.data.frame`(crossloadings, , c("name", "block",
colnames(xloads))) :
  nicht definierte Spalten gew?hlt
Zus?tzlich: Warnmeldung:
Setting row names on a tibble is deprecated.

Regards,
Nadine

	[[alternative HTML version deleted]]


From |r@|nj @end|ng |rom gm@||@com  Thu Mar  3 20:48:52 2022
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Thu, 3 Mar 2022 19:48:52 +0000
Subject: [R] Applying HP and BP filters to calculate potential GDP
 (de-trending)
In-Reply-To: <CAFfFd+vJ4pN0LSvFMvgC7TDD86d0VFuneaUDpAMonFm8sGkv9w@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
 <CAFfFd+vJ4pN0LSvFMvgC7TDD86d0VFuneaUDpAMonFm8sGkv9w@mail.gmail.com>
Message-ID: <CAHrK514HS2zJz609BXSN2K1aFPfh7i2KQuu2=5Nn14_aupy4+A@mail.gmail.com>

Have you looked at the mFilter package. You may also find the time series
task view useful.  Your dataset was not attached,  It may have been in a
format not accepted by the mailing list. Have a read of the posting guide.

On Thu, 3 Mar 2022, 07:44 Admire Tarisirayi Chirume, <atchirume at gmail.com>
wrote:

> Goodday, i hope i find you well. Kindly assist me on how to apply the HP
> and BP filetrs to the following data set.
>
> Thank you in advance.
>
> Admire
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phh@80 @end|ng |rom gm@||@com  Thu Mar  3 22:00:08 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Thu, 3 Mar 2022 21:00:08 +0000
Subject: [R] Looking for package for data generation for classification and
 regression
Message-ID: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>

Dear All,

I am in need of generating artificial data for machine learning
classification and regression analysis. What I am looking for is
something similar to Python sklearn.datasets.make_classification and
sklearn.datasets.make_regression:

https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html

https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html

I have searched CRAN for something similar, but found nothing. Could
someone please help me with this?

Thanks in advance,

Paul


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Mar  3 22:01:29 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 3 Mar 2022 22:01:29 +0100
Subject: [R] Continuous variable into levels
Message-ID: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>

Hello everyone

I have a variable with about 5000 different values

var1= c(0, 123, 400, .....4988)

I want to convert it into different levels for some comparisons like

if value is between 1-100 do something
else
do other things

Is there any sophisticated way to do that than the following:

var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))

Thank you

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Mar  3 22:04:15 2022
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Thu, 03 Mar 2022 16:04:15 -0500
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
Message-ID: <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>

Hi Paul. Have you considered just going onto Kaggle and GitHub and 
searching for some of the many freely available real datasets that are 
posted there? I'm seeing a lot of productivity there days with research 
focused on data generation, and not just on creating algorithms and 
predictive models. Which is a good thing for us ;)

One of the current research papers I'm working on now is based on mining 
a dataset I discovered on Kaggle a few months back and trying to create 
a novel solution for that. Proper credit will of course be provided in 
the citation references for the data provider.


Thanks,
Tom


On 2022-03-03 16:00, Paul Smith wrote:
> Dear All,
> 
> I am in need of generating artificial data for machine learning
> classification and regression analysis. What I am looking for is
> something similar to Python sklearn.datasets.make_classification and
> sklearn.datasets.make_regression:
> 
> https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> 
> https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> 
> I have searched CRAN for something similar, but found nothing. Could
> someone please help me with this?
> 
> Thanks in advance,
> 
> Paul
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From phh@80 @end|ng |rom gm@||@com  Thu Mar  3 22:11:46 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Thu, 3 Mar 2022 21:11:46 +0000
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
Message-ID: <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>

Sounds interesting, Tom! Thanks!

I am trying to find datasets for creating assignments for students of
a course of machine learning.

Paul



On Thu, Mar 3, 2022 at 9:04 PM Tom Woolman <twoolman at ontargettek.com> wrote:
>
> Hi Paul. Have you considered just going onto Kaggle and GitHub and
> searching for some of the many freely available real datasets that are
> posted there? I'm seeing a lot of productivity there days with research
> focused on data generation, and not just on creating algorithms and
> predictive models. Which is a good thing for us ;)
>
> One of the current research papers I'm working on now is based on mining
> a dataset I discovered on Kaggle a few months back and trying to create
> a novel solution for that. Proper credit will of course be provided in
> the citation references for the data provider.
>
>
> Thanks,
> Tom
>
>
> On 2022-03-03 16:00, Paul Smith wrote:
> > Dear All,
> >
> > I am in need of generating artificial data for machine learning
> > classification and regression analysis. What I am looking for is
> > something similar to Python sklearn.datasets.make_classification and
> > sklearn.datasets.make_regression:
> >
> > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> >
> > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> >
> > I have searched CRAN for something similar, but found nothing. Could
> > someone please help me with this?
> >
> > Thanks in advance,
> >
> > Paul
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar  3 23:29:26 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 4 Mar 2022 09:29:26 +1100
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
Message-ID: <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>

Hi Neha,
I think you're looking for the "cut" function.

Jim

On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Hello everyone
>
> I have a variable with about 5000 different values
>
> var1= c(0, 123, 400, .....4988)
>
> I want to convert it into different levels for some comparisons like
>
> if value is between 1-100 do something
> else
> do other things
>
> Is there any sophisticated way to do that than the following:
>
> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Mar  3 23:36:02 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 3 Mar 2022 23:36:02 +0100
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
Message-ID: <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>

Hello Jim

So, you believe the following way is better ?

var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))



On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Neha,
> I think you're looking for the "cut" function.
>
> Jim
>
> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > Hello everyone
> >
> > I have a variable with about 5000 different values
> >
> > var1= c(0, 123, 400, .....4988)
> >
> > I want to convert it into different levels for some comparisons like
> >
> > if value is between 1-100 do something
> > else
> > do other things
> >
> > Is there any sophisticated way to do that than the following:
> >
> > var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
> >
> > Thank you
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar  3 23:38:38 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 4 Mar 2022 09:38:38 +1100
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
 <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
Message-ID: <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>

Sorry, it was such an easy question that I didn't even read it
closely. Apparently using hist() is a bit faster. Whether this is
worth it, I don't know.

Jim

On Fri, Mar 4, 2022 at 9:36 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Hello Jim
>
> So, you believe the following way is better ?
>
> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>
>
>
> On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Neha,
>> I think you're looking for the "cut" function.
>>
>> Jim
>>
>> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>> >
>> > Hello everyone
>> >
>> > I have a variable with about 5000 different values
>> >
>> > var1= c(0, 123, 400, .....4988)
>> >
>> > I want to convert it into different levels for some comparisons like
>> >
>> > if value is between 1-100 do something
>> > else
>> > do other things
>> >
>> > Is there any sophisticated way to do that than the following:
>> >
>> > var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>> >
>> > Thank you
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Mar  3 23:43:00 2022
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 3 Mar 2022 17:43:00 -0500
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
 <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>
Message-ID: <CAM_vjunyqoY_yx-H7A0ynCyBcNsOkATCyaDym9PJRKY39RSmeA@mail.gmail.com>

Hi Paul,

If you aren't committed to creating your own, the cluster.datasets
package might be of interest. I've also used
http://cs.joensuu.fi/sipu/datasets/ quite often.

Sarah

On Thu, Mar 3, 2022 at 4:20 PM Paul Smith <phhs80 at gmail.com> wrote:
>
> Sounds interesting, Tom! Thanks!
>
> I am trying to find datasets for creating assignments for students of
> a course of machine learning.
>
> Paul
>
>
>
> On Thu, Mar 3, 2022 at 9:04 PM Tom Woolman <twoolman at ontargettek.com> wrote:
> >
> > Hi Paul. Have you considered just going onto Kaggle and GitHub and
> > searching for some of the many freely available real datasets that are
> > posted there? I'm seeing a lot of productivity there days with research
> > focused on data generation, and not just on creating algorithms and
> > predictive models. Which is a good thing for us ;)
> >
> > One of the current research papers I'm working on now is based on mining
> > a dataset I discovered on Kaggle a few months back and trying to create
> > a novel solution for that. Proper credit will of course be provided in
> > the citation references for the data provider.
> >
> >
> > Thanks,
> > Tom
> >
> >
> > On 2022-03-03 16:00, Paul Smith wrote:
> > > Dear All,
> > >
> > > I am in need of generating artificial data for machine learning
> > > classification and regression analysis. What I am looking for is
> > > something similar to Python sklearn.datasets.make_classification and
> > > sklearn.datasets.make_regression:
> > >
> > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> > >
> > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> > >
> > > I have searched CRAN for something similar, but found nothing. Could
> > > someone please help me with this?
> > >
> > > Thanks in advance,
> > >
> > > Paul
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From phh@80 @end|ng |rom gm@||@com  Fri Mar  4 00:01:05 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Thu, 3 Mar 2022 23:01:05 +0000
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CAM_vjunyqoY_yx-H7A0ynCyBcNsOkATCyaDym9PJRKY39RSmeA@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
 <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>
 <CAM_vjunyqoY_yx-H7A0ynCyBcNsOkATCyaDym9PJRKY39RSmeA@mail.gmail.com>
Message-ID: <CALS=5moP-0PJVnQEn2GJ2ZTruaHtwOTcn=yKgF2OTB_R+i-KSQ@mail.gmail.com>

Thanks, Sarah! Your answer is quite helpful!

Paul


On Thu, Mar 3, 2022 at 10:43 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> Hi Paul,
>
> If you aren't committed to creating your own, the cluster.datasets
> package might be of interest. I've also used
> http://cs.joensuu.fi/sipu/datasets/ quite often.
>
> Sarah
>
> On Thu, Mar 3, 2022 at 4:20 PM Paul Smith <phhs80 at gmail.com> wrote:
> >
> > Sounds interesting, Tom! Thanks!
> >
> > I am trying to find datasets for creating assignments for students of
> > a course of machine learning.
> >
> > Paul
> >
> >
> >
> > On Thu, Mar 3, 2022 at 9:04 PM Tom Woolman <twoolman at ontargettek.com> wrote:
> > >
> > > Hi Paul. Have you considered just going onto Kaggle and GitHub and
> > > searching for some of the many freely available real datasets that are
> > > posted there? I'm seeing a lot of productivity there days with research
> > > focused on data generation, and not just on creating algorithms and
> > > predictive models. Which is a good thing for us ;)
> > >
> > > One of the current research papers I'm working on now is based on mining
> > > a dataset I discovered on Kaggle a few months back and trying to create
> > > a novel solution for that. Proper credit will of course be provided in
> > > the citation references for the data provider.
> > >
> > >
> > > Thanks,
> > > Tom
> > >
> > >
> > > On 2022-03-03 16:00, Paul Smith wrote:
> > > > Dear All,
> > > >
> > > > I am in need of generating artificial data for machine learning
> > > > classification and regression analysis. What I am looking for is
> > > > something similar to Python sklearn.datasets.make_classification and
> > > > sklearn.datasets.make_regression:
> > > >
> > > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> > > >
> > > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> > > >
> > > > I have searched CRAN for something similar, but found nothing. Could
> > > > someone please help me with this?
> > > >
> > > > Thanks in advance,
> > > >
> > > > Paul
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Mar  4 00:06:39 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 3 Mar 2022 23:06:39 +0000
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
 <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
 <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>
Message-ID: <100bfeff-4894-3fb6-fdbc-9b33f612cd63@sapo.pt>

Hello,

And ?findInterval is faster than hist.

findInterval(x, c(-Inf, 500, 1000, 5000))

Also, before the cut code, the OP wrote


if value is between 1-100 do something


but in the breaks vector there's no 100. I guess this is not important, 
though, only the function to bin the data is.

Hope this helps,

Rui Barradas

?s 22:38 de 03/03/2022, Jim Lemon escreveu:
> Sorry, it was such an easy question that I didn't even read it
> closely. Apparently using hist() is a bit faster. Whether this is
> worth it, I don't know.
> 
> Jim
> 
> On Fri, Mar 4, 2022 at 9:36 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>>
>> Hello Jim
>>
>> So, you believe the following way is better ?
>>
>> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>>
>>
>>
>> On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Neha,
>>> I think you're looking for the "cut" function.
>>>
>>> Jim
>>>
>>> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>>>>
>>>> Hello everyone
>>>>
>>>> I have a variable with about 5000 different values
>>>>
>>>> var1= c(0, 123, 400, .....4988)
>>>>
>>>> I want to convert it into different levels for some comparisons like
>>>>
>>>> if value is between 1-100 do something
>>>> else
>>>> do other things
>>>>
>>>> Is there any sophisticated way to do that than the following:
>>>>
>>>> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>>>>
>>>> Thank you
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


