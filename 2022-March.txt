From e||z@_botto @end|ng |rom out|ook@com  Tue Mar  1 04:47:00 2022
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 1 Mar 2022 03:47:00 +0000
Subject: [R] setting zeros for the missing interval in data
Message-ID: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Dear useRs,

I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.

> dput(YY)

structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,

between

30 2021 2021/05/02 10:00:00 PM      0.2

and

30 2021 2021/05/02 10:55:00 PM      0.2

the values of rainfall depth for following "time stamps" are missing because they were "zero"

30 2021 2021/05/02 10:05:00 PM      0.0

30 2021 2021/05/02 10:10:00 PM      0.0

30 2021 2021/05/02 10:15:00 PM      0.0

30 2021 2021/05/02 10:20:00 PM      0.0

30 2021 2021/05/02 10:25:00 PM      0.0

30 2021 2021/05/02 10:30:00 PM      0.0

30 2021 2021/05/02 10:35:00 PM      0.0

30 2021 2021/05/02 10:40:00 PM      0.0

30 2021 2021/05/02 10:45:00 PM      0.0

30 2021 2021/05/02 10:50:00 PM      0.0

So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.

Thank You very much in advance,

Eliza



[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

	[[alternative HTML version deleted]]


From e||z@_botto @end|ng |rom out|ook@com  Tue Mar  1 04:52:47 2022
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 1 Mar 2022 03:52:47 +0000
Subject: [R] setting zeros for missing interval in data
Message-ID: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

[The data setting in the last email might be faulty]

Dear useRs,

I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.

> dput(YY)

structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,

between

30 2021 2021/05/02 10:00:00 PM      0.2

and

30 2021 2021/05/02 10:55:00 PM      0.2

the values of rainfall depth for following "time stamps" are missing because they were "zero"

30 2021 2021/05/02 10:05:00 PM      0.0

30 2021 2021/05/02 10:10:00 PM      0.0

30 2021 2021/05/02 10:15:00 PM      0.0

30 2021 2021/05/02 10:20:00 PM      0.0

30 2021 2021/05/02 10:25:00 PM      0.0

30 2021 2021/05/02 10:30:00 PM      0.0

30 2021 2021/05/02 10:35:00 PM      0.0

30 2021 2021/05/02 10:40:00 PM      0.0

30 2021 2021/05/02 10:45:00 PM      0.0

30 2021 2021/05/02 10:50:00 PM      0.0

So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.

Thank You very much in advance,

Eliza

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar  1 05:35:14 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 1 Mar 2022 15:35:14 +1100
Subject: [R] setting zeros for the missing interval in data
In-Reply-To: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>

Hi Eliza,
Your data wouldn't read for me, so I had to do some quick hacking to
get something to work with. It's a bit long, so I've attached what may
be a solution as an R source file.

Jim

On Tue, Mar 1, 2022 at 2:47 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
> > dput(YY)
>
> structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")
>
> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
> between
>
> 30 2021 2021/05/02 10:00:00 PM      0.2
>
> and
>
> 30 2021 2021/05/02 10:55:00 PM      0.2
>
> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
> 30 2021 2021/05/02 10:05:00 PM      0.0
>
> 30 2021 2021/05/02 10:10:00 PM      0.0
>
> 30 2021 2021/05/02 10:15:00 PM      0.0
>
> 30 2021 2021/05/02 10:20:00 PM      0.0
>
> 30 2021 2021/05/02 10:25:00 PM      0.0
>
> 30 2021 2021/05/02 10:30:00 PM      0.0
>
> 30 2021 2021/05/02 10:35:00 PM      0.0
>
> 30 2021 2021/05/02 10:40:00 PM      0.0
>
> 30 2021 2021/05/02 10:45:00 PM      0.0
>
> 30 2021 2021/05/02 10:50:00 PM      0.0
>
> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
> Thank You very much in advance,
>
> Eliza
>
>
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  1 05:46:34 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Feb 2022 20:46:34 -0800
Subject: [R] setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <E00A5313-DF88-480D-AA00-A4033CBBBD2F@dcn.davis.ca.us>

There are quite a variety of approaches implemented in various contributed packages, but here is a base R approach based on merge:

Sys.setenv(TZ = "UTC" ) # or other non-DST zone unless you need it
YY$TIMESTAMP <- as.POSIXct( YY$TIMESTAMP, format = "%Y/%m/%d %I:%M:%S %p" )
tlims <- as.POSIXct( c( "2021-05-02", "2021-05-10" ) )
tdiff <- as.difftime( 5, units="mins" )
aa <- seq( tlims[1], tlims[2], by = tdiff )
AA <- expand.grid( CHANNEL = 30, TIMESTAMP = aa )
yy <- merge( AA, YY[ , c( "CHANNEL", "TIMESTAMP", "RAINFALL" ) ], by = c( "CHANNEL", "TIMESTAMP" ), all.x = TRUE )
yy$RAINFALL[ is.na( yy$RAINFALL ) ] <- 0
yy


On February 28, 2022 7:52:47 PM PST, Eliza Botto <eliza_botto at outlook.com> wrote:
>[The data setting in the last email might be faulty]
>
>Dear useRs,
>
>I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
>> dput(YY)
>
>structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
>"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
>"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
>"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
>"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
>"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
>"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
>"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
>"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
>"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
>"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
>"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
>"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
>"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
>"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
>"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
>"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
>"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
>"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
>"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
>"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
>"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
>"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
>"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
>"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
>"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
>"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
>"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
>"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
>"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
>"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
>"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
>"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
>"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
>), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
>)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
>996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
>1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
>1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
>1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
>2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
>2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
>3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
>3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
>3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
>3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
>3932L, 3933L), class = "data.frame")
>
>You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
>between
>
>30 2021 2021/05/02 10:00:00 PM      0.2
>
>and
>
>30 2021 2021/05/02 10:55:00 PM      0.2
>
>the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
>30 2021 2021/05/02 10:05:00 PM      0.0
>
>30 2021 2021/05/02 10:10:00 PM      0.0
>
>30 2021 2021/05/02 10:15:00 PM      0.0
>
>30 2021 2021/05/02 10:20:00 PM      0.0
>
>30 2021 2021/05/02 10:25:00 PM      0.0
>
>30 2021 2021/05/02 10:30:00 PM      0.0
>
>30 2021 2021/05/02 10:35:00 PM      0.0
>
>30 2021 2021/05/02 10:40:00 PM      0.0
>
>30 2021 2021/05/02 10:45:00 PM      0.0
>
>30 2021 2021/05/02 10:50:00 PM      0.0
>
>So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
>Thank You very much in advance,
>
>Eliza
>
>[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar  1 05:59:43 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 1 Mar 2022 15:59:43 +1100
Subject: [R] setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fU1iWgDXczB6KBhBBAw018rN3O+kXxXfJYq+A6JG5ySmg@mail.gmail.com>

Hi Eliza,
It sure was:

YY$datetime<-strptime(YY$TIMESTAMP,"%Y/%m/%d %I:%M:%S %p")
dt5min<-seq(ISOdate(2021,5,1,0,5),ISOdate(2021,5,31,12,55),by="5 min")
newdt<-data.frame(datetime=dt5min)
newyy<-merge(newdt,YY,by="datetime",all=TRUE)
newyy$RAINFALL[is.na(newyy$RAINFALL)]<-0
plot(newyy$datetime,newyy$RAINFALL)

Jim

On Tue, Mar 1, 2022 at 2:57 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> [The data setting in the last email might be faulty]
>
> Dear useRs,
>
> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
> > dput(YY)
>
> structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")
>
> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
> between
>
> 30 2021 2021/05/02 10:00:00 PM      0.2
>
> and
>
> 30 2021 2021/05/02 10:55:00 PM      0.2
>
> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
> 30 2021 2021/05/02 10:05:00 PM      0.0
>
> 30 2021 2021/05/02 10:10:00 PM      0.0
>
> 30 2021 2021/05/02 10:15:00 PM      0.0
>
> 30 2021 2021/05/02 10:20:00 PM      0.0
>
> 30 2021 2021/05/02 10:25:00 PM      0.0
>
> 30 2021 2021/05/02 10:30:00 PM      0.0
>
> 30 2021 2021/05/02 10:35:00 PM      0.0
>
> 30 2021 2021/05/02 10:40:00 PM      0.0
>
> 30 2021 2021/05/02 10:45:00 PM      0.0
>
> 30 2021 2021/05/02 10:50:00 PM      0.0
>
> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
> Thank You very much in advance,
>
> Eliza
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>     Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Tue Mar  1 06:18:53 2022
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 1 Mar 2022 05:18:53 +0000
Subject: [R] [External]  setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <D92EAEA4-8181-4B87-81FB-5EF6FB61A19F@temple.edu>

I believe this is what you are looking for.
The idea is to set up the full range of interest and then subset into it with the values that you have observed.
I illustrate here with three days, you will need the full five months.


Start <- strptime("2021/05/02 10:00:00 PM", format="%Y/%m/%d %H:%M:%S", tz="GMT")
CompleteTimeSet <- Start + (0:(288*3))*5*60  ## 288 5min intervals per day, 3 days, 5*60=300 seconds per 5 minutes

YY <-
structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

CompleteData <- data.frame(TIMESTAMP=CompleteTimeSet, RAINFALL=0)
YYTIME <- strptime(YY$TIMESTAMP, format="%Y/%m/%d %H:%M:%S", tz="GMT")

CompleteData[CompleteData$TIMESTAMP %in% YYTIME[1:4], "RAINFALL"] <- YY$RAINFALL[1:4]
CompleteData


## output
> CompleteData[1:14,]
              TIMESTAMP RAINFALL
1   2021-05-02 10:00:00      0.2
2   2021-05-02 10:05:00      0.0
3   2021-05-02 10:10:00      0.0
4   2021-05-02 10:15:00      0.0
5   2021-05-02 10:20:00      0.0
6   2021-05-02 10:25:00      0.0
7   2021-05-02 10:30:00      0.0
8   2021-05-02 10:35:00      0.0
9   2021-05-02 10:40:00      0.0
10  2021-05-02 10:45:00      0.0
11  2021-05-02 10:50:00      0.0
12  2021-05-02 10:55:00      0.2
13  2021-05-02 11:00:00      0.0
14  2021-05-02 11:05:00      0.0


> On Feb 28, 2022, at 22:52, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
> structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Mar  1 06:49:19 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Mar 2022 05:49:19 +0000 (UTC)
Subject: [R] setting zeros for missing interval in data
In-Reply-To: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999415DA9E3164DB57EA9409A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <1296919232.1562114.1646113759202@mail.yahoo.com>

In base R, I wish the question below had been explained better. It is nice that an example was given, albeit misleading for me.

The data shown is not flawed and has nothing inside it that reflects being missing as it first sounded like.

What sounds like it is missing is specific dates entirely. The column called Channel seems irrelevant as it is always 30. Rain fall is always 0.2 or 0.4. The YEAR is always 2021. So the ONLY interesting thing here seems to be TIMESTAMP.

But I am NOT convinced they are missing because the times are all over the place. I mean 10 PM and 5:40 PM  and 5:20 AM and so on. There are multiple rows for the same day.

Yes, there is no info for May 1 and May 6 and 7. I have no idea why but How and why are we supposed to guess that it means no rain versus some other reason? Towards the end, what I think is the real message is shown. The suggestion is there should be data for every five minute period interpolated here

Fair enough. Can I suggest that the data offered to us has the TIMESTAMP field as character, rather than some form of DATE/TIME that can be used in Python?

Converting it or extracting some info into temporary columns might be useful here.

You could then create some kind of data that loops over times starting with your start time, say midnight on the 1st and for every 5 minute interval makes a timestamp that looks like what you need and COMPARE to what is in the data shown. For any that are nor present, you can create a similar row with a zero in it for the RAINFALL field. There are oodles of ways to do that, including some more straightforward than others. Or, you may just make the sequence or all, and later in some kind of merge, only keep ones from the original data if there is a duplicate. Again, many ways, even in base R.

If my analysis is right, and clearly it may not be, a much better way to ask this question might be to say you have timestamped data about rainfall where the readings for every 5 minute interval with no rainfall have been omitted. How do you create records for all 5-minute intervals that are not present and merge that info with the records shown?

As a hint, you can make a sequence like below, with your own adjustments for starting and ending dates.

> seq(from=as.POSIXct("2020-05-01 00:00"),to=as.POSIXct("2020-05-01 01:00"),by="5 min")
 [1] "2020-05-01 00:00:00 EDT" "2020-05-01 00:05:00 EDT" "2020-05-01 00:10:00 EDT"
 [4] "2020-05-01 00:15:00 EDT" "2020-05-01 00:20:00 EDT" "2020-05-01 00:25:00 EDT"
 [7] "2020-05-01 00:30:00 EDT" "2020-05-01 00:35:00 EDT" "2020-05-01 00:40:00 EDT"
[10] "2020-05-01 00:45:00 EDT" "2020-05-01 00:50:00 EDT" "2020-05-01 00:55:00 EDT"
[13] "2020-05-01 01:00:00 EDT"

Of course you may want to know WHY you need the missing data interpolated. Some graphics programs, if properly supplied with actual dates, not character strings, may simply skip missing records and leave room between others. The missing ones might be treated as zero, depending what you are doing.


-----Original Message-----
From: Eliza Botto <eliza_botto at outlook.com>
To: R-help at r-project.org <R-help at r-project.org>
Sent: Mon, Feb 28, 2022 10:52 pm
Subject: [R] setting zeros for missing interval in data

[The data setting in the last email might be faulty]

Dear useRs,

I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.

> dput(YY)

structure(list(CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
"2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
"2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
"2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
"2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
"2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
"2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
"2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
"2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
"2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
"2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
"2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
"2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
"2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
"2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
"2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
"2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
"2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
"2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
"2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
"2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
"2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
"2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
"2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
"2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
"2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
"2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
"2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
"2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
"2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
"2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
"2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
"2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
"2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
)), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
3932L, 3933L), class = "data.frame")

You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,

between

30 2021 2021/05/02 10:00:00 PM? ? ? 0.2

and

30 2021 2021/05/02 10:55:00 PM? ? ? 0.2

the values of rainfall depth for following "time stamps" are missing because they were "zero"

30 2021 2021/05/02 10:05:00 PM? ? ? 0.0

30 2021 2021/05/02 10:10:00 PM? ? ? 0.0

30 2021 2021/05/02 10:15:00 PM? ? ? 0.0

30 2021 2021/05/02 10:20:00 PM? ? ? 0.0

30 2021 2021/05/02 10:25:00 PM? ? ? 0.0

30 2021 2021/05/02 10:30:00 PM? ? ? 0.0

30 2021 2021/05/02 10:35:00 PM? ? ? 0.0

30 2021 2021/05/02 10:40:00 PM? ? ? 0.0

30 2021 2021/05/02 10:45:00 PM? ? ? 0.0

30 2021 2021/05/02 10:50:00 PM? ? ? 0.0

So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.

Thank You very much in advance,

Eliza

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>? ?  Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Mar  1 06:52:54 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Mar 2022 05:52:54 +0000 (UTC)
Subject: [R] setting zeros for the missing interval in data
In-Reply-To: <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>
References: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>
Message-ID: <1903735100.1560703.1646113974624@mail.yahoo.com>

Hi Jim,

Just FYI, your reply to Eliza likely included your attachment but the copy to this list has it stripped.

I suspect the world would just work better if forums like this moved from text-only email to something like groups.io that allow richer text and attachments, albeit they do make images fuzzier to save on space. 

Regardless,

Avi


-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com>
To: Eliza Botto <eliza_botto at outlook.com>
Cc: R-help at r-project.org <R-help at r-project.org>
Sent: Mon, Feb 28, 2022 11:35 pm
Subject: Re: [R] setting zeros for the missing interval in data


Hi Eliza,
Your data wouldn't read for me, so I had to do some quick hacking to
get something to work with. It's a bit long, so I've attached what may
be a solution as an R source file.

Jim

On Tue, Mar 1, 2022 at 2:47 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>
> > dput(YY)
>
> structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
> 3932L, 3933L), class = "data.frame")
>
> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>
> between
>
> 30 2021 2021/05/02 10:00:00 PM? ? ? 0.2
>
> and
>
> 30 2021 2021/05/02 10:55:00 PM? ? ? 0.2
>
> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>
> 30 2021 2021/05/02 10:05:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:10:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:15:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:20:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:25:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:30:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:35:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:40:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:45:00 PM? ? ? 0.0
>
> 30 2021 2021/05/02 10:50:00 PM? ? ? 0.0
>
> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>
> Thank You very much in advance,
>
> Eliza
>
>
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>? ?  Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  1 07:42:33 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Feb 2022 22:42:33 -0800
Subject: [R] setting zeros for the missing interval in data
In-Reply-To: <1903735100.1560703.1646113974624@mail.yahoo.com>
References: <AS8P194MB0999458978E8F395C2D8DEC39A029@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fUYxCO147MN+k_c7c388ygJ9AnERLdypr3Re93VM+i1oQ@mail.gmail.com>
 <1903735100.1560703.1646113974624@mail.yahoo.com>
Message-ID: <7195DBAF-8679-459E-BABC-4253EF4345B7@dcn.davis.ca.us>

Walled gardens are single points of failure. There are many of those out there already.

There are drawbacks to mailing lists also... there is room for both... but eliminating one in favor of the other is not necessary.

On February 28, 2022 9:52:54 PM PST, Avi Gross via R-help <r-help at r-project.org> wrote:
>Hi Jim,
>
>Just FYI, your reply to Eliza likely included your attachment but the copy to this list has it stripped.
>
>I suspect the world would just work better if forums like this moved from text-only email to something like groups.io that allow richer text and attachments, albeit they do make images fuzzier to save on space. 
>
>Regardless,
>
>Avi
>
>
>-----Original Message-----
>From: Jim Lemon <drjimlemon at gmail.com>
>To: Eliza Botto <eliza_botto at outlook.com>
>Cc: R-help at r-project.org <R-help at r-project.org>
>Sent: Mon, Feb 28, 2022 11:35 pm
>Subject: Re: [R] setting zeros for the missing interval in data
>
>
>Hi Eliza,
>Your data wouldn't read for me, so I had to do some quick hacking to
>get something to work with. It's a bit long, so I've attached what may
>be a solution as an R source file.
>
>Jim
>
>On Tue, Mar 1, 2022 at 2:47 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>>
>> Dear useRs,
>>
>> I have the following dataset which represents rainfall data at a 5-minute interval from 1 May 2021 to 30 September 2021.
>>
>> > dput(YY)
>>
>> structure(list(?..CHANNEL = c(30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
>> 30L, 30L), YEAR = c(2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L, 2021L,
>> 2021L, 2021L, 2021L, 2021L), TIMESTAMP = c("2021/05/02 10:00:00 PM",
>> "2021/05/02 10:55:00 PM", "2021/05/04 05:40:00 PM", "2021/05/04 06:50:00 PM",
>> "2021/05/05 03:05:00 AM", "2021/05/08 05:15:00 AM", "2021/05/08 05:20:00 AM",
>> "2021/05/08 05:30:00 AM", "2021/05/08 05:50:00 AM", "2021/05/08 06:05:00 AM",
>> "2021/05/08 07:15:00 AM", "2021/05/08 08:00:00 AM", "2021/05/08 08:05:00 AM",
>> "2021/05/08 08:15:00 AM", "2021/05/08 08:35:00 AM", "2021/05/08 08:50:00 AM",
>> "2021/05/08 09:05:00 AM", "2021/05/08 09:30:00 AM", "2021/05/08 09:45:00 AM",
>> "2021/05/08 09:55:00 AM", "2021/05/08 10:10:00 AM", "2021/05/08 10:20:00 AM",
>> "2021/05/08 10:40:00 AM", "2021/05/08 10:55:00 AM", "2021/05/08 11:15:00 AM",
>> "2021/05/08 11:25:00 AM", "2021/05/08 11:35:00 AM", "2021/05/08 11:45:00 AM",
>> "2021/05/08 11:50:00 AM", "2021/05/08 12:00:00 PM", "2021/05/08 12:05:00 PM",
>> "2021/05/08 12:15:00 PM", "2021/05/08 12:20:00 PM", "2021/05/08 12:30:00 PM",
>> "2021/05/08 12:35:00 PM", "2021/05/08 12:50:00 PM", "2021/05/08 01:35:00 PM",
>> "2021/05/08 01:50:00 PM", "2021/05/08 02:20:00 PM", "2021/05/08 02:30:00 PM",
>> "2021/05/08 02:35:00 PM", "2021/05/08 03:00:00 PM", "2021/05/08 03:35:00 PM",
>> "2021/05/08 03:45:00 PM", "2021/05/08 04:30:00 PM", "2021/05/08 04:40:00 PM",
>> "2021/05/08 04:55:00 PM", "2021/05/08 05:05:00 PM", "2021/05/08 05:20:00 PM",
>> "2021/05/08 07:25:00 PM", "2021/05/08 09:00:00 PM", "2021/05/08 09:25:00 PM",
>> "2021/05/08 09:50:00 PM", "2021/05/08 10:15:00 PM", "2021/05/08 10:40:00 PM",
>> "2021/05/08 11:35:00 PM", "2021/05/09 12:40:00 AM", "2021/05/09 01:10:00 AM",
>> "2021/05/09 02:10:00 AM", "2021/05/09 06:00:00 AM", "2021/05/09 02:40:00 PM",
>> "2021/05/09 02:45:00 PM", "2021/05/09 02:50:00 PM", "2021/05/09 02:55:00 PM",
>> "2021/05/09 03:00:00 PM", "2021/05/09 03:05:00 PM", "2021/05/09 03:10:00 PM",
>> "2021/05/09 03:15:00 PM", "2021/05/09 03:20:00 PM", "2021/05/09 03:25:00 PM",
>> "2021/05/09 03:30:00 PM", "2021/05/09 03:35:00 PM", "2021/05/09 03:40:00 PM",
>> "2021/05/09 03:45:00 PM", "2021/05/09 03:50:00 PM", "2021/05/09 03:55:00 PM",
>> "2021/05/09 04:00:00 PM", "2021/05/09 04:05:00 PM", "2021/05/09 04:10:00 PM",
>> "2021/05/09 04:15:00 PM", "2021/05/09 04:25:00 PM", "2021/05/09 04:30:00 PM",
>> "2021/05/09 04:35:00 PM", "2021/05/09 04:40:00 PM", "2021/05/09 04:45:00 PM",
>> "2021/05/09 04:50:00 PM", "2021/05/09 05:00:00 PM", "2021/05/09 05:05:00 PM",
>> "2021/05/09 05:10:00 PM", "2021/05/09 05:20:00 PM", "2021/05/09 05:25:00 PM",
>> "2021/05/09 05:35:00 PM", "2021/05/09 05:45:00 PM", "2021/05/09 05:50:00 PM",
>> "2021/05/09 06:00:00 PM", "2021/05/09 06:10:00 PM", "2021/05/09 06:20:00 PM",
>> "2021/05/09 06:30:00 PM", "2021/05/09 06:40:00 PM", "2021/05/09 06:50:00 PM"
>> ), RAINFALL = c(0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
>> 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2
>> )), row.names = c(276L, 286L, 599L, 773L, 829L, 951L, 955L, 971L,
>> 996L, 1014L, 1123L, 1242L, 1260L, 1301L, 1378L, 1422L, 1456L,
>> 1487L, 1504L, 1515L, 1539L, 1557L, 1597L, 1629L, 1679L, 1708L,
>> 1728L, 1757L, 1775L, 1803L, 1818L, 1846L, 1859L, 1882L, 1892L,
>> 1917L, 1983L, 2007L, 2050L, 2066L, 2077L, 2124L, 2190L, 2207L,
>> 2288L, 2309L, 2334L, 2351L, 2374L, 2518L, 2588L, 2600L, 2616L,
>> 2627L, 2639L, 2655L, 2674L, 2684L, 2725L, 2967L, 3826L, 3830L,
>> 3832L, 3838L, 3842L, 3845L, 3846L, 3851L, 3854L, 3856L, 3861L,
>> 3865L, 3868L, 3871L, 3873L, 3877L, 3880L, 3881L, 3885L, 3888L,
>> 3890L, 3893L, 3897L, 3899L, 3900L, 3902L, 3906L, 3907L, 3910L,
>> 3914L, 3915L, 3917L, 3920L, 3922L, 3923L, 3926L, 3928L, 3931L,
>> 3932L, 3933L), class = "data.frame")
>>
>> You could clearly see that there are some intervals which are missing from this dataset. For example, the data values for 1st of May are missing. Similarly,
>>
>> between
>>
>> 30 2021 2021/05/02 10:00:00 PM? ? ? 0.2
>>
>> and
>>
>> 30 2021 2021/05/02 10:55:00 PM? ? ? 0.2
>>
>> the values of rainfall depth for following "time stamps" are missing because they were "zero"
>>
>> 30 2021 2021/05/02 10:05:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:10:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:15:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:20:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:25:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:30:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:35:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:40:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:45:00 PM? ? ? 0.0
>>
>> 30 2021 2021/05/02 10:50:00 PM? ? ? 0.0
>>
>> So, what I want is a uniform list starting from 2021/05/01 to 2021/09/30 at every 5-minute intervals with "zero" values for the missing intervals in the original data list. I hope my question is clear.
>>
>> Thank You very much in advance,
>>
>> Eliza
>>
>>
>>
>> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-green-avg-v1.png]<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>? ?  Virus-free. www.avg.com<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>
>>? ? ? ?  [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Tue Mar  1 08:10:33 2022
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Tue, 1 Mar 2022 07:10:33 +0000
Subject: [R] plain passwords in reminder mail
Message-ID: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>

Dear list,

The list membership reminder mail includes a plain password!

Regards, Eduard


-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20220301/762e0aac/attachment.sig>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  1 08:41:10 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 28 Feb 2022 23:41:10 -0800
Subject: [R] plain passwords in reminder mail
In-Reply-To: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
References: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
Message-ID: <37325DE9-C565-4F75-9579-6C422A8F1206@dcn.davis.ca.us>

https://www.urbandictionary.com/define.php?term=news%20at%2011&amp=true&defid=1443637

If there were problems associated with this behavior that were worse than the problems with not having it, it probably would have been changed after decades of being this way.

On February 28, 2022 11:10:33 PM PST, Eduard Drenth <edrenth at fryske-akademy.nl> wrote:
>Dear list,
>
>The list membership reminder mail includes a plain password!
>
>Regards, Eduard
>
>

-- 
Sent from my phone. Please excuse my brevity.


From m|n@h@|| @end|ng |rom um|ch@edu  Tue Mar  1 15:13:56 2022
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Tue, 01 Mar 2022 06:13:56 -0800
Subject: [R] plain passwords in reminder mail
In-Reply-To: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
References: <8e4005627d6f1bd2d27357d5531ca0a6bcef8d25.camel@fryske-akademy.nl>
Message-ID: <4055256.1646144036@apollo2.minshall.org>

Eduard,

> The list membership reminder mail includes a plain password!

this is very typical for, at least, mailman-supported, e-mail lists.
the password is of low intrinsic value, as it only allows you to change
your membership and options on the list.

cheers, Greg


From Ro@@@Boy|@n @end|ng |rom uc@|@edu  Wed Mar  2 02:51:04 2022
From: Ro@@@Boy|@n @end|ng |rom uc@|@edu (Boylan, Ross)
Date: Wed, 2 Mar 2022 01:51:04 +0000
Subject: [R] Time Zone problems: midnight goes in; 8am comes out
Message-ID: <BY3PR05MB811676D913B9117776364CDE87039@BY3PR05MB8116.namprd05.prod.outlook.com>

I'm having problems with timezones using lubridate, but it's not clear to me the difficulty is in lubridate.
---------------------------------
> r2 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz="PST")
> r2
[1] "1970-01-01 08:01:00 PST"  ## Oops: midnight has turned in 8am
> as.numeric(r2)
[1] 28860
> 8*3600 # seconds in 8 hours
[1] 28800
------------------------------------
lubridate accepts PST as the time zone, and the result prints "PST" for timezone.  Further, lubridate seems to be using the tz properly since it gets the 8 hour offset from UTC correct.

The problem is the value that is printed gives a UTC time of 08:01 despite having the PST suffix.  So the time appears to have jumped 8 hours ahead from the value parsed.

PST appears not to be a legal timezone (in spite of lubridate inferring the correct offset from it):
---------------------------------------------------
> Sys.timezone()
[1] "America/Los_Angeles"

> (grep("PST", OlsonNames(), value=TRUE))
[1] "PST8PDT"         "SystemV/PST8"    "SystemV/PST8PDT"
-------------------------------------
https://www.r-bloggers.com/2018/07/a-tour-of-timezones-troubles-in-r/ says lubridate will complain if given an invalid tz, though I don't see that explicitly in the current man page https://lubridate.tidyverse.org/reference/parse_date_time.html.  As shown above, parse_date_time() does not complain about the timezone, and does use it to get the correct offset.

Using America/Los_Angeles produces the expected results:
---------------------------------------
> r4 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz=Sys.timezone())
> r4
[1] "1970-01-01 00:01:00 PST"  # still prints PST.  This time it's true!
> as.numeric(r4)
[1] 28860
----------------------------------------------------

I suppose I can just use "America/Los_Angeles" as the time zone; this would have the advantage of making all my timezones the same, which apparently what R requires for a vector of datetimes.  But the behavior seems odd, and the "fix" also requires me to ignore the time zone specified in my inputs, which look like "2022-03-01 15:54:30 PST" or PDT, depending on time of year.

1. Why this strange behavior in which PST or PDT is used to construct the proper offset from UTC, and then kind of forgotten on output?
2. Is this a bug in lubridate or base POSIXct, particularly its print routine?

My theory on 1 is that lubridate understands PST and constructs an appropriate UTC time.  POSIXct time does not understand a tz of "PST" and so prints out the UTC value for the time, "decorating" it with the not understood tz value.  

For 2, on one hand, lubridate is constructing POSIXct dates with invalid tz values; lubridate probably shouldn't.  On the other hand, POSIXct is printing a UTC time but labeling it with a tz it doesn't understand, so it looks if it's in that local time even though it isn't.  In the context above that seems like a bug, but it's possible a lot of code that depends on it.

Under these theories, the problems only arise because the set of tz values understood by lubridate differs from the tz value understood by POSIXct.

Versions:
R 3.5.2
lubridate 1.7.4
Debian GNU/Linux 10 aka buster (amd64 flavor)

Thanks.
Ross Boylan

From @kw@|mmo @end|ng |rom gm@||@com  Wed Mar  2 03:50:31 2022
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 1 Mar 2022 21:50:31 -0500
Subject: [R] Time Zone problems: midnight goes in; 8am comes out
In-Reply-To: <BY3PR05MB811676D913B9117776364CDE87039@BY3PR05MB8116.namprd05.prod.outlook.com>
References: <BY3PR05MB811676D913B9117776364CDE87039@BY3PR05MB8116.namprd05.prod.outlook.com>
Message-ID: <CAPcHnpTELPUMZ8FB9O86VwJWwc5=d+ERS=ct2YXvxfnfFG_=mw@mail.gmail.com>

It seems like the current version of lubridate is 1.8.0, which does
raise a warning for an invalid timezone, just like as.POSIXct. This is
what I tried:


print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd
HMS"          , tz = "PST"))
print(as.POSIXct                ("1970-01-01 00:01:00", format =
"%Y-%m-%d %H:%M:%S", tz = "PST"))


outputs:


> print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd HMS"          , tz = "PST"))
[1] "1970-01-01 08:01:00 GMT"
Warning message:
In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
> print(as.POSIXct                ("1970-01-01 00:01:00", format = "%Y-%m-%d %H:%M:%S", tz = "PST"))
[1] "1970-01-01 00:01:00 GMT"
Warning messages:
1: In strptime(x, format, tz = tz) : unknown timezone 'PST'
2: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'PST'
3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
>


But I don't see the same problem when using `tz =
"America/Los_Angeles"` or `tz = "PST8PDT"`.


print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd
HMS"          , tz = "PST8PDT"))
print(as.POSIXct                ("1970-01-01 00:01:00", format =
"%Y-%m-%d %H:%M:%S", tz = "PST8PDT"))


outputs:


> print(lubridate::parse_date_time("1970-01-01 00:01:00",          "ymd HMS"          , tz = "PST8PDT"))
[1] "1970-01-01 00:01:00 PST"
> print(as.POSIXct                ("1970-01-01 00:01:00", format = "%Y-%m-%d %H:%M:%S", tz = "PST8PDT"))
[1] "1970-01-01 00:01:00 PST"
>


I would hesitate to use `tz = Sys.timezone()` because someone from
another province/state might not be able to use your code. Depends on
whether this work is being shared with other people though, up to you.

On Tue, Mar 1, 2022 at 8:51 PM Boylan, Ross via R-help
<r-help at r-project.org> wrote:
>
> I'm having problems with timezones using lubridate, but it's not clear to me the difficulty is in lubridate.
> ---------------------------------
> > r2 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz="PST")
> > r2
> [1] "1970-01-01 08:01:00 PST"  ## Oops: midnight has turned in 8am
> > as.numeric(r2)
> [1] 28860
> > 8*3600 # seconds in 8 hours
> [1] 28800
> ------------------------------------
> lubridate accepts PST as the time zone, and the result prints "PST" for timezone.  Further, lubridate seems to be using the tz properly since it gets the 8 hour offset from UTC correct.
>
> The problem is the value that is printed gives a UTC time of 08:01 despite having the PST suffix.  So the time appears to have jumped 8 hours ahead from the value parsed.
>
> PST appears not to be a legal timezone (in spite of lubridate inferring the correct offset from it):
> ---------------------------------------------------
> > Sys.timezone()
> [1] "America/Los_Angeles"
>
> > (grep("PST", OlsonNames(), value=TRUE))
> [1] "PST8PDT"         "SystemV/PST8"    "SystemV/PST8PDT"
> -------------------------------------
> https://www.r-bloggers.com/2018/07/a-tour-of-timezones-troubles-in-r/ says lubridate will complain if given an invalid tz, though I don't see that explicitly in the current man page https://lubridate.tidyverse.org/reference/parse_date_time.html.  As shown above, parse_date_time() does not complain about the timezone, and does use it to get the correct offset.
>
> Using America/Los_Angeles produces the expected results:
> ---------------------------------------
> > r4 <- parse_date_time("1970-01-01 00:01:00", "ymd HMS", tz=Sys.timezone())
> > r4
> [1] "1970-01-01 00:01:00 PST"  # still prints PST.  This time it's true!
> > as.numeric(r4)
> [1] 28860
> ----------------------------------------------------
>
> I suppose I can just use "America/Los_Angeles" as the time zone; this would have the advantage of making all my timezones the same, which apparently what R requires for a vector of datetimes.  But the behavior seems odd, and the "fix" also requires me to ignore the time zone specified in my inputs, which look like "2022-03-01 15:54:30 PST" or PDT, depending on time of year.
>
> 1. Why this strange behavior in which PST or PDT is used to construct the proper offset from UTC, and then kind of forgotten on output?
> 2. Is this a bug in lubridate or base POSIXct, particularly its print routine?
>
> My theory on 1 is that lubridate understands PST and constructs an appropriate UTC time.  POSIXct time does not understand a tz of "PST" and so prints out the UTC value for the time, "decorating" it with the not understood tz value.
>
> For 2, on one hand, lubridate is constructing POSIXct dates with invalid tz values; lubridate probably shouldn't.  On the other hand, POSIXct is printing a UTC time but labeling it with a tz it doesn't understand, so it looks if it's in that local time even though it isn't.  In the context above that seems like a bug, but it's possible a lot of code that depends on it.
>
> Under these theories, the problems only arise because the set of tz values understood by lubridate differs from the tz value understood by POSIXct.
>
> Versions:
> R 3.5.2
> lubridate 1.7.4
> Debian GNU/Linux 10 aka buster (amd64 flavor)
>
> Thanks.
> Ross Boylan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mtenneke@ @end|ng |rom gm@||@com  Wed Mar  2 10:52:04 2022
From: mtenneke@ @end|ng |rom gm@||@com (Martijn Tennekes)
Date: Wed, 2 Mar 2022 10:52:04 +0100
Subject: [R] dev.size() does not return correct size on 4K screen
Message-ID: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>

dev.size() does not return the correct screen size when using a 4K 
screen. With the R console and a x11() device, it seems to overestimate 
with factor 1.5, and in RStudio underestimate with factor 2.

See also https://github.com/rstudio/rstudio/issues/10723

Is this a bug, or is there something I can do?

Best,

Martijn Tennekes

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Mar  2 23:11:57 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 2 Mar 2022 23:11:57 +0100
Subject: [R] dev.size() does not return correct size on 4K screen
In-Reply-To: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>
References: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>
Message-ID: <D4C3DCA2-A3F3-4B4F-BDF1-F0E1C1E16514@gmail.com>

I don't know about RStudio, but in X11 this sort of thing can happen due to misconfiguration of the display itself, i.e. not in R as such. Basically, it relies on getting the correct dots-per-inch value from the display, and may otherwise use some standard value. 

What happens if you run xdpyinfo in a terminal window?

With XQuartz on an MB Air, I see

...
screen #0:
  dimensions:    1440x876 pixels (381x232 millimeters)
  resolution:    96x96 dots per inch
...

which is a multi-way lie! It is a 2560x1600 retina display, the resolution is way higher than 96x96, and it is 13.3", whereas the stated dimensions corresponds to a 17" diagonal. 

However, systems may be "lying in the users best interest", since e.g. the default for an X11() plot window is 7in square, which might not fit on a small laptop. You are somewhat more likely to want the same relative size across different laptops.  

- pd

> On 2 Mar 2022, at 10:52 , Martijn Tennekes <mtennekes at gmail.com> wrote:
> 
> dev.size() does not return the correct screen size when using a 4K 
> screen. With the R console and a x11() device, it seems to overestimate 
> with factor 1.5, and in RStudio underestimate with factor 2.
> 
> See also https://github.com/rstudio/rstudio/issues/10723
> 
> Is this a bug, or is there something I can do?
> 
> Best,
> 
> Martijn Tennekes
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Mar  2 23:54:43 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 2 Mar 2022 17:54:43 -0500
Subject: [R] How to automatically set R to read the files from a specific
 location
Message-ID: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>

Dear friends,

I am working on an assignment using R, and I would like to set my R code so
that R automatically recognizes where the files that need to be read are
without having to use the absolute path?
The idea is that when I send my .R script and my professor receives it, he
can just execute the code without running into any issues.

Thanks, beforehand, for your valuable feedback.

Cheers,
Paul

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Mar  3 00:07:17 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 2 Mar 2022 15:07:17 -0800
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
Message-ID: <CAGxFJbRpjVNjO07+qWu=w_rOiHg0+DK5E5n3ECDMzHPpfSnkTg@mail.gmail.com>

I may well be wrong, but I believe you will need to give more info on
where the files are located (e.g. on a remote server, on a website, a
local machine, ...), whether they consist only of data or whether
there are packages with functions that need to be used, etc.

A better approach might be to combine data and files into a package,
put the package where you all have access, and then give your prof the
code to download it from there.

Others may have better ideas, so do wait for more responses.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 2, 2022 at 2:55 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> I am working on an assignment using R, and I would like to set my R code so
> that R automatically recognizes where the files that need to be read are
> without having to use the absolute path?
> The idea is that when I send my .R script and my professor receives it, he
> can just execute the code without running into any issues.
>
> Thanks, beforehand, for your valuable feedback.
>
> Cheers,
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Mar  3 00:27:58 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Mar 2022 15:27:58 -0800
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
Message-ID: <B1EB47AE-AC31-43B3-AF6F-E498D11B717D@dcn.davis.ca.us>

1) make a working directory. Put all related files (including your R file(s) in that directory or in subdirectories.
2) Set your working directory as "current" before starting R. If you or anyone who wants to use your code does this, no actions will be needed in the script to "change" the directory. This is straightforward at the shell using "cd", and GUI file managers will normally do this automatically for you if you "open" a file using an action that triggers starting R from there. RStudio uses the .Rproj file to serve this purpose, so if you use RStudio then always create a Project for each separate "project" you work on.
3) Use relative paths in your code. You can access a csv file in your working directory as "filename.csv" or in a subdirectory data_dir of your working directory using "data_dir/filename.csv".
4) Send a zip archive of your "project" directory/contents to the recipient so the relative locations of files is maintained. Or consider using GitHub (e.g. [1]) to share and track changes.

Note that sometimes you may not want to include the data in your project directory because switching data sets will be common. In that case you cannot achieve this goal, but you can use a global variable to specify your data directory path and use file.path( dtadir, fname ) wherever your specify a file for input. The recipient then only needs to alter one line of your code.

[1] https://happygitwithr.com/

On March 2, 2022 2:54:43 PM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>I am working on an assignment using R, and I would like to set my R code so
>that R automatically recognizes where the files that need to be read are
>without having to use the absolute path?
>The idea is that when I send my .R script and my professor receives it, he
>can just execute the code without running into any issues.
>
>Thanks, beforehand, for your valuable feedback.
>
>Cheers,
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Mar  3 02:02:03 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 3 Mar 2022 01:02:03 +0000 (UTC)
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAGxFJbRpjVNjO07+qWu=w_rOiHg0+DK5E5n3ECDMzHPpfSnkTg@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
 <CAGxFJbRpjVNjO07+qWu=w_rOiHg0+DK5E5n3ECDMzHPpfSnkTg@mail.gmail.com>
Message-ID: <1505692023.226581.1646269323492@mail.yahoo.com>

All reasonable answers so far to the question but what is missing here is what the ASSIGNMENT is. Are the student(s) and professors/teachers sharing an environment on a multi-tasking machine or some networked situation or each is alone?
If I were teaching a class, I might be supplying the data files to be used and hence have a local copy on my machine in a designated area. This same issue comes up when someone asks me to do some analysis for them, sometimes without my having a copy of the data file, just knowing details about what it contains, such as column headers in a CSV.
So it is possibly something the teacher should have taught and set up. For example, they can tell you the file is in /usr/tmp (or whatever shared area) or a networked alternative where you are asked to copy the file into some local directory and setwd() into that directory and the? program is to be run from THAT directory. That makes it simple as each user can place the file anywhere they wish.
An alternative, as pointed out, is to ask the person to edit one line of? the R script being supplied such as:
WHERE <- "C:/..."setwd(WHERE)
Or, as pointed out, R has utilities to easily splice together a filename, as simple as:
FILE <- "xyz.csv"FULL_NAME <- paste(WHERE, "/", FILE)
and in operations on the file, use FULL_NAME.
Whatever method is used can be implemented best if you get instructions. If the Professor wants to see your program, the above and variants should work. If they just want to see the output file for correctness, and do not plan on running the R script, then attaching the output results in an email might do.
NOTE, I used slash notation for directory structures above as it is most portable. Of course, if everyone is on something like MS Windows, you have the option of doubled backslashes and so on. Some R utilities handle this better and might be preferable to what I show as a SIMPLE example using base R.

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com>
To: Paul Bernal <paulbernal07 at gmail.com>
Cc: R <r-help at r-project.org>
Sent: Wed, Mar 2, 2022 6:07 pm
Subject: Re: [R] How to automatically set R to read the files from a specific location

I may well be wrong, but I believe you will need to give more info on
where the files are located (e.g. on a remote server, on a website, a
local machine, ...), whether they consist only of data or whether
there are packages with functions that need to be used, etc.

A better approach might be to combine data and files into a package,
put the package where you all have access, and then give your prof the
code to download it from there.

Others may have better ideas, so do wait for more responses.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 2, 2022 at 2:55 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> I am working on an assignment using R, and I would like to set my R code so
> that R automatically recognizes where the files that need to be read are
> without having to use the absolute path?
> The idea is that when I send my .R script and my professor receives it, he
> can just execute the code without running into any issues.
>
> Thanks, beforehand, for your valuable feedback.
>
> Cheers,
> Paul
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Mar  3 02:08:10 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 3 Mar 2022 01:08:10 +0000 (UTC)
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
Message-ID: <456822666.230862.1646269690844@mail.yahoo.com>


Just a silly? thought, Paul. If this is really for a class and the file(s) being used are small enough, you can play a game where the data is already in the R program and is simply written into a file at the start in the current directory or a designated area. If that succeeds, you can then have the program start as if from scratch and read it back in and continue.?
An alternative if the file is not local but in a known place that can be reached, is code that copies it here ...
Of course in real life with existing huge files, not so much a good idea. But many programming assignments to students use smaller data sets. Some require having loaded a package and then have an access method to make the data visible and loaded. As long as the professor and others all have the same package, ...

-----Original Message-----
From: Paul Bernal <paulbernal07 at gmail.com>
To: R <r-help at r-project.org>
Sent: Wed, Mar 2, 2022 5:54 pm
Subject: [R] How to automatically set R to read the files from a specific location

Dear friends,

I am working on an assignment using R, and I would like to set my R code so
that R automatically recognizes where the files that need to be read are
without having to use the absolute path?
The idea is that when I send my .R script and my professor receives it, he
can just execute the code without running into any issues.

Thanks, beforehand, for your valuable feedback.

Cheers,
Paul

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Mar  3 07:50:58 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 3 Mar 2022 08:50:58 +0200
Subject: [R] 
 How to automatically set R to read the files from a specific
 location
In-Reply-To: <456822666.230862.1646269690844@mail.yahoo.com>
References: <CAMOcQfMVNetB3KQA9+SWWxZksHFbHyBtEWr5HoxK=Q0+-w7r1g@mail.gmail.com>
 <456822666.230862.1646269690844@mail.yahoo.com>
Message-ID: <CAGgJW75-jaTK3jTf1yKqycsXx4PE9QE43v+=NthpgKAkC7CeZg@mail.gmail.com>

YAA (Yet Another Approach)
If the data is part of the assignment then the instructor presumably has a
copy of the data file(s).
Your script could get the location of these files via an environment
variable using Sys.getenv().
The instructor would need to set the environment variable prior to running
your script.
Your script should issue an error if the environment variable has not been
set.


On Thu, Mar 3, 2022 at 3:12 AM Avi Gross via R-help <r-help at r-project.org>
wrote:

>
> Just a silly  thought, Paul. If this is really for a class and the file(s)
> being used are small enough, you can play a game where the data is already
> in the R program and is simply written into a file at the start in the
> current directory or a designated area. If that succeeds, you can then have
> the program start as if from scratch and read it back in and continue.
> An alternative if the file is not local but in a known place that can be
> reached, is code that copies it here ...
> Of course in real life with existing huge files, not so much a good idea.
> But many programming assignments to students use smaller data sets. Some
> require having loaded a package and then have an access method to make the
> data visible and loaded. As long as the professor and others all have the
> same package, ...
>
> -----Original Message-----
> From: Paul Bernal <paulbernal07 at gmail.com>
> To: R <r-help at r-project.org>
> Sent: Wed, Mar 2, 2022 5:54 pm
> Subject: [R] How to automatically set R to read the files from a specific
> location
>
> Dear friends,
>
> I am working on an assignment using R, and I would like to set my R code so
> that R automatically recognizes where the files that need to be read are
> without having to use the absolute path?
> The idea is that when I send my .R script and my professor receives it, he
> can just execute the code without running into any issues.
>
> Thanks, beforehand, for your valuable feedback.
>
> Cheers,
> Paul
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @tch|rume @end|ng |rom gm@||@com  Thu Mar  3 08:43:32 2022
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Thu, 3 Mar 2022 09:43:32 +0200
Subject: [R] Applying HP and BP filters to calculate potential GDP
 (de-trending)
In-Reply-To: <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
Message-ID: <CAFfFd+vJ4pN0LSvFMvgC7TDD86d0VFuneaUDpAMonFm8sGkv9w@mail.gmail.com>

Goodday, i hope i find you well. Kindly assist me on how to apply the HP
and BP filetrs to the following data set.

Thank you in advance.

Admire

From mtenneke@ @end|ng |rom gm@||@com  Thu Mar  3 11:03:44 2022
From: mtenneke@ @end|ng |rom gm@||@com (Martijn Tennekes)
Date: Thu, 3 Mar 2022 11:03:44 +0100
Subject: [R] dev.size() does not return correct size on 4K screen
In-Reply-To: <D4C3DCA2-A3F3-4B4F-BDF1-F0E1C1E16514@gmail.com>
References: <5fa37950-9685-2000-905d-77290d91242a@gmail.com>
 <D4C3DCA2-A3F3-4B4F-BDF1-F0E1C1E16514@gmail.com>
Message-ID: <aa8bd759-abdc-a821-147f-fb5530e1c893@gmail.com>

Thank you, Peter!


 From xdpyinfo I got

screen #0:
 ? dimensions:??? 5120x2880 pixels (903x508 millimeters)
 ? resolution:??? 144x144 dots per inch

According to these specs my screen should have a sqrt((5120/144)^2 + 
(2880/144)^2) = 40.8" diagonal.

However, in practice it is 27", so that perfectly explains the 1.5 
factor difference.


In RStudio, dev.size() is not equal to par("fin"), which caused the 
problem for me. I the R terminal, these two are equal. I'll post this in 
the RStudio issue list.


Best,

Martijn



On 3/2/22 23:11, peter dalgaard wrote:
> I don't know about RStudio, but in X11 this sort of thing can happen due to misconfiguration of the display itself, i.e. not in R as such. Basically, it relies on getting the correct dots-per-inch value from the display, and may otherwise use some standard value.
>
> What happens if you run xdpyinfo in a terminal window?
>
> With XQuartz on an MB Air, I see
>
> ...
> screen #0:
>    dimensions:    1440x876 pixels (381x232 millimeters)
>    resolution:    96x96 dots per inch
> ...
>
> which is a multi-way lie! It is a 2560x1600 retina display, the resolution is way higher than 96x96, and it is 13.3", whereas the stated dimensions corresponds to a 17" diagonal.
>
> However, systems may be "lying in the users best interest", since e.g. the default for an X11() plot window is 7in square, which might not fit on a small laptop. You are somewhat more likely to want the same relative size across different laptops.
>
> - pd
>
>> On 2 Mar 2022, at 10:52 , Martijn Tennekes <mtennekes at gmail.com> wrote:
>>
>> dev.size() does not return the correct screen size when using a 4K
>> screen. With the R console and a x11() device, it seems to overestimate
>> with factor 1.5, and in RStudio underestimate with factor 2.
>>
>> See also https://github.com/rstudio/rstudio/issues/10723
>>
>> Is this a bug, or is there something I can do?
>>
>> Best,
>>
>> Martijn Tennekes
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From n@d|ne@@|o|@b| @end|ng |rom gm@||@com  Thu Mar  3 13:15:35 2022
From: n@d|ne@@|o|@b| @end|ng |rom gm@||@com (Nadine Afolabi)
Date: Thu, 3 Mar 2022 13:15:35 +0100
Subject: [R] Error: `[.data.frame`(crossloadings, , c("name", "block",
 colnames(xloads))) : undefined columns
Message-ID: <CADG3JTyZdefXa6Vcr5QKRATxoApvYVKixUeuANavHO_-CR1__A@mail.gmail.com>

Hello,

I am trying to analyse a SEM with R and got the following error. I do not
know what I?ve done worng as it always worked in my previous projects. I
need your help please. Thank you.

> blocks = list(1:26, 27:47, 48:51, 52:75)
> library(plspm)
> r1= c(0,0,0,0)
> r2= c(1,0,0,0)
> r3= c(1,0,0,0)
> r4= c(1,0,0,0)
> path = rbind(r1, r2, r3, r4)
> rownames(path)= c("Leadership", "Work Values","Employee Motivation",
"Commitment")
> colnames(path)= rownames(path)
> innerplot(path)
> t(colnames(newsurvey))
> blocks = list(1:26, 27:47, 48:51, 52:75)
> modes=rep("A",4)
> pls= plspm(newsurvey, path, blocks, modes = modes)
Fehler in `[.data.frame`(crossloadings, , c("name", "block",
colnames(xloads))) :
  nicht definierte Spalten gew?hlt
Zus?tzlich: Warnmeldung:
Setting row names on a tibble is deprecated.

Regards,
Nadine

	[[alternative HTML version deleted]]


From |r@|nj @end|ng |rom gm@||@com  Thu Mar  3 20:48:52 2022
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Thu, 3 Mar 2022 19:48:52 +0000
Subject: [R] Applying HP and BP filters to calculate potential GDP
 (de-trending)
In-Reply-To: <CAFfFd+vJ4pN0LSvFMvgC7TDD86d0VFuneaUDpAMonFm8sGkv9w@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
 <CAFfFd+vJ4pN0LSvFMvgC7TDD86d0VFuneaUDpAMonFm8sGkv9w@mail.gmail.com>
Message-ID: <CAHrK514HS2zJz609BXSN2K1aFPfh7i2KQuu2=5Nn14_aupy4+A@mail.gmail.com>

Have you looked at the mFilter package. You may also find the time series
task view useful.  Your dataset was not attached,  It may have been in a
format not accepted by the mailing list. Have a read of the posting guide.

On Thu, 3 Mar 2022, 07:44 Admire Tarisirayi Chirume, <atchirume at gmail.com>
wrote:

> Goodday, i hope i find you well. Kindly assist me on how to apply the HP
> and BP filetrs to the following data set.
>
> Thank you in advance.
>
> Admire
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phh@80 @end|ng |rom gm@||@com  Thu Mar  3 22:00:08 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Thu, 3 Mar 2022 21:00:08 +0000
Subject: [R] Looking for package for data generation for classification and
 regression
Message-ID: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>

Dear All,

I am in need of generating artificial data for machine learning
classification and regression analysis. What I am looking for is
something similar to Python sklearn.datasets.make_classification and
sklearn.datasets.make_regression:

https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html

https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html

I have searched CRAN for something similar, but found nothing. Could
someone please help me with this?

Thanks in advance,

Paul


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Mar  3 22:01:29 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 3 Mar 2022 22:01:29 +0100
Subject: [R] Continuous variable into levels
Message-ID: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>

Hello everyone

I have a variable with about 5000 different values

var1= c(0, 123, 400, .....4988)

I want to convert it into different levels for some comparisons like

if value is between 1-100 do something
else
do other things

Is there any sophisticated way to do that than the following:

var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))

Thank you

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Mar  3 22:04:15 2022
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Thu, 03 Mar 2022 16:04:15 -0500
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
Message-ID: <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>

Hi Paul. Have you considered just going onto Kaggle and GitHub and 
searching for some of the many freely available real datasets that are 
posted there? I'm seeing a lot of productivity there days with research 
focused on data generation, and not just on creating algorithms and 
predictive models. Which is a good thing for us ;)

One of the current research papers I'm working on now is based on mining 
a dataset I discovered on Kaggle a few months back and trying to create 
a novel solution for that. Proper credit will of course be provided in 
the citation references for the data provider.


Thanks,
Tom


On 2022-03-03 16:00, Paul Smith wrote:
> Dear All,
> 
> I am in need of generating artificial data for machine learning
> classification and regression analysis. What I am looking for is
> something similar to Python sklearn.datasets.make_classification and
> sklearn.datasets.make_regression:
> 
> https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> 
> https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> 
> I have searched CRAN for something similar, but found nothing. Could
> someone please help me with this?
> 
> Thanks in advance,
> 
> Paul
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From phh@80 @end|ng |rom gm@||@com  Thu Mar  3 22:11:46 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Thu, 3 Mar 2022 21:11:46 +0000
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
Message-ID: <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>

Sounds interesting, Tom! Thanks!

I am trying to find datasets for creating assignments for students of
a course of machine learning.

Paul



On Thu, Mar 3, 2022 at 9:04 PM Tom Woolman <twoolman at ontargettek.com> wrote:
>
> Hi Paul. Have you considered just going onto Kaggle and GitHub and
> searching for some of the many freely available real datasets that are
> posted there? I'm seeing a lot of productivity there days with research
> focused on data generation, and not just on creating algorithms and
> predictive models. Which is a good thing for us ;)
>
> One of the current research papers I'm working on now is based on mining
> a dataset I discovered on Kaggle a few months back and trying to create
> a novel solution for that. Proper credit will of course be provided in
> the citation references for the data provider.
>
>
> Thanks,
> Tom
>
>
> On 2022-03-03 16:00, Paul Smith wrote:
> > Dear All,
> >
> > I am in need of generating artificial data for machine learning
> > classification and regression analysis. What I am looking for is
> > something similar to Python sklearn.datasets.make_classification and
> > sklearn.datasets.make_regression:
> >
> > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> >
> > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> >
> > I have searched CRAN for something similar, but found nothing. Could
> > someone please help me with this?
> >
> > Thanks in advance,
> >
> > Paul
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar  3 23:29:26 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 4 Mar 2022 09:29:26 +1100
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
Message-ID: <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>

Hi Neha,
I think you're looking for the "cut" function.

Jim

On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Hello everyone
>
> I have a variable with about 5000 different values
>
> var1= c(0, 123, 400, .....4988)
>
> I want to convert it into different levels for some comparisons like
>
> if value is between 1-100 do something
> else
> do other things
>
> Is there any sophisticated way to do that than the following:
>
> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Mar  3 23:36:02 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 3 Mar 2022 23:36:02 +0100
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
Message-ID: <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>

Hello Jim

So, you believe the following way is better ?

var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))



On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Neha,
> I think you're looking for the "cut" function.
>
> Jim
>
> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > Hello everyone
> >
> > I have a variable with about 5000 different values
> >
> > var1= c(0, 123, 400, .....4988)
> >
> > I want to convert it into different levels for some comparisons like
> >
> > if value is between 1-100 do something
> > else
> > do other things
> >
> > Is there any sophisticated way to do that than the following:
> >
> > var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
> >
> > Thank you
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar  3 23:38:38 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 4 Mar 2022 09:38:38 +1100
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
 <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
Message-ID: <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>

Sorry, it was such an easy question that I didn't even read it
closely. Apparently using hist() is a bit faster. Whether this is
worth it, I don't know.

Jim

On Fri, Mar 4, 2022 at 9:36 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Hello Jim
>
> So, you believe the following way is better ?
>
> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>
>
>
> On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Neha,
>> I think you're looking for the "cut" function.
>>
>> Jim
>>
>> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>> >
>> > Hello everyone
>> >
>> > I have a variable with about 5000 different values
>> >
>> > var1= c(0, 123, 400, .....4988)
>> >
>> > I want to convert it into different levels for some comparisons like
>> >
>> > if value is between 1-100 do something
>> > else
>> > do other things
>> >
>> > Is there any sophisticated way to do that than the following:
>> >
>> > var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>> >
>> > Thank you
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Mar  3 23:43:00 2022
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 3 Mar 2022 17:43:00 -0500
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
 <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>
Message-ID: <CAM_vjunyqoY_yx-H7A0ynCyBcNsOkATCyaDym9PJRKY39RSmeA@mail.gmail.com>

Hi Paul,

If you aren't committed to creating your own, the cluster.datasets
package might be of interest. I've also used
http://cs.joensuu.fi/sipu/datasets/ quite often.

Sarah

On Thu, Mar 3, 2022 at 4:20 PM Paul Smith <phhs80 at gmail.com> wrote:
>
> Sounds interesting, Tom! Thanks!
>
> I am trying to find datasets for creating assignments for students of
> a course of machine learning.
>
> Paul
>
>
>
> On Thu, Mar 3, 2022 at 9:04 PM Tom Woolman <twoolman at ontargettek.com> wrote:
> >
> > Hi Paul. Have you considered just going onto Kaggle and GitHub and
> > searching for some of the many freely available real datasets that are
> > posted there? I'm seeing a lot of productivity there days with research
> > focused on data generation, and not just on creating algorithms and
> > predictive models. Which is a good thing for us ;)
> >
> > One of the current research papers I'm working on now is based on mining
> > a dataset I discovered on Kaggle a few months back and trying to create
> > a novel solution for that. Proper credit will of course be provided in
> > the citation references for the data provider.
> >
> >
> > Thanks,
> > Tom
> >
> >
> > On 2022-03-03 16:00, Paul Smith wrote:
> > > Dear All,
> > >
> > > I am in need of generating artificial data for machine learning
> > > classification and regression analysis. What I am looking for is
> > > something similar to Python sklearn.datasets.make_classification and
> > > sklearn.datasets.make_regression:
> > >
> > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> > >
> > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> > >
> > > I have searched CRAN for something similar, but found nothing. Could
> > > someone please help me with this?
> > >
> > > Thanks in advance,
> > >
> > > Paul
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From phh@80 @end|ng |rom gm@||@com  Fri Mar  4 00:01:05 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Thu, 3 Mar 2022 23:01:05 +0000
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CAM_vjunyqoY_yx-H7A0ynCyBcNsOkATCyaDym9PJRKY39RSmeA@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <d64c86d6ee66eb8c2f2c67f6d53bbe0d@ontargettek.com>
 <CALS=5mp7mX6T2uy1iX=jAVn2+N_trn_RjcJ5iQOOs0NpSLNxrQ@mail.gmail.com>
 <CAM_vjunyqoY_yx-H7A0ynCyBcNsOkATCyaDym9PJRKY39RSmeA@mail.gmail.com>
Message-ID: <CALS=5moP-0PJVnQEn2GJ2ZTruaHtwOTcn=yKgF2OTB_R+i-KSQ@mail.gmail.com>

Thanks, Sarah! Your answer is quite helpful!

Paul


On Thu, Mar 3, 2022 at 10:43 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> Hi Paul,
>
> If you aren't committed to creating your own, the cluster.datasets
> package might be of interest. I've also used
> http://cs.joensuu.fi/sipu/datasets/ quite often.
>
> Sarah
>
> On Thu, Mar 3, 2022 at 4:20 PM Paul Smith <phhs80 at gmail.com> wrote:
> >
> > Sounds interesting, Tom! Thanks!
> >
> > I am trying to find datasets for creating assignments for students of
> > a course of machine learning.
> >
> > Paul
> >
> >
> >
> > On Thu, Mar 3, 2022 at 9:04 PM Tom Woolman <twoolman at ontargettek.com> wrote:
> > >
> > > Hi Paul. Have you considered just going onto Kaggle and GitHub and
> > > searching for some of the many freely available real datasets that are
> > > posted there? I'm seeing a lot of productivity there days with research
> > > focused on data generation, and not just on creating algorithms and
> > > predictive models. Which is a good thing for us ;)
> > >
> > > One of the current research papers I'm working on now is based on mining
> > > a dataset I discovered on Kaggle a few months back and trying to create
> > > a novel solution for that. Proper credit will of course be provided in
> > > the citation references for the data provider.
> > >
> > >
> > > Thanks,
> > > Tom
> > >
> > >
> > > On 2022-03-03 16:00, Paul Smith wrote:
> > > > Dear All,
> > > >
> > > > I am in need of generating artificial data for machine learning
> > > > classification and regression analysis. What I am looking for is
> > > > something similar to Python sklearn.datasets.make_classification and
> > > > sklearn.datasets.make_regression:
> > > >
> > > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> > > >
> > > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> > > >
> > > > I have searched CRAN for something similar, but found nothing. Could
> > > > someone please help me with this?
> > > >
> > > > Thanks in advance,
> > > >
> > > > Paul
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Mar  4 00:06:39 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 3 Mar 2022 23:06:39 +0000
Subject: [R] Continuous variable into levels
In-Reply-To: <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
 <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
 <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>
Message-ID: <100bfeff-4894-3fb6-fdbc-9b33f612cd63@sapo.pt>

Hello,

And ?findInterval is faster than hist.

findInterval(x, c(-Inf, 500, 1000, 5000))

Also, before the cut code, the OP wrote


if value is between 1-100 do something


but in the breaks vector there's no 100. I guess this is not important, 
though, only the function to bin the data is.

Hope this helps,

Rui Barradas

?s 22:38 de 03/03/2022, Jim Lemon escreveu:
> Sorry, it was such an easy question that I didn't even read it
> closely. Apparently using hist() is a bit faster. Whether this is
> worth it, I don't know.
> 
> Jim
> 
> On Fri, Mar 4, 2022 at 9:36 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>>
>> Hello Jim
>>
>> So, you believe the following way is better ?
>>
>> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>>
>>
>>
>> On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Neha,
>>> I think you're looking for the "cut" function.
>>>
>>> Jim
>>>
>>> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>>>>
>>>> Hello everyone
>>>>
>>>> I have a variable with about 5000 different values
>>>>
>>>> var1= c(0, 123, 400, .....4988)
>>>>
>>>> I want to convert it into different levels for some comparisons like
>>>>
>>>> if value is between 1-100 do something
>>>> else
>>>> do other things
>>>>
>>>> Is there any sophisticated way to do that than the following:
>>>>
>>>> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>>>>
>>>> Thank you
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @rth|en @end|ng |rom gm@||@com  Thu Mar  3 20:11:53 2022
From: @rth|en @end|ng |rom gm@||@com (Arthur Fendrich)
Date: Thu, 3 Mar 2022 20:11:53 +0100
Subject: [R] Possible causes of unexpected behavior
Message-ID: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>

Dear all,

I am currently having a weird problem with a large-scale optimization
routine. It would be nice to know if any of you have already gone through
something similar, and how you solved it.

I apologize in advance for not providing an example, but I think the
non-reproducibility of the error is maybe a key point of this problem.

Simplest possible description of the problem: I have two functions: g(X)
and f(v).
g(X) does:
 i) inputs a large matrix X;
 ii) derives four other matrices from X (I'll call them A, B, C and D) then
saves to disk for debugging purposes;

Then, f(v) does:
 iii) loads A, B, C, D from disk
 iv) calculates the log-likelihood, which vary according to a vector of
parameters, v.

My goal application is quite big (X is a 40000x40000 matrix), so I created
the following versions to test and run the codes/math/parallelization:
#1) A simulated example with X being 100x100
#2) A degraded version of the goal application, with X being 4000x4000
#3) The goal application, with X being 40000x40000

When I use qsub to submit the job, using the exact same code and processing
cluster, #1 and #2 run flawlessly, so no problem. These results tell me
that the codes/math/parallelization are fine.

For application #3, it converges to a vector v*. However, when I manually
load A, B, C and D from disk and calculate f(v*), then the value I get is
completely different.
For example:
- qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
- when I manually load A, B, C, D from disk and calculate f(v*) on the
exact same machine with the same libraries and environment variables, I get
f(v*) = 1000.

This is a very confusing behavior. In theory the size of X should not
affect my problem, but it seems that things get unstable as the dimension
grows. The main issue for debugging is that g(X) for simulation #3 takes
two hours to run, and I am completely lost on how I could find the causes
of the problem. Would you have any general advices?

Thank you very much in advance for literally any suggestions you might have!

Best regards,
Arthur

	[[alternative HTML version deleted]]


From m|m@|tr@ @end|ng |rom gmx@com  Fri Mar  4 06:00:06 2022
From: m|m@|tr@ @end|ng |rom gmx@com (Ranjan Maitra)
Date: Thu, 3 Mar 2022 23:00:06 -0600
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
Message-ID: <YiGc1p7HZZP/jrAq@iastate.edu>

On Thu Mar03'22 09:00:08PM, Paul Smith wrote:
> From: Paul Smith <phhs80 at gmail.com>
> Date: Thu, 3 Mar 2022 21:00:08 +0000
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] Looking for package for data generation for classification and
>  regression
>
> Dear All,
>
> I am in need of generating artificial data for machine learning
> classification and regression analysis. What I am looking for is
> something similar to Python sklearn.datasets.make_classification and
> sklearn.datasets.make_regression:
>
> https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
>
> https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
>
> I have searched CRAN for something similar, but found nothing. Could
> someone please help me with this?

Not sure if this helps, but at least for classification and clustering, there is the MixSim package on CRAN which provides classification datasets according to an overall overlap measure.


Hope this helps!

Best wishes,
Ranjan


From er|cjberger @end|ng |rom gm@||@com  Fri Mar  4 09:47:57 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 4 Mar 2022 10:47:57 +0200
Subject: [R] Possible causes of unexpected behavior
In-Reply-To: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
References: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
Message-ID: <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>

Please confirm that when you do the manual load and check that f(v*)
matches the result from qsub() it succeeds for cases #1,#2 but only fails
for #3.


On Fri, Mar 4, 2022 at 10:06 AM Arthur Fendrich <arthfen at gmail.com> wrote:

> Dear all,
>
> I am currently having a weird problem with a large-scale optimization
> routine. It would be nice to know if any of you have already gone through
> something similar, and how you solved it.
>
> I apologize in advance for not providing an example, but I think the
> non-reproducibility of the error is maybe a key point of this problem.
>
> Simplest possible description of the problem: I have two functions: g(X)
> and f(v).
> g(X) does:
>  i) inputs a large matrix X;
>  ii) derives four other matrices from X (I'll call them A, B, C and D) then
> saves to disk for debugging purposes;
>
> Then, f(v) does:
>  iii) loads A, B, C, D from disk
>  iv) calculates the log-likelihood, which vary according to a vector of
> parameters, v.
>
> My goal application is quite big (X is a 40000x40000 matrix), so I created
> the following versions to test and run the codes/math/parallelization:
> #1) A simulated example with X being 100x100
> #2) A degraded version of the goal application, with X being 4000x4000
> #3) The goal application, with X being 40000x40000
>
> When I use qsub to submit the job, using the exact same code and processing
> cluster, #1 and #2 run flawlessly, so no problem. These results tell me
> that the codes/math/parallelization are fine.
>
> For application #3, it converges to a vector v*. However, when I manually
> load A, B, C and D from disk and calculate f(v*), then the value I get is
> completely different.
> For example:
> - qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
> - when I manually load A, B, C, D from disk and calculate f(v*) on the
> exact same machine with the same libraries and environment variables, I get
> f(v*) = 1000.
>
> This is a very confusing behavior. In theory the size of X should not
> affect my problem, but it seems that things get unstable as the dimension
> grows. The main issue for debugging is that g(X) for simulation #3 takes
> two hours to run, and I am completely lost on how I could find the causes
> of the problem. Would you have any general advices?
>
> Thank you very much in advance for literally any suggestions you might
> have!
>
> Best regards,
> Arthur
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Fri Mar  4 10:26:03 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Fri, 4 Mar 2022 10:26:03 +0100
Subject: [R] Continuous variable into levels
In-Reply-To: <100bfeff-4894-3fb6-fdbc-9b33f612cd63@sapo.pt>
References: <CA+nrPnup8rLzGHB3XEydm-PTqZzBL1TyyAAD7=wY8c8D_-tqxw@mail.gmail.com>
 <CA+8X3fWy57M16M=aF9jsCPXn30+wT_YKcNtvqurupJX6KOaYjA@mail.gmail.com>
 <CA+nrPnuxefq0hfiqsm-hLEBUjOqqqGV=xogDXDiYOErokGUf2g@mail.gmail.com>
 <CA+8X3fX2jC9Kk4Y+dTmzo1deDqeVG23ak94o1kaLs27v7nVuJA@mail.gmail.com>
 <100bfeff-4894-3fb6-fdbc-9b33f612cd63@sapo.pt>
Message-ID: <CA+nrPnsZ_jKDgJ_rQDW==UokKHjtw2_v7tENmnptBrs_COR15g@mail.gmail.com>

Thank you dear Rui

Yes, it helps.

Best regards

On Thursday, March 3, 2022, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> And ?findInterval is faster than hist.
>
> findInterval(x, c(-Inf, 500, 1000, 5000))
>
> Also, before the cut code, the OP wrote
>
>
> if value is between 1-100 do something
>
>
> but in the breaks vector there's no 100. I guess this is not important,
> though, only the function to bin the data is.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 22:38 de 03/03/2022, Jim Lemon escreveu:
>
>> Sorry, it was such an easy question that I didn't even read it
>> closely. Apparently using hist() is a bit faster. Whether this is
>> worth it, I don't know.
>>
>> Jim
>>
>> On Fri, Mar 4, 2022 at 9:36 AM Neha gupta <neha.bologna90 at gmail.com>
>> wrote:
>>
>>>
>>> Hello Jim
>>>
>>> So, you believe the following way is better ?
>>>
>>> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>>>
>>>
>>>
>>> On Thu, Mar 3, 2022 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>>>
>>>> Hi Neha,
>>>> I think you're looking for the "cut" function.
>>>>
>>>> Jim
>>>>
>>>> On Fri, Mar 4, 2022 at 8:10 AM Neha gupta <neha.bologna90 at gmail.com>
>>>> wrote:
>>>>
>>>>>
>>>>> Hello everyone
>>>>>
>>>>> I have a variable with about 5000 different values
>>>>>
>>>>> var1= c(0, 123, 400, .....4988)
>>>>>
>>>>> I want to convert it into different levels for some comparisons like
>>>>>
>>>>> if value is between 1-100 do something
>>>>> else
>>>>> do other things
>>>>>
>>>>> Is there any sophisticated way to do that than the following:
>>>>>
>>>>> var2=cut(var1, br=c(-1,500, 501,1000, 1001,5000))
>>>>>
>>>>> Thank you
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Mar  4 10:32:58 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 4 Mar 2022 11:32:58 +0200
Subject: [R] Possible causes of unexpected behavior
In-Reply-To: <CADxQpSkTAZ7mOx2_zeRKNa4JmBuiOiwTOPs6k2U-9ER0RyGq1A@mail.gmail.com>
References: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
 <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>
 <CADxQpSkTAZ7mOx2_zeRKNa4JmBuiOiwTOPs6k2U-9ER0RyGq1A@mail.gmail.com>
Message-ID: <CAGgJW75REvX_yiOdORUsZDdSO0uajk+FCdecZu_VjHsKZAs4jg@mail.gmail.com>

Can you confirm you have a distributed calculation running in parallel?
Have you determined that it is thread safe? How?
Your check on the smaller examples may not have ruled out such
possibilities.

On Fri, Mar 4, 2022 at 11:21 AM Arthur Fendrich <arthfen at gmail.com> wrote:

> Dear Eric,
>
> Thank you for the response. Yes, I can confirm that, please see below the
> behavior.
> For #1, results are identical. For #2, they are not identical but very
> close. For #3, they are completely different.
>
> Best regards,
> Arthur
>
> --
>
> For #1,
> - qsub execution:
> [1] "ll: 565.7251"
> [1] "norm gr @ minimum: 2.96967368608131e-08"
>
> - manual check:
> f(v*): 565.7251
> gradient norm at v*: 2.969674e-08
>
> #
> For #2,
>
> - qsub execution:
> [1] "ll: 14380.8308"
> [1] "norm gr @ minimum: 0.0140857561408041"
>
> - manual check:
> f(v*): 14380.84
> gradient norm at v*: 0.01404779
>
> #
> For #3,
>
> - qsub execution:
> [1] "ll: 14310.6812"
> [1] "norm gr @ minimum: 6232158.38877002"
>
> - manual check:
> f(v*): 97604.69
> gradient norm at v*: 6266696595
>
> Em sex., 4 de mar. de 2022 ?s 09:48, Eric Berger <ericjberger at gmail.com>
> escreveu:
>
>> Please confirm that when you do the manual load and check that f(v*)
>> matches the result from qsub() it succeeds for cases #1,#2 but only fails
>> for #3.
>>
>>
>> On Fri, Mar 4, 2022 at 10:06 AM Arthur Fendrich <arthfen at gmail.com>
>> wrote:
>>
>>> Dear all,
>>>
>>> I am currently having a weird problem with a large-scale optimization
>>> routine. It would be nice to know if any of you have already gone through
>>> something similar, and how you solved it.
>>>
>>> I apologize in advance for not providing an example, but I think the
>>> non-reproducibility of the error is maybe a key point of this problem.
>>>
>>> Simplest possible description of the problem: I have two functions: g(X)
>>> and f(v).
>>> g(X) does:
>>>  i) inputs a large matrix X;
>>>  ii) derives four other matrices from X (I'll call them A, B, C and D)
>>> then
>>> saves to disk for debugging purposes;
>>>
>>> Then, f(v) does:
>>>  iii) loads A, B, C, D from disk
>>>  iv) calculates the log-likelihood, which vary according to a vector of
>>> parameters, v.
>>>
>>> My goal application is quite big (X is a 40000x40000 matrix), so I
>>> created
>>> the following versions to test and run the codes/math/parallelization:
>>> #1) A simulated example with X being 100x100
>>> #2) A degraded version of the goal application, with X being 4000x4000
>>> #3) The goal application, with X being 40000x40000
>>>
>>> When I use qsub to submit the job, using the exact same code and
>>> processing
>>> cluster, #1 and #2 run flawlessly, so no problem. These results tell me
>>> that the codes/math/parallelization are fine.
>>>
>>> For application #3, it converges to a vector v*. However, when I manually
>>> load A, B, C and D from disk and calculate f(v*), then the value I get is
>>> completely different.
>>> For example:
>>> - qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
>>> - when I manually load A, B, C, D from disk and calculate f(v*) on the
>>> exact same machine with the same libraries and environment variables, I
>>> get
>>> f(v*) = 1000.
>>>
>>> This is a very confusing behavior. In theory the size of X should not
>>> affect my problem, but it seems that things get unstable as the dimension
>>> grows. The main issue for debugging is that g(X) for simulation #3 takes
>>> two hours to run, and I am completely lost on how I could find the causes
>>> of the problem. Would you have any general advices?
>>>
>>> Thank you very much in advance for literally any suggestions you might
>>> have!
>>>
>>> Best regards,
>>> Arthur
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Mar  4 11:13:23 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 4 Mar 2022 12:13:23 +0200
Subject: [R] Possible causes of unexpected behavior
In-Reply-To: <CADxQpSk5pxzTaQvNTVzSLqUXmJoMp-cA-jkOSNXUjrqQyAv--A@mail.gmail.com>
References: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
 <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>
 <CADxQpSkTAZ7mOx2_zeRKNa4JmBuiOiwTOPs6k2U-9ER0RyGq1A@mail.gmail.com>
 <CAGgJW75REvX_yiOdORUsZDdSO0uajk+FCdecZu_VjHsKZAs4jg@mail.gmail.com>
 <CADxQpSk5pxzTaQvNTVzSLqUXmJoMp-cA-jkOSNXUjrqQyAv--A@mail.gmail.com>
Message-ID: <CAGgJW7413G4fERhaD5DP=6uBsPp7HNqgvFyzxpp4OmJJG_BLTw@mail.gmail.com>

If I understand correctly, steps i,ii can be ignored.
i.e. we just focus on step iii with A,B,C,D fixed.

You do the optimization of f(v) to calculate, say, v* = argmin f(v).
This optimization is single threaded.

(A)
In that case, I suggest you add some logging so that for each call to f(),
you output its input and output.
Then you can (re-) confirm your validation test - i.e. that the "manual"
calc of f(v*) gives a different result than what is found in the log file.

(B) If (A) doesn't lead you anywhere ....
Re-reading your original description of the process, it seems that the time
consuming part is creating A,B,C,D.
If the evaluation of f(v) is not overly time consuming, then run the
optimization under valgrind. It is possible that you are depending on some
uninitialized variables, or trashing memory somewhere.



On Fri, Mar 4, 2022 at 11:54 AM Arthur Fendrich <arthfen at gmail.com> wrote:

> Dear Eric,
>
> Yes, I can confirm that I have distributed calculations running in
> parallel.
>
> I am not sure if this is a precise answer to the thread-safe question
> since I'm not familiar with this definition, but what I do is:
>  i) First, chunks of A, B, C and D are calculated from X in parallel by
> the worker nodes.
>  ii) Second, all the chunks are combined on my master node, and the final
> A, B, C and D are saved to disk.
>  iii) Then, still on the master node, I optimize f(v) using the final A,
> B, C and D.
>
> When I debug, I skip steps i) and ii) and check only iii) manually by
> loading A, B, C and D from the disk and evaluating f(v*). Does that seem
> correct?
>
> Best regards,
> Arthur
>
> Em sex., 4 de mar. de 2022 ?s 10:33, Eric Berger <ericjberger at gmail.com>
> escreveu:
>
>> Can you confirm you have a distributed calculation running in parallel?
>> Have you determined that it is thread safe? How?
>> Your check on the smaller examples may not have ruled out such
>> possibilities.
>>
>> On Fri, Mar 4, 2022 at 11:21 AM Arthur Fendrich <arthfen at gmail.com>
>> wrote:
>>
>>> Dear Eric,
>>>
>>> Thank you for the response. Yes, I can confirm that, please see below
>>> the behavior.
>>> For #1, results are identical. For #2, they are not identical but very
>>> close. For #3, they are completely different.
>>>
>>> Best regards,
>>> Arthur
>>>
>>> --
>>>
>>> For #1,
>>> - qsub execution:
>>> [1] "ll: 565.7251"
>>> [1] "norm gr @ minimum: 2.96967368608131e-08"
>>>
>>> - manual check:
>>> f(v*): 565.7251
>>> gradient norm at v*: 2.969674e-08
>>>
>>> #
>>> For #2,
>>>
>>> - qsub execution:
>>> [1] "ll: 14380.8308"
>>> [1] "norm gr @ minimum: 0.0140857561408041"
>>>
>>> - manual check:
>>> f(v*): 14380.84
>>> gradient norm at v*: 0.01404779
>>>
>>> #
>>> For #3,
>>>
>>> - qsub execution:
>>> [1] "ll: 14310.6812"
>>> [1] "norm gr @ minimum: 6232158.38877002"
>>>
>>> - manual check:
>>> f(v*): 97604.69
>>> gradient norm at v*: 6266696595
>>>
>>> Em sex., 4 de mar. de 2022 ?s 09:48, Eric Berger <ericjberger at gmail.com>
>>> escreveu:
>>>
>>>> Please confirm that when you do the manual load and check that f(v*)
>>>> matches the result from qsub() it succeeds for cases #1,#2 but only fails
>>>> for #3.
>>>>
>>>>
>>>> On Fri, Mar 4, 2022 at 10:06 AM Arthur Fendrich <arthfen at gmail.com>
>>>> wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> I am currently having a weird problem with a large-scale optimization
>>>>> routine. It would be nice to know if any of you have already gone
>>>>> through
>>>>> something similar, and how you solved it.
>>>>>
>>>>> I apologize in advance for not providing an example, but I think the
>>>>> non-reproducibility of the error is maybe a key point of this problem.
>>>>>
>>>>> Simplest possible description of the problem: I have two functions:
>>>>> g(X)
>>>>> and f(v).
>>>>> g(X) does:
>>>>>  i) inputs a large matrix X;
>>>>>  ii) derives four other matrices from X (I'll call them A, B, C and D)
>>>>> then
>>>>> saves to disk for debugging purposes;
>>>>>
>>>>> Then, f(v) does:
>>>>>  iii) loads A, B, C, D from disk
>>>>>  iv) calculates the log-likelihood, which vary according to a vector of
>>>>> parameters, v.
>>>>>
>>>>> My goal application is quite big (X is a 40000x40000 matrix), so I
>>>>> created
>>>>> the following versions to test and run the codes/math/parallelization:
>>>>> #1) A simulated example with X being 100x100
>>>>> #2) A degraded version of the goal application, with X being 4000x4000
>>>>> #3) The goal application, with X being 40000x40000
>>>>>
>>>>> When I use qsub to submit the job, using the exact same code and
>>>>> processing
>>>>> cluster, #1 and #2 run flawlessly, so no problem. These results tell me
>>>>> that the codes/math/parallelization are fine.
>>>>>
>>>>> For application #3, it converges to a vector v*. However, when I
>>>>> manually
>>>>> load A, B, C and D from disk and calculate f(v*), then the value I get
>>>>> is
>>>>> completely different.
>>>>> For example:
>>>>> - qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
>>>>> - when I manually load A, B, C, D from disk and calculate f(v*) on the
>>>>> exact same machine with the same libraries and environment variables,
>>>>> I get
>>>>> f(v*) = 1000.
>>>>>
>>>>> This is a very confusing behavior. In theory the size of X should not
>>>>> affect my problem, but it seems that things get unstable as the
>>>>> dimension
>>>>> grows. The main issue for debugging is that g(X) for simulation #3
>>>>> takes
>>>>> two hours to run, and I am completely lost on how I could find the
>>>>> causes
>>>>> of the problem. Would you have any general advices?
>>>>>
>>>>> Thank you very much in advance for literally any suggestions you might
>>>>> have!
>>>>>
>>>>> Best regards,
>>>>> Arthur
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>

	[[alternative HTML version deleted]]


From phh@80 @end|ng |rom gm@||@com  Fri Mar  4 11:41:24 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Fri, 4 Mar 2022 10:41:24 +0000
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <YiGc1p7HZZP/jrAq@iastate.edu>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <YiGc1p7HZZP/jrAq@iastate.edu>
Message-ID: <CALS=5moiamk9tzDdrJC05mqA-aiNOw67p6wniyuc8fOhGvZv9A@mail.gmail.com>

On Fri, Mar 4, 2022 at 8:07 AM Ranjan Maitra <mlmaitra at gmx.com> wrote:
>
> > I am in need of generating artificial data for machine learning
> > classification and regression analysis. What I am looking for is
> > something similar to Python sklearn.datasets.make_classification and
> > sklearn.datasets.make_regression:
> >
> > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> >
> > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> >
> > I have searched CRAN for something similar, but found nothing. Could
> > someone please help me with this?
>
> Not sure if this helps, but at least for classification and clustering, there is the MixSim package on CRAN which provides classification datasets according to an overall overlap measure.

Thanks, Ranjan, that is also quite helpful, since clustering is also a
topic of the course!

Paul


From @rth|en @end|ng |rom gm@||@com  Fri Mar  4 10:21:05 2022
From: @rth|en @end|ng |rom gm@||@com (Arthur Fendrich)
Date: Fri, 4 Mar 2022 10:21:05 +0100
Subject: [R] Possible causes of unexpected behavior
In-Reply-To: <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>
References: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
 <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>
Message-ID: <CADxQpSkTAZ7mOx2_zeRKNa4JmBuiOiwTOPs6k2U-9ER0RyGq1A@mail.gmail.com>

Dear Eric,

Thank you for the response. Yes, I can confirm that, please see below the
behavior.
For #1, results are identical. For #2, they are not identical but very
close. For #3, they are completely different.

Best regards,
Arthur

--

For #1,
- qsub execution:
[1] "ll: 565.7251"
[1] "norm gr @ minimum: 2.96967368608131e-08"

- manual check:
f(v*): 565.7251
gradient norm at v*: 2.969674e-08

#
For #2,

- qsub execution:
[1] "ll: 14380.8308"
[1] "norm gr @ minimum: 0.0140857561408041"

- manual check:
f(v*): 14380.84
gradient norm at v*: 0.01404779

#
For #3,

- qsub execution:
[1] "ll: 14310.6812"
[1] "norm gr @ minimum: 6232158.38877002"

- manual check:
f(v*): 97604.69
gradient norm at v*: 6266696595

Em sex., 4 de mar. de 2022 ?s 09:48, Eric Berger <ericjberger at gmail.com>
escreveu:

> Please confirm that when you do the manual load and check that f(v*)
> matches the result from qsub() it succeeds for cases #1,#2 but only fails
> for #3.
>
>
> On Fri, Mar 4, 2022 at 10:06 AM Arthur Fendrich <arthfen at gmail.com> wrote:
>
>> Dear all,
>>
>> I am currently having a weird problem with a large-scale optimization
>> routine. It would be nice to know if any of you have already gone through
>> something similar, and how you solved it.
>>
>> I apologize in advance for not providing an example, but I think the
>> non-reproducibility of the error is maybe a key point of this problem.
>>
>> Simplest possible description of the problem: I have two functions: g(X)
>> and f(v).
>> g(X) does:
>>  i) inputs a large matrix X;
>>  ii) derives four other matrices from X (I'll call them A, B, C and D)
>> then
>> saves to disk for debugging purposes;
>>
>> Then, f(v) does:
>>  iii) loads A, B, C, D from disk
>>  iv) calculates the log-likelihood, which vary according to a vector of
>> parameters, v.
>>
>> My goal application is quite big (X is a 40000x40000 matrix), so I created
>> the following versions to test and run the codes/math/parallelization:
>> #1) A simulated example with X being 100x100
>> #2) A degraded version of the goal application, with X being 4000x4000
>> #3) The goal application, with X being 40000x40000
>>
>> When I use qsub to submit the job, using the exact same code and
>> processing
>> cluster, #1 and #2 run flawlessly, so no problem. These results tell me
>> that the codes/math/parallelization are fine.
>>
>> For application #3, it converges to a vector v*. However, when I manually
>> load A, B, C and D from disk and calculate f(v*), then the value I get is
>> completely different.
>> For example:
>> - qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
>> - when I manually load A, B, C, D from disk and calculate f(v*) on the
>> exact same machine with the same libraries and environment variables, I
>> get
>> f(v*) = 1000.
>>
>> This is a very confusing behavior. In theory the size of X should not
>> affect my problem, but it seems that things get unstable as the dimension
>> grows. The main issue for debugging is that g(X) for simulation #3 takes
>> two hours to run, and I am completely lost on how I could find the causes
>> of the problem. Would you have any general advices?
>>
>> Thank you very much in advance for literally any suggestions you might
>> have!
>>
>> Best regards,
>> Arthur
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @rth|en @end|ng |rom gm@||@com  Fri Mar  4 10:53:29 2022
From: @rth|en @end|ng |rom gm@||@com (Arthur Fendrich)
Date: Fri, 4 Mar 2022 10:53:29 +0100
Subject: [R] Possible causes of unexpected behavior
In-Reply-To: <CAGgJW75REvX_yiOdORUsZDdSO0uajk+FCdecZu_VjHsKZAs4jg@mail.gmail.com>
References: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
 <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>
 <CADxQpSkTAZ7mOx2_zeRKNa4JmBuiOiwTOPs6k2U-9ER0RyGq1A@mail.gmail.com>
 <CAGgJW75REvX_yiOdORUsZDdSO0uajk+FCdecZu_VjHsKZAs4jg@mail.gmail.com>
Message-ID: <CADxQpSk5pxzTaQvNTVzSLqUXmJoMp-cA-jkOSNXUjrqQyAv--A@mail.gmail.com>

Dear Eric,

Yes, I can confirm that I have distributed calculations running in parallel.

I am not sure if this is a precise answer to the thread-safe question since
I'm not familiar with this definition, but what I do is:
 i) First, chunks of A, B, C and D are calculated from X in parallel by the
worker nodes.
 ii) Second, all the chunks are combined on my master node, and the final
A, B, C and D are saved to disk.
 iii) Then, still on the master node, I optimize f(v) using the final A, B,
C and D.

When I debug, I skip steps i) and ii) and check only iii) manually by
loading A, B, C and D from the disk and evaluating f(v*). Does that seem
correct?

Best regards,
Arthur

Em sex., 4 de mar. de 2022 ?s 10:33, Eric Berger <ericjberger at gmail.com>
escreveu:

> Can you confirm you have a distributed calculation running in parallel?
> Have you determined that it is thread safe? How?
> Your check on the smaller examples may not have ruled out such
> possibilities.
>
> On Fri, Mar 4, 2022 at 11:21 AM Arthur Fendrich <arthfen at gmail.com> wrote:
>
>> Dear Eric,
>>
>> Thank you for the response. Yes, I can confirm that, please see below the
>> behavior.
>> For #1, results are identical. For #2, they are not identical but very
>> close. For #3, they are completely different.
>>
>> Best regards,
>> Arthur
>>
>> --
>>
>> For #1,
>> - qsub execution:
>> [1] "ll: 565.7251"
>> [1] "norm gr @ minimum: 2.96967368608131e-08"
>>
>> - manual check:
>> f(v*): 565.7251
>> gradient norm at v*: 2.969674e-08
>>
>> #
>> For #2,
>>
>> - qsub execution:
>> [1] "ll: 14380.8308"
>> [1] "norm gr @ minimum: 0.0140857561408041"
>>
>> - manual check:
>> f(v*): 14380.84
>> gradient norm at v*: 0.01404779
>>
>> #
>> For #3,
>>
>> - qsub execution:
>> [1] "ll: 14310.6812"
>> [1] "norm gr @ minimum: 6232158.38877002"
>>
>> - manual check:
>> f(v*): 97604.69
>> gradient norm at v*: 6266696595
>>
>> Em sex., 4 de mar. de 2022 ?s 09:48, Eric Berger <ericjberger at gmail.com>
>> escreveu:
>>
>>> Please confirm that when you do the manual load and check that f(v*)
>>> matches the result from qsub() it succeeds for cases #1,#2 but only fails
>>> for #3.
>>>
>>>
>>> On Fri, Mar 4, 2022 at 10:06 AM Arthur Fendrich <arthfen at gmail.com>
>>> wrote:
>>>
>>>> Dear all,
>>>>
>>>> I am currently having a weird problem with a large-scale optimization
>>>> routine. It would be nice to know if any of you have already gone
>>>> through
>>>> something similar, and how you solved it.
>>>>
>>>> I apologize in advance for not providing an example, but I think the
>>>> non-reproducibility of the error is maybe a key point of this problem.
>>>>
>>>> Simplest possible description of the problem: I have two functions: g(X)
>>>> and f(v).
>>>> g(X) does:
>>>>  i) inputs a large matrix X;
>>>>  ii) derives four other matrices from X (I'll call them A, B, C and D)
>>>> then
>>>> saves to disk for debugging purposes;
>>>>
>>>> Then, f(v) does:
>>>>  iii) loads A, B, C, D from disk
>>>>  iv) calculates the log-likelihood, which vary according to a vector of
>>>> parameters, v.
>>>>
>>>> My goal application is quite big (X is a 40000x40000 matrix), so I
>>>> created
>>>> the following versions to test and run the codes/math/parallelization:
>>>> #1) A simulated example with X being 100x100
>>>> #2) A degraded version of the goal application, with X being 4000x4000
>>>> #3) The goal application, with X being 40000x40000
>>>>
>>>> When I use qsub to submit the job, using the exact same code and
>>>> processing
>>>> cluster, #1 and #2 run flawlessly, so no problem. These results tell me
>>>> that the codes/math/parallelization are fine.
>>>>
>>>> For application #3, it converges to a vector v*. However, when I
>>>> manually
>>>> load A, B, C and D from disk and calculate f(v*), then the value I get
>>>> is
>>>> completely different.
>>>> For example:
>>>> - qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
>>>> - when I manually load A, B, C, D from disk and calculate f(v*) on the
>>>> exact same machine with the same libraries and environment variables, I
>>>> get
>>>> f(v*) = 1000.
>>>>
>>>> This is a very confusing behavior. In theory the size of X should not
>>>> affect my problem, but it seems that things get unstable as the
>>>> dimension
>>>> grows. The main issue for debugging is that g(X) for simulation #3 takes
>>>> two hours to run, and I am completely lost on how I could find the
>>>> causes
>>>> of the problem. Would you have any general advices?
>>>>
>>>> Thank you very much in advance for literally any suggestions you might
>>>> have!
>>>>
>>>> Best regards,
>>>> Arthur
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From ||809 @end|ng |rom nc|@c@  Fri Mar  4 14:23:43 2022
From: ||809 @end|ng |rom nc|@c@ (Brian Lunergan)
Date: Fri, 4 Mar 2022 08:23:43 -0500
Subject: [R] Problem installing Rcmdr on version 4.1.2...
Message-ID: <c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>

Hi folks:

Running R 4.1.2 on Linux Mint 19.3. Tried to install Rcmdr, but when it
tried to install nloptr I got the following as it seemed to trip over
Cmake. Bit lengthy but here's what was spit out.

* installing *source* package ?nloptr? ...
** package ?nloptr? successfully unpacked and MD5 sums checked
** using staged installation
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ -std=gnu++14 accepts -g... yes
checking how to run the C++ preprocessor... g++ -std=gnu++14 -E
checking whether we are using the GNU C++ compiler... (cached) yes
checking whether g++ -std=gnu++14 accepts -g... (cached) yes
checking for pkg-config... /usr/bin/pkg-config
checking if pkg-config knows NLopt... no
using NLopt via local cmake build on x86_64
set CMAKE_BIN=/usr/bin/cmake
set CC=gcc -std=gnu99 -std=gnu11
set CFLAGS= -fpic -g -O2
-fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g
set CXX=g++
set CXXFLAGS=-std=gnu++11 -fpic -g -O2
-fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g
set LDFLAGS=-Wl,-Bsymbolic-functions -Wl,-z,relro
CMake Error: The source directory
"/tmp/RtmpP4rvt0/R.INSTALL360c3be2694c/nloptr/src/nlopt-build" does not
exist.
Specify --help for usage, or press the help button on the CMake GUI.
Unknown argument -j
Unknown argument 2
Usage: cmake --build <dir> [options] [-- [native-options]]
Options:
  <dir>          = Project binary directory to be built.
  --target <tgt> = Build <tgt> instead of default targets.
                   May only be specified once.
  --config <cfg> = For multi-configuration tools, choose <cfg>.
  --clean-first  = Build target 'clean' first, then build.
                   (To clean only, use --target 'clean'.)
  --use-stderr   = Ignored.  Behavior is default in CMake >= 3.0.
  --             = Pass remaining options to the native tool.
CMake Error: The source directory
"/tmp/RtmpP4rvt0/R.INSTALL360c3be2694c/nloptr/src/nlopt" does not exist.
Specify --help for usage, or press the help button on the CMake GUI.
cp: cannot stat 'nlopt/include/*': No such file or directory
configure: creating ./config.status
config.status: creating src/Makevars
** libs
gcc -std=gnu99 -std=gnu11 -I"/usr/share/R/include" -DNDEBUG
-I../inst/include
-I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
-fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -c init_nloptr.c -o init_nloptr.o
gcc -std=gnu99 -std=gnu11 -I"/usr/share/R/include" -DNDEBUG
-I../inst/include
-I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
-fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -c nloptr.c -o nloptr.o
g++ -std=gnu++11 -I"/usr/share/R/include" -DNDEBUG -I../inst/include
-I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
-fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -c test-C-API.cpp -o test-C-API.o
g++ -std=gnu++11 -I"/usr/share/R/include" -DNDEBUG -I../inst/include
-I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
-fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -c test-runner.cpp -o test-runner.o
g++ -std=gnu++11 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
-Wl,-z,relro -o nloptr.so init_nloptr.o nloptr.o test-C-API.o
test-runner.o -llapack -lblas -lgfortran -lm -lquadmath -Lnlopt/lib
-lnlopt -L/usr/lib/R/lib -lR
/usr/bin/ld: cannot find -lnlopt
collect2: error: ld returned 1 exit status
/usr/share/R/share/make/shlib.mk:10: recipe for target 'nloptr.so' failed
make: *** [nloptr.so] Error 1
ERROR: compilation failed for package ?nloptr?
* removing ?/home/brian/R/x86_64-pc-linux-gnu-library/4.1/nloptr?

I have cmake on mint in the current edition, but when I try to install
it in R it fires as not available for 4.1.2. Is there a version out
there that will work with 4.1.2? Where would I find it and how would I
install it? Any help/advice would be greatly appreciated.

Regards...
-- 
Brian Lunergan
Russell, ON
Canada

-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpenPGP_signature
Type: application/pgp-signature
Size: 665 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20220304/bb0ed18a/attachment.sig>

From kry|ov@r00t @end|ng |rom gm@||@com  Fri Mar  4 14:34:03 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 4 Mar 2022 16:34:03 +0300
Subject: [R] Problem installing Rcmdr on version 4.1.2...
In-Reply-To: <c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>
References: <c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>
Message-ID: <20220304163403.518a397a@arachnoid>

On Fri, 4 Mar 2022 08:23:43 -0500
Brian Lunergan <ff809 at ncf.ca> wrote:

> Running R 4.1.2 on Linux Mint 19.3.

> g++ -std=gnu++11 -I"/usr/share/R/include" -DNDEBUG -I../inst/include
> -I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
> -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -c test-runner.cpp -o test-runner.o
> g++ -std=gnu++11 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o nloptr.so init_nloptr.o nloptr.o test-C-API.o
> test-runner.o -llapack -lblas -lgfortran -lm -lquadmath -Lnlopt/lib
> -lnlopt -L/usr/lib/R/lib -lR
> /usr/bin/ld: cannot find -lnlopt
> collect2: error: ld returned 1 exit status

Typically, when an R package wraps a third-party library, you need a
development version of it installed in order to install that package
from source.

If you're running R from the Linux Mint repos, try to install
r-cran-nloptr from Linux Mint repositories. If you don't, or have some
trouble installing the package, install the libnlopt-dev Linux Mint
package before trying to install the nloptr R package.

-- 
Best regards,
Ivan


From ||809 @end|ng |rom nc|@c@  Fri Mar  4 15:59:45 2022
From: ||809 @end|ng |rom nc|@c@ (Brian Lunergan)
Date: Fri, 4 Mar 2022 09:59:45 -0500
Subject: [R] Problem installing Rcmdr on version 4.1.2...
In-Reply-To: <20220304163403.518a397a@arachnoid>
References: <c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>
 <20220304163403.518a397a@arachnoid>
Message-ID: <fb644a03-56e8-35af-89e3-eb5fb9d558b1@ncf.ca>

On 2022-03-04 8:34 a.m., Ivan Krylov wrote:

> Typically, when an R package wraps a third-party library, you need a
> development version of it installed in order to install that package
> from source.
> 
> If you're running R from the Linux Mint repos, try to install
> r-cran-nloptr from Linux Mint repositories. If you don't, or have some
> trouble installing the package, install the libnlopt-dev Linux Mint
> package before trying to install the nloptr R package.
> 

libnlopt-dev installed okay, but when I tried pulling in the r-cran
package I got this:

brian at brian-Aspire-ES1-511:~$ sudo apt-get install r-cran-nloptr
Reading package lists... Done
Building dependency tree
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help resolve the situation:

The following packages have unmet dependencies:
 r-cran-nloptr : Depends: r-api-3.4
E: Unable to correct problems, you have held broken packages.

I'll try the R site, but I'm open to other ideas.:-(
-- 
Brian Lunergan
Russell, ON
Canada

-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpenPGP_signature
Type: application/pgp-signature
Size: 665 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20220304/7e3cc72a/attachment.sig>

From @rth|en @end|ng |rom gm@||@com  Fri Mar  4 16:17:17 2022
From: @rth|en @end|ng |rom gm@||@com (Arthur Fendrich)
Date: Fri, 4 Mar 2022 16:17:17 +0100
Subject: [R] Possible causes of unexpected behavior
In-Reply-To: <CAGgJW7413G4fERhaD5DP=6uBsPp7HNqgvFyzxpp4OmJJG_BLTw@mail.gmail.com>
References: <CADxQpSnG4iBc9JLrnHvFV89MPiPg9YUwK5vFYq7t1XyqkdfShw@mail.gmail.com>
 <CAGgJW775Hth2rAKQc9mXfdARmYjoujEoLdcA47OVOXbRczYvvQ@mail.gmail.com>
 <CADxQpSkTAZ7mOx2_zeRKNa4JmBuiOiwTOPs6k2U-9ER0RyGq1A@mail.gmail.com>
 <CAGgJW75REvX_yiOdORUsZDdSO0uajk+FCdecZu_VjHsKZAs4jg@mail.gmail.com>
 <CADxQpSk5pxzTaQvNTVzSLqUXmJoMp-cA-jkOSNXUjrqQyAv--A@mail.gmail.com>
 <CAGgJW7413G4fERhaD5DP=6uBsPp7HNqgvFyzxpp4OmJJG_BLTw@mail.gmail.com>
Message-ID: <CADxQpS=hO=zeWNOFZDfkOLsZYOWm1UZhKDJZuDOEWWjTzf5o_Q@mail.gmail.com>

Dear Eric,

I followed your suggestion (A) and I believe I finally got to the cause of
the problem.
It turns out that I was not exporting two environment variables for step
iii. Because this part of the code does not run in parallel, I was simply
ignoring them:
> export OMP_NUM_THREADS=1
> export OPENBLAS_NUM_THREADS=1

When I do that, the results change for some reason that I still have to
investigate further. What I get now seems coherent (below).

Thank you again for the help.

Best regards,
Arthur

##

-- Results for optim(f) --

Case: qsub, with or without the two variables (same result for both):
- initial guess:
  v = [0 0 0 0 0 0 0 0 0]
  f(v) = 599765.9
- solution:
  v = [0.3529 -6.4176 -0.0271 -0.0066 0.0013 -0.0172 -0.0198 -0.0034
-0.0171]
  f(v) = 14310.68

#
Case: manual without the two variables:
- initial guess:
  v = [0 0 0 0 0 0 0 0 0]
  f(v) = 643417.1
- solution:
  v = [1.5669 -6.2815 -0.0091 -0.0022 0.0004 -0.0059 -0.0066 -0.0014 -0.005]
  f(v) = 19712.85

#
Case: manual with the two variables:
- initial guess:
  v = [0 0 0 0 0 0 0 0 0]
  f(v) = 599765.9
- solution:
  v = [0.3529 -6.4176 -0.0271 -0.0066 0.0013 -0.0172 -0.0198 -0.0034
-0.0171]
  f(v) = 14310.68

Em sex., 4 de mar. de 2022 ?s 11:13, Eric Berger <ericjberger at gmail.com>
escreveu:

> If I understand correctly, steps i,ii can be ignored.
> i.e. we just focus on step iii with A,B,C,D fixed.
>
> You do the optimization of f(v) to calculate, say, v* = argmin f(v).
> This optimization is single threaded.
>
> (A)
> In that case, I suggest you add some logging so that for each call to f(),
> you output its input and output.
> Then you can (re-) confirm your validation test - i.e. that the "manual"
> calc of f(v*) gives a different result than what is found in the log file.
>
> (B) If (A) doesn't lead you anywhere ....
> Re-reading your original description of the process, it seems that the
> time consuming part is creating A,B,C,D.
> If the evaluation of f(v) is not overly time consuming, then run the
> optimization under valgrind. It is possible that you are depending on some
> uninitialized variables, or trashing memory somewhere.
>
>
>
> On Fri, Mar 4, 2022 at 11:54 AM Arthur Fendrich <arthfen at gmail.com> wrote:
>
>> Dear Eric,
>>
>> Yes, I can confirm that I have distributed calculations running in
>> parallel.
>>
>> I am not sure if this is a precise answer to the thread-safe question
>> since I'm not familiar with this definition, but what I do is:
>>  i) First, chunks of A, B, C and D are calculated from X in parallel by
>> the worker nodes.
>>  ii) Second, all the chunks are combined on my master node, and the final
>> A, B, C and D are saved to disk.
>>  iii) Then, still on the master node, I optimize f(v) using the final A,
>> B, C and D.
>>
>> When I debug, I skip steps i) and ii) and check only iii) manually by
>> loading A, B, C and D from the disk and evaluating f(v*). Does that seem
>> correct?
>>
>> Best regards,
>> Arthur
>>
>> Em sex., 4 de mar. de 2022 ?s 10:33, Eric Berger <ericjberger at gmail.com>
>> escreveu:
>>
>>> Can you confirm you have a distributed calculation running in parallel?
>>> Have you determined that it is thread safe? How?
>>> Your check on the smaller examples may not have ruled out such
>>> possibilities.
>>>
>>> On Fri, Mar 4, 2022 at 11:21 AM Arthur Fendrich <arthfen at gmail.com>
>>> wrote:
>>>
>>>> Dear Eric,
>>>>
>>>> Thank you for the response. Yes, I can confirm that, please see below
>>>> the behavior.
>>>> For #1, results are identical. For #2, they are not identical but very
>>>> close. For #3, they are completely different.
>>>>
>>>> Best regards,
>>>> Arthur
>>>>
>>>> --
>>>>
>>>> For #1,
>>>> - qsub execution:
>>>> [1] "ll: 565.7251"
>>>> [1] "norm gr @ minimum: 2.96967368608131e-08"
>>>>
>>>> - manual check:
>>>> f(v*): 565.7251
>>>> gradient norm at v*: 2.969674e-08
>>>>
>>>> #
>>>> For #2,
>>>>
>>>> - qsub execution:
>>>> [1] "ll: 14380.8308"
>>>> [1] "norm gr @ minimum: 0.0140857561408041"
>>>>
>>>> - manual check:
>>>> f(v*): 14380.84
>>>> gradient norm at v*: 0.01404779
>>>>
>>>> #
>>>> For #3,
>>>>
>>>> - qsub execution:
>>>> [1] "ll: 14310.6812"
>>>> [1] "norm gr @ minimum: 6232158.38877002"
>>>>
>>>> - manual check:
>>>> f(v*): 97604.69
>>>> gradient norm at v*: 6266696595
>>>>
>>>> Em sex., 4 de mar. de 2022 ?s 09:48, Eric Berger <ericjberger at gmail.com>
>>>> escreveu:
>>>>
>>>>> Please confirm that when you do the manual load and check that f(v*)
>>>>> matches the result from qsub() it succeeds for cases #1,#2 but only fails
>>>>> for #3.
>>>>>
>>>>>
>>>>> On Fri, Mar 4, 2022 at 10:06 AM Arthur Fendrich <arthfen at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Dear all,
>>>>>>
>>>>>> I am currently having a weird problem with a large-scale optimization
>>>>>> routine. It would be nice to know if any of you have already gone
>>>>>> through
>>>>>> something similar, and how you solved it.
>>>>>>
>>>>>> I apologize in advance for not providing an example, but I think the
>>>>>> non-reproducibility of the error is maybe a key point of this problem.
>>>>>>
>>>>>> Simplest possible description of the problem: I have two functions:
>>>>>> g(X)
>>>>>> and f(v).
>>>>>> g(X) does:
>>>>>>  i) inputs a large matrix X;
>>>>>>  ii) derives four other matrices from X (I'll call them A, B, C and
>>>>>> D) then
>>>>>> saves to disk for debugging purposes;
>>>>>>
>>>>>> Then, f(v) does:
>>>>>>  iii) loads A, B, C, D from disk
>>>>>>  iv) calculates the log-likelihood, which vary according to a vector
>>>>>> of
>>>>>> parameters, v.
>>>>>>
>>>>>> My goal application is quite big (X is a 40000x40000 matrix), so I
>>>>>> created
>>>>>> the following versions to test and run the codes/math/parallelization:
>>>>>> #1) A simulated example with X being 100x100
>>>>>> #2) A degraded version of the goal application, with X being 4000x4000
>>>>>> #3) The goal application, with X being 40000x40000
>>>>>>
>>>>>> When I use qsub to submit the job, using the exact same code and
>>>>>> processing
>>>>>> cluster, #1 and #2 run flawlessly, so no problem. These results tell
>>>>>> me
>>>>>> that the codes/math/parallelization are fine.
>>>>>>
>>>>>> For application #3, it converges to a vector v*. However, when I
>>>>>> manually
>>>>>> load A, B, C and D from disk and calculate f(v*), then the value I
>>>>>> get is
>>>>>> completely different.
>>>>>> For example:
>>>>>> - qsub job says v* = c(0, 1, 2, 3) is a minimum with f(v*) = 1.
>>>>>> - when I manually load A, B, C, D from disk and calculate f(v*) on the
>>>>>> exact same machine with the same libraries and environment variables,
>>>>>> I get
>>>>>> f(v*) = 1000.
>>>>>>
>>>>>> This is a very confusing behavior. In theory the size of X should not
>>>>>> affect my problem, but it seems that things get unstable as the
>>>>>> dimension
>>>>>> grows. The main issue for debugging is that g(X) for simulation #3
>>>>>> takes
>>>>>> two hours to run, and I am completely lost on how I could find the
>>>>>> causes
>>>>>> of the problem. Would you have any general advices?
>>>>>>
>>>>>> Thank you very much in advance for literally any suggestions you
>>>>>> might have!
>>>>>>
>>>>>> Best regards,
>>>>>> Arthur
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From c@r| @end|ng |rom w|ttho|t@com  Fri Mar  4 17:45:39 2022
From: c@r| @end|ng |rom w|ttho|t@com (Carl Witthoft)
Date: Fri, 4 Mar 2022 11:45:39 -0500
Subject: [R] copying huge strings via clipboard?
Message-ID: <778a0fb5-08a8-7611-1bb4-ad9dace55bca@witthoft.com>

Hi,
This is on Windows10 via the R gui  .  I, admittedly inadvisably, tried 
to create a new character object by first copying a 1-million character 
string (including lead and trail "'" chars) to the clipboard and then, 
in the console,

 >> foo <-
and hitting "paste"

What I found is that, around 5000 characters, a newline ( "\n") char 
showed up.  Is this something that the Windows Clipboard does, or 
something odd about pasting into a command in R?

Postscript:  using

 >>  bar <- readChar('thefile.txt',1e6)

the import works perfectly.


-- 
Carl Witthoft
personal: carl at witthoft.com
The Witthoft Group, Consulting
https://witthoftgroup.weebly.com/


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Mar  4 17:58:30 2022
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 4 Mar 2022 08:58:30 -0800
Subject: [R] Problem installing Rcmdr on version 4.1.2...
In-Reply-To: <fb644a03-56e8-35af-89e3-eb5fb9d558b1@ncf.ca>
References: <c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>
 <20220304163403.518a397a@arachnoid>
 <fb644a03-56e8-35af-89e3-eb5fb9d558b1@ncf.ca>
Message-ID: <678f9c36-046f-1d26-ac88-0e9d1a820614@comcast.net>


On 3/4/22 06:59, Brian Lunergan wrote:
> On 2022-03-04 8:34 a.m., Ivan Krylov wrote:
>
>> Typically, when an R package wraps a third-party library, you need a
>> development version of it installed in order to install that package
>> from source.
>>
>> If you're running R from the Linux Mint repos, try to install
>> r-cran-nloptr from Linux Mint repositories. If you don't, or have some
>> trouble installing the package, install the libnlopt-dev Linux Mint
>> package before trying to install the nloptr R package.
>>
> libnlopt-dev installed okay, but when I tried pulling in the r-cran
> package I got this:
>
> brian at brian-Aspire-ES1-511:~$ sudo apt-get install r-cran-nloptr
That's not the typical way to install an R package from source.
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> Some packages could not be installed. This may mean that you have
> requested an impossible situation or if you are using the unstable
> distribution that some required packages have not yet been created
> or been moved out of Incoming.
> The following information may help resolve the situation:
>
> The following packages have unmet dependencies:
>   r-cran-nloptr : Depends: r-api-3.4


Is there anything in your setup that would explain why nloptr is looking 
for an ancient version of R? I'm wondering if that binary package was 
created years ago and hasn't been replaced since nloptr was reconfigured 
to do the work of installing nlopt?

I'm also failing to install nloptr 2.0.0 using R 4.1.2 in an Ubuntu 
18.04 machine. The first reported error was not having Cmake, but 
installing Cmake then leads to failure both from the R console and from 
a terminal session with:

R CMD INSTALL ~/Downloads/nloptr_2.0.0.tar.gz

It fails at:

checking for pkg-config... /usr/bin/pkg-config
checking if pkg-config knows NLopt... no
using NLopt via local cmake build on x86_64
set CMAKE_BIN=/usr/bin/cmake
set CC=gcc -std=gnu99 -std=gnu11
set CFLAGS= -fpic -g -O2 
-fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=. 
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time 
-D_FORTIFY_SOURCE=2 -g
set CXX=g++
set CXXFLAGS=-std=gnu++11 -fpic -g -O2 
-fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=. 
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time 
-D_FORTIFY_SOURCE=2 -g -Wno-ignored-attributes
set LDFLAGS=-Wl,-Bsymbolic-functions -Wl,-z,relro
CMake Error: The source directory 
"/tmp/RtmpzB1FjU/R.INSTALL289c4748c404/nloptr/src/nlopt-build" does not 
exist.

 ?My understanding is that the right place to post such difficulties is 
on R-SIG-debian, or at the Issues page: 
https://github.com/astamm/nloptr/issues/85

-- 

David

> E: Unable to correct problems, you have held broken packages.
>
> I'll try the R site, but I'm open to other ideas.:-(
>


From m|m@|tr@ @end|ng |rom gmx@com  Fri Mar  4 18:03:18 2022
From: m|m@|tr@ @end|ng |rom gmx@com (Ranjan Maitra)
Date: Fri, 4 Mar 2022 11:03:18 -0600
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <CALS=5moiamk9tzDdrJC05mqA-aiNOw67p6wniyuc8fOhGvZv9A@mail.gmail.com>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <YiGc1p7HZZP/jrAq@iastate.edu>
 <CALS=5moiamk9tzDdrJC05mqA-aiNOw67p6wniyuc8fOhGvZv9A@mail.gmail.com>
Message-ID: <YiJGVgbJ+uj/fhaW@iastate.edu>

On Fri Mar04'22 10:41:24AM, Paul Smith wrote:
> From: Paul Smith <phhs80 at gmail.com>
> Date: Fri, 4 Mar 2022 10:41:24 +0000
> To: Ranjan Maitra <mlmaitra at gmx.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Subject: Re: [R]  Looking for package for data generation for
>  classification and regression
>
> On Fri, Mar 4, 2022 at 8:07 AM Ranjan Maitra <mlmaitra at gmx.com> wrote:
> >
> > > I am in need of generating artificial data for machine learning
> > > classification and regression analysis. What I am looking for is
> > > something similar to Python sklearn.datasets.make_classification and
> > > sklearn.datasets.make_regression:
> > >
> > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> > >
> > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> > >
> > > I have searched CRAN for something similar, but found nothing. Could
> > > someone please help me with this?
> >
> > Not sure if this helps, but at least for classification and clustering, there is the MixSim package on CRAN which provides classification datasets according to an overall overlap measure.
>
> Thanks, Ranjan, that is also quite helpful, since clustering is also a
> topic of the course!
>
> Paul
>

The Clustering Algorithms Referee Package (CARP) uses the same codebase but is more general.

https://jmlr.org/papers/v12/melnykov11a.html

Unfortunately, it is written in C, so may not help.

It is on www.mloss.org at:

https://mloss.org/software/view/248/

but perhaps should also be moved to github.

Best wishes,
Ranjan


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Mar  4 18:34:15 2022
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 4 Mar 2022 09:34:15 -0800
Subject: [R] copying huge strings via clipboard?
In-Reply-To: <778a0fb5-08a8-7611-1bb4-ad9dace55bca@witthoft.com>
References: <778a0fb5-08a8-7611-1bb4-ad9dace55bca@witthoft.com>
Message-ID: <9bb2e8c4-cfbd-89fb-0c92-826d229496cb@comcast.net>


On 3/4/22 08:45, Carl Witthoft wrote:
> Hi,
> This is on Windows10 via the R gui? .? I, admittedly inadvisably, 
> tried to create a new character object by first copying a 1-million 
> character string (including lead and trail "'" chars) to the clipboard 
> and then, in the console,
>
> >> foo <-
> and hitting "paste"
>
> What I found is that, around 5000 characters, a newline ( "\n") char 
> showed up.? Is this something that the Windows Clipboard does, or 
> something odd about pasting into a command in R?

I'm the wrong person to comment on Windows clipboard features.

ISTR that there is a character limit for R command line input, at least 
in some or perhaps all R installations.

Subject: 	[R] parsing -?input?buffer overflow 
<http://markmail.org/message/iyjlmfsb4kp63cyi> 	permalink 
<http://markmail.org/message/iyjlmfsb4kp63cyi>
From: 	Prof Brian Ripley (rip... at stats.ox.ac.uk)
Date: 	Jun 13, 2008 1:52:06 am
List: 	org.r-project.r-help

"R does have limits on the command line length (1024 bytes up to 
R-devel, 4096 bytes there). What happens if you exceed that depends on 
the interface you are using (and you have not told us). Beyond that, the 
parser has a limit of MAXELTSIZE (8192 bytes) on strings.

I don't see any need for 'improvement' though: why are you entering very 
long strings as part of the R program? They are data, and e.g. 
readLines() and scan() have no limits on string length beyond those 
imposed by R's internals (2^31-1 bytes)."


I think that info is still current since a search of the 
../manuals/R-int page says:

--- copied

The|R_StringBuffer|structure needs to be initialized, for example by

static R_StringBuffer ex_buff = {NULL, 0, MAXELTSIZE};

which uses a default size of|MAXELTSIZE = 8192|bytes.Most current uses 
have a static|R_StringBuffer|structure, which allows the (default-sized) 
buffer to be shared between calls to e.g.|grep|and even between 
functions: this will need to be changed if R ever allows concurrent 
evaluation threads.

--- end copy


-- 

David


>
> Postscript:? using
>
> >>? bar <- readChar('thefile.txt',1e6)
>
> the import works perfectly.
>
>


From phh@80 @end|ng |rom gm@||@com  Fri Mar  4 18:45:01 2022
From: phh@80 @end|ng |rom gm@||@com (Paul Smith)
Date: Fri, 4 Mar 2022 17:45:01 +0000
Subject: [R] 
 Looking for package for data generation for classification and
 regression
In-Reply-To: <YiJGVgbJ+uj/fhaW@iastate.edu>
References: <CALS=5mqW6y_dfBDGrVQ5rGLwUwS4bSeV+5W1zf+=tifGLYvZ4Q@mail.gmail.com>
 <YiGc1p7HZZP/jrAq@iastate.edu>
 <CALS=5moiamk9tzDdrJC05mqA-aiNOw67p6wniyuc8fOhGvZv9A@mail.gmail.com>
 <YiJGVgbJ+uj/fhaW@iastate.edu>
Message-ID: <CALS=5mqtHvQJ88aUHJZos_hgZT1emDou7vE62djpMC6_mV3KxQ@mail.gmail.com>

On Fri, Mar 4, 2022 at 5:03 PM Ranjan Maitra <mlmaitra at gmx.com> wrote:
>
> > > > I am in need of generating artificial data for machine learning
> > > > classification and regression analysis. What I am looking for is
> > > > something similar to Python sklearn.datasets.make_classification and
> > > > sklearn.datasets.make_regression:
> > > >
> > > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html
> > > >
> > > > https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html
> > > >
> > > > I have searched CRAN for something similar, but found nothing. Could
> > > > someone please help me with this?
> > >
> > > Not sure if this helps, but at least for classification and clustering, there is the MixSim package on CRAN which provides classification datasets according to an overall overlap measure.
> >
> > Thanks, Ranjan, that is also quite helpful, since clustering is also a
> > topic of the course!
>
> The Clustering Algorithms Referee Package (CARP) uses the same codebase but is more general.
>
> https://jmlr.org/papers/v12/melnykov11a.html
>
> Unfortunately, it is written in C, so may not help.
>
> It is on www.mloss.org at:
>
> https://mloss.org/software/view/248/
>
> but perhaps should also be moved to github.

That is quite interesting, Ranjan! I hope you will have that on GitHub
as a R package ready for installation.

Best wishes, Paul


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Mar  4 21:13:40 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 04 Mar 2022 12:13:40 -0800
Subject: [R] copying huge strings via clipboard?
In-Reply-To: <9bb2e8c4-cfbd-89fb-0c92-826d229496cb@comcast.net>
References: <778a0fb5-08a8-7611-1bb4-ad9dace55bca@witthoft.com>
 <9bb2e8c4-cfbd-89fb-0c92-826d229496cb@comcast.net>
Message-ID: <FC0EA404-02CB-4EC5-B39D-ECD928805308@dcn.davis.ca.us>

Windows can handle up to 2GB in the clipboard... but IMO it isn't a good practice to rely on. Use files for reproducibility and portability. It is common for command line shells of all varieties to limit their buffer sizes considerably.

On March 4, 2022 9:34:15 AM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>
>On 3/4/22 08:45, Carl Witthoft wrote:
>> Hi,
>> This is on Windows10 via the R gui? .? I, admittedly inadvisably, 
>> tried to create a new character object by first copying a 1-million 
>> character string (including lead and trail "'" chars) to the clipboard 
>> and then, in the console,
>>
>> >> foo <-
>> and hitting "paste"
>>
>> What I found is that, around 5000 characters, a newline ( "\n") char 
>> showed up.? Is this something that the Windows Clipboard does, or 
>> something odd about pasting into a command in R?
>
>I'm the wrong person to comment on Windows clipboard features.
>
>ISTR that there is a character limit for R command line input, at least 
>in some or perhaps all R installations.
>
>Subject: 	[R] parsing -?input?buffer overflow 
><http://markmail.org/message/iyjlmfsb4kp63cyi> 	permalink 
><http://markmail.org/message/iyjlmfsb4kp63cyi>
>From: 	Prof Brian Ripley (rip... at stats.ox.ac.uk)
>Date: 	Jun 13, 2008 1:52:06 am
>List: 	org.r-project.r-help
>
>"R does have limits on the command line length (1024 bytes up to 
>R-devel, 4096 bytes there). What happens if you exceed that depends on 
>the interface you are using (and you have not told us). Beyond that, the 
>parser has a limit of MAXELTSIZE (8192 bytes) on strings.
>
>I don't see any need for 'improvement' though: why are you entering very 
>long strings as part of the R program? They are data, and e.g. 
>readLines() and scan() have no limits on string length beyond those 
>imposed by R's internals (2^31-1 bytes)."
>
>
>I think that info is still current since a search of the 
>../manuals/R-int page says:
>
>--- copied
>
>The|R_StringBuffer|structure needs to be initialized, for example by
>
>static R_StringBuffer ex_buff = {NULL, 0, MAXELTSIZE};
>
>which uses a default size of|MAXELTSIZE = 8192|bytes.Most current uses 
>have a static|R_StringBuffer|structure, which allows the (default-sized) 
>buffer to be shared between calls to e.g.|grep|and even between 
>functions: this will need to be changed if R ever allows concurrent 
>evaluation threads.
>
>--- end copy
>
>

-- 
Sent from my phone. Please excuse my brevity.


From @rr@ypro|||e @end|ng |rom y@hoo@com  Sat Mar  5 01:41:57 2022
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Sat, 5 Mar 2022 00:41:57 +0000 (UTC)
Subject: [R] linear mixed model using lmer
References: <306704552.453726.1646440917947.ref@mail.yahoo.com>
Message-ID: <306704552.453726.1646440917947@mail.yahoo.com>

Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (attached). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?
> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
> library(lme4)> lmer(yield~1+(1|batch),daty)
boundary (singular) fit: see ?isSingular
Linear mixed model fit by REML ['lmerMod']
Formula: yield ~ 1 + (1 | batch)
? ?Data: daty
REML criterion at convergence: 115.6358
Random effects:
?Groups? ?Name? ? ? ? Std.Dev.
?batch? ? (Intercept) 0.000? ?
?Residual? ? ? ? ? ? ?2.789? ?
Number of obs: 24, groups:? batch, 2
Fixed Effects:
(Intercept)??
? ? ? 5.788??

Thanks!
John
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: datx.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20220305/296d04e5/attachment.txt>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Mar  5 01:56:16 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 04 Mar 2022 16:56:16 -0800
Subject: [R] linear mixed model using lmer
In-Reply-To: <306704552.453726.1646440917947@mail.yahoo.com>
References: <306704552.453726.1646440917947.ref@mail.yahoo.com>
 <306704552.453726.1646440917947@mail.yahoo.com>
Message-ID: <A7919738-CB75-4978-8862-614CE21F2A8A@dcn.davis.ca.us>

a) There is a mailing list for that: https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

b) Read the Posting Guide, as most attachment types are removed to avoid propagating worms/viruses. (None seen upon receipt of this email.)

On March 4, 2022 4:41:57 PM PST, array chip via R-help <r-help at r-project.org> wrote:
>Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (attached). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?
>> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
>> library(lme4)> lmer(yield~1+(1|batch),daty)
>boundary (singular) fit: see ?isSingular
>Linear mixed model fit by REML ['lmerMod']
>Formula: yield ~ 1 + (1 | batch)
>? ?Data: daty
>REML criterion at convergence: 115.6358
>Random effects:
>?Groups? ?Name? ? ? ? Std.Dev.
>?batch? ? (Intercept) 0.000? ?
>?Residual? ? ? ? ? ? ?2.789? ?
>Number of obs: 24, groups:? batch, 2
>Fixed Effects:
>(Intercept)??
>? ? ? 5.788??
>
>Thanks!
>John
-- 
Sent from my phone. Please excuse my brevity.


From @rr@ypro|||e @end|ng |rom y@hoo@com  Sat Mar  5 02:05:59 2022
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Sat, 5 Mar 2022 01:05:59 +0000 (UTC)
Subject: [R] linear mixed model using lmer
In-Reply-To: <A7919738-CB75-4978-8862-614CE21F2A8A@dcn.davis.ca.us>
References: <306704552.453726.1646440917947.ref@mail.yahoo.com>
 <306704552.453726.1646440917947@mail.yahoo.com>
 <A7919738-CB75-4978-8862-614CE21F2A8A@dcn.davis.ca.us>
Message-ID: <325378712.461321.1646442359534@mail.yahoo.com>

 Thanks Jeff for reminding me that the attachment is removed. I put it in my google drive if anyone wants to test the data (https://drive.google.com/file/d/1lgVZVLHeecp9a_sFxEPeg6353O-qXZhM/view?usp=sharing)
I'll try the mixed model mailing list as well.
John
    On Friday, March 4, 2022, 04:56:20 PM PST, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:  
 
 a) There is a mailing list for that: https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

b) Read the Posting Guide, as most attachment types are removed to avoid propagating worms/viruses. (None seen upon receipt of this email.)

On March 4, 2022 4:41:57 PM PST, array chip via R-help <r-help at r-project.org> wrote:
>Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (attached). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?
>> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
>> library(lme4)> lmer(yield~1+(1|batch),daty)
>boundary (singular) fit: see ?isSingular
>Linear mixed model fit by REML ['lmerMod']
>Formula: yield ~ 1 + (1 | batch)
>? ?Data: daty
>REML criterion at convergence: 115.6358
>Random effects:
>?Groups? ?Name? ? ? ? Std.Dev.
>?batch? ? (Intercept) 0.000? ?
>?Residual? ? ? ? ? ? ?2.789? ?
>Number of obs: 24, groups:? batch, 2
>Fixed Effects:
>(Intercept)??
>? ? ? 5.788??
>
>Thanks!
>John
-- 
Sent from my phone. Please excuse my brevity.
  
	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Mar  5 03:09:58 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 4 Mar 2022 21:09:58 -0500
Subject: [R] Problem installing Rcmdr on version 4.1.2...
In-Reply-To: <14806_1646400247_224DO7eH001173_c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>
References: <14806_1646400247_224DO7eH001173_c924d43e-46f3-a313-deb6-a54fc8ab5a8d@ncf.ca>
Message-ID: <7c42e01a-4b21-30ff-59ae-bf6422aab586@mcmaster.ca>

Dear Brian,

You've already gotten better assistance from others than I could 
provide, but I can elucidate the nature of the dependency: The Rcmdr 
package imports the lme4 package which depends on the nloptr package.

lme4 is a sufficiently important package that it's general failure on 
common Linux distributions would attract rapid attention, and so I 
suspect that the problem isn't general.

I hope that this is of some help,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2022-03-04 8:23 a.m., Brian Lunergan wrote:
> Hi folks:
> 
> Running R 4.1.2 on Linux Mint 19.3. Tried to install Rcmdr, but when it
> tried to install nloptr I got the following as it seemed to trip over
> Cmake. Bit lengthy but here's what was spit out.
> 
> * installing *source* package ?nloptr? ...
> ** package ?nloptr? successfully unpacked and MD5 sums checked
> ** using staged installation
> checking whether the C++ compiler works... yes
> checking for C++ compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ -std=gnu++14 accepts -g... yes
> checking how to run the C++ preprocessor... g++ -std=gnu++14 -E
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ -std=gnu++14 accepts -g... (cached) yes
> checking for pkg-config... /usr/bin/pkg-config
> checking if pkg-config knows NLopt... no
> using NLopt via local cmake build on x86_64
> set CMAKE_BIN=/usr/bin/cmake
> set CC=gcc -std=gnu99 -std=gnu11
> set CFLAGS= -fpic -g -O2
> -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g
> set CXX=g++
> set CXXFLAGS=-std=gnu++11 -fpic -g -O2
> -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g
> set LDFLAGS=-Wl,-Bsymbolic-functions -Wl,-z,relro
> CMake Error: The source directory
> "/tmp/RtmpP4rvt0/R.INSTALL360c3be2694c/nloptr/src/nlopt-build" does not
> exist.
> Specify --help for usage, or press the help button on the CMake GUI.
> Unknown argument -j
> Unknown argument 2
> Usage: cmake --build <dir> [options] [-- [native-options]]
> Options:
>    <dir>          = Project binary directory to be built.
>    --target <tgt> = Build <tgt> instead of default targets.
>                     May only be specified once.
>    --config <cfg> = For multi-configuration tools, choose <cfg>.
>    --clean-first  = Build target 'clean' first, then build.
>                     (To clean only, use --target 'clean'.)
>    --use-stderr   = Ignored.  Behavior is default in CMake >= 3.0.
>    --             = Pass remaining options to the native tool.
> CMake Error: The source directory
> "/tmp/RtmpP4rvt0/R.INSTALL360c3be2694c/nloptr/src/nlopt" does not exist.
> Specify --help for usage, or press the help button on the CMake GUI.
> cp: cannot stat 'nlopt/include/*': No such file or directory
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> gcc -std=gnu99 -std=gnu11 -I"/usr/share/R/include" -DNDEBUG
> -I../inst/include
> -I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
> -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -c init_nloptr.c -o init_nloptr.o
> gcc -std=gnu99 -std=gnu11 -I"/usr/share/R/include" -DNDEBUG
> -I../inst/include
> -I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
> -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -c nloptr.c -o nloptr.o
> g++ -std=gnu++11 -I"/usr/share/R/include" -DNDEBUG -I../inst/include
> -I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
> -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -c test-C-API.cpp -o test-C-API.o
> g++ -std=gnu++11 -I"/usr/share/R/include" -DNDEBUG -I../inst/include
> -I'/home/brian/R/x86_64-pc-linux-gnu-library/4.1/testthat/include'
> -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-J7pprH/r-base-4.1.2=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -c test-runner.cpp -o test-runner.o
> g++ -std=gnu++11 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o nloptr.so init_nloptr.o nloptr.o test-C-API.o
> test-runner.o -llapack -lblas -lgfortran -lm -lquadmath -Lnlopt/lib
> -lnlopt -L/usr/lib/R/lib -lR
> /usr/bin/ld: cannot find -lnlopt
> collect2: error: ld returned 1 exit status
> /usr/share/R/share/make/shlib.mk:10: recipe for target 'nloptr.so' failed
> make: *** [nloptr.so] Error 1
> ERROR: compilation failed for package ?nloptr?
> * removing ?/home/brian/R/x86_64-pc-linux-gnu-library/4.1/nloptr?
> 
> I have cmake on mint in the current edition, but when I try to install
> it in R it fires as not available for 4.1.2. Is there a version out
> there that will work with 4.1.2? Where would I find it and how would I
> install it? Any help/advice would be greatly appreciated.
> 
> Regards...
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Mar  5 03:13:00 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 4 Mar 2022 18:13:00 -0800
Subject: [R] linear mixed model using lmer
In-Reply-To: <325378712.461321.1646442359534@mail.yahoo.com>
References: <306704552.453726.1646440917947.ref@mail.yahoo.com>
 <306704552.453726.1646440917947@mail.yahoo.com>
 <A7919738-CB75-4978-8862-614CE21F2A8A@dcn.davis.ca.us>
 <325378712.461321.1646442359534@mail.yahoo.com>
Message-ID: <CAGxFJbTsiPnh5RSctSEcUFR9afTaA9BUcwbT7V0WS0FKB+2RYA@mail.gmail.com>

Do you really think a variance from a sample size of 2 makes any sense?

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Mar 4, 2022 at 5:06 PM array chip via R-help
<r-help at r-project.org> wrote:
>
>  Thanks Jeff for reminding me that the attachment is removed. I put it in my google drive if anyone wants to test the data (https://drive.google.com/file/d/1lgVZVLHeecp9a_sFxEPeg6353O-qXZhM/view?usp=sharing)
> I'll try the mixed model mailing list as well.
> John
>     On Friday, March 4, 2022, 04:56:20 PM PST, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
>  a) There is a mailing list for that: https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> b) Read the Posting Guide, as most attachment types are removed to avoid propagating worms/viruses. (None seen upon receipt of this email.)
>
> On March 4, 2022 4:41:57 PM PST, array chip via R-help <r-help at r-project.org> wrote:
> >Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (attached). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?
> >> daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
> >> library(lme4)> lmer(yield~1+(1|batch),daty)
> >boundary (singular) fit: see ?isSingular
> >Linear mixed model fit by REML ['lmerMod']
> >Formula: yield ~ 1 + (1 | batch)
> >   Data: daty
> >REML criterion at convergence: 115.6358
> >Random effects:
> > Groups   Name        Std.Dev.
> > batch    (Intercept) 0.000
> > Residual             2.789
> >Number of obs: 24, groups:  batch, 2
> >Fixed Effects:
> >(Intercept)
> >      5.788
> >
> >Thanks!
> >John
> --
> Sent from my phone. Please excuse my brevity.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t  Mon Mar  7 13:21:11 2022
From: er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t (Erich Subscriptions)
Date: Mon, 7 Mar 2022 13:21:11 +0100
Subject: [R] R in Windows 11 ARM (in Parallels)
Message-ID: <281D21CA-6F0D-4D17-A875-89F9C4DA6B57@neuwirth.priv.at>

I tried to Install R in Windows 11 ARM in Parallels on a Mac M1.
The installed only offered to install the 32bit version (of R for Windows).
This installation works.
When I tried to install the 64bit version, I could install it,
but it does not run.

Is it possible to make it run?

Erich Neuwirth


From |8|5h9 @end|ng |rom gm@||@com  Mon Mar  7 10:14:59 2022
From: |8|5h9 @end|ng |rom gm@||@com (=?utf-8?Q?Fernando_A_L=C3=B3pez_Hern=C3=A1ndez?=)
Date: Mon, 7 Mar 2022 10:14:59 +0100
Subject: [R] [R-pkgs] spqdep: An R package to test for spatial dependence in
 categorical spatial data
Message-ID: <11C9A418-E478-41DD-ADD9-ADEB9535759F@gmail.com>

Dear R users,

I am happy to announce that a new package ?spqdep? is now available on CRAN.
https://cran.r-project.org/web/packages/spqdep/index.html <https://cran.r-project.org/web/packages/spqdep/index.html>

The objective of this R-package is to test for spatial dependence in categorical spatial data. 
https://f8l5h9.github.io/spqdep/articles/spq_userguide.html <https://f8l5h9.github.io/spqdep/articles/spq_userguide.html>

Several tests have been implemented in spqdep, namely, the classical joint count statistics, the Q-test based on symbolic dynamics, the Scan-test based on scan methodology and a new spatial test based on spatial-runs. All tests can be applied to categorical spatial cross-section data with two or more categories and asymptotic and bootstrap permutation distribution are implemented. The R package is completely documented, including several examples and an user-guide is available as a vignette.

Best regards,
Fernando L?pez


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dj@ndr|j@ @end|ng |rom gm@||@com  Mon Mar  7 15:01:46 2022
From: dj@ndr|j@ @end|ng |rom gm@||@com (Andrija Djurovic)
Date: Mon, 7 Mar 2022 15:01:46 +0100
Subject: [R] [R-pkgs] PDtoolkit: new version 0.2.0
Message-ID: <CABcwgRSNJAUbDWvpdWctGjSqTvpzdeX1YAb2DhVR0YwAq+go5g@mail.gmail.com>

Dear R users,

the new version (0.2.0) of PDtoolkit package is now on CRAN.
The is the package second update.

Since the first release, besides minor improvements of the existing
features, package is extended with a new functions:
1. psi - calculates population stability index
2. create.partitions - creates nested dummy variables
3. evrs - uses for modeling the economic value of PD rating model
4. interaction.transforme -  extracts risk factors interaction from
decision tree

For examples, please, install the new version of the package and check the
help page of the functions.

Best regards,
Andrija Djurovic

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Mar  7 17:19:15 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 07 Mar 2022 08:19:15 -0800
Subject: [R] R in Windows 11 ARM (in Parallels)
In-Reply-To: <281D21CA-6F0D-4D17-A875-89F9C4DA6B57@neuwirth.priv.at>
References: <281D21CA-6F0D-4D17-A875-89F9C4DA6B57@neuwirth.priv.at>
Message-ID: <5CC76D0F-5E16-4310-8542-EEA8F6CA496A@dcn.davis.ca.us>

I doubt any R Core developers have tested such a configuration. Perhaps you can ferret out why amd64 emulation in a Windows 11 ARM VM is not working and inform them if there is anything on the R side that is causing problems? I suspect this is an issue completely outside of their control though... you have emulation inside a VM that is fresh out of the oven...

On March 7, 2022 4:21:11 AM PST, Erich Subscriptions <erich.subs at neuwirth.priv.at> wrote:
>I tried to Install R in Windows 11 ARM in Parallels on a Mac M1.
>The installed only offered to install the 32bit version (of R for Windows).
>This installation works.
>When I tried to install the 64bit version, I could install it,
>but it does not run.
>
>Is it possible to make it run?
>
>Erich Neuwirth
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rc_@chw@rtz @end|ng |rom me@com  Mon Mar  7 19:28:51 2022
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 7 Mar 2022 13:28:51 -0500
Subject: [R] R in Windows 11 ARM (in Parallels)
In-Reply-To: <5CC76D0F-5E16-4310-8542-EEA8F6CA496A@dcn.davis.ca.us>
References: <281D21CA-6F0D-4D17-A875-89F9C4DA6B57@neuwirth.priv.at>
 <5CC76D0F-5E16-4310-8542-EEA8F6CA496A@dcn.davis.ca.us>
Message-ID: <etPan.62264ee3.2d4591ab.316@me.com>

?
Hi,

A couple of things to add:

1. You might find a more focused audience for this question on r-sig-mac:

? https://stat.ethz.ch/mailman/listinfo/r-sig-mac

given the cross-platform nature of the query, while running R and Parallels/Windows 11 on Apple silicon.

2. My understanding is that x64 (Intel 64 bit) emulation is relatively immature running under Windows 11 ARM, even on native Windows targeted ARM hardware, much less on Apple silicon. It was just announced last November, in contrast to 32 bit Intel emulation on ARM, which has been around somewhat longer. Thus, the additional layer of running Windows 11 ARM under Parallels on Apple silicon may be a confounding issue.

As a result, you might also consider posting to Parallels' own support forums to get a sense from them as to the current nature of their support and any known issues running x64 apps in their VM, under Windows 11 ARM. There may be nuances to the required configuration to get 64-bit R for Windows running under that combination of characteristics.

Regards,

Marc Schwartz

On March 7, 2022 at 11:19:15 AM, Jeff Newmiller (jdnewmil at dcn.davis.ca.us (mailto:jdnewmil at dcn.davis.ca.us)) wrote:

> I doubt any R Core developers have tested such a configuration. Perhaps you can ferret out why amd64 emulation in a Windows 11 ARM VM is not working and inform them if there is anything on the R side that is causing problems? I suspect this is an issue completely outside of their control though... you have emulation inside a VM that is fresh out of the oven...
>
> On March 7, 2022 4:21:11 AM PST, Erich Subscriptions wrote:
> >I tried to Install R in Windows 11 ARM in Parallels on a Mac M1.
> >The installed only offered to install the 32bit version (of R for Windows).
> >This installation works.
> >When I tried to install the 64bit version, I could install it,
> >but it does not run.
> >
> >Is it possible to make it run?
> >
> >Erich Neuwirth
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e||z@_botto @end|ng |rom out|ook@com  Tue Mar  8 07:21:51 2022
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 8 Mar 2022 06:21:51 +0000
Subject: [R] Raster map in R
Message-ID: <AS8P194MB0999B8B3D2F65B190C82DA569A099@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

deaR expeRts,

I have the following data

> dput(Tuto)
structure(list(X = c(-114.028, -114.011, -114.442, -113.937,
-114.187, -114.083, -113.949, -114.15, -114.068, -114.203, -113.958,
-114.248, -114.18, -114.14, -114.071, -114.042, -114.187, -114.03,
-113.97, -113.824, -114.084, -114.152, -114.468, -113.935, -113.994,
-114.048, -114.188, -114.129, -114.071, -113.934, -114.001, -114.075,
-114.121, -113.958, -114.039, -113.963, -114.062, -114.183, -114.118,
-114.119, -113.954, -114.051, -113.988, -114.194, -114.025),
    Y = c(51.431, 51.279, 51.167, 51.165, 51.155, 51.14, 51.126,
    51.126, 51.116, 51.115, 51.092, 51.091, 51.084, 51.082, 51.076,
    51.069, 51.062, 51.052, 51.051, 51.048, 51.044, 51.039, 51.037,
    51.034, 51.03, 51.029, 51.021, 51.006, 51.005, 50.99, 50.983,
    50.966, 50.958, 50.948, 50.929, 50.916, 50.911, 50.908, 50.908,
    50.907, 50.877, 50.877, 50.86, 50.854, 50.826), a = c(0.838,
    0.901, 0.953, 0.902, 0.782, 0.938, 0.884, 0.879, 0.932, 0.947,
    0.965, 0.828, 0.923, 0.892, 0.884, 0.897, 0.912, 0.988, 0.901,
    0.855, 0.999, 0.846, 0.845, 0.798, 0.749, 0.753, 0.762, 0.646,
    0.729, 0.544, 0.265, 0.449, 0.334, 0.36, 0.325, 0.337, 0.249,
    0.114, 0.149, 0.173, 0.175, 0.184, 0.219, 0.106, 0.148),
    n = c(0.653, 0.625, 0.641, 0.63, 0.656, 0.619, 0.628, 0.634,
    0.63, 0.604, 0.598, 0.617, 0.632, 0.635, 0.637, 0.646, 0.619,
    0.613, 0.63, 0.615, 0.604, 0.639, 0.598, 0.593, 0.583, 0.606,
    0.594, 0.653, 0.63, 0.577, 0.624, 0.626, 0.676, 0.641, 0.629,
    0.579, 0.603, 0.607, 0.66, 0.614, 0.618, 0.574, 0.552, 0.62,
    0.599)), row.names = c(19L, 22L, 18L, 3L, 45L, 20L, 14L,
43L, 40L, 44L, 37L, 12L, 42L, 41L, 39L, 38L, 33L, 8L, 36L, 16L,
32L, 31L, 5L, 34L, 35L, 9L, 13L, 30L, 29L, 4L, 24L, 27L, 28L,
23L, 25L, 21L, 26L, 6L, 15L, 2L, 1L, 7L, 11L, 10L, 17L), class = "data.frame")

In the given data,

X-> Latitude

Y-> Longitude

a-> Factor 1

n-> Factor 2

I want to draw a raster map of these values within the following limits  (xmn=-114.5, xmx=-113.7, ymn=50.800, ymx=51.600). I have tried through "raster" library but failed as I wasn't able to properly generate the data.
I will be thankful if I can get any kind of help. Thank-you very much in advance.

Eliza



	[[alternative HTML version deleted]]


From t@v|b@r @end|ng |rom gm@||@com  Tue Mar  8 10:11:02 2022
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 8 Mar 2022 11:11:02 +0200
Subject: [R] Raster map in R
In-Reply-To: <AS8P194MB0999B8B3D2F65B190C82DA569A099@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB0999B8B3D2F65B190C82DA569A099@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <61d3774f-e00d-3bfa-0fbb-6ff7ed6cadb7@gmail.com>


On 08/03/2022 08:21, Eliza Botto wrote:
> deaR expeRts,
>
> I have the following data
>
>> dput(Tuto)
> structure(list(X = c(-114.028, -114.011, -114.442, -113.937,
> -114.187, -114.083, -113.949, -114.15, -114.068, -114.203, -113.958,
> -114.248, -114.18, -114.14, -114.071, -114.042, -114.187, -114.03,
> -113.97, -113.824, -114.084, -114.152, -114.468, -113.935, -113.994,
> -114.048, -114.188, -114.129, -114.071, -113.934, -114.001, -114.075,
> -114.121, -113.958, -114.039, -113.963, -114.062, -114.183, -114.118,
> -114.119, -113.954, -114.051, -113.988, -114.194, -114.025),
>      Y = c(51.431, 51.279, 51.167, 51.165, 51.155, 51.14, 51.126,
>      51.126, 51.116, 51.115, 51.092, 51.091, 51.084, 51.082, 51.076,
>      51.069, 51.062, 51.052, 51.051, 51.048, 51.044, 51.039, 51.037,
>      51.034, 51.03, 51.029, 51.021, 51.006, 51.005, 50.99, 50.983,
>      50.966, 50.958, 50.948, 50.929, 50.916, 50.911, 50.908, 50.908,
>      50.907, 50.877, 50.877, 50.86, 50.854, 50.826), a = c(0.838,
>      0.901, 0.953, 0.902, 0.782, 0.938, 0.884, 0.879, 0.932, 0.947,
>      0.965, 0.828, 0.923, 0.892, 0.884, 0.897, 0.912, 0.988, 0.901,
>      0.855, 0.999, 0.846, 0.845, 0.798, 0.749, 0.753, 0.762, 0.646,
>      0.729, 0.544, 0.265, 0.449, 0.334, 0.36, 0.325, 0.337, 0.249,
>      0.114, 0.149, 0.173, 0.175, 0.184, 0.219, 0.106, 0.148),
>      n = c(0.653, 0.625, 0.641, 0.63, 0.656, 0.619, 0.628, 0.634,
>      0.63, 0.604, 0.598, 0.617, 0.632, 0.635, 0.637, 0.646, 0.619,
>      0.613, 0.63, 0.615, 0.604, 0.639, 0.598, 0.593, 0.583, 0.606,
>      0.594, 0.653, 0.63, 0.577, 0.624, 0.626, 0.676, 0.641, 0.629,
>      0.579, 0.603, 0.607, 0.66, 0.614, 0.618, 0.574, 0.552, 0.62,
>      0.599)), row.names = c(19L, 22L, 18L, 3L, 45L, 20L, 14L,
> 43L, 40L, 44L, 37L, 12L, 42L, 41L, 39L, 38L, 33L, 8L, 36L, 16L,
> 32L, 31L, 5L, 34L, 35L, 9L, 13L, 30L, 29L, 4L, 24L, 27L, 28L,
> 23L, 25L, 21L, 26L, 6L, 15L, 2L, 1L, 7L, 11L, 10L, 17L), class = "data.frame")


Here's my attempt:


I used the terra library.

First I visually checked the distribution of the points to show that you 
should use interpolation to convert the points to a raster.

Then, as an example I used the terra::interpolate function to get a 
raster interpolation using the simple IDW from gstat. This **might not** 
be the correct interpolation method. That is something you will have to 
determine.


Note: I changed your X and Y columns to lowercase to stay in line with 
the examples in gstat


library(terra)

# Points data.frame
Tuto <- structure(list(x = c(-114.028, -114.011, -114.442, -113.937,
-114.187, -114.083, -113.949, -114.15, -114.068, -114.203, -113.958,
-114.248, -114.18, -114.14, -114.071, -114.042, -114.187, -114.03,
-113.97, -113.824, -114.084, -114.152, -114.468, -113.935, -113.994,
-114.048, -114.188, -114.129, -114.071, -113.934, -114.001, -114.075,
-114.121, -113.958, -114.039, -113.963, -114.062, -114.183, -114.118,
-114.119, -113.954, -114.051, -113.988, -114.194, -114.025),
 ??? y = c(51.431, 51.279, 51.167, 51.165, 51.155, 51.14, 51.126,
 ??? 51.126, 51.116, 51.115, 51.092, 51.091, 51.084, 51.082, 51.076,
 ??? 51.069, 51.062, 51.052, 51.051, 51.048, 51.044, 51.039, 51.037,
 ??? 51.034, 51.03, 51.029, 51.021, 51.006, 51.005, 50.99, 50.983,
 ??? 50.966, 50.958, 50.948, 50.929, 50.916, 50.911, 50.908, 50.908,
 ??? 50.907, 50.877, 50.877, 50.86, 50.854, 50.826), a = c(0.838,
 ??? 0.901, 0.953, 0.902, 0.782, 0.938, 0.884, 0.879, 0.932, 0.947,
 ??? 0.965, 0.828, 0.923, 0.892, 0.884, 0.897, 0.912, 0.988, 0.901,
 ??? 0.855, 0.999, 0.846, 0.845, 0.798, 0.749, 0.753, 0.762, 0.646,
 ??? 0.729, 0.544, 0.265, 0.449, 0.334, 0.36, 0.325, 0.337, 0.249,
 ??? 0.114, 0.149, 0.173, 0.175, 0.184, 0.219, 0.106, 0.148),
 ??? n = c(0.653, 0.625, 0.641, 0.63, 0.656, 0.619, 0.628, 0.634,
 ??? 0.63, 0.604, 0.598, 0.617, 0.632, 0.635, 0.637, 0.646, 0.619,
 ??? 0.613, 0.63, 0.615, 0.604, 0.639, 0.598, 0.593, 0.583, 0.606,
 ??? 0.594, 0.653, 0.63, 0.577, 0.624, 0.626, 0.676, 0.641, 0.629,
 ??? 0.579, 0.603, 0.607, 0.66, 0.614, 0.618, 0.574, 0.552, 0.62,
 ??? 0.599)), row.names = c(19L, 22L, 18L, 3L, 45L, 20L, 14L,
43L, 40L, 44L, 37L, 12L, 42L, 41L, 39L, 38L, 33L, 8L, 36L, 16L,
32L, 31L, 5L, 34L, 35L, 9L, 13L, 30L, 29L, 4L, 24L, 27L, 28L,
23L, 25L, 21L, 26L, 6L, 15L, 2L, 1L, 7L, 11L, 10L, 17L), class = 
"data.frame")

Tuto_pts <- vect(Tuto, geom=c("x", "y"), crs="EPSG:4326")
plot(Tuto_pts)
# Clearly not evenly distributed, interpolation needed

# Prepare target raster, with given extent and resolution of 0.01 degree
Tuto_ext <- ext(-114.5, -113.7, 50.800, 51.600)
res = 0.01
Tuto_rast <- rast(crs = "EPSG:4326", extent=Tuto_ext, resolution=res, 
vals=0)

# IDW model from gstat package

library(gstat)
model_idw_a <- gstat(id = "a", formula = a~1, locations=~x+y, data=Tuto,
 ?????????????????? nmax=7, set=list(idp = .5))
Tuto_a <- interpolate(Tuto_rast, model_idw_a, debug.level=0, index=1)

model_idw_n <- gstat(id = "n", formula = n~1, locations=~x+y, data=Tuto,
 ?????????????????? nmax=7, set=list(idp = .5))
Tuto_n <- interpolate(Tuto_rast, model_idw_n, debug.level=0, index=1)


# Merge two interpolations into one multiband raster
Tuto_multiband = c(Tuto_a, Tuto_n)
plot(Tuto_multiband)


HTH,

Micha

> In the given data,
>
> X-> Latitude
>
> Y-> Longitude
>
> a-> Factor 1
>
> n-> Factor 2
>
> I want to draw a raster map of these values within the following limits  (xmn=-114.5, xmx=-113.7, ymn=50.800, ymx=51.600). I have tried through "raster" library but failed as I wasn't able to properly generate the data.
> I will be thankful if I can get any kind of help. Thank-you very much in advance.
>
> Eliza
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From dh@rm@ @end|ng |rom metr|cuk@com  Tue Mar  8 11:25:19 2022
From: dh@rm@ @end|ng |rom metr|cuk@com (Shrinivas Dharma)
Date: Tue, 8 Mar 2022 15:55:19 +0530
Subject: [R] Hello
Message-ID: <27311b37-1803-2a4d-b6db-8d34adcd13be@metricuk.com>

Hello

I am not sure if this is the right place to ask the question of my type.

Nonetheless, being desparate , let me ask

I am wirking on a social network analysis project with R igraph software.

My graph data has multiple edges and multiple self loops

Going by the instructions I used the simplify function to make it simple 
graph

code chunk as follows

 >simplify(r1,remove.multiple = T,remove.loops = T,
 ? edge.attr.comb = igraph_opt("edge.attr.comb")
)
 >plot.igraph(r1)

still I am getting loops and multiple edges. I am using the latest 
igraph edition

Please tell me how to go about it

Regards

SHRINIVAS


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Mar  8 11:54:49 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 8 Mar 2022 13:54:49 +0300
Subject: [R] Hello
In-Reply-To: <27311b37-1803-2a4d-b6db-8d34adcd13be@metricuk.com>
References: <27311b37-1803-2a4d-b6db-8d34adcd13be@metricuk.com>
Message-ID: <20220308135449.195eb1db@Tarkus>

On Tue, 8 Mar 2022 15:55:19 +0530
Shrinivas Dharma <dharma at metricuk.com> wrote:

> I am not sure if this is the right place to ask the question of my
> type.

> I am wirking on a social network analysis project with R igraph
> software.
> 
> My graph data has multiple edges and multiple self loops

Have you tried the igraph forum? It's probably a better fit because
it's more likely to have people with igraph experience:
https://igraph.discourse.group/c/usage/11

-- 
Best regards,
Ivan


From btupper @end|ng |rom b|ge|ow@org  Tue Mar  8 13:15:12 2022
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Tue, 8 Mar 2022 07:15:12 -0500
Subject: [R] Hello
In-Reply-To: <20220308135449.195eb1db@Tarkus>
References: <27311b37-1803-2a4d-b6db-8d34adcd13be@metricuk.com>
 <20220308135449.195eb1db@Tarkus>
Message-ID: <CALrbzg0fSVirnPDTv6x2HVNz7DG1qEdSVXqw3Kf+mY_hJQ01GA@mail.gmail.com>

Hello,

I agree with Ivan's suggestion, but also the few statements you show
perplex me.  According to the igraph docs
(https://igraph.org/r/doc/simplify.html) simplify() returns a "A new
graph object with the edges deleted." So wouldn't you want something
like the following?

r2 <- simplify(r1, remove.multiple = TRUE, remove.loops = TRUE,
   edge.attr.comb = igraph_opt("edge.attr.comb"))
plot.igraph(r2)

Ben


On Tue, Mar 8, 2022 at 5:55 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Tue, 8 Mar 2022 15:55:19 +0530
> Shrinivas Dharma <dharma at metricuk.com> wrote:
>
> > I am not sure if this is the right place to ask the question of my
> > type.
>
> > I am wirking on a social network analysis project with R igraph
> > software.
> >
> > My graph data has multiple edges and multiple self loops
>
> Have you tried the igraph forum? It's probably a better fit because
> it's more likely to have people with igraph experience:
> https://igraph.discourse.group/c/usage/11
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper (he/him)
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From bgunter@4567 @end|ng |rom gm@||@com  Tue Mar  8 15:54:21 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 8 Mar 2022 06:54:21 -0800
Subject: [R] Raster map in R
In-Reply-To: <61d3774f-e00d-3bfa-0fbb-6ff7ed6cadb7@gmail.com>
References: <AS8P194MB0999B8B3D2F65B190C82DA569A099@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <61d3774f-e00d-3bfa-0fbb-6ff7ed6cadb7@gmail.com>
Message-ID: <CAGxFJbR3ti1M2EoNwaf635R2peTLSxsNTcnAby+N3J11u-XRnw@mail.gmail.com>

If Micha's reply doesn't satisfy, the r-sig-geo  list would be a
better place to post this.

https://stat.ethz.ch/mailman/listinfo/r-sig-geo


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Mar 8, 2022 at 1:13 AM Micha Silver <tsvibar at gmail.com> wrote:
>
>
> On 08/03/2022 08:21, Eliza Botto wrote:
> > deaR expeRts,
> >
> > I have the following data
> >
> >> dput(Tuto)
> > structure(list(X = c(-114.028, -114.011, -114.442, -113.937,
> > -114.187, -114.083, -113.949, -114.15, -114.068, -114.203, -113.958,
> > -114.248, -114.18, -114.14, -114.071, -114.042, -114.187, -114.03,
> > -113.97, -113.824, -114.084, -114.152, -114.468, -113.935, -113.994,
> > -114.048, -114.188, -114.129, -114.071, -113.934, -114.001, -114.075,
> > -114.121, -113.958, -114.039, -113.963, -114.062, -114.183, -114.118,
> > -114.119, -113.954, -114.051, -113.988, -114.194, -114.025),
> >      Y = c(51.431, 51.279, 51.167, 51.165, 51.155, 51.14, 51.126,
> >      51.126, 51.116, 51.115, 51.092, 51.091, 51.084, 51.082, 51.076,
> >      51.069, 51.062, 51.052, 51.051, 51.048, 51.044, 51.039, 51.037,
> >      51.034, 51.03, 51.029, 51.021, 51.006, 51.005, 50.99, 50.983,
> >      50.966, 50.958, 50.948, 50.929, 50.916, 50.911, 50.908, 50.908,
> >      50.907, 50.877, 50.877, 50.86, 50.854, 50.826), a = c(0.838,
> >      0.901, 0.953, 0.902, 0.782, 0.938, 0.884, 0.879, 0.932, 0.947,
> >      0.965, 0.828, 0.923, 0.892, 0.884, 0.897, 0.912, 0.988, 0.901,
> >      0.855, 0.999, 0.846, 0.845, 0.798, 0.749, 0.753, 0.762, 0.646,
> >      0.729, 0.544, 0.265, 0.449, 0.334, 0.36, 0.325, 0.337, 0.249,
> >      0.114, 0.149, 0.173, 0.175, 0.184, 0.219, 0.106, 0.148),
> >      n = c(0.653, 0.625, 0.641, 0.63, 0.656, 0.619, 0.628, 0.634,
> >      0.63, 0.604, 0.598, 0.617, 0.632, 0.635, 0.637, 0.646, 0.619,
> >      0.613, 0.63, 0.615, 0.604, 0.639, 0.598, 0.593, 0.583, 0.606,
> >      0.594, 0.653, 0.63, 0.577, 0.624, 0.626, 0.676, 0.641, 0.629,
> >      0.579, 0.603, 0.607, 0.66, 0.614, 0.618, 0.574, 0.552, 0.62,
> >      0.599)), row.names = c(19L, 22L, 18L, 3L, 45L, 20L, 14L,
> > 43L, 40L, 44L, 37L, 12L, 42L, 41L, 39L, 38L, 33L, 8L, 36L, 16L,
> > 32L, 31L, 5L, 34L, 35L, 9L, 13L, 30L, 29L, 4L, 24L, 27L, 28L,
> > 23L, 25L, 21L, 26L, 6L, 15L, 2L, 1L, 7L, 11L, 10L, 17L), class = "data.frame")
>
>
> Here's my attempt:
>
>
> I used the terra library.
>
> First I visually checked the distribution of the points to show that you
> should use interpolation to convert the points to a raster.
>
> Then, as an example I used the terra::interpolate function to get a
> raster interpolation using the simple IDW from gstat. This **might not**
> be the correct interpolation method. That is something you will have to
> determine.
>
>
> Note: I changed your X and Y columns to lowercase to stay in line with
> the examples in gstat
>
>
> library(terra)
>
> # Points data.frame
> Tuto <- structure(list(x = c(-114.028, -114.011, -114.442, -113.937,
> -114.187, -114.083, -113.949, -114.15, -114.068, -114.203, -113.958,
> -114.248, -114.18, -114.14, -114.071, -114.042, -114.187, -114.03,
> -113.97, -113.824, -114.084, -114.152, -114.468, -113.935, -113.994,
> -114.048, -114.188, -114.129, -114.071, -113.934, -114.001, -114.075,
> -114.121, -113.958, -114.039, -113.963, -114.062, -114.183, -114.118,
> -114.119, -113.954, -114.051, -113.988, -114.194, -114.025),
>      y = c(51.431, 51.279, 51.167, 51.165, 51.155, 51.14, 51.126,
>      51.126, 51.116, 51.115, 51.092, 51.091, 51.084, 51.082, 51.076,
>      51.069, 51.062, 51.052, 51.051, 51.048, 51.044, 51.039, 51.037,
>      51.034, 51.03, 51.029, 51.021, 51.006, 51.005, 50.99, 50.983,
>      50.966, 50.958, 50.948, 50.929, 50.916, 50.911, 50.908, 50.908,
>      50.907, 50.877, 50.877, 50.86, 50.854, 50.826), a = c(0.838,
>      0.901, 0.953, 0.902, 0.782, 0.938, 0.884, 0.879, 0.932, 0.947,
>      0.965, 0.828, 0.923, 0.892, 0.884, 0.897, 0.912, 0.988, 0.901,
>      0.855, 0.999, 0.846, 0.845, 0.798, 0.749, 0.753, 0.762, 0.646,
>      0.729, 0.544, 0.265, 0.449, 0.334, 0.36, 0.325, 0.337, 0.249,
>      0.114, 0.149, 0.173, 0.175, 0.184, 0.219, 0.106, 0.148),
>      n = c(0.653, 0.625, 0.641, 0.63, 0.656, 0.619, 0.628, 0.634,
>      0.63, 0.604, 0.598, 0.617, 0.632, 0.635, 0.637, 0.646, 0.619,
>      0.613, 0.63, 0.615, 0.604, 0.639, 0.598, 0.593, 0.583, 0.606,
>      0.594, 0.653, 0.63, 0.577, 0.624, 0.626, 0.676, 0.641, 0.629,
>      0.579, 0.603, 0.607, 0.66, 0.614, 0.618, 0.574, 0.552, 0.62,
>      0.599)), row.names = c(19L, 22L, 18L, 3L, 45L, 20L, 14L,
> 43L, 40L, 44L, 37L, 12L, 42L, 41L, 39L, 38L, 33L, 8L, 36L, 16L,
> 32L, 31L, 5L, 34L, 35L, 9L, 13L, 30L, 29L, 4L, 24L, 27L, 28L,
> 23L, 25L, 21L, 26L, 6L, 15L, 2L, 1L, 7L, 11L, 10L, 17L), class =
> "data.frame")
>
> Tuto_pts <- vect(Tuto, geom=c("x", "y"), crs="EPSG:4326")
> plot(Tuto_pts)
> # Clearly not evenly distributed, interpolation needed
>
> # Prepare target raster, with given extent and resolution of 0.01 degree
> Tuto_ext <- ext(-114.5, -113.7, 50.800, 51.600)
> res = 0.01
> Tuto_rast <- rast(crs = "EPSG:4326", extent=Tuto_ext, resolution=res,
> vals=0)
>
> # IDW model from gstat package
>
> library(gstat)
> model_idw_a <- gstat(id = "a", formula = a~1, locations=~x+y, data=Tuto,
>                     nmax=7, set=list(idp = .5))
> Tuto_a <- interpolate(Tuto_rast, model_idw_a, debug.level=0, index=1)
>
> model_idw_n <- gstat(id = "n", formula = n~1, locations=~x+y, data=Tuto,
>                     nmax=7, set=list(idp = .5))
> Tuto_n <- interpolate(Tuto_rast, model_idw_n, debug.level=0, index=1)
>
>
> # Merge two interpolations into one multiband raster
> Tuto_multiband = c(Tuto_a, Tuto_n)
> plot(Tuto_multiband)
>
>
> HTH,
>
> Micha
>
> > In the given data,
> >
> > X-> Latitude
> >
> > Y-> Longitude
> >
> > a-> Factor 1
> >
> > n-> Factor 2
> >
> > I want to draw a raster map of these values within the following limits  (xmn=-114.5, xmx=-113.7, ymn=50.800, ymx=51.600). I have tried through "raster" library but failed as I wasn't able to properly generate the data.
> > I will be thankful if I can get any kind of help. Thank-you very much in advance.
> >
> > Eliza
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Wed Mar  9 13:57:36 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 9 Mar 2022 13:57:36 +0100
Subject: [R] placeholder for native pipes
Message-ID: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>

Dear useRs,

When the implementation of the native pipe was announced (e.g. 
https://www.r-bloggers.com/2021/05/the-new-r-pipe/), there was no 
placeholder similar to the dot in magrittr.

Has it changed? Is there now a placeholder? There is no mention of it in 
the help page for "|>" so I guess not, but maybe someone on the list 
knows more about future developments?

Thank you!
Ivan

-- 

Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Mar  9 14:14:20 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 9 Mar 2022 16:14:20 +0300
Subject: [R] placeholder for native pipes
In-Reply-To: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
References: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
Message-ID: <20220309161420.4042e7d0@arachnoid>

On Wed, 9 Mar 2022 13:57:36 +0100
Ivan Calandra <ivan.calandra at rgzm.de> wrote:

> Has it changed? Is there now a placeholder? There is no mention of it
> in the help page for "|>" so I guess not, but maybe someone on the
> list knows more about future developments?

In an interesting coincidence, support for use of _ as a placeholder
(once per call, in named arguments) in native R pipe has been committed
to R-devel yesterday:
https://github.com/r-devel/r-svn/commit/7cce339c9fc2f61b228d2ea2a022a0cf60d86155

-- 
Best regards,
Ivan


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Wed Mar  9 14:16:47 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 9 Mar 2022 14:16:47 +0100
Subject: [R] placeholder for native pipes
In-Reply-To: <20220309161420.4042e7d0@arachnoid>
References: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
 <20220309161420.4042e7d0@arachnoid>
Message-ID: <6fde8e82-278f-4426-d2b7-053c66bedb81@rgzm.de>

Thank you Ivan for the info. That's exciting!
Do you also know for which R release it is planned?

Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 09/03/2022 14:14, Ivan Krylov wrote:
> On Wed, 9 Mar 2022 13:57:36 +0100
> Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>
>> Has it changed? Is there now a placeholder? There is no mention of it
>> in the help page for "|>" so I guess not, but maybe someone on the
>> list knows more about future developments?
> In an interesting coincidence, support for use of _ as a placeholder
> (once per call, in named arguments) in native R pipe has been committed
> to R-devel yesterday:
> https://github.com/r-devel/r-svn/commit/7cce339c9fc2f61b228d2ea2a022a0cf60d86155
>


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Mar  9 14:42:18 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 9 Mar 2022 16:42:18 +0300
Subject: [R] placeholder for native pipes
In-Reply-To: <6fde8e82-278f-4426-d2b7-053c66bedb81@rgzm.de>
References: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
 <20220309161420.4042e7d0@arachnoid>
 <6fde8e82-278f-4426-d2b7-053c66bedb81@rgzm.de>
Message-ID: <20220309164218.09e49750@arachnoid>

On Wed, 9 Mar 2022 14:16:47 +0100
Ivan Calandra <ivan.calandra at rgzm.de> wrote:

> Do you also know for which R release it is planned?

Assuming it survives in its present state, I think it'll be released
together with R 4.2.0. Definitely not R-patched (4.1.x) if my
understanding of <https://developer.r-project.org/devel-guidelines.txt>
is correct, but I'm not an R developer.

-- 
Best regards,
Ivan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Mar  9 18:21:26 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 09 Mar 2022 09:21:26 -0800
Subject: [R] placeholder for native pipes
In-Reply-To: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
References: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
Message-ID: <59B09B36-DEFB-4BCF-AC38-E84E0AAAB703@dcn.davis.ca.us>

Not currently, but you can emulate it with the anonymous function shorthand:

(\(.) expression_using_dot ))()

e.g. https://i.reddit.com/r/rstats/comments/nkiavh/is_base_r_pipe_faster_than_dplyr/


On March 9, 2022 4:57:36 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>Dear useRs,
>
>When the implementation of the native pipe was announced (e.g. 
>https://www.r-bloggers.com/2021/05/the-new-r-pipe/), there was no 
>placeholder similar to the dot in magrittr.
>
>Has it changed? Is there now a placeholder? There is no mention of it in 
>the help page for "|>" so I guess not, but maybe someone on the list 
>knows more about future developments?
>
>Thank you!
>Ivan
>

-- 
Sent from my phone. Please excuse my brevity.


From xwu @end|ng |rom em@||@t@mu@edu  Tue Mar  8 03:51:40 2022
From: xwu @end|ng |rom em@||@t@mu@edu (ximing wu)
Date: Mon, 7 Mar 2022 20:51:40 -0600
Subject: [R] [R-pkgs] rlcv: robust likelihood cross validation bandwidth
 selection for kernel density estimation
Message-ID: <be3c1a41-e3ee-52ef-a0fc-b40d4d3c669f@email.tamu.edu>

Dear R users,

I am happy to announce that a new package 'rlcv' is now available on? CRAN.

https://cran.r-project.org/web/packages/rlcv/index.html

Robust likelihood cross validation bandwidth for uni- and multi-variate 
kernel densities. It is robust against fat-tailed distributions and/or 
outliers. Based on "Robust Likelihood Cross-Validation for Kernel 
Density Estimation," Wu (2019) <doi:10.1080/07350015.2018.1424633 
<https://doi.org/10.1080%2F07350015.2018.1424633>>.

Best regards,

Ximing Wu


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From kw@@t@t @end|ng |rom gm@||@com  Wed Mar  9 23:14:08 2022
From: kw@@t@t @end|ng |rom gm@||@com (Kevin Wright)
Date: Wed, 9 Mar 2022 16:14:08 -0600
Subject: [R] linear mixed model using lmer
In-Reply-To: <306704552.453726.1646440917947@mail.yahoo.com>
References: <306704552.453726.1646440917947.ref@mail.yahoo.com>
 <306704552.453726.1646440917947@mail.yahoo.com>
Message-ID: <CAKFxdiRy5-5Ed0RU_ShftJkpYBddkDbAJn8K7Qp8DrKZd1TDug@mail.gmail.com>

I think the best analysis of this data is:

library(lattice)
dotplot(yield ~ batch, daty)
bwplot(yield ~ batch, daty)

There is no detectable difference between batches.

But, if you insist, try removing the overall intercept.

m1 <- lmer(yield~0+(1|batch),daty)
coef(m1)
summary(m1)
VarCorr(m1)



On Fri, Mar 4, 2022 at 6:44 PM array chip via R-help
<r-help at r-project.org> wrote:
>
> Dear all, I have this simple dataset to measure the yeild of a crop collected in 2 batches (attached). when I ran a simple inear mixed model using lmer to estimate within-batch and between-batch variability, the between-batch variability is 0. The run showed that data is singular. Does anyone know why the data is singular and what's the reason for 0 variability? is it because the dataset only has 2 batches?
> > daty<-read.table("datx.txt",sep='\t',header=T,row.names=NULL)
> > library(lme4)> lmer(yield~1+(1|batch),daty)
> boundary (singular) fit: see ?isSingular
> Linear mixed model fit by REML ['lmerMod']
> Formula: yield ~ 1 + (1 | batch)
>    Data: daty
> REML criterion at convergence: 115.6358
> Random effects:
>  Groups   Name        Std.Dev.
>  batch    (Intercept) 0.000
>  Residual             2.789
> Number of obs: 24, groups:  batch, 2
> Fixed Effects:
> (Intercept)
>       5.788
>
> Thanks!
> John______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Kevin Wright


From me||n@@co|nte @end|ng |rom out|ook@|r  Tue Mar  8 21:44:35 2022
From: me||n@@co|nte @end|ng |rom out|ook@|r (=?Windows-1252?Q?M=E9lina_Cointe?=)
Date: Tue, 8 Mar 2022 20:44:35 +0000
Subject: [R] NA's in segmented
Message-ID: <VI1PR06MB5069823FEB2F232B5EF356569F099@VI1PR06MB5069.eurprd06.prod.outlook.com>

Hi,

I?m contacting you because I have some trouble with the slope() function of segmented. When I plot the predicted value everything seems to have worked well. But when I use slope(), the slope for the first segment is a line with 0 and Nas? Also I can get a negative slope whereas on the graph it?s clearly a positive slope?

Here are the lines I?m using :

Mod = lm(as.numeric(data[,"meanMSD25"])~(as.numeric(data[,"Slice"])), weights=1*sqrt(as.numeric(data[,"Detec"])))
  x = (as.numeric(data[,"Slice"]))
  o <- segmented(Mod, seg.Z=~x, psi=NA, control=seg.control(display=FALSE, K=2))

Thanks in advance for your help,

Best regards,

M?lina COINTE



	[[alternative HTML version deleted]]


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Thu Mar 10 08:56:36 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 10 Mar 2022 08:56:36 +0100
Subject: [R] placeholder for native pipes
In-Reply-To: <59B09B36-DEFB-4BCF-AC38-E84E0AAAB703@dcn.davis.ca.us>
References: <49781471-6094-2712-576d-0fc802fbe1cb@rgzm.de>
 <59B09B36-DEFB-4BCF-AC38-E84E0AAAB703@dcn.davis.ca.us>
Message-ID: <63254fa1-f644-6ed7-bbfe-9cf8b1000043@rgzm.de>

Dear Jeff,

Thank you for the hint. I had read about it. While it is quite useful, I 
doubt that any of my colleagues would understand the construct... 
Waiting for the placeholder :)

Best,
Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 09/03/2022 18:21, Jeff Newmiller wrote:
> Not currently, but you can emulate it with the anonymous function shorthand:
>
> (\(.) expression_using_dot ))()
>
> e.g. https://i.reddit.com/r/rstats/comments/nkiavh/is_base_r_pipe_faster_than_dplyr/
>
>
> On March 9, 2022 4:57:36 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> When the implementation of the native pipe was announced (e.g.
>> https://www.r-bloggers.com/2021/05/the-new-r-pipe/), there was no
>> placeholder similar to the dot in magrittr.
>>
>> Has it changed? Is there now a placeholder? There is no mention of it in
>> the help page for "|>" so I guess not, but maybe someone on the list
>> knows more about future developments?
>>
>> Thank you!
>> Ivan
>>


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Mar 10 09:03:05 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 10 Mar 2022 11:03:05 +0300
Subject: [R] NA's in segmented
In-Reply-To: <VI1PR06MB5069823FEB2F232B5EF356569F099@VI1PR06MB5069.eurprd06.prod.outlook.com>
References: <VI1PR06MB5069823FEB2F232B5EF356569F099@VI1PR06MB5069.eurprd06.prod.outlook.com>
Message-ID: <20220310110305.0a017f0f@Tarkus>

Hi M?lina,

If you don't get an answer here, consider running maintainer(segmented)
and contacting the e-mail address shown by the command.

On Tue, 8 Mar 2022 20:44:35 +0000
M?lina Cointe <melina.cointe at outlook.fr> wrote:

> I have some trouble with the slope() function of segmented. When I
> plot the predicted value everything seems to have worked well. But
> when I use slope(), the slope for the first segment is a line with 0
> and Nas_ Also I can get a negative slope whereas on the graph it_s
> clearly a positive slope_

It would help if you show us a small sample of your data. Use dput() to
produce a plain text representation of it. Otherwise it's next to
impossible to reproduce the problems you're having.

> [[alternative HTML version deleted]]

When you post in HTML, the list removes the HTML version for safety
reasons, and all we're left with is the plain text version
automatically prepared by your mailer. This plain text version can be
severely mangled and hard to understand. Please post in plain text:
http://www.R-project.org/posting-guide.html

-- 
Best regards,
Ivan


From pd@me@ @end|ng |rom cb@@dk  Thu Mar 10 10:41:55 2022
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Thu, 10 Mar 2022 09:41:55 +0000
Subject: [R] [Rd] R 4.1.3 is released
Message-ID: <3523D985-CFB4-415A-A07F-A8F1A745ED0A@cbs.dk>

The build system rolled up R-4.1.3.tar.gz (codename "One Push-Up") this morning.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.1.3.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = 320967884b547734d6279dedbc739dd4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = ade6a3d38fe5e6a456929cae2b94d568
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 179217ce1f9cd78ecdb2d43c7f555d8d
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = a767f7809324c73c49eaff47d14bce81
MD5 (NEWS.3) = e55ed2c8a547b827b46e08eb7137ba23
MD5 (R-latest.tar.gz) = 409bc782b1a42c8247712f6446d7d640
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = a79b9b338cab09bd665f6b62ac6f455b
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 895a0ce812ecbe4ae45fc62c8776a077
MD5 (R-4/R-4.1.3.tar.gz) = 409bc782b1a42c8247712f6446d7d640

60a0d150e6fc1f424be76ad7b645d236b56e747692a4679f81ce6536c550e949  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
e84c67931e9b925abb9142d4a6b4ef03b7605948bbf384d7e3d2401823c7f1fe  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
66ccaca407fb45deefca634398e51756a8abd7e993957334e422542064f39533  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ba74618bc3f4c0e336dca13d472402a1863d12ba6f7f91a1782bc469ee986f6d  NEWS.2
1910a2405300b9bc7c76beeb0753a5249cf799afe175ce28f8d782fab723e012  NEWS.3
15ff5b333c61094060b2a52e9c1d8ec55cc42dd029e39ca22abdaa909526fed6  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
8b7d3856100220f4555d4d57140829f2e81c27eccec5b441f5dce616e9ec9061  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
4918cbcf4824121f35c229b69ba9b5a7fbdeaa4a4a70be23fc48e1ffcdd2f42f  VERSION-INFO.dcf
1e74ef089b526538bbb658dc189bc3d34d931839e9933415fb2f267fd57b0b69  VERSION-INFO.dcf~
15ff5b333c61094060b2a52e9c1d8ec55cc42dd029e39ca22abdaa909526fed6  R-4/R-4.1.3.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.1.3:

  NEW FEATURES:

    * The default version of Bioconductor has been changed to 3.14.
      (This is used by setRepositories and the menus in GUIs.)

  UTILITIES:

    * R CMD check --as-cran has a workaround for a bug in versions of
      file up to at least 5.41 which mis-identify DBF files last
      changed in 2022 as executables.

  C-LEVEL FACILITIES:

    * The legacy S-compatibility macros SINGLE_* in R_ext/Constants.h
      (included by R.h) are deprecated and will be removed in R 4.2.0.

  BUG FIXES:

    * Initialization of self-starting nls() models with initialization
      functions following the pre-R-4.1.0 API (without the ...
      argument) works again for now, with a deprecation warning.

    * Fixed quoting of ~autodetect~ in Java setting defaults to avoid
      inadvertent user lookup due to leading ~, reported in PR#18231 by
      Harold Gutch.

    * substr(., start, stop) <- v now treats _negative_ stop values
      correctly.  Reported with a patch in PR#18228 by Brodie Gaslam.

    * Subscripting an array x without dimnames by a
      length(dim(x))-column character matrix gave "random" non-sense,
      now an error; reported in PR#18244 by Mikael Jagan.

    * ...names() now matches names(list(...)) closely, fixing PR#18247.

    * all.equal(*, scale = s) now works as intended when length(s) > 1,
      partly thanks to Michael Chirico's PR#18272.

    * print(x) for long vectors x now also works for named atomic
      vectors or lists and prints the correct number when reaching the
      getOption("max.print") limit; partly thanks to a report and
      proposal by Hugh Parsonage to the R-devel list.

    * all.equal(<selfStart>, *) no longer signals a deprecation
      warning.

    * reformulate(*, response=r) gives a helpful error message now when
      length(r) > 1, thanks to Bill Dunlap's PR#18281.

    * Modifying globalCallingHandlers inside withCallingHandlers() now
      works or fails correctly, thanks to Henrik Bengtsson's PR#18257.

    * hist(<Date>, breaks = "days") and hist(<POSIXt>, breaks = "secs")
      no longer fail for inputs of length 1.

    * qbeta(.001, .9, .009) and similar cases now converge correctly
      thanks to Ben Bolker's report in PR#17746.

    * window(x, start, end) no longer wrongly signals "'start' cannot
      be after 'end'", fixing PR#17527 and PR#18291.

    * data() now checks that its (rarely used) list argument is a
      character vector - a couple of packages passed other types and
      gave incorrect results.

    * which() now checks its arr.ind argument is TRUE rather coercing
      to logical and taking the first element - which gave incorrect
      results in package code.

    * model.weights() and model.offset() more carefully extract their
      model components, thanks to Ben Bolker and Tim Taylor's R-devel
      post.

    * list.files(recursive = TRUE) now shows all broken symlinks
      (previously, some of them may have been omitted, PR#18296).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Mar 10 10:55:04 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 10 Mar 2022 09:55:04 +0000
Subject: [R] NA's in segmented
In-Reply-To: <VI1PR06MB5069823FEB2F232B5EF356569F099@VI1PR06MB5069.eurprd06.prod.outlook.com>
References: <VI1PR06MB5069823FEB2F232B5EF356569F099@VI1PR06MB5069.eurprd06.prod.outlook.com>
Message-ID: <577cb4ea4b334b8ba7f847891eeb7a1d@SRVEXCHCM1301.precheza.cz>

Hi

1. Do not use HTML formated mail, your message is scrambled
2. With your code only you can get result all of us get error

> Mod = lm(as.numeric(data[,"meanMSD25"])~(as.numeric(data[,"Slice"])), weights=1*sqrt(as.numeric(data[,"Detec"])))
Error in data[, "meanMSD25"] : 
  object of type 'closure' is not subsettable
Try to provide reproducible example.

3. with lm it is not necessary to use data[,"meanMSD25"], you should provide your data object to data option in lm call (it is silly to call your data data - fortune("dog") applies here)
4. why do you use as.numeric(data[,"meanMSD25"]), shouldn't the column be numeric itself?

So my  wild guess is that you read the data into R wrong way and instead of numeric they are character, which could be one source of your problem.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of M?lina Cointe
> Sent: Tuesday, March 8, 2022 9:45 PM
> To: r-help at r-project.org
> Subject: Re: [R] NA's in segmented
> 
> Hi,
> 
> I?m contacting you because I have some trouble with the slope() function of
> segmented. When I plot the predicted value everything seems to have worked
> well. But when I use slope(), the slope for the first segment is a line with 0
> and Nas? Also I can get a negative slope whereas on the graph it?s clearly a
> positive slope?
> 
> Here are the lines I?m using :
> 
> Mod = lm(as.numeric(data[,"meanMSD25"])~(as.numeric(data[,"Slice"])),
> weights=1*sqrt(as.numeric(data[,"Detec"])))
>   x = (as.numeric(data[,"Slice"]))
>   o <- segmented(Mod, seg.Z=~x, psi=NA, control=seg.control(display=FALSE,
> K=2))
> 
> Thanks in advance for your help,
> 
> Best regards,
> 
> M?lina COINTE
> 
> 
> 
> 	[[alternative HTML version deleted]]


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Thu Mar 10 16:50:23 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 10 Mar 2022 16:50:23 +0100
Subject: [R] conditional filling of data.frame - improve code
Message-ID: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>

Dear useRs,

I would like to improve my ugly (though working) code, but I think I 
need a completely different approach and I just can't think out of my box!

I have some external information about which sample(s) belong to which 
experiment. I need to get that manually into R (either typing directly 
in a script or read a CSV file, but that makes no difference):
exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1", 
"sample2-2" , "sample2-3"))

Then I have my data, only with the sample IDs:
mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", 
"sample1-1", "sample1-1", "sample2-1"))

Now I want to add a column to mydata with the experiment ID. The best I 
could find is that:
for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]], 
"experiment"] <- i

In this example, the experiment ID could be extracted from the sample 
IDs, but this is not the case with my real data so it really is a matter 
of matching. Of course I also have other columns with my real data.

I'm pretty sure the last line (with the loop) can be improved in terms 
of readability (speed is not an issue here). I have close to no 
constraints on 'exp' (here I chose a list, but anything could do), the 
only thing that cannot change is the format of 'mydata'.

Thank you in advance!
Ivan

-- 

Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From @kw@|mmo @end|ng |rom gm@||@com  Thu Mar 10 17:15:17 2022
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 10 Mar 2022 11:15:17 -0500
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
Message-ID: <CAPcHnpThEZZKtdM1A3k7WbN4axFdNPHM0Z3-pS3Eb_NM-ejduA@mail.gmail.com>

I think what you're looking for is match.
It returns the indexes of the output where the inputs can be matched, and
has a nomatch argument incase no match is found, usually people would use
NA or 0 for nomatch.

On Thu, Mar 10, 2022, 10:51 Ivan Calandra <ivan.calandra at rgzm.de> wrote:

> Dear useRs,
>
> I would like to improve my ugly (though working) code, but I think I
> need a completely different approach and I just can't think out of my box!
>
> I have some external information about which sample(s) belong to which
> experiment. I need to get that manually into R (either typing directly
> in a script or read a CSV file, but that makes no difference):
> exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1",
> "sample2-2" , "sample2-3"))
>
> Then I have my data, only with the sample IDs:
> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1",
> "sample1-1", "sample1-1", "sample2-1"))
>
> Now I want to add a column to mydata with the experiment ID. The best I
> could find is that:
> for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]],
> "experiment"] <- i
>
> In this example, the experiment ID could be extracted from the sample
> IDs, but this is not the case with my real data so it really is a matter
> of matching. Of course I also have other columns with my real data.
>
> I'm pretty sure the last line (with the loop) can be improved in terms
> of readability (speed is not an issue here). I have close to no
> constraints on 'exp' (here I chose a list, but anything could do), the
> only thing that cannot change is the format of 'mydata'.
>
> Thank you in advance!
> Ivan
>
> --
>
> Dr. Ivan Calandra
> Imaging lab
> RGZM - MONREPOS Archaeological Research Centre
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Mar 10 17:24:59 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 10 Mar 2022 08:24:59 -0800
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
Message-ID: <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>

Use merge.

expts <- read.csv( text =
"expt,sample
ex1,sample1-1
ex1,sample1-2
ex2,sample2-1
ex2,sample2-2
ex2,sample2-3
", header=TRUE, as.is=TRUE )

mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", "sample1-1", "sample1-1", "sample2-1"))

merge( mydata, expts, by="sample", all.x=TRUE )


On March 10, 2022 7:50:23 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>Dear useRs,
>
>I would like to improve my ugly (though working) code, but I think I 
>need a completely different approach and I just can't think out of my box!
>
>I have some external information about which sample(s) belong to which 
>experiment. I need to get that manually into R (either typing directly 
>in a script or read a CSV file, but that makes no difference):
>exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1", 
>"sample2-2" , "sample2-3"))
>
>Then I have my data, only with the sample IDs:
>mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", 
>"sample1-1", "sample1-1", "sample2-1"))
>
>Now I want to add a column to mydata with the experiment ID. The best I 
>could find is that:
>for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]], 
>"experiment"] <- i
>
>In this example, the experiment ID could be extracted from the sample 
>IDs, but this is not the case with my real data so it really is a matter 
>of matching. Of course I also have other columns with my real data.
>
>I'm pretty sure the last line (with the loop) can be improved in terms 
>of readability (speed is not an issue here). I have close to no 
>constraints on 'exp' (here I chose a list, but anything could do), the 
>only thing that cannot change is the format of 'mydata'.
>
>Thank you in advance!
>Ivan
>

-- 
Sent from my phone. Please excuse my brevity.


From tebert @end|ng |rom u||@edu  Thu Mar 10 18:58:35 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 10 Mar 2022 17:58:35 +0000
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
 <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
Message-ID: <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>

You could try some of the "join" commands from dplyr.
https://dplyr.tidyverse.org/reference/mutate-joins.html
https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti


Regards,
Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
Sent: Thursday, March 10, 2022 11:25 AM
To: r-help at r-project.org; Ivan Calandra <ivan.calandra at rgzm.de>; R-help <r-help at r-project.org>
Subject: Re: [R] conditional filling of data.frame - improve code

[External Email]

Use merge.

expts <- read.csv( text =
"expt,sample
ex1,sample1-1
ex1,sample1-2
ex2,sample2-1
ex2,sample2-2
ex2,sample2-3
", header=TRUE, as.is=TRUE )

mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", "sample1-1", "sample1-1", "sample2-1"))

merge( mydata, expts, by="sample", all.x=TRUE )


On March 10, 2022 7:50:23 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>Dear useRs,
>
>I would like to improve my ugly (though working) code, but I think I 
>need a completely different approach and I just can't think out of my box!
>
>I have some external information about which sample(s) belong to which 
>experiment. I need to get that manually into R (either typing directly 
>in a script or read a CSV file, but that makes no difference):
>exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1", 
>"sample2-2" , "sample2-3"))
>
>Then I have my data, only with the sample IDs:
>mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", 
>"sample1-1", "sample1-1", "sample2-1"))
>
>Now I want to add a column to mydata with the experiment ID. The best I 
>could find is that:
>for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]], 
>"experiment"] <- i
>
>In this example, the experiment ID could be extracted from the sample 
>IDs, but this is not the case with my real data so it really is a 
>matter of matching. Of course I also have other columns with my real data.
>
>I'm pretty sure the last line (with the loop) can be improved in terms 
>of readability (speed is not an issue here). I have close to no 
>constraints on 'exp' (here I chose a list, but anything could do), the 
>only thing that cannot change is the format of 'mydata'.
>
>Thank you in advance!
>Ivan
>

--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=4HazMU4Mqs2oOcAkBrZd0VGrHX_lw6J1XozQNQ9RsHk&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=LdQqnVBkEAmRk7baBZLPs2svUpN6DIYaznrka_X8maI&e=
and provide commented, minimal, self-contained, reproducible code.


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Fri Mar 11 08:24:27 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Fri, 11 Mar 2022 08:24:27 +0100
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
 <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
 <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <001a0ec0-866a-30b1-570c-b040878460a5@rgzm.de>

Thank you Jeff and Tim for your ideas. Indeed merge/join is probably the 
nicest way. Still, the code becomes much longer because I need more 
formatting of the input and output objects than with my ugly for loop :)

Cheers,
Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

Le 10/03/2022 ? 18:58, Ebert,Timothy Aaron a ?crit?:
> You could try some of the "join" commands from dplyr.
> https://dplyr.tidyverse.org/reference/mutate-joins.html
> https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti
>
>
> Regards,
> Tim
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
> Sent: Thursday, March 10, 2022 11:25 AM
> To: r-help at r-project.org; Ivan Calandra <ivan.calandra at rgzm.de>; R-help <r-help at r-project.org>
> Subject: Re: [R] conditional filling of data.frame - improve code
>
> [External Email]
>
> Use merge.
>
> expts <- read.csv( text =
> "expt,sample
> ex1,sample1-1
> ex1,sample1-2
> ex2,sample2-1
> ex2,sample2-2
> ex2,sample2-3
> ", header=TRUE, as.is=TRUE )
>
> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", "sample1-1", "sample1-1", "sample2-1"))
>
> merge( mydata, expts, by="sample", all.x=TRUE )
>
>
> On March 10, 2022 7:50:23 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> I would like to improve my ugly (though working) code, but I think I
>> need a completely different approach and I just can't think out of my box!
>>
>> I have some external information about which sample(s) belong to which
>> experiment. I need to get that manually into R (either typing directly
>> in a script or read a CSV file, but that makes no difference):
>> exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1",
>> "sample2-2" , "sample2-3"))
>>
>> Then I have my data, only with the sample IDs:
>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1",
>> "sample1-1", "sample1-1", "sample2-1"))
>>
>> Now I want to add a column to mydata with the experiment ID. The best I
>> could find is that:
>> for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]],
>> "experiment"] <- i
>>
>> In this example, the experiment ID could be extracted from the sample
>> IDs, but this is not the case with my real data so it really is a
>> matter of matching. Of course I also have other columns with my real data.
>>
>> I'm pretty sure the last line (with the loop) can be improved in terms
>> of readability (speed is not an issue here). I have close to no
>> constraints on 'exp' (here I chose a list, but anything could do), the
>> only thing that cannot change is the format of 'mydata'.
>>
>> Thank you in advance!
>> Ivan
>>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=4HazMU4Mqs2oOcAkBrZd0VGrHX_lw6J1XozQNQ9RsHk&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=LdQqnVBkEAmRk7baBZLPs2svUpN6DIYaznrka_X8maI&e=
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Mar 11 08:47:15 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 10 Mar 2022 23:47:15 -0800
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <001a0ec0-866a-30b1-570c-b040878460a5@rgzm.de>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
 <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
 <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <001a0ec0-866a-30b1-570c-b040878460a5@rgzm.de>
Message-ID: <2DAE6E29-026D-42EF-AF5D-C2B79AF483A8@dcn.davis.ca.us>

What a strange objection. You wouldn't keep the inline definition of expts in working code... that would be in a reference data file, and the merge is one line.

On March 10, 2022 11:24:27 PM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>Thank you Jeff and Tim for your ideas. Indeed merge/join is probably the 
>nicest way. Still, the code becomes much longer because I need more 
>formatting of the input and output objects than with my ugly for loop :)
>
>Cheers,
>Ivan
>
>--
>Dr. Ivan Calandra
>Imaging lab
>RGZM - MONREPOS Archaeological Research Centre
>Schloss Monrepos
>56567 Neuwied, Germany
>+49 (0) 2631 9772-243
>https://www.researchgate.net/profile/Ivan_Calandra
>
>Le 10/03/2022 ? 18:58, Ebert,Timothy Aaron a ?crit?:
>> You could try some of the "join" commands from dplyr.
>> https://dplyr.tidyverse.org/reference/mutate-joins.html
>> https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti
>>
>>
>> Regards,
>> Tim
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>> Sent: Thursday, March 10, 2022 11:25 AM
>> To: r-help at r-project.org; Ivan Calandra <ivan.calandra at rgzm.de>; R-help <r-help at r-project.org>
>> Subject: Re: [R] conditional filling of data.frame - improve code
>>
>> [External Email]
>>
>> Use merge.
>>
>> expts <- read.csv( text =
>> "expt,sample
>> ex1,sample1-1
>> ex1,sample1-2
>> ex2,sample2-1
>> ex2,sample2-2
>> ex2,sample2-3
>> ", header=TRUE, as.is=TRUE )
>>
>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", "sample1-1", "sample1-1", "sample2-1"))
>>
>> merge( mydata, expts, by="sample", all.x=TRUE )
>>
>>
>> On March 10, 2022 7:50:23 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>>> Dear useRs,
>>>
>>> I would like to improve my ugly (though working) code, but I think I
>>> need a completely different approach and I just can't think out of my box!
>>>
>>> I have some external information about which sample(s) belong to which
>>> experiment. I need to get that manually into R (either typing directly
>>> in a script or read a CSV file, but that makes no difference):
>>> exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1",
>>> "sample2-2" , "sample2-3"))
>>>
>>> Then I have my data, only with the sample IDs:
>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1",
>>> "sample1-1", "sample1-1", "sample2-1"))
>>>
>>> Now I want to add a column to mydata with the experiment ID. The best I
>>> could find is that:
>>> for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]],
>>> "experiment"] <- i
>>>
>>> In this example, the experiment ID could be extracted from the sample
>>> IDs, but this is not the case with my real data so it really is a
>>> matter of matching. Of course I also have other columns with my real data.
>>>
>>> I'm pretty sure the last line (with the loop) can be improved in terms
>>> of readability (speed is not an issue here). I have close to no
>>> constraints on 'exp' (here I chose a list, but anything could do), the
>>> only thing that cannot change is the format of 'mydata'.
>>>
>>> Thank you in advance!
>>> Ivan
>>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=4HazMU4Mqs2oOcAkBrZd0VGrHX_lw6J1XozQNQ9RsHk&e=
>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=LdQqnVBkEAmRk7baBZLPs2svUpN6DIYaznrka_X8maI&e=
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Fri Mar 11 09:48:51 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Fri, 11 Mar 2022 09:48:51 +0100
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <2DAE6E29-026D-42EF-AF5D-C2B79AF483A8@dcn.davis.ca.us>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
 <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
 <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <001a0ec0-866a-30b1-570c-b040878460a5@rgzm.de>
 <2DAE6E29-026D-42EF-AF5D-C2B79AF483A8@dcn.davis.ca.us>
Message-ID: <e8ce017a-9251-f260-a0af-fdc2c5d8310a@rgzm.de>

In my first trials, I made a typo, which resulted in more columns than 
needed in the output of merge, which is why I needed more formatting. 
But now, it is indeed done all in one line and it is, as I said already, 
nicer anyway!

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

Le 11/03/2022 ? 08:47, Jeff Newmiller a ?crit?:
> What a strange objection. You wouldn't keep the inline definition of expts in working code... that would be in a reference data file, and the merge is one line.
>
> On March 10, 2022 11:24:27 PM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>> Thank you Jeff and Tim for your ideas. Indeed merge/join is probably the
>> nicest way. Still, the code becomes much longer because I need more
>> formatting of the input and output objects than with my ugly for loop :)
>>
>> Cheers,
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> Imaging lab
>> RGZM - MONREPOS Archaeological Research Centre
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> Le 10/03/2022 ? 18:58, Ebert,Timothy Aaron a ?crit?:
>>> You could try some of the "join" commands from dplyr.
>>> https://dplyr.tidyverse.org/reference/mutate-joins.html
>>> https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti
>>>
>>>
>>> Regards,
>>> Tim
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>>> Sent: Thursday, March 10, 2022 11:25 AM
>>> To: r-help at r-project.org; Ivan Calandra <ivan.calandra at rgzm.de>; R-help <r-help at r-project.org>
>>> Subject: Re: [R] conditional filling of data.frame - improve code
>>>
>>> [External Email]
>>>
>>> Use merge.
>>>
>>> expts <- read.csv( text =
>>> "expt,sample
>>> ex1,sample1-1
>>> ex1,sample1-2
>>> ex2,sample2-1
>>> ex2,sample2-2
>>> ex2,sample2-3
>>> ", header=TRUE, as.is=TRUE )
>>>
>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", "sample1-1", "sample1-1", "sample2-1"))
>>>
>>> merge( mydata, expts, by="sample", all.x=TRUE )
>>>
>>>
>>> On March 10, 2022 7:50:23 AM PST, Ivan Calandra <ivan.calandra at rgzm.de> wrote:
>>>> Dear useRs,
>>>>
>>>> I would like to improve my ugly (though working) code, but I think I
>>>> need a completely different approach and I just can't think out of my box!
>>>>
>>>> I have some external information about which sample(s) belong to which
>>>> experiment. I need to get that manually into R (either typing directly
>>>> in a script or read a CSV file, but that makes no difference):
>>>> exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1",
>>>> "sample2-2" , "sample2-3"))
>>>>
>>>> Then I have my data, only with the sample IDs:
>>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1",
>>>> "sample1-1", "sample1-1", "sample2-1"))
>>>>
>>>> Now I want to add a column to mydata with the experiment ID. The best I
>>>> could find is that:
>>>> for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]],
>>>> "experiment"] <- i
>>>>
>>>> In this example, the experiment ID could be extracted from the sample
>>>> IDs, but this is not the case with my real data so it really is a
>>>> matter of matching. Of course I also have other columns with my real data.
>>>>
>>>> I'm pretty sure the last line (with the loop) can be improved in terms
>>>> of readability (speed is not an issue here). I have close to no
>>>> constraints on 'exp' (here I chose a list, but anything could do), the
>>>> only thing that cannot change is the format of 'mydata'.
>>>>
>>>> Thank you in advance!
>>>> Ivan
>>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=4HazMU4Mqs2oOcAkBrZd0VGrHX_lw6J1XozQNQ9RsHk&e=
>>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=LdQqnVBkEAmRk7baBZLPs2svUpN6DIYaznrka_X8maI&e=
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Mar 11 10:14:10 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 11 Mar 2022 09:14:10 +0000
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <e8ce017a-9251-f260-a0af-fdc2c5d8310a@rgzm.de>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
 <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
 <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <001a0ec0-866a-30b1-570c-b040878460a5@rgzm.de>
 <2DAE6E29-026D-42EF-AF5D-C2B79AF483A8@dcn.davis.ca.us>
 <e8ce017a-9251-f260-a0af-fdc2c5d8310a@rgzm.de>
Message-ID: <403e5959-a5af-8464-ce2f-e9a6229a06f3@sapo.pt>

Heello,

I hadn't posted an answer because my mapply is more complicated that the 
original and much more complicated than Jeff's merge but here it is. But 
if there's a problem with the output of merge, maybe the mapply can be 
of use, only the column expressly named is created.
The result is equal to the original.
I have changed the name exp to exp1.

mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", 
"sample1-1", "sample1-1", "sample2-1"))
exp1 <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1", 
"sample2-2" , "sample2-3"))

for(i in names(exp1)) {
   mydata[mydata[["sample"]] %in% exp1[[i]], "experiment"] <- i
}

# must create the new column beforehand
mydata[["experiment2"]] <- NA_character_
mapply(\(value, name, s){
   i <- which(s %in% value)
   mydata[["experiment2"]][i] <<- name
}, exp1, names(exp1), MoreArgs = list(s = mydata$sample))

mydata
#     sample experiment experiment2
#1 sample2-2        ex2         ex2
#2 sample2-3        ex2         ex2
#3 sample1-1        ex1         ex1
#4 sample1-1        ex1         ex1
#5 sample1-1        ex1         ex1
#6 sample2-1        ex2         ex2


Hope this helps,

Rui Barradas

?s 08:48 de 11/03/2022, Ivan Calandra escreveu:
> In my first trials, I made a typo, which resulted in more columns than 
> needed in the output of merge, which is why I needed more formatting. 
> But now, it is indeed done all in one line and it is, as I said already, 
> nicer anyway!
> 
> -- 
> Dr. Ivan Calandra
> Imaging lab
> RGZM - MONREPOS Archaeological Research Centre
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> Le 11/03/2022 ? 08:47, Jeff Newmiller a ?crit?:
>> What a strange objection. You wouldn't keep the inline definition of 
>> expts in working code... that would be in a reference data file, and 
>> the merge is one line.
>>
>> On March 10, 2022 11:24:27 PM PST, Ivan Calandra 
>> <ivan.calandra at rgzm.de> wrote:
>>> Thank you Jeff and Tim for your ideas. Indeed merge/join is probably the
>>> nicest way. Still, the code becomes much longer because I need more
>>> formatting of the input and output objects than with my ugly for loop :)
>>>
>>> Cheers,
>>> Ivan
>>>
>>> -- 
>>> Dr. Ivan Calandra
>>> Imaging lab
>>> RGZM - MONREPOS Archaeological Research Centre
>>> Schloss Monrepos
>>> 56567 Neuwied, Germany
>>> +49 (0) 2631 9772-243
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>
>>> Le 10/03/2022 ? 18:58, Ebert,Timothy Aaron a ?crit?:
>>>> You could try some of the "join" commands from dplyr.
>>>> https://dplyr.tidyverse.org/reference/mutate-joins.html
>>>> https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti 
>>>>
>>>>
>>>>
>>>> Regards,
>>>> Tim
>>>> -----Original Message-----
>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>>>> Sent: Thursday, March 10, 2022 11:25 AM
>>>> To: r-help at r-project.org; Ivan Calandra <ivan.calandra at rgzm.de>; 
>>>> R-help <r-help at r-project.org>
>>>> Subject: Re: [R] conditional filling of data.frame - improve code
>>>>
>>>> [External Email]
>>>>
>>>> Use merge.
>>>>
>>>> expts <- read.csv( text =
>>>> "expt,sample
>>>> ex1,sample1-1
>>>> ex1,sample1-2
>>>> ex2,sample2-1
>>>> ex2,sample2-2
>>>> ex2,sample2-3
>>>> ", header=TRUE, as.is=TRUE )
>>>>
>>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", 
>>>> "sample1-1", "sample1-1", "sample1-1", "sample2-1"))
>>>>
>>>> merge( mydata, expts, by="sample", all.x=TRUE )
>>>>
>>>>
>>>> On March 10, 2022 7:50:23 AM PST, Ivan Calandra 
>>>> <ivan.calandra at rgzm.de> wrote:
>>>>> Dear useRs,
>>>>>
>>>>> I would like to improve my ugly (though working) code, but I think I
>>>>> need a completely different approach and I just can't think out of 
>>>>> my box!
>>>>>
>>>>> I have some external information about which sample(s) belong to which
>>>>> experiment. I need to get that manually into R (either typing directly
>>>>> in a script or read a CSV file, but that makes no difference):
>>>>> exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1",
>>>>> "sample2-2" , "sample2-3"))
>>>>>
>>>>> Then I have my data, only with the sample IDs:
>>>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1",
>>>>> "sample1-1", "sample1-1", "sample2-1"))
>>>>>
>>>>> Now I want to add a column to mydata with the experiment ID. The 
>>>>> best I
>>>>> could find is that:
>>>>> for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]],
>>>>> "experiment"] <- i
>>>>>
>>>>> In this example, the experiment ID could be extracted from the sample
>>>>> IDs, but this is not the case with my real data so it really is a
>>>>> matter of matching. Of course I also have other columns with my 
>>>>> real data.
>>>>>
>>>>> I'm pretty sure the last line (with the loop) can be improved in terms
>>>>> of readability (speed is not an issue here). I have close to no
>>>>> constraints on 'exp' (here I chose a list, but anything could do), the
>>>>> only thing that cannot change is the format of 'mydata'.
>>>>>
>>>>> Thank you in advance!
>>>>> Ivan
>>>>>
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=4HazMU4Mqs2oOcAkBrZd0VGrHX_lw6J1XozQNQ9RsHk&e= 
>>>>
>>>> PLEASE do read the posting guide 
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=LdQqnVBkEAmRk7baBZLPs2svUpN6DIYaznrka_X8maI&e= 
>>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |v@n@c@|@ndr@ @end|ng |rom rgzm@de  Fri Mar 11 10:15:50 2022
From: |v@n@c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Fri, 11 Mar 2022 10:15:50 +0100
Subject: [R] conditional filling of data.frame - improve code
In-Reply-To: <403e5959-a5af-8464-ce2f-e9a6229a06f3@sapo.pt>
References: <fca6451b-326c-27c3-a082-2a8dfe470326@rgzm.de>
 <B1D6ED25-278F-484A-9AF5-EE5453B633EF@dcn.davis.ca.us>
 <BN6PR2201MB1553ED560A090ADD078D485ACF0B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <001a0ec0-866a-30b1-570c-b040878460a5@rgzm.de>
 <2DAE6E29-026D-42EF-AF5D-C2B79AF483A8@dcn.davis.ca.us>
 <e8ce017a-9251-f260-a0af-fdc2c5d8310a@rgzm.de>
 <403e5959-a5af-8464-ce2f-e9a6229a06f3@sapo.pt>
Message-ID: <1a8a18a1-4e20-f684-9621-122c8efff89b@rgzm.de>

Thank you Rui for your input.
I thought about mapply() too, but I'm not confident with it, I usually 
prefer loops (more intuitive to me).

It's good to have the choice :)

Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

Le 11/03/2022 ? 10:14, Rui Barradas a ?crit?:
> Heello,
>
> I hadn't posted an answer because my mapply is more complicated that 
> the original and much more complicated than Jeff's merge but here it 
> is. But if there's a problem with the output of merge, maybe the 
> mapply can be of use, only the column expressly named is created.
> The result is equal to the original.
> I have changed the name exp to exp1.
>
> mydata <- data.frame(sample = c("sample2-2", "sample2-3", "sample1-1", 
> "sample1-1", "sample1-1", "sample2-1"))
> exp1 <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1", 
> "sample2-2" , "sample2-3"))
>
> for(i in names(exp1)) {
> ? mydata[mydata[["sample"]] %in% exp1[[i]], "experiment"] <- i
> }
>
> # must create the new column beforehand
> mydata[["experiment2"]] <- NA_character_
> mapply(\(value, name, s){
> ? i <- which(s %in% value)
> ? mydata[["experiment2"]][i] <<- name
> }, exp1, names(exp1), MoreArgs = list(s = mydata$sample))
>
> mydata
> #???? sample experiment experiment2
> #1 sample2-2??????? ex2???????? ex2
> #2 sample2-3??????? ex2???????? ex2
> #3 sample1-1??????? ex1???????? ex1
> #4 sample1-1??????? ex1???????? ex1
> #5 sample1-1??????? ex1???????? ex1
> #6 sample2-1??????? ex2???????? ex2
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 08:48 de 11/03/2022, Ivan Calandra escreveu:
>> In my first trials, I made a typo, which resulted in more columns 
>> than needed in the output of merge, which is why I needed more 
>> formatting. But now, it is indeed done all in one line and it is, as 
>> I said already, nicer anyway!
>>
>> -- 
>> Dr. Ivan Calandra
>> Imaging lab
>> RGZM - MONREPOS Archaeological Research Centre
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> Le 11/03/2022 ? 08:47, Jeff Newmiller a ?crit?:
>>> What a strange objection. You wouldn't keep the inline definition of 
>>> expts in working code... that would be in a reference data file, and 
>>> the merge is one line.
>>>
>>> On March 10, 2022 11:24:27 PM PST, Ivan Calandra 
>>> <ivan.calandra at rgzm.de> wrote:
>>>> Thank you Jeff and Tim for your ideas. Indeed merge/join is 
>>>> probably the
>>>> nicest way. Still, the code becomes much longer because I need more
>>>> formatting of the input and output objects than with my ugly for 
>>>> loop :)
>>>>
>>>> Cheers,
>>>> Ivan
>>>>
>>>> -- 
>>>> Dr. Ivan Calandra
>>>> Imaging lab
>>>> RGZM - MONREPOS Archaeological Research Centre
>>>> Schloss Monrepos
>>>> 56567 Neuwied, Germany
>>>> +49 (0) 2631 9772-243
>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>>
>>>> Le 10/03/2022 ? 18:58, Ebert,Timothy Aaron a ?crit?:
>>>>> You could try some of the "join" commands from dplyr.
>>>>> https://dplyr.tidyverse.org/reference/mutate-joins.html
>>>>> https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti 
>>>>>
>>>>>
>>>>>
>>>>> Regards,
>>>>> Tim
>>>>> -----Original Message-----
>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff 
>>>>> Newmiller
>>>>> Sent: Thursday, March 10, 2022 11:25 AM
>>>>> To: r-help at r-project.org; Ivan Calandra <ivan.calandra at rgzm.de>; 
>>>>> R-help <r-help at r-project.org>
>>>>> Subject: Re: [R] conditional filling of data.frame - improve code
>>>>>
>>>>> [External Email]
>>>>>
>>>>> Use merge.
>>>>>
>>>>> expts <- read.csv( text =
>>>>> "expt,sample
>>>>> ex1,sample1-1
>>>>> ex1,sample1-2
>>>>> ex2,sample2-1
>>>>> ex2,sample2-2
>>>>> ex2,sample2-3
>>>>> ", header=TRUE, as.is=TRUE )
>>>>>
>>>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", 
>>>>> "sample1-1", "sample1-1", "sample1-1", "sample2-1"))
>>>>>
>>>>> merge( mydata, expts, by="sample", all.x=TRUE )
>>>>>
>>>>>
>>>>> On March 10, 2022 7:50:23 AM PST, Ivan Calandra 
>>>>> <ivan.calandra at rgzm.de> wrote:
>>>>>> Dear useRs,
>>>>>>
>>>>>> I would like to improve my ugly (though working) code, but I think I
>>>>>> need a completely different approach and I just can't think out 
>>>>>> of my box!
>>>>>>
>>>>>> I have some external information about which sample(s) belong to 
>>>>>> which
>>>>>> experiment. I need to get that manually into R (either typing 
>>>>>> directly
>>>>>> in a script or read a CSV file, but that makes no difference):
>>>>>> exp <- list(ex1 = c("sample1-1", "sample1-2"), ex2 = c("sample2-1",
>>>>>> "sample2-2" , "sample2-3"))
>>>>>>
>>>>>> Then I have my data, only with the sample IDs:
>>>>>> mydata <- data.frame(sample = c("sample2-2", "sample2-3", 
>>>>>> "sample1-1",
>>>>>> "sample1-1", "sample1-1", "sample2-1"))
>>>>>>
>>>>>> Now I want to add a column to mydata with the experiment ID. The 
>>>>>> best I
>>>>>> could find is that:
>>>>>> for (i in names(exp)) mydata[mydata[["sample"]] %in% exp[[i]],
>>>>>> "experiment"] <- i
>>>>>>
>>>>>> In this example, the experiment ID could be extracted from the 
>>>>>> sample
>>>>>> IDs, but this is not the case with my real data so it really is a
>>>>>> matter of matching. Of course I also have other columns with my 
>>>>>> real data.
>>>>>>
>>>>>> I'm pretty sure the last line (with the loop) can be improved in 
>>>>>> terms
>>>>>> of readability (speed is not an issue here). I have close to no
>>>>>> constraints on 'exp' (here I chose a list, but anything could 
>>>>>> do), the
>>>>>> only thing that cannot change is the format of 'mydata'.
>>>>>>
>>>>>> Thank you in advance!
>>>>>> Ivan
>>>>>>
>>>>> -- 
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=4HazMU4Mqs2oOcAkBrZd0VGrHX_lw6J1XozQNQ9RsHk&e= 
>>>>>
>>>>> PLEASE do read the posting guide 
>>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Jzc7veojt_O3lQLFgC3O7ArDl8buUJGuuOHJZMWZJ9wTuTTwl_piuFOAv-w0ckT5&s=LdQqnVBkEAmRk7baBZLPs2svUpN6DIYaznrka_X8maI&e= 
>>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Mar 11 15:14:52 2022
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 11 Mar 2022 08:14:52 -0600
Subject: [R] stdev error
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
Message-ID: <006501d83552$61007540$23015fc0$@sbcglobal.net>

r-help forum

 

When I run the following code 

 

my_tbl %>% 

  mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>% 

  group_by(Cat, Bse_bwt) %>% 

  summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = sd(Bse_ftv))

 

I get the following error:

 

Error: `stdev` refers to a variable created earlier in this summarise().

Do you need an extra mutate() step?

 

I suspect it is because the standard deviation of a length-one vector is NA
and R is errorerrors out on the standard deviation  of 1. So then I tried

 

summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
sd(Bse_ftv) else 0) and this didn't seem to work either. So there has to be
a way to add some sort of error checker to my standard deviation function to
check if n > 1 and then take the standard deviation in dplyr.

 

Jeff

 


	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Mar 11 15:21:05 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 11 Mar 2022 16:21:05 +0200
Subject: [R] stdev error
In-Reply-To: <006501d83552$61007540$23015fc0$@sbcglobal.net>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
Message-ID: <CAGgJW76pvxoM7fdT3EhYXpYjvfg4ZeGsaqVNp23-72fiFnEDGw@mail.gmail.com>

try changing
Bse_ftv = mean(Bse_ftv)
to
Bse_ftv_mean = mean(Bse_ftv)

On Fri, Mar 11, 2022 at 4:15 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> r-help forum
>
>
>
> When I run the following code
>
>
>
> my_tbl %>%
>
>   mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
>
>   group_by(Cat, Bse_bwt) %>%
>
>   summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = sd(Bse_ftv))
>
>
>
> I get the following error:
>
>
>
> Error: `stdev` refers to a variable created earlier in this summarise().
>
> Do you need an extra mutate() step?
>
>
>
> I suspect it is because the standard deviation of a length-one vector is NA
> and R is errorerrors out on the standard deviation  of 1. So then I tried
>
>
>
> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has to be
> a way to add some sort of error checker to my standard deviation function
> to
> check if n > 1 and then take the standard deviation in dplyr.
>
>
>
> Jeff
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chr|@ho|d @end|ng |rom p@yctc@org  Fri Mar 11 15:21:39 2022
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Fri, 11 Mar 2022 14:21:39 +0000 (UTC)
Subject: [R] stdev error
In-Reply-To: <006501d83552$61007540$23015fc0$@sbcglobal.net>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
Message-ID: <78609194.4064951.1647008499840.JavaMail.zimbra@psyctc.org>

Can't see your data but perhaps:

my_tbl %>%
  mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
  group_by(Cat, Bse_bwt) %>%
  summarize(count = n(), 
     Bse_ftv = mean(Bse_ftv), 
     stdev = if_else(count > 1,
                     sd(Bse_ftv),
                     NA_real_))
 

----- Original Message -----
> From: "Jeff Reichman" <reichmanj at sbcglobal.net>
> To: r-help at r-project.org
> Sent: Friday, 11 March, 2022 15:14:52
> Subject: [R] stdev error

> r-help forum
> 
> 
> 
> When I run the following code
> 
> 
> 
> my_tbl %>%
> 
>  mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
> 
>  group_by(Cat, Bse_bwt) %>%
> 
>  summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = sd(Bse_ftv))
> 
> 
> 
> I get the following error:
> 
> 
> 
> Error: `stdev` refers to a variable created earlier in this summarise().
> 
> Do you need an extra mutate() step?
> 
> 
> 
> I suspect it is because the standard deviation of a length-one vector is NA
> and R is errorerrors out on the standard deviation  of 1. So then I tried
> 
> 
> 
> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has to be
> a way to add some sort of error checker to my standard deviation function to
> check if n > 1 and then take the standard deviation in dplyr.
> 
> 
> 
> Jeff
> 
> 
> 
> 
>	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans (he/him) <chris at psyctc.org> 
Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor, University of Roehampton, London, UK.
Work web site: https://www.psyctc.org/psyctc/ 
CORE site:     https://www.coresystemtrust.org.uk/
Personal site: https://www.psyctc.org/pelerinage2016/
OMbook:        https://ombook.psyctc.org/book/


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Mar 11 15:27:40 2022
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 11 Mar 2022 08:27:40 -0600
Subject: [R] stdev error
In-Reply-To: <006501d83552$61007540$23015fc0$@sbcglobal.net>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
Message-ID: <007d01d83554$2a69c750$7f3d55f0$@sbcglobal.net>

Well I can see my "ifelse" syntax is wrong so I've changed it to 

  summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = ifelse(count>1,
sd(Bse_ftv),0)) but still getting

Error: `stdev` refers to a variable created earlier in this summarise().
Do you need an extra mutate() step?

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Friday, March 11, 2022 8:15 AM
To: r-help at r-project.org
Subject: [R] stdev error

r-help forum

 When I run the following code 

my_tbl %>% 
  mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>% 
  group_by(Cat, Bse_bwt) %>% 
  summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = sd(Bse_ftv))

I get the following error:

Error: `stdev` refers to a variable created earlier in this summarise().
Do you need an extra mutate() step?

 I suspect it is because the standard deviation of a length-one vector is NA
and R is errorerrors out on the standard deviation  of 1. So then I tried

summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
sd(Bse_ftv) else 0) and this didn't seem to work either. So there has to be
a way to add some sort of error checker to my standard deviation function to
check if n > 1 and then take the standard deviation in dplyr.

 

Jeff

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Mar 11 15:30:16 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 11 Mar 2022 17:30:16 +0300
Subject: [R] stdev error
In-Reply-To: <006501d83552$61007540$23015fc0$@sbcglobal.net>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
Message-ID: <20220311173016.1b76db7b@arachnoid>

? Fri, 11 Mar 2022 08:14:52 -0600
"Jeff Reichman" <reichmanj at sbcglobal.net> ?????:

> I get the following error:
> 
>> Error: `stdev` refers to a variable created earlier in this
>> summarise().
>> 
>> Do you need an extra mutate() step?
> 
> I suspect it is because the standard deviation of a length-one vector
> is NA and R is errorerrors out on the standard deviation  of 1.

My interpretation of the error message is that summarise() thinks that
you're creating a variable (Bse_ftv = mean(Bse_ftv)) and then asking
summarise() to compute its standard deviation (stdev = sd(Bse_ftv)) in
the same call. This is apparently not always supported, according
to ?summarise [1].

You know that you meant the previously available Bse_ftv column, not
the newly created Bse_ftv = mean(Bse_ftv), but this is not how the call
is interpreted. Try setting a different name for the result of
mean(Bse_ftv).

-- 
Best regards,
Ivan

[1] https://search.r-project.org/CRAN/refmans/dplyr/html/summarise.html


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Mar 11 15:50:24 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 11 Mar 2022 14:50:24 +0000
Subject: [R] stdev error
In-Reply-To: <78609194.4064951.1647008499840.JavaMail.zimbra@psyctc.org>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
 <78609194.4064951.1647008499840.JavaMail.zimbra@psyctc.org>
Message-ID: <339bfa04247a409fabd3f7a62805caff@SRVEXCHCM1301.precheza.cz>

Hallo

with(my_tbl, aggregate(Bse_bwt, list(Cat), function(x) c(n=length(x), mean=mean(x), st_dev=sd(x))))

Or am I missing something?

Cheers
Petr


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Chris Evans
Sent: Friday, March 11, 2022 3:22 PM
To: reichmanj at sbcglobal.net
Cc: r-help at r-project.org
Subject: Re: [R] stdev error

Can't see your data but perhaps:

my_tbl %>%
  mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
  group_by(Cat, Bse_bwt) %>%
  summarize(count = n(),
     Bse_ftv = mean(Bse_ftv),
     stdev = if_else(count > 1,
                     sd(Bse_ftv),
                     NA_real_))


----- Original Message -----
> From: "Jeff Reichman" <reichmanj at sbcglobal.net>
> To: r-help at r-project.org
> Sent: Friday, 11 March, 2022 15:14:52
> Subject: [R] stdev error

> r-help forum
>
>
>
> When I run the following code
>
>
>
> my_tbl %>%
>
>  mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
>
>  group_by(Cat, Bse_bwt) %>%
>
>  summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = sd(Bse_ftv))
>
>
>
> I get the following error:
>
>
>
> Error: `stdev` refers to a variable created earlier in this summarise().
>
> Do you need an extra mutate() step?
>
>
>
> I suspect it is because the standard deviation of a length-one vector
> is NA and R is errorerrors out on the standard deviation  of 1. So
> then I tried
>
>
>
> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has
> to be a way to add some sort of error checker to my standard deviation
> function to check if n > 1 and then take the standard deviation in dplyr.
>
>
>
> Jeff
>
>
>
>
>[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Chris Evans (he/him) <chris at psyctc.org> Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor, University of Roehampton, London, UK.
Work web site: https://www.psyctc.org/psyctc/
CORE site:     https://www.coresystemtrust.org.uk/
Personal site: https://www.psyctc.org/pelerinage2016/
OMbook:        https://ombook.psyctc.org/book/

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Mar 11 16:24:03 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 11 Mar 2022 15:24:03 +0000
Subject: [R] stdev error
In-Reply-To: <006501d83552$61007540$23015fc0$@sbcglobal.net>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
Message-ID: <01b77e81-b40a-7d48-b740-ae8ac0a383fc@sapo.pt>

Hello,

I cannot reproduce this error with a built-in data set.
Can you post str(my_tbl)?


suppressPackageStartupMessages(library(dplyr))

mtcars %>%
   mutate(hp = round(hp * 2) / 2) %>%
   group_by(cyl, hp) %>%
   summarise(
     count = n(),
     hp = mean(hp),
     stdev = sd(hp)
   )
#> `summarise()` has grouped output by 'cyl'. You can override using the 
`.groups`
#> argument.
#> # A tibble: 23 x 4
#> # Groups:   cyl [3]
#>      cyl    hp count stdev
#>    <dbl> <dbl> <int> <dbl>
#>  1     4    52     1    NA
#>  2     4    62     1    NA
#>  3     4    65     1    NA
#>  4     4    66     2    NA
#>  5     4    91     1    NA
#>  6     4    93     1    NA
#>  7     4    95     1    NA
#>  8     4    97     1    NA
#>  9     4   109     1    NA
#> 10     4   113     1    NA
#> # ... with 13 more rows

Hope this helps,

Rui Barradas


?s 14:14 de 11/03/2022, Jeff Reichman escreveu:
> r-help forum
> 
>   
> 
> When I run the following code
> 
>   
> 
> my_tbl %>%
> 
>    mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
> 
>    group_by(Cat, Bse_bwt) %>%
> 
>    summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = sd(Bse_ftv))
> 
>   
> 
> I get the following error:
> 
>   
> 
> Error: `stdev` refers to a variable created earlier in this summarise().
> 
> Do you need an extra mutate() step?
> 
>   
> 
> I suspect it is because the standard deviation of a length-one vector is NA
> and R is errorerrors out on the standard deviation  of 1. So then I tried
> 
>   
> 
> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has to be
> a way to add some sort of error checker to my standard deviation function to
> check if n > 1 and then take the standard deviation in dplyr.
> 
>   
> 
> Jeff
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Mar 11 16:43:49 2022
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 11 Mar 2022 09:43:49 -0600
Subject: [R] stdev error
In-Reply-To: <01b77e81-b40a-7d48-b740-ae8ac0a383fc@sapo.pt>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
 <01b77e81-b40a-7d48-b740-ae8ac0a383fc@sapo.pt>
Message-ID: <00a101d8355e$cda1ca80$68e55f80$@sbcglobal.net>

Rui

I don't have the data with med. But I did try using the mtcars dataset you used

mtcars %>%
  mutate(hp = round(hp * 2) / 2) %>%
  group_by(gear, carb) %>%
  summarise(count = n(), mean_hp = mean(hp), stdev_hp = sd(hp))

which resulted in 

# A tibble: 11 x 5
# Groups:   gear [3]
    gear  carb count mean_hp stdev_hp
   <dbl> <dbl> <int>   <dbl>    <dbl>
 1     3     1     3   104       6.56
 2     3     2     4   162.     14.4 
 3     3     3     3   180       0   
 4     3     4     5   228      17.9 
 5     4     1     4    72.5    13.7 
 6     4     2     4    79.5    26.9 
 7     4     4     4   116.      7.51
 8     5     2     2   102      15.6 
 9     5     4     1   264      NA   
10     5     6     1   175      NA   
11     5     8     1   335      NA

So maybe there is something odd with my dataset. Because the mtcars dataset code ran just fine. Where count == 1 sd returned NA. Which is what I was expecting originally


-----Original Message-----
From: Rui Barradas <ruipbarradas at sapo.pt> 
Sent: Friday, March 11, 2022 9:24 AM
To: reichmanj at sbcglobal.net; r-help at r-project.org
Subject: Re: [R] stdev error

Hello,

I cannot reproduce this error with a built-in data set.
Can you post str(my_tbl)?


suppressPackageStartupMessages(library(dplyr))

mtcars %>%
   mutate(hp = round(hp * 2) / 2) %>%
   group_by(cyl, hp) %>%
   summarise(
     count = n(),
     hp = mean(hp),
     stdev = sd(hp)
   )
#> `summarise()` has grouped output by 'cyl'. You can override using the `.groups` #> argument.
#> # A tibble: 23 x 4
#> # Groups:   cyl [3]
#>      cyl    hp count stdev
#>    <dbl> <dbl> <int> <dbl>
#>  1     4    52     1    NA
#>  2     4    62     1    NA
#>  3     4    65     1    NA
#>  4     4    66     2    NA
#>  5     4    91     1    NA
#>  6     4    93     1    NA
#>  7     4    95     1    NA
#>  8     4    97     1    NA
#>  9     4   109     1    NA
#> 10     4   113     1    NA
#> # ... with 13 more rows

Hope this helps,

Rui Barradas


?s 14:14 de 11/03/2022, Jeff Reichman escreveu:
> r-help forum
> 
>   
> 
> When I run the following code
> 
>   
> 
> my_tbl %>%
> 
>    mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
> 
>    group_by(Cat, Bse_bwt) %>%
> 
>    summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = 
> sd(Bse_ftv))
> 
>   
> 
> I get the following error:
> 
>   
> 
> Error: `stdev` refers to a variable created earlier in this summarise().
> 
> Do you need an extra mutate() step?
> 
>   
> 
> I suspect it is because the standard deviation of a length-one vector 
> is NA and R is errorerrors out on the standard deviation  of 1. So 
> then I tried
> 
>   
> 
> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has 
> to be a way to add some sort of error checker to my standard deviation 
> function to check if n > 1 and then take the standard deviation in dplyr.
> 
>   
> 
> Jeff
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Mar 11 18:49:52 2022
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 11 Mar 2022 11:49:52 -0600
Subject: [R] stdev error
In-Reply-To: <01b77e81-b40a-7d48-b740-ae8ac0a383fc@sapo.pt>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
 <01b77e81-b40a-7d48-b740-ae8ac0a383fc@sapo.pt>
Message-ID: <00b601d83570$69dd7500$3d985f00$@sbcglobal.net>

Rui

Found my problem, or at least I think I found the problem. 

# BEWARE: reusing variables may lead to unexpected results - https://dplyr.tidyverse.org/reference/summarise.html

I changed my variable name  and problem resolved.

Jeff

-----Original Message-----
From: Rui Barradas <ruipbarradas at sapo.pt> 
Sent: Friday, March 11, 2022 9:24 AM
To: reichmanj at sbcglobal.net; r-help at r-project.org
Subject: Re: [R] stdev error

Hello,

I cannot reproduce this error with a built-in data set.
Can you post str(my_tbl)?


suppressPackageStartupMessages(library(dplyr))

mtcars %>%
   mutate(hp = round(hp * 2) / 2) %>%
   group_by(cyl, hp) %>%
   summarise(
     count = n(),
     hp = mean(hp),
     stdev = sd(hp)
   )
#> `summarise()` has grouped output by 'cyl'. You can override using the `.groups` #> argument.
#> # A tibble: 23 x 4
#> # Groups:   cyl [3]
#>      cyl    hp count stdev
#>    <dbl> <dbl> <int> <dbl>
#>  1     4    52     1    NA
#>  2     4    62     1    NA
#>  3     4    65     1    NA
#>  4     4    66     2    NA
#>  5     4    91     1    NA
#>  6     4    93     1    NA
#>  7     4    95     1    NA
#>  8     4    97     1    NA
#>  9     4   109     1    NA
#> 10     4   113     1    NA
#> # ... with 13 more rows

Hope this helps,

Rui Barradas


?s 14:14 de 11/03/2022, Jeff Reichman escreveu:
> r-help forum
> 
>   
> 
> When I run the following code
> 
>   
> 
> my_tbl %>%
> 
>    mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
> 
>    group_by(Cat, Bse_bwt) %>%
> 
>    summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = 
> sd(Bse_ftv))
> 
>   
> 
> I get the following error:
> 
>   
> 
> Error: `stdev` refers to a variable created earlier in this summarise().
> 
> Do you need an extra mutate() step?
> 
>   
> 
> I suspect it is because the standard deviation of a length-one vector 
> is NA and R is errorerrors out on the standard deviation  of 1. So 
> then I tried
> 
>   
> 
> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has 
> to be a way to add some sort of error checker to my standard deviation 
> function to check if n > 1 and then take the standard deviation in dplyr.
> 
>   
> 
> Jeff
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Mar 11 20:31:50 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 11 Mar 2022 19:31:50 +0000
Subject: [R] stdev error
In-Reply-To: <00b601d83570$69dd7500$3d985f00$@sbcglobal.net>
References: <006501d83552$61007540$23015fc0$.ref@sbcglobal.net>
 <006501d83552$61007540$23015fc0$@sbcglobal.net>
 <01b77e81-b40a-7d48-b740-ae8ac0a383fc@sapo.pt>
 <00b601d83570$69dd7500$3d985f00$@sbcglobal.net>
Message-ID: <49b639f1-cd58-5c85-24f7-f4066feebb38@sapo.pt>

Hello,

Yes, you're right.
Thanks for posting this, in my original post unlike what I thought I was 
able to reproduce the error. All stdev values were NA when in fact after 
changing the mean to hp1 = mean(hp) some of them are not, there are 
zeros in the output column stdev.

Rui Barradas

?s 17:49 de 11/03/2022, Jeff Reichman escreveu:
> Rui
> 
> Found my problem, or at least I think I found the problem.
> 
> # BEWARE: reusing variables may lead to unexpected results - https://dplyr.tidyverse.org/reference/summarise.html
> 
> I changed my variable name  and problem resolved.
> 
> Jeff
> 
> -----Original Message-----
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Friday, March 11, 2022 9:24 AM
> To: reichmanj at sbcglobal.net; r-help at r-project.org
> Subject: Re: [R] stdev error
> 
> Hello,
> 
> I cannot reproduce this error with a built-in data set.
> Can you post str(my_tbl)?
> 
> 
> suppressPackageStartupMessages(library(dplyr))
> 
> mtcars %>%
>     mutate(hp = round(hp * 2) / 2) %>%
>     group_by(cyl, hp) %>%
>     summarise(
>       count = n(),
>       hp = mean(hp),
>       stdev = sd(hp)
>     )
> #> `summarise()` has grouped output by 'cyl'. You can override using the `.groups` #> argument.
> #> # A tibble: 23 x 4
> #> # Groups:   cyl [3]
> #>      cyl    hp count stdev
> #>    <dbl> <dbl> <int> <dbl>
> #>  1     4    52     1    NA
> #>  2     4    62     1    NA
> #>  3     4    65     1    NA
> #>  4     4    66     2    NA
> #>  5     4    91     1    NA
> #>  6     4    93     1    NA
> #>  7     4    95     1    NA
> #>  8     4    97     1    NA
> #>  9     4   109     1    NA
> #> 10     4   113     1    NA
> #> # ... with 13 more rows
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 14:14 de 11/03/2022, Jeff Reichman escreveu:
>> r-help forum
>>
>>    
>>
>> When I run the following code
>>
>>    
>>
>> my_tbl %>%
>>
>>     mutate(Bse_bwt = round(Bse_bwt * 2) / 2) %>%
>>
>>     group_by(Cat, Bse_bwt) %>%
>>
>>     summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev =
>> sd(Bse_ftv))
>>
>>    
>>
>> I get the following error:
>>
>>    
>>
>> Error: `stdev` refers to a variable created earlier in this summarise().
>>
>> Do you need an extra mutate() step?
>>
>>    
>>
>> I suspect it is because the standard deviation of a length-one vector
>> is NA and R is errorerrors out on the standard deviation  of 1. So
>> then I tried
>>
>>    
>>
>> summarize(count = n(), Bse_ftv = mean(Bse_ftv), stdev = if(n()>1)
>> sd(Bse_ftv) else 0) and this didn't seem to work either. So there has
>> to be a way to add some sort of error checker to my standard deviation
>> function to check if n > 1 and then take the standard deviation in dplyr.
>>
>>    
>>
>> Jeff
>>
>>    
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Mar 12 17:42:28 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 12 Mar 2022 11:42:28 -0500
Subject: [R] Is there a Truth Table Generator in R?
Message-ID: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>

Dear friends,

Hope you are doing great. I have been searching for a truth table generator
in R, but everything I find has a Python implementation instead.

Maybe there is in fact a truth table generator in R, but I am not searching
in the right places?

Any help and/or guidance will be greatly appreciated.

Best regards,
Paul

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sat Mar 12 17:48:24 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 12 Mar 2022 16:48:24 +0000
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
Message-ID: <BN6PR2201MB155353612C3CF69671316BB6CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>

Hi Paul,
Can you describe a truth table so that those persons who don't know your specific application might be able to help? Is possible that it is known by a different name? My first guess is confusion matrix.
Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
Sent: Saturday, March 12, 2022 11:42 AM
To: R <r-help at r-project.org>
Subject: [R] Is there a Truth Table Generator in R?

[External Email]

Dear friends,

Hope you are doing great. I have been searching for a truth table generator in R, but everything I find has a Python implementation instead.

Maybe there is in fact a truth table generator in R, but I am not searching in the right places?

Any help and/or guidance will be greatly appreciated.

Best regards,
Paul

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CtTRgVrLfmt90LZKdUbT_g6aHRJ-kVQogNxWfmzlUtgiW4qDeBreSVq1oI-5B09z&s=10AZl9R7fUIEB2c-nixiSLoAg9aergAyNJnwNoI_W-Y&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CtTRgVrLfmt90LZKdUbT_g6aHRJ-kVQogNxWfmzlUtgiW4qDeBreSVq1oI-5B09z&s=UQzuG0nG_5HKiiR0wX2pUQfsc39cPZtYkKFkzBxuC2U&e=
and provide commented, minimal, self-contained, reproducible code.


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sat Mar 12 17:49:11 2022
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sat, 12 Mar 2022 10:49:11 -0600
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
Message-ID: <8152a20d-aef4-a8fc-1c7a-eea961e471a6@effectivedefense.org>

library(sos)
tt <- findFn("{truth table}")
installPackages(tt)
tt


	  This just now opened two sheets in my default browser.  The first 
listed all the help pages in contributed packages with the phrase "truth 
table", sorted to put first the ones in packages with the most matches. 
  The second is a summary by package.


	  Hope this helps.
	  Spencer Graves


On 3/12/22 10:42 AM, Paul Bernal wrote:
> Dear friends,
> 
> Hope you are doing great. I have been searching for a truth table generator
> in R, but everything I find has a Python implementation instead.
> 
> Maybe there is in fact a truth table generator in R, but I am not searching
> in the right places?
> 
> Any help and/or guidance will be greatly appreciated.
> 
> Best regards,
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Mar 12 18:04:30 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 12 Mar 2022 09:04:30 -0800
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
Message-ID: <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>

both <- c( FALSE, TRUE )
tt <- expand.grid( C = both
                 , B = both
                 , A = both
                 )
tt <- tt[, 3:1 ]

On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>Hope you are doing great. I have been searching for a truth table generator
>in R, but everything I find has a Python implementation instead.
>
>Maybe there is in fact a truth table generator in R, but I am not searching
>in the right places?
>
>Any help and/or guidance will be greatly appreciated.
>
>Best regards,
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kt1572757 @end|ng |rom gm@||@com  Sat Mar 12 22:29:58 2022
From: kt1572757 @end|ng |rom gm@||@com (Kelly Thompson)
Date: Sat, 12 Mar 2022 13:29:58 -0800
Subject: [R] obtain names & values of all arguments passed to a function
 including args passed using the "three dots" ellipsis ( ...) parameter,
 for use in do.call
Message-ID: <CAHfBD2c5j22e=+GNr4x_p74SBaUUrY-XPySmHeuaftBWj3CDEA@mail.gmail.com>

#What are "good" ways to obtain all arguments passed to or being used
by a function, including arguments passed to the function using the
"three dots" ellipsis ( ...) parameter, so that these arguments can be
used in the args parameter of do.call(what, args) .

#I think I've figured out a method that uses environment() and
match.call() (see example below).

#I'm looking for feedback about problems with my approach, and
suggestions about better ways to do this.

#Thank you!

#Related posts
#https://stackoverflow.com/questions/51259346/how-to-get-names-of-dot-dot-dot-arguments-in-r
#https://stackoverflow.com/questions/35317587/extract-names-of-dataframes-passed-with-dots
#https://stackoverflow.com/questions/17256834/getting-the-arguments-of-a-parent-function-in-r-with-names

#Example

#Note: "udf_" indicates this is a "user-defined function"

#start udf_return_all_arguments
    udf_return_all_arguments <- function (...)  {

#obtain all arguments passed to or being used by a function, including
arguments passed to the function using the "three dots" ellipsis (
...) parameter
#
#this obtains the arguments for parameters explicitly listed in the function
        env <- as.list( environment() )

#this obtains the arguments for parameters NOT explicitly listed in
the function and included    using the 3 dots ellipses ( ... )
parameters feature
        mc <- match.call(expand.dots = FALSE)
        dots <- as.list( mc$...)

#these are all the arguments from the function
        args_in <-  c(env, dots)

        return(args_in)

    } # end udf_return_all_arguments

################################################################

#start udf_pass_all_argumens_to_do_call
    udf_pass_all_argumens_to_do_call <- function(x, y, z = NULL, na.rm
= T, FUN, ... ) {

#obtain all arguments passed to or being used by a function, including
arguments passed to the function using the "three dots" ellipsis (
...) parameter
#
#this obtains the arguments for parameters explicitly listed in the function
        env <- as.list( environment() )

#this obtains the arguments for parameters NOT explicitly listed in
the function and included using the 3 dots ellipses ( ... ) parameters
feature
        mc <- match.call(expand.dots = FALSE)
        dots <- as.list( mc$...)

#these are all the arguments from the function
        args_in <-  c(env, dots)

        do.call( what = FUN, args = args_in)

    } #end udf_pass_all_argumens_to_do_call

    my_list_all_args <- udf_pass_all_argumens_to_do_call(x = 123, y =
456, FUN = udf_return_all_arguments, non_specified_paramter = "this is
an example")
    my_list_all_args
### end of example


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Mar 12 18:47:33 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 12 Mar 2022 09:47:33 -0800
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CAMOcQfM9anSaAUz36_4jEMXpfvWqv0emYtZuGdMhg=-t+mZ_aQ@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <CAMOcQfM9anSaAUz36_4jEMXpfvWqv0emYtZuGdMhg=-t+mZ_aQ@mail.gmail.com>
Message-ID: <D2BFAF8D-0E12-4546-9405-DEC9F1473AA3@dcn.davis.ca.us>

Please keep the list included in the thread using reply-all...

tt[,3:1] reverses the columns in tt. The expand.grid function cycles through possible values most quickly in the first column, which is useful if you intend to convert the result to a matrix, but is not conventional for truth tables.

Here is a generalized version for any sequence of legal R symbol labels nm:

both <- c( FALSE, TRUE )
nm <- letters[ 1:4 ]
tt <- rev( do.call( expand.grid, setNames( rep( list( both ), length( nm ) ), rev( nm ) ) ) )
tt

or in R 4.1+...

tt <- (  list( both )
      |> rep( length( nm ) )
      |> setNames( rev( nm ) )
      |> ( \(.) do.call( expand.grid, . ) )()
      |> rev()
      )

On March 12, 2022 9:08:23 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear Jeff,
>
>Thank you so much for your valuable feedback. at the end, in the command tt
><- [,3:1] what exactly does this do? If I wanted to create code to
>accomodate for any number of variables, how would I change that code?
>
>Best regards,
>Paul
>
>El s?b, 12 mar 2022 a las 12:04, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
>escribi?:
>
>> both <- c( FALSE, TRUE )
>> tt <- expand.grid( C = both
>>                  , B = both
>>                  , A = both
>>                  )
>> tt <- tt[, 3:1 ]
>>
>> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> >Dear friends,
>> >
>> >Hope you are doing great. I have been searching for a truth table
>> generator
>> >in R, but everything I find has a Python implementation instead.
>> >
>> >Maybe there is in fact a truth table generator in R, but I am not
>> searching
>> >in the right places?
>> >
>> >Any help and/or guidance will be greatly appreciated.
>> >
>> >Best regards,
>> >Paul
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Mar 12 18:49:30 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 12 Mar 2022 12:49:30 -0500
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <D2BFAF8D-0E12-4546-9405-DEC9F1473AA3@dcn.davis.ca.us>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <CAMOcQfM9anSaAUz36_4jEMXpfvWqv0emYtZuGdMhg=-t+mZ_aQ@mail.gmail.com>
 <D2BFAF8D-0E12-4546-9405-DEC9F1473AA3@dcn.davis.ca.us>
Message-ID: <CAMOcQfNvd8us6Lq7ikpDhNrnXhtvj0LN0LLxPMjAy7aWuLnSfA@mail.gmail.com>

Dear Jeff,

Thank you so much for your extremely valuable feedback. I apologize for not
doing the reply all, forgot it.

Best regards,
Paul

El s?b, 12 mar 2022 a las 12:47, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
escribi?:

> Please keep the list included in the thread using reply-all...
>
> tt[,3:1] reverses the columns in tt. The expand.grid function cycles
> through possible values most quickly in the first column, which is useful
> if you intend to convert the result to a matrix, but is not conventional
> for truth tables.
>
> Here is a generalized version for any sequence of legal R symbol labels nm:
>
> both <- c( FALSE, TRUE )
> nm <- letters[ 1:4 ]
> tt <- rev( do.call( expand.grid, setNames( rep( list( both ), length( nm )
> ), rev( nm ) ) ) )
> tt
>
> or in R 4.1+...
>
> tt <- (  list( both )
>       |> rep( length( nm ) )
>       |> setNames( rev( nm ) )
>       |> ( \(.) do.call( expand.grid, . ) )()
>       |> rev()
>       )
>
> On March 12, 2022 9:08:23 AM PST, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >Dear Jeff,
> >
> >Thank you so much for your valuable feedback. at the end, in the command
> tt
> ><- [,3:1] what exactly does this do? If I wanted to create code to
> >accomodate for any number of variables, how would I change that code?
> >
> >Best regards,
> >Paul
> >
> >El s?b, 12 mar 2022 a las 12:04, Jeff Newmiller (<
> jdnewmil at dcn.davis.ca.us>)
> >escribi?:
> >
> >> both <- c( FALSE, TRUE )
> >> tt <- expand.grid( C = both
> >>                  , B = both
> >>                  , A = both
> >>                  )
> >> tt <- tt[, 3:1 ]
> >>
> >> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com>
> >> wrote:
> >> >Dear friends,
> >> >
> >> >Hope you are doing great. I have been searching for a truth table
> >> generator
> >> >in R, but everything I find has a Python implementation instead.
> >> >
> >> >Maybe there is in fact a truth table generator in R, but I am not
> >> searching
> >> >in the right places?
> >> >
> >> >Any help and/or guidance will be greatly appreciated.
> >> >
> >> >Best regards,
> >> >Paul
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Mar 12 19:33:38 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 12 Mar 2022 10:33:38 -0800
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
Message-ID: <CAGxFJbTqyeLuokZiw9mLHerjbtMH-SJMypq5ur5TpS0cv1aUwA@mail.gmail.com>

As Tim pointed out, your query is rather vague. A reprex would have
really helped here: please include them whenever possible in future
queries.

As Spencer said, a simple search would likely have yielded whatever
you were seeking. Do make such efforts before posting.

And as Jeff indicated, it's most likely straightforward to create a
function that does what you want de novo. Here is such a function
based on my guess of what you meant:

tt <- function(tabl, fun)
 {## fun is a function that when applied rowwise to
 ## the logical data frame tabl yields a
 ## logical result
 cbind(tabl, Result = apply(tabl,1,fun))
 }

## some examples
> tt(dat,any) ## or
   Var1  Var2 Result
1  TRUE  TRUE   TRUE
2 FALSE  TRUE   TRUE
3  TRUE FALSE   TRUE
4 FALSE FALSE  FALSE

> tt(dat, all) ## and
   Var1  Var2 Result
1  TRUE  TRUE   TRUE
2 FALSE  TRUE  FALSE
3  TRUE FALSE  FALSE
4 FALSE FALSE  FALSE

> tt(dat, function(x) !x[1] | x[2]) ## if-then
   Var1  Var2 Result
1  TRUE  TRUE   TRUE
2 FALSE  TRUE   TRUE
3  TRUE FALSE  FALSE
4 FALSE FALSE   TRUE

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Mar 12, 2022 at 9:13 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> both <- c( FALSE, TRUE )
> tt <- expand.grid( C = both
>                  , B = both
>                  , A = both
>                  )
> tt <- tt[, 3:1 ]
>
> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >Dear friends,
> >
> >Hope you are doing great. I have been searching for a truth table generator
> >in R, but everything I find has a Python implementation instead.
> >
> >Maybe there is in fact a truth table generator in R, but I am not searching
> >in the right places?
> >
> >Any help and/or guidance will be greatly appreciated.
> >
> >Best regards,
> >Paul
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Sat Mar 12 19:37:41 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 12 Mar 2022 18:37:41 +0000
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
Message-ID: <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>

To the end of Jeff's program add
tt$truth <- tt$A & tt$B & tt$C
to evaluate the outcome of expand.grid. 

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
Sent: Saturday, March 12, 2022 12:05 PM
To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <r-help at r-project.org>
Subject: Re: [R] Is there a Truth Table Generator in R?

[External Email]

both <- c( FALSE, TRUE )
tt <- expand.grid( C = both
                 , B = both
                 , A = both
                 )
tt <- tt[, 3:1 ]

On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>Hope you are doing great. I have been searching for a truth table 
>generator in R, but everything I find has a Python implementation instead.
>
>Maybe there is in fact a truth table generator in R, but I am not 
>searching in the right places?
>
>Any help and/or guidance will be greatly appreciated.
>
>Best regards,
>Paul
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
>ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>PLEASE do read the posting guide 
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
>oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Mar 12 21:14:41 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 12 Mar 2022 12:14:41 -0800
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CAGxFJbTqyeLuokZiw9mLHerjbtMH-SJMypq5ur5TpS0cv1aUwA@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <CAGxFJbTqyeLuokZiw9mLHerjbtMH-SJMypq5ur5TpS0cv1aUwA@mail.gmail.com>
Message-ID: <CAGxFJbR3GPoXEwQEkuER6EQcS2ts9875_OWFZrXo9Qu9rE_cgg@mail.gmail.com>

... Forgot to include for completeness: dat is as Jeff suggested:

both <- c(TRUE, FALSE)
dat <- expand.grid(both, both)

Bert Gunter

On Sat, Mar 12, 2022 at 10:33 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> As Tim pointed out, your query is rather vague. A reprex would have
> really helped here: please include them whenever possible in future
> queries.
>
> As Spencer said, a simple search would likely have yielded whatever
> you were seeking. Do make such efforts before posting.
>
> And as Jeff indicated, it's most likely straightforward to create a
> function that does what you want de novo. Here is such a function
> based on my guess of what you meant:
>
> tt <- function(tabl, fun)
>  {## fun is a function that when applied rowwise to
>  ## the logical data frame tabl yields a
>  ## logical result
>  cbind(tabl, Result = apply(tabl,1,fun))
>  }
>
> ## some examples
> > tt(dat,any) ## or
>    Var1  Var2 Result
> 1  TRUE  TRUE   TRUE
> 2 FALSE  TRUE   TRUE
> 3  TRUE FALSE   TRUE
> 4 FALSE FALSE  FALSE
>
> > tt(dat, all) ## and
>    Var1  Var2 Result
> 1  TRUE  TRUE   TRUE
> 2 FALSE  TRUE  FALSE
> 3  TRUE FALSE  FALSE
> 4 FALSE FALSE  FALSE
>
> > tt(dat, function(x) !x[1] | x[2]) ## if-then
>    Var1  Var2 Result
> 1  TRUE  TRUE   TRUE
> 2 FALSE  TRUE   TRUE
> 3  TRUE FALSE  FALSE
> 4 FALSE FALSE   TRUE
>
> Cheers,
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Mar 12, 2022 at 9:13 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> >
> > both <- c( FALSE, TRUE )
> > tt <- expand.grid( C = both
> >                  , B = both
> >                  , A = both
> >                  )
> > tt <- tt[, 3:1 ]
> >
> > On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
> > >Dear friends,
> > >
> > >Hope you are doing great. I have been searching for a truth table generator
> > >in R, but everything I find has a Python implementation instead.
> > >
> > >Maybe there is in fact a truth table generator in R, but I am not searching
> > >in the right places?
> > >
> > >Any help and/or guidance will be greatly appreciated.
> > >
> > >Best regards,
> > >Paul
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Mar 12 23:17:32 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 12 Mar 2022 14:17:32 -0800
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>

...
tt$truth <- tt$A & tt$B & tt$C
to evaluate the outcome of expand.grid.

or, as I said,
tt$truth <- apply(tt,1, all)
which works for any number of columns in tt.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Mar 12, 2022 at 2:02 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> To the end of Jeff's program add
> tt$truth <- tt$A & tt$B & tt$C
> to evaluate the outcome of expand.grid.
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
> Sent: Saturday, March 12, 2022 12:05 PM
> To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <r-help at r-project.org>
> Subject: Re: [R] Is there a Truth Table Generator in R?
>
> [External Email]
>
> both <- c( FALSE, TRUE )
> tt <- expand.grid( C = both
>                  , B = both
>                  , A = both
>                  )
> tt <- tt[, 3:1 ]
>
> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >Dear friends,
> >
> >Hope you are doing great. I have been searching for a truth table
> >generator in R, but everything I find has a Python implementation instead.
> >
> >Maybe there is in fact a truth table generator in R, but I am not
> >searching in the right places?
> >
> >Any help and/or guidance will be greatly appreciated.
> >
> >Best regards,
> >Paul
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
> >ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
> >oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Mar 13 10:17:37 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 13 Mar 2022 01:17:37 -0800
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>
Message-ID: <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>

There are 2^(2^length(tt)) possible "truth" vectors for the inputs defined in tt. AND-ing all of the inputs only gives one of those possibilities. Some popular named cases for 2 inputs are shown here [1], but it is common to use combinations of !, & and | to specify a particular truth vector. There is also the problem of reverse-engineering such a boolean expeession [2] in simplest form from a given truth vector, but I don't know if anyone has implemented such algorithms in R.

[1] https://en.wikipedia.org/wiki/Truth_table

[2] https://en.wikipedia.org/wiki/Karnaugh_maps

On March 12, 2022 2:17:32 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>...
>tt$truth <- tt$A & tt$B & tt$C
>to evaluate the outcome of expand.grid.
>
>or, as I said,
>tt$truth <- apply(tt,1, all)
>which works for any number of columns in tt.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Sat, Mar 12, 2022 at 2:02 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>>
>> To the end of Jeff's program add
>> tt$truth <- tt$A & tt$B & tt$C
>> to evaluate the outcome of expand.grid.
>>
>> Tim
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>> Sent: Saturday, March 12, 2022 12:05 PM
>> To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <r-help at r-project.org>
>> Subject: Re: [R] Is there a Truth Table Generator in R?
>>
>> [External Email]
>>
>> both <- c( FALSE, TRUE )
>> tt <- expand.grid( C = both
>>                  , B = both
>>                  , A = both
>>                  )
>> tt <- tt[, 3:1 ]
>>
>> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >Dear friends,
>> >
>> >Hope you are doing great. I have been searching for a truth table
>> >generator in R, but everything I find has a Python implementation instead.
>> >
>> >Maybe there is in fact a truth table generator in R, but I am not
>> >searching in the right places?
>> >
>> >Any help and/or guidance will be greatly appreciated.
>> >
>> >Best regards,
>> >Paul
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>> >sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
>> >ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>> >PLEASE do read the posting guide
>> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>> >zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
>> >oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t  Sun Mar 13 13:51:04 2022
From: er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t (Erich Subscriptions)
Date: Sun, 13 Mar 2022 13:51:04 +0100
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>
 <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>
Message-ID: <4CB0FAEF-07E9-474A-9C99-E6A51904EB65@neuwirth.priv.at>

I played around and dame up with the following raw idea for truth tables


library(tidyverse)


truth_table_inputs <- 
  function(n){
  if (n==1) return(
    tibble(x1=c(FALSE,TRUE)))
  expand_grid(truth_table_inputs(n-1),
              last_var=c(FALSE,TRUE)) ->
    res
  names(res) <- paste0("x",1:n)
  res              
}


```{r}
eval_truth_table <-
  function(n,fun){
    truth_table_inputs(n) |>
      bind_cols(
    truth_table_inputs(n) |>
      rowwise() |>
      (\(x)do.call(fun,as.list(x)))()
      ) -> res
    names(res)[n+1] <-
      deparse(substitute(fun))
    res
  } 

Example

eval_truth_table(3,function(x1,x2,x3)x1&x2|x3)

If there are more inputs than the function consumes, use dots

eval_truth_table(3,function(x1,x2,...)x1&x2)



> On 13.03.2022, at 10:17, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> There are 2^(2^length(tt)) possible "truth" vectors for the inputs defined in tt. AND-ing all of the inputs only gives one of those possibilities. Some popular named cases for 2 inputs are shown here [1], but it is common to use combinations of !, & and | to specify a particular truth vector. There is also the problem of reverse-engineering such a boolean expeession [2] in simplest form from a given truth vector, but I don't know if anyone has implemented such algorithms in R.
> 
> [1] https://en.wikipedia.org/wiki/Truth_table
> 
> [2] https://en.wikipedia.org/wiki/Karnaugh_maps
> 
> On March 12, 2022 2:17:32 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> ...
>> tt$truth <- tt$A & tt$B & tt$C
>> to evaluate the outcome of expand.grid.
>> 
>> or, as I said,
>> tt$truth <- apply(tt,1, all)
>> which works for any number of columns in tt.
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Sat, Mar 12, 2022 at 2:02 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>>> 
>>> To the end of Jeff's program add
>>> tt$truth <- tt$A & tt$B & tt$C
>>> to evaluate the outcome of expand.grid.
>>> 
>>> Tim
>>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>>> Sent: Saturday, March 12, 2022 12:05 PM
>>> To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <r-help at r-project.org>
>>> Subject: Re: [R] Is there a Truth Table Generator in R?
>>> 
>>> [External Email]
>>> 
>>> both <- c( FALSE, TRUE )
>>> tt <- expand.grid( C = both
>>>                 , B = both
>>>                 , A = both
>>>                 )
>>> tt <- tt[, 3:1 ]
>>> 
>>> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>>>> Dear friends,
>>>> 
>>>> Hope you are doing great. I have been searching for a truth table
>>>> generator in R, but everything I find has a Python implementation instead.
>>>> 
>>>> Maybe there is in fact a truth table generator in R, but I am not
>>>> searching in the right places?
>>>> 
>>>> Any help and/or guidance will be greatly appreciated.
>>>> 
>>>> Best regards,
>>>> Paul
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>>>> an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>>>> sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
>>>> ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>>>> _posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>>> zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
>>>> oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Mar 13 20:33:28 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 13 Mar 2022 19:33:28 +0000 (UTC)
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>
 <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>
Message-ID: <657572012.934065.1647200008858@mail.yahoo.com>

After slogging through lots of posts about a poorly defined request, I am left wondering if I missed the original sender properly explaining what THEY mean by a truth table and what it should look like.
Some here seem to know (or are guessing) that the request is to make all combinations of TRUE and FALSE for N columns in a data.frame and some for an indefinite value of N. Some others may also want to throw in additional columns that reflect a logical AND operation and perhaps others.
So I calmly request someone tell us what the real request is so I can evaluate if anything said here makes much sense in answering the real request.
As I see it, if you have 2 columns, there are four possible combination in what amounts to a 4x2 matrix. If your mailer allows my text to be seen as intended, the following shows combinations starting with F, albeit a table starting with T is equivalent in terms of meaning:
FFFTTFTT

For an N=3 column it gets more rows using binary notation with T=0 and F=1 so 8 rows.
000001010011100101110111

The trend becomes clear that the number of rows is 2**N power so a simple approach (albeit there are other ways shown that may be simpler to code using existing software) is to note the pattern. The first column requires 2**N items alternating every (2**N)/2 times. Meaning if N=5 then you want 32 rows in the result with 16 units of F and then 16 units of T, or vice versa. The R function that does this easily (as part of a loop perhaps) is rep() and sample code (hopefully blank lines keep it from getting wrapped funny is something like this that can be simplified:
N <- 5
rows <- 2**N
TF <- data.frame(index=1:rows)
for (ind in rev(2**(N:1))) {??? TF <- cbind(TF, rep(c(TRUE, FALSE), each=rows/ind, length.out=rows))??}
names(TF) <- c("index", paste("col", 1:N, sep=""))
The above uses rep() repeatedly to produce runs of TRUE and FALSE of decreasing size and keeps concatenating them to an existing data.frame with cbind(). The result is a column with 16 TRUE followed by 16 FALSE then another column with 8 by 8 and repeated again as 8 by 8. The next column alternates in groups of 4 then the next in groups of two and finally alternating in "groups" of 1.
Obviously this can be wrapped up in a function that takes N as an argument and makes an arbitrary N column construct with 2**N rows as described and this may be what is wanted for the main table. I threw this together rapidly and I am sure can improve it so column names are created as appropriate.
For example, rather than cbind, the following would work well too:
colnm <- ...TF[colnm] <-?rep(c(TRUE, FALSE), each=rows/ind, length.out=rows)

But the question is whether this makes what is wanted, or needs something more like columns that represent whether the OR or AND or some other boolean function of N boolean items is TRUE or FALSE.
I repeat, the above analysis does not suggest other supplied solutions are bad or wrong, just a suggestion of how fairly simple functionality in R can do what is wanted. Of course, if something else is wanted, we are all wasting our time answering. I waited a while hoping not to need to or to reply to an actual question I know how to deal with.
-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
To: Bert Gunter <bgunter.4567 at gmail.com>; Ebert, Timothy Aaron <tebert at ufl.edu>
Cc: r-help at r-project.org <r-help at r-project.org>; Paul Bernal <paulbernal07 at gmail.com>
Sent: Sun, Mar 13, 2022 5:17 am
Subject: Re: [R] Is there a Truth Table Generator in R?

There are 2^(2^length(tt)) possible "truth" vectors for the inputs defined in tt. AND-ing all of the inputs only gives one of those possibilities. Some popular named cases for 2 inputs are shown here [1], but it is common to use combinations of !, & and | to specify a particular truth vector. There is also the problem of reverse-engineering such a boolean expeession [2] in simplest form from a given truth vector, but I don't know if anyone has implemented such algorithms in R.

[1] https://en.wikipedia.org/wiki/Truth_table

[2] https://en.wikipedia.org/wiki/Karnaugh_maps

On March 12, 2022 2:17:32 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>...
>tt$truth <- tt$A & tt$B & tt$C
>to evaluate the outcome of expand.grid.
>
>or, as I said,
>tt$truth <- apply(tt,1, all)
>which works for any number of columns in tt.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Sat, Mar 12, 2022 at 2:02 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>>
>> To the end of Jeff's program add
>> tt$truth <- tt$A & tt$B & tt$C
>> to evaluate the outcome of expand.grid.
>>
>> Tim
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>> Sent: Saturday, March 12, 2022 12:05 PM
>> To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <r-help at r-project.org>
>> Subject: Re: [R] Is there a Truth Table Generator in R?
>>
>> [External Email]
>>
>> both <- c( FALSE, TRUE )
>> tt <- expand.grid( C = both
>>? ? ? ? ? ? ? ? ? , B = both
>>? ? ? ? ? ? ? ? ? , A = both
>>? ? ? ? ? ? ? ? ? )
>> tt <- tt[, 3:1 ]
>>
>> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >Dear friends,
>> >
>> >Hope you are doing great. I have been searching for a truth table
>> >generator in R, but everything I find has a Python implementation instead.
>> >
>> >Maybe there is in fact a truth table generator in R, but I am not
>> >searching in the right places?
>> >
>> >Any help and/or guidance will be greatly appreciated.
>> >
>> >Best regards,
>> >Paul
>> >
>> >? ? ? [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>> >sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
>> >ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>> >PLEASE do read the posting guide
>> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>> >zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
>> >oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Mar 14 01:36:33 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 14 Mar 2022 13:36:33 +1300
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <657572012.934065.1647200008858@mail.yahoo.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>
 <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>
 <657572012.934065.1647200008858@mail.yahoo.com>
Message-ID: <CABcYAd+=4YrNcEqi7D3KsfEBr=kh5eHPDb2ua7SaY+T1ctUkJg@mail.gmail.com>

I too have been wondering what "a truth table generator"
meant to the OP.  There are web sites like
https://web.stanford.edu/class/cs103/tools/truth-table-tool/
where you can type in a formula and it will display a
truth table with a column for each variable and a column for the result.
The last propositional problem I worked with had
about a hundred variables, so I am somewhat puzzled about
what use this would be in practice.   (Yes, I know a hundred
variables is a a very small problem these days.)

But then I found
https://www.r-bloggers.com/2021/05/learning-r-creating-truth-tables/

If this is what the OP's after, then it's not about
*using* a truth table generator but about how to *write*
one: how to parse a propositional formula, how to evaluate
one, how to make the grid, &c.


On Mon, 14 Mar 2022 at 08:34, Avi Gross via R-help <r-help at r-project.org>
wrote:

> After slogging through lots of posts about a poorly defined request, I am
> left wondering if I missed the original sender properly explaining what
> THEY mean by a truth table and what it should look like.
> Some here seem to know (or are guessing) that the request is to make all
> combinations of TRUE and FALSE for N columns in a data.frame and some for
> an indefinite value of N. Some others may also want to throw in additional
> columns that reflect a logical AND operation and perhaps others.
> So I calmly request someone tell us what the real request is so I can
> evaluate if anything said here makes much sense in answering the real
> request.
> As I see it, if you have 2 columns, there are four possible combination in
> what amounts to a 4x2 matrix. If your mailer allows my text to be seen as
> intended, the following shows combinations starting with F, albeit a table
> starting with T is equivalent in terms of meaning:
> FFFTTFTT
>
> For an N=3 column it gets more rows using binary notation with T=0 and F=1
> so 8 rows.
> 000001010011100101110111
>
> The trend becomes clear that the number of rows is 2**N power so a simple
> approach (albeit there are other ways shown that may be simpler to code
> using existing software) is to note the pattern. The first column requires
> 2**N items alternating every (2**N)/2 times. Meaning if N=5 then you want
> 32 rows in the result with 16 units of F and then 16 units of T, or vice
> versa. The R function that does this easily (as part of a loop perhaps) is
> rep() and sample code (hopefully blank lines keep it from getting wrapped
> funny is something like this that can be simplified:
> N <- 5
> rows <- 2**N
> TF <- data.frame(index=1:rows)
> for (ind in rev(2**(N:1))) {    TF <- cbind(TF, rep(c(TRUE, FALSE),
> each=rows/ind, length.out=rows))  }
> names(TF) <- c("index", paste("col", 1:N, sep=""))
> The above uses rep() repeatedly to produce runs of TRUE and FALSE of
> decreasing size and keeps concatenating them to an existing data.frame with
> cbind(). The result is a column with 16 TRUE followed by 16 FALSE then
> another column with 8 by 8 and repeated again as 8 by 8. The next column
> alternates in groups of 4 then the next in groups of two and finally
> alternating in "groups" of 1.
> Obviously this can be wrapped up in a function that takes N as an argument
> and makes an arbitrary N column construct with 2**N rows as described and
> this may be what is wanted for the main table. I threw this together
> rapidly and I am sure can improve it so column names are created as
> appropriate.
> For example, rather than cbind, the following would work well too:
> colnm <- ...TF[colnm] <- rep(c(TRUE, FALSE), each=rows/ind,
> length.out=rows)
>
> But the question is whether this makes what is wanted, or needs something
> more like columns that represent whether the OR or AND or some other
> boolean function of N boolean items is TRUE or FALSE.
> I repeat, the above analysis does not suggest other supplied solutions are
> bad or wrong, just a suggestion of how fairly simple functionality in R can
> do what is wanted. Of course, if something else is wanted, we are all
> wasting our time answering. I waited a while hoping not to need to or to
> reply to an actual question I know how to deal with.
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> To: Bert Gunter <bgunter.4567 at gmail.com>; Ebert, Timothy Aaron <
> tebert at ufl.edu>
> Cc: r-help at r-project.org <r-help at r-project.org>; Paul Bernal <
> paulbernal07 at gmail.com>
> Sent: Sun, Mar 13, 2022 5:17 am
> Subject: Re: [R] Is there a Truth Table Generator in R?
>
> There are 2^(2^length(tt)) possible "truth" vectors for the inputs defined
> in tt. AND-ing all of the inputs only gives one of those possibilities.
> Some popular named cases for 2 inputs are shown here [1], but it is common
> to use combinations of !, & and | to specify a particular truth vector.
> There is also the problem of reverse-engineering such a boolean expeession
> [2] in simplest form from a given truth vector, but I don't know if anyone
> has implemented such algorithms in R.
>
> [1] https://en.wikipedia.org/wiki/Truth_table
>
> [2] https://en.wikipedia.org/wiki/Karnaugh_maps
>
> On March 12, 2022 2:17:32 PM PST, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >...
> >tt$truth <- tt$A & tt$B & tt$C
> >to evaluate the outcome of expand.grid.
> >
> >or, as I said,
> >tt$truth <- apply(tt,1, all)
> >which works for any number of columns in tt.
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >On Sat, Mar 12, 2022 at 2:02 PM Ebert,Timothy Aaron <tebert at ufl.edu>
> wrote:
> >>
> >> To the end of Jeff's program add
> >> tt$truth <- tt$A & tt$B & tt$C
> >> to evaluate the outcome of expand.grid.
> >>
> >> Tim
> >>
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
> >> Sent: Saturday, March 12, 2022 12:05 PM
> >> To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <
> r-help at r-project.org>
> >> Subject: Re: [R] Is there a Truth Table Generator in R?
> >>
> >> [External Email]
> >>
> >> both <- c( FALSE, TRUE )
> >> tt <- expand.grid( C = both
> >>                  , B = both
> >>                  , A = both
> >>                  )
> >> tt <- tt[, 3:1 ]
> >>
> >> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >> >Dear friends,
> >> >
> >> >Hope you are doing great. I have been searching for a truth table
> >> >generator in R, but everything I find has a Python implementation
> instead.
> >> >
> >> >Maybe there is in fact a truth table generator in R, but I am not
> >> >searching in the right places?
> >> >
> >> >Any help and/or guidance will be greatly appreciated.
> >> >
> >> >Best regards,
> >> >Paul
> >> >
> >> >      [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >> >sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
> >> >ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
> >> >PLEASE do read the posting guide
> >> >
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >> >zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
> >> >oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
> >> PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Mar 14 02:05:50 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 14 Mar 2022 01:05:50 +0000 (UTC)
Subject: [R] Is there a Truth Table Generator in R?
In-Reply-To: <CABcYAd+=4YrNcEqi7D3KsfEBr=kh5eHPDb2ua7SaY+T1ctUkJg@mail.gmail.com>
References: <CAMOcQfOO3gj791HwBSk6uLuoWfqHUCu55POA1gwm6ijVmYcFGA@mail.gmail.com>
 <3D84C09A-A82A-4685-AA20-471269F4AA46@dcn.davis.ca.us>
 <BN6PR2201MB1553E34B1D13F555C1680B22CF0D9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CAGxFJbQFz0-rzcd+vyE+qMsjmNFCtUxsq3u7FKVJKk1rmmWw6g@mail.gmail.com>
 <2EE04CF6-5ABA-4DA3-A343-91D94B1D262D@dcn.davis.ca.us>
 <657572012.934065.1647200008858@mail.yahoo.com>
 <CABcYAd+=4YrNcEqi7D3KsfEBr=kh5eHPDb2ua7SaY+T1ctUkJg@mail.gmail.com>
Message-ID: <62397071.970815.1647219950836@mail.yahoo.com>

Richard, the second one made some sense to me as a practical application. The eval() of some random string scares me a bit, LOL!
As I see it, that task sounds like it wants you to parse the expression and find all unique alphabetic names in a formula and make a? table (something like a data.frame) using that set of names for the columns. Then you want to evaluate the formula in an environment where the names of the columns are available in an enriched environment. It looks straightforward enough and any of the methods we have described here might make the initial table and set the column names and then afterward add one (or if needed more) columns that implement whatever logical formula you want.
Of course, this being R, the formula could as easily produce a numeric result or other things but cannot contain various kinds of text like f(x) or %in% as those would be picked up and made into named columns! I might prefer a version where the formula is passed in as one argument and the variable names needed are passed as a vector or other list or as dots and then a wider array of arguments can be used, or even a request for multiple evaluations and so on.
BTW, I looked to see how my post looked after being forwarded through you and it is not a pleasure. Multiple lines of say?FF/FT/TF/TT? are collapsed into?FFFTTFTT. My lines of code were not left alone. This darn mailer has an option to always use plain text but when I do that, some complain lines are not wrapped and long lines need to be read by scrolling horizontally.
Can't win!

-----Original Message-----
From: Richard O'Keefe <raoknz at gmail.com>
To: Avi Gross <avigross at verizon.net>
Cc: r-help at r-project.org <r-help at r-project.org>
Sent: Sun, Mar 13, 2022 8:36 pm
Subject: Re: [R] Is there a Truth Table Generator in R?

I too have been wondering what "a truth table generator"meant to the OP.? There are web sites likehttps://web.stanford.edu/class/cs103/tools/truth-table-tool/where you can type in a formula and it will display atruth table with a column for each variable and a column for the result.? The last propositional problem I worked with hadabout a hundred variables, so I am somewhat puzzled aboutwhat use this would be in practice. ? (Yes, I know a hundredvariables is a a very small problem these days.)
But then I foundhttps://www.r-bloggers.com/2021/05/learning-r-creating-truth-tables/
If this is what the OP's after, then it's not about*using* a truth table generator but about how to *write*one: how to parse a propositional formula, how to evaluateone, how to make the grid, &c. 


On Mon, 14 Mar 2022 at 08:34, Avi Gross via R-help <r-help at r-project.org> wrote:

After slogging through lots of posts about a poorly defined request, I am left wondering if I missed the original sender properly explaining what THEY mean by a truth table and what it should look like.
Some here seem to know (or are guessing) that the request is to make all combinations of TRUE and FALSE for N columns in a data.frame and some for an indefinite value of N. Some others may also want to throw in additional columns that reflect a logical AND operation and perhaps others.
So I calmly request someone tell us what the real request is so I can evaluate if anything said here makes much sense in answering the real request.
As I see it, if you have 2 columns, there are four possible combination in what amounts to a 4x2 matrix. If your mailer allows my text to be seen as intended, the following shows combinations starting with F, albeit a table starting with T is equivalent in terms of meaning:
FFFTTFTT

For an N=3 column it gets more rows using binary notation with T=0 and F=1 so 8 rows.
000001010011100101110111

The trend becomes clear that the number of rows is 2**N power so a simple approach (albeit there are other ways shown that may be simpler to code using existing software) is to note the pattern. The first column requires 2**N items alternating every (2**N)/2 times. Meaning if N=5 then you want 32 rows in the result with 16 units of F and then 16 units of T, or vice versa. The R function that does this easily (as part of a loop perhaps) is rep() and sample code (hopefully blank lines keep it from getting wrapped funny is something like this that can be simplified:
N <- 5
rows <- 2**N
TF <- data.frame(index=1:rows)
for (ind in rev(2**(N:1))) {??? TF <- cbind(TF, rep(c(TRUE, FALSE), each=rows/ind, length.out=rows))??}
names(TF) <- c("index", paste("col", 1:N, sep=""))
The above uses rep() repeatedly to produce runs of TRUE and FALSE of decreasing size and keeps concatenating them to an existing data.frame with cbind(). The result is a column with 16 TRUE followed by 16 FALSE then another column with 8 by 8 and repeated again as 8 by 8. The next column alternates in groups of 4 then the next in groups of two and finally alternating in "groups" of 1.
Obviously this can be wrapped up in a function that takes N as an argument and makes an arbitrary N column construct with 2**N rows as described and this may be what is wanted for the main table. I threw this together rapidly and I am sure can improve it so column names are created as appropriate.
For example, rather than cbind, the following would work well too:
colnm <- ...TF[colnm] <-?rep(c(TRUE, FALSE), each=rows/ind, length.out=rows)

But the question is whether this makes what is wanted, or needs something more like columns that represent whether the OR or AND or some other boolean function of N boolean items is TRUE or FALSE.
I repeat, the above analysis does not suggest other supplied solutions are bad or wrong, just a suggestion of how fairly simple functionality in R can do what is wanted. Of course, if something else is wanted, we are all wasting our time answering. I waited a while hoping not to need to or to reply to an actual question I know how to deal with.
-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
To: Bert Gunter <bgunter.4567 at gmail.com>; Ebert, Timothy Aaron <tebert at ufl.edu>
Cc: r-help at r-project.org <r-help at r-project.org>; Paul Bernal <paulbernal07 at gmail.com>
Sent: Sun, Mar 13, 2022 5:17 am
Subject: Re: [R] Is there a Truth Table Generator in R?

There are 2^(2^length(tt)) possible "truth" vectors for the inputs defined in tt. AND-ing all of the inputs only gives one of those possibilities. Some popular named cases for 2 inputs are shown here [1], but it is common to use combinations of !, & and | to specify a particular truth vector. There is also the problem of reverse-engineering such a boolean expeession [2] in simplest form from a given truth vector, but I don't know if anyone has implemented such algorithms in R.

[1] https://en.wikipedia.org/wiki/Truth_table

[2] https://en.wikipedia.org/wiki/Karnaugh_maps

On March 12, 2022 2:17:32 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>...
>tt$truth <- tt$A & tt$B & tt$C
>to evaluate the outcome of expand.grid.
>
>or, as I said,
>tt$truth <- apply(tt,1, all)
>which works for any number of columns in tt.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Sat, Mar 12, 2022 at 2:02 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>>
>> To the end of Jeff's program add
>> tt$truth <- tt$A & tt$B & tt$C
>> to evaluate the outcome of expand.grid.
>>
>> Tim
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
>> Sent: Saturday, March 12, 2022 12:05 PM
>> To: r-help at r-project.org; Paul Bernal <paulbernal07 at gmail.com>; R <r-help at r-project.org>
>> Subject: Re: [R] Is there a Truth Table Generator in R?
>>
>> [External Email]
>>
>> both <- c( FALSE, TRUE )
>> tt <- expand.grid( C = both
>>? ? ? ? ? ? ? ? ? , B = both
>>? ? ? ? ? ? ? ? ? , A = both
>>? ? ? ? ? ? ? ? ? )
>> tt <- tt[, 3:1 ]
>>
>> On March 12, 2022 8:42:28 AM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >Dear friends,
>> >
>> >Hope you are doing great. I have been searching for a truth table
>> >generator in R, but everything I find has a Python implementation instead.
>> >
>> >Maybe there is in fact a truth table generator in R, but I am not
>> >searching in the right places?
>> >
>> >Any help and/or guidance will be greatly appreciated.
>> >
>> >Best regards,
>> >Paul
>> >
>> >? ? ? [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>> >sn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNo
>> >ZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>> >PLEASE do read the posting guide
>> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>> >zsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDN
>> >oZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=h0wdH7OvIxKWgjwFmBIGHvswAKy8VKwyyI3IbB9dKkc&e=
>> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=Cj0cRxlu_GS0ARzvxm-eD27PhuhkgT_azaq1hamiYDmCglHF8_9hGTAkcDNoZtUq&s=tsrpB1zmIQL_wMcn70xPEkvpaisBrAM9k2OQ8kDrebw&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


