From reichmanj at sbcglobal.net  Mon Feb  1 00:59:30 2016
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Sun, 31 Jan 2016 17:59:30 -0600
Subject: [R] Plotting Dates Time Series Data
Message-ID: <002501d15c83$6d4e6360$47eb2a20$@sbcglobal.net>

R-Help Users

 

How do I plot "Dates" on the x-axis of a TS plot 

 

>
mydata<-c(575,125,950,5020,2515,565,135,945,5100,2510,580,140,955,5045,2505,
570,135,1000,5005,2520,580,130,925,5000,2525,585,120,960,5025,2520)

> myts<-ts(mydata,start=as.Date("2015-01-01"))

> myts

Time Series:

Start = 16436 

End = 16465 

Frequency = 1 

 [1]  575  125  950 5020 2515  565  135  945 5100 2510  580  140  955 5045
2505

[16]  570  135 1000 5005 2520  580  130  925 5000 2525  585  120  960 5025
2520

> plot.ts(myts)

 

I'm assuming I have to reformat my start date values.  I just assume R would
do that.


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb  1 06:39:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 31 Jan 2016 21:39:22 -0800
Subject: [R] Plotting Dates Time Series Data
In-Reply-To: <002501d15c83$6d4e6360$47eb2a20$@sbcglobal.net>
References: <002501d15c83$6d4e6360$47eb2a20$@sbcglobal.net>
Message-ID: <63A6D4E4-300F-47E0-AF16-C177CA4E3636@dcn.davis.ca.us>

Try ?xts or ?zoo packages instead of ts.
-- 
Sent from my phone. Please excuse my brevity.

On January 31, 2016 3:59:30 PM PST, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>R-Help Users
>
> 
>
>How do I plot "Dates" on the x-axis of a TS plot 
>
> 
>
>>
>mydata<-c(575,125,950,5020,2515,565,135,945,5100,2510,580,140,955,5045,2505,
>570,135,1000,5005,2520,580,130,925,5000,2525,585,120,960,5025,2520)
>
>> myts<-ts(mydata,start=as.Date("2015-01-01"))
>
>> myts
>
>Time Series:
>
>Start = 16436 
>
>End = 16465 
>
>Frequency = 1 
>
>[1]  575  125  950 5020 2515  565  135  945 5100 2510  580  140  955
>5045
>2505
>
>[16]  570  135 1000 5005 2520  580  130  925 5000 2525  585  120  960
>5025
>2520
>
>> plot.ts(myts)
>
> 
>
>I'm assuming I have to reformat my start date values.  I just assume R
>would
>do that.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb  1 08:03:59 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 1 Feb 2016 07:03:59 +0000
Subject: [R] String Matching
In-Reply-To: <a3fd27d2-8ade-45d0-a368-c519b942a049@me.com>
References: <a3fd27d2-8ade-45d0-a368-c519b942a049@me.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C254@SRVEXCHMBX.precheza.cz>

Hi

Maybe I am completely wrong but do you really need regular expressions?

You say you want to compare first nine characters of id?

> substr(id, 1,9)==cusip
[1] TRUE
>

or the last six?

> substr(id, nchar(id)-6, nchar(id))=="432.rds"
[1] TRUE
>

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Glenn
> Schultz
> Sent: Friday, January 29, 2016 6:02 PM
> To: R Help R
> Subject: [R] String Matching
>
> All,
>
> I have a file named as so 313929BL4FNMA2432.rds  the user may pass
> either the first 9 character or the last six characters.  I need to
> match the remainder of the file name using either the first nine or
> last six.  I have read the help files for Regular Expression as used in
> R and I think what I want to use is glob2rx.
>
> I have worked a minimal example to test my code:
>
> id <- "313929BL4FNMA2432.rds"
> cusip <- "313929BL4"
> poolnumm <- "FNMA2432"
> paste(cusip, ".*", ".rds")
> glob2rx(paste(cusip, ".*", ".rds"), trim.head = TRUE, trim.tail = TRUE)
>
> This returns false which leads me to believe that it is not working
> glob2rx(paste(cusip, ".*", ".rds"), trim.head = TRUE, trim.tail = TRUE)
> == id
>
> I am going to use as follows in the function below - which returns the
> error file not found
>
> MBS_Test <- function(MBS.id = "character"){ MBS <-
> glob2rx(paste(MBS.id, ".*", "//.rds", sep = ""), trim.tail = TRUE)
> MBS.Conn <- gzfile(description = paste(system.file(package =
> "BondLab"), "/BondData/", MBS, sep = ""), open = "rb") MBS <-
> readRDS(MBS.Conn)
> on.exit(close.connection(MBS.Conn))
> return(MBS)
> }
>
> Any help to get me in the right direction is appreciated - Glenn
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bhh at xs4all.nl  Mon Feb  1 09:00:09 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 1 Feb 2016 09:00:09 +0100
Subject: [R] String Matching
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C254@SRVEXCHMBX.precheza.cz>
References: <a3fd27d2-8ade-45d0-a368-c519b942a049@me.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C254@SRVEXCHMBX.precheza.cz>
Message-ID: <2D71C802-5249-46B3-BA82-140DD39CB147@xs4all.nl>


> On 1 Feb 2016, at 08:03, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
> Maybe I am completely wrong but do you really need regular expressions?
> 
> You say you want to compare first nine characters of id?
> 
>> substr(id, 1,9)==cusip
> [1] TRUE
>> 
> 
> or the last six?
> 
>> substr(id, nchar(id)-6, nchar(id))=="432.rds"
> [1] TRUE
>> 
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Glenn
>> Schultz
>> Sent: Friday, January 29, 2016 6:02 PM
>> To: R Help R
>> Subject: [R] String Matching
>> 
>> All,
>> 
>> I have a file named as so 313929BL4FNMA2432.rds  the user may pass
>> either the first 9 character or the last six characters.  I need to
>> match the remainder of the file name using either the first nine or
>> last six.  I have read the help files for Regular Expression as used in
>> R and I think what I want to use is glob2rx.
>> 
>> I have worked a minimal example to test my code:
>> 
>> id <- "313929BL4FNMA2432.rds"
>> cusip <- "313929BL4"
>> poolnumm <- "FNMA2432"
>> paste(cusip, ".*", ".rds")
>> glob2rx(paste(cusip, ".*", ".rds"), trim.head = TRUE, trim.tail = TRUE)
>> 
>> This returns false which leads me to believe that it is not working
>> glob2rx(paste(cusip, ".*", ".rds"), trim.head = TRUE, trim.tail = TRUE)
>> == id
>> 
>> I am going to use as follows in the function below - which returns the
>> error file not found
>> 
>> MBS_Test <- function(MBS.id = "character"){ MBS <-
>> glob2rx(paste(MBS.id, ".*", "//.rds", sep = ""), trim.tail = TRUE)
>> MBS.Conn <- gzfile(description = paste(system.file(package =
>> "BondLab"), "/BondData/", MBS, sep = ""), open = "rb") MBS <-
>> readRDS(MBS.Conn)
>> on.exit(close.connection(MBS.Conn))
>> return(MBS)
>> }
>> 


I don't think you are using (glob) wild characters correctly; where you write .* you likely need *?
In addition why not use paste0, which does not use <space> as separator,  instead of paste?
Finally your poolnumm variable consists of 8 characters and not 6.

If you change your minimal example to this:

paste0(cusip, "*", ".rds")
glob2rx(paste0(cusip, "*", ".rds"))
grepl(glob2rx(paste0(cusip, "*", ".rds")), id)
grepl(glob2rx(paste0("*", poolnumm, ".rds")), id)

you get TRUE twice.

But Petr's solution for the first 9 characters is much simpler.
And for matching the last 6 (8) you'll have to remove the extension first and then use substr (if I understand your problem correctly).

Berend


From thierry.onkelinx at inbo.be  Mon Feb  1 10:56:32 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 1 Feb 2016 10:56:32 +0100
Subject: [R] Multilevel Modeling in R
In-Reply-To: <CAPwiEwWWu4V2NrZ7ema-5dZ2WiiChWzWtwYpEyVrt+0F-zVdHw@mail.gmail.com>
References: <CAPwiEwWWu4V2NrZ7ema-5dZ2WiiChWzWtwYpEyVrt+0F-zVdHw@mail.gmail.com>
Message-ID: <CAJuCY5ypmsTUrD1qZG5cUwCk14G8OKXhvAspf_nWcT9aRv4k6w@mail.gmail.com>

Dear David,

R-sig-mixedmodels is a better mailing list for this kind of question.

1) yes
2) use  (Treatment | Random_Assignment_Block) instead of  (1 |
Random_Assignment_Block)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-01-29 7:10 GMT+01:00 David Roy <dmr02004 at gmail.com>:

> I am conducting a multilevel regression analysis on the effect of an
> intervention on student test results, and am not sure how to implement the
> necessary R code to correctly capture the nested structure.
>
>
>
> The outcome measure for the study is whether a student passed or failed a
> final exam.  The structure of the data is students nested within schools,
> and then schools nested within random assignment blocks.  Treatment (i.e.,
> the intervention) was implemented at the school-level.  The covariates that
> I am planning to use are prior year test scores (this is also a binary
> variable for pass or fail), race, and gender.
>
>
>
> My ideal output would show the impact of the treatment for each of the
> random assignment blocks, and then the weighted average of the impact
> across all of the random assignment blocks.
>
>
>
> Based on my research thus far, it seems like the **lmer** function from the
> **lme4** package would be the best route to go.
>
>
>
> This is the code that I have tried:
>
>
>
>     # Fit multilevel regression with random assignment blocks
>
>     glmer2 <- glmer(Post_Test_Score ~ Treatment +
>
>                                       Pre_Test_Score +
>
>                                       (1 | School) +
>
>                                       (1 | Random_Assignment_Block),
>
>                     data = StudyData,
>
>                     family = binomial("logit"))
>
>
>
> My two questions are the following:
>
>
>
> 1.) Given the nested structure of my data, would the above regression
> output the correct coefficient for the impact of treatment across all
> random assignment blocks?
>
>
>
> 2.) How would I code the interaction effect between Treatment and
> Random_Assignment_Block in order to generate separate impact estimates for
> each of the random assignment blocks?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From eswright at wisc.edu  Mon Feb  1 13:52:24 2016
From: eswright at wisc.edu (Erik Wright)
Date: Mon, 01 Feb 2016 12:52:24 +0000
Subject: [R] as(, "numeric") vs as.numeric()
Message-ID: <40BA1827-82D3-4A11-A02B-6A0C3B4F07AC@wisc.edu>

Hi everyone,

Could someone please explain this R behavior to me:

> typeof(as.numeric(1:10))
[1] "double"
> typeof(as(1:10, "numeric"))
[1] "integer"

I expected "double" in both cases.  In the help for the "as" function it says:

"Methods are pre-defined for coercing any object to one of the basic datatypes. For example, as(x, "numeric") uses the existing as.numeric function."

Thanks,
Erik


From bretschr at xs4all.nl  Mon Feb  1 15:16:29 2016
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Mon, 1 Feb 2016 15:16:29 +0100
Subject: [R] as(, "numeric") vs as.numeric()
In-Reply-To: <40BA1827-82D3-4A11-A02B-6A0C3B4F07AC@wisc.edu>
References: <40BA1827-82D3-4A11-A02B-6A0C3B4F07AC@wisc.edu>
Message-ID: <9CBDE311-16CB-414A-85CF-42526A75ACBC@xs4all.nl>

Dear Erik Wright,


Re:

> Could someone please explain this R behavior to me:
> 
>> typeof(as.numeric(1:10))
> [1] "double"
>> typeof(as(1:10, "numeric"))
> [1] "integer"
> 
> I expected "double" in both cases.  In the help for the "as" function it says:
> 
> "Methods are pre-defined for coercing any object to one of the basic datatypes. For example, as(x, "numeric") uses the existing as.numeric function."


This happens because 1:10 yields only integers, and so can be stored cheap,
whereas as.numeric() actually means: as.double.
The "numeric" in the second line is an unused argument.

Best regards,

Frank
---




Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From jl.iccp at gmail.com  Mon Feb  1 15:29:53 2016
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Mon, 1 Feb 2016 15:29:53 +0100
Subject: [R] updating elements of a list of matrixes without 'for' cycles
Message-ID: <CAAMkPW90iovuj6mgPQ85Bu9mqquQpmK1ZnrNUtp_tjnWGXhG-w@mail.gmail.com>

>
> Date: Sat, 30 Jan 2016 01:03:30 +0000
> From: Matteo Richiardi <
> ??
> Matteo.Richiardi at maths.ox.ac.uk>
> To: r-help at r-project.org
> Subject: [R] updating elements of a list of matrixes without 'for'
>         cycles
> Message-ID:
>         <
> CABSrU1LkOHUZ8M9JW1ju+neMksPriRRTD_0WzOtRLWi3z6dA9w at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> Hi, following an earlier suggestion from the list, I am storing my
> data in a "cube", i.e. an array of matrixes.
> Is there any smarter way of updating the elements of the cube through
> a function, other than the three 'for' cycles in the example below?
> (please note that the example is simplistic; in particular, my
> function is more complicated).
>
> # parameters
> I <- 2L
> J <- 2L
> H <- 2L
>
> # data container: an array of matrixes
> mycube <- array(dim=c(I,J,H))
>
> # initialisation
> for (h in 1:H) {
>   init <- matrix(c(rep(0,J)),nrow=I,ncol=J)
>   mycube[,,h] <- init
> }
>
> # function
> foo = function(i,j,h){
>   mycube[i,j,h] <<- i*j*h
> }
>
> # update
>
> for(h in 1:H){
>   # males:
>   for(i in 1:I)
>     for(j in 1:J)
>       foo(i,j,h)
> }
>
> Thanks a lot for your help. Matteo
>
>
>
?Greetings! Have you tried sapply() on this script??

-- 
?Jue

	[[alternative HTML version deleted]]


From eswright at wisc.edu  Mon Feb  1 16:00:45 2016
From: eswright at wisc.edu (Erik Wright)
Date: Mon, 01 Feb 2016 15:00:45 +0000
Subject: [R] as(, "numeric") vs as.numeric()
In-Reply-To: <9CBDE311-16CB-414A-85CF-42526A75ACBC@xs4all.nl>
References: <40BA1827-82D3-4A11-A02B-6A0C3B4F07AC@wisc.edu>
	<9CBDE311-16CB-414A-85CF-42526A75ACBC@xs4all.nl>
Message-ID: <5227CDFB-BB50-4EE5-BF15-AA517BBB1783@wisc.edu>

Dear Frank,

Thank you for the quick response.

I am familiar with the tradeoffs between integers and doubles.  However, I do not believe this answers my question.

If you look at the help information for the as() function it says:  "as(x, "numeric") uses the existing as.numeric function."  But clearly the result is different in each case.

If the help for as() is correct, then as(1:10, "numeric") should also return doubles, and the second argument is not ignored.

Erik


> On Feb 1, 2016, at 8:16 AM, Franklin Bretschneider <bretschr at xs4all.nl> wrote:
> 
> Dear Erik Wright,
> 
> 
> Re:
> 
>> Could someone please explain this R behavior to me:
>> 
>>> typeof(as.numeric(1:10))
>> [1] "double"
>>> typeof(as(1:10, "numeric"))
>> [1] "integer"
>> 
>> I expected "double" in both cases.  In the help for the "as" function it says:
>> 
>> "Methods are pre-defined for coercing any object to one of the basic datatypes. For example, as(x, "numeric") uses the existing as.numeric function."
> 
> 
> This happens because 1:10 yields only integers, and so can be stored cheap,
> whereas as.numeric() actually means: as.double.
> The "numeric" in the second line is an unused argument.
> 
> Best regards,
> 
> Frank
> ---
> 
> 
> 
> 
> Franklin Bretschneider
> Dept of Biology
> Utrecht University
> bretschr at xs4all.nl
> 
> 
>


From murdoch.duncan at gmail.com  Mon Feb  1 16:33:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 1 Feb 2016 10:33:41 -0500
Subject: [R] as(, "numeric") vs as.numeric()
In-Reply-To: <5227CDFB-BB50-4EE5-BF15-AA517BBB1783@wisc.edu>
References: <40BA1827-82D3-4A11-A02B-6A0C3B4F07AC@wisc.edu>
	<9CBDE311-16CB-414A-85CF-42526A75ACBC@xs4all.nl>
	<5227CDFB-BB50-4EE5-BF15-AA517BBB1783@wisc.edu>
Message-ID: <56AF7AD5.2050506@gmail.com>

On 01/02/2016 10:00 AM, Erik Wright wrote:
> Dear Frank,
>
> Thank you for the quick response.
>
> I am familiar with the tradeoffs between integers and doubles.  However, I do not believe this answers my question.
>
> If you look at the help information for the as() function it says:  "as(x, "numeric") uses the existing as.numeric function."  But clearly the result is different in each case.

Since is.numeric(1:10) and is(1:10, "numeric") are both true, the as() 
function eventually bails out and does nothing.  So yes, as(x, 
"numeric") uses as.numeric() when it needs to coerce, but not when no 
coercion is necessary.   The docs could perhaps add this condition.

Duncan Murdovh
>
> If the help for as() is correct, then as(1:10, "numeric") should also return doubles, and the second argument is not ignored.
>
> Erik
>
>
> > On Feb 1, 2016, at 8:16 AM, Franklin Bretschneider <bretschr at xs4all.nl> wrote:
> >
> > Dear Erik Wright,
> >
> >
> > Re:
> >
> >> Could someone please explain this R behavior to me:
> >>
> >>> typeof(as.numeric(1:10))
> >> [1] "double"
> >>> typeof(as(1:10, "numeric"))
> >> [1] "integer"
> >>
> >> I expected "double" in both cases.  In the help for the "as" function it says:
> >>
> >> "Methods are pre-defined for coercing any object to one of the basic datatypes. For example, as(x, "numeric") uses the existing as.numeric function."
> >
> >
> > This happens because 1:10 yields only integers, and so can be stored cheap,
> > whereas as.numeric() actually means: as.double.
> > The "numeric" in the second line is an unused argument.
> >
> > Best regards,
> >
> > Frank
> > ---
> >
> >
> >
> >
> > Franklin Bretschneider
> > Dept of Biology
> > Utrecht University
> > bretschr at xs4all.nl
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Feb  1 17:38:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 Feb 2016 08:38:14 -0800
Subject: [R] updating elements of a list of matrixes without 'for' cycles
In-Reply-To: <CAAMkPW90iovuj6mgPQ85Bu9mqquQpmK1ZnrNUtp_tjnWGXhG-w@mail.gmail.com>
References: <CAAMkPW90iovuj6mgPQ85Bu9mqquQpmK1ZnrNUtp_tjnWGXhG-w@mail.gmail.com>
Message-ID: <CAGxFJbQ_XT+qhQQVgAj60HCvgUAPNYHA_SXL89tW7qVZduj5Dw@mail.gmail.com>

A perhaps faster approach takes advantage of the column major ordering
of arrays and the expand.grid() function. I say "perhaps" faster,
because "apply" family functions are still actually loops at the R
level.

Anyway, try this (using your little example):

## create a data frame (which is also a list) of i,j,k,index combinations:
z <- expand.grid(i=1:2, j= 1:2, k = 1:2)

## Use do.call() to feed the columns of z to mapply
yourarray <- array(do.call(mapply,c(prod,z)),dim=c(2,2,2))


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 1, 2016 at 6:29 AM, Jue Lin-Ye <jl.iccp at gmail.com> wrote:
>>
>> Date: Sat, 30 Jan 2016 01:03:30 +0000
>> From: Matteo Richiardi <
>>
>> Matteo.Richiardi at maths.ox.ac.uk>
>> To: r-help at r-project.org
>> Subject: [R] updating elements of a list of matrixes without 'for'
>>         cycles
>> Message-ID:
>>         <
>> CABSrU1LkOHUZ8M9JW1ju+neMksPriRRTD_0WzOtRLWi3z6dA9w at mail.gmail.com>
>> Content-Type: text/plain; charset=UTF-8
>>
>> Hi, following an earlier suggestion from the list, I am storing my
>> data in a "cube", i.e. an array of matrixes.
>> Is there any smarter way of updating the elements of the cube through
>> a function, other than the three 'for' cycles in the example below?
>> (please note that the example is simplistic; in particular, my
>> function is more complicated).
>>
>> # parameters
>> I <- 2L
>> J <- 2L
>> H <- 2L
>>
>> # data container: an array of matrixes
>> mycube <- array(dim=c(I,J,H))
>>
>> # initialisation
>> for (h in 1:H) {
>>   init <- matrix(c(rep(0,J)),nrow=I,ncol=J)
>>   mycube[,,h] <- init
>> }
>>
>> # function
>> foo = function(i,j,h){
>>   mycube[i,j,h] <<- i*j*h
>> }
>>
>> # update
>>
>> for(h in 1:H){
>>   # males:
>>   for(i in 1:I)
>>     for(j in 1:J)
>>       foo(i,j,h)
>> }
>>
>> Thanks a lot for your help. Matteo
>>
>>
>>
> Greetings! Have you tried sapply() on this script?
>
> --
> Jue
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Mon Feb  1 19:50:48 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 1 Feb 2016 18:50:48 +0000
Subject: [R] Plotting Dates Time Series Data
Message-ID: <248E6FA047A8C746BA491485764190F53D32DA2B@ESESSMB210.ericsson.se>

This tutorial may help:

http://faculty.washington.edu/ezivot/econ424/Working%20with%20Time%20Series%20Data%20in%20R.pdf

See pages 20 and 27 for your specific issue.


Best,

--
GG




	[[alternative HTML version deleted]]


From francesco.perugini at yahoo.it  Mon Feb  1 18:34:17 2016
From: francesco.perugini at yahoo.it (Francesco Perugini)
Date: Mon, 1 Feb 2016 17:34:17 +0000 (UTC)
Subject: [R] R Sig-Geo group - loop for creating spatial matrix
References: <1152754048.5452209.1454348057898.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1152754048.5452209.1454348057898.JavaMail.yahoo@mail.yahoo.com>

Dear all,I want to create a routine to generate an object for different value of val: 

z <- c(1,2,3,4,5,6,7,8,9)
for (val in z) {
 neighbors.knn <- knn2nb(knearneigh(coord, val, longlat=F),
 row.names=cod_pro,sym=F)
 }
 
However, it seems it does not work. 
How to store the neighbors.knn created matrix befoire being overwritten.
In other words, I want to create multiple spatial matrix, say, for different k neighbours.
Thanks a lot for any help. 
francper


	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Mon Feb  1 20:39:44 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 1 Feb 2016 19:39:44 +0000
Subject: [R] R Sig-Geo group - loop for creating spatial matrix
Message-ID: <248E6FA047A8C746BA491485764190F53D32DA4F@ESESSMB210.ericsson.se>

You may handle that as a list of "nb" objects.

library(spdep)
example(columbus)
coord <- coordinates(columbus)

z <- c(1,2,3,4,5,6,7,8,9)
neighbors.knn <- list()

for (val in z) {
  neighbors.knn <- c(neighbors.knn, list(knn2nb(knearneigh(coord, val, longlat=F), sym=F)))
}

class(neighbours.knn)

class(neighbors.knn[[1]])
plot(neighbors.knn[[1]], coord)

class(neighbors.knn[[2]])
plot(neighbors.knn[[2]], coord)

and so on.

Best,

--
GG


	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Mon Feb  1 21:38:56 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 1 Feb 2016 20:38:56 +0000
Subject: [R] Modelling non-Negative Time Series
Message-ID: <248E6FA047A8C746BA491485764190F53D32DA8E@ESESSMB210.ericsson.se>


https://cran.r-project.org/web/packages/tsintermittent/tsintermittent.pdf


Best,

--
GG



	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Mon Feb  1 23:06:48 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 1 Feb 2016 14:06:48 -0800
Subject: [R] Efficient way to create new column based on comparison with
 another dataframe
In-Reply-To: <CACNwPfYXQN3+z+yO6DPLTEhN1c0SiwJrS==Zn0cte3P1zLay1A@mail.gmail.com>
References: <CACNwPfYXQN3+z+yO6DPLTEhN1c0SiwJrS==Zn0cte3P1zLay1A@mail.gmail.com>
Message-ID: <56AFD6F8.1010007@fredhutch.org>

Hi Gaius,

On 01/29/2016 10:52 AM, Gaius Augustus wrote:
> I have two dataframes. One has chromosome arm information, and the other
> has SNP position information. I am trying to assign each SNP an arm
> identity.  I'd like to create this new column based on comparing it to the
> reference file.
>
> *1) Mapfile (has millions of rows)*
>
> Name    Chr   Position
> S1      1      3000
> S2      1      6000
> S3      1      1000
>
> *2) Chr.Arms   file (has 39 rows)*
>
> Chr    Arm    Start   End
> 1      p      0       5000
> 1      q      5001    10000
>
>
> *R Script that works, but slow:*
> Arms  <- c()
> for (line in 1:nrow(Mapfile)){
>        Arms[line] <- Chr.Arms$Arm[ Mapfile$Chr[line] == Chr.Arms$Chr &
>   Mapfile$Position[line] > Chr.Arms$Start &  Mapfile$Position[line] <
> Chr.Arms$End]}
> }
> Mapfile$Arm <- Arms
>
>
> *Output Table:*
>
> Name   Chr   Position   Arm
> S1      1     3000      p
> S2      1     6000      q
> S3      1     1000      p
>
>
> In words: I want each line to look up the location ( 1) find the right Chr,
> 2) find the line where the START < POSITION < END), then get the ARM
> information and place it in a new column.
>
> This R script works, but surely there is a more time/processing efficient
> way to do it.

You could use the GenomicRanges package for this:

1) Turn 'Mapfile' and 'Chr.Arms' into GRanges objects:

   library(GenomicRanges)
   query <- makeGRangesFromDataFrame(Mapfile, start.field="Position",
                                              end.field="Position")
   subject <- makeGRangesFromDataFrame(Chr.Arms)

2) Call findOverlaps() on them:

   Mapfile2Chr.Arms <- findOverlaps(query, subject, select="arbitrary")

3) Use the result of findOverlaps() to create the column to add to
   'Mapfile':

   Mapfile$Arm <- Chr.Arms$Arm[Mapfile2Chr.Arms]
   Mapfile
   #   Name Chr Position Arm
   # 1   S1   1     3000   p
   # 2   S2   1     6000   q
   # 3   S3   1     1000   p

Should be very fast.

Note that GenomicRanges is a Bioconductor package:

   http://bioconductor.org/packages/GenomicRanges

Make sure you follow the Installation instructions on that page.

Cheers,
H.

>
> Thanks in advance for any help,
> Gaius
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Mon Feb  1 23:18:54 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 1 Feb 2016 14:18:54 -0800
Subject: [R] as(, "numeric") vs as.numeric()
In-Reply-To: <56AF7AD5.2050506@gmail.com>
References: <40BA1827-82D3-4A11-A02B-6A0C3B4F07AC@wisc.edu>
	<9CBDE311-16CB-414A-85CF-42526A75ACBC@xs4all.nl>
	<5227CDFB-BB50-4EE5-BF15-AA517BBB1783@wisc.edu>
	<56AF7AD5.2050506@gmail.com>
Message-ID: <56AFD9CE.2050905@fredhutch.org>

On 02/01/2016 07:33 AM, Duncan Murdoch wrote:
> On 01/02/2016 10:00 AM, Erik Wright wrote:
>> Dear Frank,
>>
>> Thank you for the quick response.
>>
>> I am familiar with the tradeoffs between integers and doubles.
>> However, I do not believe this answers my question.
>>
>> If you look at the help information for the as() function it says:
>> "as(x, "numeric") uses the existing as.numeric function."  But clearly
>> the result is different in each case.
>
> Since is.numeric(1:10) and is(1:10, "numeric") are both true, the as()
> function eventually bails out and does nothing.

But it should. Because as() has an extra argument 'strict' that is TRUE
by default. From the man page for as():

   strict: logical flag.  If ?TRUE?, the returned object must be
           strictly from the target class (unless that class is a
           virtual class, in which case the object will be from the
           closest actual class, in particular the original object, if
           that class extends the virtual class directly).

           If ?strict = FALSE?, any simple extension of the target class
           will be returned, without further change.  A simple extension
           is, roughly, one that just adds slots to an existing class.

So the current behavior is clearly a bug, has been reported several
times, and is known from the R-core folks:

   https://stat.ethz.ch/pipermail/r-devel/2015-December/072079.html

FWIW this bug is actually related to this other bug:

   x <- 1:10
   class(x)
   # [1] "integer"

   class(x) <- "numeric"
   class(x)
   # [1] "integer"

Cheers,
H.


>  So yes, as(x,
> "numeric") uses as.numeric() when it needs to coerce, but not when no
> coercion is necessary.   The docs could perhaps add this condition.
>
> Duncan Murdovh
>>
>> If the help for as() is correct, then as(1:10, "numeric") should also
>> return doubles, and the second argument is not ignored.
>>
>> Erik
>>
>>
>> > On Feb 1, 2016, at 8:16 AM, Franklin Bretschneider
>> <bretschr at xs4all.nl> wrote:
>> >
>> > Dear Erik Wright,
>> >
>> >
>> > Re:
>> >
>> >> Could someone please explain this R behavior to me:
>> >>
>> >>> typeof(as.numeric(1:10))
>> >> [1] "double"
>> >>> typeof(as(1:10, "numeric"))
>> >> [1] "integer"
>> >>
>> >> I expected "double" in both cases.  In the help for the "as"
>> function it says:
>> >>
>> >> "Methods are pre-defined for coercing any object to one of the
>> basic datatypes. For example, as(x, "numeric") uses the existing
>> as.numeric function."
>> >
>> >
>> > This happens because 1:10 yields only integers, and so can be stored
>> cheap,
>> > whereas as.numeric() actually means: as.double.
>> > The "numeric" in the second line is an unused argument.
>> >
>> > Best regards,
>> >
>> > Frank
>> > ---
>> >
>> >
>> >
>> >
>> > Franklin Bretschneider
>> > Dept of Biology
>> > Utrecht University
>> > bretschr at xs4all.nl
>> >
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From p_connolly at slingshot.co.nz  Tue Feb  2 00:06:43 2016
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Tue, 02 Feb 2016 12:06:43 +1300
Subject: [R] How to read ./configure messages
Message-ID: <5084d814783f05b5271e88e062fbfb22@slingshot.co.nz>


I've installed R from the tgz file since about R-0.9.x following the
INSTALL instructions and have always succeeded using rpm-based OSes.
With each new OS, that involved installing various additional packages
before the configure script would complete.  Figuring out which
packages were required usually involved searching for rpms that
supplied missing .so or .h files, dev packages or something else I
could figure out.

I'm now trying to do the same with LinuxMint 17.2 but I got stuck when
this message came up:

    checking for main in -ltermlib... no
    checking for rl_callback_read_char in -lreadline... no
    checking for history_truncate_file... no
    configure: error: --with-readline=yes (default) and headers/libs are 
not available

Near the bottom of the log file it shows this:

    configure:6747: gcc -E -I/usr/local/include conftest.c
    configure:6747: $? = 0
    configure:6761: gcc -E -I/usr/local/include conftest.c
    conftest.c:17:28: fatal error: ac_nonexistent.h: No such file or 
directory
     #include <ac_nonexistent.h>
                                ^
    compilation terminated.
    configure:6761: $? = 1
    configure: failed program was:
    | /* confdefs.h */
    | #define PACKAGE_NAME "R"

So I'm assuming that's behind the failure.  Searching shows the same
problem shows up in all sorts of places for decades, notably cygwin
users.  But I didn't see anything that would help to work out what is
missing.

Ideas greatly appreciated.


best
Patrick


From dbastos at toledo.com  Mon Feb  1 20:56:01 2016
From: dbastos at toledo.com (Daniel Bastos)
Date: Mon, 01 Feb 2016 17:56:01 -0200
Subject: [R] on specifying an encoding for plot's main-argument
In-Reply-To: <56AC188C.4050609@gmail.com> (Duncan Murdoch's message of "Fri,
	29 Jan 2016 20:57:32 -0500")
References: <0q37tgz9d5.fsf@toledo.com> <56AC188C.4050609@gmail.com>
Message-ID: <0qk2mo2oj2.fsf@toledo.com>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 29/01/2016 10:35 AM, Daniel Bastos wrote:
>> Here's how I plot a graph.
>>
>>    plot(c(1,2,3), main = "graph ?")
>>
>> The main-string has a UTF-8 character "?".  I believe I'm using the
>> windows device.  It opens up on my screen.  (The window says ``R
>> Graphics: Device 2 (ACTIVE)''.)  How can I tell it to use my encoding of
>> choice?
>
> As far as I know that's impossible.  R uses the system encoding, and I
> don't think any Windows versions use UTF-8 code pages.  They use
> UTF-16 for wide characters, and some 8 bit encoding for byte-sized
> characters. R will use whatever 8 bit code page Windows chooses.

You seem to be correct.  Here's what Microsoft has to say.  ``[...]
UTF-16 [...] is the most common encoding of Unicode and the one used for
native Unicode encoding on Windows operating systems.''[1] 

They also claim that ``[w]hile Unicode-enabled functions in Windows use
UTF-16, it is also possible to work with data encoded in UTF-8 or UTF-7,
which are supported in Windows as multibyte character set code
pages.''[1]

But I couldn't verify the claim.

The documentation of setlocale[2] says the ``set of available locale
names, languages, country/region codes, and code pages includes all
those supported by the Windows NLS API except code pages that require
more than two bytes per character, such as UTF-7 and UTF-8. If you
provide a code page value of UTF-7 or UTF-8, setlocale will fail,
returning NULL.''[2]

That seems to be correct as per the following C code.

  printf("locale: %s\n", setlocale(LC_ALL, "UTF-8"));

And [3] makes me think that _wsetlocale behaves the same way:
``_wsetlocale [...] is a wide-character version of setlocale; the
arguments and return values of _wsetlocale are wide-character strings.''
The following program seems to confirm it.

int main(int argc, char *argv[]) {
  printf("locale: %s\n", _wsetlocale(LC_ALL, (const wchar_t *) "UTF-8"));
  return 0;
}

[...]

(*) A workaround

Since R comes with iconv(), the following might be a safe way to
translate UTF-8 into the current system locale, displaying correctly
plot's titles on Windows systems.

  iconv("utf8-string", from="UTF-8", 
     to=localeToCharset(Sys.getlocale("LC_CTYPE")))

(*) References

[1] MSDN Unicode
https://msdn.microsoft.com/en-us/library/windows/desktop/dd374081(v=vs.85).aspx

[2] MSDN setlocale
https://msdn.microsoft.com/en-us/library/x99tb11d.aspx

[3] MSDN Locales and Code Pages
https://msdn.microsoft.com/en-us/library/8w60z792.aspx


From ddorchuck at gmail.com  Mon Feb  1 21:36:36 2016
From: ddorchuck at gmail.com (Daniel Dorchuck)
Date: Mon, 1 Feb 2016 15:36:36 -0500
Subject: [R] Panel Data Help
Message-ID: <CALgjPRLVuTmQxQyUTh17eSGcaojKEZT-zc9hya_9QjpL6uFPNw@mail.gmail.com>

Hi,

I'm currently working on an econometrics project on banking and looking to
merge a dataframe of bank specific data with dataframes of macro variables.
I am then going to transform the data set into a plm dataframe using the plm
package. The bank specific observations are indexed across time while the
macro ones are indexed only across time. Is there a way to merge the two so
I can use both in my panel regression?

Best,
Dan

	[[alternative HTML version deleted]]


From klerer at sxmail.de  Tue Feb  2 01:00:20 2016
From: klerer at sxmail.de (klerer at sxmail.de)
Date: Tue, 2 Feb 2016 01:00:20 +0100
Subject: [R] amending R+dependencies
Message-ID: <51f092248fbf5ffb49ecd10989fd3d6a@www.sxmail.de>

Dear all,[a] after I have virtually given up on gearing up my R (v. 3.0.2; GUI: rkward; on last Linux Kubuntu LTS) for properly installing useful packages containing functions that were not delivered with base R, amendment of R through getting packages from CRAN became the only viable way to obtain functionality in R for me so far.[b] By the time I used my GUI for supplementary packages' installation, dependencies were treated by that GUI's updater and it occurred that packages were uninstallable due to packages not suitable for that very R version.[c] Now I wonder whether there were any (massive?) impending problems when one would eventually proceed to extract corresponding package archives upon download into the corresponding file folder subsequently using R, say in its interactive mode via the GUI of choice. I am referring to that kind of problem(s) which the R console (interactive mode) could throw after me, I have to be sufficiently precise...Best regards,Markus Hofstetter


	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Tue Feb  2 06:30:32 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 1 Feb 2016 21:30:32 -0800
Subject: [R] How to read ./configure messages
In-Reply-To: <5084d814783f05b5271e88e062fbfb22@slingshot.co.nz>
References: <5084d814783f05b5271e88e062fbfb22@slingshot.co.nz>
Message-ID: <CA+hbrhVGyMxxXpn-VMps_pMUaWDJQwV0a1s4jncgr1Es3Qyiqg@mail.gmail.com>

I am not overly familar with Mint, but you need the "development
version" of the readline library. If you have a GUI package manager
installed, open it and search for readline. You should see a version
that ends with -dev or -devel; you need to install that.

HTH,

Peter

On Mon, Feb 1, 2016 at 3:06 PM, p_connolly <p_connolly at slingshot.co.nz> wrote:
>
> I've installed R from the tgz file since about R-0.9.x following the
> INSTALL instructions and have always succeeded using rpm-based OSes.
> With each new OS, that involved installing various additional packages
> before the configure script would complete.  Figuring out which
> packages were required usually involved searching for rpms that
> supplied missing .so or .h files, dev packages or something else I
> could figure out.
>
> I'm now trying to do the same with LinuxMint 17.2 but I got stuck when
> this message came up:
>
>    checking for main in -ltermlib... no
>    checking for rl_callback_read_char in -lreadline... no
>    checking for history_truncate_file... no
>    configure: error: --with-readline=yes (default) and headers/libs are not
> available
>
> Near the bottom of the log file it shows this:
>
>    configure:6747: gcc -E -I/usr/local/include conftest.c
>    configure:6747: $? = 0
>    configure:6761: gcc -E -I/usr/local/include conftest.c
>    conftest.c:17:28: fatal error: ac_nonexistent.h: No such file or
> directory
>     #include <ac_nonexistent.h>
>                                ^
>    compilation terminated.
>    configure:6761: $? = 1
>    configure: failed program was:
>    | /* confdefs.h */
>    | #define PACKAGE_NAME "R"
>
> So I'm assuming that's behind the failure.  Searching shows the same
> problem shows up in all sorts of places for decades, notably cygwin
> users.  But I didn't see anything that would help to work out what is
> missing.
>
> Ideas greatly appreciated.
>
>
> best
> Patrick
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Feb  2 07:15:21 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 01 Feb 2016 22:15:21 -0800
Subject: [R] Panel Data Help
In-Reply-To: <CALgjPRLVuTmQxQyUTh17eSGcaojKEZT-zc9hya_9QjpL6uFPNw@mail.gmail.com>
References: <CALgjPRLVuTmQxQyUTh17eSGcaojKEZT-zc9hya_9QjpL6uFPNw@mail.gmail.com>
Message-ID: <0D8BB2AA-40BE-4C62-B752-77B2F516509B@dcn.davis.ca.us>

I am going to go out on a limb and say that the answer to your question is "Yes".

However,  I cannot decipher specifics from your description.  If you want a more useful answer you need to follow the advice in the Posting Guide mentioned in the footer  (including posting in plain text rather than HTML, and providing some sample data). You will also benefit from reading [1], with particular attention to using the dput function. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
-- 
Sent from my phone. Please excuse my brevity.

On February 1, 2016 12:36:36 PM PST, Daniel Dorchuck <ddorchuck at gmail.com> wrote:
>Hi,
>
>I'm currently working on an econometrics project on banking and looking
>to
>merge a dataframe of bank specific data with dataframes of macro
>variables.
>I am then going to transform the data set into a plm dataframe using
>the plm
>package. The bank specific observations are indexed across time while
>the
>macro ones are indexed only across time. Is there a way to merge the
>two so
>I can use both in my panel regression?
>
>Best,
>Dan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bennfine at gmail.com  Tue Feb  2 06:16:59 2016
From: bennfine at gmail.com (Benn Fine)
Date: Tue, 2 Feb 2016 00:16:59 -0500
Subject: [R] open script from web
Message-ID: <CALghxgTbvTk-NE9iUNz+J07k8q8PfL3KL8FoCPoyweEahFPf1w@mail.gmail.com>

Hello

In R, is it possible to load a script file into the editor via a web
address?

That is, I have a script file I want people to grab located at
http://www.foo.com/bar.R
and want to do something like file.edit("http://www.foo.com/bar.R"). But
that doesn't seem to work.

thanks

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Feb  2 07:38:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 01 Feb 2016 22:38:54 -0800
Subject: [R] open script from web
In-Reply-To: <CALghxgTbvTk-NE9iUNz+J07k8q8PfL3KL8FoCPoyweEahFPf1w@mail.gmail.com>
References: <CALghxgTbvTk-NE9iUNz+J07k8q8PfL3KL8FoCPoyweEahFPf1w@mail.gmail.com>
Message-ID: <C2BF1D87-67DB-4062-AADA-8AC38F6D3BA7@dcn.davis.ca.us>

In almost all cases the answer is No.

Some Web servers support WebDAV, but standard HTTP does not work that way. Has nothing to do with R.
-- 
Sent from my phone. Please excuse my brevity.

On February 1, 2016 9:16:59 PM PST, Benn Fine <bennfine at gmail.com> wrote:
>Hello
>
>In R, is it possible to load a script file into the editor via a web
>address?
>
>That is, I have a script file I want people to grab located at
>http://www.foo.com/bar.R
>and want to do something like file.edit("http://www.foo.com/bar.R").
>But
>that doesn't seem to work.
>
>thanks
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Feb  2 07:42:05 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 2 Feb 2016 07:42:05 +0100
Subject: [R] open script from web
In-Reply-To: <CALghxgTbvTk-NE9iUNz+J07k8q8PfL3KL8FoCPoyweEahFPf1w@mail.gmail.com>
References: <CALghxgTbvTk-NE9iUNz+J07k8q8PfL3KL8FoCPoyweEahFPf1w@mail.gmail.com>
Message-ID: <56B04FBD.6040809@statistik.tu-dortmund.de>

Well, two steps: download.file() and then file.edit().

Best,
Uwe Ligges



On 02.02.2016 06:16, Benn Fine wrote:
> Hello
>
> In R, is it possible to load a script file into the editor via a web
> address?
>
> That is, I have a script file I want people to grab located at
> http://www.foo.com/bar.R
> and want to do something like file.edit("http://www.foo.com/bar.R"). But
> that doesn't seem to work.
>
> thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Feb  2 07:44:02 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 2 Feb 2016 07:44:02 +0100
Subject: [R] amending R+dependencies
In-Reply-To: <51f092248fbf5ffb49ecd10989fd3d6a@www.sxmail.de>
References: <51f092248fbf5ffb49ecd10989fd3d6a@www.sxmail.de>
Message-ID: <56B05032.5030905@statistik.tu-dortmund.de>

Install a recent version of R such as R-3.2.3.

R-3.0.2 is unsupported.


Best,
Uwe Ligges




On 02.02.2016 01:00, klerer at sxmail.de wrote:
> Dear all,[a] after I have virtually given up on gearing up my R (v. 3.0.2; GUI: rkward; on last Linux Kubuntu LTS) for properly installing useful packages containing functions that were not delivered with base R, amendment of R through getting packages from CRAN became the only viable way to obtain functionality in R for me so far.[b] By the time I used my GUI for supplementary packages' installation, dependencies were treated by that GUI's updater and it occurred that packages were uninstallable due to packages not suitable for that very R version.[c] Now I wonder whether there were any (massive?) impending problems when one would eventually proceed to extract corresponding package archives upon download into the corresponding file folder subsequently using R, say in its interactive mode via the GUI of choice. I am referring to that kind of problem(s) which the R console (interactive mode) could throw after me, I have to be sufficiently precise...Best regards,Markus Hofstet!
>   ter
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From giorgio.garziano at ericsson.com  Tue Feb  2 09:48:37 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 2 Feb 2016 08:48:37 +0000
Subject: [R] R Sig-Geo group - loop for creating spatial matrix
In-Reply-To: <723465948.286217.1454401459757.JavaMail.yahoo@mail.yahoo.com>
References: <248E6FA047A8C746BA491485764190F53D32DA4F@ESESSMB210.ericsson.se>
	<723465948.286217.1454401459757.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <248E6FA047A8C746BA491485764190F53D32DB46@ESESSMB210.ericsson.se>

Dear Francesco,

from that point ahead, you have to handle a list of ?nb? objects.
I used class() in order to show you what the list is made of.

The R code outlined in your reply may follow a pattern like this (showing an option):

for (val in z) {
    dlwknn.B <- nb2listw(neighbors.knn[[val]], style="B", zero.policy=TRUE)
    globalG.test(CRIME, dlwknn.B, zero.policy=F)
}


You may want to collect the results of the GlobalG.test in a list as well, the

help(globalG.test) provides an example at the bottom of its R help page.

To further point out that R language makes possible to implement functions call
over a list without specifying ?for? loops. Some examples at:

http://www.r-bloggers.com/using-apply-sapply-lapply-in-r/


The R-SIG-Geo mailing list is reachable at:

https://stat.ethz.ch/pipermail/r-sig-geo/

if that was your original intention.


Best,

--
GG

From: Francesco Perugini [mailto:francesco.perugini at yahoo.it]
Sent: marted? 2 febbraio 2016 09:24
To: Giorgio Garziano
Subject: Re: [R] R Sig-Geo group - loop for creating spatial matrix

Dear Giorgio,
thanks a lot for your reply.
From here now,  I want to implement the Global G test for spatial autocorrelation for the generated different matrix and plot the Global G statistic (on the y-axes) against different val (on the x-axis). How should the code be? I've tried the following:

# Global G
dlwknn.B <- nb2listw(class(neighbors.knn[[val]]), style="B", zero.policy=TRUE)
globalG.test(CRIME, dlwknn.B, zero.policy=F)

but it is not working. Thanks a lot for your help..
franc.per


________________________________
Da: Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>>
A: "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Cc: "francesco.perugini at yahoo.it<mailto:francesco.perugini at yahoo.it>" <francesco.perugini at yahoo.it<mailto:francesco.perugini at yahoo.it>>
Inviato: Luned? 1 Febbraio 2016 20:39
Oggetto: Re: [R] R Sig-Geo group - loop for creating spatial matrix

You may handle that as a list of ?nb? objects.

library(spdep)
example(columbus)
coord <- coordinates(columbus)

z <- c(1,2,3,4,5,6,7,8,9)
neighbors.knn <- list()

for (val in z) {
  neighbors.knn <- c(neighbors.knn, list(knn2nb(knearneigh(coord, val, longlat=F), sym=F)))
}

class(neighbours.knn)

class(neighbors.knn[[1]])
plot(neighbors.knn[[1]], coord)

class(neighbors.knn[[2]])
plot(neighbors.knn[[2]], coord)

and so on.

Best,

--
GG



	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Tue Feb  2 10:04:26 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Tue, 2 Feb 2016 22:04:26 +1300
Subject: [R] How to read ./configure messages
In-Reply-To: <CA+hbrhVGyMxxXpn-VMps_pMUaWDJQwV0a1s4jncgr1Es3Qyiqg@mail.gmail.com>
References: <5084d814783f05b5271e88e062fbfb22@slingshot.co.nz>
	<CA+hbrhVGyMxxXpn-VMps_pMUaWDJQwV0a1s4jncgr1Es3Qyiqg@mail.gmail.com>
Message-ID: <20160202090426.GA3887@slingshot.co.nz>

Thanks Peter.  That certainly got me past that one,  (Few more to go)


On Mon, 01-Feb-2016 at 09:30PM -0800, Peter Langfelder wrote:

|> I am not overly familar with Mint, but you need the "development
|> version" of the readline library. If you have a GUI package manager
|> installed, open it and search for readline. You should see a version
|> that ends with -dev or -devel; you need to install that.
|> 
|> HTH,
|> 
|> Peter
|> 
|> On Mon, Feb 1, 2016 at 3:06 PM, p_connolly <p_connolly at slingshot.co.nz> wrote:
|> >
|> > I've installed R from the tgz file since about R-0.9.x following the
|> > INSTALL instructions and have always succeeded using rpm-based OSes.
|> > With each new OS, that involved installing various additional packages
|> > before the configure script would complete.  Figuring out which
|> > packages were required usually involved searching for rpms that
|> > supplied missing .so or .h files, dev packages or something else I
|> > could figure out.
|> >
|> > I'm now trying to do the same with LinuxMint 17.2 but I got stuck when
|> > this message came up:
|> >
|> >    checking for main in -ltermlib... no
|> >    checking for rl_callback_read_char in -lreadline... no
|> >    checking for history_truncate_file... no
|> >    configure: error: --with-readline=yes (default) and headers/libs are not
|> > available
|> >
|> > Near the bottom of the log file it shows this:
|> >
|> >    configure:6747: gcc -E -I/usr/local/include conftest.c
|> >    configure:6747: $? = 0
|> >    configure:6761: gcc -E -I/usr/local/include conftest.c
|> >    conftest.c:17:28: fatal error: ac_nonexistent.h: No such file or
|> > directory
|> >     #include <ac_nonexistent.h>
|> >                                ^
|> >    compilation terminated.
|> >    configure:6761: $? = 1
|> >    configure: failed program was:
|> >    | /* confdefs.h */
|> >    | #define PACKAGE_NAME "R"
|> >
|> > So I'm assuming that's behind the failure.  Searching shows the same
|> > problem shows up in all sorts of places for decades, notably cygwin
|> > users.  But I didn't see anything that would help to work out what is
|> > missing.
|> >
|> > Ideas greatly appreciated.
|> >
|> >
|> > best
|> > Patrick
|> >
|> > ______________________________________________
|> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> > https://stat.ethz.ch/mailman/listinfo/r-help
|> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> > and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From petr.pikal at precheza.cz  Tue Feb  2 12:35:42 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 2 Feb 2016 11:35:42 +0000
Subject: [R] fancy linear model and grouping
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>

Dear all

I have data like this

> dput(temp)

temp <- structure(list(X1 = c(93, 82, NA, 93, 93, 79, 79, 93, 93, 85,
82, 93, 87, 93, 92, NA, 87, 93, 93, 93, 74, 77, 87, 93, 82, 87,
75, 82, 93, 92, 68, 93, 93, 73, NA, 85, 81, 79, 75, 87, 93, NA,
87, 87, 85, 92, 87, 92, 93, 87, 87, NA, 69, 87, 93, 87, 93, 87,
82, 79, 87, 93, 87, 80, 87, 87, 87, 92, 93, 69, 76, 87, 82, 93,
82, NA, 54, 87, 77, 73, 93, 82, 73, 93, 92, 82, 77, 93, 87, 75,
87, 87, 87, 60, 92, 87, 87, NA, 77, 78), X2 = c(224, 624, NA,
224, 224, 642, 642, 224, 224, 599, 622, 224, 239, 224, 225, NA,
239, 224, 224, 224, 688, 657, 239, 224, 624, 239, 672, 254, 224,
225, 499, 224, 224, 692, NA, 599, 627, 642, 677, 239, 224, NA,
239, 239, NA, 375, 239, 375, 224, 239, 239, NA, 299, 239, 224,
239, 224, 239, 621, 642, 239, 224, 239, 638, 239, 239, 239, 225,
224, 299, 672, 239, 618, 224, 620, NA, 626, 239, 657, 693, 224,
624, 693, 224, 225, 621, 657, 224, 239, 673, 239, 239, 239, 569,
224, 239, 239, NA, 657, 651)), .Names = c("X1", "X2"), row.names = c(NA,
-100L), class = "data.frame")
>

You can see there are 3 distinct linear relationships of those 2 variables.

plot(1/temp[,1], temp[,2])

Is there any simple way how to evaluate such data without grouping variable? I know that in case I have proper grouping variable I can evaluate it with lme and get intercepts and/or slopes.

My question is:

Does anybody know about a way/package/function which can give me appropriate grouping of such data or which can give me separate slope/intercept for each set.

I hope I expressed my problem clearly.

Best regards
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From amelia_marsh08 at yahoo.com  Tue Feb  2 13:03:02 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Tue, 2 Feb 2016 12:03:02 +0000 (UTC)
Subject: [R] Improvement in Process time
References: <2054761393.626759.1454414582950.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2054761393.626759.1454414582950.JavaMail.yahoo@mail.yahoo.com>

Dear R forum,

I am running a Particular process 1000 times for different rates. Each time the result of the process is getting stored (appended) in a data.frame. However, the process is taking unsual time at times more than 2 hours. When I had tried to find out the reason for such a long process time, I have realized that writing a data.frame is consuming lot of time. 

Here is an extract of my code

# ---------------------------------------------------------------

tx_discounted <- read.csv('transaction_discounted.csv', na.strings='') 
tx_discounted$id <- as.character(tx_discounted$id) 

n             <- max(unique(simulated_exchange$id)) 

result	 <- NULL 
current  <- 1 
rcount   <- 0 
current1 <- 1 
rcount1  <- 0 
current2 <- 1 
rcount2  <- 0 
for (env in 0:n) { 

if (rcount == 0) rcount <- nrow(subset(simulated_interest, id==env)) 
temp		 <- current+rcount-1 
env_rates  <- simulated_interest[current:temp,] 
env_rates  <- env_rates[order(env_rates$curve, env_rates$day_count), ] 
if (rcount1 == 0)	rcount1 <- nrow(subset(simulated_exchange, id==env)) 
temp		 <- current1+rcount1-1 
exch_rates <- simulated_exchange[current1:temp,] 
if (rcount2 == 0)	rcount2 <- nrow(subset(simulated_instruments, id==env)) 
temp		 <- current2+rcount2-1 
instr_rates<- simulated_instruments[current2:temp,] 
current	 <- current+rcount 
current1	 <- current1+rcount1 
current2	 <- current2+rcount2 

curve       <- daply(env_rates, 'curve', function(x) { 
return(approxfun(x$day_count, x$rate, rule = 2)) 
}) 

# ____________________________________________________

## Actual time consumtion begins from following part

# ____________________________________________________

result <- rbind(result, ddply(tx_discounted, 'id', function(x) { 

if(!is.na(x$curve) && x$curve != '') { 
intrate <- curve[[x$curve]](x$maturity_period) 
} else { 
intrate <- subset(instr_rates, instrument==as.character(x$instrument))$value 
} 

cross_rate <- subset(exch_rates, key==paste(x$currency, x$currency_base, sep='_'))$rate 
mtm_bc     <- cross_rate * (x$amount/(1+((intrate/100)*(x$maturity_period/x$intbasis)))) 

return(data.frame(env=env, id=x$id, instrument=x$instrument, currency=x$currency, 
intrate = intrate, maturity_period = x$maturity_period,  intbasis = x$intbasis, cross_rate = cross_rate, amount=x$amount, mtm_bc=mtm_bc)) 
})) 
} 


# ---------------------------------------------------------------------------

Unfortuantely I can't share the input files. Is there any way I can improve the process time.

Regards and thanking in advance

Amelia


From ggrothendieck at gmail.com  Tue Feb  2 13:19:57 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 2 Feb 2016 07:19:57 -0500
Subject: [R] fancy linear model and grouping
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
Message-ID: <CAP01uRmdyAFnfPNh109pKeqoc4Zj5T_pgt3cXexm8XnCjfnN6w@mail.gmail.com>

Try the mclust package:

library(mclust)
temp.na <- na.omit(temp)
fm <- Mclust(temp.na)
g <- fm$classification
plot(temp.na, pch = g, col = g)



On Tue, Feb 2, 2016 at 6:35 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I have data like this
>
>> dput(temp)
>
> temp <- structure(list(X1 = c(93, 82, NA, 93, 93, 79, 79, 93, 93, 85,
> 82, 93, 87, 93, 92, NA, 87, 93, 93, 93, 74, 77, 87, 93, 82, 87,
> 75, 82, 93, 92, 68, 93, 93, 73, NA, 85, 81, 79, 75, 87, 93, NA,
> 87, 87, 85, 92, 87, 92, 93, 87, 87, NA, 69, 87, 93, 87, 93, 87,
> 82, 79, 87, 93, 87, 80, 87, 87, 87, 92, 93, 69, 76, 87, 82, 93,
> 82, NA, 54, 87, 77, 73, 93, 82, 73, 93, 92, 82, 77, 93, 87, 75,
> 87, 87, 87, 60, 92, 87, 87, NA, 77, 78), X2 = c(224, 624, NA,
> 224, 224, 642, 642, 224, 224, 599, 622, 224, 239, 224, 225, NA,
> 239, 224, 224, 224, 688, 657, 239, 224, 624, 239, 672, 254, 224,
> 225, 499, 224, 224, 692, NA, 599, 627, 642, 677, 239, 224, NA,
> 239, 239, NA, 375, 239, 375, 224, 239, 239, NA, 299, 239, 224,
> 239, 224, 239, 621, 642, 239, 224, 239, 638, 239, 239, 239, 225,
> 224, 299, 672, 239, 618, 224, 620, NA, 626, 239, 657, 693, 224,
> 624, 693, 224, 225, 621, 657, 224, 239, 673, 239, 239, 239, 569,
> 224, 239, 239, NA, 657, 651)), .Names = c("X1", "X2"), row.names = c(NA,
> -100L), class = "data.frame")
>>
>
> You can see there are 3 distinct linear relationships of those 2 variables.
>
> plot(1/temp[,1], temp[,2])
>
> Is there any simple way how to evaluate such data without grouping variable? I know that in case I have proper grouping variable I can evaluate it with lme and get intercepts and/or slopes.
>
> My question is:
>
> Does anybody know about a way/package/function which can give me appropriate grouping of such data or which can give me separate slope/intercept for each set.
>
> I hope I expressed my problem clearly.
>
> Best regards
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From petr.pikal at precheza.cz  Tue Feb  2 13:29:49 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 2 Feb 2016 12:29:49 +0000
Subject: [R] Improvement in Process time
In-Reply-To: <2054761393.626759.1454414582950.JavaMail.yahoo@mail.yahoo.com>
References: <2054761393.626759.1454414582950.JavaMail.yahoo.ref@mail.yahoo.com>
	<2054761393.626759.1454414582950.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C58A@SRVEXCHMBX.precheza.cz>

Hi

Basically you can define your data frame before the cycle begins (specify total size, populate rows and columns with NA) and only populate it with your results during a cycle.

Or you can use a list for storing results and use do.call to transform it to data frame.

something like this

lll<- vector("list", 10)
for(i in 1:10) lll[[i]] <- rnorm(12)
do.call(cbind, lll)


I wonder if you get better answer without toy example, because there can be other reasons for slow computation.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Amelia
> Marsh via R-help
> Sent: Tuesday, February 02, 2016 1:03 PM
> To: R Help R
> Subject: [R] Improvement in Process time
>
> Dear R forum,
>
> I am running a Particular process 1000 times for different rates. Each
> time the result of the process is getting stored (appended) in a
> data.frame. However, the process is taking unsual time at times more
> than 2 hours. When I had tried to find out the reason for such a long
> process time, I have realized that writing a data.frame is consuming
> lot of time.
>
> Here is an extract of my code
>
> # ---------------------------------------------------------------
>
> tx_discounted <- read.csv('transaction_discounted.csv', na.strings='')
> tx_discounted$id <- as.character(tx_discounted$id)
>
> n             <- max(unique(simulated_exchange$id))
>
> result         <- NULL
> current  <- 1
> rcount   <- 0
> current1 <- 1
> rcount1  <- 0
> current2 <- 1
> rcount2  <- 0
> for (env in 0:n) {
>
> if (rcount == 0) rcount <- nrow(subset(simulated_interest, id==env))
> temp           <- current+rcount-1
> env_rates  <- simulated_interest[current:temp,] env_rates  <-
> env_rates[order(env_rates$curve, env_rates$day_count), ]
> if (rcount1 == 0)     rcount1 <- nrow(subset(simulated_exchange, id==env))
> temp           <- current1+rcount1-1
> exch_rates <- simulated_exchange[current1:temp,]
> if (rcount2 == 0)     rcount2 <- nrow(subset(simulated_instruments,
> id==env))
> temp           <- current2+rcount2-1
> instr_rates<- simulated_instruments[current2:temp,]
> current        <- current+rcount
> current1       <- current1+rcount1
> current2       <- current2+rcount2
>
> curve       <- daply(env_rates, 'curve', function(x) {
> return(approxfun(x$day_count, x$rate, rule = 2))
> })
>
> # ____________________________________________________
>
> ## Actual time consumtion begins from following part
>
> # ____________________________________________________
>
> result <- rbind(result, ddply(tx_discounted, 'id', function(x) {
>
> if(!is.na(x$curve) && x$curve != '') {
> intrate <- curve[[x$curve]](x$maturity_period)
> } else {
> intrate <- subset(instr_rates,
> instrument==as.character(x$instrument))$value
> }
>
> cross_rate <- subset(exch_rates, key==paste(x$currency,
> x$currency_base, sep='_'))$rate
> mtm_bc     <- cross_rate *
> (x$amount/(1+((intrate/100)*(x$maturity_period/x$intbasis))))
>
> return(data.frame(env=env, id=x$id, instrument=x$instrument,
> currency=x$currency, intrate = intrate, maturity_period =
> x$maturity_period,  intbasis = x$intbasis, cross_rate = cross_rate,
> amount=x$amount, mtm_bc=mtm_bc))
> }))
> }
>
>
> # ---------------------------------------------------------------------
> ------
>
> Unfortuantely I can't share the input files. Is there any way I can
> improve the process time.
>
> Regards and thanking in advance
>
> Amelia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Feb  2 14:13:49 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 2 Feb 2016 13:13:49 +0000
Subject: [R] fancy linear model and grouping
In-Reply-To: <CAP01uRmdyAFnfPNh109pKeqoc4Zj5T_pgt3cXexm8XnCjfnN6w@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
	<CAP01uRmdyAFnfPNh109pKeqoc4Zj5T_pgt3cXexm8XnCjfnN6w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C5AA@SRVEXCHMBX.precheza.cz>

Hi

Thanks, it work for my example, which is actually a subset of a bigger data (4000 rows) with the same characteristics. For the whole problem it does not give correct clustering. I tried to set G to 3 but it did not help either.

I attached the whole dataset (dput) that you can use, however after quick tour through Mclust it seems to me that it is designed for slightly different problem.

Here is the result with whole data.

fm <- Mclust(temp)
g <- fm$classification
plot(1/temp[,1], temp[,2], pch = g, col = g)

I will go through the docs more thoroughly, to be 100% sure I did not miss anything.

Cheers
Petr


> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Tuesday, February 02, 2016 1:20 PM
> To: PIKAL Petr
> Cc: R Help R
> Subject: Re: [R] fancy linear model and grouping
>
> Try the mclust package:
>
> library(mclust)
> temp.na <- na.omit(temp)
> fm <- Mclust(temp.na)
> g <- fm$classification
> plot(temp.na, pch = g, col = g)
>
>
>
> On Tue, Feb 2, 2016 at 6:35 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Dear all
> >
> > I have data like this
> >
> >> dput(temp)
> >
> > temp <- structure(list(X1 = c(93, 82, NA, 93, 93, 79, 79, 93, 93, 85,
> > 82, 93, 87, 93, 92, NA, 87, 93, 93, 93, 74, 77, 87, 93, 82, 87, 75,
> > 82, 93, 92, 68, 93, 93, 73, NA, 85, 81, 79, 75, 87, 93, NA, 87, 87,
> > 85, 92, 87, 92, 93, 87, 87, NA, 69, 87, 93, 87, 93, 87, 82, 79, 87,
> > 93, 87, 80, 87, 87, 87, 92, 93, 69, 76, 87, 82, 93, 82, NA, 54, 87,
> > 77, 73, 93, 82, 73, 93, 92, 82, 77, 93, 87, 75, 87, 87, 87, 60, 92,
> > 87, 87, NA, 77, 78), X2 = c(224, 624, NA, 224, 224, 642, 642, 224,
> > 224, 599, 622, 224, 239, 224, 225, NA, 239, 224, 224, 224, 688, 657,
> > 239, 224, 624, 239, 672, 254, 224, 225, 499, 224, 224, 692, NA, 599,
> > 627, 642, 677, 239, 224, NA, 239, 239, NA, 375, 239, 375, 224, 239,
> > 239, NA, 299, 239, 224, 239, 224, 239, 621, 642, 239, 224, 239, 638,
> > 239, 239, 239, 225, 224, 299, 672, 239, 618, 224, 620, NA, 626, 239,
> > 657, 693, 224, 624, 693, 224, 225, 621, 657, 224, 239, 673, 239, 239,
> > 239, 569, 224, 239, 239, NA, 657, 651)), .Names = c("X1", "X2"),
> > row.names = c(NA, -100L), class = "data.frame")
> >>
> >
> > You can see there are 3 distinct linear relationships of those 2
> variables.
> >
> > plot(1/temp[,1], temp[,2])
> >
> > Is there any simple way how to evaluate such data without grouping
> variable? I know that in case I have proper grouping variable I can
> evaluate it with lme and get intercepts and/or slopes.
> >
> > My question is:
> >
> > Does anybody know about a way/package/function which can give me
> appropriate grouping of such data or which can give me separate
> slope/intercept for each set.
> >
> > I hope I expressed my problem clearly.
> >
> > Best regards
> > Petr
> >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: temp.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160202/7e7a35c0/attachment.txt>

From bgunter at comcast.net  Mon Feb  1 18:48:18 2016
From: bgunter at comcast.net (Bert Gunter)
Date: Mon, 1 Feb 2016 09:48:18 -0800
Subject: [R] [R-pkgs] New Package: stripless (V. 1.0)
Message-ID: <515D97C4-DE1E-4283-9082-ECA9486E3B03@comcast.net>

A new package, ?stripless?, is now available on CRAN. It should be mostly of interest to those who use Lattice graphics when there are more than a couple of conditioning variables. Quoting from the DESCRIPTION:

For making Trellis-type conditioning plots without strip labels. This is useful for displaying the structure of results from factorial designs and other studies when many conditioning variables would clutter the display with layers of redundant strip labels. Settings of the variables are encoded by layout and spacing in the trellis array and decoded by a separate legend. The functionality is implemented by a single S3 generic strucplot() function that is a wrapper for the Lattice package's xyplot() function. This allows access to all Lattice graphics capabilities in the usual way.

A vignette is in preparation, but the existing Help pages should contain sufficient explanation and examples to get going. Feedback, suggestions, reports of bugs or any other infelicities are welcome. 

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it.?
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From mfay at niaid.nih.gov  Mon Feb  1 15:01:27 2016
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Mon, 1 Feb 2016 14:01:27 +0000
Subject: [R] [R-pkgs] Update on bpcp R package: Confidence intervals to use
 with Kaplan-Meier Survival Estimator
Message-ID: <F064307CEF0BC64593398B58FBE7EC661D152F5C@msgb07.nih.gov>

R Users,

We have updated the bpcp R package.  It gives pointwise confidence intervals for a survival distribution from right censored data. It is not based on asymptotic approximations, so it may be used with any sample size, and with any censoring distribution, as long as the censoring is non-informative.   Extensive simulations show that the bpcp confidence intervals appear to guarantee coverage.  When there is no censoring the method reduces to the exact binomial intervals for the proportion of survivors at each time point.

Here are some important improvements:


1.       The bpcp function now includes a midp option. This provides an confidence interval that is closer to the nominal level "on average" over the values of the parameter.  It reduces to the mid-p confidence interval for a binomial parameter when there is no censoring.  Just like other mid-p confidence intevals, for some values of the parameter it can be conservative, and for some values it can be slightly anti-conservative.  With extensive censoring it can be very conservative, because (as with the original version) no assumptions are made about the censoring distribution.

2.       There is a new convention for the original bpcp exactly at the failure times. This new convention ensures that the bpcp confidence intervals enclose the Kaplan-Meier estimator.

3.       There is a new option to enforce monotonicity. This is rarely needed, but is used by default. All new simulations were done using this enforced monotonicity.

4.       An error was fixed in the method that only occurred when non-default Delta values were used.

References:

Fay, MP, Brittain, EH (2016). Finite Sample Pointwise Confidence Intervals for a Survival Distribution with Right-Censored Data. (to appear in Statistics in Medicine, outlines midp modification, and provides many more simulations).

Fay, MP, Brittain, EH, and Proschan, MA (2013). Pointwise confidence intervals for a survival distribution with small samples or heavy censoring. Biostatistics. 14(4): 723-736.


Thanks,

Let me know if you have comments or want a preprint of the 2016 paper.

Mike
**************************************
Michael P. Fay, PhD
Mathematical Statistician
Biostatistics Research Branch/DCR/NIAID
5601 Fishers Lane,  Room 4B53
Rockville, MD 20852
240-669-5228

For FexEx/UPS use:
Rockville, MD 20852

For US Mail use:
Bethesda, MD 20892

Disclaimer: The information in this e-mail and any of its attachments is confidential and may contain sensitive information.  It should not be used by anyone who is not the original intended recipient.  If you have received this e-mail in error please inform the sender and delete it from your mailbox or any other storage devices.  The National Institute of Allergy and Infectious Diseases (NIAID)  shall not accept liability for any statement made that are the sender's own and not expressly made on behalf of the NIAID by one of its representatives.



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ggrothendieck at gmail.com  Tue Feb  2 16:55:04 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 2 Feb 2016 10:55:04 -0500
Subject: [R] fancy linear model and grouping
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C5AA@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
	<CAP01uRmdyAFnfPNh109pKeqoc4Zj5T_pgt3cXexm8XnCjfnN6w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C5AA@SRVEXCHMBX.precheza.cz>
Message-ID: <CAP01uRnYvKUX=rZhfw6CJQ3wjU3WY-+5o4RTgNhdrU93MCvHPQ@mail.gmail.com>

Try the EEV model with 3 clusters where temp is the large dataset:

   Mclust(temp, 3, modelNames = "EEV")

On Tue, Feb 2, 2016 at 8:13 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> Thanks, it work for my example, which is actually a subset of a bigger data (4000 rows) with the same characteristics. For the whole problem it does not give correct clustering. I tried to set G to 3 but it did not help either.
>
> I attached the whole dataset (dput) that you can use, however after quick tour through Mclust it seems to me that it is designed for slightly different problem.
>
> Here is the result with whole data.
>
> fm <- Mclust(temp)
> g <- fm$classification
> plot(1/temp[,1], temp[,2], pch = g, col = g)
>
> I will go through the docs more thoroughly, to be 100% sure I did not miss anything.
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
>> Sent: Tuesday, February 02, 2016 1:20 PM
>> To: PIKAL Petr
>> Cc: R Help R
>> Subject: Re: [R] fancy linear model and grouping
>>
>> Try the mclust package:
>>
>> library(mclust)
>> temp.na <- na.omit(temp)
>> fm <- Mclust(temp.na)
>> g <- fm$classification
>> plot(temp.na, pch = g, col = g)
>>
>>
>>
>> On Tue, Feb 2, 2016 at 6:35 AM, PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>> > Dear all
>> >
>> > I have data like this
>> >
>> >> dput(temp)
>> >
>> > temp <- structure(list(X1 = c(93, 82, NA, 93, 93, 79, 79, 93, 93, 85,
>> > 82, 93, 87, 93, 92, NA, 87, 93, 93, 93, 74, 77, 87, 93, 82, 87, 75,
>> > 82, 93, 92, 68, 93, 93, 73, NA, 85, 81, 79, 75, 87, 93, NA, 87, 87,
>> > 85, 92, 87, 92, 93, 87, 87, NA, 69, 87, 93, 87, 93, 87, 82, 79, 87,
>> > 93, 87, 80, 87, 87, 87, 92, 93, 69, 76, 87, 82, 93, 82, NA, 54, 87,
>> > 77, 73, 93, 82, 73, 93, 92, 82, 77, 93, 87, 75, 87, 87, 87, 60, 92,
>> > 87, 87, NA, 77, 78), X2 = c(224, 624, NA, 224, 224, 642, 642, 224,
>> > 224, 599, 622, 224, 239, 224, 225, NA, 239, 224, 224, 224, 688, 657,
>> > 239, 224, 624, 239, 672, 254, 224, 225, 499, 224, 224, 692, NA, 599,
>> > 627, 642, 677, 239, 224, NA, 239, 239, NA, 375, 239, 375, 224, 239,
>> > 239, NA, 299, 239, 224, 239, 224, 239, 621, 642, 239, 224, 239, 638,
>> > 239, 239, 239, 225, 224, 299, 672, 239, 618, 224, 620, NA, 626, 239,
>> > 657, 693, 224, 624, 693, 224, 225, 621, 657, 224, 239, 673, 239, 239,
>> > 239, 569, 224, 239, 239, NA, 657, 651)), .Names = c("X1", "X2"),
>> > row.names = c(NA, -100L), class = "data.frame")
>> >>
>> >
>> > You can see there are 3 distinct linear relationships of those 2
>> variables.
>> >
>> > plot(1/temp[,1], temp[,2])
>> >
>> > Is there any simple way how to evaluate such data without grouping
>> variable? I know that in case I have proper grouping variable I can
>> evaluate it with lme and get intercepts and/or slopes.
>> >
>> > My question is:
>> >
>> > Does anybody know about a way/package/function which can give me
>> appropriate grouping of such data or which can give me separate
>> slope/intercept for each set.
>> >
>> > I hope I expressed my problem clearly.
>> >
>> > Best regards
>> > Petr
>> >
>> >
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Tue Feb  2 18:08:46 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Feb 2016 09:08:46 -0800
Subject: [R] fancy linear model and grouping
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF8bMcbJqcJv+6=Qwx02CjqkSgEsgbMCK3cc9HVcRtUe+M3A9g@mail.gmail.com>

Perhaps you can try clustering the output of the Hough transform.
PET::hough() will compute it, given a matrix like
gplots::hist2d(1/temp[,1],temp[,2])$hData.  I do not have much experience
here.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Feb 2, 2016 at 3:35 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Dear all
>
> I have data like this
>
> > dput(temp)
>
> temp <- structure(list(X1 = c(93, 82, NA, 93, 93, 79, 79, 93, 93, 85,
> 82, 93, 87, 93, 92, NA, 87, 93, 93, 93, 74, 77, 87, 93, 82, 87,
> 75, 82, 93, 92, 68, 93, 93, 73, NA, 85, 81, 79, 75, 87, 93, NA,
> 87, 87, 85, 92, 87, 92, 93, 87, 87, NA, 69, 87, 93, 87, 93, 87,
> 82, 79, 87, 93, 87, 80, 87, 87, 87, 92, 93, 69, 76, 87, 82, 93,
> 82, NA, 54, 87, 77, 73, 93, 82, 73, 93, 92, 82, 77, 93, 87, 75,
> 87, 87, 87, 60, 92, 87, 87, NA, 77, 78), X2 = c(224, 624, NA,
> 224, 224, 642, 642, 224, 224, 599, 622, 224, 239, 224, 225, NA,
> 239, 224, 224, 224, 688, 657, 239, 224, 624, 239, 672, 254, 224,
> 225, 499, 224, 224, 692, NA, 599, 627, 642, 677, 239, 224, NA,
> 239, 239, NA, 375, 239, 375, 224, 239, 239, NA, 299, 239, 224,
> 239, 224, 239, 621, 642, 239, 224, 239, 638, 239, 239, 239, 225,
> 224, 299, 672, 239, 618, 224, 620, NA, 626, 239, 657, 693, 224,
> 624, 693, 224, 225, 621, 657, 224, 239, 673, 239, 239, 239, 569,
> 224, 239, 239, NA, 657, 651)), .Names = c("X1", "X2"), row.names = c(NA,
> -100L), class = "data.frame")
> >
>
> You can see there are 3 distinct linear relationships of those 2 variables.
>
> plot(1/temp[,1], temp[,2])
>
> Is there any simple way how to evaluate such data without grouping
> variable? I know that in case I have proper grouping variable I can
> evaluate it with lme and get intercepts and/or slopes.
>
> My question is:
>
> Does anybody know about a way/package/function which can give me
> appropriate grouping of such data or which can give me separate
> slope/intercept for each set.
>
> I hope I expressed my problem clearly.
>
> Best regards
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From brian at mcneilco.com  Tue Feb  2 19:30:53 2016
From: brian at mcneilco.com (Brian Bolt)
Date: Tue, 2 Feb 2016 10:30:53 -0800
Subject: [R] Reducing of car package when loading
In-Reply-To: <B18C046C-9D8C-44EC-AAA9-B49BF0F1631E@comcast.net>
References: <4F4F3486-5A1B-49F2-9439-CE29308DF1CD@mcneilco.com>
	<B18C046C-9D8C-44EC-AAA9-B49BF0F1631E@comcast.net>
Message-ID: <317DC203-BE1F-4D0D-BECB-890281FA889C@mcneilco.com>

I am not sure what functions I use in car actually.  I am dependent on the drc package which imports "car".  The main drc function I use is "drm", along with "LL.4"

https://cran.r-project.org/web/packages/drc/index.html <https://cran.r-project.org/web/packages/drc/index.html>



Brian Bolt | John McNeil & Co. Inc. | 2223 Avenida de la Playa Suite 204, La Jolla, CA | 707.217.7598

> On Jan 29, 2016, at 10:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jan 29, 2016, at 10:11 AM, Brian Bolt <brian at mcneilco.com> wrote:
>> 
>> I have a non-CRAN package that has a large number of dependencies and as such, the memory footprint from loading my package in R is becoming larger.  I use Rapache often to pre-load my package and provide web services for my code, so the consistent memory footprint is hurting other processes on the machine.
>> 
>> I have created an R docker container and when I start R, the memory footprint is 27.89MB, after loading the car package, the memory footprint shoots up to 131.4MB. A difference of 103.51MB.  For comparison, loading ggplot2 only gives a difference of 9.32MB.
>> 
>> Is there something I can do, without removing dependencies, that could relieve some of my memory footprint?  To be clear, I am not just asking about the car package but reducing memory dependence in general.  Can I force the R package loader to only load functions from packages that I am dependent on? Is there a way to not load all of the datasets? 
> 
> You could be more specific about which functions you need.
> 
> 
>> 
>> Thanks,
>> Brian
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Feb  2 21:31:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Feb 2016 12:31:05 -0800
Subject: [R] Avoiding car package when loading pkg:doc
In-Reply-To: <317DC203-BE1F-4D0D-BECB-890281FA889C@mcneilco.com>
References: <4F4F3486-5A1B-49F2-9439-CE29308DF1CD@mcneilco.com>
	<B18C046C-9D8C-44EC-AAA9-B49BF0F1631E@comcast.net>
	<317DC203-BE1F-4D0D-BECB-890281FA889C@mcneilco.com>
Message-ID: <17690DB4-BFAC-4303-856B-897DCCA6B83B@comcast.net>


> On Feb 2, 2016, at 10:30 AM, Brian Bolt <brian at mcneilco.com> wrote:
> 
> I am not sure what functions I use in car actually.  I am dependent on the drc package which imports "car".  The main drc function I use is "drm", along with "LL.4"
> 
> https://cran.r-project.org/web/packages/drc/index.html

I think that there are packages that provide tools for examine the potential "flow" of function calls in packages, but I'm not a knowledgeable consumer of such tools. I did just look at the drm.R code and see that the only package that it loads is MASS. I see no packages loaded in the llogistic.R code where LL.4 is defined.

The NAMESPACE file says: importFrom(car, deltaMethod)

You might recompile a source version of drc without those functions and manual pages that require `deltaMethod`. I did that and then removed the 'car' references in ?DESCRIPTION?, ?NAMESPACE?.

'drm' seems to be "working" at least to the extent of running the ryegrass example without complaint after removing my old copy and running install.packages on the expanded and edited source:

 install.packages("~/Downloads/drc", repos=NULL, type="source")

#Although the package Description says it needs compilation, I didn't see any C code get compiled when I installed it as source.

### I did get an (unsurprising) warning for my modifications: 

* installing *source* package ?drc? ...
files ?R/ED.lin.R?, ?man/chickweed.Rd? are missing
files ?DESCRIPTION?, ?NAMESPACE? have the wrong MD5 checksums

... but the installation proceeded

?ryegrass

## Fitting a four-parameter Weibull model (type 2)
ryegrass.m1 <- drm(rootl ~ conc, data = ryegrass, fct = W2.4())

The `summary` and `plot` calls succeeded.

No warranties on the procedure, and I expect that the more knowledgeable user will find it "dirty" and possibly even dangerous. To make it cleaner, one should probably recompile the package from the system command line before installing

-- 
David.

> 
> 
> 
> Brian Bolt | John McNeil & Co. Inc. | 2223 Avenida de la Playa Suite 204, La Jolla, CA | 707.217.7598
> 
>> On Jan 29, 2016, at 10:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> 
>>> On Jan 29, 2016, at 10:11 AM, Brian Bolt <brian at mcneilco.com> wrote:
>>> 
>>> I have a non-CRAN package that has a large number of dependencies and as such, the memory footprint from loading my package in R is becoming larger.  I use Rapache often to pre-load my package and provide web services for my code, so the consistent memory footprint is hurting other processes on the machine.
>>> 
>>> I have created an R docker container and when I start R, the memory footprint is 27.89MB, after loading the car package, the memory footprint shoots up to 131.4MB. A difference of 103.51MB.  For comparison, loading ggplot2 only gives a difference of 9.32MB.
>>> 
>>> Is there something I can do, without removing dependencies, that could relieve some of my memory footprint?  To be clear, I am not just asking about the car package but reducing memory dependence in general.  Can I force the R package loader to only load functions from packages that I am dependent on? Is there a way to not load all of the datasets? 
>> 
>> You could be more specific about which functions you need.
>> 
>> 
>>> 
>>> Thanks,
>>> Brian
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 

David Winsemius
Alameda, CA, USA


From alaios at yahoo.com  Tue Feb  2 23:04:51 2016
From: alaios at yahoo.com (Alaios)
Date: Tue, 2 Feb 2016 22:04:51 +0000 (UTC)
Subject: [R] find numbers that fall in a region or the next available.
References: <1529521926.554402.1454450691029.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1529521926.554402.1454450691029.JavaMail.yahoo@mail.yahoo.com>

Dear all,I have GPS coordinates (one vector for longitude and one for latitude: GPSLong and GPSLat) of small are that is around 300meters X 300 meters (location falls inside UK).At the same time I have two more vectors (Longitude and Latitude) that include position of food stores again the UK
I would like to find within my 300x300 square area which as the food stores that fall inside.I thought to try to find which of the Longitude of the food stores fall inside my area. I tried something the below

Longitude[Longitude>(min(GPSLong)-0.001)&&Longitude<(max(GPSLong)+0.001)]
but this returned me zero results.The next option would be the code to return me at least the place that falls outside but still is close to that region.'Do you have any idea how to do that and not fall back in the time consuming look at each element iteration?
I would like to thank you for your replyRegardsAlex



	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Feb  2 23:33:32 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 3 Feb 2016 11:33:32 +1300
Subject: [R] [FORGED] find numbers that fall in a region or the next
 available.
In-Reply-To: <1529521926.554402.1454450691029.JavaMail.yahoo@mail.yahoo.com>
References: <1529521926.554402.1454450691029.JavaMail.yahoo.ref@mail.yahoo.com>
	<1529521926.554402.1454450691029.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56B12EBC.30803@auckland.ac.nz>

On 03/02/16 11:04, Alaios via R-help wrote:
> Dear all,I have GPS coordinates (one vector for longitude and one for
> latitude: GPSLong and GPSLat) of small are that is around 300meters X
> 300 meters (location falls inside UK).At the same time I have two
> more vectors (Longitude and Latitude) that include position of food
> stores again the UK I would like to find within my 300x300 square
> area which as the food stores that fall inside.I thought to try to
> find which of the Longitude of the food stores fall inside my area. I
> tried something the below
>
> Longitude[Longitude>(min(GPSLong)-0.001)&&Longitude<(max(GPSLong)+0.001)]
> but this returned me zero results.The next option would be the code
> to return me at least the place that falls outside but still is close
> to that region.'Do you have any idea how to do that and not fall back
> in the time consuming look at each element iteration?
> I would like to thank you for your reply


You could make use of the distfun() function from the spatstat package. 
  Represent your "small area" as an object of class "owin".  The 
longitude and latitude coordinates will be treated as if they were 
Euclidean coordinates, but over distances of the order of 300 metres 
this should not matter much.  You could of course convert your long and 
lat coordinates to metres, using some appropriate projection, which 
might make more sense in your context.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pai1981 at gmail.com  Wed Feb  3 00:28:21 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Tue, 2 Feb 2016 16:28:21 -0700
Subject: [R] Static to interactive map (leaflet spplot)
Message-ID: <CAM9mbiBrBXvAoe_natwLi7uHcokTCe9UOgvVSJy=b_vvbpLJLg@mail.gmail.com>

Hi ALL,

I have a script to plot hexagonal polygon on a map. Its a static map. I
used spplot. I would like to convert this plot to interactive plot using "
*leaflet*". How do I make it interactive plot?

Here is spplot lines:

cl = map("world", xlim = c(-120, 20), ylim = c(-10, 70), plot = TRUE)
cl = map("world",plot = TRUE)
clp = map2SpatialLines(cl, proj4string = CRS(ll))
clp = spTransform(clp, CRS(lcc))
l2 = list("sp.lines", clp, col = "black", lty = 1, lwd = 3)

cr = colorRampPalette(brewer.pal(9,"YlOrRd"))(100)

require(grid)
spplot(hspdf, "CDP", col = "white", col.regions = cr,
            sp.layout = list(l2),
            at = seq(0,100,10),
            sub = list("CDP", cex = 1.5, font = 2))

where
> hspdf
class       : SpatialPolygonsDataFrame
features    : 95
extent      : -4141330, 3748528, 1530846, 6914278  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-60 +ellps=WGS84
variables   : 4
names       : hexid, count, hct,               CDP
min values  :    37,     1,   1, 0.136612021857923
max values  :   448,     7,   3,  39.4391854927413

CDP values of each hexagonal polygon.

-Deb

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Tue Feb  2 22:28:11 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Tue, 02 Feb 2016 21:28:11 +0000 (GMT)
Subject: [R] Big Finance and digits
Message-ID: <f9968117-c92d-4c50-b5f8-841857df8768@me.com>

All,

I am modeling a FNMA credit risk transfer deal. ?The size of the collateral 250 billion. ?Naturally, the cashflow is quite large the cash flow is calculated and stored in a S4 object which is then converted to an array and the result is character values - converting back to numeric I lose the decimal unless I set options(digits = 22). ?Are there any other options available. ?I have searched the internet and well as some R sites and it seems this maybe my?only option.

Glenn?

From murdoch.duncan at gmail.com  Wed Feb  3 00:57:31 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 2 Feb 2016 18:57:31 -0500
Subject: [R] Big Finance and digits
In-Reply-To: <f9968117-c92d-4c50-b5f8-841857df8768@me.com>
References: <f9968117-c92d-4c50-b5f8-841857df8768@me.com>
Message-ID: <56B1426B.4050308@gmail.com>

On 02/02/2016 4:28 PM, Glenn Schultz wrote:
> All,
>
> I am modeling a FNMA credit risk transfer deal.  The size of the collateral 250 billion.  Naturally, the cashflow is quite large the cash flow is calculated and stored in a S4 object which is then converted to an array and the result is character values - converting back to numeric I lose the decimal unless I set options(digits = 22).  Are there any other options available.  I have searched the internet and well as some R sites and it seems this maybe my only option.

Most R values are stored in double precision, which gives 15-16 digit 
accuracy.  That should give you values accurate to 1 cent in 10^13 
dollars, which covers your range.

Automatic conversion to characters shouldn't happen.  If it does, 
something is going wrong in your computations.  (It happens when you mix 
characters and numbers in the same vector.  Don't do that.)

At the end when you want to print, you need to convert to character. 
You can use options(digits=) to set the default number of digits, or you 
can do the conversion explicitly, using format(), sprintf(), or a 
related function.  It's up to you how many decimals you print.

Duncan Murdoch


From marc_grt at yahoo.fr  Wed Feb  3 08:08:39 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 3 Feb 2016 08:08:39 +0100
Subject: [R] Use predict() after lmer() (library lme4)
Message-ID: <56B1A777.7060004@yahoo.fr>

Bonjour, (don't worry, after I will write in English [at least I will 
try ;) ])

I try to understand better mixed models and then I have generated data 
and I try to understand how the fixed and the random effects are used in 
predict(). I understand when the random effect is of the form (1 | rf] 
but I don't understand for the form (rf1 | rf2]. Let do an example. The 
last formula does not give the same than predict().

Thanks if someone could explain what formula use to reproduce the 
predict() results.

Marc

# 1/ Generate data in a data.frame, 1 response (number), one effect 
(effect) and two factors (sector and beach) that I want use as random 
effect. These two factors are hierarchical beach within sector

Sector <- c(rep("I", 100), rep("II", 100))
Beach <- c(
   sample(c("A", "B", "C", "D", "E"), 100, replace=TRUE),
   sample(c("F", "G"), 100, replace=TRUE)
   )

number <- rnorm(200, 10, 1)

# Sector effect
number[1:100] <- number[1:100] +0.1
number[101:200] <- number[101:200] +0.5

# beach effect
beach.value <- 1:7
names(beach.value) <- LETTERS[1:7]
number <- number + unname(beach.value[Beach])


dataF <- data.frame(number=number, effect= number/10+runif(200, 0, 2),
                     Sector=Sector, Beach=Beach)

plot(dataF$number, dataF$effect)

##############
library("lme4")
##############

##############
# 2/ Random effect is (1 | Beach). I can reproduce the predict()
##############

out1 <- lmer(formula = number ~ effect + (1 | Sector) , data=dataF)
head(predict(out1))
ef <- fixef(out1)
er <- ranef(out1)

head(ef["(Intercept)"]+dataF$effect*ef["effect"]+
   er$Sector[dataF$Sector, "(Intercept)"]
   )

##############
# 3/ Random effect is (1 | Beach) + (1 | Sector). I can reproduce the 
predict()
##############

out2 <- lmer(formula = number ~ effect + (1 | Sector)  + (1 | Beach), 
data=dataF)

head(predict(out2))
ef <- fixef(out2)
er <- ranef(out2)

head(ef["(Intercept)"]+dataF$effect*ef["effect"]+
        er$Sector[dataF$Sector, "(Intercept)"] +
        er$Beach[dataF$Beach, "(Intercept)"]
      )

##############
# 4/ Random effect if (Sector | Beach). I don't understand how to 
reproduce the predict()
##############

out3 <- lmer(formula = number ~ effect + (Sector | Beach), data=dataF)

head(predict(out3))
ef <- fixef(out3)
er <- ranef(out3)

head(ef["(Intercept)"]+dataF$effect*ef["effect"]+
        er$Beach[dataF$Beach, "(Intercept)"]+
        er$Beach[dataF$Beach, "SectorII"]
)


From petr.pikal at precheza.cz  Wed Feb  3 08:37:50 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 3 Feb 2016 07:37:50 +0000
Subject: [R] fancy linear model and grouping
In-Reply-To: <CAF8bMcbJqcJv+6=Qwx02CjqkSgEsgbMCK3cc9HVcRtUe+M3A9g@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C53B@SRVEXCHMBX.precheza.cz>
	<CAF8bMcbJqcJv+6=Qwx02CjqkSgEsgbMCK3cc9HVcRtUe+M3A9g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500C66A@SRVEXCHMBX.precheza.cz>

Hi Bill and Gabor

Thank you for your answers.

PET approach is quite interesting but as I hardly understand what it really does it seems to me rather complicated to use it properly.

OTOH using Mclust is quite understandable and what is important it provides correct grouping after I used EEV model.

As usual, Rhelp is powerful tool for getting answers if one tries to keep Posting guide rules.

Cheers
Petr

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Tuesday, February 02, 2016 6:09 PM
To: PIKAL Petr
Cc: R Help R
Subject: Re: [R] fancy linear model and grouping

Perhaps you can try clustering the output of the Hough transform.
PET::hough() will compute it, given a matrix like gplots::hist2d(1/temp[,1],temp[,2])$hData.  I do not have much experience here.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Tue, Feb 2, 2016 at 3:35 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Dear all

I have data like this

> dput(temp)

temp <- structure(list(X1 = c(93, 82, NA, 93, 93, 79, 79, 93, 93, 85,
82, 93, 87, 93, 92, NA, 87, 93, 93, 93, 74, 77, 87, 93, 82, 87,
75, 82, 93, 92, 68, 93, 93, 73, NA, 85, 81, 79, 75, 87, 93, NA,
87, 87, 85, 92, 87, 92, 93, 87, 87, NA, 69, 87, 93, 87, 93, 87,
82, 79, 87, 93, 87, 80, 87, 87, 87, 92, 93, 69, 76, 87, 82, 93,
82, NA, 54, 87, 77, 73, 93, 82, 73, 93, 92, 82, 77, 93, 87, 75,
87, 87, 87, 60, 92, 87, 87, NA, 77, 78), X2 = c(224, 624, NA,
224, 224, 642, 642, 224, 224, 599, 622, 224, 239, 224, 225, NA,
239, 224, 224, 224, 688, 657, 239, 224, 624, 239, 672, 254, 224,
225, 499, 224, 224, 692, NA, 599, 627, 642, 677, 239, 224, NA,
239, 239, NA, 375, 239, 375, 224, 239, 239, NA, 299, 239, 224,
239, 224, 239, 621, 642, 239, 224, 239, 638, 239, 239, 239, 225,
224, 299, 672, 239, 618, 224, 620, NA, 626, 239, 657, 693, 224,
624, 693, 224, 225, 621, 657, 224, 239, 673, 239, 239, 239, 569,
224, 239, 239, NA, 657, 651)), .Names = c("X1", "X2"), row.names = c(NA,
-100L), class = "data.frame")
>

You can see there are 3 distinct linear relationships of those 2 variables.

plot(1/temp[,1], temp[,2])

Is there any simple way how to evaluate such data without grouping variable? I know that in case I have proper grouping variable I can evaluate it with lme and get intercepts and/or slopes.

My question is:

Does anybody know about a way/package/function which can give me appropriate grouping of such data or which can give me separate slope/intercept for each set.

I hope I expressed my problem clearly.

Best regards
Petr





________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb  3 09:41:50 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 3 Feb 2016 09:41:50 +0100
Subject: [R] Use predict() after lmer() (library lme4)
In-Reply-To: <56B1A777.7060004@yahoo.fr>
References: <56B1A777.7060004@yahoo.fr>
Message-ID: <CAJuCY5z33EEtAt3i4qKYOUHQAfb8FLUHWQQWfjYf1OPDVLmaTA@mail.gmail.com>

Dear Marc,

This question is more suited for R-Sig-mixed models to which I'm forwarding
it.

Your manual predictions for out3 are wrong. Here are the correct manual
predictions.

fixed <- model.matrix(~effect, data = dataF) %*% fixef(out3)
random <- rowSums(model.matrix(~Sector, data = dataF) *
ranef(out3)$Beach[dataF$Beach, ])
range(fixed + random - predict(out3))

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-02-03 8:08 GMT+01:00 Marc Girondot <marc_grt at yahoo.fr>:

> Bonjour, (don't worry, after I will write in English [at least I will try
> ;) ])
>
> I try to understand better mixed models and then I have generated data and
> I try to understand how the fixed and the random effects are used in
> predict(). I understand when the random effect is of the form (1 | rf] but
> I don't understand for the form (rf1 | rf2]. Let do an example. The last
> formula does not give the same than predict().
>
> Thanks if someone could explain what formula use to reproduce the
> predict() results.
>
> Marc
>
> # 1/ Generate data in a data.frame, 1 response (number), one effect
> (effect) and two factors (sector and beach) that I want use as random
> effect. These two factors are hierarchical beach within sector
>
> Sector <- c(rep("I", 100), rep("II", 100))
> Beach <- c(
>   sample(c("A", "B", "C", "D", "E"), 100, replace=TRUE),
>   sample(c("F", "G"), 100, replace=TRUE)
>   )
>
> number <- rnorm(200, 10, 1)
>
> # Sector effect
> number[1:100] <- number[1:100] +0.1
> number[101:200] <- number[101:200] +0.5
>
> # beach effect
> beach.value <- 1:7
> names(beach.value) <- LETTERS[1:7]
> number <- number + unname(beach.value[Beach])
>
>
> dataF <- data.frame(number=number, effect= number/10+runif(200, 0, 2),
>                     Sector=Sector, Beach=Beach)
>
> plot(dataF$number, dataF$effect)
>
> ##############
> library("lme4")
> ##############
>
> ##############
> # 2/ Random effect is (1 | Beach). I can reproduce the predict()
> ##############
>
> out1 <- lmer(formula = number ~ effect + (1 | Sector) , data=dataF)
> head(predict(out1))
> ef <- fixef(out1)
> er <- ranef(out1)
>
> head(ef["(Intercept)"]+dataF$effect*ef["effect"]+
>   er$Sector[dataF$Sector, "(Intercept)"]
>   )
>
> ##############
> # 3/ Random effect is (1 | Beach) + (1 | Sector). I can reproduce the
> predict()
> ##############
>
> out2 <- lmer(formula = number ~ effect + (1 | Sector)  + (1 | Beach),
> data=dataF)
>
> head(predict(out2))
> ef <- fixef(out2)
> er <- ranef(out2)
>
> head(ef["(Intercept)"]+dataF$effect*ef["effect"]+
>        er$Sector[dataF$Sector, "(Intercept)"] +
>        er$Beach[dataF$Beach, "(Intercept)"]
>      )
>
> ##############
> # 4/ Random effect if (Sector | Beach). I don't understand how to
> reproduce the predict()
> ##############
>
> out3 <- lmer(formula = number ~ effect + (Sector | Beach), data=dataF)
>
> head(predict(out3))
> ef <- fixef(out3)
> er <- ranef(out3)
>
> head(ef["(Intercept)"]+dataF$effect*ef["effect"]+
>        er$Beach[dataF$Beach, "(Intercept)"]+
>        er$Beach[dataF$Beach, "SectorII"]
> )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Wed Feb  3 09:42:11 2016
From: alaios at yahoo.com (Alaios)
Date: Wed, 3 Feb 2016 08:42:11 +0000 (UTC)
Subject: [R] [FORGED] find numbers that fall in a region or the next
 available.
In-Reply-To: <56B12EBC.30803@auckland.ac.nz>
References: <56B12EBC.30803@auckland.ac.nz>
Message-ID: <1468760587.739337.1454488931498.JavaMail.yahoo@mail.yahoo.com>

Thanks. I am using distm of the geoshere package.I still wonder if there is a package that can tell me if a gps coordinate or not falls inside my area that is defined as:
bbox <- c(min(PlotPoints[, 1])-0.001, min(PlotPoints[, 2])-0.001, max(PlotPoints[, 1])+0.001, max(PlotPoints[, 2])+0.001)

PlotPoints are gps coordinates.
That would make it sure that I have no mistakes in my code.
Any ideas?Alex 

    On Tuesday, February 2, 2016 11:33 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
 

 On 03/02/16 11:04, Alaios via R-help wrote:
> Dear all,I have GPS coordinates (one vector for longitude and one for
> latitude: GPSLong and GPSLat) of small are that is around 300meters X
> 300 meters (location falls inside UK).At the same time I have two
> more vectors (Longitude and Latitude) that include position of food
> stores again the UK I would like to find within my 300x300 square
> area which as the food stores that fall inside.I thought to try to
> find which of the Longitude of the food stores fall inside my area. I
> tried something the below
>
> Longitude[Longitude>(min(GPSLong)-0.001)&&Longitude<(max(GPSLong)+0.001)]
> but this returned me zero results.The next option would be the code
> to return me at least the place that falls outside but still is close
> to that region.'Do you have any idea how to do that and not fall back
> in the time consuming look at each element iteration?
> I would like to thank you for your reply


You could make use of the distfun() function from the spatstat package. 
? Represent your "small area" as an object of class "owin".? The 
longitude and latitude coordinates will be treated as if they were 
Euclidean coordinates, but over distances of the order of 300 metres 
this should not matter much.? You could of course convert your long and 
lat coordinates to metres, using some appropriate projection, which 
might make more sense in your context.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


  
	[[alternative HTML version deleted]]


From bran.chri at gmail.com  Wed Feb  3 15:55:03 2016
From: bran.chri at gmail.com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Wed, 3 Feb 2016 15:55:03 +0100
Subject: [R] vertical lines in riverplot
Message-ID: <CAALi0vLY2nYcsva0LacmEExqJZzehu=BRs42UtEze7RVzpNmeA@mail.gmail.com>

Dear List,

I want to draw a Sankey-diagramm in R, for which I would use the
riverplot package.
It would be really nice to be able to
1. draw vertical lines (="edges") between nodes on the same x-axis
(T03-T04 in the example below) and
2. to invert the plot.
Now the "edge" between T03 and T04 is straight, but not vertical (1.).
I could invert the plot manually after drawing it, but there could
most likely be a more elegant solution (2.).

Any ideas would be appreciated.

Thank you,
Christian


library(riverplot)

trplot <- function ()
{

  ret <- list(nodes = data.frame(ID = c("T01","T02","T03","T04"),
                                 x = c(1,2,3,3),
                                 labels = c("T1","T2","T3","T4"),
                                 stringsAsFactors = FALSE),
              styles = list(T01 = list(col = "red",lty = 0, textcol = "white"),
                            T02 = list(col = "blue",lty = 0, textcol = "white"),
                            T03 = list(col = "green",lty = 0, textcol
= "white"),
                            T04 = list(col = "cyan",lty = 0, textcol =
"white")))

  ret$edges <- data.frame(stringsAsFactors = FALSE,
                          N1 = c("T01","T02","T03"),
                          N2 = c("T03","T03","T04"),
                          Value=c(5,5,12))

  rownames(ret$nodes) <- ret$nodes$ID
  class(ret) <- c(class(ret), "riverplot")
  return(ret)
}

style2 <- default.style()
style2[["edgestyle"]] <- "straight"
riverplot(trplot(),default_style=style2)


From wht_crl at yahoo.com  Wed Feb  3 17:03:25 2016
From: wht_crl at yahoo.com (carol white)
Date: Wed, 3 Feb 2016 16:03:25 +0000 (UTC)
Subject: [R] determine the year of a date
References: <2142003040.900669.1454515405461.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2142003040.900669.1454515405461.JavaMail.yahoo@mail.yahoo.com>

Hi,might be trivial but how to determine the year of a date which is in the %m/%d/%y format and those whose year is century should be modified to ISO so that all date will have with year in ISO?
Regards,
Carol

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Wed Feb  3 17:29:12 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 3 Feb 2016 11:29:12 -0500
Subject: [R] [R-pkgs] New Package: stripless (V. 1.0)
In-Reply-To: <515D97C4-DE1E-4283-9082-ECA9486E3B03__41487.6959323466$1454428205$gmane$org@comcast.net>
References: <515D97C4-DE1E-4283-9082-ECA9486E3B03__41487.6959323466$1454428205$gmane$org@comcast.net>
Message-ID: <56B22AD8.2040101@yorku.ca>

Hi Burt

This looks like an interesting package.  However, you should know that 
'strucplot()' might not be the best choice for your generic, because 
vcd::strucplot() is now well-established as the general name for 
functions plotting structured multi-way frequency tables, like mosaic 
plots and friends.

Would you consider a non-clashing alternative?  The semantics of your
functions are like xyplot(), but without strip labels, so how about
xystripless()?  That also says more directly what it does, and avoids
confusing users.
NAMESPACEs help with clashes, but make it very awkward
to use such packages together without `::` qualifiers.

best,
-Michael



On 2/1/2016 12:48 PM, Bert Gunter wrote:
> A new package, ?stripless?, is now available on CRAN. It should be mostly of interest to those who use Lattice graphics when there are more than a couple of conditioning variables. Quoting from the DESCRIPTION:
>
> For making Trellis-type conditioning plots without strip labels. This is useful for displaying the structure of results from factorial designs and other studies when many conditioning variables would clutter the display with layers of redundant strip labels. Settings of the variables are encoded by layout and spacing in the trellis array and decoded by a separate legend. The functionality is implemented by a single S3 generic strucplot() function that is a wrapper for the Lattice package's xyplot() function. This allows access to all Lattice graphics capabilities in the usual way.
>
> A vignette is in preparation, but the existing Help pages should contain sufficient explanation and examples to get going. Feedback, suggestions, reports of bugs or any other infelicities are welcome.
>
> Cheers,
>
> Bert Gunter


From S.Ellison at LGCGroup.com  Wed Feb  3 17:33:28 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 3 Feb 2016 16:33:28 +0000
Subject: [R] find numbers that fall in a region or the next available.
In-Reply-To: <1529521926.554402.1454450691029.JavaMail.yahoo@mail.yahoo.com>
References: <1529521926.554402.1454450691029.JavaMail.yahoo.ref@mail.yahoo.com>
	<1529521926.554402.1454450691029.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D0E31705@GBTEDVPEXCMB04.corp.lgc-group.com>

> Dear all,I have GPS coordinates (one vector for longitude and one for latitude:
> GPSLong and GPSLat) of small are that is around 300meters X 300 meters
> (location falls inside UK).At the same time I have two more vectors (Longitude
> and Latitude) that include position of food stores again the UK I would like to
> find within my 300x300 square area which as the food stores that fall inside.I
> thought to try to find which of the Longitude of the food stores fall inside my
> area. I tried something the below
> 
> Longitude[Longitude>(min(GPSLong)-
> 0.001)&&Longitude<(max(GPSLong)+0.001)]
> but this returned me zero results.The next option would be the code to return
> me at least the place that falls outside but still is close to that region.'Do you
> have any idea how to do that and not fall back in the time consuming look at
> each element iteration?

Well, in a sense R has already looked at every element of Longitude to get Min and Max, so you're not avoiding that.

But wouldn't something like

which.min( c( GPSLong-Longitude, GPSLat-latitude )^2  ) 

return the index of the closest Latitude/Longitude pair to your GPS location? 

And once you have the distances you could use order() or rank() to pick the top 5 (maybe using head()) or just rank() on the distances.
And once you've picked a set you can still additionally check whether a location was within the box.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From pascal.niklaus at ieu.uzh.ch  Wed Feb  3 15:34:04 2016
From: pascal.niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Wed, 3 Feb 2016 15:34:04 +0100
Subject: [R] Keep factor order in lmer
Message-ID: <56B20FDC.7050809@ieu.uzh.ch>

I would like to keep a specific order of fixed effects in a model passed 
to lmer. In particular, I would like to prevent that interactions are 
automatically moved after all main effects.

In aov and lme, this is possible with terms(..., keep.order=TRUE). 
Unfortunately, I have not found a way to achieve this behaviour in lmer.

Here is an example that illustrates the problem:

d <- data.frame(
     R=factor(rep(1:4,each=8)),
     A=factor(rep(1:2,each=4)),
     B=factor(rep(1:2,each=2)),
     C=factor(1:2))

d$y <- rnorm(nrow(d))

## example using aov, with intended output

summary(aov(terms(y~A*B+C,keep.order = TRUE),data=d))

             Df Sum Sq Mean Sq F value Pr(>F)
A            1  0.831  0.8308   0.832  0.370
B            1  0.356  0.3557   0.356  0.556
A:B          1  0.103  0.1035   0.104  0.750
C            1  0.992  0.9919   0.993  0.328
Residuals   27 26.970  0.9989

## works also in lme

anova(lme(terms(y~A*B+C,keep.order=TRUE),random=~1|R,data=d))

## but how do I achieve this in lmer?

anova(lmer(y~A*B+C+(1|R),data=d))

Of course, I could recode the interactions into new single factors, but 
that seems rather cumbersome.

Thanks for your help

Pascal


From sarah.brennenstuhl at utoronto.ca  Wed Feb  3 16:25:04 2016
From: sarah.brennenstuhl at utoronto.ca (Sarah Brennenstuhl)
Date: Wed, 3 Feb 2016 15:25:04 +0000
Subject: [R] Problems loading lme4
Message-ID: <0B20906367ED2546A30BBDF1E02F572E39B09AD3@arborexmbx1.UTORARBOR.UTORAD.Utoronto.ca>

Hi there!

I having a problem loading lme4. When I try to load the package I get the following error message:

Error : object 'sigma' is not exported by 'namespace:stats'
In addition: Warning message:
package 'lme4' was built under R version 3.3.0
Error: package or namespace load failed for 'lme4'

Any suggestions for resolving this problem?

Thanks,

Sarah

	[[alternative HTML version deleted]]


From gabriela.wofkova at gmail.com  Wed Feb  3 17:45:42 2016
From: gabriela.wofkova at gmail.com (Gabriela Wofkova)
Date: Wed, 3 Feb 2016 17:45:42 +0100
Subject: [R] Install.package CAIC
Message-ID: <CACaW0dVq124gs52GXEUmtrFaY9s+XXsyPpVvjOWe7Mj+geXGvA@mail.gmail.com>

?H
?ello,

I am a begginer in R and I need to incorporate phylogeny into my data. So i
tried to instal package CAIC.

> install.packages("CAIC")
> install.packages("CAIC", repos="http://R-Forge.R-project.org",type="source")
> install.packages("CAIC", repos="http://R-Forge.R-project.org")


But it doesn?t work.

Installing package into ?C:/Users..../3.2?
(as ?lib? is unspecified)Warning in install.packages :
  package ?CAIC? is not available (for R version 3.2.3)



I see on forum one question on it:

http://r.789695.n4.nabble.com/Installing-CAIC-tt3693455.html

but the advice doesn?t work for me.
Have you got any other idea?

I have the newest version of R program (R version 3.2.3).

Is it possible that the package is available just for older versions? I had
also R version 3.1.2, but also it didn?t work.

I am sorry, if it is stupid or easy question, but I am at the end with any
idea.


Thank a lot for every advice.


Gabriela W.
?

	[[alternative HTML version deleted]]


From amoy_y at yahoo.com  Wed Feb  3 18:41:25 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Wed, 3 Feb 2016 17:41:25 +0000 (UTC)
Subject: [R] Create macro_var in R
References: <375580549.935567.1454521285487.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <375580549.935567.1454521285487.JavaMail.yahoo@mail.yahoo.com>

 There is a?%LET statement in SAS: %let MVAR=population; Thus,?MVAR can be used through entire program.
In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
Thanks in advance for helps!
Amoy


	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Feb  3 18:48:37 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 3 Feb 2016 09:48:37 -0800
Subject: [R] Create macro_var in R
In-Reply-To: <375580549.935567.1454521285487.JavaMail.yahoo@mail.yahoo.com>
References: <375580549.935567.1454521285487.JavaMail.yahoo.ref@mail.yahoo.com>
	<375580549.935567.1454521285487.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAFDcVCQg-dE95YFHeDuWG+Gv1LkB43QVRL+dv7eLhDsqGdr1Fg@mail.gmail.com>

Don't know what `population` is, but a simple assignment

MVAR <- population

may provide what you need.  Note, no c().  For example,

> foo <- rnorm
> foo(3)
[1] -0.08093862 -0.87827617  1.52826914

/Henrik

On Wed, Feb 3, 2016 at 9:41 AM, Amoy Yang via R-help
<r-help at r-project.org> wrote:
>  There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> Thanks in advance for helps!
> Amoy
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Feb  3 18:54:38 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 3 Feb 2016 12:54:38 -0500
Subject: [R] Create macro_var in R
In-Reply-To: <375580549.935567.1454521285487.JavaMail.yahoo@mail.yahoo.com>
References: <375580549.935567.1454521285487.JavaMail.yahoo.ref@mail.yahoo.com>
	<375580549.935567.1454521285487.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56B23EDE.9060808@gmail.com>

On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>   There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> Thanks in advance for helps!

R doesn't have a macro language, and you usually don't need one.

If you are only reading the value of population, then

MAVR <- population

is fine.  This is sometimes the same as c(population), but in general 
it's different:  c() will remove some attributes, such as
the dimensions on arrays.

If you need to modify it in your program, it's likely more complicated.  
The normal way to go would be to put your code in a function, and have 
it return the modified version.  For example,

population <- doModifications(population)

where doModifications is a function with a definition like

doModifications <- function(MAVR) {
    # do all your calculations on MAVR
    # then return it at the end using
    MAVR
}

Duncan Murdoch


From lordpreetam at gmail.com  Wed Feb  3 19:09:20 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Wed, 3 Feb 2016 23:39:20 +0530
Subject: [R] OLS Regression on subset of data
Message-ID: <CAHVFrXGeA_7ykmLsMphXOSHOJUtTVXzLk+GZ5tO+-ieH4BMQag@mail.gmail.com>

Hi,

I am performing OLS regression on a dataset involving variables Y, X1 and
X2, each having 500 observations. I want to perform the regression only on
a subset of the dataset (say, using observations 50 till 350). Is there any
way in which I can pass the entire dataset, but somewhere select these
indices 50-350 and pass this as an argument in the regression function?

Regards,
Preetam

	[[alternative HTML version deleted]]


From amoy_y at yahoo.com  Wed Feb  3 19:23:12 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Wed, 3 Feb 2016 18:23:12 +0000 (UTC)
Subject: [R] Create macro_var in R
In-Reply-To: <56B23EDE.9060808@gmail.com>
References: <56B23EDE.9060808@gmail.com>
Message-ID: <1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>

population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:? %let MVAR=population;
In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself?since MVAR is defined as "population" with double quotes if using MVAR<-c("population") 

    On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
 

 On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>? There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> Thanks in advance for helps!

R doesn't have a macro language, and you usually don't need one.

If you are only reading the value of population, then

MAVR <- population

is fine.? This is sometimes the same as c(population), but in general 
it's different:? c() will remove some attributes, such as
the dimensions on arrays.

If you need to modify it in your program, it's likely more complicated.? 
The normal way to go would be to put your code in a function, and have 
it return the modified version.? For example,

population <- doModifications(population)

where doModifications is a function with a definition like

doModifications <- function(MAVR) {
? ? # do all your calculations on MAVR
? ? # then return it at the end using
? ? MAVR
}

Duncan Murdoch


  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Feb  3 19:25:59 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 03 Feb 2016 10:25:59 -0800
Subject: [R] Problems loading lme4
In-Reply-To: <0B20906367ED2546A30BBDF1E02F572E39B09AD3@arborexmbx1.UTORARBOR.UTORAD.Utoronto.ca>
References: <0B20906367ED2546A30BBDF1E02F572E39B09AD3@arborexmbx1.UTORARBOR.UTORAD.Utoronto.ca>
Message-ID: <802DEA5C-7610-4696-8B2B-5540B81099CB@dcn.davis.ca.us>

R 3.3.0 is not a released version of R. It appears that you have obtained a version of lme4 that is ahead of its time. This would have been a perfect time for you to have followed the Posting Guide mentioned below (in particular the inclusion of complete version information such as the sessionInfo function would provide). If you obtained your lme4 through CRAN, the maintainers made a mistake.  If you found it somewhere else then you are the one who erred. Since it loads fine for me my bet is on your mistake. 
-- 
Sent from my phone. Please excuse my brevity.

On February 3, 2016 7:25:04 AM PST, Sarah Brennenstuhl <sarah.brennenstuhl at utoronto.ca> wrote:
>Hi there!
>
>I having a problem loading lme4. When I try to load the package I get
>the following error message:
>
>Error : object 'sigma' is not exported by 'namespace:stats'
>In addition: Warning message:
>package 'lme4' was built under R version 3.3.0
>Error: package or namespace load failed for 'lme4'
>
>Any suggestions for resolving this problem?
>
>Thanks,
>
>Sarah
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb  3 19:27:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 3 Feb 2016 10:27:06 -0800
Subject: [R] OLS Regression on subset of data
In-Reply-To: <CAHVFrXGeA_7ykmLsMphXOSHOJUtTVXzLk+GZ5tO+-ieH4BMQag@mail.gmail.com>
References: <CAHVFrXGeA_7ykmLsMphXOSHOJUtTVXzLk+GZ5tO+-ieH4BMQag@mail.gmail.com>
Message-ID: <CAGxFJbSZhnUAZVoZCeeBgWpxX8YuJ8_AnOdB=XDiMXVqR9mFBw@mail.gmail.com>

Did you not read about the "subset" argument of lm() ?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 3, 2016 at 10:09 AM, Preetam Pal <lordpreetam at gmail.com> wrote:
> Hi,
>
> I am performing OLS regression on a dataset involving variables Y, X1 and
> X2, each having 500 observations. I want to perform the regression only on
> a subset of the dataset (say, using observations 50 till 350). Is there any
> way in which I can pass the entire dataset, but somewhere select these
> indices 50-350 and pass this as an argument in the regression function?
>
> Regards,
> Preetam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Feb  3 19:29:39 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Feb 2016 13:29:39 -0500
Subject: [R] determine the year of a date
In-Reply-To: <2142003040.900669.1454515405461.JavaMail.yahoo@mail.yahoo.com>
References: <2142003040.900669.1454515405461.JavaMail.yahoo.ref@mail.yahoo.com>
	<2142003040.900669.1454515405461.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <B9986732-BD5D-4362-8431-0A9724F7F964@utoronto.ca>

It seems your autocorrect is playing tricks on you but if I understand you correctly you have a two digit year and want to convert that to a four digit year? That's not uniquely possible of course; by convention, as the documentation to strptime() says:

  On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
  is the behaviour specified by the 2004 and 2008 POSIX standards...

If this is correct for you, you need to convert the string to a time object and the time object back to string. The format specifier %Y prints four-digit years:


d <- "7/27/59"
strptime(d, format="%m/%d/%y")   # "2059-07-27 EDT"
x <- strptime(d, format="%m/%d/%y")

strftime(x, format="%m/%d/%Y")   # "07/27/1977"



B.







On Feb 3, 2016, at 11:03 AM, carol white via R-help <r-help at r-project.org> wrote:

> Hi,might be trivial but how to determine the year of a date which is in the %m/%d/%y format and those whose year is century should be modified to ISO so that all date will have with year in ISO?
> Regards,
> Carol
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Feb  3 19:30:11 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 3 Feb 2016 13:30:11 -0500
Subject: [R] Create macro_var in R
In-Reply-To: <1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
References: <56B23EDE.9060808@gmail.com>
	<1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56B24733.5050605@gmail.com>

On 03/02/2016 1:23 PM, Amoy Yang wrote:
> population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:  %let MVAR=population;
> In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself since MVAR is defined as "population" with double quotes if using MVAR<-c("population")

In that case, you can use

MVAR <- "population"

and then work with

tab[[MVAR]]

instead of tab$population.

But it would often make more sense to extract that column into a 
separate variable, and work with that, either as

MVAR <- tab$population

or

tab$population <- doModifications(tab$population)

following the same patterns as below.

Duncan Murdoch

>
>      On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>   
>
>   On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
> >  There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> > In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> > Thanks in advance for helps!
>
> R doesn't have a macro language, and you usually don't need one.
>
> If you are only reading the value of population, then
>
> MAVR <- population
>
> is fine.  This is sometimes the same as c(population), but in general
> it's different:  c() will remove some attributes, such as
> the dimensions on arrays.
>
> If you need to modify it in your program, it's likely more complicated.
> The normal way to go would be to put your code in a function, and have
> it return the modified version.  For example,
>
> population <- doModifications(population)
>
> where doModifications is a function with a definition like
>
> doModifications <- function(MAVR) {
>      # do all your calculations on MAVR
>      # then return it at the end using
>      MAVR
> }
>
> Duncan Murdoch
>
>
>


From bgunter.4567 at gmail.com  Wed Feb  3 19:34:09 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 3 Feb 2016 10:34:09 -0800
Subject: [R] Create macro_var in R
In-Reply-To: <1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
References: <56B23EDE.9060808@gmail.com>
	<1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTs48z6F2K4Pne94GrgLzrZQ-FZhS8Sstdu26px1GiqyQ@mail.gmail.com>

I am not sure what you want, but:

1) If you have not already done so, go through an R tutorial or two.
For some suggestions:

https://www.rstudio.com/resources/training/online-learning/#R

 R is quite different than SAS.

2) If I misunderstand, perhaps

?within

is what you are looking for.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 3, 2016 at 10:23 AM, Amoy Yang via R-help
<r-help at r-project.org> wrote:
> population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:  %let MVAR=population;
> In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself since MVAR is defined as "population" with double quotes if using MVAR<-c("population")
>
>     On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>
>  On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>>  There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
>> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
>> Thanks in advance for helps!
>
> R doesn't have a macro language, and you usually don't need one.
>
> If you are only reading the value of population, then
>
> MAVR <- population
>
> is fine.  This is sometimes the same as c(population), but in general
> it's different:  c() will remove some attributes, such as
> the dimensions on arrays.
>
> If you need to modify it in your program, it's likely more complicated.
> The normal way to go would be to put your code in a function, and have
> it return the modified version.  For example,
>
> population <- doModifications(population)
>
> where doModifications is a function with a definition like
>
> doModifications <- function(MAVR) {
>     # do all your calculations on MAVR
>     # then return it at the end using
>     MAVR
> }
>
> Duncan Murdoch
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Feb  3 19:34:14 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 03 Feb 2016 18:34:14 +0000
Subject: [R] Create macro_var in R
In-Reply-To: <1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
References: <56B23EDE.9060808@gmail.com>
	<1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>

Hello,

You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <-  
"population" (no need for c()).

Hope this helps,

Rui Barradas
?

Citando Amoy Yang via R-help <r-help at r-project.org>:

> population is the field-name in data-file (say, tab).  
> MVAR<-population takes data (in the column of population) rather  
> than field-name as done in SAS:? %let MVAR=population;
> In the following r-program, for instance, I cannot use ...  
> tab$MVAR...or simply MVAR itself?since MVAR is defined as  
> "population" with double quotes if using MVAR<-c("population")
>
> ? ?On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch  
> <murdoch.duncan at gmail.com> wrote:
>
> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>> ? There is a %LET statement in SAS: %let MVAR=population; Thus,  
>> MVAR can be used through entire program.
>> In R, I tried MAVR<-c("population"). The problem is that MAVR comes  
>> with double quote "...." that I don't need. But MVAR<-c(population)  
>> did NOT work out. Any way that double quote can be removed as done  
>> in SAS when creating macro_var?
>> Thanks in advance for helps!
>
> R doesn't have a macro language, and you usually don't need one.
>
> If you are only reading the value of population, then
>
> MAVR <- population
>
> is fine.? This is sometimes the same as c(population), but in general
> it's different:? c() will remove some attributes, such as
> the dimensions on arrays.
>
> If you need to modify it in your program, it's likely more complicated.?
> The normal way to go would be to put your code in a function, and have
> it return the modified version.? For example,
>
> population <- doModifications(population)
>
> where doModifications is a function with a definition like
>
> doModifications <- function(MAVR) {
> ? ? # do all your calculations on MAVR
> ? ? # then return it at the end using
> ? ? MAVR
> }
>
> Duncan Murdoch
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Feb  3 19:34:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 03 Feb 2016 10:34:20 -0800
Subject: [R] Create macro_var in R
In-Reply-To: <1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
References: <56B23EDE.9060808@gmail.com>
	<1501998852.989891.1454523792963.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A5590D12-C32A-463E-8E5F-71EF7816E846@dcn.davis.ca.us>

Are you perhaps needing to (re-)read the discussion on indexing in the "Introduction to R" document that comes with the software? (That is a common deficiency...)

It looks to me like you want something like

MVAR <- "population"
tab[[ MVAR ]]

-- 
Sent from my phone. Please excuse my brevity.

On February 3, 2016 10:23:12 AM PST, Amoy Yang via R-help <r-help at r-project.org> wrote:
>population is the field-name in data-file (say, tab). MVAR<-population
>takes data (in the column of population) rather than field-name as done
>in SAS:? %let MVAR=population;
>In the following r-program, for instance, I cannot use ...
>tab$MVAR...or simply MVAR itself?since MVAR is defined as "population"
>with double quotes if using MVAR<-c("population") 
>
>On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
> 
>
> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>>? There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR
>can be used through entire program.
>> In R, I tried MAVR<-c("population"). The problem is that MAVR comes
>with double quote "...." that I don't need. But MVAR<-c(population) did
>NOT work out. Any way that double quote can be removed as done in SAS
>when creating macro_var?
>> Thanks in advance for helps!
>
>R doesn't have a macro language, and you usually don't need one.
>
>If you are only reading the value of population, then
>
>MAVR <- population
>
>is fine.? This is sometimes the same as c(population), but in general 
>it's different:? c() will remove some attributes, such as
>the dimensions on arrays.
>
>If you need to modify it in your program, it's likely more
>complicated.? 
>The normal way to go would be to put your code in a function, and have 
>it return the modified version.? For example,
>
>population <- doModifications(population)
>
>where doModifications is a function with a definition like
>
>doModifications <- function(MAVR) {
>? ? # do all your calculations on MAVR
>? ? # then return it at the end using
>? ? MAVR
>}
>
>Duncan Murdoch
>
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Feb  3 19:34:40 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Feb 2016 13:34:40 -0500
Subject: [R] determine the year of a date
In-Reply-To: <B9986732-BD5D-4362-8431-0A9724F7F964@utoronto.ca>
References: <2142003040.900669.1454515405461.JavaMail.yahoo.ref@mail.yahoo.com>
	<2142003040.900669.1454515405461.JavaMail.yahoo@mail.yahoo.com>
	<B9986732-BD5D-4362-8431-0A9724F7F964@utoronto.ca>
Message-ID: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>

Sorry - messed up example: corrected here...

d <- "7/27/77"
strptime(d, format="%m/%d/%y")  #  "1977-07-27 EDT"
x <- strptime(d, format="%m/%d/%y")

strftime(x, format="%m/%d/%Y")  # "07/27/1977"


On Feb 3, 2016, at 1:29 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> It seems your autocorrect is playing tricks on you but if I understand you correctly you have a two digit year and want to convert that to a four digit year? That's not uniquely possible of course; by convention, as the documentation to strptime() says:
> 
>  On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
>  is the behaviour specified by the 2004 and 2008 POSIX standards...
> 
> If this is correct for you, you need to convert the string to a time object and the time object back to string. The format specifier %Y prints four-digit years:
> 
> 
> d <- "7/27/59"
> strptime(d, format="%m/%d/%y")   # "2059-07-27 EDT"
> x <- strptime(d, format="%m/%d/%y")
> 
> strftime(x, format="%m/%d/%Y")   # "07/27/1977"
> 
> 
> 
> B.
> 
> 
> 
> 
> 
> 
> 
> On Feb 3, 2016, at 11:03 AM, carol white via R-help <r-help at r-project.org> wrote:
> 
>> Hi,might be trivial but how to determine the year of a date which is in the %m/%d/%y format and those whose year is century should be modified to ISO so that all date will have with year in ISO?
>> Regards,
>> Carol
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Feb  3 19:51:59 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Feb 2016 13:51:59 -0500
Subject: [R] Install.package CAIC
In-Reply-To: <CACaW0dVq124gs52GXEUmtrFaY9s+XXsyPpVvjOWe7Mj+geXGvA@mail.gmail.com>
References: <CACaW0dVq124gs52GXEUmtrFaY9s+XXsyPpVvjOWe7Mj+geXGvA@mail.gmail.com>
Message-ID: <E3D27B0C-EFC2-42A7-A1CC-29273088B2C0@utoronto.ca>

I don't see a "CAIC" package on CRAN or bioconductor. Are you sure you got that right? Perhaps you meant another package? Or a function in another package? E.g. ape has a read.caic() function ...

See https://cran.r-project.org/web/views/Phylogenetics.html


B.
(Please also read the posting guide ... )

On Feb 3, 2016, at 11:45 AM, Gabriela Wofkova <gabriela.wofkova at gmail.com> wrote:

> ?H
> ?ello,
> 
> I am a begginer in R and I need to incorporate phylogeny into my data. So i
> tried to instal package CAIC.
> 
>> install.packages("CAIC")
>> install.packages("CAIC", repos="http://R-Forge.R-project.org",type="source")
>> install.packages("CAIC", repos="http://R-Forge.R-project.org")
> 
> 
> But it doesn?t work.
> 
> Installing package into ?C:/Users..../3.2?
> (as ?lib? is unspecified)Warning in install.packages :
>  package ?CAIC? is not available (for R version 3.2.3)
> 
> 
> 
> I see on forum one question on it:
> 
> http://r.789695.n4.nabble.com/Installing-CAIC-tt3693455.html
> 
> but the advice doesn?t work for me.
> Have you got any other idea?
> 
> I have the newest version of R program (R version 3.2.3).
> 
> Is it possible that the package is available just for older versions? I had
> also R version 3.1.2, but also it didn?t work.
> 
> I am sorry, if it is stupid or easy question, but I am at the end with any
> idea.
> 
> 
> Thank a lot for every advice.
> 
> 
> Gabriela W.
> ?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amoy_y at yahoo.com  Wed Feb  3 20:16:54 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Wed, 3 Feb 2016 19:16:54 +0000 (UTC)
Subject: [R] Create macro_var in R
In-Reply-To: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
Message-ID: <812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>

First, MVAR<-c("population) should be the same as "population'". Correct?
You use tab[[MVAR]] to refer to "population" where double [[...]] removes double quotes "...", which seemingly work for r-code although it is tedious in comparison direct application in SAS %let MVAR=population. But it does not work for sqldef in R as shown below.

> key<-"pop"
> library(sqldf)
> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min, 
+ max(pop) as max, avg(pop) as mean, median(pop) as median,
+ stdev(pop) as stdev from tab group by grade")
Error in sqliteSendQuery(con, statement, bind.data) : 
? error in statement: near "[[key]": syntax error


 

    On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt" <ruipbarradas at sapo.pt> wrote:
 

 Hello,

You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <- "population" (no need for c()).

Hope this helps,

Rui Barradas
?Citando Amoy Yang via R-help <r-help at r-project.org>:
population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:? %let MVAR=population;
In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself?since MVAR is defined as "population" with double quotes if using MVAR<-c("population")

? ?On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:


On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
? There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
Thanks in advance for helps!
R doesn't have a macro language, and you usually don't need one.

If you are only reading the value of population, then

MAVR <- population

is fine.? This is sometimes the same as c(population), but in general
it's different:? c() will remove some attributes, such as
the dimensions on arrays.

If you need to modify it in your program, it's likely more complicated.?
The normal way to go would be to put your code in a function, and have
it return the modified version.? For example,

population <- doModifications(population)

where doModifications is a function with a definition like

doModifications <- function(MAVR) {
? ? # do all your calculations on MAVR
? ? # then return it at the end using
? ? MAVR
}

Duncan Murdoch



? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.

?

  
	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Wed Feb  3 20:31:48 2016
From: wht_crl at yahoo.com (carol white)
Date: Wed, 3 Feb 2016 19:31:48 +0000 (UTC)
Subject: [R] determine the year of a date
In-Reply-To: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
Message-ID: <1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>

yes, some of them are like 09/01/15 and some others are 09/01/2015 and all of them range between 2015 and 2016. The goal was to convert 09/01/15 to 09/01/2015. I don't know if the fact that they range between 2015 and 2016 make the task easier.
Best wishes
Carol

    On Wednesday, February 3, 2016 7:34 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
 

 Sorry - messed up example: corrected here...

d <- "7/27/77"
strptime(d, format="%m/%d/%y")? #? "1977-07-27 EDT"
x <- strptime(d, format="%m/%d/%y")

strftime(x, format="%m/%d/%Y")? # "07/27/1977"


On Feb 3, 2016, at 1:29 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> It seems your autocorrect is playing tricks on you but if I understand you correctly you have a two digit year and want to convert that to a four digit year? That's not uniquely possible of course; by convention, as the documentation to strptime() says:
> 
>? On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
>? is the behaviour specified by the 2004 and 2008 POSIX standards...
> 
> If this is correct for you, you need to convert the string to a time object and the time object back to string. The format specifier %Y prints four-digit years:
> 
> 
> d <- "7/27/59"
> strptime(d, format="%m/%d/%y")? # "2059-07-27 EDT"
> x <- strptime(d, format="%m/%d/%y")
> 
> strftime(x, format="%m/%d/%Y")? # "07/27/1977"
> 
> 
> 
> B.
> 
> 
> 
> 
> 
> 
> 
> On Feb 3, 2016, at 11:03 AM, carol white via R-help <r-help at r-project.org> wrote:
> 
>> Hi,might be trivial but how to determine the year of a date which is in the %m/%d/%y format and those whose year is century should be modified to ISO so that all date will have with year in ISO?
>> Regards,
>> Carol
>> 
>> ??? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Feb  3 20:35:14 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 3 Feb 2016 19:35:14 +0000
Subject: [R] [FORGED] find numbers that fall in a region or the next
 available.
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D7075BA@mb02.ads.tamu.edu>

Look at the point.in.polygon() and over() functions in package sp.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alaios via R-help
Sent: Wednesday, February 3, 2016 2:42 AM
To: Rolf Turner; R-help Mailing List
Subject: Re: [R] [FORGED] find numbers that fall in a region or the next available.

Thanks. I am using distm of the geoshere package.I still wonder if there is a package that can tell me if a gps coordinate or not fal

ls inside my area that is defined as:
bbox <- c(min(PlotPoints[, 1])-0.001, min(PlotPoints[, 2])-0.001, max(PlotPoints[, 1])+0.001, max(PlotPoints[, 2])+0.001)

PlotPoints are gps coordinates.
That would make it sure that I have no mistakes in my code.
Any ideas?Alex 

    On Tuesday, February 2, 2016 11:33 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
 

 On 03/02/16 11:04, Alaios via R-help wrote:
> Dear all,I have GPS coordinates (one vector for longitude and one for
> latitude: GPSLong and GPSLat) of small are that is around 300meters X
> 300 meters (location falls inside UK).At the same time I have two
> more vectors (Longitude and Latitude) that include position of food
> stores again the UK I would like to find within my 300x300 square
> area which as the food stores that fall inside.I thought to try to
> find which of the Longitude of the food stores fall inside my area. I
> tried something the below
>
> Longitude[Longitude>(min(GPSLong)-0.001)&&Longitude<(max(GPSLong)+0.001)]
> but this returned me zero results.The next option would be the code
> to return me at least the place that falls outside but still is close
> to that region.'Do you have any idea how to do that and not fall back
> in the time consuming look at each element iteration?
> I would like to thank you for your reply


You could make use of the distfun() function from the spatstat package. 
? Represent your "small area" as an object of class "owin".? The 
longitude and latitude coordinates will be treated as if they were 
Euclidean coordinates, but over distances of the order of 300 metres 
this should not matter much.? You could of course convert your long and 
lat coordinates to metres, using some appropriate projection, which 
might make more sense in your context.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From JLucke at ria.buffalo.edu  Wed Feb  3 20:47:12 2016
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Wed, 3 Feb 2016 14:47:12 -0500
Subject: [R] Install.package CAIC
In-Reply-To: <CACaW0dVq124gs52GXEUmtrFaY9s+XXsyPpVvjOWe7Mj+geXGvA@mail.gmail.com>
References: <CACaW0dVq124gs52GXEUmtrFaY9s+XXsyPpVvjOWe7Mj+geXGvA@mail.gmail.com>
Message-ID: <OFC7C10285.FD21C815-ON85257F4E.006C8873-85257F4E.006CB046@ria.buffalo.edu>

You should consider the package "caper", which provides a CAIC. 

From the caper manual
"The caper package implements the methods originally provided in the 
programs CAIC (Purvis
and Rambaut, 1995b) and MacroCAIC (Agapow and Isaac, 2002)."

Hope this helps.



Gabriela Wofkova <gabriela.wofkova at gmail.com> 
Sent by: "R-help" <r-help-bounces at r-project.org>
02/03/2016 11:45 AM

To
r-help at r-project.org, 
cc

Subject
[R] Install.package CAIC






?H
?ello,

I am a begginer in R and I need to incorporate phylogeny into my data. So 
i
tried to instal package CAIC.

> install.packages("CAIC")
> install.packages("CAIC", repos="http://R-Forge.R-project.org
",type="source")
> install.packages("CAIC", repos="http://R-Forge.R-project.org")


But it doesn?t work.

Installing package into ?C:/Users..../3.2?
(as ?lib? is unspecified)Warning in install.packages :
  package ?CAIC? is not available (for R version 3.2.3)



I see on forum one question on it:

http://r.789695.n4.nabble.com/Installing-CAIC-tt3693455.html

but the advice doesn?t work for me.
Have you got any other idea?

I have the newest version of R program (R version 3.2.3).

Is it possible that the package is available just for older versions? I 
had
also R version 3.1.2, but also it didn?t work.

I am sorry, if it is stupid or easy question, but I am at the end with any
idea.


Thank a lot for every advice.


Gabriela W.
?

                 [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed Feb  3 20:51:49 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 3 Feb 2016 19:51:49 +0000
Subject: [R] Create macro_var in R
In-Reply-To: <812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
	<812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D2D7971C.1619A1%macqueen1@llnl.gov>

Repeat many times:   R does not work the same way as SAS, do not expect it
to

If I needed to construct an SQL statement in which the name of a field is
provided by the value of another variable, I would consider this:

key <- 'pop'
sql.stmt <- paste("select grade,
 count(*) as cnt,
 min(",key,") as min,
 max(",key,") as max,
 avg(",key,") as mean,
 median(",key,") as median,
 stdev(",key,") as stdev
from tab
group by grade"

)

Then
  print(sql.stmt, quote=FALSE)
to make sure I got what I wanted.

Use paste0() instead of paste() if you don't want the extra space
characters, even though they don't matter to SQL.

And, no, the double [[...]] does not remove double quotes. That's not how
it works.
  tab[['pop']]
  tab[ , 'pop']
  tab$pop
are three different ways to reference the pop column in the tab data
frame. Of the three, the value 'pop' can be stored in a variable with the
first two, but not the third one.

Remember, R is not SAS, so you have to use a different technique to
construct the desired SQL statement; there is nothing in R that works
exactly like SAS macro variables. (R has other advantages).

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/3/16, 11:16 AM, "R-help on behalf of Amoy Yang via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>First, MVAR<-c("population) should be the same as "population'". Correct?
>You use tab[[MVAR]] to refer to "population" where double [[...]] removes
>double quotes "...", which seemingly work for r-code although it is
>tedious in comparison direct application in SAS %let MVAR=population. But
>it does not work for sqldef in R as shown below.
>
>> key<-"pop"
>> library(sqldf)
>> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min,
>+ max(pop) as max, avg(pop) as mean, median(pop) as median,
>+ stdev(pop) as stdev from tab group by grade")
>Error in sqliteSendQuery(con, statement, bind.data) :
>  error in statement: near "[[key]": syntax error
>
>
> 
>
>    On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt"
><ruipbarradas at sapo.pt> wrote:
> 
>
> Hello,
>
>You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <-
>"population" (no need for c()).
>
>Hope this helps,
>
>Rui Barradas
> Citando Amoy Yang via R-help <r-help at r-project.org>:
>population is the field-name in data-file (say, tab). MVAR<-population
>takes data (in the column of population) rather than field-name as done
>in SAS:  %let MVAR=population;
>In the following r-program, for instance, I cannot use ... tab$MVAR...or
>simply MVAR itself since MVAR is defined as "population" with double
>quotes if using MVAR<-c("population")
>
>   On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>
>
>On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>  There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can
>be used through entire program.
>In R, I tried MAVR<-c("population"). The problem is that MAVR comes with
>double quote "...." that I don't need. But MVAR<-c(population) did NOT
>work out. Any way that double quote can be removed as done in SAS when
>creating macro_var?
>Thanks in advance for helps!
>R doesn't have a macro language, and you usually don't need one.
>
>If you are only reading the value of population, then
>
>MAVR <- population
>
>is fine.  This is sometimes the same as c(population), but in general
>it's different:  c() will remove some attributes, such as
>the dimensions on arrays.
>
>If you need to modify it in your program, it's likely more complicated.
>The normal way to go would be to put your code in a function, and have
>it return the modified version.  For example,
>
>population <- doModifications(population)
>
>where doModifications is a function with a definition like
>
>doModifications <- function(MAVR) {
>    # do all your calculations on MAVR
>    # then return it at the end using
>    MAVR
>}
>
>Duncan Murdoch
>
>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.htmland provide commented,
>minimal, self-contained, reproducible code.
>
> 
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From amoy_y at yahoo.com  Wed Feb  3 20:57:23 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Wed, 3 Feb 2016 19:57:23 +0000 (UTC)
Subject: [R] Create macro_var in R
In-Reply-To: <812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
References: <812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <408455641.1041641.1454529443486.JavaMail.yahoo@mail.yahoo.com>

Right! the following works to r but not sqldf.
MVAR <- "population"
 tab[[ MVAR ]]
sqldf("select tab[[MVAR]] from tab") 

    On Wednesday, February 3, 2016 1:18 PM, Amoy Yang via R-help <r-help at r-project.org> wrote:
 

 First, MVAR<-c("population) should be the same as "population'". Correct?
You use tab[[MVAR]] to refer to "population" where double [[...]] removes double quotes "...", which seemingly work for r-code although it is tedious in comparison direct application in SAS %let MVAR=population. But it does not work for sqldef in R as shown below.

> key<-"pop"
> library(sqldf)
> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min, 
+ max(pop) as max, avg(pop) as mean, median(pop) as median,
+ stdev(pop) as stdev from tab group by grade")
Error in sqliteSendQuery(con, statement, bind.data) : 
? error in statement: near "[[key]": syntax error


 

? ? On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt" <ruipbarradas at sapo.pt> wrote:
 

 Hello,

You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <- "population" (no need for c()).

Hope this helps,

Rui Barradas
?Citando Amoy Yang via R-help <r-help at r-project.org>:
population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:? %let MVAR=population;
In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself?since MVAR is defined as "population" with double quotes if using MVAR<-c("population")

? ?On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:


On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
? There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
Thanks in advance for helps!
R doesn't have a macro language, and you usually don't need one.

If you are only reading the value of population, then

MAVR <- population

is fine.? This is sometimes the same as c(population), but in general
it's different:? c() will remove some attributes, such as
the dimensions on arrays.

If you need to modify it in your program, it's likely more complicated.?
The normal way to go would be to put your code in a function, and have
it return the modified version.? For example,

population <- doModifications(population)

where doModifications is a function with a definition like

doModifications <- function(MAVR) {
? ? # do all your calculations on MAVR
? ? # then return it at the end using
? ? MAVR
}

Duncan Murdoch



? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.htmlandprovide commented, minimal, self-contained, reproducible code.

?

? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Feb  3 21:07:50 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Feb 2016 15:07:50 -0500
Subject: [R] determine the year of a date
In-Reply-To: <1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>

As the documentation says, that's exactly what the expansion will do by default.

B.


On Feb 3, 2016, at 2:31 PM, carol white <wht_crl at yahoo.com> wrote:

> yes, some of them are like 09/01/15 and some others are 09/01/2015 and all of them range between 2015 and 2016. The goal was to convert 09/01/15 to 09/01/2015. I don't know if the fact that they range between 2015 and 2016 make the task easier.
> 
> Best wishes
> Carol
> 
> 
> On Wednesday, February 3, 2016 7:34 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> Sorry - messed up example: corrected here...
> 
> d <- "7/27/77"
> strptime(d, format="%m/%d/%y")  #  "1977-07-27 EDT"
> x <- strptime(d, format="%m/%d/%y")
> 
> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
> 
> 
> On Feb 3, 2016, at 1:29 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> > It seems your autocorrect is playing tricks on you but if I understand you correctly you have a two digit year and want to convert that to a four digit year? That's not uniquely possible of course; by convention, as the documentation to strptime() says:
> > 
> >  On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
> >  is the behaviour specified by the 2004 and 2008 POSIX standards...
> > 
> > If this is correct for you, you need to convert the string to a time object and the time object back to string. The format specifier %Y prints four-digit years:
> > 
> > 
> > d <- "7/27/59"
> > strptime(d, format="%m/%d/%y")  # "2059-07-27 EDT"
> > x <- strptime(d, format="%m/%d/%y")
> > 
> > strftime(x, format="%m/%d/%Y")  # "07/27/1977"
> > 
> > 
> > 
> > B.
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > On Feb 3, 2016, at 11:03 AM, carol white via R-help <r-help at r-project.org> wrote:
> > 
> >> Hi,might be trivial but how to determine the year of a date which is in the %m/%d/%y format and those whose year is century should be modified to ISO so that all date will have with year in ISO?
> >> Regards,
> >> Carol
> >> 
> >>     [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From dwinsemius at comcast.net  Wed Feb  3 21:26:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Feb 2016 12:26:15 -0800
Subject: [R] Create macro_var in R
In-Reply-To: <408455641.1041641.1454529443486.JavaMail.yahoo@mail.yahoo.com>
References: <812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
	<408455641.1041641.1454529443486.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <11D69BC6-B353-45E6-B9F0-3AB1467098E1@comcast.net>


> On Feb 3, 2016, at 11:57 AM, Amoy Yang via R-help <r-help at r-project.org> wrote:
> 
> Right! the following works to r but not sqldf.
> MVAR <- "population"
> tab[[ MVAR ]]
> sqldf("select tab[[MVAR]] from tab") 

If ypu need a string to pass to sqldf, then use the `paste` function to build a single string:

sqldf( paste("select",  MVAR, " from tab") )

-- 
David.


> 
>    On Wednesday, February 3, 2016 1:18 PM, Amoy Yang via R-help <r-help at r-project.org> wrote:
> 
> 
> First, MVAR<-c("population) should be the same as "population'". Correct?
> You use tab[[MVAR]] to refer to "population" where double [[...]] removes double quotes "...", which seemingly work for r-code although it is tedious in comparison direct application in SAS %let MVAR=population. But it does not work for sqldef in R as shown below.
> 
>> key<-"pop"
>> library(sqldf)
>> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min, 
> + max(pop) as max, avg(pop) as mean, median(pop) as median,
> + stdev(pop) as stdev from tab group by grade")
> Error in sqliteSendQuery(con, statement, bind.data) : 
>   error in statement: near "[[key]": syntax error
> 
> 
> 
> 
>     On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt" <ruipbarradas at sapo.pt> wrote:
> 
> 
> Hello,
> 
> You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <- "population" (no need for c()).
> 
> Hope this helps,
> 
> Rui Barradas
>  Citando Amoy Yang via R-help <r-help at r-project.org>:
> population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:  %let MVAR=population;
> In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself since MVAR is defined as "population" with double quotes if using MVAR<-c("population")
> 
>    On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>   There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> Thanks in advance for helps!
> R doesn't have a macro language, and you usually don't need one.
> 
> If you are only reading the value of population, then
> 
> MAVR <- population
> 
> is fine.  This is sometimes the same as c(population), but in general
> it's different:  c() will remove some attributes, such as
> the dimensions on arrays.
> 
> If you need to modify it in your program, it's likely more complicated. 
> The normal way to go would be to put your code in a function, and have
> it return the modified version.  For example,
> 
> population <- doModifications(population)
> 
> where doModifications is a function with a definition like
> 
> doModifications <- function(MAVR) {
>     # do all your calculations on MAVR
>     # then return it at the end using
>     MAVR
> }
> 
> Duncan Murdoch
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.htmlandprovide commented, minimal, self-contained, reproducible code.
> 
>  
> 
>   
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Wed Feb  3 21:43:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 3 Feb 2016 12:43:36 -0800 (PST)
Subject: [R] determine the year of a date
In-Reply-To: <67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
	<67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
Message-ID: <alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>

Not exactly.

If you have been "Excel"ed and have both formats in one column then you 
really have a data cleanup task to do. The best route to resolution is to 
fix the source of the data (e.g. go back into Excel and reformat the 
column with consistent formatting).

If you need to do this on an ongoing basis and cannot fix the data source, 
then you might need to choose the correct format on the fly... something 
like:

yYdates <- function( ds ) {
   fmt <- ifelse( grepl( "^\\d{1,2}/\\d{1,2}/\\d{2}$", ds )
                , "%m/%d/%y"
                , "%m/%d/%Y"
                )
   as.Date( ds, format=fmt )
}

yYdates( c( "02/18/2015", "03/21/16" ) )
[1] "2015-02-18" "2016-03-21"

but this would have to be tailored to the formatting problems in your data 
and is not really a general solution.

On Wed, 3 Feb 2016, Boris Steipe wrote:

> As the documentation says, that's exactly what the expansion will do by default.
>
> B.
>
>
> On Feb 3, 2016, at 2:31 PM, carol white <wht_crl at yahoo.com> wrote:
>
>> yes, some of them are like 09/01/15 and some others are 09/01/2015 and all of them range between 2015 and 2016. The goal was to convert 09/01/15 to 09/01/2015. I don't know if the fact that they range between 2015 and 2016 make the task easier.
>>
>> Best wishes
>> Carol
>>
>>
>> On Wednesday, February 3, 2016 7:34 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>>
>> Sorry - messed up example: corrected here...
>>
>> d <- "7/27/77"
>> strptime(d, format="%m/%d/%y")  #  "1977-07-27 EDT"
>> x <- strptime(d, format="%m/%d/%y")
>>
>> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
>>
>>
>> On Feb 3, 2016, at 1:29 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>>> It seems your autocorrect is playing tricks on you but if I understand you correctly you have a two digit year and want to convert that to a four digit year? That's not uniquely possible of course; by convention, as the documentation to strptime() says:
>>>
>>>  On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
>>>  is the behaviour specified by the 2004 and 2008 POSIX standards...
>>>
>>> If this is correct for you, you need to convert the string to a time object and the time object back to string. The format specifier %Y prints four-digit years:
>>>
>>>
>>> d <- "7/27/59"
>>> strptime(d, format="%m/%d/%y")  # "2059-07-27 EDT"
>>> x <- strptime(d, format="%m/%d/%y")
>>>
>>> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
>>>
>>>
>>>
>>> B.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Feb 3, 2016, at 11:03 AM, carol white via R-help <r-help at r-project.org> wrote:
>>>
>>>> Hi,might be trivial but how to determine the year of a date which is in the %m/%d/%y format and those whose year is century should be modified to ISO so that all date will have with year in ISO?
>>>> Regards,
>>>> Carol
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From istazahn at gmail.com  Wed Feb  3 21:52:37 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 3 Feb 2016 15:52:37 -0500
Subject: [R] determine the year of a date
In-Reply-To: <alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
	<67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
	<alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>
Message-ID: <CA+vqiLEpYyxU7BOUZ0QLQ0_ziPQs2ryU0X0fTSdFH4JVNion3Q@mail.gmail.com>

On Wed, Feb 3, 2016 at 3:43 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Not exactly.
>
> If you have been "Excel"ed and have both formats in one column then you
> really have a data cleanup task to do.

No need to reinvent the wheel. Just do

library(lubridate)
mdy(c("09/01/15", "09/01/2015"))

Best,
ista
 The best route to resolution is to
> fix the source of the data (e.g. go back into Excel and reformat the column
> with consistent formatting).
>
> If you need to do this on an ongoing basis and cannot fix the data source,
> then you might need to choose the correct format on the fly... something
> like:
>
> yYdates <- function( ds ) {
>   fmt <- ifelse( grepl( "^\\d{1,2}/\\d{1,2}/\\d{2}$", ds )
>                , "%m/%d/%y"
>                , "%m/%d/%Y"
>                )
>   as.Date( ds, format=fmt )
> }
>
> yYdates( c( "02/18/2015", "03/21/16" ) )
> [1] "2015-02-18" "2016-03-21"
>
> but this would have to be tailored to the formatting problems in your data
> and is not really a general solution.
>
> On Wed, 3 Feb 2016, Boris Steipe wrote:
>
>> As the documentation says, that's exactly what the expansion will do by
>> default.
>>
>> B.
>>
>>
>> On Feb 3, 2016, at 2:31 PM, carol white <wht_crl at yahoo.com> wrote:
>>
>>> yes, some of them are like 09/01/15 and some others are 09/01/2015 and
>>> all of them range between 2015 and 2016. The goal was to convert 09/01/15 to
>>> 09/01/2015. I don't know if the fact that they range between 2015 and 2016
>>> make the task easier.
>>>
>>> Best wishes
>>> Carol
>>>
>>>
>>> On Wednesday, February 3, 2016 7:34 PM, Boris Steipe
>>> <boris.steipe at utoronto.ca> wrote:
>>>
>>>
>>> Sorry - messed up example: corrected here...
>>>
>>> d <- "7/27/77"
>>> strptime(d, format="%m/%d/%y")  #  "1977-07-27 EDT"
>>> x <- strptime(d, format="%m/%d/%y")
>>>
>>> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
>>>
>>>
>>> On Feb 3, 2016, at 1:29 PM, Boris Steipe <boris.steipe at utoronto.ca>
>>> wrote:
>>>
>>>> It seems your autocorrect is playing tricks on you but if I understand
>>>> you correctly you have a two digit year and want to convert that to a four
>>>> digit year? That's not uniquely possible of course; by convention, as the
>>>> documentation to strptime() says:
>>>>
>>>>  On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
>>>>
>>>>  is the behaviour specified by the 2004 and 2008 POSIX standards...
>>>>
>>>> If this is correct for you, you need to convert the string to a time
>>>> object and the time object back to string. The format specifier %Y prints
>>>> four-digit years:
>>>>
>>>>
>>>> d <- "7/27/59"
>>>> strptime(d, format="%m/%d/%y")  # "2059-07-27 EDT"
>>>> x <- strptime(d, format="%m/%d/%y")
>>>>
>>>> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
>>>>
>>>>
>>>>
>>>> B.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Feb 3, 2016, at 11:03 AM, carol white via R-help
>>>> <r-help at r-project.org> wrote:
>>>>
>>>>> Hi,might be trivial but how to determine the year of a date which is in
>>>>> the %m/%d/%y format and those whose year is century should be modified to
>>>>> ISO so that all date will have with year in ISO?
>>>>> Regards,
>>>>> Carol
>>>>>
>>>>>     [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Feb  3 21:55:26 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Feb 2016 15:55:26 -0500
Subject: [R] determine the year of a date
In-Reply-To: <CA+vqiLEpYyxU7BOUZ0QLQ0_ziPQs2ryU0X0fTSdFH4JVNion3Q@mail.gmail.com>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
	<67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
	<alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>
	<CA+vqiLEpYyxU7BOUZ0QLQ0_ziPQs2ryU0X0fTSdFH4JVNion3Q@mail.gmail.com>
Message-ID: <BE9A2447-1471-4DB5-AD63-9BB56A83A0FC@utoronto.ca>

Who said this was Excel? What did I miss?

B.


On Feb 3, 2016, at 3:52 PM, Ista Zahn <istazahn at gmail.com> wrote:

> On Wed, Feb 3, 2016 at 3:43 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> Not exactly.
>> 
>> If you have been "Excel"ed and have both formats in one column then you
>> really have a data cleanup task to do.
> 
> No need to reinvent the wheel. Just do
> 
> library(lubridate)
> mdy(c("09/01/15", "09/01/2015"))
> 
> Best,
> ista
> The best route to resolution is to
>> fix the source of the data (e.g. go back into Excel and reformat the column
>> with consistent formatting).
>> 
>> If you need to do this on an ongoing basis and cannot fix the data source,
>> then you might need to choose the correct format on the fly... something
>> like:
>> 
>> yYdates <- function( ds ) {
>>  fmt <- ifelse( grepl( "^\\d{1,2}/\\d{1,2}/\\d{2}$", ds )
>>               , "%m/%d/%y"
>>               , "%m/%d/%Y"
>>               )
>>  as.Date( ds, format=fmt )
>> }
>> 
>> yYdates( c( "02/18/2015", "03/21/16" ) )
>> [1] "2015-02-18" "2016-03-21"
>> 
>> but this would have to be tailored to the formatting problems in your data
>> and is not really a general solution.
>> 
>> On Wed, 3 Feb 2016, Boris Steipe wrote:
>> 
>>> As the documentation says, that's exactly what the expansion will do by
>>> default.
>>> 
>>> B.
>>> 
>>> 
>>> On Feb 3, 2016, at 2:31 PM, carol white <wht_crl at yahoo.com> wrote:
>>> 
>>>> yes, some of them are like 09/01/15 and some others are 09/01/2015 and
>>>> all of them range between 2015 and 2016. The goal was to convert 09/01/15 to
>>>> 09/01/2015. I don't know if the fact that they range between 2015 and 2016
>>>> make the task easier.
>>>> 
>>>> Best wishes
>>>> Carol
>>>> 
>>>> 
>>>> On Wednesday, February 3, 2016 7:34 PM, Boris Steipe
>>>> <boris.steipe at utoronto.ca> wrote:
>>>> 
>>>> 
>>>> Sorry - messed up example: corrected here...
>>>> 
>>>> d <- "7/27/77"
>>>> strptime(d, format="%m/%d/%y")  #  "1977-07-27 EDT"
>>>> x <- strptime(d, format="%m/%d/%y")
>>>> 
>>>> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
>>>> 
>>>> 
>>>> On Feb 3, 2016, at 1:29 PM, Boris Steipe <boris.steipe at utoronto.ca>
>>>> wrote:
>>>> 
>>>>> It seems your autocorrect is playing tricks on you but if I understand
>>>>> you correctly you have a two digit year and want to convert that to a four
>>>>> digit year? That's not uniquely possible of course; by convention, as the
>>>>> documentation to strptime() says:
>>>>> 
>>>>> On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 ? that
>>>>> 
>>>>> is the behaviour specified by the 2004 and 2008 POSIX standards...
>>>>> 
>>>>> If this is correct for you, you need to convert the string to a time
>>>>> object and the time object back to string. The format specifier %Y prints
>>>>> four-digit years:
>>>>> 
>>>>> 
>>>>> d <- "7/27/59"
>>>>> strptime(d, format="%m/%d/%y")  # "2059-07-27 EDT"
>>>>> x <- strptime(d, format="%m/%d/%y")
>>>>> 
>>>>> strftime(x, format="%m/%d/%Y")  # "07/27/1977"
>>>>> 
>>>>> 
>>>>> 
>>>>> B.
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Feb 3, 2016, at 11:03 AM, carol white via R-help
>>>>> <r-help at r-project.org> wrote:
>>>>> 
>>>>>> Hi,might be trivial but how to determine the year of a date which is in
>>>>>> the %m/%d/%y format and those whose year is century should be modified to
>>>>>> ISO so that all date will have with year in ISO?
>>>>>> Regards,
>>>>>> Carol
>>>>>> 
>>>>>>    [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Feb  3 22:13:23 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 4 Feb 2016 10:13:23 +1300
Subject: [R] [FORGED] Re:  determine the year of a date
In-Reply-To: <BE9A2447-1471-4DB5-AD63-9BB56A83A0FC@utoronto.ca>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
	<67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
	<alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>
	<CA+vqiLEpYyxU7BOUZ0QLQ0_ziPQs2ryU0X0fTSdFH4JVNion3Q@mail.gmail.com>
	<BE9A2447-1471-4DB5-AD63-9BB56A83A0FC@utoronto.ca>
Message-ID: <56B26D73.30501@auckland.ac.nz>

On 04/02/16 09:55, Boris Steipe wrote:
> Who said this was Excel? What did I miss?

If data have been fucked up, it is odds-on that Excel is to blame.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pdalgd at gmail.com  Wed Feb  3 22:26:20 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 3 Feb 2016 22:26:20 +0100
Subject: [R] [FORGED] Re:  determine the year of a date
In-Reply-To: <56B26D73.30501@auckland.ac.nz>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
	<67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
	<alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>
	<CA+vqiLEpYyxU7BOUZ0QLQ0_ziPQs2ryU0X0fTSdFH4JVNion3Q@mail.gmail.com>
	<BE9A2447-1471-4DB5-AD63-9BB56A83A0FC@utoronto.ca>
	<56B26D73.30501@auckland.ac.nz>
Message-ID: <F5624D98-FE4F-4024-8EBC-6469C7E85C4F@gmail.com>

Fortune candidate...

-pd

> On 03 Feb 2016, at 22:13 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 04/02/16 09:55, Boris Steipe wrote:
>> Who said this was Excel? What did I miss?
> 
> If data have been fucked up, it is odds-on that Excel is to blame.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sewashm at gmail.com  Wed Feb  3 22:49:08 2016
From: sewashm at gmail.com (Ashta)
Date: Wed, 3 Feb 2016 15:49:08 -0600
Subject: [R] LDheatmap
Message-ID: <CADDFq31Fp-z7TgNTex__o90LgR1Xk_i3qoQb6FcKaekaZWDWLA@mail.gmail.com>

Hi all,

I am  looking for an R package that calculates  a pair wise LD
(linkage disequilibrium) I came up with  library(LDheatmap).  has any
one used this library? I would appreciate if I get a help how to use
this library for my set of data..


My data set look like

Geno file
Name1 1 1 2 2 2 2
Name2 2 2 2 2 2 2
Name3 2 2 2 2 2 2
Name4  2 2 2 2 2 2
Name5 1 1 2 2 2 2


NameN  1   1 1 2 2 2 2


The other file is map file
Chromosome, SNP, Location (physical)


Thank you in advance


From bgunter.4567 at gmail.com  Wed Feb  3 23:00:44 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 3 Feb 2016 14:00:44 -0800
Subject: [R] LDheatmap
In-Reply-To: <CADDFq31Fp-z7TgNTex__o90LgR1Xk_i3qoQb6FcKaekaZWDWLA@mail.gmail.com>
References: <CADDFq31Fp-z7TgNTex__o90LgR1Xk_i3qoQb6FcKaekaZWDWLA@mail.gmail.com>
Message-ID: <CAGxFJbTKC2kv1ezJF_mA+dKgwBoPg1=Lq+vWNHxMPOO8pMJdXg@mail.gmail.com>

Have you looked here (found immediately by an internet search!)?

https://cran.r-project.org/web/packages/LDheatmap/vignettes/LDheatmap.pdf

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 3, 2016 at 1:49 PM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I am  looking for an R package that calculates  a pair wise LD
> (linkage disequilibrium) I came up with  library(LDheatmap).  has any
> one used this library? I would appreciate if I get a help how to use
> this library for my set of data..
>
>
> My data set look like
>
> Geno file
> Name1 1 1 2 2 2 2
> Name2 2 2 2 2 2 2
> Name3 2 2 2 2 2 2
> Name4  2 2 2 2 2 2
> Name5 1 1 2 2 2 2
>
>
> NameN  1   1 1 2 2 2 2
>
>
> The other file is map file
> Chromosome, SNP, Location (physical)
>
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Feb  4 00:17:24 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 Feb 2016 10:17:24 +1100
Subject: [R] [FORGED] Re: determine the year of a date
In-Reply-To: <F5624D98-FE4F-4024-8EBC-6469C7E85C4F@gmail.com>
References: <E2E6DB1E-810D-4A42-9C54-C29276465FB5@utoronto.ca>
	<1840158278.1014095.1454527908931.JavaMail.yahoo@mail.yahoo.com>
	<67D1796A-797F-4D09-A504-55B703DE1E32@utoronto.ca>
	<alpine.BSF.2.00.1602031239180.91469@pedal.dcn.davis.ca.us>
	<CA+vqiLEpYyxU7BOUZ0QLQ0_ziPQs2ryU0X0fTSdFH4JVNion3Q@mail.gmail.com>
	<BE9A2447-1471-4DB5-AD63-9BB56A83A0FC@utoronto.ca>
	<56B26D73.30501@auckland.ac.nz>
	<F5624D98-FE4F-4024-8EBC-6469C7E85C4F@gmail.com>
Message-ID: <CA+8X3fXkVdZSN+RDtC9Mz5bg7HpUKjBrLLUvY-O9t=5G4bU5nA@mail.gmail.com>

Hi all,
If you don't want Excel to surreptitiously "correct" dates that are not in
mm/dd/yyyy format, always specify international format yyyy-mm-dd in Excel.

Jim


On Thu, Feb 4, 2016 at 8:26 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> Fortune candidate...
>
> -pd
>
> > On 03 Feb 2016, at 22:13 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> > On 04/02/16 09:55, Boris Steipe wrote:
> >> Who said this was Excel? What did I miss?
> >
> > If data have been fucked up, it is odds-on that Excel is to blame.
> >
> > cheers,
> >
> > Rolf Turner
> >
>

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Thu Feb  4 00:25:32 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 3 Feb 2016 18:25:32 -0500
Subject: [R] Create macro_var in R
In-Reply-To: <812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
	<812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAP01uRniHVgY6uPi7UabtB9k66rLk9-VmaDfX8ZgN4Mym-jr1A@mail.gmail.com>

See

  Example 5.  Insert Variables

on the sqldf home page.

  https://github.com/ggrothendieck/sqldf


On Wed, Feb 3, 2016 at 2:16 PM, Amoy Yang via R-help
<r-help at r-project.org> wrote:
> First, MVAR<-c("population) should be the same as "population'". Correct?
> You use tab[[MVAR]] to refer to "population" where double [[...]] removes double quotes "...", which seemingly work for r-code although it is tedious in comparison direct application in SAS %let MVAR=population. But it does not work for sqldef in R as shown below.
>
>> key<-"pop"
>> library(sqldf)
>> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min,
> + max(pop) as max, avg(pop) as mean, median(pop) as median,
> + stdev(pop) as stdev from tab group by grade")
> Error in sqliteSendQuery(con, statement, bind.data) :
>   error in statement: near "[[key]": syntax error
>
>
>
>
>     On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt" <ruipbarradas at sapo.pt> wrote:
>
>
>  Hello,
>
> You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <- "population" (no need for c()).
>
> Hope this helps,
>
> Rui Barradas
>  Citando Amoy Yang via R-help <r-help at r-project.org>:
> population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:  %let MVAR=population;
> In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself since MVAR is defined as "population" with double quotes if using MVAR<-c("population")
>
>    On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>
> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>   There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> Thanks in advance for helps!
> R doesn't have a macro language, and you usually don't need one.
>
> If you are only reading the value of population, then
>
> MAVR <- population
>
> is fine.  This is sometimes the same as c(population), but in general
> it's different:  c() will remove some attributes, such as
> the dimensions on arrays.
>
> If you need to modify it in your program, it's likely more complicated.
> The normal way to go would be to put your code in a function, and have
> it return the modified version.  For example,
>
> population <- doModifications(population)
>
> where doModifications is a function with a definition like
>
> doModifications <- function(MAVR) {
>     # do all your calculations on MAVR
>     # then return it at the end using
>     MAVR
> }
>
> Duncan Murdoch
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From valkremk at gmail.com  Thu Feb  4 01:07:15 2016
From: valkremk at gmail.com (Val)
Date: Wed, 3 Feb 2016 18:07:15 -0600
Subject: [R] LDheatmap
In-Reply-To: <CAGxFJbTKC2kv1ezJF_mA+dKgwBoPg1=Lq+vWNHxMPOO8pMJdXg@mail.gmail.com>
References: <CADDFq31Fp-z7TgNTex__o90LgR1Xk_i3qoQb6FcKaekaZWDWLA@mail.gmail.com>
	<CAGxFJbTKC2kv1ezJF_mA+dKgwBoPg1=Lq+vWNHxMPOO8pMJdXg@mail.gmail.com>
Message-ID: <CAJOiR6aUvacA40aCX-rep0MQMvMqAvqYFfhL6M3yNYRKjL8BOA@mail.gmail.com>

Thank you Bert,

Yes I looked a this one and I was looking for if any one has used it or not
before?  My data set is different what they are showing in the paper





On Wed, Feb 3, 2016 at 4:00 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Have you looked here (found immediately by an internet search!)?
>
> https://cran.r-project.org/web/packages/LDheatmap/vignettes/LDheatmap.pdf
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 3, 2016 at 1:49 PM, Ashta <sewashm at gmail.com> wrote:
> > Hi all,
> >
> > I am  looking for an R package that calculates  a pair wise LD
> > (linkage disequilibrium) I came up with  library(LDheatmap).  has any
> > one used this library? I would appreciate if I get a help how to use
> > this library for my set of data..
> >
> >
> > My data set look like
> >
> > Geno file
> > Name1 1 1 2 2 2 2
> > Name2 2 2 2 2 2 2
> > Name3 2 2 2 2 2 2
> > Name4  2 2 2 2 2 2
> > Name5 1 1 2 2 2 2
> >
> >
> > NameN  1   1 1 2 2 2 2
> >
> >
> > The other file is map file
> > Chromosome, SNP, Location (physical)
> >
> >
> > Thank you in advance
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From putra_autumn86 at yahoo.com  Thu Feb  4 05:08:06 2016
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Thu, 4 Feb 2016 04:08:06 +0000 (UTC)
Subject: [R] Generate arrival of time based on uniform random number
References: <874004043.1213242.1454558886571.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <874004043.1213242.1454558886571.JavaMail.yahoo@mail.yahoo.com>

Hi everyone,
I have problem regarding to generate arrival of time based on uniform random number.
Let day0 = 0.383, lambda = 0.2612

1) Generate uniform random number (already settled) using the code below:
set.seed(1234)
rand.no <- function(n,itr){
? matrix(runif(n*itr, 0, 1), nrow=n, ncol=itr)
} 
x<-rand.no(10,1)
2) For day 1,
?? a) if 1st rand.no < day0, then its not rain,? else its rain (i want the rseult in next colum, let say rain)
3) For day 2 and so on ( it depend from next rain when it happened)
4) Next rain,
?? to know the next rain i need i need to calculate using the exponential 

? a) 1st rain = - ln (1st rand.no) / lambda
? b) 2nd nextRain = 1st rain - ln (2nd rand.no) / lambda
? c) 3rd nextRain = 2nd next rain - ln (3rd rand.no)/lambda,? and so on
?eg: if nextRain = 2.435, then 2nd day will rain


Hope anyone can help me solve this problems. Thanks so much.
????? 


? 



	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Feb  4 05:17:12 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 4 Feb 2016 17:17:12 +1300
Subject: [R] [FORGED] Generate arrival of time based on uniform random
 number
In-Reply-To: <874004043.1213242.1454558886571.JavaMail.yahoo@mail.yahoo.com>
References: <874004043.1213242.1454558886571.JavaMail.yahoo.ref@mail.yahoo.com>
	<874004043.1213242.1454558886571.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56B2D0C8.6090501@auckland.ac.nz>


This looks very much like a homework problem and this list has a "no 
homework" policy.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 04/02/16 17:08, smart hendsome via R-help wrote:
> Hi everyone,
> I have problem regarding to generate arrival of time based on uniform random number.
> Let day0 = 0.383, lambda = 0.2612
>
> 1) Generate uniform random number (already settled) using the code below:
> set.seed(1234)
> rand.no <- function(n,itr){
>    matrix(runif(n*itr, 0, 1), nrow=n, ncol=itr)
> }
> x<-rand.no(10,1)
> 2) For day 1,
>     a) if 1st rand.no < day0, then its not rain,  else its rain (i want the rseult in next colum, let say rain)
> 3) For day 2 and so on ( it depend from next rain when it happened)
> 4) Next rain,
>     to know the next rain i need i need to calculate using the exponential
>
>    a) 1st rain = - ln (1st rand.no) / lambda
>    b) 2nd nextRain = 1st rain - ln (2nd rand.no) / lambda
>    c) 3rd nextRain = 2nd next rain - ln (3rd rand.no)/lambda,  and so on
>   eg: if nextRain = 2.435, then 2nd day will rain
>
>
> Hope anyone can help me solve this problems. Thanks so much.


From alaios at yahoo.com  Thu Feb  4 08:34:28 2016
From: alaios at yahoo.com (Alaios)
Date: Thu, 4 Feb 2016 07:34:28 +0000 (UTC)
Subject: [R] [FORGED] find numbers that fall in a region or the next
 available.
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D7075BA@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D7075BA@mb02.ads.tamu.edu>
Message-ID: <1973279900.1280359.1454571268511.JavaMail.yahoo@mail.yahoo.com>

That is a great tip thanks.That would indeed bring me points that are the closes to my area.. but if I am not wront that returns points that are part of a circle surface. It might be that I get a point that is just 50 meters outside of my map area. Is not that true? I would need after I find closest point to confirm which ones fall inside my map region.
Alex
 

    On Wednesday, February 3, 2016 8:36 PM, David L Carlson <dcarlson at tamu.edu> wrote:
 

 Look at the point.in.polygon() and over() functions in package sp.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alaios via R-help
Sent: Wednesday, February 3, 2016 2:42 AM
To: Rolf Turner; R-help Mailing List
Subject: Re: [R] [FORGED] find numbers that fall in a region or the next available.

Thanks. I am using distm of the geoshere package.I still wonder if there is a package that can tell me if a gps coordinate or not fal

ls inside my area that is defined as:
bbox <- c(min(PlotPoints[, 1])-0.001, min(PlotPoints[, 2])-0.001, max(PlotPoints[, 1])+0.001, max(PlotPoints[, 2])+0.001)

PlotPoints are gps coordinates.
That would make it sure that I have no mistakes in my code.
Any ideas?Alex 

? ? On Tuesday, February 2, 2016 11:33 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:


 On 03/02/16 11:04, Alaios via R-help wrote:
> Dear all,I have GPS coordinates (one vector for longitude and one for
> latitude: GPSLong and GPSLat) of small are that is around 300meters X
> 300 meters (location falls inside UK).At the same time I have two
> more vectors (Longitude and Latitude) that include position of food
> stores again the UK I would like to find within my 300x300 square
> area which as the food stores that fall inside.I thought to try to
> find which of the Longitude of the food stores fall inside my area. I
> tried something the below
>
> Longitude[Longitude>(min(GPSLong)-0.001)&&Longitude<(max(GPSLong)+0.001)]
> but this returned me zero results.The next option would be the code
> to return me at least the place that falls outside but still is close
> to that region.'Do you have any idea how to do that and not fall back
> in the time consuming look at each element iteration?
> I would like to thank you for your reply


You could make use of the distfun() function from the spatstat package. 
? Represent your "small area" as an object of class "owin".? The
longitude and latitude coordinates will be treated as if they were 
Euclidean coordinates, but over distances of the order of 300 metres 
this should not matter much.? You could of course convert your long and 
lat coordinates to metres, using some appropriate projection, which 
might make more sense in your context.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From ashenkin at ufl.edu  Thu Feb  4 11:24:26 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Thu, 4 Feb 2016 10:24:26 +0000
Subject: [R] ggplot: geom_bar not respecting factor order when stacking
Message-ID: <56B326DA.8020300@ufl.edu>

Hi all,

ggplot2 (v2.0.0) does not seem to respect factor order when stacking 
bars in geom_bar().

##################
 > dput(temp)
structure(list(phylo_sig = c(0.148740270638472, 0.148740270638472,
0.148740270638472, 0.148740270638472, 0.148740270638472), trait = 
c("p_corrected_percent",
"p_corrected_percent", "p_corrected_percent", "p_corrected_percent",
"p_corrected_percent"), value = c(0.031015586683513, 0.0553330412480036,
0.73674222087599, 0.114517508485538, 0.0623916427069555), varlevel = 
structure(c(3L,
2L, 4L, 5L, 1L), .Label = c("species", "genus", "family", "plot_code",
"Residual"), class = "factor")), .Names = c("phylo_sig", "trait",
"value", "varlevel"), row.names = c(28L, 62L, 96L, 130L, 164L
), class = "data.frame")
 > str(temp)
'data.frame':    5 obs. of  4 variables:
  $ phylo_sig: num  0.149 0.149 0.149 0.149 0.149
  $ trait    : chr  "p_corrected_percent" "p_corrected_percent" 
"p_corrected_percent" "p_corrected_percent" ...
  $ value    : num  0.031 0.0553 0.7367 0.1145 0.0624
  $ varlevel : Factor w/ 5 levels "species","genus",..: 3 2 4 5 1
 > ggplot(temp, aes(x=trait, y = value)) + geom_bar(stat = "identity", 
aes(fill=varlevel, order = varlevel))
##################

The code above results in the correct legend order, but incorrect order 
of stacking (https://i.imgur.com/lgAxTFh.png).  I have to change the 
order of the actual dataframe rows in order to coerce the stacking to work:

##################
 > temp = temp[c(5,2,1,3,4),]
 > ggplot(temp, aes(x=trait, y = value)) + geom_bar(stat = "identity", 
aes(fill=varlevel, order = varlevel))
##################

This results in correct stacking (https://i.imgur.com/baww43x.png).  Any 
assistance in getting ggplot to pay attention to the factor ordering 
when stacking bars would be much appreciated!

Thanks,
Allie


From marammagdysalem at gmail.com  Thu Feb  4 11:31:21 2016
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Thu, 4 Feb 2016 12:31:21 +0200
Subject: [R] Metropolis-within-Gibbs algorithm
Message-ID: <CAPLSCn3aKTQ_S=vf__KsgOY=NQGFo98C9kA=h1LUcX40JA5Qdg@mail.gmail.com>

Hi all,

I'm trying to write a code that performs the Metropolis-within-Gibbs
algorithm, to draw values of a 2x1 parameter vector from a posterior
distribution that doesn't have a well known form.

So one of the parameters, theta1, has a well known full conditional
distribution( for which the gibbs sampler can be used), but the other,
theta2, doesn't have a well known full conditional (for which a random walk
Metropolis-Hastings algorithm should be used). But theta1 depends on the
generated value of theta 2.

I know this code can be hand-written, but is there any package that can
perform such update of the Metropolis-within-gibbs algorithm and provide me
with acceptance rates or different scaling for the proposal distribution?
 I've checked the gibbs.met package but it used an independent proposal
distribution. I went through the MCMCpack but couldn't find a function that
performs what I want.

So is there any other packages that you recommend or do I have to write my
own functions?

Thanks for helping,
Maram Salem

	[[alternative HTML version deleted]]


From ste.depo.bio at gmail.com  Thu Feb  4 11:00:11 2016
From: ste.depo.bio at gmail.com (Stefano de Pretis)
Date: Thu, 4 Feb 2016 11:00:11 +0100
Subject: [R] Subset with missing argument within a function
Message-ID: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>

Hi all,

I'm guessing what's the rationale behind this:

> subsettingFun <- function(vec, ix) vec[ix]
> subsettingFun(letters, c(1,2,5))
[1] "a" "b" "e"
> subsettingFun(letters)
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
"r" "s"
[20] "t" "u" "v" "w" "x" "y" "z"

If the argument "ix" is missing, I'm expecting an error not to return the
variable "vec" as it is.

I think this is VERY dangerous and does not help the development of
reliable code and the debugging.

Cheers,

Stefano

*Center for Genomic Science of IIT at SEMM*

Stefano de Pretis, PhD

*Postdoctoral fellow *

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Feb  4 15:14:50 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 4 Feb 2016 14:14:50 +0000
Subject: [R] [FORGED] find numbers that fall in a region or the next
 available.
In-Reply-To: <1973279900.1280359.1454571268511.JavaMail.yahoo@mail.yahoo.com>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D7075BA@mb02.ads.tamu.edu>
	<1973279900.1280359.1454571268511.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D707805@mb02.ads.tamu.edu>

Assuming your map area can be described as a closed polygon, these functions would tell you which points lie within the boundaries of the polygon.

David C

From: Alaios [mailto:alaios at yahoo.com] 
Sent: Thursday, February 4, 2016 1:34 AM
To: David L Carlson; r-help at r-project.org
Subject: Re: [R] [FORGED] find numbers that fall in a region or the next available.

That is a great tip thanks.
That would indeed bring me points that are the closes to my area.. but if I am not wront that returns points that are part of a circle surface. It might be that I get a point that is just 50 meters outside of my map area. Is not that true? I would need after I find closest point to confirm which ones fall inside my map region.

Alex

On Wednesday, February 3, 2016 8:36 PM, David L Carlson <dcarlson at tamu.edu> wrote:

Look at the point.in.polygon() and over() functions in package sp.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alaios via R-help
Sent: Wednesday, February 3, 2016 2:42 AM
To: Rolf Turner; R-help Mailing List
Subject: Re: [R] [FORGED] find numbers that fall in a region or the next available.

Thanks. I am using distm of the geoshere package.I still wonder if there is a package that can tell me if a gps coordinate or not fal

ls inside my area that is defined as:
bbox <- c(min(PlotPoints[, 1])-0.001, min(PlotPoints[, 2])-0.001, max(PlotPoints[, 1])+0.001, max(PlotPoints[, 2])+0.001)

PlotPoints are gps coordinates.
That would make it sure that I have no mistakes in my code.
Any ideas?Alex 

? ? On Tuesday, February 2, 2016 11:33 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:


On 03/02/16 11:04, Alaios via R-help wrote:
> Dear all,I have GPS coordinates (one vector for longitude and one for
> latitude: GPSLong and GPSLat) of small are that is around 300meters X
> 300 meters (location falls inside UK).At the same time I have two
> more vectors (Longitude and Latitude) that include position of food
> stores again the UK I would like to find within my 300x300 square
> area which as the food stores that fall inside.I thought to try to
> find which of the Longitude of the food stores fall inside my area. I
> tried something the below
>
> Longitude[Longitude>(min(GPSLong)-0.001)&&Longitude<(max(GPSLong)+0.001)]
> but this returned me zero results.The next option would be the code
> to return me at least the place that falls outside but still is close
> to that region.'Do you have any idea how to do that and not fall back
> in the time consuming look at each element iteration?
> I would like to thank you for your reply


You could make use of the distfun() function from the spatstat package. 
? Represent your "small area" as an object of class "owin".? The 
longitude and latitude coordinates will be treated as if they were 
Euclidean coordinates, but over distances of the order of 300 metres 
this should not matter much.? You could of course convert your long and 
lat coordinates to metres, using some appropriate projection, which 
might make more sense in your context.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bolseiro.raiz.csilva at portucelsoporcel.com  Thu Feb  4 10:57:14 2016
From: bolseiro.raiz.csilva at portucelsoporcel.com (Catarina Silva)
Date: Thu, 4 Feb 2016 09:57:14 -0000
Subject: [R] Package for error analysis
Message-ID: <000001d15f32$6cc30a20$46491e60$@portucelsoporcel.com>

Hi,

I'm doing error analysis of predictive models and I need to calculate global
error, this is, I need to calculate the resultant error from propagation of
indirect measurements errors.

I know a little about propagation error theory, using derivation formulas to
calculate it, but I want to know if exists some package to do it.

 

Ty

Catarina  




	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb  4 15:26:35 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 4 Feb 2016 14:26:35 +0000
Subject: [R] ggplot: geom_bar not respecting factor order when stacking
In-Reply-To: <56B326DA.8020300@ufl.edu>
References: <56B326DA.8020300@ufl.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CA9E@SRVEXCHMBX.precheza.cz>

Hi

So if the legend is in correct order you need to reorder the sequence of bars from top/bottom to bottom/top here is one solution.

ggplot(temp, aes(x=trait, y = value)) + geom_bar(stat = "identity",
aes(fill=varlevel, order= -as.numeric(varlevel)))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Alexander Shenkin
> Sent: Thursday, February 04, 2016 11:24 AM
> To: r-help at r-project.org
> Subject: [R] ggplot: geom_bar not respecting factor order when stacking
>
> Hi all,
>
> ggplot2 (v2.0.0) does not seem to respect factor order when stacking
> bars in geom_bar().
>
> ##################
>  > dput(temp)
> structure(list(phylo_sig = c(0.148740270638472, 0.148740270638472,
> 0.148740270638472, 0.148740270638472, 0.148740270638472), trait =
> c("p_corrected_percent",
> "p_corrected_percent", "p_corrected_percent", "p_corrected_percent",
> "p_corrected_percent"), value = c(0.031015586683513,
> 0.0553330412480036,
> 0.73674222087599, 0.114517508485538, 0.0623916427069555), varlevel =
> structure(c(3L,
> 2L, 4L, 5L, 1L), .Label = c("species", "genus", "family", "plot_code",
> "Residual"), class = "factor")), .Names = c("phylo_sig", "trait",
> "value", "varlevel"), row.names = c(28L, 62L, 96L, 130L, 164L
> ), class = "data.frame")
>  > str(temp)
> 'data.frame':    5 obs. of  4 variables:
>   $ phylo_sig: num  0.149 0.149 0.149 0.149 0.149
>   $ trait    : chr  "p_corrected_percent" "p_corrected_percent"
> "p_corrected_percent" "p_corrected_percent" ...
>   $ value    : num  0.031 0.0553 0.7367 0.1145 0.0624
>   $ varlevel : Factor w/ 5 levels "species","genus",..: 3 2 4 5 1
>  > ggplot(temp, aes(x=trait, y = value)) + geom_bar(stat = "identity",
> aes(fill=varlevel, order = varlevel))
> ##################
>
> The code above results in the correct legend order, but incorrect order
> of stacking (https://i.imgur.com/lgAxTFh.png).  I have to change the
> order of the actual dataframe rows in order to coerce the stacking to
> work:
>
> ##################
>  > temp = temp[c(5,2,1,3,4),]
>  > ggplot(temp, aes(x=trait, y = value)) + geom_bar(stat = "identity",
> aes(fill=varlevel, order = varlevel))
> ##################
>
> This results in correct stacking (https://i.imgur.com/baww43x.png).
> Any
> assistance in getting ggplot to pay attention to the factor ordering
> when stacking bars would be much appreciated!
>
> Thanks,
> Allie
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Feb  4 15:39:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 4 Feb 2016 14:39:16 +0000
Subject: [R] Subset with missing argument within a function
In-Reply-To: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>
References: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CAB1@SRVEXCHMBX.precheza.cz>

Hi

Help page for ?"[" says

An empty index selects all values: this is most often used to replace all the entries but keep the attributes.

and actually you function construction works with empty index

> x<-c(1,2,5)
> letters[x]
[1] "a" "b" "e"
> letters[]
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q" "r" "s"
[20] "t" "u" "v" "w" "x" "y" "z"

It is sometimes useful not "expect" the program behavior but "inspect" why it behaves differently.

If you want your function to throw error when some arguments are missing you need to do the check yourself and not rely on programming language.

And BTW I did not know an answer before I inspected docs.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefano
> de Pretis
> Sent: Thursday, February 04, 2016 11:00 AM
> To: r-help at r-project.org
> Subject: [R] Subset with missing argument within a function
>
> Hi all,
>
> I'm guessing what's the rationale behind this:
>
> > subsettingFun <- function(vec, ix) vec[ix]
> > subsettingFun(letters, c(1,2,5))
> [1] "a" "b" "e"
> > subsettingFun(letters)
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p"
> "q"
> "r" "s"
> [20] "t" "u" "v" "w" "x" "y" "z"
>
> If the argument "ix" is missing, I'm expecting an error not to return
> the
> variable "vec" as it is.
>
> I think this is VERY dangerous and does not help the development of
> reliable code and the debugging.
>
> Cheers,
>
> Stefano
>
> *Center for Genomic Science of IIT at SEMM*
>
> Stefano de Pretis, PhD
>
> *Postdoctoral fellow *
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jbustosmelo at gmail.com  Thu Feb  4 15:43:29 2016
From: jbustosmelo at gmail.com (=?UTF-8?B?Sm9zw6kgQnVzdG9z?=)
Date: Thu, 4 Feb 2016 11:43:29 -0300
Subject: [R] R project and the TPP
Message-ID: <CALwjrWQSt_v4L9i725e4igf8it8Bk8R-TROB=gDLJtGt6G7MTA@mail.gmail.com>

Hi everyone,

I have a question regarding the use R software under the new TPP laws
adopted by some governments in the region. Who know how this new agreements
will affect researchers and the R community?

Hope some of you knows better and can give ideas about it.

saludos,
Jos?

	[[alternative HTML version deleted]]


From shivi.bhatia at safexpress.com  Thu Feb  4 09:33:13 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Thu, 04 Feb 2016 14:03:13 +0530
Subject: [R] Paste Funtion Help
Message-ID: <000001d15f26$a3b418a0$eb1c49e0$@safexpress.com>

HI Team, 

 

Need help with the below syntax.

 

merge.salaries[, name:=paste("nameFirst","nameLast")]. Here merge.salaries
is the data set I have merged. 

 

There are 2 columns nameFirst and nameLast I need to merge these two into
one and name as name however I can getting an error:

 

Error in `[.data.frame`(merge.salaries, , `:=`(name, paste("nameFirst",  : 

  could not find function ":="

 

Please advice. 

 

Thanks, Shivi

Mb: 9891002021

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160204/99039a80/attachment.pl>

From ste.depo.bio at gmail.com  Thu Feb  4 16:47:33 2016
From: ste.depo.bio at gmail.com (Stefano de Pretis)
Date: Thu, 4 Feb 2016 16:47:33 +0100
Subject: [R] Subset with missing argument within a function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CAB1@SRVEXCHMBX.precheza.cz>
References: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CAB1@SRVEXCHMBX.precheza.cz>
Message-ID: <CABj-uJdcgrHULvVw-SuvaSpQfCaJu-U2vA1Sm-YF=P8YiMnE9g@mail.gmail.com>

Hi Petr,

Thank you for your answer.

I'm not sure how the empty index reflects what I'm showing in my example.
If my function was

emptySubset <- function(vec) vec[]

I would then agree that this was the case. But I think it's different: I'm
specifically telling my function that it should have two arguments ("vec"
and "ix")

subsettingFun <- function(vec, ix) vec[ix]

and I guess why, within the function, it does not happen what happens on
the command line:

> ix
Error: object 'ix' not found
> letters[ix]
Error: object 'ix' not found

My "expectation" came from a matter of coherence, but probably I'm still
missing something.

Regards,

Stefano



2016-02-04 15:39 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> Help page for ?"[" says
>
> An empty index selects all values: this is most often used to replace all
> the entries but keep the attributes.
>
> and actually you function construction works with empty index
>
> > x<-c(1,2,5)
> > letters[x]
> [1] "a" "b" "e"
> > letters[]
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
> "r" "s"
> [20] "t" "u" "v" "w" "x" "y" "z"
>
> It is sometimes useful not "expect" the program behavior but "inspect" why
> it behaves differently.
>
> If you want your function to throw error when some arguments are missing
> you need to do the check yourself and not rely on programming language.
>
> And BTW I did not know an answer before I inspected docs.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefano
> > de Pretis
> > Sent: Thursday, February 04, 2016 11:00 AM
> > To: r-help at r-project.org
> > Subject: [R] Subset with missing argument within a function
> >
> > Hi all,
> >
> > I'm guessing what's the rationale behind this:
> >
> > > subsettingFun <- function(vec, ix) vec[ix]
> > > subsettingFun(letters, c(1,2,5))
> > [1] "a" "b" "e"
> > > subsettingFun(letters)
> >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p"
> > "q"
> > "r" "s"
> > [20] "t" "u" "v" "w" "x" "y" "z"
> >
> > If the argument "ix" is missing, I'm expecting an error not to return
> > the
> > variable "vec" as it is.
> >
> > I think this is VERY dangerous and does not help the development of
> > reliable code and the debugging.
> >
> > Cheers,
> >
> > Stefano
> >
> > *Center for Genomic Science of IIT at SEMM*
> >
> > Stefano de Pretis, PhD
> >
> > *Postdoctoral fellow *
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Feb  4 17:33:29 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 4 Feb 2016 16:33:29 +0000
Subject: [R] Has R-help changed reply-to policy?
Message-ID: <1A8C1289955EF649A09086A153E2672403D0E319B5@GBTEDVPEXCMB04.corp.lgc-group.com>

Apologies if I've missed a post, but have the default treatment of posts and reply-to changed on R-Help of late?

I ask because as of today, my email client now only lists the OP email when replying to an R-help message, even with a reply-all, so the default reply is not to the list.
I also noticed a few months back that I no longer see my own posts, other than as a receipt notification, and tinkering with my account defaults doesn't change that.

I don't _think_ things have changed at my end ...

Steve Ellison





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From Ted.Harding at wlandres.net  Thu Feb  4 18:03:44 2016
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 04 Feb 2016 17:03:44 -0000 (GMT)
Subject: [R] Has R-help changed reply-to policy?
In-Reply-To: <1A8C1289955EF649A09086A153E2672403D0E319B5@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <XFMail.20160204170344.Ted.Harding@wlandres.net>

Steve, I'm inclined to suspect that something *has* changed at your end
(or along the line between you and R-help). In replying to your message,
selecting "include all recipients" (i.e. reply to all), the result was:
  To: S Ellison <S.Ellison at LGCGroup.com>
  Cc: r-help at r-project.org
just as it always has been! So no change that *I* can perceive at the
R-help end.

Hoping this is useful,
Ted.

On 04-Feb-2016 16:33:29 S Ellison wrote:
> Apologies if I've missed a post, but have the default treatment of posts and
> reply-to changed on R-Help of late?
> 
> I ask because as of today, my email client now only lists the OP email when
> replying to an R-help message, even with a reply-all, so the default reply is
> not to the list.
> I also noticed a few months back that I no longer see my own posts, other
> than as a receipt notification, and tinkering with my account defaults
> doesn't change that.
> 
> I don't _think_ things have changed at my end ...
> 
> Steve Ellison

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 04-Feb-2016  Time: 17:03:37
This message was sent by XFMail


From ulrik.stervbo at gmail.com  Thu Feb  4 18:12:46 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 04 Feb 2016 17:12:46 +0000
Subject: [R] Paste Funtion Help
In-Reply-To: <000001d15f26$a3b418a0$eb1c49e0$@safexpress.com>
References: <000001d15f26$a3b418a0$eb1c49e0$@safexpress.com>
Message-ID: <CAKVAULPVQjfB6-W-HdGcCjfNw=EPFa9cv4Z0xf8vhiOFr6D54g@mail.gmail.com>

Hi Shivi,

I usually do

merge.salaries$name <- paste(merge.salaries$nameFirst,
merge.salaries$nameLast)

also if merge.salaries[, name:=paste("nameFirst","nameLast")] would work,
you would end up with a column full of "nameFirst nameLast".

Best,
Ulrik

On Thu, 4 Feb 2016 at 17:32 SHIVI BHATIA <shivi.bhatia at safexpress.com>
wrote:

> HI Team,
>
>
>
> Need help with the below syntax.
>
>
>
> merge.salaries[, name:=paste("nameFirst","nameLast")]. Here merge.salaries
> is the data set I have merged.
>
>
>
> There are 2 columns nameFirst and nameLast I need to merge these two into
> one and name as name however I can getting an error:
>
>
>
> Error in `[.data.frame`(merge.salaries, , `:=`(name, paste("nameFirst",  :
>
>   could not find function ":="
>
>
>
> Please advice.
>
>
>
> Thanks, Shivi
>
> Mb: 9891002021
>
>
>
> This e-mail is confidential. It may also be legally privileged. If you are
> not the addressee you may not copy, forward, disclose or use any part of
> it. If you have received this message in error, please delete it and all
> copies from your system and notify the sender immediately by return e-mail.
> Internet communications cannot be guaranteed to be timely, secure, error or
> virus-free. The sender does not accept liability for any errors or
> omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb  4 18:18:51 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 4 Feb 2016 09:18:51 -0800
Subject: [R] Paste Funtion Help
In-Reply-To: <CAKVAULPVQjfB6-W-HdGcCjfNw=EPFa9cv4Z0xf8vhiOFr6D54g@mail.gmail.com>
References: <000001d15f26$a3b418a0$eb1c49e0$@safexpress.com>
	<CAKVAULPVQjfB6-W-HdGcCjfNw=EPFa9cv4Z0xf8vhiOFr6D54g@mail.gmail.com>
Message-ID: <CAGxFJbSrR1y7ZhwKFW1iNy4k8Lc+qY089qXbGhK2agn42P+2oQ@mail.gmail.com>

The problem in the original post is, as clearly stated , the ":=",
which is some other language, not R. From which I infer that the OP
needs to spend some additional time with an R tutorial or two to learn
R.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 4, 2016 at 9:12 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Shivi,
>
> I usually do
>
> merge.salaries$name <- paste(merge.salaries$nameFirst,
> merge.salaries$nameLast)
>
> also if merge.salaries[, name:=paste("nameFirst","nameLast")] would work,
> you would end up with a column full of "nameFirst nameLast".
>
> Best,
> Ulrik
>
> On Thu, 4 Feb 2016 at 17:32 SHIVI BHATIA <shivi.bhatia at safexpress.com>
> wrote:
>
>> HI Team,
>>
>>
>>
>> Need help with the below syntax.
>>
>>
>>
>> merge.salaries[, name:=paste("nameFirst","nameLast")]. Here merge.salaries
>> is the data set I have merged.
>>
>>
>>
>> There are 2 columns nameFirst and nameLast I need to merge these two into
>> one and name as name however I can getting an error:
>>
>>
>>
>> Error in `[.data.frame`(merge.salaries, , `:=`(name, paste("nameFirst",  :
>>
>>   could not find function ":="
>>
>>
>>
>> Please advice.
>>
>>
>>
>> Thanks, Shivi
>>
>> Mb: 9891002021
>>
>>
>>
>> This e-mail is confidential. It may also be legally privileged. If you are
>> not the addressee you may not copy, forward, disclose or use any part of
>> it. If you have received this message in error, please delete it and all
>> copies from your system and notify the sender immediately by return e-mail.
>> Internet communications cannot be guaranteed to be timely, secure, error or
>> virus-free. The sender does not accept liability for any errors or
>> omissions.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Feb  4 18:19:20 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 4 Feb 2016 09:19:20 -0800
Subject: [R] Subset with missing argument within a function
In-Reply-To: <CABj-uJdcgrHULvVw-SuvaSpQfCaJu-U2vA1Sm-YF=P8YiMnE9g@mail.gmail.com>
References: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CAB1@SRVEXCHMBX.precheza.cz>
	<CABj-uJdcgrHULvVw-SuvaSpQfCaJu-U2vA1Sm-YF=P8YiMnE9g@mail.gmail.com>
Message-ID: <CAF8bMcY_Wc7EL9GxxGMGCnRdG+WLzQsn7Sh+9NFL_0d0PdDvLw@mail.gmail.com>

The "missingness" of an argument gets passed down through nested function
calls.  E.g.,
  fOuter <- function(x) c(outerMissing=missing(x), innerMissing=fInner(x))
  fInner <- function(x) missing(x)
  fInner()
  #[1] TRUE
  fOuter()
  #outerMissing innerMissing
  #      TRUE         TRUE
It is only when a function evaluates an argument that you get a message
like 'argument is missing, with no default'.  ('[' checks for missingness
before
evaluating a subscript argument so it will not give that error.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Feb 4, 2016 at 7:47 AM, Stefano de Pretis <ste.depo.bio at gmail.com>
wrote:

> Hi Petr,
>
> Thank you for your answer.
>
> I'm not sure how the empty index reflects what I'm showing in my example.
> If my function was
>
> emptySubset <- function(vec) vec[]
>
> I would then agree that this was the case. But I think it's different: I'm
> specifically telling my function that it should have two arguments ("vec"
> and "ix")
>
> subsettingFun <- function(vec, ix) vec[ix]
>
> and I guess why, within the function, it does not happen what happens on
> the command line:
>
> > ix
> Error: object 'ix' not found
> > letters[ix]
> Error: object 'ix' not found
>
> My "expectation" came from a matter of coherence, but probably I'm still
> missing something.
>
> Regards,
>
> Stefano
>
>
>
> 2016-02-04 15:39 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
>
> > Hi
> >
> > Help page for ?"[" says
> >
> > An empty index selects all values: this is most often used to replace all
> > the entries but keep the attributes.
> >
> > and actually you function construction works with empty index
> >
> > > x<-c(1,2,5)
> > > letters[x]
> > [1] "a" "b" "e"
> > > letters[]
> >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
> > "r" "s"
> > [20] "t" "u" "v" "w" "x" "y" "z"
> >
> > It is sometimes useful not "expect" the program behavior but "inspect"
> why
> > it behaves differently.
> >
> > If you want your function to throw error when some arguments are missing
> > you need to do the check yourself and not rely on programming language.
> >
> > And BTW I did not know an answer before I inspected docs.
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Stefano
> > > de Pretis
> > > Sent: Thursday, February 04, 2016 11:00 AM
> > > To: r-help at r-project.org
> > > Subject: [R] Subset with missing argument within a function
> > >
> > > Hi all,
> > >
> > > I'm guessing what's the rationale behind this:
> > >
> > > > subsettingFun <- function(vec, ix) vec[ix]
> > > > subsettingFun(letters, c(1,2,5))
> > > [1] "a" "b" "e"
> > > > subsettingFun(letters)
> > >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p"
> > > "q"
> > > "r" "s"
> > > [20] "t" "u" "v" "w" "x" "y" "z"
> > >
> > > If the argument "ix" is missing, I'm expecting an error not to return
> > > the
> > > variable "vec" as it is.
> > >
> > > I think this is VERY dangerous and does not help the development of
> > > reliable code and the debugging.
> > >
> > > Cheers,
> > >
> > > Stefano
> > >
> > > *Center for Genomic Science of IIT at SEMM*
> > >
> > > Stefano de Pretis, PhD
> > >
> > > *Postdoctoral fellow *
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> > vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> > ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> > intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> > sender. Delete the contents of this e-mail with all attachments and its
> > copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> > authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> > caused by modifications of the e-mail or by delay with transfer of the
> > email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> > contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> > immediately accept such offer; The sender of this e-mail (offer) excludes
> > any acceptance of the offer on the part of the recipient containing any
> > amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> > upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter
> > into any contracts on behalf of the company except for cases in which
> > he/she is expressly authorized to do so in writing, and such
> authorization
> > or power of attorney is submitted to the recipient or the person
> > represented by the recipient, or the existence of such authorization is
> > known to the recipient of the person represented by the recipient.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb  4 18:21:26 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 4 Feb 2016 12:21:26 -0500
Subject: [R] Paste Funtion Help
In-Reply-To: <000001d15f26$a3b418a0$eb1c49e0$@safexpress.com>
References: <000001d15f26$a3b418a0$eb1c49e0$@safexpress.com>
Message-ID: <56B38896.4040904@gmail.com>

On 04/02/2016 3:33 AM, SHIVI BHATIA wrote:
> HI Team,
>
>   
>
> Need help with the below syntax.
>
>   
>
> merge.salaries[, name:=paste("nameFirst","nameLast")]. Here merge.salaries
> is the data set I have merged.
>
>   
>
> There are 2 columns nameFirst and nameLast I need to merge these two into
> one and name as name however I can getting an error:
>
>   
>
> Error in `[.data.frame`(merge.salaries, , `:=`(name, paste("nameFirst",  :
>
>    could not find function ":="

It looks as though you're using syntax defined by the data.table 
package, but you don't have it attached.

Duncan Murdoch
>
>   
>
> Please advice.
>
>   
>
> Thanks, Shivi
>
> Mb: 9891002021
>
>   
>
>
>
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From remilesmerises at yahoo.ca  Thu Feb  4 17:50:04 2016
From: remilesmerises at yahoo.ca (=?UTF-8?Q?R=C3=A9mi_Lesmerises?=)
Date: Thu, 4 Feb 2016 16:50:04 +0000 (UTC)
Subject: [R] Conditional (paired) design for binomial regression in MCMCglmm
References: <71613949.1856513.1454604604069.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <71613949.1856513.1454604604069.JavaMail.yahoo@mail.yahoo.com>


| This is my first attempt asking question in this forum and I do it because thorough research on the web didn't give me any answer.I am trying to accomodate a conditional regression in a Bayesian generalized linear mixed model using Monte Carlo Markov Chain. I am using the package {MCMCglmm} in R. I already did such analysis with the {coxme} package and it worked well, but as I want to access random slope, it seems that I must use such approach to decrease the bias of estimates (Hadfield 2010). I (partly) understand how to code for binomial regression (link logit) in MCMCglmm but I cannot find any indication for paired design. Here an example of my dataset.data(bear)

  Id  Strata   Site Real_rand  Spruce  Fir    Road
Adele  Ade-1  Ade-1         1      3   60   100.49
Adele  Ade-1 Ade-1A         0      5   58    89.22
Adele  Ade-1 Ade-1B         0      2   37   109.79
Adele  Ade-2  Ade-2         1      1  103   198.48
Adele  Ade-2 Ade-2A         0      0  192   199.26
Adele  Ade-2 Ade-2B         0      0   53   201.61
Sally  Sal-7  Sal-7         1      0    2     7.02
Sally  Sal-7 Sal-7A         0     40    0    94.40
Sally  Sal-7 Sal-7B         0      2    3    16.58
Sally  Sal-8  Sal-8         1      2   21    48.74
Sally  Sal-8 Sal-8A         0      8   17   112.75
Sally  Sal-8 Sal-8B         0     63    0   205.04It is a black bear habitat selection analysis, with used sites (variable Real_rand coded 1) compared with available sites (coded 0). It is a paired design because available sites were randomly drawn within a buffer zone around used site. I wonder if strata, nested in Id, could used as random factor and provide similar result than cox regression. Here an example of what it could looks like:prior <- list(R = list(V = 1, nu = 0.002), G = list(G1 = list(V = 1, nu=0.002),
         (G2 = list(V = 1, nu=0.002)))


mod1 <- MCMCglmm(Real_rand ~ Spruce + Fir + Road, random = ~Strata:Id + us(Road):Id, 
        family = "categorical", data = bear, prior = prior, verbose = FALSE, pr = TRUE)I added a random slope (us(Road):Id) to have individual coefficient for road selection. There is probably many errors, both in the prior formula and the glm call, but if anyone can help me to find a way to code it more correctly, I would be grateful! |

?R?mi L.
	[[alternative HTML version deleted]]


From Lluis.Hurtado at uv.es  Thu Feb  4 18:42:56 2016
From: Lluis.Hurtado at uv.es (Lluis.Hurtado at uv.es)
Date: Thu, 4 Feb 2016 18:42:56 +0100 (CET)
Subject: [R] LaplacesDemon package installation
Message-ID: <8788892359hurgil@uv.es>

Dear all,

I've recently changed my Mac and I am trying to reinstall my commonly used R-packages. I'm having troubles with a package called LaplacesDemon.

This package is no more in the CRAN list and the developers web page (http://www.bayesian-inference.com/software) is out for more than half a year. Old versions of the package can still be found in tar.gz in

https://cran.r-project.org/src/contrib/Archive/LaplacesDemon/

and in github

https://github.com/ecbrown/LaplacesDemon

Last version is LaplacesDemon_13.03.04.tar.gz, but I was able to get version LaplacesDemon_15.03.19.tar.gz time ago (can't find it anymore).

I have tried to install this packages from source in my computer using 

> install.packages("/Users/.../LaplacesDemon_15.03.19.tar.gz", repos = NULL, type="source")

answer:

> Warning: invalid package 'Users/.../LaplacesDemon_15.03.19.tar.gz?
>Error: ERROR: no packages specified
>Warning message:
>In install.packages("Users/.../LaplacesDemon_15.03.19.tar.gz",  :
  installation of package ?Users/.../LaplacesDemon_15.03.19.tar.gz? had non-zero exit status

I also tried the 'Packages & Data' menu in R, selecting the source file or the directory from Finder and I got this message:

> * installing *source* package ?LaplacesDemon? ...
> ** R
> ** data
> ** inst
> ** byte-compile and prepare package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> * DONE (LaplacesDemon)

but

> library(LaplacesDemon)
Error in library(LaplacesDemon) : 
  there is no package called ?LaplacesDemon?

Finally I tried 

> install.packages("devtools")
> library(devtools)
> install_github("ecbrown/LaplacesDemon")

but I am not able to install devtools (for similar reasons). So my questions are:

-Do anyone knows how to install this packages in my Mac?
-Do anyone knows were can I find the information previously content in http://www.bayesian-inference.com/software?

Thank you,

Llu?s Hurtado
PhD student
OAUV


From shyam.kumar.basnet at slu.se  Thu Feb  4 19:25:37 2016
From: shyam.kumar.basnet at slu.se (Shyam Kumar Basnet)
Date: Thu, 4 Feb 2016 18:25:37 +0000
Subject: [R] Elasticities in Nested logit model
Message-ID: <feafeb370242491d9d481c67392d3689@EXCH2-1.slu.se>

Dear all,

I am trying to compute the elasticities based on the Nested Logit Model.

I have been following the book "Econometric Analysis by Greene (2002)".

I am first trying to re-produce the ELASTICITIES as reported by Greene(2002), and then plan to replicate with my original data.

Unfortunately, I could not re-produce the output given by Greene.

Could you please suggest me some papers or Software package estimating ELASTICITIES based on the Nested Logit Model?

Thanks,

Best,
Shyam Basnet
Sweden


	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Feb  4 22:23:05 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 5 Feb 2016 10:23:05 +1300
Subject: [R] LaplacesDemon package installation
In-Reply-To: <8788892359hurgil@uv.es>
References: <8788892359hurgil@uv.es>
Message-ID: <56B3C139.60209@auckland.ac.nz>


(1) You might get better mileage asking this on the r-sig-mac list.

(2) The phenomena you describe are puzzling and are beyond my capacity 
to explain.  Perhaps someone else will be able to enlighten you.

(3) Out of idle curiosity I went to the github site and downloaded the
zip file of the package.  (I could not see a *.tag.gz file, but perhaps 
I just don't understand how github works.  Actually, there's no 
"perhaps" about it!)

I unzipped the download and then did

     R CMD build LaplacesDemon-master

in the appropriate directory.  This created a file

     LaplacesDemon_15.03.19.tar.gz

Note that the version number seems to be as you require.

I then used your install.packages syntax, and the package installed 
seamlessly.  It also loaded seamlessly.

So I don't know why the computer gods are picking on you.

Note that I am not working on a Mac, but rather running Linux (as do all 
civilized human beings! :-) )

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 05/02/16 06:42, Lluis.Hurtado at uv.es wrote:
> Dear all,
>
> I've recently changed my Mac and I am trying to reinstall my commonly
> used R-packages. I'm having troubles with a package called
> LaplacesDemon.
>
> This package is no more in the CRAN list and the developers web page
> (http://www.bayesian-inference.com/software) is out for more than
> half a year. Old versions of the package can still be found in tar.gz
> in
>
> https://cran.r-project.org/src/contrib/Archive/LaplacesDemon/
>
> and in github
>
> https://github.com/ecbrown/LaplacesDemon
>
> Last version is LaplacesDemon_13.03.04.tar.gz, but I was able to get
> version LaplacesDemon_15.03.19.tar.gz time ago (can't find it
> anymore).
>
> I have tried to install this packages from source in my computer
> using
>
>> install.packages("/Users/.../LaplacesDemon_15.03.19.tar.gz", repos
>> = NULL, type="source")
>
> answer:
>
>> Warning: invalid package 'Users/.../LaplacesDemon_15.03.19.tar.gz?
>> Error: ERROR: no packages specified Warning message: In
>> install.packages("Users/.../LaplacesDemon_15.03.19.tar.gz",  :
> installation of package ?Users/.../LaplacesDemon_15.03.19.tar.gz? had
> non-zero exit status
>
> I also tried the 'Packages & Data' menu in R, selecting the source
> file or the directory from Finder and I got this message:
>
>> * installing *source* package ?LaplacesDemon? ... ** R ** data **
>> inst ** byte-compile and prepare package for lazy loading ** help
>> *** installing help indices ** building package indices **
>> installing vignettes ** testing if installed package can be loaded
>> * DONE (LaplacesDemon)
>
> but
>
>> library(LaplacesDemon)
> Error in library(LaplacesDemon) : there is no package called
> ?LaplacesDemon?
>
> Finally I tried
>
>> install.packages("devtools") library(devtools)
>> install_github("ecbrown/LaplacesDemon")
>
> but I am not able to install devtools (for similar reasons). So my
> questions are:
>
> -Do anyone knows how to install this packages in my Mac? -Do anyone
> knows were can I find the information previously content in
> http://www.bayesian-inference.com/software?


From Ted.Harding at wlandres.net  Thu Feb  4 23:01:48 2016
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 04 Feb 2016 22:01:48 -0000 (GMT)
Subject: [R] R project and the TPP
In-Reply-To: <CALwjrWQSt_v4L9i725e4igf8it8Bk8R-TROB=gDLJtGt6G7MTA@mail.gmail.com>
Message-ID: <XFMail.20160204220148.Ted.Harding@wlandres.net>

Saludos Jos?!
Could you please give a summary of the relevant parts of TPP
that might affect the use of R? I have looked up TPP on Wikipedia
without beginning to understand what it might imply for the use of R.
Best wishes,
Ted.

On 04-Feb-2016 14:43:29 Jos?? Bustos wrote:
> Hi everyone,
> 
> I have a question regarding the use R software under the new TPP laws
> adopted by some governments in the region. Who know how this new agreements
> will affect researchers and the R community?
> 
> Hope some of you knows better and can give ideas about it.
> 
> saludos,
> Jos??

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 04-Feb-2016  Time: 22:01:42
This message was sent by XFMail


From Ted.Harding at wlandres.net  Thu Feb  4 23:03:35 2016
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 04 Feb 2016 22:03:35 -0000 (GMT)
Subject: [R] LaplacesDemon package installation
In-Reply-To: <56B3C139.60209@auckland.ac.nz>
Message-ID: <XFMail.20160204220335.Ted.Harding@wlandres.net>

See at [***] below.

On 04-Feb-2016 21:23:05 Rolf Turner wrote:
> 
> (1) You might get better mileage asking this on the r-sig-mac list.
> 
> (2) The phenomena you describe are puzzling and are beyond my capacity 
> to explain.  Perhaps someone else will be able to enlighten you.
> 
> (3) Out of idle curiosity I went to the github site and downloaded the
> zip file of the package.  (I could not see a *.tag.gz file, but perhaps 
> I just don't understand how github works.  Actually, there's no 
> "perhaps" about it!)
> 
> I unzipped the download and then did
> 
>      R CMD build LaplacesDemon-master
> 
> in the appropriate directory.  This created a file
> 
>      LaplacesDemon_15.03.19.tar.gz
> 
> Note that the version number seems to be as you require.
> 
> I then used your install.packages syntax, and the package installed 
> seamlessly.  It also loaded seamlessly.
> 
> So I don't know why the computer gods are picking on you.
>
[***] 
> Note that I am not working on a Mac, but rather running Linux (as do all 
> civilized human beings! :-) )

Might this be yet another candidate for a Fortune today?

Ted.

> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> On 05/02/16 06:42, Lluis.Hurtado at uv.es wrote:
>> Dear all,
>>
>> I've recently changed my Mac and I am trying to reinstall my commonly
>> used R-packages. I'm having troubles with a package called
>> LaplacesDemon.
>>
>> This package is no more in the CRAN list and the developers web page
>> (http://www.bayesian-inference.com/software) is out for more than
>> half a year. Old versions of the package can still be found in tar.gz
>> in
>>
>> https://cran.r-project.org/src/contrib/Archive/LaplacesDemon/
>>
>> and in github
>>
>> https://github.com/ecbrown/LaplacesDemon
>>
>> Last version is LaplacesDemon_13.03.04.tar.gz, but I was able to get
>> version LaplacesDemon_15.03.19.tar.gz time ago (can't find it
>> anymore).
>>
>> I have tried to install this packages from source in my computer
>> using
>>
>>> install.packages("/Users/.../LaplacesDemon_15.03.19.tar.gz", repos
>>> = NULL, type="source")
>>
>> answer:
>>
>>> Warning: invalid package 'Users/.../LaplacesDemon_15.03.19.tar.gz???
>>> Error: ERROR: no packages specified Warning message: In
>>> install.packages("Users/.../LaplacesDemon_15.03.19.tar.gz",  :
>> installation of package ???Users/.../LaplacesDemon_15.03.19.tar.gz??? had
>> non-zero exit status
>>
>> I also tried the 'Packages & Data' menu in R, selecting the source
>> file or the directory from Finder and I got this message:
>>
>>> * installing *source* package ???LaplacesDemon??? ... ** R ** data **
>>> inst ** byte-compile and prepare package for lazy loading ** help
>>> *** installing help indices ** building package indices **
>>> installing vignettes ** testing if installed package can be loaded
>>> * DONE (LaplacesDemon)
>>
>> but
>>
>>> library(LaplacesDemon)
>> Error in library(LaplacesDemon) : there is no package called
>> ???LaplacesDemon???
>>
>> Finally I tried
>>
>>> install.packages("devtools") library(devtools)
>>> install_github("ecbrown/LaplacesDemon")
>>
>> but I am not able to install devtools (for similar reasons). So my
>> questions are:
>>
>> -Do anyone knows how to install this packages in my Mac? -Do anyone
>> knows were can I find the information previously content in
>> http://www.bayesian-inference.com/software?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 04-Feb-2016  Time: 22:03:31
This message was sent by XFMail


From marc_schwartz at me.com  Thu Feb  4 23:33:18 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 04 Feb 2016 16:33:18 -0600
Subject: [R] R project and the TPP
In-Reply-To: <XFMail.20160204220148.Ted.Harding@wlandres.net>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
Message-ID: <5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>

Ted and Jos?,

The FSF has a blog post here that might provide some insights:

  http://www.fsf.org/blogs/licensing/time-to-act-on-tpp-is-now-rallies-against-tpp-in-washington-d-c-november-14-18

That is from last November, but the relevant passage, perhaps in a temporal vacuum, seems to be the second paragraph with the following sentences focused on the GPL:

"The regulation would not affect freely licensed software, such as software under the GPL, that already comes with its own conditions ensuring users receive source code. Such licenses are grants of permission from the copyright holders on the work, who are not a "Party" to TPP."


The Software Freedom Conservancy has a post on this as well, from the same time frame:

  https://sfconservancy.org/blog/2015/nov/09/gpl-tpp/

Regards,

Marc


> On Feb 4, 2016, at 4:01 PM, Ted Harding <Ted.Harding at wlandres.net> wrote:
> 
> Saludos Jos?!
> Could you please give a summary of the relevant parts of TPP
> that might affect the use of R? I have looked up TPP on Wikipedia
> without beginning to understand what it might imply for the use of R.
> Best wishes,
> Ted.
> 
> On 04-Feb-2016 14:43:29 Jos?? Bustos wrote:
>> Hi everyone,
>> 
>> I have a question regarding the use R software under the new TPP laws
>> adopted by some governments in the region. Who know how this new agreements
>> will affect researchers and the R community?
>> 
>> Hope some of you knows better and can give ideas about it.
>> 
>> saludos,
>> Jos??


From r.turner at auckland.ac.nz  Fri Feb  5 00:15:08 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 5 Feb 2016 12:15:08 +1300
Subject: [R] R project and the TPP
In-Reply-To: <5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
Message-ID: <56B3DB7C.8000100@auckland.ac.nz>



Quite a while ago I went to talk (I think it may have been at an NZSA 
conference) given by the great Ross Ihaka.  I forget the details but my 
vague recollection was that it involved a technique for automatic choice 
of some sort of smoothing parameter involved in a graphical display. 
Apparently Ross's ideas related peripherally to some patented technique 
owned by Texas Instruments, and TI was causing problems for Ross.  He 
seemed to be of the opinion that the TPP would make matters worse.

I suspect he's right.  It will make matters worse for everyone except 
the rich bastards in the multinationals, in all respects.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 05/02/16 11:33, Marc Schwartz wrote:
> Ted and Jos?,
>
> The FSF has a blog post here that might provide some insights:
>
>    http://www.fsf.org/blogs/licensing/time-to-act-on-tpp-is-now-rallies-against-tpp-in-washington-d-c-november-14-18
>
> That is from last November, but the relevant passage, perhaps in a temporal vacuum, seems to be the second paragraph with the following sentences focused on the GPL:
>
> "The regulation would not affect freely licensed software, such as software under the GPL, that already comes with its own conditions ensuring users receive source code. Such licenses are grants of permission from the copyright holders on the work, who are not a "Party" to TPP."
>
>
> The Software Freedom Conservancy has a post on this as well, from the same time frame:
>
>    https://sfconservancy.org/blog/2015/nov/09/gpl-tpp/
>
> Regards,
>
> Marc
>
>
>> On Feb 4, 2016, at 4:01 PM, Ted Harding <Ted.Harding at wlandres.net> wrote:
>>
>> Saludos Jos?!
>> Could you please give a summary of the relevant parts of TPP
>> that might affect the use of R? I have looked up TPP on Wikipedia
>> without beginning to understand what it might imply for the use of R.
>> Best wishes,
>> Ted.
>>
>> On 04-Feb-2016 14:43:29 Jos?? Bustos wrote:
>>> Hi everyone,
>>>
>>> I have a question regarding the use R software under the new TPP laws
>>> adopted by some governments in the region. Who know how this new agreements
>>> will affect researchers and the R community?
>>>
>>> Hope some of you knows better and can give ideas about it.
>>>
>>> saludos,
>>> Jos??


From dwinsemius at comcast.net  Fri Feb  5 01:59:18 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Feb 2016 16:59:18 -0800
Subject: [R] R project and the TPP
In-Reply-To: <56B3DB7C.8000100@auckland.ac.nz>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
	<56B3DB7C.8000100@auckland.ac.nz>
Message-ID: <ECC48108-8669-4E57-8407-B43A2D843FF3@comcast.net>


> On Feb 4, 2016, at 3:15 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> 
> Quite a while ago I went to talk (I think it may have been at an NZSA conference) given by the great Ross Ihaka.  I forget the details but my vague recollection was that it involved a technique for automatic choice of some sort of smoothing parameter involved in a graphical display. 

Identifying discontinuities:

https://www.stat.auckland.ac.nz/~ihaka/downloads/Curves.pdf

http://www.google.com/patents/US6704013

TI can now own analytic geometry if they file enough patents.

-- 
David.
> Apparently Ross's ideas related peripherally to some patented technique owned by Texas Instruments, and TI was causing problems for Ross.  He seemed to be of the opinion that the TPP would make matters worse.
> 
> I suspect he's right.  It will make matters worse for everyone except the rich bastards in the multinationals, in all respects.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> On 05/02/16 11:33, Marc Schwartz wrote:
>> Ted and Jos?,
>> 
>> The FSF has a blog post here that might provide some insights:
>> 
>>   http://www.fsf.org/blogs/licensing/time-to-act-on-tpp-is-now-rallies-against-tpp-in-washington-d-c-november-14-18
>> 
>> That is from last November, but the relevant passage, perhaps in a temporal vacuum, seems to be the second paragraph with the following sentences focused on the GPL:
>> 
>> "The regulation would not affect freely licensed software, such as software under the GPL, that already comes with its own conditions ensuring users receive source code. Such licenses are grants of permission from the copyright holders on the work, who are not a "Party" to TPP."
>> 
>> 
>> The Software Freedom Conservancy has a post on this as well, from the same time frame:
>> 
>>   https://sfconservancy.org/blog/2015/nov/09/gpl-tpp/
>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>>> On Feb 4, 2016, at 4:01 PM, Ted Harding <Ted.Harding at wlandres.net> wrote:
>>> 
>>> Saludos Jos?!
>>> Could you please give a summary of the relevant parts of TPP
>>> that might affect the use of R? I have looked up TPP on Wikipedia
>>> without beginning to understand what it might imply for the use of R.
>>> Best wishes,
>>> Ted.
>>> 
>>> On 04-Feb-2016 14:43:29 Jos?? Bustos wrote:
>>>> Hi everyone,
>>>> 
>>>> I have a question regarding the use R software under the new TPP laws
>>>> adopted by some governments in the region. Who know how this new agreements
>>>> will affect researchers and the R community?
>>>> 
>>>> Hope some of you knows better and can give ideas about it.
>>>> 
>>>> saludos,
>>>> Jos??
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From spencer.graves at effectivedefense.org  Fri Feb  5 01:48:18 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 4 Feb 2016 18:48:18 -0600
Subject: [R] R project and the TPP
In-Reply-To: <56B3DB7C.8000100@auckland.ac.nz>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
	<56B3DB7C.8000100@auckland.ac.nz>
Message-ID: <56B3F152.1010107@effectivedefense.org>

       It's not clear if the TPP would ever directly impact the R 
project.  However, it could impact many R users.


             * For example, if someone decides that something you have 
on the web includes material for which they claim copyright, the TPP 
allows them to order your Internet Service Provider to take down your 
web site.   No court order is required.  No proof is required.  If you 
want to contest, the dispute might go through the "Investor-State 
Dispute Settlement" process, where the issue will be judged by people 
essentially selected by multinational businesses. (Article 18, Section 
J.)  [Phillip Morris Tobacco Company has already sued Uruguay, Australia 
and Norway over packaging requirements that has actually been effective 
in reducing tobacco consumption in those countries.  Former New York 
City Mayor Bloomberg has been paying legal fees for Uruguay, because 
they can't afford the legal fees.  Tobacco is explicitly excluded from 
the TPP, but similar suits could be brought over other types of products 
or services.]  This could include some algorithm you've coded into R, if 
some company decides you're using their copyrighted algorithm or 
whatever without paying for it.  Current US copyright law covers 
"derivative works", which could be almost anything.  This sounds far 
fetched.  However, the Recording Industry Association of America (RIAA) 
sued four college students for close to $100 billion, because their 
improvements of search engines made it easier for people in a university 
intranet to find copyrighted music placed by others in their "public" 
folder.  The attorney uncle of one of those four told his nephew that it 
would cost him a million dollars to defend himself, and there would be 
no way he could recoup that money even if he won.  In negotiations, they 
asked the student how much money he had.  He said he had saved $12,000 
for college.  They took it. Major media organizations similarly sued 
Venture Capitalists who funded Napster and Lawyers who advised MP3.com 
that they had reasonable grounds to that MP3's business model was legal. 
  The Napster funders and MP3 lawyers similarly knew they could not 
afford to defend themselves and settled.  [Wikipedia, "Free Culture 
(book)";  https://en.wikipedia.org/wiki/Free_Culture_(book)]


       Other parts of the TPP are highly undemocratic but may not relate 
as closely to R as the provision I just mentioned.


             * The provision that worries me the most is Article 18.78 
on ?Trade Secrets?.  This broadly criminalizes ?unauthorized and willful 
disclosure of a trade secret?.  This doesn't sound bad, except that a 
"trade secret" could include documentation of criminal behavior.  This 
substantially increases risks for journalists and whistleblowers.  For 
example The Guardian could be sued for having published documents 
released by Ed Snowden -- even though what Snowden did was expose 
perjury by James Clapper, US Director of National Intelligence. 
(http://tumblr.fightforthefuture.org/post/132605875893/final-tpp-text-confirms-worst-fears-shadowy)


             * Article 18.63 "forces the most draconian parts of the 
U.S.?s broken copyright system on the rest of the world without 
expanding protections for fair use and free speech. This section 
requires countries to enforce copyright until 70 years after the 
creator?s death. This will keep an enormous amount of information, art, 
and creativity out of the public domain for decades longer than 
necessary, and allow for governments to abuse copyright laws to censor 
online content at will, since so much of it will be copyrighted for so 
long." 
(http://tumblr.fightforthefuture.org/post/132605875893/final-tpp-text-confirms-worst-fears-shadowy) 



             * The TPP could also make the Internet less secure.  For 
example, the Electronic Frontier Foundation says that, "With no good 
rationale, the agreement would outlaw a country from adopting rules for 
the sale of software that include mandatory code review or the release 
of source code. This could inhibit countries from addressing pressing 
information security problems, such as widespread and massive 
vulnerability in closed-source home routers." (www.eff.org/issues/tpp)


       I hope you find this interesting and useful even if some of it is 
off topic.


       Spencer Graves


On 2/4/2016 5:15 PM, Rolf Turner wrote:
>
>
> Quite a while ago I went to talk (I think it may have been at an NZSA
> conference) given by the great Ross Ihaka.  I forget the details but
> my vague recollection was that it involved a technique for automatic
> choice of some sort of smoothing parameter involved in a graphical
> display. Apparently Ross's ideas related peripherally to some patented
> technique owned by Texas Instruments, and TI was causing problems for
> Ross.  He seemed to be of the opinion that the TPP would make matters
> worse.
>
> I suspect he's right.  It will make matters worse for everyone except
> the rich bastards in the multinationals, in all respects.
>
> cheers,
>
> Rolf
>


From spencer.graves at effectivedefense.org  Fri Feb  5 04:59:53 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 4 Feb 2016 21:59:53 -0600
Subject: [R] R project and the TPP
In-Reply-To: <ECC48108-8669-4E57-8407-B43A2D843FF3@comcast.net>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
	<56B3DB7C.8000100@auckland.ac.nz>
	<ECC48108-8669-4E57-8407-B43A2D843FF3@comcast.net>
Message-ID: <56B41E39.2070108@effectivedefense.org>



On 2/4/2016 6:59 PM, David Winsemius wrote:
>> On Feb 4, 2016, at 3:15 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>>
>> Quite a while ago I went to talk (I think it may have been at an NZSA conference) given by the great Ross Ihaka.  I forget the details but my vague recollection was that it involved a technique for automatic choice of some sort of smoothing parameter involved in a graphical display.
> Identifying discontinuities:
>
> https://www.stat.auckland.ac.nz/~ihaka/downloads/Curves.pdf
>
> http://www.google.com/patents/US6704013
>
> TI can now own analytic geometry if they file enough patents.

       And TI could therefore under TPP demand that any Internet Service 
Provider remove any R content (or R generated content) that they claimed 
(correctly or otherwise) infringed on their intellectual property, 
without a court order, and with common citizens having only slightly 
more ability to seek redress than the British peasants had when their 
nobility got King John of England to sign the Magna Carta on 15 June 1215?


       And, of course, this is only one concrete example.


       More relevant, TPP might prohibit any government from promoting 
the use of open-source software, because it could deprive a for-profit 
company of income, and they could therefore sue for lost profit under 
the Investor-State Dispute Settlement Settlement (ISDS) provisions of 
the TPP or other "free trade" agreements like NAFTA.  This is hardly far 
fetched:  Last Dec. 21, the U.S. Congress decided that consumers in the 
U.S. did not have the right to know the origins of the meat they buy 
under NAFTA (Scott Smith, "Congress repeals country of origin labeling 
for meat", United Press International, Dec. 21, 2015 at 10:12 AM, 
http://www.upi.com/Top_News/US/2015/12/21/Congress-repeals-country-of-origin-labeling-for-meat/3241450709277/). 



       Spencer Graves


From kogan.clark at gmail.com  Fri Feb  5 05:13:13 2016
From: kogan.clark at gmail.com (Clark Kogan)
Date: Thu, 4 Feb 2016 20:13:13 -0800
Subject: [R] Accessing specific data.frame columns within function
Message-ID: <CAJXvfGQgJr3P4p0J7FHnDu6nSZ1JeqA-X970Um-RqSnyBS_eew@mail.gmail.com>

Hello,

I am trying to write a function that adds a few columns to a data.frame. The
function uses the columns in a specific way. For instance, it might take a^2
+ c to produce a column d. Or it might do more complex manipulations that I
don't think I need to discuss here. I want to keep x as a data.frame when I
pass it into the function, as I want to use some data.frame functionality on
x.

Furthermore, I don't want the names in x to have to be specific. I want to
be able to specify which columns the function should treat as "a" and "c".

The way I am currently doing it, is that I pass the names of the columns
that I want to treat as a and c.

f <- function(data,oldnames) {
  newnames <- c("a","c")
  ix <- match(oldnames,names(y))
  names(y)[ix] <- newnames
  y <- subset(y,c==4)
  y$d <- y$a^2 + y$c
  ix <- match(newnames,names(y))
  names(y)[ix] <- oldnames
  y
}

y <- data.frame(k=c(1,1,1),l=c(2,2,5),m=c(4,2,4))
f(y,c("k","m"))

The way that I am doing it does not seem all that elegent or standard
practice. My question is: are there potential problems programming with
data.frames in this way, and are their standard practice methods of
referencing data.frame names that deal with these problems?

Thanks!

Clark

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Feb  5 05:59:03 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 05 Feb 2016 04:59:03 +0000
Subject: [R] Accessing specific data.frame columns within function
In-Reply-To: <CAJXvfGQgJr3P4p0J7FHnDu6nSZ1JeqA-X970Um-RqSnyBS_eew@mail.gmail.com>
References: <CAJXvfGQgJr3P4p0J7FHnDu6nSZ1JeqA-X970Um-RqSnyBS_eew@mail.gmail.com>
Message-ID: <CAKVAULOvMDsTu=-FPOp8jWeOJ3hY=5Jk5fPwf2ud5pN=ix7pSg@mail.gmail.com>

Hi Clark,

In your function you are using the variable 'y' and not 'data'. If this
indeed is your intention, there is no need to pass 'data' to your function,
otherwise all 'y's in your function should be 'data'.

Does this work for you:

f <- function(data, oldnames, subset.val = 4){
  data <- data[ data[[ oldnames[2] ]] == subset.val, ]
  data$d <- data[[ oldnames[1] ]]^2 + data[[ oldnames[2] ]]
  return(data)
}

y <- data.frame(k=c(1,1,1),l=c(2,2,5),m=c(4,2,4))
f(data = y, oldnames = c("k","m"))

Its probably safer to pass the 'oldnames' as two arguments. Also, if you
want to subset your data.frame in the function, you should pass the value
or subset before you call the function, along the lines of

f <- function(data, oldname.1, oldname.2){
  data$d <- data[[ oldname.1 ]]^2 + data[[ oldname.2 ]]
  return(data)
}

y <- data.frame(k=c(1,1,1),l=c(2,2,5),m=c(4,2,4))
y <- subset(y, m == 4)
f(data = y, oldname.1 = "k", oldname.2 = "m")

Hope this helps,
Ulrik



On Fri, 5 Feb 2016 at 05:14 Clark Kogan <kogan.clark at gmail.com> wrote:

> Hello,
>
> I am trying to write a function that adds a few columns to a data.frame.
> The
> function uses the columns in a specific way. For instance, it might take
> a^2
> + c to produce a column d. Or it might do more complex manipulations that I
> don't think I need to discuss here. I want to keep x as a data.frame when I
> pass it into the function, as I want to use some data.frame functionality
> on
> x.
>
> Furthermore, I don't want the names in x to have to be specific. I want to
> be able to specify which columns the function should treat as "a" and "c".
>
> The way I am currently doing it, is that I pass the names of the columns
> that I want to treat as a and c.
>
> f <- function(data,oldnames) {
>   newnames <- c("a","c")
>   ix <- match(oldnames,names(y))
>   names(y)[ix] <- newnames
>   y <- subset(y,c==4)
>   y$d <- y$a^2 + y$c
>   ix <- match(newnames,names(y))
>   names(y)[ix] <- oldnames
>   y
> }
>
> y <- data.frame(k=c(1,1,1),l=c(2,2,5),m=c(4,2,4))
> f(y,c("k","m"))
>
> The way that I am doing it does not seem all that elegent or standard
> practice. My question is: are there potential problems programming with
> data.frames in this way, and are their standard practice methods of
> referencing data.frame names that deal with these problems?
>
> Thanks!
>
> Clark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ste.depo.bio at gmail.com  Fri Feb  5 08:23:14 2016
From: ste.depo.bio at gmail.com (Stefano de Pretis)
Date: Fri, 5 Feb 2016 08:23:14 +0100
Subject: [R] Subset with missing argument within a function
In-Reply-To: <CAF8bMcY_Wc7EL9GxxGMGCnRdG+WLzQsn7Sh+9NFL_0d0PdDvLw@mail.gmail.com>
References: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CAB1@SRVEXCHMBX.precheza.cz>
	<CABj-uJdcgrHULvVw-SuvaSpQfCaJu-U2vA1Sm-YF=P8YiMnE9g@mail.gmail.com>
	<CAF8bMcY_Wc7EL9GxxGMGCnRdG+WLzQsn7Sh+9NFL_0d0PdDvLw@mail.gmail.com>
Message-ID: <CABj-uJfSi-Mum8jHJRa+43kdOf80-Ln=9akCpkAw87tBwpqz-A@mail.gmail.com>

Thanks Bill,

This is more clear.

In any case, I find very inappropriate that a programming language tries to
guess the value of a missing argument. It is unfair towards code developers
and it promotes the production of bugged piece of software.

I hope R will revise its policies sooner or later.

Thanks for the discussion,

Stefano







2016-02-04 18:19 GMT+01:00 William Dunlap <wdunlap at tibco.com>:

> The "missingness" of an argument gets passed down through nested function
> calls.  E.g.,
>   fOuter <- function(x) c(outerMissing=missing(x), innerMissing=fInner(x))
>   fInner <- function(x) missing(x)
>   fInner()
>   #[1] TRUE
>   fOuter()
>   #outerMissing innerMissing
>   #      TRUE         TRUE
> It is only when a function evaluates an argument that you get a message
> like 'argument is missing, with no default'.  ('[' checks for missingness
> before
> evaluating a subscript argument so it will not give that error.)
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Feb 4, 2016 at 7:47 AM, Stefano de Pretis <ste.depo.bio at gmail.com>
> wrote:
>
>> Hi Petr,
>>
>> Thank you for your answer.
>>
>> I'm not sure how the empty index reflects what I'm showing in my example.
>> If my function was
>>
>> emptySubset <- function(vec) vec[]
>>
>> I would then agree that this was the case. But I think it's different: I'm
>> specifically telling my function that it should have two arguments ("vec"
>> and "ix")
>>
>> subsettingFun <- function(vec, ix) vec[ix]
>>
>> and I guess why, within the function, it does not happen what happens on
>> the command line:
>>
>> > ix
>> Error: object 'ix' not found
>> > letters[ix]
>> Error: object 'ix' not found
>>
>> My "expectation" came from a matter of coherence, but probably I'm still
>> missing something.
>>
>> Regards,
>>
>> Stefano
>>
>>
>>
>> 2016-02-04 15:39 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>
>> > Hi
>> >
>> > Help page for ?"[" says
>> >
>> > An empty index selects all values: this is most often used to replace
>> all
>> > the entries but keep the attributes.
>> >
>> > and actually you function construction works with empty index
>> >
>> > > x<-c(1,2,5)
>> > > letters[x]
>> > [1] "a" "b" "e"
>> > > letters[]
>> >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
>> > "r" "s"
>> > [20] "t" "u" "v" "w" "x" "y" "z"
>> >
>> > It is sometimes useful not "expect" the program behavior but "inspect"
>> why
>> > it behaves differently.
>> >
>> > If you want your function to throw error when some arguments are missing
>> > you need to do the check yourself and not rely on programming language.
>> >
>> > And BTW I did not know an answer before I inspected docs.
>> >
>> > Cheers
>> > Petr
>> >
>> >
>> > > -----Original Message-----
>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> Stefano
>> > > de Pretis
>> > > Sent: Thursday, February 04, 2016 11:00 AM
>> > > To: r-help at r-project.org
>> > > Subject: [R] Subset with missing argument within a function
>> > >
>> > > Hi all,
>> > >
>> > > I'm guessing what's the rationale behind this:
>> > >
>> > > > subsettingFun <- function(vec, ix) vec[ix]
>> > > > subsettingFun(letters, c(1,2,5))
>> > > [1] "a" "b" "e"
>> > > > subsettingFun(letters)
>> > >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p"
>> > > "q"
>> > > "r" "s"
>> > > [20] "t" "u" "v" "w" "x" "y" "z"
>> > >
>> > > If the argument "ix" is missing, I'm expecting an error not to return
>> > > the
>> > > variable "vec" as it is.
>> > >
>> > > I think this is VERY dangerous and does not help the development of
>> > > reliable code and the debugging.
>> > >
>> > > Cheers,
>> > >
>> > > Stefano
>> > >
>> > > *Center for Genomic Science of IIT at SEMM*
>> > >
>> > > Stefano de Pretis, PhD
>> > >
>> > > *Postdoctoral fellow *
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > > guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> > ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>> kopie
>> > vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email
>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi
>> > ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout;
>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> > p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n
>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>> tohoto
>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential and are
>> > intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform its
>> > sender. Delete the contents of this e-mail with all attachments and its
>> > copies from your system.
>> > If you are not the intended recipient of this e-mail, you are not
>> > authorized to use, disseminate, copy or disclose this e-mail in any
>> manner.
>> > The sender of this e-mail shall not be liable for any possible damage
>> > caused by modifications of the e-mail or by delay with transfer of the
>> > email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering into
>> a
>> > contract in any time, for any reason, and without stating any reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to
>> > immediately accept such offer; The sender of this e-mail (offer)
>> excludes
>> > any acceptance of the offer on the part of the recipient containing any
>> > amendment or variation.
>> > - the sender insists on that the respective contract is concluded only
>> > upon an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized to
>> enter
>> > into any contracts on behalf of the company except for cases in which
>> > he/she is expressly authorized to do so in writing, and such
>> authorization
>> > or power of attorney is submitted to the recipient or the person
>> > represented by the recipient, or the existence of such authorization is
>> > known to the recipient of the person represented by the recipient.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From aurora.gonzalez2 at um.es  Fri Feb  5 09:50:09 2016
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Fri, 05 Feb 2016 09:50:09 +0100
Subject: [R] hourly prediction time series
Message-ID: <20160205095009.Horde.f0DOCXhe2Q4F-ctHtQS0vw1@webmail.um.es>

Dear R users,

I am fronting my firts time series problem. I have hourly temperature data
for 3 years (from 01/01/2013 to 5/02/2016). I would like to use those in
order to PREDICT TEMPERATURE OF THE NEXT HOURS according to the
observations.

A subset of the data look like this:

date <- rep(seq(as.Date("14-01-01"), as.Date("14-01-03"), by="days"), 24)
hour <-rep(c(paste0("0",0:9,":00:00"), paste0(10:23,":00:00")),3)
temperature <- c(6.1, 6.8, 6.5, 7.2, 7.1, 7.9, 5.9, 6.8, 7.7, 9.5, 12.6,
???????????????? 14.0, 15.9, 17.3, 17.5, 17.2, 15.0, 14.1,
13.1, 11.7, 10.9,
???????????????? 11.0, 11.6, 11.0, 11.2, 11.0, 11.0, 11.4,
12.2, 13.7, 12.9,
???????????????? 12.9, 12.8, 13.4, 13.9, 14.9, 16.6, 16.0,
15.2, 15.4, 14.7,
???????????????? 14.6, 13.3, 13.0, 13.8, 13.1, 12.0, 11.9,
11.8, 11.6, 11.0,
???????????????? 11.2, 11.6, 10.6, 9.5, 9.8, 9.9, 11.7,
15.3, 18.6, 20.7,
???????????????? 22.2, 22.2, 20.8, 20.2, 18.3, 15.6, 13.6,
12.8, 13.1, 13.7, 14.7)

dfExample <- data.frame(date, hour, temperature)?

So as to plot 3 years ( from 01/01/2013 to 31/12/2015) I use this code and
obtained the attached picture. It is observed seasonality.

tempdf4 <- ts(df4$temperature, frequency=365*24*3)
plot.ts(tempdf4)

Am I doing it well? Could you help me with any information in this type of
problem (mainly with the prediction). For example, if I want to use Arima,
according with my data structure, what are the arguments of the funcion??

fit=Arima(df4$temperature, seasonal=list(order=c(xxx,xxx,xxx),period=xxx)
plot(forecast(fit))

I could use also some predictions from other source that I am collecting
since January, 2016. But I would prefer to understand the simplest way to
solve the problem and then, progressively, understand more complex
approaches.

Thank you very much for any kind of help.


------
Aurora Gonz?lez Vidal
Phd student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae
------------ pr?xima parte ------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 9610 bytes
Desc: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160205/45a2d22b/attachment.png>

From sporter at ori.org.za  Fri Feb  5 10:18:29 2016
From: sporter at ori.org.za (Sean Porter)
Date: Fri, 5 Feb 2016 11:18:29 +0200
Subject: [R] hourly prediction time series
In-Reply-To: <20160205095009.Horde.f0DOCXhe2Q4F-ctHtQS0vw1@webmail.um.es>
References: <20160205095009.Horde.f0DOCXhe2Q4F-ctHtQS0vw1@webmail.um.es>
Message-ID: <058801d15ff6$30712510$91536f30$@ori.org.za>

Try the auto.arima function in the forecast package..

Regards,
 
DR SEAN PORTER
Scientist

South African Association for Marine Biological Research
Direct Tel: +27 (31) 328 8169   Fax: +27 (31) 328 8188
E-mail: sporter at ori.org.za Web: www.saambr.org.za
1 King Shaka Avenue, Point, Durban 4001 KwaZulu-Natal South Africa
PO Box 10712, Marine Parade 4056 KwaZulu-Natal South Africa

         


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AURORA GONZALEZ VIDAL
Sent: 05 February 2016 10:50 AM
To: r-help at r-project.org
Subject: [R] hourly prediction time series

Dear R users,

I am fronting my firts time series problem. I have hourly temperature data for 3 years (from 01/01/2013 to 5/02/2016). I would like to use those in order to PREDICT TEMPERATURE OF THE NEXT HOURS according to the observations.

A subset of the data look like this:

date <- rep(seq(as.Date("14-01-01"), as.Date("14-01-03"), by="days"), 24) hour <-rep(c(paste0("0",0:9,":00:00"), paste0(10:23,":00:00")),3) temperature <- c(6.1, 6.8, 6.5, 7.2, 7.1, 7.9, 5.9, 6.8, 7.7, 9.5, 12.6,
                 14.0, 15.9, 17.3, 17.5, 17.2, 15.0, 14.1, 13.1, 11.7, 10.9,
                 11.0, 11.6, 11.0, 11.2, 11.0, 11.0, 11.4, 12.2, 13.7, 12.9,
                 12.9, 12.8, 13.4, 13.9, 14.9, 16.6, 16.0, 15.2, 15.4, 14.7,
                 14.6, 13.3, 13.0, 13.8, 13.1, 12.0, 11.9, 11.8, 11.6, 11.0,
                 11.2, 11.6, 10.6, 9.5, 9.8, 9.9, 11.7, 15.3, 18.6, 20.7,
                 22.2, 22.2, 20.8, 20.2, 18.3, 15.6, 13.6, 12.8, 13.1, 13.7, 14.7)

dfExample <- data.frame(date, hour, temperature) 

So as to plot 3 years ( from 01/01/2013 to 31/12/2015) I use this code and obtained the attached picture. It is observed seasonality.

tempdf4 <- ts(df4$temperature, frequency=365*24*3)
plot.ts(tempdf4)

Am I doing it well? Could you help me with any information in this type of problem (mainly with the prediction). For example, if I want to use Arima, according with my data structure, what are the arguments of the funcion??

fit=Arima(df4$temperature, seasonal=list(order=c(xxx,xxx,xxx),period=xxx)
plot(forecast(fit))

I could use also some predictions from other source that I am collecting since January, 2016. But I would prefer to understand the simplest way to solve the problem and then, progressively, understand more complex approaches.

Thank you very much for any kind of help.


------
Aurora Gonz?lez Vidal
Phd student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae


From giorgio.garziano at ericsson.com  Fri Feb  5 10:20:59 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 5 Feb 2016 09:20:59 +0000
Subject: [R] hourly prediction time series
Message-ID: <248E6FA047A8C746BA491485764190F53D32EE25@ESESSMB210.ericsson.se>

Some good references:

https://www.otexts.org/fpp

http://link.springer.com/book/10.1007%2F978-0-387-88698-5

http://www.statoek.wiso.uni-goettingen.de/veranstaltungen/zeitreihen/sommer03/ts_r_intro.pdf


Best,

--

GG

This Communication is Ericsson Confidential.
We only send and receive email on the basis of the term set out at http://www.ericsson.com/email_disclaimer




	[[alternative HTML version deleted]]


From j.logsdon at quantex-research.com  Fri Feb  5 11:25:18 2016
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Fri, 5 Feb 2016 10:25:18 -0000
Subject: [R] R project and the TPP
In-Reply-To: <56B41E39.2070108@effectivedefense.org>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
	<56B3DB7C.8000100@auckland.ac.nz>
	<ECC48108-8669-4E57-8407-B43A2D843FF3@comcast.net>
	<56B41E39.2070108@effectivedefense.org>
Message-ID: <4d16cf8a7ee6d4f4eb894ca6cecdfa70.squirrel@quantex.zedcore.com>

Folks

TPP, and in a European context, TTIP are very dangerous not only to open
source software but to any public service and no satisfactory response has
been forthcoming.

There are ways of circumventing it I guess or opposing it (maybe using
ISPs in China, Russia or North Korea???).  The issue really should be
reversed - how muchy open source coding has found its way into closed
source software?  We do not know because proprietory coding is secret, and
hence insecure.  Perhaps a court could rule that all software should be
available for inspection by independent experts.  This possibility may be
sufficient to shut TI etc up.

But this seems to have been put together in total secrecy and undermines
pretty nearly every 'freedom' people have fought for since at least King
John and probably others (not that English peasants enjoyed too much
freedom after 1215 as it was the barons who got it all!)

I really do not understand why legislators have done this unless
corruption has become so pervasive that there are no longer any good guys
and girls around (well, maybe Bernie Sanders and Jeremy Corbyn excepted
but their chance of power is pretty slim at the moment despite Iowa).

In the UK we have a referendum on EU membership which under ordinary
circumstances I would automatically support as very much a pro-Europe
person.  But if TTIP is implemented, I don't know which way to vote.  Of
course it is a total sham anyway, so maybe a bloody nose for the
legislators would not be a bad idea.  And looking at the way the EU has
treated Greece, Cyprus, Ireland, Portugal, I don't hold out much hope for
an epiphany.

Anyway this is a bit OT. :)


>
>
> On 2/4/2016 6:59 PM, David Winsemius wrote:
>>> On Feb 4, 2016, at 3:15 PM, Rolf Turner <r.turner at auckland.ac.nz>
>>> wrote:
>>>
>>>
>>>
>>> Quite a while ago I went to talk (I think it may have been at an NZSA
>>> conference) given by the great Ross Ihaka.  I forget the details but my
>>> vague recollection was that it involved a technique for automatic
>>> choice of some sort of smoothing parameter involved in a graphical
>>> display.
>> Identifying discontinuities:
>>
>> https://www.stat.auckland.ac.nz/~ihaka/downloads/Curves.pdf
>>
>> http://www.google.com/patents/US6704013
>>
>> TI can now own analytic geometry if they file enough patents.
>
>        And TI could therefore under TPP demand that any Internet Service
> Provider remove any R content (or R generated content) that they claimed
> (correctly or otherwise) infringed on their intellectual property,
> without a court order, and with common citizens having only slightly
> more ability to seek redress than the British peasants had when their
> nobility got King John of England to sign the Magna Carta on 15 June 1215?
>
>
>        And, of course, this is only one concrete example.
>
>
>        More relevant, TPP might prohibit any government from promoting
> the use of open-source software, because it could deprive a for-profit
> company of income, and they could therefore sue for lost profit under
> the Investor-State Dispute Settlement Settlement (ISDS) provisions of
> the TPP or other "free trade" agreements like NAFTA.  This is hardly far
> fetched:  Last Dec. 21, the U.S. Congress decided that consumers in the
> U.S. did not have the right to know the origins of the meat they buy
> under NAFTA (Scott Smith, "Congress repeals country of origin labeling
> for meat", United Press International, Dec. 21, 2015 at 10:12 AM,
> http://www.upi.com/Top_News/US/2015/12/21/Congress-repeals-country-of-origin-labeling-for-meat/3241450709277/).
>
>
>
>        Spencer Graves
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


Best wishes

John

John Logsdon
Quantex Research Ltd
+44 161 445 4951/+44 7717758675


From boris.steipe at utoronto.ca  Fri Feb  5 12:44:36 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 5 Feb 2016 06:44:36 -0500
Subject: [R] R project and the TPP
In-Reply-To: <56B3F152.1010107@effectivedefense.org>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
	<56B3DB7C.8000100@auckland.ac.nz>
	<56B3F152.1010107@effectivedefense.org>
Message-ID: <DFA5FE7A-A018-40E5-9DDC-AAD29686019B@utoronto.ca>

Does that mean I could poison the Archive by posting IP on this list, or poison someone else's code if they use some of mine that I post here?

B.



On Feb 4, 2016, at 7:48 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:

>      It's not clear if the TPP would ever directly impact the R project.  However, it could impact many R users.
> 
> 
>            * For example, if someone decides that something you have on the web includes material for which they claim copyright, the TPP allows them to order your Internet Service Provider to take down your web site.   No court order is required.  No proof is required.  If you want to contest, the dispute might go through the "Investor-State Dispute Settlement" process, where the issue will be judged by people essentially selected by multinational businesses. (Article 18, Section J.)  [Phillip Morris Tobacco Company has already sued Uruguay, Australia and Norway over packaging requirements that has actually been effective in reducing tobacco consumption in those countries.  Former New York City Mayor Bloomberg has been paying legal fees for Uruguay, because they can't afford the legal fees.  Tobacco is explicitly excluded from the TPP, but similar suits could be brought over other types of products or services.]  This could include some algorithm you've coded into R, if some company decides you're using their copyrighted algorithm or whatever without paying for it.  Current US copyright law covers "derivative works", which could be almost anything.  This sounds far fetched.  However, the Recording Industry Association of America (RIAA) sued four college students for close to $100 billion, because their improvements of search engines made it easier for people in a university intranet to find copyrighted music placed by others in their "public" folder.  The attorney uncle of one of those four told his nephew that it would cost him a million dollars to defend himself, and there would be no way he could recoup that money even if he won.  In negotiations, they asked the student how much money he had.  He said he had saved $12,000 for college.  They took it. Major media organizations similarly sued Venture Capitalists who funded Napster and Lawyers who advised MP3.com that they had reasonable grounds to that MP3's business model was legal.  The Napster funders and MP3 lawyers similarly knew they could not afford to defend themselves and settled.  [Wikipedia, "Free Culture (book)";  https://en.wikipedia.org/wiki/Free_Culture_(book)]
> 
> 
>      Other parts of the TPP are highly undemocratic but may not relate as closely to R as the provision I just mentioned.
> 
> 
>            * The provision that worries me the most is Article 18.78 on ?Trade Secrets?.  This broadly criminalizes ?unauthorized and willful disclosure of a trade secret?.  This doesn't sound bad, except that a "trade secret" could include documentation of criminal behavior.  This substantially increases risks for journalists and whistleblowers.  For example The Guardian could be sued for having published documents released by Ed Snowden -- even though what Snowden did was expose perjury by James Clapper, US Director of National Intelligence. (http://tumblr.fightforthefuture.org/post/132605875893/final-tpp-text-confirms-worst-fears-shadowy)
> 
> 
>            * Article 18.63 "forces the most draconian parts of the U.S.?s broken copyright system on the rest of the world without expanding protections for fair use and free speech. This section requires countries to enforce copyright until 70 years after the creator?s death. This will keep an enormous amount of information, art, and creativity out of the public domain for decades longer than necessary, and allow for governments to abuse copyright laws to censor online content at will, since so much of it will be copyrighted for so long." (http://tumblr.fightforthefuture.org/post/132605875893/final-tpp-text-confirms-worst-fears-shadowy) 
> 
> 
>            * The TPP could also make the Internet less secure.  For example, the Electronic Frontier Foundation says that, "With no good rationale, the agreement would outlaw a country from adopting rules for the sale of software that include mandatory code review or the release of source code. This could inhibit countries from addressing pressing information security problems, such as widespread and massive vulnerability in closed-source home routers." (www.eff.org/issues/tpp)
> 
> 
>      I hope you find this interesting and useful even if some of it is off topic.
> 
> 
>      Spencer Graves
> 
> 
> On 2/4/2016 5:15 PM, Rolf Turner wrote:
>> 
>> 
>> Quite a while ago I went to talk (I think it may have been at an NZSA
>> conference) given by the great Ross Ihaka.  I forget the details but
>> my vague recollection was that it involved a technique for automatic
>> choice of some sort of smoothing parameter involved in a graphical
>> display. Apparently Ross's ideas related peripherally to some patented
>> technique owned by Texas Instruments, and TI was causing problems for
>> Ross.  He seemed to be of the opinion that the TPP would make matters
>> worse.
>> 
>> I suspect he's right.  It will make matters worse for everyone except
>> the rich bastards in the multinationals, in all respects.
>> 
>> cheers,
>> 
>> Rolf
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Thu Feb  4 17:21:03 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 4 Feb 2016 16:21:03 +0000
Subject: [R] Package for error analysis
In-Reply-To: <000001d15f32$6cc30a20$46491e60$@portucelsoporcel.com>
References: <000001d15f32$6cc30a20$46491e60$@portucelsoporcel.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D0E319A2@GBTEDVPEXCMB04.corp.lgc-group.com>

> I'm doing error analysis of predictive models and I need to calculate global
> error, this is, I need to calculate the resultant error from propagation of
> indirect measurements errors.

If the problem is propagation of variance on inputs through a known function, you could look at uncert() in the metRology package.
That basically does first order error propagation using analytic (if available) or numerical differentiation of the function, or (via uncertMC()) Monte Carlo simulation to get error distributions (which I would recommend for larger variance over first order calculations).

I wouldn't exactly call it statistics - it's based on recommendations for measurement science and they assume a pretty simple deterministic model and that has little or nothing to do with model fitting and inference.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Catarina
> Silva
> Sent: 04 February 2016 09:57
> To: R mailling list
> Subject: [R] Package for error analysis
> 
> Hi,
> 
> I'm doing error analysis of predictive models and I need to calculate global
> error, this is, I need to calculate the resultant error from propagation of
> indirect measurements errors.
> 
> I know a little about propagation error theory, using derivation formulas to
> calculate it, but I want to know if exists some package to do it.
> 
> 
> 
> Ty
> 
> Catarina
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jbustosmelo at gmail.com  Fri Feb  5 13:41:41 2016
From: jbustosmelo at gmail.com (=?UTF-8?B?Sm9zw6kgQnVzdG9z?=)
Date: Fri, 5 Feb 2016 09:41:41 -0300
Subject: [R] R project and the TPP
In-Reply-To: <ECC48108-8669-4E57-8407-B43A2D843FF3@comcast.net>
References: <XFMail.20160204220148.Ted.Harding@wlandres.net>
	<5F768AE7-DBD6-4A2E-9B1D-CFB7703DF556@me.com>
	<56B3DB7C.8000100@auckland.ac.nz>
	<ECC48108-8669-4E57-8407-B43A2D843FF3@comcast.net>
Message-ID: <CALwjrWQ3MyAVWjW1HUGrN=PvkRtoATzuiW-mBSNugRdYBrnosw@mail.gmail.com>

Thank everyone, I have found some good, but limited infomation about it. As
Ross Ihaka mention in his presentation: "Houston, We Have a Problem".

The R software is a important part of the Free Software Fundation, they
have been fighting back TPP long time, but last weeks in Chile was not so
good. Some chilean politician (as Minister of the Interior and Public
Security Jorge Burgos) are impulsing the TPP to be signed as soon as
possible. On the other side, some smart representatives have been trying to
stop the fast track.

It is a very big issue, there will be a ton of more limitations like Ross
Ihaka had mentioned.

Please get informed about the impacts and send emails to yours
representatives in congress to NOT aprove what we all don't know.

Here some articles to read:

http://www.ip-watch.org/2015/11/24/tpp-article-14-17-free-software-no-harm-no-foul/
https://www.fsf.org/blogs/licensing/latest-tpp-leak-shows-systemic-threat-to-software-freedom

Keep talking about hte impacts and limitations of this agreement.

Jose

2016-02-04 21:59 GMT-03:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Feb 4, 2016, at 3:15 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> >
> > Quite a while ago I went to talk (I think it may have been at an NZSA
> conference) given by the great Ross Ihaka.  I forget the details but my
> vague recollection was that it involved a technique for automatic choice of
> some sort of smoothing parameter involved in a graphical display.
>
> Identifying discontinuities:
>
> https://www.stat.auckland.ac.nz/~ihaka/downloads/Curves.pdf
>
> http://www.google.com/patents/US6704013
>
> TI can now own analytic geometry if they file enough patents.
>
> --
> David.
> > Apparently Ross's ideas related peripherally to some patented technique
> owned by Texas Instruments, and TI was causing problems for Ross.  He
> seemed to be of the opinion that the TPP would make matters worse.
> >
> > I suspect he's right.  It will make matters worse for everyone except
> the rich bastards in the multinationals, in all respects.
> >
> > cheers,
> >
> > Rolf
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > On 05/02/16 11:33, Marc Schwartz wrote:
> >> Ted and Jos?,
> >>
> >> The FSF has a blog post here that might provide some insights:
> >>
> >>
> http://www.fsf.org/blogs/licensing/time-to-act-on-tpp-is-now-rallies-against-tpp-in-washington-d-c-november-14-18
> >>
> >> That is from last November, but the relevant passage, perhaps in a
> temporal vacuum, seems to be the second paragraph with the following
> sentences focused on the GPL:
> >>
> >> "The regulation would not affect freely licensed software, such as
> software under the GPL, that already comes with its own conditions ensuring
> users receive source code. Such licenses are grants of permission from the
> copyright holders on the work, who are not a "Party" to TPP."
> >>
> >>
> >> The Software Freedom Conservancy has a post on this as well, from the
> same time frame:
> >>
> >>   https://sfconservancy.org/blog/2015/nov/09/gpl-tpp/
> >>
> >> Regards,
> >>
> >> Marc
> >>
> >>
> >>> On Feb 4, 2016, at 4:01 PM, Ted Harding <Ted.Harding at wlandres.net>
> wrote:
> >>>
> >>> Saludos Jos?!
> >>> Could you please give a summary of the relevant parts of TPP
> >>> that might affect the use of R? I have looked up TPP on Wikipedia
> >>> without beginning to understand what it might imply for the use of R.
> >>> Best wishes,
> >>> Ted.
> >>>
> >>> On 04-Feb-2016 14:43:29 Jos?? Bustos wrote:
> >>>> Hi everyone,
> >>>>
> >>>> I have a question regarding the use R software under the new TPP laws
> >>>> adopted by some governments in the region. Who know how this new
> agreements
> >>>> will affect researchers and the R community?
> >>>>
> >>>> Hope some of you knows better and can give ideas about it.
> >>>>
> >>>> saludos,
> >>>> Jos??
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Jos? Bustos
Director AESPRO
Mag?ster en Estad?stica Aplicada
Movil +56 995939144
www.aespro.cl

------------------------------

Este mensaje y/o documento adjunto est? dirigido exclusivamente al
destinatario especificado y puede contener informaci?n confidencial,
privilegiada o de divulgaci?n restringida. Cualquier revelaci?n, copia,
distribuci?n o acci?n que comprometa el contenido de esta informaci?n est?
prohibida. Si usted recibe este correo por error, contacte al emisor y
borre la informaci?n de su computador.

	[[alternative HTML version deleted]]


From emmanuelle.morin at nancy.inra.fr  Fri Feb  5 15:06:45 2016
From: emmanuelle.morin at nancy.inra.fr (emmanuelle morin)
Date: Fri, 5 Feb 2016 15:06:45 +0100
Subject: [R] pearson correlation matrix
Message-ID: <56B4AC75.5020506@nancy.inra.fr>

Hello,

I have a set of 12 individuals with thousands of variables measured.
I understand that when I'm using the cor() function on my matrix I'm 
calculating the correlation between the different variables according to 
their values for the different individuals.

What I'm willing to do is to calculate a correlation between the 
individuals and I have no clue how I can do that.
Could you please help me ?

Thanks,

Emmanuelle

-- 
Emmanuelle MORIN
UMR 1136 INRA/Universit? de Lorraine
F-54280 Champenoux
Tel : + 33 3 83 39 41 33
http://mycor.nancy.inra.fr


From dcarlson at tamu.edu  Fri Feb  5 15:30:42 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 5 Feb 2016 14:30:42 +0000
Subject: [R] pearson correlation matrix
In-Reply-To: <56B4AC75.5020506@nancy.inra.fr>
References: <56B4AC75.5020506@nancy.inra.fr>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D708BCF@mb02.ads.tamu.edu>

Assuming your data is called BIG and has 12 rows and thousands of columns:

cor(t(BIG))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of emmanuelle morin
Sent: Friday, February 5, 2016 8:07 AM
To: r-help at r-project.org
Subject: [R] pearson correlation matrix

Hello,

I have a set of 12 individuals with thousands of variables measured.
I understand that when I'm using the cor() function on my matrix I'm 
calculating the correlation between the different variables according to 
their values for the different individuals.

What I'm willing to do is to calculate a correlation between the 
individuals and I have no clue how I can do that.
Could you please help me ?

Thanks,

Emmanuelle

-- 
Emmanuelle MORIN
UMR 1136 INRA/Universit? de Lorraine
F-54280 Champenoux
Tel : + 33 3 83 39 41 33
http://mycor.nancy.inra.fr

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From lists at dewey.myzen.co.uk  Fri Feb  5 15:31:49 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 5 Feb 2016 14:31:49 +0000
Subject: [R] pearson correlation matrix
In-Reply-To: <56B4AC75.5020506@nancy.inra.fr>
References: <56B4AC75.5020506@nancy.inra.fr>
Message-ID: <56B4B255.7000406@dewey.myzen.co.uk>

Assuming your dataset is in a matrix you want to transpose it. So you 
can go t(mesdonnees) and then call cor on that.

On 05/02/2016 14:06, emmanuelle morin wrote:
> Hello,
>
> I have a set of 12 individuals with thousands of variables measured.
> I understand that when I'm using the cor() function on my matrix I'm
> calculating the correlation between the different variables according to
> their values for the different individuals.
>
> What I'm willing to do is to calculate a correlation between the
> individuals and I have no clue how I can do that.
> Could you please help me ?
>
> Thanks,
>
> Emmanuelle
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wdunlap at tibco.com  Fri Feb  5 16:39:32 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Feb 2016 07:39:32 -0800
Subject: [R] Subset with missing argument within a function
In-Reply-To: <CABj-uJfSi-Mum8jHJRa+43kdOf80-Ln=9akCpkAw87tBwpqz-A@mail.gmail.com>
References: <CABj-uJeh+grHe5XakfK0xZtb6EkTRF2wdaqnDs2eruyrRPaP6A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500CAB1@SRVEXCHMBX.precheza.cz>
	<CABj-uJdcgrHULvVw-SuvaSpQfCaJu-U2vA1Sm-YF=P8YiMnE9g@mail.gmail.com>
	<CAF8bMcY_Wc7EL9GxxGMGCnRdG+WLzQsn7Sh+9NFL_0d0PdDvLw@mail.gmail.com>
	<CABj-uJfSi-Mum8jHJRa+43kdOf80-Ln=9akCpkAw87tBwpqz-A@mail.gmail.com>
Message-ID: <CAF8bMcZVZePAxKjK3OkpYJM6phmLDrzB1UnAhp6iLiNa+9AT=Q@mail.gmail.com>

R's subscripting operators do not "guess" the value of a missing
argument: a missing k'th subscript means seq_len(dim(x)[k]).
I bet that you use syntax like x[,1] (the entire first column of x)
all the time and that you don't want this syntax to go away.

Some languages use a placeholder like '.' or '*' to do this.  Perhaps
S should have, but it is now late to make such a change.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Feb 4, 2016 at 11:23 PM, Stefano de Pretis <ste.depo.bio at gmail.com>
wrote:

> Thanks Bill,
>
> This is more clear.
>
> In any case, I find very inappropriate that a programming language tries
> to guess the value of a missing argument. It is unfair towards code
> developers and it promotes the production of bugged piece of software.
>
> I hope R will revise its policies sooner or later.
>
> Thanks for the discussion,
>
> Stefano
>
>
>
>
>
>
>
> 2016-02-04 18:19 GMT+01:00 William Dunlap <wdunlap at tibco.com>:
>
>> The "missingness" of an argument gets passed down through nested function
>> calls.  E.g.,
>>   fOuter <- function(x) c(outerMissing=missing(x), innerMissing=fInner(x))
>>   fInner <- function(x) missing(x)
>>   fInner()
>>   #[1] TRUE
>>   fOuter()
>>   #outerMissing innerMissing
>>   #      TRUE         TRUE
>> It is only when a function evaluates an argument that you get a message
>> like 'argument is missing, with no default'.  ('[' checks for missingness
>> before
>> evaluating a subscript argument so it will not give that error.)
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Feb 4, 2016 at 7:47 AM, Stefano de Pretis <ste.depo.bio at gmail.com
>> > wrote:
>>
>>> Hi Petr,
>>>
>>> Thank you for your answer.
>>>
>>> I'm not sure how the empty index reflects what I'm showing in my example.
>>> If my function was
>>>
>>> emptySubset <- function(vec) vec[]
>>>
>>> I would then agree that this was the case. But I think it's different:
>>> I'm
>>> specifically telling my function that it should have two arguments ("vec"
>>> and "ix")
>>>
>>> subsettingFun <- function(vec, ix) vec[ix]
>>>
>>> and I guess why, within the function, it does not happen what happens on
>>> the command line:
>>>
>>> > ix
>>> Error: object 'ix' not found
>>> > letters[ix]
>>> Error: object 'ix' not found
>>>
>>> My "expectation" came from a matter of coherence, but probably I'm still
>>> missing something.
>>>
>>> Regards,
>>>
>>> Stefano
>>>
>>>
>>>
>>> 2016-02-04 15:39 GMT+01:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>>
>>> > Hi
>>> >
>>> > Help page for ?"[" says
>>> >
>>> > An empty index selects all values: this is most often used to replace
>>> all
>>> > the entries but keep the attributes.
>>> >
>>> > and actually you function construction works with empty index
>>> >
>>> > > x<-c(1,2,5)
>>> > > letters[x]
>>> > [1] "a" "b" "e"
>>> > > letters[]
>>> >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p"
>>> "q"
>>> > "r" "s"
>>> > [20] "t" "u" "v" "w" "x" "y" "z"
>>> >
>>> > It is sometimes useful not "expect" the program behavior but "inspect"
>>> why
>>> > it behaves differently.
>>> >
>>> > If you want your function to throw error when some arguments are
>>> missing
>>> > you need to do the check yourself and not rely on programming language.
>>> >
>>> > And BTW I did not know an answer before I inspected docs.
>>> >
>>> > Cheers
>>> > Petr
>>> >
>>> >
>>> > > -----Original Message-----
>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Stefano
>>> > > de Pretis
>>> > > Sent: Thursday, February 04, 2016 11:00 AM
>>> > > To: r-help at r-project.org
>>> > > Subject: [R] Subset with missing argument within a function
>>> > >
>>> > > Hi all,
>>> > >
>>> > > I'm guessing what's the rationale behind this:
>>> > >
>>> > > > subsettingFun <- function(vec, ix) vec[ix]
>>> > > > subsettingFun(letters, c(1,2,5))
>>> > > [1] "a" "b" "e"
>>> > > > subsettingFun(letters)
>>> > >  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p"
>>> > > "q"
>>> > > "r" "s"
>>> > > [20] "t" "u" "v" "w" "x" "y" "z"
>>> > >
>>> > > If the argument "ix" is missing, I'm expecting an error not to return
>>> > > the
>>> > > variable "vec" as it is.
>>> > >
>>> > > I think this is VERY dangerous and does not help the development of
>>> > > reliable code and the debugging.
>>> > >
>>> > > Cheers,
>>> > >
>>> > > Stefano
>>> > >
>>> > > *Center for Genomic Science of IIT at SEMM*
>>> > >
>>> > > Stefano de Pretis, PhD
>>> > >
>>> > > *Postdoctoral fellow *
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>>> > > guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ________________________________
>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>>> > ur?eny pouze jeho adres?t?m.
>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>> kopie
>>> > vyma?te ze sv?ho syst?mu.
>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>> email
>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi
>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>> >
>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> p?ijmout;
>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>>> > p??jemce s dodatkem ?i odchylkou.
>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>> zmocn?n
>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>> tohoto
>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>> >
>>> > This e-mail and any documents attached to it may be confidential and
>>> are
>>> > intended only for its intended recipients.
>>> > If you received this e-mail by mistake, please immediately inform its
>>> > sender. Delete the contents of this e-mail with all attachments and its
>>> > copies from your system.
>>> > If you are not the intended recipient of this e-mail, you are not
>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>> manner.
>>> > The sender of this e-mail shall not be liable for any possible damage
>>> > caused by modifications of the e-mail or by delay with transfer of the
>>> > email.
>>> >
>>> > In case that this e-mail forms part of business dealings:
>>> > - the sender reserves the right to end negotiations about entering
>>> into a
>>> > contract in any time, for any reason, and without stating any
>>> reasoning.
>>> > - if the e-mail contains an offer, the recipient is entitled to
>>> > immediately accept such offer; The sender of this e-mail (offer)
>>> excludes
>>> > any acceptance of the offer on the part of the recipient containing any
>>> > amendment or variation.
>>> > - the sender insists on that the respective contract is concluded only
>>> > upon an express mutual agreement on all its aspects.
>>> > - the sender of this e-mail informs that he/she is not authorized to
>>> enter
>>> > into any contracts on behalf of the company except for cases in which
>>> > he/she is expressly authorized to do so in writing, and such
>>> authorization
>>> > or power of attorney is submitted to the recipient or the person
>>> > represented by the recipient, or the existence of such authorization is
>>> > known to the recipient of the person represented by the recipient.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Fri Feb  5 17:14:16 2016
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sat, 6 Feb 2016 00:14:16 +0800
Subject: [R] does save.image() also save the random state?
Message-ID: <56B4CA58.2040808@yeah.net>

Dear there,

Here is a snipped code,

 > rm(list = ls())
 > x <- 123
 > save.image("abc.RData")
 > rm(list = ls())
 > load("abc.RData")
 > sample(10)
  [1]  3  7  4  6 10  2  5  9  8  1
 > rm(list = ls())
 > load("abc.RData")
 > sample(10)
  [1]  3  7  4  6 10  2  5  9  8  1

you will see that, after loading a abc.RData file that is saved by 
save.image(), sample(10) gives the same results. I am wondering whether 
it's designed purposely. And if it is, how can I get a different results 
of sample(10) every time after loading the saved image?

Any help will be really appreciated. Thanks in advance.

Best,
Jinsong


From G.Rudge at bham.ac.uk  Fri Feb  5 17:19:28 2016
From: G.Rudge at bham.ac.uk (Gavin Rudge)
Date: Fri, 5 Feb 2016 16:19:28 +0000
Subject: [R] Alignment of a double plot where one has a switched axis
Message-ID: <B8D87DA108D62D448DBE22A7775AB6BB0132D2A1E7@EX11.adf.bham.ac.uk>

Hi Rgonauts,

I am plotting 3 variables from one data set on one plot.  Two of them as a stacked bar and a ratio on a completely different scale, so I  need to put one of the axes on the top of the plot for clarity.  Whilst this is not good visualisation practice, there is a valid reason why, in this case, people viewing this plot would be interested in the magnitude of the values in the stacked bars and the distribution of the ratio of them (too complex and dull to go into here).

The plot consists of horizontal stacked bars showing two values, with a dot plot showing the ratio of them, all in order of the magnitude of the ratio (this is important).  I want them to look something like the code below but with a correct alignment

I wanted to avoid something overly complex with grobs as I don't find working with them very intuitive, although this may be the only way.  I've codged together this imperfect solution from code I found about the place and was hoping someone could either suggest a much better way or help with the final task of nudging the plots to make them coherent

Thanks in advance for any help received.

GavinR

#here is my code

require(ggplot2)
require(cowplot)
require(reshape2)
require(gridExtra)
require(grid)

#my original data set looks something like this, but with many more values

Set.seed=42
df1<-data.frame(idcode=LETTERS[1:10],v1=rnorm(10,mean=30,sd=10),v2=rnorm(10,mean=10,sd=5))
str(df1)
df1$rto<-(df1$v1/df1$v2)

#melt the frame
require(reshape2)
df2<-melt(df1,id.vars=c("idcode","rto"))
df2

#oder the data by the ratio variable

df2$idcode<-reorder(df2$idcode,df2$rto)

#make the first plot
plot1<-ggplot(df2)+geom_bar(stat="identity",aes(x=idcode,y=value, fill=variable))+theme(legend.position=c(.92,.87))+coord_flip()
plot1

#make the second plot

plot2<-ggplot(df2)+geom_point(stat="identity",aes(x=idcode,y=rto))+coord_flip()+theme(panel.background = element_rect(fill="transparent"))+coord_flip()
plot2

#flip the axis with cowplot

plot2<-ggdraw(switch_axis_position(plot2, axis='x'))

#plot both on the same page

grid.newpage()

#create the layout

pushViewport(viewport(layout=grid.layout(1,1)))

#helper function to get the regions right - no idea what this does but I cribbed it from:
#http://www.sthda.com/english/wiki/ggplot2-easy-way-to-mix-multiple-graphs-on-the-same-page-r-software-and-data-visualization#create-a-complex-layout-using-the-function-viewport

define_region <- function(row, col){
  viewport(layout.pos.row = row, layout.pos.col = col)
}

#here is the plot

print(plot1,vp=define_region(1,1))
print(plot2, vp=define_region(1,1))

#has all the ingredients but how to nudge it?


From murdoch.duncan at gmail.com  Fri Feb  5 17:25:13 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 5 Feb 2016 11:25:13 -0500
Subject: [R] does save.image() also save the random state?
In-Reply-To: <56B4CA58.2040808@yeah.net>
References: <56B4CA58.2040808@yeah.net>
Message-ID: <56B4CCE9.20807@gmail.com>

On 05/02/2016 11:14 AM, Jinsong Zhao wrote:
> Dear there,
>
> Here is a snipped code,
>
>   > rm(list = ls())
>   > x <- 123
>   > save.image("abc.RData")
>   > rm(list = ls())
>   > load("abc.RData")
>   > sample(10)
>    [1]  3  7  4  6 10  2  5  9  8  1
>   > rm(list = ls())
>   > load("abc.RData")
>   > sample(10)
>    [1]  3  7  4  6 10  2  5  9  8  1
>
> you will see that, after loading a abc.RData file that is saved by
> save.image(), sample(10) gives the same results. I am wondering whether
> it's designed purposely. And if it is, how can I get a different results
> of sample(10) every time after loading the saved image?

This happens because you are reloading the random number seed.  You can 
tell R to ignore it by calling

set.seed(NULL)

just after you load the image.  See ?set.seed for more details.

Duncan Murdoch


From toth.denes at ttk.mta.hu  Fri Feb  5 17:49:50 2016
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Fri, 05 Feb 2016 17:49:50 +0100
Subject: [R] does save.image() also save the random state?
In-Reply-To: <56B4CCE9.20807@gmail.com>
References: <56B4CA58.2040808@yeah.net> <56B4CCE9.20807@gmail.com>
Message-ID: <56B4D2AE.2010403@ttk.mta.hu>

On 02/05/2016 05:25 PM, Duncan Murdoch wrote:
> On 05/02/2016 11:14 AM, Jinsong Zhao wrote:
>> Dear there,
>>
>> Here is a snipped code,
>>
>>   > rm(list = ls())
>>   > x <- 123
>>   > save.image("abc.RData")
>>   > rm(list = ls())
>>   > load("abc.RData")
>>   > sample(10)
>>    [1]  3  7  4  6 10  2  5  9  8  1
>>   > rm(list = ls())
>>   > load("abc.RData")
>>   > sample(10)
>>    [1]  3  7  4  6 10  2  5  9  8  1
>>
>> you will see that, after loading a abc.RData file that is saved by
>> save.image(), sample(10) gives the same results. I am wondering whether
>> it's designed purposely. And if it is, how can I get a different results
>> of sample(10) every time after loading the saved image?
>
> This happens because you are reloading the random number seed.  You can
> tell R to ignore it by calling
>
> set.seed(NULL)
>
> just after you load the image.  See ?set.seed for more details.
>
> Duncan Murdoch
>

Based on your problem description, it seems that you actually do not 
want to restore the whole workspace but only the objects that you worked 
with. If this is indeed the case, it is much better to use 
save(list=ls(), file = "abc.RData") instead of save.image("abc.RData").
(Actually it is almost always better to use an explicitly parametrized 
save() call instead of save.image()).

save.image() can cause a lot of troubles besides the one you faced 
recently (which is caused due to the save and restore of the 
.Random.seed hidden object, as Duncan mentioned).

Cheers,
Denes




> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amoy_y at yahoo.com  Fri Feb  5 17:53:28 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Fri, 5 Feb 2016 16:53:28 +0000 (UTC)
Subject: [R]  Create macro_var in R
In-Reply-To: <1183155603.1534071.1454615171266.JavaMail.yahoo@mail.yahoo.com>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
	<812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
	<CAP01uRniHVgY6uPi7UabtB9k66rLk9-VmaDfX8ZgN4Mym-jr1A@mail.gmail.com>
	<592300871.1371153.1454605358145.JavaMail.yahoo@mail.yahoo.com>
	<1183155603.1534071.1454615171266.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>



 One more question (see below). I cannot use macro-var, mvar, for creating new name, as shown below. Any?advice is highly appreciated!

> mvar<-"pop"
> new.pop<-tab[[mvar]]; new.pop
?[1]? 698 1214 1003 1167 2549? 824? 944 1937? 935? 570??? 0
> new.tab[[mvar]]<-d$pop; 
Error in new.tab[[mvar]] <- d$pop : object 'new.tab' not found 

    On Thursday, February 4, 2016 11:02 AM, Amoy Yang <amoy_y at yahoo.com> wrote:
 

 This works although it looks rare by using min(",key,"). Don't know why but just have to remember it. This is a tough part in R.
Thanks for helps!
Amoy 

    On Wednesday, February 3, 2016 5:25 PM, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
 

 See

? Example 5.? Insert Variables

on the sqldf home page.

? https://github.com/ggrothendieck/sqldf


On Wed, Feb 3, 2016 at 2:16 PM, Amoy Yang via R-help
<r-help at r-project.org> wrote:
> First, MVAR<-c("population) should be the same as "population'". Correct?
> You use tab[[MVAR]] to refer to "population" where double [[...]] removes double quotes "...", which seemingly work for r-code although it is tedious in comparison direct application in SAS %let MVAR=population. But it does not work for sqldef in R as shown below.
>
>> key<-"pop"
>> library(sqldf)
>> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min,
> + max(pop) as max, avg(pop) as mean, median(pop) as median,
> + stdev(pop) as stdev from tab group by grade")
> Error in sqliteSendQuery(con, statement, bind.data) :
>? error in statement: near "[[key]": syntax error
>
>
>
>
>? ? On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt" <ruipbarradas at sapo.pt> wrote:
>
>
>? Hello,
>
> You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <- "population" (no need for c()).
>
> Hope this helps,
>
> Rui Barradas
>? Citando Amoy Yang via R-help <r-help at r-project.org>:
> population is the field-name in data-file (say, tab). MVAR<-population takes data (in the column of population) rather than field-name as done in SAS:? %let MVAR=population;
> In the following r-program, for instance, I cannot use ... tab$MVAR...or simply MVAR itself since MVAR is defined as "population" with double quotes if using MVAR<-c("population")
>
>? ? On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>
> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>? There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can be used through entire program.
> In R, I tried MAVR<-c("population"). The problem is that MAVR comes with double quote "...." that I don't need. But MVAR<-c(population) did NOT work out. Any way that double quote can be removed as done in SAS when creating macro_var?
> Thanks in advance for helps!
> R doesn't have a macro language, and you usually don't need one.
>
> If you are only reading the value of population, then
>
> MAVR <- population
>
> is fine.? This is sometimes the same as c(population), but in general
> it's different:? c() will remove some attributes, such as
> the dimensions on arrays.
>
> If you need to modify it in your program, it's likely more complicated.
> The normal way to go would be to put your code in a function, and have
> it return the modified version.? For example,
>
> population <- doModifications(population)
>
> where doModifications is a function with a definition like
>
> doModifications <- function(MAVR) {
>? ? # do all your calculations on MAVR
>? ? # then return it at the end using
>? ? MAVR
> }
>
> Duncan Murdoch
>
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.htmlandprovide commented, minimal, self-contained, reproducible code.
>
>
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

   

   

  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb  5 18:25:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 5 Feb 2016 12:25:32 -0500
Subject: [R] does save.image() also save the random state?
In-Reply-To: <56B4D2AE.2010403@ttk.mta.hu>
References: <56B4CA58.2040808@yeah.net> <56B4CCE9.20807@gmail.com>
	<56B4D2AE.2010403@ttk.mta.hu>
Message-ID: <56B4DB0C.3030005@gmail.com>

On 05/02/2016 11:49 AM, D?nes T?th wrote:
> On 02/05/2016 05:25 PM, Duncan Murdoch wrote:
> > On 05/02/2016 11:14 AM, Jinsong Zhao wrote:
> >> Dear there,
> >>
> >> Here is a snipped code,
> >>
> >>   > rm(list = ls())
> >>   > x <- 123
> >>   > save.image("abc.RData")
> >>   > rm(list = ls())
> >>   > load("abc.RData")
> >>   > sample(10)
> >>    [1]  3  7  4  6 10  2  5  9  8  1
> >>   > rm(list = ls())
> >>   > load("abc.RData")
> >>   > sample(10)
> >>    [1]  3  7  4  6 10  2  5  9  8  1
> >>
> >> you will see that, after loading a abc.RData file that is saved by
> >> save.image(), sample(10) gives the same results. I am wondering whether
> >> it's designed purposely. And if it is, how can I get a different results
> >> of sample(10) every time after loading the saved image?
> >
> > This happens because you are reloading the random number seed.  You can
> > tell R to ignore it by calling
> >
> > set.seed(NULL)
> >
> > just after you load the image.  See ?set.seed for more details.
> >
> > Duncan Murdoch
> >
>
> Based on your problem description, it seems that you actually do not
> want to restore the whole workspace but only the objects that you worked
> with. If this is indeed the case, it is much better to use
> save(list=ls(), file = "abc.RData") instead of save.image("abc.RData").
> (Actually it is almost always better to use an explicitly parametrized
> save() call instead of save.image()).
>
> save.image() can cause a lot of troubles besides the one you faced
> recently (which is caused due to the save and restore of the
> .Random.seed hidden object, as Duncan mentioned).

Yes, that's good advice.

One problem I've heard of is that some people save the workspace a few 
times before reading that it's good to tell R not to save on exit.  Then 
they keep reloading the same random seed in every session thereafter.

Duncan Murdoch


From macqueen1 at llnl.gov  Fri Feb  5 18:47:09 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 5 Feb 2016 17:47:09 +0000
Subject: [R] Create macro_var in R
In-Reply-To: <1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
	<812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
	<CAP01uRniHVgY6uPi7UabtB9k66rLk9-VmaDfX8ZgN4Mym-jr1A@mail.gmail.com>
	<592300871.1371153.1454605358145.JavaMail.yahoo@mail.yahoo.com>
	<1183155603.1534071.1454615171266.JavaMail.yahoo@mail.yahoo.com>
	<1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D2DA1F50.162700%macqueen1@llnl.gov>

Yes, you can use a name stored in a variable to create a new column in a
data frame (guessing that's what you want). Here's an example:

> df <- data.frame(a=1:5)
> df[['b']] <- 2:6
> df
  a b
1 1 2
2 2 3
3 3 4
4 4 5
5 5 6
> mvar <- 'c'
> df[[mvar]] <- 0:4
> df
  a b c
1 1 2 0
2 2 3 1
3 3 4 2
4 4 5 3
5 5 6 4


In your case, the object named "new.tab" does not exist when you try to
create a new variable in it. That's what the error message says.

Try, perhaps,

new.tab <- tab
new.tab[[mvar]] <- d$pop


(and hope that the number of elements in d$pop is the same as the number
of rows in new.tab)

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/5/16, 8:53 AM, "R-help on behalf of Amoy Yang via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>
>
> One more question (see below). I cannot use macro-var, mvar, for
>creating new name, as shown below. Any advice is highly appreciated!
>
>> mvar<-"pop"
>> new.pop<-tab[[mvar]]; new.pop
> [1]  698 1214 1003 1167 2549  824  944 1937  935  570    0
>> new.tab[[mvar]]<-d$pop;
>Error in new.tab[[mvar]] <- d$pop : object 'new.tab' not found
>
>    On Thursday, February 4, 2016 11:02 AM, Amoy Yang <amoy_y at yahoo.com>
>wrote:
> 
>
> This works although it looks rare by using min(",key,"). Don't know why
>but just have to remember it. This is a tough part in R.
>Thanks for helps!
>Amoy 
>
>    On Wednesday, February 3, 2016 5:25 PM, Gabor Grothendieck
><ggrothendieck at gmail.com> wrote:
> 
>
> See
>
>  Example 5.  Insert Variables
>
>on the sqldf home page.
>
>  https://github.com/ggrothendieck/sqldf
>
>
>On Wed, Feb 3, 2016 at 2:16 PM, Amoy Yang via R-help
><r-help at r-project.org> wrote:
>> First, MVAR<-c("population) should be the same as "population'".
>>Correct?
>> You use tab[[MVAR]] to refer to "population" where double [[...]]
>>removes double quotes "...", which seemingly work for r-code although it
>>is tedious in comparison direct application in SAS %let MVAR=population.
>>But it does not work for sqldef in R as shown below.
>>
>>> key<-"pop"
>>> library(sqldf)
>>> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min,
>> + max(pop) as max, avg(pop) as mean, median(pop) as median,
>> + stdev(pop) as stdev from tab group by grade")
>> Error in sqliteSendQuery(con, statement, bind.data) :
>>  error in statement: near "[[key]": syntax error
>>
>>
>>
>>
>>    On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt"
>><ruipbarradas at sapo.pt> wrote:
>>
>>
>>  Hello,
>>
>> You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <-
>>"population" (no need for c()).
>>
>> Hope this helps,
>>
>> Rui Barradas
>>  Citando Amoy Yang via R-help <r-help at r-project.org>:
>> population is the field-name in data-file (say, tab). MVAR<-population
>>takes data (in the column of population) rather than field-name as done
>>in SAS:  %let MVAR=population;
>> In the following r-program, for instance, I cannot use ...
>>tab$MVAR...or simply MVAR itself since MVAR is defined as "population"
>>with double quotes if using MVAR<-c("population")
>>
>>    On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch
>><murdoch.duncan at gmail.com> wrote:
>>
>>
>> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>>  There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can
>>be used through entire program.
>> In R, I tried MAVR<-c("population"). The problem is that MAVR comes
>>with double quote "...." that I don't need. But MVAR<-c(population) did
>>NOT work out. Any way that double quote can be removed as done in SAS
>>when creating macro_var?
>> Thanks in advance for helps!
>> R doesn't have a macro language, and you usually don't need one.
>>
>> If you are only reading the value of population, then
>>
>> MAVR <- population
>>
>> is fine.  This is sometimes the same as c(population), but in general
>> it's different:  c() will remove some attributes, such as
>> the dimensions on arrays.
>>
>> If you need to modify it in your program, it's likely more complicated.
>> The normal way to go would be to put your code in a function, and have
>> it return the modified version.  For example,
>>
>> population <- doModifications(population)
>>
>> where doModifications is a function with a definition like
>>
>> doModifications <- function(MAVR) {
>>    # do all your calculations on MAVR
>>    # then return it at the end using
>>    MAVR
>> }
>>
>> Duncan Murdoch
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.r-project.org/posting-guide.htmlandprovide commented,
>>minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>-- 
>Statistics & Software Consulting
>GKX Group, GKX Associates Inc.
>tel: 1-877-GKX-GROUP
>email: ggrothendieck at gmail.com
>
>   
>
>   
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Feb  5 19:01:40 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Feb 2016 10:01:40 -0800
Subject: [R] Create macro_var in R
In-Reply-To: <1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
	<812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
	<CAP01uRniHVgY6uPi7UabtB9k66rLk9-VmaDfX8ZgN4Mym-jr1A@mail.gmail.com>
	<592300871.1371153.1454605358145.JavaMail.yahoo@mail.yahoo.com>
	<1183155603.1534071.1454615171266.JavaMail.yahoo@mail.yahoo.com>
	<1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcbS-9m_qj4f7Uw=91xr5ZxJgkJ_ydyNwrK28V8WSf1LTA@mail.gmail.com>

If 'tab' is a data.frame then new.tab <- tab[[mvar]] is a column from that
data.frame, not a data.frame with one column.  new.tab <- tab[ , mvar,
drop=FALSE ] will give you a data.frame that you can add to with either of
    nvar <- "newName"
    new.tab[ , nvar] <- newColumn
    new.tab[[nvar]] <- newColumn

If you have a fixed name for the new column (not a variable containing
the name), you can also use
    new.tab <- cbind(new.tab, newName=newColumn)
    new.tab$newName <- newColumn


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 5, 2016 at 8:53 AM, Amoy Yang via R-help <r-help at r-project.org>
wrote:

>
>
>  One more question (see below). I cannot use macro-var, mvar, for creating
> new name, as shown below. Any advice is highly appreciated!
>
> > mvar<-"pop"
> > new.pop<-tab[[mvar]]; new.pop
>  [1]  698 1214 1003 1167 2549  824  944 1937  935  570    0
> > new.tab[[mvar]]<-d$pop;
> Error in new.tab[[mvar]] <- d$pop : object 'new.tab' not found
>
>     On Thursday, February 4, 2016 11:02 AM, Amoy Yang <amoy_y at yahoo.com>
> wrote:
>
>
>  This works although it looks rare by using min(",key,"). Don't know why
> but just have to remember it. This is a tough part in R.
> Thanks for helps!
> Amoy
>
>     On Wednesday, February 3, 2016 5:25 PM, Gabor Grothendieck <
> ggrothendieck at gmail.com> wrote:
>
>
>  See
>
>   Example 5.  Insert Variables
>
> on the sqldf home page.
>
>   https://github.com/ggrothendieck/sqldf
>
>
> On Wed, Feb 3, 2016 at 2:16 PM, Amoy Yang via R-help
> <r-help at r-project.org> wrote:
> > First, MVAR<-c("population) should be the same as "population'". Correct?
> > You use tab[[MVAR]] to refer to "population" where double [[...]]
> removes double quotes "...", which seemingly work for r-code although it is
> tedious in comparison direct application in SAS %let MVAR=population. But
> it does not work for sqldef in R as shown below.
> >
> >> key<-"pop"
> >> library(sqldf)
> >> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min,
> > + max(pop) as max, avg(pop) as mean, median(pop) as median,
> > + stdev(pop) as stdev from tab group by grade")
> > Error in sqliteSendQuery(con, statement, bind.data) :
> >  error in statement: near "[[key]": syntax error
> >
> >
> >
> >
> >    On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt" <
> ruipbarradas at sapo.pt> wrote:
> >
> >
> >  Hello,
> >
> > You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <-
> "population" (no need for c()).
> >
> > Hope this helps,
> >
> > Rui Barradas
> >  Citando Amoy Yang via R-help <r-help at r-project.org>:
> > population is the field-name in data-file (say, tab). MVAR<-population
> takes data (in the column of population) rather than field-name as done in
> SAS:  %let MVAR=population;
> > In the following r-program, for instance, I cannot use ... tab$MVAR...or
> simply MVAR itself since MVAR is defined as "population" with double quotes
> if using MVAR<-c("population")
> >
> >    On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch <
> murdoch.duncan at gmail.com> wrote:
> >
> >
> > On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
> >  There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR can
> be used through entire program.
> > In R, I tried MAVR<-c("population"). The problem is that MAVR comes with
> double quote "...." that I don't need. But MVAR<-c(population) did NOT work
> out. Any way that double quote can be removed as done in SAS when creating
> macro_var?
> > Thanks in advance for helps!
> > R doesn't have a macro language, and you usually don't need one.
> >
> > If you are only reading the value of population, then
> >
> > MAVR <- population
> >
> > is fine.  This is sometimes the same as c(population), but in general
> > it's different:  c() will remove some attributes, such as
> > the dimensions on arrays.
> >
> > If you need to modify it in your program, it's likely more complicated.
> > The normal way to go would be to put your code in a function, and have
> > it return the modified version.  For example,
> >
> > population <- doModifications(population)
> >
> > where doModifications is a function with a definition like
> >
> > doModifications <- function(MAVR) {
> >    # do all your calculations on MAVR
> >    # then return it at the end using
> >    MAVR
> > }
> >
> > Duncan Murdoch
> >
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.htmlandprovide commented, minimal,
> self-contained, reproducible code.
> >
> >
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Feb  5 19:30:21 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 05 Feb 2016 10:30:21 -0800
Subject: [R] Create macro_var in R
In-Reply-To: <1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>
References: <20160203183414.Horde.wFHO_-30i25LQlxz7ty_TpS@mail.sapo.pt>
	<812766047.987250.1454527014962.JavaMail.yahoo@mail.yahoo.com>
	<CAP01uRniHVgY6uPi7UabtB9k66rLk9-VmaDfX8ZgN4Mym-jr1A@mail.gmail.com>
	<592300871.1371153.1454605358145.JavaMail.yahoo@mail.yahoo.com>
	<1183155603.1534071.1454615171266.JavaMail.yahoo@mail.yahoo.com>
	<1814222375.1896445.1454691208094.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <F756CC64-2061-4E54-88A0-B472E252931A@dcn.davis.ca.us>

You REALLY NEED to read the "Introduction to R" document discussion of indexing. 

tab is a variable. It is apparently a data.frame. tab[[mvar]] is an expression that retrieves part of the data in the tab data.frame. The data it returns is a vector, not a data.frame. 

The "[[" operator extracts an element of a list.  A data.frame is a list of vectors (all of the same length). A vector of mode "numeric" is just numbers, not a list. 

You created a new variable new.pop that holds a numeric vector. You printed it and confirmed that that is what it is. 

You then tried to refer to a variable that you have NOT created, new.tab. However,  if you had tried the expression new.pop[[mvar]] you would have been trying to treat a numeric vector as a list, which it is not... and if it was it would have to have an element named pop inside it already to extract something, which it doesn't. 

A key step in getting out of your state of confusion is to learn how objects can contain other objects, and when to work with containing objects and when to work work contained objects. 

Some possible solutions:

new.tab <- data.frame( pop=new.pop )

or

new.tab <- data.frame( pop = tab[[mvar]] )

or

new.tab <- tab[ , "pop", drop=FALSE )

With which you can then add new columns

new.tab$pop2 <- new.pop ^2
new.pop[[ "pop3" ]] <- new.pop^3

-- 
Sent from my phone. Please excuse my brevity.

On February 5, 2016 8:53:28 AM PST, Amoy Yang via R-help <r-help at r-project.org> wrote:
>
>
>One more question (see below). I cannot use macro-var, mvar, for
>creating new name, as shown below. Any?advice is highly appreciated!
>
>> mvar<-"pop"
>> new.pop<-tab[[mvar]]; new.pop
>?[1]? 698 1214 1003 1167 2549? 824? 944 1937? 935? 570??? 0
>> new.tab[[mvar]]<-d$pop; 
>Error in new.tab[[mvar]] <- d$pop : object 'new.tab' not found 
>
>On Thursday, February 4, 2016 11:02 AM, Amoy Yang <amoy_y at yahoo.com>
>wrote:
> 
>
>This works although it looks rare by using min(",key,"). Don't know why
>but just have to remember it. This is a tough part in R.
>Thanks for helps!
>Amoy 
>
>On Wednesday, February 3, 2016 5:25 PM, Gabor Grothendieck
><ggrothendieck at gmail.com> wrote:
> 
>
> See
>
>? Example 5.? Insert Variables
>
>on the sqldf home page.
>
>? https://github.com/ggrothendieck/sqldf
>
>
>On Wed, Feb 3, 2016 at 2:16 PM, Amoy Yang via R-help
><r-help at r-project.org> wrote:
>> First, MVAR<-c("population) should be the same as "population'".
>Correct?
>> You use tab[[MVAR]] to refer to "population" where double [[...]]
>removes double quotes "...", which seemingly work for r-code although
>it is tedious in comparison direct application in SAS %let
>MVAR=population. But it does not work for sqldef in R as shown below.
>>
>>> key<-"pop"
>>> library(sqldf)
>>> sqldf("select grade, count(*) as cnt, min(tab[[key]]) as min,
>> + max(pop) as max, avg(pop) as mean, median(pop) as median,
>> + stdev(pop) as stdev from tab group by grade")
>> Error in sqliteSendQuery(con, statement, bind.data) :
>>? error in statement: near "[[key]": syntax error
>>
>>
>>
>>
>>? ? On Wednesday, February 3, 2016 12:40 PM, "ruipbarradas at sapo.pt"
><ruipbarradas at sapo.pt> wrote:
>>
>>
>>? Hello,
>>
>> You can't use tab$MVAR but you can use tab[[MVAR]] if you do MVAR <-
>"population" (no need for c()).
>>
>> Hope this helps,
>>
>> Rui Barradas
>>? Citando Amoy Yang via R-help <r-help at r-project.org>:
>> population is the field-name in data-file (say, tab).
>MVAR<-population takes data (in the column of population) rather than
>field-name as done in SAS:? %let MVAR=population;
>> In the following r-program, for instance, I cannot use ...
>tab$MVAR...or simply MVAR itself since MVAR is defined as "population"
>with double quotes if using MVAR<-c("population")
>>
>>? ? On Wednesday, February 3, 2016 11:54 AM, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>>
>>
>> On 03/02/2016 12:41 PM, Amoy Yang via R-help wrote:
>>? There is a %LET statement in SAS: %let MVAR=population; Thus, MVAR
>can be used through entire program.
>> In R, I tried MAVR<-c("population"). The problem is that MAVR comes
>with double quote "...." that I don't need. But MVAR<-c(population) did
>NOT work out. Any way that double quote can be removed as done in SAS
>when creating macro_var?
>> Thanks in advance for helps!
>> R doesn't have a macro language, and you usually don't need one.
>>
>> If you are only reading the value of population, then
>>
>> MAVR <- population
>>
>> is fine.? This is sometimes the same as c(population), but in general
>> it's different:? c() will remove some attributes, such as
>> the dimensions on arrays.
>>
>> If you need to modify it in your program, it's likely more
>complicated.
>> The normal way to go would be to put your code in a function, and
>have
>> it return the modified version.? For example,
>>
>> population <- doModifications(population)
>>
>> where doModifications is a function with a definition like
>>
>> doModifications <- function(MAVR) {
>>? ? # do all your calculations on MAVR
>>? ? # then return it at the end using
>>? ? MAVR
>> }
>>
>> Duncan Murdoch
>>
>>
>>
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.r-project.org/posting-guide.htmlandprovide commented,
>minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>-- 
>Statistics & Software Consulting
>GKX Group, GKX Associates Inc.
>tel: 1-877-GKX-GROUP
>email: ggrothendieck at gmail.com
>
>   
>
>   
>
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Feb  5 19:36:49 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 5 Feb 2016 18:36:49 +0000
Subject: [R] pearson correlation matrix
In-Reply-To: <56B4D78D.7000804@nancy.inra.fr>
References: <56B4AC75.5020506@nancy.inra.fr>
	<56B4B255.7000406@dewey.myzen.co.uk> <56B4D78D.7000804@nancy.inra.fr>
Message-ID: <56B4EBC1.8000701@dewey.myzen.co.uk>



On 05/02/2016 17:10, emmanuelle morin wrote:
> ok, it will still make sense ?
>

Whether it makes sense to correlate the people rather than the variables 
depends on the underlying science which (a) we do not know, and (b) is 
not really an R question.


> Le 05/02/2016 15:31, Michael Dewey a ?crit :
>> Assuming your dataset is in a matrix you want to transpose it. So you
>> can go t(mesdonnees) and then call cor on that.
>>
>> On 05/02/2016 14:06, emmanuelle morin wrote:
>>> Hello,
>>>
>>> I have a set of 12 individuals with thousands of variables measured.
>>> I understand that when I'm using the cor() function on my matrix I'm
>>> calculating the correlation between the different variables according to
>>> their values for the different individuals.
>>>
>>> What I'm willing to do is to calculate a correlation between the
>>> individuals and I have no clue how I can do that.
>>> Could you please help me ?
>>>
>>> Thanks,
>>>
>>> Emmanuelle
>>>
>>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From 538280 at gmail.com  Fri Feb  5 19:42:07 2016
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 5 Feb 2016 11:42:07 -0700
Subject: [R] Accessing specific data.frame columns within function
In-Reply-To: <CAJXvfGQgJr3P4p0J7FHnDu6nSZ1JeqA-X970Um-RqSnyBS_eew@mail.gmail.com>
References: <CAJXvfGQgJr3P4p0J7FHnDu6nSZ1JeqA-X970Um-RqSnyBS_eew@mail.gmail.com>
Message-ID: <CAFEqCdwpaROAWDr4hu9UWhP0hi18oYgm6evL7JDsoC5fgNe-rg@mail.gmail.com>

You are trying to use shortcuts where shortcuts are not appropriate
and having to go a lot longer around than if you did not use the
shortcut, see fortune(312).

You should really reread the help page: help("[[") and section 6.1 of
An Introduction to R.

Basically you should be able to do something like:

f <- function(data, oldnames) {
  data <- data[ data[[oldnames[2] ]] == 4, ]
  data[['d']] <- data[[ oldnames[1] ]]^2 + data[[ oldnames[2] ]]
  data
}

Or maybe a little more readable (but not as good a golf score):

f <- function(data, oldnames) {
  aa <- oldnames[1]
  cc <- oldnames[2]
  data <- data[ data[[ cc ]] == 4, ]
  data[['d']] <- data[[ aa ]]^2 + data[[ cc ]]
  data
}

I could have used a and c instead of aa and cc, but the doubled
letters mean less confusion with the `c` function in R.

Also you should read (and heed) the Warning section on the help page
for subset (?subset).

On Thu, Feb 4, 2016 at 9:13 PM, Clark Kogan <kogan.clark at gmail.com> wrote:
> Hello,
>
> I am trying to write a function that adds a few columns to a data.frame. The
> function uses the columns in a specific way. For instance, it might take a^2
> + c to produce a column d. Or it might do more complex manipulations that I
> don't think I need to discuss here. I want to keep x as a data.frame when I
> pass it into the function, as I want to use some data.frame functionality on
> x.
>
> Furthermore, I don't want the names in x to have to be specific. I want to
> be able to specify which columns the function should treat as "a" and "c".
>
> The way I am currently doing it, is that I pass the names of the columns
> that I want to treat as a and c.
>
> f <- function(data,oldnames) {
>   newnames <- c("a","c")
>   ix <- match(oldnames,names(y))
>   names(y)[ix] <- newnames
>   y <- subset(y,c==4)
>   y$d <- y$a^2 + y$c
>   ix <- match(newnames,names(y))
>   names(y)[ix] <- oldnames
>   y
> }
>
> y <- data.frame(k=c(1,1,1),l=c(2,2,5),m=c(4,2,4))
> f(y,c("k","m"))
>
> The way that I am doing it does not seem all that elegent or standard
> practice. My question is: are there potential problems programming with
> data.frames in this way, and are their standard practice methods of
> referencing data.frame names that deal with these problems?
>
> Thanks!
>
> Clark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From emmanuelle.morin at nancy.inra.fr  Fri Feb  5 18:10:37 2016
From: emmanuelle.morin at nancy.inra.fr (emmanuelle morin)
Date: Fri, 5 Feb 2016 18:10:37 +0100
Subject: [R] pearson correlation matrix
In-Reply-To: <56B4B255.7000406@dewey.myzen.co.uk>
References: <56B4AC75.5020506@nancy.inra.fr>
	<56B4B255.7000406@dewey.myzen.co.uk>
Message-ID: <56B4D78D.7000804@nancy.inra.fr>

ok, it will still make sense ?

Le 05/02/2016 15:31, Michael Dewey a ?crit :
> Assuming your dataset is in a matrix you want to transpose it. So you 
> can go t(mesdonnees) and then call cor on that.
>
> On 05/02/2016 14:06, emmanuelle morin wrote:
>> Hello,
>>
>> I have a set of 12 individuals with thousands of variables measured.
>> I understand that when I'm using the cor() function on my matrix I'm
>> calculating the correlation between the different variables according to
>> their values for the different individuals.
>>
>> What I'm willing to do is to calculate a correlation between the
>> individuals and I have no clue how I can do that.
>> Could you please help me ?
>>
>> Thanks,
>>
>> Emmanuelle
>>
>

-- 
Emmanuelle MORIN
UMR 1136 INRA/Universit? de Lorraine
F-54280 Champenoux
Tel : + 33 3 83 39 41 33
http://mycor.nancy.inra.fr


From howardr at iastate.edu  Sat Feb  6 06:53:57 2016
From: howardr at iastate.edu (Reka Howard)
Date: Fri, 5 Feb 2016 23:53:57 -0600
Subject: [R] reading in multiple data sets in 2 loops
Message-ID: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>

Hello,
I have over 1000 csv data sets I need to read into R, so I want to read
them in using a loop. The data sets are named as
pheno_1000ind_4000m_add_h70_prog_1_2.csv,
pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
last 2 numbers in the names). What I would like to do is the following:

setwd("C:/Research3/simulation1/second_gen")
d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
.
.
.

I am wondering how I can accomplish this with a loop. Any suggestion is
appreciated!
I tried the following but it does not work:

data <- lapply(
 paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
read.csv, header=TRUE, sep=',' )
names(data) <- paste("d", LETTERS[1:3], sep='')

Thanks!
Reka

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Feb  6 10:44:54 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 6 Feb 2016 20:44:54 +1100
Subject: [R] reading in multiple data sets in 2 loops
In-Reply-To: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
References: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
Message-ID: <CA+8X3fUUd5651AK+dRJQPCoKARkOFGpEvpSNAdnC=_no-Dg6vA@mail.gmail.com>

Hi Reka,
Try this:

header<-"C:/Research3/simulation1/second_gen/pheno_
1000ind_4000m_add_h70_prog"
for(index1 in 1:2) {
 for(index2 in 2:3)
  read.csv(paste(paste(header,index1,index2,sep="_"),".csv",sep=""))
}

Jim

On Sat, Feb 6, 2016 at 4:53 PM, Reka Howard <howardr at iastate.edu> wrote:

> Hello,
> I have over 1000 csv data sets I need to read into R, so I want to read
> them in using a loop. The data sets are named as
> pheno_1000ind_4000m_add_h70_prog_1_2.csv,
> pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
> last 2 numbers in the names). What I would like to do is the following:
>
> setwd("C:/Research3/simulation1/second_gen")
> d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
> d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
> d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
> .
> .
> .
>
> I am wondering how I can accomplish this with a loop. Any suggestion is
> appreciated!
> I tried the following but it does not work:
>
> data <- lapply(
>
>  paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
> read.csv, header=TRUE, sep=',' )
> names(data) <- paste("d", LETTERS[1:3], sep='')
>
> Thanks!
> Reka
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jupiter.hce at gmail.com  Sat Feb  6 13:11:05 2016
From: jupiter.hce at gmail.com (jupiter)
Date: Sat, 6 Feb 2016 23:11:05 +1100
Subject: [R] Plot step function
Message-ID: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>

Hi,

I am just starting to learn R, sorry for asking a simple question. How can
plot a line x <= 0 y = 0, x > 0 y = 1?

Thank you.

- j

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Feb  6 17:05:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 6 Feb 2016 11:05:56 -0500
Subject: [R] Plot step function
In-Reply-To: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
Message-ID: <56B619E4.4060501@gmail.com>

On 06/02/2016 7:11 AM, jupiter wrote:
> Hi,
>
> I am just starting to learn R, sorry for asking a simple question. How can
> plot a line x <= 0 y = 0, x > 0 y = 1?
>

There are lots of ways.  One is

curve(ifelse(x < 0, 0, 1), from=-2, to=2)

This isn't perfectly vertical at x=0; a more accurate approach would be 
to work out the coordinates of the endpoints and two corners in the 
appropriate order, and join them by lines.  For example,

plot(c(-2,0,0,2), c(0,0,1,1), type="l")

In either case you'll probably want to change axis labels using xlab or 
ylab arguments.

Duncan Murdoch


From dwinsemius at comcast.net  Sat Feb  6 19:23:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 6 Feb 2016 10:23:12 -0800
Subject: [R] Plot step function
In-Reply-To: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
Message-ID: <A37864CE-F0DD-4BF8-B7DC-6000FD751CA8@comcast.net>


> On Feb 6, 2016, at 4:11 AM, jupiter <jupiter.hce at gmail.com> wrote:
> 
> Hi,
> 
> I am just starting to learn R, sorry for asking a simple question. How can
> plot a line x <= 0 y = 0, x > 0 y = 1?

There is a stepfun function and an associated plotting method:

 y0 <- c(rep(0,3),rep(1,3))
 sfun0  <- stepfun(-2:2, y0, right=TRUE)
 plot(sfun0)
 
-- 

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Sat Feb  6 19:29:39 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 7 Feb 2016 07:29:39 +1300
Subject: [R] [FORGED]  Plot step function
In-Reply-To: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
Message-ID: <56B63B93.3030303@auckland.ac.nz>

On 07/02/16 01:11, jupiter wrote:
> Hi,
>
> I am just starting to learn R, sorry for asking a simple question. How can
> plot a line x <= 0 y = 0, x > 0 y = 1?

One way:

     plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Sat Feb  6 20:57:49 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 6 Feb 2016 11:57:49 -0800
Subject: [R] [FORGED] Plot step function
In-Reply-To: <56B63B93.3030303@auckland.ac.nz>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<56B63B93.3030303@auckland.ac.nz>
Message-ID: <CAGxFJbRPNEXw8Fwtb0Qp8=KavBLO=c0zEomOetg=Fyh-JGz64Q@mail.gmail.com>

All of which should suggest:

1. Before posting further, spend some time with an R tutorial or two.
"An Intro to R" ships with R; and links to some of the many excellent
web resources can be found here:

https://www.rstudio.com/resources/training/online-learning/#R


2. Search!  A web search of "plot step function in R"  would have
brought up stepfun() and other relevant links. rseek.org or the sos
package  -- or even the RSiteSearch() function -- are other ways to
find about R and R package functionality. See also the CRAN task view
pages.

Typically, answers to basic questions like the OP's can be found more
quickly and easily through such means; and with the added benefit of
providing examples and connections to related material. Of course, if
**after** consulting such resources questions still remain, asking
here is usually helpful.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 6, 2016 at 10:29 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 07/02/16 01:11, jupiter wrote:
>>
>> Hi,
>>
>> I am just starting to learn R, sorry for asking a simple question. How can
>> plot a line x <= 0 y = 0, x > 0 y = 1?
>
>
> One way:
>
>     plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Feb  6 21:01:23 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 6 Feb 2016 12:01:23 -0800 (PST)
Subject: [R] reading in multiple data sets in 2 loops
In-Reply-To: <CA+8X3fUUd5651AK+dRJQPCoKARkOFGpEvpSNAdnC=_no-Dg6vA@mail.gmail.com>
References: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
	<CA+8X3fUUd5651AK+dRJQPCoKARkOFGpEvpSNAdnC=_no-Dg6vA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1602061158580.55184@pedal.dcn.davis.ca.us>

Normally one wants not only to read the data, but to save it in an object 
as well. Here are some modifications toward achieving that (untested):

header<-"C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog"
fnums <- expand.grid( a = 1:2, b = 2:3 )
result <- vector( "list", nrow( fnums ) )
for ( idx in seq.int( nrow( fnums ) ) ) {
   result[[ idx ]] <- read.csv( paste( paste( header
                                            , fnums$a[ idx ]
                                            , fnums$b[ idx ]
                                            , sep = "_"
                                            )
                                     , ".csv"
                                     , sep = ""
                                     )
                              )
   # optionally remember which file each data record came from
   # assumes none of your input columns are labelled "a" or "b"
   result[[ idx ]]$a <- fnums$a[ idx ]
   result[[ idx ]]$b <- fnums$b[ idx ]
}

# you could also put all of the data into one data frame
result2 <- do.call( rbind, result )

# you could also do all of this in one dplyr pipe
library(dplyr)
result3 <- (   expand.grid( a = 1:2, b = 2:3 )
            %>% rowwise # work through each row of the a/b combinations
            %>% do( data.frame( a = .$a
                              , b = .$b
                              , read.csv( paste( paste( header
                                                      , .$a
                                                      , .$b
                                                      , sep = "_"
                                                      )
                                               , ".csv"
                                               , sep = ""
                                               )
                                        )
                              )
                  )
            %>% as.data.frame
            )


On Sat, 6 Feb 2016, Jim Lemon wrote:

> Hi Reka,
> Try this:
>
> header<-"C:/Research3/simulation1/second_gen/pheno_
> 1000ind_4000m_add_h70_prog"
> for(index1 in 1:2) {
> for(index2 in 2:3)
>  read.csv(paste(paste(header,index1,index2,sep="_"),".csv",sep=""))
> }
>
> Jim
>
> On Sat, Feb 6, 2016 at 4:53 PM, Reka Howard <howardr at iastate.edu> wrote:
>
>> Hello,
>> I have over 1000 csv data sets I need to read into R, so I want to read
>> them in using a loop. The data sets are named as
>> pheno_1000ind_4000m_add_h70_prog_1_2.csv,
>> pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
>> last 2 numbers in the names). What I would like to do is the following:
>>
>> setwd("C:/Research3/simulation1/second_gen")
>> d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
>> d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
>> d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
>> .
>> .
>> .
>>
>> I am wondering how I can accomplish this with a loop. Any suggestion is
>> appreciated!
>> I tried the following but it does not work:
>>
>> data <- lapply(
>>
>>  paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
>> read.csv, header=TRUE, sep=',' )
>> names(data) <- paste("d", LETTERS[1:3], sep='')
>>
>> Thanks!
>> Reka
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From goran.brostrom at umu.se  Sat Feb  6 21:12:33 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sat, 6 Feb 2016 21:12:33 +0100
Subject: [R] Plot step function
In-Reply-To: <A37864CE-F0DD-4BF8-B7DC-6000FD751CA8@comcast.net>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<A37864CE-F0DD-4BF8-B7DC-6000FD751CA8@comcast.net>
Message-ID: <56B653B1.6030806@umu.se>

On 2016-02-06 19:23, David Winsemius wrote:
>
>> On Feb 6, 2016, at 4:11 AM, jupiter <jupiter.hce at gmail.com> wrote:
>>
>> Hi,
>>
>> I am just starting to learn R, sorry for asking a simple question. How can
>> plot a line x <= 0 y = 0, x > 0 y = 1?
>
> There is a stepfun function and an associated plotting method:
>
>   y0 <- c(rep(0,3),rep(1,3))
>   sfun0  <- stepfun(-2:2, y0, right=TRUE)
>   plot(sfun0)

I would like to suggest the correct way:

Replace the last line by

 > plot(sfun0, verticals = FALSE)

G?ran Brostr?m


From jupiter.hce at gmail.com  Sat Feb  6 22:49:36 2016
From: jupiter.hce at gmail.com (jupiter)
Date: Sun, 7 Feb 2016 08:49:36 +1100
Subject: [R] [FORGED]  Plot step function
In-Reply-To: <56B63B93.3030303@auckland.ac.nz>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<56B63B93.3030303@auckland.ac.nz>
Message-ID: <CAA=hcWQX9or8TSyRVnCvBwPErqksMC2hm7Uatua6xh2bHKVcBA@mail.gmail.com>

Thank you for the all response, how can the point y (0.0) on the same x
axis, and X increases 1 between [-4, 4]?

On Sun, Feb 7, 2016 at 5:29 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 07/02/16 01:11, jupiter wrote:
>
>> Hi,
>>
>> I am just starting to learn R, sorry for asking a simple question. How can
>> plot a line x <= 0 y = 0, x > 0 y = 1?
>>
>
> One way:
>
>     plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Feb  7 00:27:24 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 6 Feb 2016 15:27:24 -0800
Subject: [R] reading in multiple data sets in 2 loops
In-Reply-To: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
References: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
Message-ID: <CAF8bMcYx_DUQ8+16sWvDfbK-KurrOWBrBT7sekkTAzQWaqKVEA@mail.gmail.com>

    I tried the following but it does not work:

    data <- lapply(
     paste(("C:/Research3/simulation1/second_gen/pheno_
1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
    read.csv, header=TRUE, sep=',' )
    names(data) <- paste("d", LETTERS[1:3], sep='')

I tried that and R complained about syntax errors - unexpected commas,
mismatched parentheses, illegal square brackets, etc.

Using lapply like this a perfectly fine way to solve  the problem but you
need to get the details right.  I find it easier to break  that statement
into parts and make sure each part is working.  E.g., after a minimal
cleanup of your code the file names would be computed as
    fileNames <-  paste("C:/Research3/simulation1/second_gen/pheno_
1000ind_4000m_add_h70_prog_", 1:2 ,"_", 2:3 ,".csv",sep='')
    print(fileNames) # do they look right?  You said you wanted 1_2, 1_3,
2_3 but that will give you only 2 of them
or perhaps you want all the files in that directory with a given pattern
    fileNames <- dir("C:/Research3/simulation1/second_gen",
pattern="^pheno_1000ind_4000m_add_h70_prog_[[:digit:]]+_[[:digit:]]+\\.csv$",
full.names=TRUE, ignore.case=TRUE)
    head(fileNames) # keep at it until the fileNames list looks good
    tail(fileNames)

Then read the data from the files with
    data <- lapply(fileNames, read.csv, header=TRUE, sep=",")
If there are errors reading the files in csv format you could try
    data <- lapply(fileNames, function(fileName) { cat(fileName, "\n");
read.csv(fileName, header=TRUE, sep=",")}
so you can see the name of the first offending file.

When you attach names you probably want to get the names from the fileNames
variable, perhaps just the digits part
    names(data) <- gsub("^.*([[:digit:]]+_[[:digit:]]+)\\.csv$", "d_\\1",
fileNames)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 5, 2016 at 9:53 PM, Reka Howard <howardr at iastate.edu> wrote:

> Hello,
> I have over 1000 csv data sets I need to read into R, so I want to read
> them in using a loop. The data sets are named as
> pheno_1000ind_4000m_add_h70_prog_1_2.csv,
> pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
> last 2 numbers in the names). What I would like to do is the following:
>
> setwd("C:/Research3/simulation1/second_gen")
> d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
> d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
> d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
> .
> .
> .
>
> I am wondering how I can accomplish this with a loop. Any suggestion is
> appreciated!
> I tried the following but it does not work:
>
> data <- lapply(
>
>  paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
> read.csv, header=TRUE, sep=',' )
> names(data) <- paste("d", LETTERS[1:3], sep='')
>
> Thanks!
> Reka
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oriolebaltimore at gmail.com  Sun Feb  7 00:45:16 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Sat, 6 Feb 2016 18:45:16 -0500
Subject: [R] sorting matrix by sets rows
Message-ID: <CAL2fYnPfMm0CxuNgEYCWtzUiGk=O6Zxk-s0Oms14deAuy_c4xw@mail.gmail.com>

Hello:
sorry I've been trying to sort a matrix to make waterfall plot using
barplot function.

I have have 30x5 matrix.    Rows are samples and columns are results
for a test as numeric vector.

I want sort matrix by column. For example, first I want to sort column
1, in decreasing values where column 5 $ Cluster == 1 and then again
decreasing by those rows with column == 2.

How can I sort the column, by decreasing order, first by samples where
clusters belong to 1 and then sort rows that belong to cluster 2.

Thanks
adrian

Example data is given as dput.

structure(list(Byers_EMT = c(4003.034387, 3768.281515, 3050.928331,
3176.920101, 2934.668097, 4823.117405, 3223.478884, 4241.000063,
2283.048518, 4338.528845, 3036.77349, 4300.743191, 3368.661555,
4658.908373, 4388.761884, 4081.057216, 3096.255942, 4705.843311,
4198.967015, 4273.724545, 3748.975301, 3686.148902, 4538.225296,
3799.86772, 4055.619424, 2242.591587, 3240.442781, 4881.301143,
4715.630605, 2390.426857), GOTZ_EMT = c(-462.4488505, 221.7113983,
382.0156009, -213.9475246, 412.4785725, -876.3339338, -428.6239051,
-904.5665305, 1095.115995, -74.39566533, 462.2938373, -1114.129494,
490.1939685, -686.8375546, -265.4837211, -19.85851263, -143.0651772,
-474.8515908, 59.99735, -245.9500041, -116.9701906, 164.9975774,
-353.3706953, 296.4978516, -225.2971721, 841.0098397, 311.3738267,
-497.1874598, -507.8169759, 893.5205575), GOT_EMT = c(3647.970274,
4308.586674, 4284.509207, 3864.143199, 4546.207066, 2857.187171,
3689.57683, 3342.042018, 5081.829902, 3984.897048, 4300.881677,
3296.588856, 4187.054703, 3586.055372, 3614.984328, 4478.424137,
3725.619911, 3922.904098, 4055.279616, 3915.446721, 4087.219866,
4243.127381, 4029.672242, 4331.676433, 4034.186023, 4718.144867,
4627.10284, 3948.356452, 3856.944245, 5041.236254), GOT_DN_EMT = c(4110.419124,
4086.875276, 3902.493606, 4078.090724, 4133.728494, 3733.521105,
4118.200735, 4246.608548, 3986.713907, 4059.292713, 3838.587839,
4410.71835, 3696.860734, 4272.892927, 3880.468049, 4498.282649,
3868.685088, 4397.755689, 3995.282266, 4161.396725, 4204.190056,
4078.129803, 4383.042937, 4035.178581, 4259.483195, 3877.135027,
4315.729014, 4445.543912, 4364.761221, 4147.715697), Cluster = c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L)), .Names = c("Byers_EMT",
"GOTZ_EMT", "GOT_EMT", "GOT_DN_EMT", "Cluster"), class = "data.frame",
row.names = c("BA.5555",
"CN.5356", "CR.7398", "CR.7402", "CV.7247", "CN.6988", "CV.5440",
"BA.6869", "CN.6022", "CN.5360", "CR.7399", "CV.7250", "CV.7440",
"CV.7242", "CN.4739", "CV.7421", "CV.5441", "CR.7364", "CN.4727",
"F7.7848", "CV.7245", "CR.7370", "CR.7371", "CV.7415", "CV.6935",
"CV.5444", "CV.5978", "CN.4738", "CV.7089", "CN.6989"))


From boris.steipe at utoronto.ca  Sun Feb  7 02:18:22 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 6 Feb 2016 20:18:22 -0500
Subject: [R] reading in multiple data sets in 2 loops
In-Reply-To: <CAF8bMcYx_DUQ8+16sWvDfbK-KurrOWBrBT7sekkTAzQWaqKVEA@mail.gmail.com>
References: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
	<CAF8bMcYx_DUQ8+16sWvDfbK-KurrOWBrBT7sekkTAzQWaqKVEA@mail.gmail.com>
Message-ID: <EACA68E3-CDCA-4A8F-951C-0405F144F052@utoronto.ca>

Computing filenames is a dangerous, backwards approach. If you already _have_ files, it's wrong to create filenames from assumptions. Rather you need to capture the existing filenames with an appropriate use of list.files(), and then process that vector. Computing filenames only has a place when you are creating new files.

Cheers,
Boris




On Feb 6, 2016, at 6:27 PM, William Dunlap via R-help <r-help at r-project.org> wrote:

>    I tried the following but it does not work:
> 
>    data <- lapply(
>     paste(("C:/Research3/simulation1/second_gen/pheno_
> 1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
>    read.csv, header=TRUE, sep=',' )
>    names(data) <- paste("d", LETTERS[1:3], sep='')
> 
> I tried that and R complained about syntax errors - unexpected commas,
> mismatched parentheses, illegal square brackets, etc.
> 
> Using lapply like this a perfectly fine way to solve  the problem but you
> need to get the details right.  I find it easier to break  that statement
> into parts and make sure each part is working.  E.g., after a minimal
> cleanup of your code the file names would be computed as
>    fileNames <-  paste("C:/Research3/simulation1/second_gen/pheno_
> 1000ind_4000m_add_h70_prog_", 1:2 ,"_", 2:3 ,".csv",sep='')
>    print(fileNames) # do they look right?  You said you wanted 1_2, 1_3,
> 2_3 but that will give you only 2 of them
> or perhaps you want all the files in that directory with a given pattern
>    fileNames <- dir("C:/Research3/simulation1/second_gen",
> pattern="^pheno_1000ind_4000m_add_h70_prog_[[:digit:]]+_[[:digit:]]+\\.csv$",
> full.names=TRUE, ignore.case=TRUE)
>    head(fileNames) # keep at it until the fileNames list looks good
>    tail(fileNames)
> 
> Then read the data from the files with
>    data <- lapply(fileNames, read.csv, header=TRUE, sep=",")
> If there are errors reading the files in csv format you could try
>    data <- lapply(fileNames, function(fileName) { cat(fileName, "\n");
> read.csv(fileName, header=TRUE, sep=",")}
> so you can see the name of the first offending file.
> 
> When you attach names you probably want to get the names from the fileNames
> variable, perhaps just the digits part
>    names(data) <- gsub("^.*([[:digit:]]+_[[:digit:]]+)\\.csv$", "d_\\1",
> fileNames)
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Fri, Feb 5, 2016 at 9:53 PM, Reka Howard <howardr at iastate.edu> wrote:
> 
>> Hello,
>> I have over 1000 csv data sets I need to read into R, so I want to read
>> them in using a loop. The data sets are named as
>> pheno_1000ind_4000m_add_h70_prog_1_2.csv,
>> pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
>> last 2 numbers in the names). What I would like to do is the following:
>> 
>> setwd("C:/Research3/simulation1/second_gen")
>> d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
>> d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
>> d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
>> .
>> .
>> .
>> 
>> I am wondering how I can accomplish this with a loop. Any suggestion is
>> appreciated!
>> I tried the following but it does not work:
>> 
>> data <- lapply(
>> 
>> paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
>> read.csv, header=TRUE, sep=',' )
>> names(data) <- paste("d", LETTERS[1:3], sep='')
>> 
>> Thanks!
>> Reka
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Feb  7 06:34:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 6 Feb 2016 21:34:30 -0800
Subject: [R] sorting matrix by sets rows
In-Reply-To: <CAL2fYnPfMm0CxuNgEYCWtzUiGk=O6Zxk-s0Oms14deAuy_c4xw@mail.gmail.com>
References: <CAL2fYnPfMm0CxuNgEYCWtzUiGk=O6Zxk-s0Oms14deAuy_c4xw@mail.gmail.com>
Message-ID: <CAGxFJbQMK+XVnnbJ1N+g74iuT0vm7yezrvMsRSrAxEJmXnzzKQ@mail.gmail.com>

?order

is what I think you want. There is a slight wrinkle here, however. You
want to sort Cluster in *increasing* order and Byers_EMT in
*decreasing*, as I understand. order() will do both increasing, or
both decreasing, but not differently. So a simple but inefficient way
around this is to first do them both decreasing and then use order()
by Cluster increasing. Perhaps others will find a slicker way. Also
**PLEASE** note that your structure is a data frame, not a matrix! If
you do not understand the difference you need to spend some time with
an R tutorial or two to learn. It is basic and essential.

Anyway here is my suggestion. I have taken a slight shortcut by using
the very convenient with() function. See ?with for details.

## z is your data frame from dput. Thanks for the minimal example.

znew <- with(z,z[order(Cluster,Byers_EMT), ])

## now sort by Cluster

znew <- with(znew,znew[order(Cluster), ])


Again, while I think this does what you want, someone else may provide
something slicker. Or simpler. But the order() function is still very
useful to know about anyway for this sort of thing.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 6, 2016 at 3:45 PM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hello:
> sorry I've been trying to sort a matrix to make waterfall plot using
> barplot function.
>
> I have have 30x5 matrix.    Rows are samples and columns are results
> for a test as numeric vector.
>
> I want sort matrix by column. For example, first I want to sort column
> 1, in decreasing values where column 5 $ Cluster == 1 and then again
> decreasing by those rows with column == 2.
>
> How can I sort the column, by decreasing order, first by samples where
> clusters belong to 1 and then sort rows that belong to cluster 2.
>
> Thanks
> adrian
>
> Example data is given as dput.
>
> structure(list(Byers_EMT = c(4003.034387, 3768.281515, 3050.928331,
> 3176.920101, 2934.668097, 4823.117405, 3223.478884, 4241.000063,
> 2283.048518, 4338.528845, 3036.77349, 4300.743191, 3368.661555,
> 4658.908373, 4388.761884, 4081.057216, 3096.255942, 4705.843311,
> 4198.967015, 4273.724545, 3748.975301, 3686.148902, 4538.225296,
> 3799.86772, 4055.619424, 2242.591587, 3240.442781, 4881.301143,
> 4715.630605, 2390.426857), GOTZ_EMT = c(-462.4488505, 221.7113983,
> 382.0156009, -213.9475246, 412.4785725, -876.3339338, -428.6239051,
> -904.5665305, 1095.115995, -74.39566533, 462.2938373, -1114.129494,
> 490.1939685, -686.8375546, -265.4837211, -19.85851263, -143.0651772,
> -474.8515908, 59.99735, -245.9500041, -116.9701906, 164.9975774,
> -353.3706953, 296.4978516, -225.2971721, 841.0098397, 311.3738267,
> -497.1874598, -507.8169759, 893.5205575), GOT_EMT = c(3647.970274,
> 4308.586674, 4284.509207, 3864.143199, 4546.207066, 2857.187171,
> 3689.57683, 3342.042018, 5081.829902, 3984.897048, 4300.881677,
> 3296.588856, 4187.054703, 3586.055372, 3614.984328, 4478.424137,
> 3725.619911, 3922.904098, 4055.279616, 3915.446721, 4087.219866,
> 4243.127381, 4029.672242, 4331.676433, 4034.186023, 4718.144867,
> 4627.10284, 3948.356452, 3856.944245, 5041.236254), GOT_DN_EMT = c(4110.419124,
> 4086.875276, 3902.493606, 4078.090724, 4133.728494, 3733.521105,
> 4118.200735, 4246.608548, 3986.713907, 4059.292713, 3838.587839,
> 4410.71835, 3696.860734, 4272.892927, 3880.468049, 4498.282649,
> 3868.685088, 4397.755689, 3995.282266, 4161.396725, 4204.190056,
> 4078.129803, 4383.042937, 4035.178581, 4259.483195, 3877.135027,
> 4315.729014, 4445.543912, 4364.761221, 4147.715697), Cluster = c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L)), .Names = c("Byers_EMT",
> "GOTZ_EMT", "GOT_EMT", "GOT_DN_EMT", "Cluster"), class = "data.frame",
> row.names = c("BA.5555",
> "CN.5356", "CR.7398", "CR.7402", "CV.7247", "CN.6988", "CV.5440",
> "BA.6869", "CN.6022", "CN.5360", "CR.7399", "CV.7250", "CV.7440",
> "CV.7242", "CN.4739", "CV.7421", "CV.5441", "CR.7364", "CN.4727",
> "F7.7848", "CV.7245", "CR.7370", "CR.7371", "CV.7415", "CV.6935",
> "CV.5444", "CV.5978", "CN.4738", "CV.7089", "CN.6989"))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aurora.gonzalez2 at um.es  Sun Feb  7 14:36:40 2016
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Sun, 07 Feb 2016 14:36:40 +0100
Subject: [R] evaluation + Re:  hourly prediction time series
In-Reply-To: <058801d15ff6$30712510$91536f30$@ori.org.za>
References: <20160205095009.Horde.f0DOCXhe2Q4F-ctHtQS0vw1@webmail.um.es>
	<058801d15ff6$30712510$91536f30$@ori.org.za>
Message-ID: <20160207143640.Horde.Deqc0we2hN_doxifsYBueg1@webmail.um.es>

  Thank you, it works fine.

Now, I am trying to evaluate the performance of the model across time. So
as to do that I use rolling window which I understand as sort of a "leave
one out".

The example:

The data are from the 1st of January to nowadays so, I use data from the
1st of January to the 1st of December to fit the model and then I predict
the temperatures of the 2nd of December. As I have the real ones, I can
compute RMSE or other metrics.
Then, I use data from 1st of January to the 2nd of December in order to
predict the 24 values of temperature on the 3rd of December, and later I
compute again the RMSE (between predicted and real of the 3rd).
So on untill I have no more data.
Then, I have several RMSE, I compute their mean and sd and I consider this
as the evaluation of the model's performance.

The question is: do you know any book or documentation where I can cosult
how many times should I do this process so as to know where I should start.
Should I start before December to do the rolling? I mean, is there any
agreement? For example, if I have 400 days of data, meaning 9600 (400 * 24)
observations maybe I could choose a 10 % of the windows so as to start
evaluating, which means, do the process 40 times starting with the day 360.

Any source of information will be appreciated.

Sean Porter <sporter at ori.org.za> escribi?:

> Try the auto.arima function in the forecast package..
>
> Regards,
>
> DR SEAN PORTER
> Scientist
>
> South African Association for Marine Biological Research
> Direct Tel: +27 (31) 328 8169? ?Fax: +27 (31) 328 8188
> E-mail: sporter at ori.org.za Web: www.saambr.org.za[1]
> 1 King Shaka Avenue, Point, Durban 4001 KwaZulu-Natal South Africa
> PO Box 10712, Marine Parade 4056 KwaZulu-Natal South Africa
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AURORA
> GONZALEZ VIDAL
> Sent: 05 February 2016 10:50 AM
> To: r-help at r-project.org
> Subject: [R] hourly prediction time series
>
> Dear R users,
>
> I am fronting my firts time series problem. I have hourly temperature
> data for 3 years (from 01/01/2013 to 5/02/2016). I would like to use
> those in order to PREDICT TEMPERATURE OF THE NEXT HOURS according to the
> observations.
>
> A subset of the data look like this:
>
> date <- rep(seq(as.Date("14-01-01"), as.Date("14-01-03"), by="days"),
> 24) hour <-rep(c(paste0("0",0:9,":00:00"), paste0(10:23,":00:00")),3)
> temperature <- c(6.1, 6.8, 6.5, 7.2, 7.1, 7.9, 5.9, 6.8, 7.7, 9.5, 12.6,
> ? ? ? ? ? ? ? ? 14.0, 15.9, 17.3, 17.5, 17.2, 15.0, 14.1, 13.1,
11.7,
> 10.9,
> ? ? ? ? ? ? ? ? 11.0, 11.6, 11.0, 11.2, 11.0, 11.0, 11.4, 12.2,
13.7,
> 12.9,
> ? ? ? ? ? ? ? ? 12.9, 12.8, 13.4, 13.9, 14.9, 16.6, 16.0, 15.2,
15.4,
> 14.7,
> ? ? ? ? ? ? ? ? 14.6, 13.3, 13.0, 13.8, 13.1, 12.0, 11.9, 11.8,
11.6,
> 11.0,
> ? ? ? ? ? ? ? ? 11.2, 11.6, 10.6, 9.5, 9.8, 9.9, 11.7, 15.3,
18.6, 20.7,
> ? ? ? ? ? ? ? ? 22.2, 22.2, 20.8, 20.2, 18.3, 15.6, 13.6, 12.8,
13.1,
> 13.7, 14.7)
>
> dfExample <- data.frame(date, hour, temperature)
>
> So as to plot 3 years ( from 01/01/2013 to 31/12/2015) I use this code
> and obtained the attached picture. It is observed seasonality.
>
> tempdf4 <- ts(df4$temperature, frequency=365*24*3)
> plot.ts(tempdf4)
>
> Am I doing it well? Could you help me with any information in this type
> of problem (mainly with the prediction). For example, if I want to use
> Arima, according with my data structure, what are the arguments of the
> funcion??
>
> fit=Arima(df4$temperature, seasonal=list(order=c(xxx,xxx,xxx),period=xxx)
> plot(forecast(fit))
>
> I could use also some predictions from other source that I am collecting
> since January, 2016. But I would prefer to understand the simplest way
> to solve the problem and then, progressively, understand more complex
> approaches.
>
> Thank you very much for any kind of help.
>
> ------
> Aurora Gonz?lez Vidal
> Phd student in Data Analytics for Energy Efficiency
>
> Faculty of Computer Sciences
> University of Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7866www.um.es/ae[2]



V?nculos:
---------
[1] http://www.saambr.org.za
[2] http://7866www.um.es/ae


------
Aurora Gonz?lez Vidal
Phd student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Sun Feb  7 14:51:06 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 7 Feb 2016 14:51:06 +0100
Subject: [R] reading in multiple data sets in 2 loops
In-Reply-To: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
References: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
Message-ID: <56B74BCA.8030401@yahoo.fr>

Try this:

# install package HelpersMG from CRAN including dependencies
install.packages("HelpersMG")
# Update to the lastest version
install.packages("http://www.ese.u-psud.fr/epc/conservation/CRAN/HelpersMG.tar.gz", 
repos=NULL, type="source")

# Use the function read_folder()
library("HelpersMG")

content_as_list <- read_folder(folder = 
"C:/Research3/simulation1/second_gen", wildcard = "*.csv",
   read = read.csv)

I have created this function because I had exactely the same poblem that 
you described !

Sincerely,

Marc

Le 06/02/2016 06:53, Reka Howard a ?crit :
> Hello,
> I have over 1000 csv data sets I need to read into R, so I want to read
> them in using a loop. The data sets are named as
> pheno_1000ind_4000m_add_h70_prog_1_2.csv,
> pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
> last 2 numbers in the names). What I would like to do is the following:
>
> setwd("C:/Research3/simulation1/second_gen")
> d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
> d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
> d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
> .
> .
> .
>
> I am wondering how I can accomplish this with a loop. Any suggestion is
> appreciated!
> I tried the following but it does not work:
>
> data <- lapply(
>   paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
> read.csv, header=TRUE, sep=',' )
> names(data) <- paste("d", LETTERS[1:3], sep='')
>
> Thanks!
> Reka
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sunnysingha.analytics at gmail.com  Sun Feb  7 16:19:53 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Sun, 7 Feb 2016 20:49:53 +0530
Subject: [R] rfImpute() error-- while missing imputation --
Message-ID: <48305685-D9E3-4A05-98AE-20F652CC3E9D@gmail.com>

Hi,
While executing rfImpute() in order to impute missing values in the data set I receive below error :

     |      Out-of-bag   |
Tree |      MSE  %Var(y) |
 800 | 2.979e+04     1.02 |
Error in prox[miss, -miss, drop = FALSE] %*% xf[, j][-miss] : 
  requires numeric/complex matrix/vector arguments

Has anyone experienced it aware of the cause? Below is the command I used to :
 x_tr_imp <- rfImpute(x_train[,-c(1,7)], x_train$Outlet_Sales, iter=5, 800)

Regards,
Sandeep S. Rana
sunnysingha.analytics at gmail.com <mailto:sunnysingha.analytics at gmail.com>
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Feb  7 16:28:59 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 7 Feb 2016 07:28:59 -0800
Subject: [R] rfImpute() error-- while missing imputation --
In-Reply-To: <48305685-D9E3-4A05-98AE-20F652CC3E9D@gmail.com>
References: <48305685-D9E3-4A05-98AE-20F652CC3E9D@gmail.com>
Message-ID: <CAGxFJbSQk8Qx4MQ6cg+VkpMERVkyO=B+E_xWiNUr2W6vNMqDsg@mail.gmail.com>

5800  **not 5, 800** , no commas and no spaces.

Please read an R tutorial or two to learn how to properly work with R
if this is not merely a typo.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 7, 2016 at 7:19 AM, Sandeep Rana
<sunnysingha.analytics at gmail.com> wrote:
> Hi,
> While executing rfImpute() in order to impute missing values in the data set I receive below error :
>
>      |      Out-of-bag   |
> Tree |      MSE  %Var(y) |
>  800 | 2.979e+04     1.02 |
> Error in prox[miss, -miss, drop = FALSE] %*% xf[, j][-miss] :
>   requires numeric/complex matrix/vector arguments
>
> Has anyone experienced it aware of the cause? Below is the command I used to :
>  x_tr_imp <- rfImpute(x_train[,-c(1,7)], x_train$Outlet_Sales, iter=5, 800)
>
> Regards,
> Sandeep S. Rana
> sunnysingha.analytics at gmail.com <mailto:sunnysingha.analytics at gmail.com>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rekahoward at gmail.com  Sun Feb  7 08:06:09 2016
From: rekahoward at gmail.com (Reka Howard)
Date: Sun, 7 Feb 2016 01:06:09 -0600
Subject: [R] reading in multiple data sets in 2 loops
In-Reply-To: <alpine.BSF.2.00.1602061158580.55184@pedal.dcn.davis.ca.us>
References: <CA+AfSTibtOcaQfFGFi0HHAeMD4W4b7QyCPHgOTO-GKHgLQbouw@mail.gmail.com>
	<CA+8X3fUUd5651AK+dRJQPCoKARkOFGpEvpSNAdnC=_no-Dg6vA@mail.gmail.com>
	<alpine.BSF.2.00.1602061158580.55184@pedal.dcn.davis.ca.us>
Message-ID: <CA+AfSTjK4GdsF6jZAeAjWN2SVXT+Jz8Gr4DzK8_z1XGpSJfeww@mail.gmail.com>

Thank you very much for all of the help!!! For what I need, Jim's and
Jeff's solutions were the most useful, but I really appreciate all of the
help I got.

On Sat, Feb 6, 2016 at 2:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Normally one wants not only to read the data, but to save it in an object
> as well. Here are some modifications toward achieving that (untested):
>
>
> header<-"C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog"
> fnums <- expand.grid( a = 1:2, b = 2:3 )
> result <- vector( "list", nrow( fnums ) )
> for ( idx in seq.int( nrow( fnums ) ) ) {
>   result[[ idx ]] <- read.csv( paste( paste( header
>                                            , fnums$a[ idx ]
>                                            , fnums$b[ idx ]
>                                            , sep = "_"
>                                            )
>                                     , ".csv"
>                                     , sep = ""
>                                     )
>                              )
>   # optionally remember which file each data record came from
>   # assumes none of your input columns are labelled "a" or "b"
>   result[[ idx ]]$a <- fnums$a[ idx ]
>   result[[ idx ]]$b <- fnums$b[ idx ]
> }
>
> # you could also put all of the data into one data frame
> result2 <- do.call( rbind, result )
>
> # you could also do all of this in one dplyr pipe
> library(dplyr)
> result3 <- (   expand.grid( a = 1:2, b = 2:3 )
>            %>% rowwise # work through each row of the a/b combinations
>            %>% do( data.frame( a = .$a
>                              , b = .$b
>                              , read.csv( paste( paste( header
>                                                      , .$a
>                                                      , .$b
>                                                      , sep = "_"
>                                                      )
>                                               , ".csv"
>                                               , sep = ""
>                                               )
>                                        )
>                              )
>                  )
>            %>% as.data.frame
>            )
>
>
>
> On Sat, 6 Feb 2016, Jim Lemon wrote:
>
> Hi Reka,
>> Try this:
>>
>> header<-"C:/Research3/simulation1/second_gen/pheno_
>> 1000ind_4000m_add_h70_prog"
>> for(index1 in 1:2) {
>> for(index2 in 2:3)
>>  read.csv(paste(paste(header,index1,index2,sep="_"),".csv",sep=""))
>> }
>>
>> Jim
>>
>> On Sat, Feb 6, 2016 at 4:53 PM, Reka Howard <howardr at iastate.edu> wrote:
>>
>> Hello,
>>> I have over 1000 csv data sets I need to read into R, so I want to read
>>> them in using a loop. The data sets are named as
>>> pheno_1000ind_4000m_add_h70_prog_1_2.csv,
>>> pheno_1000ind_4000m_add_h70_prog_1_3.csv, ... so I need 2 loops (for the
>>> last 2 numbers in the names). What I would like to do is the following:
>>>
>>> setwd("C:/Research3/simulation1/second_gen")
>>> d1<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_2.csv")
>>> d2<-read.csv("pheno_1000ind_4000m_add_h70_prog_1_3.csv")
>>> d3<-read.csv("pheno_1000ind_4000m_add_h70_prog_2_3.csv")
>>> .
>>> .
>>> .
>>>
>>> I am wondering how I can accomplish this with a loop. Any suggestion is
>>> appreciated!
>>> I tried the following but it does not work:
>>>
>>> data <- lapply(
>>>
>>>
>>>  paste(("C:/Research3/simulation1/second_gen/pheno_1000ind_4000m_add_h70_prog_",[1:2],"_",[2:3],".csv",sep=''),
>>> read.csv, header=TRUE, sep=',' )
>>> names(data) <- paste("d", LETTERS[1:3], sep='')
>>>
>>> Thanks!
>>> Reka
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Sun Feb  7 17:40:21 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Sun, 7 Feb 2016 22:10:21 +0530
Subject: [R] rfImpute() error-- while missing imputation --
In-Reply-To: <CAGxFJbSQk8Qx4MQ6cg+VkpMERVkyO=B+E_xWiNUr2W6vNMqDsg@mail.gmail.com>
References: <48305685-D9E3-4A05-98AE-20F652CC3E9D@gmail.com>
	<CAGxFJbSQk8Qx4MQ6cg+VkpMERVkyO=B+E_xWiNUr2W6vNMqDsg@mail.gmail.com>
Message-ID: <50553430-AFE9-4D03-A647-EFA941FF9BB9@gmail.com>

Oh! It was a typo. ntree=800 was to be specified. Thanks Bret.
> .On 07-Feb-2016, at 8:58 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> 5800  **not 5, 800** , no commas and no spaces.
> 
> Please read an R tutorial or two to learn how to properly work with R
> if this is not merely a typo.
> 
> -- Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Feb 7, 2016 at 7:19 AM, Sandeep Rana
> <sunnysingha.analytics at gmail.com> wrote:
>> Hi,
>> While executing rfImpute() in order to impute missing values in the data set I receive below error :
>> 
>>     |      Out-of-bag   |
>> Tree |      MSE  %Var(y) |
>> 800 | 2.979e+04     1.02 |
>> Error in prox[miss, -miss, drop = FALSE] %*% xf[, j][-miss] :
>>  requires numeric/complex matrix/vector arguments
>> 
>> Has anyone experienced it aware of the cause? Below is the command I used to :
>> x_tr_imp <- rfImpute(x_train[,-c(1,7)], x_train$Outlet_Sales, iter=5, 800)
>> 
>> Regards,
>> Sandeep S. Rana
>> sunnysingha.analytics at gmail.com <mailto:sunnysingha.analytics at gmail.com>
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From stefano.sofia at regione.marche.it  Sun Feb  7 19:24:57 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Sun, 7 Feb 2016 18:24:57 +0000
Subject: [R] five multiple plots with ggplot
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DB8A14E@ESINO.regionemarche.intra>

Dear list users,
I would like to have multiple plots in one page with ggplot, in particular five graphs:
in the central plot the snow cover (hs) of two meteorological stations; above wind direction and temperature of one of the two stations and below wind direction and temperature of the other station.

My data frame (df) is like

date hs1 temp1 wind1 wind_dir1 pch_wind_dir1 color_wind_dir1 hs2 temp2 wind2 wind_dir2 pch_wind_dir2 color_wind_dir2
2014-12-27 00:00:00 20 -4.2 6.8 NW 5 "blue" 40 -4.2 6.8 NW 5 "blue"
2014-12-27 00:30:00 22 -4.3 4.3 NNE 5 "cyan" 42 -4.3 4.3 NNE 5 "cyan"
2014-12-27 01:00:00 24 -4.1 5.7 NNW 10 "cyan" 44 -4.1 5.7 NNW 10 "cyan"
2014-12-27 10:00:00 30 -2.6 7.2 NNW 10 "cyan" 44 -3.1 5.7 NNW 10 "cyan"
...

with 48 rows.

The ylim of hs1 and hs2 should be fixed between 0 and 200cm, hs1 colored with blue and the other with red;
wind1 and wind2 should take the pch and color described in each row.

lapply(df, class) gives

$date
[1] "POSIXct" "POSIXt"

$hs1
[1] "numeric"

$temp1
[1] "numeric"

$wind1
[1] "numeric"

and so on.

I have been trying for a long time to do that starting from some examples found in the web, with no success. The example code I started with is

> ggplot(df, aes(date, hs1, ymin=0, ymax=200, colour = "blue")) + scale_colour_identity() + xlim(trunc(df$date[1], "days"), trunc(df$date[48], "days")) + facet_grid(variable ~ ., scales = "free", as.table = FALSE) + theme_bw()
> f1 <- f + geom_step(subset = .(variable =="HS"))

but I always get the following error:
Error in layout_base(data, rows, drop = drop) :
At least one layer must contain all variables used for facetting.

Is the problem due to how date has been specified? I tried both with
> df$date <- strptime(df$olddata, format = "%Y-%m-%d-%H-%M")
and
> df$date <- as.POSIXct(df$olddata, format = "%Y-%m-%d-%H-%M", tz = "")
but the result is the same.

Could somebody help me in that?

Thank you for your attention and your help
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Sun Feb  7 19:54:15 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sun, 07 Feb 2016 18:54:15 +0000
Subject: [R] five multiple plots with ggplot
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DB8A14E@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DB8A14E@ESINO.regionemarche.intra>
Message-ID: <CAKVAULP72CPhv_5-Vh0WJ9ZcD0RFDspHKcYcSSTTXaZq+24V4g@mail.gmail.com>

Hi Stefano,

you try to facet on 'variable' and 'scales' which aren't part of your
data.frame as far as I can see. The error 'At least one layer must contain
all variables used for facetting' also tells you this - that at least one
of the variables you use for facetting are missing.

Hope this helps,
Ulrik

On Sun, 7 Feb 2016 at 19:28 Stefano Sofia <stefano.sofia at regione.marche.it>
wrote:

> Dear list users,
> I would like to have multiple plots in one page with ggplot, in particular
> five graphs:
> in the central plot the snow cover (hs) of two meteorological stations;
> above wind direction and temperature of one of the two stations and below
> wind direction and temperature of the other station.
>
> My data frame (df) is like
>
> date hs1 temp1 wind1 wind_dir1 pch_wind_dir1 color_wind_dir1 hs2 temp2
> wind2 wind_dir2 pch_wind_dir2 color_wind_dir2
> 2014-12-27 00:00:00 20 -4.2 6.8 NW 5 "blue" 40 -4.2 6.8 NW 5 "blue"
> 2014-12-27 00:30:00 22 -4.3 4.3 NNE 5 "cyan" 42 -4.3 4.3 NNE 5 "cyan"
> 2014-12-27 01:00:00 24 -4.1 5.7 NNW 10 "cyan" 44 -4.1 5.7 NNW 10 "cyan"
> 2014-12-27 10:00:00 30 -2.6 7.2 NNW 10 "cyan" 44 -3.1 5.7 NNW 10 "cyan"
> ...
>
> with 48 rows.
>
> The ylim of hs1 and hs2 should be fixed between 0 and 200cm, hs1 colored
> with blue and the other with red;
> wind1 and wind2 should take the pch and color described in each row.
>
> lapply(df, class) gives
>
> $date
> [1] "POSIXct" "POSIXt"
>
> $hs1
> [1] "numeric"
>
> $temp1
> [1] "numeric"
>
> $wind1
> [1] "numeric"
>
> and so on.
>
> I have been trying for a long time to do that starting from some examples
> found in the web, with no success. The example code I started with is
>
> > ggplot(df, aes(date, hs1, ymin=0, ymax=200, colour = "blue")) +
> scale_colour_identity() + xlim(trunc(df$date[1], "days"),
> trunc(df$date[48], "days")) + facet_grid(variable ~ ., scales = "free",
> as.table = FALSE) + theme_bw()
> > f1 <- f + geom_step(subset = .(variable =="HS"))
>
> but I always get the following error:
> Error in layout_base(data, rows, drop = drop) :
> At least one layer must contain all variables used for facetting.
>
> Is the problem due to how date has been specified? I tried both with
> > df$date <- strptime(df$olddata, format = "%Y-%m-%d-%H-%M")
> and
> > df$date <- as.POSIXct(df$olddata, format = "%Y-%m-%d-%H-%M", tz = "")
> but the result is the same.
>
> Could somebody help me in that?
>
> Thank you for your attention and your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb  7 20:09:33 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 7 Feb 2016 11:09:33 -0800 (PST)
Subject: [R] five multiple plots with ggplot
In-Reply-To: <CAKVAULP72CPhv_5-Vh0WJ9ZcD0RFDspHKcYcSSTTXaZq+24V4g@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3DB8A14E@ESINO.regionemarche.intra>
	<CAKVAULP72CPhv_5-Vh0WJ9ZcD0RFDspHKcYcSSTTXaZq+24V4g@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1602071107240.55184@pedal.dcn.davis.ca.us>

Looks like the data frame needs to be reshaped before being given to 
ggplot.

"melt" function from the "reshape2" package, or "gather" function from 
"tidyr" package are good tools for this.

On Sun, 7 Feb 2016, Ulrik Stervbo wrote:

> Hi Stefano,
>
> you try to facet on 'variable' and 'scales' which aren't part of your
> data.frame as far as I can see. The error 'At least one layer must contain
> all variables used for facetting' also tells you this - that at least one
> of the variables you use for facetting are missing.
>
> Hope this helps,
> Ulrik
>
> On Sun, 7 Feb 2016 at 19:28 Stefano Sofia <stefano.sofia at regione.marche.it>
> wrote:
>
>> Dear list users,
>> I would like to have multiple plots in one page with ggplot, in particular
>> five graphs:
>> in the central plot the snow cover (hs) of two meteorological stations;
>> above wind direction and temperature of one of the two stations and below
>> wind direction and temperature of the other station.
>>
>> My data frame (df) is like
>>
>> date hs1 temp1 wind1 wind_dir1 pch_wind_dir1 color_wind_dir1 hs2 temp2
>> wind2 wind_dir2 pch_wind_dir2 color_wind_dir2
>> 2014-12-27 00:00:00 20 -4.2 6.8 NW 5 "blue" 40 -4.2 6.8 NW 5 "blue"
>> 2014-12-27 00:30:00 22 -4.3 4.3 NNE 5 "cyan" 42 -4.3 4.3 NNE 5 "cyan"
>> 2014-12-27 01:00:00 24 -4.1 5.7 NNW 10 "cyan" 44 -4.1 5.7 NNW 10 "cyan"
>> 2014-12-27 10:00:00 30 -2.6 7.2 NNW 10 "cyan" 44 -3.1 5.7 NNW 10 "cyan"
>> ...
>>
>> with 48 rows.
>>
>> The ylim of hs1 and hs2 should be fixed between 0 and 200cm, hs1 colored
>> with blue and the other with red;
>> wind1 and wind2 should take the pch and color described in each row.
>>
>> lapply(df, class) gives
>>
>> $date
>> [1] "POSIXct" "POSIXt"
>>
>> $hs1
>> [1] "numeric"
>>
>> $temp1
>> [1] "numeric"
>>
>> $wind1
>> [1] "numeric"
>>
>> and so on.
>>
>> I have been trying for a long time to do that starting from some examples
>> found in the web, with no success. The example code I started with is
>>
>> > ggplot(df, aes(date, hs1, ymin=0, ymax=200, colour = "blue")) +
>> scale_colour_identity() + xlim(trunc(df$date[1], "days"),
>> trunc(df$date[48], "days")) + facet_grid(variable ~ ., scales = "free",
>> as.table = FALSE) + theme_bw()
>> > f1 <- f + geom_step(subset = .(variable =="HS"))
>>
>> but I always get the following error:
>> Error in layout_base(data, rows, drop = drop) :
>> At least one layer must contain all variables used for facetting.
>>
>> Is the problem due to how date has been specified? I tried both with
>> > df$date <- strptime(df$olddata, format = "%Y-%m-%d-%H-%M")
>> and
>> > df$date <- as.POSIXct(df$olddata, format = "%Y-%m-%d-%H-%M", tz = "")
>> but the result is the same.
>>
>> Could somebody help me in that?
>>
>> Thank you for your attention and your help
>> Stefano
>>
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
>> alla ricezione. I messaggi di posta elettronica per i client di Regione
>> Marche possono contenere informazioni confidenziali e con privilegi legali.
>> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
>> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
>> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
>> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
>> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
>> elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only by
>> persons entitled to receive the confidential information it may contain.
>> E-mail messages to clients of Regione Marche may contain information that
>> is confidential and legally privileged. Please do not read, copy, forward,
>> or store this message unless you are an intended recipient of it. If you
>> have received this message in error, please forward it to the sender and
>> delete it completely from your computer system.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From drjimlemon at gmail.com  Sun Feb  7 22:19:49 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 8 Feb 2016 08:19:49 +1100
Subject: [R] [FORGED] Plot step function
In-Reply-To: <CAA=hcWQX9or8TSyRVnCvBwPErqksMC2hm7Uatua6xh2bHKVcBA@mail.gmail.com>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<56B63B93.3030303@auckland.ac.nz>
	<CAA=hcWQX9or8TSyRVnCvBwPErqksMC2hm7Uatua6xh2bHKVcBA@mail.gmail.com>
Message-ID: <CA+8X3fXjsUDxjBMa4Zig63wzMdDcmS=+wjSNboZ+tNZiFuxUfw@mail.gmail.com>

Hail Jupiter,
Might a slight alteration of Rolf's suggestion do the trick?

 plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y")

Jim

On Sun, Feb 7, 2016 at 8:49 AM, jupiter <jupiter.hce at gmail.com> wrote:

> Thank you for the all response, how can the point y (0.0) on the same x
> axis, and X increases 1 between [-4, 4]?
>
> On Sun, Feb 7, 2016 at 5:29 AM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
> > On 07/02/16 01:11, jupiter wrote:
> >
> >> Hi,
> >>
> >> I am just starting to learn R, sorry for asking a simple question. How
> can
> >> plot a line x <= 0 y = 0, x > 0 y = 1?
> >>
> >
> > One way:
> >
> >     plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Sun Feb  7 22:24:23 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 7 Feb 2016 15:24:23 -0600
Subject: [R] Combining a character array into a character string
Message-ID: <CACxE24nYvJHub-RbXcY4FZA5WLbZyyQemEBtkGpJG=j0DdpXYA@mail.gmail.com>

Hello everyone!

I'm sure this is very simple and that I'm just having "forest and trees"
syndrome.

I have the following character array:

> xxy
[1] "A" "G" "C" "G" "T"

I want to end up with
"AGCGT:"

I've tried paste, paste0, gsub, no good.

Any suggestions much appreciated.

Thanks and have a great day!

Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Sun Feb  7 22:35:05 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 7 Feb 2016 15:35:05 -0600
Subject: [R] Combining a character array into a character string
In-Reply-To: <CACxE24nYvJHub-RbXcY4FZA5WLbZyyQemEBtkGpJG=j0DdpXYA@mail.gmail.com>
References: <CACxE24nYvJHub-RbXcY4FZA5WLbZyyQemEBtkGpJG=j0DdpXYA@mail.gmail.com>
Message-ID: <CACxE24mSsRCnVo=uYWOs-kxZc=VbBZVTpaJcaingBaSyOcvLgw@mail.gmail.com>

Back again.

I ran the paste with collapse and it worked this time.

Spooky.

Sorry for the trouble.
Erin


On Sun, Feb 7, 2016 at 3:24 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello everyone!
>
> I'm sure this is very simple and that I'm just having "forest and trees"
> syndrome.
>
> I have the following character array:
>
> > xxy
> [1] "A" "G" "C" "G" "T"
>
> I want to end up with
> "AGCGT:"
>
> I've tried paste, paste0, gsub, no good.
>
> Any suggestions much appreciated.
>
> Thanks and have a great day!
>
> Sincerely,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From niessen at att.net  Sun Feb  7 21:18:49 2016
From: niessen at att.net (Walter Niessen)
Date: Sun, 7 Feb 2016 15:18:49 -0500
Subject: [R] (no subject)
Message-ID: <8FF6B96690FC46EF98B5897AEECCB54B@NiessenPC>

Helpers,

I am a pretty savvy computer user (over 40 years) but am having trouble with the most basic process in using the R program.  I am taking a course to learn the statistics utility of ?R? but can?t seem to get past the opening where it shows the student how to input data into R.

It suggests identifying as the a target folder in the Properties of the R x64 3.2.3 icon (I use a 64-bit Windows 7 OS) the location where data files are found. I entered: 

As the Target:  "C:\Program Files\R\R-3.2.3\bin\x64\Rgui.exe"  ... which contains Rgui.exe and the supporting dlls etc.

As the Start in: "C:\Program Files\R\R-3.2.3\Appendix" ... where Appendix is a folder which contains data files such as the text file DATA1.txt which I created from an Excel file.

When I try and get R to input the data, I get the following sequence of messages:


> X=scan("DATA1.txt")
Error in file(file, "r") : cannot open the connection
In addition: Warning message:
In file(file, "r") :
  cannot open file 'DATA1.txt': No such file or directory

When I try again but use the complete file description, I get:

X=scan("C:\Program Files\R\R-3.2.3\Appendix\DATA1.txt")
Error: '\P' is an unrecognized escape in character string starting ""C:\P"

I hate to ask a question not related to R or its features (that may come later), but, clearly, the first baby step is to be able to load data into the application . . . and, I am really frustrated with my inability to do so.  

Can you help?

Walt

Walter R. Niessen
(978) 470-4622



	[[alternative HTML version deleted]]


From niessen at att.net  Sun Feb  7 21:23:49 2016
From: niessen at att.net (Walter Niessen)
Date: Sun, 7 Feb 2016 15:23:49 -0500
Subject: [R] Basic Problem with Data Input
Message-ID: <A109253094D94CFB86A05D5AE3D6228D@NiessenPC>

Helpers,

I am a pretty savvy computer user (over 40 years) but am having trouble with the most basic process in using the R program.  I am taking a course to learn the statistics utility of ?R? but can?t seem to get past the opening where it shows the student how to input data into R.

It suggests identifying as the a target folder in the Properties of the R x64 3.2.3 icon (I use a 64-bit Windows 7 OS) the location where data files are found. I entered: 

As the Target:  "C:\Program Files\R\R-3.2.3\bin\x64\Rgui.exe"  ... which contains Rgui.exe and the supporting dlls etc.

As the Start in: "C:\Program Files\R\R-3.2.3\Appendix" ... where Appendix is a folder which contains data files such as the text file DATA1.txt which I created from an Excel file.

When I try and get R to input the data, I get the following sequence of messages:


> X=scan("DATA1.txt")
Error in file(file, "r") : cannot open the connection
In addition: Warning message:
In file(file, "r") :
  cannot open file 'DATA1.txt': No such file or directory

When I try again but use the complete file description, I get:

X=scan("C:\Program Files\R\R-3.2.3\Appendix\DATA1.txt")
Error: '\P' is an unrecognized escape in character string starting ""C:\P"

I hate to ask a question not related to R or its features (that may come later), but, clearly, the first baby step is to be able to load data into the application . . . and, I am really frustrated with my inability to do so.  I apologize for this but really need to get past this business to jump into the REAL use of R.

Can you help?

Walt

Walter R. Niessen
(978) 470-4622

P.S. I apologize, but I sent the first ?edition? a few minutes ago without a Subject and not quite finished up.



	[[alternative HTML version deleted]]


From jupiter.hce at gmail.com  Sun Feb  7 23:54:48 2016
From: jupiter.hce at gmail.com (jupiter)
Date: Mon, 8 Feb 2016 09:54:48 +1100
Subject: [R] [FORGED] Plot step function
In-Reply-To: <CA+8X3fXjsUDxjBMa4Zig63wzMdDcmS=+wjSNboZ+tNZiFuxUfw@mail.gmail.com>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<56B63B93.3030303@auckland.ac.nz>
	<CAA=hcWQX9or8TSyRVnCvBwPErqksMC2hm7Uatua6xh2bHKVcBA@mail.gmail.com>
	<CA+8X3fXjsUDxjBMa4Zig63wzMdDcmS=+wjSNboZ+tNZiFuxUfw@mail.gmail.com>
Message-ID: <CAA=hcWR3aPfBrFMR1EedXv4+WBGUqqqmrr9stuoLHo2K5uY5vQ@mail.gmail.com>

Thanks Jim, that was I did to generate graphic from
plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y"), it displayed [-4, -2,
0, 2, 4] in X, I tried to twist it, but could not get [-4, -3, -2, -1, 0,
1, 2, 3, 4] in X. Also, that the y 0.0 is above the X axis.

I guess I try to figure out if, in general, there are parameters to define
?x (i.e ?x= 1), and to define [0, 0.0] at the joint of x axis and y axis.
But never mind, if it is too much to ask :-).

Thank you and greatly appreciate kind responses.

- j



On Mon, Feb 8, 2016 at 8:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hail Jupiter,
> Might a slight alteration of Rolf's suggestion do the trick?
>
>  plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y")
>
> Jim
>
> On Sun, Feb 7, 2016 at 8:49 AM, jupiter <jupiter.hce at gmail.com> wrote:
>
>> Thank you for the all response, how can the point y (0.0) on the same x
>> axis, and X increases 1 between [-4, 4]?
>>
>> On Sun, Feb 7, 2016 at 5:29 AM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>
>> > On 07/02/16 01:11, jupiter wrote:
>> >
>> >> Hi,
>> >>
>> >> I am just starting to learn R, sorry for asking a simple question. How
>> can
>> >> plot a line x <= 0 y = 0, x > 0 y = 1?
>> >>
>> >
>> > One way:
>> >
>> >     plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>> > --
>> > Technical Editor ANZJS
>> > Department of Statistics
>> > University of Auckland
>> > Phone: +64-9-373-7599 ext. 88276
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sun Feb  7 23:58:44 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 7 Feb 2016 17:58:44 -0500
Subject: [R] Basic Problem with Data Input
In-Reply-To: <A109253094D94CFB86A05D5AE3D6228D@NiessenPC>
References: <A109253094D94CFB86A05D5AE3D6228D@NiessenPC>
Message-ID: <CAM_vjum0MSfJ491kX4ej6N_f_V2nJhKcT-oDCUUAikki-sTjow@mail.gmail.com>

Hi Walter,

I'm not sure changing the shortcut properties are the best approach.
Instead, after you start R, you can use the
getwd()
command to see where R will start looking for things, and the
setwd()
command to change that (wd is working directory).

Because of the way R parses strings, you either need to use double
backslashes or single forward slashes if you want to specify a full
path:
X <- scan("C:\\Program Files\\R\\R-3.2.3\\Appendix\\DATA1.txt")
X <- scan("C:/Program Files/R/R-3.2.3/Appendix/DATA1.txt")
will both work.

Here's a basic overview of the relevant material:
http://www.dummies.com/how-to/content/how-to-work-with-files-and-folders-in-r.html

It's perhaps not the most logical place to look, but it's also in the
R Windows FAQ as number 2.16:
https://cran.r-project.org/bin/windows/base/rw-FAQ.html

Sarah

On Sun, Feb 7, 2016 at 3:23 PM, Walter Niessen <niessen at att.net> wrote:
> Helpers,
>
> I am a pretty savvy computer user (over 40 years) but am having trouble with the most basic process in using the R program.  I am taking a course to learn the statistics utility of ?R? but can?t seem to get past the opening where it shows the student how to input data into R.
>
> It suggests identifying as the a target folder in the Properties of the R x64 3.2.3 icon (I use a 64-bit Windows 7 OS) the location where data files are found. I entered:
>
> As the Target:  "C:\Program Files\R\R-3.2.3\bin\x64\Rgui.exe"  ... which contains Rgui.exe and the supporting dlls etc.
>
> As the Start in: "C:\Program Files\R\R-3.2.3\Appendix" ... where Appendix is a folder which contains data files such as the text file DATA1.txt which I created from an Excel file.
>
> When I try and get R to input the data, I get the following sequence of messages:
>
>
>> X=scan("DATA1.txt")
> Error in file(file, "r") : cannot open the connection
> In addition: Warning message:
> In file(file, "r") :
>   cannot open file 'DATA1.txt': No such file or directory
>
> When I try again but use the complete file description, I get:
>
> X=scan("C:\Program Files\R\R-3.2.3\Appendix\DATA1.txt")
> Error: '\P' is an unrecognized escape in character string starting ""C:\P"
>
> I hate to ask a question not related to R or its features (that may come later), but, clearly, the first baby step is to be able to load data into the application . . . and, I am really frustrated with my inability to do so.  I apologize for this but really need to get past this business to jump into the REAL use of R.
>
> Can you help?
>
> Walt
>
> Walter R. Niessen
> (978) 470-4622
>
> P.S. I apologize, but I sent the first ?edition? a few minutes ago without a Subject and not quite finished up.
>
>
-- 
Sarah Goslee
http://www.numberwright.com


From btupper at bigelow.org  Mon Feb  8 00:06:34 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 7 Feb 2016 18:06:34 -0500
Subject: [R] Basic Problem with Data Input
In-Reply-To: <A109253094D94CFB86A05D5AE3D6228D@NiessenPC>
References: <A109253094D94CFB86A05D5AE3D6228D@NiessenPC>
Message-ID: <219B4ED0-82CD-4A21-83F0-4BEB6E111A82@bigelow.org>

Hi,

Using the full path specification, as you have done in your second example, is a good idea.   Have you tried forward slashes?  If I am reading the docs correctly you should be able to use either forward or back slashes.  I haven't used R in Windows for ages, but my memory is that switching to forward slashes skirted any troublesome issues.  Try this...

filename <- "C:/Program Files/R/R-3.2.3/Appendix/DATA1.txt"
if (file.exists(filename)){
	X <- scan(file = filename, what = double())
} else {
	cat('file not found\n')
}

Here's the doc page...

https://cran.r-project.org/doc/manuals/r-release/R-intro.html#OS-facilities

Ben

> On Feb 7, 2016, at 3:23 PM, Walter Niessen <niessen at att.net> wrote:
> 
> Helpers,
> 
> I am a pretty savvy computer user (over 40 years) but am having trouble with the most basic process in using the R program.  I am taking a course to learn the statistics utility of ?R? but can?t seem to get past the opening where it shows the student how to input data into R.
> 
> It suggests identifying as the a target folder in the Properties of the R x64 3.2.3 icon (I use a 64-bit Windows 7 OS) the location where data files are found. I entered: 
> 
> As the Target:  "C:\Program Files\R\R-3.2.3\bin\x64\Rgui.exe"  ... which contains Rgui.exe and the supporting dlls etc.
> 
> As the Start in: "C:\Program Files\R\R-3.2.3\Appendix" ... where Appendix is a folder which contains data files such as the text file DATA1.txt which I created from an Excel file.
> 
> When I try and get R to input the data, I get the following sequence of messages:
> 
> 
>> X=scan("DATA1.txt")
> Error in file(file, "r") : cannot open the connection
> In addition: Warning message:
> In file(file, "r") :
>  cannot open file 'DATA1.txt': No such file or directory
> 
> When I try again but use the complete file description, I get:
> 
> X=scan("C:\Program Files\R\R-3.2.3\Appendix\DATA1.txt")
> Error: '\P' is an unrecognized escape in character string starting ""C:\P"
> 
> I hate to ask a question not related to R or its features (that may come later), but, clearly, the first baby step is to be able to load data into the application . . . and, I am really frustrated with my inability to do so.  I apologize for this but really need to get past this business to jump into the REAL use of R.
> 
> Can you help?
> 
> Walt
> 
> Walter R. Niessen
> (978) 470-4622
> 
> P.S. I apologize, but I sent the first ?edition? a few minutes ago without a Subject and not quite finished up.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From rsherry8 at comcast.net  Mon Feb  8 00:12:32 2016
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sun, 7 Feb 2016 18:12:32 -0500
Subject: [R] Variable Argument Function
Message-ID: <56B7CF60.30209@comcast.net>


I would like to write a function in R that would take a variable number 
of integers as parameters. I do not have a pressing reason to do this, I 
am just trying to learn R. I thought a good first step would be to print 
out the arguments. So I wrote the following function:

f1 = function (...)
{
     list1 = as.list(...)
     for( i in 1:length(list1) )
         cat( "i is ", list1[[i]], "\n" )
     return (0)
}

I ran it as:
     f1(2,4,10,12)
and I get:
     i is  2
     [1] 0
I was hoping for
     i is  2
     i is  4
     i is  10
     i is  12

I am hoping somebody can tell me what I am doing wrong. Is using a list 
a bad idea?

Thanks
Bob


From murdoch.duncan at gmail.com  Mon Feb  8 00:20:46 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 7 Feb 2016 18:20:46 -0500
Subject: [R] Setting directory in Windows
In-Reply-To: <8FF6B96690FC46EF98B5897AEECCB54B@NiessenPC>
References: <8FF6B96690FC46EF98B5897AEECCB54B@NiessenPC>
Message-ID: <56B7D14E.7060602@gmail.com>

I added an informative subject line; that's a good idea in this list so 
people can choose whether to read your question or not.

On 07/02/2016 3:18 PM, Walter Niessen wrote:
> Helpers,
>
> I am a pretty savvy computer user (over 40 years) but am having trouble with the most basic process in using the R program.  I am taking a course to learn the statistics utility of ?R? but can?t seem to get past the opening where it shows the student how to input data into R.
>
> It suggests identifying as the a target folder in the Properties of the R x64 3.2.3 icon (I use a 64-bit Windows 7 OS) the location where data files are found. I entered:
>
> As the Target:  "C:\Program Files\R\R-3.2.3\bin\x64\Rgui.exe"  ... which contains Rgui.exe and the supporting dlls etc.
>
> As the Start in: "C:\Program Files\R\R-3.2.3\Appendix" ... where Appendix is a folder which contains data files such as the text file DATA1.txt which I created from an Excel file.
>
> When I try and get R to input the data, I get the following sequence of messages:
>
>
>> X=scan("DATA1.txt")
> Error in file(file, "r") : cannot open the connection
> In addition: Warning message:
> In file(file, "r") :
>    cannot open file 'DATA1.txt': No such file or directory
>
> When I try again but use the complete file description, I get:
>
> X=scan("C:\Program Files\R\R-3.2.3\Appendix\DATA1.txt")
> Error: '\P' is an unrecognized escape in character string starting ""C:\P"
>
> I hate to ask a question not related to R or its features (that may come later), but, clearly, the first baby step is to be able to load data into the application . . . and, I am really frustrated with my inability to do so.

There are a few things you should know.

1.  R uses the \ character as an escape, so \t is a tab, etc.  If you 
really want a \ in a string, you need to escape it, i.e. enter \\.  This 
is a pain, so you can instead use / in place of \\ when specifying file 
paths.

2.  I think your course is giving bad advice.  Don't mess with the 
shortcut.  Use RStudio as your front end.  It allows you to set up 
"projects"; it remembers the current directory for each project, so you 
just "Open project" X, and R will be started in the directory of X.

3.  If you don't want to use RStudio, then run choose.dir() in R at the 
start of your session.  It lets you set the current directory to the one 
with your files in it, using a old-fashioned Windows dialog box.  If 
things stop working the way you expect, run getwd() to get R to print 
what's the current directory.

4.  You can also use file.choose() to use Windows dialogs to pick a 
file; then it doesn't really matter what the current directory is.

I hope some of this helps.

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Feb  8 00:24:15 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 7 Feb 2016 18:24:15 -0500
Subject: [R] Variable Argument Function
In-Reply-To: <56B7CF60.30209@comcast.net>
References: <56B7CF60.30209@comcast.net>
Message-ID: <56B7D21F.5080002@gmail.com>

On 07/02/2016 6:12 PM, Robert Sherry wrote:
>
> I would like to write a function in R that would take a variable number
> of integers as parameters. I do not have a pressing reason to do this, I
> am just trying to learn R. I thought a good first step would be to print
> out the arguments. So I wrote the following function:
>
> f1 = function (...)
> {
>       list1 = as.list(...)

This is wrong.  The ... object is weird; it's not something that can be 
coerced to a list.  However, you can pass it as list(...) and it will 
give you what you were expecting.

The theory is that it will expand to multiple arguments to the list() 
function, which constructs a list containing them.  as.list() doesn't 
want a bunch of arguments, it will just ignore most of them.

Duncan Murdoch

>       for( i in 1:length(list1) )
>           cat( "i is ", list1[[i]], "\n" )
>       return (0)
> }
>
> I ran it as:
>       f1(2,4,10,12)
> and I get:
>       i is  2
>       [1] 0
> I was hoping for
>       i is  2
>       i is  4
>       i is  10
>       i is  12
>
> I am hoping somebody can tell me what I am doing wrong. Is using a list
> a bad idea?
>
> Thanks
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From btupper at bigelow.org  Mon Feb  8 01:14:38 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 7 Feb 2016 19:14:38 -0500
Subject: [R] Variable Argument Function
In-Reply-To: <56B7D21F.5080002@gmail.com>
References: <56B7CF60.30209@comcast.net> <56B7D21F.5080002@gmail.com>
Message-ID: <611FD73E-605E-4BC3-93D1-DF4065F6984D@bigelow.org>

Hi,

> On Feb 7, 2016, at 6:24 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 07/02/2016 6:12 PM, Robert Sherry wrote:
>> 
>> I would like to write a function in R that would take a variable number
>> of integers as parameters. I do not have a pressing reason to do this, I
>> am just trying to learn R. I thought a good first step would be to print
>> out the arguments. So I wrote the following function:
>> 
>> f1 = function (...)
>> {
>>      list1 = as.list(...)
> 
> This is wrong.  The ... object is weird; it's not something that can be coerced to a list.  However, you can pass it as list(...) and it will give you what you were expecting.
> 

Do you mean that Bob should nest a function within f1?  Like this?

f1 = function (...){
   f2 <- function(list1){
      for( i in 1:length(list1) ) cat( "i is ", list1[[i]], "\n" )
      return (0)
    }
    f2(list(...))
}

f1(2,4,10,12)

> f1(2,4,10,12)
i is  2 
i is  4 
i is  10 
i is  12 

Ben


> The theory is that it will expand to multiple arguments to the list() function, which constructs a list containing them.  as.list() doesn't want a bunch of arguments, it will just ignore most of them.
> 
> Duncan Murdoch
> 
>>      for( i in 1:length(list1) )
>>          cat( "i is ", list1[[i]], "\n" )
>>      return (0)
>> }
>> 
>> I ran it as:
>>      f1(2,4,10,12)
>> and I get:
>>      i is  2
>>      [1] 0
>> I was hoping for
>>      i is  2
>>      i is  4
>>      i is  10
>>      i is  12
>> 
>> I am hoping somebody can tell me what I am doing wrong. Is using a list
>> a bad idea?
>> 
>> Thanks
>> Bob
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From rsherry8 at comcast.net  Mon Feb  8 01:37:11 2016
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sun, 7 Feb 2016 19:37:11 -0500
Subject: [R] Variable Argument Function
In-Reply-To: <611FD73E-605E-4BC3-93D1-DF4065F6984D@bigelow.org>
References: <56B7CF60.30209@comcast.net> <56B7D21F.5080002@gmail.com>
	<611FD73E-605E-4BC3-93D1-DF4065F6984D@bigelow.org>
Message-ID: <56B7E337.7040001@comcast.net>

Ben,

Your solution solved my issue. Thank you. I do not see a need for a 
nested function. Based upon your solution, I came up with
this solution:

fbob = function (...)
{
     l1 = list(...)
     for( i in 1:length(l1) )
         cat( "i is ", l1[[i]], "\n" )
     return (0);
}

It does not use nested functions and it works also. Is there a reason 
why your solution is better?

Bob

On 2/7/2016 7:14 PM, Ben Tupper wrote:
> Hi,
>
>> On Feb 7, 2016, at 6:24 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 07/02/2016 6:12 PM, Robert Sherry wrote:
>>> I would like to write a function in R that would take a variable number
>>> of integers as parameters. I do not have a pressing reason to do this, I
>>> am just trying to learn R. I thought a good first step would be to print
>>> out the arguments. So I wrote the following function:
>>>
>>> f1 = function (...)
>>> {
>>>       list1 = as.list(...)
>> This is wrong.  The ... object is weird; it's not something that can be coerced to a list.  However, you can pass it as list(...) and it will give you what you were expecting.
>>
> Do you mean that Bob should nest a function within f1?  Like this?
>
> f1 = function (...){
>     f2 <- function(list1){
>        for( i in 1:length(list1) ) cat( "i is ", list1[[i]], "\n" )
>        return (0)
>      }
>      f2(list(...))
> }
>
> f1(2,4,10,12)
>
>> f1(2,4,10,12)
> i is  2
> i is  4
> i is  10
> i is  12
>
> Ben
>
>
>> The theory is that it will expand to multiple arguments to the list() function, which constructs a list containing them.  as.list() doesn't want a bunch of arguments, it will just ignore most of them.
>>
>> Duncan Murdoch
>>
>>>       for( i in 1:length(list1) )
>>>           cat( "i is ", list1[[i]], "\n" )
>>>       return (0)
>>> }
>>>
>>> I ran it as:
>>>       f1(2,4,10,12)
>>> and I get:
>>>       i is  2
>>>       [1] 0
>>> I was hoping for
>>>       i is  2
>>>       i is  4
>>>       i is  10
>>>       i is  12
>>>
>>> I am hoping somebody can tell me what I am doing wrong. Is using a list
>>> a bad idea?
>>>
>>> Thanks
>>> Bob
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Feb  8 01:36:55 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 7 Feb 2016 19:36:55 -0500
Subject: [R] Variable Argument Function
In-Reply-To: <611FD73E-605E-4BC3-93D1-DF4065F6984D@bigelow.org>
References: <56B7CF60.30209@comcast.net> <56B7D21F.5080002@gmail.com>
	<611FD73E-605E-4BC3-93D1-DF4065F6984D@bigelow.org>
Message-ID: <56B7E327.6040104@gmail.com>

On 07/02/2016 7:14 PM, Ben Tupper wrote:
> Hi,
>
>> On Feb 7, 2016, at 6:24 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 07/02/2016 6:12 PM, Robert Sherry wrote:
>>>
>>> I would like to write a function in R that would take a variable number
>>> of integers as parameters. I do not have a pressing reason to do this, I
>>> am just trying to learn R. I thought a good first step would be to print
>>> out the arguments. So I wrote the following function:
>>>
>>> f1 = function (...)
>>> {
>>>       list1 = as.list(...)
>>
>> This is wrong.  The ... object is weird; it's not something that can be coerced to a list.  However, you can pass it as list(...) and it will give you what you were expecting.
>>
>
> Do you mean that Bob should nest a function within f1?  Like this?

No need for that.  His original function would work if he had used 
list(...) instead of as.list(...).

Duncan Murdoch

>
> f1 = function (...){
>     f2 <- function(list1){
>        for( i in 1:length(list1) ) cat( "i is ", list1[[i]], "\n" )
>        return (0)
>      }
>      f2(list(...))
> }
>
> f1(2,4,10,12)
>
>> f1(2,4,10,12)
> i is  2
> i is  4
> i is  10
> i is  12
>
> Ben
>
>
>> The theory is that it will expand to multiple arguments to the list() function, which constructs a list containing them.  as.list() doesn't want a bunch of arguments, it will just ignore most of them.
>>
>> Duncan Murdoch
>>
>>>       for( i in 1:length(list1) )
>>>           cat( "i is ", list1[[i]], "\n" )
>>>       return (0)
>>> }
>>>
>>> I ran it as:
>>>       f1(2,4,10,12)
>>> and I get:
>>>       i is  2
>>>       [1] 0
>>> I was hoping for
>>>       i is  2
>>>       i is  4
>>>       i is  10
>>>       i is  12
>>>
>>> I am hoping somebody can tell me what I am doing wrong. Is using a list
>>> a bad idea?
>>>
>>> Thanks
>>> Bob
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Mon Feb  8 01:55:58 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 8 Feb 2016 11:55:58 +1100
Subject: [R] (no subject)
In-Reply-To: <8FF6B96690FC46EF98B5897AEECCB54B@NiessenPC>
References: <8FF6B96690FC46EF98B5897AEECCB54B@NiessenPC>
Message-ID: <CA+8X3fUZWA0mjjytDkA1TLUh4RJEJZmHpBOxPPu=MqcKHW063g@mail.gmail.com>

Hi Walter,
To make sure that the current R working directory is what you think it is:

getwd()

If it is not what you want, you can change it with:

setwd("C:/Program Files/R/R-3.2.3/Appendix")

Notice that I have changed the backslashes (\) to slashes (/). You can also
use doubled backslashes if you prefer. Same for loading a file with an
explicit path in another directory.

Jim

On Mon, Feb 8, 2016 at 7:18 AM, Walter Niessen <niessen at att.net> wrote:

> Helpers,
>
> I am a pretty savvy computer user (over 40 years) but am having trouble
> with the most basic process in using the R program.  I am taking a course
> to learn the statistics utility of ?R? but can?t seem to get past the
> opening where it shows the student how to input data into R.
>
> It suggests identifying as the a target folder in the Properties of the R
> x64 3.2.3 icon (I use a 64-bit Windows 7 OS) the location where data files
> are found. I entered:
>
> As the Target:  "C:\Program Files\R\R-3.2.3\bin\x64\Rgui.exe"  ... which
> contains Rgui.exe and the supporting dlls etc.
>
> As the Start in: "C:\Program Files\R\R-3.2.3\Appendix" ... where Appendix
> is a folder which contains data files such as the text file DATA1.txt which
> I created from an Excel file.
>
> When I try and get R to input the data, I get the following sequence of
> messages:
>
>
> > X=scan("DATA1.txt")
> Error in file(file, "r") : cannot open the connection
> In addition: Warning message:
> In file(file, "r") :
>   cannot open file 'DATA1.txt': No such file or directory
>
> When I try again but use the complete file description, I get:
>
> X=scan("C:\Program Files\R\R-3.2.3\Appendix\DATA1.txt")
> Error: '\P' is an unrecognized escape in character string starting ""C:\P"
>
> I hate to ask a question not related to R or its features (that may come
> later), but, clearly, the first baby step is to be able to load data into
> the application . . . and, I am really frustrated with my inability to do
> so.
>
> Can you help?
>
> Walt
>
> Walter R. Niessen
> (978) 470-4622
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From catalinroibu at gmail.com  Mon Feb  8 11:09:01 2016
From: catalinroibu at gmail.com (catalin roibu)
Date: Mon, 8 Feb 2016 12:09:01 +0200
Subject: [R] middle of interval
Message-ID: <CAEW+BD+EHUcJefQ=O66KXciM4s_eJ5pPqgxg_3iZ=aU_O2zo0g@mail.gmail.com>

Dear R users!

I have a data frame with first column is an interval (1902-1931) and I want
to find the middle of the interval? Is there a possibility to do that in R?

Thank you very much!

Best regards!

-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Feb  8 11:17:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 8 Feb 2016 05:17:06 -0500
Subject: [R] middle of interval
In-Reply-To: <CAEW+BD+EHUcJefQ=O66KXciM4s_eJ5pPqgxg_3iZ=aU_O2zo0g@mail.gmail.com>
References: <CAEW+BD+EHUcJefQ=O66KXciM4s_eJ5pPqgxg_3iZ=aU_O2zo0g@mail.gmail.com>
Message-ID: <56B86B22.5020403@gmail.com>

On 08/02/2016 5:09 AM, catalin roibu wrote:
> Dear R users!
>
> I have a data frame with first column is an interval (1902-1931) and I want
> to find the middle of the interval? Is there a possibility to do that in R?
>
> Thank you very much!
>
> Best regards!
>

I don't know of a single function that does that, but the way to do it 
would be to separate the interval into two numbers, then take the 
average.  If your intervals are strings in the form shown above (not 
including the parentheses), this would work:

interval <- "1902-1931"
start <- as.numeric(sub("-.*", "", interval))
stop  <- as.numeric(sub(".*-", "", interval))
(start + stop)/2

Duncan Murdoch


From petr.pikal at precheza.cz  Mon Feb  8 11:44:52 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Feb 2016 10:44:52 +0000
Subject: [R] middle of interval
In-Reply-To: <CAEW+BD+EHUcJefQ=O66KXciM4s_eJ5pPqgxg_3iZ=aU_O2zo0g@mail.gmail.com>
References: <CAEW+BD+EHUcJefQ=O66KXciM4s_eJ5pPqgxg_3iZ=aU_O2zo0g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500D2D2@SRVEXCHMBX.precheza.cz>

Hi

you have got one answer, here is another

interval <- c("1902-1931", "1912-1930", "1902-1951")

(as.numeric(substr(interval, 1,4))+as.numeric(substr(interval, nchar(interval)-3, nchar(interval))))/2
[1] 1916.5 1921.0 1926.5

It works only if positions of years in intervals is first and last 4 characters.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of catalin
> roibu
> Sent: Monday, February 08, 2016 11:09 AM
> To: r-help at r-project.org
> Subject: [R] middle of interval
>
> Dear R users!
>
> I have a data frame with first column is an interval (1902-1931) and I
> want to find the middle of the interval? Is there a possibility to do
> that in R?
>
> Thank you very much!
>
> Best regards!
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From yuhuilin at live.cn  Mon Feb  8 14:11:16 2016
From: yuhuilin at live.cn (=?utf-8?B?5LqO5oWn55Cz?=)
Date: Mon, 8 Feb 2016 13:11:16 +0000
Subject: [R] =?utf-8?q?Help_for_survival_curves_for_the_survfit_object?=
 =?utf-8?b?4oCP?=
Message-ID: <BAY167-W357EB505F7AE4A291C8503DCD50@phx.gbl>

Hi guy,I have some problems when plotting survival curves for the survfit object.My survfit model is as follows:fit6<-survfit(Surv(Survival_time_year_,event)~Race_1_Desc,data=data6)Race_1_Desc is a indicator variable which has 0 and 1 values.However, in my dataset, all of the Race_1_Desc are of value 0, which means I have only 1 group.When I plot my survival curve use the following command,plot(fit6,col=c("blue","red"),xlab="Survival Time",ylab="Survival Probability",main="Survival Plot for Leaf 6")  It is correct that I only has one curve for Race_1_Desc coded as 0, which is the blue full line. But there are also two dashed line, one is red and one is blue.I just want to know what are the two dashed lines mean and why the show up in the plot.
 		 	   		  
	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Mon Feb  8 09:16:42 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Mon, 8 Feb 2016 08:16:42 +0000
Subject: [R] readline is not working
Message-ID: <f97ef51205ac42989b51487fb4d26f6c@NOEINTPEXMU007.NEOPROD.EDF.FR>

HI,
I am new to R and English is not my natural language.

I work on 4 laptops that are supposed to be the same. Win7-64. R version 3.1.0. I can use readline to enter a value from keyboard on three of them but not on the fourth : R doesn't stop on the readline instruction and acts as if the response was 'enter' and I think that the cursor 'disappears' .

What can I look for ? environment variable, GUI preferences, ... ?

Thanks in advance for your answers ...
Jean in France
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From waser at frankenfoerder-fg.de  Mon Feb  8 14:33:21 2016
From: waser at frankenfoerder-fg.de (Wolfgang Waser)
Date: Mon, 8 Feb 2016 14:33:21 +0100
Subject: [R] How to extract same columns from identical dataframes in a list?
Message-ID: <56B89921.4040405@frankenfoerder-fg.de>

Hello,

I have a list of 7 data frames, each data frame having 24 rows (hour of
the day) and 5 columns (weeks) with a total of 5 x 24 values

I would like to combine all 7 columns of week 1 (and 2 ...) in a
separate data frame for hourly calculations, e.g.
> apply(new.data.frame,1,mean)

In some way sapply (lapply) works, but I cannot directly select columns
of the original data frames in the list. As a workaround I have to
select a range of values:

> sapply(list_of_dataframes,"[",1:24)

Values 1:24 give the first column, 25:48 the second and so on.

Is there an easier / more direct way to select for specific columns
instead of selecting a range of values, avoiding loops?


Cheers,

Wolfgang


From dcarlson at tamu.edu  Mon Feb  8 16:12:21 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 8 Feb 2016 15:12:21 +0000
Subject: [R] middle of interval
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500D2D2@SRVEXCHMBX.precheza.cz>
References: <CAEW+BD+EHUcJefQ=O66KXciM4s_eJ5pPqgxg_3iZ=aU_O2zo0g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500D2D2@SRVEXCHMBX.precheza.cz>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70911C@mb02.ads.tamu.edu>

Here is another approach:

> interval <- c("1902-1931", "1912-1930", "1902-1951")
> sapply(strsplit(interval, "-"), function(x) mean(as.numeric(x)))
[1] 1916.5 1921.0 1926.5

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Monday, February 8, 2016 4:45 AM
To: catalin roibu; r-help at r-project.org
Subject: Re: [R] middle of interval

Hi

you have got one answer, here is another

interval <- c("1902-1931", "1912-1930", "1902-1951")

(as.numeric(substr(interval, 1,4))+as.numeric(substr(interval, nchar(interval)-3, nchar(interval))))/2
[1] 1916.5 1921.0 1926.5

It works only if positions of years in intervals is first and last 4 characters.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of catalin
> roibu
> Sent: Monday, February 08, 2016 11:09 AM
> To: r-help at r-project.org
> Subject: [R] middle of interval
>
> Dear R users!
>
> I have a data frame with first column is an interval (1902-1931) and I
> want to find the middle of the interval? Is there a possibility to do
> that in R?
>
> Thank you very much!
>
> Best regards!
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From goran.brostrom at umu.se  Mon Feb  8 16:18:39 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Mon, 8 Feb 2016 16:18:39 +0100
Subject: [R] =?utf-8?q?Help_for_survival_curves_for_the_survfit_object?=
 =?utf-8?b?4oCP?=
In-Reply-To: <BAY167-W357EB505F7AE4A291C8503DCD50@phx.gbl>
References: <BAY167-W357EB505F7AE4A291C8503DCD50@phx.gbl>
Message-ID: <56B8B1CF.8090103@umu.se>



On 2016-02-08 14:11, ??? wrote:
> Hi guy,I have some problems when plotting survival curves for the
> survfit object.My survfit model is as
> follows:fit6<-survfit(Surv(Survival_time_year_,event)~Race_1_Desc,data=data6)Race_1_Desc
> is a indicator variable which has 0 and 1 values.However, in my
> dataset, all of the Race_1_Desc are of value 0, which means I have
> only 1 group.When I plot my survival curve use the following
> command,plot(fit6,col=c("blue","red"),xlab="Survival
> Time",ylab="Survival Probability",main="Survival Plot for Leaf 6")
> It is correct that I only has one curve for Race_1_Desc coded as 0,
> which is the blue full line. But there are also two dashed line, one
> is red and one is blue.I just want to know what are the two dashed
> lines mean and why the show up in the plot.

Maybe they are confidence limits? Read the help page for plot.survfit, 
especially 'conf.int'.

G?ran

   [[alternative HTML
> version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Mon Feb  8 16:33:54 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 08 Feb 2016 15:33:54 +0000
Subject: [R] How to extract same columns from identical dataframes in a
	list?
In-Reply-To: <56B89921.4040405@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
Message-ID: <CAKVAULPUTzrGGSVHgdySWD0P+OMg38+S2umpUUqKC-3CYESXaA@mail.gmail.com>

Hi Wolfgang,

I'm not sure exactly what you want, but the ldply in the package plyr can
help you make a data.frame from a list of data.frames:

library(plyr)

dfa <- data.frame(cola = LETTERS[1:5], colb = c(1:5))
dfb <- data.frame(cola = LETTERS[1:5], colb = c(1:5))

df.lst <- list(dfa.name = dfa, dfb.name = dfb)

# If you want to use column number
ldply(df.lst, function(cur.df){return(cur.df[, 2])})

# If the column name is always the same
ldply(df.lst, function(cur.df){return(cur.df$colb)})

# Use the entire data.frame
ldply(df.lst, function(cur.df){return(cur.df)})

# The latter can also be done with do.call
do.call(rbind, df.lst)

Hope this helps,
Ulrik

On Mon, 8 Feb 2016 at 16:07 Wolfgang Waser <waser at frankenfoerder-fg.de>
wrote:

> Hello,
>
> I have a list of 7 data frames, each data frame having 24 rows (hour of
> the day) and 5 columns (weeks) with a total of 5 x 24 values
>
> I would like to combine all 7 columns of week 1 (and 2 ...) in a
> separate data frame for hourly calculations, e.g.
> > apply(new.data.frame,1,mean)
>
> In some way sapply (lapply) works, but I cannot directly select columns
> of the original data frames in the list. As a workaround I have to
> select a range of values:
>
> > sapply(list_of_dataframes,"[",1:24)
>
> Values 1:24 give the first column, 25:48 the second and so on.
>
> Is there an easier / more direct way to select for specific columns
> instead of selecting a range of values, avoiding loops?
>
>
> Cheers,
>
> Wolfgang
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb  8 17:11:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Feb 2016 08:11:26 -0800
Subject: [R] [FORGED] Plot step function
In-Reply-To: <CAA=hcWR3aPfBrFMR1EedXv4+WBGUqqqmrr9stuoLHo2K5uY5vQ@mail.gmail.com>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<56B63B93.3030303@auckland.ac.nz>
	<CAA=hcWQX9or8TSyRVnCvBwPErqksMC2hm7Uatua6xh2bHKVcBA@mail.gmail.com>
	<CA+8X3fXjsUDxjBMa4Zig63wzMdDcmS=+wjSNboZ+tNZiFuxUfw@mail.gmail.com>
	<CAA=hcWR3aPfBrFMR1EedXv4+WBGUqqqmrr9stuoLHo2K5uY5vQ@mail.gmail.com>
Message-ID: <525F75F3-AA30-438E-9C28-8BD294E80534@dcn.davis.ca.us>

R by default puts the axes at the edge of the plot, not at x=0 and y=0, for the reason that doing otherwise makes the plot harder to read. To see this, consider:

plot( c( -4, 0, 4 ), c( 0, 1, 1 ), type="s", xlab="x", ylab="y", axes=FALSE, xlim=c( -5, 5 ), ylim=c( -2, 2 ), lwd=2 )
axis( side=1, at=seq( -4, 4, 1 ), pos=0 )
axis( side=2, at=seq( -2, 2, 1 ), pos=0 )

You should read the help pages
?plot.default
?axis
-- 
Sent from my phone. Please excuse my brevity.

On February 7, 2016 2:54:48 PM PST, jupiter <jupiter.hce at gmail.com> wrote:
>Thanks Jim, that was I did to generate graphic from
>plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y"), it displayed [-4,
>-2,
>0, 2, 4] in X, I tried to twist it, but could not get [-4, -3, -2, -1,
>0,
>1, 2, 3, 4] in X. Also, that the y 0.0 is above the X axis.
>
>I guess I try to figure out if, in general, there are parameters to
>define
>?x (i.e ?x= 1), and to define [0, 0.0] at the joint of x axis and y
>axis.
>But never mind, if it is too much to ask :-).
>
>Thank you and greatly appreciate kind responses.
>
>- j
>
>
>
>On Mon, Feb 8, 2016 at 8:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hail Jupiter,
>> Might a slight alteration of Rolf's suggestion do the trick?
>>
>>  plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y")
>>
>> Jim
>>
>> On Sun, Feb 7, 2016 at 8:49 AM, jupiter <jupiter.hce at gmail.com>
>wrote:
>>
>>> Thank you for the all response, how can the point y (0.0) on the
>same x
>>> axis, and X increases 1 between [-4, 4]?
>>>
>>> On Sun, Feb 7, 2016 at 5:29 AM, Rolf Turner
><r.turner at auckland.ac.nz>
>>> wrote:
>>>
>>> > On 07/02/16 01:11, jupiter wrote:
>>> >
>>> >> Hi,
>>> >>
>>> >> I am just starting to learn R, sorry for asking a simple
>question. How
>>> can
>>> >> plot a line x <= 0 y = 0, x > 0 y = 1?
>>> >>
>>> >
>>> > One way:
>>> >
>>> >     plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")
>>> >
>>> > cheers,
>>> >
>>> > Rolf Turner
>>> >
>>> > --
>>> > Technical Editor ANZJS
>>> > Department of Statistics
>>> > University of Auckland
>>> > Phone: +64-9-373-7599 ext. 88276
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb  8 17:26:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Feb 2016 08:26:38 -0800
Subject: [R] How to extract same columns from identical dataframes in
	a	list?
In-Reply-To: <CAKVAULPUTzrGGSVHgdySWD0P+OMg38+S2umpUUqKC-3CYESXaA@mail.gmail.com>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<CAKVAULPUTzrGGSVHgdySWD0P+OMg38+S2umpUUqKC-3CYESXaA@mail.gmail.com>
Message-ID: <65917377-CED7-4AF7-BFAE-4CC36F9EDA26@dcn.davis.ca.us>

Or

do.call( rbind, list.of.df )

from base R (without some of the robust behaviors that ldply implements).
-- 
Sent from my phone. Please excuse my brevity.

On February 8, 2016 7:33:54 AM PST, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>Hi Wolfgang,
>
>I'm not sure exactly what you want, but the ldply in the package plyr
>can
>help you make a data.frame from a list of data.frames:
>
>library(plyr)
>
>dfa <- data.frame(cola = LETTERS[1:5], colb = c(1:5))
>dfb <- data.frame(cola = LETTERS[1:5], colb = c(1:5))
>
>df.lst <- list(dfa.name = dfa, dfb.name = dfb)
>
># If you want to use column number
>ldply(df.lst, function(cur.df){return(cur.df[, 2])})
>
># If the column name is always the same
>ldply(df.lst, function(cur.df){return(cur.df$colb)})
>
># Use the entire data.frame
>ldply(df.lst, function(cur.df){return(cur.df)})
>
># The latter can also be done with do.call
>do.call(rbind, df.lst)
>
>Hope this helps,
>Ulrik
>
>On Mon, 8 Feb 2016 at 16:07 Wolfgang Waser <waser at frankenfoerder-fg.de>
>wrote:
>
>> Hello,
>>
>> I have a list of 7 data frames, each data frame having 24 rows (hour
>of
>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>
>> I would like to combine all 7 columns of week 1 (and 2 ...) in a
>> separate data frame for hourly calculations, e.g.
>> > apply(new.data.frame,1,mean)
>>
>> In some way sapply (lapply) works, but I cannot directly select
>columns
>> of the original data frames in the list. As a workaround I have to
>> select a range of values:
>>
>> > sapply(list_of_dataframes,"[",1:24)
>>
>> Values 1:24 give the first column, 25:48 the second and so on.
>>
>> Is there an easier / more direct way to select for specific columns
>> instead of selecting a range of values, avoiding loops?
>>
>>
>> Cheers,
>>
>> Wolfgang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From toth.denes at ttk.mta.hu  Mon Feb  8 18:00:07 2016
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Mon, 8 Feb 2016 18:00:07 +0100
Subject: [R] How to extract same columns from identical dataframes in a
 list?
In-Reply-To: <56B89921.4040405@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
Message-ID: <56B8C997.2010201@ttk.mta.hu>

Hi,

Although you did not provide any reproducible example, it seems you 
store the same type of values in your data.frames. If this is true, it 
is much more efficient to store your data in an array:

mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
                b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))

myarray <- unlist(mylist, use.names = FALSE)
dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
dimnames(myarray) <- list(hour = rownames(mylist$a),
                           week = colnames(mylist$a),
                           other = names(mylist))
# now you can do:
mean(myarray[, "week1", "a"])

# or:
colMeans(myarray)


Cheers,
   Denes


On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
> Hello,
>
> I have a list of 7 data frames, each data frame having 24 rows (hour of
> the day) and 5 columns (weeks) with a total of 5 x 24 values
>
> I would like to combine all 7 columns of week 1 (and 2 ...) in a
> separate data frame for hourly calculations, e.g.
>> apply(new.data.frame,1,mean)
>
> In some way sapply (lapply) works, but I cannot directly select columns
> of the original data frames in the list. As a workaround I have to
> select a range of values:
>
>> sapply(list_of_dataframes,"[",1:24)
>
> Values 1:24 give the first column, 25:48 the second and so on.
>
> Is there an easier / more direct way to select for specific columns
> instead of selecting a range of values, avoiding loops?
>
>
> Cheers,
>
> Wolfgang
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From goran.brostrom at umu.se  Mon Feb  8 18:26:20 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Mon, 8 Feb 2016 18:26:20 +0100
Subject: [R] Dates and missing values
Message-ID: <56B8CFBC.5030309@umu.se>

I have a data frame with dates as integers:

 > summary(persons[, c("foddat", "doddat")])
      foddat             doddat
  Min.   :16790000   Min.   :18000000
  1st Qu.:18760904   1st Qu.:18810924
  Median :19030426   Median :19091227
  Mean   :18946659   Mean   :19027233
  3rd Qu.:19220911   3rd Qu.:19310526
  Max.   :19660124   Max.   :19691228
  NA's   :624        NA's   :207570

After converting the dates to Date format ('as.Date') I get:

 > summary(per[, c("foddat", "doddat")])
     foddat               doddat
  Min.   :1679-07-01   Min.   :1800-01-26
  1st Qu.:1876-09-04   1st Qu.:1881-09-24
  Median :1903-04-26   Median :1909-12-27
  Mean   :1895-02-04   Mean   :1903-02-22
  3rd Qu.:1922-09-10   3rd Qu.:1931-05-26
  Max.   :1966-01-24   Max.   :1969-12-28

My question is: Why are the numbers of missing values not printed in the 
second case? 'is.na' gives the correct (same) numbers.

Can I somehow force 'summary' to print NA's? I found no clues in the 
documentation.

 > sessionInfo()
R version 3.2.3 Patched (2016-01-19 r69960)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.10

G?ran Brostr?m


From marc_schwartz at me.com  Mon Feb  8 19:26:54 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 08 Feb 2016 12:26:54 -0600
Subject: [R] Dates and missing values
In-Reply-To: <56B8CFBC.5030309@umu.se>
References: <56B8CFBC.5030309@umu.se>
Message-ID: <AD9C4DF7-0D13-4F6C-9959-31AF86C2B0A4@me.com>


> On Feb 8, 2016, at 11:26 AM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
> 
> I have a data frame with dates as integers:
> 
> > summary(persons[, c("foddat", "doddat")])
>     foddat             doddat
> Min.   :16790000   Min.   :18000000
> 1st Qu.:18760904   1st Qu.:18810924
> Median :19030426   Median :19091227
> Mean   :18946659   Mean   :19027233
> 3rd Qu.:19220911   3rd Qu.:19310526
> Max.   :19660124   Max.   :19691228
> NA's   :624        NA's   :207570
> 
> After converting the dates to Date format ('as.Date') I get:
> 
> > summary(per[, c("foddat", "doddat")])
>    foddat               doddat
> Min.   :1679-07-01   Min.   :1800-01-26
> 1st Qu.:1876-09-04   1st Qu.:1881-09-24
> Median :1903-04-26   Median :1909-12-27
> Mean   :1895-02-04   Mean   :1903-02-22
> 3rd Qu.:1922-09-10   3rd Qu.:1931-05-26
> Max.   :1966-01-24   Max.   :1969-12-28
> 
> My question is: Why are the numbers of missing values not printed in the second case? 'is.na' gives the correct (same) numbers.
> 
> Can I somehow force 'summary' to print NA's? I found no clues in the documentation.


Hi,

Two things:

1. We are going to need to see the exact call to as.Date() that you used. as.Date() will take a numeric vector as input, but the presumption is that the number represents the number of days since an origin, which needs to be specified explicitly. If you coerced the numeric vector to character first, presuming a "%Y%m%d" format, then you need to be cautious about how that is done and the result.

2. Your second call is to a data frame called 'per', which may or may not have the same content as 'persons' in your first call.


If I do the following, taking some of your numeric values from above:

x <- c(18000000, 18810924, 19091227, 19027233, 19310526, 19691228, NA)

DF <- data.frame(x)

> summary(DF)
       x           
 Min.   :18000000  
 1st Qu.:18865001  
 Median :19059230  
 Mean   :18988523  
 3rd Qu.:19255701  
 Max.   :19691228  
 NA's   :1   

> as.character(DF$x)
[1] "1.8e+07"  "18810924" "19091227" "19027233" "19310526" "19691228"
[7] NA    

DF$x.Date <- as.Date(as.character(DF$x), format = "%Y%m%d")

> DF
         x     x.Date
1 18000000       <NA>
2 18810924 1881-09-24
3 19091227 1909-12-27
4 19027233       <NA>
5 19310526 1931-05-26
6 19691228 1969-12-28
7       NA       <NA>

> summary(DF)
       x                x.Date          
 Min.   :18000000   Min.   :1881-09-24  
 1st Qu.:18865001   1st Qu.:1902-12-04  
 Median :19059230   Median :1920-09-10  
 Mean   :18988523   Mean   :1923-04-12  
 3rd Qu.:19255701   3rd Qu.:1941-01-17  
 Max.   :19691228   Max.   :1969-12-28  
 NA's   :1          NA's   :3   


So summary does support the reporting of NA's for Dates, using summary.Date().

Regards,

Marc Schwartz


From goran.brostrom at umu.se  Mon Feb  8 19:45:25 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Mon, 8 Feb 2016 19:45:25 +0100
Subject: [R] Dates and missing values
In-Reply-To: <AD9C4DF7-0D13-4F6C-9959-31AF86C2B0A4@me.com>
References: <56B8CFBC.5030309@umu.se>
	<AD9C4DF7-0D13-4F6C-9959-31AF86C2B0A4@me.com>
Message-ID: <56B8E245.50304@umu.se>

Thanks Marc, but see below!

On 2016-02-08 19:26, Marc Schwartz wrote:
>
>> On Feb 8, 2016, at 11:26 AM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
>>
>> I have a data frame with dates as integers:
>>
>>> summary(persons[, c("foddat", "doddat")])
>>      foddat             doddat
>> Min.   :16790000   Min.   :18000000
>> 1st Qu.:18760904   1st Qu.:18810924
>> Median :19030426   Median :19091227
>> Mean   :18946659   Mean   :19027233
>> 3rd Qu.:19220911   3rd Qu.:19310526
>> Max.   :19660124   Max.   :19691228
>> NA's   :624        NA's   :207570
>>
>> After converting the dates to Date format ('as.Date') I get:
>>
>>> summary(per[, c("foddat", "doddat")])
>>     foddat               doddat
>> Min.   :1679-07-01   Min.   :1800-01-26
>> 1st Qu.:1876-09-04   1st Qu.:1881-09-24
>> Median :1903-04-26   Median :1909-12-27
>> Mean   :1895-02-04   Mean   :1903-02-22
>> 3rd Qu.:1922-09-10   3rd Qu.:1931-05-26
>> Max.   :1966-01-24   Max.   :1969-12-28
>>
>> My question is: Why are the numbers of missing values not printed in the second case? 'is.na' gives the correct (same) numbers.
>>
>> Can I somehow force 'summary' to print NA's? I found no clues in the documentation.
>
>
> Hi,
>
> Two things:
>
> 1. We are going to need to see the exact call to as.Date() that you used. as.Date() will take a numeric vector as input, but the presumption is that the number represents the number of days since an origin, which needs to be specified explicitly. If you coerced the numeric vector to character first, presuming a "%Y%m%d" format, then you need to be cautious about how that is done and the result.
>
> 2. Your second call is to a data frame called 'per', which may or may not have the same content as 'persons' in your first call.
>
>
> If I do the following, taking some of your numeric values from above:
>
> x <- c(18000000, 18810924, 19091227, 19027233, 19310526, 19691228, NA)
>
> DF <- data.frame(x)
>
>> summary(DF)
>         x
>   Min.   :18000000
>   1st Qu.:18865001
>   Median :19059230
>   Mean   :18988523
>   3rd Qu.:19255701
>   Max.   :19691228
>   NA's   :1
>
>> as.character(DF$x)
> [1] "1.8e+07"  "18810924" "19091227" "19027233" "19310526" "19691228"
> [7] NA
>
> DF$x.Date <- as.Date(as.character(DF$x), format = "%Y%m%d")
>
>> DF
>           x     x.Date
> 1 18000000       <NA>
> 2 18810924 1881-09-24
> 3 19091227 1909-12-27
> 4 19027233       <NA>
> 5 19310526 1931-05-26
> 6 19691228 1969-12-28
> 7       NA       <NA>
>
>> summary(DF)
>         x                x.Date
>   Min.   :18000000   Min.   :1881-09-24
>   1st Qu.:18865001   1st Qu.:1902-12-04
>   Median :19059230   Median :1920-09-10
>   Mean   :18988523   Mean   :1923-04-12
>   3rd Qu.:19255701   3rd Qu.:1941-01-17
>   Max.   :19691228   Max.   :1969-12-28
>   NA's   :1          NA's   :3
>
But:

 > summary(DF[, "x.Date", drop = FALSE])
      x.Date
  Min.   :1881-09-24
  1st Qu.:1902-12-04
  Median :1920-09-10
  Mean   :1923-04-12
  3rd Qu.:1941-01-17
  Max.   :1969-12-28

No NA's. But again:

 > summary(DF[, "x.Date"])
         Min.      1st Qu.       Median         Mean      3rd Qu. 
   Max.
"1881-09-24" "1902-12-04" "1920-09-10" "1923-04-12" "1941-01-17" 
"1969-12-28"
         NA's
          "3"

>
> So summary does support the reporting of NA's for Dates, using summary.Date().

Not always, as it seems. Strange. (The 'persons' vs. 'per' is a red 
herring.)

G?ran Brostr?m

>
> Regards,
>
> Marc Schwartz
>


From kathleen.cote at gmail.com  Mon Feb  8 19:41:31 2016
From: kathleen.cote at gmail.com (=?UTF-8?B?S2F0aGxlZW4gQ8O0dMOp?=)
Date: Mon, 8 Feb 2016 13:41:31 -0500
Subject: [R] syntax for nested random factors in lme
Message-ID: <CA+G7zRi8DYKrfFxtcWXEUVrfjqARPTfPE9ncHKFZJDBb52SHNA@mail.gmail.com>

Hi,

I've been taught that if I want to nest random factor A into B in an lme
model, the syntax is as follows: lme(x~y+B,random=~1|B/A).

In the case of my data, matters seem to be complicated by the fact that B
is a categorical variable with only 2 levels. When I run the lme with the
above syntax, I obtain an NaN p value for B as a fixed factor in the
model. When
I rewrite the random factor as random=~1|A/B, I obtain a p value.

Is the correct format for a nested random factor indeed B/A in this case?
Is it incorrect to write it as A/B?

Please let me know if you would like additional information, such as
observations and output.

Kathleen

	[[alternative HTML version deleted]]


From rosita21 at gmail.com  Mon Feb  8 19:40:20 2016
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Mon, 8 Feb 2016 18:40:20 +0000
Subject: [R] Help in meta-analysis (URGENT please)
Message-ID: <68693AC4-30CD-49FE-837C-12CD01F05F72@gmail.com>

Dear all,

I?m conducting a met analysis and I usually use Revman, bur as I?m trying to use R more and more, I would like to conduct the met analysis here, in R (R-studio).

One off my problems, I think, is that:
1st. it?s the first time :)
2. I only have data for 1 arm as you can see on the data that follows.

ARTIGO	qt	tt	qc	tc	Personal Notes	qt2
Giuliani M. (2014)	-	-	1515	1862	only MSM.	347
Diaz A. (2015)	-	-	-	-	only MSM (n=3081)	2499
Niedz?wiedzka-Stadnik M. (2015)	828	1098	-	-		326
Hoenig M. (2015)	-	-	8506	-	MSM (n=8925)	419
Wu H. (2015)	58	145	-	16713	n=16892	87
Pan X. (2015)	-			-	only MSM (n=1316)	-
Ma Q. (2015)	-			-	only MSM (n=424)	-
Op de Coul E. (2015)	8596			-	HIV-infected patients (n=20965)	12369
Liu G. (2015)	-	-	1003 (?)	-	only MSM (n=1041) - some converted to HIV+ during the study	-
Hoenigl M. (2015)	-			-	only MSM (n=8935) analysis HIV tests repetitions	-
Moller L. M. (2015)	-	-	469	-	only MSM (N=561)	92
watkins (2015)	-	-	-	-	only MSM (n=1154) only analysis believes concerning the risk	-
den Dass C. (2015)	-	-	2408	-	only MSM (n=3787)	589
Jia Z. (2015)	-	-	5314	-	only MSM (n=5800)	486
solomon S. (2015)	-	-	10875	-	only MSM (n=12022)	1147
Diez M. (2014)	-	3599	-	-	n=145337	



legend:
qt the number of hiv subjetcs who are not sms.
qt2 the number of hiv subjetcs who are  sms.
tt the total number of hiv subjects.
qc the number of subjetcs who are sms without being hiv.
tc the total number of subject not hiv.



Is it possible to conduct a met analysis concerning the risk of hiv among MSM relative to the ones that are not MSM?

or simply concerning the risk of hiv among MSM????

If yes, How?

Metafor? I?ve tried, but wasn?t succeed :(


Best,
RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________



Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates


From marc_schwartz at me.com  Mon Feb  8 21:36:56 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 08 Feb 2016 14:36:56 -0600
Subject: [R] Dates and missing values
In-Reply-To: <56B8E245.50304@umu.se>
References: <56B8CFBC.5030309@umu.se>
	<AD9C4DF7-0D13-4F6C-9959-31AF86C2B0A4@me.com> <56B8E245.50304@umu.se>
Message-ID: <D074D393-E174-4FCD-B9EA-A7677404CFF1@me.com>


> On Feb 8, 2016, at 12:45 PM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
> 
> Thanks Marc, but see below!
> 
> On 2016-02-08 19:26, Marc Schwartz wrote:
>> 
>>> On Feb 8, 2016, at 11:26 AM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
>>> 
>>> I have a data frame with dates as integers:
>>> 
>>>> summary(persons[, c("foddat", "doddat")])
>>>     foddat             doddat
>>> Min.   :16790000   Min.   :18000000
>>> 1st Qu.:18760904   1st Qu.:18810924
>>> Median :19030426   Median :19091227
>>> Mean   :18946659   Mean   :19027233
>>> 3rd Qu.:19220911   3rd Qu.:19310526
>>> Max.   :19660124   Max.   :19691228
>>> NA's   :624        NA's   :207570
>>> 
>>> After converting the dates to Date format ('as.Date') I get:
>>> 
>>>> summary(per[, c("foddat", "doddat")])
>>>    foddat               doddat
>>> Min.   :1679-07-01   Min.   :1800-01-26
>>> 1st Qu.:1876-09-04   1st Qu.:1881-09-24
>>> Median :1903-04-26   Median :1909-12-27
>>> Mean   :1895-02-04   Mean   :1903-02-22
>>> 3rd Qu.:1922-09-10   3rd Qu.:1931-05-26
>>> Max.   :1966-01-24   Max.   :1969-12-28
>>> 
>>> My question is: Why are the numbers of missing values not printed in the second case? 'is.na' gives the correct (same) numbers.
>>> 
>>> Can I somehow force 'summary' to print NA's? I found no clues in the documentation.
>> 
>> 
>> Hi,
>> 
>> Two things:
>> 
>> 1. We are going to need to see the exact call to as.Date() that you used. as.Date() will take a numeric vector as input, but the presumption is that the number represents the number of days since an origin, which needs to be specified explicitly. If you coerced the numeric vector to character first, presuming a "%Y%m%d" format, then you need to be cautious about how that is done and the result.
>> 
>> 2. Your second call is to a data frame called 'per', which may or may not have the same content as 'persons' in your first call.
>> 
>> 
>> If I do the following, taking some of your numeric values from above:
>> 
>> x <- c(18000000, 18810924, 19091227, 19027233, 19310526, 19691228, NA)
>> 
>> DF <- data.frame(x)
>> 
>>> summary(DF)
>>        x
>>  Min.   :18000000
>>  1st Qu.:18865001
>>  Median :19059230
>>  Mean   :18988523
>>  3rd Qu.:19255701
>>  Max.   :19691228
>>  NA's   :1
>> 
>>> as.character(DF$x)
>> [1] "1.8e+07"  "18810924" "19091227" "19027233" "19310526" "19691228"
>> [7] NA
>> 
>> DF$x.Date <- as.Date(as.character(DF$x), format = "%Y%m%d")
>> 
>>> DF
>>          x     x.Date
>> 1 18000000       <NA>
>> 2 18810924 1881-09-24
>> 3 19091227 1909-12-27
>> 4 19027233       <NA>
>> 5 19310526 1931-05-26
>> 6 19691228 1969-12-28
>> 7       NA       <NA>
>> 
>>> summary(DF)
>>        x                x.Date
>>  Min.   :18000000   Min.   :1881-09-24
>>  1st Qu.:18865001   1st Qu.:1902-12-04
>>  Median :19059230   Median :1920-09-10
>>  Mean   :18988523   Mean   :1923-04-12
>>  3rd Qu.:19255701   3rd Qu.:1941-01-17
>>  Max.   :19691228   Max.   :1969-12-28
>>  NA's   :1          NA's   :3
>> 
> But:
> 
> > summary(DF[, "x.Date", drop = FALSE])
>     x.Date
> Min.   :1881-09-24
> 1st Qu.:1902-12-04
> Median :1920-09-10
> Mean   :1923-04-12
> 3rd Qu.:1941-01-17
> Max.   :1969-12-28
> 
> No NA's. But again:
> 
> > summary(DF[, "x.Date"])
>        Min.      1st Qu.       Median         Mean      3rd Qu.   Max.
> "1881-09-24" "1902-12-04" "1920-09-10" "1923-04-12" "1941-01-17" "1969-12-28"
>        NA's
>         "3"
> 
>> 
>> So summary does support the reporting of NA's for Dates, using summary.Date().
> 
> Not always, as it seems. Strange. (The 'persons' vs. 'per' is a red herring.)
> 
> G?ran Brostr?m


Ok, thanks for the clarification.

I spent some time running summary.Date() under debug, trying to see where things fail.

Within the function, the result object 'x', is created correctly, with the correct class attributes and the count of NA values retained in an "NAs" attribute

However, upon function exit, the class attributes appear to be lost and the result is of class table, which also loses the "NAs" attribute, which is assigned within the function body.

I believe that this is happening within summary.data.frame().

I can extend the example more generally, when the only columns in the source data frame are Dates:

DF.Dates <- data.frame(Col1 = DF$x.Date, Col2 = DF$x.Date)

> DF.Dates
        Col1       Col2
1       <NA>       <NA>
2 1881-09-24 1881-09-24
3 1909-12-27 1909-12-27
4       <NA>       <NA>
5 1931-05-26 1931-05-26
6 1969-12-28 1969-12-28
7       <NA>       <NA>

> summary(DF.Dates)
      Col1                 Col2           
 Min.   :1881-09-24   Min.   :1881-09-24  
 1st Qu.:1902-12-04   1st Qu.:1902-12-04  
 Median :1920-09-10   Median :1920-09-10  
 Mean   :1923-04-12   Mean   :1923-04-12  
 3rd Qu.:1941-01-17   3rd Qu.:1941-01-17  
 Max.   :1969-12-28   Max.   :1969-12-28  


So, it is not dependent upon the subsetting used in your original call per se, but when the data frame passed to summary.data.frame() consists of only Date class columns.

I am still working through the code, but the preliminary source of the issue appears to be the following line in summary.data.frame:

length(sms) <- nr

which truncates the internal object 'sms', where before that line, 'sms' is of length 7 and afterwards, 6:

Browse[2]> nr
[1] 6
Browse[2]> sms
[1] "Min.   :1881-09-24  " "1st Qu.:1902-12-04  " "Median :1920-09-10  "
[4] "Mean   :1923-04-12  " "3rd Qu.:1941-01-17  " "Max.   :1969-12-28  "
[7] "NA's   :3  "         
Browse[2]> 
debug: length(sms) <- nr
Browse[2]> sms
[1] "Min.   :1881-09-24  " "1st Qu.:1902-12-04  " "Median :1920-09-10  "
[4] "Mean   :1923-04-12  " "3rd Qu.:1941-01-17  " "Max.   :1969-12-28  "
[7] "NA's   :3  "         
Browse[2]> 
debug: z[[i]] <- sms
Browse[2]> sms
[1] "Min.   :1881-09-24  " "1st Qu.:1902-12-04  " "Median :1920-09-10  "
[4] "Mean   :1923-04-12  " "3rd Qu.:1941-01-17  " "Max.   :1969-12-28  "



OK, I now believe that I have found the issue...

Internally, an object 'z' is created by the following:

z <- lapply(X = as.list(object), FUN = summary, maxsum = maxsum, 
        digits = 12L, ...)

For my data frame, DF.Dates, 'z' is:

Browse[2]> z
$Col1
        Min.      1st Qu.       Median         Mean      3rd Qu. 
"1881-09-24" "1902-12-04" "1920-09-10" "1923-04-12" "1941-01-17" 
        Max.         NA's 
"1969-12-28"          "3" 

$Col2
        Min.      1st Qu.       Median         Mean      3rd Qu. 
"1881-09-24" "1902-12-04" "1920-09-10" "1923-04-12" "1941-01-17" 
        Max.         NA's 
"1969-12-28"          "3" 

which shows the result of summary.Date() on the two columns. 

The print()ed output is the result of each list element being of the class set by summary.Date():

Browse[2]> class(z$Col1)
[1] "summaryDefault" "table"          "Date"          
Browse[2]> class(z$Col2)
[1] "summaryDefault" "table"          "Date"       


The problem is that the NA component of the result is an attribute and not part of the vector itself:

Browse[2]> str(z)
List of 2
 $ Col1: summaryDefault[1:6], format: "1881-09-24" ...
  ..- attr(*, "names")="Min." ...
 $ Col2: summaryDefault[1:6], format: "1881-09-24" ...
  ..- attr(*, "names")="Min." ...


Note that each list element is of length 6, hence the value used in 'nr' above, rather than 7.

The count of NA values are stored in attributes:

Browse[2]> attr(z$Col1, "NAs")
[1] 3
Browse[2]> attr(z$Col2, "NAs")
[1] 3


Hence, when internal variable 'nr' is set, it is:

Browse[2]> max(unlist(lapply(z, NROW)))
[1] 6

Browse[2]> nr
[1] 6


And...that results in the truncation seen above and the loss of the NA attribute components otherwise returned.

My original example worked, where a Date column is present with columns of other data types, because that 'nr' variable internally is set to the correct length (7) for the other data types, BUT, only if NA's are present in at least one other column:

DF.Dates$Col3 <- 1:7

> DF.Dates
        Col1       Col2 Col3
1       <NA>       <NA>    1
2 1881-09-24 1881-09-24    2
3 1909-12-27 1909-12-27    3
4       <NA>       <NA>    4
5 1931-05-26 1931-05-26    5
6 1969-12-28 1969-12-28    6
7       <NA>       <NA>    7

> summary(DF.Dates)
      Col1                 Col2                 Col3    
 Min.   :1881-09-24   Min.   :1881-09-24   Min.   :1.0  
 1st Qu.:1902-12-04   1st Qu.:1902-12-04   1st Qu.:2.5  
 Median :1920-09-10   Median :1920-09-10   Median :4.0  
 Mean   :1923-04-12   Mean   :1923-04-12   Mean   :4.0  
 3rd Qu.:1941-01-17   3rd Qu.:1941-01-17   3rd Qu.:5.5  
 Max.   :1969-12-28   Max.   :1969-12-28   Max.   :7.0  


DF.Dates$Col3 <- c(1:6, NA)

> summary(DF.Dates)
      Col1                 Col2                 Col3     
 Min.   :1881-09-24   Min.   :1881-09-24   Min.   :1.00  
 1st Qu.:1902-12-04   1st Qu.:1902-12-04   1st Qu.:2.25  
 Median :1920-09-10   Median :1920-09-10   Median :3.50  
 Mean   :1923-04-12   Mean   :1923-04-12   Mean   :3.50  
 3rd Qu.:1941-01-17   3rd Qu.:1941-01-17   3rd Qu.:4.75  
 Max.   :1969-12-28   Max.   :1969-12-28   Max.   :6.00  
 NA's   :3            NA's   :3            NA's   :1     



So, there is a bug in summary.data.frame() when only Date class columns are present and no other columns have NA's, from what this suggests.

The key would seem to be to modify the code that creates 'nr', which is currently:

nr <- if (nv) 
        max(unlist(lapply(z, NROW)))
    else 0


to account for the presence of the "NAs" attribute from summary.Date(), restore the attribute further down in the code, if present, or alternatively, to modify the code for summary.Date() so that rather than adding the "NAs" attribute:

  x <- summary.default(unclass(object), digits = digits, ...)
  if (m <- match("NA's", names(x), 0)) {
        NAs <- as.integer(x[m])
        x <- x[-m]
        attr(x, "NAs") <- NAs
    }


it behaves more like summary.default(), so that the NA count is an actual element in the result vector, rather than an attribute:

nas <- is.na(object)
        object <- object[!nas]
        qq <- stats::quantile(object)
        qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
        names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", 
            "Max.")
        if (any(nas)) 
            c(qq, `NA's` = sum(nas))
        else qq


This is where I would defer to a member of R Core for guidance, since I presume that there may be some logic in the difference, other than perhaps different authors over time and there may be other implications that I am not considering here.

Regards,

Marc


From projectbasu at gmail.com  Mon Feb  8 23:15:37 2016
From: projectbasu at gmail.com (swaraj basu)
Date: Mon, 8 Feb 2016 23:15:37 +0100
Subject: [R] Compare correlation coefficients between samples
Message-ID: <CAKNnbJR1aBjPkdK8vX5Gy5qmYEY9x68Ad1keQJtz8moc5K=2xg@mail.gmail.com>

Dear All,

I have a dataframe of 1000 rows and 4 columns. Each row represents a pair
of vectors (in my case a pair of genes) while the columns represent the
following

estimate.A: spearman correlation coefficient of gene[i] and gene[j]
expression across 120 samples from cancer type A
prob.A: Probability value associated with the estimate.A as inferred from
cor.test

estimate.B: spearman correlation coefficient of gene[i] and gene[j]
expression across 48 samples from cancer type B
prob.B: Probability value associated with the estimate.A as inferred from
cor.test

To sum up the data.frame will look like

S<-data.frame(estimate.A=runif(1000,-1,1),prob.A=runif(1000,0,1),estimate.B=runif(1000,-1,1),prob.B=runif(1000,0,1))

I want to calculate the conditional probability for all the pair of genes
showing negative correlation in B (at p.value < 0.01) when they show a
strong negative correlation in A (again at p.value < 0.01). I was thinking
in the lines of using the "prob" package to estimate the conditional
probability but I am not able to figure out the correct way to do so in my
case. Thanks for any help in advance.

-- 
Swaraj Basu
Institute of Biomedicine
University of Gothenburg

	[[alternative HTML version deleted]]


From rmcgu at doh.health.nsw.gov.au  Mon Feb  8 23:23:52 2016
From: rmcgu at doh.health.nsw.gov.au (MCGUIRE, Rhydwyn)
Date: Mon, 8 Feb 2016 22:23:52 +0000
Subject: [R] Help in meta-analysis (URGENT please)
In-Reply-To: <68693AC4-30CD-49FE-837C-12CD01F05F72@gmail.com>
References: <68693AC4-30CD-49FE-837C-12CD01F05F72@gmail.com>
Message-ID: <AF36C32BE015CB48883C4A9F73CC8C3201748958E5@DOHNSMXDB03.doh.health.nsw.gov.au>

Hi Rosa, 

This looks like a mix of a R problem and a statistical problem. For the statistical part I think you are going to need to find a statistician/adviser to sit down with and workout what you want to measure and whether it is possible. 
For the R part it might be more useful to ask specific question about metafor, what happened when you tried to use it? Do you have an error message or a small example you could post so we could rerun your analysis? 

Cheers,
Rhydwyn 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rosa Oliveira
Sent: Tuesday, 9 February 2016 5:40 AM
To: r-help mailing list
Subject: [R] Help in meta-analysis (URGENT please)

Dear all,

I?m conducting a met analysis and I usually use Revman, bur as I?m trying to use R more and more, I would like to conduct the met analysis here, in R (R-studio).

One off my problems, I think, is that:
1st. it?s the first time :)
2. I only have data for 1 arm as you can see on the data that follows.

ARTIGO	qt	tt	qc	tc	Personal Notes	qt2
Giuliani M. (2014)	-	-	1515	1862	only MSM.	347
Diaz A. (2015)	-	-	-	-	only MSM (n=3081)	2499
Niedz?wiedzka-Stadnik M. (2015)	828	1098	-	-		326
Hoenig M. (2015)	-	-	8506	-	MSM (n=8925)	419
Wu H. (2015)	58	145	-	16713	n=16892	87
Pan X. (2015)	-			-	only MSM (n=1316)	-
Ma Q. (2015)	-			-	only MSM (n=424)	-
Op de Coul E. (2015)	8596			-	HIV-infected patients (n=20965)	12369
Liu G. (2015)	-	-	1003 (?)	-	only MSM (n=1041) - some converted to HIV+ during the study	-
Hoenigl M. (2015)	-			-	only MSM (n=8935) analysis HIV tests repetitions	-
Moller L. M. (2015)	-	-	469	-	only MSM (N=561)	92
watkins (2015)	-	-	-	-	only MSM (n=1154) only analysis believes concerning the risk	-
den Dass C. (2015)	-	-	2408	-	only MSM (n=3787)	589
Jia Z. (2015)	-	-	5314	-	only MSM (n=5800)	486
solomon S. (2015)	-	-	10875	-	only MSM (n=12022)	1147
Diez M. (2014)	-	3599	-	-	n=145337	



legend:
qt the number of hiv subjetcs who are not sms.
qt2 the number of hiv subjetcs who are  sms.
tt the total number of hiv subjects.
qc the number of subjetcs who are sms without being hiv.
tc the total number of subject not hiv.



Is it possible to conduct a met analysis concerning the risk of hiv among MSM relative to the ones that are not MSM?

or simply concerning the risk of hiv among MSM????

If yes, How?

Metafor? I?ve tried, but wasn?t succeed :(


Best,
RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________



Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.__________________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of health's Electronic Messaging Policy.
__________________________________________________________________________________________________________
_______________________________________________________________________________________________________
Disclaimer: This message is intended for the addressee named and may contain confidential information.
If you are not the intended recipient, please delete it and notify the sender.
Views expressed in this message are those of the individual sender, and are not necessarily the views of the NSW Ministry of Health.
_______________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
_______________________________________________________________________________________________________

From drjimlemon at gmail.com  Mon Feb  8 23:42:05 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 9 Feb 2016 09:42:05 +1100
Subject: [R] readline is not working
In-Reply-To: <f97ef51205ac42989b51487fb4d26f6c@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <f97ef51205ac42989b51487fb4d26f6c@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <CA+8X3fUyOZ-zdcTKznjg17xV40Zt1DKKStFdSxya7APF0Z73ig@mail.gmail.com>

Hi Jean,
Many laptops perform complicated workarounds to accommodate the virtual
keypads on the keyboard. Sometimes a sticky shift key (e.g. NumLock, Caps
Lock) will mess up keyboard entry if it is on. Just a wild guess.

Jim


On Mon, Feb 8, 2016 at 7:16 PM, MAURICE Jean - externe <
jean-externe.maurice at edf.fr> wrote:

> HI,
> I am new to R and English is not my natural language.
>
> I work on 4 laptops that are supposed to be the same. Win7-64. R version
> 3.1.0. I can use readline to enter a value from keyboard on three of them
> but not on the fourth : R doesn't stop on the readline instruction and acts
> as if the response was 'enter' and I think that the cursor 'disappears' .
>
> What can I look for ? environment variable, GUI preferences, ... ?
>
> Thanks in advance for your answers ...
> Jean in France
>
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations qui y
> figurent sont strictement confidentielles. Toute utilisation de ce Message
> non conforme ? sa destination, toute diffusion ou toute publication totale
> ou partielle, est interdite sauf autorisation expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de
> le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou
> partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de
> votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace
> sur quelque support que ce soit. Nous vous remercions ?galement d'en
> avertir imm?diatement l'exp?diteur par retour du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute
> erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely for
> the addressees. The information contained in this Message is confidential.
> Any use of information contained in this Message not in accord with its
> purpose, any dissemination or disclosure, either whole or partial, is
> prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or use
> any part of it. If you have received this message in error, please delete
> it and all copies from your system and notify the sender immediately by
> return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Tue Feb  9 04:17:57 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Mon, 8 Feb 2016 21:17:57 -0600
Subject: [R] calling plot
Message-ID: <56B95A65.8010009@effectivedefense.org>

I'm getting an interesting error:


 > plotxy <- function(x, ...){
+   plot(x, ...)
+ }
 > XY <- data.frame(x1=1:3, y1=4:6)
 > plotxy(y1~x1, XY, xlim=c(0, max(x1)))
  Show Traceback

  Rerun with Debug
  Error in eval(expr, envir, enclos) : object 'x1' not found


       The following work:


plotxy(y1~x1, XY)
plot(y1~x1, XY, xlim=c(0, max(x1)))


       Within "plotxy", R can't find "x1" to compute "xlim".  Is there a 
way I can make x1 available to xlim?


       Thanks,
       Spencer


From jdnewmil at dcn.davis.ca.us  Tue Feb  9 04:52:17 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Feb 2016 19:52:17 -0800
Subject: [R] calling plot
In-Reply-To: <56B95A65.8010009@effectivedefense.org>
References: <56B95A65.8010009@effectivedefense.org>
Message-ID: <1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>

plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))
-- 
Sent from my phone. Please excuse my brevity.

On February 8, 2016 7:17:57 PM PST, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>I'm getting an interesting error:
>
>
> > plotxy <- function(x, ...){
>+   plot(x, ...)
>+ }
> > XY <- data.frame(x1=1:3, y1=4:6)
> > plotxy(y1~x1, XY, xlim=c(0, max(x1)))
>  Show Traceback
>
>  Rerun with Debug
>  Error in eval(expr, envir, enclos) : object 'x1' not found
>
>
>       The following work:
>
>
>plotxy(y1~x1, XY)
>plot(y1~x1, XY, xlim=c(0, max(x1)))
>
>
>     Within "plotxy", R can't find "x1" to compute "xlim".  Is there a 
>way I can make x1 available to xlim?
>
>
>       Thanks,
>       Spencer
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Tue Feb  9 05:10:18 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Mon, 8 Feb 2016 22:10:18 -0600
Subject: [R] calling plot
In-Reply-To: <1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
References: <56B95A65.8010009@effectivedefense.org>
	<1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
Message-ID: <56B966AA.8060809@effectivedefense.org>

Hi, Jeff et al.:


On 2/8/2016 9:52 PM, Jeff Newmiller wrote:
> plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))


       Yes, Thanks.


       Is there a way to do this from within "plotxy", so I can call 
"plotxy" as I call "plot"?


       Thanks,
       Spencer


> -- 
> Sent from my phone. Please excuse my brevity.
>
> On February 8, 2016 7:17:57 PM PST, Spencer Graves 
> <spencer.graves at effectivedefense.org> wrote:
>
>     I'm getting an interesting error:
>
>
>         plotxy <- function(x, ...){ 
>
>     +   plot(x, ...)
>     + }
>
>         XY <- data.frame(x1=1:3, y1=4:6) plotxy(y1~x1, XY, xlim=c(0,
>         max(x1))) 
>
>        Show Traceback
>
>        Rerun with Debug
>        Error in eval(expr, envir, enclos) : object 'x1' not found
>
>
>             The following work:
>
>
>     plotxy(y1~x1, XY)
>     plot(y1~x1, XY, xlim=c(0, max(x1)))
>
>
>             Within "plotxy", R can't find "x1" to compute "xlim".  Is there a
>     way I can make x1 available to xlim?
>
>
>             Thanks,
>             Spencer
>
>     ------------------------------------------------------------------------
>
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jupiter.hce at gmail.com  Tue Feb  9 05:37:44 2016
From: jupiter.hce at gmail.com (jupiter)
Date: Tue, 9 Feb 2016 15:37:44 +1100
Subject: [R] [FORGED] Plot step function
In-Reply-To: <525F75F3-AA30-438E-9C28-8BD294E80534@dcn.davis.ca.us>
References: <CAA=hcWTe4AHY43JcyVqF9pf7X9Cpz9zQNTyLasuzhZdtHcLzRQ@mail.gmail.com>
	<56B63B93.3030303@auckland.ac.nz>
	<CAA=hcWQX9or8TSyRVnCvBwPErqksMC2hm7Uatua6xh2bHKVcBA@mail.gmail.com>
	<CA+8X3fXjsUDxjBMa4Zig63wzMdDcmS=+wjSNboZ+tNZiFuxUfw@mail.gmail.com>
	<CAA=hcWR3aPfBrFMR1EedXv4+WBGUqqqmrr9stuoLHo2K5uY5vQ@mail.gmail.com>
	<525F75F3-AA30-438E-9C28-8BD294E80534@dcn.davis.ca.us>
Message-ID: <CAA=hcWTAVADWTb593ph=74H5voNa=phM3C3S0=mKcBqAUYUCBw@mail.gmail.com>

Thanks Jeff, I've already added color and lwd to make it visible. I know it
is not the optimal thing to do, but I was required.

Cheers.

On Tue, Feb 9, 2016 at 3:11 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> R by default puts the axes at the edge of the plot, not at x=0 and y=0,
> for the reason that doing otherwise makes the plot harder to read. To see
> this, consider:
>
> plot( c( -4, 0, 4 ), c( 0, 1, 1 ), type="s", xlab="x", ylab="y",
> axes=FALSE, xlim=c( -5, 5 ), ylim=c( -2, 2 ), lwd=2 )
> axis( side=1, at=seq( -4, 4, 1 ), pos=0 )
> axis( side=2, at=seq( -2, 2, 1 ), pos=0 )
>
> You should read the help pages
> ?plot.default
> ?axis
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 7, 2016 2:54:48 PM PST, jupiter <jupiter.hce at gmail.com> wrote:
>
>> Thanks Jim, that was I did to generate graphic from
>> plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y"), it displayed [-4, -2,
>> 0, 2, 4] in X, I tried to twist it, but could not get [-4, -3, -2, -1, 0,
>> 1, 2, 3, 4] in X. Also, that the y 0.0 is above the X axis.
>>
>> I guess I try to figure out if, in general, there are parameters to define
>> ?x (i.e ?x= 1), and to define [0, 0.0] at the joint of x axis and y axis.
>> But never mind, if it is too much to ask :-).
>>
>> Thank you and greatly appreciate kind responses.
>>
>> - j
>>
>>
>>
>> On Mon, Feb 8, 2016 at 8:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>  Hail Jupiter,
>>>  Might a slight alteration of Rolf's suggestion do the trick?
>>>
>>>   plot(c(-4,0,4),c(0,1,1),type="s",xlab="x",ylab="y")
>>>
>>>  Jim
>>>
>>>  On
>>> Sun, Feb 7, 2016 at 8:49 AM, jupiter <jupiter.hce at gmail.com> wrote:
>>>
>>>  Thank you for the all response, how can the point y (0.0) on the same x
>>>>  axis, and X increases 1 between [-4, 4]?
>>>>
>>>>  On Sun, Feb 7, 2016 at 5:29 AM, Rolf Turner <r.turner at auckland.ac.nz>
>>>>  wrote:
>>>>
>>>>  On 07/02/16 01:11, jupiter wrote:
>>>>>
>>>>>  Hi,
>>>>>>
>>>>>>  I am just starting to learn R, sorry for asking a simple question. How
>>>>>>
>>>>>  can
>>>>
>>>>>  plot a line x <= 0 y = 0, x > 0 y = 1?
>>>>>
>>>>>
>>>>>
>>>>>  One way:
>>>>>
>>>>>      plot(c(-1,0,1),c(0,1,1),type="s",xlab="x",ylab="y")
>>>>>
>>>>>  cheers,
>>>>>
>>>>>  Rolf Turner
>>>>>
>>>>>  --
>>>>>  Technical Editor ANZJS
>>>>>  Department of Statistics
>>>>>  University of Auckland
>>>>>  Phone: +64-9-373-7599 ext. 88276
>>>>
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ------------------------------
>>>>
>>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>  PLEASE do read the posting guide
>>>>  http://www.R-project.org/posting-guide.html
>>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From kcarr2001 at gmail.com  Mon Feb  8 23:45:38 2016
From: kcarr2001 at gmail.com (Kristin Bornstein)
Date: Mon, 8 Feb 2016 17:45:38 -0500
Subject: [R]  Markovchain and Sensitivity analysis
Message-ID: <CAGmi8TtU3xT1L_m6RZ1NFCYSdJV_6FmsOVckUN4Si-ZuhpVJHQ@mail.gmail.com>

I'm trying to develop a markov chain transition matrix to simulate an
infectious disease model.  I've got a much larger matrix that I'm working
with but here's the code for a toy version of the model:

library("markovchain")
byRow <- TRUE
#Parameters
pop <- 1000
b1 <- 0.0000095
b2 <- 0.0000048
b3 <- 0.0000097
u1 <- 0.046
u2 <- 0.05
c <- 0.91
cf <- 0.25
e <- 0.1014
vb <- b3*e
s1s2 <- 1-b1-u1
s2s3 <- 1-b2-c-u2
s3e <- 1-b3
ir <- 1-cf
ve <- 1-vb
toyModel <- new("markovchain", states = c("birth", "Susceptible1",
"Susceptible2", "Susceptible3", "Infected", "Vaccinated", "Recovered",
"Exit"),
transitionMatrix = matrix(data = c(1, (pop*0.024), 0, 0, 0, 0, 0,
-(pop*0.024),
0, 0, s1s2, 0, b1, 0, 0, u1,
0, 0, 0, s2s3, b2, c, 0, u2,
0, 0, 0, 0, b3, 0, 0, s3e,
0, 0, 0, 0, 0, 0, ir, cf,
0, 0, 0, 0, vb, 0, 0, ve,
0, 0, 0, 0, 0, 0, 0.5, 0.5,
0, 0, 0, 0, 0, 0, 0, 1), byrow = byRow, nrow = 8),
name = "Toy")
initial <- c(1, 0, 0, 0, 0, 0, 0, 0)
after100 <- initial * (toyModel^ 100)


The issue is that the current variable values are based on point estimates,
and I'd like to run some sensitivity and distribution analyses on
confidence interval values I have for each parameter.  Does anyone know a
good approach to use to do this or have any experience using Latin
Hypercube Sampling (LHS package) or partial correlation coefficients
(sensitivity package) to do this?
Thanks in advance!

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Tue Feb  9 07:18:23 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Tue, 9 Feb 2016 11:48:23 +0530
Subject: [R] XGBoost continuos outcome case --- reg:linear in R
Message-ID: <B72D0EAB-6B07-41F6-8306-536663EB9023@gmail.com>

Hi,
While learning how to implement XGBoost in R I came across below case and want to know how to go about it.

Outcome variable: continous
independent features: mix of categorical and continuous 
nrow(train_set): 8523

Since, XGBoost natively supports only numeric features, I applied one hot encoding on the training data set:

target <- train_set$Outlet_sales
sparsed_train_set <- sparse.model.matrix(~.-1, data=train_set)

nrow(sparsed_train_set) : 4526 #As expected, the row count is reduced.

Note: The target variable is continuous and has as many rows as in train_set i.e 8523, before one hot encoding is applied.

# To build mode:
bst <- xgboost(data = sparsed_train_set, label = target, max.depth = 4,
               eta = 1, nthread = 4, nround = 50, objective=reg:linear)

# Above execution would fail as 

My questions:
- How should I handle above disparity between sparsed training data and label  while building the model ?
- How should I use XGBoost to perform regression where outcome is continuous ? Most of the web portals refers to the cases related to classification.
  If any could lead me to the source explaining this. I have gone through the documentation but not much cleared in this case.

Regards,
Sandeep S. Rana















	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Tue Feb  9 07:18:23 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Tue, 9 Feb 2016 11:48:23 +0530
Subject: [R] XGBoost continuos outcome case --- reg:linear in R
Message-ID: <B72D0EAB-6B07-41F6-8306-536663EB9023@gmail.com>

Hi,
While learning how to implement XGBoost in R I came across below case and want to know how to go about it.

Outcome variable: continous
independent features: mix of categorical and continuous 
nrow(train_set): 8523

Since, XGBoost natively supports only numeric features, I applied one hot encoding on the training data set:

target <- train_set$Outlet_sales
sparsed_train_set <- sparse.model.matrix(~.-1, data=train_set)

nrow(sparsed_train_set) : 4526 #As expected, the row count is reduced.

Note: The target variable is continuous and has as many rows as in train_set i.e 8523, before one hot encoding is applied.

# To build mode:
bst <- xgboost(data = sparsed_train_set, label = target, max.depth = 4,
               eta = 1, nthread = 4, nround = 50, objective=reg:linear)

# Above execution would fail as 

My questions:
- How should I handle above disparity between sparsed training data and label  while building the model ?
- How should I use XGBoost to perform regression where outcome is continuous ? Most of the web portals refers to the cases related to classification.
  If any could lead me to the source explaining this. I have gone through the documentation but not much cleared in this case.

Regards,
Sandeep S. Rana















	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb  9 08:58:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 8 Feb 2016 23:58:46 -0800
Subject: [R] calling plot
In-Reply-To: <56B966AA.8060809@effectivedefense.org>
References: <56B95A65.8010009@effectivedefense.org>
	<1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
	<56B966AA.8060809@effectivedefense.org>
Message-ID: <CAGxFJbThxgOva8fpJS5uLoGPVrgPCopDWoiXvEoL+Q4nUjKaMQ@mail.gmail.com>

Well, this may not be the most elegant, but how about:

 plotxy <- function(x,data = NULL,...) {
   mcall <- match.call()
   if(inherits(x,"formula")) enc <- environment(x)
    else enc <- parent.frame()
   if(!is.null(data)){
        env <- data
        mcall <- mcall[-match("data",names(mcall))]
   } else env <- NULL
   mcall[[1]] <- plot.default
   eval(mcall,envir=env,enclos=enc)
}

Cheers,
Bert

P.S. I would welcome more elegant solutions (especially if this one
doesn't work right!)
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 8, 2016 at 8:10 PM, Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
> Hi, Jeff et al.:
>
>
> On 2/8/2016 9:52 PM, Jeff Newmiller wrote:
>> plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))
>
>
>        Yes, Thanks.
>
>
>        Is there a way to do this from within "plotxy", so I can call
> "plotxy" as I call "plot"?
>
>
>        Thanks,
>        Spencer
>
>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 8, 2016 7:17:57 PM PST, Spencer Graves
>> <spencer.graves at effectivedefense.org> wrote:
>>
>>     I'm getting an interesting error:
>>
>>
>>         plotxy <- function(x, ...){
>>
>>     +   plot(x, ...)
>>     + }
>>
>>         XY <- data.frame(x1=1:3, y1=4:6) plotxy(y1~x1, XY, xlim=c(0,
>>         max(x1)))
>>
>>        Show Traceback
>>
>>        Rerun with Debug
>>        Error in eval(expr, envir, enclos) : object 'x1' not found
>>
>>
>>             The following work:
>>
>>
>>     plotxy(y1~x1, XY)
>>     plot(y1~x1, XY, xlim=c(0, max(x1)))
>>
>>
>>             Within "plotxy", R can't find "x1" to compute "xlim".  Is there a
>>     way I can make x1 available to xlim?
>>
>>
>>             Thanks,
>>             Spencer
>>
>>     ------------------------------------------------------------------------
>>
>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Tue Feb  9 09:23:15 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 9 Feb 2016 09:23:15 +0100
Subject: [R] syntax for nested random factors in lme
In-Reply-To: <CA+G7zRi8DYKrfFxtcWXEUVrfjqARPTfPE9ncHKFZJDBb52SHNA@mail.gmail.com>
References: <CA+G7zRi8DYKrfFxtcWXEUVrfjqARPTfPE9ncHKFZJDBb52SHNA@mail.gmail.com>
Message-ID: <CAJuCY5xU=px5KCDYjWqEkkZyq5wv0teetwrv9qLtj1BfZJRdKw@mail.gmail.com>

Dear Kathleen,

R sig mixed models is more suited for questions on mixed models.

It doesn't make sense to add the main effect of B to both the fixed and the
random. Use me(x~y+B,random=~1|B:A) instead. 1|B:A is the interaction
between B and A. Since B is in the fixed effects, it is equivalent to A
nested in B.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-02-08 19:41 GMT+01:00 Kathleen C?t? <kathleen.cote at gmail.com>:

> Hi,
>
> I've been taught that if I want to nest random factor A into B in an lme
> model, the syntax is as follows: lme(x~y+B,random=~1|B/A).
>
> In the case of my data, matters seem to be complicated by the fact that B
> is a categorical variable with only 2 levels. When I run the lme with the
> above syntax, I obtain an NaN p value for B as a fixed factor in the
> model. When
> I rewrite the random factor as random=~1|A/B, I obtain a p value.
>
> Is the correct format for a nested random factor indeed B/A in this case?
> Is it incorrect to write it as A/B?
>
> Please let me know if you would like additional information, such as
> observations and output.
>
> Kathleen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Tue Feb  9 14:01:51 2016
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 9 Feb 2016 15:01:51 +0200
Subject: [R] missing value where TRUE/FALSE needed ERROR
Message-ID: <CAPLSCn2qiPndqHBY7eSy7HvLm7gzpu+6jeH+D2y1+3Rk02dUbw@mail.gmail.com>

Hi all,

I'm trying to write a function to implement a Metropolis-within-Gibbs
algorithm for two parameters.I'm including a naive version here so as to be
able to spot the error I got. So I first generate the vectors, X and R,
that will help to start the algorithm using (for example):

n=8; m=5; p=0.1; t=0.9 ; JH=10;

R <- numeric(m)

W <- numeric(m)

V <- numeric(m)

U <- numeric(m)

X <- numeric(m)

Bay.alpha<- numeric (JH)

Bay.beta<- numeric (JH)

Bay.Surv <- numeric (JH)

hyp=c(3,15,6,22.5)

theta<-c(0.2,2)


alpha.curr<-theta[1]

beta.curr<- theta[2]



R[1]<-rbinom(1, n-m, p)

 for (i in 2:m-1) {

 R[i]<-rbinom(1,n-m-sum(R[1:i-1]),p)

 }

 R[m]<-n-m-sum(R[1:m-1])

W<-runif(m, min = 0, max = 1)

for (i in 1:m){

 V[i]<-W[i]^(1/(i+sum(R[(m-i+1):m])))

}

for (i in 1:m){

 U[i]<- 1- prod(V[(m-i+1):m])

}

for (i in 1:m){

X[i]<- ((-1/theta[1])*log(1-U[i]))^(1/theta[2])

}


Then, I defined three functions 1- alpha.update() for updating alpha (Gibbs
step) 2- bettarg(), for the target distribution of beta 3- beta.update()
for updating beta using a Metropolis Hastings technique.


   alpha.update=function(X, R, alpha.curr, beta.curr ,m, hyp)

  {

  o<-numeric(m)

     for (i in 1:m) {

       o[i]<- (1+R[i])*((X[i])^(beta.curr))

        }

   sh<-sum(o) + hyp[2] + (hyp[4]* beta.curr)

   rg<-rgamma(1, shape= m+hyp[1]+hyp[3] , rate = sh )

   return(rg)

   }



   bettarg<- function(X, R, alpha.curr, beta.curr ,m, hyp)

       {

           o<-numeric(m)

           for (i in 1:m) {

       o[i]<- (1+R[i])*((X[i])^( beta.curr))

        }

      bt<- beta.curr ^(m+hyp[3]-1) * prod((X)^( beta.curr -1)) *
exp(-1*alpha.curr *(sum(o) +      (hyp[4]* beta.curr)))

    return(bt)

       }

       beta.update<- function (X, R, alpha.curr, beta.curr ,m, hyp, cand.sd)

       {

       beta.cand<- rnorm(1, mean = beta.curr, sd = cand.sd)

      AB<- bettarg (X, R, alpha.curr, beta.curr = beta.cand ,m, hyp)

      CD<- bettarg (X, R, alpha.curr, beta.curr ,m, hyp)

      accept.prob <- AB/CD

     if (runif(1) <= accept.prob)

     beta.cand

    else  beta.curr

     }


Then I started a tiny chain using ten iterations but got this ERROR:


for (k in 1:JH)

{

alpha.curr<- alpha.update(X, R, alpha.curr, beta.curr ,m, hyp)

 Bay.alpha[k]<-alpha.curr

beta.curr<- beta.update (X, R, alpha.curr, beta.curr ,m, hyp, cand.sd=2)

     Bay.beta[k]<- beta.curr

     Bay.Surv [k]<- exp (-1*Bay.alpha[k] * (t)^Bay.beta[k])

     }


Error in if (runif(1) <= accept.prob) beta.cand else beta.curr :

  missing value where TRUE/FALSE needed

In addition: Warning message:

In rgamma(1, shape = m + hyp[1] + hyp[3], rate = sh) : NAs produced


I ran the code several times for only one iteration but everything was fine
with no errors or warnings, so I don't know from where does the missing
value/ NA come from?

In addition, I want to calculate the acceptance rate for the
Metropolis-Hastings step, is this possible?

Any help would be appreciated.
Thanks,

Maram Salem

	[[alternative HTML version deleted]]


From waser at frankenfoerder-fg.de  Tue Feb  9 10:03:01 2016
From: waser at frankenfoerder-fg.de (Wolfgang Waser)
Date: Tue, 9 Feb 2016 10:03:01 +0100
Subject: [R] How to extract same columns from identical dataframes in a
 list?
In-Reply-To: <56B8C997.2010201@ttk.mta.hu>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu>
Message-ID: <56B9AB45.10603@frankenfoerder-fg.de>

Hi,

sorry if my description was too short / unclear.

> I have a list of 7 data frames, each data frame having 24 rows (hour of
> the day) and 5 columns (weeks) with a total of 5 x 24 values

[1]
	week1	week2	week3	...
1	x	a	m	...
2	y	b	n
3	z	c	o
.	.	.	.
.	.	.	.
.	.	.	.
24	.	.	.


[2]
	week1 week2 week3 ...
1	x2	a2	m2	...
2	y2	b2	n2
3	z2	c2	o2
.	.	.	.
.	.	.	.
.	.	.	.
24	.	.	.


[3]
...

.
.
.


[7]
...



I now would like to extract e.g. all week2 columns of all data frames in
the list and combine them in a new data frame using cbind.

new data frame

week2 ([1])	week2 ([2])	week2 ([3])	...
a		a2		.
b		b2		.
c		c2		.
.
.
.

I will then do further row-wise calculations using e.g. apply(x,1,mean),
the result being a vector of 24 values.


I have not found a way to extract specific columns of the data frames in
a list.


As mentioned I can use

sapply(list_of_dataframes,"[",1:24)

which will pick the first 24 values (first column) of each data frame in
the list and arrange them as an array of 24 rows and 7 columns (7 data
frames are in the list).
To pick the second column (week2) using sapply I have to use the next 24
values from 25 to 48:

sapply(list_of_dataframes,"[",25:48)


It seems that sapply treats the data frames in the list as vectors. I
can of course extract all consecutive weeks using consecutive blocks of
24 values, but this seems cumbersome.


The question remains, how to select specific columns from data frames in
a list, e.g. all columns 3 of all data frames in the list.


Reformatting (unlist(), dim()) in one data frame with one column for
each week does not help, since I'm not calculating colMeans etc, but
row-wise calculations using apply(x,1,FUN) ("applying a function to
margins of an array or matrix").



Thanks for you help and suggestions!


Wolfgang



On 08/02/16 18:00, D?nes T?th wrote:
> Hi,
> 
> Although you did not provide any reproducible example, it seems you
> store the same type of values in your data.frames. If this is true, it
> is much more efficient to store your data in an array:
> 
> mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
>                b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
> 
> myarray <- unlist(mylist, use.names = FALSE)
> dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
> dimnames(myarray) <- list(hour = rownames(mylist$a),
>                           week = colnames(mylist$a),
>                           other = names(mylist))
> # now you can do:
> mean(myarray[, "week1", "a"])
> 
> # or:
> colMeans(myarray)
> 
> 
> Cheers,
>   Denes
> 
> 
> On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
>> Hello,
>>
>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>
>> I would like to combine all 7 columns of week 1 (and 2 ...) in a
>> separate data frame for hourly calculations, e.g.
>>> apply(new.data.frame,1,mean)
>>
>> In some way sapply (lapply) works, but I cannot directly select columns
>> of the original data frames in the list. As a workaround I have to
>> select a range of values:
>>
>>> sapply(list_of_dataframes,"[",1:24)
>>
>> Values 1:24 give the first column, 25:48 the second and so on.
>>
>> Is there an easier / more direct way to select for specific columns
>> instead of selecting a range of values, avoiding loops?
>>
>>
>> Cheers,
>>
>> Wolfgang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 

-- 
Frankenf?rder Forschungsgesellschaft mbH
Dr. Wolfgang Waser
Wissenschaftsbereich Berlin
Chausseestra?e 10
10115 Berlin
Tel.:  +49(0)30 2809 1936
Fax.:  +49(0)30 2809 1940
E-Mail: waser at frankenfoerder-fg.de

Frankenf?rder Forschungsgesellschaft mbH (FFG)
Sitz: Luckenwalde,Amtsgericht Potsdam, HRB: 6499
Gesch?ftsf?hrerin: Dipl. Agraring. Doreen Sparborth
Tel.: +49(0)30 2809 1931, E-Mail: info at frankenfoerder-fg.de
http://www.frankenfoerder-fg.de


From ashu4487 at gmail.com  Tue Feb  9 08:24:36 2016
From: ashu4487 at gmail.com (ashutosh srivastava)
Date: Tue, 9 Feb 2016 16:24:36 +0900
Subject: [R] R hangs when plot() is used
Message-ID: <CAN6ydJySNt+U5RJYNhZP+4-RotHw0oS8P-UoXkmWmWfqJhtz9w@mail.gmail.com>

Dear R users

I have compiled R from source in local user account (at non default
location). R seems to be working fine but issuing plot() command opens a
window (supposedly graph, but nothing is visible) and then R terminal also
freezes. Any suggestions?
Following is the session info output.

> sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS release 6.7 (Final)

locale:
 [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
 [4] LC_COLLATE=en_US     LC_MONETARY=en_US    LC_MESSAGES=en_US
 [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Thank you

Best
Ashutosh

	[[alternative HTML version deleted]]


From venkatesansekhar at gmail.com  Tue Feb  9 12:44:39 2016
From: venkatesansekhar at gmail.com (Sekhar Venkatesan)
Date: Tue, 9 Feb 2016 17:14:39 +0530
Subject: [R] Help required for Rcmdr
In-Reply-To: <56B8B3BA.4040306@gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
Message-ID: <CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>

Dear Mr. Murdoch,
I am extremely sorry to have sent the mail to you instead of R-help. Thanks
for directing me.
I have downloaded R 3.2.3 version. After that i asked for
install.packages("Rcmdr") . It says that Rcmdr is not available with
version 3.2.3. On looking at the pdf file for getting started with R, i
found that i should download with SDI Graphical interface which I did once
again but still i could not get the Rcmdr console.
I attended a workshop where the faculty brought out the R console as well
as the R-commander console where i could import files and also do all the
statistics easily. I am not getting the R-commander console.
Shall be grateful if i could get help on getting the R-commander console
with the user friendly way of doing the statistical operations.
Thanks and regards,
Once again apologize to Dr. Duncan Murdoch for disturbing him.
Sekhar

On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
>
>> Dear Sirs,
>> I have downloaded R 3.2.3 version from the CRAN site. I have tried to
>> download with both MDI and SDI user interface. But Rcmdr is not opening in
>> as a console  along with R console. Help is required to open Rcmdr. I have
>> tried install.packages("Rcmdr"), library(Rcmdr) etc but to no avail.
>> thanks
>> Sekhar
>> Delhi
>> India
>>
>> This is the wrong email address for help.  Please write to R-help, and
> describe what happens when you try the commands that are failing.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Feb  9 15:46:36 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 9 Feb 2016 14:46:36 +0000
Subject: [R] How to extract same columns from identical dataframes in a
 list?
In-Reply-To: <56B9AB45.10603@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu> <56B9AB45.10603@frankenfoerder-fg.de>
Message-ID: <1A8C1289955EF649A09086A153E2672403D0E32071@GBTEDVPEXCMB04.corp.lgc-group.com>

Does
do.call('cbind', list_of_dataframes)

do what you want?

S Ellison


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Wolfgang
> Waser
> Sent: 09 February 2016 09:03
> To: D?nes T?th; r-help at r-project.org
> Subject: Re: [R] How to extract same columns from identical dataframes in a
> list?
> 
> Hi,
> 
> sorry if my description was too short / unclear.
> 
> > I have a list of 7 data frames, each data frame having 24 rows (hour
> > of the day) and 5 columns (weeks) with a total of 5 x 24 values
> 
> [1]
> 	week1	week2	week3	...
> 1	x	a	m	...
> 2	y	b	n
> 3	z	c	o
> .	.	.	.
> .	.	.	.
> .	.	.	.
> 24	.	.	.
> 
> 
> [2]
> 	week1 week2 week3 ...
> 1	x2	a2	m2	...
> 2	y2	b2	n2
> 3	z2	c2	o2
> .	.	.	.
> .	.	.	.
> .	.	.	.
> 24	.	.	.
> 
> 
> [3]
> ...
> 
> .
> .
> .
> 
> 
> [7]
> ...
> 
> 
> 
> I now would like to extract e.g. all week2 columns of all data frames in the list
> and combine them in a new data frame using cbind.
> 
> new data frame
> 
> week2 ([1])	week2 ([2])	week2 ([3])	...
> a		a2		.
> b		b2		.
> c		c2		.
> .
> .
> .
> 
> I will then do further row-wise calculations using e.g. apply(x,1,mean), the
> result being a vector of 24 values.
> 
> 
> I have not found a way to extract specific columns of the data frames in a list.
> 
> 
> As mentioned I can use
> 
> sapply(list_of_dataframes,"[",1:24)
> 
> which will pick the first 24 values (first column) of each data frame in the list
> and arrange them as an array of 24 rows and 7 columns (7 data frames are in
> the list).
> To pick the second column (week2) using sapply I have to use the next 24 values
> from 25 to 48:
> 
> sapply(list_of_dataframes,"[",25:48)
> 
> 
> It seems that sapply treats the data frames in the list as vectors. I can of course
> extract all consecutive weeks using consecutive blocks of
> 24 values, but this seems cumbersome.
> 
> 
> The question remains, how to select specific columns from data frames in a list,
> e.g. all columns 3 of all data frames in the list.
> 
> 
> Reformatting (unlist(), dim()) in one data frame with one column for each week
> does not help, since I'm not calculating colMeans etc, but row-wise calculations
> using apply(x,1,FUN) ("applying a function to margins of an array or matrix").
> 
> 
> 
> Thanks for you help and suggestions!
> 
> 
> Wolfgang
> 
> 
> 
> On 08/02/16 18:00, D?nes T?th wrote:
> > Hi,
> >
> > Although you did not provide any reproducible example, it seems you
> > store the same type of values in your data.frames. If this is true, it
> > is much more efficient to store your data in an array:
> >
> > mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
> >                b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
> >
> > myarray <- unlist(mylist, use.names = FALSE)
> > dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
> > dimnames(myarray) <- list(hour = rownames(mylist$a),
> >                           week = colnames(mylist$a),
> >                           other = names(mylist)) # now you can do:
> > mean(myarray[, "week1", "a"])
> >
> > # or:
> > colMeans(myarray)
> >
> >
> > Cheers,
> >   Denes
> >
> >
> > On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
> >> Hello,
> >>
> >> I have a list of 7 data frames, each data frame having 24 rows (hour
> >> of the day) and 5 columns (weeks) with a total of 5 x 24 values
> >>
> >> I would like to combine all 7 columns of week 1 (and 2 ...) in a
> >> separate data frame for hourly calculations, e.g.
> >>> apply(new.data.frame,1,mean)
> >>
> >> In some way sapply (lapply) works, but I cannot directly select
> >> columns of the original data frames in the list. As a workaround I
> >> have to select a range of values:
> >>
> >>> sapply(list_of_dataframes,"[",1:24)
> >>
> >> Values 1:24 give the first column, 25:48 the second and so on.
> >>
> >> Is there an easier / more direct way to select for specific columns
> >> instead of selecting a range of values, avoiding loops?
> >>
> >>
> >> Cheers,
> >>
> >> Wolfgang
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> 
> --
> Frankenf?rder Forschungsgesellschaft mbH Dr. Wolfgang Waser
> Wissenschaftsbereich Berlin Chausseestra?e 10
> 10115 Berlin
> Tel.:  +49(0)30 2809 1936
> Fax.:  +49(0)30 2809 1940
> E-Mail: waser at frankenfoerder-fg.de
> 
> Frankenf?rder Forschungsgesellschaft mbH (FFG)
> Sitz: Luckenwalde,Amtsgericht Potsdam, HRB: 6499
> Gesch?ftsf?hrerin: Dipl. Agraring. Doreen Sparborth
> Tel.: +49(0)30 2809 1931, E-Mail: info at frankenfoerder-fg.de
> http://webdefence.global.blackspider.com/urlwrap/?q=AXicJcrBCsIwDADQgHfB
> DzFbEUU97bKh_-CldGkdZslIO4t_L-
> g7v90Gtg7gcQMw_rTOY7Y3zn7ioFJMGYPOsLpLf0-
> DtO5wOh8hIzFPWaXjFJLpuvzWs5Tl2jS1Vozm5UUSlWwk28eEI8HfF6ucIuc&Z
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ulrik.stervbo at gmail.com  Tue Feb  9 15:49:03 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 09 Feb 2016 14:49:03 +0000
Subject: [R] How to extract same columns from identical dataframes in a
	list?
In-Reply-To: <56B9AB45.10603@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu> <56B9AB45.10603@frankenfoerder-fg.de>
Message-ID: <CAKVAULNVek3z7fjyssnW3Xg2VziOyr+8EWLkD+HZmKcpQvr=0g@mail.gmail.com>

Hi Wolfgang,

If you use cbind in the do.call you get something close to what you want.
You can then use grep to get just the columns you are interested in (I
assume they all have the same name in the original data.frames)

dfa <- data.frame(cola = c(6:10), colb = c(1:5), colc = c(11:15))
dfb <- data.frame(cola = c(6:10), colb = c(1:5), colc = c(11:15))

df.lst <- list(dfa.name = dfa, dfb.name = dfb)

# Bind together
all.df <- do.call(cbind, df.lst)
colnames(all.df)
# Get just those with colb in the column name
all.df <- all.df[, grep("colb", colnames(all.df))]
# And calculate the means
rowMeans(all.df)

This also works if you want to use more then one column
all.df <- do.call(cbind, df.lst)
all.df <- all.df[, grep("colb|colc", colnames(all.df))]
rowMeans(all.df)

You can still use plyr:
library(plyr)

all.df <- ldply(df.lst, function(cur.df){return(cur.df$colb)}, .id =
"org.df")
all.df$org.df <- NULL
colMeans(all.df)

but if you want to extract more then one column form each data.frame it be
comes a little tricky.

HTH
Ulrik

On Tue, 9 Feb 2016 at 15:18 Wolfgang Waser <waser at frankenfoerder-fg.de>
wrote:

> Hi,
>
> sorry if my description was too short / unclear.
>
> > I have a list of 7 data frames, each data frame having 24 rows (hour of
> > the day) and 5 columns (weeks) with a total of 5 x 24 values
>
> [1]
>         week1   week2   week3   ...
> 1       x       a       m       ...
> 2       y       b       n
> 3       z       c       o
> .       .       .       .
> .       .       .       .
> .       .       .       .
> 24      .       .       .
>
>
> [2]
>         week1 week2 week3 ...
> 1       x2      a2      m2      ...
> 2       y2      b2      n2
> 3       z2      c2      o2
> .       .       .       .
> .       .       .       .
> .       .       .       .
> 24      .       .       .
>
>
> [3]
> ...
>
> .
> .
> .
>
>
> [7]
> ...
>
>
>
> I now would like to extract e.g. all week2 columns of all data frames in
> the list and combine them in a new data frame using cbind.
>
> new data frame
>
> week2 ([1])     week2 ([2])     week2 ([3])     ...
> a               a2              .
> b               b2              .
> c               c2              .
> .
> .
> .
>
> I will then do further row-wise calculations using e.g. apply(x,1,mean),
> the result being a vector of 24 values.
>
>
> I have not found a way to extract specific columns of the data frames in
> a list.
>
>
> As mentioned I can use
>
> sapply(list_of_dataframes,"[",1:24)
>
> which will pick the first 24 values (first column) of each data frame in
> the list and arrange them as an array of 24 rows and 7 columns (7 data
> frames are in the list).
> To pick the second column (week2) using sapply I have to use the next 24
> values from 25 to 48:
>
> sapply(list_of_dataframes,"[",25:48)
>
>
> It seems that sapply treats the data frames in the list as vectors. I
> can of course extract all consecutive weeks using consecutive blocks of
> 24 values, but this seems cumbersome.
>
>
> The question remains, how to select specific columns from data frames in
> a list, e.g. all columns 3 of all data frames in the list.
>
>
> Reformatting (unlist(), dim()) in one data frame with one column for
> each week does not help, since I'm not calculating colMeans etc, but
> row-wise calculations using apply(x,1,FUN) ("applying a function to
> margins of an array or matrix").
>
>
>
> Thanks for you help and suggestions!
>
>
> Wolfgang
>
>
>
> On 08/02/16 18:00, D?nes T?th wrote:
> > Hi,
> >
> > Although you did not provide any reproducible example, it seems you
> > store the same type of values in your data.frames. If this is true, it
> > is much more efficient to store your data in an array:
> >
> > mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
> >                b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
> >
> > myarray <- unlist(mylist, use.names = FALSE)
> > dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
> > dimnames(myarray) <- list(hour = rownames(mylist$a),
> >                           week = colnames(mylist$a),
> >                           other = names(mylist))
> > # now you can do:
> > mean(myarray[, "week1", "a"])
> >
> > # or:
> > colMeans(myarray)
> >
> >
> > Cheers,
> >   Denes
> >
> >
> > On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
> >> Hello,
> >>
> >> I have a list of 7 data frames, each data frame having 24 rows (hour of
> >> the day) and 5 columns (weeks) with a total of 5 x 24 values
> >>
> >> I would like to combine all 7 columns of week 1 (and 2 ...) in a
> >> separate data frame for hourly calculations, e.g.
> >>> apply(new.data.frame,1,mean)
> >>
> >> In some way sapply (lapply) works, but I cannot directly select columns
> >> of the original data frames in the list. As a workaround I have to
> >> select a range of values:
> >>
> >>> sapply(list_of_dataframes,"[",1:24)
> >>
> >> Values 1:24 give the first column, 25:48 the second and so on.
> >>
> >> Is there an easier / more direct way to select for specific columns
> >> instead of selecting a range of values, avoiding loops?
> >>
> >>
> >> Cheers,
> >>
> >> Wolfgang
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> --
> Frankenf?rder Forschungsgesellschaft mbH
> Dr. Wolfgang Waser
> Wissenschaftsbereich Berlin
> Chausseestra?e 10
> 10115 Berlin
> Tel.:  +49(0)30 2809 1936
> Fax.:  +49(0)30 2809 1940
> E-Mail: waser at frankenfoerder-fg.de
>
> Frankenf?rder Forschungsgesellschaft mbH (FFG)
> Sitz: Luckenwalde,Amtsgericht Potsdam, HRB: 6499
> Gesch?ftsf?hrerin: Dipl. Agraring. Doreen Sparborth
> Tel.: +49(0)30 2809 1931, E-Mail: info at frankenfoerder-fg.de
> http://www.frankenfoerder-fg.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Feb  9 16:01:09 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 9 Feb 2016 15:01:09 +0000
Subject: [R] pearson correlation matrix
In-Reply-To: <56B4D78D.7000804@nancy.inra.fr>
References: <56B4AC75.5020506@nancy.inra.fr>
	<56B4B255.7000406@dewey.myzen.co.uk> <56B4D78D.7000804@nancy.inra.fr>
Message-ID: <1A8C1289955EF649A09086A153E2672403D0E32082@GBTEDVPEXCMB04.corp.lgc-group.com>

> -----Original Message-----
> > Assuming your dataset is in a matrix you want to transpose it. So you
> > can go t(mesdonnees) and then call cor on that.
> 
> ok, it will still make sense ?

If the idea does not make sense before you do it, it probably won't make more sense afterwards ...

But you'll have a correlation matrix by individual, and that will show you pairs of individuals whose measures on the different variables tend to correlate more or less strongly. I can't help a suspicion that something like PCA might help more than a raw correlation matrix, if you want to see how closely individuals are associated, but correlation is a possible step on the way.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From marammagdysalem at gmail.com  Tue Feb  9 16:03:24 2016
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 9 Feb 2016 17:03:24 +0200
Subject: [R] missing value where TRUE/FALSE needed ERROR
In-Reply-To: <CABLo8nFE+-GZVWQrQBR9HRTYygxxmmMmViV6voRRuoTs4SPLXg@mail.gmail.com>
References: <CAPLSCn2qiPndqHBY7eSy7HvLm7gzpu+6jeH+D2y1+3Rk02dUbw@mail.gmail.com>
	<CABLo8nFE+-GZVWQrQBR9HRTYygxxmmMmViV6voRRuoTs4SPLXg@mail.gmail.com>
Message-ID: <CAPLSCn1WrP2EhswASV09u4m2hpdbTG62_83pM-ZZHmLrhmwMTw@mail.gmail.com>

Thanks for helping thanoon.
 I used the if()  {
                     ....
                      } else {
                           .....
                                }
and it worked better

On 9 February 2016 at 15:56, thanoon younis <thanoon.younis80 at gmail.com>
wrote:

> Hi,
>
> Try to check the function only
> if (runif(1) <= accept.prob) beta.cand else beta.curr
> something is missing here. Why you take only runif(1).
>
> Regards
>
> On 9 February 2016 at 16:01, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I'm trying to write a function to implement a Metropolis-within-Gibbs
>> algorithm for two parameters.I'm including a naive version here so as to
>> be
>> able to spot the error I got. So I first generate the vectors, X and R,
>> that will help to start the algorithm using (for example):
>>
>> n=8; m=5; p=0.1; t=0.9 ; JH=10;
>>
>> R <- numeric(m)
>>
>> W <- numeric(m)
>>
>> V <- numeric(m)
>>
>> U <- numeric(m)
>>
>> X <- numeric(m)
>>
>> Bay.alpha<- numeric (JH)
>>
>> Bay.beta<- numeric (JH)
>>
>> Bay.Surv <- numeric (JH)
>>
>> hyp=c(3,15,6,22.5)
>>
>> theta<-c(0.2,2)
>>
>>
>> alpha.curr<-theta[1]
>>
>> beta.curr<- theta[2]
>>
>>
>>
>> R[1]<-rbinom(1, n-m, p)
>>
>>  for (i in 2:m-1) {
>>
>>  R[i]<-rbinom(1,n-m-sum(R[1:i-1]),p)
>>
>>  }
>>
>>  R[m]<-n-m-sum(R[1:m-1])
>>
>> W<-runif(m, min = 0, max = 1)
>>
>> for (i in 1:m){
>>
>>  V[i]<-W[i]^(1/(i+sum(R[(m-i+1):m])))
>>
>> }
>>
>> for (i in 1:m){
>>
>>  U[i]<- 1- prod(V[(m-i+1):m])
>>
>> }
>>
>> for (i in 1:m){
>>
>> X[i]<- ((-1/theta[1])*log(1-U[i]))^(1/theta[2])
>>
>> }
>>
>>
>> Then, I defined three functions 1- alpha.update() for updating alpha
>> (Gibbs
>> step) 2- bettarg(), for the target distribution of beta 3- beta.update()
>> for updating beta using a Metropolis Hastings technique.
>>
>>
>>    alpha.update=function(X, R, alpha.curr, beta.curr ,m, hyp)
>>
>>   {
>>
>>   o<-numeric(m)
>>
>>      for (i in 1:m) {
>>
>>        o[i]<- (1+R[i])*((X[i])^(beta.curr))
>>
>>         }
>>
>>    sh<-sum(o) + hyp[2] + (hyp[4]* beta.curr)
>>
>>    rg<-rgamma(1, shape= m+hyp[1]+hyp[3] , rate = sh )
>>
>>    return(rg)
>>
>>    }
>>
>>
>>
>>    bettarg<- function(X, R, alpha.curr, beta.curr ,m, hyp)
>>
>>        {
>>
>>            o<-numeric(m)
>>
>>            for (i in 1:m) {
>>
>>        o[i]<- (1+R[i])*((X[i])^( beta.curr))
>>
>>         }
>>
>>       bt<- beta.curr ^(m+hyp[3]-1) * prod((X)^( beta.curr -1)) *
>> exp(-1*alpha.curr *(sum(o) +      (hyp[4]* beta.curr)))
>>
>>     return(bt)
>>
>>        }
>>
>>        beta.update<- function (X, R, alpha.curr, beta.curr ,m, hyp,
>> cand.sd)
>>
>>        {
>>
>>        beta.cand<- rnorm(1, mean = beta.curr, sd = cand.sd)
>>
>>       AB<- bettarg (X, R, alpha.curr, beta.curr = beta.cand ,m, hyp)
>>
>>       CD<- bettarg (X, R, alpha.curr, beta.curr ,m, hyp)
>>
>>       accept.prob <- AB/CD
>>
>>      if (runif(1) <= accept.prob)
>>
>>      beta.cand
>>
>>     else  beta.curr
>>
>>      }
>>
>>
>> Then I started a tiny chain using ten iterations but got this ERROR:
>>
>>
>> for (k in 1:JH)
>>
>> {
>>
>> alpha.curr<- alpha.update(X, R, alpha.curr, beta.curr ,m, hyp)
>>
>>  Bay.alpha[k]<-alpha.curr
>>
>> beta.curr<- beta.update (X, R, alpha.curr, beta.curr ,m, hyp, cand.sd=2)
>>
>>      Bay.beta[k]<- beta.curr
>>
>>      Bay.Surv [k]<- exp (-1*Bay.alpha[k] * (t)^Bay.beta[k])
>>
>>      }
>>
>>
>> Error in if (runif(1) <= accept.prob) beta.cand else beta.curr :
>>
>>   missing value where TRUE/FALSE needed
>>
>> In addition: Warning message:
>>
>> In rgamma(1, shape = m + hyp[1] + hyp[3], rate = sh) : NAs produced
>>
>>
>> I ran the code several times for only one iteration but everything was
>> fine
>> with no errors or warnings, so I don't know from where does the missing
>> value/ NA come from?
>>
>> In addition, I want to calculate the acceptance rate for the
>> Metropolis-Hastings step, is this possible?
>>
>> Any help would be appreciated.
>> Thanks,
>>
>> Maram Salem
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Feb  9 16:05:57 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 09 Feb 2016 07:05:57 -0800
Subject: [R] R hangs when plot() is used
In-Reply-To: <CAN6ydJySNt+U5RJYNhZP+4-RotHw0oS8P-UoXkmWmWfqJhtz9w@mail.gmail.com>
References: <CAN6ydJySNt+U5RJYNhZP+4-RotHw0oS8P-UoXkmWmWfqJhtz9w@mail.gmail.com>
Message-ID: <23355DFA-00BE-482F-8134-BE85CB1B319E@dcn.davis.ca.us>

Read the Posting Guide... you are in the wrong forum. 
-- 
Sent from my phone. Please excuse my brevity.

On February 8, 2016 11:24:36 PM PST, ashutosh srivastava <ashu4487 at gmail.com> wrote:
>Dear R users
>
>I have compiled R from source in local user account (at non default
>location). R seems to be working fine but issuing plot() command opens
>a
>window (supposedly graph, but nothing is visible) and then R terminal
>also
>freezes. Any suggestions?
>Following is the session info output.
>
>> sessionInfo()
>R version 3.2.3 (2015-12-10)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: CentOS release 6.7 (Final)
>
>locale:
> [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
> [4] LC_COLLATE=en_US     LC_MONETARY=en_US    LC_MESSAGES=en_US
> [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
>[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>Thank you
>
>Best
>Ashutosh
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From vito.muggeo at unipa.it  Tue Feb  9 16:15:52 2016
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Tue, 9 Feb 2016 16:15:52 +0100
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
Message-ID: <56BA02A8.2070608@unipa.it>

dear all,
I don't know if that problem is related to the Rcmdr package itself..
(Sekhar try to install any other packages..)

I am experiencing the same problem, in that when typing

 > install.packages("_ANY_PACKAGE_")

I get the message
Warning message:
package ?_ANY_PACKAGE_? is not available (for R version 3.2.3)

But I can download the .zip file and unzip it..

I tried different CRAN mirrors...

best,
vito


Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> Dear Mr. Murdoch,
> I am extremely sorry to have sent the mail to you instead of R-help. Thanks
> for directing me.
> I have downloaded R 3.2.3 version. After that i asked for
> install.packages("Rcmdr") . It says that Rcmdr is not available with
> version 3.2.3. On looking at the pdf file for getting started with R, i
> found that i should download with SDI Graphical interface which I did once
> again but still i could not get the Rcmdr console.
> I attended a workshop where the faculty brought out the R console as well
> as the R-commander console where i could import files and also do all the
> statistics easily. I am not getting the R-commander console.
> Shall be grateful if i could get help on getting the R-commander console
> with the user friendly way of doing the statistical operations.
> Thanks and regards,
> Once again apologize to Dr. Duncan Murdoch for disturbing him.
> Sekhar
>
> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
>>
>>> Dear Sirs,
>>> I have downloaded R 3.2.3 version from the CRAN site. I have tried to
>>> download with both MDI and SDI user interface. But Rcmdr is not opening in
>>> as a console  along with R console. Help is required to open Rcmdr. I have
>>> tried install.packages("Rcmdr"), library(Rcmdr) etc but to no avail.
>>> thanks
>>> Sekhar
>>> Delhi
>>> India
>>>
>>> This is the wrong email address for help.  Please write to R-help, and
>> describe what happens when you try the commands that are failing.
>>
>> Duncan Murdoch
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling


From jfox at mcmaster.ca  Tue Feb  9 16:15:42 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 9 Feb 2016 15:15:42 +0000
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>,
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F55D5F@FHSDB2D11-2.csu.mcmaster.ca>

Dear Sekhar,

The Rcmdr package, including a Windows binary, *is* available for version 3.2.3 (the current version) of R, as you can verify from the CRAN webpage for the package, at <https://cran.r-project.org/web/packages/Rcmdr/index.html>. My guess is that the CRAN mirror you're using has a problem, and you might try selecting a different mirror.

I hope that this help,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Sekhar Venkatesan [venkatesansekhar at gmail.com]
Sent: February 9, 2016 6:44 AM
To: Duncan Murdoch; R-help at r-project.org
Cc: R-windows at r-project.org
Subject: Re: [R] Help required for Rcmdr

Dear Mr. Murdoch,
I am extremely sorry to have sent the mail to you instead of R-help. Thanks
for directing me.
I have downloaded R 3.2.3 version. After that i asked for
install.packages("Rcmdr") . It says that Rcmdr is not available with
version 3.2.3. On looking at the pdf file for getting started with R, i
found that i should download with SDI Graphical interface which I did once
again but still i could not get the Rcmdr console.
I attended a workshop where the faculty brought out the R console as well
as the R-commander console where i could import files and also do all the
statistics easily. I am not getting the R-commander console.
Shall be grateful if i could get help on getting the R-commander console
with the user friendly way of doing the statistical operations.
Thanks and regards,
Once again apologize to Dr. Duncan Murdoch for disturbing him.
Sekhar

On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
>
>> Dear Sirs,
>> I have downloaded R 3.2.3 version from the CRAN site. I have tried to
>> download with both MDI and SDI user interface. But Rcmdr is not opening in
>> as a console  along with R console. Help is required to open Rcmdr. I have
>> tried install.packages("Rcmdr"), library(Rcmdr) etc but to no avail.
>> thanks
>> Sekhar
>> Delhi
>> India
>>
>> This is the wrong email address for help.  Please write to R-help, and
> describe what happens when you try the commands that are failing.
>
> Duncan Murdoch
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Feb  9 16:19:00 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 9 Feb 2016 16:19:00 +0100
Subject: [R] How to extract same columns from identical dataframes in a
	list?
In-Reply-To: <56B9AB45.10603@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu> <56B9AB45.10603@frankenfoerder-fg.de>
Message-ID: <E749E4FE-AC69-4F60-9625-9DD7E8C7F09B@gmail.com>

Like this?

> l <- replicate(3,data.frame(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
> l
[[1]]
  w1 w2
1  2  2
2  3  3
3  1  1
4  4  4

[[2]]
  w1 w2
1  3  4
2  2  2
3  1  3
4  4  1

[[3]]
  w1 w2
1  1  4
2  4  3
3  2  1
4  3  2

> sapply(l,"[[",2)
     [,1] [,2] [,3]
[1,]    2    4    4
[2,]    3    2    3
[3,]    1    3    1
[4,]    4    1    2

Or even

> sapply(l,"[",,2)
     [,1] [,2] [,3]
[1,]    2    4    4
[2,]    3    2    3
[3,]    1    3    1
[4,]    4    1    2


Notice that if dd[1:24] gives you the 1st column, then dd is not a data frame but rather a matrix, and indexing semantics are different. In that case, for some unspeakable reason, the empty index does not work and you'll need something like

> l <- replicate(3,cbind(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
> sapply(l,"[",T,2)
     [,1] [,2] [,3]
[1,]    4    3    2
[2,]    1    1    4
[3,]    3    2    3
[4,]    2    4    1

Or, brute-force-and-ignorance:

> sapply(l, function(e) e[, 2])
     [,1] [,2] [,3]
[1,]    4    3    2
[2,]    1    1    4
[3,]    3    2    3
[4,]    2    4    1





On 09 Feb 2016, at 10:03 , Wolfgang Waser <waser at frankenfoerder-fg.de> wrote:

> Hi,
> 
> sorry if my description was too short / unclear.
> 
>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>> the day) and 5 columns (weeks) with a total of 5 x 24 values
> 
> [1]
> 	week1	week2	week3	...
> 1	x	a	m	...
> 2	y	b	n
> 3	z	c	o
> .	.	.	.
> .	.	.	.
> .	.	.	.
> 24	.	.	.
> 
> 
> [2]
> 	week1 week2 week3 ...
> 1	x2	a2	m2	...
> 2	y2	b2	n2
> 3	z2	c2	o2
> .	.	.	.
> .	.	.	.
> .	.	.	.
> 24	.	.	.
> 
> 
> [3]
> ...
> 
> .
> .
> .
> 
> 
> [7]
> ...
> 
> 
> 
> I now would like to extract e.g. all week2 columns of all data frames in
> the list and combine them in a new data frame using cbind.
> 
> new data frame
> 
> week2 ([1])	week2 ([2])	week2 ([3])	...
> a		a2		.
> b		b2		.
> c		c2		.
> .
> .
> .
> 
> I will then do further row-wise calculations using e.g. apply(x,1,mean),
> the result being a vector of 24 values.
> 
> 
> I have not found a way to extract specific columns of the data frames in
> a list.
> 
> 
> As mentioned I can use
> 
> sapply(list_of_dataframes,"[",1:24)
> 
> which will pick the first 24 values (first column) of each data frame in
> the list and arrange them as an array of 24 rows and 7 columns (7 data
> frames are in the list).
> To pick the second column (week2) using sapply I have to use the next 24
> values from 25 to 48:
> 
> sapply(list_of_dataframes,"[",25:48)
> 
> 
> It seems that sapply treats the data frames in the list as vectors. I
> can of course extract all consecutive weeks using consecutive blocks of
> 24 values, but this seems cumbersome.
> 
> 
> The question remains, how to select specific columns from data frames in
> a list, e.g. all columns 3 of all data frames in the list.
> 
> 
> Reformatting (unlist(), dim()) in one data frame with one column for
> each week does not help, since I'm not calculating colMeans etc, but
> row-wise calculations using apply(x,1,FUN) ("applying a function to
> margins of an array or matrix").
> 
> 
> 
> Thanks for you help and suggestions!
> 
> 
> Wolfgang
> 
> 
> 
> On 08/02/16 18:00, D?nes T?th wrote:
>> Hi,
>> 
>> Although you did not provide any reproducible example, it seems you
>> store the same type of values in your data.frames. If this is true, it
>> is much more efficient to store your data in an array:
>> 
>> mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
>>               b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
>> 
>> myarray <- unlist(mylist, use.names = FALSE)
>> dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
>> dimnames(myarray) <- list(hour = rownames(mylist$a),
>>                          week = colnames(mylist$a),
>>                          other = names(mylist))
>> # now you can do:
>> mean(myarray[, "week1", "a"])
>> 
>> # or:
>> colMeans(myarray)
>> 
>> 
>> Cheers,
>>  Denes
>> 
>> 
>> On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
>>> Hello,
>>> 
>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>> 
>>> I would like to combine all 7 columns of week 1 (and 2 ...) in a
>>> separate data frame for hourly calculations, e.g.
>>>> apply(new.data.frame,1,mean)
>>> 
>>> In some way sapply (lapply) works, but I cannot directly select columns
>>> of the original data frames in the list. As a workaround I have to
>>> select a range of values:
>>> 
>>>> sapply(list_of_dataframes,"[",1:24)
>>> 
>>> Values 1:24 give the first column, 25:48 the second and so on.
>>> 
>>> Is there an easier / more direct way to select for specific columns
>>> instead of selecting a range of values, avoiding loops?
>>> 
>>> 
>>> Cheers,
>>> 
>>> Wolfgang
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> -- 
> Frankenf?rder Forschungsgesellschaft mbH
> Dr. Wolfgang Waser
> Wissenschaftsbereich Berlin
> Chausseestra?e 10
> 10115 Berlin
> Tel.:  +49(0)30 2809 1936
> Fax.:  +49(0)30 2809 1940
> E-Mail: waser at frankenfoerder-fg.de
> 
> Frankenf?rder Forschungsgesellschaft mbH (FFG)
> Sitz: Luckenwalde,Amtsgericht Potsdam, HRB: 6499
> Gesch?ftsf?hrerin: Dipl. Agraring. Doreen Sparborth
> Tel.: +49(0)30 2809 1931, E-Mail: info at frankenfoerder-fg.de
> http://www.frankenfoerder-fg.de
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Tue Feb  9 16:23:46 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 9 Feb 2016 15:23:46 +0000
Subject: [R] Help required for Rcmdr
In-Reply-To: <56BA02A8.2070608@unipa.it>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>,
	<56BA02A8.2070608@unipa.it>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>

Dear Vito,

I've never experienced this problem myself in a general way, and I'm sure that Windows users of R call install.packages() all the time to install packages from CRAN mirrors. So the question to ask, I think, is what's preventing install.packages() from working in your case -- possibly an Internet connectivity problem due to a firewall, proxy server, use of https, etc. I'm sure that others more knowledgeable about these issues than I am will be able to make more specific suggestions for fixing the problem.

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Vito M. R. Muggeo [vito.muggeo at unipa.it]
Sent: February 9, 2016 10:15 AM
To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-project.org
Cc: R-windows at r-project.org
Subject: Re: [R] Help required for Rcmdr

dear all,
I don't know if that problem is related to the Rcmdr package itself..
(Sekhar try to install any other packages..)

I am experiencing the same problem, in that when typing

 > install.packages("_ANY_PACKAGE_")

I get the message
Warning message:
package ?_ANY_PACKAGE_? is not available (for R version 3.2.3)

But I can download the .zip file and unzip it..

I tried different CRAN mirrors...

best,
vito


Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> Dear Mr. Murdoch,
> I am extremely sorry to have sent the mail to you instead of R-help. Thanks
> for directing me.
> I have downloaded R 3.2.3 version. After that i asked for
> install.packages("Rcmdr") . It says that Rcmdr is not available with
> version 3.2.3. On looking at the pdf file for getting started with R, i
> found that i should download with SDI Graphical interface which I did once
> again but still i could not get the Rcmdr console.
> I attended a workshop where the faculty brought out the R console as well
> as the R-commander console where i could import files and also do all the
> statistics easily. I am not getting the R-commander console.
> Shall be grateful if i could get help on getting the R-commander console
> with the user friendly way of doing the statistical operations.
> Thanks and regards,
> Once again apologize to Dr. Duncan Murdoch for disturbing him.
> Sekhar
>
> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
>>
>>> Dear Sirs,
>>> I have downloaded R 3.2.3 version from the CRAN site. I have tried to
>>> download with both MDI and SDI user interface. But Rcmdr is not opening in
>>> as a console  along with R console. Help is required to open Rcmdr. I have
>>> tried install.packages("Rcmdr"), library(Rcmdr) etc but to no avail.
>>> thanks
>>> Sekhar
>>> Delhi
>>> India
>>>
>>> This is the wrong email address for help.  Please write to R-help, and
>> describe what happens when you try the commands that are failing.
>>
>> Duncan Murdoch
>>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From vito.muggeo at unipa.it  Tue Feb  9 16:34:18 2016
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Tue, 9 Feb 2016 16:34:18 +0100
Subject: [R] Help required for Rcmdr
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <56BA06FA.9060005@unipa.it>

dear John,
Thanks for your prompt reply

Il 09/02/2016 16.23, Fox, John ha scritto:
> Dear Vito,
>
> I've never experienced this problem myself in a general way,
Me too. I have always installed R packages straightforwardly..

and I'm sure that Windows users of R call install.packages() all the 
time to
install packages from CRAN mirrors.
Of course..

So the question to ask, I think, is what's preventing install.packages()
from working in your case -- possibly an Internet connectivity problem
due to a firewall, proxy server, use of https, etc.
I'm sure that others more knowledgeable about these issues than I am will
be able to make more specific suggestions for fixing the problem.

However I have just checked that it works with *http* servers (but not 
for any other *https*..)

Thanks for your support,
best,
vito

>
> Best,
>   John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> web: socserv.mcmaster.ca/jfox
>
>
> ________________________________________
> From: R-help [r-help-bounces at r-project.org] on behalf of Vito M. R. Muggeo [vito.muggeo at unipa.it]
> Sent: February 9, 2016 10:15 AM
> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-project.org
> Cc: R-windows at r-project.org
> Subject: Re: [R] Help required for Rcmdr
>
> dear all,
> I don't know if that problem is related to the Rcmdr package itself..
> (Sekhar try to install any other packages..)
>
> I am experiencing the same problem, in that when typing
>
>   > install.packages("_ANY_PACKAGE_")
>
> I get the message
> Warning message:
> package ?_ANY_PACKAGE_? is not available (for R version 3.2.3)
>
> But I can download the .zip file and unzip it..
>
> I tried different CRAN mirrors...
>
> best,
> vito
>
>
> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
>> Dear Mr. Murdoch,
>> I am extremely sorry to have sent the mail to you instead of R-help. Thanks
>> for directing me.
>> I have downloaded R 3.2.3 version. After that i asked for
>> install.packages("Rcmdr") . It says that Rcmdr is not available with
>> version 3.2.3. On looking at the pdf file for getting started with R, i
>> found that i should download with SDI Graphical interface which I did once
>> again but still i could not get the Rcmdr console.
>> I attended a workshop where the faculty brought out the R console as well
>> as the R-commander console where i could import files and also do all the
>> statistics easily. I am not getting the R-commander console.
>> Shall be grateful if i could get help on getting the R-commander console
>> with the user friendly way of doing the statistical operations.
>> Thanks and regards,
>> Once again apologize to Dr. Duncan Murdoch for disturbing him.
>> Sekhar
>>
>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
>>>
>>>> Dear Sirs,
>>>> I have downloaded R 3.2.3 version from the CRAN site. I have tried to
>>>> download with both MDI and SDI user interface. But Rcmdr is not opening in
>>>> as a console  along with R console. Help is required to open Rcmdr. I have
>>>> tried install.packages("Rcmdr"), library(Rcmdr) etc but to no avail.
>>>> thanks
>>>> Sekhar
>>>> Delhi
>>>> India
>>>>
>>>> This is the wrong email address for help.  Please write to R-help, and
>>> describe what happens when you try the commands that are failing.
>>>
>>> Duncan Murdoch
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> ==============================================
> Vito M.R. Muggeo
> Dip.to Sc Statist e Matem `Vianelli'
> Universit? di Palermo
> viale delle Scienze, edificio 13
> 90128 Palermo - ITALY
> tel: 091 23895240
> fax: 091 485726
> http://dssm.unipa.it/vmuggeo
> Associate Editor, Statistical Modelling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling


From bgunter.4567 at gmail.com  Tue Feb  9 16:51:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 9 Feb 2016 07:51:53 -0800
Subject: [R] calling plot
In-Reply-To: <56B966AA.8060809@effectivedefense.org>
References: <56B95A65.8010009@effectivedefense.org>
	<1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
	<56B966AA.8060809@effectivedefense.org>
Message-ID: <CAGxFJbQO8j8O=K=z3_onrHHNj90NtdkyYFf-B5c-C4oRgATarg@mail.gmail.com>

Spencer, et. al.:

As I suspected, my previous "solution" was pretty stupid. Here is, I
think, the "right" way to
 go about it:

 plotxy <- function(x,...){
   mcall <- match.call(expand.dots=FALSE)
   mcall[[1]]<- plot.default
   eval(mcall)
 }

Best,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 8, 2016 at 8:10 PM, Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
> Hi, Jeff et al.:
>
>
> On 2/8/2016 9:52 PM, Jeff Newmiller wrote:
>> plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))
>
>
>        Yes, Thanks.
>
>
>        Is there a way to do this from within "plotxy", so I can call
> "plotxy" as I call "plot"?
>
>
>        Thanks,
>        Spencer
>
>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 8, 2016 7:17:57 PM PST, Spencer Graves
>> <spencer.graves at effectivedefense.org> wrote:
>>
>>     I'm getting an interesting error:
>>
>>
>>         plotxy <- function(x, ...){
>>
>>     +   plot(x, ...)
>>     + }
>>
>>         XY <- data.frame(x1=1:3, y1=4:6) plotxy(y1~x1, XY, xlim=c(0,
>>         max(x1)))
>>
>>        Show Traceback
>>
>>        Rerun with Debug
>>        Error in eval(expr, envir, enclos) : object 'x1' not found
>>
>>
>>             The following work:
>>
>>
>>     plotxy(y1~x1, XY)
>>     plot(y1~x1, XY, xlim=c(0, max(x1)))
>>
>>
>>             Within "plotxy", R can't find "x1" to compute "xlim".  Is there a
>>     way I can make x1 available to xlim?
>>
>>
>>             Thanks,
>>             Spencer
>>
>>     ------------------------------------------------------------------------
>>
>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Tue Feb  9 16:57:12 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 9 Feb 2016 10:57:12 -0500
Subject: [R] Help required for Rcmdr
In-Reply-To: <56BA06FA.9060005@unipa.it>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
Message-ID: <CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>

Several of my students have had this type of difficulty with Rstudio.

Rstudio masks install.packages with a similarly named function in an
environment that does not appear in
either conflicts(details=TRUE) or in search().

The workaround is an explicit call to utils

utils::install.packages("package.name")

Rich

On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo <vito.muggeo at unipa.it> wrote:
> dear John,
> Thanks for your prompt reply
>
> Il 09/02/2016 16.23, Fox, John ha scritto:
>>
>> Dear Vito,
>>
>> I've never experienced this problem myself in a general way,
>
> Me too. I have always installed R packages straightforwardly..
>
> and I'm sure that Windows users of R call install.packages() all the time to
> install packages from CRAN mirrors.
> Of course..
>
> So the question to ask, I think, is what's preventing install.packages()
> from working in your case -- possibly an Internet connectivity problem
> due to a firewall, proxy server, use of https, etc.
> I'm sure that others more knowledgeable about these issues than I am will
> be able to make more specific suggestions for fixing the problem.
>
> However I have just checked that it works with *http* servers (but not for
> any other *https*..)
>
> Thanks for your support,
> best,
> vito
>
>
>>
>> Best,
>>   John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> web: socserv.mcmaster.ca/jfox
>>
>>
>> ________________________________________
>> From: R-help [r-help-bounces at r-project.org] on behalf of Vito M. R. Muggeo
>> [vito.muggeo at unipa.it]
>> Sent: February 9, 2016 10:15 AM
>> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-project.org
>> Cc: R-windows at r-project.org
>> Subject: Re: [R] Help required for Rcmdr
>>
>> dear all,
>> I don't know if that problem is related to the Rcmdr package itself..
>> (Sekhar try to install any other packages..)
>>
>> I am experiencing the same problem, in that when typing
>>
>>   > install.packages("_ANY_PACKAGE_")
>>
>> I get the message
>> Warning message:
>> package ?_ANY_PACKAGE_? is not available (for R version 3.2.3)
>>
>> But I can download the .zip file and unzip it..
>>
>> I tried different CRAN mirrors...
>>
>> best,
>> vito
>>
>>
>> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
>>>
>>> Dear Mr. Murdoch,
>>> I am extremely sorry to have sent the mail to you instead of R-help.
>>> Thanks
>>> for directing me.
>>> I have downloaded R 3.2.3 version. After that i asked for
>>> install.packages("Rcmdr") . It says that Rcmdr is not available with
>>> version 3.2.3. On looking at the pdf file for getting started with R, i
>>> found that i should download with SDI Graphical interface which I did
>>> once
>>> again but still i could not get the Rcmdr console.
>>> I attended a workshop where the faculty brought out the R console as well
>>> as the R-commander console where i could import files and also do all the
>>> statistics easily. I am not getting the R-commander console.
>>> Shall be grateful if i could get help on getting the R-commander console
>>> with the user friendly way of doing the statistical operations.
>>> Thanks and regards,
>>> Once again apologize to Dr. Duncan Murdoch for disturbing him.
>>> Sekhar
>>>
>>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>
>>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
>>>>
>>>>> Dear Sirs,
>>>>> I have downloaded R 3.2.3 version from the CRAN site. I have tried to
>>>>> download with both MDI and SDI user interface. But Rcmdr is not opening
>>>>> in
>>>>> as a console  along with R console. Help is required to open Rcmdr. I
>>>>> have
>>>>> tried install.packages("Rcmdr"), library(Rcmdr) etc but to no avail.
>>>>> thanks
>>>>> Sekhar
>>>>> Delhi
>>>>> India
>>>>>
>>>>> This is the wrong email address for help.  Please write to R-help, and
>>>>
>>>> describe what happens when you try the commands that are failing.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> ==============================================
>> Vito M.R. Muggeo
>> Dip.to Sc Statist e Matem `Vianelli'
>> Universit? di Palermo
>> viale delle Scienze, edificio 13
>> 90128 Palermo - ITALY
>> tel: 091 23895240
>> fax: 091 485726
>> http://dssm.unipa.it/vmuggeo
>> Associate Editor, Statistical Modelling
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> ==============================================
> Vito M.R. Muggeo
> Dip.to Sc Statist e Matem `Vianelli'
> Universit? di Palermo
> viale delle Scienze, edificio 13
> 90128 Palermo - ITALY
> tel: 091 23895240
> fax: 091 485726
> http://dssm.unipa.it/vmuggeo
> Associate Editor, Statistical Modelling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Tue Feb  9 17:30:50 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 9 Feb 2016 16:30:50 +0000
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
	<CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F55E86@FHSDB2D11-2.csu.mcmaster.ca>

Hi Rich,

> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: February 9, 2016 4:57 PM
> To: Vito M. R. Muggeo <vito.muggeo at unipa.it>
> Cc: Fox, John <jfox at mcmaster.ca>; Sekhar Venkatesan
> <venkatesansekhar at gmail.com>; Duncan Murdoch
> <murdoch.duncan at gmail.com>; R-help at r-project.org; R-windows at r-
> project.org
> Subject: Re: [R] Help required for Rcmdr
> 
> Several of my students have had this type of difficulty with Rstudio.
> 

Good to know, but the original poster tried both with the R Windows SDI and MDI.

Best,
 John

> Rstudio masks install.packages with a similarly named function in an
> environment that does not appear in either conflicts(details=TRUE) or in
> search().
> 
> The workaround is an explicit call to utils
> 
> utils::install.packages("package.name")
> 
> Rich
> 
> On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo <vito.muggeo at unipa.it>
> wrote:
> > dear John,
> > Thanks for your prompt reply
> >
> > Il 09/02/2016 16.23, Fox, John ha scritto:
> >>
> >> Dear Vito,
> >>
> >> I've never experienced this problem myself in a general way,
> >
> > Me too. I have always installed R packages straightforwardly..
> >
> > and I'm sure that Windows users of R call install.packages() all the
> > time to install packages from CRAN mirrors.
> > Of course..
> >
> > So the question to ask, I think, is what's preventing
> > install.packages() from working in your case -- possibly an Internet
> > connectivity problem due to a firewall, proxy server, use of https, etc.
> > I'm sure that others more knowledgeable about these issues than I am
> > will be able to make more specific suggestions for fixing the problem.
> >
> > However I have just checked that it works with *http* servers (but not
> > for any other *https*..)
> >
> > Thanks for your support,
> > best,
> > vito
> >
> >
> >>
> >> Best,
> >>   John
> >>
> >> -----------------------------
> >> John Fox, Professor
> >> McMaster University
> >> Hamilton, Ontario
> >> Canada L8S 4M4
> >> web: socserv.mcmaster.ca/jfox
> >>
> >>
> >> ________________________________________
> >> From: R-help [r-help-bounces at r-project.org] on behalf of Vito M. R.
> >> Muggeo [vito.muggeo at unipa.it]
> >> Sent: February 9, 2016 10:15 AM
> >> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-project.org
> >> Cc: R-windows at r-project.org
> >> Subject: Re: [R] Help required for Rcmdr
> >>
> >> dear all,
> >> I don't know if that problem is related to the Rcmdr package itself..
> >> (Sekhar try to install any other packages..)
> >>
> >> I am experiencing the same problem, in that when typing
> >>
> >>   > install.packages("_ANY_PACKAGE_")
> >>
> >> I get the message
> >> Warning message:
> >> package ?_ANY_PACKAGE_? is not available (for R version 3.2.3)
> >>
> >> But I can download the .zip file and unzip it..
> >>
> >> I tried different CRAN mirrors...
> >>
> >> best,
> >> vito
> >>
> >>
> >> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> >>>
> >>> Dear Mr. Murdoch,
> >>> I am extremely sorry to have sent the mail to you instead of R-help.
> >>> Thanks
> >>> for directing me.
> >>> I have downloaded R 3.2.3 version. After that i asked for
> >>> install.packages("Rcmdr") . It says that Rcmdr is not available with
> >>> version 3.2.3. On looking at the pdf file for getting started with
> >>> R, i found that i should download with SDI Graphical interface which
> >>> I did once again but still i could not get the Rcmdr console.
> >>> I attended a workshop where the faculty brought out the R console as
> >>> well as the R-commander console where i could import files and also
> >>> do all the statistics easily. I am not getting the R-commander console.
> >>> Shall be grateful if i could get help on getting the R-commander
> >>> console with the user friendly way of doing the statistical operations.
> >>> Thanks and regards,
> >>> Once again apologize to Dr. Duncan Murdoch for disturbing him.
> >>> Sekhar
> >>>
> >>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch
> >>> <murdoch.duncan at gmail.com>
> >>> wrote:
> >>>
> >>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
> >>>>
> >>>>> Dear Sirs,
> >>>>> I have downloaded R 3.2.3 version from the CRAN site. I have tried
> >>>>> to download with both MDI and SDI user interface. But Rcmdr is not
> >>>>> opening in as a console  along with R console. Help is required to
> >>>>> open Rcmdr. I have tried install.packages("Rcmdr"), library(Rcmdr)
> >>>>> etc but to no avail.
> >>>>> thanks
> >>>>> Sekhar
> >>>>> Delhi
> >>>>> India
> >>>>>
> >>>>> This is the wrong email address for help.  Please write to R-help,
> >>>>> and
> >>>>
> >>>> describe what happens when you try the commands that are failing.
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> --
> >> ==============================================
> >> Vito M.R. Muggeo
> >> Dip.to Sc Statist e Matem `Vianelli'
> >> Universit? di Palermo
> >> viale delle Scienze, edificio 13
> >> 90128 Palermo - ITALY
> >> tel: 091 23895240
> >> fax: 091 485726
> >> http://dssm.unipa.it/vmuggeo
> >> Associate Editor, Statistical Modelling
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > --
> > ==============================================
> > Vito M.R. Muggeo
> > Dip.to Sc Statist e Matem `Vianelli'
> > Universit? di Palermo
> > viale delle Scienze, edificio 13
> > 90128 Palermo - ITALY
> > tel: 091 23895240
> > fax: 091 485726
> > http://dssm.unipa.it/vmuggeo
> > Associate Editor, Statistical Modelling
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From spencer.graves at effectivedefense.org  Tue Feb  9 17:33:01 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Tue, 9 Feb 2016 10:33:01 -0600
Subject: [R] calling plot
In-Reply-To: <CAGxFJbQO8j8O=K=z3_onrHHNj90NtdkyYFf-B5c-C4oRgATarg@mail.gmail.com>
References: <56B95A65.8010009@effectivedefense.org>
	<1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
	<56B966AA.8060809@effectivedefense.org>
	<CAGxFJbQO8j8O=K=z3_onrHHNj90NtdkyYFf-B5c-C4oRgATarg@mail.gmail.com>
Message-ID: <56BA14BD.1060603@effectivedefense.org>



On 2/9/2016 9:51 AM, Bert Gunter wrote:
> Spencer, et. al.:
>
> As I suspected, my previous "solution" was pretty stupid. Here is, I
> think, the "right" way to
>   go about it:
>
>   plotxy <- function(x,...){
>     mcall <- match.call(expand.dots=FALSE)
>     mcall[[1]]<- plot.default
>     eval(mcall)
>   }


Hi, Bert, et al.:  I couldn't get that to work, either:


 > XY <- data.frame(x1=1:3, y1=4:6)
 > plotxy(y1~x1, XY, xlim=c(0, max(x1)))

  Error in eval(expr, envir, enclos) : object 'y1' not found


       However, my original function inside "with" worked, but Bert's 
suggestion didn't:


 > plot.sg <- function(x, ...){
+ plot(x, ...)
+ }
 > with(XY, plot.sg(y1~x1, xlim=c(0, max(x1))))
 > # worked, but "plotxy" with match.call didn't:
 > with(XY, plotxy(y1~x1, xlim=c(0, max(x1))))

  Error in eval(expr, envir, enclos) : object 'y1' not found

 > sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.2 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

loaded via a namespace (and not attached):
[1] tools_3.2.3


       I don't understand this, but "with" is acceptable for my current 
needs.


       Thanks again to Bert & Jeff.


       Spencer Graves
>
> Best,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Feb 8, 2016 at 8:10 PM, Spencer Graves
> <spencer.graves at effectivedefense.org> wrote:
>> Hi, Jeff et al.:
>>
>>
>> On 2/8/2016 9:52 PM, Jeff Newmiller wrote:
>>> plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))
>>
>>         Yes, Thanks.
>>
>>
>>         Is there a way to do this from within "plotxy", so I can call
>> "plotxy" as I call "plot"?
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On February 8, 2016 7:17:57 PM PST, Spencer Graves
>>> <spencer.graves at effectivedefense.org> wrote:
>>>
>>>      I'm getting an interesting error:
>>>
>>>
>>>          plotxy <- function(x, ...){
>>>
>>>      +   plot(x, ...)
>>>      + }
>>>
>>>          XY <- data.frame(x1=1:3, y1=4:6) plotxy(y1~x1, XY, xlim=c(0,
>>>          max(x1)))
>>>
>>>         Show Traceback
>>>
>>>         Rerun with Debug
>>>         Error in eval(expr, envir, enclos) : object 'x1' not found
>>>
>>>
>>>              The following work:
>>>
>>>
>>>      plotxy(y1~x1, XY)
>>>      plot(y1~x1, XY, xlim=c(0, max(x1)))
>>>
>>>
>>>              Within "plotxy", R can't find "x1" to compute "xlim".  Is there a
>>>      way I can make x1 available to xlim?
>>>
>>>
>>>              Thanks,
>>>              Spencer
>>>
>>>      ------------------------------------------------------------------------
>>>
>>>      R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>      PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>>      and provide commented, minimal, self-contained, reproducible code.
>>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Feb  9 17:55:33 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 9 Feb 2016 11:55:33 -0500
Subject: [R] platform dependent regex
Message-ID: <CA+vqiLETAWXyDPfpvAHxVujw3THMs4HLnmk6kZshdFHWH4wp+g@mail.gmail.com>

I just spent a day and a half debugging someone's code, only to
discover that the problem is platform dependent regular expressions.
For example:

## Windows:
grepl("\\W", "", "?")  # TRUE

## OS X:
grepl("\\W", "", "?")  # TRUE

## Linux:
grepl("\\W", "", "?")  # FALSE

Ouch. The documentation does say "Certain named classes of characters
are predefined.  Their interpretation depends on the _locale_", but
that doesn't seem to cover it given that the locale on OS X and Linux
was the same (en_US.UTF-8).

Question: Is this considered a bug, and if so what can I do to help
fix it? I've checked and the issue is present in both r-patched and
r-devel.

Best,
Ista


From jholtman at gmail.com  Tue Feb  9 18:10:16 2016
From: jholtman at gmail.com (jim holtman)
Date: Tue, 9 Feb 2016 12:10:16 -0500
Subject: [R] platform dependent regex
In-Reply-To: <CA+vqiLETAWXyDPfpvAHxVujw3THMs4HLnmk6kZshdFHWH4wp+g@mail.gmail.com>
References: <CA+vqiLETAWXyDPfpvAHxVujw3THMs4HLnmk6kZshdFHWH4wp+g@mail.gmail.com>
Message-ID: <CAAxdm-4EuiHQFHPO3wUS+q=AH2uhdo0=YcuRrRuagEk9NR5DNg@mail.gmail.com>

why 3 parameters on the 'grepl'?  Did you mean to say:

?grepl("\\W", "?")  # FALSE


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Feb 9, 2016 at 11:55 AM, Ista Zahn <istazahn at gmail.com> wrote:

> I just spent a day and a half debugging someone's code, only to
> discover that the problem is platform dependent regular expressions.
> For example:
>
> ## Windows:
> grepl("\\W", "", "?")  # TRUE
>
> ## OS X:
> grepl("\\W", "", "?")  # TRUE
>
> ## Linux:
> grepl("\\W", "", "?")  # FALSE
>
> Ouch. The documentation does say "Certain named classes of characters
> are predefined.  Their interpretation depends on the _locale_", but
> that doesn't seem to cover it given that the locale on OS X and Linux
> was the same (en_US.UTF-8).
>
> Question: Is this considered a bug, and if so what can I do to help
> fix it? I've checked and the issue is present in both r-patched and
> r-devel.
>
> Best,
> Ista
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Feb  9 18:39:00 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 9 Feb 2016 12:39:00 -0500
Subject: [R] platform dependent regex
In-Reply-To: <CAAxdm-4EuiHQFHPO3wUS+q=AH2uhdo0=YcuRrRuagEk9NR5DNg@mail.gmail.com>
References: <CA+vqiLETAWXyDPfpvAHxVujw3THMs4HLnmk6kZshdFHWH4wp+g@mail.gmail.com>
	<CAAxdm-4EuiHQFHPO3wUS+q=AH2uhdo0=YcuRrRuagEk9NR5DNg@mail.gmail.com>
Message-ID: <CA+vqiLFTT4XyYsAW5xM9atP1rD795CWfS9zVejUynNEZ5XQGWg@mail.gmail.com>

Hi Jim,

Bah, yes, I meant,

## Windows:
grepl("\\W",  "?")  # TRUE

## OS X:
grepl("\\W",  "?")  # TRUE

## Linux:
grepl("\\W", "?")  # FALSE

Sorry about that. My original example was with gsub, but I thought
changing to grepl example was clearer. Thank you.

-- Ista

On Tue, Feb 9, 2016 at 12:10 PM, jim holtman <jholtman at gmail.com> wrote:
> why 3 parameters on the 'grepl'?  Did you mean to say:
>
> grepl("\\W", "?")  # FALSE
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Tue, Feb 9, 2016 at 11:55 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> I just spent a day and a half debugging someone's code, only to
>> discover that the problem is platform dependent regular expressions.
>> For example:
>>
>> ## Windows:
>> grepl("\\W", "", "?")  # TRUE
>>
>> ## OS X:
>> grepl("\\W", "", "?")  # TRUE
>>
>> ## Linux:
>> grepl("\\W", "", "?")  # FALSE
>>
>> Ouch. The documentation does say "Certain named classes of characters
>> are predefined.  Their interpretation depends on the _locale_", but
>> that doesn't seem to cover it given that the locale on OS X and Linux
>> was the same (en_US.UTF-8).
>>
>> Question: Is this considered a bug, and if so what can I do to help
>> fix it? I've checked and the issue is present in both r-patched and
>> r-devel.
>>
>> Best,
>> Ista
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From bgunter.4567 at gmail.com  Tue Feb  9 18:46:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 9 Feb 2016 09:46:46 -0800
Subject: [R] calling plot
In-Reply-To: <56BA14BD.1060603@effectivedefense.org>
References: <56B95A65.8010009@effectivedefense.org>
	<1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
	<56B966AA.8060809@effectivedefense.org>
	<CAGxFJbQO8j8O=K=z3_onrHHNj90NtdkyYFf-B5c-C4oRgATarg@mail.gmail.com>
	<56BA14BD.1060603@effectivedefense.org>
Message-ID: <CAGxFJbSqZgbsJoOQdSxZs8P-B=+cOMqRAe2dg7FoNUDiYDiE0A@mail.gmail.com>

Oh, yes certainly. But I thought the point was to avoid "cheating"
with with() or assuming that the "x" argument was a formula.

Yes, my "smarter" solution doesn't work  -- my error. I still think
there must be a small tweak to fix it, but I haven't figured it out
yet. AFAICS, my earlier "stupid" solution does work as originally
intended with no "cheating" :

> plotxy <- function(x,data = NULL,...){
+    mcall <- match.call()
+    if(inherits(x,"formula"))enc <- environment(x)
+     else enc <- parent.frame()
+    if(!is.null(data)){
+         env <- data
+         mcall <- mcall[-match("data",names(mcall))]
+    } else env <- NULL
+    mcall[[1]] <- plot.default
+    eval(mcall,envir=env,enclos=enc)
+ }
>
>
>
>  XY <- data.frame(x1=1:3, y1=4:6)
>  plotxy(y1~x1, XY, xlim=c(0, max(x1)))

The problem with your original approach I believe is that the
evaluator wants to evaluate xlim before it passes it on to your plot
call. By default, it evaluates it in the parent frame where there is
no x1 -- ergo the error (I would appreciate correction if this is
wrong).  If you look at the code for plot.default() and then
grDevices:: xy.coords, you'll see how the call is parsed and evaluated
in the appropriate environment.  My code above is trying to do the
same thing, though I may still have holes.

Cheers,
Bert




Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 9, 2016 at 8:33 AM, Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
>
>
> On 2/9/2016 9:51 AM, Bert Gunter wrote:
>>
>> Spencer, et. al.:
>>
>> As I suspected, my previous "solution" was pretty stupid. Here is, I
>> think, the "right" way to
>>   go about it:
>>
>>   plotxy <- function(x,...){
>>     mcall <- match.call(expand.dots=FALSE)
>>     mcall[[1]]<- plot.default
>>     eval(mcall)
>>   }
>
>
>
> Hi, Bert, et al.:  I couldn't get that to work, either:
>
>
>> XY <- data.frame(x1=1:3, y1=4:6)
>> plotxy(y1~x1, XY, xlim=c(0, max(x1)))
>
>  Error in eval(expr, envir, enclos) : object 'y1' not found
>
>
>       However, my original function inside "with" worked, but Bert's
> suggestion didn't:
>
>
>> plot.sg <- function(x, ...){
> + plot(x, ...)
> + }
>> with(XY, plot.sg(y1~x1, xlim=c(0, max(x1))))
>> # worked, but "plotxy" with match.call didn't:
>> with(XY, plotxy(y1~x1, xlim=c(0, max(x1))))
>
>  Error in eval(expr, envir, enclos) : object 'y1' not found
>
>> sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.2 (El Capitan)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.3
>
>
>       I don't understand this, but "with" is acceptable for my current
> needs.
>
>
>       Thanks again to Bert & Jeff.
>
>
>       Spencer Graves
>>
>>
>> Best,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Feb 8, 2016 at 8:10 PM, Spencer Graves
>> <spencer.graves at effectivedefense.org> wrote:
>>>
>>> Hi, Jeff et al.:
>>>
>>>
>>> On 2/8/2016 9:52 PM, Jeff Newmiller wrote:
>>>>
>>>> plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))
>>>
>>>
>>>         Yes, Thanks.
>>>
>>>
>>>         Is there a way to do this from within "plotxy", so I can call
>>> "plotxy" as I call "plot"?
>>>
>>>
>>>         Thanks,
>>>         Spencer
>>>
>>>
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On February 8, 2016 7:17:57 PM PST, Spencer Graves
>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>
>>>>      I'm getting an interesting error:
>>>>
>>>>
>>>>          plotxy <- function(x, ...){
>>>>
>>>>      +   plot(x, ...)
>>>>      + }
>>>>
>>>>          XY <- data.frame(x1=1:3, y1=4:6) plotxy(y1~x1, XY, xlim=c(0,
>>>>          max(x1)))
>>>>
>>>>         Show Traceback
>>>>
>>>>         Rerun with Debug
>>>>         Error in eval(expr, envir, enclos) : object 'x1' not found
>>>>
>>>>
>>>>              The following work:
>>>>
>>>>
>>>>      plotxy(y1~x1, XY)
>>>>      plot(y1~x1, XY, xlim=c(0, max(x1)))
>>>>
>>>>
>>>>              Within "plotxy", R can't find "x1" to compute "xlim".  Is
>>>> there a
>>>>      way I can make x1 available to xlim?
>>>>
>>>>
>>>>              Thanks,
>>>>              Spencer
>>>>
>>>>
>>>> ------------------------------------------------------------------------
>>>>
>>>>      R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>>      PLEASE do read the posting
>>>> guidehttp://www.R-project.org/posting-guide.html
>>>>      and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>


From lists at dewey.myzen.co.uk  Tue Feb  9 19:08:27 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 9 Feb 2016 18:08:27 +0000
Subject: [R] Help in meta-analysis (URGENT please)
In-Reply-To: <68693AC4-30CD-49FE-837C-12CD01F05F72@gmail.com>
References: <68693AC4-30CD-49FE-837C-12CD01F05F72@gmail.com>
Message-ID: <56BA2B1B.6090909@dewey.myzen.co.uk>

Dear Rosa

I suggest reformatting your dataset to have four variables (a) study (2) 
MSM yes or no (3) number with HIV (4) total number. Then you can use any 
of the options in metafor (look for outcomes for individual groups in 
?escalc) and use MSM as a moderator.

Is there any reason why you did not just do a logistic regression?

On 08/02/2016 18:40, Rosa Oliveira wrote:
> Dear all,
>
> I?m conducting a met analysis and I usually use Revman, bur as I?m trying to use R more and more, I would like to conduct the met analysis here, in R (R-studio).
>
> One off my problems, I think, is that:
> 1st. it?s the first time :)
> 2. I only have data for 1 arm as you can see on the data that follows.
>
> ARTIGO	qt	tt	qc	tc	Personal Notes	qt2
> Giuliani M. (2014)	-	-	1515	1862	only MSM.	347
> Diaz A. (2015)	-	-	-	-	only MSM (n=3081)	2499
> Niedz?wiedzka-Stadnik M. (2015)	828	1098	-	-		326
> Hoenig M. (2015)	-	-	8506	-	MSM (n=8925)	419
> Wu H. (2015)	58	145	-	16713	n=16892	87
> Pan X. (2015)	-			-	only MSM (n=1316)	-
> Ma Q. (2015)	-			-	only MSM (n=424)	-
> Op de Coul E. (2015)	8596			-	HIV-infected patients (n=20965)	12369
> Liu G. (2015)	-	-	1003 (?)	-	only MSM (n=1041) - some converted to HIV+ during the study	-
> Hoenigl M. (2015)	-			-	only MSM (n=8935) analysis HIV tests repetitions	-
> Moller L. M. (2015)	-	-	469	-	only MSM (N=561)	92
> watkins (2015)	-	-	-	-	only MSM (n=1154) only analysis believes concerning the risk	-
> den Dass C. (2015)	-	-	2408	-	only MSM (n=3787)	589
> Jia Z. (2015)	-	-	5314	-	only MSM (n=5800)	486
> solomon S. (2015)	-	-	10875	-	only MSM (n=12022)	1147
> Diez M. (2014)	-	3599	-	-	n=145337	
>
>
>
> legend:
> qt the number of hiv subjetcs who are not sms.
> qt2 the number of hiv subjetcs who are  sms.
> tt the total number of hiv subjects.
> qc the number of subjetcs who are sms without being hiv.
> tc the total number of subject not hiv.
>
>
>
> Is it possible to conduct a met analysis concerning the risk of hiv among MSM relative to the ones that are not MSM?
>
> or simply concerning the risk of hiv among MSM????
>
> If yes, How?
>
> Metafor? I?ve tried, but wasn?t succeed :(
>
>
> Best,
> RO
>
>
>
> Atenciosamente,
> Rosa Oliveira
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From cdetermanjr at gmail.com  Tue Feb  9 19:20:19 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Tue, 9 Feb 2016 12:20:19 -0600
Subject: [R] GPU package crowd-source testing
Message-ID: <CAKxd1KMgAkcArNYQzwxBAvnewsz33hMEuaz5bb_z_B0C7nqD=g@mail.gmail.com>

Greetings R users,

I would like to request any users who would be willing to test one of my
packages.  Normally I would be content using testthat and continuous
integration services but this particular package is used for GPU computing
(hence the cross-posting).  It is intended to be as general as possible for
available devices but I only have access to so much hardware.  I can't
possibly test it against every GPU available.

As such, I would sincerely appreciate any user that has at least one GPU
device (Intel, AMD, or NVIDIA) and is willing to experiment with the
package to try it out.  Note, this will require installing an OpenCL SDK of
some form.  Installation instructions for the package are found here (
https://github.com/cdeterman/gpuR/wiki).

At the very least, if you have a valid device, you would only need to
download the 'development' version of the package and experiment with the
functions such as a matrix multiplication.

devtools::install_github("cdeterman/gpuR", ref = "develop")

library(gpuR)
A <- gpuMatrix(rnorm(10000), 100, 100)
A %*% A

You could also clone my github repo and run all the unit tests I have
included

git clone -b develop https://github.com/cdeterman/gpuR.git

If using RStudio, just open the package in a new project and press
'Ctrl-Shift-T' or more directly run  `devtools::test()`

If using command-line R, switch to the gpuR directory, start R and run
`devtools::test()`.

If you find any errors or bugs, please report them in my github issues (
https://github.com/cdeterman/gpuR/issues).  Naturally any recommendations
on additional features are welcome.

Thank you in advance for any support you can provide.  I want to continue
improving this package but I am beginning to reach the end of what I can
accomplish from a hardware perspective.

Best Regards,
Charles

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Tue Feb  9 19:38:28 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Tue, 9 Feb 2016 12:38:28 -0600
Subject: [R] calling plot
In-Reply-To: <CAGxFJbSqZgbsJoOQdSxZs8P-B=+cOMqRAe2dg7FoNUDiYDiE0A@mail.gmail.com>
References: <56B95A65.8010009@effectivedefense.org>
	<1AB6B99C-D413-41EF-936F-7F46802339A7@dcn.davis.ca.us>
	<56B966AA.8060809@effectivedefense.org>
	<CAGxFJbQO8j8O=K=z3_onrHHNj90NtdkyYFf-B5c-C4oRgATarg@mail.gmail.com>
	<56BA14BD.1060603@effectivedefense.org>
	<CAGxFJbSqZgbsJoOQdSxZs8P-B=+cOMqRAe2dg7FoNUDiYDiE0A@mail.gmail.com>
Message-ID: <56BA3224.7070208@effectivedefense.org>

Hi, Bert:


On 2/9/2016 11:46 AM, Bert Gunter wrote:
> Oh, yes certainly. But I thought the point was to avoid "cheating"
> with with() or assuming that the "x" argument was a formula.
>
> Yes, my "smarter" solution doesn't work  -- my error. I still think
> there must be a small tweak to fix it, but I haven't figured it out
> yet. AFAICS, my earlier "stupid" solution does work as originally
> intended with no "cheating" :
>
>> plotxy <- function(x,data = NULL,...){
> +    mcall <- match.call()
> +    if(inherits(x,"formula"))enc <- environment(x)
> +     else enc <- parent.frame()
> +    if(!is.null(data)){
> +         env <- data
> +         mcall <- mcall[-match("data",names(mcall))]
> +    } else env <- NULL
> +    mcall[[1]] <- plot.default
> +    eval(mcall,envir=env,enclos=enc)
> + }
>>
>>
>>   XY <- data.frame(x1=1:3, y1=4:6)
>>   plotxy(y1~x1, XY, xlim=c(0, max(x1)))
> The problem with your original approach I believe is that the
> evaluator wants to evaluate xlim before it passes it on to your plot
> call. By default, it evaluates it in the parent frame where there is
> no x1 -- ergo the error (I would appreciate correction if this is
> wrong).  If you look at the code for plot.default() and then
> grDevices:: xy.coords, you'll see how the call is parsed and evaluated
> in the appropriate environment.  My code above is trying to do the
> same thing, though I may still have holes.


Thanks.  I failed to mention that I also wanted the same function to 
work with a time series, class "ts".  Amazingly, my "plot.sg" worked 
with an object of class "ts", but your "plotxy" didn't plot what I wanted:


y.ts <- ts(matrix(1:6, 3), 7)

plotxy(y.ts)
# plots the first series as points and ignores the second
plot.sg(y.ts) # works as desired


When I replaced "plot.default" with "plot" in your "plotxy", 
plotxy(y.ts) performed as desired, but  plotxy(y1~x1, XY, xlim=c(0, 
max(x1))) threw an error.


The following revision of your function works:


plotxy <- function(x, data = NULL,...){
     mcall <- match.call()
     if(inherits(x,"formula"))enc <- environment(x)
      else enc <- parent.frame()
     if(!is.null(data)){
          env <- data
          mcall <- mcall[-match("data",names(mcall))]
     } else env <- NULL
     mcall[[1]] <- (if(is.ts(x)) plot else plot.default)
     eval(mcall,envir=env,enclos=enc)
}

plotxy(y1~x1, XY, xlim=c(0, max(x1))) # good
plotxy(y.ts) # good


       However, this will be embedded in a vignette on time series 
analysis, so I think I'll stick with the simpler "with" solution.


       Thanks again,
       Spencer
>
> Cheers,
> Bert
>
>
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 9, 2016 at 8:33 AM, Spencer Graves
> <spencer.graves at effectivedefense.org> wrote:
>>
>> On 2/9/2016 9:51 AM, Bert Gunter wrote:
>>> Spencer, et. al.:
>>>
>>> As I suspected, my previous "solution" was pretty stupid. Here is, I
>>> think, the "right" way to
>>>    go about it:
>>>
>>>    plotxy <- function(x,...){
>>>      mcall <- match.call(expand.dots=FALSE)
>>>      mcall[[1]]<- plot.default
>>>      eval(mcall)
>>>    }
>>
>>
>> Hi, Bert, et al.:  I couldn't get that to work, either:
>>
>>
>>> XY <- data.frame(x1=1:3, y1=4:6)
>>> plotxy(y1~x1, XY, xlim=c(0, max(x1)))
>>   Error in eval(expr, envir, enclos) : object 'y1' not found
>>
>>
>>        However, my original function inside "with" worked, but Bert's
>> suggestion didn't:
>>
>>
>>> plot.sg <- function(x, ...){
>> + plot(x, ...)
>> + }
>>> with(XY, plot.sg(y1~x1, xlim=c(0, max(x1))))
>>> # worked, but "plotxy" with match.call didn't:
>>> with(XY, plotxy(y1~x1, xlim=c(0, max(x1))))
>>   Error in eval(expr, envir, enclos) : object 'y1' not found
>>
>>> sessionInfo()
>> R version 3.2.3 (2015-12-10)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.11.2 (El Capitan)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.3
>>
>>
>>        I don't understand this, but "with" is acceptable for my current
>> needs.
>>
>>
>>        Thanks again to Bert & Jeff.
>>
>>
>>        Spencer Graves
>>>
>>> Best,
>>> Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Feb 8, 2016 at 8:10 PM, Spencer Graves
>>> <spencer.graves at effectivedefense.org> wrote:
>>>> Hi, Jeff et al.:
>>>>
>>>>
>>>> On 2/8/2016 9:52 PM, Jeff Newmiller wrote:
>>>>> plotxy(y1~x1, XY, xlim=c(0, max(XY$x1)))
>>>>
>>>>          Yes, Thanks.
>>>>
>>>>
>>>>          Is there a way to do this from within "plotxy", so I can call
>>>> "plotxy" as I call "plot"?
>>>>
>>>>
>>>>          Thanks,
>>>>          Spencer
>>>>
>>>>
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On February 8, 2016 7:17:57 PM PST, Spencer Graves
>>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>>
>>>>>       I'm getting an interesting error:
>>>>>
>>>>>
>>>>>           plotxy <- function(x, ...){
>>>>>
>>>>>       +   plot(x, ...)
>>>>>       + }
>>>>>
>>>>>           XY <- data.frame(x1=1:3, y1=4:6) plotxy(y1~x1, XY, xlim=c(0,
>>>>>           max(x1)))
>>>>>
>>>>>          Show Traceback
>>>>>
>>>>>          Rerun with Debug
>>>>>          Error in eval(expr, envir, enclos) : object 'x1' not found
>>>>>
>>>>>
>>>>>               The following work:
>>>>>
>>>>>
>>>>>       plotxy(y1~x1, XY)
>>>>>       plot(y1~x1, XY, xlim=c(0, max(x1)))
>>>>>
>>>>>
>>>>>               Within "plotxy", R can't find "x1" to compute "xlim".  Is
>>>>> there a
>>>>>       way I can make x1 available to xlim?
>>>>>
>>>>>
>>>>>               Thanks,
>>>>>               Spencer
>>>>>
>>>>>
>>>>> ------------------------------------------------------------------------
>>>>>
>>>>>       R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>       PLEASE do read the posting
>>>>> guidehttp://www.R-project.org/posting-guide.html
>>>>>       and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>


From davidsmi at microsoft.com  Wed Feb 10 00:07:28 2016
From: davidsmi at microsoft.com (David Smith)
Date: Tue, 9 Feb 2016 23:07:28 +0000
Subject: [R] Revolutions blog: January 2016 roundup
Message-ID: <DM2PR0301MB0848536FBBE92002285EF66AC8D60@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of January:

Animated visualizations and analysis of data from NYC's municipal bike program, created with R:
http://blog.revolutionanalytics.com/2016/01/new-yorkers-municipal-bikes-and-the-weather.html

Many local R user groups are sharing materials from meetups using Github:
http://blog.revolutionanalytics.com/2016/01/r-user-groups-on-github.html

A detailed R tutorial on analyzing your Twitter archive and performing sentiment analysis:
http://blog.revolutionanalytics.com/2016/01/twitter-sentiment.html

How to combine R and Python in Jupyter notebooks: http://blog.revolutionanalytics.com/2016/01/pipelining-r-python.html

Many datasets are available for analysis in R using Kaggle's online platform, including the American Community Survey:
http://blog.revolutionanalytics.com/2016/01/american-community-survey-analyzed-with-r.html

Getting started with Markov Chains in R
http://blog.revolutionanalytics.com/2016/01/getting-started-with-markov-chains.html and even more R packages for Markov
Chain analysis: http://blog.revolutionanalytics.com/2016/01/markov-chains-part-2.html

Replays are available for recent webinars on Microsoft R Open and Microsoft R Server:
http://blog.revolutionanalytics.com/2016/01/microsoft-r-webinars.html

Microsoft R Open 3.2.3 (formerly Revolution R Open), and new CRAN Time Machine now available at MRAN:
http://blog.revolutionanalytics.com/2016/01/microsoft-r-open-323-now-available.html

Overview of parallel computing in R:
http://blog.revolutionanalytics.com/2016/01/a-gentle-introduction-to-parallel-computing-in-r.html

R packages providing sources of data: http://blog.revolutionanalytics.com/2016/01/new-data-sources-for-r.html

Visual Studio will soon support the R language: http://blog.revolutionanalytics.com/2016/01/new-data-sources-for-r.html

Microsoft R Server available free to students and developers:
http://blog.revolutionanalytics.com/2016/01/r-dreamspark.html

Revolution R is now Microsoft R: http://blog.revolutionanalytics.com/2016/01/microsoft-r-open.html

A new ggplot2 extension avoids overlapping text labels:
http://blog.revolutionanalytics.com/2016/01/avoid-overlapping-labels-in-ggplot2-charts.html

R played a big part in a scientific breakthrough regarding reproducibility of results:
http://blog.revolutionanalytics.com/2016/01/rs-role-in-science-breakthrough-reproducibility-of-psychology-studies.html

An online data science course using Microsoft Azure and R:
http://blog.revolutionanalytics.com/2016/01/video-course-data-science-with-microsoft-azure-and-r.html

A review of the 7th R user conference in Spain:
http://blog.revolutionanalytics.com/2016/01/7th-meeting-of-spanish-r-users-5-6-november-2015-salamanca-spain.html

Using network analysis in R to explore connections in the movie "Love Actually"
http://blog.revolutionanalytics.com/2016/01/analyzing-movie-connections-with-r.html

The most popular posts on the Revolutions blog in 2015:
http://blog.revolutionanalytics.com/2016/01/top-posts-of-2015.html

General interest stories (not related to R) in the past month included: pinball skills
(http://blog.revolutionanalytics.com/2016/01/because-its-friday-flipper-tricks.html), when walking up the escalator is
inefficient (http://blog.revolutionanalytics.com/2016/01/because-its-friday-stand-on-the-left-and-on-the-right.html),
Pokemon or Big Data (http://blog.revolutionanalytics.com/2016/01/because-its-friday-pokemon-or-big-data-tool.html), and
mimicking famous guitar styles (http://blog.revolutionanalytics.com/2016/01/get-lucky-guitar.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the
updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html
If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From heshamibb at yahoo.com  Wed Feb 10 06:02:07 2016
From: heshamibb at yahoo.com (hehsham alpukhity)
Date: Wed, 10 Feb 2016 05:02:07 +0000 (UTC)
Subject: [R] generate levels with different number of replications with gl()
 function
References: <1649581181.1930596.1455080527164.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1649581181.1930596.1455080527164.JavaMail.yahoo@mail.yahoo.com>

I am trying to use the function gl (generate levels with different number of replications), generate different number of replications in each level.examplei have factor with this levels (BR,CNS ,CO,LE,ME,LC,OV,PR,RE),
?and the replications is not the same , i want (4 replication for BR),( 6 replications for?
CNS,7 replications for CO,6 for LE,10 for ME,9 for LC,7 for OV, 2 for PR ,and 8 for RE).thank you v much .?Hisham AL-bukhaiti??Ph.D Student?(Information system )??China, changsha,Hunan university.??Mobile: 0068-15 111 4246 91.
	[[alternative HTML version deleted]]


From seotaewong40 at gmail.com  Wed Feb 10 04:15:20 2016
From: seotaewong40 at gmail.com (Tae Wong)
Date: Wed, 10 Feb 2016 12:15:20 +0900
Subject: [R] Complete archives for MARC needed for r-devel,
	r-help and r-packages
Message-ID: <CAMumzTehy340VB7Ai69JJqhAU1ZNvUR12HhDM3EgN=DOpPOWFg@mail.gmail.com>

I need the archives for r-help from October 2007 to November 2013 in MARC [1].

The same goes for r-devel [2] who needs archives for July 2005 to
November 2013 and r-packages [3] needing archives for August 2007 to
December 2013.

P.S.: I'm not subscribed to this mailing list.

[1] http://marc.info/?l=r-help
[2] http://marc.info/?l=r-devel
[3] http://marc.info/?l=r-packages


From dwinsemius at comcast.net  Wed Feb 10 07:18:53 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 Feb 2016 22:18:53 -0800
Subject: [R] Complete archives for MARC needed for r-devel,
	r-help and r-packages
In-Reply-To: <CAMumzTehy340VB7Ai69JJqhAU1ZNvUR12HhDM3EgN=DOpPOWFg@mail.gmail.com>
References: <CAMumzTehy340VB7Ai69JJqhAU1ZNvUR12HhDM3EgN=DOpPOWFg@mail.gmail.com>
Message-ID: <BF87540A-8DE5-41E8-BCE1-BD2289EE1223@comcast.net>


> On Feb 9, 2016, at 7:15 PM, Tae Wong <seotaewong40 at gmail.com> wrote:
> 
> I need the archives for r-help from October 2007 to November 2013 in MARC [1].
> 
> The same goes for r-devel [2] who needs archives for July 2005 to
> November 2013 and r-packages [3] needing archives for August 2007 to
> December 2013.
> 

Appears you want to fill in the gap. The original is here:

https://stat.ethz.ch/pipermail/r-help/

You can find the r-devel and package archives by following links in the info pages.

https://stat.ethz.ch/mailman/listinfo/r-devel

https://stat.ethz.ch/mailman/listinfo/r-packages


> P.S.: I'm not subscribed to this mailing list.
> 
> [1] http://marc.info/?l=r-help
> [2] http://marc.info/?l=r-devel
> [3] http://marc.info/?l=r-packages
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From waser at frankenfoerder-fg.de  Wed Feb 10 10:04:26 2016
From: waser at frankenfoerder-fg.de (Wolfgang Waser)
Date: Wed, 10 Feb 2016 10:04:26 +0100
Subject: [R] How to extract same columns from identical dataframes in a
 list?
In-Reply-To: <E749E4FE-AC69-4F60-9625-9DD7E8C7F09B@gmail.com>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu> <56B9AB45.10603@frankenfoerder-fg.de>
	<E749E4FE-AC69-4F60-9625-9DD7E8C7F09B@gmail.com>
Message-ID: <56BAFD1A.1060705@frankenfoerder-fg.de>

Hi,

sapply(l,"[",T,2)

and

sapply(l, function(e) e[, 2])


work fine!


Thanks a lot!

Why is the second version "brute force and ignorance"? Is one of the
versions to be preferred? If so, which and why (very briefly, please)?


Results of the other options mentioned:

> sapply(l,"[[",2)

results in a single vector of length 7


> sapply(l,"[",,2)
Error in lapply(X = X, FUN = FUN, ...) :
argument is missing, with no default

These versions probably don't work due the "data frames" in the list
actually being matrices.


I'm not enough of a programer to always make complete sense of the R
help pages. Should I have found this information in the sapply - R help
page?
Where else could I check before pestering the R mailing list, which, of
course, provides quick and valuable answers.


Cheers,

Wolfgang




On 09/02/16 16:19, peter dalgaard wrote:
> Like this?
> 
>> l <- replicate(3,data.frame(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
>> l
> [[1]]
>   w1 w2
> 1  2  2
> 2  3  3
> 3  1  1
> 4  4  4
> 
> [[2]]
>   w1 w2
> 1  3  4
> 2  2  2
> 3  1  3
> 4  4  1
> 
> [[3]]
>   w1 w2
> 1  1  4
> 2  4  3
> 3  2  1
> 4  3  2
> 
>> sapply(l,"[[",2)
>      [,1] [,2] [,3]
> [1,]    2    4    4
> [2,]    3    2    3
> [3,]    1    3    1
> [4,]    4    1    2
> 
> Or even
> 
>> sapply(l,"[",,2)
>      [,1] [,2] [,3]
> [1,]    2    4    4
> [2,]    3    2    3
> [3,]    1    3    1
> [4,]    4    1    2
> 
> 
> Notice that if dd[1:24] gives you the 1st column, then dd is not a data frame but rather a matrix, and indexing semantics are different. In that case, for some unspeakable reason, the empty index does not work and you'll need something like
> 
>> l <- replicate(3,cbind(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
>> sapply(l,"[",T,2)
>      [,1] [,2] [,3]
> [1,]    4    3    2
> [2,]    1    1    4
> [3,]    3    2    3
> [4,]    2    4    1
> 
> Or, brute-force-and-ignorance:
> 
>> sapply(l, function(e) e[, 2])
>      [,1] [,2] [,3]
> [1,]    4    3    2
> [2,]    1    1    4
> [3,]    3    2    3
> [4,]    2    4    1
> 
> 
> 
> 
> 
> On 09 Feb 2016, at 10:03 , Wolfgang Waser <waser at frankenfoerder-fg.de> wrote:
> 
>> Hi,
>>
>> sorry if my description was too short / unclear.
>>
>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>
>> [1]
>> 	week1	week2	week3	...
>> 1	x	a	m	...
>> 2	y	b	n
>> 3	z	c	o
>> .	.	.	.
>> .	.	.	.
>> .	.	.	.
>> 24	.	.	.
>>
>>
>> [2]
>> 	week1 week2 week3 ...
>> 1	x2	a2	m2	...
>> 2	y2	b2	n2
>> 3	z2	c2	o2
>> .	.	.	.
>> .	.	.	.
>> .	.	.	.
>> 24	.	.	.
>>
>>
>> [3]
>> ...
>>
>> .
>> .
>> .
>>
>>
>> [7]
>> ...
>>
>>
>>
>> I now would like to extract e.g. all week2 columns of all data frames in
>> the list and combine them in a new data frame using cbind.
>>
>> new data frame
>>
>> week2 ([1])	week2 ([2])	week2 ([3])	...
>> a		a2		.
>> b		b2		.
>> c		c2		.
>> .
>> .
>> .
>>
>> I will then do further row-wise calculations using e.g. apply(x,1,mean),
>> the result being a vector of 24 values.
>>
>>
>> I have not found a way to extract specific columns of the data frames in
>> a list.
>>
>>
>> As mentioned I can use
>>
>> sapply(list_of_dataframes,"[",1:24)
>>
>> which will pick the first 24 values (first column) of each data frame in
>> the list and arrange them as an array of 24 rows and 7 columns (7 data
>> frames are in the list).
>> To pick the second column (week2) using sapply I have to use the next 24
>> values from 25 to 48:
>>
>> sapply(list_of_dataframes,"[",25:48)
>>
>>
>> It seems that sapply treats the data frames in the list as vectors. I
>> can of course extract all consecutive weeks using consecutive blocks of
>> 24 values, but this seems cumbersome.
>>
>>
>> The question remains, how to select specific columns from data frames in
>> a list, e.g. all columns 3 of all data frames in the list.
>>
>>
>> Reformatting (unlist(), dim()) in one data frame with one column for
>> each week does not help, since I'm not calculating colMeans etc, but
>> row-wise calculations using apply(x,1,FUN) ("applying a function to
>> margins of an array or matrix").
>>
>>
>>
>> Thanks for you help and suggestions!
>>
>>
>> Wolfgang
>>
>>
>>
>> On 08/02/16 18:00, D?nes T?th wrote:
>>> Hi,
>>>
>>> Although you did not provide any reproducible example, it seems you
>>> store the same type of values in your data.frames. If this is true, it
>>> is much more efficient to store your data in an array:
>>>
>>> mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
>>>               b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
>>>
>>> myarray <- unlist(mylist, use.names = FALSE)
>>> dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
>>> dimnames(myarray) <- list(hour = rownames(mylist$a),
>>>                          week = colnames(mylist$a),
>>>                          other = names(mylist))
>>> # now you can do:
>>> mean(myarray[, "week1", "a"])
>>>
>>> # or:
>>> colMeans(myarray)
>>>
>>>
>>> Cheers,
>>>  Denes
>>>
>>>
>>> On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
>>>> Hello,
>>>>
>>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>>>
>>>> I would like to combine all 7 columns of week 1 (and 2 ...) in a
>>>> separate data frame for hourly calculations, e.g.
>>>>> apply(new.data.frame,1,mean)
>>>>
>>>> In some way sapply (lapply) works, but I cannot directly select columns
>>>> of the original data frames in the list. As a workaround I have to
>>>> select a range of values:
>>>>
>>>>> sapply(list_of_dataframes,"[",1:24)
>>>>
>>>> Values 1:24 give the first column, 25:48 the second and so on.
>>>>
>>>> Is there an easier / more direct way to select for specific columns
>>>> instead of selecting a range of values, avoiding loops?
>>>>
>>>>
>>>> Cheers,
>>>>
>>>> Wolfgang
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From dnbarron at gmail.com  Wed Feb 10 11:42:50 2016
From: dnbarron at gmail.com (David Barron)
Date: Wed, 10 Feb 2016 10:42:50 +0000
Subject: [R] generate levels with different number of replications with
 gl() function
In-Reply-To: <1649581181.1930596.1455080527164.JavaMail.yahoo@mail.yahoo.com>
References: <1649581181.1930596.1455080527164.JavaMail.yahoo.ref@mail.yahoo.com>
	<1649581181.1930596.1455080527164.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAHuze_LRgV=KiQsFZSpngyN8HJX-m38kYreC7zJ4Kneu4qvvaA@mail.gmail.com>

Why not use rep instead of gl:

levels <- c('BR', 'CNS', 'CO', 'LE', 'ME', 'LC', 'OV', 'PR', 'RE')
reps <- c(4, 6, 7, 6, 10, 9, 7, 2, 8)
rep(levels, reps)

David

On 10 February 2016 at 05:02, hehsham alpukhity via R-help <
r-help at r-project.org> wrote:

> I am trying to use the function gl (generate levels with different number
> of replications), generate different number of replications in each
> level.examplei have factor with this levels (BR,CNS ,CO,LE,ME,LC,OV,PR,RE),
>  and the replications is not the same , i want (4 replication for BR),( 6
> replications for
> CNS,7 replications for CO,6 for LE,10 for ME,9 for LC,7 for OV, 2 for PR
> ,and 8 for RE).thank you v much . Hisham AL-bukhaiti  Ph.D
> Student (Information system )  China, changsha,Hunan university.  Mobile:
> 0068-15 111 4246 91.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Wed Feb 10 13:40:06 2016
From: venkynov10 at gmail.com (Venky)
Date: Wed, 10 Feb 2016 18:10:06 +0530
Subject: [R] Shiny Import data set
Message-ID: <CAAM-fZ4Ah+6boVoLDKB8-Abzo4aU=9B8rvzJBreOfU_ZCGeURA@mail.gmail.com>

Hi,

I am trying to import Excel data set into Shiny app and i want to to create
dropdown menu for that.
Eg:1st column of the Excel data must come one tab, and 2nd column of Excel
data is an another,...and so on

And i have seperate caluculation file like(Wordcloud,Binomial Reg etc). I
want to merge these file into Shiny and UI. Please do the needful to figure
out this issues.

Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Wed Feb 10 13:41:30 2016
From: venkynov10 at gmail.com (Venky)
Date: Wed, 10 Feb 2016 18:11:30 +0530
Subject: [R] Shiny
Message-ID: <CAAM-fZ5FX=P8rVZPY-XkUjtfEoaczDOwh+QU_86pCH3XJ2LZRw@mail.gmail.com>

Hi Team,

Please anyone share the Shiny app code(Server and UI)  for Multiple Linear
Regression. With dropdown menu

Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Feb 10 14:23:07 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Feb 2016 08:23:07 -0500
Subject: [R] Shiny
In-Reply-To: <CAAM-fZ5FX=P8rVZPY-XkUjtfEoaczDOwh+QU_86pCH3XJ2LZRw@mail.gmail.com>
References: <CAAM-fZ5FX=P8rVZPY-XkUjtfEoaczDOwh+QU_86pCH3XJ2LZRw@mail.gmail.com>
Message-ID: <56BB39BB.9010801@gmail.com>

On 10/02/2016 7:41 AM, Venky wrote:
> Hi Team,
>
> Please anyone share the Shiny app code(Server and UI)  for Multiple Linear
> Regression. With dropdown menu
>

This is the wrong place to write for help with Shiny.  I think RStudio 
runs some forums for that, and StackOverflow also answers questions 
about it.

Duncan Murdoch


From pdalgd at gmail.com  Wed Feb 10 15:48:49 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 10 Feb 2016 15:48:49 +0100
Subject: [R] How to extract same columns from identical dataframes in a
	list?
In-Reply-To: <56BAFD1A.1060705@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu> <56B9AB45.10603@frankenfoerder-fg.de>
	<E749E4FE-AC69-4F60-9625-9DD7E8C7F09B@gmail.com>
	<56BAFD1A.1060705@frankenfoerder-fg.de>
Message-ID: <059BE954-15AC-478E-A928-8621E30D2C73@gmail.com>


On 10 Feb 2016, at 10:04 , Wolfgang Waser <waser at frankenfoerder-fg.de> wrote:

> Hi,
> 
> sapply(l,"[",T,2)
> 
> and
> 
> sapply(l, function(e) e[, 2])
> 
> 
> work fine!
> 
> 
> Thanks a lot!
> 
> Why is the second version "brute force and ignorance"? Is one of the
> versions to be preferred? If so, which and why (very briefly, please)?


It's slightly less elegant and it requires you to set up an extra function, rather than just using the indexing operator as a function. 

On the other hand, it is the obvious generic approach: Write a function to do what you want for one element, then apply the function to each element with sapply(). The extra overhead is likely irrelevant. It is also more readable since you don't need to mentally keep track of things like the fact that "["(x,T,2) is the same as x[T,2].



> 
> 
> Results of the other options mentioned:
> 
>> sapply(l,"[[",2)
> 
> results in a single vector of length 7
> 
> 
>> sapply(l,"[",,2)
> Error in lapply(X = X, FUN = FUN, ...) :
> argument is missing, with no default
> 
> These versions probably don't work due the "data frames" in the list
> actually being matrices.

Exactly.

> 
> 
> I'm not enough of a programer to always make complete sense of the R
> help pages. Should I have found this information in the sapply - R help
> page?

Not really. Well, the brute-force-and-ignorance approach should transpire, but the sapply(l, "[",.....) stuff requires that you first understand that operators are really function calls, and the what arguments they take. The is part of a general understanding that won't fit in any individual help page.

> Where else could I check before pestering the R mailing list, which, of
> course, provides quick and valuable answers.

You may need someone who got intro'ed shorter time ago than me for that. There are multiple books on R programming and also the free manuals from CRAN could be useful.

-pd


> 
> 
> Cheers,
> 
> Wolfgang
> 
> 
> 
> 
> On 09/02/16 16:19, peter dalgaard wrote:
>> Like this?
>> 
>>> l <- replicate(3,data.frame(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
>>> l
>> [[1]]
>>  w1 w2
>> 1  2  2
>> 2  3  3
>> 3  1  1
>> 4  4  4
>> 
>> [[2]]
>>  w1 w2
>> 1  3  4
>> 2  2  2
>> 3  1  3
>> 4  4  1
>> 
>> [[3]]
>>  w1 w2
>> 1  1  4
>> 2  4  3
>> 3  2  1
>> 4  3  2
>> 
>>> sapply(l,"[[",2)
>>     [,1] [,2] [,3]
>> [1,]    2    4    4
>> [2,]    3    2    3
>> [3,]    1    3    1
>> [4,]    4    1    2
>> 
>> Or even
>> 
>>> sapply(l,"[",,2)
>>     [,1] [,2] [,3]
>> [1,]    2    4    4
>> [2,]    3    2    3
>> [3,]    1    3    1
>> [4,]    4    1    2
>> 
>> 
>> Notice that if dd[1:24] gives you the 1st column, then dd is not a data frame but rather a matrix, and indexing semantics are different. In that case, for some unspeakable reason, the empty index does not work and you'll need something like
>> 
>>> l <- replicate(3,cbind(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
>>> sapply(l,"[",T,2)
>>     [,1] [,2] [,3]
>> [1,]    4    3    2
>> [2,]    1    1    4
>> [3,]    3    2    3
>> [4,]    2    4    1
>> 
>> Or, brute-force-and-ignorance:
>> 
>>> sapply(l, function(e) e[, 2])
>>     [,1] [,2] [,3]
>> [1,]    4    3    2
>> [2,]    1    1    4
>> [3,]    3    2    3
>> [4,]    2    4    1
>> 
>> 
>> 
>> 
>> 
>> On 09 Feb 2016, at 10:03 , Wolfgang Waser <waser at frankenfoerder-fg.de> wrote:
>> 
>>> Hi,
>>> 
>>> sorry if my description was too short / unclear.
>>> 
>>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>> 
>>> [1]
>>> 	week1	week2	week3	...
>>> 1	x	a	m	...
>>> 2	y	b	n
>>> 3	z	c	o
>>> .	.	.	.
>>> .	.	.	.
>>> .	.	.	.
>>> 24	.	.	.
>>> 
>>> 
>>> [2]
>>> 	week1 week2 week3 ...
>>> 1	x2	a2	m2	...
>>> 2	y2	b2	n2
>>> 3	z2	c2	o2
>>> .	.	.	.
>>> .	.	.	.
>>> .	.	.	.
>>> 24	.	.	.
>>> 
>>> 
>>> [3]
>>> ...
>>> 
>>> .
>>> .
>>> .
>>> 
>>> 
>>> [7]
>>> ...
>>> 
>>> 
>>> 
>>> I now would like to extract e.g. all week2 columns of all data frames in
>>> the list and combine them in a new data frame using cbind.
>>> 
>>> new data frame
>>> 
>>> week2 ([1])	week2 ([2])	week2 ([3])	...
>>> a		a2		.
>>> b		b2		.
>>> c		c2		.
>>> .
>>> .
>>> .
>>> 
>>> I will then do further row-wise calculations using e.g. apply(x,1,mean),
>>> the result being a vector of 24 values.
>>> 
>>> 
>>> I have not found a way to extract specific columns of the data frames in
>>> a list.
>>> 
>>> 
>>> As mentioned I can use
>>> 
>>> sapply(list_of_dataframes,"[",1:24)
>>> 
>>> which will pick the first 24 values (first column) of each data frame in
>>> the list and arrange them as an array of 24 rows and 7 columns (7 data
>>> frames are in the list).
>>> To pick the second column (week2) using sapply I have to use the next 24
>>> values from 25 to 48:
>>> 
>>> sapply(list_of_dataframes,"[",25:48)
>>> 
>>> 
>>> It seems that sapply treats the data frames in the list as vectors. I
>>> can of course extract all consecutive weeks using consecutive blocks of
>>> 24 values, but this seems cumbersome.
>>> 
>>> 
>>> The question remains, how to select specific columns from data frames in
>>> a list, e.g. all columns 3 of all data frames in the list.
>>> 
>>> 
>>> Reformatting (unlist(), dim()) in one data frame with one column for
>>> each week does not help, since I'm not calculating colMeans etc, but
>>> row-wise calculations using apply(x,1,FUN) ("applying a function to
>>> margins of an array or matrix").
>>> 
>>> 
>>> 
>>> Thanks for you help and suggestions!
>>> 
>>> 
>>> Wolfgang
>>> 
>>> 
>>> 
>>> On 08/02/16 18:00, D?nes T?th wrote:
>>>> Hi,
>>>> 
>>>> Although you did not provide any reproducible example, it seems you
>>>> store the same type of values in your data.frames. If this is true, it
>>>> is much more efficient to store your data in an array:
>>>> 
>>>> mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
>>>>              b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
>>>> 
>>>> myarray <- unlist(mylist, use.names = FALSE)
>>>> dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
>>>> dimnames(myarray) <- list(hour = rownames(mylist$a),
>>>>                         week = colnames(mylist$a),
>>>>                         other = names(mylist))
>>>> # now you can do:
>>>> mean(myarray[, "week1", "a"])
>>>> 
>>>> # or:
>>>> colMeans(myarray)
>>>> 
>>>> 
>>>> Cheers,
>>>> Denes
>>>> 
>>>> 
>>>> On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
>>>>> Hello,
>>>>> 
>>>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>>>> 
>>>>> I would like to combine all 7 columns of week 1 (and 2 ...) in a
>>>>> separate data frame for hourly calculations, e.g.
>>>>>> apply(new.data.frame,1,mean)
>>>>> 
>>>>> In some way sapply (lapply) works, but I cannot directly select columns
>>>>> of the original data frames in the list. As a workaround I have to
>>>>> select a range of values:
>>>>> 
>>>>>> sapply(list_of_dataframes,"[",1:24)
>>>>> 
>>>>> Values 1:24 give the first column, 25:48 the second and so on.
>>>>> 
>>>>> Is there an easier / more direct way to select for specific columns
>>>>> instead of selecting a range of values, avoiding loops?
>>>>> 
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Wolfgang
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter.4567 at gmail.com  Wed Feb 10 16:27:29 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Feb 2016 07:27:29 -0800
Subject: [R] How to extract same columns from identical dataframes in a
	list?
In-Reply-To: <56BAFD1A.1060705@frankenfoerder-fg.de>
References: <56B89921.4040405@frankenfoerder-fg.de>
	<56B8C997.2010201@ttk.mta.hu> <56B9AB45.10603@frankenfoerder-fg.de>
	<E749E4FE-AC69-4F60-9625-9DD7E8C7F09B@gmail.com>
	<56BAFD1A.1060705@frankenfoerder-fg.de>
Message-ID: <CAGxFJbQveBN8s1p+MBc9PB6ZoiA-u3H0Jogdf_R1L8FKpwon6A@mail.gmail.com>

Google! (e.g. on "R Language tutorials")

Some specific recommendations can be found here:

https://www.rstudio.com/resources/training/online-learning/#R


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 10, 2016 at 1:04 AM, Wolfgang Waser
<waser at frankenfoerder-fg.de> wrote:
> Hi,
>
> sapply(l,"[",T,2)
>
> and
>
> sapply(l, function(e) e[, 2])
>
>
> work fine!
>
>
> Thanks a lot!
>
> Why is the second version "brute force and ignorance"? Is one of the
> versions to be preferred? If so, which and why (very briefly, please)?
>
>
> Results of the other options mentioned:
>
>> sapply(l,"[[",2)
>
> results in a single vector of length 7
>
>
>> sapply(l,"[",,2)
> Error in lapply(X = X, FUN = FUN, ...) :
> argument is missing, with no default
>
> These versions probably don't work due the "data frames" in the list
> actually being matrices.
>
>
> I'm not enough of a programer to always make complete sense of the R
> help pages. Should I have found this information in the sapply - R help
> page?
> Where else could I check before pestering the R mailing list, which, of
> course, provides quick and valuable answers.
>
>
> Cheers,
>
> Wolfgang
>
>
>
>
> On 09/02/16 16:19, peter dalgaard wrote:
>> Like this?
>>
>>> l <- replicate(3,data.frame(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
>>> l
>> [[1]]
>>   w1 w2
>> 1  2  2
>> 2  3  3
>> 3  1  1
>> 4  4  4
>>
>> [[2]]
>>   w1 w2
>> 1  3  4
>> 2  2  2
>> 3  1  3
>> 4  4  1
>>
>> [[3]]
>>   w1 w2
>> 1  1  4
>> 2  4  3
>> 3  2  1
>> 4  3  2
>>
>>> sapply(l,"[[",2)
>>      [,1] [,2] [,3]
>> [1,]    2    4    4
>> [2,]    3    2    3
>> [3,]    1    3    1
>> [4,]    4    1    2
>>
>> Or even
>>
>>> sapply(l,"[",,2)
>>      [,1] [,2] [,3]
>> [1,]    2    4    4
>> [2,]    3    2    3
>> [3,]    1    3    1
>> [4,]    4    1    2
>>
>>
>> Notice that if dd[1:24] gives you the 1st column, then dd is not a data frame but rather a matrix, and indexing semantics are different. In that case, for some unspeakable reason, the empty index does not work and you'll need something like
>>
>>> l <- replicate(3,cbind(w1=sample(1:4),w2=sample(1:4)), simplify=FALSE)
>>> sapply(l,"[",T,2)
>>      [,1] [,2] [,3]
>> [1,]    4    3    2
>> [2,]    1    1    4
>> [3,]    3    2    3
>> [4,]    2    4    1
>>
>> Or, brute-force-and-ignorance:
>>
>>> sapply(l, function(e) e[, 2])
>>      [,1] [,2] [,3]
>> [1,]    4    3    2
>> [2,]    1    1    4
>> [3,]    3    2    3
>> [4,]    2    4    1
>>
>>
>>
>>
>>
>> On 09 Feb 2016, at 10:03 , Wolfgang Waser <waser at frankenfoerder-fg.de> wrote:
>>
>>> Hi,
>>>
>>> sorry if my description was too short / unclear.
>>>
>>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>>
>>> [1]
>>>      week1   week2   week3   ...
>>> 1    x       a       m       ...
>>> 2    y       b       n
>>> 3    z       c       o
>>> .    .       .       .
>>> .    .       .       .
>>> .    .       .       .
>>> 24   .       .       .
>>>
>>>
>>> [2]
>>>      week1 week2 week3 ...
>>> 1    x2      a2      m2      ...
>>> 2    y2      b2      n2
>>> 3    z2      c2      o2
>>> .    .       .       .
>>> .    .       .       .
>>> .    .       .       .
>>> 24   .       .       .
>>>
>>>
>>> [3]
>>> ...
>>>
>>> .
>>> .
>>> .
>>>
>>>
>>> [7]
>>> ...
>>>
>>>
>>>
>>> I now would like to extract e.g. all week2 columns of all data frames in
>>> the list and combine them in a new data frame using cbind.
>>>
>>> new data frame
>>>
>>> week2 ([1])  week2 ([2])     week2 ([3])     ...
>>> a            a2              .
>>> b            b2              .
>>> c            c2              .
>>> .
>>> .
>>> .
>>>
>>> I will then do further row-wise calculations using e.g. apply(x,1,mean),
>>> the result being a vector of 24 values.
>>>
>>>
>>> I have not found a way to extract specific columns of the data frames in
>>> a list.
>>>
>>>
>>> As mentioned I can use
>>>
>>> sapply(list_of_dataframes,"[",1:24)
>>>
>>> which will pick the first 24 values (first column) of each data frame in
>>> the list and arrange them as an array of 24 rows and 7 columns (7 data
>>> frames are in the list).
>>> To pick the second column (week2) using sapply I have to use the next 24
>>> values from 25 to 48:
>>>
>>> sapply(list_of_dataframes,"[",25:48)
>>>
>>>
>>> It seems that sapply treats the data frames in the list as vectors. I
>>> can of course extract all consecutive weeks using consecutive blocks of
>>> 24 values, but this seems cumbersome.
>>>
>>>
>>> The question remains, how to select specific columns from data frames in
>>> a list, e.g. all columns 3 of all data frames in the list.
>>>
>>>
>>> Reformatting (unlist(), dim()) in one data frame with one column for
>>> each week does not help, since I'm not calculating colMeans etc, but
>>> row-wise calculations using apply(x,1,FUN) ("applying a function to
>>> margins of an array or matrix").
>>>
>>>
>>>
>>> Thanks for you help and suggestions!
>>>
>>>
>>> Wolfgang
>>>
>>>
>>>
>>> On 08/02/16 18:00, D?nes T?th wrote:
>>>> Hi,
>>>>
>>>> Although you did not provide any reproducible example, it seems you
>>>> store the same type of values in your data.frames. If this is true, it
>>>> is much more efficient to store your data in an array:
>>>>
>>>> mylist <- list(a = data.frame(week1 = rnorm(24), week2 = rnorm(24)),
>>>>               b = data.frame(week1 = rnorm(24), week2 = rnorm(24)))
>>>>
>>>> myarray <- unlist(mylist, use.names = FALSE)
>>>> dim(myarray) <- c(nrow(mylist$a), ncol(mylist$a), length(mylist))
>>>> dimnames(myarray) <- list(hour = rownames(mylist$a),
>>>>                          week = colnames(mylist$a),
>>>>                          other = names(mylist))
>>>> # now you can do:
>>>> mean(myarray[, "week1", "a"])
>>>>
>>>> # or:
>>>> colMeans(myarray)
>>>>
>>>>
>>>> Cheers,
>>>>  Denes
>>>>
>>>>
>>>> On 02/08/2016 02:33 PM, Wolfgang Waser wrote:
>>>>> Hello,
>>>>>
>>>>> I have a list of 7 data frames, each data frame having 24 rows (hour of
>>>>> the day) and 5 columns (weeks) with a total of 5 x 24 values
>>>>>
>>>>> I would like to combine all 7 columns of week 1 (and 2 ...) in a
>>>>> separate data frame for hourly calculations, e.g.
>>>>>> apply(new.data.frame,1,mean)
>>>>>
>>>>> In some way sapply (lapply) works, but I cannot directly select columns
>>>>> of the original data frames in the list. As a workaround I have to
>>>>> select a range of values:
>>>>>
>>>>>> sapply(list_of_dataframes,"[",1:24)
>>>>>
>>>>> Values 1:24 give the first column, 25:48 the second and so on.
>>>>>
>>>>> Is there an easier / more direct way to select for specific columns
>>>>> instead of selecting a range of values, avoiding loops?
>>>>>
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Wolfgang
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From collet.lila at gmail.com  Wed Feb 10 16:19:21 2016
From: collet.lila at gmail.com (Lila Collet)
Date: Wed, 10 Feb 2016 15:19:21 +0000
Subject: [R] MonteCarlo sampling on profile log likelihood - package extRemes
Message-ID: <CACddt2dBeO=tXHuVp3DK4xmzOxVjftM3JoRadO4xQ05z=sDmxg@mail.gmail.com>

Hi


I am using the package extRemes to assess 100-year return period
runoffs with the GEV and GP distribution functions and the associated
95% confidence intervals.

I use the MLE method for that.


Now I would like to sample a few thousands values of return levels on
the profile likelihood between the 95% confidence interval boundaries.

I saw that the function ?profliker? allows to sample log-likelihood
values along the profile likelihood.

Is there any way to sample return levels or get the return levels
corresponding to these log-likelihood values?


Thanks for any help.

Kind regards,

LCollet


From bortolamiol.sarah at gmail.com  Wed Feb 10 12:01:00 2016
From: bortolamiol.sarah at gmail.com (Sarah Bortolamiol)
Date: Wed, 10 Feb 2016 12:01:00 +0100
Subject: [R] MCA, Rcmdr, FactoMineR
Message-ID: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>

Dear R users,

I am a beginner in R so my question may be a bit stupid. I tried to search
in forums and did not find the answer I am looking for. I should precise
that I am using Rstudio on Mac (OsX 10.10.5).

I want to run a MCA analysis on my data (with Benzecri correction, with
active and supplementary variables). It seems that the FactoMineR package
is doing this. However, it seems it is not working as it should. In Rstudio
console I call "library(Rcmdr)", and it opens a new window with XQuartz.
Then I want to upload FactoMineR package so I go in tool, I select
FactoMineR and validate. Then I am supposed to charge plug-ins but the
option is not available (see picture attached)
Do you know where it comes from?

Thank you very much for your help,
Sarah

From jfox at mcmaster.ca  Wed Feb 10 17:39:54 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 10 Feb 2016 16:39:54 +0000
Subject: [R] MCA, Rcmdr, FactoMineR
In-Reply-To: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>
References: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F563ED@FHSDB2D11-2.csu.mcmaster.ca>

Dear Sarah,

I don't entirely follow what you did, but my guess is that you installed the Rcmdr and FactoMineR packages but not the RcmdrPlugin.FactoMineR package. If that's the case, then install the RcmdrPlugin.FactoMineR, e.g., via install.packages("RcmdrPlugin.FactoMineR") and try again. 

You should be able to load the plug-in from the R Commander "Tools > Load Rcmdr Plug-in(s)" menu (it works for me). Unfortunately, you can't load the RcmdrPlugin.FactoMineR  package directly by the command library(RcmdrPlugin.FactoMineR) because the authors of the plug-in apparently didn't make it self-starting.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
> Bortolamiol
> Sent: February 10, 2016 6:01 AM
> To: r-help at r-project.org
> Subject: [R] MCA, Rcmdr, FactoMineR
> 
> Dear R users,
> 
> I am a beginner in R so my question may be a bit stupid. I tried to search in
> forums and did not find the answer I am looking for. I should precise that I
> am using Rstudio on Mac (OsX 10.10.5).
> 
> I want to run a MCA analysis on my data (with Benzecri correction, with active
> and supplementary variables). It seems that the FactoMineR package is doing
> this. However, it seems it is not working as it should. In Rstudio console I call
> "library(Rcmdr)", and it opens a new window with XQuartz.
> Then I want to upload FactoMineR package so I go in tool, I select
> FactoMineR and validate. Then I am supposed to charge plug-ins but the
> option is not available (see picture attached) Do you know where it comes
> from?
> 
> Thank you very much for your help,
> Sarah
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Wed Feb 10 17:47:15 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 10 Feb 2016 16:47:15 +0000
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGyA+HMLYtWcndPc4Mn68FD+o4UWSPk0OAcAiR7VrbDGEagHmw@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
	<CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F55E86@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMBzcc8ma-19+ZebH4Ci-xpDm3fvCxg8o=8sFKO4H45Dw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563C2@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMLYtWcndPc4Mn68FD+o4UWSPk0OAcAiR7VrbDGEagHmw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F56414@FHSDB2D11-2.csu.mcmaster.ca>

Dear Sekhar,

> -----Original Message-----
> From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com]
> Sent: February 10, 2016 11:37 AM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: RE: [R] Help required for Rcmdr
> 
> Tks and sorry for inadvertently sending to u alone

And you apparently just did that again, so again I'm cc'ing to r-help.

> In any case I hv tried all
> over again but to no avail Regards Sekhar

I assume that  by "tried all over again" you mean you tried again with an HTTP rather than HTTPS CRAN mirror and that didn't work.

I'm afraid that I'm out of ideas.

Maybe someone else will have a suggestion.

John

> 
> On Feb 10, 2016 9:59 PM, "Fox, John" <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Sekhar,
> 
> 	I'm sorry that you're experiencing these problems. Although you
> haven't said so directly, I assume that you aren't able to use install.packages()
> to install *any* CRAN packages, not just the Rcmdr package.
> 
> 	Downloading and unpacking the Rcmdr zip file doesn't install the
> package. You can install the zip-file binary package from the R Windows GUI
> via the "Packages > Install package(s) from local zip files" menu, but that too
> won't really help because it won't install the many CRAN packages on which
> the Rcmdr depends.
> 
> 	As I said earlier, my guess is that you're experiencing a problem with
> a firewall, proxy server, or HTTPS. If the latter (which was Vito's problem),
> you can easily solve the problem by using an HTTP CRAN server in preference
> to the default HTTPS:
> 
> 	Enter the command chooseCRANmirror(useHTTPS=FALSE) at the R
> Console > prompt and select a CRAN mirror -- I suggest the first (0-Cloud)
> mirror. Then issue the command install.packages("Rcmdr"), as before.
> 
> 	If that doesn't work, I'm afraid I don't have other suggestions.
> 
> 	You appear to have sent this message only to me, not to r-help. That
> not a good idea for several reasons, not least of which is that people who
> have other suggestions won't see your message. I'm cc'ing this response to r-
> help.
> 
> 	Best,
> 	 John
> 
> 	> -----Original Message-----
> 	> From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com
> <mailto:venkatesansekhar at gmail.com> ]
> 	> Sent: February 10, 2016 12:03 AM
> 	> To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> 	> Subject: Re: [R] Help required for Rcmdr
> 	>
> 	> Dear Sirs,
> 	> Thanks to everyone for trying to help me. i have tried several CRAN
> mirrors
> 	> but to no help. I am getting the Zip file for Rcmdr and can also unzip
> the
> 	> same. However, after that i am unable to open the Rcmdr console.
> 	> that is the problem.
> 	> regards
> 	> sekhar
> 	>
> 	> On Tue, Feb 9, 2016 at 10:00 PM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca>
> 	> <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > > wrote:
> 	>
> 	>
> 	>       Hi Rich,
> 	>
> 	>       > -----Original Message-----
> 	>       > From: Richard M. Heiberger [mailto:rmh at temple.edu
> <mailto:rmh at temple.edu>
> 	> <mailto:rmh at temple.edu <mailto:rmh at temple.edu> > ]
> 	>       > Sent: February 9, 2016 4:57 PM
> 	>       > To: Vito M. R. Muggeo <vito.muggeo at unipa.it
> <mailto:vito.muggeo at unipa.it>
> 	> <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
> 	>       > Cc: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > >;
> 	> Sekhar Venkatesan
> 	>       > <venkatesansekhar at gmail.com
> <mailto:venkatesansekhar at gmail.com>
> 	> <mailto:venkatesansekhar at gmail.com
> <mailto:venkatesansekhar at gmail.com> > >; Duncan Murdoch
> 	>       > <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>
> 	> <mailto:murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com> > >; R-help at r-project.org <mailto:R-
> help at r-project.org>  <mailto:R- <mailto:R->
> 	> help at r-project.org <mailto:help at r-project.org> > ; R-windows at r-
> 	>       > project.org <http://project.org>  <http://project.org>
> 	>       > Subject: Re: [R] Help required for Rcmdr
> 	>       >
> 	>       > Several of my students have had this type of difficulty with
> Rstudio.
> 	>       >
> 	>
> 	>       Good to know, but the original poster tried both with the R
> Windows
> 	> SDI and MDI.
> 	>
> 	>       Best,
> 	>        John
> 	>
> 	>
> 	>       > Rstudio masks install.packages with a similarly named function
> in an
> 	>       > environment that does not appear in either
> conflicts(details=TRUE)
> 	> or in
> 	>       > search().
> 	>       >
> 	>       > The workaround is an explicit call to utils
> 	>       >
> 	>       > utils::install.packages("package.name <http://package.name>
> <http://package.name> ")
> 	>       >
> 	>       > Rich
> 	>       >
> 	>       > On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo
> 	> <vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it>
> <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
> 	>       > wrote:
> 	>       > > dear John,
> 	>       > > Thanks for your prompt reply
> 	>       > >
> 	>       > > Il 09/02/2016 16.23, Fox, John ha scritto:
> 	>       > >>
> 	>       > >> Dear Vito,
> 	>       > >>
> 	>       > >> I've never experienced this problem myself in a general
> way,
> 	>       > >
> 	>       > > Me too. I have always installed R packages
> straightforwardly..
> 	>       > >
> 	>       > > and I'm sure that Windows users of R call install.packages()
> all the
> 	>       > > time to install packages from CRAN mirrors.
> 	>       > > Of course..
> 	>       > >
> 	>       > > So the question to ask, I think, is what's preventing
> 	>       > > install.packages() from working in your case -- possibly an
> 	> Internet
> 	>       > > connectivity problem due to a firewall, proxy server, use of
> https,
> 	> etc.
> 	>       > > I'm sure that others more knowledgeable about these issues
> 	> than I am
> 	>       > > will be able to make more specific suggestions for fixing the
> 	> problem.
> 	>       > >
> 	>       > > However I have just checked that it works with *http*
> servers
> 	> (but not
> 	>       > > for any other *https*..)
> 	>       > >
> 	>       > > Thanks for your support,
> 	>       > > best,
> 	>       > > vito
> 	>       > >
> 	>       > >
> 	>       > >>
> 	>       > >> Best,
> 	>       > >>   John
> 	>       > >>
> 	>       > >> -----------------------------
> 	>       > >> John Fox, Professor
> 	>       > >> McMaster University
> 	>       > >> Hamilton, Ontario
> 	>       > >> Canada L8S 4M4
> 	>       > >> web: socserv.mcmaster.ca/jfox
> <http://socserv.mcmaster.ca/jfox>
> 	> <http://socserv.mcmaster.ca/jfox>
> 	>       > >>
> 	>       > >>
> 	>       > >> ________________________________________
> 	>       > >> From: R-help [r-help-bounces at r-project.org <mailto:r-
> help-bounces at r-project.org>  <mailto:r-help- <mailto:r-help->
> 	> bounces at r-project.org <mailto:bounces at r-project.org> > ] on
> behalf of Vito M. R.
> 	>       > >> Muggeo [vito.muggeo at unipa.it
> <mailto:vito.muggeo at unipa.it>  <mailto:vito.muggeo at unipa.it
> <mailto:vito.muggeo at unipa.it> >
> 	> ]
> 	>       > >> Sent: February 9, 2016 10:15 AM
> 	>       > >> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-
> project.org <mailto:R-help at r-project.org>
> 	> <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >
> 	>       > >> Cc: R-windows at r-project.org <mailto:R-windows at r-
> project.org>  <mailto:R-windows at r- <mailto:R-windows at r->
> 	> project.org <http://project.org> >
> 	>       > >> Subject: Re: [R] Help required for Rcmdr
> 	>       > >>
> 	>       > >> dear all,
> 	>       > >> I don't know if that problem is related to the Rcmdr
> package
> 	> itself..
> 	>       > >> (Sekhar try to install any other packages..)
> 	>       > >>
> 	>       > >> I am experiencing the same problem, in that when typing
> 	>       > >>
> 	>       > >>   > install.packages("_ANY_PACKAGE_")
> 	>       > >>
> 	>       > >> I get the message
> 	>       > >> Warning message:
> 	>       > >> package ?_ANY_PACKAGE_? is not available (for R version
> 3.2.3)
> 	>       > >>
> 	>       > >> But I can download the .zip file and unzip it..
> 	>       > >>
> 	>       > >> I tried different CRAN mirrors...
> 	>       > >>
> 	>       > >> best,
> 	>       > >> vito
> 	>       > >>
> 	>       > >>
> 	>       > >> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> 	>       > >>>
> 	>       > >>> Dear Mr. Murdoch,
> 	>       > >>> I am extremely sorry to have sent the mail to you instead
> of R-
> 	> help.
> 	>       > >>> Thanks
> 	>       > >>> for directing me.
> 	>       > >>> I have downloaded R 3.2.3 version. After that i asked for
> 	>       > >>> install.packages("Rcmdr") . It says that Rcmdr is not
> available
> 	> with
> 	>       > >>> version 3.2.3. On looking at the pdf file for getting started
> with
> 	>       > >>> R, i found that i should download with SDI Graphical
> interface
> 	> which
> 	>       > >>> I did once again but still i could not get the Rcmdr console.
> 	>       > >>> I attended a workshop where the faculty brought out the
> R
> 	> console as
> 	>       > >>> well as the R-commander console where i could import
> files
> 	> and also
> 	>       > >>> do all the statistics easily. I am not getting the R-
> commander
> 	> console.
> 	>       > >>> Shall be grateful if i could get help on getting the R-
> commander
> 	>       > >>> console with the user friendly way of doing the statistical
> 	> operations.
> 	>       > >>> Thanks and regards,
> 	>       > >>> Once again apologize to Dr. Duncan Murdoch for
> disturbing
> 	> him.
> 	>       > >>> Sekhar
> 	>       > >>>
> 	>       > >>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch
> 	>       > >>> <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>
> 	> <mailto:murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com> > >
> 	>       > >>> wrote:
> 	>       > >>>
> 	>       > >>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
> 	>       > >>>>
> 	>       > >>>>> Dear Sirs,
> 	>       > >>>>> I have downloaded R 3.2.3 version from the CRAN site. I
> 	> have tried
> 	>       > >>>>> to download with both MDI and SDI user interface. But
> 	> Rcmdr is not
> 	>       > >>>>> opening in as a console  along with R console. Help is
> 	> required to
> 	>       > >>>>> open Rcmdr. I have tried install.packages("Rcmdr"),
> 	> library(Rcmdr)
> 	>       > >>>>> etc but to no avail.
> 	>       > >>>>> thanks
> 	>       > >>>>> Sekhar
> 	>       > >>>>> Delhi
> 	>       > >>>>> India
> 	>       > >>>>>
> 	>       > >>>>> This is the wrong email address for help.  Please write
> to R-
> 	> help,
> 	>       > >>>>> and
> 	>       > >>>>
> 	>       > >>>> describe what happens when you try the commands
> that are
> 	> failing.
> 	>       > >>>>
> 	>       > >>>> Duncan Murdoch
> 	>       > >>>>
> 	>       > >>>
> 	>       > >>>        [[alternative HTML version deleted]]
> 	>       > >>>
> 	>       > >>>
> ______________________________________________
> 	>       > >>> R-help at r-project.org <mailto:R-help at r-project.org>
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> 	> list -- To UNSUBSCRIBE and more, see
> 	>       > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> 	>       > >>> PLEASE do read the posting guide
> 	>       > >>> http://www.R-project.org/posting-guide.html
> 	>       > >>> and provide commented, minimal, self-contained,
> 	> reproducible code.
> 	>       > >>>
> 	>       > >>
> 	>       > >> --
> 	>       > >>
> ==============================================
> 	>       > >> Vito M.R. Muggeo
> 	>       > >> Dip.to Sc Statist e Matem `Vianelli'
> 	>       > >> Universit? di Palermo
> 	>       > >> viale delle Scienze, edificio 13
> 	>       > >> 90128 Palermo - ITALY
> 	>       > >> tel: 091 23895240
> 	>       > >> fax: 091 485726
> 	>       > >> http://dssm.unipa.it/vmuggeo
> 	>       > >> Associate Editor, Statistical Modelling
> 	>       > >>
> 	>       > >>
> ______________________________________________
> 	>       > >> R-help at r-project.org <mailto:R-help at r-project.org>
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing list
> 	> -- To UNSUBSCRIBE and more, see
> 	>       > >> https://stat.ethz.ch/mailman/listinfo/r-help
> 	>       > >> PLEASE do read the posting guide
> 	>       > >> http://www.R-project.org/posting-guide.html
> 	>       > >> and provide commented, minimal, self-contained,
> reproducible
> 	> code.
> 	>       > >>
> 	>       > >
> 	>       > > --
> 	>       > > ==============================================
> 	>       > > Vito M.R. Muggeo
> 	>       > > Dip.to Sc Statist e Matem `Vianelli'
> 	>       > > Universit? di Palermo
> 	>       > > viale delle Scienze, edificio 13
> 	>       > > 90128 Palermo - ITALY
> 	>       > > tel: 091 23895240
> 	>       > > fax: 091 485726
> 	>       > > http://dssm.unipa.it/vmuggeo
> 	>       > > Associate Editor, Statistical Modelling
> 	>       > >
> 	>       > > ______________________________________________
> 	>       > > R-help at r-project.org <mailto:R-help at r-project.org>
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing list -
> 	> - To UNSUBSCRIBE and more, see
> 	>       > > https://stat.ethz.ch/mailman/listinfo/r-help
> 	>       > > PLEASE do read the posting guide
> 	>       > > http://www.R-project.org/posting-guide.html
> 	>       > > and provide commented, minimal, self-contained,
> reproducible
> 	> code.
> 	>
> 	>
> 
> 


From dwinsemius at comcast.net  Wed Feb 10 17:52:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Feb 2016 08:52:51 -0800
Subject: [R] Shiny
In-Reply-To: <56BB39BB.9010801@gmail.com>
References: <CAAM-fZ5FX=P8rVZPY-XkUjtfEoaczDOwh+QU_86pCH3XJ2LZRw@mail.gmail.com>
	<56BB39BB.9010801@gmail.com>
Message-ID: <2A9FC6D6-F592-4840-8727-88E7B3C518B9@comcast.net>


> On Feb 10, 2016, at 5:23 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 10/02/2016 7:41 AM, Venky wrote:
>> Hi Team,
>> 
>> Please anyone share the Shiny app code(Server and UI)  for Multiple Linear
>> Regression. With dropdown menu
>> 
> 
> This is the wrong place to write for help with Shiny.  I think RStudio runs some forums for that, and StackOverflow also answers questions about it.

However, StackOverflow attempts to position itself as a coding site for coders and generally vague requests along the line of "give me the codez" or "do my searching for me"  are not warmly received.

I don't know what the typical reception to such vague requests might be on the RStudio forums. They might have a more welcoming posture toward persons hoping to use their product.

-- 
David Winsemius
Alameda, CA, USA


From jorfega80 at hotmail.com  Wed Feb 10 18:05:29 2016
From: jorfega80 at hotmail.com (=?iso-8859-1?Q?Jorge_Fern=E1ndez_Garc=EDa?=)
Date: Wed, 10 Feb 2016 17:05:29 +0000
Subject: [R] Problem displaying greek symbols
In-Reply-To: <AA4A2B86-A789-4C8D-956D-D128A8CDDB18@comcast.net>
References: <AM4PR02MB137700BFBEEF1B0F8BE48331B5DC0@AM4PR02MB1377.eurprd02.prod.outlook.com>
	<CAGxFJbRi0q0xa_aMQm9cM3att2VWbZP_JGzy4nE1GFijZg-W8A@mail.gmail.com>,
	<AA4A2B86-A789-4C8D-956D-D128A8CDDB18@comcast.net>
Message-ID: <AM4PR02MB137752BC386C0E4111806DBBB5D70@AM4PR02MB1377.eurprd02.prod.outlook.com>

Thanks for your help.

The output of > pdfFonts()$serif$metrics and > pdfFonts()$mono$metrics is what you mention.

Unfortunately I have no duplicated fonts, so the problem is not there...

________________________________________
De: David Winsemius <dwinsemius at comcast.net>
Enviado: domingo, 31 de enero de 2016 2:17
Para: Bert Gunter
Cc: Jorge Fern?ndez Garc?a; r-help at r-project.org
Asunto: Re: [R] Problem displaying greek symbols

> On Jan 30, 2016, at 3:24 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> (Ill give it a try, but more expertise than I have may be needed)
>
> Works fine for me (on OS X).
>
> Take a look at ?pdf . I believe the font family in use (Helvetica is
> the default) needs to have the (Adobe) symbol font as font 5. What
> family are you using?
>
> To see what families are available, use:
>
> names(grDevices::pdfFonts())

That's not very informative, since the actual fonts that are going to be used are inside the 'serif', "sans", and  "mono" families. Try this instead:

> pdfFonts()$serif$metrics
[1] "Times-Roman.afm"      "Times-Bold.afm"       "Times-Italic.afm"
[4] "Times-BoldItalic.afm" "Symbol.afm"

> pdfFonts()$mono$metrics
[1] "Courier.afm"             "Courier-Bold.afm"
[3] "Courier-Oblique.afm"     "Courier-BoldOblique.afm"
[5] "Symbol.afm"

Notice the the fifth item in both is Symbol.

Which may also not be very useful either since for reasons that I have never been able to fathom, the fonts sometimes get messed up on a Mac and the way to detect and correct the problem is to use Font Book.app which I think you will find in either ~/Applications or ~/Applications/Utilities. The symptom: ... you find a font type in Font Book that has duplicate entries. Delete the corrupted one and you may find your Symbols will reappear.

(This is documented in ?quartz.)


> Another possibility is that you are using the wrong encoding.
> Unfortunately, this is beyond my ability to help you with, but perhaps
> reading the Help on the encoding argument and related links might get
> you the necessary info.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Jan 30, 2016 at 1:43 PM, Jorge Fern?ndez Garc?a
> <jorfega80 at hotmail.com> wrote:
>> Hi,
>>
>>
>> I have a problem displaying greek (and in general any special character).
>>
>>
>> I know I am using the right command as the same script works in Fedora20 but not in MAC Yosemite.
>>
>>
>> ylab=expression(delta) displays a square instead of the right symbol when I view the resulting pdf file with preview or any other tool to display pdf.

A full test would be:

pdf(); plot(1,1, main=expression(delta)); dev.off()

--
David.

>>
>>
>> Any idea of what's going on?
>>
>>
>> Thanks in advance
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jfox at mcmaster.ca  Wed Feb 10 17:29:41 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 10 Feb 2016 16:29:41 +0000
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGyA+HMBzcc8ma-19+ZebH4Ci-xpDm3fvCxg8o=8sFKO4H45Dw@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
	<CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F55E86@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMBzcc8ma-19+ZebH4Ci-xpDm3fvCxg8o=8sFKO4H45Dw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F563C2@FHSDB2D11-2.csu.mcmaster.ca>

Dear Sekhar,

I'm sorry that you're experiencing these problems. Although you haven't said so directly, I assume that you aren't able to use install.packages() to install *any* CRAN packages, not just the Rcmdr package.

Downloading and unpacking the Rcmdr zip file doesn't install the package. You can install the zip-file binary package from the R Windows GUI via the "Packages > Install package(s) from local zip files" menu, but that too won't really help because it won't install the many CRAN packages on which the Rcmdr depends.

As I said earlier, my guess is that you're experiencing a problem with a firewall, proxy server, or HTTPS. If the latter (which was Vito's problem), you can easily solve the problem by using an HTTP CRAN server in preference to the default HTTPS: 

Enter the command chooseCRANmirror(useHTTPS=FALSE) at the R Console > prompt and select a CRAN mirror -- I suggest the first (0-Cloud) mirror. Then issue the command install.packages("Rcmdr"), as before.

If that doesn't work, I'm afraid I don't have other suggestions.

You appear to have sent this message only to me, not to r-help. That not a good idea for several reasons, not least of which is that people who have other suggestions won't see your message. I'm cc'ing this response to r-help.

Best,
 John

> -----Original Message-----
> From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com]
> Sent: February 10, 2016 12:03 AM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R] Help required for Rcmdr
> 
> Dear Sirs,
> Thanks to everyone for trying to help me. i have tried several CRAN mirrors
> but to no help. I am getting the Zip file for Rcmdr and can also unzip the
> same. However, after that i am unable to open the Rcmdr console.
> that is the problem.
> regards
> sekhar
> 
> On Tue, Feb 9, 2016 at 10:00 PM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Hi Rich,
> 
> 	> -----Original Message-----
> 	> From: Richard M. Heiberger [mailto:rmh at temple.edu
> <mailto:rmh at temple.edu> ]
> 	> Sent: February 9, 2016 4:57 PM
> 	> To: Vito M. R. Muggeo <vito.muggeo at unipa.it
> <mailto:vito.muggeo at unipa.it> >
> 	> Cc: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >;
> Sekhar Venkatesan
> 	> <venkatesansekhar at gmail.com
> <mailto:venkatesansekhar at gmail.com> >; Duncan Murdoch
> 	> <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com> >; R-help at r-project.org <mailto:R-
> help at r-project.org> ; R-windows at r-
> 	> project.org <http://project.org>
> 	> Subject: Re: [R] Help required for Rcmdr
> 	>
> 	> Several of my students have had this type of difficulty with Rstudio.
> 	>
> 
> 	Good to know, but the original poster tried both with the R Windows
> SDI and MDI.
> 
> 	Best,
> 	 John
> 
> 
> 	> Rstudio masks install.packages with a similarly named function in an
> 	> environment that does not appear in either conflicts(details=TRUE)
> or in
> 	> search().
> 	>
> 	> The workaround is an explicit call to utils
> 	>
> 	> utils::install.packages("package.name <http://package.name> ")
> 	>
> 	> Rich
> 	>
> 	> On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo
> <vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> >
> 	> wrote:
> 	> > dear John,
> 	> > Thanks for your prompt reply
> 	> >
> 	> > Il 09/02/2016 16.23, Fox, John ha scritto:
> 	> >>
> 	> >> Dear Vito,
> 	> >>
> 	> >> I've never experienced this problem myself in a general way,
> 	> >
> 	> > Me too. I have always installed R packages straightforwardly..
> 	> >
> 	> > and I'm sure that Windows users of R call install.packages() all the
> 	> > time to install packages from CRAN mirrors.
> 	> > Of course..
> 	> >
> 	> > So the question to ask, I think, is what's preventing
> 	> > install.packages() from working in your case -- possibly an
> Internet
> 	> > connectivity problem due to a firewall, proxy server, use of https,
> etc.
> 	> > I'm sure that others more knowledgeable about these issues
> than I am
> 	> > will be able to make more specific suggestions for fixing the
> problem.
> 	> >
> 	> > However I have just checked that it works with *http* servers
> (but not
> 	> > for any other *https*..)
> 	> >
> 	> > Thanks for your support,
> 	> > best,
> 	> > vito
> 	> >
> 	> >
> 	> >>
> 	> >> Best,
> 	> >>   John
> 	> >>
> 	> >> -----------------------------
> 	> >> John Fox, Professor
> 	> >> McMaster University
> 	> >> Hamilton, Ontario
> 	> >> Canada L8S 4M4
> 	> >> web: socserv.mcmaster.ca/jfox
> <http://socserv.mcmaster.ca/jfox>
> 	> >>
> 	> >>
> 	> >> ________________________________________
> 	> >> From: R-help [r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] on behalf of Vito M. R.
> 	> >> Muggeo [vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it>
> ]
> 	> >> Sent: February 9, 2016 10:15 AM
> 	> >> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-project.org
> <mailto:R-help at r-project.org>
> 	> >> Cc: R-windows at r-project.org <mailto:R-windows at r-
> project.org>
> 	> >> Subject: Re: [R] Help required for Rcmdr
> 	> >>
> 	> >> dear all,
> 	> >> I don't know if that problem is related to the Rcmdr package
> itself..
> 	> >> (Sekhar try to install any other packages..)
> 	> >>
> 	> >> I am experiencing the same problem, in that when typing
> 	> >>
> 	> >>   > install.packages("_ANY_PACKAGE_")
> 	> >>
> 	> >> I get the message
> 	> >> Warning message:
> 	> >> package ?_ANY_PACKAGE_? is not available (for R version 3.2.3)
> 	> >>
> 	> >> But I can download the .zip file and unzip it..
> 	> >>
> 	> >> I tried different CRAN mirrors...
> 	> >>
> 	> >> best,
> 	> >> vito
> 	> >>
> 	> >>
> 	> >> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> 	> >>>
> 	> >>> Dear Mr. Murdoch,
> 	> >>> I am extremely sorry to have sent the mail to you instead of R-
> help.
> 	> >>> Thanks
> 	> >>> for directing me.
> 	> >>> I have downloaded R 3.2.3 version. After that i asked for
> 	> >>> install.packages("Rcmdr") . It says that Rcmdr is not available
> with
> 	> >>> version 3.2.3. On looking at the pdf file for getting started with
> 	> >>> R, i found that i should download with SDI Graphical interface
> which
> 	> >>> I did once again but still i could not get the Rcmdr console.
> 	> >>> I attended a workshop where the faculty brought out the R
> console as
> 	> >>> well as the R-commander console where i could import files
> and also
> 	> >>> do all the statistics easily. I am not getting the R-commander
> console.
> 	> >>> Shall be grateful if i could get help on getting the R-commander
> 	> >>> console with the user friendly way of doing the statistical
> operations.
> 	> >>> Thanks and regards,
> 	> >>> Once again apologize to Dr. Duncan Murdoch for disturbing
> him.
> 	> >>> Sekhar
> 	> >>>
> 	> >>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch
> 	> >>> <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com> >
> 	> >>> wrote:
> 	> >>>
> 	> >>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
> 	> >>>>
> 	> >>>>> Dear Sirs,
> 	> >>>>> I have downloaded R 3.2.3 version from the CRAN site. I
> have tried
> 	> >>>>> to download with both MDI and SDI user interface. But
> Rcmdr is not
> 	> >>>>> opening in as a console  along with R console. Help is
> required to
> 	> >>>>> open Rcmdr. I have tried install.packages("Rcmdr"),
> library(Rcmdr)
> 	> >>>>> etc but to no avail.
> 	> >>>>> thanks
> 	> >>>>> Sekhar
> 	> >>>>> Delhi
> 	> >>>>> India
> 	> >>>>>
> 	> >>>>> This is the wrong email address for help.  Please write to R-
> help,
> 	> >>>>> and
> 	> >>>>
> 	> >>>> describe what happens when you try the commands that are
> failing.
> 	> >>>>
> 	> >>>> Duncan Murdoch
> 	> >>>>
> 	> >>>
> 	> >>>        [[alternative HTML version deleted]]
> 	> >>>
> 	> >>> ______________________________________________
> 	> >>> R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list -- To UNSUBSCRIBE and more, see
> 	> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> >>> PLEASE do read the posting guide
> 	> >>> http://www.R-project.org/posting-guide.html
> 	> >>> and provide commented, minimal, self-contained,
> reproducible code.
> 	> >>>
> 	> >>
> 	> >> --
> 	> >> ==============================================
> 	> >> Vito M.R. Muggeo
> 	> >> Dip.to Sc Statist e Matem `Vianelli'
> 	> >> Universit? di Palermo
> 	> >> viale delle Scienze, edificio 13
> 	> >> 90128 Palermo - ITALY
> 	> >> tel: 091 23895240
> 	> >> fax: 091 485726
> 	> >> http://dssm.unipa.it/vmuggeo
> 	> >> Associate Editor, Statistical Modelling
> 	> >>
> 	> >> ______________________________________________
> 	> >> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list
> -- To UNSUBSCRIBE and more, see
> 	> >> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> >> PLEASE do read the posting guide
> 	> >> http://www.R-project.org/posting-guide.html
> 	> >> and provide commented, minimal, self-contained, reproducible
> code.
> 	> >>
> 	> >
> 	> > --
> 	> > ==============================================
> 	> > Vito M.R. Muggeo
> 	> > Dip.to Sc Statist e Matem `Vianelli'
> 	> > Universit? di Palermo
> 	> > viale delle Scienze, edificio 13
> 	> > 90128 Palermo - ITALY
> 	> > tel: 091 23895240
> 	> > fax: 091 485726
> 	> > http://dssm.unipa.it/vmuggeo
> 	> > Associate Editor, Statistical Modelling
> 	> >
> 	> > ______________________________________________
> 	> > R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -
> - To UNSUBSCRIBE and more, see
> 	> > https://stat.ethz.ch/mailman/listinfo/r-help
> 	> > PLEASE do read the posting guide
> 	> > http://www.R-project.org/posting-guide.html
> 	> > and provide commented, minimal, self-contained, reproducible
> code.
> 
> 


From bortolamiol.sarah at gmail.com  Wed Feb 10 17:52:44 2016
From: bortolamiol.sarah at gmail.com (Sarah Bortolamiol)
Date: Wed, 10 Feb 2016 17:52:44 +0100
Subject: [R] MCA, Rcmdr, FactoMineR
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F563ED@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563ED@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAFKeWY5E2QbBrH47PJ00f2roztHfB8MG-oW5WN-gOYWtfYqgeA@mail.gmail.com>

Dear John and R users,

Thank you very much for your help
In my consol, i typed:
> install.packages("RcmdrPlugin.FactoMineR")
And got the following message
"Installing package(s) into '/Users/sarahcontequoi/Library/R/2.15/library'
(as 'lib' is unspecified)
Warning in install.packages :
  package 'RcmdrPlugin.FactoMineR' is not available (for R version 2.15.1)"



2016-02-10 17:39 GMT+01:00 Fox, John <jfox at mcmaster.ca>:

> Dear Sarah,
>
> I don't entirely follow what you did, but my guess is that you installed
> the Rcmdr and FactoMineR packages but not the RcmdrPlugin.FactoMineR
> package. If that's the case, then install the RcmdrPlugin.FactoMineR, e.g.,
> via install.packages("RcmdrPlugin.FactoMineR") and try again.
>
> You should be able to load the plug-in from the R Commander "Tools > Load
> Rcmdr Plug-in(s)" menu (it works for me). Unfortunately, you can't load the
> RcmdrPlugin.FactoMineR  package directly by the command
> library(RcmdrPlugin.FactoMineR) because the authors of the plug-in
> apparently didn't make it self-starting.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
> > Bortolamiol
> > Sent: February 10, 2016 6:01 AM
> > To: r-help at r-project.org
> > Subject: [R] MCA, Rcmdr, FactoMineR
> >
> > Dear R users,
> >
> > I am a beginner in R so my question may be a bit stupid. I tried to
> search in
> > forums and did not find the answer I am looking for. I should precise
> that I
> > am using Rstudio on Mac (OsX 10.10.5).
> >
> > I want to run a MCA analysis on my data (with Benzecri correction, with
> active
> > and supplementary variables). It seems that the FactoMineR package is
> doing
> > this. However, it seems it is not working as it should. In Rstudio
> console I call
> > "library(Rcmdr)", and it opens a new window with XQuartz.
> > Then I want to upload FactoMineR package so I go in tool, I select
> > FactoMineR and validate. Then I am supposed to charge plug-ins but the
> > option is not available (see picture attached) Do you know where it comes
> > from?
> >
> > Thank you very much for your help,
> > Sarah
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Sarah Bortolamiol
Projet FOX-TROTTE

Docteure en G?ographie
UMR 7533 - LADYSS
UMR 7206 - Mus?um national d'histoire naturelle
Mail: bortolamiol.sarah at gmail.com
Tel: +33 6 78 05 31 78

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Wed Feb 10 18:26:01 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 10 Feb 2016 17:26:01 +0000
Subject: [R] MCA, Rcmdr, FactoMineR
Message-ID: <Zen-1aTYWf-000878-62@smarthost03b.mail.zen.net.uk>

Sarah Bortolamiol <bortolamiol.sarah at gmail.com> wrote :

> Dear John and R users,
> 
> Thank you very much for your help
> In my consol, i typed:
> > install.packages("RcmdrPlugin.FactoMineR")
> And got the following message
> "Installing package(s) into '/Users/sarahcontequoi/Library/R/2.15/library'
> (as 'lib' is unspecified)
> Warning in install.packages :
>   package 'RcmdrPlugin.FactoMineR' is not available (for R version 2.15.1)"

That is a very old version of R. Try upgrading to the latest version and try again.


> 
> 
> 
> 2016-02-10 17:39 GMT+01:00 Fox, John jfox at mcmaster.ca>:
> 
> > Dear Sarah,
> >
> > I don't entirely follow what you did, but my guess is that you installed
> > the Rcmdr and FactoMineR packages but not the RcmdrPlugin.FactoMineR
> > package. If that's the case, then install the RcmdrPlugin.FactoMineR,
> e.g.,
> > via install.packages("RcmdrPlugin.FactoMineR") and try again.
> >
> > You should be able to load the plug-in from the R Commander "Tools > Load
> > Rcmdr Plug-in(s)" menu (it works for me). Unfortunately, you can't load
> the
> > RcmdrPlugin.FactoMineR  package directly by the command
> > library(RcmdrPlugin.FactoMineR) because the authors of the plug-in
> > apparently didn't make it self-starting.
> >
> > I hope this helps,
> >  John
> >
> > -----------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org]
> On Behalf Of Sarah
> > > Bortolamiol
> > > Sent: February 10, 2016 6:01 AM
> > > To: r-help at r-project.org
> > > Subject: [R] MCA, Rcmdr, FactoMineR
> > >
> > > Dear R users,
> > >
> > > I am a beginner in R so my question may be a bit stupid. I tried to
> > search in
> > > forums and did not find the answer I am looking for. I should precise
> > that I
> > > am using Rstudio on Mac (OsX 10.10.5).
> > >
> > > I want to run a MCA analysis on my data (with Benzecri correction, with
> > active
> > > and supplementary variables). It seems that the FactoMineR package is
> > doing
> > > this. However, it seems it is not working as it should. In Rstudio
> > console I call
> > > "library(Rcmdr)", and it opens a new window with XQuartz.
> > > Then I want to upload FactoMineR package so I go in tool, I select
> > > FactoMineR and validate. Then I am supposed to charge plug-ins but the
> > > option is not available (see picture attached) Do you know where it
> comes
> > > from?
> > >
> > > Thank you very much for your help,
> > > Sarah
> > > ______________________________________________
> > > R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> 
> -- 
> Sarah Bortolamiol
> Projet FOX-TROTTE
> 
> Docteure en G??ographie
> UMR 7533 - LADYSS
> UMR 7206 - Mus??um national d'histoire naturelle
> Mail: bortolamiol.sarah at gmail.com
> Tel: +33 6 78 05 31 78
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Feb 10 18:27:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Feb 2016 09:27:11 -0800
Subject: [R] MCA, Rcmdr, FactoMineR
In-Reply-To: <CAFKeWY5E2QbBrH47PJ00f2roztHfB8MG-oW5WN-gOYWtfYqgeA@mail.gmail.com>
References: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563ED@FHSDB2D11-2.csu.mcmaster.ca>
	<CAFKeWY5E2QbBrH47PJ00f2roztHfB8MG-oW5WN-gOYWtfYqgeA@mail.gmail.com>
Message-ID: <CAGxFJbQpfgVdowASQGrCNP_4atr391+_pycJQarO4LR2JP5ygw@mail.gmail.com>

Your R is quite old -- newest version is at least 3.2.3 . As a general
rule, you should first upgrade to the current versions of both R and
packages **before posting**, as the posting guide requests I believe.
This is precisely to avoid problems like this.

If this fails to resolve your problems, re-post.

(Ignore this advice if John or others with greater expertise respond.
Mine is a general prescription only).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 10, 2016 at 8:52 AM, Sarah Bortolamiol
<bortolamiol.sarah at gmail.com> wrote:
> Dear John and R users,
>
> Thank you very much for your help
> In my consol, i typed:
>> install.packages("RcmdrPlugin.FactoMineR")
> And got the following message
> "Installing package(s) into '/Users/sarahcontequoi/Library/R/2.15/library'
> (as 'lib' is unspecified)
> Warning in install.packages :
>   package 'RcmdrPlugin.FactoMineR' is not available (for R version 2.15.1)"
>
>
>
> 2016-02-10 17:39 GMT+01:00 Fox, John <jfox at mcmaster.ca>:
>
>> Dear Sarah,
>>
>> I don't entirely follow what you did, but my guess is that you installed
>> the Rcmdr and FactoMineR packages but not the RcmdrPlugin.FactoMineR
>> package. If that's the case, then install the RcmdrPlugin.FactoMineR, e.g.,
>> via install.packages("RcmdrPlugin.FactoMineR") and try again.
>>
>> You should be able to load the plug-in from the R Commander "Tools > Load
>> Rcmdr Plug-in(s)" menu (it works for me). Unfortunately, you can't load the
>> RcmdrPlugin.FactoMineR  package directly by the command
>> library(RcmdrPlugin.FactoMineR) because the authors of the plug-in
>> apparently didn't make it self-starting.
>>
>> I hope this helps,
>>  John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
>> > Bortolamiol
>> > Sent: February 10, 2016 6:01 AM
>> > To: r-help at r-project.org
>> > Subject: [R] MCA, Rcmdr, FactoMineR
>> >
>> > Dear R users,
>> >
>> > I am a beginner in R so my question may be a bit stupid. I tried to
>> search in
>> > forums and did not find the answer I am looking for. I should precise
>> that I
>> > am using Rstudio on Mac (OsX 10.10.5).
>> >
>> > I want to run a MCA analysis on my data (with Benzecri correction, with
>> active
>> > and supplementary variables). It seems that the FactoMineR package is
>> doing
>> > this. However, it seems it is not working as it should. In Rstudio
>> console I call
>> > "library(Rcmdr)", and it opens a new window with XQuartz.
>> > Then I want to upload FactoMineR package so I go in tool, I select
>> > FactoMineR and validate. Then I am supposed to charge plug-ins but the
>> > option is not available (see picture attached) Do you know where it comes
>> > from?
>> >
>> > Thank you very much for your help,
>> > Sarah
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Sarah Bortolamiol
> Projet FOX-TROTTE
>
> Docteure en G?ographie
> UMR 7533 - LADYSS
> UMR 7206 - Mus?um national d'histoire naturelle
> Mail: bortolamiol.sarah at gmail.com
> Tel: +33 6 78 05 31 78
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Feb 10 18:47:12 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 10 Feb 2016 09:47:12 -0800
Subject: [R] MCA, Rcmdr, FactoMineR
In-Reply-To: <CAFKeWY5E2QbBrH47PJ00f2roztHfB8MG-oW5WN-gOYWtfYqgeA@mail.gmail.com>
References: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563ED@FHSDB2D11-2.csu.mcmaster.ca>
	<CAFKeWY5E2QbBrH47PJ00f2roztHfB8MG-oW5WN-gOYWtfYqgeA@mail.gmail.com>
Message-ID: <42C38B33-0FC8-4C8A-AD09-3BCCB2207EE2@dcn.davis.ca.us>

The Posting Guide mentioned at the bottom of every message on the list has many helpful tips.  One of these is that you should install the latest version of R before asking for help on the list.  v2.15.1 is quite old in Internet time.

BTW, if this your troubles are specific to running on MacOSX, the PG also recommends asking your question on the R-sig-mac list. That is, if you are having trouble installing the latest version of R because of your OS, you probably should be asking people more likely to be familiar with R on your OS. (You might get lucky here anyway, but targeting your question is preferred.)
-- 
Sent from my phone. Please excuse my brevity.

On February 10, 2016 8:52:44 AM PST, Sarah Bortolamiol <bortolamiol.sarah at gmail.com> wrote:
>Dear John and R users,
>
>Thank you very much for your help
>In my consol, i typed:
>> install.packages("RcmdrPlugin.FactoMineR")
>And got the following message
>"Installing package(s) into
>'/Users/sarahcontequoi/Library/R/2.15/library'
>(as 'lib' is unspecified)
>Warning in install.packages :
>package 'RcmdrPlugin.FactoMineR' is not available (for R version
>2.15.1)"
>
>
>
>2016-02-10 17:39 GMT+01:00 Fox, John <jfox at mcmaster.ca>:
>
>> Dear Sarah,
>>
>> I don't entirely follow what you did, but my guess is that you
>installed
>> the Rcmdr and FactoMineR packages but not the RcmdrPlugin.FactoMineR
>> package. If that's the case, then install the RcmdrPlugin.FactoMineR,
>e.g.,
>> via install.packages("RcmdrPlugin.FactoMineR") and try again.
>>
>> You should be able to load the plug-in from the R Commander "Tools >
>Load
>> Rcmdr Plug-in(s)" menu (it works for me). Unfortunately, you can't
>load the
>> RcmdrPlugin.FactoMineR  package directly by the command
>> library(RcmdrPlugin.FactoMineR) because the authors of the plug-in
>> apparently didn't make it self-starting.
>>
>> I hope this helps,
>>  John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Sarah
>> > Bortolamiol
>> > Sent: February 10, 2016 6:01 AM
>> > To: r-help at r-project.org
>> > Subject: [R] MCA, Rcmdr, FactoMineR
>> >
>> > Dear R users,
>> >
>> > I am a beginner in R so my question may be a bit stupid. I tried to
>> search in
>> > forums and did not find the answer I am looking for. I should
>precise
>> that I
>> > am using Rstudio on Mac (OsX 10.10.5).
>> >
>> > I want to run a MCA analysis on my data (with Benzecri correction,
>with
>> active
>> > and supplementary variables). It seems that the FactoMineR package
>is
>> doing
>> > this. However, it seems it is not working as it should. In Rstudio
>> console I call
>> > "library(Rcmdr)", and it opens a new window with XQuartz.
>> > Then I want to upload FactoMineR package so I go in tool, I select
>> > FactoMineR and validate. Then I am supposed to charge plug-ins but
>the
>> > option is not available (see picture attached) Do you know where it
>comes
>> > from?
>> >
>> > Thank you very much for your help,
>> > Sarah
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>-- 
>Sarah Bortolamiol
>Projet FOX-TROTTE
>
>Docteure en G?ographie
>UMR 7533 - LADYSS
>UMR 7206 - Mus?um national d'histoire naturelle
>Mail: bortolamiol.sarah at gmail.com
>Tel: +33 6 78 05 31 78
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From archboldways at hotmail.com  Wed Feb 10 18:29:48 2016
From: archboldways at hotmail.com (Archbold Muhle)
Date: Wed, 10 Feb 2016 19:29:48 +0200
Subject: [R] Installing Rstudio Addinexamples
Message-ID: <DUB127-W14F101B9074E714A444FDDCED70@phx.gbl>

Kindly assist. I run the below command in Rstudio
> devtools::install_github("rstudio/addinexamples")
and get the following error
Downloading GitHub repo rstudio/addinexamples at masterfrom URL https://api.github.com/repos/rstudio/addinexamples/zipball/masterError in curl::curl_fetch_memory(url, handle = handle) :   Timeout was reached 		 	   		  
	[[alternative HTML version deleted]]


From bortolamiol.sarah at gmail.com  Wed Feb 10 19:14:17 2016
From: bortolamiol.sarah at gmail.com (Sarah Bortolamiol)
Date: Wed, 10 Feb 2016 19:14:17 +0100
Subject: [R] MCA, Rcmdr, FactoMineR
In-Reply-To: <CAGxFJbQpfgVdowASQGrCNP_4atr391+_pycJQarO4LR2JP5ygw@mail.gmail.com>
References: <CAFKeWY69NGyrUsf5nLrN9irNdjo5PBLCytANO667h0w-1BDd3Q@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563ED@FHSDB2D11-2.csu.mcmaster.ca>
	<CAFKeWY5E2QbBrH47PJ00f2roztHfB8MG-oW5WN-gOYWtfYqgeA@mail.gmail.com>
	<CAGxFJbQpfgVdowASQGrCNP_4atr391+_pycJQarO4LR2JP5ygw@mail.gmail.com>
Message-ID: <CAFKeWY5Dmdct=gdTbh97ug92NwSE3hf-ANb+-48Pf1E_WhEFaA@mail.gmail.com>

Dear all,
I am very sorry for this mistake (I will definetly remember the lesson!),
its now working with R latest version...
Thank you very much for your help and advices
Sarah

2016-02-10 18:27 GMT+01:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Your R is quite old -- newest version is at least 3.2.3 . As a general
> rule, you should first upgrade to the current versions of both R and
> packages **before posting**, as the posting guide requests I believe.
> This is precisely to avoid problems like this.
>
> If this fails to resolve your problems, re-post.
>
> (Ignore this advice if John or others with greater expertise respond.
> Mine is a general prescription only).
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 10, 2016 at 8:52 AM, Sarah Bortolamiol
> <bortolamiol.sarah at gmail.com> wrote:
> > Dear John and R users,
> >
> > Thank you very much for your help
> > In my consol, i typed:
> >> install.packages("RcmdrPlugin.FactoMineR")
> > And got the following message
> > "Installing package(s) into
> '/Users/sarahcontequoi/Library/R/2.15/library'
> > (as 'lib' is unspecified)
> > Warning in install.packages :
> >   package 'RcmdrPlugin.FactoMineR' is not available (for R version
> 2.15.1)"
> >
> >
> >
> > 2016-02-10 17:39 GMT+01:00 Fox, John <jfox at mcmaster.ca>:
> >
> >> Dear Sarah,
> >>
> >> I don't entirely follow what you did, but my guess is that you installed
> >> the Rcmdr and FactoMineR packages but not the RcmdrPlugin.FactoMineR
> >> package. If that's the case, then install the RcmdrPlugin.FactoMineR,
> e.g.,
> >> via install.packages("RcmdrPlugin.FactoMineR") and try again.
> >>
> >> You should be able to load the plug-in from the R Commander "Tools >
> Load
> >> Rcmdr Plug-in(s)" menu (it works for me). Unfortunately, you can't load
> the
> >> RcmdrPlugin.FactoMineR  package directly by the command
> >> library(RcmdrPlugin.FactoMineR) because the authors of the plug-in
> >> apparently didn't make it self-starting.
> >>
> >> I hope this helps,
> >>  John
> >>
> >> -----------------------------
> >> John Fox, Professor
> >> McMaster University
> >> Hamilton, Ontario
> >> Canada L8S 4M4
> >> Web: socserv.mcmaster.ca/jfox
> >>
> >>
> >>
> >> > -----Original Message-----
> >> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
> >> > Bortolamiol
> >> > Sent: February 10, 2016 6:01 AM
> >> > To: r-help at r-project.org
> >> > Subject: [R] MCA, Rcmdr, FactoMineR
> >> >
> >> > Dear R users,
> >> >
> >> > I am a beginner in R so my question may be a bit stupid. I tried to
> >> search in
> >> > forums and did not find the answer I am looking for. I should precise
> >> that I
> >> > am using Rstudio on Mac (OsX 10.10.5).
> >> >
> >> > I want to run a MCA analysis on my data (with Benzecri correction,
> with
> >> active
> >> > and supplementary variables). It seems that the FactoMineR package is
> >> doing
> >> > this. However, it seems it is not working as it should. In Rstudio
> >> console I call
> >> > "library(Rcmdr)", and it opens a new window with XQuartz.
> >> > Then I want to upload FactoMineR package so I go in tool, I select
> >> > FactoMineR and validate. Then I am supposed to charge plug-ins but the
> >> > option is not available (see picture attached) Do you know where it
> comes
> >> > from?
> >> >
> >> > Thank you very much for your help,
> >> > Sarah
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-
> >> > guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Sarah Bortolamiol
> > Projet FOX-TROTTE
> >
> > Docteure en G?ographie
> > UMR 7533 - LADYSS
> > UMR 7206 - Mus?um national d'histoire naturelle
> > Mail: bortolamiol.sarah at gmail.com
> > Tel: +33 6 78 05 31 78
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Sarah Bortolamiol
Projet FOX-TROTTE

Docteure en G?ographie
UMR 7533 - LADYSS
UMR 7206 - Mus?um national d'histoire naturelle
Mail: bortolamiol.sarah at gmail.com
Tel: +33 6 78 05 31 78

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Feb 10 20:08:10 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Feb 2016 14:08:10 -0500
Subject: [R] Installing Rstudio Addinexamples
In-Reply-To: <DUB127-W14F101B9074E714A444FDDCED70@phx.gbl>
References: <DUB127-W14F101B9074E714A444FDDCED70@phx.gbl>
Message-ID: <56BB8A9A.7030309@gmail.com>

On 10/02/2016 12:29 PM, Archbold Muhle wrote:
> Kindly assist. I run the below command in Rstudio
> > devtools::install_github("rstudio/addinexamples")
> and get the following error
> Downloading GitHub repo rstudio/addinexamples at masterfrom URL https://api.github.com/repos/rstudio/addinexamples/zipball/masterError in curl::curl_fetch_memory(url, handle = handle) :   Timeout was reached 	

You'll need to ask RStudio this.

Duncan Murdoch


From peter.br.lomas at gmail.com  Wed Feb 10 21:18:36 2016
From: peter.br.lomas at gmail.com (Peter Lomas)
Date: Wed, 10 Feb 2016 13:18:36 -0700
Subject: [R] Calculate average of many subsets based on columns in another
	dataframe
Message-ID: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>

Hello, I have a dataframe with a date range, and another dataframe
with observations by date.  For each date range, I'd like to average
the values within that range from the other dataframe.  I've provided
code below doing what I would like, but using a for loop is too
inefficient for my actual case (takes about an hour).  So I'm looking
for a way to vectorize.


set.seed(345)
date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
by="DSTday")
observations <- data.frame(date=date.range, values=runif(152,1,100) )
groups <- data.frame(start=sample(date.range[1:50], 20), end =
sample(date.range[51:152], 20), average = NA)

#Potential Solution (too inefficient)

for(i in 1:NROW(groups)){
 groups[i, "average"] <- mean(observations[observations$date >=
groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
}

As an extension to this, there will end up being multiple value
columns, and each range will also identify which column to average.  I
think if I can figure out the first problem I can try to extend it
myself.

Thanks,
Peter


From dwinsemius at comcast.net  Wed Feb 10 22:08:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Feb 2016 13:08:41 -0800
Subject: [R] Calculate average of many subsets based on columns in
	another dataframe
In-Reply-To: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
References: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
Message-ID: <98952DDC-F913-4B6A-98CA-6EBDEED8EDBC@comcast.net>


> On Feb 10, 2016, at 12:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
> 
> Hello, I have a dataframe with a date range, and another dataframe
> with observations by date.  For each date range, I'd like to average
> the values within that range from the other dataframe.  I've provided
> code below doing what I would like, but using a for loop is too
> inefficient for my actual case (takes about an hour).  So I'm looking
> for a way to vectorize.
> 
> 
> set.seed(345)
> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
> by="DSTday")
> observations <- data.frame(date=date.range, values=runif(152,1,100) )
> groups <- data.frame(start=sample(date.range[1:50], 20), end =
> sample(date.range[51:152], 20), average = NA)
> 
> #Potential Solution (too inefficient)
> 
> for(i in 1:NROW(groups)){
> groups[i, "average"] <- mean(observations[observations$date >=
> groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
> }
> 
The 'average' column could be added to groups with this value:

mapply( function(start,end){ mean(observations[['values']][
                     observations$date >= start & observations$date <=end])}, 
        groups$start, groups$end)

 [1] 50.96831 49.42286 47.27240 49.07534 47.66570 49.30977 48.47503 47.74036
 [9] 46.02527 58.76492 48.86580 49.90655 45.79705 48.84071 39.53846 46.44601
[17] 47.06631 47.74199 49.16980 46.85131

I don't really think this is fully "vectorized" in the usual R-meaning of the word. And I don't expect it to be any faster than the for-loop. Perhaps some of the range functions in the data.table package could accelerate your processing. If you don't get any volunteers in this list, you could repost the question on StackOverflow after a suitable pause that avoids accusations of cross-posting. SO has several skilled users of data.table functions.

> As an extension to this, there will end up being multiple value
> columns, and each range will also identify which column to average.  I
> think if I can figure out the first problem I can try to extend it
> myself.

Sorry, I didn't understand what was being described in that paragraph.

-- 

David Winsemius
Alameda, CA, USA


From aurora.gonzalez2 at um.es  Wed Feb 10 20:34:46 2016
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Wed, 10 Feb 2016 20:34:46 +0100
Subject: [R] customize R code in latex
Message-ID: <20160210203446.Horde.6AUufPwHHRtPpQD9omM4uA2@webmail.um.es>

Hello,

I am struggling with the fact of include a chunk of R code in a paper,
writing in latex.

I have seen some examples using listings() but I would like to keep R
colors.

So as to do that, I have written the code in Rmarkdown and when knitr I
keep the latex file so I obtain the attached files.

But, in order to fit in the paper, I would like to modify the dimensions of
the chunk (make it smaller) and also put it inside a black box.

Do you have any advise?

Thank you very much in advance.


------
Aurora Gonz?lez Vidal
Phd student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae
------------ pr?xima parte ------------
A non-text attachment was scrubbed...
Name: theData-iq.pdf
Type: application/pdf
Size: 118296 bytes
Desc: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160210/68910a43/attachment.pdf>

From bgunter.4567 at gmail.com  Wed Feb 10 22:26:59 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Feb 2016 13:26:59 -0800
Subject: [R] Calculate average of many subsets based on columns in
	another dataframe
In-Reply-To: <98952DDC-F913-4B6A-98CA-6EBDEED8EDBC@comcast.net>
References: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
	<98952DDC-F913-4B6A-98CA-6EBDEED8EDBC@comcast.net>
Message-ID: <CAGxFJbR=dPQt2yFJm_XBPHi97OzJ7Pxq=GOrdPo_U5s0yh3duw@mail.gmail.com>

A strategy:

 1. Convert your dates and intervals to numerics that give the days
since a time origin. See as.POSIXlt (or ** ct for details and an
example that does this). Should be fast...

2. Use the findInterval() function to get the interval into which each
date falls. This **is** "vectorized" and should be fairly fast.

3. Use the ave() function using the intervals as your factor that
splits your data column(s) for which you wish to compute statistics.
The basic statistics functions like mean, sum, etc. **are**
vectorized, so this should be fast.

As David said, the *apply functions will probably not be much, if at
all, faster than an explicit for() loop. Most of the time will be
spent spent comparing the dates to the intervals to find in which each
falls, and findInterval is a fast way to do this.

... I think.

If you try this, let me know (perhaps privately) how/if it works.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 10, 2016 at 1:08 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Feb 10, 2016, at 12:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
>>
>> Hello, I have a dataframe with a date range, and another dataframe
>> with observations by date.  For each date range, I'd like to average
>> the values within that range from the other dataframe.  I've provided
>> code below doing what I would like, but using a for loop is too
>> inefficient for my actual case (takes about an hour).  So I'm looking
>> for a way to vectorize.
>>
>>
>> set.seed(345)
>> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
>> by="DSTday")
>> observations <- data.frame(date=date.range, values=runif(152,1,100) )
>> groups <- data.frame(start=sample(date.range[1:50], 20), end =
>> sample(date.range[51:152], 20), average = NA)
>>
>> #Potential Solution (too inefficient)
>>
>> for(i in 1:NROW(groups)){
>> groups[i, "average"] <- mean(observations[observations$date >=
>> groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
>> }
>>
> The 'average' column could be added to groups with this value:
>
> mapply( function(start,end){ mean(observations[['values']][
>                      observations$date >= start & observations$date <=end])},
>         groups$start, groups$end)
>
>  [1] 50.96831 49.42286 47.27240 49.07534 47.66570 49.30977 48.47503 47.74036
>  [9] 46.02527 58.76492 48.86580 49.90655 45.79705 48.84071 39.53846 46.44601
> [17] 47.06631 47.74199 49.16980 46.85131
>
> I don't really think this is fully "vectorized" in the usual R-meaning of the word. And I don't expect it to be any faster than the for-loop. Perhaps some of the range functions in the data.table package could accelerate your processing. If you don't get any volunteers in this list, you could repost the question on StackOverflow after a suitable pause that avoids accusations of cross-posting. SO has several skilled users of data.table functions.
>
>> As an extension to this, there will end up being multiple value
>> columns, and each range will also identify which column to average.  I
>> think if I can figure out the first problem I can try to extend it
>> myself.
>
> Sorry, I didn't understand what was being described in that paragraph.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.br.lomas at gmail.com  Wed Feb 10 23:18:12 2016
From: peter.br.lomas at gmail.com (Peter Lomas)
Date: Wed, 10 Feb 2016 15:18:12 -0700
Subject: [R] Calculate average of many subsets based on columns in
	another dataframe
In-Reply-To: <CAGxFJbR=dPQt2yFJm_XBPHi97OzJ7Pxq=GOrdPo_U5s0yh3duw@mail.gmail.com>
References: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
	<98952DDC-F913-4B6A-98CA-6EBDEED8EDBC@comcast.net>
	<CAGxFJbR=dPQt2yFJm_XBPHi97OzJ7Pxq=GOrdPo_U5s0yh3duw@mail.gmail.com>
Message-ID: <CAOHXzyXObvimRPfNA1ngEFxFMG2KD_SudFkua1MCKka_JNrL_g@mail.gmail.com>

Thanks David, Bert,

>From what I'm reading on ?findInterval, It may not be workable because
of overlapping date ranges.  findInterval seems to take a series of
bin breakpoints as its argument. I'm currently exploring data.table
documentation and will keep thinking about this.

Just on David's point, the extension of this with "groups" would look
as below.  I just don't want to complicate it before I've solved the
simplest issue.

set.seed(345)
date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
by="DSTday")
observations <- data.frame(date=date.range, a=runif(152,1,100),
b=runif(152,1,100), c=runif(152,1,100) )
groups <- data.frame(start=sample(date.range[1:50], 20), end =
sample(date.range[51:152], 20), group=sample(letters[1:3], 20,
replace=TRUE), average = NA)

#Potential Solutions (too inefficient)
for(i in 1:NROW(groups)){
 groups[i, "average"] <- mean(observations[observations$date >=
groups[i, "start"] & observations$date <=groups[i, "end"],
as.character(groups[i, "group"])])
}

Thanks again,
Peter

On Wed, Feb 10, 2016 at 2:26 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> A strategy:
>
>  1. Convert your dates and intervals to numerics that give the days
> since a time origin. See as.POSIXlt (or ** ct for details and an
> example that does this). Should be fast...
>
> 2. Use the findInterval() function to get the interval into which each
> date falls. This **is** "vectorized" and should be fairly fast.
>
> 3. Use the ave() function using the intervals as your factor that
> splits your data column(s) for which you wish to compute statistics.
> The basic statistics functions like mean, sum, etc. **are**
> vectorized, so this should be fast.
>
> As David said, the *apply functions will probably not be much, if at
> all, faster than an explicit for() loop. Most of the time will be
> spent spent comparing the dates to the intervals to find in which each
> falls, and findInterval is a fast way to do this.
>
> ... I think.
>
> If you try this, let me know (perhaps privately) how/if it works.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 10, 2016 at 1:08 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Feb 10, 2016, at 12:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
>>>
>>> Hello, I have a dataframe with a date range, and another dataframe
>>> with observations by date.  For each date range, I'd like to average
>>> the values within that range from the other dataframe.  I've provided
>>> code below doing what I would like, but using a for loop is too
>>> inefficient for my actual case (takes about an hour).  So I'm looking
>>> for a way to vectorize.
>>>
>>>
>>> set.seed(345)
>>> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
>>> by="DSTday")
>>> observations <- data.frame(date=date.range, values=runif(152,1,100) )
>>> groups <- data.frame(start=sample(date.range[1:50], 20), end =
>>> sample(date.range[51:152], 20), average = NA)
>>>
>>> #Potential Solution (too inefficient)
>>>
>>> for(i in 1:NROW(groups)){
>>> groups[i, "average"] <- mean(observations[observations$date >=
>>> groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
>>> }
>>>
>> The 'average' column could be added to groups with this value:
>>
>> mapply( function(start,end){ mean(observations[['values']][
>>                      observations$date >= start & observations$date <=end])},
>>         groups$start, groups$end)
>>
>>  [1] 50.96831 49.42286 47.27240 49.07534 47.66570 49.30977 48.47503 47.74036
>>  [9] 46.02527 58.76492 48.86580 49.90655 45.79705 48.84071 39.53846 46.44601
>> [17] 47.06631 47.74199 49.16980 46.85131
>>
>> I don't really think this is fully "vectorized" in the usual R-meaning of the word. And I don't expect it to be any faster than the for-loop. Perhaps some of the range functions in the data.table package could accelerate your processing. If you don't get any volunteers in this list, you could repost the question on StackOverflow after a suitable pause that avoids accusations of cross-posting. SO has several skilled users of data.table functions.
>>
>>> As an extension to this, there will end up being multiple value
>>> columns, and each range will also identify which column to average.  I
>>> think if I can figure out the first problem I can try to extend it
>>> myself.
>>
>> Sorry, I didn't understand what was being described in that paragraph.
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Feb 11 00:02:10 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Feb 2016 15:02:10 -0800
Subject: [R] Calculate average of many subsets based on columns in
	another dataframe
In-Reply-To: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
References: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
Message-ID: <CAF8bMcY_F5CFoA8F900Z344U2XkK5LJG6_ZMES+TH7Wgb1UYPA@mail.gmail.com>

You could try pulling some of the repeated subscripting operations,
especially the insertions, out of the loop.  E.g.,

    values <- observations[,"values"];
    date <- observations[,"date"] ;
    groups$average <- vapply(seq_len(NROW(groups)), function(i)
mean(values[date >= groups[i, "start"] & date <= groups[i, "end"]]),
FUN.VALUE=0)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 10, 2016 at 12:18 PM, Peter Lomas <peter.br.lomas at gmail.com>
wrote:

> Hello, I have a dataframe with a date range, and another dataframe
> with observations by date.  For each date range, I'd like to average
> the values within that range from the other dataframe.  I've provided
> code below doing what I would like, but using a for loop is too
> inefficient for my actual case (takes about an hour).  So I'm looking
> for a way to vectorize.
>
>
> set.seed(345)
> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
> by="DSTday")
> observations <- data.frame(date=date.range, values=runif(152,1,100) )
> groups <- data.frame(start=sample(date.range[1:50], 20), end =
> sample(date.range[51:152], 20), average = NA)
>
> #Potential Solution (too inefficient)
>
> for(i in 1:NROW(groups)){
>  groups[i, "average"] <- mean(observations[observations$date >=
> groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
> }
>
> As an extension to this, there will end up being multiple value
> columns, and each range will also identify which column to average.  I
> think if I can figure out the first problem I can try to extend it
> myself.
>
> Thanks,
> Peter
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb 11 00:32:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Feb 2016 15:32:43 -0800
Subject: [R] Calculate average of many subsets based on columns in
	another dataframe
In-Reply-To: <CAOHXzyXObvimRPfNA1ngEFxFMG2KD_SudFkua1MCKka_JNrL_g@mail.gmail.com>
References: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
	<98952DDC-F913-4B6A-98CA-6EBDEED8EDBC@comcast.net>
	<CAGxFJbR=dPQt2yFJm_XBPHi97OzJ7Pxq=GOrdPo_U5s0yh3duw@mail.gmail.com>
	<CAOHXzyXObvimRPfNA1ngEFxFMG2KD_SudFkua1MCKka_JNrL_g@mail.gmail.com>
Message-ID: <CAGxFJbTK7s5MN8DrjtNj-tRZCTO-mO39OQLuXEoYFztcTsAMRw@mail.gmail.com>

Oh, you didn't say the intervals could overlap!

If Bill D's suggestions don't suffice, try the following:

(again assuming all dates are in a form that allow comparison
operations, e.g. via as.POSIX**)

Assume you have g intervals with start dates "starts" and end dates
"ends" and that you have d "dates".

Then:

wh <- outer(starts, dates,,"<=") & outer(ends,dates,">") ## arrange
"<" and ">"   as you wish

## (?outer for details.)

is a d x g matrix with each column's TRUE values giving the rows =
dates contained in that column's interval.

Then if "somedat" is a data vector of length d

apply(wh, 2, function(x) mean(somedat[x]) )

will give you the means for each interval of all somedat values whose
dates  fell into that interval.
This last step can be repeated for as many somedats as you like.

Note that this is still a loop (via apply), however, so it may not
satisfy your efficiency needs.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 10, 2016 at 2:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
> Thanks David, Bert,
>
> From what I'm reading on ?findInterval, It may not be workable because
> of overlapping date ranges.  findInterval seems to take a series of
> bin breakpoints as its argument. I'm currently exploring data.table
> documentation and will keep thinking about this.
>
> Just on David's point, the extension of this with "groups" would look
> as below.  I just don't want to complicate it before I've solved the
> simplest issue.
>
> set.seed(345)
> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
> by="DSTday")
> observations <- data.frame(date=date.range, a=runif(152,1,100),
> b=runif(152,1,100), c=runif(152,1,100) )
> groups <- data.frame(start=sample(date.range[1:50], 20), end =
> sample(date.range[51:152], 20), group=sample(letters[1:3], 20,
> replace=TRUE), average = NA)
>
> #Potential Solutions (too inefficient)
> for(i in 1:NROW(groups)){
>  groups[i, "average"] <- mean(observations[observations$date >=
> groups[i, "start"] & observations$date <=groups[i, "end"],
> as.character(groups[i, "group"])])
> }
>
> Thanks again,
> Peter
>
> On Wed, Feb 10, 2016 at 2:26 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> A strategy:
>>
>>  1. Convert your dates and intervals to numerics that give the days
>> since a time origin. See as.POSIXlt (or ** ct for details and an
>> example that does this). Should be fast...
>>
>> 2. Use the findInterval() function to get the interval into which each
>> date falls. This **is** "vectorized" and should be fairly fast.
>>
>> 3. Use the ave() function using the intervals as your factor that
>> splits your data column(s) for which you wish to compute statistics.
>> The basic statistics functions like mean, sum, etc. **are**
>> vectorized, so this should be fast.
>>
>> As David said, the *apply functions will probably not be much, if at
>> all, faster than an explicit for() loop. Most of the time will be
>> spent spent comparing the dates to the intervals to find in which each
>> falls, and findInterval is a fast way to do this.
>>
>> ... I think.
>>
>> If you try this, let me know (perhaps privately) how/if it works.
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Feb 10, 2016 at 1:08 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>> On Feb 10, 2016, at 12:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
>>>>
>>>> Hello, I have a dataframe with a date range, and another dataframe
>>>> with observations by date.  For each date range, I'd like to average
>>>> the values within that range from the other dataframe.  I've provided
>>>> code below doing what I would like, but using a for loop is too
>>>> inefficient for my actual case (takes about an hour).  So I'm looking
>>>> for a way to vectorize.
>>>>
>>>>
>>>> set.seed(345)
>>>> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
>>>> by="DSTday")
>>>> observations <- data.frame(date=date.range, values=runif(152,1,100) )
>>>> groups <- data.frame(start=sample(date.range[1:50], 20), end =
>>>> sample(date.range[51:152], 20), average = NA)
>>>>
>>>> #Potential Solution (too inefficient)
>>>>
>>>> for(i in 1:NROW(groups)){
>>>> groups[i, "average"] <- mean(observations[observations$date >=
>>>> groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
>>>> }
>>>>
>>> The 'average' column could be added to groups with this value:
>>>
>>> mapply( function(start,end){ mean(observations[['values']][
>>>                      observations$date >= start & observations$date <=end])},
>>>         groups$start, groups$end)
>>>
>>>  [1] 50.96831 49.42286 47.27240 49.07534 47.66570 49.30977 48.47503 47.74036
>>>  [9] 46.02527 58.76492 48.86580 49.90655 45.79705 48.84071 39.53846 46.44601
>>> [17] 47.06631 47.74199 49.16980 46.85131
>>>
>>> I don't really think this is fully "vectorized" in the usual R-meaning of the word. And I don't expect it to be any faster than the for-loop. Perhaps some of the range functions in the data.table package could accelerate your processing. If you don't get any volunteers in this list, you could repost the question on StackOverflow after a suitable pause that avoids accusations of cross-posting. SO has several skilled users of data.table functions.
>>>
>>>> As an extension to this, there will end up being multiple value
>>>> columns, and each range will also identify which column to average.  I
>>>> think if I can figure out the first problem I can try to extend it
>>>> myself.
>>>
>>> Sorry, I didn't understand what was being described in that paragraph.
>>>
>>> --
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Thu Feb 11 03:37:18 2016
From: tmrsg11 at gmail.com (C W)
Date: Wed, 10 Feb 2016 21:37:18 -0500
Subject: [R] Why two curves and numerical integration look so different?
Message-ID: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>

Dear R,

I am graphing the following normal density curve.  Why does it look so
different?

# the curves
x <- seq(-2, 4, by=0.00001)
curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong answer

Why the second curve is flat?  I just changed it from -4 to -3.  There is
no density in that region.


Also, I am doing numerical integration.  Why are they so different?

> x <- seq(-2, 4, by=0.00001)
> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
[1] 7.978846e+94
> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
[1] 0

What is going here?  What a I doing wrong?

Thanks so much!

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Thu Feb 11 04:10:44 2016
From: valkremk at gmail.com (Val)
Date: Wed, 10 Feb 2016 21:10:44 -0600
Subject: [R] Table
Message-ID: <CAJOiR6ZVxXJv5jF50ijFKwExxkhof8Z7ngowOWuGAUHBcsy9gg@mail.gmail.com>

Hi all,

I want create a frequency table using this :

xc1<- sample(c(1:10), 100, replace = TRUE)
xc2<- sample(c(0,1), 100, replace = TRUE)

xc3<- cbind(xc1,xc2)

tab1<- xc3[,list( d1=sum(xc2==0), d2=sum(xc2==1)),by=xc1]

but not working.

Error in `[.data.frame`(xc3, , list(d1 = sum(xc2 == 1), d2 = sum(xc2 ==  :
  unused argument (by = xc1)

any idea?



I want the result like this

xc1  d1  d2
  1  11  5
  2   5  4
  3   5  4
  4   2  5
  5   2  7
  6   7  4
  7   9  5
  8   2  6
  9   5  4
  10  3  5

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Feb 11 06:10:46 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 11 Feb 2016 05:10:46 +0000
Subject: [R] Table
In-Reply-To: <CAJOiR6ZVxXJv5jF50ijFKwExxkhof8Z7ngowOWuGAUHBcsy9gg@mail.gmail.com>
References: <CAJOiR6ZVxXJv5jF50ijFKwExxkhof8Z7ngowOWuGAUHBcsy9gg@mail.gmail.com>
Message-ID: <CAKVAULM1PRbf=kMv5FJBeO3KF+YDAbOXoYfNS+33J47_tTBNGw@mail.gmail.com>

Hi Val,

Does this help:

library(plyr)
ddply(as.data.frame(xc3), .variables = "xc1", summarise, d1 = sum(xc2 ==
0), d2 = sum(xc2 == 1))

You could also try
aggregate(xc3, by = list(xc1, xc2), FUN = sum)

and modify the output.

Best,
Ulrik


On Thu, 11 Feb 2016 at 04:12 Val <valkremk at gmail.com> wrote:

> Hi all,
>
> I want create a frequency table using this :
>
> xc1<- sample(c(1:10), 100, replace = TRUE)
> xc2<- sample(c(0,1), 100, replace = TRUE)
>
> xc3<- cbind(xc1,xc2)
>
> tab1<- xc3[,list( d1=sum(xc2==0), d2=sum(xc2==1)),by=xc1]
>
> but not working.
>
> Error in `[.data.frame`(xc3, , list(d1 = sum(xc2 == 1), d2 = sum(xc2 ==  :
>   unused argument (by = xc1)
>
> any idea?
>
>
>
> I want the result like this
>
> xc1  d1  d2
>   1  11  5
>   2   5  4
>   3   5  4
>   4   2  5
>   5   2  7
>   6   7  4
>   7   9  5
>   8   2  6
>   9   5  4
>   10  3  5
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 11 06:31:10 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Feb 2016 21:31:10 -0800
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
Message-ID: <CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>

Most of the mass of that distribution is within 3e-100 of 2.
You have to be pretty lucky to have a point in sequence
land there.  (You will get at most one point there because
the difference between 2 and its nearest neightbors is on
the order of 1e-16.)

seq(-2,4,len=101), as used by default in curve, does include 2
but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the bump.
The same principal holds for numerical integration.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:

> Dear R,
>
> I am graphing the following normal density curve.  Why does it look so
> different?
>
> # the curves
> x <- seq(-2, 4, by=0.00001)
> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong answer
>
> Why the second curve is flat?  I just changed it from -4 to -3.  There is
> no density in that region.
>
>
> Also, I am doing numerical integration.  Why are they so different?
>
> > x <- seq(-2, 4, by=0.00001)
> > sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> [1] 7.978846e+94
> > x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> > sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> [1] 0
>
> What is going here?  What a I doing wrong?
>
> Thanks so much!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jimplante at me.com  Thu Feb 11 06:39:16 2016
From: jimplante at me.com (James Plante)
Date: Wed, 10 Feb 2016 23:39:16 -0600
Subject: [R] Removing a dollar sign from a character vector
Message-ID: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>

What I?ve got:
# sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.3 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] XML_3.98-1.3 dplyr_0.4.3 

loaded via a namespace (and not attached):
[1] magrittr_1.5      R6_2.1.2          assertthat_0.1    rsconnect_0.4.1.4
[5] parallel_3.2.3    DBI_0.3.1         tools_3.2.3       Rcpp_0.12.3     

> str(y) #toy vector, subset of larger vector in a dataframe of ~4,600 rows.
 chr [1:5] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ?

y is a subset of a column in a dataframe that?s too big to post. I tried the commands listed here on the dataframe and it didn?t work. So I?m using a small subset to find out where my error is. It?s being a PITA, and I?m trying to solve it. What I want is a vector of numbers: 1000, 1000, 1000, 2600, 2,600. 

What I?ve tried:
> y
[1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
> gsub("$", "", y)
[1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? # no change. Why?
> gsub(".00", "", y)  # note: that?s dot zero zero, replace with ?"
[1] "$10 " "$10 " "$10 " "$2, " "$2, ?  #WTF?

I?ve also tried sapply and apply, but haven?t yet tried a loop. (These were done in desperation; gsub ought to work the way the help says.) I?ve tried lots more than is listed here, over and over, with no results. I?d be grateful for any guidance you can provide. 

Thanks in advance,

Jim Plante


From jdnewmil at dcn.davis.ca.us  Thu Feb 11 06:53:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 10 Feb 2016 21:53:50 -0800
Subject: [R] Removing a dollar sign from a character vector
In-Reply-To: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
References: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
Message-ID: <451F2A9A-A784-4BE2-889B-832E2B934609@dcn.davis.ca.us>

y <- as.numeric( gsub( "[$, ]", "", y ) )
-- 
Sent from my phone. Please excuse my brevity.

On February 10, 2016 9:39:16 PM PST, James Plante <jimplante at me.com> wrote:
>What I?ve got:
># sessionInfo()
>R version 3.2.3 (2015-12-10)
>Platform: x86_64-apple-darwin13.4.0 (64-bit)
>Running under: OS X 10.11.3 (El Capitan)
>
>locale:
>[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>other attached packages:
>[1] XML_3.98-1.3 dplyr_0.4.3 
>
>loaded via a namespace (and not attached):
>[1] magrittr_1.5      R6_2.1.2          assertthat_0.1   
>rsconnect_0.4.1.4
>[5] parallel_3.2.3    DBI_0.3.1         tools_3.2.3       Rcpp_0.12.3  
>  
>
>> str(y) #toy vector, subset of larger vector in a dataframe of ~4,600
>rows.
>chr [1:5] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 "
>"$2,600.00 ?
>
>y is a subset of a column in a dataframe that?s too big to post. I
>tried the commands listed here on the dataframe and it didn?t work. So
>I?m using a small subset to find out where my error is. It?s being a
>PITA, and I?m trying to solve it. What I want is a vector of numbers:
>1000, 1000, 1000, 2600, 2,600. 
>
>What I?ve tried:
>> y
>[1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>> gsub("$", "", y)
>[1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? #
>no change. Why?
>> gsub(".00", "", y)  # note: that?s dot zero zero, replace with ?"
>[1] "$10 " "$10 " "$10 " "$2, " "$2, ?  #WTF?
>
>I?ve also tried sapply and apply, but haven?t yet tried a loop. (These
>were done in desperation; gsub ought to work the way the help says.)
>I?ve tried lots more than is listed here, over and over, with no
>results. I?d be grateful for any guidance you can provide. 
>
>Thanks in advance,
>
>Jim Plante
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 11 07:10:40 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Feb 2016 22:10:40 -0800
Subject: [R] Removing a dollar sign from a character vector
In-Reply-To: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
References: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
Message-ID: <CAF8bMcZ-oNvgR_CZBwyeQbeMPJsj7tH2bcD0S+adP8A4XLdjQw@mail.gmail.com>

   > y
   [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
   > gsub("$", "", y)
   [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? #
no change. Why?

"$" as a regular expression means "end of string", which has zero length -
replacing "end
of string" with nothing does not affect the string.  Try gsub("$",
"DOLLAR", "$100")
to see it do something.

Use either fixed=TRUE so the 'pattern'  argument is not regarded as a
regular expression or pattern="\\$" or pattern="[$]" to remove dollar's special
meaning in the pattern language.

Read up on regular expressions (probably there is a See Also entry in
help(gsub)).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 10, 2016 at 9:39 PM, James Plante <jimplante at me.com> wrote:

> What I?ve got:
> # sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.3 (El Capitan)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] XML_3.98-1.3 dplyr_0.4.3
>
> loaded via a namespace (and not attached):
> [1] magrittr_1.5      R6_2.1.2          assertthat_0.1    rsconnect_0.4.1.4
> [5] parallel_3.2.3    DBI_0.3.1         tools_3.2.3       Rcpp_0.12.3
>
> > str(y) #toy vector, subset of larger vector in a dataframe of ~4,600
> rows.
>  chr [1:5] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ?
>
> y is a subset of a column in a dataframe that?s too big to post. I tried
> the commands listed here on the dataframe and it didn?t work. So I?m using
> a small subset to find out where my error is. It?s being a PITA, and I?m
> trying to solve it. What I want is a vector of numbers: 1000, 1000, 1000,
> 2600, 2,600.
>
> What I?ve tried:
> > y
> [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
> > gsub("$", "", y)
> [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? # no
> change. Why?
> > gsub(".00", "", y)  # note: that?s dot zero zero, replace with ?"
> [1] "$10 " "$10 " "$10 " "$2, " "$2, ?  #WTF?
>
> I?ve also tried sapply and apply, but haven?t yet tried a loop. (These
> were done in desperation; gsub ought to work the way the help says.) I?ve
> tried lots more than is listed here, over and over, with no results. I?d be
> grateful for any guidance you can provide.
>
> Thanks in advance,
>
> Jim Plante
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Feb 11 08:57:52 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Feb 2016 23:57:52 -0800
Subject: [R] Table
In-Reply-To: <CAJOiR6ZVxXJv5jF50ijFKwExxkhof8Z7ngowOWuGAUHBcsy9gg@mail.gmail.com>
References: <CAJOiR6ZVxXJv5jF50ijFKwExxkhof8Z7ngowOWuGAUHBcsy9gg@mail.gmail.com>
Message-ID: <C6EE46FB-0FF4-428F-8BE2-2268BD793F56@comcast.net>


> On Feb 10, 2016, at 7:10 PM, Val <valkremk at gmail.com> wrote:
> 
> Hi all,
> 
> I want create a frequency table using this :
> 
> xc1<- sample(c(1:10), 100, replace = TRUE)
> xc2<- sample(c(0,1), 100, replace = TRUE)
> 
> xc3<- cbind(xc1,xc2)
> 
> tab1<- xc3[,list( d1=sum(xc2==0), d2=sum(xc2==1)),by=xc1]
> 
> but not working.
> 

"Not working." Sadder and less specific complaints were never heard. You are not saying what the goal of this effort might be. Perhaps:

> table(xc1=xc3[,1], d=xc3[,2])
    d
xc1   0  1
  1   5  4
  2   5  5
  3   6  3
  4   1  5
  5   4  6
  6   6  8
  7  10  5
  8   4  6
  9   8  3
  10  2  4

Furthermore, your syntax uses suggest you may be expecting us all to have data.table loaded, .... not a reasonable expectation. One which you should be stating explicitly with a library or require call.




> Error in `[.data.frame`(xc3, , list(d1 = sum(xc2 == 1), d2 = sum(xc2 ==  :
>  unused argument (by = xc1)
> 
> any idea?
> 
> 
> 
> I want the result like this

Well, the resutl from `table` does resemble this, but since the goal was never articulated, I'm unsure if it is a success.
> 
> xc1  d1  d2
>  1  11  5
>  2   5  4
>  3   5  4
>  4   2  5
>  5   2  7
>  6   7  4
>  7   9  5
>  8   2  6
>  9   5  4
>  10  3  5
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tmrsg11 at gmail.com  Thu Feb 11 15:14:11 2016
From: tmrsg11 at gmail.com (C W)
Date: Thu, 11 Feb 2016 09:14:11 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
Message-ID: <CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>

Wow, thank you, that was very clear.  Let me give it some more runs and
investigate this.

On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com> wrote:

> Most of the mass of that distribution is within 3e-100 of 2.
> You have to be pretty lucky to have a point in sequence
> land there.  (You will get at most one point there because
> the difference between 2 and its nearest neightbors is on
> the order of 1e-16.)
>
> seq(-2,4,len=101), as used by default in curve, does include 2
> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the bump.
> The same principal holds for numerical integration.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
>
>> Dear R,
>>
>> I am graphing the following normal density curve.  Why does it look so
>> different?
>>
>> # the curves
>> x <- seq(-2, 4, by=0.00001)
>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
>> answer
>>
>> Why the second curve is flat?  I just changed it from -4 to -3.  There is
>> no density in that region.
>>
>>
>> Also, I am doing numerical integration.  Why are they so different?
>>
>> > x <- seq(-2, 4, by=0.00001)
>> > sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>> [1] 7.978846e+94
>> > x <- seq(-1, 4, by=0.00001) #changed -2 to -1
>> > sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>> [1] 0
>>
>> What is going here?  What a I doing wrong?
>>
>> Thanks so much!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Thu Feb 11 16:36:12 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Thu, 11 Feb 2016 09:36:12 -0600
Subject: [R] GPU package crowd-source testing
In-Reply-To: <CAKxd1KMgAkcArNYQzwxBAvnewsz33hMEuaz5bb_z_B0C7nqD=g@mail.gmail.com>
References: <CAKxd1KMgAkcArNYQzwxBAvnewsz33hMEuaz5bb_z_B0C7nqD=g@mail.gmail.com>
Message-ID: <CAKxd1KMiOSQ7=z_51=aDfv1veKdNFDCo6Bj2MXhWpqan=VSmXQ@mail.gmail.com>

R Users,

My sincere thanks to all those who have been coming forward to test my GPU
package and provide bug reports.  I want to followup on my initial request
with a few qualifiers.

1. I neglected to tell users to also use my github version of 'RViennaCL'
instead of the CRAN version.  I have made some updates that I was
postponing release of until I can solve the multiple device issues with
'gpuR'.

devtools::install_github("cdeterman/RViennaCL")

2. When reporting bugs, either directly to me or ideally in my github
issues (https://github.com/cdeterman/gpuR/issues), please provide your
Operating System, OpenCL version (e.g. 1.0, 1.2, 2.0), OpenCL SDK (e.g.
AMD, CUDA toolkit, etc.) and GPU device.  If you don't know these things
you can get them from Sys.info() for the OS, platformInfo() for the OpenCL
SDK, gpuInfo() for the GPU information, and check your OpenCL header (cl.h)
for the /* OpenCL Version */ section for the highest version number.

3. If you have installed 'gpuR' and it is running without problems I would
still like to know this.  It would be good to begin generating a list of
'tested' devices and associated platform.  I have just created a gitter
account.  I am relatively new to it but I'm hoping it can be used to try
and consolidate responses.  In this case, you can simply reply on the
Tested_GPUs thread (https://gitter.im/cdeterman/gpuR/Tested_GPUs) with your
device and platform backend.

Again, thanks to all for taking the time to try out this package.

Regards,
Charles



On Tue, Feb 9, 2016 at 12:20 PM, Charles Determan <cdetermanjr at gmail.com>
wrote:

> Greetings R users,
>
> I would like to request any users who would be willing to test one of my
> packages.  Normally I would be content using testthat and continuous
> integration services but this particular package is used for GPU computing
> (hence the cross-posting).  It is intended to be as general as possible for
> available devices but I only have access to so much hardware.  I can't
> possibly test it against every GPU available.
>
> As such, I would sincerely appreciate any user that has at least one GPU
> device (Intel, AMD, or NVIDIA) and is willing to experiment with the
> package to try it out.  Note, this will require installing an OpenCL SDK of
> some form.  Installation instructions for the package are found here (
> https://github.com/cdeterman/gpuR/wiki).
>
> At the very least, if you have a valid device, you would only need to
> download the 'development' version of the package and experiment with the
> functions such as a matrix multiplication.
>
> devtools::install_github("cdeterman/gpuR", ref = "develop")
>
> library(gpuR)
> A <- gpuMatrix(rnorm(10000), 100, 100)
> A %*% A
>
> You could also clone my github repo and run all the unit tests I have
> included
>
> git clone -b develop https://github.com/cdeterman/gpuR.git
>
> If using RStudio, just open the package in a new project and press
> 'Ctrl-Shift-T' or more directly run  `devtools::test()`
>
> If using command-line R, switch to the gpuR directory, start R and run
> `devtools::test()`.
>
> If you find any errors or bugs, please report them in my github issues (
> https://github.com/cdeterman/gpuR/issues).  Naturally any recommendations
> on additional features are welcome.
>
> Thank you in advance for any support you can provide.  I want to continue
> improving this package but I am beginning to reach the end of what I can
> accomplish from a hardware perspective.
>
> Best Regards,
> Charles
>
>
>

	[[alternative HTML version deleted]]


From martyn.plummer at r-project.org  Thu Feb 11 11:25:30 2016
From: martyn.plummer at r-project.org (Martyn Plummer)
Date: Thu, 11 Feb 2016 11:25:30 +0100
Subject: [R] New R logo
Message-ID: <1455186330.4644.99.camel@r-project.org>

The R logo has been revised in to be more compatible with the principles
of flat design followed by some recent user interfaces such as Microsoft
Windows >= 8 and Mac OS X >= 10.10 (Yosemite). The new logo is
available for download from the R project web site in SVG and
high-resolution PNG formats:

https://www.r-project.org/logo

Thanks to Hadley Wickham and others at RStudio for lending their graphic
design skills.

The logo is dual licensed. You may use either the Creative Commons
Attribution-ShareAlike 4.0 International license (CC-BY-SA 4.0) or the
GNU General Public License version 2 (GPL?2). For further details,
please refer to the link above.

For the R Foundation
Martyn Plummer, Co-President

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

From legbadoc at gmail.com  Thu Feb 11 13:43:24 2016
From: legbadoc at gmail.com (papa legba)
Date: Thu, 11 Feb 2016 13:43:24 +0100
Subject: [R] problem with rJava and install option
Message-ID: <CAB1ctboo+az7z_d=mJsQx+6r5wi_gP6+a4s6Yi38WgkULMPh6A@mail.gmail.com>

Hi,
So working with docker and rJava i have a freeze at the Xrs check
there is a solution that is to use the --disable-Xrs option
https://github.com/s-u/rJava/issues/63

but as i'am a beginner :  install.packages("rJava", repos='
http://cran.us.r-project.org', configure.args ="--disable-Xrs")

doesn't work and still freeze my install...

So any help welcome.

regards and thanks
Bussiere

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb 11 18:01:14 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 11 Feb 2016 09:01:14 -0800
Subject: [R] Removing a dollar sign from a character vector
In-Reply-To: <CAF8bMcZ-oNvgR_CZBwyeQbeMPJsj7tH2bcD0S+adP8A4XLdjQw@mail.gmail.com>
References: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
	<CAF8bMcZ-oNvgR_CZBwyeQbeMPJsj7tH2bcD0S+adP8A4XLdjQw@mail.gmail.com>
Message-ID: <315B7E03-9A3D-4420-8689-39369ABE7C02@dcn.davis.ca.us>

The "end of string" special meaning only applies when the dollar sign is at the right end of the string (as it was in the OP attempt). That is,  it is NOT generally necessary to wrap it in brackets to remove the special meaning unless it would otherwise be at the end of the pattern string. 
-- 
Sent from my phone. Please excuse my brevity.

On February 10, 2016 10:10:40 PM PST, William Dunlap via R-help <r-help at r-project.org> wrote:
>   > y
>   [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>   > gsub("$", "", y)
> [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? #
>no change. Why?
>
>"$" as a regular expression means "end of string", which has zero
>length -
>replacing "end
>of string" with nothing does not affect the string.  Try gsub("$",
>"DOLLAR", "$100")
>to see it do something.
>
>Use either fixed=TRUE so the 'pattern'  argument is not regarded as a
>regular expression or pattern="\\$" or pattern="[$]" to remove dollar's
>special
>meaning in the pattern language.
>
>Read up on regular expressions (probably there is a See Also entry in
>help(gsub)).
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Wed, Feb 10, 2016 at 9:39 PM, James Plante <jimplante at me.com> wrote:
>
>> What I?ve got:
>> # sessionInfo()
>> R version 3.2.3 (2015-12-10)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.11.3 (El Capitan)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] XML_3.98-1.3 dplyr_0.4.3
>>
>> loaded via a namespace (and not attached):
>> [1] magrittr_1.5      R6_2.1.2          assertthat_0.1   
>rsconnect_0.4.1.4
>> [5] parallel_3.2.3    DBI_0.3.1         tools_3.2.3       Rcpp_0.12.3
>>
>> > str(y) #toy vector, subset of larger vector in a dataframe of
>~4,600
>> rows.
>>  chr [1:5] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 "
>"$2,600.00 ?
>>
>> y is a subset of a column in a dataframe that?s too big to post. I
>tried
>> the commands listed here on the dataframe and it didn?t work. So I?m
>using
>> a small subset to find out where my error is. It?s being a PITA, and
>I?m
>> trying to solve it. What I want is a vector of numbers: 1000, 1000,
>1000,
>> 2600, 2,600.
>>
>> What I?ve tried:
>> > y
>> [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>> > gsub("$", "", y)
>> [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ?
># no
>> change. Why?
>> > gsub(".00", "", y)  # note: that?s dot zero zero, replace with ?"
>> [1] "$10 " "$10 " "$10 " "$2, " "$2, ?  #WTF?
>>
>> I?ve also tried sapply and apply, but haven?t yet tried a loop.
>(These
>> were done in desperation; gsub ought to work the way the help says.)
>I?ve
>> tried lots more than is listed here, over and over, with no results.
>I?d be
>> grateful for any guidance you can provide.
>>
>> Thanks in advance,
>>
>> Jim Plante
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Thu Feb 11 18:20:04 2016
From: tmrsg11 at gmail.com (C W)
Date: Thu, 11 Feb 2016 12:20:04 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
Message-ID: <CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>

I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)

Because the variance is small, it results in density like: 7.978846e+94

Is there any good suggestion for this?

Thanks so much!


On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:

> Wow, thank you, that was very clear.  Let me give it some more runs and
> investigate this.
>
> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>> Most of the mass of that distribution is within 3e-100 of 2.
>> You have to be pretty lucky to have a point in sequence
>> land there.  (You will get at most one point there because
>> the difference between 2 and its nearest neightbors is on
>> the order of 1e-16.)
>>
>> seq(-2,4,len=101), as used by default in curve, does include 2
>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the bump.
>> The same principal holds for numerical integration.
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
>>
>>> Dear R,
>>>
>>> I am graphing the following normal density curve.  Why does it look so
>>> different?
>>>
>>> # the curves
>>> x <- seq(-2, 4, by=0.00001)
>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
>>> answer
>>>
>>> Why the second curve is flat?  I just changed it from -4 to -3.  There is
>>> no density in that region.
>>>
>>>
>>> Also, I am doing numerical integration.  Why are they so different?
>>>
>>> > x <- seq(-2, 4, by=0.00001)
>>> > sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>>> [1] 7.978846e+94
>>> > x <- seq(-1, 4, by=0.00001) #changed -2 to -1
>>> > sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>>> [1] 0
>>>
>>> What is going here?  What a I doing wrong?
>>>
>>> Thanks so much!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 11 18:30:50 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 11 Feb 2016 09:30:50 -0800
Subject: [R] Removing a dollar sign from a character vector
In-Reply-To: <315B7E03-9A3D-4420-8689-39369ABE7C02@dcn.davis.ca.us>
References: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
	<CAF8bMcZ-oNvgR_CZBwyeQbeMPJsj7tH2bcD0S+adP8A4XLdjQw@mail.gmail.com>
	<315B7E03-9A3D-4420-8689-39369ABE7C02@dcn.davis.ca.us>
Message-ID: <CAF8bMcbKPB9r32cvaAH7MjR+nSegfCVk90C0G71uJCG=E1uYoA@mail.gmail.com>

In certain programs (not current R), a pattern with stuff after a naked
dollar
sign would not match anything because dollar meant end-of-string.

In any case I prefer simple rules like 'backslash a dollar sign' instead of
'backslash a dollar sign at the end of the pattern but not elsewhere'.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Feb 11, 2016 at 9:01 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The "end of string" special meaning only applies when the dollar sign is
> at the right end of the string (as it was in the OP attempt). That is, it
> is NOT generally necessary to wrap it in brackets to remove the special
> meaning unless it would otherwise be at the end of the pattern string.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 10, 2016 10:10:40 PM PST, William Dunlap via R-help <
> r-help at r-project.org> wrote:
>
>>  y
>>>
>>    [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>>
>>>  gsub("$", "", y)
>>>
>>    [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? #
>> no change. Why?
>>
>> "$" as a regular expression means "end of string", which has zero length -
>> replacing "end
>> of string" with nothing does not affect the string.  Try gsub("$",
>> "DOLLAR", "$100")
>> to see it do something.
>>
>> Use either fixed=TRUE so the 'pattern'  argument is not regarded as a
>> regular expression or pattern="\\$" or pattern="[$]" to remove dollar's special
>> meaning in the pattern language.
>>
>> Read up on regular expressions (probably there is a See Also
>> entry in
>> help(gsub)).
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Wed, Feb 10, 2016 at 9:39 PM, James Plante <jimplante at me.com> wrote:
>>
>>  What I?ve got:
>>>  # sessionInfo()
>>>  R version 3.2.3 (2015-12-10)
>>>  Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>  Running under: OS X 10.11.3 (El Capitan)
>>>
>>>  locale:
>>>  [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>>  attached base packages:
>>>  [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>  other attached packages:
>>>  [1] XML_3.98-1.3 dplyr_0.4.3
>>>
>>>  loaded via a namespace (and not attached):
>>>  [1] magrittr_1.5      R6_2.1.2          assertthat_0.1    rsconnect_0.4.1.4
>>>  [5] parallel_3.2.3    DBI_0.3.1         tools_3.2.3
>>> Rcpp_0.12.3
>>>
>>>  str(y) #toy vector, subset of larger vector in a dataframe of ~4,600
>>>>
>>>  rows.
>>>   chr [1:5] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ?
>>>
>>>  y is a subset of a column in a dataframe that?s too big to post. I tried
>>>  the commands listed here on the dataframe and it didn?t work. So I?m using
>>>  a small subset to find out where my error is. It?s being a PITA, and I?m
>>>  trying to solve it. What I want is a vector of numbers: 1000, 1000, 1000,
>>>  2600, 2,600.
>>>
>>>  What I?ve tried:
>>>
>>>>  y
>>>>
>>>  [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>>>
>>>>  gsub("$", "", y)
>>>>
>>>  [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? # no
>>>  change. Why?
>>>
>>>>  gsub(".00", "", y)  # note: that?s dot zero zero, replace with ?"
>>>>
>>>  [1] "$10 " "$10 " "$10 " "$2, " "$2, ?  #WTF?
>>>
>>>  I?ve also tried sapply and apply, but haven?t yet tried a loop. (These
>>>  were done in desperation; gsub ought to work the way the help says.) I?ve
>>>  tried lots more than is listed here, over and over, with no results. I?d be
>>>  grateful for any guidance you can provide.
>>>
>>>  Thanks in advance,
>>>
>>>  Jim Plante
>>>
>>> ------------------------------
>>>
>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>  PLEASE do read the posting guide
>>>  http://www.R-project.org/posting-guide.html
>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 11 18:52:34 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 11 Feb 2016 09:52:34 -0800
Subject: [R] Removing a dollar sign from a character vector
In-Reply-To: <CAF8bMcbKPB9r32cvaAH7MjR+nSegfCVk90C0G71uJCG=E1uYoA@mail.gmail.com>
References: <B4B4B0E4-02BE-4E1F-8DA5-11A9BC8F8424@me.com>
	<CAF8bMcZ-oNvgR_CZBwyeQbeMPJsj7tH2bcD0S+adP8A4XLdjQw@mail.gmail.com>
	<315B7E03-9A3D-4420-8689-39369ABE7C02@dcn.davis.ca.us>
	<CAF8bMcbKPB9r32cvaAH7MjR+nSegfCVk90C0G71uJCG=E1uYoA@mail.gmail.com>
Message-ID: <CAF8bMcYv1bo=RFUNW+rWyMBs1O2eK4T=0XZhi5K_jOzNuZvr6Q@mail.gmail.com>

I should have said that R-3.2.3 requires the $ to be backslashed even when
it
is not at the end of the pattern:

  > gsub("$[[:digit:]]*", "<money>", c("$VAR", "$20/oz."))
  [1] "$VAR<money>"    "$20/oz.<money>"
  > gsub("\\$[[:digit:]]*", "<money>", c("$VAR", "$20/oz."))
  [1] "<money>VAR"  "<money>/oz."

Modern Linuxen's tools like sed do not seem to have this requirement.
  % echo '$VAR' '$20/oz.' | sed -e 's/$[0-9]*/<money>/g'
  <money>VAR <money>/oz.
  % echo '$VAR' '$20/oz.' | sed -e 's/\$[0-9]*/<money>/g'
  <money>VAR <money>/oz.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Feb 11, 2016 at 9:30 AM, William Dunlap <wdunlap at tibco.com> wrote:

> In certain programs (not current R), a pattern with stuff after a naked
> dollar
> sign would not match anything because dollar meant end-of-string.
>
> In any case I prefer simple rules like 'backslash a dollar sign' instead of
> 'backslash a dollar sign at the end of the pattern but not elsewhere'.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Feb 11, 2016 at 9:01 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> The "end of string" special meaning only applies when the dollar sign is
>> at the right end of the string (as it was in the OP attempt). That is, it
>> is NOT generally necessary to wrap it in brackets to remove the special
>> meaning unless it would otherwise be at the end of the pattern string.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 10, 2016 10:10:40 PM PST, William Dunlap via R-help <
>> r-help at r-project.org> wrote:
>>
>>>  y
>>>>
>>>    [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>>>
>>>>  gsub("$", "", y)
>>>>
>>>    [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? #
>>> no change. Why?
>>>
>>> "$" as a regular expression means "end of string", which has zero length -
>>> replacing "end
>>> of string" with nothing does not affect the string.  Try gsub("$",
>>> "DOLLAR", "$100")
>>> to see it do something.
>>>
>>> Use either fixed=TRUE so the 'pattern'  argument is not regarded as a
>>> regular expression or pattern="\\$" or pattern="[$]" to remove dollar's special
>>> meaning in the pattern language.
>>>
>>> Read up on regular expressions (probably there is a See Also
>>> entry in
>>> help(gsub)).
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Wed, Feb 10, 2016 at 9:39 PM, James Plante <jimplante at me.com> wrote:
>>>
>>>  What I?ve got:
>>>>  # sessionInfo()
>>>>  R version 3.2.3 (2015-12-10)
>>>>  Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>  Running under: OS X 10.11.3 (El Capitan)
>>>>
>>>>  locale:
>>>>  [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>>  attached base packages:
>>>>  [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>>  other attached packages:
>>>>  [1] XML_3.98-1.3 dplyr_0.4.3
>>>>
>>>>  loaded via a namespace (and not attached):
>>>>  [1] magrittr_1.5      R6_2.1.2          assertthat_0.1    rsconnect_0.4.1.4
>>>>  [5] parallel_3.2.3    DBI_0.3.1         tools_3.2.3
>>>> Rcpp_0.12.3
>>>>
>>>>  str(y) #toy vector, subset of larger vector in a dataframe of ~4,600
>>>>>
>>>>  rows.
>>>>   chr [1:5] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ?
>>>>
>>>>  y is a subset of a column in a dataframe that?s too big to post. I tried
>>>>  the commands listed here on the dataframe and it didn?t work. So I?m using
>>>>  a small subset to find out where my error is. It?s being a PITA, and I?m
>>>>  trying to solve it. What I want is a vector of numbers: 1000, 1000, 1000,
>>>>  2600, 2,600.
>>>>
>>>>  What I?ve tried:
>>>>
>>>>>  y
>>>>>
>>>>  [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 "
>>>>
>>>>>  gsub("$", "", y)
>>>>>
>>>>  [1] "$1,000.00 " "$1,000.00 " "$1,000.00 " "$2,600.00 " "$2,600.00 ? # no
>>>>  change. Why?
>>>>
>>>>>  gsub(".00", "", y)  # note: that?s dot zero zero, replace with ?"
>>>>>
>>>>  [1] "$10 " "$10 " "$10 " "$2, " "$2, ?  #WTF?
>>>>
>>>>  I?ve also tried sapply and apply, but haven?t yet tried a loop. (These
>>>>  were done in desperation; gsub ought to work the way the help says.) I?ve
>>>>  tried lots more than is listed here, over and over, with no results. I?d be
>>>>  grateful for any guidance you can provide.
>>>>
>>>>  Thanks in advance,
>>>>
>>>>  Jim Plante
>>>>
>>>> ------------------------------
>>>>
>>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>  PLEASE do read the posting guide
>>>>  http://www.R-project.org/posting-guide.html
>>>>  and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>

	[[alternative HTML version deleted]]


From peter.br.lomas at gmail.com  Thu Feb 11 19:37:40 2016
From: peter.br.lomas at gmail.com (Peter Lomas)
Date: Thu, 11 Feb 2016 11:37:40 -0700
Subject: [R] Calculate average of many subsets based on columns in
	another dataframe
In-Reply-To: <CAGxFJbTK7s5MN8DrjtNj-tRZCTO-mO39OQLuXEoYFztcTsAMRw@mail.gmail.com>
References: <CAOHXzyUiBp4Ztjk-+u_9aVuMjO5+yC50seuCaMKvgyYUCdi8wg@mail.gmail.com>
	<98952DDC-F913-4B6A-98CA-6EBDEED8EDBC@comcast.net>
	<CAGxFJbR=dPQt2yFJm_XBPHi97OzJ7Pxq=GOrdPo_U5s0yh3duw@mail.gmail.com>
	<CAOHXzyXObvimRPfNA1ngEFxFMG2KD_SudFkua1MCKka_JNrL_g@mail.gmail.com>
	<CAGxFJbTK7s5MN8DrjtNj-tRZCTO-mO39OQLuXEoYFztcTsAMRw@mail.gmail.com>
Message-ID: <CAOHXzyUaNcPWaE8JTLZ+PWWv_0kT9P3qzY0uhcQH=Uy6VoPMsA@mail.gmail.com>

Thanks to everybody for trying to help me with this, I think there are
a few workable options here.  However, I think the most efficient
option that I've found was to avoid the join/aggregate in R
altogether.  I've joined them at the database level to accomplish the
same thing.  This may not be a helpful solution for everybody, but
it's an option to be aware of for those seeking efficiency perhaps.

In oracle this would be something like:

select
  groups.rangeStart,
  groups.rangeEnd,
  avg(observations.values)
from groups, observations
where observations.date between groups.rangeStart and groups.rangeEnd
group by rangeStart, rangeEnd

On Wed, Feb 10, 2016 at 4:32 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Oh, you didn't say the intervals could overlap!
>
> If Bill D's suggestions don't suffice, try the following:
>
> (again assuming all dates are in a form that allow comparison
> operations, e.g. via as.POSIX**)
>
> Assume you have g intervals with start dates "starts" and end dates
> "ends" and that you have d "dates".
>
> Then:
>
> wh <- outer(starts, dates,,"<=") & outer(ends,dates,">") ## arrange
> "<" and ">"   as you wish
>
> ## (?outer for details.)
>
> is a d x g matrix with each column's TRUE values giving the rows =
> dates contained in that column's interval.
>
> Then if "somedat" is a data vector of length d
>
> apply(wh, 2, function(x) mean(somedat[x]) )
>
> will give you the means for each interval of all somedat values whose
> dates  fell into that interval.
> This last step can be repeated for as many somedats as you like.
>
> Note that this is still a loop (via apply), however, so it may not
> satisfy your efficiency needs.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 10, 2016 at 2:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
>> Thanks David, Bert,
>>
>> From what I'm reading on ?findInterval, It may not be workable because
>> of overlapping date ranges.  findInterval seems to take a series of
>> bin breakpoints as its argument. I'm currently exploring data.table
>> documentation and will keep thinking about this.
>>
>> Just on David's point, the extension of this with "groups" would look
>> as below.  I just don't want to complicate it before I've solved the
>> simplest issue.
>>
>> set.seed(345)
>> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
>> by="DSTday")
>> observations <- data.frame(date=date.range, a=runif(152,1,100),
>> b=runif(152,1,100), c=runif(152,1,100) )
>> groups <- data.frame(start=sample(date.range[1:50], 20), end =
>> sample(date.range[51:152], 20), group=sample(letters[1:3], 20,
>> replace=TRUE), average = NA)
>>
>> #Potential Solutions (too inefficient)
>> for(i in 1:NROW(groups)){
>>  groups[i, "average"] <- mean(observations[observations$date >=
>> groups[i, "start"] & observations$date <=groups[i, "end"],
>> as.character(groups[i, "group"])])
>> }
>>
>> Thanks again,
>> Peter
>>
>> On Wed, Feb 10, 2016 at 2:26 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> A strategy:
>>>
>>>  1. Convert your dates and intervals to numerics that give the days
>>> since a time origin. See as.POSIXlt (or ** ct for details and an
>>> example that does this). Should be fast...
>>>
>>> 2. Use the findInterval() function to get the interval into which each
>>> date falls. This **is** "vectorized" and should be fairly fast.
>>>
>>> 3. Use the ave() function using the intervals as your factor that
>>> splits your data column(s) for which you wish to compute statistics.
>>> The basic statistics functions like mean, sum, etc. **are**
>>> vectorized, so this should be fast.
>>>
>>> As David said, the *apply functions will probably not be much, if at
>>> all, faster than an explicit for() loop. Most of the time will be
>>> spent spent comparing the dates to the intervals to find in which each
>>> falls, and findInterval is a fast way to do this.
>>>
>>> ... I think.
>>>
>>> If you try this, let me know (perhaps privately) how/if it works.
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, Feb 10, 2016 at 1:08 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>> On Feb 10, 2016, at 12:18 PM, Peter Lomas <peter.br.lomas at gmail.com> wrote:
>>>>>
>>>>> Hello, I have a dataframe with a date range, and another dataframe
>>>>> with observations by date.  For each date range, I'd like to average
>>>>> the values within that range from the other dataframe.  I've provided
>>>>> code below doing what I would like, but using a for loop is too
>>>>> inefficient for my actual case (takes about an hour).  So I'm looking
>>>>> for a way to vectorize.
>>>>>
>>>>>
>>>>> set.seed(345)
>>>>> date.range <- seq(as.POSIXct("2015-01-01"),as.POSIXct("2015-06-01"),
>>>>> by="DSTday")
>>>>> observations <- data.frame(date=date.range, values=runif(152,1,100) )
>>>>> groups <- data.frame(start=sample(date.range[1:50], 20), end =
>>>>> sample(date.range[51:152], 20), average = NA)
>>>>>
>>>>> #Potential Solution (too inefficient)
>>>>>
>>>>> for(i in 1:NROW(groups)){
>>>>> groups[i, "average"] <- mean(observations[observations$date >=
>>>>> groups[i, "start"] & observations$date <=groups[i, "end"], "values"])
>>>>> }
>>>>>
>>>> The 'average' column could be added to groups with this value:
>>>>
>>>> mapply( function(start,end){ mean(observations[['values']][
>>>>                      observations$date >= start & observations$date <=end])},
>>>>         groups$start, groups$end)
>>>>
>>>>  [1] 50.96831 49.42286 47.27240 49.07534 47.66570 49.30977 48.47503 47.74036
>>>>  [9] 46.02527 58.76492 48.86580 49.90655 45.79705 48.84071 39.53846 46.44601
>>>> [17] 47.06631 47.74199 49.16980 46.85131
>>>>
>>>> I don't really think this is fully "vectorized" in the usual R-meaning of the word. And I don't expect it to be any faster than the for-loop. Perhaps some of the range functions in the data.table package could accelerate your processing. If you don't get any volunteers in this list, you could repost the question on StackOverflow after a suitable pause that avoids accusations of cross-posting. SO has several skilled users of data.table functions.
>>>>
>>>>> As an extension to this, there will end up being multiple value
>>>>> columns, and each range will also identify which column to average.  I
>>>>> think if I can figure out the first problem I can try to extend it
>>>>> myself.
>>>>
>>>> Sorry, I didn't understand what was being described in that paragraph.
>>>>
>>>> --
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Feb 11 20:06:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Feb 2016 11:06:12 -0800
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
Message-ID: <A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>


> On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> 
> I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> 
> Because the variance is small, it results in density like: 7.978846e+94
> 
> Is there any good suggestion for this?

So what's the difficulty? It's rather like the Dirac function.

> integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
1 with absolute error < 7.4e-05


-- 
David.

> 
> Thanks so much!
> 
> 
> On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> 
>> Wow, thank you, that was very clear.  Let me give it some more runs and
>> investigate this.
>> 
>> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>> 
>>> Most of the mass of that distribution is within 3e-100 of 2.
>>> You have to be pretty lucky to have a point in sequence
>>> land there.  (You will get at most one point there because
>>> the difference between 2 and its nearest neightbors is on
>>> the order of 1e-16.)
>>> 
>>> seq(-2,4,len=101), as used by default in curve, does include 2
>>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
>>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the bump.
>>> The same principal holds for numerical integration.
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
>>> 
>>>> Dear R,
>>>> 
>>>> I am graphing the following normal density curve.  Why does it look so
>>>> different?
>>>> 
>>>> # the curves
>>>> x <- seq(-2, 4, by=0.00001)
>>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
>>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
>>>> answer
>>>> 
>>>> Why the second curve is flat?  I just changed it from -4 to -3.  There is
>>>> no density in that region.
>>>> 
>>>> 
>>>> Also, I am doing numerical integration.  Why are they so different?
>>>> 
>>>>> x <- seq(-2, 4, by=0.00001)
>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>>>> [1] 7.978846e+94
>>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>>>> [1] 0
>>>> 
>>>> What is going here?  What a I doing wrong?
>>>> 
>>>> Thanks so much!
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tmrsg11 at gmail.com  Thu Feb 11 20:30:20 2016
From: tmrsg11 at gmail.com (C W)
Date: Thu, 11 Feb 2016 14:30:20 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
Message-ID: <CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>

Hi David,

My real function is actually a multivariate normal, the simple toy 1-d
normal won't work.

But, you gave me an idea about restricting the bounds, and focus
integrating on that.  I will get back to you if I need any further
assistance.

Thank you so much!

On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> >
> > I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> >
> > Because the variance is small, it results in density like: 7.978846e+94
> >
> > Is there any good suggestion for this?
>
> So what's the difficulty? It's rather like the Dirac function.
>
> > integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
> 1 with absolute error < 7.4e-05
>
>
> --
> David.
>
> >
> > Thanks so much!
> >
> >
> > On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> >
> >> Wow, thank you, that was very clear.  Let me give it some more runs and
> >> investigate this.
> >>
> >> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com>
> >> wrote:
> >>
> >>> Most of the mass of that distribution is within 3e-100 of 2.
> >>> You have to be pretty lucky to have a point in sequence
> >>> land there.  (You will get at most one point there because
> >>> the difference between 2 and its nearest neightbors is on
> >>> the order of 1e-16.)
> >>>
> >>> seq(-2,4,len=101), as used by default in curve, does include 2
> >>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> >>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the
> bump.
> >>> The same principal holds for numerical integration.
> >>>
> >>>
> >>> Bill Dunlap
> >>> TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
> >>>
> >>>> Dear R,
> >>>>
> >>>> I am graphing the following normal density curve.  Why does it look so
> >>>> different?
> >>>>
> >>>> # the curves
> >>>> x <- seq(-2, 4, by=0.00001)
> >>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> >>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
> >>>> answer
> >>>>
> >>>> Why the second curve is flat?  I just changed it from -4 to -3.
> There is
> >>>> no density in that region.
> >>>>
> >>>>
> >>>> Also, I am doing numerical integration.  Why are they so different?
> >>>>
> >>>>> x <- seq(-2, 4, by=0.00001)
> >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>> [1] 7.978846e+94
> >>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>> [1] 0
> >>>>
> >>>> What is going here?  What a I doing wrong?
> >>>>
> >>>> Thanks so much!
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Feb 11 21:32:22 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Feb 2016 12:32:22 -0800
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
Message-ID: <657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>


> On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
> 
> Hi David,
> 
> My real function is actually a multivariate normal, the simple toy 1-d normal won't work.
> 
> But, you gave me an idea about restricting the bounds, and focus integrating on that.  I will get back to you if I need any further assistance.

You'll probably need to restrict your bounds even more severely than I did in the 1-d case (using 10 SD's on either side of the mean) . You might need adequate representation of points near the center of your hyper-rectangles. At least that's my armchair notion since I expect the densities tail off rapidly in the corners. You can shoehorn multivariate integration around the `integrate` function but it's messy and inefficient. There are other packages that would be better choices. There's an entire section on numerical differentiation and integration in CRAN Task View: Numerical Mathematics.

-- 
David.


> 
> Thank you so much!
> 
> On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> >
> > I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> >
> > Because the variance is small, it results in density like: 7.978846e+94
> >
> > Is there any good suggestion for this?
> 
> So what's the difficulty? It's rather like the Dirac function.
> 
> > integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
> 1 with absolute error < 7.4e-05
> 
> 
> --
> David.
> 
> >
> > Thanks so much!
> >
> >
> > On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> >
> >> Wow, thank you, that was very clear.  Let me give it some more runs and
> >> investigate this.
> >>
> >> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com>
> >> wrote:
> >>
> >>> Most of the mass of that distribution is within 3e-100 of 2.
> >>> You have to be pretty lucky to have a point in sequence
> >>> land there.  (You will get at most one point there because
> >>> the difference between 2 and its nearest neightbors is on
> >>> the order of 1e-16.)
> >>>
> >>> seq(-2,4,len=101), as used by default in curve, does include 2
> >>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> >>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the bump.
> >>> The same principal holds for numerical integration.
> >>>
> >>>
> >>> Bill Dunlap
> >>> TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
> >>>
> >>>> Dear R,
> >>>>
> >>>> I am graphing the following normal density curve.  Why does it look so
> >>>> different?
> >>>>
> >>>> # the curves
> >>>> x <- seq(-2, 4, by=0.00001)
> >>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> >>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
> >>>> answer
> >>>>
> >>>> Why the second curve is flat?  I just changed it from -4 to -3.  There is
> >>>> no density in that region.
> >>>>
> >>>>
> >>>> Also, I am doing numerical integration.  Why are they so different?
> >>>>
> >>>>> x <- seq(-2, 4, by=0.00001)
> >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>> [1] 7.978846e+94
> >>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>> [1] 0
> >>>>
> >>>> What is going here?  What a I doing wrong?
> >>>>
> >>>> Thanks so much!
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From valkremk at gmail.com  Thu Feb 11 23:52:03 2016
From: valkremk at gmail.com (Val)
Date: Thu, 11 Feb 2016 16:52:03 -0600
Subject: [R] Pairing and
Message-ID: <CAJOiR6Yeg+=-LaO=Amj4USAteFmLH9=p30JPJNAWsmEiAGS7mg@mail.gmail.com>

Hi  all,

I have SNP data set: the first column is the ID and the the
subsequent pair of columns are the alleles for each
SNP1, SNP2 and So on. Each SNP has two columns.  Based on the alleles
I want make phenotype

if the alleles  are 1 1        then  genotype is 0
                  2 2        then  genotype is 1
and if it is          1 2 or 2 1 then  genotyep is 3

This is a sample data set but the actual has 13,000 SNP(26,000columns)


Geno data
AB95 1 1 2 2 2 2 2 2 1 1
AB82 2 2 2 2 2 2 2 2 2 2
AB95 2 1 2 2 2 2 2 2 1 1
AB59 1 1 2 2 1 2 1 2 1 2
AB32 2 1 2 2 2 2 2 2 1 2
AB46 2 1 2 2 1 2 1 1 2 2
AB61 1 1 2 2 1 2 1 2 1 2
AB32 2 2 1 2 2 2 2 2 1 2
AB35 2 2 1 2 2 2 2 2 2 2
AB43 2 2 1 2 2 2 2 2 2 2

Desired output
AB95  0   1   1   1   0
AB82  1   1   1   1   1
AB95  3   1   1   1   0
AB59  0   1   3   3   3
AB32  3   1   1   1   3
AB46  3   1   3   0   1
AB61  0   1   3   3   3
AB32  1   3   1   1   3
AB35  1   3   1   1   1
AB43  1   3   1   1   1

I would appreciate if you help me out here.
Thank you in advance

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Fri Feb 12 00:58:34 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Thu, 11 Feb 2016 15:58:34 -0800
Subject: [R] Pairing and
In-Reply-To: <CAJOiR6Yeg+=-LaO=Amj4USAteFmLH9=p30JPJNAWsmEiAGS7mg@mail.gmail.com>
References: <CAJOiR6Yeg+=-LaO=Amj4USAteFmLH9=p30JPJNAWsmEiAGS7mg@mail.gmail.com>
Message-ID: <CAJeYpE8v_7f4EH_SCatPAQXKH4vuEoe82nCGX6-bvjQ3kT0nuw@mail.gmail.com>

Hi Val,
There are probably more elegant ways to do it, but the following is fairly
transparent:

# input data arranged as an array:
indat<-cbind(c(1,2,2,1),c(1,2,1,1),c(2,2,2,2),c(2,2,2,2),c(2,2,2,1),c(2,2,2,2),c(2,2,2,1),c(2,2,2,2),c(1,2,1,1),c(1,2,1,2))
indat

outdat<-array(dim=c(dim(indat)[1],dim(indat)[2]/2)) # output data has same
number of rows and half as many columns
for (i in 1:dim(outdat)[2]){
  outdat[,i]<-apply(indat[,(i-1)*2+1:2],F=sum,M=1) # each column of output
= sum(two columns of input)
}
outdat[outdat==2]<-0 # allele pairs that sum to 2 are genotype 0
outdat[outdat==4]<-1 # allele pairs that sum to 4 are genotype 1
# allele pairs that sum to 3 are genotype 3, so no need to change anything
with them
outdat

# faster but a little more difficult to see what is going on:
outdat<-indat %*%
array(c(rep(c(rep(1,2),rep(0,dim(indat)[2])),dim(indat)[2]/2),1,1),dim=c(dim(indat)[2],dim(indat)[2]/2))
outdat[outdat==2]<-0
outdat[outdat==4]<-1
outdat

-Dan



On Thu, Feb 11, 2016 at 2:52 PM, Val <valkremk at gmail.com> wrote:

> Hi  all,
>
> I have SNP data set: the first column is the ID and the the
> subsequent pair of columns are the alleles for each
> SNP1, SNP2 and So on. Each SNP has two columns.  Based on the alleles
> I want make phenotype
>
> if the alleles  are 1 1        then  genotype is 0
>                   2 2        then  genotype is 1
> and if it is          1 2 or 2 1 then  genotyep is 3
>
> This is a sample data set but the actual has 13,000 SNP(26,000columns)
>
>
> Geno data
> AB95 1 1 2 2 2 2 2 2 1 1
> AB82 2 2 2 2 2 2 2 2 2 2
> AB95 2 1 2 2 2 2 2 2 1 1
> AB59 1 1 2 2 1 2 1 2 1 2
> AB32 2 1 2 2 2 2 2 2 1 2
> AB46 2 1 2 2 1 2 1 1 2 2
> AB61 1 1 2 2 1 2 1 2 1 2
> AB32 2 2 1 2 2 2 2 2 1 2
> AB35 2 2 1 2 2 2 2 2 2 2
> AB43 2 2 1 2 2 2 2 2 2 2
>
> Desired output
> AB95  0   1   1   1   0
> AB82  1   1   1   1   1
> AB95  3   1   1   1   0
> AB59  0   1   3   3   3
> AB32  3   1   1   1   3
> AB46  3   1   3   0   1
> AB61  0   1   3   3   3
> AB32  1   3   1   1   3
> AB35  1   3   1   1   1
> AB43  1   3   1   1   1
>
> I would appreciate if you help me out here.
> Thank you in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Fri Feb 12 01:05:39 2016
From: valkremk at gmail.com (Val)
Date: Thu, 11 Feb 2016 18:05:39 -0600
Subject: [R] Pairing and
In-Reply-To: <CAJeYpE8v_7f4EH_SCatPAQXKH4vuEoe82nCGX6-bvjQ3kT0nuw@mail.gmail.com>
References: <CAJOiR6Yeg+=-LaO=Amj4USAteFmLH9=p30JPJNAWsmEiAGS7mg@mail.gmail.com>
	<CAJeYpE8v_7f4EH_SCatPAQXKH4vuEoe82nCGX6-bvjQ3kT0nuw@mail.gmail.com>
Message-ID: <CAJOiR6bfGK5UAx3V2AY8iMOM5LmOGGWQH4Oj_xNZGxR_tyS-SA@mail.gmail.com>

Thank you very much Dan!

I want go with the  second one, because the data very huge (>25,000
columns) and > 3,000 row.
The data is loaded  as "testdat"

Can you help  me to fit in the following code please,


# faster but a little more difficult to see what is going on:
outdat<-indat %*%
array(c(rep(c(rep(1,2),rep(0,dim(indat)[2])),dim(indat)[2]/2),1,1),dim=c(dim(indat)[2],dim(indat)[2]/2))
outdat[outdat==2]<-0
outdat[outdat==4]<-1
outdat


Thank you!



On Thu, Feb 11, 2016 at 5:58 PM, Dalthorp, Daniel <ddalthorp at usgs.gov>
wrote:

> Hi Val,
> There are probably more elegant ways to do it, but the following is fairly
> transparent:
>
> # input data arranged as an array:
>
> indat<-cbind(c(1,2,2,1),c(1,2,1,1),c(2,2,2,2),c(2,2,2,2),c(2,2,2,1),c(2,2,2,2),c(2,2,2,1),c(2,2,2,2),c(1,2,1,1),c(1,2,1,2))
> indat
>
> outdat<-array(dim=c(dim(indat)[1],dim(indat)[2]/2)) # output data has same
> number of rows and half as many columns
> for (i in 1:dim(outdat)[2]){
>   outdat[,i]<-apply(indat[,(i-1)*2+1:2],F=sum,M=1) # each column of output
> = sum(two columns of input)
> }
> outdat[outdat==2]<-0 # allele pairs that sum to 2 are genotype 0
> outdat[outdat==4]<-1 # allele pairs that sum to 4 are genotype 1
> # allele pairs that sum to 3 are genotype 3, so no need to change anything
> with them
> outdat
>
> # faster but a little more difficult to see what is going on:
> outdat<-indat %*%
> array(c(rep(c(rep(1,2),rep(0,dim(indat)[2])),dim(indat)[2]/2),1,1),dim=c(dim(indat)[2],dim(indat)[2]/2))
> outdat[outdat==2]<-0
> outdat[outdat==4]<-1
> outdat
>
> -Dan
>
>
>
> On Thu, Feb 11, 2016 at 2:52 PM, Val <valkremk at gmail.com> wrote:
>
>> Hi  all,
>>
>> I have SNP data set: the first column is the ID and the the
>> subsequent pair of columns are the alleles for each
>> SNP1, SNP2 and So on. Each SNP has two columns.  Based on the alleles
>> I want make phenotype
>>
>> if the alleles  are 1 1        then  genotype is 0
>>                   2 2        then  genotype is 1
>> and if it is          1 2 or 2 1 then  genotyep is 3
>>
>> This is a sample data set but the actual has 13,000 SNP(26,000columns)
>>
>>
>> Geno data
>> AB95 1 1 2 2 2 2 2 2 1 1
>> AB82 2 2 2 2 2 2 2 2 2 2
>> AB95 2 1 2 2 2 2 2 2 1 1
>> AB59 1 1 2 2 1 2 1 2 1 2
>> AB32 2 1 2 2 2 2 2 2 1 2
>> AB46 2 1 2 2 1 2 1 1 2 2
>> AB61 1 1 2 2 1 2 1 2 1 2
>> AB32 2 2 1 2 2 2 2 2 1 2
>> AB35 2 2 1 2 2 2 2 2 2 2
>> AB43 2 2 1 2 2 2 2 2 2 2
>>
>> Desired output
>> AB95  0   1   1   1   0
>> AB82  1   1   1   1   1
>> AB95  3   1   1   1   0
>> AB59  0   1   3   3   3
>> AB32  3   1   1   1   3
>> AB46  3   1   3   0   1
>> AB61  0   1   3   3   3
>> AB32  1   3   1   1   3
>> AB35  1   3   1   1   1
>> AB43  1   3   1   1   1
>>
>> I would appreciate if you help me out here.
>> Thank you in advance
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center
> Forest Sciences Lab, Rm 189
> 3200 SW Jefferson Way
> Corvallis, OR 97331
> ph: 541-750-0953
> ddalthorp at usgs.gov
>
>

	[[alternative HTML version deleted]]


From mhrashidbau at yahoo.com  Fri Feb 12 04:41:22 2016
From: mhrashidbau at yahoo.com (Harun Rashid)
Date: Fri, 12 Feb 2016 12:41:22 +0900
Subject: [R] Putting subscript in facet_grid label of ggplot
Message-ID: <56BD5462.8050305@yahoo.com>

Hello,
I am having trouble with putting subscript in facet_grid label. Here is 
an example of the work I have been trying to do.

 > 
df<-data.frame(species=gl(2,10,labels=c('sp1','sp2')),age=sample(3:12,40,replace=T),variable=gl(2,20,labels=c('N1P1 
var','N2P1 var')),value=rnorm(40))

 > 
test.plot<-ggplot(data=df,aes(x=age,y=value))+geom_point()+facet_grid(variable~species)

Now I want to make by vertical facet label as 'N[1]P[1] var' and so on, 
where the numbers in the squared bracket means subscript.
Thanks in advance for your  help.
Regards,
Harun
-- 

<mailto:mhrashidbau at yahoo.com>
<mailto:mhrashidbau at yahoo.com>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Feb 12 05:52:48 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 12 Feb 2016 17:52:48 +1300
Subject: [R] Separating point symbols and line types in a legend.
Message-ID: <56BD6520.20909@auckland.ac.nz>


I would like to have a legend given in the manner

legend("topleft",pch=c(20,8,1),lty=1:3,bty="n",
        legend=c("clyde","irving","melvin"))

but with the point symbol *NOT* being superimposed on the line segments 
that are plotted.

I saw that I can specify "merge=FALSE" in the call to legend() but this 
gives results like unto

    ----* irving

with the plot symbol being immediately juxtaposed to the plotted line 
segment.  I would like a space between them, like so:

    ---- * irving

(See the difference?)

I can see no arguments to legend that allow me to effect this.  I can 
adjust positioning of the legend text, but not of the plotted point 
character or line segment.  Is there any way to effect the desired 
result?  Or is there a "simple" adjustment that one could make to the 
code for legend() that would allow me to accomplish what I want?

Ta.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Fri Feb 12 08:08:07 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Feb 2016 23:08:07 -0800
Subject: [R] Putting subscript in facet_grid label of ggplot
In-Reply-To: <56BD5462.8050305@yahoo.com>
References: <56BD5462.8050305@yahoo.com>
Message-ID: <1C1A67EA-FA48-448D-8A1C-BFDCD7284431@comcast.net>


> On Feb 11, 2016, at 7:41 PM, Harun Rashid via R-help <r-help at r-project.org> wrote:
> 
> Hello,
> I am having trouble with putting subscript in facet_grid label. Here is 
> an example of the work I have been trying to do.
> 
>> 
> df<-data.frame(species=gl(2,10,labels=c('sp1','sp2')),age=sample(3:12,40,replace=T),variable=gl(2,20,labels=c('N1P1 
> var','N2P1 var')),value=rnorm(40))
> 
>> 
> test.plot<-ggplot(data=df,aes(x=age,y=value))+geom_point()+facet_grid(variable~species)

The default evaluation of labels in facet_grid is just as character. To get an expression (successfully) parsed you need to change the `labeller` argument and you need a valid expression (which at the moment you do not provide.)

See ?plotmath and ?facet_grid for worked examples:

 Try this instead:

df<-data.frame(species=gl(2,10,
   labels=c('sp1','sp2')),
   age=sample(3:12,40,replace=T),
   variable=gl(2,20,labels=c('N[1]*P[1]~var','N[2]*P[1]~var')), 
   value=rnorm(40) )

test.plot <-ggplot(data=df,aes(x=age,y=value)) + geom_point() + facet_grid(variable~species, labeller=label_parsed)

test.plot

-- 
David.

> 
> Now I want to make by vertical facet label as 'N[1]P[1] var' and so on, 
> where the numbers in the squared bracket means subscript.
> Thanks in advance for your  help.
> Regards,
> Harun
> -- 
> 
> <mailto:mhrashidbau at yahoo.com>
> <mailto:mhrashidbau at yahoo.com>
> 
> 	[[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From jl.iccp at gmail.com  Fri Feb 12 12:02:45 2016
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Fri, 12 Feb 2016 12:02:45 +0100
Subject: [R] MonteCarlo sampling on profile log likelihood - package
	extRemes
Message-ID: <CAAMkPW8CwJHP4tAqt=KpzRkvNKiG9_DHya9HEBBqzjVjYH=RGw@mail.gmail.com>

>
> ??
> Date: Wed, 10 Feb 2016 15:19:21 +0000
> From: Lila Collet <collet.lila at gmail.com>
> To: r-help at R-project.org
> Subject: [R] MonteCarlo sampling on profile log likelihood - package
>         extRemes
>
>
> Hi
>
>
> I am using the package extRemes to assess 100-year return period
> runoffs with the GEV and GP distribution functions and the associated
> 95% confidence intervals.
>
> I use the MLE method for that.
>
>
> Now I would like to sample a few thousands values of return levels on
> the profile likelihood between the 95% confidence interval boundaries.
>
> I saw that the function ?profliker? allows to sample log-likelihood
> values along the profile likelihood.
>
> Is there any way to sample return levels or get the return levels
> corresponding to these log-likelihood values?
>
>
> Thanks for any help.
>
> Kind regards,
>
> LCollet
>
>
?A string with the subject "Generate random numbers under constrain" saved
in the r-help Archive (website: https://stat.ethz.ch/pipermail/r-help/)
around Thu, 27 Nov 2014 19:20:41 +0100 might help you.

-- 
Jue Lin-Ye?

	[[alternative HTML version deleted]]


From federico.calboli at helsinki.fi  Fri Feb 12 16:13:02 2016
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Fri, 12 Feb 2016 17:13:02 +0200
Subject: [R] why is 9 after 10?
Message-ID: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>

Hi All,

I have some data, one of the columns is a bunch of numbers from 6 to 41.

table(my.data[,2])

returns

  10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35   36   37 
1761 1782 1897 1749 1907 1797 1734 1810 1913 1988 1914 1822 1951 1973 1951 1947 2067 1967 1812 2119 1999 2086 2133 2081 2165 2365 2330 2340 
  38   39   40   41    6    7    8    9 
2681 2905 3399 3941 1648 1690 1727 1668 

whereas the reasonable expectation is that the numbers from 6 to 9 would come before 10 to 41.

How do I sort this incredibly silly behaviour so that my table follows a reasonable expectation that 9 comes before 10 (and so on and so forth)?

BW

F

--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From jfox at mcmaster.ca  Fri Feb 12 16:22:21 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 12 Feb 2016 15:22:21 +0000
Subject: [R] why is 9 after 10?
In-Reply-To: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>
References: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F56FF2@FHSDB2D11-2.csu.mcmaster.ca>

Dear Federico,

Might my.data[, 2] contain character data, which therefore would be sorted in this manner? For example:

> x <- sample(6:37, 1000, replace=TRUE)
> table(x)
x
 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 
29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35 39 31 40 35 29 
> y <- as.character(x)
> table(y)
y
10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  6  7  8  9 
41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35 39 31 40 35 29 29 30 35 29

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Federico
> Calboli
> Sent: February 12, 2016 10:13 AM
> To: R Help <r-help at r-project.org>
> Subject: [R] why is 9 after 10?
> 
> Hi All,
> 
> I have some data, one of the columns is a bunch of numbers from 6 to 41.
> 
> table(my.data[,2])
> 
> returns
> 
>   10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29
> 30   31   32   33   34   35   36   37
> 1761 1782 1897 1749 1907 1797 1734 1810 1913 1988 1914 1822 1951 1973 1951
> 1947 2067 1967 1812 2119 1999 2086 2133 2081 2165 2365 2330 2340
>   38   39   40   41    6    7    8    9
> 2681 2905 3399 3941 1648 1690 1727 1668
> 
> whereas the reasonable expectation is that the numbers from 6 to 9 would
> come before 10 to 41.
> 
> How do I sort this incredibly silly behaviour so that my table follows a
> reasonable expectation that 9 comes before 10 (and so on and so forth)?
> 
> BW
> 
> F
> 
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
> 
> federico.calboli at helsinki.fi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From federico.calboli at helsinki.fi  Fri Feb 12 16:26:42 2016
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Fri, 12 Feb 2016 17:26:42 +0200
Subject: [R] why is 9 after 10?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F56FF2@FHSDB2D11-2.csu.mcmaster.ca>
References: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>
	<ACD1644AA6C67E4FBD0C350625508EC810F56FF2@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <FCC1FD59-0308-46F6-88D9-7DE584E07C30@helsinki.fi>

Dear John,

that is fortunatey not the case, I just managed to figure out that the problem was that in the data reshaping pipeline the numeric column was transformed into a factor.

Many thanks for your time.

BW

F



> On 12 Feb 2016, at 17:22, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Federico,
> 
> Might my.data[, 2] contain character data, which therefore would be sorted in this manner? For example:
> 
>> x <- sample(6:37, 1000, replace=TRUE)
>> table(x)
> x
> 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 
> 29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35 39 31 40 35 29 
>> y <- as.character(x)
>> table(y)
> y
> 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  6  7  8  9 
> 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35 39 31 40 35 29 29 30 35 29
> 
> I hope this helps,
> John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Federico
>> Calboli
>> Sent: February 12, 2016 10:13 AM
>> To: R Help <r-help at r-project.org>
>> Subject: [R] why is 9 after 10?
>> 
>> Hi All,
>> 
>> I have some data, one of the columns is a bunch of numbers from 6 to 41.
>> 
>> table(my.data[,2])
>> 
>> returns
>> 
>>  10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29
>> 30   31   32   33   34   35   36   37
>> 1761 1782 1897 1749 1907 1797 1734 1810 1913 1988 1914 1822 1951 1973 1951
>> 1947 2067 1967 1812 2119 1999 2086 2133 2081 2165 2365 2330 2340
>>  38   39   40   41    6    7    8    9
>> 2681 2905 3399 3941 1648 1690 1727 1668
>> 
>> whereas the reasonable expectation is that the numbers from 6 to 9 would
>> come before 10 to 41.
>> 
>> How do I sort this incredibly silly behaviour so that my table follows a
>> reasonable expectation that 9 comes before 10 (and so on and so forth)?
>> 
>> BW
>> 
>> F
>> 
>> --
>> Federico Calboli
>> Ecological Genetics Research Unit
>> Department of Biosciences
>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>> FIN-00014 University of Helsinki
>> Finland
>> 
>> federico.calboli at helsinki.fi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.

--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From tmrsg11 at gmail.com  Fri Feb 12 16:36:47 2016
From: tmrsg11 at gmail.com (C W)
Date: Fri, 12 Feb 2016 10:36:47 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
Message-ID: <CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>

Hi David,

This is the Gaussian looking distribution I am trying to integrate.
https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing

Notice the unnormalized density goes up as high as 2.5*101^191.

I tried to create small intervals like
> seq(0.5, 1.3, by = 10^(-8))

but that doesn't seem to be good enough, as we know, it should integrate to
1.

On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
> >
> > Hi David,
> >
> > My real function is actually a multivariate normal, the simple toy 1-d
> normal won't work.
> >
> > But, you gave me an idea about restricting the bounds, and focus
> integrating on that.  I will get back to you if I need any further
> assistance.
>
> You'll probably need to restrict your bounds even more severely than I did
> in the 1-d case (using 10 SD's on either side of the mean) . You might need
> adequate representation of points near the center of your hyper-rectangles.
> At least that's my armchair notion since I expect the densities tail off
> rapidly in the corners. You can shoehorn multivariate integration around
> the `integrate` function but it's messy and inefficient. There are other
> packages that would be better choices. There's an entire section on
> numerical differentiation and integration in CRAN Task View: Numerical
> Mathematics.
>
> --
> David.
>
>
> >
> > Thank you so much!
> >
> > On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> > >
> > > I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> > >
> > > Because the variance is small, it results in density like: 7.978846e+94
> > >
> > > Is there any good suggestion for this?
> >
> > So what's the difficulty? It's rather like the Dirac function.
> >
> > > integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
> > 1 with absolute error < 7.4e-05
> >
> >
> > --
> > David.
> >
> > >
> > > Thanks so much!
> > >
> > >
> > > On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> > >
> > >> Wow, thank you, that was very clear.  Let me give it some more runs
> and
> > >> investigate this.
> > >>
> > >> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com>
> > >> wrote:
> > >>
> > >>> Most of the mass of that distribution is within 3e-100 of 2.
> > >>> You have to be pretty lucky to have a point in sequence
> > >>> land there.  (You will get at most one point there because
> > >>> the difference between 2 and its nearest neightbors is on
> > >>> the order of 1e-16.)
> > >>>
> > >>> seq(-2,4,len=101), as used by default in curve, does include 2
> > >>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> > >>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the
> bump.
> > >>> The same principal holds for numerical integration.
> > >>>
> > >>>
> > >>> Bill Dunlap
> > >>> TIBCO Software
> > >>> wdunlap tibco.com
> > >>>
> > >>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
> > >>>
> > >>>> Dear R,
> > >>>>
> > >>>> I am graphing the following normal density curve.  Why does it look
> so
> > >>>> different?
> > >>>>
> > >>>> # the curves
> > >>>> x <- seq(-2, 4, by=0.00001)
> > >>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> > >>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
> > >>>> answer
> > >>>>
> > >>>> Why the second curve is flat?  I just changed it from -4 to -3.
> There is
> > >>>> no density in that region.
> > >>>>
> > >>>>
> > >>>> Also, I am doing numerical integration.  Why are they so different?
> > >>>>
> > >>>>> x <- seq(-2, 4, by=0.00001)
> > >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> > >>>> [1] 7.978846e+94
> > >>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> > >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> > >>>> [1] 0
> > >>>>
> > >>>> What is going here?  What a I doing wrong?
> > >>>>
> > >>>> Thanks so much!
> > >>>>
> > >>>>        [[alternative HTML version deleted]]
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide
> > >>>> http://www.R-project.org/posting-guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>>
> > >>>
> > >>>
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Fri Feb 12 16:41:08 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 12 Feb 2016 15:41:08 +0000
Subject: [R] why is 9 after 10?
In-Reply-To: <FCC1FD59-0308-46F6-88D9-7DE584E07C30@helsinki.fi>
References: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>
	<ACD1644AA6C67E4FBD0C350625508EC810F56FF2@FHSDB2D11-2.csu.mcmaster.ca>
	<FCC1FD59-0308-46F6-88D9-7DE584E07C30@helsinki.fi>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F57021@FHSDB2D11-2.csu.mcmaster.ca>

Dear Federico,

> -----Original Message-----
> From: Federico Calboli [mailto:federico.calboli at helsinki.fi]
> Sent: February 12, 2016 10:27 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: R Help <r-help at r-project.org>
> Subject: Re: [R] why is 9 after 10?
> 
> Dear John,
> 
> that is fortunatey not the case, I just managed to figure out that the problem
> was that in the data reshaping pipeline the numeric column was transformed
> into a factor.

But that shouldn't have this effect, I think:

> z <- as.factor(x)
> table(z)
z
 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 
29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35 39 31 40 35 29

> levels(z)
 [1] "6"  "7"  "8"  "9"  "10" "11" "12" "13" "14" "15" "16" "17" "18" "19" "20" "21" "22" "23" "24" "25" "26" "27" "28" "29" "30" "31"
[27] "32" "33" "34" "35" "36" "37"

Best,
 John

> 
> Many thanks for your time.
> 
> BW
> 
> F
> 
> 
> 
> > On 12 Feb 2016, at 17:22, Fox, John <jfox at mcmaster.ca> wrote:
> >
> > Dear Federico,
> >
> > Might my.data[, 2] contain character data, which therefore would be
> sorted in this manner? For example:
> >
> >> x <- sample(6:37, 1000, replace=TRUE)
> >> table(x)
> > x
> > 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
> > 30 31 32 33 34 35 36 37
> > 29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31
> > 34 23 32 35 39 31 40 35 29
> >> y <- as.character(x)
> >> table(y)
> > y
> > 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
> > 33 34 35 36 37  6  7  8  9
> > 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35
> > 39 31 40 35 29 29 30 35 29
> >
> > I hope this helps,
> > John
> >
> > -----------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Federico Calboli
> >> Sent: February 12, 2016 10:13 AM
> >> To: R Help <r-help at r-project.org>
> >> Subject: [R] why is 9 after 10?
> >>
> >> Hi All,
> >>
> >> I have some data, one of the columns is a bunch of numbers from 6 to 41.
> >>
> >> table(my.data[,2])
> >>
> >> returns
> >>
> >>  10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28
> 29
> >> 30   31   32   33   34   35   36   37
> >> 1761 1782 1897 1749 1907 1797 1734 1810 1913 1988 1914 1822 1951 1973
> >> 1951
> >> 1947 2067 1967 1812 2119 1999 2086 2133 2081 2165 2365 2330 2340
> >>  38   39   40   41    6    7    8    9
> >> 2681 2905 3399 3941 1648 1690 1727 1668
> >>
> >> whereas the reasonable expectation is that the numbers from 6 to 9
> >> would come before 10 to 41.
> >>
> >> How do I sort this incredibly silly behaviour so that my table
> >> follows a reasonable expectation that 9 comes before 10 (and so on and
> so forth)?
> >>
> >> BW
> >>
> >> F
> >>
> >> --
> >> Federico Calboli
> >> Ecological Genetics Research Unit
> >> Department of Biosciences
> >> PO Box 65 (Biocenter 3, Viikinkaari 1)
> >> FIN-00014 University of Helsinki
> >> Finland
> >>
> >> federico.calboli at helsinki.fi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> 
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
> 
> federico.calboli at helsinki.fi


From bgunter.4567 at gmail.com  Fri Feb 12 16:53:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Feb 2016 07:53:27 -0800
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
	<CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
Message-ID: <CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>

You are working in fantasyland. Your density is nonsense.

Please see FAQ 7.31 for links to computer precision of numeric calculations.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 12, 2016 at 7:36 AM, C W <tmrsg11 at gmail.com> wrote:
> Hi David,
>
> This is the Gaussian looking distribution I am trying to integrate.
> https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing
>
> Notice the unnormalized density goes up as high as 2.5*101^191.
>
> I tried to create small intervals like
>> seq(0.5, 1.3, by = 10^(-8))
>
> but that doesn't seem to be good enough, as we know, it should integrate to
> 1.
>
> On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> > On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
>> >
>> > Hi David,
>> >
>> > My real function is actually a multivariate normal, the simple toy 1-d
>> normal won't work.
>> >
>> > But, you gave me an idea about restricting the bounds, and focus
>> integrating on that.  I will get back to you if I need any further
>> assistance.
>>
>> You'll probably need to restrict your bounds even more severely than I did
>> in the 1-d case (using 10 SD's on either side of the mean) . You might need
>> adequate representation of points near the center of your hyper-rectangles.
>> At least that's my armchair notion since I expect the densities tail off
>> rapidly in the corners. You can shoehorn multivariate integration around
>> the `integrate` function but it's messy and inefficient. There are other
>> packages that would be better choices. There's an entire section on
>> numerical differentiation and integration in CRAN Task View: Numerical
>> Mathematics.
>>
>> --
>> David.
>>
>>
>> >
>> > Thank you so much!
>> >
>> > On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> >
>> > > On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
>> > >
>> > > I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
>> > >
>> > > Because the variance is small, it results in density like: 7.978846e+94
>> > >
>> > > Is there any good suggestion for this?
>> >
>> > So what's the difficulty? It's rather like the Dirac function.
>> >
>> > > integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
>> > 1 with absolute error < 7.4e-05
>> >
>> >
>> > --
>> > David.
>> >
>> > >
>> > > Thanks so much!
>> > >
>> > >
>> > > On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
>> > >
>> > >> Wow, thank you, that was very clear.  Let me give it some more runs
>> and
>> > >> investigate this.
>> > >>
>> > >> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <wdunlap at tibco.com>
>> > >> wrote:
>> > >>
>> > >>> Most of the mass of that distribution is within 3e-100 of 2.
>> > >>> You have to be pretty lucky to have a point in sequence
>> > >>> land there.  (You will get at most one point there because
>> > >>> the difference between 2 and its nearest neightbors is on
>> > >>> the order of 1e-16.)
>> > >>>
>> > >>> seq(-2,4,len=101), as used by default in curve, does include 2
>> > >>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
>> > >>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show the
>> bump.
>> > >>> The same principal holds for numerical integration.
>> > >>>
>> > >>>
>> > >>> Bill Dunlap
>> > >>> TIBCO Software
>> > >>> wdunlap tibco.com
>> > >>>
>> > >>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
>> > >>>
>> > >>>> Dear R,
>> > >>>>
>> > >>>> I am graphing the following normal density curve.  Why does it look
>> so
>> > >>>> different?
>> > >>>>
>> > >>>> # the curves
>> > >>>> x <- seq(-2, 4, by=0.00001)
>> > >>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
>> > >>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get wrong
>> > >>>> answer
>> > >>>>
>> > >>>> Why the second curve is flat?  I just changed it from -4 to -3.
>> There is
>> > >>>> no density in that region.
>> > >>>>
>> > >>>>
>> > >>>> Also, I am doing numerical integration.  Why are they so different?
>> > >>>>
>> > >>>>> x <- seq(-2, 4, by=0.00001)
>> > >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>> > >>>> [1] 7.978846e+94
>> > >>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
>> > >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>> > >>>> [1] 0
>> > >>>>
>> > >>>> What is going here?  What a I doing wrong?
>> > >>>>
>> > >>>> Thanks so much!
>> > >>>>
>> > >>>>        [[alternative HTML version deleted]]
>> > >>>>
>> > >>>> ______________________________________________
>> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>> PLEASE do read the posting guide
>> > >>>> http://www.R-project.org/posting-guide.html
>> > >>>> and provide commented, minimal, self-contained, reproducible code.
>> > >>>>
>> > >>>
>> > >>>
>> > >>
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> >
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Fri Feb 12 16:57:32 2016
From: tmrsg11 at gmail.com (C W)
Date: Fri, 12 Feb 2016 10:57:32 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
	<CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
	<CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>
Message-ID: <CAE2FW2khVTusF7Ar8R5p6nmQjr02xT6Vi507T7kQ2zK11y3bJA@mail.gmail.com>

Hi Bert,

Yay fantasyland!

In all seriousness, You are referring to this?
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

In particular, you mean this: .Machine$double.eps ^ 0.5?

Thanks!

On Fri, Feb 12, 2016 at 10:53 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> You are working in fantasyland. Your density is nonsense.
>
> Please see FAQ 7.31 for links to computer precision of numeric
> calculations.
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Feb 12, 2016 at 7:36 AM, C W <tmrsg11 at gmail.com> wrote:
> > Hi David,
> >
> > This is the Gaussian looking distribution I am trying to integrate.
> >
> https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing
> >
> > Notice the unnormalized density goes up as high as 2.5*101^191.
> >
> > I tried to create small intervals like
> >> seq(0.5, 1.3, by = 10^(-8))
> >
> > but that doesn't seem to be good enough, as we know, it should integrate
> to
> > 1.
> >
> > On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <dwinsemius at comcast.net
> >
> > wrote:
> >
> >>
> >> > On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
> >> >
> >> > Hi David,
> >> >
> >> > My real function is actually a multivariate normal, the simple toy 1-d
> >> normal won't work.
> >> >
> >> > But, you gave me an idea about restricting the bounds, and focus
> >> integrating on that.  I will get back to you if I need any further
> >> assistance.
> >>
> >> You'll probably need to restrict your bounds even more severely than I
> did
> >> in the 1-d case (using 10 SD's on either side of the mean) . You might
> need
> >> adequate representation of points near the center of your
> hyper-rectangles.
> >> At least that's my armchair notion since I expect the densities tail off
> >> rapidly in the corners. You can shoehorn multivariate integration around
> >> the `integrate` function but it's messy and inefficient. There are other
> >> packages that would be better choices. There's an entire section on
> >> numerical differentiation and integration in CRAN Task View: Numerical
> >> Mathematics.
> >>
> >> --
> >> David.
> >>
> >>
> >> >
> >> > Thank you so much!
> >> >
> >> > On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <
> dwinsemius at comcast.net>
> >> wrote:
> >> >
> >> > > On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> >> > >
> >> > > I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> >> > >
> >> > > Because the variance is small, it results in density like:
> 7.978846e+94
> >> > >
> >> > > Is there any good suggestion for this?
> >> >
> >> > So what's the difficulty? It's rather like the Dirac function.
> >> >
> >> > > integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
> >> > 1 with absolute error < 7.4e-05
> >> >
> >> >
> >> > --
> >> > David.
> >> >
> >> > >
> >> > > Thanks so much!
> >> > >
> >> > >
> >> > > On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> >> > >
> >> > >> Wow, thank you, that was very clear.  Let me give it some more runs
> >> and
> >> > >> investigate this.
> >> > >>
> >> > >> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <
> wdunlap at tibco.com>
> >> > >> wrote:
> >> > >>
> >> > >>> Most of the mass of that distribution is within 3e-100 of 2.
> >> > >>> You have to be pretty lucky to have a point in sequence
> >> > >>> land there.  (You will get at most one point there because
> >> > >>> the difference between 2 and its nearest neightbors is on
> >> > >>> the order of 1e-16.)
> >> > >>>
> >> > >>> seq(-2,4,len=101), as used by default in curve, does include 2
> >> > >>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> >> > >>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show
> the
> >> bump.
> >> > >>> The same principal holds for numerical integration.
> >> > >>>
> >> > >>>
> >> > >>> Bill Dunlap
> >> > >>> TIBCO Software
> >> > >>> wdunlap tibco.com
> >> > >>>
> >> > >>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
> >> > >>>
> >> > >>>> Dear R,
> >> > >>>>
> >> > >>>> I am graphing the following normal density curve.  Why does it
> look
> >> so
> >> > >>>> different?
> >> > >>>>
> >> > >>>> # the curves
> >> > >>>> x <- seq(-2, 4, by=0.00001)
> >> > >>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> >> > >>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get
> wrong
> >> > >>>> answer
> >> > >>>>
> >> > >>>> Why the second curve is flat?  I just changed it from -4 to -3.
> >> There is
> >> > >>>> no density in that region.
> >> > >>>>
> >> > >>>>
> >> > >>>> Also, I am doing numerical integration.  Why are they so
> different?
> >> > >>>>
> >> > >>>>> x <- seq(-2, 4, by=0.00001)
> >> > >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >> > >>>> [1] 7.978846e+94
> >> > >>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> >> > >>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >> > >>>> [1] 0
> >> > >>>>
> >> > >>>> What is going here?  What a I doing wrong?
> >> > >>>>
> >> > >>>> Thanks so much!
> >> > >>>>
> >> > >>>>        [[alternative HTML version deleted]]
> >> > >>>>
> >> > >>>> ______________________________________________
> >> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> > >>>> PLEASE do read the posting guide
> >> > >>>> http://www.R-project.org/posting-guide.html
> >> > >>>> and provide commented, minimal, self-contained, reproducible
> code.
> >> > >>>>
> >> > >>>
> >> > >>>
> >> > >>
> >> > >
> >> > >       [[alternative HTML version deleted]]
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > David Winsemius
> >> > Alameda, CA, USA
> >> >
> >> >
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Feb 12 17:09:34 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Feb 2016 17:09:34 +0100
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2khVTusF7Ar8R5p6nmQjr02xT6Vi507T7kQ2zK11y3bJA@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
	<CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
	<CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>
	<CAE2FW2khVTusF7Ar8R5p6nmQjr02xT6Vi507T7kQ2zK11y3bJA@mail.gmail.com>
Message-ID: <9CB3AF25-C124-47B4-8D75-D3F6E422F4CE@gmail.com>

I don't see here FAQ 7.31 comes in either (for once!...)

However, either the density is unnormalized and the integral is not 1, or the integral is 1 and it is normalized. The one in the picture clearly does not integrate to one. You can fit a rectangle of size 0.1 by 1e191 under the curve so the integral should be > 1e190 .

As depicted, I don't see why a plain integral from .5 to 1.5 shouldn't work. 

-pd

On 12 Feb 2016, at 16:57 , C W <tmrsg11 at gmail.com> wrote:

> Hi Bert,
> 
> Yay fantasyland!
> 
> In all seriousness, You are referring to this?
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
> 
> In particular, you mean this: .Machine$double.eps ^ 0.5?
> 
> Thanks!
> 
> On Fri, Feb 12, 2016 at 10:53 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> 
>> You are working in fantasyland. Your density is nonsense.
>> 
>> Please see FAQ 7.31 for links to computer precision of numeric
>> calculations.
>> 
>> 
>> Cheers,
>> Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Fri, Feb 12, 2016 at 7:36 AM, C W <tmrsg11 at gmail.com> wrote:
>>> Hi David,
>>> 
>>> This is the Gaussian looking distribution I am trying to integrate.
>>> 
>> https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing
>>> 
>>> Notice the unnormalized density goes up as high as 2.5*101^191.
>>> 
>>> I tried to create small intervals like
>>>> seq(0.5, 1.3, by = 10^(-8))
>>> 
>>> but that doesn't seem to be good enough, as we know, it should integrate
>> to
>>> 1.
>>> 
>>> On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <dwinsemius at comcast.net
>>> 
>>> wrote:
>>> 
>>>> 
>>>>> On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
>>>>> 
>>>>> Hi David,
>>>>> 
>>>>> My real function is actually a multivariate normal, the simple toy 1-d
>>>> normal won't work.
>>>>> 
>>>>> But, you gave me an idea about restricting the bounds, and focus
>>>> integrating on that.  I will get back to you if I need any further
>>>> assistance.
>>>> 
>>>> You'll probably need to restrict your bounds even more severely than I
>> did
>>>> in the 1-d case (using 10 SD's on either side of the mean) . You might
>> need
>>>> adequate representation of points near the center of your
>> hyper-rectangles.
>>>> At least that's my armchair notion since I expect the densities tail off
>>>> rapidly in the corners. You can shoehorn multivariate integration around
>>>> the `integrate` function but it's messy and inefficient. There are other
>>>> packages that would be better choices. There's an entire section on
>>>> numerical differentiation and integration in CRAN Task View: Numerical
>>>> Mathematics.
>>>> 
>>>> --
>>>> David.
>>>> 
>>>> 
>>>>> 
>>>>> Thank you so much!
>>>>> 
>>>>> On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <
>> dwinsemius at comcast.net>
>>>> wrote:
>>>>> 
>>>>>> On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
>>>>>> 
>>>>>> I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
>>>>>> 
>>>>>> Because the variance is small, it results in density like:
>> 7.978846e+94
>>>>>> 
>>>>>> Is there any good suggestion for this?
>>>>> 
>>>>> So what's the difficulty? It's rather like the Dirac function.
>>>>> 
>>>>>> integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
>>>>> 1 with absolute error < 7.4e-05
>>>>> 
>>>>> 
>>>>> --
>>>>> David.
>>>>> 
>>>>>> 
>>>>>> Thanks so much!
>>>>>> 
>>>>>> 
>>>>>> On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
>>>>>> 
>>>>>>> Wow, thank you, that was very clear.  Let me give it some more runs
>>>> and
>>>>>>> investigate this.
>>>>>>> 
>>>>>>> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <
>> wdunlap at tibco.com>
>>>>>>> wrote:
>>>>>>> 
>>>>>>>> Most of the mass of that distribution is within 3e-100 of 2.
>>>>>>>> You have to be pretty lucky to have a point in sequence
>>>>>>>> land there.  (You will get at most one point there because
>>>>>>>> the difference between 2 and its nearest neightbors is on
>>>>>>>> the order of 1e-16.)
>>>>>>>> 
>>>>>>>> seq(-2,4,len=101), as used by default in curve, does include 2
>>>>>>>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
>>>>>>>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show
>> the
>>>> bump.
>>>>>>>> The same principal holds for numerical integration.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Bill Dunlap
>>>>>>>> TIBCO Software
>>>>>>>> wdunlap tibco.com
>>>>>>>> 
>>>>>>>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
>>>>>>>> 
>>>>>>>>> Dear R,
>>>>>>>>> 
>>>>>>>>> I am graphing the following normal density curve.  Why does it
>> look
>>>> so
>>>>>>>>> different?
>>>>>>>>> 
>>>>>>>>> # the curves
>>>>>>>>> x <- seq(-2, 4, by=0.00001)
>>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
>>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get
>> wrong
>>>>>>>>> answer
>>>>>>>>> 
>>>>>>>>> Why the second curve is flat?  I just changed it from -4 to -3.
>>>> There is
>>>>>>>>> no density in that region.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Also, I am doing numerical integration.  Why are they so
>> different?
>>>>>>>>> 
>>>>>>>>>> x <- seq(-2, 4, by=0.00001)
>>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>>>>>>>>> [1] 7.978846e+94
>>>>>>>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
>>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>>>>>>>>> [1] 0
>>>>>>>>> 
>>>>>>>>> What is going here?  What a I doing wrong?
>>>>>>>>> 
>>>>>>>>> Thanks so much!
>>>>>>>>> 
>>>>>>>>>       [[alternative HTML version deleted]]
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>>      [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>>>> 
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pamela.foggia at gmail.com  Fri Feb 12 14:11:49 2016
From: pamela.foggia at gmail.com (Pamela Foggia)
Date: Fri, 12 Feb 2016 14:11:49 +0100
Subject: [R] Help with truncated normal distribution
Message-ID: <CALLwW6GE0tRNPPPxcmrpOzTUNq-K4RMJ-TWCo1QgvY=LHQ3sCw@mail.gmail.com>

Hello,
Do you know how to obtain the parameters of a theoretical normal
distribution knowing the parameters of the same truncated normal
distribution? Is there in R any function that can do it?

Thanks in advance

	[[alternative HTML version deleted]]


From shivi.bhatia at safexpress.com  Fri Feb 12 14:18:35 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Fri, 12 Feb 2016 18:48:35 +0530
Subject: [R] Help with the Twitter Analysis
Message-ID: <001a01d16597$d458ee00$7d0aca00$@safexpress.com>

Dear Team, 

 

Kindly refer to the error below while generating a Twitter Analysis for my
firm:

 

# Warning message:<NEED TO CHECK ON THIS ERROR MESSAGE>

# In doRppAPICall("search/tweets", n, params = params, retryOnRateLimit =
retryOnRateLimit,  :

 

As I checked on forums such as StackOverflow and other r related literature
it mentioned that this error happened due to the reason that there were less
tweets than what I requested for. On further investigation I got to know
that due to twitter API restrictions we can't fetch older tweets i.e. any
tweet prior to 6-7 days. This seems to be a very big hurdle for me to build
a sentiment analysis for the company as the time frame is very low. 

 

Request to please advise if there is some work around for the same or best
possible alternative. 

 

Thanks, Shivi

Mb: 9891002021

 

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160212/0050b0f9/attachment.pl>

From tmrsg11 at gmail.com  Fri Feb 12 17:29:16 2016
From: tmrsg11 at gmail.com (C W)
Date: Fri, 12 Feb 2016 11:29:16 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <9CB3AF25-C124-47B4-8D75-D3F6E422F4CE@gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
	<CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
	<CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>
	<CAE2FW2khVTusF7Ar8R5p6nmQjr02xT6Vi507T7kQ2zK11y3bJA@mail.gmail.com>
	<9CB3AF25-C124-47B4-8D75-D3F6E422F4CE@gmail.com>
Message-ID: <CAE2FW2=YLiYVk+o8dURMGstm3iVb2+GY5cOpWksps3gCt48mDw@mail.gmail.com>

Hi Peter,

Great, let me try that and get back to you on my findings in a few hours!
 :)

On Fri, Feb 12, 2016 at 11:09 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> I don't see here FAQ 7.31 comes in either (for once!...)
>
> However, either the density is unnormalized and the integral is not 1, or
> the integral is 1 and it is normalized. The one in the picture clearly does
> not integrate to one. You can fit a rectangle of size 0.1 by 1e191 under
> the curve so the integral should be > 1e190 .
>
> As depicted, I don't see why a plain integral from .5 to 1.5 shouldn't
> work.
>
> -pd
>
> On 12 Feb 2016, at 16:57 , C W <tmrsg11 at gmail.com> wrote:
>
> > Hi Bert,
> >
> > Yay fantasyland!
> >
> > In all seriousness, You are referring to this?
> >
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
> >
> > In particular, you mean this: .Machine$double.eps ^ 0.5?
> >
> > Thanks!
> >
> > On Fri, Feb 12, 2016 at 10:53 AM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> >> You are working in fantasyland. Your density is nonsense.
> >>
> >> Please see FAQ 7.31 for links to computer precision of numeric
> >> calculations.
> >>
> >>
> >> Cheers,
> >> Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Fri, Feb 12, 2016 at 7:36 AM, C W <tmrsg11 at gmail.com> wrote:
> >>> Hi David,
> >>>
> >>> This is the Gaussian looking distribution I am trying to integrate.
> >>>
> >>
> https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing
> >>>
> >>> Notice the unnormalized density goes up as high as 2.5*101^191.
> >>>
> >>> I tried to create small intervals like
> >>>> seq(0.5, 1.3, by = 10^(-8))
> >>>
> >>> but that doesn't seem to be good enough, as we know, it should
> integrate
> >> to
> >>> 1.
> >>>
> >>> On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <
> dwinsemius at comcast.net
> >>>
> >>> wrote:
> >>>
> >>>>
> >>>>> On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>
> >>>>> Hi David,
> >>>>>
> >>>>> My real function is actually a multivariate normal, the simple toy
> 1-d
> >>>> normal won't work.
> >>>>>
> >>>>> But, you gave me an idea about restricting the bounds, and focus
> >>>> integrating on that.  I will get back to you if I need any further
> >>>> assistance.
> >>>>
> >>>> You'll probably need to restrict your bounds even more severely than I
> >> did
> >>>> in the 1-d case (using 10 SD's on either side of the mean) . You might
> >> need
> >>>> adequate representation of points near the center of your
> >> hyper-rectangles.
> >>>> At least that's my armchair notion since I expect the densities tail
> off
> >>>> rapidly in the corners. You can shoehorn multivariate integration
> around
> >>>> the `integrate` function but it's messy and inefficient. There are
> other
> >>>> packages that would be better choices. There's an entire section on
> >>>> numerical differentiation and integration in CRAN Task View: Numerical
> >>>> Mathematics.
> >>>>
> >>>> --
> >>>> David.
> >>>>
> >>>>
> >>>>>
> >>>>> Thank you so much!
> >>>>>
> >>>>> On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <
> >> dwinsemius at comcast.net>
> >>>> wrote:
> >>>>>
> >>>>>> On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>>
> >>>>>> I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> >>>>>>
> >>>>>> Because the variance is small, it results in density like:
> >> 7.978846e+94
> >>>>>>
> >>>>>> Is there any good suggestion for this?
> >>>>>
> >>>>> So what's the difficulty? It's rather like the Dirac function.
> >>>>>
> >>>>>> integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
> >>>>> 1 with absolute error < 7.4e-05
> >>>>>
> >>>>>
> >>>>> --
> >>>>> David.
> >>>>>
> >>>>>>
> >>>>>> Thanks so much!
> >>>>>>
> >>>>>>
> >>>>>> On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>>
> >>>>>>> Wow, thank you, that was very clear.  Let me give it some more runs
> >>>> and
> >>>>>>> investigate this.
> >>>>>>>
> >>>>>>> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <
> >> wdunlap at tibco.com>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> Most of the mass of that distribution is within 3e-100 of 2.
> >>>>>>>> You have to be pretty lucky to have a point in sequence
> >>>>>>>> land there.  (You will get at most one point there because
> >>>>>>>> the difference between 2 and its nearest neightbors is on
> >>>>>>>> the order of 1e-16.)
> >>>>>>>>
> >>>>>>>> seq(-2,4,len=101), as used by default in curve, does include 2
> >>>>>>>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> >>>>>>>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show
> >> the
> >>>> bump.
> >>>>>>>> The same principal holds for numerical integration.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Bill Dunlap
> >>>>>>>> TIBCO Software
> >>>>>>>> wdunlap tibco.com
> >>>>>>>>
> >>>>>>>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>>>>
> >>>>>>>>> Dear R,
> >>>>>>>>>
> >>>>>>>>> I am graphing the following normal density curve.  Why does it
> >> look
> >>>> so
> >>>>>>>>> different?
> >>>>>>>>>
> >>>>>>>>> # the curves
> >>>>>>>>> x <- seq(-2, 4, by=0.00001)
> >>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> >>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get
> >> wrong
> >>>>>>>>> answer
> >>>>>>>>>
> >>>>>>>>> Why the second curve is flat?  I just changed it from -4 to -3.
> >>>> There is
> >>>>>>>>> no density in that region.
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> Also, I am doing numerical integration.  Why are they so
> >> different?
> >>>>>>>>>
> >>>>>>>>>> x <- seq(-2, 4, by=0.00001)
> >>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>>>>>>> [1] 7.978846e+94
> >>>>>>>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> >>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>>>>>>> [1] 0
> >>>>>>>>>
> >>>>>>>>> What is going here?  What a I doing wrong?
> >>>>>>>>>
> >>>>>>>>> Thanks so much!
> >>>>>>>>>
> >>>>>>>>>       [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> see
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >> code.
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>>      [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>> David Winsemius
> >>>>> Alameda, CA, USA
> >>>>>
> >>>>>
> >>>>
> >>>> David Winsemius
> >>>> Alameda, CA, USA
> >>>>
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>

	[[alternative HTML version deleted]]


From jacobwegelin at fastmail.fm  Fri Feb 12 17:33:59 2016
From: jacobwegelin at fastmail.fm (Jacob Wegelin)
Date: Fri, 12 Feb 2016 11:33:59 -0500
Subject: [R] confirm family==binomial and link==logistic
Message-ID: <alpine.OSX.2.20.1602111643530.35119@QQT>

To check that a regression object comes from logistic regression, I employ the following two lines:

 	stopifnot(glmObject$family$family=="binomial")

 	stopifnot(glmObject$family$link=="logit")

For instance:

toyfunction<-function(glmObject) {
 	stopifnot(inherits(glmObject, "glm"))
 	stopifnot(glmObject$family$family=="binomial")
 	stopifnot(glmObject$family$link=="logit")
 	cat("okay, I guess\n")
 	glmObject
}

mydata <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")

someobject<- glm(admit~gre+gpa, data=mydata)

toyfunction(someobject)

someobject<- glm(admit~gre+gpa, data=mydata, family="binomial")

toyfunction(someobject)

But Doug Bates once stated that it's preferable to use extractor functions (and perhaps other ready-made functions?) rather than "deconstructing" an object (his term), as I do here.

Accordingly, is there a smarter way to perform the check that I perform inside toyfunction?

Thanks for any insight

Jacob A. Wegelin
Assistant Professor
C. Kenneth and Dianne Wright Center for Clinical and Translational Research
Department of Biostatistics
Virginia Commonwealth University
830 E. Main St., Seventh Floor
P. O. Box 980032
Richmond VA 23298-0032
U.S.A. 
CTSA grant: UL1TR000058
E-mail: jacobwegelin at fastmail.fm 
URL: http://www.people.vcu.edu/~jwegelin


From boris.steipe at utoronto.ca  Fri Feb 12 17:40:14 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 12 Feb 2016 11:40:14 -0500
Subject: [R] Help with the Twitter Analysis
In-Reply-To: <001a01d16597$d458ee00$7d0aca00$@safexpress.com>
References: <001a01d16597$d458ee00$7d0aca00$@safexpress.com>
Message-ID: <0995E24A-5099-42A7-A20F-BF9E3123AA38@utoronto.ca>

Since this is due to a throttle in Twitter's API, I would assume that attempts to bypass this will violate Twitter's TOS. You'll either have to purchase the data you need, or build your own in-house data set, going forward.


B.

On Feb 12, 2016, at 8:18 AM, SHIVI BHATIA <shivi.bhatia at safexpress.com> wrote:

> Dear Team, 
> 
> 
> 
> Kindly refer to the error below while generating a Twitter Analysis for my
> firm:
> 
> 
> 
> # Warning message:<NEED TO CHECK ON THIS ERROR MESSAGE>
> 
> # In doRppAPICall("search/tweets", n, params = params, retryOnRateLimit =
> retryOnRateLimit,  :
> 
> 
> 
> As I checked on forums such as StackOverflow and other r related literature
> it mentioned that this error happened due to the reason that there were less
> tweets than what I requested for. On further investigation I got to know
> that due to twitter API restrictions we can't fetch older tweets i.e. any
> tweet prior to 6-7 days. This seems to be a very big hurdle for me to build
> a sentiment analysis for the company as the time frame is very low. 
> 
> 
> 
> Request to please advise if there is some work around for the same or best
> possible alternative. 
> 
> 
> 
> Thanks, Shivi
> 
> Mb: 9891002021
> 
> 
> 
> 
> 
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Fri Feb 12 17:44:00 2016
From: tmrsg11 at gmail.com (C W)
Date: Fri, 12 Feb 2016 11:44:00 -0500
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2=YLiYVk+o8dURMGstm3iVb2+GY5cOpWksps3gCt48mDw@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
	<CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
	<CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>
	<CAE2FW2khVTusF7Ar8R5p6nmQjr02xT6Vi507T7kQ2zK11y3bJA@mail.gmail.com>
	<9CB3AF25-C124-47B4-8D75-D3F6E422F4CE@gmail.com>
	<CAE2FW2=YLiYVk+o8dURMGstm3iVb2+GY5cOpWksps3gCt48mDw@mail.gmail.com>
Message-ID: <CAE2FW2=oET2B1XcyMKvqQX2jEJjpvntsw8B5VDvNVee42LCMbQ@mail.gmail.com>

On a side note, is it ok to do?

> which(max(p_x))
and use that instead of numerical integration to get E[X]?

I will try both and report back!  Thank you expeRts

On Fri, Feb 12, 2016 at 11:29 AM, C W <tmrsg11 at gmail.com> wrote:

> Hi Peter,
>
> Great, let me try that and get back to you on my findings in a few hours!
>  :)
>
> On Fri, Feb 12, 2016 at 11:09 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> I don't see here FAQ 7.31 comes in either (for once!...)
>>
>> However, either the density is unnormalized and the integral is not 1, or
>> the integral is 1 and it is normalized. The one in the picture clearly does
>> not integrate to one. You can fit a rectangle of size 0.1 by 1e191 under
>> the curve so the integral should be > 1e190 .
>>
>> As depicted, I don't see why a plain integral from .5 to 1.5 shouldn't
>> work.
>>
>> -pd
>>
>> On 12 Feb 2016, at 16:57 , C W <tmrsg11 at gmail.com> wrote:
>>
>> > Hi Bert,
>> >
>> > Yay fantasyland!
>> >
>> > In all seriousness, You are referring to this?
>> >
>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>> >
>> > In particular, you mean this: .Machine$double.eps ^ 0.5?
>> >
>> > Thanks!
>> >
>> > On Fri, Feb 12, 2016 at 10:53 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> > wrote:
>> >
>> >> You are working in fantasyland. Your density is nonsense.
>> >>
>> >> Please see FAQ 7.31 for links to computer precision of numeric
>> >> calculations.
>> >>
>> >>
>> >> Cheers,
>> >> Bert
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Fri, Feb 12, 2016 at 7:36 AM, C W <tmrsg11 at gmail.com> wrote:
>> >>> Hi David,
>> >>>
>> >>> This is the Gaussian looking distribution I am trying to integrate.
>> >>>
>> >>
>> https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing
>> >>>
>> >>> Notice the unnormalized density goes up as high as 2.5*101^191.
>> >>>
>> >>> I tried to create small intervals like
>> >>>> seq(0.5, 1.3, by = 10^(-8))
>> >>>
>> >>> but that doesn't seem to be good enough, as we know, it should
>> integrate
>> >> to
>> >>> 1.
>> >>>
>> >>> On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <
>> dwinsemius at comcast.net
>> >>>
>> >>> wrote:
>> >>>
>> >>>>
>> >>>>> On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
>> >>>>>
>> >>>>> Hi David,
>> >>>>>
>> >>>>> My real function is actually a multivariate normal, the simple toy
>> 1-d
>> >>>> normal won't work.
>> >>>>>
>> >>>>> But, you gave me an idea about restricting the bounds, and focus
>> >>>> integrating on that.  I will get back to you if I need any further
>> >>>> assistance.
>> >>>>
>> >>>> You'll probably need to restrict your bounds even more severely than
>> I
>> >> did
>> >>>> in the 1-d case (using 10 SD's on either side of the mean) . You
>> might
>> >> need
>> >>>> adequate representation of points near the center of your
>> >> hyper-rectangles.
>> >>>> At least that's my armchair notion since I expect the densities tail
>> off
>> >>>> rapidly in the corners. You can shoehorn multivariate integration
>> around
>> >>>> the `integrate` function but it's messy and inefficient. There are
>> other
>> >>>> packages that would be better choices. There's an entire section on
>> >>>> numerical differentiation and integration in CRAN Task View:
>> Numerical
>> >>>> Mathematics.
>> >>>>
>> >>>> --
>> >>>> David.
>> >>>>
>> >>>>
>> >>>>>
>> >>>>> Thank you so much!
>> >>>>>
>> >>>>> On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <
>> >> dwinsemius at comcast.net>
>> >>>> wrote:
>> >>>>>
>> >>>>>> On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
>> >>>>>>
>> >>>>>> I want to do numerical integration w.r.t. mu: P(mu) ? N(mu,
>> 0.00001)
>> >>>>>>
>> >>>>>> Because the variance is small, it results in density like:
>> >> 7.978846e+94
>> >>>>>>
>> >>>>>> Is there any good suggestion for this?
>> >>>>>
>> >>>>> So what's the difficulty? It's rather like the Dirac function.
>> >>>>>
>> >>>>>> integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
>> >>>>> 1 with absolute error < 7.4e-05
>> >>>>>
>> >>>>>
>> >>>>> --
>> >>>>> David.
>> >>>>>
>> >>>>>>
>> >>>>>> Thanks so much!
>> >>>>>>
>> >>>>>>
>> >>>>>> On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
>> >>>>>>
>> >>>>>>> Wow, thank you, that was very clear.  Let me give it some more
>> runs
>> >>>> and
>> >>>>>>> investigate this.
>> >>>>>>>
>> >>>>>>> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <
>> >> wdunlap at tibco.com>
>> >>>>>>> wrote:
>> >>>>>>>
>> >>>>>>>> Most of the mass of that distribution is within 3e-100 of 2.
>> >>>>>>>> You have to be pretty lucky to have a point in sequence
>> >>>>>>>> land there.  (You will get at most one point there because
>> >>>>>>>> the difference between 2 and its nearest neightbors is on
>> >>>>>>>> the order of 1e-16.)
>> >>>>>>>>
>> >>>>>>>> seq(-2,4,len=101), as used by default in curve, does include 2
>> >>>>>>>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
>> >>>>>>>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show
>> >> the
>> >>>> bump.
>> >>>>>>>> The same principal holds for numerical integration.
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> Bill Dunlap
>> >>>>>>>> TIBCO Software
>> >>>>>>>> wdunlap tibco.com
>> >>>>>>>>
>> >>>>>>>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
>> >>>>>>>>
>> >>>>>>>>> Dear R,
>> >>>>>>>>>
>> >>>>>>>>> I am graphing the following normal density curve.  Why does it
>> >> look
>> >>>> so
>> >>>>>>>>> different?
>> >>>>>>>>>
>> >>>>>>>>> # the curves
>> >>>>>>>>> x <- seq(-2, 4, by=0.00001)
>> >>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
>> >>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get
>> >> wrong
>> >>>>>>>>> answer
>> >>>>>>>>>
>> >>>>>>>>> Why the second curve is flat?  I just changed it from -4 to -3.
>> >>>> There is
>> >>>>>>>>> no density in that region.
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> Also, I am doing numerical integration.  Why are they so
>> >> different?
>> >>>>>>>>>
>> >>>>>>>>>> x <- seq(-2, 4, by=0.00001)
>> >>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>> >>>>>>>>> [1] 7.978846e+94
>> >>>>>>>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
>> >>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
>> >>>>>>>>> [1] 0
>> >>>>>>>>>
>> >>>>>>>>> What is going here?  What a I doing wrong?
>> >>>>>>>>>
>> >>>>>>>>> Thanks so much!
>> >>>>>>>>>
>> >>>>>>>>>       [[alternative HTML version deleted]]
>> >>>>>>>>>
>> >>>>>>>>> ______________________________________________
>> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> see
>> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>>>> PLEASE do read the posting guide
>> >>>>>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> >> code.
>> >>>>>>>>>
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>
>> >>>>>>
>> >>>>>>      [[alternative HTML version deleted]]
>> >>>>>>
>> >>>>>> ______________________________________________
>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>>> David Winsemius
>> >>>>> Alameda, CA, USA
>> >>>>>
>> >>>>>
>> >>>>
>> >>>> David Winsemius
>> >>>> Alameda, CA, USA
>> >>>>
>> >>>>
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Feb 12 17:48:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Feb 2016 08:48:03 -0800
Subject: [R] Help with truncated normal distribution
In-Reply-To: <CALLwW6GE0tRNPPPxcmrpOzTUNq-K4RMJ-TWCo1QgvY=LHQ3sCw@mail.gmail.com>
References: <CALLwW6GE0tRNPPPxcmrpOzTUNq-K4RMJ-TWCo1QgvY=LHQ3sCw@mail.gmail.com>
Message-ID: <CAGxFJbSgH=QgiCFBFFzkUnSrFhhz9S7sZK0p9vy1k_38E-RvAw@mail.gmail.com>

Define "truncated." (It is often confused with "censored".)  As
stated, it seems to me that you already have the answer. Do you have
data? -- i.e. what do you mean by "parameters" ?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 12, 2016 at 5:11 AM, Pamela Foggia <pamela.foggia at gmail.com> wrote:
> Hello,
> Do you know how to obtain the parameters of a theoretical normal
> distribution knowing the parameters of the same truncated normal
> distribution? Is there in R any function that can do it?
>
> Thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Feb 12 17:50:29 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 12 Feb 2016 10:50:29 -0600
Subject: [R] confirm family==binomial and link==logistic
In-Reply-To: <alpine.OSX.2.20.1602111643530.35119@QQT>
References: <alpine.OSX.2.20.1602111643530.35119@QQT>
Message-ID: <73798FA5-22B2-4B1B-B49F-0C043984078F@me.com>


> On Feb 12, 2016, at 10:33 AM, Jacob Wegelin <jacobwegelin at fastmail.fm> wrote:
> 
> To check that a regression object comes from logistic regression, I employ the following two lines:
> 
> 	stopifnot(glmObject$family$family=="binomial")
> 
> 	stopifnot(glmObject$family$link=="logit")
> 
> For instance:
> 
> toyfunction<-function(glmObject) {
> 	stopifnot(inherits(glmObject, "glm"))
> 	stopifnot(glmObject$family$family=="binomial")
> 	stopifnot(glmObject$family$link=="logit")
> 	cat("okay, I guess\n")
> 	glmObject
> }
> 
> mydata <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
> 
> someobject<- glm(admit~gre+gpa, data=mydata)
> 
> toyfunction(someobject)
> 
> someobject<- glm(admit~gre+gpa, data=mydata, family="binomial")
> 
> toyfunction(someobject)
> 
> But Doug Bates once stated that it's preferable to use extractor functions (and perhaps other ready-made functions?) rather than "deconstructing" an object (his term), as I do here.
> 
> Accordingly, is there a smarter way to perform the check that I perform inside toyfunction?
> 
> Thanks for any insight
> 
> Jacob A. Wegelin


Hi Jacob,

The rationale behind Doug's comment is that if there is a pre-existing extractor function, you are at less risk due to future possible changes in the underlying object structure, than if you try to access an object element directly. 

If the underlying object structure should change in the future, you never know what result you might get by accessing the element directly, if you get one at all. 

If you use the extractor function, that would be (or should be) modified to reflect the change in the underlying object.

For your examples above, ?family should work, but returns more than just the 'family' and 'link' components, which print.family() displays:

someobject<- glm(admit~gre+gpa, data=mydata)
> family(someobject)

Family: gaussian 
Link function: identity 


someobject<- glm(admit~gre+gpa, data=mydata, family="binomial")
> family(someobject)

Family: binomial 
Link function: logit 


So, you could feasibly use:

  family(someobject)$family
  family(someobject)$link

and so forth, to perform your checks. If you look at the output of str(family(someobject)), you will see the other elements contained.

Regards,

Marc Schwartz


From bgunter.4567 at gmail.com  Fri Feb 12 17:50:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Feb 2016 08:50:53 -0800
Subject: [R] confirm family==binomial and link==logistic
In-Reply-To: <alpine.OSX.2.20.1602111643530.35119@QQT>
References: <alpine.OSX.2.20.1602111643530.35119@QQT>
Message-ID: <CAGxFJbS6AYGoUuJXWuQ64FqgFR-EArDtxeOj7An=EKEEZXvgsw@mail.gmail.com>

Not an answer ....

But note that your several stopifnot() statements can be combined into
1. See ?stopifnot .

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 12, 2016 at 8:33 AM, Jacob Wegelin <jacobwegelin at fastmail.fm> wrote:
> To check that a regression object comes from logistic regression, I employ
> the following two lines:
>
>         stopifnot(glmObject$family$family=="binomial")
>
>         stopifnot(glmObject$family$link=="logit")
>
> For instance:
>
> toyfunction<-function(glmObject) {
>         stopifnot(inherits(glmObject, "glm"))
>         stopifnot(glmObject$family$family=="binomial")
>         stopifnot(glmObject$family$link=="logit")
>         cat("okay, I guess\n")
>         glmObject
> }
>
> mydata <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
>
> someobject<- glm(admit~gre+gpa, data=mydata)
>
> toyfunction(someobject)
>
> someobject<- glm(admit~gre+gpa, data=mydata, family="binomial")
>
> toyfunction(someobject)
>
> But Doug Bates once stated that it's preferable to use extractor functions
> (and perhaps other ready-made functions?) rather than "deconstructing" an
> object (his term), as I do here.
>
> Accordingly, is there a smarter way to perform the check that I perform
> inside toyfunction?
>
> Thanks for any insight
>
> Jacob A. Wegelin
> Assistant Professor
> C. Kenneth and Dianne Wright Center for Clinical and Translational Research
> Department of Biostatistics
> Virginia Commonwealth University
> 830 E. Main St., Seventh Floor
> P. O. Box 980032
> Richmond VA 23298-0032
> U.S.A. CTSA grant: UL1TR000058
> E-mail: jacobwegelin at fastmail.fm URL: http://www.people.vcu.edu/~jwegelin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stefano.sofia at regione.marche.it  Fri Feb 12 18:03:49 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 12 Feb 2016 17:03:49 +0000
Subject: [R] lapply on list of lists
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DB8A77F@ESINO.regionemarche.intra>

Dear R list users,
I have three lists of data frames, respectively temp_list, wind_list and snow_list.
The elements of these three lists are

temp_list$station1, temp_list$station2 and temp_list$station3 with columns date and temp;
wind_list$station1, wind_list$station2 and wind_list$station3 with columns date, wind_vel and wind_dir;
snow_list$station1, snow_list$station2 and snow_list$station3 with columns date and hs

where date has been transformed to character.
I need to merge temp_list$station1, wind_list$station1 and snow_list$station1, and same thing for station2 and station3.

If I create a list
list_all <- list(temp_list$station1, wind_list$station1, snow_list$station1)

then
Reduce(function(x, y) merge(x, y, by=c("date"), all=TRUE), list_all)

will do it. But then I have to create the other two lists and apply again Reduce.

I would like to create a list of list and using lapply twice in order to get this process completely automatic.
I tried

list_all <- list(temp_list, wind_list, snow_list)
names(list_all) <- c("temp", "wind", "snow")
lapply(names(list_all), function(val){list_all$val, lapply(c("station1", "station2", "station3"), function(val){Reduce(function(x, y) merge(x$val, y$val, by=c("date"), all=TRUE), list_all)}), list_all})

but it gives me a syntax error and I am struggling to make it work.
Could someboby help me to create the correct loop?

Thank you for your help
Stefano

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Fri Feb 12 21:22:42 2016
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 12 Feb 2016 13:22:42 -0700
Subject: [R] Separating point symbols and line types in a legend.
In-Reply-To: <56BD6520.20909@auckland.ac.nz>
References: <56BD6520.20909@auckland.ac.nz>
Message-ID: <CAFEqCdyXMk090ARiZ_4rPUYpFx7nFhBfQBBfJrSmEH-X7FijJQ@mail.gmail.com>

One option is to call `legend` twice and do some manual positioning.
This worked for me:

plot(1:10)
legend('topleft', lty=1:3, bty="n", legend=c('','','') )
legend('topleft', pch=c(20,8,1), bty="n",
legend=c('clyde','irving','melvin'), inset=c(0.1,0))

You may need to fiddle with the amount of inset for your particular
plot and device combination.



On Thu, Feb 11, 2016 at 9:52 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> I would like to have a legend given in the manner
>
> legend("topleft",pch=c(20,8,1),lty=1:3,bty="n",
>        legend=c("clyde","irving","melvin"))
>
> but with the point symbol *NOT* being superimposed on the line segments that
> are plotted.
>
> I saw that I can specify "merge=FALSE" in the call to legend() but this
> gives results like unto
>
>    ----* irving
>
> with the plot symbol being immediately juxtaposed to the plotted line
> segment.  I would like a space between them, like so:
>
>    ---- * irving
>
> (See the difference?)
>
> I can see no arguments to legend that allow me to effect this.  I can adjust
> positioning of the legend text, but not of the plotted point character or
> line segment.  Is there any way to effect the desired result?  Or is there a
> "simple" adjustment that one could make to the code for legend() that would
> allow me to accomplish what I want?
>
> Ta.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From pdalgd at gmail.com  Fri Feb 12 21:54:35 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Feb 2016 21:54:35 +0100
Subject: [R] Why two curves and numerical integration look so different?
In-Reply-To: <CAE2FW2=oET2B1XcyMKvqQX2jEJjpvntsw8B5VDvNVee42LCMbQ@mail.gmail.com>
References: <CAE2FW2nO8q9TsAN9Pc5AGjX1ZK56ivdaYdXOC15Bp09euO-NWA@mail.gmail.com>
	<CAF8bMcY_XTP8919r0TK=EwWS95Wm3xBjqsuE5CqdWohBBaVXZg@mail.gmail.com>
	<CAE2FW2nfsvbC5paTui_+53A3KthucBRCMYc52Vq_a4mBP8xjqA@mail.gmail.com>
	<CAE2FW2=r_atTF7sHbjpkf-5Mfa9HvQNB-jxMGzw9O+FYbLXA5A@mail.gmail.com>
	<A3252D38-00D9-455A-B426-59687E86FC2E@comcast.net>
	<CAE2FW2nubzYP43MrcMiK5DDyZdrVXOC35S5tu7chJMhme2X5cA@mail.gmail.com>
	<657F187D-3F51-41C1-8BB7-E0578B7E830F@comcast.net>
	<CAE2FW2ni76YGkeVRwncUOd7En+3+wUF6_7rR1XEEFLNfXdA94Q@mail.gmail.com>
	<CAGxFJbQyfObTUevxpRgiKNYMD-1qZ2JA6QPW+tTzpupebEDinA@mail.gmail.com>
	<CAE2FW2khVTusF7Ar8R5p6nmQjr02xT6Vi507T7kQ2zK11y3bJA@mail.gmail.com>
	<9CB3AF25-C124-47B4-8D75-D3F6E422F4CE@gmail.com>
	<CAE2FW2=YLiYVk+o8dURMGstm3iVb2+GY5cOpWksps3gCt48mDw@mail.gmail.com>
	<CAE2FW2=oET2B1XcyMKvqQX2jEJjpvntsw8B5VDvNVee42LCMbQ@mail.gmail.com>
Message-ID: <F6D32630-A7C7-4F85-A798-1D1F89C01373@gmail.com>


> On 12 Feb 2016, at 17:44 , C W <tmrsg11 at gmail.com> wrote:
> 
> On a side note, is it ok to do?
> 
> > which(max(p_x)) 
> and use that instead of numerical integration to get E[X]?

Now THAT makes absolutely no sense. max() is a number, so which(max()) usually returns 1.

If you mean whether the mode is equal to the mean: Only if the distribution is symmetric and unimodal.

-pd

> 
> I will try both and report back!  Thank you expeRts
> 
> On Fri, Feb 12, 2016 at 11:29 AM, C W <tmrsg11 at gmail.com> wrote:
> Hi Peter,
> 
> Great, let me try that and get back to you on my findings in a few hours!  :)
> 
> On Fri, Feb 12, 2016 at 11:09 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> I don't see here FAQ 7.31 comes in either (for once!...)
> 
> However, either the density is unnormalized and the integral is not 1, or the integral is 1 and it is normalized. The one in the picture clearly does not integrate to one. You can fit a rectangle of size 0.1 by 1e191 under the curve so the integral should be > 1e190 .
> 
> As depicted, I don't see why a plain integral from .5 to 1.5 shouldn't work.
> 
> -pd
> 
> On 12 Feb 2016, at 16:57 , C W <tmrsg11 at gmail.com> wrote:
> 
> > Hi Bert,
> >
> > Yay fantasyland!
> >
> > In all seriousness, You are referring to this?
> > https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
> >
> > In particular, you mean this: .Machine$double.eps ^ 0.5?
> >
> > Thanks!
> >
> > On Fri, Feb 12, 2016 at 10:53 AM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> >> You are working in fantasyland. Your density is nonsense.
> >>
> >> Please see FAQ 7.31 for links to computer precision of numeric
> >> calculations.
> >>
> >>
> >> Cheers,
> >> Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Fri, Feb 12, 2016 at 7:36 AM, C W <tmrsg11 at gmail.com> wrote:
> >>> Hi David,
> >>>
> >>> This is the Gaussian looking distribution I am trying to integrate.
> >>>
> >> https://drive.google.com/file/d/0B2xN0-A6iTB4NThIZ2tYdGxHc00/view?usp=sharing
> >>>
> >>> Notice the unnormalized density goes up as high as 2.5*101^191.
> >>>
> >>> I tried to create small intervals like
> >>>> seq(0.5, 1.3, by = 10^(-8))
> >>>
> >>> but that doesn't seem to be good enough, as we know, it should integrate
> >> to
> >>> 1.
> >>>
> >>> On Thu, Feb 11, 2016 at 3:32 PM, David Winsemius <dwinsemius at comcast.net
> >>>
> >>> wrote:
> >>>
> >>>>
> >>>>> On Feb 11, 2016, at 11:30 AM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>
> >>>>> Hi David,
> >>>>>
> >>>>> My real function is actually a multivariate normal, the simple toy 1-d
> >>>> normal won't work.
> >>>>>
> >>>>> But, you gave me an idea about restricting the bounds, and focus
> >>>> integrating on that.  I will get back to you if I need any further
> >>>> assistance.
> >>>>
> >>>> You'll probably need to restrict your bounds even more severely than I
> >> did
> >>>> in the 1-d case (using 10 SD's on either side of the mean) . You might
> >> need
> >>>> adequate representation of points near the center of your
> >> hyper-rectangles.
> >>>> At least that's my armchair notion since I expect the densities tail off
> >>>> rapidly in the corners. You can shoehorn multivariate integration around
> >>>> the `integrate` function but it's messy and inefficient. There are other
> >>>> packages that would be better choices. There's an entire section on
> >>>> numerical differentiation and integration in CRAN Task View: Numerical
> >>>> Mathematics.
> >>>>
> >>>> --
> >>>> David.
> >>>>
> >>>>
> >>>>>
> >>>>> Thank you so much!
> >>>>>
> >>>>> On Thu, Feb 11, 2016 at 2:06 PM, David Winsemius <
> >> dwinsemius at comcast.net>
> >>>> wrote:
> >>>>>
> >>>>>> On Feb 11, 2016, at 9:20 AM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>>
> >>>>>> I want to do numerical integration w.r.t. mu: P(mu) ? N(mu, 0.00001)
> >>>>>>
> >>>>>> Because the variance is small, it results in density like:
> >> 7.978846e+94
> >>>>>>
> >>>>>> Is there any good suggestion for this?
> >>>>>
> >>>>> So what's the difficulty? It's rather like the Dirac function.
> >>>>>
> >>>>>> integrate( function(x) dnorm(x, sd=0.00001), -.0001,0.0001)
> >>>>> 1 with absolute error < 7.4e-05
> >>>>>
> >>>>>
> >>>>> --
> >>>>> David.
> >>>>>
> >>>>>>
> >>>>>> Thanks so much!
> >>>>>>
> >>>>>>
> >>>>>> On Thu, Feb 11, 2016 at 9:14 AM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>>
> >>>>>>> Wow, thank you, that was very clear.  Let me give it some more runs
> >>>> and
> >>>>>>> investigate this.
> >>>>>>>
> >>>>>>> On Thu, Feb 11, 2016 at 12:31 AM, William Dunlap <
> >> wdunlap at tibco.com>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> Most of the mass of that distribution is within 3e-100 of 2.
> >>>>>>>> You have to be pretty lucky to have a point in sequence
> >>>>>>>> land there.  (You will get at most one point there because
> >>>>>>>> the difference between 2 and its nearest neightbors is on
> >>>>>>>> the order of 1e-16.)
> >>>>>>>>
> >>>>>>>> seq(-2,4,len=101), as used by default in curve, does include 2
> >>>>>>>> but seq(-3,4,len=101) and seq(-2,4,len=100) do not so
> >>>>>>>> curve(..., -3, 4, 101) and curve(..., -2, 4, 100) will not show
> >> the
> >>>> bump.
> >>>>>>>> The same principal holds for numerical integration.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Bill Dunlap
> >>>>>>>> TIBCO Software
> >>>>>>>> wdunlap tibco.com
> >>>>>>>>
> >>>>>>>> On Wed, Feb 10, 2016 at 6:37 PM, C W <tmrsg11 at gmail.com> wrote:
> >>>>>>>>
> >>>>>>>>> Dear R,
> >>>>>>>>>
> >>>>>>>>> I am graphing the following normal density curve.  Why does it
> >> look
> >>>> so
> >>>>>>>>> different?
> >>>>>>>>>
> >>>>>>>>> # the curves
> >>>>>>>>> x <- seq(-2, 4, by=0.00001)
> >>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -4, 4)  #right answer
> >>>>>>>>> curve(dnorm(x, 2, 10^(-100)), -3, 4)  #changed -4 to -3, I get
> >> wrong
> >>>>>>>>> answer
> >>>>>>>>>
> >>>>>>>>> Why the second curve is flat?  I just changed it from -4 to -3.
> >>>> There is
> >>>>>>>>> no density in that region.
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> Also, I am doing numerical integration.  Why are they so
> >> different?
> >>>>>>>>>
> >>>>>>>>>> x <- seq(-2, 4, by=0.00001)
> >>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>>>>>>> [1] 7.978846e+94
> >>>>>>>>>> x <- seq(-1, 4, by=0.00001) #changed -2 to -1
> >>>>>>>>>> sum(x*dnorm(x, 2, 10^(-100)))*0.00001
> >>>>>>>>> [1] 0
> >>>>>>>>>
> >>>>>>>>> What is going here?  What a I doing wrong?
> >>>>>>>>>
> >>>>>>>>> Thanks so much!
> >>>>>>>>>
> >>>>>>>>>       [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> see
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >> code.
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>>      [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>> David Winsemius
> >>>>> Alameda, CA, USA
> >>>>>
> >>>>>
> >>>>
> >>>> David Winsemius
> >>>> Alameda, CA, USA
> >>>>
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Fri Feb 12 22:29:45 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 13 Feb 2016 10:29:45 +1300
Subject: [R] Separating point symbols and line types in a legend.
In-Reply-To: <CAFEqCdyXMk090ARiZ_4rPUYpFx7nFhBfQBBfJrSmEH-X7FijJQ@mail.gmail.com>
References: <56BD6520.20909@auckland.ac.nz>
	<CAFEqCdyXMk090ARiZ_4rPUYpFx7nFhBfQBBfJrSmEH-X7FijJQ@mail.gmail.com>
Message-ID: <56BE4EC9.6030803@auckland.ac.nz>


Thanks Greg.  Worked perfectly!!!

cheers,

Rolf

On 13/02/16 09:22, Greg Snow wrote:
> One option is to call `legend` twice and do some manual positioning.
> This worked for me:
>
> plot(1:10)
> legend('topleft', lty=1:3, bty="n", legend=c('','','') )
> legend('topleft', pch=c(20,8,1), bty="n",
> legend=c('clyde','irving','melvin'), inset=c(0.1,0))
>
> You may need to fiddle with the amount of inset for your particular
> plot and device combination.
>
>
>
> On Thu, Feb 11, 2016 at 9:52 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> I would like to have a legend given in the manner
>>
>> legend("topleft",pch=c(20,8,1),lty=1:3,bty="n",
>>         legend=c("clyde","irving","melvin"))
>>
>> but with the point symbol *NOT* being superimposed on the line segments that
>> are plotted.
>>
>> I saw that I can specify "merge=FALSE" in the call to legend() but this
>> gives results like unto
>>
>>     ----* irving
>>
>> with the plot symbol being immediately juxtaposed to the plotted line
>> segment.  I would like a space between them, like so:
>>
>>     ---- * irving
>>
>> (See the difference?)
>>
>> I can see no arguments to legend that allow me to effect this.  I can adjust
>> positioning of the legend text, but not of the plotted point character or
>> line segment.  Is there any way to effect the desired result?  Or is there a
>> "simple" adjustment that one could make to the code for legend() that would
>> allow me to accomplish what I want?
>>
>> Ta.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Fri Feb 12 22:43:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 13 Feb 2016 08:43:07 +1100
Subject: [R] why is 9 after 10?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F57021@FHSDB2D11-2.csu.mcmaster.ca>
References: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>
	<ACD1644AA6C67E4FBD0C350625508EC810F56FF2@FHSDB2D11-2.csu.mcmaster.ca>
	<FCC1FD59-0308-46F6-88D9-7DE584E07C30@helsinki.fi>
	<ACD1644AA6C67E4FBD0C350625508EC810F57021@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CA+8X3fUf_4cQcZ4gUKgf2vicCf916xdfQqJkUNykvL01tGGerg@mail.gmail.com>

It depends upon what goes into the "data reshaping pipeline". If there is a
single non-numeric value in the data read in, it will alpha sort it upon
conversion to a factor:

x<-factor(c(sample(6:37,1000,TRUE)," "))
z<-factor(x)
levels(z)
 [1] " "  "10" "11" "12" "13" "14" "15" "16" "17" "18" "19" "20" "21" "22"
"23"
[16] "24" "25" "26" "27" "28" "29" "30" "31" "32" "33" "34" "35" "36" "37"
"6"
[31] "7"  "8"  "9"

Jim


On Sat, Feb 13, 2016 at 2:41 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Federico,
>
> > -----Original Message-----
> > From: Federico Calboli [mailto:federico.calboli at helsinki.fi]
> > Sent: February 12, 2016 10:27 AM
> > To: Fox, John <jfox at mcmaster.ca>
> > Cc: R Help <r-help at r-project.org>
> > Subject: Re: [R] why is 9 after 10?
> >
> > Dear John,
> >
> > that is fortunatey not the case, I just managed to figure out that the
> problem
> > was that in the data reshaping pipeline the numeric column was
> transformed
> > into a factor.
>
> But that shouldn't have this effect, I think:
>
> > z <- as.factor(x)
> > table(z)
> z
>  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
> 31 32 33 34 35 36 37
> 29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23
> 32 35 39 31 40 35 29
>
> > levels(z)
>  [1] "6"  "7"  "8"  "9"  "10" "11" "12" "13" "14" "15" "16" "17" "18" "19"
> "20" "21" "22" "23" "24" "25" "26" "27" "28" "29" "30" "31"
> [27] "32" "33" "34" "35" "36" "37"
>
> Best,
>  John
>
> >
> > Many thanks for your time.
> >
> > BW
> >
> > F
> >
> >
> >
> > > On 12 Feb 2016, at 17:22, Fox, John <jfox at mcmaster.ca> wrote:
> > >
> > > Dear Federico,
> > >
> > > Might my.data[, 2] contain character data, which therefore would be
> > sorted in this manner? For example:
> > >
> > >> x <- sample(6:37, 1000, replace=TRUE)
> > >> table(x)
> > > x
> > > 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
> > > 30 31 32 33 34 35 36 37
> > > 29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31
> > > 34 23 32 35 39 31 40 35 29
> > >> y <- as.character(x)
> > >> table(y)
> > > y
> > > 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
> > > 33 34 35 36 37  6  7  8  9
> > > 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35
> > > 39 31 40 35 29 29 30 35 29
> > >
> > > I hope this helps,
> > > John
> > >
> > > -----------------------------
> > > John Fox, Professor
> > > McMaster University
> > > Hamilton, Ontario
> > > Canada L8S 4M4
> > > Web: socserv.mcmaster.ca/jfox
> > >
> > >
> > >
> > >
> > >> -----Original Message-----
> > >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > >> Federico Calboli
> > >> Sent: February 12, 2016 10:13 AM
> > >> To: R Help <r-help at r-project.org>
> > >> Subject: [R] why is 9 after 10?
> > >>
> > >> Hi All,
> > >>
> > >> I have some data, one of the columns is a bunch of numbers from 6 to
> 41.
> > >>
> > >> table(my.data[,2])
> > >>
> > >> returns
> > >>
> > >>  10   11   12   13   14   15   16   17   18   19   20   21   22   23
>  24   25   26   27   28
> > 29
> > >> 30   31   32   33   34   35   36   37
> > >> 1761 1782 1897 1749 1907 1797 1734 1810 1913 1988 1914 1822 1951 1973
> > >> 1951
> > >> 1947 2067 1967 1812 2119 1999 2086 2133 2081 2165 2365 2330 2340
> > >>  38   39   40   41    6    7    8    9
> > >> 2681 2905 3399 3941 1648 1690 1727 1668
> > >>
> > >> whereas the reasonable expectation is that the numbers from 6 to 9
> > >> would come before 10 to 41.
> > >>
> > >> How do I sort this incredibly silly behaviour so that my table
> > >> follows a reasonable expectation that 9 comes before 10 (and so on and
> > so forth)?
> > >>
> > >> BW
> > >>
> > >> F
> > >>
> > >> --
> > >> Federico Calboli
> > >> Ecological Genetics Research Unit
> > >> Department of Biosciences
> > >> PO Box 65 (Biocenter 3, Viikinkaari 1)
> > >> FIN-00014 University of Helsinki
> > >> Finland
> > >>
> > >> federico.calboli at helsinki.fi
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >> guide.html and provide commented, minimal, self-contained,
> > >> reproducible code.
> >
> > --
> > Federico Calboli
> > Ecological Genetics Research Unit
> > Department of Biosciences
> > PO Box 65 (Biocenter 3, Viikinkaari 1)
> > FIN-00014 University of Helsinki
> > Finland
> >
> > federico.calboli at helsinki.fi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Feb 12 23:10:13 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Feb 2016 23:10:13 +0100
Subject: [R] why is 9 after 10?
In-Reply-To: <CA+8X3fUf_4cQcZ4gUKgf2vicCf916xdfQqJkUNykvL01tGGerg@mail.gmail.com>
References: <32C716EC-F19D-45E2-B06A-3B94EFBECDA7@helsinki.fi>
	<ACD1644AA6C67E4FBD0C350625508EC810F56FF2@FHSDB2D11-2.csu.mcmaster.ca>
	<FCC1FD59-0308-46F6-88D9-7DE584E07C30@helsinki.fi>
	<ACD1644AA6C67E4FBD0C350625508EC810F57021@FHSDB2D11-2.csu.mcmaster.ca>
	<CA+8X3fUf_4cQcZ4gUKgf2vicCf916xdfQqJkUNykvL01tGGerg@mail.gmail.com>
Message-ID: <5AF78D77-6095-45F4-BB06-887687266D7B@gmail.com>

It can also happen if you use colClasses, since that applies as.factor to the input column without first converting it to numeric. To wit:

> read.table(text="
+ 9
+ 10", colClasses="factor")$V1
[1] 9  10
Levels: 10 9

-pd

> On 12 Feb 2016, at 22:43 , Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> It depends upon what goes into the "data reshaping pipeline". If there is a
> single non-numeric value in the data read in, it will alpha sort it upon
> conversion to a factor:
> 
> x<-factor(c(sample(6:37,1000,TRUE)," "))
> z<-factor(x)
> levels(z)
> [1] " "  "10" "11" "12" "13" "14" "15" "16" "17" "18" "19" "20" "21" "22"
> "23"
> [16] "24" "25" "26" "27" "28" "29" "30" "31" "32" "33" "34" "35" "36" "37"
> "6"
> [31] "7"  "8"  "9"
> 
> Jim
> 
> 
> On Sat, Feb 13, 2016 at 2:41 AM, Fox, John <jfox at mcmaster.ca> wrote:
> 
>> Dear Federico,
>> 
>>> -----Original Message-----
>>> From: Federico Calboli [mailto:federico.calboli at helsinki.fi]
>>> Sent: February 12, 2016 10:27 AM
>>> To: Fox, John <jfox at mcmaster.ca>
>>> Cc: R Help <r-help at r-project.org>
>>> Subject: Re: [R] why is 9 after 10?
>>> 
>>> Dear John,
>>> 
>>> that is fortunatey not the case, I just managed to figure out that the
>> problem
>>> was that in the data reshaping pipeline the numeric column was
>> transformed
>>> into a factor.
>> 
>> But that shouldn't have this effect, I think:
>> 
>>> z <- as.factor(x)
>>> table(z)
>> z
>> 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
>> 31 32 33 34 35 36 37
>> 29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23
>> 32 35 39 31 40 35 29
>> 
>>> levels(z)
>> [1] "6"  "7"  "8"  "9"  "10" "11" "12" "13" "14" "15" "16" "17" "18" "19"
>> "20" "21" "22" "23" "24" "25" "26" "27" "28" "29" "30" "31"
>> [27] "32" "33" "34" "35" "36" "37"
>> 
>> Best,
>> John
>> 
>>> 
>>> Many thanks for your time.
>>> 
>>> BW
>>> 
>>> F
>>> 
>>> 
>>> 
>>>> On 12 Feb 2016, at 17:22, Fox, John <jfox at mcmaster.ca> wrote:
>>>> 
>>>> Dear Federico,
>>>> 
>>>> Might my.data[, 2] contain character data, which therefore would be
>>> sorted in this manner? For example:
>>>> 
>>>>> x <- sample(6:37, 1000, replace=TRUE)
>>>>> table(x)
>>>> x
>>>> 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
>>>> 30 31 32 33 34 35 36 37
>>>> 29 30 35 29 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31
>>>> 34 23 32 35 39 31 40 35 29
>>>>> y <- as.character(x)
>>>>> table(y)
>>>> y
>>>> 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
>>>> 33 34 35 36 37  6  7  8  9
>>>> 41 33 27 21 38 36 34 35 31 29 27 26 28 22 21 34 32 33 31 34 23 32 35
>>>> 39 31 40 35 29 29 30 35 29
>>>> 
>>>> I hope this helps,
>>>> John
>>>> 
>>>> -----------------------------
>>>> John Fox, Professor
>>>> McMaster University
>>>> Hamilton, Ontario
>>>> Canada L8S 4M4
>>>> Web: socserv.mcmaster.ca/jfox
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>> Federico Calboli
>>>>> Sent: February 12, 2016 10:13 AM
>>>>> To: R Help <r-help at r-project.org>
>>>>> Subject: [R] why is 9 after 10?
>>>>> 
>>>>> Hi All,
>>>>> 
>>>>> I have some data, one of the columns is a bunch of numbers from 6 to
>> 41.
>>>>> 
>>>>> table(my.data[,2])
>>>>> 
>>>>> returns
>>>>> 
>>>>> 10   11   12   13   14   15   16   17   18   19   20   21   22   23
>> 24   25   26   27   28
>>> 29
>>>>> 30   31   32   33   34   35   36   37
>>>>> 1761 1782 1897 1749 1907 1797 1734 1810 1913 1988 1914 1822 1951 1973
>>>>> 1951
>>>>> 1947 2067 1967 1812 2119 1999 2086 2133 2081 2165 2365 2330 2340
>>>>> 38   39   40   41    6    7    8    9
>>>>> 2681 2905 3399 3941 1648 1690 1727 1668
>>>>> 
>>>>> whereas the reasonable expectation is that the numbers from 6 to 9
>>>>> would come before 10 to 41.
>>>>> 
>>>>> How do I sort this incredibly silly behaviour so that my table
>>>>> follows a reasonable expectation that 9 comes before 10 (and so on and
>>> so forth)?
>>>>> 
>>>>> BW
>>>>> 
>>>>> F
>>>>> 
>>>>> --
>>>>> Federico Calboli
>>>>> Ecological Genetics Research Unit
>>>>> Department of Biosciences
>>>>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>>>>> FIN-00014 University of Helsinki
>>>>> Finland
>>>>> 
>>>>> federico.calboli at helsinki.fi
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>>> guide.html and provide commented, minimal, self-contained,
>>>>> reproducible code.
>>> 
>>> --
>>> Federico Calboli
>>> Ecological Genetics Research Unit
>>> Department of Biosciences
>>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>>> FIN-00014 University of Helsinki
>>> Finland
>>> 
>>> federico.calboli at helsinki.fi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sewashm at gmail.com  Sat Feb 13 05:04:44 2016
From: sewashm at gmail.com (Ashta)
Date: Fri, 12 Feb 2016 22:04:44 -0600
Subject: [R] Matrix summary
Message-ID: <CADDFq33FTruqc0nkGahp=RhzOnnZqN5kFXeBoNFnQOvbY5G5yQ@mail.gmail.com>

hi all,

I have  a square matrix (1000 by 1000),
1. I want calculate  mean,  min and max values for each column and row.

2, I want pick the  coordinate value of the matrix that has the max
and min value for each row and column.
This an example 4 by 4 square matrix


                                              Mean    Min    Max
            117   12    13     21    40.75       12    117
             21    32    11       1     16.25       1       32
             65    43    23       7      34.5        7       65
             58    61    78     95        73        58      95
Mean    65    25    37   31.25
Min        21    12    11    1
Max     117    61    78    95


Thank you


From drjimlemon at gmail.com  Sat Feb 13 06:15:20 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 13 Feb 2016 16:15:20 +1100
Subject: [R] Matrix summary
In-Reply-To: <CADDFq33FTruqc0nkGahp=RhzOnnZqN5kFXeBoNFnQOvbY5G5yQ@mail.gmail.com>
References: <CADDFq33FTruqc0nkGahp=RhzOnnZqN5kFXeBoNFnQOvbY5G5yQ@mail.gmail.com>
Message-ID: <CA+8X3fUL+8uM+_r+Q0s3G00mAPN4_y8GsxbyoXFju13PqZDK-Q@mail.gmail.com>

Hi Ashta,
Surely you are aware of the "apply" family of functions that return the
numbers you want:

ashmat<-matrix(c(117,12,13,21,21,32,11,1,65,43,23,7,58,61,78,95 ),
 nrow=4,byrow=TRUE)
apply(ashmat,2,mean)
[1] 65.25 37.00 31.25 31.00
apply(ashmat,1,which.max)
[1] 1 2 1 4

Jim


On Sat, Feb 13, 2016 at 3:04 PM, Ashta <sewashm at gmail.com> wrote:

> hi all,
>
> I have  a square matrix (1000 by 1000),
> 1. I want calculate  mean,  min and max values for each column and row.
>
> 2, I want pick the  coordinate value of the matrix that has the max
> and min value for each row and column.
> This an example 4 by 4 square matrix
>
>
>                                               Mean    Min    Max
>             117   12    13     21    40.75       12    117
>              21    32    11       1     16.25       1       32
>              65    43    23       7      34.5        7       65
>              58    61    78     95        73        58      95
> Mean    65    25    37   31.25
> Min        21    12    11    1
> Max     117    61    78    95
>
>
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Feb 13 06:35:24 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Feb 2016 21:35:24 -0800
Subject: [R] Matrix summary
In-Reply-To: <CA+8X3fUL+8uM+_r+Q0s3G00mAPN4_y8GsxbyoXFju13PqZDK-Q@mail.gmail.com>
References: <CADDFq33FTruqc0nkGahp=RhzOnnZqN5kFXeBoNFnQOvbY5G5yQ@mail.gmail.com>
	<CA+8X3fUL+8uM+_r+Q0s3G00mAPN4_y8GsxbyoXFju13PqZDK-Q@mail.gmail.com>
Message-ID: <CAGxFJbR94azojvQDKEq2R5bSCKuKz_zO2y3nuPX4B0p1aw6TJw@mail.gmail.com>

Yes, but colMeans, rowMeans, pmax, pmin , etc. are *much* faster.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 12, 2016 at 9:15 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Ashta,
> Surely you are aware of the "apply" family of functions that return the
> numbers you want:
>
> ashmat<-matrix(c(117,12,13,21,21,32,11,1,65,43,23,7,58,61,78,95 ),
>  nrow=4,byrow=TRUE)
> apply(ashmat,2,mean)
> [1] 65.25 37.00 31.25 31.00
> apply(ashmat,1,which.max)
> [1] 1 2 1 4
>
> Jim
>
>
> On Sat, Feb 13, 2016 at 3:04 PM, Ashta <sewashm at gmail.com> wrote:
>
>> hi all,
>>
>> I have  a square matrix (1000 by 1000),
>> 1. I want calculate  mean,  min and max values for each column and row.
>>
>> 2, I want pick the  coordinate value of the matrix that has the max
>> and min value for each row and column.
>> This an example 4 by 4 square matrix
>>
>>
>>                                               Mean    Min    Max
>>             117   12    13     21    40.75       12    117
>>              21    32    11       1     16.25       1       32
>>              65    43    23       7      34.5        7       65
>>              58    61    78     95        73        58      95
>> Mean    65    25    37   31.25
>> Min        21    12    11    1
>> Max     117    61    78    95
>>
>>
>> Thank you
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Thomas.Lofaro at SurveySampling.com  Fri Feb 12 19:12:37 2016
From: Thomas.Lofaro at SurveySampling.com (Thomas Lofaro)
Date: Fri, 12 Feb 2016 18:12:37 +0000
Subject: [R] FW: Multivariate ARIMA Question....
In-Reply-To: <faee8beaa07456593715bd45efa9996d@sanger.ac.uk>
References: <BN4PR07MB22106BCC12B2E9B185A5DF4E93A80@BN4PR07MB2210.namprd07.prod.outlook.com>
	<faee8beaa07456593715bd45efa9996d@sanger.ac.uk>
Message-ID: <BN4PR07MB22103CC8EB3FF13CCDF00D4D93A90@BN4PR07MB2210.namprd07.prod.outlook.com>

Hi, sorry, I will try to make this short. Essentially, what I am trying to do is run a multivariate ARIMA model predicting one variable with another.  However, the only R packages I have found to accommodate such an analysis are ARIMAX and VAR.  Unfortunately, there don?t seem to be any good tutorials or demonstrations of how to actually perform this analysis in practice, on my two columns of data.  I was wondering if anyone knew of a resource that might help (or one that provided an example of r code to accomplish this).  Thanks sooo much!



	[[alternative HTML version deleted]]


From h_bukhaiti at hnu.edu.cn  Sat Feb 13 06:34:27 2016
From: h_bukhaiti at hnu.edu.cn (ALBUKHAITI HESHAM)
Date: Sat, 13 Feb 2016 13:34:27 +0800 (GMT+08:00)
Subject: [R] View() function
Message-ID: <1c0f0c2.2cc0f.152d91f8319.Coremail.h_bukhaiti@hnu.edu.cn>

i am try to show the rows name in r by View() function but i cannot ,return only numbers of columns  , but when i use NameData[,1] ,, no problem ,i can get it.
i do not no where is the problem ,
becouse some file in text i downloaded it form internet doesn't have problem.
>>>>>>>>>>>>>>>>
also when i want to read my data as text , R return this message >
mydata<-read.table("mirnat.txt", header=T,row.names = 1)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : line 1 did not have 62 elements.
please help , thanks


From mohsenhs82 at yahoo.com  Sat Feb 13 09:45:02 2016
From: mohsenhs82 at yahoo.com (mohsen hs)
Date: Sat, 13 Feb 2016 08:45:02 +0000 (UTC)
Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
 censoring
References: <1728178712.2866868.1455353102254.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1728178712.2866868.1455353102254.JavaMail.yahoo@mail.yahoo.com>

Dear all,
I appreciate that if you let me know if there is any package implemented in R for Estimating Mean of a Poisson Distribution Based on Interval censoring? And if yes, could you please provide some information about it:)?
By the way, is there anything for lognormal?I think fitdistcens is not good for this purpose as it gives me different result compared to SAS and only useful for right/left censoring and not interval censoring?(or both left and right together).?
Kind regards,Mohsen
	[[alternative HTML version deleted]]


From power.julian.chen at gmail.com  Fri Feb 12 19:57:56 2016
From: power.julian.chen at gmail.com (Julian Chen)
Date: Fri, 12 Feb 2016 13:57:56 -0500
Subject: [R] Random effects in GAMs
Message-ID: <CABch2GupkFU-5JmLd0d8NDXHzQf=DBq9fWy=hMdnO0GM4bt_Fg@mail.gmail.com>

I am now trying to use random effects in GAMs developed by Professor Simon
Wood. Prof Wood uses  s(...,bs="re") to account for the random effects.
Random intercepts models or random slopes models are two different types of
mixed linear models or general random effects model (Cameron and Trivedi,
2005). I wonder if the Wood's method includes both random intercepts and
random slopes. Based on my understanding, this method does? Anyone can help
me clarify this method? The following is the link of Random effects in GAM
developed by Prof Wood.

https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html

-- 
Life is nothing but a dream,
     and if we are artists,
then we can create our life with Love,
     and our dream becomes
       a masterpiece of art.

	[[alternative HTML version deleted]]


From shivi.bhatia at safexpress.com  Fri Feb 12 20:33:32 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Sat, 13 Feb 2016 01:03:32 +0530
Subject: [R] Error on Text Mining for WordCloud
Message-ID: <001f01d165cc$358d1ff0$a0a75fd0$@safexpress.com>

Dear Team, 

 

Please suggest on the below error while I am building a WordCloud on R for
one of user twitter account:

 

Error in UseMethod("TermDocumentMatrix", x) : 

  no applicable method for 'TermDocumentMatrix' applied to an object of
class "c('double', 'numeric')"

 

 

I have tried searching a lot on this issue however don't get much help. 

 

Used Tm package and corpus. Below are the expression below:

 

as.character(nwCorp1<- tm_map(corpuss1, removeNumbers))

as.character(nwCorp1<- tm_map(nwCorp1, removePunctuation))

as.character(nwCorp1<- tm_map(nwCorp1,PlainTextDocument))

as.character(nwCorp1<- tm_map(nwCorp1, removeWords,stopwords("english")))

as.character(nwCorp1<- tm_map(nwCorp1,stripWhitespace))

as.character(nwCorp1)

 

dtm11<- DocumentTermMatrix(nwCorp1)

dtm11

dtm12<- as.matrix(dtm11)

dtm12

frequency<- colSums(dtm12)

 

 

Thanks, Shivi

Mb: 9891002021

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160213/134d90da/attachment.pl>

From power.julian.chen at gmail.com  Sat Feb 13 00:27:04 2016
From: power.julian.chen at gmail.com (Julian Chen)
Date: Fri, 12 Feb 2016 18:27:04 -0500
Subject: [R] Random effects in GAMs
In-Reply-To: <CABch2GupkFU-5JmLd0d8NDXHzQf=DBq9fWy=hMdnO0GM4bt_Fg@mail.gmail.com>
References: <CABch2GupkFU-5JmLd0d8NDXHzQf=DBq9fWy=hMdnO0GM4bt_Fg@mail.gmail.com>
Message-ID: <CABch2Gs-o6XJ=rhdkqQyVNZHnmcmKx=UCy38gb1CVJKFvMU8wQ@mail.gmail.com>

I am now using random effects of GAM to predict crash frequency at
intersections. The family is negative binomial distribution. I wonder if
this term bs="re" developed by Prof Simon Wood can account for both random
intercepts and random slopes effects together?

It is longitudinal data. The number of crashes, traffic volume on major
roads and traffic volume on minor roads are observed repeatedly three years
for each different intersection as below.

crash main.traffic.volume minor.traffic.volume  ID
1 38122 2789 1
0 40216 2930 1
0 41231 3022 1
2 12890 3401 2
3 13241 3211 2
2 13568 3322 2
1 46889 5688 3
2 48232 5843 3
0 52301 6012 3
*... ...         ...         ...*

I wonder if my code below can account for both random intercepts and random
slopes effects together? or only random slopes effects? Any suggestions?
#########################################################################################
gam(crash~s(main.traffic.volume, ID, bs=?re")+s(minor.traffic.volume, ID,
bs="re"), family=nb(),data=mydata3sg)
#########################################################################################

Many thanks!

On Fri, Feb 12, 2016 at 1:57 PM, Julian Chen <power.julian.chen at gmail.com>
wrote:

> I am now trying to use random effects in GAMs developed by Professor Simon
> Wood. Prof Wood uses  s(...,bs="re") to account for the random effects.
> Random intercepts models or random slopes models are two different types of
> mixed linear models or general random effects model (Cameron and Trivedi,
> 2005). I wonder if the Wood's method includes both random intercepts and
> random slopes. Based on my understanding, this method does? Anyone can help
> me clarify this method? The following is the link of Random effects in GAM
> developed by Prof Wood.
>
> https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html
>
> --
> Life is nothing but a dream,
>      and if we are artists,
> then we can create our life with Love,
>      and our dream becomes
>        a masterpiece of art.
>



-- 
Life is nothing but a dream,
     and if we are artists,
then we can create our life with Love,
     and our dream becomes
       a masterpiece of art.

	[[alternative HTML version deleted]]


From legbadoc at gmail.com  Sat Feb 13 18:42:50 2016
From: legbadoc at gmail.com (papa legba)
Date: Sat, 13 Feb 2016 18:42:50 +0100
Subject: [R] =?utf-8?q?package_=E2=80=98xlsx=E2=80=99_is_not_available_=28?=
	=?utf-8?q?for_R_version_3=2E2=2E3=29?=
Message-ID: <CAB1ctbp9y94e0ozAyo4CM9yPSSsLLubWRVvKYp-+UzyCeDGGGQ@mail.gmail.com>

Hi,
Does anyone have any idea how to work around this ?
package ?xlsx? is not available (for R version 3.2.3)

To make xlsx work for 3.2.3 ?

Thanks

	[[alternative HTML version deleted]]


From hasan.diwan at gmail.com  Sat Feb 13 21:36:32 2016
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Sat, 13 Feb 2016 12:36:32 -0800
Subject: [R]
	=?utf-8?q?package_=E2=80=98xlsx=E2=80=99_is_not_available_=28?=
	=?utf-8?q?for_R_version_3=2E2=2E3=29?=
In-Reply-To: <CAB1ctbp9y94e0ozAyo4CM9yPSSsLLubWRVvKYp-+UzyCeDGGGQ@mail.gmail.com>
References: <CAB1ctbp9y94e0ozAyo4CM9yPSSsLLubWRVvKYp-+UzyCeDGGGQ@mail.gmail.com>
Message-ID: <CAP+bYWAP9CDBAf8Djf6MbEj=x+mHpubcJBv=e-W4RK-VdmVs0g@mail.gmail.com>

install.packages('xlsx', type='source', repos='http://cran.rstudio.com')
should sort you. -- H

On 13 February 2016 at 09:42, papa legba <legbadoc at gmail.com> wrote:

> Hi,
> Does anyone have any idea how to work around this ?
> package ?xlsx? is not available (for R version 3.2.3)
>
> To make xlsx work for 3.2.3 ?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
OpenPGP: http://hasan.d8u.us/gpg.asc
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Sat Feb 13 21:45:34 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sat, 13 Feb 2016 14:45:34 -0600
Subject: [R]
 =?utf-8?q?package_=E2=80=98xlsx=E2=80=99_is_not_available_=28?=
 =?utf-8?q?for_R_version_3=2E2=2E3=29?=
In-Reply-To: <CAP+bYWAP9CDBAf8Djf6MbEj=x+mHpubcJBv=e-W4RK-VdmVs0g@mail.gmail.com>
References: <CAB1ctbp9y94e0ozAyo4CM9yPSSsLLubWRVvKYp-+UzyCeDGGGQ@mail.gmail.com>
	<CAP+bYWAP9CDBAf8Djf6MbEj=x+mHpubcJBv=e-W4RK-VdmVs0g@mail.gmail.com>
Message-ID: <56BF95EE.90102@effectivedefense.org>

If you aren't happy with that, you might review other options:


library(sos)
 > (xlsx <- ???xlsx)
found 372 matches;  retrieving 19 pages
2 3 4 5 6 7 8 9 10
11 12 13 14 15 16 17 18 19
Downloaded 268 links in 58 packages.


       This opened a table in my default browser listing 268 help pages 
containing "xlsx", sorted to put first the package with the most matches.


 > findFn2xls(xlsx)


       This wrote a file "xlsx.xls" to the working directly, the first 
sheet of which gave a summary of the 58 packages containing at least one 
match.


       For years, I've used read.xls{gdata}.  That's number 8 on this 
list.  I don't know which is best.


       Spencer


On 2/13/2016 2:36 PM, Hasan Diwan wrote:
> install.packages('xlsx', type='source', repos='http://cran.rstudio.com')
> should sort you. -- H
>
> On 13 February 2016 at 09:42, papa legba <legbadoc at gmail.com> wrote:
>
>> Hi,
>> Does anyone have any idea how to work around this ?
>> package ?xlsx? is not available (for R version 3.2.3)
>>
>> To make xlsx work for 3.2.3 ?
>>
>> Thanks
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From divakarreddy.a at gmail.com  Sat Feb 13 21:32:25 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Sat, 13 Feb 2016 13:32:25 -0700
Subject: [R]
	=?utf-8?q?package_=E2=80=98xlsx=E2=80=99_is_not_available_=28?=
	=?utf-8?q?for_R_version_3=2E2=2E3=29?=
In-Reply-To: <CAB1ctbp9y94e0ozAyo4CM9yPSSsLLubWRVvKYp-+UzyCeDGGGQ@mail.gmail.com>
References: <CAB1ctbp9y94e0ozAyo4CM9yPSSsLLubWRVvKYp-+UzyCeDGGGQ@mail.gmail.com>
Message-ID: <CALEm3d0iew89XY3GFC6-w-TUpjemC0iB8_rYSoD2RNRc1JRSSQ@mail.gmail.com>

I installed 'xlsx' using below repo and din't see any issues.
install.packages("xlsx", repos = "http://cran.cnr.Berkeley.edu/")

> version
               _
platform       x86_64-redhat-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          2.3
year           2015
month          12
day            10
svn rev        69752
language       R
version.string R version 3.2.3 (2015-12-10)
nickname       Wooden Christmas-Tree

> packageVersion("xlsx")
[1] ?0.5.7?
>

Thanks,
Divakar


On Sat, Feb 13, 2016 at 10:42 AM, papa legba <legbadoc at gmail.com> wrote:

> Hi,
> Does anyone have any idea how to work around this ?
> package ?xlsx? is not available (for R version 3.2.3)
>
> To make xlsx work for 3.2.3 ?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Feb 14 03:59:00 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 13 Feb 2016 21:59:00 -0500
Subject: [R] Error on Text Mining for WordCloud
In-Reply-To: <001f01d165cc$358d1ff0$a0a75fd0$@safexpress.com>
References: <001f01d165cc$358d1ff0$a0a75fd0$@safexpress.com>
Message-ID: <3F745F0F-DCD5-4C7C-99A6-7C8B5D340651@utoronto.ca>

That looks to me like a rather basic misunderstanding of how R syntax works. You might want to have a look at the documentation of as.character(), and read about its return value. Then note that you are not assigning the return value to anything. 

To wit:

a <- 5
mode(a)

as.character(a)
mode(a) # simply calling as.character() does not change a!

a <- as.character(a)
mode(a)  # there we go.



B.

On Feb 12, 2016, at 2:33 PM, SHIVI BHATIA <shivi.bhatia at safexpress.com> wrote:

> Dear Team, 
> 
> 
> 
> Please suggest on the below error while I am building a WordCloud on R for
> one of user twitter account:
> 
> 
> 
> Error in UseMethod("TermDocumentMatrix", x) : 
> 
>  no applicable method for 'TermDocumentMatrix' applied to an object of
> class "c('double', 'numeric')"
> 
> 
> 
> 
> 
> I have tried searching a lot on this issue however don't get much help. 
> 
> 
> 
> Used Tm package and corpus. Below are the expression below:
> 
> 
> 
> as.character(nwCorp1<- tm_map(corpuss1, removeNumbers))
> 
> as.character(nwCorp1<- tm_map(nwCorp1, removePunctuation))
> 
> as.character(nwCorp1<- tm_map(nwCorp1,PlainTextDocument))
> 
> as.character(nwCorp1<- tm_map(nwCorp1, removeWords,stopwords("english")))
> 
> as.character(nwCorp1<- tm_map(nwCorp1,stripWhitespace))
> 
> as.character(nwCorp1)
> 
> 
> 
> dtm11<- DocumentTermMatrix(nwCorp1)
> 
> dtm11
> 
> dtm12<- as.matrix(dtm11)
> 
> dtm12
> 
> frequency<- colSums(dtm12)
> 
> 
> 
> 
> 
> Thanks, Shivi
> 
> Mb: 9891002021
> 
> 
> 
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun Feb 14 14:35:48 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 14 Feb 2016 05:35:48 -0800
Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
 censoring
In-Reply-To: <1728178712.2866868.1455353102254.JavaMail.yahoo@mail.yahoo.com>
References: <1728178712.2866868.1455353102254.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <500B1AFF78E.0000025Cjrkrideau@inbox.com>

> By the way, is there anything for lognormal?I think fitdistcens is not
> good for this purpose as it gives me different result compared to SAS 

The general assumption is that if Excel or any other spreadsheet gives a result that is different from R then R will be correct.

Generally with SAS it may be that R is correct or just that R and SAS use slightly different algorithms.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Sat, 13 Feb 2016 08:45:02 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
> censoring
> 
> Dear all,
> I appreciate that if you let me know if there is any package implemented
> in R for Estimating Mean of a Poisson Distribution Based on Interval
> censoring? And if yes, could you please provide some information about
> it:)
> By the way, is there anything for lognormal?I think fitdistcens is not
> good for this purpose as it gives me different result compared to SAS and
> only useful for right/left censoring and not interval censoring?(or both
> left and right together).
> Kind regards,Mohsen
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From pdalgd at gmail.com  Sun Feb 14 15:37:22 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 14 Feb 2016 15:37:22 +0100
Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
	censoring
In-Reply-To: <500B1AFF78E.0000025Cjrkrideau@inbox.com>
References: <1728178712.2866868.1455353102254.javamail.yahoo.ref@mail.yahoo.com>
	<500B1AFF78E.0000025Cjrkrideau@inbox.com>
Message-ID: <F0C7CCBA-701B-4BDA-A804-05C2BAC5ED16@gmail.com>

Fortune candidate :-)

However, the more scientific approach would be to ask for evidence to be scrutinized, acknowledging that R might be fallible, however unlikely that may seem.

Also, there is always the possibility that there are two answers because the question is not the same.

-pd

> On 14 Feb 2016, at 14:35 , John Kane <jrkrideau at inbox.com> wrote:
> 
>> By the way, is there anything for lognormal?I think fitdistcens is not
>> good for this purpose as it gives me different result compared to SAS 
> 
> The general assumption is that if Excel or any other spreadsheet gives a result that is different from R then R will be correct.
> 
> Generally with SAS it may be that R is correct or just that R and SAS use slightly different algorithms.
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: r-help at r-project.org
>> Sent: Sat, 13 Feb 2016 08:45:02 +0000 (UTC)
>> To: r-help at r-project.org
>> Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
>> censoring
>> 
>> Dear all,
>> I appreciate that if you let me know if there is any package implemented
>> in R for Estimating Mean of a Poisson Distribution Based on Interval
>> censoring? And if yes, could you please provide some information about
>> it:)
>> By the way, is there anything for lognormal?I think fitdistcens is not
>> good for this purpose as it gives me different result compared to SAS and
>> only useful for right/left censoring and not interval censoring (or both
>> left and right together).
>> Kind regards,Mohsen
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Sun Feb 14 15:40:45 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 14 Feb 2016 06:40:45 -0800
Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
 censoring
In-Reply-To: <F0C7CCBA-701B-4BDA-A804-05C2BAC5ED16@gmail.com>
References: <500b1aff78e.0000025cjrkrideau@inbox.com>
	<1728178712.2866868.1455353102254.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <509C41C1836.00000299jrkrideau@inbox.com>

Thank you, kind sir, you are correct but I was too rushed to write more as the bread needed to be taken out of the oven.  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: pdalgd at gmail.com
> Sent: Sun, 14 Feb 2016 15:37:22 +0100
> To: jrkrideau at inbox.com
> Subject: Re: [R] Estimating Mean of a Poisson Distribution Based on
> Interval censoring
> 
> Fortune candidate :-)
> 
> However, the more scientific approach would be to ask for evidence to be
> scrutinized, acknowledging that R might be fallible, however unlikely
> that may seem.
> 
> Also, there is always the possibility that there are two answers because
> the question is not the same.
> 
> -pd
> 
>> On 14 Feb 2016, at 14:35 , John Kane <jrkrideau at inbox.com> wrote:
>> 
>>> By the way, is there anything for lognormal?I think fitdistcens is not
>>> good for this purpose as it gives me different result compared to SAS
>> 
>> The general assumption is that if Excel or any other spreadsheet gives a
>> result that is different from R then R will be correct.
>> 
>> Generally with SAS it may be that R is correct or just that R and SAS
>> use slightly different algorithms.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: r-help at r-project.org
>>> Sent: Sat, 13 Feb 2016 08:45:02 +0000 (UTC)
>>> To: r-help at r-project.org
>>> Subject: [R] Estimating Mean of a Poisson Distribution Based on
>>> Interval
>>> censoring
>>> 
>>> Dear all,
>>> I appreciate that if you let me know if there is any package
>>> implemented
>>> in R for Estimating Mean of a Poisson Distribution Based on Interval
>>> censoring? And if yes, could you please provide some information about
>>> it:)
>>> By the way, is there anything for lognormal?I think fitdistcens is not
>>> good for this purpose as it gives me different result compared to SAS
>>> and
>>> only useful for right/left censoring and not interval censoring (or
>>> both
>>> left and right together).
>>> Kind regards,Mohsen
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From marammagdysalem at gmail.com  Sun Feb 14 18:22:03 2016
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 14 Feb 2016 19:22:03 +0200
Subject: [R] NaNs produced as a returned value for a function
Message-ID: <CAPLSCn3SwYmPr01g29OpNf8X1OgyUQNvWaH_YOyQ47x6fcfV6Q@mail.gmail.com>

Hi all,

I'm trying to write 2 functions(as a part of a larger code) to evaluate a
certain equation.  The function is :

X= c (0.3893094  2.0962311  2.6007558  3.0761810  3.3246947  3.3917976
 4.1981546  6.8826140 12.3128013 15.5588470)
R=c (0 1 0 0 0 1 1 1 0 1)

alpha.update=function(X, R, alpha.curr, beta.curr=1 ,m=10,
hyp=c(3,15,6,22.5))

  {

  o<-numeric(m)

     for (i in 1:m) {

       o[i]<- (1+R[i])*((X[i])^(beta.curr))

        }

   sh<-sum(o) + hyp[2] + (hyp[4]* beta.curr)

   rg<-rgamma(1, shape= m+hyp[1]+hyp[3] , rate = sh )

   return(rg)

   }


alpha.curr<- alpha.update(X, R, alpha.curr=0.2, beta.curr=1 ,m, hyp)


    bettarg<- function(X, R, alpha.curr, beta.curr=1 ,m=10,
hyp=c(3,15,6,22.5))

       {

           o<-numeric(m)

           for (i in 1:m) {

       o[i]<- (1+R[i])*((X[i])^( beta.curr))

        }

      logbt<- log(beta.curr ^(m+hyp[3]-1)) + log(prod((X)^( beta.curr -1)))
+ (-1*alpha.curr *(sum(o) +  (hyp[4]* beta.curr)))



      bt<- exp(logbt)

      return(bt)

       }


The problem is that the function bettarg() sometimes produces   NaN, and
this stops the evaluation of my equation, so how can I force it to ignore
the NaNs produced and repeat the evaluation again till it prroduces a
number?


Thanks in advance,


Maram Salem

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Feb 14 21:08:59 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 14 Feb 2016 12:08:59 -0800
Subject: [R] NaNs produced as a returned value for a function
In-Reply-To: <CAPLSCn3SwYmPr01g29OpNf8X1OgyUQNvWaH_YOyQ47x6fcfV6Q@mail.gmail.com>
References: <CAPLSCn3SwYmPr01g29OpNf8X1OgyUQNvWaH_YOyQ47x6fcfV6Q@mail.gmail.com>
Message-ID: <CAF8bMcbDUO4kTVos7O5orSLPTqxrXEJYGT=wT4nbKTjnc62wEw@mail.gmail.com>

You can do things like
   while ( !is.nan( r <- randomFunction(x) )) {}
   # r will be a non-NaN value of randomFunction(x) now
or
   for(i in seq_len(1000)) {
      if (!is.nan( r <- randomFunction(x))) {
          break
      }
      if (i == 1000) {
          stop("no good values of randomFunction(x) in 1000 tries")
      }
   }
to avoid infinite loops when randomFunction [almost] always produces a NaN.

You may  be able to avoid some NaNs by replacing log(b^n) with n*log(b) and
log(prod(x^b)) with sum(b*log(x)).  That would avoid unneeded Inf values,
which
can lead to NaN down the line (Inf-Inf -> NaN, Inf/Inf -> NaN).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Feb 14, 2016 at 9:22 AM, Maram SAlem <marammagdysalem at gmail.com>
wrote:

> Hi all,
>
> I'm trying to write 2 functions(as a part of a larger code) to evaluate a
> certain equation.  The function is :
>
> X= c (0.3893094  2.0962311  2.6007558  3.0761810  3.3246947  3.3917976
>  4.1981546  6.8826140 12.3128013 15.5588470)
> R=c (0 1 0 0 0 1 1 1 0 1)
>
> alpha.update=function(X, R, alpha.curr, beta.curr=1 ,m=10,
> hyp=c(3,15,6,22.5))
>
>   {
>
>   o<-numeric(m)
>
>      for (i in 1:m) {
>
>        o[i]<- (1+R[i])*((X[i])^(beta.curr))
>
>         }
>
>    sh<-sum(o) + hyp[2] + (hyp[4]* beta.curr)
>
>    rg<-rgamma(1, shape= m+hyp[1]+hyp[3] , rate = sh )
>
>    return(rg)
>
>    }
>
>
> alpha.curr<- alpha.update(X, R, alpha.curr=0.2, beta.curr=1 ,m, hyp)
>
>
>     bettarg<- function(X, R, alpha.curr, beta.curr=1 ,m=10,
> hyp=c(3,15,6,22.5))
>
>        {
>
>            o<-numeric(m)
>
>            for (i in 1:m) {
>
>        o[i]<- (1+R[i])*((X[i])^( beta.curr))
>
>         }
>
>       logbt<- log(beta.curr ^(m+hyp[3]-1)) + log(prod((X)^( beta.curr -1)))
> + (-1*alpha.curr *(sum(o) +  (hyp[4]* beta.curr)))
>
>
>
>       bt<- exp(logbt)
>
>       return(bt)
>
>        }
>
>
> The problem is that the function bettarg() sometimes produces   NaN, and
> this stops the evaluation of my equation, so how can I force it to ignore
> the NaNs produced and repeat the evaluation again till it prroduces a
> number?
>
>
> Thanks in advance,
>
>
> Maram Salem
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Sun Feb 14 22:46:04 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Sun, 14 Feb 2016 21:46:04 +0000
Subject: [R] Error on Text Mining for WordCloud
In-Reply-To: <001f01d165cc$358d1ff0$a0a75fd0$@safexpress.com>
References: <001f01d165cc$358d1ff0$a0a75fd0$@safexpress.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D0D4AD7C@GBTEDVPEXCMB04.corp.lgc-group.com>

No specific experience of the package you are using, but you have 

> as.character(nwCorp1)
This does nothing to nwCorp1; it just returns a character version of it to the console. If it was not the right kind of object you can expect later commands to throw errors.
Perhaps you meant
nwCorp1 <-  as.character(nwCorp1)   ?

S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From greenapp2012 at gmail.com  Sun Feb 14 22:40:38 2016
From: greenapp2012 at gmail.com (lululu)
Date: Sun, 14 Feb 2016 16:40:38 -0500
Subject: [R] How to run a hierarchical bayes model using runiregGibbs
Message-ID: <CAJk7HGWFyeP-rT-ZC8X+EFPUVtO7tCZyJRyg3GcOWU9pKjecgQ@mail.gmail.com>

I want to run a hierarchical Bayes regression model using this runiregGibbs
function. My data is like the following:

      y  userid  Proximity   Time    Knowledge     Test     Purchase
Service1     8     1      4        2        2          1        32
7     1      2        2        2          2        23     9     2
1        4        2          1        34     7     2      2        1
     2          1        1

My X are the six attributes plus the userid listed above. They are
categorical variables. Each has 4 possible levels represented by number 1
to 4.

I have created the following code:

   y = c$Buy
   x = c[,4:10] #corresponding to the 7 X listed above
   df = list(y=y,X=x)
   R = 10000
   mcmc1 = list(R = R)
   try1 = runiregGibbs(df, Mcmc = mcmc1)

but it is giving me error saying

 Error: not compatible with requested type

I don't know how could this function be a hierarchical bayseian model. I
did not see the hierarchy. We are supposed to get both individual level
estimate and aggregate estimate. But I don't know how this can be achieved.
Am I supposed to use this function for each individual or just specify the
aggregate model is fine?

Also, I am not sure how to specify the MCMC chain. Is it sufficient to use
just specify the number of R and is there a general guideline in terms of
determining the suitable number of R?

I am new to Bayseian and I am confused about the basics. Would sincerely
appreciate if anyone could help. From google search, there is not much
about how to use this function and there is always only one example
provided which is also not very illuminating.

	[[alternative HTML version deleted]]


From heathermichel at rocketmail.com  Sun Feb 14 20:40:22 2016
From: heathermichel at rocketmail.com (HEATHER MICHEL)
Date: Sun, 14 Feb 2016 19:40:22 +0000 (UTC)
Subject: [R] R 3.2.3 on Win8;  mkdir command produces error
References: <879632620.1043610.1455478822248.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <879632620.1043610.1455478822248.JavaMail.yahoo@mail.yahoo.com>

I am trying to complete a homework assignment, but I know very little about R.The assignment says, "For this programming assignment you will need to unzip this file and create the directory 'specdata".I unzipped the file on my desktop, and my computer automatically created a new folder which I renamed "specdata."However, when I try to make this directory within R using mkdir, I get this:
> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo documentation for ?mkdir? in specified packages and libraries:you could try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found

This makes me believe that some of the old command names have been updated in this version that is only 2 months old. Of course, the lectures I took notes on used an older version of R and were created more than 2 months ago.
Please tell me the command I should be using to create a directory named 'specdata' in R 3.2.3
Heather Michel
	[[alternative HTML version deleted]]


From mohsenhs82 at yahoo.com  Sun Feb 14 20:48:37 2016
From: mohsenhs82 at yahoo.com (mohsen hs)
Date: Sun, 14 Feb 2016 19:48:37 +0000 (UTC)
Subject: [R] Estimating Mean of a Poisson Distribution Based on Interval
 censoring
In-Reply-To: <509C41C1836.00000299jrkrideau@inbox.com>
References: <500b1aff78e.0000025cjrkrideau@inbox.com>
	<1728178712.2866868.1455353102254.javamail.yahoo.ref@mail.yahoo.com>
	<F0C7CCBA-701B-4BDA-A804-05C2BAC5ED16@gmail.com>
	<509C41C1836.00000299jrkrideau@inbox.com>
Message-ID: <178984942.3246222.1455479317836.JavaMail.yahoo@mail.yahoo.com>

Hi John and Peter,
Thanks for your reply. I found that fitdistcens, is a good approach. I did that for lognormal,?exp?,and other?distributions. Values for lnorm?from SAS and R were close, but slightly different.?At the moment, my main concern is finding the estimated lambda value for?poisson?for the interval censored data, and it seems there is a problem somewhere and I really appreciate your support.Error:"Error in optim(par =?vstart,?fn?=?fnobjcens, fix.arg?= fix.arg,?rcens?=?rcens,??:?\n ?initial value in 'vmmin' is not finite\n"?
Kind regards,Mohsen
Background about my data and code:

I have to say I do not have any idea,?
> max(z)?
[1] 39011?
> min(z)?
[1] 1?
>?
I am using ?library(fitdistrplus). I also passed the start param for optim, but no success as suggested before in some forums earlier.?
I have provided all scenarios (the first two ones work, the 3rd is my problem, and the 4th also works).?
And No missing value. I am getting some NAN form gamma also, but I do not know the reason.?

?------works?
df= read.csv ("E:/mydata/Motorway-Urban/hour/PathAll_TWOMONTH _BothDirection715_2.csv")?
?z=rep(df$timenum,time=df$count)?
?y<-z?
?ycens <- data.frame(left=y,right=y)?
? max=27219?
? ct=max?
? for(i in max:28666 )?
? {?
? ? ycens$right[ct]=NA?
? ? ? ct=ct+1?
? ?}?
? ct=1;?
? for(i in 1:28666 )?
? {?
? ?if( ycens$left[i]<3)?
? {?
? ? ycens$left[ct]=NA?
? }?
? ? if( i>max)?
? {?
? ycens$left[ct]=500?
? ?} ??
? ct=ct+1?
}?
?fitlnc<-fitdistcens(ycens,"pois")?
> fitlnc?
Fitting of the distribution ' pois ' on censored data by maximum likelihood?
Parameters:?
? ? ? ?estimate?
lambda 93.34093?

-----------------Works method 2--------------?
?z=rep(df$timenum,time=df$count)?
> ?y<-z?
>?
> ?ycens <- data.frame(left=y,right=y)?
> ?max=27219?
> ?ct=max?
> ?for(i in max:28666 )?
+ ?{?
+ ? ?ycens$right[ct]=NA?
+ ??
+ ? ?ct=ct+1?
+ ? ??
+ ?}?
> ?ct=1;?
> ?for(i in 1:28666 )?
+ ?{?
+ ??
+ ?if( ycens$left[i]<3)?
+ ?{?
+ ? ?ycens$left[ct]=NA?
+?
+ ? ?}?
+ ? ? ? ct=ct+1?
+ ?}?
> ?fitlnc<-fitdistcens(ycens,"pois")?
> fitlnc?
Fitting of the distribution ' pois ' on censored data by maximum likelihood?
Parameters:?
? ? ? ?estimate?
lambda 142.0141?

==================PROBLEEEEEEEEEEMMMM======================?
? z=rep(df$timenum,time=df$count)?
? y<-z?
??
? ycens <- data.frame(left=y,right=y)?
? max=27219?
? ct=max?
? for(i in max:28666 )?
? {?
? ? ycens$right[ct]=y[ct]?
? ? ycens$left[ct]=500?
? ? ct=ct+1?
? ??
? }?
? ct=1;?
? for(i in 1:28666 )?
? {?
??
? if( ycens$left[i]<4)?
? {?
? ? ycens$left[ct]=1?
??
? ? } ? ? ? ct=ct+1?
?}?
> ?fitlnc<-fitdistcens(ycens,"pois")?
[1] "Error in optim(par = vstart, fn = fnobjcens, fix.arg = fix.arg, rcens = rcens, ?: \n ?initial value in 'vmmin' is not finite\n"?
attr(,"class")?
[1] "try-error"?
attr(,"condition")?
<simpleError in optim(par = vstart, fn = fnobjcens, fix.arg = fix.arg, rcens = rcens, ? ? lcens = lcens, icens = icens, ncens = ncens, ddistnam = ddistname, ? ? pdistnam = pdistname, hessian = TRUE, method = meth, lower = lower, ? ? upper = upper, ...): initial value in 'vmmin' is not finite>
Error in fitdistcens(ycens, "pois") :?
? the function mle failed to estimate the parameters,?
? ? ? ? with the error code 100?
====================Works=========================?
z=rep(df$timenum,time=df$count)?
? y<-z?
??
? ycens <- data.frame(left=y,right=y)?
? max=27219?
? ct=max?
? for(i in max:28666 )?
? {?
? ? ycens$right[ct]=y[ct]?
? ? ycens$left[ct]=500?
? ? ct=ct+1?
? ??
? }?
? ct=1;?
? for(i in 1:28666 )?
? {?
??
? if( ycens$left[i]<4)?
? {?
? ? ycens$left[ct]=1?
??
? ? } ? ? ??
?ct=ct+1?
?}?

?fitlnc<-fitdistcens(ycens,"lnorm")?
?fitlnc<-fitdistcens(ycens,"exp")?
> fitlnc<-fitdistcens(ycens,"gamma")?
There were 12 warnings (use warnings() to see them)?
> warnings()?
Warning messages:?
1: In dgamma(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
2: In pgamma(q = c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, ?... : NaNs produced?
3: In pgamma(q = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
4: In dgamma(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
5: In pgamma(q = c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, ?... : NaNs produced?
6: In pgamma(q = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
7: In dgamma(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
8: In pgamma(q = c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, ?... : NaNs produced?
9: In pgamma(q = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
10: In dgamma(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
11: In pgamma(q = c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, ?... : NaNs produced?
12: In pgamma(q = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?... : NaNs produced?
Remove Ads 

    On Monday, February 15, 2016 3:40 AM, John Kane <jrkrideau at inbox.com> wrote:
 

 Thank you, kind sir, you are correct but I was too rushed to write more as the bread needed to be taken out of the oven.? 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: pdalgd at gmail.com
> Sent: Sun, 14 Feb 2016 15:37:22 +0100
> To: jrkrideau at inbox.com
> Subject: Re: [R] Estimating Mean of a Poisson Distribution Based on
> Interval censoring
> 
> Fortune candidate :-)
> 
> However, the more scientific approach would be to ask for evidence to be
> scrutinized, acknowledging that R might be fallible, however unlikely
> that may seem.
> 
> Also, there is always the possibility that there are two answers because
> the question is not the same.
> 
> -pd
> 
>> On 14 Feb 2016, at 14:35 , John Kane <jrkrideau at inbox.com> wrote:
>> 
>>> By the way, is there anything for lognormal?I think fitdistcens is not
>>> good for this purpose as it gives me different result compared to SAS
>> 
>> The general assumption is that if Excel or any other spreadsheet gives a
>> result that is different from R then R will be correct.
>> 
>> Generally with SAS it may be that R is correct or just that R and SAS
>> use slightly different algorithms.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: r-help at r-project.org
>>> Sent: Sat, 13 Feb 2016 08:45:02 +0000 (UTC)
>>> To: r-help at r-project.org
>>> Subject: [R] Estimating Mean of a Poisson Distribution Based on
>>> Interval
>>> censoring
>>> 
>>> Dear all,
>>> I appreciate that if you let me know if there is any package
>>> implemented
>>> in R for Estimating Mean of a Poisson Distribution Based on Interval
>>> censoring? And if yes, could you please provide some information about
>>> it:)
>>> By the way, is there anything for lognormal?I think fitdistcens is not
>>> good for this purpose as it gives me different result compared to SAS
>>> and
>>> only useful for right/left censoring and not interval censoring (or
>>> both
>>> left and right together).
>>> Kind regards,Mohsen
>>> ??? [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
[[elided Yahoo spam]]



  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Feb 15 00:52:21 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 14 Feb 2016 18:52:21 -0500
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <879632620.1043610.1455478822248.JavaMail.yahoo@mail.yahoo.com>
References: <879632620.1043610.1455478822248.JavaMail.yahoo.ref@mail.yahoo.com>
	<879632620.1043610.1455478822248.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56C11335.8090000@gmail.com>

On 14/02/2016 2:40 PM, HEATHER MICHEL via R-help wrote:
> I am trying to complete a homework assignment, but I know very little about R.The assignment says, "For this programming assignment you will need to unzip this file and create the directory 'specdata".I unzipped the file on my desktop, and my computer automatically created a new folder which I renamed "specdata."However, when I try to make this directory within R using mkdir, I get this:
>> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo documentation for ?mkdir? in specified packages and libraries:you could try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found
>
> This makes me believe that some of the old command names have been updated in this version that is only 2 months old. Of course, the lectures I took notes on used an older version of R and were created more than 2 months ago.
> Please tell me the command I should be using to create a directory named 'specdata' in R 3.2.3

There hasn't been a mkdir() function in R that I can recall.  The 
function name is dir.create().  But there might be some package that has 
a mkdir() function.

Remember to quote the name; you probably need

dir.create("specdata")

Duncan Murdoch


From marongiu.luigi at gmail.com  Mon Feb 15 01:13:36 2016
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 15 Feb 2016 00:13:36 +0000
Subject: [R] cut-off point to separate overlapping distributions
Message-ID: <CAMk+s2Tk44QaL4-7mXsDJgXp2AyWTBquqC+k9a+Qc82PEUoF-g@mail.gmail.com>

dear all,
I have a set of data that can be defined as bimodal; would be possible
to define a cut-off to split it? my mathematical/statistical knowledge
is limited, my apologies, thus i am not sure what kind of area this
problem belongs to; at the moment I can fit -- thanks to previous help
from the community -- the modes of the distribution, but the problem i
am facing is to split the distribution in two. based on the example
below, i recknon the cut-off would be where i placed the green arrow
-- the local minimum -- but would be even better if the cut-off could
be be placed as close as possible to the first peak (blue arrow).
thank you
luigi

>>>
xval <- c(42.39, 44.53, 5.05, 6.9, 45, 2.35, 20.73, 3.31, 45, 4.76,
2.47, 2.37, 2.8, 3.26, 3.21, 45, 6.41, 4.77, 4.72, 4.89, 44.71, 2.8,
4.08, 4.07, 4.81, 2.93, 2.73, 44.75, 2.61, 2.56, 2.75, 2.75, 44.82,
36.59, 2.8, 43.82, 2.53, 2.75, 2.73, 3.05, 2.66, 5.61, 2.28, 4.83,
38.63, 44.23, 2.35, 2.47, 44.03, 6.33, 2.7, 2.96, 42.85, 2.47, 2,
12.76, 2.99, 2, 35.11, 2.63, 44.69, 2.96, 45, 42.13, 41.04, 3.22, 45,
45, 2.55, 4.58, 3.09, 39.98, 2, 2.97, 2.87, 2, 44.82, 45, 2.95, 45, 2,
2.82, 2.47, 2.98, 4.81, 44.53, 44.38, 2.87, 44.45, 2.9, 2.48, 44.14,
3.05, 2.76, 45, 45, 44.54, 42.85, 3.17, 2.46, 39.95, 36.96, 2.59,
2.75, 5.38, 2.8, 44.53, 45, 38.84, 4.64, 3.04, 2.59, 2.64, 45, 2.66,
44.37, 45, 26.32, 3.29, 40.44, 2, 41.51, 2, 45, 2, 5, 2.78, 2.11,
3.31, 2.61, 2.83, 2.6, 2.66, 2.95, 2.46, 2.58, 2.94, 45, 45, 2.71,
2.63, 2.81, 2, 3.29, 5.48, 45, 3.02, 2.82, 3.07, 2.65, 2.61, 2.67,
36.6, 2.08, 40.2, 45, 2.5, 45, 41.46, 45, 2.62, 2.77, 4.14, 2.63,
3.21, 4.79, 42.63, 2.66, 45, 4.69, 3.05, 45, 45, 2.97, 42.07, 2.73,
3.26, 5.17, 2.47, 44.66, 2.42, 5.14, 5.03, 2.65, 2.88, 2.69, 44.1,
3.15, 4.92, 42.02, 6.97, 2.46, 35.98, 2.95, 32.98, 2.79, 44.82, 2.84,
2.15, 44.42, 2.96, 45, 2.42, 2.75, 2.44, 4.58, 2, 45, 41.04, 4.04,
3.08, 2.46, 44.54, 3.21, 39.16, 2, 35.36, 3.08, 5.77, 2.71, 4.41,
2.46, 44.43, 2.62, 45, 2.7, 45, 41.43, 4.65, 3.05, 4.76, 40.66, 32.88,
45, 44.94, 44.67, 3.07, 2.92, 2.75, 2.63, 2.68, 34.15, 3.27, 2.47, 2,
2.63, 45, 3.06, 42.53, 35.25, 2.82, 42.62, 5.83, 4.69, 38.04, 2.47,
38.14, 3.73, 10, 4.93, 4.93, 4.65, 40.8, 2.32, 5.53, 3.01, 41.13, 4.5,
2.65, 44.85, 5.02, 2, 39.99, 2.89, 3.09, 2, 43.77, 44.53, 4.09, 6.22,
3.31, 44.64, 4.65, 45, 6.68, 39.93, 45, 2.77, 2.51, 2, 45, 4.08, 4.61,
6.11, 3.02, 44.8, 45, 44.54, 2.95, 2.77)
yval <- c(-0.002, 0.001, 0.002, 0.001, -0.001, 0.003, 0.003, 0.005, 0,
0.011, 0.003, 0.011, 0.004, 0.012, 0.004, 0.005, 0.001, 0.007, 0.006,
0.007, -0.001, 0.011, 0.005, 0.002, 0.007, 0.028, 0.01, 0.002, 0.003,
0.007, 0.033, 0.006, 0.003, 0, 0.01, 0.018, 0.01, 0.008, 0.002, 0.022,
0.02, 0.002, 0.006, 0.008, 0, -0.002, -0.001, 0.001, 0.001, 0.007,
0.005, 0.011, 0.004, 0.001, 0.005, 0.001, 0.019, 0.002, 0.001, 0.002,
-0.001, 0.003, 0.001, 0, -0.001, 0.002, 0.005, 0.001, 0, 0.007, 0.011,
-0.001, 0.002, 0.01, 0.004, 0.003, 0.001, 0, 0.015, 0.004, 0.001,
0.003, 0.003, 0.027, 0.005, 0, 0.003, 0.003, 0, 0.017, 0.004, -0.001,
0.043, 0.003, -0.001, 0.001, 0, 0, 0.019, 0.003, -0.001, 0.001, 0.009,
0.013, 0.001, 0.021, 0.001, -0.001, -0.001, 0.002, 0.008, 0.004,
0.007, 0.001, 0.007, 0.001, 0, 0.001, 0.004, -0.001, 0.001, 0, 0.007,
0.003, 0.002, 0.001, 0.028, 0.002, 0.005, 0.013, 0.017, 0.013, 0.009,
0.021, 0.01, 0.007, 0.015, 0, 0.002, 0.002, 0.013, 0.012, 0, 0.034,
0.005, 0, 0.041, 0.02, 0.036, 0.004, 0.002, 0.004, 0.001, 0.001,
0.001, 0.003, 0.016, 0.002, 0, 0, 0.002, 0.009, 0.006, 0.022, 0.002,
0.01, 0, 0.012, 0.006, 0.01, 0.005, 0.001, 0.001, 0.027, 0.003, 0.002,
0.02, 0.014, 0.003, 0.003, -0.001, 0.002, 0.008, 0.011, 0.014, 0.017,
0, 0.015, 0.008, 0.001, 0.005, 0.002, 0.001, 0.012, 0.002, 0.004, 0,
0.012, 0, 0.001, 0.005, 0.001, 0.008, 0.011, 0.006, 0.007, 0.005, 0,
0, 0.003, 0.004, 0.002, 0, 0.015, -0.001, 0.002, -0.001, 0.006, 0.005,
0.006, 0.003, 0.002, 0.001, 0.001, 0, 0.007, 0.002, -0.001, 0.033,
0.01, 0.007, 0.003, 0, 0.001, -0.001, 0.011, 0.006, 0.015, 0.013,
0.01, 0.015, 0, 0.014, 0.001, 0.001, 0.003, 0, 0.012, -0.001, 0.002,
0.027, -0.001, 0.009, 0.021, 0.001, 0.001, -0.001, 0.008, 0.001,
0.017, 0.002, 0.027, 0.003, -0.001, 0.018, 0.026, -0.001, 0.004,
0.003, 0.001, 0.019, 0.001, 0.001, 0.019, 0.005, 0.001, -0.001, 0.002,
0.001, 0.001, 0.004, 0.002, 0.007, 0.003, 0.01, 0.002, 0.003, 0.002,
0.005, 0.003, 0, 0.004, 0.032, 0.005, 0.018, 0.002, 0.001, 0.002,
0.003, 0.005)
df <- data.frame(xval,yval)

d.rv = density(df$xval)
plot(df$yval ~ df$xval, ylim=c(0,0.05))
lines(d.rv)
d.x = d.rv$x
d.y = d.rv$y
runs <- rle(sign(diff(d.rv$y)))
length(runs$lengths)
mode1 <- runs$lengths[1]+1
mode2 <- length(d.rv$x)- runs$lengths[4]
Y1 <- d.rv$y[mode1]
X1 <- d.rv$x[d.rv$y == Y1]
abline(v=X1, col="red")
Y2 <- d.rv$y[mode2]
X2 <- d.rv$x[d.rv$y == Y2]
abline(v=X2, col="red")

arrows(21, 0.03, 21, 0.01, col="green")
arrows(10, 0.03, 10, 0.01, col="blue")


From boris.steipe at utoronto.ca  Mon Feb 15 02:30:52 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 14 Feb 2016 20:30:52 -0500
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <56C11335.8090000@gmail.com>
References: <879632620.1043610.1455478822248.JavaMail.yahoo.ref@mail.yahoo.com>
	<879632620.1043610.1455478822248.JavaMail.yahoo@mail.yahoo.com>
	<56C11335.8090000@gmail.com>
Message-ID: <D2CDD5AA-5DBD-466C-BA74-946D93DCB2FF@utoronto.ca>

Also ... it doesn't make sense to create a directory that already exists in the first place. Are you perhaps thinking about setting the working directory to "specdata"? That would be the setwd() command.


B.

On Feb 14, 2016, at 6:52 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 14/02/2016 2:40 PM, HEATHER MICHEL via R-help wrote:
>> I am trying to complete a homework assignment, but I know very little about R.The assignment says, "For this programming assignment you will need to unzip this file and create the directory 'specdata".I unzipped the file on my desktop, and my computer automatically created a new folder which I renamed "specdata."However, when I try to make this directory within R using mkdir, I get this:
>>> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo documentation for ?mkdir? in specified packages and libraries:you could try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found
>> 
>> This makes me believe that some of the old command names have been updated in this version that is only 2 months old. Of course, the lectures I took notes on used an older version of R and were created more than 2 months ago.
>> Please tell me the command I should be using to create a directory named 'specdata' in R 3.2.3
> 
> There hasn't been a mkdir() function in R that I can recall.  The function name is dir.create().  But there might be some package that has a mkdir() function.
> 
> Remember to quote the name; you probably need
> 
> dir.create("specdata")
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From heathermichel at rocketmail.com  Mon Feb 15 00:50:34 2016
From: heathermichel at rocketmail.com (HEATHER MICHEL)
Date: Sun, 14 Feb 2016 23:50:34 +0000 (UTC)
Subject: [R] R 3.2.3 on Win8;  mkdir command produces error
In-Reply-To: <262825107.3212829.1455493360506.JavaMail.yahoo@mail.yahoo.com>
References: <879632620.1043610.1455478822248.JavaMail.yahoo.ref@mail.yahoo.com>
	<879632620.1043610.1455478822248.JavaMail.yahoo@mail.yahoo.com>
	<262825107.3212829.1455493360506.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1001578271.3233546.1455493834255.JavaMail.yahoo@mail.yahoo.com>

As a follow-up to my request for help this morning, I have watched tutorials on R all afternoon. Many topics come close to my problem, but none specifically address my situation where "specdata" is not a text file but a list of small files in a folder.I found a command that should be more right than mkdir, but it still won't work for my assignment. What argument am I getting wrong?To recap, I can't access in R my data files that are on my desktop. I need more understanding about how directories transfer between Windows and R.
> dir.create('specdata')

 > dir.exists("specdata")[1] TRUE
> load("C:/Users/rhmichel/Desktop/rprog-data-specdata/specdata/001.csv")Error: bad restore file magic number (file may be corrupted) -- no data loadedIn addition: Warning message:file ?001.csv? has magic number '"Date'? Use of save versions prior to 2 is deprecated?
> pollutantmean("C:\Users\rhmichel\Desktop\rprog-data-specdata\specdata", "sulfate", 1:10)Error: '\U' used without hex digits in character string starting ""C:\U">?
Thank you for any help you can provide me,Heather Michel
    On Sunday, February 14, 2016 2:40 PM, HEATHER MICHEL <heathermichel at rocketmail.com> wrote:
 

 I am trying to complete a homework assignment, but I know very little about R.The assignment says, "For this programming assignment you will need to unzip this file and create the directory 'specdata".I unzipped the file on my desktop, and my computer automatically created a new folder which I renamed "specdata."However, when I try to make this directory within R using mkdir, I get this:
> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo documentation for ?mkdir? in specified packages and libraries:you could try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found

This makes me believe that some of the old command names have been updated in this version that is only 2 months old. Of course, the lectures I took notes on used an older version of R and were created more than 2 months ago.
Please tell me the command I should be using to create a directory named 'specdata' in R 3.2.3
Heather Michel

  
	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon Feb 15 04:07:37 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 14 Feb 2016 22:07:37 -0500
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <1001578271.3233546.1455493834255.JavaMail.yahoo@mail.yahoo.com>
References: <879632620.1043610.1455478822248.JavaMail.yahoo.ref@mail.yahoo.com>
	<879632620.1043610.1455478822248.JavaMail.yahoo@mail.yahoo.com>
	<262825107.3212829.1455493360506.JavaMail.yahoo@mail.yahoo.com>
	<1001578271.3233546.1455493834255.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+vqiLE_U2PHk=inVv-4GbEyHHkw0dt=wVPDPxCVcPnaZWa-dg@mail.gmail.com>

This mailing list is not meant for homework help, you should ask your
instructor to clarify the assignment.

Best,
Ista

On Feb 14, 2016 9:24 PM, "HEATHER MICHEL via R-help" <r-help at r-project.org>
wrote:
>
> As a follow-up to my request for help this morning, I have watched
tutorials on R all afternoon. Many topics come close to my problem, but
none specifically address my situation where "specdata" is not a text file
but a list of small files in a folder.I found a command that should be more
right than mkdir, but it still won't work for my assignment. What argument
am I getting wrong?To recap, I can't access in R my data files that are on
my desktop. I need more understanding about how directories transfer
between Windows and R.
> > dir.create('specdata')
>
>  > dir.exists("specdata")[1] TRUE
> >
load("C:/Users/rhmichel/Desktop/rprog-data-specdata/specdata/001.csv")Error:
bad restore file magic number (file may be corrupted) -- no data loadedIn
addition: Warning message:file ?001.csv? has magic number '"Date'  Use of
save versions prior to 2 is deprecated
> > pollutantmean("C:\Users\rhmichel\Desktop\rprog-data-specdata\specdata",
"sulfate", 1:10)Error: '\U' used without hex digits in character string
starting ""C:\U">
> Thank you for any help you can provide me,Heather Michel
>     On Sunday, February 14, 2016 2:40 PM, HEATHER MICHEL <
heathermichel at rocketmail.com> wrote:
>
>
>  I am trying to complete a homework assignment, but I know very little
about R.The assignment says, "For this programming assignment you will need
to unzip this file and create the directory 'specdata".I unzipped the file
on my desktop, and my computer automatically created a new folder which I
renamed "specdata."However, when I try to make this directory within R
using mkdir, I get this:
> > mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo
documentation for ?mkdir? in specified packages and libraries:you could try
???mkdir?> ??mkdir> pwdError: object 'pwd' not found
>
> This makes me believe that some of the old command names have been
updated in this version that is only 2 months old. Of course, the lectures
I took notes on used an older version of R and were created more than 2
months ago.
> Please tell me the command I should be using to create a directory named
'specdata' in R 3.2.3
> Heather Michel
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 15 09:09:53 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Feb 2016 08:09:53 +0000
Subject: [R] View() function
In-Reply-To: <1c0f0c2.2cc0f.152d91f8319.Coremail.h_bukhaiti@hnu.edu.cn>
References: <1c0f0c2.2cc0f.152d91f8319.Coremail.h_bukhaiti@hnu.edu.cn>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F1F0@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> ALBUKHAITI HESHAM
> Sent: Saturday, February 13, 2016 6:34 AM
> To: R-help at r-project.org
> Subject: [R] View() function
>
> i am try to show the rows name in r by View() function but i cannot

How View function looks like, I did not find it in base and other packages I use.

> ?Viev
No documentation for ?Viev? in specified packages and libraries:
you could try ???Viev?

> ,return only numbers of columns  , but when i use NameData[,1] ,, no
> problem ,i can get it.
> i do not no where is the problem ,

Neither I. Your message is rather cryptic. You can get number of columns by

ncol(x)

NameData[,1] does not have anything to do with number of columns, it gives you first column of NameData object (if NameData object is data frame or matrix).


> becouse some file in text i downloaded it form internet doesn't have
> problem.
> >>>>>>>>>>>>>>>>
> also when i want to read my data as text , R return this message >
> mydata<-read.table("mirnat.txt", header=T,row.names = 1) Error in
> scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
> line 1 did not have 62 elements.
> please help , thanks

The error seems to me pretty straightforward. First line of mirnat.txt is a header and based on separator (read.table assumes it is white space) read.table expects 62 elements in any row.

Maybe it is problem in column names (they may contain white space as a part of a name - like e.g. in "New York").

Or you wanted to use first column as row names but this column has a name, so there is one name more for columns.

BTW, you may have broken keyboard, there are no capital letters and EOLs in your mail.

Cheers
Petr


>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From shivi.bhatia at safexpress.com  Sun Feb 14 11:15:59 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Sun, 14 Feb 2016 15:45:59 +0530
Subject: [R] Error with Twitter Authorization for Sentiment Analysis
Message-ID: <002701d16710$a76de5b0$f649b110$@safexpress.com>

Dear Team,

 

Every now and then I face issues while connecting to Twitter:

 

Error in check_twitter_oauth() : OAuth authentication error:

This most likely means that you have incorrectly called
setup_twitter_oauth()'

 

I have checked multiple github suggestion and statsexchange forum & have
followed all suggestion such as to update httpuv package and calling out the
library names in a certain manner however I am still not successful.. Also
apart from these there was also recommendation on httr package to be called
first though while calling the httr package I got this message:

 

Error in unloadNamespace(package) : 
  namespace 'httr' is imported by 'twitteR' so cannot be unloaded
 
 
Not sure on what is to be done here hence require help from the forum. 

 

 

Thanks, Shivi

Mb: 9891002021

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160214/5c66cf6e/attachment.pl>

From psandeepmallya at gmail.com  Mon Feb 15 10:51:14 2016
From: psandeepmallya at gmail.com (Sandeep Mallya)
Date: Mon, 15 Feb 2016 15:21:14 +0530
Subject: [R] Error installing the package "Cairo"
Message-ID: <CAM++Fzta7gwvPsbTGA_eNsOuHrA=tL+TLs3L_9pcuvYiriYSRA@mail.gmail.com>

Hello all,

I am trying to install the package Cairo on RedHat running R version 3.2.3.
So far I have tried install.packages("Cairo")
R CMD INSTALL Cairo_1.5-9.tar.gz

Both the approaches giving me the same error below.


Error : .onLoad failed in loadNamespace() for 'Cairo', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object
'/home/sandeep/R/x86_64-pc-linux-gnu-library/3.2/Cairo/libs/Cairo.so':
  libpng15.so.15: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted


Can someone please guide me.

Thanks,
Sandeep

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Mon Feb 15 13:22:15 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Mon, 15 Feb 2016 17:52:15 +0530
Subject: [R] Error with Twitter Authorization for Sentiment Analysis
In-Reply-To: <002701d16710$a76de5b0$f649b110$@safexpress.com>
References: <002701d16710$a76de5b0$f649b110$@safexpress.com>
Message-ID: <2E238312-8C3B-4D1C-9C7D-0EA3EBD89C9F@gmail.com>

Shivi,
Could you also share the piece of code to have a look at ?

Regards,
Sunny Singha

> On 14-Feb-2016, at 3:45 PM, SHIVI BHATIA <shivi.bhatia at safexpress.com> wrote:
> 
> Dear Team,
> 
> 
> 
> Every now and then I face issues while connecting to Twitter:
> 
> 
> 
> Error in check_twitter_oauth() : OAuth authentication error:
> 
> This most likely means that you have incorrectly called
> setup_twitter_oauth()'
> 
> 
> 
> I have checked multiple github suggestion and statsexchange forum & have
> followed all suggestion such as to update httpuv package and calling out the
> library names in a certain manner however I am still not successful.. Also
> apart from these there was also recommendation on httr package to be called
> first though while calling the httr package I got this message:
> 
> 
> 
> Error in unloadNamespace(package) : 
>  namespace 'httr' is imported by 'twitteR' so cannot be unloaded
> 
> 
> Not sure on what is to be done here hence require help from the forum. 
> 
> 
> 
> 
> 
> Thanks, Shivi
> 
> Mb: 9891002021
> 
> 
> 
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Mon Feb 15 13:38:21 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 15 Feb 2016 06:38:21 -0600
Subject: [R] Estimating Mean of a Poisson Distribution Based on interval
 censoring
In-Reply-To: <mailman.1.1455447601.17866.r-help@r-project.org>
References: <mailman.1.1455447601.17866.r-help@r-project.org>
Message-ID: <7b6d90$2egau9@ironport10.mayo.edu>

For an interval censored poisson or lognormal, use survreg() in the survival package.  (Or 
if you are a SAS fan use proc lifereg).  If you have a data set where R and SAS give 
different answers I'd like to know about it, but my general experience is that this is 
more often a user error.  I am also curious to learn exactly what you mean by "interval 
censored poisson".  Exponential with interval time to first event is equivalent to 
poisson, which is what I'd guess from "lognormal", but you may mean something else.


Terry Therneau
(author of survival)



On 02/14/2016 05:00 AM, r-help-request at r-project.org wrote:
> Dear all,
> I appreciate that if you let me know if there is any package implemented in R for Estimating Mean of a Poisson Distribution Based on Interval censoring? And if yes, could you please provide some information about it:)?
> By the way, is there anything for lognormal?I think fitdistcens is not good for this purpose as it gives me different result compared to SAS and only useful for right/left censoring and not interval censoring?(or both left and right together).?
> Kind regards,Mohsen


From jrkrideau at inbox.com  Mon Feb 15 14:51:25 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 15 Feb 2016 05:51:25 -0800
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <1001578271.3233546.1455493834255.JavaMail.yahoo@mail.yahoo.com>
References: <879632620.1043610.1455478822248.javamail.yahoo.ref@mail.yahoo.com>
	<262825107.3212829.1455493360506.javamail.yahoo@mail.yahoo.com>
	<879632620.1043610.1455478822248.javamail.yahoo@mail.yahoo.com>
Message-ID: <5CC0A6E5610.00000250jrkrideau@inbox.com>

I'd say that Boris Steipe's suggestion is the most likely answer to the problem.  Also, it's been a long time since I used Windows (deo gratias) but that path name does not look right. I think I would have expected something more like:

"C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv"

Any comments from Windows users?

However,  you cannot "load" a .csv file. "load" is intended to load a compiled .Rdata file as I understand it. It may do more but that's all I've ever used it for.

You probably want:
dat1  <-  read.csv("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv")

Depending on how the data file is set up you may need to add various options to the read.csv file.

read.csv()  assumes that the file has headers  for the columns and that the separator between the columns is a blank space or spaces.

Let's say the separator is a tab and there are no headers you would need to change the read.csv() to 
xx  <-  read.csv("load("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv", sep = "\t", header = FALSE)

You need to open the data file in a text editor, Notebook will do, and see what it looks like if my two suggestions, or combinations thereof, don't work.

Then do a ?read.csv or perhaps a ?read.table try to figure out what the cryptic help documentation tells you. The solution will be there, it just often is not obvious.. read.csv() is simply a subset of  the more powerful read.table().  

I have great sympathy for you. For the first six months of using R, I seemed to  spend more time trying to get the data into R than working on the problem. Just to be encouraging. :).

BTW if the instructor did not suggest it, I would recommend downloading and installing RStudio. https://www.rstudio.com/products/rstudio/download/ . It is an excellent IDE and makes working with R much easier.

@Ista
While I agree that Heather should ask her instructor for help, I don't see assisting a student getting data into R as helping with a programming assignment. Perhaps at the margins but that is all.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Sun, 14 Feb 2016 23:50:34 +0000 (UTC)
> To: r-help at r-project.org
> Subject: Re: [R] R 3.2.3 on Win8; mkdir command produces error
> 
> As a follow-up to my request for help this morning, I have watched
> tutorials on R all afternoon. Many topics come close to my problem, but
> none specifically address my situation where "specdata" is not a text
> file but a list of small files in a folder.I found a command that should
> be more right than mkdir, but it still won't work for my assignment. What
> argument am I getting wrong?To recap, I can't access in R my data files
> that are on my desktop. I need more understanding about how directories
> transfer between Windows and R.
>> dir.create('specdata')
> 
>  > dir.exists("specdata")[1] TRUE
Error:
>> bad restore file magic number (file may be corrupted) -- no data
>> loadedIn addition: Warning message:file ?001.csv? has magic number
>> '"Date'? Use of save versions prior to 2 is deprecated
>> pollutantmean("C:\Users\rhmichel\Desktop\rprog-data-specdata\specdata",
>> "sulfate", 1:10)Error: '\U' used without hex digits in character string
>> starting ""C:\U">
> Thank you for any help you can provide me,Heather Michel
>     On Sunday, February 14, 2016 2:40 PM, HEATHER MICHEL
> <heathermichel at rocketmail.com> wrote:
> 
> 
>  I am trying to complete a homework assignment, but I know very little
> about R.The assignment says, "For this programming assignment you will
> need to unzip this file and create the directory 'specdata".I unzipped
> the file on my desktop, and my computer automatically created a new
> folder which I renamed "specdata."However, when I try to make this
> directory within R using mkdir, I get this:
>> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo
>> documentation for ?mkdir? in specified packages and libraries:you could
>> try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found
> 
> This makes me believe that some of the old command names have been
> updated in this version that is only 2 months old. Of course, the
> lectures I took notes on used an older version of R and were created more
> than 2 months ago.
> Please tell me the command I should be using to create a directory named
> 'specdata' in R 3.2.3
> Heather Michel
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From marongiu.luigi at gmail.com  Mon Feb 15 15:36:38 2016
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 15 Feb 2016 14:36:38 +0000
Subject: [R] non parametric algorithm npEM (library mixtools) usage
Message-ID: <CAMk+s2QyKwqq6a3yt7WFvHRb7kj0x5rBA8fNWMW=FHzXPtTQhA@mail.gmail.com>

Dear all,
I am using mixtols to find cut-off values from datasets. At the moment
I can run the parametric function normalmixEM from the library
mixtools, but I owuld like to generalize the procedure with the non
parametric version npEM. However I am confused regarding the arguments
to use in this implementation. I reckon that x should be the dataframe
of the values I have, mu0 should probably give the locations of the
mode (or modes if the data are described by overlapping distributions)
of the data, but all the other arguments are beyond me.
could you please give me a hint?
thank you
luigi

Here I am placing an example for the normalmixEM function that
provides a cut-off for the value highlighted with the arrow.

>>>
xval <- c(42.39, 44.53, 5.05, 6.9, 45, 2.35, 20.73, 3.31, 45, 4.76,
2.47, 2.37, 2.8, 3.26, 3.21, 45, 6.41, 4.77, 4.72, 4.89, 44.71, 2.8,
4.08, 4.07, 4.81, 2.93, 2.73, 44.75, 2.61, 2.56, 2.75, 2.75, 44.82,
36.59, 2.8, 43.82, 2.53, 2.75, 2.73, 3.05, 2.66, 5.61, 2.28, 4.83,
38.63, 44.23, 2.35, 2.47, 44.03, 6.33, 2.7, 2.96, 42.85, 2.47, 2,
12.76, 2.99, 2, 35.11, 2.63, 44.69, 2.96, 45, 42.13, 41.04, 3.22, 45,
45, 2.55, 4.58, 3.09, 39.98, 2, 2.97, 2.87, 2, 44.82, 45, 2.95, 45, 2,
2.82, 2.47, 2.98, 4.81, 44.53, 44.38, 2.87, 44.45, 2.9, 2.48, 44.14,
3.05, 2.76, 45, 45, 44.54, 42.85, 3.17, 2.46, 39.95, 36.96, 2.59,
2.75, 5.38, 2.8, 44.53, 45, 38.84, 4.64, 3.04, 2.59, 2.64, 45, 2.66,
44.37, 45, 26.32, 3.29, 40.44, 2, 41.51, 2, 45, 2, 5, 2.78, 2.11,
3.31, 2.61, 2.83, 2.6, 2.66, 2.95, 2.46, 2.58, 2.94, 45, 45, 2.71,
2.63, 2.81, 2, 3.29, 5.48, 45, 3.02, 2.82, 3.07, 2.65, 2.61, 2.67,
36.6, 2.08, 40.2, 45, 2.5, 45, 41.46, 45, 2.62, 2.77, 4.14, 2.63,
3.21, 4.79, 42.63, 2.66, 45, 4.69, 3.05, 45, 45, 2.97, 42.07, 2.73,
3.26, 5.17, 2.47, 44.66, 2.42, 5.14, 5.03, 2.65, 2.88, 2.69, 44.1,
3.15, 4.92, 42.02, 6.97, 2.46, 35.98, 2.95, 32.98, 2.79, 44.82, 2.84,
2.15, 44.42, 2.96, 45, 2.42, 2.75, 2.44, 4.58, 2, 45, 41.04, 4.04,
3.08, 2.46, 44.54, 3.21, 39.16, 2, 35.36, 3.08, 5.77, 2.71, 4.41,
2.46, 44.43, 2.62, 45, 2.7, 45, 41.43, 4.65, 3.05, 4.76, 40.66, 32.88,
45, 44.94, 44.67, 3.07, 2.92, 2.75, 2.63, 2.68, 34.15, 3.27, 2.47, 2,
2.63, 45, 3.06, 42.53, 35.25, 2.82, 42.62, 5.83, 4.69, 38.04, 2.47,
38.14, 3.73, 10, 4.93, 4.93, 4.65, 40.8, 2.32, 5.53, 3.01, 41.13, 4.5,
2.65, 44.85, 5.02, 2, 39.99, 2.89, 3.09, 2, 43.77, 44.53, 4.09, 6.22,
3.31, 44.64, 4.65, 45, 6.68, 39.93, 45, 2.77, 2.51, 2, 45, 4.08, 4.61,
6.11, 3.02, 44.8, 45, 44.54, 2.95, 2.77)
yval <- c(-0.002, 0.001, 0.002, 0.001, -0.001, 0.003, 0.003, 0.005, 0,
0.011, 0.003, 0.011, 0.004, 0.012, 0.004, 0.005, 0.001, 0.007, 0.006,
0.007, -0.001, 0.011, 0.005, 0.002, 0.007, 0.028, 0.01, 0.002, 0.003,
0.007, 0.033, 0.006, 0.003, 0, 0.01, 0.018, 0.01, 0.008, 0.002, 0.022,
0.02, 0.002, 0.006, 0.008, 0, -0.002, -0.001, 0.001, 0.001, 0.007,
0.005, 0.011, 0.004, 0.001, 0.005, 0.001, 0.019, 0.002, 0.001, 0.002,
-0.001, 0.003, 0.001, 0, -0.001, 0.002, 0.005, 0.001, 0, 0.007, 0.011,
-0.001, 0.002, 0.01, 0.004, 0.003, 0.001, 0, 0.015, 0.004, 0.001,
0.003, 0.003, 0.027, 0.005, 0, 0.003, 0.003, 0, 0.017, 0.004, -0.001,
0.043, 0.003, -0.001, 0.001, 0, 0, 0.019, 0.003, -0.001, 0.001, 0.009,
0.013, 0.001, 0.021, 0.001, -0.001, -0.001, 0.002, 0.008, 0.004,
0.007, 0.001, 0.007, 0.001, 0, 0.001, 0.004, -0.001, 0.001, 0, 0.007,
0.003, 0.002, 0.001, 0.028, 0.002, 0.005, 0.013, 0.017, 0.013, 0.009,
0.021, 0.01, 0.007, 0.015, 0, 0.002, 0.002, 0.013, 0.012, 0, 0.034,
0.005, 0, 0.041, 0.02, 0.036, 0.004, 0.002, 0.004, 0.001, 0.001,
0.001, 0.003, 0.016, 0.002, 0, 0, 0.002, 0.009, 0.006, 0.022, 0.002,
0.01, 0, 0.012, 0.006, 0.01, 0.005, 0.001, 0.001, 0.027, 0.003, 0.002,
0.02, 0.014, 0.003, 0.003, -0.001, 0.002, 0.008, 0.011, 0.014, 0.017,
0, 0.015, 0.008, 0.001, 0.005, 0.002, 0.001, 0.012, 0.002, 0.004, 0,
0.012, 0, 0.001, 0.005, 0.001, 0.008, 0.011, 0.006, 0.007, 0.005, 0,
0, 0.003, 0.004, 0.002, 0, 0.015, -0.001, 0.002, -0.001, 0.006, 0.005,
0.006, 0.003, 0.002, 0.001, 0.001, 0, 0.007, 0.002, -0.001, 0.033,
0.01, 0.007, 0.003, 0, 0.001, -0.001, 0.011, 0.006, 0.015, 0.013,
0.01, 0.015, 0, 0.014, 0.001, 0.001, 0.003, 0, 0.012, -0.001, 0.002,
0.027, -0.001, 0.009, 0.021, 0.001, 0.001, -0.001, 0.008, 0.001,
0.017, 0.002, 0.027, 0.003, -0.001, 0.018, 0.026, -0.001, 0.004,
0.003, 0.001, 0.019, 0.001, 0.001, 0.019, 0.005, 0.001, -0.001, 0.002,
0.001, 0.001, 0.004, 0.002, 0.007, 0.003, 0.01, 0.002, 0.003, 0.002,
0.005, 0.003, 0, 0.004, 0.032, 0.005, 0.018, 0.002, 0.001, 0.002,
0.003, 0.005)
df <- data.frame(xval,yval)

DF <- subset(df, xval>=10)
sdmult = 10 # A guess to get started
library(mixtools)
model = normalmixEM((x = DF$yval))
muneg = model$mu[1] # Mean of negative population
sdneg = model$sigma[1] # SD of negative population
mupos = model$mu[2] # Mean of positive population
sdpos = model$sigma[2] # SD of positive population
co = muneg + sdmult*sdneg # Calculate threshold based on SD multiplier
plot(DF$yval ~ DF$xval)
abline(h=co, lty=2)
arrows(37,0.018, 42, 0.018, col="red")


From sunnysingha.analytics at gmail.com  Mon Feb 15 15:37:32 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Mon, 15 Feb 2016 20:07:32 +0530
Subject: [R] Error with Twitter Authorization for Sentiment Analysis
In-Reply-To: <000001d167f1$937d59a0$ba780ce0$@safexpress.com>
References: <002701d16710$a76de5b0$f649b110$@safexpress.com>
	<2E238312-8C3B-4D1C-9C7D-0EA3EBD89C9F@gmail.com>
	<000001d167f1$937d59a0$ba780ce0$@safexpress.com>
Message-ID: <2E53DA0B-EE17-4F8F-8E75-049656CEDBDE@gmail.com>

Shivi,
I?m not sure how you have installed ?twitterR? package. But please follow below steps and your issue will be resolved: 
- Ensure there are no objects in memory. To be sure run these commands : 
		- .r.restartR()
		- rm(list=ls())  
		- gc()

	# Remove packages
	remove.packages('twitteR')
	remove.packages('ROAuth')
	remove.packages('rjson')
	remove.packages('bit64')
	remove.packages('httr')
	remove.packages('devtools')

- Execute below in sequence and later assign your keys to get going:
	 #Twitter analytics with R
	install.packages(c("devtools", "rjson", "bit64", "httr"))
	install_github("twitteR", "geoffjentry")
	install.packages("ROAuth")

	library(devtools)
	library(ROAuth)
	library(twitteR)

Regards,
Sunny Singha


> On 15-Feb-2016, at 6:36 PM, SHIVI BHATIA <shivi.bhatia at safexpress.com> wrote:
> 
> Hi Sandeep,
> 
> Here is my authorization code:
> 
> setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
> .
> 
> Prior to this I have just added my consumer key and the other var after
> logging at https://apps.twitter.com. Does this help.
> 
> -----Original Message-----
> From: Sandeep Rana [mailto:sunnysingha.analytics at gmail.com]
> Sent: Monday, February 15, 2016 5:52 PM
> To: SHIVI BHATIA <shivi.bhatia at safexpress.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Error with Twitter Authorization for Sentiment Analysis
> 
> Shivi,
> Could you also share the piece of code to have a look at ?
> 
> Regards,
> Sunny Singha
> 
>> On 14-Feb-2016, at 3:45 PM, SHIVI BHATIA <shivi.bhatia at safexpress.com>
> wrote:
>> 
>> Dear Team,
>> 
>> 
>> 
>> Every now and then I face issues while connecting to Twitter:
>> 
>> 
>> 
>> Error in check_twitter_oauth() : OAuth authentication error:
>> 
>> This most likely means that you have incorrectly called
>> setup_twitter_oauth()'
>> 
>> 
>> 
>> I have checked multiple github suggestion and statsexchange forum &
>> have followed all suggestion such as to update httpuv package and
>> calling out the library names in a certain manner however I am still
>> not successful.. Also apart from these there was also recommendation
>> on httr package to be called first though while calling the httr package I
> got this message:
>> 
>> 
>> 
>> Error in unloadNamespace(package) :
>> namespace 'httr' is imported by 'twitteR' so cannot be unloaded
>> 
>> 
>> Not sure on what is to be done here hence require help from the forum.
>> 
>> 
>> 
>> 
>> 
>> Thanks, Shivi
>> 
>> Mb: 9891002021
>> 
>> 
>> 
>> This e-mail is confidential. It may also be legally privileged. If you are
> not the addressee you may not copy, forward, disclose or use any part of it.
> If you have received this message in error, please delete it and all copies
> from your system and notify the sender immediately by return e-mail.
> Internet communications cannot be guaranteed to be timely, secure, error or
> virus-free. The sender does not accept liability for any errors or
> omissions.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
> 


	[[alternative HTML version deleted]]


From cpblpublic+rhelp at gmail.com  Mon Feb 15 16:19:11 2016
From: cpblpublic+rhelp at gmail.com (cpblpublic+rhelp at gmail.com)
Date: Mon, 15 Feb 2016 10:19:11 -0500 (EST)
Subject: [R] Package for: Instrumental variables with spatial error and lags
 for cross-sectional data?
Message-ID: <alpine.DEB.2.20.1602151017500.12648@cpbl-x230>

I have a spatial cross-sectional dataset. I think I have an instrument for 
my dependent variable, but there's reason to suspect I need a spatial lag 
with spatial error model. The dataset has about 100,000 observations.

I am looking for a package which will estimate my model in R (or Stata or 
Python, if that will be a lot easier).

Here's where I'm stuck in R:

Package spdep has some spatial error /spatial lag models (sarar and 
gstsls), but no I.V.

Package splm has a g2sls function, which seems to offer nearly what I 
want. But this package is for spatial panels ... but not cross-sections.

Package sphet makes use of IV, but not the kind where you have your own 
instrument. Instead, it's simply using spatial lags of X as instruments 
for a spatial lag model. This seems also what this blog is about.

There's a s2sls package, i.e. spatial 2sls, version 0.1 in Jan 2016. It 
looks too new and undocumented to try.

Surely if there's a nice package for panel data IV, there's one also for 
cross-sections?

Thanks,
Chris


From zadig_1 at excite.com  Mon Feb 15 16:53:23 2016
From: zadig_1 at excite.com (ce)
Date: Mon, 15 Feb 2016 10:53:23 -0500
Subject: [R] ts time-object indexing question?
Message-ID: <20160215105323.1626@web004.roc2.bluetie.com>


Dear all, 

I can't find an answer to this simple question:

 a.ts <- ts(1:10, frequency = 1, start = c(1959, 1))
 > a.ts
Time Series:
Start = 1959
End = 1968
Frequency = 1
 [1]  1  2  3  4  5  6  7  8  9 10

Now I want to get let's say value for 1965 , how to get it ?
> a.ts["1965"]
[1] NA

doesn't work . 

And  how I can get the date of a.ts[5]  ?


From istazahn at gmail.com  Mon Feb 15 17:06:47 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 15 Feb 2016 11:06:47 -0500
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <5CC0A6E5610.00000250jrkrideau@inbox.com>
References: <879632620.1043610.1455478822248.javamail.yahoo.ref@mail.yahoo.com>
	<262825107.3212829.1455493360506.javamail.yahoo@mail.yahoo.com>
	<879632620.1043610.1455478822248.javamail.yahoo@mail.yahoo.com>
	<1001578271.3233546.1455493834255.JavaMail.yahoo@mail.yahoo.com>
	<5CC0A6E5610.00000250jrkrideau@inbox.com>
Message-ID: <CA+vqiLEUuF9wQEzhVXNQBbowuc+9K1ohd7gYfR2Y196pieNX5g@mail.gmail.com>

On Feb 15, 2016 8:53 AM, "John Kane" <jrkrideau at inbox.com> wrote:
>
> I'd say that Boris Steipe's suggestion is the most likely answer to the
problem.  Also, it's been a long time since I used Windows (deo gratias)
but that path name does not look right. I think I would have expected
something more like:
>
> "C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv"
>
> Any comments from Windows users?
>
> However,  you cannot "load" a .csv file. "load" is intended to load a
compiled .Rdata file as I understand it. It may do more but that's all I've
ever used it for.
>
> You probably want:
> dat1  <-
read.csv("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv")
>
> Depending on how the data file is set up you may need to add various
options to the read.csv file.
>
> read.csv()  assumes that the file has headers  for the columns and that
the separator between the columns is a blank space or spaces.
>
> Let's say the separator is a tab and there are no headers you would need
to change the read.csv() to
> xx  <-
read.csv("load("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv",
sep = "\t", header = FALSE)
>
> You need to open the data file in a text editor, Notebook will do, and
see what it looks like if my two suggestions, or combinations thereof,
don't work.
>
> Then do a ?read.csv or perhaps a ?read.table try to figure out what the
cryptic help documentation tells you. The solution will be there, it just
often is not obvious.. read.csv() is simply a subset of  the more powerful
read.table().
>
> I have great sympathy for you. For the first six months of using R, I
seemed to  spend more time trying to get the data into R than working on
the problem. Just to be encouraging. :).
>
> BTW if the instructor did not suggest it, I would recommend downloading
and installing RStudio. https://www.rstudio.com/products/rstudio/download/
. It is an excellent IDE and makes working with R much easier.
>
> @Ista
> While I agree that Heather should ask her instructor for help, I don't
see assisting a student getting data into R as helping with a programming
assignment. Perhaps at the margins but that is all.

I don't have any objection except the practical concern that people on this
list guessing what the problem might be is less likely to lead to a
satisfactory answer than asking the instructor. IMO the answers provided so
far may have actually increased the OP's confusion. Asking the instructor
directly seems to me more likely to produce an illuminating response.

Best,
Ista

>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: r-help at r-project.org
> > Sent: Sun, 14 Feb 2016 23:50:34 +0000 (UTC)
> > To: r-help at r-project.org
> > Subject: Re: [R] R 3.2.3 on Win8; mkdir command produces error
> >
> > As a follow-up to my request for help this morning, I have watched
> > tutorials on R all afternoon. Many topics come close to my problem, but
> > none specifically address my situation where "specdata" is not a text
> > file but a list of small files in a folder.I found a command that should
> > be more right than mkdir, but it still won't work for my assignment.
What
> > argument am I getting wrong?To recap, I can't access in R my data files
> > that are on my desktop. I need more understanding about how directories
> > transfer between Windows and R.
> >> dir.create('specdata')
> >
> >  > dir.exists("specdata")[1] TRUE
> Error:
> >> bad restore file magic number (file may be corrupted) -- no data
> >> loadedIn addition: Warning message:file ?001.csv? has magic number
> >> '"Date'  Use of save versions prior to 2 is deprecated
> >> pollutantmean("C:\Users\rhmichel\Desktop\rprog-data-specdata\specdata",
> >> "sulfate", 1:10)Error: '\U' used without hex digits in character string
> >> starting ""C:\U">
> > Thank you for any help you can provide me,Heather Michel
> >     On Sunday, February 14, 2016 2:40 PM, HEATHER MICHEL
> > <heathermichel at rocketmail.com> wrote:
> >
> >
> >  I am trying to complete a homework assignment, but I know very little
> > about R.The assignment says, "For this programming assignment you will
> > need to unzip this file and create the directory 'specdata".I unzipped
> > the file on my desktop, and my computer automatically created a new
> > folder which I renamed "specdata."However, when I try to make this
> > directory within R using mkdir, I get this:
> >> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo
> >> documentation for ?mkdir? in specified packages and libraries:you could
> >> try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found
> >
> > This makes me believe that some of the old command names have been
> > updated in this version that is only 2 months old. Of course, the
> > lectures I took notes on used an older version of R and were created
more
> > than 2 months ago.
> > Please tell me the command I should be using to create a directory named
> > 'specdata' in R 3.2.3
> > Heather Michel
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From michael.gang.peng at gmail.com  Mon Feb 15 17:17:25 2016
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Mon, 15 Feb 2016 11:17:25 -0500
Subject: [R] ts time-object indexing question?
In-Reply-To: <20160215105323.1626@web004.roc2.bluetie.com>
References: <20160215105323.1626@web004.roc2.bluetie.com>
Message-ID: <CAMjJGR0xM9-j+dE72s-MSwWBGQYL=wN0jZgM4-8fCpiXo932mg@mail.gmail.com>

a.ts[time(a.ts)==1965]

2016-02-15 10:53 GMT-05:00 ce <zadig_1 at excite.com>:

>
> Dear all,
>
> I can't find an answer to this simple question:
>
>  a.ts <- ts(1:10, frequency = 1, start = c(1959, 1))
>  > a.ts
> Time Series:
> Start = 1959
> End = 1968
> Frequency = 1
>  [1]  1  2  3  4  5  6  7  8  9 10
>
> Now I want to get let's say value for 1965 , how to get it ?
> > a.ts["1965"]
> [1] NA
>
> doesn't work .
>
> And  how I can get the date of a.ts[5]  ?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Mon Feb 15 17:39:29 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 15 Feb 2016 16:39:29 +0000
Subject: [R] filtering a data frame from a column of type integer
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DB8A95E@ESINO.regionemarche.intra>

Dear R list users,
I am not able to perform a trivial filter of a data frame.
From a txt file (df_file.txt) of this form:

sensor_RM station_RM place_RM municipality_RM Y_init_RM M_init_RM D_init_RM Y_fin_RM M_fin_RM D_fin_RM goes_on notes sensor_RT station_RT net Omogneneous
2000 1510 Candelara Pesaro 1951 1 1 1997 8 4 NO NA NA NA NA NO
2004 2230 Montemonaco Montemonaco 1951 1 1 2008 1 1 Y NA 1586 142 RT Y
2011 2240 Diga_di_Carassai Carassai 1951 1 1 2008 1 1 Y passata_in_RT_il_20140314_chiamata_Carassai 2976 708 RT Y
2012 2250 Monterubbiano Monterubbiano 1951 1 1 2008 1 1 NO NA NA NA NA NO
2014 1700 Fonte_Avellana Serra_S_Abbondio 1951 1 1 2005 1 4 Y NA 1206 109 RT Y
2016 1710 Pergola Pergola 1951 1 1 2008 1 7 Y NA 1198 108 RT Y

I load it with

df <- read.table(file="df_file.txt", header = TRUE, sep=" ", stringsAsFactors=FALSE)

There are 16 columns, some of them are integer and others are character.

My problem is that

station_list <- df[df$station_RT==142, ]

should give me only the second row, while I get

     sensor_RM station_RM    place_RM municipality_RM Y_init_RM M_init_RM
NA          NA         NA        <NA>            <NA>        NA        NA
2         2004       2230 Montemonaco     Montemonaco      1951         1
NA.1        NA         NA        <NA>            <NA>        NA        NA
     D_init_RM Y_fin_RM M_fin_RM D_fin_RM goes_on notes sensor_RT station_RT
NA          NA       NA       NA       NA    <NA>  <NA>        NA         NA
2            1     2008        1        1       Y  <NA>      1586        142
NA.1        NA       NA       NA       NA    <NA>  <NA>        NA         NA
      net Omogneneous
NA   <NA>        <NA>
2      RT           Y
NA.1 <NA>        <NA>

Why? I struggled for a long time trying to understand where is the bug.
Could you please help me in that?

Thank you
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From huzefa.khalil at umich.edu  Mon Feb 15 17:52:42 2016
From: huzefa.khalil at umich.edu (Huzefa Khalil)
Date: Mon, 15 Feb 2016 11:52:42 -0500
Subject: [R] filtering a data frame from a column of type integer
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DB8A95E@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DB8A95E@ESINO.regionemarche.intra>
Message-ID: <CADsG8gPcNH_JFK_CyzBVoDGi5-T6Jf1L8YZp51HMh+omdwdFEA@mail.gmail.com>

This is because of the presence of NA's in your "station_RT" column. If you
use which(), it will give you the correct result:

station_list <- df[which(df$station_RT==142), ]

best,
huzefa

On Mon, Feb 15, 2016 at 11:39 AM, Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Dear R list users,
> I am not able to perform a trivial filter of a data frame.
> From a txt file (df_file.txt) of this form:
>
> sensor_RM station_RM place_RM municipality_RM Y_init_RM M_init_RM
> D_init_RM Y_fin_RM M_fin_RM D_fin_RM goes_on notes sensor_RT station_RT net
> Omogneneous
> 2000 1510 Candelara Pesaro 1951 1 1 1997 8 4 NO NA NA NA NA NO
> 2004 2230 Montemonaco Montemonaco 1951 1 1 2008 1 1 Y NA 1586 142 RT Y
> 2011 2240 Diga_di_Carassai Carassai 1951 1 1 2008 1 1 Y
> passata_in_RT_il_20140314_chiamata_Carassai 2976 708 RT Y
> 2012 2250 Monterubbiano Monterubbiano 1951 1 1 2008 1 1 NO NA NA NA NA NO
> 2014 1700 Fonte_Avellana Serra_S_Abbondio 1951 1 1 2005 1 4 Y NA 1206 109
> RT Y
> 2016 1710 Pergola Pergola 1951 1 1 2008 1 7 Y NA 1198 108 RT Y
>
> I load it with
>
> df <- read.table(file="df_file.txt", header = TRUE, sep=" ",
> stringsAsFactors=FALSE)
>
> There are 16 columns, some of them are integer and others are character.
>
> My problem is that
>
> station_list <- df[df$station_RT==142, ]
>
> should give me only the second row, while I get
>
>      sensor_RM station_RM    place_RM municipality_RM Y_init_RM M_init_RM
> NA          NA         NA        <NA>            <NA>        NA        NA
> 2         2004       2230 Montemonaco     Montemonaco      1951         1
> NA.1        NA         NA        <NA>            <NA>        NA        NA
>      D_init_RM Y_fin_RM M_fin_RM D_fin_RM goes_on notes sensor_RT
> station_RT
> NA          NA       NA       NA       NA    <NA>  <NA>        NA
>  NA
> 2            1     2008        1        1       Y  <NA>      1586
> 142
> NA.1        NA       NA       NA       NA    <NA>  <NA>        NA
>  NA
>       net Omogneneous
> NA   <NA>        <NA>
> 2      RT           Y
> NA.1 <NA>        <NA>
>
> Why? I struggled for a long time trying to understand where is the bug.
> Could you please help me in that?
>
> Thank you
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From stev0175 at gmail.com  Mon Feb 15 17:58:37 2016
From: stev0175 at gmail.com (Jeff Stevens)
Date: Mon, 15 Feb 2016 10:58:37 -0600
Subject: [R] Condition layer across panels in lattice
Message-ID: <CAJ6UiDSRcSbtzwqMP7NW_efsG1gV4hQgKRJJBB9WS=2hcHNCwA@mail.gmail.com>

I would like to plot individual subject means for two different
conditions in a lattice stripplot with two panels. I would also like
to add within-subject confidence intervals that I have calculated and
stored in separate data frame. I am trying to overlay these confidence
intervals with latticeExtra's layer function. When I add the layer,
either both sets of intervals display on both panels (as illustrated
in code) or both sets of intervals display on only the first panel if
I add [subscripts] to the x's and y's in the layer command
(illustrated in second code clip). How do I get the appropriate
intervals to display on the appropriate panel?

Produces stripplot with both sets of intervals on both panels:
raw_data <- data.frame(subject = rep(1:6, 4), cond1 =
as.factor(rep(1:2, each = 12)), cond2 = rep(rep(c("A", "B"), each =
6), 2), response = c(2:7, 6:11, 3:8, 7:12))
summary_data <- data.frame(cond1 = as.factor(rep(1:2, each = 2)),
cond2 = rep(c("A", "B"), times = 2), mean = aggregate(response ~ cond2
* cond1, raw_data, mean)$response, within_ci = c(0.57, 0.54, 0.6,
0.63))
summary_data$lci <- summary_data$mean - summary_data$within_ci
summary_data$uci <- summary_data$mean + summary_data$within_ci

subject_stripplot <- stripplot(response ~ cond1 | cond2, groups =
subject, data = raw_data,
  panel = function(x, y, ...) {
    panel.stripplot(x, y, type = "b", lty = 2, ...)
    panel.average(x, y, fun = mean, lwd = 2, col = "black", ...)    #
plot line connecting means
  }
)
addWithinCI <- layer(panel.segments(x0 = cond1, y0 = lci, x1 = cond1,
y1 = uci, subscripts = TRUE), data = summary_data, under = FALSE)
plot(subject_stripplot + addWithinCI)

Produces stripplot with both sets of intervals on only the first panel:
addWithinCI2 <- layer(panel.segments(x0 = cond1[subscripts], y0 =
lci[subscripts], x1 = cond1[subscripts], y1 = uci[subscripts],
subscripts = TRUE), data = summary_data, under = FALSE)
plot(subject_stripplot + addWithinCI2)

Thanks,
Jeff


From alaios at yahoo.com  Mon Feb 15 18:04:38 2016
From: alaios at yahoo.com (Alaios)
Date: Mon, 15 Feb 2016 17:04:38 +0000 (UTC)
Subject: [R] Data structure to hold the following
References: <1373259580.3598597.1455555878359.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1373259580.3598597.1455555878359.JavaMail.yahoo@mail.yahoo.com>

Dear all,I am using R to emulate radio propagation dynamics.
I have 90 antennas in a region and each of these 90 antennas hold information about 36 points (these are all exactly the same and there is no need to differentiate them further)
Each of these antennas now should keep information about the distances from the 36 points (each of the 90 antennas have a different distance for each of the unique 36 points), which gives use in total 90 times a 36 elements vector.
Each antenna should also keep a [36,600] matrix (each matrix describes in details the relation between one of the 90 antennas and one of the 36 points and 600 elements are needed for doing that). In total that mines 90 times [36,600] matrices

What is an appropriate data structure for doing that in R ? I am giving fixed numbers here but in reality the 90,36 and 600 are just examples. Variable should be used here and thus we do not talk about fixed data structures before hand. 

I would like to thank you for your replyRegardsAlex


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 15 19:17:32 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Feb 2016 10:17:32 -0800
Subject: [R] Data structure to hold the following
In-Reply-To: <1373259580.3598597.1455555878359.JavaMail.yahoo@mail.yahoo.com>
References: <1373259580.3598597.1455555878359.JavaMail.yahoo.ref@mail.yahoo.com>
	<1373259580.3598597.1455555878359.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbReY-CFDEWpuTYYRE165L3QeY1V+52Vsb4PJM3AA7XXpA@mail.gmail.com>

I would say that it depends on what you want to do with the data.

Bert



On Monday, February 15, 2016, Alaios via R-help <r-help at r-project.org>
wrote:

> Dear all,I am using R to emulate radio propagation dynamics.
> I have 90 antennas in a region and each of these 90 antennas hold
> information about 36 points (these are all exactly the same and there is no
> need to differentiate them further)
> Each of these antennas now should keep information about the distances
> from the 36 points (each of the 90 antennas have a different distance for
> each of the unique 36 points), which gives use in total 90 times a 36
> elements vector.
> Each antenna should also keep a [36,600] matrix (each matrix describes in
> details the relation between one of the 90 antennas and one of the 36
> points and 600 elements are needed for doing that). In total that mines 90
> times [36,600] matrices
>
> What is an appropriate data structure for doing that in R ? I am giving
> fixed numbers here but in reality the 90,36 and 600 are just examples.
> Variable should be used here and thus we do not talk about fixed data
> structures before hand.
>
> I would like to thank you for your replyRegardsAlex
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From shivi.bhatia at safexpress.com  Mon Feb 15 14:06:02 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Mon, 15 Feb 2016 18:36:02 +0530
Subject: [R] Error with Twitter Authorization for Sentiment Analysis
In-Reply-To: <2E238312-8C3B-4D1C-9C7D-0EA3EBD89C9F@gmail.com>
References: <002701d16710$a76de5b0$f649b110$@safexpress.com>
	<2E238312-8C3B-4D1C-9C7D-0EA3EBD89C9F@gmail.com>
Message-ID: <000001d167f1$937d59a0$ba780ce0$@safexpress.com>

Hi Sandeep,

Here is my authorization code:

setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
.

Prior to this I have just added my consumer key and the other var after
logging at https://apps.twitter.com. Does this help.

-----Original Message-----
From: Sandeep Rana [mailto:sunnysingha.analytics at gmail.com]
Sent: Monday, February 15, 2016 5:52 PM
To: SHIVI BHATIA <shivi.bhatia at safexpress.com>
Cc: r-help at r-project.org
Subject: Re: [R] Error with Twitter Authorization for Sentiment Analysis

Shivi,
Could you also share the piece of code to have a look at ?

Regards,
Sunny Singha

> On 14-Feb-2016, at 3:45 PM, SHIVI BHATIA <shivi.bhatia at safexpress.com>
wrote:
>
> Dear Team,
>
>
>
> Every now and then I face issues while connecting to Twitter:
>
>
>
> Error in check_twitter_oauth() : OAuth authentication error:
>
> This most likely means that you have incorrectly called
> setup_twitter_oauth()'
>
>
>
> I have checked multiple github suggestion and statsexchange forum &
> have followed all suggestion such as to update httpuv package and
> calling out the library names in a certain manner however I am still
> not successful.. Also apart from these there was also recommendation
> on httr package to be called first though while calling the httr package I
got this message:
>
>
>
> Error in unloadNamespace(package) :
>  namespace 'httr' is imported by 'twitteR' so cannot be unloaded
>
>
> Not sure on what is to be done here hence require help from the forum.
>
>
>
>
>
> Thanks, Shivi
>
> Mb: 9891002021
>
>
>
> This e-mail is confidential. It may also be legally privileged. If you are
not the addressee you may not copy, forward, disclose or use any part of it.
If you have received this message in error, please delete it and all copies
from your system and notify the sender immediately by return e-mail.
Internet communications cannot be guaranteed to be timely, secure, error or
virus-free. The sender does not accept liability for any errors or
omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.


From asma.rabe at gmail.com  Mon Feb 15 13:41:54 2016
From: asma.rabe at gmail.com (asma.rabe at gmail.com)
Date: Mon, 15 Feb 2016 21:41:54 +0900
Subject: [R] Convert list to data frame
Message-ID: <7EDCB1C9-9EDA-4613-BEA7-718650F9B87A@gmail.com>

Hi,

I  read data from file as follows

Data<-read.table("file.txt",header=T,sep="\t")

mode(Data)
list

I want to convert data to data frame, I tried the following:

as.data.frame(Data)
data.frame(Data)

But the Data did not change

When I tried
as.data.frame(unlist(Data))

The Data converted to a vector not to a data frame. Any idea ?

Thank you in advance


From sarah.goslee at gmail.com  Mon Feb 15 20:08:30 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 15 Feb 2016 14:08:30 -0500
Subject: [R] Convert list to data frame
In-Reply-To: <7EDCB1C9-9EDA-4613-BEA7-718650F9B87A@gmail.com>
References: <7EDCB1C9-9EDA-4613-BEA7-718650F9B87A@gmail.com>
Message-ID: <CAM_vjukhzq90OQ+cPfT097YvDhnr+7q7NtOZ+N8f8S-rW89qLg@mail.gmail.com>

On Monday, February 15, 2016, <asma.rabe at gmail.com> wrote:

> Hi,
>
> I  read data from file as follows
>
> Data<-read.table("file.txt",header=T,sep="\t")
>
> mode(Data)
> list


Data is a data frame; that's what read.table() produces. A data frame is a
special type of list.

Take a look at
class(Data)



>
> I want to convert data to data frame, I tried the following:
>
> as.data.frame(Data)
> data.frame(Data)
>
> But the Data did not change


Because it was already a data frame.



>
> When I tried
> as.data.frame(unlist(Data))
>
> The Data converted to a vector not to a data frame. Any idea ?
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Feb 15 20:12:20 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 15 Feb 2016 14:12:20 -0500
Subject: [R] Convert list to data frame
In-Reply-To: <7EDCB1C9-9EDA-4613-BEA7-718650F9B87A@gmail.com>
References: <7EDCB1C9-9EDA-4613-BEA7-718650F9B87A@gmail.com>
Message-ID: <56C22314.8010108@gmail.com>

On 15/02/2016 7:41 AM, asma.rabe at gmail.com wrote:
> Hi,
>
> I  read data from file as follows
>
> Data<-read.table("file.txt",header=T,sep="\t")
>
> mode(Data)
> list
>
> I want to convert data to data frame, I tried the following:
>
> as.data.frame(Data)
> data.frame(Data)
>
> But the Data did not change

It is already a dataframe.  Whoever told you that mode(Data) is the way 
to test for that is giving you bad advice.  (Probably the same source 
that said T always means TRUE.)

There's a function is.data.frame() that does the proper test, i.e.

inherits(Data, "data.frame")

Or you can look at class(Data).

Duncan Murdoch

>
> When I tried
> as.data.frame(unlist(Data))
>
> The Data converted to a vector not to a data frame. Any idea ?
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Mon Feb 15 22:04:02 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 15 Feb 2016 13:04:02 -0800
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <CA+vqiLEUuF9wQEzhVXNQBbowuc+9K1ohd7gYfR2Y196pieNX5g@mail.gmail.com>
References: <879632620.1043610.1455478822248.javamail.yahoo.ref@mail.yahoo.com>
	<1001578271.3233546.1455493834255.javamail.yahoo@mail.yahoo.com>
	<262825107.3212829.1455493360506.javamail.yahoo@mail.yahoo.com>
	<5cc0a6e5610.00000250jrkrideau@inbox.com>
	<879632620.1043610.1455478822248.javamail.yahoo@mail.yahoo.com>
Message-ID: <60879E2D775.00000796jrkrideau@inbox.com>

John Kane
Kingston ON Canada

-----Original Message-----
From: istazahn at gmail.com
Sent: Mon, 15 Feb 2016 11:06:47 -0500
To: jrkrideau at inbox.com
Subject: Re: [R] R 3.2.3 on Win8; mkdir command produces error

 On Feb 15, 2016 8:53 AM, "John Kane" <jrkrideau at inbox.com> wrote:
 >
 > I'd say that Boris Steipe's suggestion is the most likely answer to the problem.? Also, it's been a long time since I used Windows (deo gratias) but that path name does not look right. I think I would have expected something more like:
 >
 > "C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv"
 >
 > Any comments from Windows users?
 >
 > However,? you cannot "load" a .csv file. "load" is intended to load a compiled .Rdata file as I understand it. It may do more but that's all I've ever used it for.
 >
 > You probably want:
 > dat1? <-? read.csv("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv")
 >
 > Depending on how the data file is set up you may need to add various options to the read.csv file.
 >
 > read.csv()? assumes that the file has headers? for the columns and that the separator between the columns is a blank space or spaces.
 >
 > Let's say the separator is a tab and there are no headers you would need to change the read.csv() to
 > xx? <-? read.csv("load("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv", sep = "\t", header = FALSE)
 >
 > You need to open the data file in a text editor, Notebook will do, and see what it looks like if my two suggestions, or combinations thereof, don't work.
 >
 > Then do a ?read.csv or perhaps a ?read.table try to figure out what the cryptic help documentation tells you. The solution will be there, it just often is not obvious.. read.csv() is simply a subset of? the more powerful read.table().
 >
 > I have great sympathy for you. For the first six months of using R, I seemed to? spend more time trying to get the data into R than working on the problem. Just to be encouraging. :).
 >
 > BTW if the instructor did not suggest it, I would recommend downloading and installing RStudio. https://www.rstudio.com/products/rstudio/download/ [https://www.rstudio.com/products/rstudio/download/] . It is an excellent IDE and makes working with R much easier.
 >
 > @Ista
 > While I agree that Heather should ask her instructor for help, I don't see assisting a student getting data into R as helping with a programming assignment. Perhaps at the margins but that is all.

	I don't have any objection except the practical concern that people on this list guessing what the problem might be is less likely to lead to a satisfactory answer than asking the instructor. IMO the answers provided so far may have actually increased the OP's confusion. Asking the instructor directly seems to me more likely to produce an illuminating response. 

	Best,
 Ista


Good point but we already started confusing her :(
	>
 > John Kane
 > Kingston ON Canada
 >
 >
 > > -----Original Message-----
 > > From: r-help at r-project.org
 > > Sent: Sun, 14 Feb 2016 23:50:34 +0000 (UTC)
 > > To: r-help at r-project.org
 > > Subject: Re: [R] R 3.2.3 on Win8; mkdir command produces error
 > >
 > > As a follow-up to my request for help this morning, I have watched
 > > tutorials on R all afternoon. Many topics come close to my problem, but
 > > none specifically address my situation where "specdata" is not a text
 > > file but a list of small files in a folder.I found a command that should
 > > be more right than mkdir, but it still won't work for my assignment. What
 > > argument am I getting wrong?To recap, I can't access in R my data files
 > > that are on my desktop. I need more understanding about how directories
 > > transfer between Windows and R.
 > >> dir.create('specdata')
 > >
 > >? > dir.exists("specdata")[1] TRUE
 > Error:
 > >> bad restore file magic number (file may be corrupted) -- no data
 > >> loadedIn addition: Warning message:file ?001.csv? has magic number
 > >> '"Date'? Use of save versions prior to 2 is deprecated
 > >> pollutantmean("C:\Users\rhmichel\Desktop\rprog-data-specdata\specdata",
 > >> "sulfate", 1:10)Error: '\U' used without hex digits in character string
 > >> starting ""C:\U">
 > > Thank you for any help you can provide me,Heather Michel
 > >? ? ?On Sunday, February 14, 2016 2:40 PM, HEATHER MICHEL
 > > <heathermichel at rocketmail.com> wrote:
 > >
 > >
 > >? I am trying to complete a homework assignment, but I know very little
 > > about R.The assignment says, "For this programming assignment you will
 > > need to unzip this file and create the directory 'specdata".I unzipped
 > > the file on my desktop, and my computer automatically created a new
 > > folder which I renamed "specdata."However, when I try to make this
 > > directory within R using mkdir, I get this:
 > >> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo
 > >> documentation for ?mkdir? in specified packages and libraries:you could
 > >> try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found
 > >
 > > This makes me believe that some of the old command names have been
 > > updated in this version that is only 2 months old. Of course, the
 > > lectures I took notes on used an older version of R and were created more
 > > than 2 months ago.
 > > Please tell me the command I should be using to create a directory named
 > > 'specdata' in R 3.2.3
 > > Heather Michel
 > >
 > >
 > >? ? ? ?[[alternative HTML version deleted]]
 > >
 > > ______________________________________________
 > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > > PLEASE do read the posting guide
 > > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > > and provide commented, minimal, self-contained, reproducible code.
 >
 > ____________________________________________________________
 > FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 > Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] to find out more!
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From r.turner at auckland.ac.nz  Mon Feb 15 22:39:10 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 16 Feb 2016 10:39:10 +1300
Subject: [R] [FORGED]  Error installing the package "Cairo"
In-Reply-To: <CAM++Fzta7gwvPsbTGA_eNsOuHrA=tL+TLs3L_9pcuvYiriYSRA@mail.gmail.com>
References: <CAM++Fzta7gwvPsbTGA_eNsOuHrA=tL+TLs3L_9pcuvYiriYSRA@mail.gmail.com>
Message-ID: <56C2457E.2050705@auckland.ac.nz>

On 15/02/16 22:51, Sandeep Mallya wrote:
> Hello all,
>
> I am trying to install the package Cairo on RedHat running R version 3.2.3.
> So far I have tried install.packages("Cairo")
> R CMD INSTALL Cairo_1.5-9.tar.gz
>
> Both the approaches giving me the same error below.
>
>
> Error : .onLoad failed in loadNamespace() for 'Cairo', details:
>    call: dyn.load(file, DLLpath = DLLpath, ...)
>    error: unable to load shared object
> '/home/sandeep/R/x86_64-pc-linux-gnu-library/3.2/Cairo/libs/Cairo.so':
>    libpng15.so.15: cannot open shared object file: No such file or directory
> Error: loading failed
> Execution halted
>
>
> Can someone please guide me.

You apparently do not have the "cairo infrastructure" installed on your 
computer.  You probably need to do something like:

sudo yum install cairo.x86_64 # Prob'ly not necessary, this package
                               # should be already there.
sudo yum install cairo-devel.x86_64

You may not need to include the ".x86.64" strings, I'm not sure.  Or you 
may need *not* to include them!

HTH.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pgilbert902 at gmail.com  Tue Feb 16 00:27:03 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 15 Feb 2016 18:27:03 -0500
Subject: [R] FW: Multivariate ARIMA
In-Reply-To: <mailman.1.1455447601.17866.r-help@r-project.org>
References: <mailman.1.1455447601.17866.r-help@r-project.org>
Message-ID: <56C25EC7.9070308@gmail.com>

See also package dse.  There are examples in the guide: 
http://cran.at.r-project.org/web/packages/dse/vignettes/Guide.pdf

Paul

On 02/14/2016 06:00 AM, r-help-request at r-project.org wrote:
> Date: Fri, 12 Feb 2016 18:12:37 +0000 From: Thomas
> Lofaro<Thomas.Lofaro at SurveySampling.com> To:"r-help at R-project.org"
> <r-help at R-project.org> Subject: [R] FW: Multivariate ARIMA
> Question.... Message-ID:
> <BN4PR07MB22103CC8EB3FF13CCDF00D4D93A90 at BN4PR07MB2210.namprd07.prod.outlook.com>
>
>  Content-Type: text/plain; charset="UTF-8"
>
> Hi, sorry, I will try to make this short. Essentially, what I am
> trying to do is run a multivariate ARIMA model predicting one
> variable with another.  However, the only R packages I have found to
> accommodate such an analysis are ARIMAX and VAR.  Unfortunately,
> there don?t seem to be any good tutorials or demonstrations of how to
> actually perform this analysis in practice, on my two columns of
> data.  I was wondering if anyone knew of a resource that might help
> (or one that provided an example of r code to accomplish this).
> Thanks sooo much!


From dulcalma at bigpond.com  Tue Feb 16 05:15:42 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 16 Feb 2016 15:15:42 +1100
Subject: [R] Condition layer across panels in lattice
References: <CAJ6UiDSRcSbtzwqMP7NW_efsG1gV4hQgKRJJBB9WS=2hcHNCwA@mail.gmail.com>
Message-ID: <000a01d16870$b499a8d0$1dccfa70$@bigpond.com>

Sorry forgot to reply to list.

In addition (untested) modifying demo(lattice::intervals) to suit may help

Duncan 

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Tuesday, 16 February 2016 12:12
To: 'Jeff Stevens'
Subject: RE: [R] Condition layer across panels in lattice

Hi Jeff

Try this

mypanel <-
function(x, y, ...,  groups, type, lty){

    pnl = panel.number()

    panel.xyplot(x, y, ..., groups = groups, type = type, lty = lty)

    panel.average(x, y, horizontal = FALSE,
                  col = "black", lwd = 3)

   # print(summary_data[,"lci"][summary_data$cond2==LETTERS[1:2][pnl]])
   # print(summary_data[,"uci"][summary_data$cond2==LETTERS[1:2][pnl]])

    panel.segments(x0 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y0 =
summary_data[,"lci"][summary_data$cond2==LETTERS[1:2][pnl]],
                   x1 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y1 =
summary_data[,"uci"][summary_data$cond2==LETTERS[1:2][pnl]])
    panel.segments(x0 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y0 =
summary_data[,"lci"][summary_data$cond2==LETTERS[1:2][pnl]],
                   x1 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y1 =
summary_data[,"uci"][summary_data$cond2==LETTERS[1:2][pnl]])

}

    stripplot(response ~ cond1 | cond2, data = raw_data,
              groups = subject,
              #lci = summary_data$lci,
              #uci = summary_data$uci,
              #scond1 = summary_data$cond1,
              type = "b",lty = 2,
              panel = mypanel

    )

It's a bit kludgy - I need some coffee to sort out the subscripting.

I used the panel.number to group the panels because the grouping factor for
the raw_data (subjects) is different from the summary_data (cond2)

I tried to keep it within lattice itself without having to go to
latticeExtra:::layer as you had. layering can have adverse changes to the
graphics appearance sometimes.

For the basis on why I did it this way see
 https://stat.ethz.ch/pipermail/r-help/2009-November/412966.html

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Stevens
Sent: Tuesday, 16 February 2016 03:59
To: R-help Forum
Subject: [R] Condition layer across panels in lattice

I would like to plot individual subject means for two different
conditions in a lattice stripplot with two panels. I would also like
to add within-subject confidence intervals that I have calculated and
stored in separate data frame. I am trying to overlay these confidence
intervals with latticeExtra's layer function. When I add the layer,
either both sets of intervals display on both panels (as illustrated
in code) or both sets of intervals display on only the first panel if
I add [subscripts] to the x's and y's in the layer command
(illustrated in second code clip). How do I get the appropriate
intervals to display on the appropriate panel?

Produces stripplot with both sets of intervals on both panels:
raw_data <- data.frame(subject = rep(1:6, 4), cond1 =
as.factor(rep(1:2, each = 12)), cond2 = rep(rep(c("A", "B"), each =
6), 2), response = c(2:7, 6:11, 3:8, 7:12))
summary_data <- data.frame(cond1 = as.factor(rep(1:2, each = 2)),
cond2 = rep(c("A", "B"), times = 2), mean = aggregate(response ~ cond2
* cond1, raw_data, mean)$response, within_ci = c(0.57, 0.54, 0.6,
0.63))
summary_data$lci <- summary_data$mean - summary_data$within_ci
summary_data$uci <- summary_data$mean + summary_data$within_ci

subject_stripplot <- stripplot(response ~ cond1 | cond2, groups =
subject, data = raw_data,
  panel = function(x, y, ...) {
    panel.stripplot(x, y, type = "b", lty = 2, ...)
    panel.average(x, y, fun = mean, lwd = 2, col = "black", ...)    #
plot line connecting means
  }
)
addWithinCI <- layer(panel.segments(x0 = cond1, y0 = lci, x1 = cond1,
y1 = uci, subscripts = TRUE), data = summary_data, under = FALSE)
plot(subject_stripplot + addWithinCI)

Produces stripplot with both sets of intervals on only the first panel:
addWithinCI2 <- layer(panel.segments(x0 = cond1[subscripts], y0 =
lci[subscripts], x1 = cond1[subscripts], y1 = uci[subscripts],
subscripts = TRUE), data = summary_data, under = FALSE)
plot(subject_stripplot + addWithinCI2)

Thanks,
Jeff

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Feb 16 05:50:14 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 16 Feb 2016 15:50:14 +1100
Subject: [R] Condition layer across panels in lattice
In-Reply-To: <000a01d16870$b499a8d0$1dccfa70$@bigpond.com>
References: <CAJ6UiDSRcSbtzwqMP7NW_efsG1gV4hQgKRJJBB9WS=2hcHNCwA@mail.gmail.com>
	<000a01d16870$b499a8d0$1dccfa70$@bigpond.com>
Message-ID: <000b01d16875$86d78a70$94869f50$@bigpond.com>

Adding a condition column in the summary_data simplifies things a bit

summary_data$cond3 <- sapply(summary_data$cond2, pmatch, LETTERS)

mypanel <-
function(x, y, ..., lci, uci, scond1, scond3, groups, type, lty){

    pnl = panel.number()

    panel.xyplot(x, y, ..., groups = groups, type = type, lty = lty)

    panel.average(x, y, horizontal = FALSE,
                                 col = "black",

                                  lwd = 3)

    panel.segments(x0 = scond1[scond3 == pnl],
                   y0 = lci[scond3 == pnl],
                   x1 = scond1[scond3 == pnl],
                   y1 = uci[scond3 == pnl])
}

    with(summary_data,
    stripplot(response ~ cond1 | cond2, data = raw_data,
              groups = subject,
              lci = lci,
              uci = uci,
              scond1 = summary_data$cond1,
              scond3 = cond3,
              type = "b",
              lty = 2,
              panel = mypanel

    ))

Regards

Duncan


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
Mackay
Sent: Tuesday, 16 February 2016 15:16
To: R
Subject: Re: [R] Condition layer across panels in lattice

Sorry forgot to reply to list.

In addition (untested) modifying demo(lattice::intervals) to suit may help

Duncan 

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Tuesday, 16 February 2016 12:12
To: 'Jeff Stevens'
Subject: RE: [R] Condition layer across panels in lattice

Hi Jeff

Try this

mypanel <-
function(x, y, ...,  groups, type, lty){

    pnl = panel.number()

    panel.xyplot(x, y, ..., groups = groups, type = type, lty = lty)

    panel.average(x, y, horizontal = FALSE,
                  col = "black", lwd = 3)

   # print(summary_data[,"lci"][summary_data$cond2==LETTERS[1:2][pnl]])
   # print(summary_data[,"uci"][summary_data$cond2==LETTERS[1:2][pnl]])

    panel.segments(x0 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y0 =
summary_data[,"lci"][summary_data$cond2==LETTERS[1:2][pnl]],
                   x1 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y1 =
summary_data[,"uci"][summary_data$cond2==LETTERS[1:2][pnl]])
    panel.segments(x0 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y0 =
summary_data[,"lci"][summary_data$cond2==LETTERS[1:2][pnl]],
                   x1 =
summary_data[,"cond1"][summary_data$cond2==LETTERS[1:2][pnl]],
                   y1 =
summary_data[,"uci"][summary_data$cond2==LETTERS[1:2][pnl]])

}

    stripplot(response ~ cond1 | cond2, data = raw_data,
              groups = subject,
              #lci = summary_data$lci,
              #uci = summary_data$uci,
              #scond1 = summary_data$cond1,
              type = "b",lty = 2,
              panel = mypanel

    )

It's a bit kludgy - I need some coffee to sort out the subscripting.

I used the panel.number to group the panels because the grouping factor for
the raw_data (subjects) is different from the summary_data (cond2)

I tried to keep it within lattice itself without having to go to
latticeExtra:::layer as you had. layering can have adverse changes to the
graphics appearance sometimes.

For the basis on why I did it this way see
 https://stat.ethz.ch/pipermail/r-help/2009-November/412966.html

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Stevens
Sent: Tuesday, 16 February 2016 03:59
To: R-help Forum
Subject: [R] Condition layer across panels in lattice

I would like to plot individual subject means for two different
conditions in a lattice stripplot with two panels. I would also like
to add within-subject confidence intervals that I have calculated and
stored in separate data frame. I am trying to overlay these confidence
intervals with latticeExtra's layer function. When I add the layer,
either both sets of intervals display on both panels (as illustrated
in code) or both sets of intervals display on only the first panel if
I add [subscripts] to the x's and y's in the layer command
(illustrated in second code clip). How do I get the appropriate
intervals to display on the appropriate panel?

Produces stripplot with both sets of intervals on both panels:
raw_data <- data.frame(subject = rep(1:6, 4), cond1 =
as.factor(rep(1:2, each = 12)), cond2 = rep(rep(c("A", "B"), each =
6), 2), response = c(2:7, 6:11, 3:8, 7:12))
summary_data <- data.frame(cond1 = as.factor(rep(1:2, each = 2)),
cond2 = rep(c("A", "B"), times = 2), mean = aggregate(response ~ cond2
* cond1, raw_data, mean)$response, within_ci = c(0.57, 0.54, 0.6,
0.63))
summary_data$lci <- summary_data$mean - summary_data$within_ci
summary_data$uci <- summary_data$mean + summary_data$within_ci

subject_stripplot <- stripplot(response ~ cond1 | cond2, groups =
subject, data = raw_data,
  panel = function(x, y, ...) {
    panel.stripplot(x, y, type = "b", lty = 2, ...)
    panel.average(x, y, fun = mean, lwd = 2, col = "black", ...)    #
plot line connecting means
  }
)
addWithinCI <- layer(panel.segments(x0 = cond1, y0 = lci, x1 = cond1,
y1 = uci, subscripts = TRUE), data = summary_data, under = FALSE)
plot(subject_stripplot + addWithinCI)

Produces stripplot with both sets of intervals on only the first panel:
addWithinCI2 <- layer(panel.segments(x0 = cond1[subscripts], y0 =
lci[subscripts], x1 = cond1[subscripts], y1 = uci[subscripts],
subscripts = TRUE), data = summary_data, under = FALSE)
plot(subject_stripplot + addWithinCI2)

Thanks,
Jeff

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Tue Feb 16 07:16:53 2016
From: alaios at yahoo.com (Alaios)
Date: Tue, 16 Feb 2016 06:16:53 +0000 (UTC)
Subject: [R] Data structure to hold the following
In-Reply-To: <CAGxFJbReY-CFDEWpuTYYRE165L3QeY1V+52Vsb4PJM3AA7XXpA@mail.gmail.com>
References: <CAGxFJbReY-CFDEWpuTYYRE165L3QeY1V+52Vsb4PJM3AA7XXpA@mail.gmail.com>
Message-ID: <889379425.3677151.1455603413513.JavaMail.yahoo@mail.yahoo.com>

The tables and vectors storing the data will be used for accessing the data (sequentially is also fine) to do calculations as needed.
RegardsAlex 

    On Monday, February 15, 2016 7:17 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 I would say that it depends on what you want to do with the data.
Bert


On Monday, February 15, 2016, Alaios via R-help <r-help at r-project.org> wrote:

Dear all,I am using R to emulate radio propagation dynamics.
I have 90 antennas in a region and each of these 90 antennas hold information about 36 points (these are all exactly the same and there is no need to differentiate them further)
Each of these antennas now should keep information about the distances from the 36 points (each of the 90 antennas have a different distance for each of the unique 36 points), which gives use in total 90 times a 36 elements vector.
Each antenna should also keep a [36,600] matrix (each matrix describes in details the relation between one of the 90 antennas and one of the 36 points and 600 elements are needed for doing that). In total that mines 90 times [36,600] matrices

What is an appropriate data structure for doing that in R ? I am giving fixed numbers here but in reality the 90,36 and 600 are just examples. Variable should be used here and thus we do not talk about fixed data structures before hand.

I would like to thank you for your replyRegardsAlex


? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



  
	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Tue Feb 16 12:16:08 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Tue, 16 Feb 2016 11:16:08 +0000
Subject: [R] filtering a data frame from a column of type integer
In-Reply-To: <CADsG8gPcNH_JFK_CyzBVoDGi5-T6Jf1L8YZp51HMh+omdwdFEA@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3DB8A95E@ESINO.regionemarche.intra>,
	<CADsG8gPcNH_JFK_CyzBVoDGi5-T6Jf1L8YZp51HMh+omdwdFEA@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DB8AA25@ESINO.regionemarche.intra>

Thank you
Stefano

________________________________
Da: Huzefa Khalil [huzefa.khalil at umich.edu]
Inviato: luned? 15 febbraio 2016 17.52
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] filtering a data frame from a column of type integer

This is because of the presence of NA's in your "station_RT" column. If you use which(), it will give you the correct result:

station_list <- df[which(df$station_RT==142), ]

best,
huzefa

On Mon, Feb 15, 2016 at 11:39 AM, Stefano Sofia <stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>> wrote:
Dear R list users,
I am not able to perform a trivial filter of a data frame.
>From a txt file (df_file.txt) of this form:

sensor_RM station_RM place_RM municipality_RM Y_init_RM M_init_RM D_init_RM Y_fin_RM M_fin_RM D_fin_RM goes_on notes sensor_RT station_RT net Omogneneous
2000 1510 Candelara Pesaro 1951 1 1 1997 8 4 NO NA NA NA NA NO
2004 2230 Montemonaco Montemonaco 1951 1 1 2008 1 1 Y NA 1586 142 RT Y
2011 2240 Diga_di_Carassai Carassai 1951 1 1 2008 1 1 Y passata_in_RT_il_20140314_chiamata_Carassai 2976 708 RT Y
2012 2250 Monterubbiano Monterubbiano 1951 1 1 2008 1 1 NO NA NA NA NA NO
2014 1700 Fonte_Avellana Serra_S_Abbondio 1951 1 1 2005 1 4 Y NA 1206 109 RT Y
2016 1710 Pergola Pergola 1951 1 1 2008 1 7 Y NA 1198 108 RT Y

I load it with

df <- read.table(file="df_file.txt", header = TRUE, sep=" ", stringsAsFactors=FALSE)

There are 16 columns, some of them are integer and others are character.

My problem is that

station_list <- df[df$station_RT==142, ]

should give me only the second row, while I get

     sensor_RM station_RM    place_RM municipality_RM Y_init_RM M_init_RM
NA          NA         NA        <NA>            <NA>        NA        NA
2         2004       2230 Montemonaco     Montemonaco      1951         1
NA.1        NA         NA        <NA>            <NA>        NA        NA
     D_init_RM Y_fin_RM M_fin_RM D_fin_RM goes_on notes sensor_RT station_RT
NA          NA       NA       NA       NA    <NA>  <NA>        NA         NA
2            1     2008        1        1       Y  <NA>      1586        142
NA.1        NA       NA       NA       NA    <NA>  <NA>        NA         NA
      net Omogneneous
NA   <NA>        <NA>
2      RT           Y
NA.1 <NA>        <NA>

Why? I struggled for a long time trying to understand where is the bug.
Could you please help me in that?

Thank you
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From antony.lee at berkeley.edu  Tue Feb 16 08:37:20 2016
From: antony.lee at berkeley.edu (Antony Lee)
Date: Mon, 15 Feb 2016 23:37:20 -0800
Subject: [R] Matrix-free fused lasso
Message-ID: <CAGRr6BFKQkDMMAWmcnGRokGvvEa-Jwkaf3-v=O79+G1poQFfFQ@mail.gmail.com>

Hi,
I am looking for an implementation of the fused lasso that allows the
predictor matrix to be an "abstract" linear operator, namely the cumulative
sum (that is, (X.b)_i = sum(b_k, k=1..i)) (due to the size of the problem,
forming the entire matrix is unlikely to be a good approach).  Any pointers
would be welcome.
Thanks!
Antony

	[[alternative HTML version deleted]]


From kerin at usc.edu  Tue Feb 16 03:49:05 2016
From: kerin at usc.edu (Tara Kerin)
Date: Mon, 15 Feb 2016 18:49:05 -0800
Subject: [R] error message for every parenthesis
Message-ID: <CAP73j161US+z2aUsJJ8VV_pusfKSAfp3bW9SSfnpvfkhDBrdWg@mail.gmail.com>

Hi,

I seem to be having the same problem Garrett (below) had in 2009.
However, I do not have functions named try written in my active code.
In fact, I don't have any of my own functions written at all yet.  I
did just install version 3.2.1 today, and the errors started after
that.  Please advise!

Thank you,

Tara Kerin

An example from my GUI is below:

[Workspace restored from /Users/tarakerin/.RData]
[History restored from /Users/tarakerin/.Rapp.history]

Error in try(gsub("\\s+", " ", paste(capture.output(print(args(library))),  :
  unused argument (silent = TRUE)
> library()



On 7/13/2009 12:35 PM, Garrett Grolemund wrote:
>* Whenever I type a parenthesis immediately following a word (as if I'm
*>* entering a function) R displays the following error
*> >* Error in try(gsub("\\s+", " ", paste(capture.output(print(args(try))),  :
*>*   unused argument(s) (silent = TRUE)
*>>* try(
*> >* The above is pasted from my R console. The error appears above the command
*>* because it appears immediately upon typing the parenthesis.  It does not
*>* wait until I try to execute the command.  This happens for every function.
*>* I can finish typing the function and execute it.  But these error messages
*>* make it difficult to debug my code.  In particular, if I have options(error
*>* = recover) set, the above crashes R.
*> >* I can avoid the error by typing the parentheses first and then moving the
*>* cursor back to type in the word. This error displays on the console whether
*>* I'm typing in the console or in an open document window.
*> >* I'm using the mac GUI for R.  The error only occurs on my Macbook (OS X
*>* 10.5.7), which I bought a few months ago.  It has occurred  every time I use
*>* R on this computer.  It has happened with R 2.8 and now R 2.91.
*> >* Any idea what may be going on?
*
Presumably this has something to do with command completion or argument
hints.  From the "silent = TRUE" error, and your example, I would guess
you have a function named try(), and the GUI is finding yours instead of
the one in the base package.

The GUI shouldn't do that, it should look in the right place, but as a
workaround, you could remove your function named "try", and call it
something else.

Duncan Murdoch

	[[alternative HTML version deleted]]


From kerin at usc.edu  Tue Feb 16 04:11:20 2016
From: kerin at usc.edu (Tara Kerin)
Date: Mon, 15 Feb 2016 19:11:20 -0800
Subject: [R] error in try
Message-ID: <CAP73j14a=UM8=4F8dBWbD_VKGC+xa26TQaMzFcny-kYf2JazpA@mail.gmail.com>

Hi,

I seem to be having the same problem Garrett (below) had in 2009.
However, I do not have functions named try written in my active code.
In fact, I don't have any of my own functions written at all yet.  I
did just install version 3.2.1 today, and the errors started after
that.  Please advise!

Thank you,

Tara Kerin

An example from my GUI is below:

[Workspace restored from /Users/tarakerin/.RData]
[History restored from /Users/tarakerin/.Rapp.history]

Error in try(gsub("\\s+", " ", paste(capture.output(print(args(library))),  :
  unused argument (silent = TRUE)
> library()



On 7/13/2009 12:35 PM, Garrett Grolemund wrote:
>* Whenever I type a parenthesis immediately following a word (as if I'm
*>* entering a function) R displays the following error
*> >* Error in try(gsub("\\s+", " ", paste(capture.output(print(args(try))),  :
*>*   unused argument(s) (silent = TRUE)
*>>* try(
*> >* The above is pasted from my R console. The error appears above the command
*>* because it appears immediately upon typing the parenthesis.  It does not
*>* wait until I try to execute the command.  This happens for every function.
*>* I can finish typing the function and execute it.  But these error messages
*>* make it difficult to debug my code.  In particular, if I have options(error
*>* = recover) set, the above crashes R.
*> >* I can avoid the error by typing the parentheses first and then moving the
*>* cursor back to type in the word. This error displays on the console whether
*>* I'm typing in the console or in an open document window.
*> >* I'm using the mac GUI for R.  The error only occurs on my Macbook (OS X
*>* 10.5.7), which I bought a few months ago.  It has occurred  every time I use
*>* R on this computer.  It has happened with R 2.8 and now R 2.91.
*> >* Any idea what may be going on?
*
Presumably this has something to do with command completion or argument
hints.  From the "silent = TRUE" error, and your example, I would guess
you have a function named try(), and the GUI is finding yours instead of
the one in the base package.

The GUI shouldn't do that, it should look in the right place, but as a
workaround, you could remove your function named "try", and call it
something else.

Duncan Murdoch

	[[alternative HTML version deleted]]


From psandeepmallya at gmail.com  Tue Feb 16 06:42:17 2016
From: psandeepmallya at gmail.com (Sandeep Mallya)
Date: Tue, 16 Feb 2016 11:12:17 +0530
Subject: [R] [FORGED]  Error installing the package "Cairo"
In-Reply-To: <56C2457E.2050705@auckland.ac.nz>
References: <CAM++Fzta7gwvPsbTGA_eNsOuHrA=tL+TLs3L_9pcuvYiriYSRA@mail.gmail.com>
	<56C2457E.2050705@auckland.ac.nz>
Message-ID: <CAM++FzsRT2ZyEmidkmMU39+OrHeyrtpDqYqCge5_12vA7V6nRQ@mail.gmail.com>

I tried the command below

sudo yum install cairo-devel.x86_64

Package cairo-devel-1.8.8-6.el6_6.x86_64 already installed and latest
version
Nothing to do

I have also tried installing libpng-devel

Still the error persists.

Thanks,
Sandeep


On Tue, Feb 16, 2016 at 3:09 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 15/02/16 22:51, Sandeep Mallya wrote:
>
>> Hello all,
>>
>> I am trying to install the package Cairo on RedHat running R version
>> 3.2.3.
>> So far I have tried install.packages("Cairo")
>> R CMD INSTALL Cairo_1.5-9.tar.gz
>>
>> Both the approaches giving me the same error below.
>>
>>
>> Error : .onLoad failed in loadNamespace() for 'Cairo', details:
>>    call: dyn.load(file, DLLpath = DLLpath, ...)
>>    error: unable to load shared object
>> '/home/sandeep/R/x86_64-pc-linux-gnu-library/3.2/Cairo/libs/Cairo.so':
>>    libpng15.so.15: cannot open shared object file: No such file or
>> directory
>> Error: loading failed
>> Execution halted
>>
>>
>> Can someone please guide me.
>>
>
> You apparently do not have the "cairo infrastructure" installed on your
> computer.  You probably need to do something like:
>
> sudo yum install cairo.x86_64 # Prob'ly not necessary, this package
>                               # should be already there.
> sudo yum install cairo-devel.x86_64
>
> You may not need to include the ".x86.64" strings, I'm not sure.  Or you
> may need *not* to include them!
>
> HTH.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Feb 16 12:42:20 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 16 Feb 2016 11:42:20 +0000
Subject: [R] error message for every parenthesis
In-Reply-To: <CAP73j161US+z2aUsJJ8VV_pusfKSAfp3bW9SSfnpvfkhDBrdWg@mail.gmail.com>
References: <CAP73j161US+z2aUsJJ8VV_pusfKSAfp3bW9SSfnpvfkhDBrdWg@mail.gmail.com>
Message-ID: <56C30B1C.1000602@dewey.myzen.co.uk>

Dear Tara

1 - why did you install 3.2.1 when 3.2.3 is the latest version
2 - what happens if you delete .RData and .Rapp.history from your workspace?
3 - you do have a function try as it is part of R

On 16/02/2016 02:49, Tara Kerin wrote:
> Hi,
>
> I seem to be having the same problem Garrett (below) had in 2009.
> However, I do not have functions named try written in my active code.
> In fact, I don't have any of my own functions written at all yet.  I
> did just install version 3.2.1 today, and the errors started after
> that.  Please advise!
>
> Thank you,
>
> Tara Kerin
>
> An example from my GUI is below:
>
> [Workspace restored from /Users/tarakerin/.RData]
> [History restored from /Users/tarakerin/.Rapp.history]
>
> Error in try(gsub("\\s+", " ", paste(capture.output(print(args(library))),  :
>    unused argument (silent = TRUE)
>> library()
>
>
>
> On 7/13/2009 12:35 PM, Garrett Grolemund wrote:
>> * Whenever I type a parenthesis immediately following a word (as if I'm
> *>* entering a function) R displays the following error
> *> >* Error in try(gsub("\\s+", " ", paste(capture.output(print(args(try))),  :
> *>*   unused argument(s) (silent = TRUE)
> *>>* try(
> *> >* The above is pasted from my R console. The error appears above the command
> *>* because it appears immediately upon typing the parenthesis.  It does not
> *>* wait until I try to execute the command.  This happens for every function.
> *>* I can finish typing the function and execute it.  But these error messages
> *>* make it difficult to debug my code.  In particular, if I have options(error
> *>* = recover) set, the above crashes R.
> *> >* I can avoid the error by typing the parentheses first and then moving the
> *>* cursor back to type in the word. This error displays on the console whether
> *>* I'm typing in the console or in an open document window.
> *> >* I'm using the mac GUI for R.  The error only occurs on my Macbook (OS X
> *>* 10.5.7), which I bought a few months ago.  It has occurred  every time I use
> *>* R on this computer.  It has happened with R 2.8 and now R 2.91.
> *> >* Any idea what may be going on?
> *
> Presumably this has something to do with command completion or argument
> hints.  From the "silent = TRUE" error, and your example, I would guess
> you have a function named try(), and the GUI is finding yours instead of
> the one in the base package.
>
> The GUI shouldn't do that, it should look in the right place, but as a
> workaround, you could remove your function named "try", and call it
> something else.
>
> Duncan Murdoch
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From sunnysingha.analytics at gmail.com  Tue Feb 16 12:52:16 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Tue, 16 Feb 2016 17:22:16 +0530
Subject: [R] Need your favour : twitter sentiment issue while cleaning the
	corpus
Message-ID: <59D2E375-7BD5-4549-9C7E-AE0FA075B237@gmail.com>

Hi,
I need your favour. I received below warning while cleaning the corpus of tweets which is not allowing me to further the analysis:

Warning message:
In mclapply(content(x), FUN, ...) :
  scheduled core 1 encountered error in user code, all values of the job will be affected

Code used: for cleaning. 
tw_clean <- tm_map(tw_corpus, removePunctuation)
tw_clean <- tm_map(tw_clean, content_transformer(tolower))
tw_clean <- tm_map(tw_clean, removeWords, stopwords('english'))
tw_clean <- tm_map(tw_clean, removeNumbers)
tw_clean <- tm_map(tw_clean, stripWhitespace)

Code used to create the corpus:
tw_corpus <- Corpus(VectorSource(tw_text))

The error is raised for each of the above line of code. 

I some how found a way to ignore the error/warning message by including ?lazy=TRUE? argument in the tm_map() function
but when attempted to view the wordcloud(tw_clean)  below error is raised with the same warning.

Error in UseMethod("meta", x) : 
  no applicable method for 'meta' applied to an object of class "try-error"

In addition: Warning message:
In mclapply(unname(content(x)), termFreq, control) :
  scheduled core 1 encountered error in user code, all values of the job will be affected

Regards,
Sunny Singha
	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Tue Feb 16 13:51:26 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Tue, 16 Feb 2016 18:21:26 +0530
Subject: [R] Need your favour : twitter sentiment issue while cleaning
	the corpus
In-Reply-To: <59D2E375-7BD5-4549-9C7E-AE0FA075B237@gmail.com>
References: <59D2E375-7BD5-4549-9C7E-AE0FA075B237@gmail.com>
Message-ID: <F3EBECD2-3A51-4C25-A26C-2E6E730D38A7@gmail.com>

Hi,
In continuation to my initial mail I also observed that as I include more number of tweets, the likelihood of getting this error increases.

Platform I?m using:
- Mac Yosemite
- R version 3.2.2(RStudio) 

I have below questions:
- Does this error has to do anything with the default locale set in R session? I have had it set from Mac terminal ?defaults write org.R-project.R force.LANG en_US.UTF-8? 
- Before creating the Corpus() I had the tweets converted to character by using this command tw_text <- sapply(tw, function(x) x$getText()). Is it the recommended approach ?

How should I go about getting this issue resolved ?

Regards,
Sunny Singha


> On 16-Feb-2016, at 5:22 PM, Sandeep Rana <sunnysingha.analytics at gmail.com> wrote:
> 
> Hi,
> I need your favour. I received below warning while cleaning the corpus of tweets which is not allowing me to further the analysis:
> 
> Warning message:
> In mclapply(content(x), FUN, ...) :
>   scheduled core 1 encountered error in user code, all values of the job will be affected
> 
> Code used: for cleaning. 
> tw_clean <- tm_map(tw_corpus, removePunctuation)
> tw_clean <- tm_map(tw_clean, content_transformer(tolower))
> tw_clean <- tm_map(tw_clean, removeWords, stopwords('english'))
> tw_clean <- tm_map(tw_clean, removeNumbers)
> tw_clean <- tm_map(tw_clean, stripWhitespace)
> 
> Code used to create the corpus:
> tw_corpus <- Corpus(VectorSource(tw_text))
> 
> The error is raised for each of the above line of code. 
> 
> I some how found a way to ignore the error/warning message by including ?lazy=TRUE? argument in the tm_map() function
> but when attempted to view the wordcloud(tw_clean)  below error is raised with the same warning.
> 
> Error in UseMethod("meta", x) : 
>   no applicable method for 'meta' applied to an object of class "try-error"
> 
> In addition: Warning message:
> In mclapply(unname(content(x)), termFreq, control) :
>   scheduled core 1 encountered error in user code, all values of the job will be affected
> 
> Regards,
> Sunny Singha


	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Tue Feb 16 13:51:26 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Tue, 16 Feb 2016 18:21:26 +0530
Subject: [R] Need your favour : twitter sentiment issue while cleaning
	the corpus
In-Reply-To: <59D2E375-7BD5-4549-9C7E-AE0FA075B237@gmail.com>
References: <59D2E375-7BD5-4549-9C7E-AE0FA075B237@gmail.com>
Message-ID: <F3EBECD2-3A51-4C25-A26C-2E6E730D38A7@gmail.com>

Hi,
In continuation to my initial mail I also observed that as I include more number of tweets, the likelihood of getting this error increases.

Platform I?m using:
- Mac Yosemite
- R version 3.2.2(RStudio) 

I have below questions:
- Does this error has to do anything with the default locale set in R session? I have had it set from Mac terminal ?defaults write org.R-project.R force.LANG en_US.UTF-8? 
- Before creating the Corpus() I had the tweets converted to character by using this command tw_text <- sapply(tw, function(x) x$getText()). Is it the recommended approach ?

How should I go about getting this issue resolved ?

Regards,
Sunny Singha


> On 16-Feb-2016, at 5:22 PM, Sandeep Rana <sunnysingha.analytics at gmail.com> wrote:
> 
> Hi,
> I need your favour. I received below warning while cleaning the corpus of tweets which is not allowing me to further the analysis:
> 
> Warning message:
> In mclapply(content(x), FUN, ...) :
>   scheduled core 1 encountered error in user code, all values of the job will be affected
> 
> Code used: for cleaning. 
> tw_clean <- tm_map(tw_corpus, removePunctuation)
> tw_clean <- tm_map(tw_clean, content_transformer(tolower))
> tw_clean <- tm_map(tw_clean, removeWords, stopwords('english'))
> tw_clean <- tm_map(tw_clean, removeNumbers)
> tw_clean <- tm_map(tw_clean, stripWhitespace)
> 
> Code used to create the corpus:
> tw_corpus <- Corpus(VectorSource(tw_text))
> 
> The error is raised for each of the above line of code. 
> 
> I some how found a way to ignore the error/warning message by including ?lazy=TRUE? argument in the tm_map() function
> but when attempted to view the wordcloud(tw_clean)  below error is raised with the same warning.
> 
> Error in UseMethod("meta", x) : 
>   no applicable method for 'meta' applied to an object of class "try-error"
> 
> In addition: Warning message:
> In mclapply(unname(content(x)), termFreq, control) :
>   scheduled core 1 encountered error in user code, all values of the job will be affected
> 
> Regards,
> Sunny Singha


	[[alternative HTML version deleted]]


From mohsenhs82 at yahoo.com  Tue Feb 16 06:14:12 2016
From: mohsenhs82 at yahoo.com (mohsen hs)
Date: Tue, 16 Feb 2016 05:14:12 +0000 (UTC)
Subject: [R] Estimating Mean of a Poisson Distribution Based on interval
 censoring
In-Reply-To: <7b6d90$2egaua@ironport10.mayo.edu>
References: <mailman.1.1455447601.17866.r-help@r-project.org>
	<7b6d90$2egaua@ironport10.mayo.edu>
Message-ID: <371153070.3839874.1455599652776.JavaMail.yahoo@mail.yahoo.com>

Hi Terry,
Thank you for your reply and your time. I really appreciate your time and I know that you should be very busy.
Please forgive me for any possible technical mistake as I am not a professional in statistic.
R has a package with the name of fitdist that gave me the estimation. It seems that lifereg does not support Poisson at list without any specific modification,
(https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_lifereg_sect019.htm).
Please let me explain my problem which you can find below. Since, you are interested to know the problem, I tried to explain the problem clearly. Please forgive me if it is too long:( .?I really appreciate your time, consideration, and feedback.


Many thanks,Mohsen
We collected the data from some devices and they are able to count the data within a minute. For example, we had 10 observations in 12:01, 15 in 12:02, and so forth. I randomly distributed the data (10 obs) in the first 60 sec, and the 15 obs in (60 to 120 sec) and count the interarrival of obs. In this case, I got a result like this:1, 2002, 4003, 150The first row means I had 200 objects that arrived with the difference of 1 second, 400 objects with the difference of two seconds (interarrival rate was 2 sec?for 400 objects), and so on. To do that, I wrote a function to repeat 1, two hundred times, repeat 2, four hundred times, and ...?Now, I would like to investigate which distribution they follow. Since some of the devices were faulty and ?for some other reasons such as tails of QQ plot, I decided to censor?some of the data, and those are interarrival(obs)<3 sec and?interarrival(obs)>500 sec.?

On a different topic related to difference between R and SAS, I have provided you with the mu, sigma, and codes.

In SAS and R, I used interval censoring with the boundaries of 3, and 500 and formed a table like this:

? ? ? ? count & t1 ?& t2 ??? ? ? ? 1 ? ? & 1 ? & 3 ? ??? ? ? ? 1 ? ? & 1 ? & 3 ? ??? ? ? ? 2 ? ? & 2 ? & 3 ? ??? ? ? ? 3 ? ? & 3 ? & 3 ? ?? ? ? ? 3 ? ? & 3 ? & 3 ? ??? ? ? ? 4 ? ? & 4 ? & 4 ? ??? ? ? ? .. ? ?& .. ?& .. ? ?? ? ? ? 500 ? & 500 & 500 ?? ? ? ? 501 ? & 500 & 501 ??? ? ? ? .. ? ?& .. ?& .. ??? ? ? ? 39011 & 500 & 39011

count is the observed value and is the response variable, t1 is the bound of right censoring and t2 is the bound of left censoring. This is done by the following command in SAS
?loss count/ lc=t2 rc=t1;

SAS estimated:
?$\mu=3.67361$ ,?$\sigma=1.45265$?http://support.sas.com/documentation/cdl/en/etsug/63939/HTML/default/viewer.htm#etsug_severity_sect037.htm? ? ? The LOSS statement specifies the left and right boundary of each group as the?? ? ??right-censoring and left-censoring limits, respectively.?? ? ? lc=t2 rc=t1;? ? ? t1 ? t2? ? ? 1 ? ?3? ? ? 1 ? ?3? ? ? 500 ?600? ? ? 500 ?4500
SAS code,/////////////////////////////
? ? ??? ? ??? ? ?data df; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?infile "/home/Username/PathAll_TWOMONTH _BothDirection715_2.csv" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?LRECL=10000000 ?DLM=',' firstobs=2; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?input ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?timenumn count right left ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?run; ?? ? ?data t1(drop=count left right rename=(timenumn=t1)) ; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?set df; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?do i = 1 to count; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?output; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?end; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?run;?? ? ?? ? ?data t2(drop=count left right rename=(timenumn=t2)); ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?set df; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?do i = 1 to count; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?output; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?end; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?run;?? ? ?? ? ?data count(drop=count left right rename=(timenumn=count)) ; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?set df; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?do i = 1 to count; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?output; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?end; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ?run;?? ? ?? ? ?? ? ?? ? ?data t1;? ? ?set t1;? ? ?/*If t1 < 3 then t1 = 1;? ? ?if t1>1000 then t1=1000;*/? ? ?if (t1<3 ) then t1=1;? ? ?if(t1>2) then t1=t1;? ? ?if(t1>500) then t1=500;? ? ?run;? ? ?? ? ?data t2;? ? ?set t2;? ? ?/*If t2 < 3 then t2 = 5;? ? ?if t2 >1000 then t2=t2;*/? ? ?if(t2<3) then t2=3;? ? ?/*if(t2<501) then t2=t2;? ? ?if (t2>500 ) then t2=500;*/? ? ?run;? ? ?;? ? ?/*? ? ?data count;? ? ?set count;? ? ?if count <100005 then count=1? ? ?run;? ? ?;? ? ?*/? ? ?data final;? ? ?merge t1 t2 count;? ? ?run;? ? ?? ? ?proc severity data=final print=all plots(histogram kernel)=all? ? ?criterion=ad;? ? ?loss count/ lc=t2 rc=t1; ? ? ?? ? ?dist logn; /* _predef_; */? ? ?run;

| Parameter Estimates |
| Parameter | Estimate | Standard
Error | t?Value | Approx
Pr > |t| |
| Mu | 3.67361 | 0.00859 | 427.50 | <.0001 |
| Sigma | 1.45265 | 0.00615 | 236.07 | <.0001 |

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
I decided to compare the $\mu$ and $\sigma$ values from R and SAS. I got the following values from R which is slightly different:
$\mu=3.653001$$\sigma=1.497570$
////////R codelibrary(fitdistrplus)df= read.csv ("E:/Motorway-Urban/hour/PathAll_TWOMONTH _BothDirection715_2.csv")z=rep(df$timenum,time=df$count)y<-zycens <- data.frame(left=y,right=y)max=27219ct=maxfor(i in max:28666 ){? ? ycens$right[ct]=y[ct]? ? ycens$left[ct]=500? ? ct=ct+1}
ct=1;for(i in 1:28666 ){ ? ?? ? if( ycens$left[i]<3)? ? {? ? ? ? ycens$left[ct]=1 ? ? ? ?? ? }? ? ct=ct+1}fitlnc<-fitdistcens(ycens,"lnorm")Fitting of the distribution ' lnorm ' on censored data by maximum likelihood?Parameters:? ? ? ? estimatemeanlog 3.653001sdlog ? 1.497570
?? 

    On Tuesday, February 16, 2016 1:38 AM, "Therneau, Terry M., Ph.D." <therneau at mayo.edu> wrote:


 For an interval censored poisson or lognormal, use survreg() in the survival package.? (Or 
if you are a SAS fan use proc lifereg).? If you have a data set where R and SAS give 
different answers I'd like to know about it, but my general experience is that this is 
more often a user error.? I am also curious to learn exactly what you mean by "interval 
censored poisson".? Exponential with interval time to first event is equivalent to 
poisson, which is what I'd guess from "lognormal", but you may mean something else.


Terry Therneau
(author of survival)



On 02/14/2016 05:00 AM, r-help-request at r-project.org wrote:
> Dear all,
> I appreciate that if you let me know if there is any package implemented in R for Estimating Mean of a Poisson Distribution Based on Interval censoring? And if yes, could you please provide some information about it:)?
> By the way, is there anything for lognormal?I think fitdistcens is not good for this purpose as it gives me different result compared to SAS and only useful for right/left censoring and not interval censoring?(or both left and right together).?
> Kind regards,Mohsen


  
	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Tue Feb 16 16:03:41 2016
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 16 Feb 2016 17:03:41 +0200
Subject: [R] NaNs produced as a returned value for a function
In-Reply-To: <CAF8bMcbDUO4kTVos7O5orSLPTqxrXEJYGT=wT4nbKTjnc62wEw@mail.gmail.com>
References: <CAPLSCn3SwYmPr01g29OpNf8X1OgyUQNvWaH_YOyQ47x6fcfV6Q@mail.gmail.com>
	<CAF8bMcbDUO4kTVos7O5orSLPTqxrXEJYGT=wT4nbKTjnc62wEw@mail.gmail.com>
Message-ID: <CAPLSCn3XunKo+m-fdaPaHwD_009BdcWorpec6p1vu09LcbG-Fg@mail.gmail.com>

Thanks for helping Dunlap.

I just don't get why does the function bettarg() executes well if I
evaluate it (by hand) step-by step . nut for the same input values , if I
tried to execute bettarg() it will give me the error

Error in if (y <= accept.prob) { : missing value where TRUE/FALSE needed
 Although both y and accept.prob have values and are not missing.

Any help would be appreciated as this error is causing my entire(large and
complicated) code to stop execution.

Maram Salem

On 14 February 2016 at 22:08, William Dunlap <wdunlap at tibco.com> wrote:

> You can do things like
>    while ( !is.nan( r <- randomFunction(x) )) {}
>    # r will be a non-NaN value of randomFunction(x) now
> or
>    for(i in seq_len(1000)) {
>       if (!is.nan( r <- randomFunction(x))) {
>           break
>       }
>       if (i == 1000) {
>           stop("no good values of randomFunction(x) in 1000 tries")
>       }
>    }
> to avoid infinite loops when randomFunction [almost] always produces a NaN.
>
> You may  be able to avoid some NaNs by replacing log(b^n) with n*log(b) and
> log(prod(x^b)) with sum(b*log(x)).  That would avoid unneeded Inf values,
> which
> can lead to NaN down the line (Inf-Inf -> NaN, Inf/Inf -> NaN).
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sun, Feb 14, 2016 at 9:22 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I'm trying to write 2 functions(as a part of a larger code) to evaluate a
>> certain equation.  The function is :
>>
>> X= c (0.3893094  2.0962311  2.6007558  3.0761810  3.3246947  3.3917976
>>  4.1981546  6.8826140 12.3128013 15.5588470)
>> R=c (0 1 0 0 0 1 1 1 0 1)
>>
>> alpha.update=function(X, R, alpha.curr, beta.curr=1 ,m=10,
>> hyp=c(3,15,6,22.5))
>>
>>   {
>>
>>   o<-numeric(m)
>>
>>      for (i in 1:m) {
>>
>>        o[i]<- (1+R[i])*((X[i])^(beta.curr))
>>
>>         }
>>
>>    sh<-sum(o) + hyp[2] + (hyp[4]* beta.curr)
>>
>>    rg<-rgamma(1, shape= m+hyp[1]+hyp[3] , rate = sh )
>>
>>    return(rg)
>>
>>    }
>>
>>
>> alpha.curr<- alpha.update(X, R, alpha.curr=0.2, beta.curr=1 ,m, hyp)
>>
>>
>>     bettarg<- function(X, R, alpha.curr, beta.curr=1 ,m=10,
>> hyp=c(3,15,6,22.5))
>>
>>        {
>>
>>            o<-numeric(m)
>>
>>            for (i in 1:m) {
>>
>>        o[i]<- (1+R[i])*((X[i])^( beta.curr))
>>
>>         }
>>
>>       logbt<- log(beta.curr ^(m+hyp[3]-1)) + log(prod((X)^( beta.curr
>> -1)))
>> + (-1*alpha.curr *(sum(o) +  (hyp[4]* beta.curr)))
>>
>>
>>
>>       bt<- exp(logbt)
>>
>>       return(bt)
>>
>>        }
>>
>>
>> The problem is that the function bettarg() sometimes produces   NaN, and
>> this stops the evaluation of my equation, so how can I force it to ignore
>> the NaNs produced and repeat the evaluation again till it prroduces a
>> number?
>>
>>
>> Thanks in advance,
>>
>>
>> Maram Salem
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From whuang.ustc at gmail.com  Tue Feb 16 16:56:57 2016
From: whuang.ustc at gmail.com (Wen Huang)
Date: Tue, 16 Feb 2016 10:56:57 -0500
Subject: [R] Comparing variance components
Message-ID: <477CE007-DA6D-4031-B86F-FCAB156578EB@gmail.com>

Dear R-help members,

Say I have two data sets collected at different times with the same design. I fit a mixed model using in R using lmer

lmer(y ~ (1|A))

to these data sets and get two estimates of sigma2_A and sigma2_e

What would be a good way to compare sigma2_A and sigma2_e for these two data sets and obtain a P value for the hypothesis that sigma2_A1 = sigma2_A2? There is obvious shrinkage on these estimates, should I be worried about the differential levels of shrinkage on these estimates and how to account for that?

Thank you for your thoughts and inputs!



	[[alternative HTML version deleted]]


From HDoran at air.org  Tue Feb 16 18:40:02 2016
From: HDoran at air.org (Doran, Harold)
Date: Tue, 16 Feb 2016 17:40:02 +0000
Subject: [R] Comparing variance components
In-Reply-To: <477CE007-DA6D-4031-B86F-FCAB156578EB@gmail.com>
References: <477CE007-DA6D-4031-B86F-FCAB156578EB@gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686012BB58ADB@DC1VEX10MB01.air.org>

(adding R mixed group). You actually do not want to do this test, and there is no "shrinkage" here on these variances. First, there are conditional variances and marginal variances in the mixed model. What you are have below as "A" is the marginal variances of the random effects and there is no shrinkage on these, per se.

The conditional means of the random effects have shrinkage and each conditional mean (or BLUP) has a conditional variance. 

Now, it seems very odd to want to compare the variance between A and then what you have as sigma2_e, which is presumably the residual variance. These are variances of two completely different things, so a test comparing them seems strange, though I suppose some theoretical reason could exists justifying it, I cannot imagine one though. 





-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Wen Huang
Sent: Tuesday, February 16, 2016 10:57 AM
To: r-help at r-project.org
Subject: [R] Comparing variance components

Dear R-help members,

Say I have two data sets collected at different times with the same design. I fit a mixed model using in R using lmer

lmer(y ~ (1|A))

to these data sets and get two estimates of sigma2_A and sigma2_e

What would be a good way to compare sigma2_A and sigma2_e for these two data sets and obtain a P value for the hypothesis that sigma2_A1 = sigma2_A2? There is obvious shrinkage on these estimates, should I be worried about the differential levels of shrinkage on these estimates and how to account for that?

Thank you for your thoughts and inputs!



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From whuang.ustc at gmail.com  Tue Feb 16 18:54:08 2016
From: whuang.ustc at gmail.com (Wen Huang)
Date: Tue, 16 Feb 2016 12:54:08 -0500
Subject: [R] Comparing variance components
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686012BB58ADB@DC1VEX10MB01.air.org>
References: <477CE007-DA6D-4031-B86F-FCAB156578EB@gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686012BB58ADB@DC1VEX10MB01.air.org>
Message-ID: <1B7ADF10-E2B4-4633-B790-32698DCFA5BF@gmail.com>

Hi Harold,

Thank you for your input. I was not very clear. I wanted to compare the sigma2_A?s from the same model fitted to two different data sets. The same for sigma2_e?s. The motivation is when I did the same experiment at two different times, whether the variance due to A (sigma2_A) is bigger at one time versus another. The same for sigma2_e, whether the residual variance is bigger for one experiment versus another.

Thanks,
Wen

> On Feb 16, 2016, at 12:40 PM, Doran, Harold <HDoran at air.org> wrote:
> 
> (adding R mixed group). You actually do not want to do this test, and there is no "shrinkage" here on these variances. First, there are conditional variances and marginal variances in the mixed model. What you are have below as "A" is the marginal variances of the random effects and there is no shrinkage on these, per se.
> 
> The conditional means of the random effects have shrinkage and each conditional mean (or BLUP) has a conditional variance. 
> 
> Now, it seems very odd to want to compare the variance between A and then what you have as sigma2_e, which is presumably the residual variance. These are variances of two completely different things, so a test comparing them seems strange, though I suppose some theoretical reason could exists justifying it, I cannot imagine one though. 
> 
> 
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Wen Huang
> Sent: Tuesday, February 16, 2016 10:57 AM
> To: r-help at r-project.org
> Subject: [R] Comparing variance components
> 
> Dear R-help members,
> 
> Say I have two data sets collected at different times with the same design. I fit a mixed model using in R using lmer
> 
> lmer(y ~ (1|A))
> 
> to these data sets and get two estimates of sigma2_A and sigma2_e
> 
> What would be a good way to compare sigma2_A and sigma2_e for these two data sets and obtain a P value for the hypothesis that sigma2_A1 = sigma2_A2? There is obvious shrinkage on these estimates, should I be worried about the differential levels of shrinkage on these estimates and how to account for that?
> 
> Thank you for your thoughts and inputs!
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 16 19:07:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Feb 2016 10:07:11 -0800
Subject: [R] Comparing variance components
In-Reply-To: <1B7ADF10-E2B4-4633-B790-32698DCFA5BF@gmail.com>
References: <477CE007-DA6D-4031-B86F-FCAB156578EB@gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686012BB58ADB@DC1VEX10MB01.air.org>
	<1B7ADF10-E2B4-4633-B790-32698DCFA5BF@gmail.com>
Message-ID: <CAGxFJbRoY41xsaXMXLirwuujoT2OX-53oKVSnTeQ3C0xbdS_aQ@mail.gmail.com>

I'll save you the trouble.

Yes, they're bigger. Or smaller. Certainly differ between experiments.  So
what? That is just the way things work.

 Google "weighting in meta-analysis" or similar for ways folks try to deal
with this.

Cheers,

Bert

On Tuesday, February 16, 2016, Wen Huang <whuang.ustc at gmail.com> wrote:

> Hi Harold,
> R
> Thank you for your input. I was not very clear. I wanted to compare the
> sigma2_A?s from the same model fitted to two different data sets. The same
> for sigma2_e?s. The motivation is when I did the same experiment at two
> different times, whether the variance due to A (sigma2_A) is bigger at one
> time versus another. The same for sigma2_e, whether the residual variance
> is bigger for one experiment versus another.
>
> Thanks,
> Wen
>
> > On Feb 16, 2016, at 12:40 PM, Doran, Harold <HDoran at air.org
> <javascript:;>> wrote:
> >
> > (adding R mixed group). You actually do not want to do this test, and
> there is no "shrinkage" here on these variances. First, there are
> conditional variances and marginal variances in the mixed model. What you
> are have below as "A" is the marginal variances of the random effects and
> there is no shrinkage on these, per se.
> >
> > The conditional means of the random effects have shrinkage and each
> conditional mean (or BLUP) has a conditional variance.
> >
> > Now, it seems very odd to want to compare the variance between A and
> then what you have as sigma2_e, which is presumably the residual variance.
> These are variances of two completely different things, so a test comparing
> them seems strange, though I suppose some theoretical reason could exists
> justifying it, I cannot imagine one though.
> >
> >
> >
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org <javascript:;>] On
> Behalf Of Wen Huang
> > Sent: Tuesday, February 16, 2016 10:57 AM
> > To: r-help at r-project.org <javascript:;>
> > Subject: [R] Comparing variance components
> >
> > Dear R-help members,
> >
> > Say I have two data sets collected at different times with the same
> design. I fit a mixed model using in R using lmer
> >
> > lmer(y ~ (1|A))
> >
> > to these data sets and get two estimates of sigma2_A and sigma2_e
> >
> > What would be a good way to compare sigma2_A and sigma2_e for these two
> data sets and obtain a P value for the hypothesis that sigma2_A1 =
> sigma2_A2? There is obvious shrinkage on these estimates, should I be
> worried about the differential levels of shrinkage on these estimates and
> how to account for that?
> >
> > Thank you for your thoughts and inputs!
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Tue Feb 16 15:58:25 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Tue, 16 Feb 2016 14:58:25 +0000
Subject: [R] this is not a list, not a data frame, but what ?
Message-ID: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>

HI,
I am new to R and English is not my natural language.

I am working on an old R application where there is a matrix containing parameters. Something like :
  parametres=matrix(NA,15,3)
  parametres[1,1]<- "Point de convergence hauteur en metre"
  parametres[1,2]<- 5.00
  parametres[1,3]<- "PC_h_m"
  parametres[2,1]<- "Point de convergence debit en m3/s"
  parametres[2,2]<- 805.00
  parametres[2,3]<- "PC_Q_m3"
and so on.

>From 15 parameters, we shall reach 40.

I'd like to be able to use something like
  Parameters$PC_h_m$descript to have "Point de convergence hauteur en metre"
  Parameters$PC_h_m$value to have 5
  Parameters$ PC_Q_m3$descript to have "Point de convergence debit en m3/s"
  Parameters$ PC_Q_m3$value to have 805.00

It's a lot more 'readable' by humans ... Is it possible and, if yes, how ?

Thanks in advance for your answers ...
Jean in France

-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From ulrik.stervbo at gmail.com  Tue Feb 16 19:36:34 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 16 Feb 2016 18:36:34 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>

Hi Maurice,

Could you use a data.frame with a description  and a value column?

Something like

data.frame(description1 = c ("Point de convergence hauteur en metre",
"Point de convergence debit en m3/s"),
description2 = c ( "PC_h_m", "PC_Q_m3" ),
value = c (  5.00, 805.00 ))

You can then subset the data.frame to get the values you are interested in.

Best,
Ulrik

MAURICE Jean - externe <jean-externe.maurice at edf.fr> schrieb am Di., 16.
Feb. 2016 19:22:

> HI,
> I am new to R and English is not my natural language.
>
> I am working on an old R application where there is a matrix containing
> parameters. Something like :
>   parametres=matrix(NA,15,3)
>   parametres[1,1]<- "Point de convergence hauteur en metre"
>   parametres[1,2]<- 5.00
>   parametres[1,3]<- "PC_h_m"
>   parametres[2,1]<- "Point de convergence debit en m3/s"
>   parametres[2,2]<- 805.00
>   parametres[2,3]<- "PC_Q_m3"
> and so on.
>
> >From 15 parameters, we shall reach 40.
>
> I'd like to be able to use something like
>   Parameters$PC_h_m$descript to have "Point de convergence hauteur en
> metre"
>   Parameters$PC_h_m$value to have 5
>   Parameters$ PC_Q_m3$descript to have "Point de convergence debit en m3/s"
>   Parameters$ PC_Q_m3$value to have 805.00
>
> It's a lot more 'readable' by humans ... Is it possible and, if yes, how ?
>
> Thanks in advance for your answers ...
> Jean in France
>
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations qui y
> figurent sont strictement confidentielles. Toute utilisation de ce Message
> non conforme ? sa destination, toute diffusion ou toute publication totale
> ou partielle, est interdite sauf autorisation expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de
> le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou
> partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de
> votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace
> sur quelque support que ce soit. Nous vous remercions ?galement d'en
> avertir imm?diatement l'exp?diteur par retour du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute
> erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely for
> the addressees. The information contained in this Message is confidential.
> Any use of information contained in this Message not in accord with its
> purpose, any dissemination or disclosure, either whole or partial, is
> prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or use
> any part of it. If you have received this message in error, please delete
> it and all copies from your system and notify the sender immediately by
> return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Feb 16 19:39:37 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 16 Feb 2016 18:39:37 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <20160216183937.Horde.8ErsG8KK_RZBVBsL4gPLJX7@mail.sapo.pt>

Hello,

What you want is a list of lists.
Try something like

Parameters <- list(PC_h_m = list(descript = "Point de convergence  
hauteur en metre", value = 5),
?? ??? ?PC_Q_m3 = list(descript = "Point de convergence debit en  
m3/s", value = 805.00))

Hope this helps,

Rui Barradas
?

Citando MAURICE Jean - externe <jean-externe.maurice at edf.fr>:

> HI,
> I am new to R and English is not my natural language.
>
> I am working on an old R application where there is a matrix  
> containing parameters. Something like :
> parametres=matrix(NA,15,3)
> parametres[1,1]<- "Point de convergence hauteur en metre"
> parametres[1,2]<- 5.00
> parametres[1,3]<- "PC_h_m"
> parametres[2,1]<- "Point de convergence debit en m3/s"
> parametres[2,2]<- 805.00
> parametres[2,3]<- "PC_Q_m3"
> and so on.
>> From 15 parameters, we shall reach 40.
>
> I'd like to be able to use something like
> Parameters$PC_h_m$descript to have "Point de convergence hauteur en metre"
> Parameters$PC_h_m$value to have 5
> Parameters$ PC_Q_m3$descript to have "Point de convergence debit en m3/s"
> Parameters$ PC_Q_m3$value to have 805.00
>
> It's a lot more 'readable' by humans ... Is it possible and, if yes, how ?
>
> Thanks in advance for your answers ...Jean in France

?

	[[alternative HTML version deleted]]


From f.harrell at Vanderbilt.Edu  Tue Feb 16 21:01:22 2016
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Tue, 16 Feb 2016 14:01:22 -0600
Subject: [R] Recommendation for updating packages such as nlme
Message-ID: <56C38012.2020000@vanderbilt.edu>

I use this function to update my installed R packages:

updatePac <- function (checkBuilt = FALSE, ...)
update.packages(repos = "http://cran.rstudio.com", instlib = 
"/usr/local/lib/R/site-library",
     checkBuilt = checkBuilt, ...)

When I type updatePac() I get:

Warning: package 'MASS' in library '/usr/lib/R/library' will not be updated
Warning: package 'Matrix' in library '/usr/lib/R/library' will not be 
updated
Warning: package 'mgcv' in library '/usr/lib/R/library' will not be updated
Warning: package 'nlme' in library '/usr/lib/R/library' will not be updated
Warning: package 'nnet' in library '/usr/lib/R/library' will not be updated
Warning: package 'spatial' in library '/usr/lib/R/library' will not be 
updated

Should I not try to update recommended packages in 
/usr/local/lib/R/site-library on my Ubuntu system but specify 
/usr/lib/R/library instead?

-- 
------------------------------------------------------------------------
Frank E Harrell Jr 	Professor and Chairman 	School of Medicine

	Department of *Biostatistics* 	*Vanderbilt University*


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Feb 16 21:53:46 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 Feb 2016 12:53:46 -0800
Subject: [R] Recommendation for updating packages such as nlme
In-Reply-To: <56C38012.2020000@vanderbilt.edu>
References: <56C38012.2020000@vanderbilt.edu>
Message-ID: <B0E4D328-C925-4EFD-B7C0-AE839D93FA2A@dcn.davis.ca.us>

Isn't /usr/local for software your sysadmin (you, when you wear that hat) have compiled, while /usr/lib is managed by the system package manager (apt-get for Ubuntu)?

FWIW I usually only manage my personal R library and ignore the system R library... I never specify instLib myself, and never run R as root. There might be advantages to specifying instLib, but I have not encountered them. 
-- 
Sent from my phone. Please excuse my brevity.

On February 16, 2016 12:01:22 PM PST, Frank Harrell <f.harrell at vanderbilt.edu> wrote:
>I use this function to update my installed R packages:
>
>updatePac <- function (checkBuilt = FALSE, ...)
>update.packages(repos = "http://cran.rstudio.com", instlib = 
>"/usr/local/lib/R/site-library",
>     checkBuilt = checkBuilt, ...)
>
>When I type updatePac() I get:
>
>Warning: package 'MASS' in library '/usr/lib/R/library' will not be
>updated
>Warning: package 'Matrix' in library '/usr/lib/R/library' will not be 
>updated
>Warning: package 'mgcv' in library '/usr/lib/R/library' will not be
>updated
>Warning: package 'nlme' in library '/usr/lib/R/library' will not be
>updated
>Warning: package 'nnet' in library '/usr/lib/R/library' will not be
>updated
>Warning: package 'spatial' in library '/usr/lib/R/library' will not be 
>updated
>
>Should I not try to update recommended packages in 
>/usr/local/lib/R/site-library on my Ubuntu system but specify 
>/usr/lib/R/library instead?
>
>-- 
>------------------------------------------------------------------------
>Frank E Harrell Jr 	Professor and Chairman 	School of Medicine
>
>	Department of *Biostatistics* 	*Vanderbilt University*
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From remilesmerises at yahoo.ca  Tue Feb 16 21:58:38 2016
From: remilesmerises at yahoo.ca (=?UTF-8?Q?R=C3=A9mi_Lesmerises?=)
Date: Tue, 16 Feb 2016 20:58:38 +0000 (UTC)
Subject: [R] MCMCglmm and iteration
References: <1976293102.5340210.1455656318792.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1976293102.5340210.1455656318792.JavaMail.yahoo@mail.yahoo.com>

Hi everyone,
I'm running a bayesian regression using the package MCMCglmm (Hadfield 2010) and to reach a normal posterior distribution of estimates, I increased the number of iteration as well as the burnin threshold. However, it had unexpected outcomes. Although it improved posterior distribution, it also increased dramatically the value of estimates and decrease DIC.?
Here an example:
>head(spring)
pres ? large_road ? ?small_road ? ?cab0 ? ? ? ? ? ? 2011 ? ? ? ? ? ? ? ?32 ? ? ? ? ? 781 ? ? ? ? ? ? ?102 ? ? ? ? ? ? ? 179 ? ? ? ? ?2040 ? ? ? ? ? ? ?1256 ? ? ? ? ? ? 654 ? ? ? ? ?9841 ? ? ? ? ? ? ?187 ? ? ? ? ? ? ? 986 ? ? ? ? ?7560 ? ? ? ? ? ? ? 21 ? ? ? ? ? ? ? ?438 ? ? ? ? ? 571 ? ? ? ? ? ? ? 13 ? ? ? ? ? ? ? ? ? 5 ? ? ? ? ? 439 ? ?
>#pres is presence/absence data and other variable are distance to these features
>## with?200,000 iteration and 30,000 burnin>prior <- list(R = list(V = 1, nu=0.002))>sp.simple <- MCMCglmm(pres ~ large_road + cab + small_road,?family = "categorical", nitt = 200000, thin = 200, burnin = 30000,?????????????????????????????????????????????data = spring,?prior = prior, verbose = FALSE, pr = TRUE)
>summary(sp.simple)
?Iterations = 30001:199801?Thinning interval ?= 200?Sample size ?= 850?
?DIC: 14045.31?
?R-structure: ?~units
? ? ? ? ?post.mean ? ? l-95% ? ? CI u-95% ? ? CI eff.sampunits ? ? 294.7 ? ? ? ? 1.621 ? ? ? ?621.9 ? ? ? ? ? ?1.982
?Location effects: pres ~ large + cab + small + Coupe_0_5 + Regeneration + Res_mature + DH + Autre + Eau + Pert_nonregen + MF + Coupe_6_20?
? ? ? ? ? ? ? ? ? ? ?post.mean ? ? l-95% ? ? ? CI ?u-95% ? ? CI eff.samp ? ? pMCMC ??(Intercept) ? ? 5.76781 ? ? ?0.77622 ? ? ? 9.24375 ? ? ? ? ?1.829 ? ? ? ? ? ?<0.001 **large ? ? ? ? ? ? 0.37487 ? ? ?0.02692 ? ? ? 0.75282 ? ? ? ? ? 3.310 ? ? ? ? ? ?<0.001 **cab ? ? ? ? ? ? ? 0.94639 ? ? ?0.09906 ? ? ? 1.57939 ? ? ? ? ? 2.096 ? ? ? ? ? ?<0.001 **small ? ? ? ? ? -1.62192 ? ? -2.60873 ? ? ?-0.20191 ? ? ? ? ? 2.002 ? ? ? ? ? ?<0.001 **


>## with?1,000,000 iteration and 500,000 burnin>prior <- list(R = list(V = 1, nu=0.002))>sp.simple <- MCMCglmm(pres ~ large_road + cab + small_road,?family = "categorical", nitt = 1000000, thin = 200, burnin = 500000,?????????????????????????????????????????????data = spring,?prior = prior, verbose = FALSE, pr = TRUE)
>summary(sp.simple)
?Iterations = 500001:999801?Thinning interval ?= 200?Sample size ?= 2500?
?DIC: 858.6316?
?R-structure: ?~units
? ? ? ? ?post.mean ? ?l-95% ? CI u-95% ? ? CI eff.sampunits ? ? 26764 ? ? ?17548 ? ? ?34226 ? ? ? ? ? ? 124.5
?Location effects: pres ~ large_road + cab + small_road?
? ? ? ? ? ? ? ? ? ?post.mean ? ?l-95% ? ?CI u-95% ? ?CI eff.samp ? ? ?pMCMC ? ?(Intercept) ? ? 60.033 ? ? ?47.360 ? ? 70.042 ? ? ? ? ?137.9 ? ? ? ? ? ?<4e-04 ***large_road ? ? ?3.977 ? ? ? ?1.279 ? ? ? 6.616 ? ? ? ?1484.6 ? ? ? ? ? ?0.0080 **?cab_road ? ? ? ?9.913 ? ? ? ?6.761 ? ? 13.020 ? ? ? ? ?333.7 ? ? ? ? ? ?<4e-04 ***small ? ? ? ? ? -16.945 ? ? -20.694 ? ?-13.492 ? ? ? ? ?194.9 ? ? ? ? ? ?<4e-04 ***

?
I'm then wandering if it is because more iteration produce better estimates and then a model that had a better fit with the data.
Anyone can help me??

R?mi


	[[alternative HTML version deleted]]


From kerin at usc.edu  Tue Feb 16 20:37:40 2016
From: kerin at usc.edu (Tara Kerin)
Date: Tue, 16 Feb 2016 11:37:40 -0800
Subject: [R] error message for every parenthesis
In-Reply-To: <56C30B1C.1000602@dewey.myzen.co.uk>
References: <CAP73j161US+z2aUsJJ8VV_pusfKSAfp3bW9SSfnpvfkhDBrdWg@mail.gmail.com>
	<56C30B1C.1000602@dewey.myzen.co.uk>
Message-ID: <CAP73j16jH0EeS1fut0hKMFtDEsagj3w8o=fvR91j1st5+-_ysw@mail.gmail.com>

Thank you both for your quick reply!
I did install 3.2.3, it appears that was just a typo in my earlier message.

Yes! deleting the workspace and history seems to correct the problem. I
will also not continue the practice of saving my workspace. I have also now
downloaded R studio.  Thank you for the tip. The interface is nice, and I
hope this will help my transition over to R.  I'll have to send my thanks
to Garrett as well. :)

I appreciate your help with this, and your patience with a R newbie!

Thanks,
Tara

On Tue, Feb 16, 2016 at 3:42 AM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Tara
>
> 1 - why did you install 3.2.1 when 3.2.3 is the latest version
> 2 - what happens if you delete .RData and .Rapp.history from your
> workspace?
> 3 - you do have a function try as it is part of R
>
> On 16/02/2016 02:49, Tara Kerin wrote:
>
>> Hi,
>>
>> I seem to be having the same problem Garrett (below) had in 2009.
>> However, I do not have functions named try written in my active code.
>> In fact, I don't have any of my own functions written at all yet.  I
>> did just install version 3.2.1 today, and the errors started after
>> that.  Please advise!
>>
>> Thank you,
>>
>> Tara Kerin
>>
>> An example from my GUI is below:
>>
>> [Workspace restored from /Users/tarakerin/.RData]
>> [History restored from /Users/tarakerin/.Rapp.history]
>>
>> Error in try(gsub("\\s+", " ",
>> paste(capture.output(print(args(library))),  :
>>    unused argument (silent = TRUE)
>>
>>> library()
>>>
>>
>>
>>
>> On 7/13/2009 12:35 PM, Garrett Grolemund wrote:
>>
>>> * Whenever I type a parenthesis immediately following a word (as if I'm
>>>
>> *>* entering a function) R displays the following error
>> *> >* Error in try(gsub("\\s+", " ",
>> paste(capture.output(print(args(try))),  :
>> *>*   unused argument(s) (silent = TRUE)
>> *>>* try(
>> *> >* The above is pasted from my R console. The error appears above the
>> command
>> *>* because it appears immediately upon typing the parenthesis.  It does
>> not
>> *>* wait until I try to execute the command.  This happens for every
>> function.
>> *>* I can finish typing the function and execute it.  But these error
>> messages
>> *>* make it difficult to debug my code.  In particular, if I have
>> options(error
>> *>* = recover) set, the above crashes R.
>> *> >* I can avoid the error by typing the parentheses first and then
>> moving the
>> *>* cursor back to type in the word. This error displays on the console
>> whether
>> *>* I'm typing in the console or in an open document window.
>> *> >* I'm using the mac GUI for R.  The error only occurs on my Macbook
>> (OS X
>> *>* 10.5.7), which I bought a few months ago.  It has occurred  every
>> time I use
>> *>* R on this computer.  It has happened with R 2.8 and now R 2.91.
>> *> >* Any idea what may be going on?
>> *
>> Presumably this has something to do with command completion or argument
>> hints.  From the "silent = TRUE" error, and your example, I would guess
>> you have a function named try(), and the GUI is finding yours instead of
>> the one in the base package.
>>
>> The GUI shouldn't do that, it should look in the right place, but as a
>> workaround, you could remove your function named "try", and call it
>> something else.
>>
>> Duncan Murdoch
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=CwIC-g&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=prT9XxFuaRugndr7R7tjdw&m=HVCyKiQWRxny54BBUQ0nDk5GMBt-Tqu5QKL9lPLHz68&s=q4D_wqmRhBJGJthwMhvTyghlur-p0y7tvRFFyQzEKrY&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=CwIC-g&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=prT9XxFuaRugndr7R7tjdw&m=HVCyKiQWRxny54BBUQ0nDk5GMBt-Tqu5QKL9lPLHz68&s=Q6yO2ncF0da0PoI6_hWTYJpGUERfu3iQB1Uvl_-rr_I&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
>
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.dewey.myzen.co.uk_home.html&d=CwIC-g&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=prT9XxFuaRugndr7R7tjdw&m=HVCyKiQWRxny54BBUQ0nDk5GMBt-Tqu5QKL9lPLHz68&s=dg8BMn7W326f_R6GuQUhbH3-QoXSzP40qHbv_wLeNkI&e=

	[[alternative HTML version deleted]]


From remilesmerises at yahoo.ca  Tue Feb 16 22:27:46 2016
From: remilesmerises at yahoo.ca (=?UTF-8?Q?R=C3=A9mi_Lesmerises?=)
Date: Tue, 16 Feb 2016 21:27:46 +0000 (UTC)
Subject: [R] MCMCglmm and iteration behaviour (new attempt)
References: <1195329803.5307268.1455658066417.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1195329803.5307268.1455658066417.JavaMail.yahoo@mail.yahoo.com>

Here a new attempt in trying to improve the visual of my request: 

I'm running a bayesian regression using the package MCMCglmm (Hadfield 2010) and to reach a normal posterior distribution of estimates, I increased the number of iteration as well as the burnin threshold. However, it had unexpected outcomes. Although it improved posterior distribution, it also increased dramatically the value of estimates and decrease DIC. 

Here an example: 

>head(spring) 

pres large_road  small_road  cab 
0      2011         32         78 
1       102        179        204 
0      1256        654        984 
1       187        986        756 
0        21        438         57 
1        13          5        439 



>#pres is presence/absence data and other variable are distance to these features 

>## with 200,000 iteration and 30,000 burnin 
>prior <- list(R = list(V = 1, nu=0.002)) 
>sp.simple <- MCMCglmm(pres ~ large_road + cab + small_road, family = "categorical", nitt = 200000, thin = 200, burnin = 30000, 
              data = spring, prior = prior, verbose = FALSE, pr = TRUE) 

>summary(sp.simple) 

Iterations = 30001:199801 
Thinning interval  = 200 
Sample size  = 850 

DIC: 14045.31 

R-structure:  ~units 

      post.mean   l-95%   CI u-95%     CI eff.samp 
units   294.7     1.621    621.9          1.982 

Location effects: pres ~ large_road + cab + small_road 

               post.mean   l-95%       CI    u-95%     CI    eff.samp    pMCMC 
(Intercept)    5.76781     0.77622     9.24375     1.829       <0.001 ** 
large_road     0.37487     0.02692     0.75282     3.310       <0.001 ** 
cab            0.94639     0.09906     1.57939     2.096       <0.001 ** 
small_raod    -1.62192    -2.60873    -0.20191     2.002       <0.001 ** 



>## with 1,000,000 iteration and 500,000 burnin 
>prior <- list(R = list(V = 1, nu=0.002)) 
>sp.simple <- MCMCglmm(pres ~ large_road + cab + small_road, family = "categorical", nitt = 1000000, thin = 200, burnin = 500000, 
              data = spring, prior = prior, verbose = FALSE, pr = TRUE) 

>summary(sp.simple) 

Iterations = 500001:999801 
Thinning interval  = 200 
Sample size  = 2500 

DIC: 858.6316 

R-structure:  ~units 

post.mean    l-95%   CI u-95%     CI eff.samp 
units     26764      17548      34226             124.5 

Location effects: pres ~ large_road + cab + small_road 

              post.mean   l-95%    CI     u-95%    CI    eff.samp    pMCMC 
(Intercept)   60.033       47.360      70.042       137.9     <4e-04 *** 
large_road     3.977        1.279       6.616      1484.6     0.0080 ** 
cab            9.913        6.761      13.020       333.7     <4e-04 *** 
small_raod   -16.945      -20.694     -13.492       194.9     <4e-04 *** 




I'm then wandering if it is because more iteration produce better estimates and then a model that had a better fit with the data. 

Anyone can help me? 


R?mi Lesmerises
Universit? du Qu?bec ? Rimouski


From akh22 at pitt.edu  Wed Feb 17 03:43:02 2016
From: akh22 at pitt.edu (Hoji, Akihiko)
Date: Wed, 17 Feb 2016 02:43:02 +0000
Subject: [R] Updating github R packages
Message-ID: <36B816FC-5265-4B82-ADF3-7B63A0B3B1A7@pitt.edu>

Hi, 

Is there a way to update a R package and its dependencies,  installed from the github repo by a simple command equivalent to ?update_packages()??

Thanks. 



From bbolker at gmail.com  Wed Feb 17 03:32:56 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 17 Feb 2016 02:32:56 +0000
Subject: [R] MCMCglmm and iteration
References: <1976293102.5340210.1455656318792.JavaMail.yahoo.ref@mail.yahoo.com>
	<1976293102.5340210.1455656318792.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <loom.20160217T031843-715@post.gmane.org>

R?mi Lesmerises <remilesmerises <at> yahoo.ca> writes:

>  Hi everyone, I'm running a bayesian regression using the package
> MCMCglmm (Hadfield 2010) and to reach a normal posterior
> distribution of estimates, I increased the number of iteration as
> well as the burnin threshold. However, it had unexpected
> outcomes. Although it improved posterior distribution, it also
> increased dramatically the value of estimates and decrease DIC.?
> Here's an example:

head(spring)

pres large_road  small_road  cab 
0      2011         32         78 
1       102        179        204 
0      1256        654        984 
1       187        986        756 
0        21        438         57 
1        13          5        439 

# pres is presence/absence data and other variable are distance to these
features
# with?200,000 iteration and 30,000 burnin

prior <- list(R = list(V = 1, nu=0.002))
sp.simple <- MCMCglmm(pres ~ large_road + cab + small_road,
   family = "categorical", nitt = 200000, thin = 200,
    burnin = 30000, data = spring,?prior = prior, verbose = FALSE, pr = TRUE)
------------

(1) you will do much better with this kind of question on r-sig-mixed-models.
(2) it looks like your chain is mixing very, very badly.  If I'm reading
the output correctly, it looks like your effective sample sizes for the
first run (200K iterations) are 1-3 (!) -- you should be aiming for 
effective sample sizes of 100s to 1000s.  Even with a million iterations
you're only getting up to effective sample sizes of ~150 for some
parameters.  I would recommend (a) centring and scaling your parameters
to improve mixing and (b) cross-checking with a different method
(e.g. lme4 or glmmADMB) to make sure you're in the right ballpark.

  You shouldn't necessarily expect a Normal posterior as you increase
the number of iterations; the posterior distributions are only 
asymptotically Normal as the number of *observations* increases.

From flarochelle1964 at gmail.com  Wed Feb 17 01:13:42 2016
From: flarochelle1964 at gmail.com (filaro1964 .)
Date: Tue, 16 Feb 2016 19:13:42 -0500
Subject: [R] Randomizing list independence
Message-ID: <CAE_sqRDVTtk5VkSkgg2MnXk5PLRg0ZtWBS=jDxU_M-KKgDzuAw@mail.gmail.com>

Bonjour, Hi,

English follow (google trad.)


Mon fils fait des course de ski alpin. Lors des courses, il y a un tirage
au sort pour d?terminer l'ordre de d?part. Au fil du temps, j'ai remarqu?
que sa position de d?part semblait r?pondre ? un certain patron. Il se
retrouve tr?s souvent en d?but de liste (2 ou 3eme) ou en fin de liste (2
ou 3eme avant dernier). De plus, un autre courreur se retrouve toujours
juste avant ou juste apr?s ? une ou deux position pr?s. Je cherche donc un
test statistique qui pourrait me dire s'il y a un biais dans le tirage au
hasard. Je sais que le tirage au hasard est fait sous Excel et que le
g?n?rateur de nombres al?atoires est biais? (nombreux articles
scientifiques sur le sujet). Pour gagner mon point, je cherche un test
statistique qui m'aiderait ? v?rifier si il y a une corr?lation entre la
liste des courreurs (tri?e par club et ?ge) et la liste de d?part apr?s
tirage al?atoire.

Merci,

Fran?ois.


Cas d'exemple de listes de d?part apr?s tirage al?atoire sous excel


Courreur-1
Courreur-2
Fils
Ami
Courreur-5
...

-=-=-=

...
Fils
Ami
Courreur-n
Courreur-n+1

-=-=-=

Courreur-1
Courreur-2
Fils
Courreur-4
Ami
Courreur-6
...

------------------------------Google trad------------------------

My son made the ski race. During the races, there is a draw to determine
the starting order. Over time, I noticed that his starting position seemed
to respond to a boss. It is very often top of the list (2 or 3rd) or end of
the list (2 or 3rd before last). In addition, another runner is always
found just before or just after one or two position closely. I seek a
statistical test that could tell me if there is a bias in the random draw. I
know the random drawing is done in Excel and the random number generator is
biased (many scientific articles on the subject). To win my point, looking
for a statistical test that would help me to check if there is a
correlation between the list of runners (sorted by age and club) and the
start list after randomization.

Thank you,

Fran?ois.


Case of start lists after randomization in Excel


Runner-1
Runner-2
Son
Friend
Runner-5
...

- = - = - =

...
Son
Friend
Runner-n
Runner-n + 1

- = - = - =

Runner-1
Runner-2
Son
Runner-4
Friend
Runner-6
...

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Feb 17 08:44:53 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 Feb 2016 23:44:53 -0800
Subject: [R] Updating github R packages
In-Reply-To: <36B816FC-5265-4B82-ADF3-7B63A0B3B1A7@pitt.edu>
References: <36B816FC-5265-4B82-ADF3-7B63A0B3B1A7@pitt.edu>
Message-ID: <ACC37D29-D7E3-40BB-885C-09852156F292@dcn.davis.ca.us>

AFAIK the answer is no. That would be one of the main drawbacks of depending on github for packages. It isn't really a package repository so much as it is a herd of cats.
-- 
Sent from my phone. Please excuse my brevity.

On February 16, 2016 6:43:02 PM PST, "Hoji, Akihiko" <akh22 at pitt.edu> wrote:
>Hi, 
>
>Is there a way to update a R package and its dependencies,  installed
>from the github repo by a simple command equivalent to
>?update_packages()??
>
>Thanks. 
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From abinnogoes at gmail.com  Wed Feb 17 09:01:56 2016
From: abinnogoes at gmail.com (Moss Moss)
Date: Wed, 17 Feb 2016 00:01:56 -0800
Subject: [R] I Need Help for Location Model
Message-ID: <CACxOM1uBgGhGaZXF75PZf4ia32AVasmO6T5svaE_9V31YhxKGA@mail.gmail.com>

I am working on "Discrimination and Classification Using Both Binary
and Continuous Variables".

Please, how can I use R-programming in running the following:
(1) Location Model
(2) Misclassification
(3) Error Rate
(4) Etc

I have R i386 3.2.2 installed to in my system. How do I trace
statistical tool like Location model, etc.

Moses


From abinnogoes at gmail.com  Wed Feb 17 09:12:53 2016
From: abinnogoes at gmail.com (Moss Moss)
Date: Wed, 17 Feb 2016 00:12:53 -0800
Subject: [R] I Need Help for Location Model, etc
Message-ID: <CACxOM1sVsEMjCRkNJWnDL7GAN6JR8d0FAe9zsJhbA7wWzaNxzg@mail.gmail.com>

I am working on "Discrimination and Classification Using Both Binary
and Continuous Variables".

Please, how can I use R-programming in running the following:
(1) Location Model
(2) Misclassification
(3) Error Rate
(4) Etc

I have R i386 3.2.2 installed to in my system. How do I trace
statistical tool like Location model, etc.

Moses


From jean-externe.maurice at edf.fr  Wed Feb 17 08:39:33 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 17 Feb 2016 07:39:33 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
Message-ID: <314359b127be43d4ad3046242e235a8d@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Ulrik and Rui,

Both solutions work but data.frame is the way i?ll go because there is an advantage that I was?nt aware at the beginning : we can save the data.frame in a text file, modify this file with notepad, ?

Thank you very much
Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

	[[alternative HTML version deleted]]


From vidupranam at gmail.com  Wed Feb 17 05:33:20 2016
From: vidupranam at gmail.com (vidu pranam)
Date: Wed, 17 Feb 2016 10:03:20 +0530
Subject: [R] How to read DiCOM images using R?
Message-ID: <CAOxUbyVy-msZS6zH8FSr8E6-ndOmF+Ad=nizRu-UQTnBr2b4Dw@mail.gmail.com>

Hai,

  I have some DICOM format images for my project. Can you please help me
how can I read it by using R and how to analyse the images?

Regards
Vidu

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Wed Feb 17 06:07:55 2016
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 17 Feb 2016 00:07:55 -0500
Subject: [R] Constructing a symmetric matrix using library(corpcor)
Message-ID: <CAKTtY6S8k5vY+fc_pgTk9gO0ftNLRwJXKeSKvF9b09YMAkRNTA@mail.gmail.com>

Hello

I am constructing a symmetric matrix with library "corpcor". In the
codes below, I am able to construct a symmetric matrix of order 3 and
4. However, the 5 x 5 matrix does not seem right? Help?

Thanks.


> library(corpcor)> r  <- 1:3> rr <- vec2sm(r, diag = F)> rr <- rr[upper.tri(rr)]> r  <- vec2sm(rr, diag = F); diag(r) <- 1> r     [,1] [,2] [,3]
[1,]    1    1    2
[2,]    1    1    3
[3,]    2    3    1> > r  <- 1:6> rr <- vec2sm(r, diag = F)> rr <-
rr[upper.tri(rr)]> r  <- vec2sm(rr, diag = F); diag(r) <- 1> r
[,1] [,2] [,3] [,4]
[1,]    1    1    2    4
[2,]    1    1    3    5
[3,]    2    3    1    6
[4,]    4    5    6    1> > r  <- 1:10> rr <- vec2sm(r, diag = F)> rr
<- rr[upper.tri(rr)]> r  <- vec2sm(rr, diag = F); diag(r) <- 1> r
[,1] [,2] [,3] [,4] [,5]
[1,]    1    1    2    5    3
[2,]    1    1    6    8    4
[3,]    2    6    1    7    9
[4,]    5    8    7    1   10
[5,]    3    4    9   10    1

>

	[[alternative HTML version deleted]]


From phi771 at gmail.com  Wed Feb 17 09:14:59 2016
From: phi771 at gmail.com (Steve Ryan)
Date: Wed, 17 Feb 2016 09:14:59 +0100
Subject: [R] "predict" values from object of type "list"
Message-ID: <CADh78ZRXKVvfJox4VWCN1kQ0sxhJetT-ScSggbh=HVAaH0+g+Q@mail.gmail.com>

Hi Guys,

I could need some help here. I have a set of 3d points (x,y,v). These
points are not randomly scattered but lie on a surface. This surface can be
taken as a calibration plane for x and y -values. My goal is to quantify
this surface and than predict the v-values for given pairs of x- and
y-coordinates.

This iscode shows how I started to solve this problem. First, I generate
more points between existing points using 3d-splines. That way I
"pre-smooth" my data set. After that I use interp to create even more
points and I end up with an object called "sp" (class "list"). sp is
visualized using surface3d. The surface looks like I wish it to be.

Now, how can I predict a x/y-pair of, say -2, 2 ??
Can somebody help?
Thanks a lot!

library(rgl)
library(akima)

v <- read.table(text="5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6
6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9
9 9 9 9 9 9 9 9 9 9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11
11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12
12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14
14 14 14 14 14 14 14", sep=" ")
v <- as.numeric(v)
x <- read.table(text="3.4 3.3 3.4 3.4 3.4 3.4 3.6 3.5 3.5 3.4 3.4 3.4 3.4
3.5 3.5 2.6 2.6 2.6 2.7 2.6 2.7 2.9 2.9 2.8 2.7 2.7 2.7 2.7 2.7 2.8 1.8 1.7
1.7 1.7 1.8 1.9 2.1 2.2 2.0 1.9 1.9 1.9 1.9 1.9 2.0 0.8 0.8 0.8 0.8 0.9 1.1
1.3 1.4 1.2 1.1 1.0 1.0 1.0 1.1 1.1 -0.2 -0.2 -0.2 -0.2 0.0 0.2 0.4 0.6 0.3
0.1 0.1 0.1 0.1 0.1 0.2 -1.2 -1.3 -1.3 -1.3 -1.1 -0.8 -0.5 -0.3 -0.6 -0.9
-0.9 -0.9 -0.9 -1.0 -0.9 -2.4 -2.6 -2.6 -2.5 -2.3 -2.0 -1.1 -1.2 -1.6 -2.0
-2.0 -2.0 -2.1 -2.2 -2.1 -3.9 -4.2 -4.3 -4.2 -3.9 -3.6 -2.5 -2.7 -3.3 -3.7
-3.7 -3.8 -3.8 -4.0 -3.9 -5.8 -6.1 -6.2 -6.1 -5.7 -5.3 -3.9 -4.1 -4.8 -5.3
-5.3 -5.3 -5.4 -5.5 -5.4 -7.5 -7.8 -8.0 -7.8 -7.4 -6.8 -5.1 -5.3 -6.1 -6.6
-6.7 -6.8 -6.9 -6.9 -6.9", sep=" ")
y <- read.table(text="0.5 0.6 0.6 0.7 0.7 0.8 0.8 0.9 0.9 1.0 1.0 1.1 1.1
1.2 1.2 0.5 0.5 0.6 0.7 0.8 0.9 0.9 1.0 1.1 1.1 1.2 1.3 1.4 1.4 1.5 0.4 0.5
0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 0.4 0.5 0.7 0.8 0.9 1.0
1.1 1.2 1.3 1.5 1.6 1.7 1.9 2.0 2.1 0.4 0.5 0.7 0.8 1.0 1.1 1.2 1.3 1.5 1.7
1.8 2.0 2.1 2.3 2.4 0.3 0.5 0.7 0.9 1.0 1.2 1.4 1.5 1.7 1.9 2.1 2.3 2.5 2.7
2.8 0.2 0.4 0.7 0.9 1.1 1.3 1.4 1.6 1.9 2.2 2.4 2.6 2.8 3.1 3.3 0.2 0.4 0.7
1.0 1.3 1.5 1.6 1.8 2.2 2.5 2.7 3.0 3.3 3.6 3.8 0.2 0.5 0.8 1.1 1.4 1.7 1.8
2.0 2.4 2.8 3.1 3.4 3.7 4.1 4.3 0.1 0.4 0.8 1.2 1.5 1.8 1.9 2.2 2.7 3.1 3.5
3.8 4.2 4.5 4.9", sep=" ")
x <- as.numeric(x)
y <- as.numeric(y)
z <- read.table(text="-35 -30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 -35
-30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 -35 -30 -25 -20 -15 -10 -5 0 5
10 15 20 25 30 35 -35 -30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 -35 -30
-25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 -35 -30 -25 -20 -15 -10 -5 0 5 10
15 20 25 30 35 -35 -30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35 -35 -30 -25
-20 -15 -10 -5 0 5 10 15 20 25 30 35 -35 -30 -25 -20 -15 -10 -5 0 5 10 15
20 25 30 35 -35 -30 -25 -20 -15 -10 -5 0 5 10 15 20 25 30 35", sep=" ")
z <- as.numeric(z)

df <- data.frame(x,y,z,v) #hier ist df die originale kali
plot3d(x,y,v)
all_dat <- c()

for (n in seq(min(z), max(z),5))
{
  blubb <- (which(df$z == n)) #hier werden gleiche winkel gesucht
  gleicheWink <- df[(blubb),]
  red_df <- data.frame(t=seq(1,length(gleicheWink[,1]),1), x =
gleicheWink$x, y= gleicheWink$y, v=gleicheWink$v )
  ts <- seq( from = min(red_df$t), max(red_df$t), length=50 )
  d2 <- apply( red_df[,-1], 2, function(u) spline(red_df$t, u, xout = ts
)$y )
  all_dat <- rbind(all_dat, d2)
}

x <- all_dat[,1]
y <- all_dat[,2]
z <- all_dat[,3]

sp <- interp(x,y,z,linear=TRUE, xo=seq(min(x),max(x), length=50),
             yo=seq(min(y),max(y), length=50), duplicate="mean")

open3d(scale=c(1/diff(range(x)),1/diff(range(y)),1/diff(range(z))))

zlen=5
cols <- heat.colors(zlen)

with(sp,surface3d(x,y,z, color=cols)) #,alpha=.2))
points3d(x,y,z)

title3d(xlab="x",ylab="y",zlab="v")
axes3d()

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 17 09:35:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Feb 2016 00:35:22 -0800
Subject: [R] I Need Help for Location Model,
Message-ID: <CAGxFJbQayAsH2kox-PKZKpqZBkDkxhZDiomBPeysLVt8rgiX_A@mail.gmail.com>

Pls do not repeat posts. That's spam.

This list has a no homework policy. Your query seems to be homework. Ergo,
you should not expect a response unless you clarify that it is not.

Bert



On Tuesday, February 16, 2016, Moss Moss <abinnogoes at gmail.com> wrote:

> I am working on "Discrimination and Classification Using Both Binary
> and Continuous Variables".
>
> Please, how can I use R-programming in running the following:
> (1) Location Model
> (2) Misclassification
> (3) Error Rate
> (4) Etc
>
> I have R i386 3.2.2 installed to in my system. How do I trace
> statistical tool like Location model, etc.
>
> Moses
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 17 10:10:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Feb 2016 01:10:11 -0800
Subject: [R] I Need Help for Location Model,
In-Reply-To: <CACxOM1ssqyeb1dzwz9p_8gGT+N9nAAnfhnZ8kJyYoibuFejdJw@mail.gmail.com>
References: <CAGxFJbQayAsH2kox-PKZKpqZBkDkxhZDiomBPeysLVt8rgiX_A@mail.gmail.com>
	<CACxOM1ssqyeb1dzwz9p_8gGT+N9nAAnfhnZ8kJyYoibuFejdJw@mail.gmail.com>
Message-ID: <CAGxFJbRfQJU1GmV3uC5Mr7bQ0J2kJ05SXi=3Uj3tR9Q6i+syxQ@mail.gmail.com>

Pls always respond to the list, which I have cc'ed.

It sounds like you want us to teach you R and statistics. You need to do
this yourself, using local resources or available tutorials and courses on
the web. Some recommendations for this can be found here:

https://www.rstudio.com/resources/training/online-learning/#R

Bert




On Tuesday, February 16, 2016, Moss Moss <abinnogoes at gmail.com> wrote:

> I want to generate data from a location model for my thesis.
> Please, what do you mean by "homework policy".
>
> Help me to run R-programming in my system.
>
> On 2/17/16, Bert Gunter <bgunter.4567 at gmail.com <javascript:;>> wrote:
> > Pls do not repeat posts. That's spam.
> >
> > This list has a no homework policy. Your query seems to be homework.
> Ergo,
> > you should not expect a response unless you clarify that it is not.
> >
> > Bert
> >
> >
> >
> > On Tuesday, February 16, 2016, Moss Moss <abinnogoes at gmail.com
> <javascript:;>> wrote:
> >
> >> I am working on "Discrimination and Classification Using Both Binary
> >> and Continuous Variables".
> >>
> >> Please, how can I use R-programming in running the following:
> >> (1) Location Model
> >> (2) Misclassification
> >> (3) Error Rate
> >> (4) Etc
> >>
> >> I have R i386 3.2.2 installed to in my system. How do I trace
> >> statistical tool like Location model, etc.
> >>
> >> Moses
> >>
> >> ______________________________________________
> >> R-help at r-project.org <javascript:;> <javascript:;> mailing list -- To
> UNSUBSCRIBE and
> >> more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> > --
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From kroberts012 at gmail.com  Wed Feb 17 10:19:47 2016
From: kroberts012 at gmail.com (Kieran)
Date: Wed, 17 Feb 2016 10:19:47 +0100
Subject: [R] Excluding "small data" from plot.
Message-ID: <CAMVnMy2KT12iN0BvZEuCuq6k3oOH2tZzhx1AwNF9uHiQuRheKA@mail.gmail.com>

To R-help users:

I want to use ggplot two plot summary statistics on the frequency of
letters from
a page of text. My data frame has four columns:

(1) The line number [1 to 30]
(2) The letter [a to z]
(3) The frequency of the letter [assuming there is 80 letters per line]
(4) The factor 'type': bad or good (purely artificial factor)

I want to achieve the following plot:

(a) Bar plot with an x-axis to be the letters and the y-axis the sum of
30 letter frequencies from each line of each letter.
(b) Split each bar (for a letter) into two bars for 'good' and 'bad' types.
(c) Display the union of the top 8 most frequency used letters for both types
'good' and 'bad'.

By point (c) I mean: if a,e,f,h,i,t,s,r are the most frequent letter of type
'good' and a,e,f,h,i,m,l,p are the most frequent letter of type 'bad'. Then
I would like my plot to feature the letters a,e,f,h,i,t,s,r,m,l,p.

Here is my code:

# There will be 30 lines and we want to record the frequency of each letter
# on each line.

lines <- c(rep(1:30, each=26))
letter <- c(rep(letters, times=30))

# We have taken the letter frequencies from
# http://www.math.cornell.edu/~mec/2003-2004/cryptography/subs/frequencies.html

freq <- c(8.12, 1.49, 2.71, 4.32, 12.02, 2.30, 2.03, 5.92, 7.31, 0.10, 0.69,
3.98, 2.61, 6.95, 7.68, 1.82, 0.11, 6.02, 6.28, 9.10, 2.88, 1.11, 2.09, 0.17,
2.11, 0.07)
freq <- freq/100


# We assume each line contains 80 letters and change the seed for each line
# for variability.

letterfreq <- integer()
for (i in 1:30) {
    set.seed(i)
    s<-data.frame(sample(letters, size = 80, replace = TRUE, prob = freq))
    names(s) <- "ltr"
    s$ltr <- factor(s$ltr, levels = letters)
    frq<-as.data.frame(table(s))
    letterfreq <- append(letterfreq, frq$Freq)
}

ltrfreq <- data.frame(lines, letter, letterfreq)

# Add an artificial factor column _type_: good/bad. So each pair
# (week, letter) has type 'good' or 'bad' with equal probability.
# Set the seed for reproducibility.

set.seed(999)
ltrfreq$type <-  factor(sample(c("good","bad"), size = 780, replace = TRUE,
    prob = c(0.5,0.5)))


# Here is the plot I want but this includes all 26 letters.

ggplot(ltrfreq,aes(x=factor(letter),y=letterfreq, fill=type), color=type) +
  stat_summary(fun.y=sum,position=position_dodge(),geom="bar")

Best regards,
Kieran.


From h.wickham at gmail.com  Wed Feb 17 10:25:11 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 17 Feb 2016 20:25:11 +1100
Subject: [R] Updating github R packages
In-Reply-To: <ACC37D29-D7E3-40BB-885C-09852156F292@dcn.davis.ca.us>
References: <36B816FC-5265-4B82-ADF3-7B63A0B3B1A7@pitt.edu>
	<ACC37D29-D7E3-40BB-885C-09852156F292@dcn.davis.ca.us>
Message-ID: <CABdHhvEThGA-5aqUR_tfsczYVB4dd_XWTwR94F9wqibscknSnw@mail.gmail.com>

It will be included in the next version of devtools - it's totally
do-able, but no one has done it yet.

Hadley

On Wed, Feb 17, 2016 at 6:44 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> AFAIK the answer is no. That would be one of the main drawbacks of depending on github for packages. It isn't really a package repository so much as it is a herd of cats.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 16, 2016 6:43:02 PM PST, "Hoji, Akihiko" <akh22 at pitt.edu> wrote:
>>Hi,
>>
>>Is there a way to update a R package and its dependencies,  installed
>>from the github repo by a simple command equivalent to
>>?update_packages()??
>>
>>Thanks.
>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From petr.pikal at precheza.cz  Wed Feb 17 13:08:42 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Feb 2016 12:08:42 +0000
Subject: [R] I Need Help for Location Model, etc
In-Reply-To: <CACxOM1sVsEMjCRkNJWnDL7GAN6JR8d0FAe9zsJhbA7wWzaNxzg@mail.gmail.com>
References: <CACxOM1sVsEMjCRkNJWnDL7GAN6JR8d0FAe9zsJhbA7wWzaNxzg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F8EC@SRVEXCHMBX.precheza.cz>

Hi

You can use either search within CRAN or Task Views. Both can suggest appropriate packages. Do not expect that we can decide which function/package you shall use for your data.

I found among others:

https://cran.r-project.org/web/packages/mix/mix.pdf

but there are plenty of packages which state they compute location model. The same applies with misclassification.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Moss
> Moss
> Sent: Wednesday, February 17, 2016 9:13 AM
> To: r-help at r-project.org
> Subject: [R] I Need Help for Location Model, etc
>
> I am working on "Discrimination and Classification Using Both Binary
> and Continuous Variables".
>
> Please, how can I use R-programming in running the following:
> (1) Location Model
> (2) Misclassification
> (3) Error Rate
> (4) Etc
>
> I have R i386 3.2.2 installed to in my system. How do I trace
> statistical tool like Location model, etc.
>
> Moses
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ulrik.stervbo at gmail.com  Wed Feb 17 13:43:37 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 17 Feb 2016 12:43:37 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <bbcd60eda364484f959c2940a4bac82e@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
	<bbcd60eda364484f959c2940a4bac82e@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <CAKVAULPab+9-Jetr82XdWRy1QCJLs3f8tzP=aRj3=isEC+k4yA@mail.gmail.com>

Hi Jean,

the 'unused argument (stringAsFactors = FALSE)' gives you a good clue. It
tells you, that you are passing an unexpected argument to the read.table
function.

In this case the argument is stringsAsFactors (string in plural).

I don't know how you modify the columns, but the factors should not be the
reason why it doesn't work.

If your table have headers as hinted in the data.frame example, you should
include header = TRUE

Hope this helps
Ulrik

On Wed, 17 Feb 2016 at 12:01 MAURICE Jean - externe <
jean-externe.maurice at edf.fr> wrote:

> I need some more help !
>
>
>
> Data.frame is working great but for one thing : once the file has been
> read, I can?t modify a ?string? column. This is, I suppose, because the
> column is a factor.
>
>
>
> But I get an error when I write :
>
> > mim = read.table(file = "GESDYN_COMPLET_parametres.txt", row.names =
> "clef", stringAsFactors = FALSE)
>
> Error in read.table(file = "GESDYN_COMPLET_parametres.txt", row.names =
> "clef",  :
>
>   unused argument (stringAsFactors = FALSE)
>
> Why ?
>
> Jean
>
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations qui y
> figurent sont strictement confidentielles. Toute utilisation de ce Message
> non conforme ? sa destination, toute diffusion ou toute publication totale
> ou partielle, est interdite sauf autorisation expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de
> le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou
> partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de
> votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace
> sur quelque support que ce soit. Nous vous remercions ?galement d'en
> avertir imm?diatement l'exp?diteur par retour du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute
> erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely for
> the addressees. The information contained in this Message is confidential.
> Any use of information contained in this Message not in accord with its
> purpose, any dissemination or disclosure, either whole or partial, is
> prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or use
> any part of it. If you have received this message in error, please delete
> it and all copies from your system and notify the sender immediately by
> return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Feb 17 13:49:51 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Feb 2016 12:49:51 +0000
Subject: [R] Excluding "small data" from plot.
In-Reply-To: <CAMVnMy2KT12iN0BvZEuCuq6k3oOH2tZzhx1AwNF9uHiQuRheKA@mail.gmail.com>
References: <CAMVnMy2KT12iN0BvZEuCuq6k3oOH2tZzhx1AwNF9uHiQuRheKA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F917@SRVEXCHMBX.precheza.cz>

Hi

There is probably better solution but I would aggregate

lll <- aggregate(ltrfreq$letterfreq, list(ltrfreq$letter, ltrfreq$type), sum)

order

ooo<-order(lll$x, decreasing=T)

split and sapply
lll<- lll[ooo,]
lll <- lapply(split(lll, lll$Group.2), head, 8)

and do.call rbind to get 8 letters for good and bad plotting.

lll<-do.call(rbind, lll)
library(ggplot2)
ggplot(lll,aes(x=Group.1,y=x, fill=Group.2), color=Group.2) +
+  stat_summary(fun.y=sum,position=position_dodge(),geom="bar")


Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kieran
> Sent: Wednesday, February 17, 2016 10:20 AM
> To: R-help at r-project.org
> Subject: [R] Excluding "small data" from plot.
>
> To R-help users:
>
> I want to use ggplot two plot summary statistics on the frequency of
> letters from
> a page of text. My data frame has four columns:
>
> (1) The line number [1 to 30]
> (2) The letter [a to z]
> (3) The frequency of the letter [assuming there is 80 letters per line]
> (4) The factor 'type': bad or good (purely artificial factor)
>
> I want to achieve the following plot:
>
> (a) Bar plot with an x-axis to be the letters and the y-axis the sum of
> 30 letter frequencies from each line of each letter.
> (b) Split each bar (for a letter) into two bars for 'good' and 'bad'
> types.
> (c) Display the union of the top 8 most frequency used letters for both
> types
> 'good' and 'bad'.
>
> By point (c) I mean: if a,e,f,h,i,t,s,r are the most frequent letter of
> type
> 'good' and a,e,f,h,i,m,l,p are the most frequent letter of type 'bad'.
> Then
> I would like my plot to feature the letters a,e,f,h,i,t,s,r,m,l,p.
>
> Here is my code:
>
> # There will be 30 lines and we want to record the frequency of each
> letter
> # on each line.
>
> lines <- c(rep(1:30, each=26))
> letter <- c(rep(letters, times=30))
>
> # We have taken the letter frequencies from
> # http://www.math.cornell.edu/~mec/2003-
> 2004/cryptography/subs/frequencies.html
>
> freq <- c(8.12, 1.49, 2.71, 4.32, 12.02, 2.30, 2.03, 5.92, 7.31, 0.10,
> 0.69,
> 3.98, 2.61, 6.95, 7.68, 1.82, 0.11, 6.02, 6.28, 9.10, 2.88, 1.11, 2.09,
> 0.17,
> 2.11, 0.07)
> freq <- freq/100
>
>
> # We assume each line contains 80 letters and change the seed for each
> line
> # for variability.
>
> letterfreq <- integer()
> for (i in 1:30) {
>     set.seed(i)
>     s<-data.frame(sample(letters, size = 80, replace = TRUE, prob =
> freq))
>     names(s) <- "ltr"
>     s$ltr <- factor(s$ltr, levels = letters)
>     frq<-as.data.frame(table(s))
>     letterfreq <- append(letterfreq, frq$Freq)
> }
>
> ltrfreq <- data.frame(lines, letter, letterfreq)
>
> # Add an artificial factor column _type_: good/bad. So each pair
> # (week, letter) has type 'good' or 'bad' with equal probability.
> # Set the seed for reproducibility.
>
> set.seed(999)
> ltrfreq$type <-  factor(sample(c("good","bad"), size = 780, replace =
> TRUE,
>     prob = c(0.5,0.5)))
>
>
> # Here is the plot I want but this includes all 26 letters.
>
> ggplot(ltrfreq,aes(x=factor(letter),y=letterfreq, fill=type),
> color=type) +
>   stat_summary(fun.y=sum,position=position_dodge(),geom="bar")
>
> Best regards,
> Kieran.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jan.kacaba at gmail.com  Wed Feb 17 11:04:38 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Wed, 17 Feb 2016 11:04:38 +0100
Subject: [R] missing values in csv file
Message-ID: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>

In my original data a csv file I have missing values. If I use read.table
the missing values are replaced by NAs.

Is it possible to get object where missing values aren't replaced with NAs?
Is it possible to replace NAs with empty space?

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Wed Feb 17 10:10:54 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 17 Feb 2016 09:10:54 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
Message-ID: <1a6ebacffd8f4dbd98781f07169bb97e@NOEINTPEXMU007.NEOPROD.EDF.FR>

I went further !

I could give a name to each row based on column 2 in the read.table command and then access to the value by :

mom["PC_Q_m3",]$value

It?s great
Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Wed Feb 17 12:00:59 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 17 Feb 2016 11:00:59 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
Message-ID: <bbcd60eda364484f959c2940a4bac82e@NOEINTPEXMU007.NEOPROD.EDF.FR>

I need some more help !

Data.frame is working great but for one thing : once the file has been read, I can?t modify a ?string? column. This is, I suppose, because the column is a factor.

But I get an error when I write :
> mim = read.table(file = "GESDYN_COMPLET_parametres.txt", row.names = "clef", stringAsFactors = FALSE)
Error in read.table(file = "GESDYN_COMPLET_parametres.txt", row.names = "clef",  :
  unused argument (stringAsFactors = FALSE)



Why ?
Jean





Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

	[[alternative HTML version deleted]]


From shivi.bhatia at safexpress.com  Wed Feb 17 10:16:14 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Wed, 17 Feb 2016 14:46:14 +0530
Subject: [R] R Memory Issue
Message-ID: <001001d16963$cc7f5230$657df690$@safexpress.com>

Dear Team,

 

Every now and then I face some weird issues with R. For instance it would
not read my csv file or any other read.table command and once I would close
the session and reopen again it works fine. 

 

It have tried using rm(list=ls()) & gc() to free some memory and restart R
<Cntrl+Shft+F10>

 

Also today while closing the R session it took more than 10 minutes. I am
not sure as to what is leading to this. Kindly throw some light on this. Not
sure if I have provided enough information.      

 

Thanks, Shivi

Mb: 9891002021

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160217/aa7c2d2d/attachment.pl>

From dusa.adrian at unibuc.ro  Wed Feb 17 14:01:26 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Wed, 17 Feb 2016 15:01:26 +0200
Subject: [R] missing values in csv file
In-Reply-To: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
References: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
Message-ID: <CAJ=0CtDNQh=30s0rENtdyBsfQvWna7kRQcH5Cjj=4J+h8AS6eA@mail.gmail.com>

On Wed, Feb 17, 2016 at 12:04 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:

> In my original data a csv file I have missing values. If I use read.table
> the missing values are replaced by NAs.
>

That is the normal way of dealing with missing values, in R.


Is it possible to get object where missing values aren't replaced with NAs?
> Is it possible to replace NAs with empty space?
>

It is possible to replace the NAs with empty space, but nobody would
recommend that because your variable will be coerced to a character mode.
If the other values are numbers, you won't be able to compute any numerical
measures.
Try to accept that NA is there for a reason, in R.

I hope this helps,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Wed Feb 17 14:02:59 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 17 Feb 2016 07:02:59 -0600
Subject: [R] Static to interactive map (leaflet spplot)
In-Reply-To: <CAM9mbiBrBXvAoe_natwLi7uHcokTCe9UOgvVSJy=b_vvbpLJLg@mail.gmail.com>
References: <CAM9mbiBrBXvAoe_natwLi7uHcokTCe9UOgvVSJy=b_vvbpLJLg@mail.gmail.com>
Message-ID: <CAN5YmCFP=tdjVVB5yb1iDfRL3byAMuaiqm48HkN2TS_q+z3R0A@mail.gmail.com>

Deb,

I assume you have already seen the great introduction to leaflet here ...
http://rstudio.github.io/leaflet/

You may find these two answers on stackoverflow helpful ...

http://stackoverflow.com/a/28240058/2140956
http://stackoverflow.com/a/29118680/2140956


Jean

On Tue, Feb 2, 2016 at 5:28 PM, Debasish Pai Mazumder <pai1981 at gmail.com>
wrote:

> Hi ALL,
>
> I have a script to plot hexagonal polygon on a map. Its a static map. I
> used spplot. I would like to convert this plot to interactive plot using "
> *leaflet*". How do I make it interactive plot?
>
> Here is spplot lines:
>
> cl = map("world", xlim = c(-120, 20), ylim = c(-10, 70), plot = TRUE)
> cl = map("world",plot = TRUE)
> clp = map2SpatialLines(cl, proj4string = CRS(ll))
> clp = spTransform(clp, CRS(lcc))
> l2 = list("sp.lines", clp, col = "black", lty = 1, lwd = 3)
>
> cr = colorRampPalette(brewer.pal(9,"YlOrRd"))(100)
>
> require(grid)
> spplot(hspdf, "CDP", col = "white", col.regions = cr,
>             sp.layout = list(l2),
>             at = seq(0,100,10),
>             sub = list("CDP", cex = 1.5, font = 2))
>
> where
> > hspdf
> class       : SpatialPolygonsDataFrame
> features    : 95
> extent      : -4141330, 3748528, 1530846, 6914278  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-60 +ellps=WGS84
> variables   : 4
> names       : hexid, count, hct,               CDP
> min values  :    37,     1,   1, 0.136612021857923
> max values  :   448,     7,   3,  39.4391854927413
>
> CDP values of each hexagonal polygon.
>
> -Deb
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Feb 17 14:10:30 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Feb 2016 13:10:30 +0000
Subject: [R] missing values in csv file
In-Reply-To: <CAJ=0CtDNQh=30s0rENtdyBsfQvWna7kRQcH5Cjj=4J+h8AS6eA@mail.gmail.com>
References: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
	<CAJ=0CtDNQh=30s0rENtdyBsfQvWna7kRQcH5Cjj=4J+h8AS6eA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F969@SRVEXCHMBX.precheza.cz>

Beside of Adrian's answer, R can simply manage NAs but you need to deal with "empty space" on your own.

See

?is.na
?na.omit

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian
> Du?a
> Sent: Wednesday, February 17, 2016 2:01 PM
> To: Jan Kacaba
> Cc: r-help at r-project.org
> Subject: Re: [R] missing values in csv file
>
> On Wed, Feb 17, 2016 at 12:04 PM, Jan Kacaba <jan.kacaba at gmail.com>
> wrote:
>
> > In my original data a csv file I have missing values. If I use
> > read.table the missing values are replaced by NAs.
> >
>
> That is the normal way of dealing with missing values, in R.
>
>
> Is it possible to get object where missing values aren't replaced with
> NAs?
> > Is it possible to replace NAs with empty space?
> >
>
> It is possible to replace the NAs with empty space, but nobody would
> recommend that because your variable will be coerced to a character
> mode.
> If the other values are numbers, you won't be able to compute any
> numerical measures.
> Try to accept that NA is there for a reason, in R.
>
> I hope this helps,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Feb 17 14:16:30 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Feb 2016 13:16:30 +0000
Subject: [R] R Memory Issue
In-Reply-To: <001001d16963$cc7f5230$657df690$@safexpress.com>
References: <001001d16963$cc7f5230$657df690$@safexpress.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F97D@SRVEXCHMBX.precheza.cz>

Hi

I have this enhanced ls function, which evaluates size of objects generated by myself or by other functions sitting in my environment.

ls.objects <- function (pos = 1, pattern, order.by)
{
    napply <- function(names, fn) sapply(names, function(x) fn(get(x,
        pos = pos)))
    names <- ls(pos = pos, pattern = pattern)
    obj.class <- napply(names, function(x) as.character(class(x))[1])
    obj.mode <- napply(names, mode)
    obj.type <- ifelse(is.na(obj.class), obj.mode, obj.class)
    obj.size <- napply(names, object.size)
    obj.dim <- t(napply(names, function(x) as.numeric(dim(x))[1:2]))
    vec <- is.na(obj.dim)[, 1] & (obj.type != "function")
    obj.dim[vec, 1] <- napply(names, length)[vec]
    out <- data.frame(obj.type, obj.size, obj.dim)
    names(out) <- c("Type", "Size", "Rows", "Columns")
    if (!missing(order.by))
        out <- out[order(out[[order.by]]), ]
    out
}

Lengthy R closing can be due to such big objects e.g. generated by strucchange functions.

However it may have another resons. Without more information from your side it would be difficult to bring definite answer.

Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of SHIVI
> BHATIA
> Sent: Wednesday, February 17, 2016 10:16 AM
> To: r-help at r-project.org
> Subject: [R] R Memory Issue
>
> Dear Team,
>
>
>
> Every now and then I face some weird issues with R. For instance it
> would not read my csv file or any other read.table command and once I
> would close the session and reopen again it works fine.
>
>
>
> It have tried using rm(list=ls()) & gc() to free some memory and
> restart R <Cntrl+Shft+F10>
>
>
>
> Also today while closing the R session it took more than 10 minutes. I
> am not sure as to what is leading to this. Kindly throw some light on
> this. Not
> sure if I have provided enough information.
>
>
>
> Thanks, Shivi
>
> Mb: 9891002021
>
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From lists at dewey.myzen.co.uk  Wed Feb 17 14:19:20 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 17 Feb 2016 13:19:20 +0000
Subject: [R] missing values in csv file
In-Reply-To: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
References: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
Message-ID: <56C47358.50406@dewey.myzen.co.uk>

Assuming it is a character variable

test <- c("a", NA, "b")
 > test
[1] "a" NA  "b"
 > test[is.na(test)] <- " "
 > test
[1] "a" " " "b"

but if it is numeric this as, as others have said, almost certainly not 
what you really wanted to do

On 17/02/2016 10:04, Jan Kacaba wrote:
> In my original data a csv file I have missing values. If I use read.table
> the missing values are replaced by NAs.
>
> Is it possible to get object where missing values aren't replaced with NAs?
> Is it possible to replace NAs with empty space?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From sunnysingha.analytics at gmail.com  Wed Feb 17 14:21:12 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Wed, 17 Feb 2016 18:51:12 +0530
Subject: [R] R Memory Issue
In-Reply-To: <001001d16963$cc7f5230$657df690$@safexpress.com>
References: <001001d16963$cc7f5230$657df690$@safexpress.com>
Message-ID: <F614BBBF-8E86-424D-B0D5-343D45F95102@gmail.com>

Hi,
May be its reading your file and taking time which depends on size of the file that you are reading.
Please explore ?data.table? library to read big files in few seconds.

If you attempt to close the application while execution had been in progress for sometime it would take time most of the times.
Instead, end the r_session process from task manager which is immediate. 

Regards,
Sandeep S. Rana


> On 17-Feb-2016, at 2:46 PM, SHIVI BHATIA <shivi.bhatia at safexpress.com> wrote:
> 
> Dear Team,
> 
> 
> 
> Every now and then I face some weird issues with R. For instance it would
> not read my csv file or any other read.table command and once I would close
> the session and reopen again it works fine. 
> 
> 
> 
> It have tried using rm(list=ls()) & gc() to free some memory and restart R
> <Cntrl+Shft+F10>
> 
> 
> 
> Also today while closing the R session it took more than 10 minutes. I am
> not sure as to what is leading to this. Kindly throw some light on this. Not
> sure if I have provided enough information.      
> 
> 
> 
> Thanks, Shivi
> 
> Mb: 9891002021
> 
> 
> 
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Feb 17 14:24:11 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Feb 2016 13:24:11 +0000
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <1a6ebacffd8f4dbd98781f07169bb97e@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
	<1a6ebacffd8f4dbd98781f07169bb97e@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F99F@SRVEXCHMBX.precheza.cz>

Hi

Seems to me that it is time for you to go through R intro. I do not remember myself using such weird construction.

mom["PC_Q_m3",]$value

You are lucky that you do not have duplicated values in your second column as in this case you would get error

Error in `row.names<-.data.frame`(`*tmp*`, value = value) :
  duplicate 'row.names' are not allowed
In addition: Warning message:
non-unique values when setting 'row.names': ?adi?, ?cg100?, ?cg100mod?

I consider those preferable

mom["PC_Q_m3","value"]
mom[mom[,2]=="PC_Q_m3","value"]

but others may have different opinion.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of MAURICE
> Jean - externe
> Sent: Wednesday, February 17, 2016 10:11 AM
> To: r-help at r-project.org
> Subject: Re: [R] this is not a list, not a data frame, but what ?
>
> I went further !
>
> I could give a name to each row based on column 2 in the read.table
> command and then access to the value by :
>
> mom["PC_Q_m3",]$value
>
> It?s great
> Jean
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations
> qui y figurent sont strictement confidentielles. Toute utilisation de
> ce Message non conforme ? sa destination, toute diffusion ou toute
> publication totale ou partielle, est interdite sauf autorisation
> expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit
> de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout
> ou partie. Si vous avez re?u ce Message par erreur, merci de le
> supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en
> garder aucune trace sur quelque support que ce soit. Nous vous
> remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour
> du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de
> toute erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely
> for the addressees. The information contained in this Message is
> confidential. Any use of information contained in this Message not in
> accord with its purpose, any dissemination or disclosure, either whole
> or partial, is prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or
> use any part of it. If you have received this message in error, please
> delete it and all copies from your system and notify the sender
> immediately by return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Wed Feb 17 14:37:27 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 17 Feb 2016 13:37:27 +0000
Subject: [R] missing values in csv file
In-Reply-To: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
References: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D0F0E91B@GBTEDVPEXCMB04.corp.lgc-group.com>

> Is it possible to get object where missing values aren't replaced with NAs?
Not with read.table, if they are really missing. But you can replace them later - see below - and if they are marked you can change what read.table considers to be 'missing'.

> Is it possible to replace NAs with empty space?
NA _is_ an 'empty space', in the sense of a correctly recorded missing value.

If you mean some other kind of empty space - perhaps the string "" - that's not missing, just empty (!).

But with a vector containing NA's, like
(  x <- c(NA, NA, letters[1:5]) )

you can do things like 

x[is.na(x)] <- "Empty Space"
x

or
x[is.na(x)] <- ""

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From sarah.goslee at gmail.com  Wed Feb 17 15:15:36 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 17 Feb 2016 09:15:36 -0500
Subject: [R] How to read DiCOM images using R?
In-Reply-To: <CAOxUbyVy-msZS6zH8FSr8E6-ndOmF+Ad=nizRu-UQTnBr2b4Dw@mail.gmail.com>
References: <CAOxUbyVy-msZS6zH8FSr8E6-ndOmF+Ad=nizRu-UQTnBr2b4Dw@mail.gmail.com>
Message-ID: <CAM_vju=34OtgnZZnYJpWrGD3p8D5AbS-e0iL_OV8vkrpx8ZsVg@mail.gmail.com>

Searching for DICOM at www.rseek.org turns up a few options for
working with that image format.

But with no idea of what you want to do with them, we can't help with
the analysis. You will need to develop some clear objectives, do some
reading in how you might use R to accomplish those objectives, and
then if you get stuck you could come back here with clear ideas and
reproducible examples.

Best,
Sarah

On Tue, Feb 16, 2016 at 11:33 PM, vidu pranam <vidupranam at gmail.com> wrote:
> Hai,
>
>   I have some DICOM format images for my project. Can you please help me
> how can I read it by using R and how to analyse the images?
>
> Regards
> Vidu
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From pd.mes at cbs.dk  Wed Feb 17 15:31:23 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Wed, 17 Feb 2016 14:31:23 +0000
Subject: [R] R 3.2.4 and 3.3.0
Message-ID: <29C9952A-F6B3-4153-95B4-F31AA48EC5E0@cbs.dk>

R 3.2.4 "Very Secure Dishes", the wrap-up release of R-3.2.x is now scheduled for March 10 
R 3.3.0 "Supposedly Educational", is scheduled for April 14.

Detailed schedules are published on developer.r-project.org.

For the Core Team 

Peter D.
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From careyshan at gmail.com  Wed Feb 17 17:01:53 2016
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 17 Feb 2016 16:01:53 +0000
Subject: [R] data merging
Message-ID: <CA+jRDxDeWer8ARvMtUkDS2WTuD7x_tyHMx3ddbTm4e5oo0RYzA@mail.gmail.com>

Hi,

Im trying to append rows to a data frame using smartbind

I have 3 dataframes:

> dim(DATA_WH)[1] 235  24> dim(DATA_GW)[1] 3037   41> dim(DATA_NFGWS)[1] 2485   62

B<-smartbind(DATA_NFGWS,DATA_WH)


However I get the following error:

 Error in `[.data.frame`(block, , col) : undefined columns selected


Any advice on this would be greatly appreciated!! Driving me nuts!!
Thanks
-- 
Shane

	[[alternative HTML version deleted]]


From careyshan at gmail.com  Wed Feb 17 17:34:33 2016
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 17 Feb 2016 16:34:33 +0000
Subject: [R] data merging
In-Reply-To: <CA+jRDxDeWer8ARvMtUkDS2WTuD7x_tyHMx3ddbTm4e5oo0RYzA@mail.gmail.com>
References: <CA+jRDxDeWer8ARvMtUkDS2WTuD7x_tyHMx3ddbTm4e5oo0RYzA@mail.gmail.com>
Message-ID: <CA+jRDxB9fXym4rFbi=XUJSNpn5ir9USqL7YU0hRPuBq4rMwNMg@mail.gmail.com>

Hi,

I found the error.

Thanks in advance

On Wed, Feb 17, 2016 at 4:01 PM, Shane Carey <careyshan at gmail.com> wrote:

> Hi,
>
> Im trying to append rows to a data frame using smartbind
>
> I have 3 dataframes:
>
> > dim(DATA_WH)[1] 235  24> dim(DATA_GW)[1] 3037   41> dim(DATA_NFGWS)[1] 2485   62
>
> B<-smartbind(DATA_NFGWS,DATA_WH)
>
>
> However I get the following error:
>
>  Error in `[.data.frame`(block, , col) : undefined columns selected
>
>
> Any advice on this would be greatly appreciated!! Driving me nuts!!
> Thanks
> --
> Shane
>



-- 
Shane

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Feb 17 17:49:47 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 17 Feb 2016 08:49:47 -0800
Subject: [R] missing values in csv file
In-Reply-To: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
References: <CAHby=D27bcO6eHJ8hPkCswMoGGJj8zM7mBQdFuedgibGxYq-2A@mail.gmail.com>
Message-ID: <CAF8bMcZ3HdA=Tbzk7GErOWuDKTS95t0QijJ5TZSfcDPOLBO-SA@mail.gmail.com>

You can add the argument na.print=" " to print() to make
the missing values print as " " instead of as NA.  Some,
but not all print methods support this.  E.g.,
 > print(c(1,2,NA,4,5,NA), na.print="-")
 [1] 1 2 - 4 5 -
 > print(matrix(c(1,2,NA,4,5,NA),2), na.print="-")
      [,1] [,2] [,3]
 [1,]    1    -    5
 [2,]    2    4    -
 > # print.data.frame use na.print for factor/character data only
 > print(data.frame(X=c(1,NA,3), Y=LETTERS[c(NA,2,3)]), na.print="-")
> print(data.frame(X=c(1,NA,3), Y=LETTERS[c(NA,2,3)], Z=c(NA,TRUE,FALSE)),
na.print="-")
    X Y     Z
 1  1 -    NA
 2 NA B  TRUE
 3  3 C FALSE

In write.table (& write.csv) the argument na=" " does the trick.
 > write.csv(data.frame(X=c(1,NA,3), Y=LETTERS[c(NA,2,3)],
Z=c(NA,TRUE,FALSE)), na="-")
 "","X","Y","Z"
 "1",1,-,-
 "2",-,"B",TRUE
 "3",3,"C",FALSE


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 17, 2016 at 2:04 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:

> In my original data a csv file I have missing values. If I use read.table
> the missing values are replaced by NAs.
>
> Is it possible to get object where missing values aren't replaced with NAs?
> Is it possible to replace NAs with empty space?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 17 18:48:37 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Feb 2016 09:48:37 -0800
Subject: [R] this is not a list, not a data frame, but what ?
In-Reply-To: <1a6ebacffd8f4dbd98781f07169bb97e@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <837561f68d634883b551d6d50b06b48b@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<CAKVAULMnD4a7JWet6z=PchVhVemuGpU4YhFjyZZk=ajJ20VGmQ@mail.gmail.com>
	<1a6ebacffd8f4dbd98781f07169bb97e@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <CAGxFJbSLjTWEjdha-6xVfDsBHWZ_WPFc6SnhSy1FUbzfmKjEBQ@mail.gmail.com>

Better:

mom["PC_Q_m3","value"]

Read about indexing in R .

Bert




On Tuesday, February 16, 2016, MAURICE Jean - externe <
jean-externe.maurice at edf.fr> wrote:

> I went further !
>
> I could give a name to each row based on column 2 in the read.table
> command and then access to the value by :
>
> mom["PC_Q_m3",]$value
>
> It?s great
> Jean
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations qui y
> figurent sont strictement confidentielles. Toute utilisation de ce Message
> non conforme ? sa destination, toute diffusion ou toute publication totale
> ou partielle, est interdite sauf autorisation expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de
> le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou
> partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de
> votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace
> sur quelque support que ce soit. Nous vous remercions ?galement d'en
> avertir imm?diatement l'exp?diteur par retour du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute
> erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely for
> the addressees. The information contained in this Message is confidential.
> Any use of information contained in this Message not in accord with its
> purpose, any dissemination or disclosure, either whole or partial, is
> prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or use
> any part of it. If you have received this message in error, please delete
> it and all copies from your system and notify the sender immediately by
> return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From yoyohashao at qq.com  Wed Feb 17 16:06:19 2016
From: yoyohashao at qq.com (=?gb18030?B?L3R5t8XX0MreL3ls?=)
Date: Wed, 17 Feb 2016 23:06:19 +0800
Subject: [R] Error in cut.default(a, breaks = 100) : 'breaks' are not unique
Message-ID: <tencent_00C23143782282E64E7AD418@qq.com>

Dear R users,
as my first post for this mailing list, I'd like to ask questions about 'break' in cut.default.


I am using pheatmap in RStudio. Pheatmap is a function to draw clustered heatmap in R. 


According to the manual, breaks is 'a sequence of numbers that covers the range of values in data matrix and is one element longer than color vector. Used for mapping values to colors. Useful, if needed to map certain values to certain colors, to certain values. If value is NA then the breaks are calculated automatically.' 


I left it NA but received an error message. I then assigned a seq to it by typing breaks=c(0,1,2,3,4,5,6,7,8,9), which didn't work as well (my col.pal has 9 elements so I made a breaks with 10 elements).


One thing I felt confused was that it said breaks should cover the range of values in data matrix. My data has 20 obs. of 23 variables. Which number would cover it? And how should I understand 'cover' in this context.


Sorry to bother you guys. I am quite a rookie to R.


Kind. Sebastian
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Feb 17 21:16:43 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 17 Feb 2016 15:16:43 -0500
Subject: [R] Error in cut.default(a,
	breaks = 100) : 'breaks' are not unique
In-Reply-To: <tencent_00C23143782282E64E7AD418@qq.com>
References: <tencent_00C23143782282E64E7AD418@qq.com>
Message-ID: <CAM_vjum_-M1QBM+PjDJenSTRtqHMsxaNSe0VBmtzhGhKBK7j4g@mail.gmail.com>

It should cover the range of values - from below the minimum to above
the maximum of your data.
One break would do it, or 10, or whatever. It doesn't matter how many
breaks you have, it matters that they have a sufficient range.
So you might make breaks like
seq(floor(min(x)), ceiling(max(x)), length.out = 10)
if you want equal lengths.

Sarah



On Wed, Feb 17, 2016 at 10:06 AM, /ty???/yl <yoyohashao at qq.com> wrote:
> Dear R users,
> as my first post for this mailing list, I'd like to ask questions about 'break' in cut.default.
>
>
> I am using pheatmap in RStudio. Pheatmap is a function to draw clustered heatmap in R.
>
>
> According to the manual, breaks is 'a sequence of numbers that covers the range of values in data matrix and is one element longer than color vector. Used for mapping values to colors. Useful, if needed to map certain values to certain colors, to certain values. If value is NA then the breaks are calculated automatically.'
>
>
> I left it NA but received an error message. I then assigned a seq to it by typing breaks=c(0,1,2,3,4,5,6,7,8,9), which didn't work as well (my col.pal has 9 elements so I made a breaks with 10 elements).
>
>
> One thing I felt confused was that it said breaks should cover the range of values in data matrix. My data has 20 obs. of 23 variables. Which number would cover it? And how should I understand 'cover' in this context.
>
>
> Sorry to bother you guys. I am quite a rookie to R.
>


From jdnewmil at dcn.davis.ca.us  Wed Feb 17 21:33:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Feb 2016 12:33:09 -0800
Subject: [R] Error in cut.default(a,
	breaks = 100) : 'breaks' are not unique
In-Reply-To: <tencent_00C23143782282E64E7AD418@qq.com>
References: <tencent_00C23143782282E64E7AD418@qq.com>
Message-ID: <DAA0EDFA-E62C-4FAF-944E-6212DB158EB4@dcn.davis.ca.us>

Range of values is a standard mathematical concept, unrelated to the number of values in your data set.  Consider using the summary function to learn about the range of your data. 

Also, read the Posting Guide (which warns you to use pain text in formulating your emails to the list to avoid corruption of your email). Always try to supply self-contained examples of code that conveys what you understand so far. Read http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for advice on communicating examples clearly. 
-- 
Sent from my phone. Please excuse my brevity.

On February 17, 2016 7:06:19 AM PST, "/ty???/yl" <yoyohashao at qq.com> wrote:
>Dear R users,
>as my first post for this mailing list, I'd like to ask questions about
>'break' in cut.default.
>
>
>I am using pheatmap in RStudio. Pheatmap is a function to draw
>clustered heatmap in R. 
>
>
>According to the manual, breaks is 'a sequence of numbers that covers
>the range of values in data matrix and is one element longer than color
>vector. Used for mapping values to colors. Useful, if needed to map
>certain values to certain colors, to certain values. If value is NA
>then the breaks are calculated automatically.' 
>
>
>I left it NA but received an error message. I then assigned a seq to it
>by typing breaks=c(0,1,2,3,4,5,6,7,8,9), which didn't work as well (my
>col.pal has 9 elements so I made a breaks with 10 elements).
>
>
>One thing I felt confused was that it said breaks should cover the
>range of values in data matrix. My data has 20 obs. of 23 variables.
>Which number would cover it? And how should I understand 'cover' in
>this context.
>
>
>Sorry to bother you guys. I am quite a rookie to R.
>
>
>Kind. Sebastian
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From alex.deckmyn at meteo.be  Sun Feb 14 10:35:24 2016
From: alex.deckmyn at meteo.be (Alex Deckmyn)
Date: Sun, 14 Feb 2016 10:35:24 +0100
Subject: [R] [R-pkgs] announcing maps version 3.1.0
Message-ID: <1556909406.16276237.1455442524227.JavaMail.zimbra@meteo.be>

Hi, 

I am pleased to announce version 3.1.0 of the 'maps' package which has a few important changes and additions. 

CHANGES: 
- The 'world' map has been adapted: it now doesn't contain any lakes anymore. Most visible effect is the Great Lakes on the Canada/USA border. 
- Major lakes are now available in a separate database 'lakes', so they can still be added to a plot if desired. 
- As a result, plotting without interior borders now gives much cleaner results. 
- The 'world2' database has been cleaned up a bit to look better at the boundaries. 

ADDITIONS: 
- map() now accepts spatial objects of types SpatialPolygon[DataFrame] and SpatialLines[DataFrame] as database. The support is limited to the actual polygon co-ordinates and names. Any other information (plotting order, projection etc) is lost. So one can now for instance read shapefile data (e.g. readShapePoly() from the maptools package) and pass the result to map(). 

FIXES: 
- map(...,fill=TRUE) will no longer apply thinning to the map. The thinning caused polygons to have non-matching borders. For large databases (e.g. the complete worldHires database) this may have a noticable effect on speed. 

Alex Deckmyn 


--- 
Dr. Alex Deckmyn e-mail: alex.deckmyn at meteo.be 
Royal Meteorological Institute http://www.meteo.be 
Ringlaan 3, 1180 Ukkel, Belgium tel. (32)(2)3730646 


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jeff at trefftzs.org  Wed Feb 17 22:50:04 2016
From: jeff at trefftzs.org (Jeff Trefftzs)
Date: Wed, 17 Feb 2016 13:50:04 -0800
Subject: [R] How to plot gaps in chartSeries
Message-ID: <1455745804.3692.32.camel@trefftzs.org>

In hopes of isolating parts of a time series where my indicator is
above zero I have filled those rows where the indicator is <= 0  with
NAs.  I was hoping this would leave blank gaps when I plotted using
chartSeries(blanked, theme = 'white'), but chartSeries closes up the
gaps.  ggplot, however, leaves nice gaps in the output.

Is there a way to make chartSeries leave space for each value of the
time index of an xts object whether or not there is data for it?

-- 
Jeff Trefftzs
http://www.trefftzs.org


From cri.alessandro at gmail.com  Thu Feb 18 02:54:19 2016
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Wed, 17 Feb 2016 19:54:19 -0600
Subject: [R] regression coefficients
Message-ID: <56C5244B.8040306@gmail.com>

Dear all,

I am trying to visualize the regression coefficients of the linear model 
that the function aov() implicitly fits. Unfortunately the function 
summary.lm() throws an error I do not understand. Here is a toy example:

dv <- c(1,3,4,2,2,3,2,5,6,3,4,4,3,5,6);
subject <- 
factor(c("s1","s1","s1","s2","s2","s2","s3","s3","s3","s4","s4","s4","s5","s5","s5"));
myfactor_c <- 
factor(c("f1","f2","f3","f1","f2","f3","f1","f2","f3","f1","f2","f3","f1","f2","f3")) 

mydata_c <- data.frame(dv, subject, myfactor)

mod_c <- aov(dv ~ myfactor_c + Error(subject/myfactor_c), data=mydata_c)

 > summary.lm(mod_c)
Error in if (p == 0) { : argument is of length zero

Please note that the example is a within-subject design with factor 
myfactor_c.

Any help is greatly appreciated.

Best
Cristiano

PS. If this is a stupid question, I apologize. I am very new to R.


From drjimlemon at gmail.com  Thu Feb 18 04:07:57 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 18 Feb 2016 14:07:57 +1100
Subject: [R] regression coefficients
In-Reply-To: <56C5244B.8040306@gmail.com>
References: <56C5244B.8040306@gmail.com>
Message-ID: <CA+8X3fWCYdnKsk3JgQSh+6dE7FzyYoCuV-eQc2FCWwrkR8mYsw@mail.gmail.com>

Hi Cristiano,
Might be the data you have for "dv". I don't seem to get the problem.

dv<-sample(1:6,15,TRUE)
subject<-factor(rep(paste("s",1:5,sep=""),each=3))
myfactor_c<-factor(rep(paste("f",1:3,sep=""),5))
mydata_c<-data.frame(dv,subject,myfactor_c)
mod_c<-aov(dv~myfactor_c+Error(subject/myfactor_c),data=mydata_c)
mod_c

Call:
aov(formula = dv ~ myfactor_c + Error(subject/myfactor_c),
...

summary(mod_c)

Error: subject
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals  4   13.6     3.4

Error: subject:myfactor_c
                 Df Sum Sq Mean Sq F value Pr(>F)
myfactor_c  2  8.133   4.067   1.196  0.351
Residuals   8 27.200   3.400

Jim



On Thu, Feb 18, 2016 at 12:54 PM, Cristiano Alessandro <
cri.alessandro at gmail.com> wrote:

> Dear all,
>
> I am trying to visualize the regression coefficients of the linear model
> that the function aov() implicitly fits. Unfortunately the function
> summary.lm() throws an error I do not understand. Here is a toy example:
>
> dv <- c(1,3,4,2,2,3,2,5,6,3,4,4,3,5,6);
> subject <-
> factor(c("s1","s1","s1","s2","s2","s2","s3","s3","s3","s4","s4","s4","s5","s5","s5"));
> myfactor_c <-
> factor(c("f1","f2","f3","f1","f2","f3","f1","f2","f3","f1","f2","f3","f1","f2","f3"))
>
> mydata_c <- data.frame(dv, subject, myfactor)
>
> mod_c <- aov(dv ~ myfactor_c + Error(subject/myfactor_c), data=mydata_c)
>
> > summary.lm(mod_c)
> Error in if (p == 0) { : argument is of length zero
>
> Please note that the example is a within-subject design with factor
> myfactor_c.
>
> Any help is greatly appreciated.
>
> Best
> Cristiano
>
> PS. If this is a stupid question, I apologize. I am very new to R.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 18 06:16:11 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 17 Feb 2016 21:16:11 -0800
Subject: [R] regression coefficients
In-Reply-To: <56C5244B.8040306@gmail.com>
References: <56C5244B.8040306@gmail.com>
Message-ID: <CAF8bMcaAhZZJ=8jR5rTSD-3s=z4LkvDErCsa69O4cmer6m+9vg@mail.gmail.com>

> mod_c <- aov(dv ~ myfactor_c + Error(subject/myfactor_c), data=mydata_c)
>
> summary.lm(mod_c)
> Error in if (p == 0) { : argument is of length zero>

You called the lm method for summary() on an object of class c("aovlist",
"listof").   You should not expect a method for one class to work on an
object of a different class.

coefficients(mod_c) will give you the coefficients of the 3 linear models
(including the intercept-only model) that aov fits.  Since an aovlist
object is a list of c("aov","lm") objects you can get the summaries of its
components with lapply(mod_c, summary).



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 17, 2016 at 5:54 PM, Cristiano Alessandro <
cri.alessandro at gmail.com> wrote:

> Dear all,
>
> I am trying to visualize the regression coefficients of the linear model
> that the function aov() implicitly fits. Unfortunately the function
> summary.lm() throws an error I do not understand. Here is a toy example:
>
> dv <- c(1,3,4,2,2,3,2,5,6,3,4,4,3,5,6);
> subject <-
> factor(c("s1","s1","s1","s2","s2","s2","s3","s3","s3","s4","s4","s4","s5","s5","s5"));
> myfactor_c <-
> factor(c("f1","f2","f3","f1","f2","f3","f1","f2","f3","f1","f2","f3","f1","f2","f3"))
>
> mydata_c <- data.frame(dv, subject, myfactor)
>
> mod_c <- aov(dv ~ myfactor_c + Error(subject/myfactor_c), data=mydata_c)
>
> > summary.lm(mod_c)
> Error in if (p == 0) { : argument is of length zero
>
> Please note that the example is a within-subject design with factor
> myfactor_c.
>
> Any help is greatly appreciated.
>
> Best
> Cristiano
>
> PS. If this is a stupid question, I apologize. I am very new to R.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb 18 08:24:39 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 18 Feb 2016 07:24:39 +0000
Subject: [R] Excluding "small data" from plot.
In-Reply-To: <CAMVnMy1eeYNwHr7JPj9ZwFj8ABOfXpWDtwVXduRuYgSVbd3pzQ@mail.gmail.com>
References: <CAMVnMy2KT12iN0BvZEuCuq6k3oOH2tZzhx1AwNF9uHiQuRheKA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C500F917@SRVEXCHMBX.precheza.cz>
	<CAMVnMy1eeYNwHr7JPj9ZwFj8ABOfXpWDtwVXduRuYgSVbd3pzQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500FB9F@SRVEXCHMBX.precheza.cz>

Hi

Please cc your mails to r help. Users are around the world and you could have response oslo from others.

You need to put NA in a missing good or bad letter. I would probably do merging instead of do.call but there may be other options.

Something like that.

> l1<-sample(letters[1:10], 5)
> l2<-sample(letters[1:10], 5)
> x1<-data.frame(l1, x=rnorm(5))
> x2<-data.frame(l2)
> x1
  l1          x
1  d  0.7948186
2  b  1.3076922
3  j  1.8305538
4  i -0.1934532
5  e -1.5182885
> x2
  l2
1  f
2  j
3  h
4  a
5  i
> merge(x1, x2, by.x="l1",by.y="l2", all=TRUE)
  l1          x
1  b  1.3076922
2  d  0.7948186
3  e -1.5182885
4  i -0.1934532
5  j  1.8305538
6  a         NA
7  f         NA
8  h         NA

Or you can use some clever combination of intersect and setdiff

?intersect

to find which letters are missing in each group.

Cheers
Petr


> -----Original Message-----
> From: Kieran [mailto:kroberts012 at gmail.com]
> Sent: Wednesday, February 17, 2016 7:37 PM
> To: PIKAL Petr
> Subject: Re: [R] Excluding "small data" from plot.
>
> Hi Petr,
>
> Thanks for you reply. This almost does what I need but there is one
> problem.
>
> Before running
>
> lll <- do.call(rbind, lll),
>
> lll is a list with two data sets: the top 8 most frequently used
> letters of bad type [e,n,a,t,o,i,h,r] and the top 8 mostly frequently
> used letters of good type [e,t,i,a,s,o,r,h]. These two groups of
> letters are almost the same (as one would expect). They differ in two
> places: n (is bad) and s (is good).
>
> After running the do.call function with rbind I get a union of these
> rows. But then when I run
>
> ggplot(lll,aes(x=Group.1,y=x, fill=Group.2), color=Group.2) +
>     stat_summary(fun.y=sum,position=position_dodge(),geom="bar")
>
> For n on the x-axis I get two bars of the same colour red (=bad) For s
> on the x-axis I get two bars of the same colour blue (=good)
>
> But I really want is the 'good' value for n next to the bad value for
> 'n'.  And the same for 's'. This task seems more complicated.
>
> Best,
> Kieran.
>
> On 17 February 2016 at 13:49, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi
> >
> > There is probably better solution but I would aggregate
> >
> > lll <- aggregate(ltrfreq$letterfreq, list(ltrfreq$letter,
> > ltrfreq$type), sum)
> >
> > order
> >
> > ooo<-order(lll$x, decreasing=T)
> >
> > split and sapply
> > lll<- lll[ooo,]
> > lll <- lapply(split(lll, lll$Group.2), head, 8)
> >
> > and do.call rbind to get 8 letters for good and bad plotting.
> >
> > lll<-do.call(rbind, lll)
> > library(ggplot2)
> > ggplot(lll,aes(x=Group.1,y=x, fill=Group.2), color=Group.2) +
> > +  stat_summary(fun.y=sum,position=position_dodge(),geom="bar")
> >
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Kieran
> >> Sent: Wednesday, February 17, 2016 10:20 AM
> >> To: R-help at r-project.org
> >> Subject: [R] Excluding "small data" from plot.
> >>
> >> To R-help users:
> >>
> >> I want to use ggplot two plot summary statistics on the frequency of
> >> letters from a page of text. My data frame has four columns:
> >>
> >> (1) The line number [1 to 30]
> >> (2) The letter [a to z]
> >> (3) The frequency of the letter [assuming there is 80 letters per
> >> line]
> >> (4) The factor 'type': bad or good (purely artificial factor)
> >>
> >> I want to achieve the following plot:
> >>
> >> (a) Bar plot with an x-axis to be the letters and the y-axis the sum
> >> of 30 letter frequencies from each line of each letter.
> >> (b) Split each bar (for a letter) into two bars for 'good' and 'bad'
> >> types.
> >> (c) Display the union of the top 8 most frequency used letters for
> >> both types 'good' and 'bad'.
> >>
> >> By point (c) I mean: if a,e,f,h,i,t,s,r are the most frequent letter
> >> of type 'good' and a,e,f,h,i,m,l,p are the most frequent letter of
> >> type 'bad'.
> >> Then
> >> I would like my plot to feature the letters a,e,f,h,i,t,s,r,m,l,p.
> >>
> >> Here is my code:
> >>
> >> # There will be 30 lines and we want to record the frequency of each
> >> letter # on each line.
> >>
> >> lines <- c(rep(1:30, each=26))
> >> letter <- c(rep(letters, times=30))
> >>
> >> # We have taken the letter frequencies from #
> >> http://www.math.cornell.edu/~mec/2003-
> >> 2004/cryptography/subs/frequencies.html
> >>
> >> freq <- c(8.12, 1.49, 2.71, 4.32, 12.02, 2.30, 2.03, 5.92, 7.31,
> >> 0.10, 0.69, 3.98, 2.61, 6.95, 7.68, 1.82, 0.11, 6.02, 6.28, 9.10,
> >> 2.88, 1.11, 2.09, 0.17, 2.11, 0.07) freq <- freq/100
> >>
> >>
> >> # We assume each line contains 80 letters and change the seed for
> >> each line # for variability.
> >>
> >> letterfreq <- integer()
> >> for (i in 1:30) {
> >>     set.seed(i)
> >>     s<-data.frame(sample(letters, size = 80, replace = TRUE, prob =
> >> freq))
> >>     names(s) <- "ltr"
> >>     s$ltr <- factor(s$ltr, levels = letters)
> >>     frq<-as.data.frame(table(s))
> >>     letterfreq <- append(letterfreq, frq$Freq) }
> >>
> >> ltrfreq <- data.frame(lines, letter, letterfreq)
> >>
> >> # Add an artificial factor column _type_: good/bad. So each pair #
> >> (week, letter) has type 'good' or 'bad' with equal probability.
> >> # Set the seed for reproducibility.
> >>
> >> set.seed(999)
> >> ltrfreq$type <-  factor(sample(c("good","bad"), size = 780, replace
> =
> >> TRUE,
> >>     prob = c(0.5,0.5)))
> >>
> >>
> >> # Here is the plot I want but this includes all 26 letters.
> >>
> >> ggplot(ltrfreq,aes(x=factor(letter),y=letterfreq, fill=type),
> >> color=type) +
> >>   stat_summary(fun.y=sum,position=position_dodge(),geom="bar")
> >>
> >> Best regards,
> >> Kieran.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dalila.zolarsi at gmail.com  Wed Feb 17 22:19:07 2016
From: dalila.zolarsi at gmail.com (Dalila Zolarsi)
Date: Wed, 17 Feb 2016 22:19:07 +0100
Subject: [R] Problem in adapting a script I have not written.
Message-ID: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>

Dear R users,
I'm new of R, thus I apologize in advance if my following question may
result a little dumb, but I really need some expert advice.
I have a problem in applying someone else's code to my data. The author's
code works perfectly with the examples he provides, and it seems to me I am
doing all the correct steps in my case, but apparently I am not.

The main function is:
grid_boot <- function(dat,name,t,ar,grid,bq,c,all,grph)
and I should simply specify the parameter and then running the code given
in the script, or at least for the author's example this works.
All the specification in the examples are close to my case, except for the
ar parameter.
The ar parameter is the autoregressive order of a time series, so it is
simply a number from 1 to n that you choose. My series requires a simple ar
= 1, but if I run the code with this specification, R give me back the
following error:

" Error in solve.default(t(x) %*% x) :
  system is computationally singular: reciprocal condition number =
6.07898e-34 In addition: Warning messages:
1: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
  longer object length is not a multiple of shorter object length
2: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
  longer object length is not a multiple of shorter object length"

In the example, the author specifies as follow:
orig <- 2    # set to 1 for original data, set to 2 for extended data #
t <- 2
grid <- 200
bq <- 9999
c <- .9
i <- 7
d <- np[i,]
if (orig==1){
    y <- as.matrix(dat[d[1]:(d[2]-18)])
    if (i==4) y <- y[21:82]
}else{
    y <- as.matrix(dat[d[1]:d[2]])
}
name <- "GNP per Capita: 1869-1988"
ar <- d[3]

What I can't figure out is the indication ar <- d[3] and in general what
precisely he means with specifying i and d. I think this specification is
due to the fact that his dataset is made of several variables all written
in the same column and they are associated with an index.
When I give these inputs to R (I use RStudio), in the environment pane
 appears as ar = 1. When I give the numerical input (ar <- 1) for my
exercise instead, the only result is the error above mentioned.

Below, I report my data (as you can see, it is only a single series with
few observation, so it should be an easy one) and my inputs, while I attach
the script in a text file because it is quite a long one. I also attach the
example and the data used in it.
I hope someone can help me figuring out what am I doing wrong and I will be
very grateful to anyone who is willing to help a newbie like me.

library(pracma)
source(file.choose())
dat <- as.matrix(read.csv(file.choose(), header = TRUE))
print(dat)

USA
 [1,]  0.01075000
 [2,]  0.01116000
 [3,]  0.01214000
 [4,]  0.01309000
 [5,]  0.01668000
 [6,]  0.02991000
 [7,]  0.02776000
 [8,]  0.04218000
 [9,]  0.05415000
[10,]  0.05895000
[11,]  0.04256000
[12,]  0.03306000
[13,]  0.00622000
[14,]  0.11035000
[15,]  0.09132000
[16,]  0.05737000
[17,]  0.06486000
[18,]  0.07647000
[19,]  0.11266000
[20,]  0.13509000
[21,]  0.10316000
[22,]  0.06161000
[23,]  0.03212000
[24,]  0.04317000
[25,]  0.03561000
[26,]  0.01859000
[27,]  0.03741000
[28,]  0.04009000
[29,]  0.04827000
[30,]  0.05398000
[31,]  0.04235000
[32,]  0.03029000
[33,]  0.02952000
[34,]  0.02607000
[35,]  0.02805000
[36,]  0.02931000
[37,]  0.02338000
[38,]  0.01552000
[39,]  0.02188000
[40,]  0.03377000
[41,]  0.02826000
[42,]  0.01586000
[43,]  0.00002270
[44,]  0.02677000
[45,]  0.03393000
[46,]  0.03226000
[47,]  0.02853000
[48,]  0.03839000
[49,] -0.00000356
[50,]  0.00001640
[51,]  0.03157000
[52,]  0.02069000
[53,]  0.01465000
[54,]  0.01622000
[55,]  0.01622000

dat <- dat
name <- "Inflation"
t <- 1
ar <- 1
grid <- 200
bq <- 1999
c <- .9
all <- 0
grph <- 1

out <- grid_boot(dat, name, t, ar, grid, bq, c, all, grph)

	[[alternative HTML version deleted]]


From amoy_y at yahoo.com  Thu Feb 18 17:17:47 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Thu, 18 Feb 2016 16:17:47 +0000 (UTC)
Subject: [R] MACRO-LOOP in R
References: <476550192.5049006.1455812267513.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <476550192.5049006.1455812267513.JavaMail.yahoo@mail.yahoo.com>

 I am doing the data transpose with rename as shown below (step1 ~ step4)
1. Is any way?in R similar to PROC?TRANSPOSE used in SAS?2. How to use MACRO-LOOP to simplify the following procedure?
THANK YOU?FOR?HELPS!
# create data for test
x<-data.frame(
?a=c(1,2,3),
?b=c("1","2","3")); 
x; str(x)# step1: parse out to 3 tabs
x1<-x[x$a == 1,]; x1
x2<-x[x$a == 2,]; x2
x3<-x[x$a == 3,]; x3# step2: remove column a in each tab
x1$a<-NULL; x1
x2$a<-NULL; x2
x3$a<-NULL; x3# step3: rename column b to b1, b2 and b3 by y1, y2 and y3
names(x1)[names(x1)=="b"]<-"b_1"; x1
names(x2)[names(x2)=="b"]<-"b_2"; x2
names(x3)[names(x3)=="b"]<-"b_3"; x3# setp4: set x1, x3 and x3 together
x123=cbind(x1,x2,x3); x123
	[[alternative HTML version deleted]]


From fd at itsfd.de  Thu Feb 18 14:19:46 2016
From: fd at itsfd.de (Frank Duschek)
Date: Thu, 18 Feb 2016 14:19:46 +0100
Subject: [R] Problem in adapting a script I have not written.
In-Reply-To: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
References: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
Message-ID: <CAGxZ7PbRLp0t8NEM1Ou7YvumL+kGREv0TyPW-_VGOt65tCFqRQ@mail.gmail.com>

Hi Dalila,
is your function a part of a packacke or is it self-written? If you
have the code it would be helpful to provide it.

Frank


From dalila.zolarsi at gmail.com  Thu Feb 18 17:35:45 2016
From: dalila.zolarsi at gmail.com (Dalila Zolarsi)
Date: Thu, 18 Feb 2016 17:35:45 +0100
Subject: [R] Problem in adapting a script I have not written.
In-Reply-To: <CAGxZ7PbRLp0t8NEM1Ou7YvumL+kGREv0TyPW-_VGOt65tCFqRQ@mail.gmail.com>
References: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
	<CAGxZ7PbRLp0t8NEM1Ou7YvumL+kGREv0TyPW-_VGOt65tCFqRQ@mail.gmail.com>
Message-ID: <CAHKSjNGuPTe0ST_M-3q75ghY3sh-d8D6yurKm6WaLk3gqPDHKw@mail.gmail.com>

I forgot to attach the website in which there's all what is needed for this
procedure, sorry!
The text file I attach is the main standard procedure, while in the website
there is all the resources for the example.
If you can help me, I'd be so grateful!

I think it's all self written, by the way because it's the procedure in the
author's paper

http://www.ssc.wisc.edu/~bhansen/progs/restat_99.html

2016-02-18 14:19 GMT+01:00 Frank Duschek <fd at itsfd.de>:

> Hi Dalila,
> is your function a part of a packacke or is it self-written? If you
> have the code it would be helpful to provide it.
>
> Frank
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From jdnewmil at dcn.davis.ca.us  Thu Feb 18 17:57:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Feb 2016 08:57:20 -0800
Subject: [R] Problem in adapting a script I have not written.
In-Reply-To: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
References: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
Message-ID: <F7F0BD5E-9C9B-431A-BBD2-FC5BAD82FF91@dcn.davis.ca.us>

d[ 3 ] means indexing some vector-like object called "d" to extract the third value. (You really need to read the Introduction to R document that comes with R, particularly about indexing. There are actually four ways to do indexing that may come up as you read other people's code.) "d" is the contents of the seventh row of some matrix-like object called "np" which you have given no definition for. Without that information "ar" could be almost anything.   If you are right and their example works then you have not given us the whole example. You mention attaching code... the mailing list strips off most attachments to avoid spreading viruses, but if they have the extension ".txt" they usually get through okay.

If the ar parameter really is what you say it is supposed to be, giving it the value 1 should be perfectly acceptable. However,  you may not have specified the arguments to that function in the correct order, or the problem may be in other arguments.

Do be warned that this list is here to help you through rough spots... not to do your work for you. The Posting Guide mentioned at the bottom of every R-help email asks you to post minimal examples rather than long complicated code files, so you are at best near the edge of acceptable use in this request, so at least be sure we can reproduce your error. (Posting your email in plain text rather than HTML is another important step in communicating clearly by avoiding corruption of your code in the mailing list.)
-- 
Sent from my phone. Please excuse my brevity.

On February 17, 2016 1:19:07 PM PST, Dalila Zolarsi <dalila.zolarsi at gmail.com> wrote:
>Dear R users,
>I'm new of R, thus I apologize in advance if my following question may
>result a little dumb, but I really need some expert advice.
>I have a problem in applying someone else's code to my data. The
>author's
>code works perfectly with the examples he provides, and it seems to me
>I am
>doing all the correct steps in my case, but apparently I am not.
>
>The main function is:
>grid_boot <- function(dat,name,t,ar,grid,bq,c,all,grph)
>and I should simply specify the parameter and then running the code
>given
>in the script, or at least for the author's example this works.
>All the specification in the examples are close to my case, except for
>the
>ar parameter.
>The ar parameter is the autoregressive order of a time series, so it is
>simply a number from 1 to n that you choose. My series requires a
>simple ar
>= 1, but if I run the code with this specification, R give me back the
>following error:
>
>" Error in solve.default(t(x) %*% x) :
>  system is computationally singular: reciprocal condition number =
>6.07898e-34 In addition: Warning messages:
>1: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
>  longer object length is not a multiple of shorter object length
>2: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
>  longer object length is not a multiple of shorter object length"
>
>In the example, the author specifies as follow:
>orig <- 2    # set to 1 for original data, set to 2 for extended data #
>t <- 2
>grid <- 200
>bq <- 9999
>c <- .9
>i <- 7
>d <- np[i,]
>if (orig==1){
>    y <- as.matrix(dat[d[1]:(d[2]-18)])
>    if (i==4) y <- y[21:82]
>}else{
>    y <- as.matrix(dat[d[1]:d[2]])
>}
>name <- "GNP per Capita: 1869-1988"
>ar <- d[3]
>
>What I can't figure out is the indication ar <- d[3] and in general
>what
>precisely he means with specifying i and d. I think this specification
>is
>due to the fact that his dataset is made of several variables all
>written
>in the same column and they are associated with an index.
>When I give these inputs to R (I use RStudio), in the environment pane
> appears as ar = 1. When I give the numerical input (ar <- 1) for my
>exercise instead, the only result is the error above mentioned.
>
>Below, I report my data (as you can see, it is only a single series
>with
>few observation, so it should be an easy one) and my inputs, while I
>attach
>the script in a text file because it is quite a long one. I also attach
>the
>example and the data used in it.
>I hope someone can help me figuring out what am I doing wrong and I
>will be
>very grateful to anyone who is willing to help a newbie like me.
>
>library(pracma)
>source(file.choose())
>dat <- as.matrix(read.csv(file.choose(), header = TRUE))
>print(dat)
>
>USA
> [1,]  0.01075000
> [2,]  0.01116000
> [3,]  0.01214000
> [4,]  0.01309000
> [5,]  0.01668000
> [6,]  0.02991000
> [7,]  0.02776000
> [8,]  0.04218000
> [9,]  0.05415000
>[10,]  0.05895000
>[11,]  0.04256000
>[12,]  0.03306000
>[13,]  0.00622000
>[14,]  0.11035000
>[15,]  0.09132000
>[16,]  0.05737000
>[17,]  0.06486000
>[18,]  0.07647000
>[19,]  0.11266000
>[20,]  0.13509000
>[21,]  0.10316000
>[22,]  0.06161000
>[23,]  0.03212000
>[24,]  0.04317000
>[25,]  0.03561000
>[26,]  0.01859000
>[27,]  0.03741000
>[28,]  0.04009000
>[29,]  0.04827000
>[30,]  0.05398000
>[31,]  0.04235000
>[32,]  0.03029000
>[33,]  0.02952000
>[34,]  0.02607000
>[35,]  0.02805000
>[36,]  0.02931000
>[37,]  0.02338000
>[38,]  0.01552000
>[39,]  0.02188000
>[40,]  0.03377000
>[41,]  0.02826000
>[42,]  0.01586000
>[43,]  0.00002270
>[44,]  0.02677000
>[45,]  0.03393000
>[46,]  0.03226000
>[47,]  0.02853000
>[48,]  0.03839000
>[49,] -0.00000356
>[50,]  0.00001640
>[51,]  0.03157000
>[52,]  0.02069000
>[53,]  0.01465000
>[54,]  0.01622000
>[55,]  0.01622000
>
>dat <- dat
>name <- "Inflation"
>t <- 1
>ar <- 1
>grid <- 200
>bq <- 1999
>c <- .9
>all <- 0
>grph <- 1
>
>out <- grid_boot(dat, name, t, ar, grid, bq, c, all, grph)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dalila.zolarsi at gmail.com  Thu Feb 18 18:12:25 2016
From: dalila.zolarsi at gmail.com (Dalila Zolarsi)
Date: Thu, 18 Feb 2016 18:12:25 +0100
Subject: [R] Problem in adapting a script I have not written.
In-Reply-To: <F7F0BD5E-9C9B-431A-BBD2-FC5BAD82FF91@dcn.davis.ca.us>
References: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
	<F7F0BD5E-9C9B-431A-BBD2-FC5BAD82FF91@dcn.davis.ca.us>
Message-ID: <CAHKSjNGtbGFgSQkQOkAzCnCkyHXck9mAVwn2ZY44BMmjZPjmbA@mail.gmail.com>

I'm really sorry, I forgot the attachment! I attach the main code as txt
file, instead here
<http://www.ssc.wisc.edu/~bhansen/progs/restat_99.html> there
everything else I mentioned.
I apologize if I have not been able to summarize, but I am not so
proficient.

Yes, the ar parameter is exactly what I said it is; it is an index that
shouldn't be found in the data, but you decide it. Even the author
specifies it is "the order of the autoregressive parameter", thus I really
don't have a clue of why he used indexetion. Np is his dataset, you can
find it in the link below, if you want to help me.

Yes, I read about indexing but I'm asking for help just because I am sure
of what "ar" is. I am not proficient with R, but at least I have knowledge
Time series econometrics' theory.

No, I am not asking to do my homework for me howeverer. I spent the last
two whole weeks on this code trying different inputs and trying to put all
my effort in understanding every single detail of this code, otherwise I
would never asked for help to unknown people. And it is my master thesis,
thus is not really nice to use the word "homework" if you don't know my
personal situation. However, I understand you probably receive thousands of
silly problems, thus don't get me wrong for what I've just said.

All the data and the code are here
<http://www.ssc.wisc.edu/~bhansen/progs/restat_99.html>, the main procedure
is attached.
(When I sent the first mail, I sent it another right after with the
attachment, but the moderators discarded it, thus I apologize again for the
uncomplete post"



2016-02-18 17:57 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> d[ 3 ] means indexing some vector-like object called "d" to extract the
> third value. (You really need to read the Introduction to R document that
> comes with R, particularly about indexing. There are actually four ways to
> do indexing that may come up as you read other people's code.) "d" is the
> contents of the seventh row of some matrix-like object called "np" which
> you have given no definition for. Without that information "ar" could be
> almost anything. If you are right and their example works then you have not
> given us the whole example. You mention attaching code... the mailing list
> strips off most attachments to avoid spreading viruses, but if they have
> the extension ".txt" they usually get through okay.
>
> If the ar parameter really is what you say it is supposed to be, giving it
> the value 1 should be perfectly acceptable. However, you may not have
> specified the arguments to that function in the correct order, or the
> problem may be in other arguments.
>
> Do be warned that this list is here to help you through rough spots... not
> to do your work for you. The Posting Guide mentioned at the bottom of every
> R-help email asks you to post minimal examples rather than long complicated
> code files, so you are at best near the edge of acceptable use in this
> request, so at least be sure we can reproduce your error. (Posting your
> email in plain text rather than HTML is another important step in
> communicating clearly by avoiding corruption of your code in the mailing
> list.)
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 17, 2016 1:19:07 PM PST, Dalila Zolarsi <
> dalila.zolarsi at gmail.com> wrote:
>
>> Dear R users,
>> I'm new of R, thus I apologize in advance if my following question may
>> result a little dumb, but I really need some expert advice.
>> I have a problem in applying someone else's code to my data. The author's
>> code works perfectly with the examples he provides, and it seems to me I am
>> doing all the correct steps in my case, but apparently I am not.
>>
>> The main function is:
>> grid_boot <- function(dat,name,t,ar,grid,bq,c,all,grph)
>> and I should simply specify the parameter and then running the code given
>> in the script, or at least for the author's example this works.
>> All the specification in the examples are close to my case, except for the
>> ar parameter.
>> The ar parameter is the autoregressive order of a time series, so it is
>> simply a number from 1 to n that you choose. My series requires a simple ar
>> = 1, but if I run the code with this specification, R give me back the
>> following
>> error:
>>
>> " Error in solve.default(t(x) %*% x) :
>>   system is computationally singular: reciprocal condition number =
>> 6.07898e-34 In addition: Warning messages:
>> 1: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
>>   longer object length is not a multiple of shorter object length
>> 2: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
>>   longer object length is not a multiple of shorter object length"
>>
>> In the example, the author specifies as follow:
>> orig <- 2    # set to 1 for original data, set to 2 for extended data #
>> t <- 2
>> grid <- 200
>> bq <- 9999
>> c <- .9
>> i <- 7
>> d <- np[i,]
>> if (orig==1){
>>     y <- as.matrix(dat[d[1]:(d[2]-18)])
>>     if (i==4) y <- y[21:82]
>> }else{
>>     y <- as.matrix(dat[d[1]:d[2]])
>> }
>> name <- "GNP per Capita: 1869-1988"
>> ar <- d[3]
>>
>> What I can't figure out is the indication ar <-
>> d[3] and in general what
>> precisely he means with specifying i and d. I think this specification is
>> due to the fact that his dataset is made of several variables all written
>> in the same column and they are associated with an index.
>> When I give these inputs to R (I use RStudio), in the environment pane
>>  appears as ar = 1. When I give the numerical input (ar <- 1) for my
>> exercise instead, the only result is the error above mentioned.
>>
>> Below, I report my data (as you can see, it is only a single series with
>> few observation, so it should be an easy one) and my inputs, while I attach
>> the script in a text file because it is quite a long one. I also attach the
>> example and the data used in it.
>> I hope someone can help me figuring out what am I doing wrong and I will be
>> very grateful to anyone who is willing to help a newbie like me.
>>
>> library(pracma)
>> source(file.choose())
>> dat <-
>> as.matrix(read.csv(file.choose(), header = TRUE))
>> print(dat)
>>
>> USA
>>  [1,]  0.01075000
>>  [2,]  0.01116000
>>  [3,]  0.01214000
>>  [4,]  0.01309000
>>  [5,]  0.01668000
>>  [6,]  0.02991000
>>  [7,]  0.02776000
>>  [8,]  0.04218000
>>  [9,]  0.05415000
>> [10,]  0.05895000
>> [11,]  0.04256000
>> [12,]  0.03306000
>> [13,]  0.00622000
>> [14,]  0.11035000
>> [15,]  0.09132000
>> [16,]  0.05737000
>> [17,]  0.06486000
>> [18,]  0.07647000
>> [19,]  0.11266000
>> [20,]  0.13509000
>> [21,]  0.10316000
>> [22,]  0.06161000
>> [23,]  0.03212000
>> [24,]  0.04317000
>> [25,]  0.03561000
>> [26,]  0.01859000
>> [27,]  0.03741000
>> [28,]  0.04009000
>> [29,]  0.04827000
>> [30,]  0.05398000
>> [31,]  0.04235000
>> [32,]  0.03029000
>> [33,]  0.02952000
>> [34,]  0.02607000
>> [35,]  0.02805000
>> [36,]  0.02931000
>> [37,]  0.02338000
>> [38,]  0.01552000
>> [39,]  0.02188000
>> [40,]
>> 0.03377000
>> [41,]  0.02826000
>> [42,]  0.01586000
>> [43,]  0.00002270
>> [44,]  0.02677000
>> [45,]  0.03393000
>> [46,]  0.03226000
>> [47,]  0.02853000
>> [48,]  0.03839000
>> [49,] -0.00000356
>> [50,]  0.00001640
>> [51,]  0.03157000
>> [52,]  0.02069000
>> [53,]  0.01465000
>> [54,]  0.01622000
>> [55,]  0.01622000
>>
>> dat <- dat
>> name <- "Inflation"
>> t <- 1
>> ar <- 1
>> grid <- 200
>> bq <- 1999
>> c <- .9
>> all <- 0
>> grph <- 1
>>
>> out <- grid_boot(dat, name, t, ar, grid, bq, c, all, grph)
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

From simon0098 at yahoo.com  Thu Feb 18 17:27:08 2016
From: simon0098 at yahoo.com (simon0098 at yahoo.com)
Date: Thu, 18 Feb 2016 08:27:08 -0800
Subject: [R] How to create an executable file from R GUI?
Message-ID: <1455812828.45178.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>

Hi,
I've created a GUI using RGtk2 package. How can I make an executable file from my R script so that users click on it and the GUI appears for them? 


	[[alternative HTML version deleted]]


From 538280 at gmail.com  Thu Feb 18 18:24:23 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 18 Feb 2016 10:24:23 -0700
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <1455812828.45178.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>
References: <1455812828.45178.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>
Message-ID: <CAFEqCdxPp=OkvOFKjfTSw4V3R1VhFXYozjCEJ6cJGNUeMQfUfw@mail.gmail.com>

To give a full answer we need some more detail from you.  For example
what operating system are you on? what do you mean by "users click on
it"? and at what point do you want them to click (after running R,
when looking at the desktop, etc.)

But to help get you started you may want to look at the help page
`?Startup` which tells you all the things that R does as it starts up
and how to have it run commands automatically as it is starting up.

I have created some GUI examples in the past that clients then wanted
to have on their own computer to play with and demonstrate to others.
I usually would install R on their machine for them and create a
shortcut on the desktop (these were all MS Windows computers) that
pointed to the standard R executable, but started in a specific
directory/folder.  Then in that folder I created a ".Rprofile" file
with the commands to load in the appropriate data and packages and run
the gui demonstration.  The user could then double click on the
shortcut on the desktop and 2 windows would pop up (the regular R
interface and my gui demo), I instructed the client to just minimize
and ignore the regular R window and they were then able to use my demo
and then close everything when they were finished.  You could do
something similar (but exactly how will differ between Windows, Mac,
and Linux computers).

On Thu, Feb 18, 2016 at 9:27 AM, simon0098--- via R-help
<r-help at r-project.org> wrote:
> Hi,
> I've created a GUI using RGtk2 package. How can I make an executable file from my R script so that users click on it and the GUI appears for them?
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jdnewmil at dcn.davis.ca.us  Thu Feb 18 18:26:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Feb 2016 09:26:34 -0800
Subject: [R] MACRO-LOOP in R
In-Reply-To: <476550192.5049006.1455812267513.JavaMail.yahoo@mail.yahoo.com>
References: <476550192.5049006.1455812267513.JavaMail.yahoo.ref@mail.yahoo.com>
	<476550192.5049006.1455812267513.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <37A2B963-A7AE-4CC4-BBED-27FF6965CB0C@dcn.davis.ca.us>

What a mess. Transposing factors is highly unlikely to lead to sensible results. Did you look at str( x123 ) as your example created it? 

x <- data.frame( a=c(1,2,3), b=c("1","2","3"), stringsAsFactors=FALSE )

x123new <- setNames( as.data.frame( t( x[ , "b" ] ) ), paste( "b", 1:3, sep="_" ) )

R is not SAS. Please read the Introduction to R document (again). Pay attention to the discussions of indexing, character mode and factors. 

-- 
Sent from my phone. Please excuse my brevity.

On February 18, 2016 8:17:47 AM PST, Amoy Yang via R-help <r-help at r-project.org> wrote:
>I am doing the data transpose with rename as shown below (step1 ~
>step4)
>1. Is any way?in R similar to PROC?TRANSPOSE used in SAS?2. How to use
>MACRO-LOOP to simplify the following procedure?
>THANK YOU?FOR?HELPS!
># create data for test
>x<-data.frame(
>?a=c(1,2,3),
>?b=c("1","2","3")); 
>x; str(x)# step1: parse out to 3 tabs
>x1<-x[x$a == 1,]; x1
>x2<-x[x$a == 2,]; x2
>x3<-x[x$a == 3,]; x3# step2: remove column a in each tab
>x1$a<-NULL; x1
>x2$a<-NULL; x2
>x3$a<-NULL; x3# step3: rename column b to b1, b2 and b3 by y1, y2 and
>y3
>names(x1)[names(x1)=="b"]<-"b_1"; x1
>names(x2)[names(x2)=="b"]<-"b_2"; x2
>names(x3)[names(x3)=="b"]<-"b_3"; x3# setp4: set x1, x3 and x3 together
>x123=cbind(x1,x2,x3); x123
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marine.regis at hotmail.fr  Thu Feb 18 18:36:45 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 18 Feb 2016 17:36:45 +0000
Subject: [R] Split a character string with two separators
Message-ID: <AMSPR07MB470B9787CBD8AF8B5DC1E8EE2AF0@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,

>From this character string:

test <-"k0298_7832_8964"

how can I obtain:

[[1]]

"0298"

Thank you very much for your help.

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Thu Feb 18 18:41:30 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 18 Feb 2016 12:41:30 -0500
Subject: [R] Split a character string with two separators
In-Reply-To: <AMSPR07MB470B9787CBD8AF8B5DC1E8EE2AF0@AMSPR07MB470.eurprd07.prod.outlook.com>
References: <AMSPR07MB470B9787CBD8AF8B5DC1E8EE2AF0@AMSPR07MB470.eurprd07.prod.outlook.com>
Message-ID: <FB9DF234-905E-42CD-AA13-701140430633@bigelow.org>

Hi,

Will substring work for you?  

?substring

Cheers,
Ben

> On Feb 18, 2016, at 12:36 PM, Marine Regis <marine.regis at hotmail.fr> wrote:
> 
> Hello,
> 
>> From this character string:
> 
> test <-"k0298_7832_8964"
> 
> how can I obtain:
> 
> [[1]]
> 
> "0298"
> 
> Thank you very much for your help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From ulrik.stervbo at gmail.com  Thu Feb 18 18:46:27 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 18 Feb 2016 17:46:27 +0000
Subject: [R] Split a character string with two separators
In-Reply-To: <FB9DF234-905E-42CD-AA13-701140430633@bigelow.org>
References: <AMSPR07MB470B9787CBD8AF8B5DC1E8EE2AF0@AMSPR07MB470.eurprd07.prod.outlook.com>
	<FB9DF234-905E-42CD-AA13-701140430633@bigelow.org>
Message-ID: <CAKVAULOnFqYoBathjTaisGWX2YZsaZ1hcT1h0Hta0+ygkuFwRw@mail.gmail.com>

or strsplit?

test <-"k0298_7832_8964"

# Split and remove letters
test <- unlist(strsplit(test, "\\_"))
test <- gsub("[a-z]", "", test[1])

# Split on letters and underscore
test <-"k0298_7832_8964"
test <- unlist(strsplit(test, "[a-z]|\\_"))
test[2]


On Thu, 18 Feb 2016 at 18:43 Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> Will substring work for you?
>
> ?substring
>
> Cheers,
> Ben
>
> > On Feb 18, 2016, at 12:36 PM, Marine Regis <marine.regis at hotmail.fr>
> wrote:
> >
> > Hello,
> >
> >> From this character string:
> >
> > test <-"k0298_7832_8964"
> >
> > how can I obtain:
> >
> > [[1]]
> >
> > "0298"
> >
> > Thank you very much for your help.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb 18 19:49:52 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Feb 2016 10:49:52 -0800
Subject: [R] Problem in adapting a script I have not written.
In-Reply-To: <CAHKSjNGtbGFgSQkQOkAzCnCkyHXck9mAVwn2ZY44BMmjZPjmbA@mail.gmail.com>
References: <CAHKSjNHu1iOx7BjmY5Or7b5ht+Ysv909y+u6TZ6K6cKFhjBEsw@mail.gmail.com>
	<F7F0BD5E-9C9B-431A-BBD2-FC5BAD82FF91@dcn.davis.ca.us>
	<CAHKSjNGtbGFgSQkQOkAzCnCkyHXck9mAVwn2ZY44BMmjZPjmbA@mail.gmail.com>
Message-ID: <BACC7CA4-172C-4243-BAC4-87EA3C5E990B@dcn.davis.ca.us>

Looks to me like the code was not tested for an AR value of 1. Works if I set it to 2. Could be an issue of failing to use the drop=FALSE option when indexing a matrix or data frame, but I don't have time to dig thorough the code to find out where.
-- 
Sent from my phone. Please excuse my brevity.

On February 18, 2016 9:12:25 AM PST, Dalila Zolarsi <dalila.zolarsi at gmail.com> wrote:
>I'm really sorry, I forgot the attachment! I attach the main code as
>txt
>file, instead here
><http://www.ssc.wisc.edu/~bhansen/progs/restat_99.html> there
>everything else I mentioned.
>I apologize if I have not been able to summarize, but I am not so
>proficient.
>
>Yes, the ar parameter is exactly what I said it is; it is an index that
>shouldn't be found in the data, but you decide it. Even the author
>specifies it is "the order of the autoregressive parameter", thus I
>really
>don't have a clue of why he used indexetion. Np is his dataset, you can
>find it in the link below, if you want to help me.
>
>Yes, I read about indexing but I'm asking for help just because I am
>sure
>of what "ar" is. I am not proficient with R, but at least I have
>knowledge
>Time series econometrics' theory.
>
>No, I am not asking to do my homework for me howeverer. I spent the
>last
>two whole weeks on this code trying different inputs and trying to put
>all
>my effort in understanding every single detail of this code, otherwise
>I
>would never asked for help to unknown people. And it is my master
>thesis,
>thus is not really nice to use the word "homework" if you don't know my
>personal situation. However, I understand you probably receive
>thousands of
>silly problems, thus don't get me wrong for what I've just said.
>
>All the data and the code are here
><http://www.ssc.wisc.edu/~bhansen/progs/restat_99.html>, the main
>procedure
>is attached.
>(When I sent the first mail, I sent it another right after with the
>attachment, but the moderators discarded it, thus I apologize again for
>the
>uncomplete post"
>
>
>
>2016-02-18 17:57 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> d[ 3 ] means indexing some vector-like object called "d" to extract
>the
>> third value. (You really need to read the Introduction to R document
>that
>> comes with R, particularly about indexing. There are actually four
>ways to
>> do indexing that may come up as you read other people's code.) "d" is
>the
>> contents of the seventh row of some matrix-like object called "np"
>which
>> you have given no definition for. Without that information "ar" could
>be
>> almost anything. If you are right and their example works then you
>have not
>> given us the whole example. You mention attaching code... the mailing
>list
>> strips off most attachments to avoid spreading viruses, but if they
>have
>> the extension ".txt" they usually get through okay.
>>
>> If the ar parameter really is what you say it is supposed to be,
>giving it
>> the value 1 should be perfectly acceptable. However, you may not have
>> specified the arguments to that function in the correct order, or the
>> problem may be in other arguments.
>>
>> Do be warned that this list is here to help you through rough
>spots... not
>> to do your work for you. The Posting Guide mentioned at the bottom of
>every
>> R-help email asks you to post minimal examples rather than long
>complicated
>> code files, so you are at best near the edge of acceptable use in
>this
>> request, so at least be sure we can reproduce your error. (Posting
>your
>> email in plain text rather than HTML is another important step in
>> communicating clearly by avoiding corruption of your code in the
>mailing
>> list.)
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 17, 2016 1:19:07 PM PST, Dalila Zolarsi <
>> dalila.zolarsi at gmail.com> wrote:
>>
>>> Dear R users,
>>> I'm new of R, thus I apologize in advance if my following question
>may
>>> result a little dumb, but I really need some expert advice.
>>> I have a problem in applying someone else's code to my data. The
>author's
>>> code works perfectly with the examples he provides, and it seems to
>me I am
>>> doing all the correct steps in my case, but apparently I am not.
>>>
>>> The main function is:
>>> grid_boot <- function(dat,name,t,ar,grid,bq,c,all,grph)
>>> and I should simply specify the parameter and then running the code
>given
>>> in the script, or at least for the author's example this works.
>>> All the specification in the examples are close to my case, except
>for the
>>> ar parameter.
>>> The ar parameter is the autoregressive order of a time series, so it
>is
>>> simply a number from 1 to n that you choose. My series requires a
>simple ar
>>> = 1, but if I run the code with this specification, R give me back
>the
>>> following
>>> error:
>>>
>>> " Error in solve.default(t(x) %*% x) :
>>>   system is computationally singular: reciprocal condition number =
>>> 6.07898e-34 In addition: Warning messages:
>>> 1: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
>>>   longer object length is not a multiple of shorter object length
>>> 2: In dat[(ar - k + 2):(n - k + 1)] - dat[(ar - k + 1):(n - k)] :
>>>   longer object length is not a multiple of shorter object length"
>>>
>>> In the example, the author specifies as follow:
>>> orig <- 2    # set to 1 for original data, set to 2 for extended
>data #
>>> t <- 2
>>> grid <- 200
>>> bq <- 9999
>>> c <- .9
>>> i <- 7
>>> d <- np[i,]
>>> if (orig==1){
>>>     y <- as.matrix(dat[d[1]:(d[2]-18)])
>>>     if (i==4) y <- y[21:82]
>>> }else{
>>>     y <- as.matrix(dat[d[1]:d[2]])
>>> }
>>> name <- "GNP per Capita: 1869-1988"
>>> ar <- d[3]
>>>
>>> What I can't figure out is the indication ar <-
>>> d[3] and in general what
>>> precisely he means with specifying i and d. I think this
>specification is
>>> due to the fact that his dataset is made of several variables all
>written
>>> in the same column and they are associated with an index.
>>> When I give these inputs to R (I use RStudio), in the environment
>pane
>>>  appears as ar = 1. When I give the numerical input (ar <- 1) for my
>>> exercise instead, the only result is the error above mentioned.
>>>
>>> Below, I report my data (as you can see, it is only a single series
>with
>>> few observation, so it should be an easy one) and my inputs, while I
>attach
>>> the script in a text file because it is quite a long one. I also
>attach the
>>> example and the data used in it.
>>> I hope someone can help me figuring out what am I doing wrong and I
>will be
>>> very grateful to anyone who is willing to help a newbie like me.
>>>
>>> library(pracma)
>>> source(file.choose())
>>> dat <-
>>> as.matrix(read.csv(file.choose(), header = TRUE))
>>> print(dat)
>>>
>>> USA
>>>  [1,]  0.01075000
>>>  [2,]  0.01116000
>>>  [3,]  0.01214000
>>>  [4,]  0.01309000
>>>  [5,]  0.01668000
>>>  [6,]  0.02991000
>>>  [7,]  0.02776000
>>>  [8,]  0.04218000
>>>  [9,]  0.05415000
>>> [10,]  0.05895000
>>> [11,]  0.04256000
>>> [12,]  0.03306000
>>> [13,]  0.00622000
>>> [14,]  0.11035000
>>> [15,]  0.09132000
>>> [16,]  0.05737000
>>> [17,]  0.06486000
>>> [18,]  0.07647000
>>> [19,]  0.11266000
>>> [20,]  0.13509000
>>> [21,]  0.10316000
>>> [22,]  0.06161000
>>> [23,]  0.03212000
>>> [24,]  0.04317000
>>> [25,]  0.03561000
>>> [26,]  0.01859000
>>> [27,]  0.03741000
>>> [28,]  0.04009000
>>> [29,]  0.04827000
>>> [30,]  0.05398000
>>> [31,]  0.04235000
>>> [32,]  0.03029000
>>> [33,]  0.02952000
>>> [34,]  0.02607000
>>> [35,]  0.02805000
>>> [36,]  0.02931000
>>> [37,]  0.02338000
>>> [38,]  0.01552000
>>> [39,]  0.02188000
>>> [40,]
>>> 0.03377000
>>> [41,]  0.02826000
>>> [42,]  0.01586000
>>> [43,]  0.00002270
>>> [44,]  0.02677000
>>> [45,]  0.03393000
>>> [46,]  0.03226000
>>> [47,]  0.02853000
>>> [48,]  0.03839000
>>> [49,] -0.00000356
>>> [50,]  0.00001640
>>> [51,]  0.03157000
>>> [52,]  0.02069000
>>> [53,]  0.01465000
>>> [54,]  0.01622000
>>> [55,]  0.01622000
>>>
>>> dat <- dat
>>> name <- "Inflation"
>>> t <- 1
>>> ar <- 1
>>> grid <- 200
>>> bq <- 1999
>>> c <- .9
>>> all <- 0
>>> grph <- 1
>>>
>>> out <- grid_boot(dat, name, t, ar, grid, bq, c, all, grph)
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Thu Feb 18 20:45:04 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Thu, 18 Feb 2016 19:45:04 +0000
Subject: [R] cannot install stats package
Message-ID: <d5463398175d4fd2b27feae6009839f4@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,
I would like to install the stats package but I get the message
Warning in install.packages :
  package 'stats' is not available (for R version 3.2.3)

How can I install stats without changing my R version? Is there an alternative package?

Thanks for your help.


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb 18 20:49:55 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 18 Feb 2016 14:49:55 -0500
Subject: [R] cannot install stats package
In-Reply-To: <d5463398175d4fd2b27feae6009839f4@ex13-live-mbn1.ad.kent.ac.uk>
References: <d5463398175d4fd2b27feae6009839f4@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <56C62063.8060209@gmail.com>

On 18/02/2016 2:45 PM, T.Riedle wrote:
> Dear R users,
> I would like to install the stats package but I get the message
> Warning in install.packages :
>    package 'stats' is not available (for R version 3.2.3)
>
> How can I install stats without changing my R version? Is there an alternative package?
>
The stats package is a base package.  It is part of R, you don't need to 
install it.

Duncan Murdoch


From sarah.goslee at gmail.com  Thu Feb 18 20:50:09 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 18 Feb 2016 14:50:09 -0500
Subject: [R] cannot install stats package
In-Reply-To: <d5463398175d4fd2b27feae6009839f4@ex13-live-mbn1.ad.kent.ac.uk>
References: <d5463398175d4fd2b27feae6009839f4@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <CAM_vjun3Mv_0Q6HxAP9hXAB+pT4vpK6Vrs56_a7gHruwo2yF+Q@mail.gmail.com>

The stats package is automatically installed when you install R. It's
not available on CRAN because you already have it.

Sarah

On Thu, Feb 18, 2016 at 2:45 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> Dear R users,
> I would like to install the stats package but I get the message
> Warning in install.packages :
>   package 'stats' is not available (for R version 3.2.3)
>
> How can I install stats without changing my R version? Is there an alternative package?
>
> Thanks for your help.
>


From abdel.halloway at gmail.com  Thu Feb 18 21:33:29 2016
From: abdel.halloway at gmail.com (Abdel Halloway)
Date: Thu, 18 Feb 2016 14:33:29 -0600
Subject: [R] mclapply in foreach
Message-ID: <CANKjaMfnd84tpVyeXSHYCfqnN49u-BpnKdtmXL-cd4vUHFQGoA@mail.gmail.com>

Can a person put mclapply in a foreach loop? Based on this post here
<http://stackoverflow.com/questions/34704733/parallel-r-with-foreach-and-mclapply-at-the-same-time>,
I wrote a script, seen here:

"library(parallel)
library(doParallel)

cl<-makeCluster(2,outfile='')
registerDoParallel(cl)

foreach(i=1:5, .packages='parallel') %dopar% {
    system.time(mclapply(1:10, function(x){rnorm(1e5)},mc.cores=2))}

stopCluster(cl)"


It worked initially but is now throwing up error codes:

"Error in unserialize(node$con) : error reading from connection
Calls: <Anonymous> ... doTryCatch -> recvData -> recvData.SOCKnode ->
unserialize
Execution halted
Error in unserialize(socklist[[n]]) : error reading from connection
Error in unserialize(node$con) : error reading from connection
Calls: <Anonymous> ... doTryCatch -> recvData -> recvData.SOCKnode ->
unserialize
Execution halted"


Any idea what's going on? This is on a single machine, not a cluster.

	[[alternative HTML version deleted]]


From divakarreddy.a at gmail.com  Thu Feb 18 21:03:17 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Thu, 18 Feb 2016 13:03:17 -0700
Subject: [R] 'tcltk' in R2.3.3
Message-ID: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>

Dear R users,

I would to install 'tcltk' in R2.3.3 but getting below error when I tried
to install.
Can you please suggest me?


> install.packages("tcltk", repos = "http://cran.cnr.Berkeley.edu/");
Installing package into ?/usr/lib64/R/library?
(as ?lib? is unspecified)
Warning message:
package ?tcltk? is not available (for R version 3.2.3)
> capabilities("tcltk")
tcltk
 TRUE
>


Thanks,
Divakar
Phoenix,USA

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Thu Feb 18 18:36:08 2016
From: simon0098 at yahoo.com (Zahra Samadi)
Date: Thu, 18 Feb 2016 09:36:08 -0800
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAFEqCdxPp=OkvOFKjfTSw4V3R1VhFXYozjCEJ6cJGNUeMQfUfw@mail.gmail.com>
Message-ID: <1455816968.54831.YahooMailAndroidMobile@web164006.mail.gq1.yahoo.com>

OK. I should add that I want to have a shortcut on my desktop. My operating system is Windoes. I just need that when users click on this shortcut, my GUI appears without opening R environment since my users are completely unfamiliar with programming. 


	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Thu Feb 18 22:03:52 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 18 Feb 2016 23:03:52 +0200
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAFEqCdxPp=OkvOFKjfTSw4V3R1VhFXYozjCEJ6cJGNUeMQfUfw@mail.gmail.com>
References: <1455812828.45178.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>
	<CAFEqCdxPp=OkvOFKjfTSw4V3R1VhFXYozjCEJ6cJGNUeMQfUfw@mail.gmail.com>
Message-ID: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>

Simon, Greg,

That is the very reason why I've given up on Tck/Tk, in favor of shiny.
The user interface opens up in a webpage, without opening the normal R
console (it only opens a Terminal window).

To exemplify, package QCAGUI has a function called runGUI(), and on Windows
it's a simple matter of creating a .bat file,
which for my user interface it only contains this:

CLS

TITLE QCA Qualitative Comparative Analysis

C:/PROGRA~1/R/R-3.2.3/bin/R.exe --slave --no-restore -e
"setwd('D:/');QCAGUI::runGUI()"


The double click on the .bat file, and that's it.
I hope it helps,
Adrian



On Thu, Feb 18, 2016 at 7:24 PM, Greg Snow <538280 at gmail.com> wrote:

> To give a full answer we need some more detail from you.  For example
> what operating system are you on? what do you mean by "users click on
> it"? and at what point do you want them to click (after running R,
> when looking at the desktop, etc.)
>
> But to help get you started you may want to look at the help page
> `?Startup` which tells you all the things that R does as it starts up
> and how to have it run commands automatically as it is starting up.
>
> I have created some GUI examples in the past that clients then wanted
> to have on their own computer to play with and demonstrate to others.
> I usually would install R on their machine for them and create a
> shortcut on the desktop (these were all MS Windows computers) that
> pointed to the standard R executable, but started in a specific
> directory/folder.  Then in that folder I created a ".Rprofile" file
> with the commands to load in the appropriate data and packages and run
> the gui demonstration.  The user could then double click on the
> shortcut on the desktop and 2 windows would pop up (the regular R
> interface and my gui demo), I instructed the client to just minimize
> and ignore the regular R window and they were then able to use my demo
> and then close everything when they were finished.  You could do
> something similar (but exactly how will differ between Windows, Mac,
> and Linux computers).
>
> On Thu, Feb 18, 2016 at 9:27 AM, simon0098--- via R-help
> <r-help at r-project.org> wrote:
> > Hi,
> > I've created a GUI using RGtk2 package. How can I make an executable
> file from my R script so that users click on it and the GUI appears for
> them?
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb 18 22:19:20 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 18 Feb 2016 16:19:20 -0500
Subject: [R] 'tcltk' in R2.3.3
In-Reply-To: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>
References: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>
Message-ID: <56C63558.6060907@gmail.com>

On 18/02/2016 3:03 PM, Divakar Reddy wrote:
> Dear R users,
>
> I would to install 'tcltk' in R2.3.3 but getting below error when I tried
> to install.
> Can you please suggest me?

Don't try to install a base package.  You already have it.  You aren't 
allowed to update it.

Duncan Murdoch

>
>
>> install.packages("tcltk", repos = "http://cran.cnr.Berkeley.edu/");
> Installing package into ?/usr/lib64/R/library?
> (as ?lib? is unspecified)
> Warning message:
> package ?tcltk? is not available (for R version 3.2.3)
>> capabilities("tcltk")
> tcltk
>   TRUE
>>
>
>
> Thanks,
> Divakar
> Phoenix,USA
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Thu Feb 18 22:21:28 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 18 Feb 2016 22:21:28 +0100
Subject: [R] 'tcltk' in R2.3.3
In-Reply-To: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>
References: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>
Message-ID: <56C635D8.6060604@statistik.tu-dortmund.de>



On 18.02.2016 21:03, Divakar Reddy wrote:
> Dear R users,
>
> I would to install 'tcltk' in R2.3.3 but getting below error when I tried
> to install.
> Can you please suggest me?
>
>
>> install.packages("tcltk", repos = "http://cran.cnr.Berkeley.edu/");
> Installing package into ?/usr/lib64/R/library?
> (as ?lib? is unspecified)
> Warning message:
> package ?tcltk? is not available (for R version 3.2.3)
>> capabilities("tcltk")

This is a base package, you already hav it installed.

Best,
Uwe Ligges


> tcltk
>   TRUE
>>
>
>
> Thanks,
> Divakar
> Phoenix,USA
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ravi.varadhan at jhu.edu  Thu Feb 18 21:47:06 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 18 Feb 2016 20:47:06 +0000
Subject: [R] Looking for a data set - Teratology data of Chen and Kodell
	(1989)
Message-ID: <293598febaf6499bb7c34db6f92db796@ESGEBEX10.win.ad.jhu.edu>

Hi,
I am looking for the teratology data set from the Chen and Kodell (JASA 1989) on mice exposed to different doses of a chemical, DEHP.  This was also analyzed in a Biometrics 2000 paper by Louise Ryan using GEE.  I think this data set is publicly available, but I am unable to locate it.  Does anyone know of this or worked with this data set?  If so, can someone share it with me?

Thank you very much.

Best,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From bobkot at comcast.net  Thu Feb 18 21:58:35 2016
From: bobkot at comcast.net (Bob Kot)
Date: Thu, 18 Feb 2016 15:58:35 -0500
Subject: [R] 'tcltk' in R2.3.3
In-Reply-To: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>
References: <CALEm3d2MUtG_1H-Ebyh=dLOxV-jUBqKNOS3=1EcT5emdXM6j0A@mail.gmail.com>
Message-ID: <00b001d16a8f$22e3d840$68ab88c0$@comcast.net>

I believe you mean - "tcltk2" which refers to Tcl/Tk Additions - https://cran.r-project.org/web/packages/tcltk2/index.html

Kind regards,
Bob

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Divakar Reddy
Sent: Thursday, February 18, 2016 3:03 PM
To: r-help at r-project.org
Subject: [R] 'tcltk' in R2.3.3

Dear R users,

I would to install 'tcltk' in R2.3.3 but getting below error when I tried to install.
Can you please suggest me?


> install.packages("tcltk", repos = "http://cran.cnr.Berkeley.edu/");
Installing package into ?/usr/lib64/R/library?
(as ?lib? is unspecified)
Warning message:
package ?tcltk? is not available (for R version 3.2.3)
> capabilities("tcltk")
tcltk
 TRUE
>


Thanks,
Divakar
Phoenix,USA

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From doug45290 at yahoo.com  Thu Feb 18 22:12:40 2016
From: doug45290 at yahoo.com (D Wolf)
Date: Thu, 18 Feb 2016 21:12:40 +0000 (UTC)
Subject: [R] Reading a datetime vector
References: <579109766.6504683.1455829960357.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <579109766.6504683.1455829960357.JavaMail.yahoo@mail.yahoo.com>

Hello,I am trying to read a data frame column named DateTimeStamp. The time is in GMT in this format: 1/4/2013 23:30
require(xlsx)
df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")

It's good to that line. But these three lines, which makes the dataframe, converts the column's values to NA:df2_TZ$DateTimeStamp = as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")

and...?df2_TZ$DateTimeStamp = as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")

and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format = "%m/%d/%Y %H:%M:%S")

This line returns and error...df2_TZ$DateTimeStamp = as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
"Error in charToDate(x) :?? character string is not in a standard unambiguous format"
Additionally, I need to convert from GMT to North American time zones, and I think the advice on this page would be good for that:?http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
My ultimate goal is to write an R program that finds data in another variable in df2_TZ that corresponds to a date and time that match up with the date and time in another data frame. For now, any help reading the column would be much appreciated.
Thank You,Doug
	[[alternative HTML version deleted]]


From valerio at geody.com  Thu Feb 18 22:46:06 2016
From: valerio at geody.com (Valerio Capello)
Date: Thu, 18 Feb 2016 22:46:06 +0100
Subject: [R] Geody - geolocated spots on a sphere ("planet")
Message-ID: <CAMbJgqAvZdxg8XTFpBjBeuNxC-gOnVnyYzEWYWEauzDnZGmy8g@mail.gmail.com>

Hi, I'm the developer at Geody, the geospatial web tool. I've recently
added support for the R language (requires rgl module), so that you
can choose one or multiple places on Earth or other planets of the
Solar Systems and get a script that shows a 3D planet with 3D dots of
the selected places.
All you have to do is to search for the place you want, or enter
coordinates directly, then you can download the script from the [R]
link or you can add the spot to the Cart and then from the Cart's page
export it as [R] script. Scripts generated by Geody are licensed as
GPL.

You can test it here: http://www.geody.com

By the way, there are also some simple scripts I wrote (also released
as GPL) for charts, 2D/3D graphs, and stats here:
http://labs.geody.com/r_lang/

Feedback is warmly welcomed.

Valerio


From cb.mlotshwa at gmail.com  Fri Feb 19 04:27:51 2016
From: cb.mlotshwa at gmail.com (Busisiwe Mlotshwa)
Date: Thu, 18 Feb 2016 21:27:51 -0600
Subject: [R] Help with Allele frequency correlation
Message-ID: <56c68bb3.a7233c0a.dc59f.36f6@mx.google.com>

Hi, I am trying to correlate allele frequencies for two populations. My datasets are binary (bed, bim, fam), exported from Plink and read into R using read.plink (snpStats).  I want to generate a correlation matrix for the two populations and thought I would use cor.test (method = ?spearman?) to do this. R is interpreting my genotype data as a matrix; I have 45 individuals and 100 000 loci in each dataset. I tried coercing each to numeric with as.data.frame(x), but this method is just hanging. I don?t know whether the size of the dataset is the problem or if it?s the structure of the data. Please assist.

Regards,
Ceci

Sent from Mail for Windows 10


	[[alternative HTML version deleted]]


From teotjunk at hotmail.com  Fri Feb 19 06:34:28 2016
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Fri, 19 Feb 2016 13:34:28 +0800
Subject: [R] Aggregating data by data.table
Message-ID: <SNT152-W9569A191F046D5BA9AEABFDFA00@phx.gbl>

I am trying to aggregate data using data table. Here is what I am trying to do

OrgData<-data.table(fgl)
setkey(OrgData,type)
OrgData<-OrgData[,j=list(Quant=quantile(RI),m=max(RI)),by=type]

    type  Quant     m
1:  WinF -5.850  8.67
2:  WinF -0.460  8.67
3:  WinF -0.165  8.67
4:  WinF  1.560  8.67
5:  WinF  8.670  8.67
6: WinNF -3.910 15.93
I can write a function to reshape the data in the format I want it in the columns that I want. But is there a quick way to do it directly in data.table?


 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Feb 19 06:51:37 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Feb 2016 21:51:37 -0800
Subject: [R] Reading a datetime vector
In-Reply-To: <579109766.6504683.1455829960357.JavaMail.yahoo@mail.yahoo.com>
References: <579109766.6504683.1455829960357.JavaMail.yahoo.ref@mail.yahoo.com>
	<579109766.6504683.1455829960357.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1CA46D8D-1741-436B-B2FC-2C9E40B98371@dcn.davis.ca.us>

You are being rather scattershot in your explanation, so I suspect you are not being systematic in your troubleshooting. Use the str function to examine the data column after you pull it in from excel. It may be numeric, factor, or character, and the approach depends on which that function returns. 
-- 
Sent from my phone. Please excuse my brevity.

On February 18, 2016 1:12:40 PM PST, D Wolf via R-help <r-help at r-project.org> wrote:
>Hello,I am trying to read a data frame column named DateTimeStamp. The
>time is in GMT in this format: 1/4/2013 23:30
>require(xlsx)
>df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")
>
>It's good to that line. But these three lines, which makes the
>dataframe, converts the column's values to NA:df2_TZ$DateTimeStamp =
>as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")
>
>and...?df2_TZ$DateTimeStamp =
>as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y
>%H:%M:%S")
>
>and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format =
>"%m/%d/%Y %H:%M:%S")
>
>This line returns and error...df2_TZ$DateTimeStamp =
>as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
>"Error in charToDate(x) :?? character string is not in a standard
>unambiguous format"
>Additionally, I need to convert from GMT to North American time zones,
>and I think the advice on this page would be good for
>that:?http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
>My ultimate goal is to write an R program that finds data in another
>variable in df2_TZ that corresponds to a date and time that match up
>with the date and time in another data frame. For now, any help reading
>the column would be much appreciated.
>Thank You,Doug
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Feb 19 07:32:50 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 19 Feb 2016 17:32:50 +1100
Subject: [R] Reading a datetime vector
In-Reply-To: <579109766.6504683.1455829960357.JavaMail.yahoo@mail.yahoo.com>
References: <579109766.6504683.1455829960357.JavaMail.yahoo.ref@mail.yahoo.com>
	<579109766.6504683.1455829960357.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fUSAuNmpSL7tfjnu4fS+CtM-NU5L6aC21jvJjyLypt3Gg@mail.gmail.com>

Hi Doug,
For one thing, you may be using the wrong format. Your example format has
no seconds field. The other thing to watch is whether the data are in
%m/%d/%Y or %d/%m/%Y date format. If the latter, you would probably get
that error on dates like 19/02/2016.

Jim


On Fri, Feb 19, 2016 at 8:12 AM, D Wolf via R-help <r-help at r-project.org>
wrote:

> Hello,I am trying to read a data frame column named DateTimeStamp. The
> time is in GMT in this format: 1/4/2013 23:30
> require(xlsx)
> df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")
>
> It's good to that line. But these three lines, which makes the dataframe,
> converts the column's values to NA:df2_TZ$DateTimeStamp =
> as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")
>
> and... df2_TZ$DateTimeStamp =
> as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
>
> and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format =
> "%m/%d/%Y %H:%M:%S")
>
> This line returns and error...df2_TZ$DateTimeStamp =
> as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
> "Error in charToDate(x) :   character string is not in a standard
> unambiguous format"
> Additionally, I need to convert from GMT to North American time zones, and
> I think the advice on this page would be good for that:
> http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
> My ultimate goal is to write an R program that finds data in another
> variable in df2_TZ that corresponds to a date and time that match up with
> the date and time in another data frame. For now, any help reading the
> column would be much appreciated.
> Thank You,Doug
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Feb 19 09:24:25 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 19 Feb 2016 09:24:25 +0100
Subject: [R] MACRO-LOOP in R
In-Reply-To: <1750028257.5012960.1455817457553.JavaMail.yahoo@mail.yahoo.com>
References: <CAJuCY5zTwHPgjgE=2-OiHCe1J3Hz8=WygUdomyyZJCSCTSOR9Q@mail.gmail.com>
	<1750028257.5012960.1455817457553.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJuCY5x4rHVnFBQaSRgeBmwEz4RX40ZSjFieE7XRNc29Sjh2kg@mail.gmail.com>

Please keep the mailinglist in cc.

You should be able to solve this after reading the helpfiles of
?dplyr::mutate and ?tidyr::spread

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-02-18 18:44 GMT+01:00 Amoy Yang <amoy_y at yahoo.com>:

> So simply. What happens if I have multiple columns (b, d and e) to be
> transposed and renamed as you did for b? Thanks again for helps!
>
> x<-data.frame(
>  a=c(1,2,3),
>  b=c("1","2","3"),
>  d=c(5,6,7),
>  e=c("n1","n2","n3"));
> x; str(x)
>
>
> On Thursday, February 18, 2016 10:37 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>
> R has no concept of macro language like SAS because it doesn't need it.
> Here is a solution for your problem.
>
> library(dplyr)
> library(tidyr)
> x %>%
>   mutate(b = paste0("b_", b)) %>%
>   spread(key = b, value = a)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-02-18 17:17 GMT+01:00 Amoy Yang via R-help <r-help at r-project.org>:
>
>  I am doing the data transpose with rename as shown below (step1 ~ step4)
> 1. Is any way in R similar to PROC TRANSPOSE used in SAS?2. How to use
> MACRO-LOOP to simplify the following procedure?
> THANK YOU FOR HELPS!
> # create data for test
> x<-data.frame(
>  a=c(1,2,3),
>  b=c("1","2","3"));
> x; str(x)# step1: parse out to 3 tabs
> x1<-x[x$a == 1,]; x1
> x2<-x[x$a == 2,]; x2
> x3<-x[x$a == 3,]; x3# step2: remove column a in each tab
> x1$a<-NULL; x1
> x2$a<-NULL; x2
> x3$a<-NULL; x3# step3: rename column b to b1, b2 and b3 by y1, y2 and y3
> names(x1)[names(x1)=="b"]<-"b_1"; x1
> names(x2)[names(x2)=="b"]<-"b_2"; x2
> names(x3)[names(x3)=="b"]<-"b_3"; x3# setp4: set x1, x3 and x3 together
> x123=cbind(x1,x2,x3); x123
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From divakarreddy.a at gmail.com  Fri Feb 19 18:32:25 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Fri, 19 Feb 2016 10:32:25 -0700
Subject: [R] sqldf --Warning message:
Message-ID: <CALEm3d2dq_Ua8MnQ+c+FoZfM79pSco8GrkXH5DpQDN7Fbvun-Q@mail.gmail.com>

Dear R users,

I'm getting Waring message while trying to load "sqldf" package in R3.2.3
and assuming that we can ignore this as it's WARNING Message and not an
error message.
Can you guide me if my assumption is wrong?


> library(sqldf);
Loading required package: gsubfn
Loading required package: proto
Loading required package: RSQLite
Loading required package: DBI
Warning message:
no DISPLAY variable so Tk is not available

> version               _
platform       x86_64-redhat-linux-gnu
version.string R version 3.2.3 (2015-12-10)
>

Thanks,
Divakar
Phoenix,USA

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Feb 19 18:41:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 19 Feb 2016 09:41:48 -0800
Subject: [R] Reading a datetime vector
In-Reply-To: <63058673.6947413.1455896911928.JavaMail.yahoo@mail.yahoo.com>
References: <1CA46D8D-1741-436B-B2FC-2C9E40B98371@dcn.davis.ca.us>
	<63058673.6947413.1455896911928.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>

This is a mailing list. I don't know how you are interacting with it... using a website rather than an email program can lead to some confusion since there can be many ways to accomplish the task of interacting with the mailing list. My email program has a "reply-all" button when I am looking at an email. It also has an option to write the email in plain text, which often prevents the message from getting corrupted (recipient not seeing what you sent to the list).

Using the str function on a literal string (the name of a file) will indeed tell you that you gave it a character string. Specifying a column in your data might tell you something more interesting... e.g.

str( df2_TZ$DateTimeStamp )

If that says you have character data then Jim Lemon's suggestion would be a good next thing to look at.  If it is factor data then you should use the as.character function on the data column and then follow Jim's suggestion. If it is numeric then you probably need to convert it using an appropriate origin (e.g. as described at [1] or [2]).

I have had best luck setting the default timezone string when converting to POSIXt types... e.g.

# specify timezone assumed by input data
Sys.setenv( TZ="GMT" )
testdtm <- as.POSIXct( "1/1/2016 00:00", format = "%m/%d/%Y %H:%M" )
# inspect the result
testdtm
str( testdtm )
# view data from a different timezone
Sys.setenv( TZ="Etc/GMT+8" )
# no change to the underlying data, but it prints out differently now because the tz attribute is "" which implies using the default TZ
testdtm

[1] http://blog.mollietaylor.com/2013/08/date-formats-in-r.html
[2] https://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf

-- 
Sent from my phone. Please excuse my brevity.

On February 19, 2016 7:48:31 AM PST, D Wolf <doug45290 at yahoo.com> wrote:
>Hello Jeff,
>I ran str() on the vector and it returned character.>
>str("DF_exp.xlsx")?chr "DF_exp.xlsx"
>This is my first thread on this forum, and I'm not sure how to reply to
>the thread instead of just sending the reply to your email account; I
>don't see a 'reply' link in the thread.I've read this page and I don't
>think it advises on how to reply in the thread:?R: Posting Guide: How
>to ask good questions that prompt useful answers
>
>| ? |
>| ? |  | ? | ? | ? | ? | ? |
>| R: Posting Guide: How to ask good questions that prompt ...Posting
>Guide: How to ask good questions that prompt useful answers This guide
>is intended to help you get the most out of the R mailing lists, and to
>avoid embarra... |
>|  |
>| View on www.r-project.org | Preview by Yahoo |
>|  |
>| ? |
>
>
>Thank You,Doug Wolfinger
> 
>
>On Friday, February 19, 2016 12:51 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
> 
>
>You are being rather scattershot in your explanation, so I suspect you
>are not being systematic in your troubleshooting. Use the str function
>to examine the data column after you pull it in from excel. It may be
>numeric, factor, or character, and the approach depends on which that
>function returns. 
>-- 
>Sent from my phone. Please excuse my brevity.
>
>On February 18, 2016 1:12:40 PM PST, D Wolf via R-help
><r-help at r-project.org> wrote:
>Hello,I am trying to read a data frame column named DateTimeStamp. The
>time is in GMT in this format: 1/4/2013 23:30
>require(xlsx)
>df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")
>
>It's good to that line. But these three lines, which makes the
>dataframe, converts the column's values to NA:df2_TZ$DateTimeStamp =
>as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")
>
>and...?df2_TZ$DateTimeStamp =
>as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y
>%H:%M:%S")
>
>and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format =
>"%m/%d/%Y %H:%M:%S")
>
>This line returns and error...df2_TZ$DateTimeStamp =
>as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
>"Error in charToDate(x) :?? character string is not in a standard
>unambiguous format"
>Additionally, I need to convert from GMT to North American time zones,
>and I think the advice on this page would
>be good for
>that:?http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
>My ultimate goal is to write an R program that finds data in another
>variable in df2_TZ that corresponds to a date and time that match up
>with the date and time in another data frame. For now, any help reading
>the column would be much appreciated.
>Thank You,Doug
> [[alternative HTML version deleted]]
>
>
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Fri Feb 19 18:52:04 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 19 Feb 2016 12:52:04 -0500
Subject: [R] sqldf --Warning message:
In-Reply-To: <CALEm3d2dq_Ua8MnQ+c+FoZfM79pSco8GrkXH5DpQDN7Fbvun-Q@mail.gmail.com>
References: <CALEm3d2dq_Ua8MnQ+c+FoZfM79pSco8GrkXH5DpQDN7Fbvun-Q@mail.gmail.com>
Message-ID: <CAP01uRkOnVQmiM86zJi0d=66GfYF9bU9HiyMJqJ5SMJmfbWrog@mail.gmail.com>

sqldf does not use Tk so you can ignore this.

On Fri, Feb 19, 2016 at 12:32 PM, Divakar Reddy
<divakarreddy.a at gmail.com> wrote:
> Dear R users,
>
> I'm getting Waring message while trying to load "sqldf" package in R3.2.3
> and assuming that we can ignore this as it's WARNING Message and not an
> error message.
> Can you guide me if my assumption is wrong?
>
>
>> library(sqldf);
> Loading required package: gsubfn
> Loading required package: proto
> Loading required package: RSQLite
> Loading required package: DBI
> Warning message:
> no DISPLAY variable so Tk is not available
>
>> version               _
> platform       x86_64-redhat-linux-gnu
> version.string R version 3.2.3 (2015-12-10)
>>
>
> Thanks,
> Divakar
> Phoenix,USA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From alexandresuire at hotmail.fr  Fri Feb 19 09:42:55 2016
From: alexandresuire at hotmail.fr (Alexandre Suire)
Date: Fri, 19 Feb 2016 09:42:55 +0100
Subject: [R] Problems with the deSolve package
Message-ID: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>

Hello R-users,

I'm trying to build a SIR-like model under R, 
using the "deSolve" package. I'm trying to do simulations of its dynamic
 over time, with three differential equations. I'm also looking to 
calculate the equilibrium state. 

So far, my code looks like this 

library(deSolve)
#This is my system, with three differential equations
system<-function(times, init, parameters){
with(as.list(c(init, parameters)),{
di1_dt=(alpha1*(N-i1-i2-i12)*(i1+i12))+(beta2*i12+gamma1*(N-i1-i2-i12))-(beta1*i1)-(delta*alpha2*i1*(i2+i12))
di2_dt=(alpha2*(N-i1-i2-i12)*(i2+i12))+(beta1*i12+gamma2*(N-i1-i2-i12))-(beta2*i2)-(delta*alpha1*i2*(i1+i12))
di12_dt=(delta*alpha2*i1*(i12+i2))+(delta*alpha1*i2*(i12*i1))+(delta*gamma1*i1)+(delta*gamma2*i2)-((beta1+beta2)*i12)
return(list(c(di1_dt,di2_dt,di12_dt)))
})
}

# Initials values and parameters
init<-c(i1=10, i2=10, i12=0) 
parameters<-c(alpha1=0.7, alpha2=0.5, beta1=0.5, beta2=0.3, gamma1=0.5, gamma2=0.5, delta=0.5, N=100) 
times<-seq(0,200, by=1)
simul <- as.data.frame(ode(y = init, times = times, func = system, parms = parameters, method="ode45"))
simul$time <- NULL
head(simul,200) 

#Plotting the results
matplot(times,
 simul, type = "l", xlab = "Time", ylab = "i1 i2 i12", main = 
"Simulation", lwd = 2, lty = 2, bty = "l", col=c("darkblue", 
"darkred","mediumseagreen"))
legend("bottomright", c("i1", "i2","i12"), lty=2,lwd=2, col = c("darkblue", "darkred", "mediumseagreen"))

At
 first, I just tried studying with only the first two equations, and it 
seems to work completely fine, but when I wanted to add the 3rd 
equation, I sometimes get this message, even when I juggle the 
parameters, when i launch the line:
#simul <- as.data.frame(ode(y = init, times = times, func = system, parms = parameters))
Warning messages:
1: In lsode(y, times, func, parms, mf = 10, ...) :
  an excessive amount of work (> maxsteps ) was done, but integration was not successful - increase maxsteps
2: In lsode(y, times, func, parms, mf = 10, ...) :
  Returning early. Results are accurate, as far as they go

Have I overlooked something ? I tried to use methods="ode45" and methods="adams", without any sucess.
Thank you for your time
Alex
	   		 	   		  
	[[alternative HTML version deleted]]


From Behnam.ABABAEI at limagrain.com  Fri Feb 19 12:30:05 2016
From: Behnam.ABABAEI at limagrain.com (ABABAEI, Behnam)
Date: Fri, 19 Feb 2016 11:30:05 +0000
Subject: [R] Why CLARA clustering method does not give the same classes as
 when I do clustering manually?
Message-ID: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>

Hi,


I am using CLARA (in 'cluster' package). This method is supposed to assign each observation to the closest 'medoid'. But when I calculate the distance of medoids and observations manually and assign them manually, the results are slightly different (1-2 percent of occurrence probability). Does anyone know how clara calculates dissimilarities and why I get different clustering results?


Behnam.

	[[alternative HTML version deleted]]


From Behnam.ABABAEI at limagrain.com  Fri Feb 19 12:33:09 2016
From: Behnam.ABABAEI at limagrain.com (ABABAEI, Behnam)
Date: Fri, 19 Feb 2016 11:33:09 +0000
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
Message-ID: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>

Hi,


We know that clustering methods in R assign observations to the closest medoids. Hence, it is supposed to be the closest cluster each observation can have. So, I wonder how it is possible to have negative values of silhouette , while we are supposedly assign each observation to the closest cluster and the formula in silhouette method cannot get negative?


Behnam.

	[[alternative HTML version deleted]]


From wjheeringa at gmail.com  Fri Feb 19 14:01:11 2016
From: wjheeringa at gmail.com (Wilbert Heeringa)
Date: Fri, 19 Feb 2016 14:01:11 +0100
Subject: [R] mixed-effects models with (g)lmer in R and model selection
Message-ID: <CAE-DUcoBdFbpZD1VD9ySmjxQj3D0XKrGBPjreTK=+Ent=RP8Nw@mail.gmail.com>

Dear all,

Mixed-effects models are wonderful for analyzing data, but it is always a
hassle to find the best model, i.e. the model with the lowest AIC,
especially when the number of predictor variables is large.

Presently when trying to find the right model, I perform the following
steps:

   1.

   Start with a model containing all predictors. Assuming dependent
   variable X and predictors A, B, C, D, E, I start with: X~A+B+C+D+E
   2.

   Lmer warns that is has dropped columns/coefficients. These are variables
   which have a *perfect* correlation with any of the other variables or
   with a combination of variables. With summary() it can be found which
   columns have been dropped. Assume predictor D has been dropped, I continue
   with this model: X~A+B+C+E
   3.

   Subsequently I need to check whether there are variables (or groups of
   variables) which *strongly* corrrelate to each other. I included the
   function vif.mer (developed by Austin F. Frank and available at:
   https://raw.github.com/aufrank/R-hacks/master/mer-utils.R) in my script,
   and when applying this function to my reduced model, I got vif values for
   each of the variables. When vif>5 for a predictor, it probably should be
   removed. In case multiple variables have a vif>5, I first remove the
   predictor with the highest vif, then re-run lmer en vif.mer. I remove again
   the predictor with highest vif (if one or more predictors have still a
   vif>5), and I repeat this until none of the remaining predictors has a
   vif>5. In case I got a warning "Model failed to converge" in the larger
   model(s), this warning does not appear any longer in the 'cleaned' model.
   4.

   Assume the following predictors have survived: A, B en E. Now I want to
   find the combination of predictors that gives the smallest AIC. For three
   predictors it is easy to try all combinations, but if it would have been 10
   predictors, manually trying all combinations would be time-consuming. So I
   used the function fitLMER.fnc from the LMERConvenienceFunctions package.
   This function back fit fixed effects, forward fit random effects, and
   re-back fit fixed effects. I consider the model given by fitLMER.fnc as the
   right one.

I am not an expert in mixed-effects models and have struggled with model
selection. I found the procedure which I decribed working, but I would
really be appreciate to hear whether the procedure is sound, or whether
there are better alternatives.

Best,

Wilbert

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Fri Feb 19 15:35:08 2016
From: simon0098 at yahoo.com (Zahra Samadi)
Date: Fri, 19 Feb 2016 06:35:08 -0800
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>
Message-ID: <1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>

Adriana, 
My GUI file is a function returning a window. This function is named buildGui(). How should I create this batch file using the piece of code you've written?


	[[alternative HTML version deleted]]


From doug45290 at yahoo.com  Fri Feb 19 17:12:29 2016
From: doug45290 at yahoo.com (D Wolf)
Date: Fri, 19 Feb 2016 16:12:29 +0000 (UTC)
Subject: [R] Reading a datetime vector
In-Reply-To: <CA+8X3fUSAuNmpSL7tfjnu4fS+CtM-NU5L6aC21jvJjyLypt3Gg@mail.gmail.com>
References: <CA+8X3fUSAuNmpSL7tfjnu4fS+CtM-NU5L6aC21jvJjyLypt3Gg@mail.gmail.com>
Message-ID: <503667207.6990941.1455898349505.JavaMail.yahoo@mail.yahoo.com>

Hello Jim,
I ran str() on the vector and it returned character:str("DF_exp.xlsx")?chr "DF_exp.xlsx"
I tried?df2_TZ$DateTimeStamp <- strptime(as.Date(as.character(df2_TZ$DateTimeStamp, format = "%m/%d/%Y %H:%M", tz = "GMT"))), which produced an error:?Error in charToDate(x) :?? character string is not in a standard unambiguous formatIn Excel, the column is formatted to m/d/yyyy h:mm
Removing %S from these linesdf2_TZ$DateTimeStamp = as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M", tz="GMT")?df2_TZ$DateTimeStamp = as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M")
made the column NA

Thank You,Doug Wolfinger


 

    On Friday, February 19, 2016 1:35 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Doug,For one thing, you may be using the wrong format. Your example format has no seconds field. The other thing to watch is whether the data are in %m/%d/%Y or %d/%m/%Y date format. If the latter, you would probably get that error on dates like 19/02/2016.
Jim

On Fri, Feb 19, 2016 at 8:12 AM, D Wolf via R-help <r-help at r-project.org> wrote:

Hello,I am trying to read a data frame column named DateTimeStamp. The time is in GMT in this format: 1/4/2013 23:30
require(xlsx)
df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")

It's good to that line. But these three lines, which makes the dataframe, converts the column's values to NA:df2_TZ$DateTimeStamp = as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")

and...?df2_TZ$DateTimeStamp = as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")

and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format = "%m/%d/%Y %H:%M:%S")

This line returns and error...df2_TZ$DateTimeStamp = as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
"Error in charToDate(x) :?? character string is not in a standard unambiguous format"
Additionally, I need to convert from GMT to North American time zones, and I think the advice on this page would be good for that:?http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
My ultimate goal is to write an R program that finds data in another variable in df2_TZ that corresponds to a date and time that match up with the date and time in another data frame. For now, any help reading the column would be much appreciated.
Thank You,Doug
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



  
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Feb 19 20:48:08 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 19 Feb 2016 14:48:08 -0500
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
Message-ID: <CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>

That means that points have been assigned to the wrong groups. This
may readily happen with a clustering method like cluster::clara() that
uses a subset of the data to cluster a dataset too large to analyze as
a unit. Negative silhouette numbers strongly suggest that your
clustering parameters should be changed.

Sarah

On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi,
>
>
> We know that clustering methods in R assign observations to the closest medoids. Hence, it is supposed to be the closest cluster each observation can have. So, I wonder how it is possible to have negative values of silhouette , while we are supposedly assign each observation to the closest cluster and the formula in silhouette method cannot get negative?
>
>
> Behnam.
>


From sarah.goslee at gmail.com  Fri Feb 19 20:58:50 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 19 Feb 2016 14:58:50 -0500
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
	<D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
Message-ID: <CAM_vjunVforkEJQ2EmN2+2fcCd+coRwDa=1tggzUgCPt8bWCiA@mail.gmail.com>

You need to think more carefully about the details of the clara() method.

The algorithm draws repeated samples of sampsize from the larger
dataset, as specified by the arguments to the function.
It clusters each sample in turn, and saves the best one.
It uses the medoids from the best one to assign all of the points to a cluster.

But because the clustering is based on a subsample, it may not be
representative of the dataset as a whole, and may not provide a good
clustering overall. Just because it clusters the subsample well,
doesn't mean it clusters the entirety. The details section of the help
describes this, and the book references goes into more detail.

Sarah



On Fri, Feb 19, 2016 at 2:55 PM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi Sarah,
>
> Thank you for the response. But it is said in its description that after
> each run (sample), each observation in the whole dataset is assigned to the
> closest cluster. So how is it possible for one observation to be wrongly
> allocated, even with clara?
>
> Behnam
>
> Behnam
>
>
>
>
> On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee"
> <sarah.goslee at gmail.com> wrote:
>
> That means that points have been assigned to the wrong groups. This
> may readily happen with a clustering method like cluster::clara() that
> uses a subset of the data to cluster a dataset too large to analyze as
> a unit. Negative silhouette numbers strongly suggest that your
> clustering parameters should be changed.
>
> Sarah
>
> On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
> <Behnam.ABABAEI at limagrain.com> wrote:
>> Hi,
>>
>>
>> We know that clustering methods in R assign observations to the closest
>> medoids. Hence, it is supposed to be the closest cluster each observation
>> can have. So, I wonder how it is possible to have negative values of
>> silhouette , while we are supposedly assign each observation to the closest
>> cluster and the formula in silhouette method cannot get negative?
>>
>>
>> Behnam.
>>


From sarah.goslee at gmail.com  Fri Feb 19 21:22:22 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 19 Feb 2016 15:22:22 -0500
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <AM3PR06MB099448206FD4337C1758B8D681A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
	<D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
	<CAM_vjunVforkEJQ2EmN2+2fcCd+coRwDa=1tggzUgCPt8bWCiA@mail.gmail.com>
	<AM3PR06MB099448206FD4337C1758B8D681A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
Message-ID: <CAM_vju=yNMM3QMdwXW9je1n1-Dkgxzeqg5rM-HGJbpt5Uf8p3Q@mail.gmail.com>

Ah, my guess about the confusion was wrong, then. You're
misunderstanding silhouette() instead.

>From ?silhouette:

     Observations with a large s(i) (almost 1) are very well clustered,
     a small s(i) (around 0) means that the observation lies between
     two clusters, and observations with a negative s(i) are probably
     placed in the wrong cluster.


In more detail, they're looking at different things.
clara() assigns each point to a cluster based on the distance to the
nearest medoid.

silhouette() does something different: instead of comparing the
distances to the closest medoid and the next closest medoid, which is
what you seem to be assuming, silhouette() looks at the mean distance
to ALL other points assigned to that cluster, vs the mean distance to
all points in other clusters. The distance to the medoid is
irrelevant, except as it is one of the points in that cluster.

So a negative silhouette value is entirely possible, and means that
the cluster produced doesn't represent the dataset very well.



On Fri, Feb 19, 2016 at 3:04 PM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Sarah,
> sorry for taking up your time.
>
> I totally agree with you about how it works. But please let's take a look at this part of the description:
>
> "Once k representative objects have been selected from the sub-dataset, each observation of the entire dataset is assigned to the nearest medoid. The mean (equivalent to the sum) of the dissimilarities of the observations to their closest medoid is used as a measure of the quality of the clustering. The sub-dataset for which the mean (or sum) is minimal, is retained. A further analysis is carried out on the final partition."
>
> It says each observation is finally assigned to the closest medoid. The whole clustering process may be imperfect in terms of isolation of clusters, but each observation is already assigned to the closest one and according to the silhouette formula, the silhouette value cannot be negative, as a must be always less than b.
>
> Regards,
> Behnam.
>
> ________________________________________
> From: Sarah Goslee <sarah.goslee at gmail.com>
> Sent: 19 February 2016 20:58
> To: ABABAEI, Behnam
> Cc: r-help at r-project.org
> Subject: Re: [R] How a clustering algorithm in R can end up with negative silhouette values?
>
> You need to think more carefully about the details of the clara() method.
>
> The algorithm draws repeated samples of sampsize from the larger
> dataset, as specified by the arguments to the function.
> It clusters each sample in turn, and saves the best one.
> It uses the medoids from the best one to assign all of the points to a cluster.
>
> But because the clustering is based on a subsample, it may not be
> representative of the dataset as a whole, and may not provide a good
> clustering overall. Just because it clusters the subsample well,
> doesn't mean it clusters the entirety. The details section of the help
> describes this, and the book references goes into more detail.
>
> Sarah
>
>
>
> On Fri, Feb 19, 2016 at 2:55 PM, ABABAEI, Behnam
> <Behnam.ABABAEI at limagrain.com> wrote:
>> Hi Sarah,
>>
>> Thank you for the response. But it is said in its description that after
>> each run (sample), each observation in the whole dataset is assigned to the
>> closest cluster. So how is it possible for one observation to be wrongly
>> allocated, even with clara?
>>
>> Behnam
>>
>> Behnam
>>
>>
>>
>>
>> On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee"
>> <sarah.goslee at gmail.com> wrote:
>>
>> That means that points have been assigned to the wrong groups. This
>> may readily happen with a clustering method like cluster::clara() that
>> uses a subset of the data to cluster a dataset too large to analyze as
>> a unit. Negative silhouette numbers strongly suggest that your
>> clustering parameters should be changed.
>>
>> Sarah
>>
>> On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
>> <Behnam.ABABAEI at limagrain.com> wrote:
>>> Hi,
>>>
>>>
>>> We know that clustering methods in R assign observations to the closest
>>> medoids. Hence, it is supposed to be the closest cluster each observation
>>> can have. So, I wonder how it is possible to have negative values of
>>> silhouette , while we are supposedly assign each observation to the closest
>>> cluster and the formula in silhouette method cannot get negative?
>>>
>>>
>>> Behnam.
>>>


From sarah.goslee at gmail.com  Fri Feb 19 20:46:30 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 19 Feb 2016 14:46:30 -0500
Subject: [R] Why CLARA clustering method does not give the same classes
 as when I do clustering manually?
In-Reply-To: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
References: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
Message-ID: <CAM_vjum8kiGFhc4BvDgrhqcNsEdK0KUFnyBd2rSiX1-Sr6b8dg@mail.gmail.com>

clara() is a version of pam() adapted to use large datasets.

pam() uses the entire dataset, and should give results identical to
your manual procedure, or nearly so. clara() works on subsets of the
data, so it may give a slightly different result each time you run it.

The default parameters for clara() are very small, so you can get
substantially different results from run to run on a large dataset if
you don't change them.

Sarah

On Fri, Feb 19, 2016 at 6:30 AM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi,
>
>
> I am using CLARA (in 'cluster' package). This method is supposed to assign each observation to the closest 'medoid'. But when I calculate the distance of medoids and observations manually and assign them manually, the results are slightly different (1-2 percent of occurrence probability). Does anyone know how clara calculates dissimilarities and why I get different clustering results?
>
>
> Behnam.


From dmck at u.washington.edu  Fri Feb 19 20:42:04 2016
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 19 Feb 2016 11:42:04 -0800
Subject: [R] mixed-effects models with (g)lmer in R and model selection
In-Reply-To: <CAE-DUcoBdFbpZD1VD9ySmjxQj3D0XKrGBPjreTK=+Ent=RP8Nw@mail.gmail.com>
References: <CAE-DUcoBdFbpZD1VD9ySmjxQj3D0XKrGBPjreTK=+Ent=RP8Nw@mail.gmail.com>
Message-ID: <8CB3B78F-2886-4E2C-BB71-B5216C7EA2AA@u.washington.edu>

This is a complicated and subtle statistical issue, not an R question, the latter being the purpose of this list.  There are people on the list who could give you literate answers,
to be sure, but a statistically oriented list would be a better match.

e.g., 

http://stats.stackexchange.com/


> On Feb 19, 2016, at 5:01 AM, Wilbert Heeringa <wjheeringa at gmail.com> wrote:
> 
> Dear all,
> 
> Mixed-effects models are wonderful for analyzing data, but it is always a
> hassle to find the best model, i.e. the model with the lowest AIC,
> especially when the number of predictor variables is large.
> 
> Presently when trying to find the right model, I perform the following
> steps:
> 
>   1.
> 
>   Start with a model containing all predictors. Assuming dependent
>   variable X and predictors A, B, C, D, E, I start with: X~A+B+C+D+E
>   2.
> 
>   Lmer warns that is has dropped columns/coefficients. These are variables
>   which have a *perfect* correlation with any of the other variables or
>   with a combination of variables. With summary() it can be found which
>   columns have been dropped. Assume predictor D has been dropped, I continue
>   with this model: X~A+B+C+E
>   3.
> 
>   Subsequently I need to check whether there are variables (or groups of
>   variables) which *strongly* corrrelate to each other. I included the
>   function vif.mer (developed by Austin F. Frank and available at:
>   https://raw.github.com/aufrank/R-hacks/master/mer-utils.R) in my script,
>   and when applying this function to my reduced model, I got vif values for
>   each of the variables. When vif>5 for a predictor, it probably should be
>   removed. In case multiple variables have a vif>5, I first remove the
>   predictor with the highest vif, then re-run lmer en vif.mer. I remove again
>   the predictor with highest vif (if one or more predictors have still a
>   vif>5), and I repeat this until none of the remaining predictors has a
>   vif>5. In case I got a warning "Model failed to converge" in the larger
>   model(s), this warning does not appear any longer in the 'cleaned' model.
>   4.
> 
>   Assume the following predictors have survived: A, B en E. Now I want to
>   find the combination of predictors that gives the smallest AIC. For three
>   predictors it is easy to try all combinations, but if it would have been 10
>   predictors, manually trying all combinations would be time-consuming. So I
>   used the function fitLMER.fnc from the LMERConvenienceFunctions package.
>   This function back fit fixed effects, forward fit random effects, and
>   re-back fit fixed effects. I consider the model given by fitLMER.fnc as the
>   right one.
> 
> I am not an expert in mixed-effects models and have struggled with model
> selection. I found the procedure which I decribed working, but I would
> really be appreciate to hear whether the procedure is sound, or whether
> there are better alternatives.
> 
> Best,
> 
> Wilbert
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From Behnam.ABABAEI at limagrain.com  Fri Feb 19 20:55:18 2016
From: Behnam.ABABAEI at limagrain.com (ABABAEI, Behnam)
Date: Fri, 19 Feb 2016 19:55:18 +0000
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>,
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
Message-ID: <D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>

Hi Sarah,

Thank you for the response. But it is said in its description that after each run (sample), each observation in the whole dataset is assigned to the closest cluster. So how is it possible for one observation to be wrongly allocated, even with clara?

Behnam

Behnam



On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee" <sarah.goslee at gmail.com<mailto:sarah.goslee at gmail.com>> wrote:

That means that points have been assigned to the wrong groups. This
may readily happen with a clustering method like cluster::clara() that
uses a subset of the data to cluster a dataset too large to analyze as
a unit. Negative silhouette numbers strongly suggest that your
clustering parameters should be changed.

Sarah

On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi,
>
>
> We know that clustering methods in R assign observations to the closest medoids. Hence, it is supposed to be the closest cluster each observation can have. So, I wonder how it is possible to have negative values of silhouette , while we are supposedly assign each observation to the closest cluster and the formula in silhouette method cannot get negative?
>
>
> Behnam.
>

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Fri Feb 19 23:36:02 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sat, 20 Feb 2016 00:36:02 +0200
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>
References: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>
	<1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>
Message-ID: <CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>

Your function, buildGui(), what does it use, Tcl/Tk or something else?
If it's Tcl/Tk, I believe you need a normal R console opened. My .bat file
only works for a command line, which is fine if the user interface opens up
in a webpage, but I'm pretty sure it doesn\t work with Tcl/Tk.
What kind of window does your function return?
Adrian

On Fri, Feb 19, 2016 at 4:35 PM, Zahra Samadi <simon0098 at yahoo.com> wrote:

> Adriana,
> My GUI file is a function returning a window. This function is named
> buildGui(). How should I create this batch file using the piece of code
> you've written?
>
> ------------------------------
> * From: * Adrian Du?a <dusa.adrian at unibuc.ro>;
> * To: * Greg Snow <538280 at gmail.com>;
> * Cc: * simon0098 at yahoo.com <simon0098 at yahoo.com>; r-help at r-project.org <
> r-help at r-project.org>;
> * Subject: * Re: [R] How to create an executable file from R GUI?
> * Sent: * Thu, Feb 18, 2016 9:03:52 PM
>
> Simon, Greg,
>
> That is the very reason why I've given up on Tck/Tk, in favor of shiny.
> The user interface opens up in a webpage, without opening the normal R
> console (it only opens a Terminal window).
>
> To exemplify, package QCAGUI has a function called runGUI(), and on
> Windows it's a simple matter of creating a .bat file,
> which for my user interface it only contains this:
>
> CLS
>
> TITLE QCA Qualitative Comparative Analysis
>
> C:/PROGRA~1/R/R-3.2.3/bin/R.exe --slave --no-restore -e
> "setwd('D:/');QCAGUI::runGUI()"
>
>
> The double click on the .bat file, and that's it.
> I hope it helps,
> Adrian
>
>
>
> On Thu, Feb 18, 2016 at 7:24 PM, Greg Snow <538280 at gmail.com> wrote:
>
>> To give a full answer we need some more detail from you.  For example
>> what operating system are you on? what do you mean by "users click on
>> it"? and at what point do you want them to click (after running R,
>> when looking at the desktop, etc.)
>>
>> But to help get you started you may want to look at the help page
>> `?Startup` which tells you all the things that R does as it starts up
>> and how to have it run commands automatically as it is starting up.
>>
>> I have created some GUI examples in the past that clients then wanted
>> to have on their own computer to play with and demonstrate to others.
>> I usually would install R on their machine for them and create a
>> shortcut on the desktop (these were all MS Windows computers) that
>> pointed to the standard R executable, but started in a specific
>> directory/folder.  Then in that folder I created a ".Rprofile" file
>> with the commands to load in the appropriate data and packages and run
>> the gui demonstration.  The user could then double click on the
>> shortcut on the desktop and 2 windows would pop up (the regular R
>> interface and my gui demo), I instructed the client to just minimize
>> and ignore the regular R window and they were then able to use my demo
>> and then close everything when they were finished.  You could do
>> something similar (but exactly how will differ between Windows, Mac,
>> and Linux computers).
>>
>> On Thu, Feb 18, 2016 at 9:27 AM, simon0098--- via R-help
>> <r-help at r-project.org> wrote:
>> > Hi,
>> > I've created a GUI using RGtk2 package. How can I make an executable
>> file from my R script so that users click on it and the GUI appears for
>> them?
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From fanjianling at gmail.com  Sat Feb 20 00:30:28 2016
From: fanjianling at gmail.com (Jianling Fan)
Date: Fri, 19 Feb 2016 17:30:28 -0600
Subject: [R] mixed-effects models with (g)lmer in R and model selection
In-Reply-To: <CAE-DUcoBdFbpZD1VD9ySmjxQj3D0XKrGBPjreTK=+Ent=RP8Nw@mail.gmail.com>
References: <CAE-DUcoBdFbpZD1VD9ySmjxQj3D0XKrGBPjreTK=+Ent=RP8Nw@mail.gmail.com>
Message-ID: <CAJ7mryLNPQyPStpyb8B05QGWo4Kgy0S054iXCpxwXVtHJ8Z0kg@mail.gmail.com>

Hello, Wilbert,

You did give a good procedure for lme model selection! thanks! I learn some.
I am also working on similar problem recently, maybe you can take a
look at "glmmLasso" package, which allows model selection in
generalized linear mixed effects models using the LASSO shrinkage
method.


Regards,

Jianling

On 19 February 2016 at 07:01, Wilbert Heeringa <wjheeringa at gmail.com> wrote:
> Dear all,
>
> Mixed-effects models are wonderful for analyzing data, but it is always a
> hassle to find the best model, i.e. the model with the lowest AIC,
> especially when the number of predictor variables is large.
>
> Presently when trying to find the right model, I perform the following
> steps:
>
>    1.
>
>    Start with a model containing all predictors. Assuming dependent
>    variable X and predictors A, B, C, D, E, I start with: X~A+B+C+D+E
>    2.
>
>    Lmer warns that is has dropped columns/coefficients. These are variables
>    which have a *perfect* correlation with any of the other variables or
>    with a combination of variables. With summary() it can be found which
>    columns have been dropped. Assume predictor D has been dropped, I continue
>    with this model: X~A+B+C+E
>    3.
>
>    Subsequently I need to check whether there are variables (or groups of
>    variables) which *strongly* corrrelate to each other. I included the
>    function vif.mer (developed by Austin F. Frank and available at:
>    https://raw.github.com/aufrank/R-hacks/master/mer-utils.R) in my script,
>    and when applying this function to my reduced model, I got vif values for
>    each of the variables. When vif>5 for a predictor, it probably should be
>    removed. In case multiple variables have a vif>5, I first remove the
>    predictor with the highest vif, then re-run lmer en vif.mer. I remove again
>    the predictor with highest vif (if one or more predictors have still a
>    vif>5), and I repeat this until none of the remaining predictors has a
>    vif>5. In case I got a warning "Model failed to converge" in the larger
>    model(s), this warning does not appear any longer in the 'cleaned' model.
>    4.
>
>    Assume the following predictors have survived: A, B en E. Now I want to
>    find the combination of predictors that gives the smallest AIC. For three
>    predictors it is easy to try all combinations, but if it would have been 10
>    predictors, manually trying all combinations would be time-consuming. So I
>    used the function fitLMER.fnc from the LMERConvenienceFunctions package.
>    This function back fit fixed effects, forward fit random effects, and
>    re-back fit fixed effects. I consider the model given by fitLMER.fnc as the
>    right one.
>
> I am not an expert in mixed-effects models and have struggled with model
> selection. I found the procedure which I decribed working, but I would
> really be appreciate to hear whether the procedure is sound, or whether
> there are better alternatives.
>
> Best,
>
> Wilbert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Feb 20 02:59:00 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 19 Feb 2016 17:59:00 -0800
Subject: [R] mixed-effects models with (g)lmer in R and model selection
In-Reply-To: <8CB3B78F-2886-4E2C-BB71-B5216C7EA2AA@u.washington.edu>
References: <CAE-DUcoBdFbpZD1VD9ySmjxQj3D0XKrGBPjreTK=+Ent=RP8Nw@mail.gmail.com>
	<8CB3B78F-2886-4E2C-BB71-B5216C7EA2AA@u.washington.edu>
Message-ID: <CAGxFJbTa4oT0ehYZ8XZviYPd1yA9LnN2ays3=8sW9K0UWuBV3g@mail.gmail.com>

Absolutely!  Even more, consult a local expert in applying mixed effects
models. The op's strategy sounded to me like a prescription to produce
irreproducible results (due to over fitting).

Cheers,
Bert



On Friday, February 19, 2016, Don McKenzie <dmck at u.washington.edu> wrote:

> This is a complicated and subtle statistical issue, not an R question, the
> latter being the purpose of this list.  There are people on the list who
> could give you literate answers,
> to be sure, but a statistically oriented list would be a better match.
>
> e.g.,
>
> http://stats.stackexchange.com/
>
>
> > On Feb 19, 2016, at 5:01 AM, Wilbert Heeringa <wjheeringa at gmail.com
> <javascript:;>> wrote:
> >
> > Dear all,
> >
> > Mixed-effects models are wonderful for analyzing data, but it is always a
> > hassle to find the best model, i.e. the model with the lowest AIC,
> > especially when the number of predictor variables is large.
> >
> > Presently when trying to find the right model, I perform the following
> > steps:
> >
> >   1.
> >
> >   Start with a model containing all predictors. Assuming dependent
> >   variable X and predictors A, B, C, D, E, I start with: X~A+B+C+D+E
> >   2.
> >
> >   Lmer warns that is has dropped columns/coefficients. These are
> variables
> >   which have a *perfect* correlation with any of the other variables or
> >   with a combination of variables. With summary() it can be found which
> >   columns have been dropped. Assume predictor D has been dropped, I
> continue
> >   with this model: X~A+B+C+E
> >   3.
> >
> >   Subsequently I need to check whether there are variables (or groups of
> >   variables) which *strongly* corrrelate to each other. I included the
> >   function vif.mer (developed by Austin F. Frank and available at:
> >   https://raw.github.com/aufrank/R-hacks/master/mer-utils.R) in my
> script,
> >   and when applying this function to my reduced model, I got vif values
> for
> >   each of the variables. When vif>5 for a predictor, it probably should
> be
> >   removed. In case multiple variables have a vif>5, I first remove the
> >   predictor with the highest vif, then re-run lmer en vif.mer. I remove
> again
> >   the predictor with highest vif (if one or more predictors have still a
> >   vif>5), and I repeat this until none of the remaining predictors has a
> >   vif>5. In case I got a warning "Model failed to converge" in the larger
> >   model(s), this warning does not appear any longer in the 'cleaned'
> model.
> >   4.
> >
> >   Assume the following predictors have survived: A, B en E. Now I want to
> >   find the combination of predictors that gives the smallest AIC. For
> three
> >   predictors it is easy to try all combinations, but if it would have
> been 10
> >   predictors, manually trying all combinations would be time-consuming.
> So I
> >   used the function fitLMER.fnc from the LMERConvenienceFunctions
> package.
> >   This function back fit fixed effects, forward fit random effects, and
> >   re-back fit fixed effects. I consider the model given by fitLMER.fnc
> as the
> >   right one.
> >
> > I am not an expert in mixed-effects models and have struggled with model
> > selection. I found the procedure which I decribed working, but I would
> > really be appreciate to hear whether the procedure is sound, or whether
> > there are better alternatives.
> >
> > Best,
> >
> > Wilbert
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From javanmard.majid at gmail.com  Sat Feb 20 11:33:31 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Sat, 20 Feb 2016 14:03:31 +0330
Subject: [R] Is there any simple guide for spatialVx R package !?
Message-ID: <CAA0OCnsF8JM5xpi9smXG52J8XWf=8NB=s+VPkY0B=Jj9vqvu4Q@mail.gmail.com>

I was searching a windows-based software to execute CRA(contiguous rain
area) method, I failed, but I found a R package and its example to execute
this method but I encountered some ambiguities !!

here is the example code :

data(pert000)
data(pert004)
data(ICPg240Locs)

hold <- make.SpatialVx(pert000, pert004,
loc=ICPg240Locs, projection=TRUE, map=TRUE, loc.byrow = TRUE,
field.type="Precipitation", units="mm/h",
data.name=c("ICP Perturbed Cases", "pert000", "pert004"))

look <- FeatureFinder(hold, smoothpar=10.5, thresh = 5)
plot(look)

look2 <- minboundmatch(look, verbose = TRUE)
plot(look2)

craer( look2 )

1)

What kind of dataset should I import here !!? I have an observation and
forecast files contains Lat/Lon and Value columns(observation 9 rows,
forecast 16 rows).

2)

Should I interpolate these files to the same bound by Arcmap ?!


I really cant understand the tutorial of SpatialVx package, I appreciate
 if someone could response on this issue !!

Many Thanks
Majid Javanmard

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Sat Feb 20 07:50:01 2016
From: simon0098 at yahoo.com (Zahra Samadi)
Date: Fri, 19 Feb 2016 22:50:01 -0800
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
Message-ID: <1455951001.48910.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>

My function returns a RGtk2 window. It's not important if my GUI opens in a browser, I just want to have a file that when clicked, my GUI opens.


	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Sat Feb 20 13:34:44 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sat, 20 Feb 2016 14:34:44 +0200
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <1455951001.48910.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>
References: <CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
	<1455951001.48910.YahooMailAndroidMobile@web164004.mail.gq1.yahoo.com>
Message-ID: <CAJ=0CtBQ6q4GJv1uNZy4t09TNUXhMOnQk_V8_H8RyW3Tq6iP5Q@mail.gmail.com>

I don't know about RGtk2, never tried it, but I assume it is similar to
Tcl/Tk situation: you need to open an R console to make it work.
My approach works, only because I am using the package shiny, and R's web
server can be started via a script in the terminal.
I might be wrong of course, but I haven't been able to start a GUI from a
script, other than using a webpage,

Package shiny is very nice, and since it can be started with a script, it
means that one can also use the normal R console in parallel, if needed.
Otherwise, if started from the R console, R will be busy listening to the
web server: it's either R, or the GUI, but not both in the same time.


On Sat, Feb 20, 2016 at 8:50 AM, Zahra Samadi <simon0098 at yahoo.com> wrote:

> My function returns a RGtk2 window. It's not important if my GUI opens in
> a browser, I just want to have a file that when clicked, my GUI opens.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Sat Feb 20 13:41:35 2016
From: simon0098 at yahoo.com (simon0098 at yahoo.com)
Date: Sat, 20 Feb 2016 04:41:35 -0800
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJ=0CtBQ6q4GJv1uNZy4t09TNUXhMOnQk_V8_H8RyW3Tq6iP5Q@mail.gmail.com>
Message-ID: <1455972095.67807.YahooMailAndroidMobile@web164003.mail.gq1.yahoo.com>

I tried Shiny using this link: 

oddhypothesis.blogspot.co.uk/2014/04/deploying-self-contained-r-apps-to.html

But I got the following error in R portable:
Fatal error: unable to open base package
I checked for base package but R 3.2.3 ( latest version) doesn't have updates for this package! So I decided to look for alternative method.


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Feb 20 13:46:43 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 20 Feb 2016 13:46:43 +0100
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
References: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>
	<1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>
	<CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
Message-ID: <BD75D26C-41FC-4395-94C2-9CD179307C44@gmail.com>

It's quite platform dependent, but this idea works for tcl/tk on Mac. I don't think it would be too hard to do similar things on Linux, Windows may be a bigger challenge (or not).

Peter-Dalgaards-MacBook-Air:tmp pd$ cat foo.app
#!/usr/bin/Rscript
library(tcltk)
demo(tkfaq)
tkwait.variable("exit")

Make it executable (chmod +x foo.app) and you can double-click it in the Finder. (Notice that as written, there is nothing to shut down the tkwait loop, so you'll have to force quit it.)

Peter D.

> On 19 Feb 2016, at 23:36 , Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> 
> Your function, buildGui(), what does it use, Tcl/Tk or something else?
> If it's Tcl/Tk, I believe you need a normal R console opened. My .bat file
> only works for a command line, which is fine if the user interface opens up
> in a webpage, but I'm pretty sure it doesn\t work with Tcl/Tk.
> What kind of window does your function return?
> Adrian
> 
> On Fri, Feb 19, 2016 at 4:35 PM, Zahra Samadi <simon0098 at yahoo.com> wrote:
> 
>> Adriana,
>> My GUI file is a function returning a window. This function is named
>> buildGui(). How should I create this batch file using the piece of code
>> you've written?
>> 
>> ------------------------------
>> * From: * Adrian Du?a <dusa.adrian at unibuc.ro>;
>> * To: * Greg Snow <538280 at gmail.com>;
>> * Cc: * simon0098 at yahoo.com <simon0098 at yahoo.com>; r-help at r-project.org <
>> r-help at r-project.org>;
>> * Subject: * Re: [R] How to create an executable file from R GUI?
>> * Sent: * Thu, Feb 18, 2016 9:03:52 PM
>> 
>> Simon, Greg,
>> 
>> That is the very reason why I've given up on Tck/Tk, in favor of shiny.
>> The user interface opens up in a webpage, without opening the normal R
>> console (it only opens a Terminal window).
>> 
>> To exemplify, package QCAGUI has a function called runGUI(), and on
>> Windows it's a simple matter of creating a .bat file,
>> which for my user interface it only contains this:
>> 
>> CLS
>> 
>> TITLE QCA Qualitative Comparative Analysis
>> 
>> C:/PROGRA~1/R/R-3.2.3/bin/R.exe --slave --no-restore -e
>> "setwd('D:/');QCAGUI::runGUI()"
>> 
>> 
>> The double click on the .bat file, and that's it.
>> I hope it helps,
>> Adrian
>> 
>> 
>> 
>> On Thu, Feb 18, 2016 at 7:24 PM, Greg Snow <538280 at gmail.com> wrote:
>> 
>>> To give a full answer we need some more detail from you.  For example
>>> what operating system are you on? what do you mean by "users click on
>>> it"? and at what point do you want them to click (after running R,
>>> when looking at the desktop, etc.)
>>> 
>>> But to help get you started you may want to look at the help page
>>> `?Startup` which tells you all the things that R does as it starts up
>>> and how to have it run commands automatically as it is starting up.
>>> 
>>> I have created some GUI examples in the past that clients then wanted
>>> to have on their own computer to play with and demonstrate to others.
>>> I usually would install R on their machine for them and create a
>>> shortcut on the desktop (these were all MS Windows computers) that
>>> pointed to the standard R executable, but started in a specific
>>> directory/folder.  Then in that folder I created a ".Rprofile" file
>>> with the commands to load in the appropriate data and packages and run
>>> the gui demonstration.  The user could then double click on the
>>> shortcut on the desktop and 2 windows would pop up (the regular R
>>> interface and my gui demo), I instructed the client to just minimize
>>> and ignore the regular R window and they were then able to use my demo
>>> and then close everything when they were finished.  You could do
>>> something similar (but exactly how will differ between Windows, Mac,
>>> and Linux computers).
>>> 
>>> On Thu, Feb 18, 2016 at 9:27 AM, simon0098--- via R-help
>>> <r-help at r-project.org> wrote:
>>>> Hi,
>>>> I've created a GUI using RGtk2 package. How can I make an executable
>>> file from my R script so that users click on it and the GUI appears for
>>> them?
>>>> 
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Gregory (Greg) L. Snow Ph.D.
>>> 538280 at gmail.com
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> 
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>> 
> 
> 
> 
> -- 
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sarah.goslee at gmail.com  Sat Feb 20 14:12:25 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 20 Feb 2016 08:12:25 -0500
Subject: [R] Is there any simple guide for spatialVx R package !?
In-Reply-To: <CAA0OCnsF8JM5xpi9smXG52J8XWf=8NB=s+VPkY0B=Jj9vqvu4Q@mail.gmail.com>
References: <CAA0OCnsF8JM5xpi9smXG52J8XWf=8NB=s+VPkY0B=Jj9vqvu4Q@mail.gmail.com>
Message-ID: <CAM_vjunFG5fc86268Bv+09JME6racaxP1cntLULX8C8sRnLAng@mail.gmail.com>

The data commands in the example load sample data. You can run those lines
in R and look at what the sample data are set up like, if the explanations
aren't clear to you. There may also be help files specifically for the
sample data.

There's some information at
https://www.ral.ucar.edu/projects/icp/SpatialVx/
but sadly no tutorial. Still, those folks are probably better to contact
for package-specific questions.

Sarah

On Saturday, February 20, 2016, Majid Javanmard <javanmard.majid at gmail.com>
wrote:

> I was searching a windows-based software to execute CRA(contiguous rain
> area) method, I failed, but I found a R package and its example to execute
> this method but I encountered some ambiguities !!
>
> here is the example code :
>
> data(pert000)
> data(pert004)
> data(ICPg240Locs)
>
> hold <- make.SpatialVx(pert000, pert004,
> loc=ICPg240Locs, projection=TRUE, map=TRUE, loc.byrow = TRUE,
> field.type="Precipitation", units="mm/h",
> data.name=c("ICP Perturbed Cases", "pert000", "pert004"))
>
> look <- FeatureFinder(hold, smoothpar=10.5, thresh = 5)
> plot(look)
>
> look2 <- minboundmatch(look, verbose = TRUE)
> plot(look2)
>
> craer( look2 )
>
> 1)
>
> What kind of dataset should I import here !!? I have an observation and
> forecast files contains Lat/Lon and Value columns(observation 9 rows,
> forecast 16 rows).
>
> 2)
>
> Should I interpolate these files to the same bound by Arcmap ?!
>
>
> I really cant understand the tutorial of SpatialVx package, I appreciate
>  if someone could response on this issue !!
>
> Many Thanks
> Majid Javanmard
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From goheer_ at hotmail.com  Sat Feb 20 15:14:26 2016
From: goheer_ at hotmail.com (Arslan Rehman)
Date: Sat, 20 Feb 2016 09:14:26 -0500
Subject: [R] chartSeries requires an xtsible object
Message-ID: <BLU174-W182E473C66DF4CB85CF56C82A10@phx.gbl>

Hello, I have a txt file that I import and want to plot a chartSeries of data.My code plus the error I receive are below: (I have installed packages TTR, fBasics, zoo, quantmod, xts)
> yt=read.table("/Users/Arslan/Documents/Econ 4140/ARModel.txt",header=T)> head(yt)       ytsim1  3.04497412 -0.95401593  0.25043094 -0.69580895  1.95196236  1.4400745> tail(yt)          ytsim994  0.46729230995 -0.19794905996  2.25884772997  0.91227832998 -0.02632859999 -0.66917710> chartSeries(yt)Error in try.xts(x, error = "chartSeries requires an xtsible object") :   chartSeries requires an xtsible object
how do I perform chartSeries command?
Thank you,Arslan 		 	   		  
	[[alternative HTML version deleted]]


From abdel.halloway at gmail.com  Sat Feb 20 18:01:00 2016
From: abdel.halloway at gmail.com (Abdel Halloway)
Date: Sat, 20 Feb 2016 11:01:00 -0600
Subject: [R] Problems with the deSolve package
In-Reply-To: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>
References: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>
Message-ID: <CANKjaMfwdqPXnd=DbHCJkgb5c6YpdmbZx9SA3Kz2CsQcdxdZMw@mail.gmail.com>

I think your parameters are off. If you look at the simul data frame, it
gives you a bunch of NaNs after the first initialization. If you put lower
the timesteps s.t.

> times<-seq(0,200, by=0.01)

it begins to run but soon your values diverge, i1 & i2 going negative while
i12 goes way high. Not sure what you are modeling but I assume those values
aren't to be like that. Try again with different parameters and see.

On Fri, Feb 19, 2016 at 2:42 AM, Alexandre Suire <alexandresuire at hotmail.fr>
wrote:

> Hello R-users,
>
> I'm trying to build a SIR-like model under R,
> using the "deSolve" package. I'm trying to do simulations of its dynamic
>  over time, with three differential equations. I'm also looking to
> calculate the equilibrium state.
>
> So far, my code looks like this
>
> library(deSolve)
> #This is my system, with three differential equations
> system<-function(times, init, parameters){
> with(as.list(c(init, parameters)),{
>
> di1_dt=(alpha1*(N-i1-i2-i12)*(i1+i12))+(beta2*i12+gamma1*(N-i1-i2-i12))-(beta1*i1)-(delta*alpha2*i1*(i2+i12))
>
> di2_dt=(alpha2*(N-i1-i2-i12)*(i2+i12))+(beta1*i12+gamma2*(N-i1-i2-i12))-(beta2*i2)-(delta*alpha1*i2*(i1+i12))
>
> di12_dt=(delta*alpha2*i1*(i12+i2))+(delta*alpha1*i2*(i12*i1))+(delta*gamma1*i1)+(delta*gamma2*i2)-((beta1+beta2)*i12)
> return(list(c(di1_dt,di2_dt,di12_dt)))
> })
> }
>
> # Initials values and parameters
> init<-c(i1=10, i2=10, i12=0)
> parameters<-c(alpha1=0.7, alpha2=0.5, beta1=0.5, beta2=0.3, gamma1=0.5,
> gamma2=0.5, delta=0.5, N=100)
> times<-seq(0,200, by=1)
> simul <- as.data.frame(ode(y = init, times = times, func = system, parms =
> parameters, method="ode45"))
> simul$time <- NULL
> head(simul,200)
>
> #Plotting the results
> matplot(times,
>  simul, type = "l", xlab = "Time", ylab = "i1 i2 i12", main =
> "Simulation", lwd = 2, lty = 2, bty = "l", col=c("darkblue",
> "darkred","mediumseagreen"))
> legend("bottomright", c("i1", "i2","i12"), lty=2,lwd=2, col =
> c("darkblue", "darkred", "mediumseagreen"))
>
> At
>  first, I just tried studying with only the first two equations, and it
> seems to work completely fine, but when I wanted to add the 3rd
> equation, I sometimes get this message, even when I juggle the
> parameters, when i launch the line:
> #simul <- as.data.frame(ode(y = init, times = times, func = system, parms
> = parameters))
> Warning messages:
> 1: In lsode(y, times, func, parms, mf = 10, ...) :
>   an excessive amount of work (> maxsteps ) was done, but integration was
> not successful - increase maxsteps
> 2: In lsode(y, times, func, parms, mf = 10, ...) :
>   Returning early. Results are accurate, as far as they go
>
> Have I overlooked something ? I tried to use methods="ode45" and
> methods="adams", without any sucess.
> Thank you for your time
> Alex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From javanmard.majid at gmail.com  Sat Feb 20 18:11:22 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Sat, 20 Feb 2016 20:41:22 +0330
Subject: [R] Is there any simple guide for spatialVx R package !?
In-Reply-To: <CAM_vjunFG5fc86268Bv+09JME6racaxP1cntLULX8C8sRnLAng@mail.gmail.com>
References: <CAA0OCnsF8JM5xpi9smXG52J8XWf=8NB=s+VPkY0B=Jj9vqvu4Q@mail.gmail.com>
	<CAM_vjunFG5fc86268Bv+09JME6racaxP1cntLULX8C8sRnLAng@mail.gmail.com>
Message-ID: <CAA0OCntVNsQfA0TpXBXZ0qG2seCRV9o5vNPBvS4fu_V-iJu-JA@mail.gmail.com>

I checked datasets,however, it is my ambiguities, I mean why there is no
Lat/Lon in pert000 and pert004 datasets, and how conncet data to each other
!!?
another question :  does this package match the two entities which RMSE is
the lowest or correlation coefficient is the highest one ?!




On Sat, Feb 20, 2016 at 4:42 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> The data commands in the example load sample data. You can run those lines
> in R and look at what the sample data are set up like, if the explanations
> aren't clear to you. There may also be help files specifically for the
> sample data.
>
> There's some information at
> https://www.ral.ucar.edu/projects/icp/SpatialVx/
> but sadly no tutorial. Still, those folks are probably better to contact
> for package-specific questions.
>
> Sarah
>
>
> On Saturday, February 20, 2016, Majid Javanmard <javanmard.majid at gmail.com>
> wrote:
>
>> I was searching a windows-based software to execute CRA(contiguous rain
>> area) method, I failed, but I found a R package and its example to execute
>> this method but I encountered some ambiguities !!
>>
>> here is the example code :
>>
>> data(pert000)
>> data(pert004)
>> data(ICPg240Locs)
>>
>> hold <- make.SpatialVx(pert000, pert004,
>> loc=ICPg240Locs, projection=TRUE, map=TRUE, loc.byrow = TRUE,
>> field.type="Precipitation", units="mm/h",
>> data.name=c("ICP Perturbed Cases", "pert000", "pert004"))
>>
>> look <- FeatureFinder(hold, smoothpar=10.5, thresh = 5)
>> plot(look)
>>
>> look2 <- minboundmatch(look, verbose = TRUE)
>> plot(look2)
>>
>> craer( look2 )
>>
>> 1)
>>
>> What kind of dataset should I import here !!? I have an observation and
>> forecast files contains Lat/Lon and Value columns(observation 9 rows,
>> forecast 16 rows).
>>
>> 2)
>>
>> Should I interpolate these files to the same bound by Arcmap ?!
>>
>>
>> I really cant understand the tutorial of SpatialVx package, I appreciate
>>  if someone could response on this issue !!
>>
>> Many Thanks
>> Majid Javanmard
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Sat Feb 20 19:31:34 2016
From: simon0098 at yahoo.com (Zahra Samadi)
Date: Sat, 20 Feb 2016 10:31:34 -0800
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <BD75D26C-41FC-4395-94C2-9CD179307C44@gmail.com>
Message-ID: <1455993094.18593.YahooMailAndroidMobile@web164006.mail.gq1.yahoo.com>

Peter, 
I didn't understand your codes :)
But I really seek Windows solution.


	[[alternative HTML version deleted]]


From virendra.mishra at gmail.com  Sat Feb 20 18:53:52 2016
From: virendra.mishra at gmail.com (Virendra Mishra)
Date: Sat, 20 Feb 2016 09:53:52 -0800
Subject: [R] Multivariate multiple linear regression question
Message-ID: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>

Hi R-users,

I have a fairly simple question to ask but I havent yet got an answer to
the question. I will describe my experiment, analysis and what have I done
and what is the question in the following paragraphs and I would appreciate
if anyone could point me to use right statistical tools to answer my
question.

Experiment:
I have 2 groups and both groups undergo 2 set of evaluations, one with MRI
scanner and the other in the lab to test for their behavior. Both these
evaluations are known to have statistically significant relationship with
age and gender.

Statistical question of interest:
Whether there is:
1) statistically significant difference between the 2 groups on each
evaluation ?
2) Whether there is any relationship between and within the 2 groups
between each evaluation

Model:

I model the problem as following:
MRI_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
[Age is continuous and gender , Group are factors/categorical]

Lab_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
[Age is continuous and gender , Group are factors/categorical]

In order to obtain the solution in R:
MRI_model<-lm(cbind(MRI_measure, Lab_measure) ~ age+gender+group,
data=data)

Result of R:
manova(MRI_model) suggests that yes indeed all the slopes are significantly
different than 0 suggesting a relationship between my measures.

Question:
1) In order to test whether the difference in the MRI_measure is
statistically significant different between the 2 groups, I use
MRI_model$fitted.values for each dependent measure and do a statistical
test (either t-test or Wilcox) and claim that the difference is
significant.
In the paper I write, multivariate multiple linear regression was performed
for the groups while controlling for age and gender. The regressed out
MRI_measure was statistically compared to see if the difference is
different.

I am assuming that the predicted/fitted.values in model are the regressed
out variables. Can I show this and use this result? Is this right

If no, what is the correct way to statistically compare whether my 2 groups
differ in their MRI measure and lab measure when controlled for age and
gender. Any R library, literature, possibly a script will be greatly
appreciated.

2) I also want to see if there is any relationship between MRI_measure and
Lab_measure within the group after they are controlled for age and gender.
What is the correct way to do this in R?

Further, I also want to see if there is any significantly different
association between the 2 groups for my set of dependent variables. I am
thinking this can be done: I first find the correlation between 2 dependent
variable in each group and test if this correlation is statistically
different between the 2 groups? Is this logic right? And if it is, how do I
compare the correlation? If not, what is the right way to do this? Any R
library, literature, possibly a script will be greatly appreciated.

I do appreciate any reply.

Thanks

Regards

Virendra

	[[alternative HTML version deleted]]


From virendra.mishra at mavs.uta.edu  Sat Feb 20 18:57:22 2016
From: virendra.mishra at mavs.uta.edu (Mishra, Virendra R)
Date: Sat, 20 Feb 2016 17:57:22 +0000
Subject: [R] Multivariate multiple linear regression question
Message-ID: <BLUPR01MB520A3B18159E94C7016B90BD4A10@BLUPR01MB520.prod.exchangelabs.com>


Hi R-users,

I have a fairly simple question to ask but I havent yet got an answer to the question. I will describe my experiment, analysis and what have I done and what is the question in the following paragraphs and I would appreciate if anyone could point me to use right statistical tools to answer my question.

Experiment:
I have 2 groups and both groups undergo 2 set of evaluations, one with MRI scanner and the other in the lab to test for their behavior. Both these evaluations are known to have statistically significant relationship with age and gender.

Statistical question of interest:
Whether there is:
1) statistically significant difference between the 2 groups on each evaluation ?
2) Whether there is any relationship between and within the 2 groups between each evaluation

Model:

I model the problem as following:
MRI_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group [Age is continuous and gender , Group are factors/categorical]

Lab_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group [Age is continuous and gender , Group are factors/categorical]

In order to obtain the solution in R:
MRI_model<-lm(cbind(MRI_measure, Lab_measure) ~ age+gender+group, data=data)

Result of R:
manova(MRI_model) suggests that yes indeed all the slopes are significantly different than 0 suggesting a relationship between my measures.

Question:
1) In order to test whether the difference in the MRI_measure is statistically significant different between the 2 groups, I use MRI_model$fitted.values for each dependent measure and do a statistical test (either t-test or Wilcox) and claim that the difference is significant.
In the paper I write, multivariate multiple linear regression was performed for the groups while controlling for age and gender. The regressed out MRI_measure was statistically compared to see if the difference is different.

I am assuming that the predicted/fitted.values in model are the regressed out variables. Can I show this and use this result? Is this right

If no, what is the correct way to statistically compare whether my 2 groups differ in their MRI measure and lab measure when controlled for age and gender. Any R library, literature, possibly a script will be greatly appreciated.

2) I also want to see if there is any relationship between MRI_measure and Lab_measure within the group after they are controlled for age and gender. What is the correct way to do this in R?

Further, I also want to see if there is any significantly different association between the 2 groups for my set of dependent variables. I am thinking this can be done: I first find the correlation between 2 dependent variable in each group and test if this correlation is statistically different between the 2 groups? Is this logic right? And if it is, how do I compare the correlation? If not, what is the right way to do this? Any R library, literature, possibly a script will be greatly appreciated.

I do appreciate any reply.

Thanks

Regards

Virendra


	[[alternative HTML version deleted]]


From goheer_ at hotmail.com  Sat Feb 20 23:10:43 2016
From: goheer_ at hotmail.com (Arslan Rehman)
Date: Sat, 20 Feb 2016 17:10:43 -0500
Subject: [R] Beginner: error when I plot histogram from imported table
In-Reply-To: <BLU174-W79ADC5EF2DB41DF9F411B82A10@phx.gbl>
References: <BLU174-W79ADC5EF2DB41DF9F411B82A10@phx.gbl>
Message-ID: <BLU174-W1171EED55EA9712F531E3282A10@phx.gbl>

Hello R users,
#I import a txt file from following code:
> da=read.table("C:/Users/agohir/Desktop/ARModel.txt",header=T)
> head(da)      ytsim1  3.04497412 -0.95401593  0.25043094 -0.69580895  1.95196236  1.4400745
#Now, I get error for following code:
> hist(da,freq=FALSE,nclass=30,ylim=c(0,60),col="blue")Error in hist.default(da, freq = FALSE, nclass = 30, ylim = c(0, 60),  :   'x' must be numeric

#when I check imported data it mention it is numeric?
> str(da)'data.frame':   999 obs. of  1 variable: $ ytsim: num  3.045 -0.954 0.25 -0.696 1.952 ..

#If not, how do I convert and then plot histogram.
#I also want to plot a probability density line afterwards
Any help is appreciated.
Thank you,Arslan

 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From tommydsheu at gmail.com  Sun Feb 21 01:09:19 2016
From: tommydsheu at gmail.com (tommy sheu)
Date: Sat, 20 Feb 2016 18:09:19 -0600
Subject: [R] RMS, CPH: Error in X[, mmcolnames,
	drop = FALSE] : subscript out of bounds
Message-ID: <CAO=8WoxvD3yTngK1Yb8B5ik5P-RH8YoyFTXO_tgdkUC2YvyEfA@mail.gmail.com>

I believe the error message started populating with a recent update of R or
RMS...unsure, as I tried to run an analysis with previously saved and
working code and got the same error message.

My command list:

    rm(list=ls(all=TRUE))
    library(boot)
    library(foreign)
    library(Hmisc,T)
    library(rms)
    valid = read.dta("file location.dta")
    Age=c(valid$dxage)
    N_Category<-factor(valid$Ntri,labels=c("N0","N1","N2","N3"))
    dd <- datadist(Age, N_Category)
    options(datadist='dd')
    f1=cph(Surv(valid$t3yr,valid$KM)~Age + factor(N_Category),
method="breslow",data=valid,surv=T, x=T, y=T)

Output:

    formula

    Surv(valid$t3yr, valid$KM) ~ Age + factor(N_Category)
         colnames(X)             mmcolnames      Design colnames
    [1,] "Age"                   "Age"           "Age"
    [2,] "factor(N_Category)N1"  "N_CategoryN1"  "N_Category=N1"
    [3,] "factor(N_Category)N2" "N_CategoryN2" "N_Category=N2"
    [4,] "factor(N_Category)N3"  "N_CategoryN3"  "N_Category=N3"
    Error in X[, mmcolnames, drop = FALSE] : subscript out of bounds

Here?s the test data set that I?m trouble shooting with:

    dxage     t3yr KM NTri Ntri1 nlab
    1     70 25.36667  1    0     1    1
    2     42 19.90000  1    2     3    3
    3     43  7.80000  1    2     3    3
    4     70 16.96667  1    1     2    2
    5     50 20.50000  1    2     3    3
    6     40 24.76667  1    2     3    3
    7     24  4.50000  1    0     1    1
    8     70 15.03333  1    1     2    2
    9     45 35.36666  1    1     2    2
    10    62 19.96667  1    3     4    4
    11    62 32.76667  1    0     1    1
    12    78 23.86667  1    2     3    3
    13    49 33.96667  1    2     3    3
    14    67 15.06667  0    0     1    1
    15    69 12.50000  0    1     2    2
    16    61  7.20000  0    0     1    1


I've also tried to recategorized the NTri column increasing all of the
values by 1 thinking that R was misreading the 0's but to no avail.

Greatly appreciate any help or guidance.

	[[alternative HTML version deleted]]


From jayuan2008 at yahoo.com  Sun Feb 21 02:27:52 2016
From: jayuan2008 at yahoo.com (Yuan Jian)
Date: Sun, 21 Feb 2016 01:27:52 +0000 (UTC)
Subject: [R] lm
References: <1233494982.7484355.1456018072703.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1233494982.7484355.1456018072703.JavaMail.yahoo@mail.yahoo.com>

Hello,I used l? to draw a figure, but I got different result (26 vs 301) when I input the same parameters.

> length(predict(lm(A$Counts ~ AT),list(ATE=timevalues)))
[1] 26
> length(predict(lm(A$Counts ~ ATE),list(ATE=timevalues)))
[1] 301

all variables are initialized as below:
>A <- structure(list(Time = c(0, 1, 2, 4, 6, 8, 9, 10, 11, 12, 13, 
?14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30), 
?Counts = c(126.6, 101.8, 71.6, 101.6, 68.1, 62.9, 45.5, 41.9, 
?46.3, 34.1, 38.2, 41.7, 24.7, 41.5, 36.6, 19.6, 
?22.8, 29.6, 23.5, 15.3, 13.4, 26.8, 9.8, 18.8, 25.9, 19.3)), .Names = c("Time", "Counts"),
?row.names = c(1L, 2L, 3L, 5L, 7L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 19L, 20L, 21L, 22L, 23L, 25L, 26L, 27L, 28L, 29L, 30L, 31L),
?class = "data.frame")
>timevalues <- seq(0, 30, 0.1)
>AT<-A$Time>ATE<-A$Time
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb 21 06:18:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 20 Feb 2016 21:18:42 -0800
Subject: [R] Beginner: error when I plot histogram from imported table
In-Reply-To: <BLU174-W1171EED55EA9712F531E3282A10@phx.gbl>
References: <BLU174-W79ADC5EF2DB41DF9F411B82A10@phx.gbl>
	<BLU174-W1171EED55EA9712F531E3282A10@phx.gbl>
Message-ID: <479865F1-FE95-45DC-BF68-89EE4A2AD7DE@dcn.davis.ca.us>

You should compare the output of str(da) with the output of str(1:10)... da is a data.frame that contains one column (a numeric vector). Data.frames are not numeric, they are lists of columns.

Replace da with da$ytsim1 in your call to hist. 
-- 
Sent from my phone. Please excuse my brevity.

On February 20, 2016 2:10:43 PM PST, Arslan Rehman <goheer_ at hotmail.com> wrote:
>Hello R users,
>#I import a txt file from following code:
>> da=read.table("C:/Users/agohir/Desktop/ARModel.txt",header=T)
>> head(da)      ytsim1  3.04497412 -0.95401593  0.25043094 -0.69580895 
>1.95196236  1.4400745
>#Now, I get error for following code:
>> hist(da,freq=FALSE,nclass=30,ylim=c(0,60),col="blue")Error in
>hist.default(da, freq = FALSE, nclass = 30, ylim = c(0, 60),  :   'x'
>must be numeric
>
>#when I check imported data it mention it is numeric?
>> str(da)'data.frame':   999 obs. of  1 variable: $ ytsim: num  3.045
>-0.954 0.25 -0.696 1.952 ..
>
>#If not, how do I convert and then plot histogram.
>#I also want to plot a probability density line afterwards
>Any help is appreciated.
>Thank you,Arslan
>
> 		 	   		   		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb 21 07:29:55 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 20 Feb 2016 22:29:55 -0800
Subject: [R] lm
In-Reply-To: <1233494982.7484355.1456018072703.JavaMail.yahoo@mail.yahoo.com>
References: <1233494982.7484355.1456018072703.JavaMail.yahoo.ref@mail.yahoo.com>
	<1233494982.7484355.1456018072703.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D0DA12BB-4D5E-445C-A63E-0127FCAC8DC7@dcn.davis.ca.us>

Your first predict sets up a newdata with a column name that is not the same as the one that you used in the lm formula. The failure to match causes R to look in the global environment, where it finds AT.

You really should make a habit of always putting your regression data into a data.frame and specifying that using the data argument to lm. Working with some input data in a data frame and other data not in the same data frame can make it much harder to debug and to understand. 

B <- data.frame( Time = timevalues )
B$Counts  <- predict( lm( Counts ~ Time, data = A ), newdata = B )

-- 
Sent from my phone. Please excuse my brevity.

On February 20, 2016 5:27:52 PM PST, Yuan Jian via R-help <r-help at r-project.org> wrote:
>Hello,I used l? to draw a figure, but I got different result (26 vs
>301) when I input the same parameters.
>
>> length(predict(lm(A$Counts ~ AT),list(ATE=timevalues)))
>[1] 26
>> length(predict(lm(A$Counts ~ ATE),list(ATE=timevalues)))
>[1] 301
>
>all variables are initialized as below:
>>A <- structure(list(Time = c(0, 1, 2, 4, 6, 8, 9, 10, 11, 12, 13, 
>?14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30), 
>?Counts = c(126.6, 101.8, 71.6, 101.6, 68.1, 62.9, 45.5, 41.9, 
>?46.3, 34.1, 38.2, 41.7, 24.7, 41.5, 36.6, 19.6, 
>?22.8, 29.6, 23.5, 15.3, 13.4, 26.8, 9.8, 18.8, 25.9, 19.3)), .Names =
>c("Time", "Counts"),
>?row.names = c(1L, 2L, 3L, 5L, 7L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
>16L, 17L, 19L, 20L, 21L, 22L, 23L, 25L, 26L, 27L, 28L, 29L, 30L, 31L),
>?class = "data.frame")
>>timevalues <- seq(0, 30, 0.1)
>>AT<-A$Time>ATE<-A$Time
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Feb 21 09:10:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 21 Feb 2016 00:10:34 -0800
Subject: [R] Multivariate multiple linear regression question
In-Reply-To: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>
References: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>
Message-ID: <CAGxFJbSNv9ek0-ZwW9g81tCzH+xC8f13yWHN4EtqBGtdjMe0-A@mail.gmail.com>

Sorry, but please do not multiple post. That's spam.

This is a list about the R programming language, not about statistical
methods. While there is often some overlap, your questions are entirely
statistical and therefore OT here( at least imo). Try a statistical list
like stats.stackexchange.com instead.

Cheers,
Bert



On Saturday, February 20, 2016, Virendra Mishra <virendra.mishra at gmail.com>
wrote:

> Hi R-users,
>
> I have a fairly simple question to ask but I havent yet got an answer to
> the question. I will describe my experiment, analysis and what have I done
> and what is the question in the following paragraphs and I would appreciate
> if anyone could point me to use right statistical tools to answer my
> question.
>
> Experiment:
> I have 2 groups and both groups undergo 2 set of evaluations, one with MRI
> scanner and the other in the lab to test for their behavior. Both these
> evaluations are known to have statistically significant relationship with
> age and gender.
>
> Statistical question of interest:
> Whether there is:
> 1) statistically significant difference between the 2 groups on each
> evaluation ?
> 2) Whether there is any relationship between and within the 2 groups
> between each evaluation
>
> Model:
>
> I model the problem as following:
> MRI_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
> [Age is continuous and gender , Group are factors/categorical]
>
> Lab_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
> [Age is continuous and gender , Group are factors/categorical]
>
> In order to obtain the solution in R:
> MRI_model<-lm(cbind(MRI_measure, Lab_measure) ~ age+gender+group,
> data=data)
>
> Result of R:
> manova(MRI_model) suggests that yes indeed all the slopes are significantly
> different than 0 suggesting a relationship between my measures.
>
> Question:
> 1) In order to test whether the difference in the MRI_measure is
> statistically significant different between the 2 groups, I use
> MRI_model$fitted.values for each dependent measure and do a statistical
> test (either t-test or Wilcox) and claim that the difference is
> significant.
> In the paper I write, multivariate multiple linear regression was performed
> for the groups while controlling for age and gender. The regressed out
> MRI_measure was statistically compared to see if the difference is
> different.
>
> I am assuming that the predicted/fitted.values in model are the regressed
> out variables. Can I show this and use this result? Is this right
>
> If no, what is the correct way to statistically compare whether my 2 groups
> differ in their MRI measure and lab measure when controlled for age and
> gender. Any R library, literature, possibly a script will be greatly
> appreciated.
>
> 2) I also want to see if there is any relationship between MRI_measure and
> Lab_measure within the group after they are controlled for age and gender.
> What is the correct way to do this in R?
>
> Further, I also want to see if there is any significantly different
> association between the 2 groups for my set of dependent variables. I am
> thinking this can be done: I first find the correlation between 2 dependent
> variable in each group and test if this correlation is statistically
> different between the 2 groups? Is this logic right? And if it is, how do I
> compare the correlation? If not, what is the right way to do this? Any R
> library, literature, possibly a script will be greatly appreciated.
>
> I do appreciate any reply.
>
> Thanks
>
> Regards
>
> Virendra
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Sun Feb 21 10:37:24 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sun, 21 Feb 2016 11:37:24 +0200
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <BD75D26C-41FC-4395-94C2-9CD179307C44@gmail.com>
References: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>
	<1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>
	<CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
	<BD75D26C-41FC-4395-94C2-9CD179307C44@gmail.com>
Message-ID: <CAJ=0CtDaSnFKAwMTwVWPn-i6nJ+YTX+AL6hAsH7q49rdFWsVRA@mail.gmail.com>

Oh, thanks Peter, good example for Mac, but indeed not working on Windows.
For a completely cross-platform solution (that is, including Windows which
is what Zahra wants), I believe shiny is the right tool.

So Zahra, if you want to use shiny, you need to look at their own
tutorials, step by step, and try to understand how it works.
They have predefined tools to make "apps", which can be deployed either
locally or on a web server. But you will be dependent on the available
shiny toolkit.
Otherwise, if you want to make a completely customized interface, you need
to use a combination of R, HTML and Javascript.

Take a look at the GUI from the QCAGUI package (download the sources, it's
in the "inst" directory): it can read the local filesystem, import / export
data, it does various data transformations and various QCA related analyses
and graphs.
Everything is highly customized, with drop-down menus and pop-up dialogs,
including an output one which mimics the R console.
To look at the interface, type:

library(QCAGUI)
runGUI()

I hope it helps,
Adrian

On Sat, Feb 20, 2016 at 2:46 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> It's quite platform dependent, but this idea works for tcl/tk on Mac. I
> don't think it would be too hard to do similar things on Linux, Windows may
> be a bigger challenge (or not).
>
> Peter-Dalgaards-MacBook-Air:tmp pd$ cat foo.app
> #!/usr/bin/Rscript
> library(tcltk)
> demo(tkfaq)
> tkwait.variable("exit")
>
> Make it executable (chmod +x foo.app) and you can double-click it in the
> Finder. (Notice that as written, there is nothing to shut down the tkwait
> loop, so you'll have to force quit it.)
>
> Peter D.
>
> > On 19 Feb 2016, at 23:36 , Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> >
> > Your function, buildGui(), what does it use, Tcl/Tk or something else?
> > If it's Tcl/Tk, I believe you need a normal R console opened. My .bat
> file
> > only works for a command line, which is fine if the user interface opens
> up
> > in a webpage, but I'm pretty sure it doesn\t work with Tcl/Tk.
> > What kind of window does your function return?
> > Adrian
> >
> > On Fri, Feb 19, 2016 at 4:35 PM, Zahra Samadi <simon0098 at yahoo.com>
> wrote:
> >
> >> Adriana,
> >> My GUI file is a function returning a window. This function is named
> >> buildGui(). How should I create this batch file using the piece of code
> >> you've written?
> >>
> >> ------------------------------
> >> * From: * Adrian Du?a <dusa.adrian at unibuc.ro>;
> >> * To: * Greg Snow <538280 at gmail.com>;
> >> * Cc: * simon0098 at yahoo.com <simon0098 at yahoo.com>; r-help at r-project.org
> <
> >> r-help at r-project.org>;
> >> * Subject: * Re: [R] How to create an executable file from R GUI?
> >> * Sent: * Thu, Feb 18, 2016 9:03:52 PM
> >>
> >> Simon, Greg,
> >>
> >> That is the very reason why I've given up on Tck/Tk, in favor of shiny.
> >> The user interface opens up in a webpage, without opening the normal R
> >> console (it only opens a Terminal window).
> >>
> >> To exemplify, package QCAGUI has a function called runGUI(), and on
> >> Windows it's a simple matter of creating a .bat file,
> >> which for my user interface it only contains this:
> >>
> >> CLS
> >>
> >> TITLE QCA Qualitative Comparative Analysis
> >>
> >> C:/PROGRA~1/R/R-3.2.3/bin/R.exe --slave --no-restore -e
> >> "setwd('D:/');QCAGUI::runGUI()"
> >>
> >>
> >> The double click on the .bat file, and that's it.
> >> I hope it helps,
> >> Adrian
> >>
> >>
> >>
> >> On Thu, Feb 18, 2016 at 7:24 PM, Greg Snow <538280 at gmail.com> wrote:
> >>
> >>> To give a full answer we need some more detail from you.  For example
> >>> what operating system are you on? what do you mean by "users click on
> >>> it"? and at what point do you want them to click (after running R,
> >>> when looking at the desktop, etc.)
> >>>
> >>> But to help get you started you may want to look at the help page
> >>> `?Startup` which tells you all the things that R does as it starts up
> >>> and how to have it run commands automatically as it is starting up.
> >>>
> >>> I have created some GUI examples in the past that clients then wanted
> >>> to have on their own computer to play with and demonstrate to others.
> >>> I usually would install R on their machine for them and create a
> >>> shortcut on the desktop (these were all MS Windows computers) that
> >>> pointed to the standard R executable, but started in a specific
> >>> directory/folder.  Then in that folder I created a ".Rprofile" file
> >>> with the commands to load in the appropriate data and packages and run
> >>> the gui demonstration.  The user could then double click on the
> >>> shortcut on the desktop and 2 windows would pop up (the regular R
> >>> interface and my gui demo), I instructed the client to just minimize
> >>> and ignore the regular R window and they were then able to use my demo
> >>> and then close everything when they were finished.  You could do
> >>> something similar (but exactly how will differ between Windows, Mac,
> >>> and Linux computers).
> >>>
> >>> On Thu, Feb 18, 2016 at 9:27 AM, simon0098--- via R-help
> >>> <r-help at r-project.org> wrote:
> >>>> Hi,
> >>>> I've created a GUI using RGtk2 package. How can I make an executable
> >>> file from my R script so that users click on it and the GUI appears for
> >>> them?
> >>>>
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>>
> >>> --
> >>> Gregory (Greg) L. Snow Ph.D.
> >>> 538280 at gmail.com
> >>>
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>
> >>
> >> --
> >> Adrian Dusa
> >> University of Bucharest
> >> Romanian Social Data Archive
> >> Soseaua Panduri nr.90
> >> 050663 Bucharest sector 5
> >> Romania
> >>
> >
> >
> >
> > --
> > Adrian Dusa
> > University of Bucharest
> > Romanian Social Data Archive
> > Soseaua Panduri nr.90
> > 050663 Bucharest sector 5
> > Romania
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From virendra.mishra at gmail.com  Sun Feb 21 09:23:34 2016
From: virendra.mishra at gmail.com (Virendra Mishra)
Date: Sun, 21 Feb 2016 00:23:34 -0800
Subject: [R] Multivariate multiple linear regression question
In-Reply-To: <CAGxFJbSNv9ek0-ZwW9g81tCzH+xC8f13yWHN4EtqBGtdjMe0-A@mail.gmail.com>
References: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>
	<CAGxFJbSNv9ek0-ZwW9g81tCzH+xC8f13yWHN4EtqBGtdjMe0-A@mail.gmail.com>
Message-ID: <CAFCvstno8M5KzF9Fy1bEKWQrcA_s4xvpOHpSn8sjLs87Fd2w9g@mail.gmail.com>

Ok. Will do thank you. I do apologize for the spam. That was done in error.
On Feb 21, 2016 12:10 AM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> Sorry, but please do not multiple post. That's spam.
>
> This is a list about the R programming language, not about statistical
> methods. While there is often some overlap, your questions are entirely
> statistical and therefore OT here( at least imo). Try a statistical list
> like stats.stackexchange.com instead.
>
> Cheers,
> Bert
>
>
>
> On Saturday, February 20, 2016, Virendra Mishra <virendra.mishra at gmail.com>
> wrote:
>
>> Hi R-users,
>>
>> I have a fairly simple question to ask but I havent yet got an answer to
>> the question. I will describe my experiment, analysis and what have I done
>> and what is the question in the following paragraphs and I would
>> appreciate
>> if anyone could point me to use right statistical tools to answer my
>> question.
>>
>> Experiment:
>> I have 2 groups and both groups undergo 2 set of evaluations, one with MRI
>> scanner and the other in the lab to test for their behavior. Both these
>> evaluations are known to have statistically significant relationship with
>> age and gender.
>>
>> Statistical question of interest:
>> Whether there is:
>> 1) statistically significant difference between the 2 groups on each
>> evaluation ?
>> 2) Whether there is any relationship between and within the 2 groups
>> between each evaluation
>>
>> Model:
>>
>> I model the problem as following:
>> MRI_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
>> [Age is continuous and gender , Group are factors/categorical]
>>
>> Lab_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
>> [Age is continuous and gender , Group are factors/categorical]
>>
>> In order to obtain the solution in R:
>> MRI_model<-lm(cbind(MRI_measure, Lab_measure) ~ age+gender+group,
>> data=data)
>>
>> Result of R:
>> manova(MRI_model) suggests that yes indeed all the slopes are
>> significantly
>> different than 0 suggesting a relationship between my measures.
>>
>> Question:
>> 1) In order to test whether the difference in the MRI_measure is
>> statistically significant different between the 2 groups, I use
>> MRI_model$fitted.values for each dependent measure and do a statistical
>> test (either t-test or Wilcox) and claim that the difference is
>> significant.
>> In the paper I write, multivariate multiple linear regression was
>> performed
>> for the groups while controlling for age and gender. The regressed out
>> MRI_measure was statistically compared to see if the difference is
>> different.
>>
>> I am assuming that the predicted/fitted.values in model are the regressed
>> out variables. Can I show this and use this result? Is this right
>>
>> If no, what is the correct way to statistically compare whether my 2
>> groups
>> differ in their MRI measure and lab measure when controlled for age and
>> gender. Any R library, literature, possibly a script will be greatly
>> appreciated.
>>
>> 2) I also want to see if there is any relationship between MRI_measure and
>> Lab_measure within the group after they are controlled for age and gender.
>> What is the correct way to do this in R?
>>
>> Further, I also want to see if there is any significantly different
>> association between the 2 groups for my set of dependent variables. I am
>> thinking this can be done: I first find the correlation between 2
>> dependent
>> variable in each group and test if this correlation is statistically
>> different between the 2 groups? Is this logic right? And if it is, how do
>> I
>> compare the correlation? If not, what is the right way to do this? Any R
>> library, literature, possibly a script will be greatly appreciated.
>>
>> I do appreciate any reply.
>>
>> Thanks
>>
>> Regards
>>
>> Virendra
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Sun Feb 21 17:37:45 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 21 Feb 2016 16:37:45 +0000
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>,
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
	<D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70C909@mb02.ads.tamu.edu>

Each observation is assigned to the closest medoid, a single observation. An observation that is between two medoids will be assigned to the closer one even if its distances to members of the other cluster are closer on average (but the medoid of that cluster is slightly farther away). If the clusters are not well separated, this can happen easily. 

You could always change the cluster assignment vector to see what happens to the silhouette plot. That will affect more than just the single observation since silhouette values of all of the points in those two clusters will change slightly (very slightly if there are lots of observations in those two clusters).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ABABAEI, Behnam
Sent: Friday, February 19, 2016 1:55 PM
To: sarah.goslee at gmail.com
Cc: r-help at r-project.org
Subject: Re: [R] How a clustering algorithm in R can end up with negative silhouette values?

Hi Sarah,

Thank you for the response. But it is said in its description that after each run (sample), each observation in the whole dataset is assigned to the closest cluster. So how is it possible for one observation to be wrongly allocated, even with clara?

Behnam

Behnam



On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee" <sarah.goslee at gmail.com<mailto:sarah.goslee at gmail.com>> wrote:

That means that points have been assigned to the wrong groups. This
may readily happen with a clustering method like cluster::clara() that
uses a subset of the data to cluster a dataset too large to analyze as
a unit. Negative silhouette numbers strongly suggest that your
clustering parameters should be changed.

Sarah

On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi,
>
>
> We know that clustering methods in R assign observations to the closest medoids. Hence, it is supposed to be the closest cluster each observation can have. So, I wonder how it is possible to have negative values of silhouette , while we are supposedly assign each observation to the closest cluster and the formula in silhouette method cannot get negative?
>
>
> Behnam.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Feb 21 17:55:56 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 21 Feb 2016 16:55:56 +0000
Subject: [R] Why CLARA clustering method does not give the same classes
 as when I do clustering manually?
In-Reply-To: <CAM_vjum8kiGFhc4BvDgrhqcNsEdK0KUFnyBd2rSiX1-Sr6b8dg@mail.gmail.com>
References: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjum8kiGFhc4BvDgrhqcNsEdK0KUFnyBd2rSiX1-Sr6b8dg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70C958@mb02.ads.tamu.edu>

I do not think this is quite true. When the medoids are not specified, pam/clara looks for a good initial set (build phase) and then finds a local minimum of the objective function (swap phase). Both pam/clara and kmeans can find local minima that are not the global minimum. If the build phase involves any random element, two runs could produce different results. If not, then the original order of the data determines the final result, but the final result is not necessarily the best one possible (assuming the order of the data is irrelevant to the analysis so we are not looking at observations taken along a line in time or space). That is why kmeans includes an argument to run the algorithm multiple times and pick the best result.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
Sent: Friday, February 19, 2016 1:47 PM
To: ABABAEI, Behnam
Cc: r-help at r-project.org
Subject: Re: [R] Why CLARA clustering method does not give the same classes as when I do clustering manually?

clara() is a version of pam() adapted to use large datasets.

pam() uses the entire dataset, and should give results identical to
your manual procedure, or nearly so. clara() works on subsets of the
data, so it may give a slightly different result each time you run it.

The default parameters for clara() are very small, so you can get
substantially different results from run to run on a large dataset if
you don't change them.

Sarah

On Fri, Feb 19, 2016 at 6:30 AM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi,
>
>
> I am using CLARA (in 'cluster' package). This method is supposed to assign each observation to the closest 'medoid'. But when I calculate the distance of medoids and observations manually and assign them manually, the results are slightly different (1-2 percent of occurrence probability). Does anyone know how clara calculates dissimilarities and why I get different clustering results?
>
>
> Behnam.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From c.hennig at ucl.ac.uk  Mon Feb 22 00:17:20 2016
From: c.hennig at ucl.ac.uk (Hennig, Christian)
Date: Sun, 21 Feb 2016 23:17:20 +0000
Subject: [R] Why CLARA clustering method does not give the same classes
 as when I do clustering manually?
In-Reply-To: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
References: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
Message-ID: <HE1PR01MB116147E08654BFF267660FEDD2A20@HE1PR01MB1161.eurprd01.prod.exchangelabs.com>

Clara uses the Euclidean distance. 
Why you get different results can only be said if you provide a reproducible code example for both what you did in clara and what you did "manually".

Best wishes,
Christian

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of ABABAEI, Behnam <Behnam.ABABAEI at limagrain.com>
Sent: 19 February 2016 11:30
To: r-help at r-project.org
Subject: [R] Why CLARA clustering method does not give the same classes as when I do clustering manually?

Hi,


I am using CLARA (in 'cluster' package). This method is supposed to assign each observation to the closest 'medoid'. But when I calculate the distance of medoids and observations manually and assign them manually, the results are slightly different (1-2 percent of occurrence probability). Does anyone know how clara calculates dissimilarities and why I get different clustering results?


Behnam.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From venkatesansekhar at gmail.com  Sun Feb 21 13:49:08 2016
From: venkatesansekhar at gmail.com (Sekhar Venkatesan)
Date: Sun, 21 Feb 2016 18:19:08 +0530
Subject: [R] Help required for Rcmdr
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F56414@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
	<CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F55E86@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMBzcc8ma-19+ZebH4Ci-xpDm3fvCxg8o=8sFKO4H45Dw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563C2@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMLYtWcndPc4Mn68FD+o4UWSPk0OAcAiR7VrbDGEagHmw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F56414@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAGyA+HMbJjUiGEfYbcF3TRFPywyH_NJ2GF02gGJrCYY5AEU57A@mail.gmail.com>

Dear Sirs,
just wanted to check whether C+ or C++ software is required to be in the
installed in the laptop in order to use Rcmdr
regards
sekhar

On Wed, Feb 10, 2016 at 10:17 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Sekhar,
>
> > -----Original Message-----
> > From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com]
> > Sent: February 10, 2016 11:37 AM
> > To: Fox, John <jfox at mcmaster.ca>
> > Subject: RE: [R] Help required for Rcmdr
> >
> > Tks and sorry for inadvertently sending to u alone
>
> And you apparently just did that again, so again I'm cc'ing to r-help.
>
> > In any case I hv tried all
> > over again but to no avail Regards Sekhar
>
> I assume that  by "tried all over again" you mean you tried again with an
> HTTP rather than HTTPS CRAN mirror and that didn't work.
>
> I'm afraid that I'm out of ideas.
>
> Maybe someone else will have a suggestion.
>
> John
>
> >
> > On Feb 10, 2016 9:59 PM, "Fox, John" <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Sekhar,
> >
> >       I'm sorry that you're experiencing these problems. Although you
> > haven't said so directly, I assume that you aren't able to use
> install.packages()
> > to install *any* CRAN packages, not just the Rcmdr package.
> >
> >       Downloading and unpacking the Rcmdr zip file doesn't install the
> > package. You can install the zip-file binary package from the R Windows
> GUI
> > via the "Packages > Install package(s) from local zip files" menu, but
> that too
> > won't really help because it won't install the many CRAN packages on
> which
> > the Rcmdr depends.
> >
> >       As I said earlier, my guess is that you're experiencing a problem
> with
> > a firewall, proxy server, or HTTPS. If the latter (which was Vito's
> problem),
> > you can easily solve the problem by using an HTTP CRAN server in
> preference
> > to the default HTTPS:
> >
> >       Enter the command chooseCRANmirror(useHTTPS=FALSE) at the R
> > Console > prompt and select a CRAN mirror -- I suggest the first
> (0-Cloud)
> > mirror. Then issue the command install.packages("Rcmdr"), as before.
> >
> >       If that doesn't work, I'm afraid I don't have other suggestions.
> >
> >       You appear to have sent this message only to me, not to r-help.
> That
> > not a good idea for several reasons, not least of which is that people
> who
> > have other suggestions won't see your message. I'm cc'ing this response
> to r-
> > help.
> >
> >       Best,
> >        John
> >
> >       > -----Original Message-----
> >       > From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com
> > <mailto:venkatesansekhar at gmail.com> ]
> >       > Sent: February 10, 2016 12:03 AM
> >       > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> >       > Subject: Re: [R] Help required for Rcmdr
> >       >
> >       > Dear Sirs,
> >       > Thanks to everyone for trying to help me. i have tried several
> CRAN
> > mirrors
> >       > but to no help. I am getting the Zip file for Rcmdr and can also
> unzip
> > the
> >       > same. However, after that i am unable to open the Rcmdr console.
> >       > that is the problem.
> >       > regards
> >       > sekhar
> >       >
> >       > On Tue, Feb 9, 2016 at 10:00 PM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>
> >       > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > > wrote:
> >       >
> >       >
> >       >       Hi Rich,
> >       >
> >       >       > -----Original Message-----
> >       >       > From: Richard M. Heiberger [mailto:rmh at temple.edu
> > <mailto:rmh at temple.edu>
> >       > <mailto:rmh at temple.edu <mailto:rmh at temple.edu> > ]
> >       >       > Sent: February 9, 2016 4:57 PM
> >       >       > To: Vito M. R. Muggeo <vito.muggeo at unipa.it
> > <mailto:vito.muggeo at unipa.it>
> >       > <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
> >       >       > Cc: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca
> >
> > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > >;
> >       > Sekhar Venkatesan
> >       >       > <venkatesansekhar at gmail.com
> > <mailto:venkatesansekhar at gmail.com>
> >       > <mailto:venkatesansekhar at gmail.com
> > <mailto:venkatesansekhar at gmail.com> > >; Duncan Murdoch
> >       >       > <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>
> >       > <mailto:murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com> > >; R-help at r-project.org <mailto:R-
> > help at r-project.org>  <mailto:R- <mailto:R->
> >       > help at r-project.org <mailto:help at r-project.org> > ; R-windows at r-
> >       >       > project.org <http://project.org>  <http://project.org>
> >       >       > Subject: Re: [R] Help required for Rcmdr
> >       >       >
> >       >       > Several of my students have had this type of difficulty
> with
> > Rstudio.
> >       >       >
> >       >
> >       >       Good to know, but the original poster tried both with the R
> > Windows
> >       > SDI and MDI.
> >       >
> >       >       Best,
> >       >        John
> >       >
> >       >
> >       >       > Rstudio masks install.packages with a similarly named
> function
> > in an
> >       >       > environment that does not appear in either
> > conflicts(details=TRUE)
> >       > or in
> >       >       > search().
> >       >       >
> >       >       > The workaround is an explicit call to utils
> >       >       >
> >       >       > utils::install.packages("package.name <
> http://package.name>
> > <http://package.name> ")
> >       >       >
> >       >       > Rich
> >       >       >
> >       >       > On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo
> >       > <vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it>
> > <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
> >       >       > wrote:
> >       >       > > dear John,
> >       >       > > Thanks for your prompt reply
> >       >       > >
> >       >       > > Il 09/02/2016 16.23, Fox, John ha scritto:
> >       >       > >>
> >       >       > >> Dear Vito,
> >       >       > >>
> >       >       > >> I've never experienced this problem myself in a
> general
> > way,
> >       >       > >
> >       >       > > Me too. I have always installed R packages
> > straightforwardly..
> >       >       > >
> >       >       > > and I'm sure that Windows users of R call
> install.packages()
> > all the
> >       >       > > time to install packages from CRAN mirrors.
> >       >       > > Of course..
> >       >       > >
> >       >       > > So the question to ask, I think, is what's preventing
> >       >       > > install.packages() from working in your case --
> possibly an
> >       > Internet
> >       >       > > connectivity problem due to a firewall, proxy server,
> use of
> > https,
> >       > etc.
> >       >       > > I'm sure that others more knowledgeable about these
> issues
> >       > than I am
> >       >       > > will be able to make more specific suggestions for
> fixing the
> >       > problem.
> >       >       > >
> >       >       > > However I have just checked that it works with *http*
> > servers
> >       > (but not
> >       >       > > for any other *https*..)
> >       >       > >
> >       >       > > Thanks for your support,
> >       >       > > best,
> >       >       > > vito
> >       >       > >
> >       >       > >
> >       >       > >>
> >       >       > >> Best,
> >       >       > >>   John
> >       >       > >>
> >       >       > >> -----------------------------
> >       >       > >> John Fox, Professor
> >       >       > >> McMaster University
> >       >       > >> Hamilton, Ontario
> >       >       > >> Canada L8S 4M4
> >       >       > >> web: socserv.mcmaster.ca/jfox
> > <http://socserv.mcmaster.ca/jfox>
> >       > <http://socserv.mcmaster.ca/jfox>
> >       >       > >>
> >       >       > >>
> >       >       > >> ________________________________________
> >       >       > >> From: R-help [r-help-bounces at r-project.org <mailto:r-
> > help-bounces at r-project.org>  <mailto:r-help- <mailto:r-help->
> >       > bounces at r-project.org <mailto:bounces at r-project.org> > ] on
> > behalf of Vito M. R.
> >       >       > >> Muggeo [vito.muggeo at unipa.it
> > <mailto:vito.muggeo at unipa.it>  <mailto:vito.muggeo at unipa.it
> > <mailto:vito.muggeo at unipa.it> >
> >       > ]
> >       >       > >> Sent: February 9, 2016 10:15 AM
> >       >       > >> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-
> > project.org <mailto:R-help at r-project.org>
> >       > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >
> >       >       > >> Cc: R-windows at r-project.org <mailto:R-windows at r-
> > project.org>  <mailto:R-windows at r- <mailto:R-windows at r->
> >       > project.org <http://project.org> >
> >       >       > >> Subject: Re: [R] Help required for Rcmdr
> >       >       > >>
> >       >       > >> dear all,
> >       >       > >> I don't know if that problem is related to the Rcmdr
> > package
> >       > itself..
> >       >       > >> (Sekhar try to install any other packages..)
> >       >       > >>
> >       >       > >> I am experiencing the same problem, in that when
> typing
> >       >       > >>
> >       >       > >>   > install.packages("_ANY_PACKAGE_")
> >       >       > >>
> >       >       > >> I get the message
> >       >       > >> Warning message:
> >       >       > >> package ?_ANY_PACKAGE_? is not available (for R
> version
> > 3.2.3)
> >       >       > >>
> >       >       > >> But I can download the .zip file and unzip it..
> >       >       > >>
> >       >       > >> I tried different CRAN mirrors...
> >       >       > >>
> >       >       > >> best,
> >       >       > >> vito
> >       >       > >>
> >       >       > >>
> >       >       > >> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> >       >       > >>>
> >       >       > >>> Dear Mr. Murdoch,
> >       >       > >>> I am extremely sorry to have sent the mail to you
> instead
> > of R-
> >       > help.
> >       >       > >>> Thanks
> >       >       > >>> for directing me.
> >       >       > >>> I have downloaded R 3.2.3 version. After that i
> asked for
> >       >       > >>> install.packages("Rcmdr") . It says that Rcmdr is not
> > available
> >       > with
> >       >       > >>> version 3.2.3. On looking at the pdf file for
> getting started
> > with
> >       >       > >>> R, i found that i should download with SDI Graphical
> > interface
> >       > which
> >       >       > >>> I did once again but still i could not get the Rcmdr
> console.
> >       >       > >>> I attended a workshop where the faculty brought out
> the
> > R
> >       > console as
> >       >       > >>> well as the R-commander console where i could import
> > files
> >       > and also
> >       >       > >>> do all the statistics easily. I am not getting the R-
> > commander
> >       > console.
> >       >       > >>> Shall be grateful if i could get help on getting the
> R-
> > commander
> >       >       > >>> console with the user friendly way of doing the
> statistical
> >       > operations.
> >       >       > >>> Thanks and regards,
> >       >       > >>> Once again apologize to Dr. Duncan Murdoch for
> > disturbing
> >       > him.
> >       >       > >>> Sekhar
> >       >       > >>>
> >       >       > >>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch
> >       >       > >>> <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>
> >       > <mailto:murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com> > >
> >       >       > >>> wrote:
> >       >       > >>>
> >       >       > >>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
> >       >       > >>>>
> >       >       > >>>>> Dear Sirs,
> >       >       > >>>>> I have downloaded R 3.2.3 version from the CRAN
> site. I
> >       > have tried
> >       >       > >>>>> to download with both MDI and SDI user interface.
> But
> >       > Rcmdr is not
> >       >       > >>>>> opening in as a console  along with R console.
> Help is
> >       > required to
> >       >       > >>>>> open Rcmdr. I have tried install.packages("Rcmdr"),
> >       > library(Rcmdr)
> >       >       > >>>>> etc but to no avail.
> >       >       > >>>>> thanks
> >       >       > >>>>> Sekhar
> >       >       > >>>>> Delhi
> >       >       > >>>>> India
> >       >       > >>>>>
> >       >       > >>>>> This is the wrong email address for help.  Please
> write
> > to R-
> >       > help,
> >       >       > >>>>> and
> >       >       > >>>>
> >       >       > >>>> describe what happens when you try the commands
> > that are
> >       > failing.
> >       >       > >>>>
> >       >       > >>>> Duncan Murdoch
> >       >       > >>>>
> >       >       > >>>
> >       >       > >>>        [[alternative HTML version deleted]]
> >       >       > >>>
> >       >       > >>>
> > ______________________________________________
> >       >       > >>> R-help at r-project.org <mailto:R-help at r-project.org>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> >       > list -- To UNSUBSCRIBE and more, see
> >       >       > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >       >       > >>> PLEASE do read the posting guide
> >       >       > >>> http://www.R-project.org/posting-guide.html
> >       >       > >>> and provide commented, minimal, self-contained,
> >       > reproducible code.
> >       >       > >>>
> >       >       > >>
> >       >       > >> --
> >       >       > >>
> > ==============================================
> >       >       > >> Vito M.R. Muggeo
> >       >       > >> Dip.to Sc Statist e Matem `Vianelli'
> >       >       > >> Universit? di Palermo
> >       >       > >> viale delle Scienze, edificio 13
> >       >       > >> 90128 Palermo - ITALY
> >       >       > >> tel: 091 23895240
> >       >       > >> fax: 091 485726
> >       >       > >> http://dssm.unipa.it/vmuggeo
> >       >       > >> Associate Editor, Statistical Modelling
> >       >       > >>
> >       >       > >>
> > ______________________________________________
> >       >       > >> R-help at r-project.org <mailto:R-help at r-project.org>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> list
> >       > -- To UNSUBSCRIBE and more, see
> >       >       > >> https://stat.ethz.ch/mailman/listinfo/r-help
> >       >       > >> PLEASE do read the posting guide
> >       >       > >> http://www.R-project.org/posting-guide.html
> >       >       > >> and provide commented, minimal, self-contained,
> > reproducible
> >       > code.
> >       >       > >>
> >       >       > >
> >       >       > > --
> >       >       > > ==============================================
> >       >       > > Vito M.R. Muggeo
> >       >       > > Dip.to Sc Statist e Matem `Vianelli'
> >       >       > > Universit? di Palermo
> >       >       > > viale delle Scienze, edificio 13
> >       >       > > 90128 Palermo - ITALY
> >       >       > > tel: 091 23895240
> >       >       > > fax: 091 485726
> >       >       > > http://dssm.unipa.it/vmuggeo
> >       >       > > Associate Editor, Statistical Modelling
> >       >       > >
> >       >       > > ______________________________________________
> >       >       > > R-help at r-project.org <mailto:R-help at r-project.org>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> list -
> >       > - To UNSUBSCRIBE and more, see
> >       >       > > https://stat.ethz.ch/mailman/listinfo/r-help
> >       >       > > PLEASE do read the posting guide
> >       >       > > http://www.R-project.org/posting-guide.html
> >       >       > > and provide commented, minimal, self-contained,
> > reproducible
> >       > code.
> >       >
> >       >
> >
> >
>
>

	[[alternative HTML version deleted]]


From Behnam.ABABAEI at limagrain.com  Sun Feb 21 18:20:02 2016
From: Behnam.ABABAEI at limagrain.com (ABABAEI, Behnam)
Date: Sun, 21 Feb 2016 17:20:02 +0000
Subject: [R] Why CLARA clustering method does not give the same classes
 as when I do clustering manually?
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70C958@mb02.ads.tamu.edu>
References: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjum8kiGFhc4BvDgrhqcNsEdK0KUFnyBd2rSiX1-Sr6b8dg@mail.gmail.com>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70C958@mb02.ads.tamu.edu>
Message-ID: <AM3PR06MB099446251D123798A188361B81A20@AM3PR06MB0994.eurprd06.prod.outlook.com>

By the way, I have to say that I am dealing with missing values and that is why I am using clara or I may use pam, as kmeans (which is very good at dealing with large datasets) cannot handle missing values.

Behnam.

________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 21 February 2016 17:55
To: Sarah Goslee; ABABAEI, Behnam
Cc: r-help at r-project.org
Subject: RE: [R] Why CLARA clustering method does not give the same classes as when I do clustering manually?

I do not think this is quite true. When the medoids are not specified, pam/clara looks for a good initial set (build phase) and then finds a local minimum of the objective function (swap phase). Both pam/clara and kmeans can find local minima that are not the global minimum. If the build phase involves any random element, two runs could produce different results. If not, then the original order of the data determines the final result, but the final result is not necessarily the best one possible (assuming the order of the data is irrelevant to the analysis so we are not looking at observations taken along a line in time or space). That is why kmeans includes an argument to run the algorithm multiple times and pick the best result.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
Sent: Friday, February 19, 2016 1:47 PM
To: ABABAEI, Behnam
Cc: r-help at r-project.org
Subject: Re: [R] Why CLARA clustering method does not give the same classes as when I do clustering manually?

clara() is a version of pam() adapted to use large datasets.

pam() uses the entire dataset, and should give results identical to
your manual procedure, or nearly so. clara() works on subsets of the
data, so it may give a slightly different result each time you run it.

The default parameters for clara() are very small, so you can get
substantially different results from run to run on a large dataset if
you don't change them.

Sarah

On Fri, Feb 19, 2016 at 6:30 AM, ABABAEI, Behnam
<Behnam.ABABAEI at limagrain.com> wrote:
> Hi,
>
>
> I am using CLARA (in 'cluster' package). This method is supposed to assign each observation to the closest 'medoid'. But when I calculate the distance of medoids and observations manually and assign them manually, the results are slightly different (1-2 percent of occurrence probability). Does anyone know how clara calculates dissimilarities and why I get different clustering results?
>
>
> Behnam.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kalyanchakravarty456 at gmail.com  Sun Feb 21 18:43:07 2016
From: kalyanchakravarty456 at gmail.com (kalyan chakravarty)
Date: Sun, 21 Feb 2016 23:13:07 +0530
Subject: [R] Question On Regex and DataFrame
Message-ID: <CAP2AoPSsc2Z3X-TDYdwXgUwGH1tDXwBnGsEt2Tj_jT_TZj83HQ@mail.gmail.com>

Hi,
I am new to R and learning the basics.so i came to know that data frame can
store any data type as oppose to matrix which stores only numeric.My
question is
1.)How to replace a particular pattern with new pattern in data frame.I
tried something like
x = as.data.frame(gsub(".*LINK.*","NA",file))........but the output is
really weird it converts every thing in zeros and ones.

what i actually want is DELETE ALL THE RANDOM COLUMS IN DF BASED ON ROW
VALUE.

file = read.csv("x.csv",header=T,sep=",")#read the file
file[file == "LINK"] = NA #replaced row pattern with NA
file[,colSums(is.na(file))==0] #deleting all colums which has na's

This approach pretty much does the thing but i want to get familiar on how
to use regular expressions over data frame.
Any suggestions on which function/package/regex to use when dealing with
DataFrame

Sorry if this is a basic question.
Thank you

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 22 04:02:12 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 21 Feb 2016 19:02:12 -0800
Subject: [R] Question On Regex and DataFrame
In-Reply-To: <CAP2AoPSsc2Z3X-TDYdwXgUwGH1tDXwBnGsEt2Tj_jT_TZj83HQ@mail.gmail.com>
References: <CAP2AoPSsc2Z3X-TDYdwXgUwGH1tDXwBnGsEt2Tj_jT_TZj83HQ@mail.gmail.com>
Message-ID: <CAGxFJbSdisJFgTfUpWW4PTkzi+u3NLhfDNb4_ia3Va2KFKvhwg@mail.gmail.com>

Inline beow.

On Sunday, February 21, 2016, kalyan chakravarty <
kalyanchakravarty456 at gmail.com> wrote:

> Hi,
> I am new to R and learning the basics.so i came to know that data frame can
> store any data type as oppose to matrix which stores only numeric.My
> question is


False. You need to spend more time with a tutorial or two, as your initial
"understanding" is already incorrect. The rstudio.com website has some nice
suggestions for web tutorials, though you can certainly find many just by
searching.

Your questions below are essentially nonsense, because you do not
understand the data frame concept.

Cheers,
Bert

1.)How to replace a particular pattern with new pattern in data frame.I
> tried something like
> x = as.data.frame(gsub(".*LINK.*","NA",file))........but the output is
> really weird it converts every thing in zeros and ones.
>
> what i actually want is DELETE ALL THE RANDOM COLUMS IN DF BASED ON ROW
> VALUE.
>
> file = read.csv("x.csv",header=T,sep=",")#read the file
> file[file == "LINK"] = NA #replaced row pattern with NA
> file[,colSums(is.na(file))==0] #deleting all colums which has na's
>
> This approach pretty much does the thing but i want to get familiar on how
> to use regular expressions over data frame.
> Any suggestions on which function/package/regex to use when dealing with
> DataFrame
>
> Sorry if this is a basic question.
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb 22 03:57:00 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 21 Feb 2016 18:57:00 -0800
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGyA+HMbJjUiGEfYbcF3TRFPywyH_NJ2GF02gGJrCYY5AEU57A@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
	<CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F55E86@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMBzcc8ma-19+ZebH4Ci-xpDm3fvCxg8o=8sFKO4H45Dw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563C2@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMLYtWcndPc4Mn68FD+o4UWSPk0OAcAiR7VrbDGEagHmw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F56414@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMbJjUiGEfYbcF3TRFPywyH_NJ2GF02gGJrCYY5AEU57A@mail.gmail.com>
Message-ID: <2ADEB78E-C2E8-4815-A360-3C2AE65EB806@dcn.davis.ca.us>

Not sure what C+ software is, but with regard to C or C++ compilers the short answer is probably not.  The true answer is that it may depend on your unspecified operating system and on what packages you want to use. 

If you are on windows you can install most packages from zip files with no compiler. Also, many packages that contain only R source code can be installed from tar.gz files even without a compiler.
-- 
Sent from my phone. Please excuse my brevity.

On February 21, 2016 4:49:08 AM PST, Sekhar Venkatesan <venkatesansekhar at gmail.com> wrote:
>Dear Sirs,
>just wanted to check whether C+ or C++ software is required to be in
>the
>installed in the laptop in order to use Rcmdr
>regards
>sekhar
>
>On Wed, Feb 10, 2016 at 10:17 PM, Fox, John <jfox at mcmaster.ca> wrote:
>
>> Dear Sekhar,
>>
>> > -----Original Message-----
>> > From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com]
>> > Sent: February 10, 2016 11:37 AM
>> > To: Fox, John <jfox at mcmaster.ca>
>> > Subject: RE: [R] Help required for Rcmdr
>> >
>> > Tks and sorry for inadvertently sending to u alone
>>
>> And you apparently just did that again, so again I'm cc'ing to
>r-help.
>>
>> > In any case I hv tried all
>> > over again but to no avail Regards Sekhar
>>
>> I assume that  by "tried all over again" you mean you tried again
>with an
>> HTTP rather than HTTPS CRAN mirror and that didn't work.
>>
>> I'm afraid that I'm out of ideas.
>>
>> Maybe someone else will have a suggestion.
>>
>> John
>>
>> >
>> > On Feb 10, 2016 9:59 PM, "Fox, John" <jfox at mcmaster.ca
>> > <mailto:jfox at mcmaster.ca> > wrote:
>> >
>> >
>> >       Dear Sekhar,
>> >
>> >       I'm sorry that you're experiencing these problems. Although
>you
>> > haven't said so directly, I assume that you aren't able to use
>> install.packages()
>> > to install *any* CRAN packages, not just the Rcmdr package.
>> >
>> >       Downloading and unpacking the Rcmdr zip file doesn't install
>the
>> > package. You can install the zip-file binary package from the R
>Windows
>> GUI
>> > via the "Packages > Install package(s) from local zip files" menu,
>but
>> that too
>> > won't really help because it won't install the many CRAN packages
>on
>> which
>> > the Rcmdr depends.
>> >
>> >       As I said earlier, my guess is that you're experiencing a
>problem
>> with
>> > a firewall, proxy server, or HTTPS. If the latter (which was Vito's
>> problem),
>> > you can easily solve the problem by using an HTTP CRAN server in
>> preference
>> > to the default HTTPS:
>> >
>> >       Enter the command chooseCRANmirror(useHTTPS=FALSE) at the R
>> > Console > prompt and select a CRAN mirror -- I suggest the first
>> (0-Cloud)
>> > mirror. Then issue the command install.packages("Rcmdr"), as
>before.
>> >
>> >       If that doesn't work, I'm afraid I don't have other
>suggestions.
>> >
>> >       You appear to have sent this message only to me, not to
>r-help.
>> That
>> > not a good idea for several reasons, not least of which is that
>people
>> who
>> > have other suggestions won't see your message. I'm cc'ing this
>response
>> to r-
>> > help.
>> >
>> >       Best,
>> >        John
>> >
>> >       > -----Original Message-----
>> >       > From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com
>> > <mailto:venkatesansekhar at gmail.com> ]
>> >       > Sent: February 10, 2016 12:03 AM
>> >       > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
>> >       > Subject: Re: [R] Help required for Rcmdr
>> >       >
>> >       > Dear Sirs,
>> >       > Thanks to everyone for trying to help me. i have tried
>several
>> CRAN
>> > mirrors
>> >       > but to no help. I am getting the Zip file for Rcmdr and can
>also
>> unzip
>> > the
>> >       > same. However, after that i am unable to open the Rcmdr
>console.
>> >       > that is the problem.
>> >       > regards
>> >       > sekhar
>> >       >
>> >       > On Tue, Feb 9, 2016 at 10:00 PM, Fox, John
><jfox at mcmaster.ca
>> > <mailto:jfox at mcmaster.ca>
>> >       > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > >
>wrote:
>> >       >
>> >       >
>> >       >       Hi Rich,
>> >       >
>> >       >       > -----Original Message-----
>> >       >       > From: Richard M. Heiberger [mailto:rmh at temple.edu
>> > <mailto:rmh at temple.edu>
>> >       > <mailto:rmh at temple.edu <mailto:rmh at temple.edu> > ]
>> >       >       > Sent: February 9, 2016 4:57 PM
>> >       >       > To: Vito M. R. Muggeo <vito.muggeo at unipa.it
>> > <mailto:vito.muggeo at unipa.it>
>> >       > <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it>
>> >
>> >       >       > Cc: Fox, John <jfox at mcmaster.ca
><mailto:jfox at mcmaster.ca
>> >
>> > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > >;
>> >       > Sekhar Venkatesan
>> >       >       > <venkatesansekhar at gmail.com
>> > <mailto:venkatesansekhar at gmail.com>
>> >       > <mailto:venkatesansekhar at gmail.com
>> > <mailto:venkatesansekhar at gmail.com> > >; Duncan Murdoch
>> >       >       > <murdoch.duncan at gmail.com
>> > <mailto:murdoch.duncan at gmail.com>
>> >       > <mailto:murdoch.duncan at gmail.com
>> > <mailto:murdoch.duncan at gmail.com> > >; R-help at r-project.org
><mailto:R-
>> > help at r-project.org>  <mailto:R- <mailto:R->
>> >       > help at r-project.org <mailto:help at r-project.org> > ;
>R-windows at r-
>> >       >       > project.org <http://project.org> 
><http://project.org>
>> >       >       > Subject: Re: [R] Help required for Rcmdr
>> >       >       >
>> >       >       > Several of my students have had this type of
>difficulty
>> with
>> > Rstudio.
>> >       >       >
>> >       >
>> >       >       Good to know, but the original poster tried both with
>the R
>> > Windows
>> >       > SDI and MDI.
>> >       >
>> >       >       Best,
>> >       >        John
>> >       >
>> >       >
>> >       >       > Rstudio masks install.packages with a similarly
>named
>> function
>> > in an
>> >       >       > environment that does not appear in either
>> > conflicts(details=TRUE)
>> >       > or in
>> >       >       > search().
>> >       >       >
>> >       >       > The workaround is an explicit call to utils
>> >       >       >
>> >       >       > utils::install.packages("package.name <
>> http://package.name>
>> > <http://package.name> ")
>> >       >       >
>> >       >       > Rich
>> >       >       >
>> >       >       > On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo
>> >       > <vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it>
>> > <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
>> >       >       > wrote:
>> >       >       > > dear John,
>> >       >       > > Thanks for your prompt reply
>> >       >       > >
>> >       >       > > Il 09/02/2016 16.23, Fox, John ha scritto:
>> >       >       > >>
>> >       >       > >> Dear Vito,
>> >       >       > >>
>> >       >       > >> I've never experienced this problem myself in a
>> general
>> > way,
>> >       >       > >
>> >       >       > > Me too. I have always installed R packages
>> > straightforwardly..
>> >       >       > >
>> >       >       > > and I'm sure that Windows users of R call
>> install.packages()
>> > all the
>> >       >       > > time to install packages from CRAN mirrors.
>> >       >       > > Of course..
>> >       >       > >
>> >       >       > > So the question to ask, I think, is what's
>preventing
>> >       >       > > install.packages() from working in your case --
>> possibly an
>> >       > Internet
>> >       >       > > connectivity problem due to a firewall, proxy
>server,
>> use of
>> > https,
>> >       > etc.
>> >       >       > > I'm sure that others more knowledgeable about
>these
>> issues
>> >       > than I am
>> >       >       > > will be able to make more specific suggestions
>for
>> fixing the
>> >       > problem.
>> >       >       > >
>> >       >       > > However I have just checked that it works with
>*http*
>> > servers
>> >       > (but not
>> >       >       > > for any other *https*..)
>> >       >       > >
>> >       >       > > Thanks for your support,
>> >       >       > > best,
>> >       >       > > vito
>> >       >       > >
>> >       >       > >
>> >       >       > >>
>> >       >       > >> Best,
>> >       >       > >>   John
>> >       >       > >>
>> >       >       > >> -----------------------------
>> >       >       > >> John Fox, Professor
>> >       >       > >> McMaster University
>> >       >       > >> Hamilton, Ontario
>> >       >       > >> Canada L8S 4M4
>> >       >       > >> web: socserv.mcmaster.ca/jfox
>> > <http://socserv.mcmaster.ca/jfox>
>> >       > <http://socserv.mcmaster.ca/jfox>
>> >       >       > >>
>> >       >       > >>
>> >       >       > >> ________________________________________
>> >       >       > >> From: R-help [r-help-bounces at r-project.org
><mailto:r-
>> > help-bounces at r-project.org>  <mailto:r-help- <mailto:r-help->
>> >       > bounces at r-project.org <mailto:bounces at r-project.org> > ] on
>> > behalf of Vito M. R.
>> >       >       > >> Muggeo [vito.muggeo at unipa.it
>> > <mailto:vito.muggeo at unipa.it>  <mailto:vito.muggeo at unipa.it
>> > <mailto:vito.muggeo at unipa.it> >
>> >       > ]
>> >       >       > >> Sent: February 9, 2016 10:15 AM
>> >       >       > >> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-
>> > project.org <mailto:R-help at r-project.org>
>> >       > <mailto:R-help at r-project.org <mailto:R-help at r-project.org>
>>
>> >       >       > >> Cc: R-windows at r-project.org <mailto:R-windows at r-
>> > project.org>  <mailto:R-windows at r- <mailto:R-windows at r->
>> >       > project.org <http://project.org> >
>> >       >       > >> Subject: Re: [R] Help required for Rcmdr
>> >       >       > >>
>> >       >       > >> dear all,
>> >       >       > >> I don't know if that problem is related to the
>Rcmdr
>> > package
>> >       > itself..
>> >       >       > >> (Sekhar try to install any other packages..)
>> >       >       > >>
>> >       >       > >> I am experiencing the same problem, in that when
>> typing
>> >       >       > >>
>> >       >       > >>   > install.packages("_ANY_PACKAGE_")
>> >       >       > >>
>> >       >       > >> I get the message
>> >       >       > >> Warning message:
>> >       >       > >> package ?_ANY_PACKAGE_? is not available (for R
>> version
>> > 3.2.3)
>> >       >       > >>
>> >       >       > >> But I can download the .zip file and unzip it..
>> >       >       > >>
>> >       >       > >> I tried different CRAN mirrors...
>> >       >       > >>
>> >       >       > >> best,
>> >       >       > >> vito
>> >       >       > >>
>> >       >       > >>
>> >       >       > >> Il 09/02/2016 12.44, Sekhar Venkatesan ha
>scritto:
>> >       >       > >>>
>> >       >       > >>> Dear Mr. Murdoch,
>> >       >       > >>> I am extremely sorry to have sent the mail to
>you
>> instead
>> > of R-
>> >       > help.
>> >       >       > >>> Thanks
>> >       >       > >>> for directing me.
>> >       >       > >>> I have downloaded R 3.2.3 version. After that i
>> asked for
>> >       >       > >>> install.packages("Rcmdr") . It says that Rcmdr
>is not
>> > available
>> >       > with
>> >       >       > >>> version 3.2.3. On looking at the pdf file for
>> getting started
>> > with
>> >       >       > >>> R, i found that i should download with SDI
>Graphical
>> > interface
>> >       > which
>> >       >       > >>> I did once again but still i could not get the
>Rcmdr
>> console.
>> >       >       > >>> I attended a workshop where the faculty brought
>out
>> the
>> > R
>> >       > console as
>> >       >       > >>> well as the R-commander console where i could
>import
>> > files
>> >       > and also
>> >       >       > >>> do all the statistics easily. I am not getting
>the R-
>> > commander
>> >       > console.
>> >       >       > >>> Shall be grateful if i could get help on
>getting the
>> R-
>> > commander
>> >       >       > >>> console with the user friendly way of doing the
>> statistical
>> >       > operations.
>> >       >       > >>> Thanks and regards,
>> >       >       > >>> Once again apologize to Dr. Duncan Murdoch for
>> > disturbing
>> >       > him.
>> >       >       > >>> Sekhar
>> >       >       > >>>
>> >       >       > >>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch
>> >       >       > >>> <murdoch.duncan at gmail.com
>> > <mailto:murdoch.duncan at gmail.com>
>> >       > <mailto:murdoch.duncan at gmail.com
>> > <mailto:murdoch.duncan at gmail.com> > >
>> >       >       > >>> wrote:
>> >       >       > >>>
>> >       >       > >>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan
>wrote:
>> >       >       > >>>>
>> >       >       > >>>>> Dear Sirs,
>> >       >       > >>>>> I have downloaded R 3.2.3 version from the
>CRAN
>> site. I
>> >       > have tried
>> >       >       > >>>>> to download with both MDI and SDI user
>interface.
>> But
>> >       > Rcmdr is not
>> >       >       > >>>>> opening in as a console  along with R
>console.
>> Help is
>> >       > required to
>> >       >       > >>>>> open Rcmdr. I have tried
>install.packages("Rcmdr"),
>> >       > library(Rcmdr)
>> >       >       > >>>>> etc but to no avail.
>> >       >       > >>>>> thanks
>> >       >       > >>>>> Sekhar
>> >       >       > >>>>> Delhi
>> >       >       > >>>>> India
>> >       >       > >>>>>
>> >       >       > >>>>> This is the wrong email address for help. 
>Please
>> write
>> > to R-
>> >       > help,
>> >       >       > >>>>> and
>> >       >       > >>>>
>> >       >       > >>>> describe what happens when you try the
>commands
>> > that are
>> >       > failing.
>> >       >       > >>>>
>> >       >       > >>>> Duncan Murdoch
>> >       >       > >>>>
>> >       >       > >>>
>> >       >       > >>>        [[alternative HTML version deleted]]
>> >       >       > >>>
>> >       >       > >>>
>> > ______________________________________________
>> >       >       > >>> R-help at r-project.org
><mailto:R-help at r-project.org>
>> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> > 
>mailing
>> >       > list -- To UNSUBSCRIBE and more, see
>> >       >       > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >       >       > >>> PLEASE do read the posting guide
>> >       >       > >>> http://www.R-project.org/posting-guide.html
>> >       >       > >>> and provide commented, minimal, self-contained,
>> >       > reproducible code.
>> >       >       > >>>
>> >       >       > >>
>> >       >       > >> --
>> >       >       > >>
>> > ==============================================
>> >       >       > >> Vito M.R. Muggeo
>> >       >       > >> Dip.to Sc Statist e Matem `Vianelli'
>> >       >       > >> Universit? di Palermo
>> >       >       > >> viale delle Scienze, edificio 13
>> >       >       > >> 90128 Palermo - ITALY
>> >       >       > >> tel: 091 23895240
>> >       >       > >> fax: 091 485726
>> >       >       > >> http://dssm.unipa.it/vmuggeo
>> >       >       > >> Associate Editor, Statistical Modelling
>> >       >       > >>
>> >       >       > >>
>> > ______________________________________________
>> >       >       > >> R-help at r-project.org
><mailto:R-help at r-project.org>
>> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> > 
>mailing
>> list
>> >       > -- To UNSUBSCRIBE and more, see
>> >       >       > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >       >       > >> PLEASE do read the posting guide
>> >       >       > >> http://www.R-project.org/posting-guide.html
>> >       >       > >> and provide commented, minimal, self-contained,
>> > reproducible
>> >       > code.
>> >       >       > >>
>> >       >       > >
>> >       >       > > --
>> >       >       > > ==============================================
>> >       >       > > Vito M.R. Muggeo
>> >       >       > > Dip.to Sc Statist e Matem `Vianelli'
>> >       >       > > Universit? di Palermo
>> >       >       > > viale delle Scienze, edificio 13
>> >       >       > > 90128 Palermo - ITALY
>> >       >       > > tel: 091 23895240
>> >       >       > > fax: 091 485726
>> >       >       > > http://dssm.unipa.it/vmuggeo
>> >       >       > > Associate Editor, Statistical Modelling
>> >       >       > >
>> >       >       > > ______________________________________________
>> >       >       > > R-help at r-project.org
><mailto:R-help at r-project.org>
>> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> > 
>mailing
>> list -
>> >       > - To UNSUBSCRIBE and more, see
>> >       >       > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >       >       > > PLEASE do read the posting guide
>> >       >       > > http://www.R-project.org/posting-guide.html
>> >       >       > > and provide commented, minimal, self-contained,
>> > reproducible
>> >       > code.
>> >       >
>> >       >
>> >
>> >
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Mon Feb 22 05:16:06 2016
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 21 Feb 2016 23:16:06 -0500
Subject: [R] Constructing a symmetric matrix with library(corpcor)
Message-ID: <CAKTtY6Q_YXPfbgr_ZEPbTjuz8dqSwh1BbQGoG7CkkqVBUkyMoA@mail.gmail.com>

I like to compose a symmetric matrix in the pattern as shown below (for 3 x
3 and 4 x 4). For a symmetric matrix of order 5, the result does not seem
right. Help? It is possible to write a two-level do loop for the task, but
I suppose that is less efficient.

> library(corpcor)> r  <- 1:3; r[1] 1 2 3> rr <- vec2sm(r, diag = F); rr     [,1] [,2] [,3]
[1,]   NA    1    2
[2,]    1   NA    3
[3,]    2    3   NA> rr <- rr[upper.tri(rr)]; rr[1] 1 2 3> r  <-
vec2sm(rr, diag = F); diag(r) <- 1; r     [,1] [,2] [,3]
[1,]    1    1    2
[2,]    1    1    3
[3,]    2    3    1> r  <- 1:6; r[1] 1 2 3 4 5 6> rr <- vec2sm(r, diag
= F); rr     [,1] [,2] [,3] [,4]
[1,]   NA    1    2    3
[2,]    1   NA    4    5
[3,]    2    4   NA    6
[4,]    3    5    6   NA> rr <- rr[upper.tri(rr)]; rr[1] 1 2 4 3 5 6>
r  <- vec2sm(rr, diag = F); diag(r) <- 1; r     [,1] [,2] [,3] [,4]
[1,]    1    1    2    4
[2,]    1    1    3    5
[3,]    2    3    1    6
[4,]    4    5    6    1> r  <- 1:10; r [1]  1  2  3  4  5  6  7  8  9
10> rr <- vec2sm(r, diag = F); rr     [,1] [,2] [,3] [,4] [,5]
[1,]   NA    1    2    3    4
[2,]    1   NA    5    6    7
[3,]    2    5   NA    8    9
[4,]    3    6    8   NA   10
[5,]    4    7    9   10   NA> rr <- rr[upper.tri(rr)]; rr [1]  1  2
5  3  6  8  4  7  9 10> r  <- vec2sm(rr, diag = F); diag(r) <- 1; r
 [,1] [,2] [,3] [,4] [,5]
[1,]    1    1    2    5    3
[2,]    1    1    6    8    4
[3,]    2    6    1    7    9
[4,]    5    8    7    1   10
[5,]    3    4    9   10    1


(Doesn't seem right).
This is what I need:

     [,1] [,2] [,3] [,4] [,5]
[1,]    1    1    2    4    7
[2,]    1    1    3    5    8
[3,]    2    3    1    6    9
[4,]    4    5    6    1   10
[5,]    7    8    9   10    1

>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Feb 22 05:46:33 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 22 Feb 2016 15:46:33 +1100
Subject: [R] Question On Regex and DataFrame
In-Reply-To: <CAP2AoPSsc2Z3X-TDYdwXgUwGH1tDXwBnGsEt2Tj_jT_TZj83HQ@mail.gmail.com>
References: <CAP2AoPSsc2Z3X-TDYdwXgUwGH1tDXwBnGsEt2Tj_jT_TZj83HQ@mail.gmail.com>
Message-ID: <CA+8X3fUKDDvkO8ArsYN=fa=rLd9o+D7FLN04Vyz_EU0==15N1Q@mail.gmail.com>

Hi kalyan,
It is a bit difficult to work out what you want to do. However, there are
some things I can suggest. The gsub function is useful for changing strings
not assigning new values. If you want to delete a column of a data frame if
there are any NA values, you first want to check for NA values (let's call
your data frame x.df to avoid confusion):

x.df<-data.frame(a=sample(1:10,10),
 b=c(sample(1:10,9),NA),c=sample(1:10,10))
any(is.na(x.df[,1]))

will return TRUE if at least one element of the first column of x.df is NA.
Next you want to know how many columns there are in x.df:

ncols<-dim(x.df)[2]

Now you can step through the columns _backwards_ (so you don't change the
order of the columns you are testing) to delete any containing NA values:

for(column in ncols:1) if(any(is.na(x.df[,column]))) x.df[[column]]<-NULL

This leaves me with the first and third columns of x.df.

Jim

On Mon, Feb 22, 2016 at 4:43 AM, kalyan chakravarty <
kalyanchakravarty456 at gmail.com> wrote:

> Hi,
> I am new to R and learning the basics.so i came to know that data frame can
> store any data type as oppose to matrix which stores only numeric.My
> question is
> 1.)How to replace a particular pattern with new pattern in data frame.I
> tried something like
> x = as.data.frame(gsub(".*LINK.*","NA",file))........but the output is
> really weird it converts every thing in zeros and ones.
>
> what i actually want is DELETE ALL THE RANDOM COLUMS IN DF BASED ON ROW
> VALUE.
>
> file = read.csv("x.csv",header=T,sep=",")#read the file
> file[file == "LINK"] = NA #replaced row pattern with NA
> file[,colSums(is.na(file))==0] #deleting all colums which has na's
>
> This approach pretty much does the thing but i want to get familiar on how
> to use regular expressions over data frame.
> Any suggestions on which function/package/regex to use when dealing with
> DataFrame
>
> Sorry if this is a basic question.
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb 22 06:59:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 21 Feb 2016 21:59:38 -0800
Subject: [R] Constructing a symmetric matrix with library(corpcor)
In-Reply-To: <CAKTtY6Q_YXPfbgr_ZEPbTjuz8dqSwh1BbQGoG7CkkqVBUkyMoA@mail.gmail.com>
References: <CAKTtY6Q_YXPfbgr_ZEPbTjuz8dqSwh1BbQGoG7CkkqVBUkyMoA@mail.gmail.com>
Message-ID: <39F3EA9C-7859-498A-8096-54C0E79123A5@dcn.davis.ca.us>

vec2sm( r, diag = FALSE, order=rr )

Next time please make an effort to post using plain text format, as your HTML-formatted email got rather messed up coming through this plain-text mailing list. 

You might find a reading of The R Inferno informative on the subject of F vs. FALSE.
-- 
Sent from my phone. Please excuse my brevity.

On February 21, 2016 8:16:06 PM PST, Steven Yen <syen04 at gmail.com> wrote:
>I like to compose a symmetric matrix in the pattern as shown below (for
>3 x
>3 and 4 x 4). For a symmetric matrix of order 5, the result does not
>seem
>right. Help? It is possible to write a two-level do loop for the task,
>but
>I suppose that is less efficient.
>
>> library(corpcor)> r  <- 1:3; r[1] 1 2 3> rr <- vec2sm(r, diag = F);
>rr     [,1] [,2] [,3]
>[1,]   NA    1    2
>[2,]    1   NA    3
>[3,]    2    3   NA> rr <- rr[upper.tri(rr)]; rr[1] 1 2 3> r  <-
>vec2sm(rr, diag = F); diag(r) <- 1; r     [,1] [,2] [,3]
>[1,]    1    1    2
>[2,]    1    1    3
>[3,]    2    3    1> r  <- 1:6; r[1] 1 2 3 4 5 6> rr <- vec2sm(r, diag
>= F); rr     [,1] [,2] [,3] [,4]
>[1,]   NA    1    2    3
>[2,]    1   NA    4    5
>[3,]    2    4   NA    6
>[4,]    3    5    6   NA> rr <- rr[upper.tri(rr)]; rr[1] 1 2 4 3 5 6>
>r  <- vec2sm(rr, diag = F); diag(r) <- 1; r     [,1] [,2] [,3] [,4]
>[1,]    1    1    2    4
>[2,]    1    1    3    5
>[3,]    2    3    1    6
>[4,]    4    5    6    1> r  <- 1:10; r [1]  1  2  3  4  5  6  7  8  9
>10> rr <- vec2sm(r, diag = F); rr     [,1] [,2] [,3] [,4] [,5]
>[1,]   NA    1    2    3    4
>[2,]    1   NA    5    6    7
>[3,]    2    5   NA    8    9
>[4,]    3    6    8   NA   10
>[5,]    4    7    9   10   NA> rr <- rr[upper.tri(rr)]; rr [1]  1  2
>5  3  6  8  4  7  9 10> r  <- vec2sm(rr, diag = F); diag(r) <- 1; r
> [,1] [,2] [,3] [,4] [,5]
>[1,]    1    1    2    5    3
>[2,]    1    1    6    8    4
>[3,]    2    6    1    7    9
>[4,]    5    8    7    1   10
>[5,]    3    4    9   10    1
>
>
>(Doesn't seem right).
>This is what I need:
>
>     [,1] [,2] [,3] [,4] [,5]
>[1,]    1    1    2    4    7
>[2,]    1    1    3    5    8
>[3,]    2    3    1    6    9
>[4,]    4    5    6    1   10
>[5,]    7    8    9   10    1
>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Mon Feb 22 09:12:43 2016
From: simon0098 at yahoo.com (simon0098 at yahoo.com)
Date: Mon, 22 Feb 2016 00:12:43 -0800
Subject: [R] R portable is unable to open base package
Message-ID: <1456128763.44881.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>

I'm using shiny package to make a desktop application for my GUI. When I run my batch file, I receive the following error in the log file:
Fatal error : unable to open the base package

I checked my library path and it was correctly set to R portable library path. Also I tried to install base package using install.packages("base") but R gave a warning: package 'base' is not available (for version R 3.2.3) 

How should I solve this problem?


	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Feb 22 09:23:37 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 22 Feb 2016 08:23:37 +0000
Subject: [R] Genoa course: Introduction to Zero Inflated Models
Message-ID: <56CAC589.7010300@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Zero Inflated Models
Where:  Italian National Antarctic Museum, Genoa, Italy
When:   9-13 May 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://highstat.com/Courses/Flyers/Flyer2016_5Genoa.pdf



Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


From santosh2005 at gmail.com  Mon Feb 22 09:35:38 2016
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 22 Feb 2016 00:35:38 -0800
Subject: [R] ReporteRs R package installation issues in R.3.2.3 (Windows)
Message-ID: <CAN_e6XuPLqz_rMHyqQ4LWWzOzH+u+TiqbeL7AQCZuuSW+rLwnA@mail.gmail.com>

Dear Rxperts..

I tried to install ReporteRs package..in R.3.2.3 (Windows)
Below are the error messages...

> install.packages("ReporteRs",dep=T)
trying URL '
http://cran.cnr.berkeley.edu/bin/windows/contrib/3.2/ReporteRs_0.8.2.zip'
Content type 'application/zip' length 947836 bytes (925 KB)
downloaded 925 KB

package ?ReporteRs? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\santosh\AppData\Local\Temp\RtmpMlGfvG\downloaded_packages

> library(ReporteRs)
Loading required package: ReporteRsjars
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: No CurrentVersion entry in Software/JavaSoft registry! Try
re-installing Java and make sure R and Java have matching architectures.
Error: package ?ReporteRsjars? could not be loaded

I tried to install ReporteRsJars..
> install.packages("ReporteRsjars")
trying URL '
http://cran.cnr.berkeley.edu/bin/windows/contrib/3.2/ReporteRsjars_0.0.2.zip
'
Content type 'application/zip' length 5502826 bytes (5.2 MB)
downloaded 5.2 MB

package ?ReporteRsjars? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\santoshAppData\Local\Temp\RtmpMlGfvG\downloaded_packages
>
> library(ReporteRsjars)
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: No CurrentVersion entry in Software/JavaSoft registry! Try
re-installing Java and make sure R and Java have matching architectures.
Error: package or namespace load failed for ?ReporteRsjars?
>

rJava and and ReporteRsjars were having issues with loading even though
there were shown as successfully installed.

Would appreciate your help/solution/ideas in this regard..

Thanks much,
Santosh

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Mon Feb 22 09:45:04 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 22 Feb 2016 09:45:04 +0100
Subject: [R] ReporteRs R package installation issues in R.3.2.3 (Windows)
In-Reply-To: <CAN_e6XuPLqz_rMHyqQ4LWWzOzH+u+TiqbeL7AQCZuuSW+rLwnA@mail.gmail.com>
References: <CAN_e6XuPLqz_rMHyqQ4LWWzOzH+u+TiqbeL7AQCZuuSW+rLwnA@mail.gmail.com>
Message-ID: <56CACA90.7010609@statistik.tu-dortmund.de>

I guess you are using a 64 bit version of R for Windows but you have 
only a 32-bit installation of Java. Please install a 64-bit Java.

Best,
Uwe Ligges


On 22.02.2016 09:35, Santosh wrote:
> Dear Rxperts..
>
> I tried to install ReporteRs package..in R.3.2.3 (Windows)
> Below are the error messages...
>
>> install.packages("ReporteRs",dep=T)
> trying URL '
> http://cran.cnr.berkeley.edu/bin/windows/contrib/3.2/ReporteRs_0.8.2.zip'
> Content type 'application/zip' length 947836 bytes (925 KB)
> downloaded 925 KB
>
> package ?ReporteRs? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>          C:\Users\santosh\AppData\Local\Temp\RtmpMlGfvG\downloaded_packages
>
>> library(ReporteRs)
> Loading required package: ReporteRsjars
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>    call: fun(libname, pkgname)
>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
> re-installing Java and make sure R and Java have matching architectures.
> Error: package ?ReporteRsjars? could not be loaded
>
> I tried to install ReporteRsJars..
>> install.packages("ReporteRsjars")
> trying URL '
> http://cran.cnr.berkeley.edu/bin/windows/contrib/3.2/ReporteRsjars_0.0.2.zip
> '
> Content type 'application/zip' length 5502826 bytes (5.2 MB)
> downloaded 5.2 MB
>
> package ?ReporteRsjars? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>          C:\Users\santoshAppData\Local\Temp\RtmpMlGfvG\downloaded_packages
>>
>> library(ReporteRsjars)
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>    call: fun(libname, pkgname)
>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
> re-installing Java and make sure R and Java have matching architectures.
> Error: package or namespace load failed for ?ReporteRsjars?
>>
>
> rJava and and ReporteRsjars were having issues with loading even though
> there were shown as successfully installed.
>
> Would appreciate your help/solution/ideas in this regard..
>
> Thanks much,
> Santosh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Mon Feb 22 10:13:57 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 22 Feb 2016 10:13:57 +0100
Subject: [R] Why CLARA clustering method does not give the same classes
 as when I do clustering manually?
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70C958@mb02.ads.tamu.edu>
References: <AM3PR06MB099438893199E6E6C6BED02B81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjum8kiGFhc4BvDgrhqcNsEdK0KUFnyBd2rSiX1-Sr6b8dg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70C958@mb02.ads.tamu.edu>
Message-ID: <22218.53589.624042.4171@stat.math.ethz.ch>

>>>>> David L Carlson <dcarlson at tamu.edu>
>>>>>     on Sun, 21 Feb 2016 16:55:56 +0000 writes:

    > I do not think this is quite true. When the medoids are
    > not specified, pam/clara looks for a good initial set
    > (build phase) and then finds a local minimum of the
    > objective function (swap phase). Both pam/clara and kmeans
    > can find local minima that are not the global minimum. 

Indeed, thank you for the explanation so far.

    > If the build phase involves any random element, two runs
    > could produce different results. 

One of the important features of pam (over kmeans) is indeed
that the build phase is entirely deterministic and typically
much better than random starts.
But there is an option to pam() to skip tbe build phase and
start from user specified medoids, so you can also do random
starts as kmeans, by using
      pam(..., medoids = sample(n, k))

And now you should not throw  clara  and  pam together:
Clara does randomly choose a subset from the LARge data
Application ("LARA") and then runs the build phase (and more) with only
that subset; hence clara necessarily has an element of
randomness to it.
Though --- for historical reasons -- the default chosen by CLARA's
original authors had been to always chose the same random seed
by default (and a cheap non-R RNG).  For that reasons, for a
long time now, clara()  has got an argument 'rngR' which you
"should" set to TRUE in order to get the variability of random starts.

.. more feature requests are welcome!

Martin Maechler,
ETH Zurich          == maintainer("cluster")


    > If not, then the original
    > order of the data determines the final result, but the
    > final result is not necessarily the best one possible
    > (assuming the order of the data is irrelevant to the
    > analysis so we are not looking at observations taken along
    > a line in time or space). That is why kmeans includes an
    > argument to run the algorithm multiple times and pick the
    > best result.

    > -------------------------------------
    > David L Carlson Department of Anthropology Texas A&M
    > University College Station, TX 77840-4352

    > -----Original Message----- From: R-help
    > [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
    > Goslee Sent: Friday, February 19, 2016 1:47 PM To:
    > ABABAEI, Behnam Cc: r-help at r-project.org Subject: Re: [R]
    > Why CLARA clustering method does not give the same classes
    > as when I do clustering manually?

    > clara() is a version of pam() adapted to use large
    > datasets.

    > pam() uses the entire dataset, and should give results
    > identical to your manual procedure, or nearly so. clara()
    > works on subsets of the data, so it may give a slightly
    > different result each time you run it.

    > The default parameters for clara() are very small, so you
    > can get substantially different results from run to run on
    > a large dataset if you don't change them.

    > Sarah

    > On Fri, Feb 19, 2016 at 6:30 AM, ABABAEI, Behnam
    > <Behnam.ABABAEI at limagrain.com> wrote:
    >> Hi,
    >> 
    >> 
    >> I am using CLARA (in 'cluster' package). This method is
    >> supposed to assign each observation to the closest
    >> 'medoid'. But when I calculate the distance of medoids
    >> and observations manually and assign them manually, the
    >> results are slightly different (1-2 percent of occurrence
    >> probability). Does anyone know how clara calculates
    >> dissimilarities and why I get different clustering
    >> results?
    >> 
    >> 
    >> Behnam.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From alexandresuire at hotmail.fr  Mon Feb 22 10:37:10 2016
From: alexandresuire at hotmail.fr (Alexandre Suire)
Date: Mon, 22 Feb 2016 10:37:10 +0100
Subject: [R] Problems with the deSolve package
In-Reply-To: <CANKjaMfwdqPXnd=DbHCJkgb5c6YpdmbZx9SA3Kz2CsQcdxdZMw@mail.gmail.com>
References: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>,
	<CANKjaMfwdqPXnd=DbHCJkgb5c6YpdmbZx9SA3Kz2CsQcdxdZMw@mail.gmail.com>
Message-ID: <DUB119-W21FE0AE8575EB6A266E3F9AEA30@phx.gbl>

Hello Abdel, 
 
I'm trying to model the spread of two viruses between different states, which are i1 and i2, and i12 if you got both viruses, but you can go back to the previous state with given probabilities (alpha, beta). The gamma probabilities are just additional infection (without contact) and delta an interaction factor between virus 1 and 2. 

I tried lowering the time steps, and, as you said, i1 and i2 are going 
negative, but it stops after a few steps. In effect, that's not what I'm
 looking for. I just want to model the dynamic of this system, and do some king of sensitivity analysis. I tried different set of parameters, but it still gives me the same error message. Maybe this has to do with my equations ? But I really doubt it. 

Thank you for your time
Alex

From: abdel.halloway at gmail.com
Date: Sat, 20 Feb 2016 11:01:00 -0600
Subject: Re: [R] Problems with the deSolve package
To: alexandresuire at hotmail.fr
CC: r-help at r-project.org

I think your parameters are off. If you look at the simul data frame, it gives you a bunch of NaNs after the first initialization. If you put lower the timesteps s.t.

>
times<-seq(0,200, by=0.01)

it begins to run but soon your values diverge, i1 & i2 going negative while i12 goes way high. Not sure what you are modeling but I assume those values aren't to be like that. Try again with different parameters and see.

On Fri, Feb 19, 2016 at 2:42 AM, Alexandre Suire <alexandresuire at hotmail.fr> wrote:
Hello R-users,



I'm trying to build a SIR-like model under R,

using the "deSolve" package. I'm trying to do simulations of its dynamic

 over time, with three differential equations. I'm also looking to

calculate the equilibrium state.



So far, my code looks like this



library(deSolve)

#This is my system, with three differential equations

system<-function(times, init, parameters){

with(as.list(c(init, parameters)),{

di1_dt=(alpha1*(N-i1-i2-i12)*(i1+i12))+(beta2*i12+gamma1*(N-i1-i2-i12))-(beta1*i1)-(delta*alpha2*i1*(i2+i12))

di2_dt=(alpha2*(N-i1-i2-i12)*(i2+i12))+(beta1*i12+gamma2*(N-i1-i2-i12))-(beta2*i2)-(delta*alpha1*i2*(i1+i12))

di12_dt=(delta*alpha2*i1*(i12+i2))+(delta*alpha1*i2*(i12*i1))+(delta*gamma1*i1)+(delta*gamma2*i2)-((beta1+beta2)*i12)

return(list(c(di1_dt,di2_dt,di12_dt)))

})

}



# Initials values and parameters

init<-c(i1=10, i2=10, i12=0)

parameters<-c(alpha1=0.7, alpha2=0.5, beta1=0.5, beta2=0.3, gamma1=0.5, gamma2=0.5, delta=0.5, N=100)

times<-seq(0,200, by=1)

simul <- as.data.frame(ode(y = init, times = times, func = system, parms = parameters, method="ode45"))

simul$time <- NULL

head(simul,200)



#Plotting the results

matplot(times,

 simul, type = "l", xlab = "Time", ylab = "i1 i2 i12", main =

"Simulation", lwd = 2, lty = 2, bty = "l", col=c("darkblue",

"darkred","mediumseagreen"))

legend("bottomright", c("i1", "i2","i12"), lty=2,lwd=2, col = c("darkblue", "darkred", "mediumseagreen"))



At

 first, I just tried studying with only the first two equations, and it

seems to work completely fine, but when I wanted to add the 3rd

equation, I sometimes get this message, even when I juggle the

parameters, when i launch the line:

#simul <- as.data.frame(ode(y = init, times = times, func = system, parms = parameters))

Warning messages:

1: In lsode(y, times, func, parms, mf = 10, ...) :

  an excessive amount of work (> maxsteps ) was done, but integration was not successful - increase maxsteps

2: In lsode(y, times, func, parms, mf = 10, ...) :

  Returning early. Results are accurate, as far as they go



Have I overlooked something ? I tried to use methods="ode45" and methods="adams", without any sucess.

Thank you for your time

Alex



        [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


 		 	   		  
	[[alternative HTML version deleted]]


From culinovic.domagoj at gmail.com  Mon Feb 22 10:57:47 2016
From: culinovic.domagoj at gmail.com (Domagoj Culinovic)
Date: Mon, 22 Feb 2016 10:57:47 +0100
Subject: [R] GIS Analyses for Economics and Marketing
Message-ID: <CACgt3o=z5Pe8rRgvUnGrBDa90jE-Np+-kdGWcvuf9fV3-C71gA@mail.gmail.com>

I am Phdoctorate Candidate at Faculty of economics.
Also i am using GIS last 26 years, but lat 3 year i am focused on QGIS.
My earea of interests are GIS in Economics and marketing, and now i am
combine R and QGIS to have results.
Can someone help me with some tutorials, training materials or course
examples in area GIS for Marketing or Economics based on QGIS (with Grass
or any other plugins), and some examples of financial analyses based on
historical data in using GIS(for exaple to analyse comunity budget spends
in last 15 years based on GIS data).

	[[alternative HTML version deleted]]


From dmitri.popavenko at gmail.com  Mon Feb 22 12:22:18 2016
From: dmitri.popavenko at gmail.com (Dmitri Popavenko)
Date: Mon, 22 Feb 2016 13:22:18 +0200
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJ=0CtDaSnFKAwMTwVWPn-i6nJ+YTX+AL6hAsH7q49rdFWsVRA@mail.gmail.com>
References: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>
	<1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>
	<CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
	<BD75D26C-41FC-4395-94C2-9CD179307C44@gmail.com>
	<CAJ=0CtDaSnFKAwMTwVWPn-i6nJ+YTX+AL6hAsH7q49rdFWsVRA@mail.gmail.com>
Message-ID: <CAJL_poiwxthPOHoXUpGVe0ft1V63HYOqi31n1XoVn3Xpz4Uaew@mail.gmail.com>

That is a very nice interface, indeed!
What kind of HTML you used for this interface, it is looking different from
the normal.

On Sun, Feb 21, 2016 at 11:37 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:

> Oh, thanks Peter, good example for Mac, but indeed not working on Windows.
> For a completely cross-platform solution (that is, including Windows which
> is what Zahra wants), I believe shiny is the right tool.
>
> So Zahra, if you want to use shiny, you need to look at their own
> tutorials, step by step, and try to understand how it works.
> They have predefined tools to make "apps", which can be deployed either
> locally or on a web server. But you will be dependent on the available
> shiny toolkit.
> Otherwise, if you want to make a completely customized interface, you need
> to use a combination of R, HTML and Javascript.
>
> Take a look at the GUI from the QCAGUI package (download the sources, it's
> in the "inst" directory): it can read the local filesystem, import / export
> data, it does various data transformations and various QCA related analyses
> and graphs.
> Everything is highly customized, with drop-down menus and pop-up dialogs,
> including an output one which mimics the R console.
> To look at the interface, type:
>
> library(QCAGUI)
> runGUI()
>
> I hope it helps,
> Adrian

	[[alternative HTML version deleted]]


From fabio.monteiro1992 at gmail.com  Mon Feb 22 11:51:15 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Mon, 22 Feb 2016 10:51:15 +0000
Subject: [R] FD package
Message-ID: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>

Hi.

First i would like to say that i'm really new in R. I recently started
working with R and i'm using the FD package.

I'm having some errors that doesn't make any sense.

I have 2 matrix, one is the species with functional traits and the second
one is the species and abundances.

When I try to run the dbFD to calculate the functional diversity, the error
is the number of species is different in x and a.

I checked a lot of times and the number of species is the same and there
are no mistakes in their names like spaces or caps.

Can you help me?

F?bio Monteiro

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Mon Feb 22 12:32:16 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 22 Feb 2016 13:32:16 +0200
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJL_poiwxthPOHoXUpGVe0ft1V63HYOqi31n1XoVn3Xpz4Uaew@mail.gmail.com>
References: <CAJ=0CtC9F=rvABn8_d-7xejj4F5=r6s9HGeF+Gt40KOE05KMpg@mail.gmail.com>
	<1455892508.39305.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>
	<CAJ=0CtC3Oe7ve3qqtzBpqKShKMNGx_O7u7Op+WUAnxiPqdH6_Q@mail.gmail.com>
	<BD75D26C-41FC-4395-94C2-9CD179307C44@gmail.com>
	<CAJ=0CtDaSnFKAwMTwVWPn-i6nJ+YTX+AL6hAsH7q49rdFWsVRA@mail.gmail.com>
	<CAJL_poiwxthPOHoXUpGVe0ft1V63HYOqi31n1XoVn3Xpz4Uaew@mail.gmail.com>
Message-ID: <CAJ=0CtCY-VTjhsy6uRSp0N3mHU64+A2_Hm0XRkOXt0uzPdb_+Q@mail.gmail.com>

It doesn't look like HTML because it is not HTML at all, it is actually SVG.
I found that creating exact locations for checkboxes, radios and text,
using raw HTML, is a pain, therefore I created my own library of functions
which combines SVG and Javascript.
The graphs are also SVG, although I am looking to embed normal R graphics
via shiny.

On Mon, Feb 22, 2016 at 1:22 PM, Dmitri Popavenko <
dmitri.popavenko at gmail.com> wrote:

> That is a very nice interface, indeed!
> What kind of HTML you used for this interface, it is looking different
> from the normal.
>
> On Sun, Feb 21, 2016 at 11:37 AM, Adrian Du?a <dusa.adrian at unibuc.ro>
> wrote:
>
>> Oh, thanks Peter, good example for Mac, but indeed not working on Windows.
>> For a completely cross-platform solution (that is, including Windows which
>> is what Zahra wants), I believe shiny is the right tool.
>>
>> So Zahra, if you want to use shiny, you need to look at their own
>> tutorials, step by step, and try to understand how it works.
>> They have predefined tools to make "apps", which can be deployed either
>> locally or on a web server. But you will be dependent on the available
>> shiny toolkit.
>> Otherwise, if you want to make a completely customized interface, you need
>> to use a combination of R, HTML and Javascript.
>>
>> Take a look at the GUI from the QCAGUI package (download the sources, it's
>> in the "inst" directory): it can read the local filesystem, import /
>> export
>> data, it does various data transformations and various QCA related
>> analyses
>> and graphs.
>> Everything is highly customized, with drop-down menus and pop-up dialogs,
>> including an output one which mimics the R console.
>> To look at the interface, type:
>>
>> library(QCAGUI)
>> runGUI()
>>
>> I hope it helps,
>> Adrian
>
>
>


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From simon0098 at yahoo.com  Mon Feb 22 12:35:13 2016
From: simon0098 at yahoo.com (simon0098 at yahoo.com)
Date: Mon, 22 Feb 2016 03:35:13 -0800
Subject: [R] How to create an executable file from R GUI?
In-Reply-To: <CAJL_poiwxthPOHoXUpGVe0ft1V63HYOqi31n1XoVn3Xpz4Uaew@mail.gmail.com>
Message-ID: <1456140913.15600.YahooMailAndroidMobile@web164001.mail.gq1.yahoo.com>

Thanks all,
I solved this problem using a batch file. Note that my problem was that my GUI disappeared quickly that I solve it using function "gtkMain()" after calling my GUI? function. So, R GUI works with batch file :)
The only problem that I had is that one of the buttons in my GUI is used to open a PDF file but as I click it, a window of some texts appear! I didn't think this problem would happen ! Let me know If you have any idea about it.


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 22 13:19:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 22 Feb 2016 12:19:16 +0000
Subject: [R] FD package
In-Reply-To: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>

Hi

comments inline

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fabio
> Monteiro
> Sent: Monday, February 22, 2016 11:51 AM
> To: r-help at r-project.org
> Subject: [R] FD package
>
> Hi.
>
> First i would like to say that i'm really new in R. I recently started
> working with R and i'm using the FD package.
>
> I'm having some errors that doesn't make any sense.
>
> I have 2 matrix, one is the species with functional traits and the
> second one is the species and abundances.

Your objects are matrices or data frames? From docs dbFD expects various inputs byt they have to be properly formatted.

>
> When I try to run the dbFD to calculate the functional diversity, the
> error is the number of species is different in x and a.
>
> I checked a lot of times and the number of species is the same and
> there are no mistakes in their names like spaces or caps.

How did you checked?

dim(trait) and  dim(abund)

shall give you the same number of rows in traits as columns in abund.

If trait is vector, you need to use length instead of dim.

>
> Can you help me?

Without better description of your objects and code you used you hardly get any answer. You can start by using examples from help page, which shall work and see how your data differ from those examples.

Cheers
Petr


>
> F?bio Monteiro
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From venkynov10 at gmail.com  Mon Feb 22 14:02:38 2016
From: venkynov10 at gmail.com (Venky)
Date: Mon, 22 Feb 2016 18:32:38 +0530
Subject: [R] Shiny-Wordcloud
Message-ID: <CAAM-fZ7J00US3+CNdqQ99eAbM0zoNr2YWe01Vkt0Dvyk0+uGuw@mail.gmail.com>

Hi R users,

I need Shiny *server and UI* code for creating Uni gram,Bi gram,and Trig
ram.
 for Word cloud from my desktop data.

I gone through this link: http://shiny.rstudio.com/gallery/word-cloud.html

It contains the source data from some where, but i need to use these word
cloud for my *DESKTOP* data

in this example (http://shiny.rstudio.com/gallery/word-cloud.html)  *"A mid
Summer night dreams",The merchant of Venice "* is drop down

In that drop-down i need to set my own Desktop file (csv) variable to show
the word cloud.

*For example*

column  1                         column 2                           column
3

what are you?               am fine                        i am from Chennai
Who are you?               Thanking you               my name is venky
bye take care                i will do that                please give me


I want to create column 1 word cloud instead of *A mid Summer night
dreams",*
and column 2 word cloud  instead of* The merchant of Venice from the * (
http://shiny.rstudio.com/gallery/word-cloud.html)

I need to create word cloud for separate,separate columns

Please help me to figure out this one




Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Mon Feb 22 14:38:35 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 22 Feb 2016 08:38:35 -0500
Subject: [R] Multivariate multiple linear regression question
In-Reply-To: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>
References: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>
Message-ID: <56CB0F5B.5080502@yorku.ca>

Hi Vivendra

A few suggestions:

* You will get more interpretable tests by using Type II (partial) tests 
of terms in your model via
library(car)
Manova(MRI_model)
as opposed to the Type I (sequential) tests available from manova()

* You will be able to understand the results better by making heplots via
library(helplots)
heplot(MRI_model)
but you will have to read the associated vignettes to learn how to
interpret them.

* You can test for equality of covariance matrices in the various
groups using heplots::boxM(), new in the development version on
R-Forge
install.packages("heplots", repos="http://R-Forge.R-project.org")
library(helplots)
res <- boxM(MRI_model, group=group)
res
plot(res)

* You can visually assess the correlations in the groups using
car::scatterplot(..., ellipse=TRUE, groups=)

hope this is helpful,
-Michael


On 2/20/2016 12:53 PM, Virendra Mishra wrote:
> Hi R-users,
>
> I have a fairly simple question to ask but I havent yet got an answer to
> the question. I will describe my experiment, analysis and what have I done
> and what is the question in the following paragraphs and I would appreciate
> if anyone could point me to use right statistical tools to answer my
> question.
>
> Experiment:
> I have 2 groups and both groups undergo 2 set of evaluations, one with MRI
> scanner and the other in the lab to test for their behavior. Both these
> evaluations are known to have statistically significant relationship with
> age and gender.
>
> Statistical question of interest:
> Whether there is:
> 1) statistically significant difference between the 2 groups on each
> evaluation ?
> 2) Whether there is any relationship between and within the 2 groups
> between each evaluation
>
> Model:
>
> I model the problem as following:
> MRI_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
> [Age is continuous and gender , Group are factors/categorical]
>
> Lab_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
> [Age is continuous and gender , Group are factors/categorical]
>
> In order to obtain the solution in R:
> MRI_model<-lm(cbind(MRI_measure, Lab_measure) ~ age+gender+group,
> data=data)
>
> Result of R:
> manova(MRI_model) suggests that yes indeed all the slopes are significantly
> different than 0 suggesting a relationship between my measures.
>
> Question:
> 1) In order to test whether the difference in the MRI_measure is
> statistically significant different between the 2 groups, I use
> MRI_model$fitted.values for each dependent measure and do a statistical
> test (either t-test or Wilcox) and claim that the difference is
> significant.
> In the paper I write, multivariate multiple linear regression was performed
> for the groups while controlling for age and gender. The regressed out
> MRI_measure was statistically compared to see if the difference is
> different.
>
> I am assuming that the predicted/fitted.values in model are the regressed
> out variables. Can I show this and use this result? Is this right
>
> If no, what is the correct way to statistically compare whether my 2 groups
> differ in their MRI measure and lab measure when controlled for age and
> gender. Any R library, literature, possibly a script will be greatly
> appreciated.
>
> 2) I also want to see if there is any relationship between MRI_measure and
> Lab_measure within the group after they are controlled for age and gender.
> What is the correct way to do this in R?
>
> Further, I also want to see if there is any significantly different
> association between the 2 groups for my set of dependent variables. I am
> thinking this can be done: I first find the correlation between 2 dependent
> variable in each group and test if this correlation is statistically
> different between the 2 groups? Is this logic right? And if it is, how do I
> compare the correlation? If not, what is the right way to do this? Any R
> library, literature, possibly a script will be greatly appreciated.
>
> I do appreciate any reply.
>
> Thanks
>
> Regards
>
> Virendra
>
> 	[[alternative HTML version deleted]]
>


From fabio.monteiro1992 at gmail.com  Mon Feb 22 14:00:24 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Mon, 22 Feb 2016 13:00:24 +0000
Subject: [R] FD package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
Message-ID: <CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>

Hi

thank you for your quick answer

I finally managed to insert everything correctly and dbFD is caltulated.

I'm now trying to plot the results.

My objects are matrices.

x is a functional trait and species matrice. a is the species and samples

Thank you

2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> comments inline
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fabio
> > Monteiro
> > Sent: Monday, February 22, 2016 11:51 AM
> > To: r-help at r-project.org
> > Subject: [R] FD package
> >
> > Hi.
> >
> > First i would like to say that i'm really new in R. I recently started
> > working with R and i'm using the FD package.
> >
> > I'm having some errors that doesn't make any sense.
> >
> > I have 2 matrix, one is the species with functional traits and the
> > second one is the species and abundances.
>
> Your objects are matrices or data frames? From docs dbFD expects various
> inputs byt they have to be properly formatted.
>
> >
> > When I try to run the dbFD to calculate the functional diversity, the
> > error is the number of species is different in x and a.
> >
> > I checked a lot of times and the number of species is the same and
> > there are no mistakes in their names like spaces or caps.
>
> How did you checked?
>
> dim(trait) and  dim(abund)
>
> shall give you the same number of rows in traits as columns in abund.
>
> If trait is vector, you need to use length instead of dim.
>
> >
> > Can you help me?
>
> Without better description of your objects and code you used you hardly
> get any answer. You can start by using examples from help page, which shall
> work and see how your data differ from those examples.
>
> Cheers
> Petr
>
>
> >
> > F?bio Monteiro
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Feb 22 14:17:10 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 22 Feb 2016 13:17:10 +0000
Subject: [R] Help required for Rcmdr
In-Reply-To: <CAGyA+HMbJjUiGEfYbcF3TRFPywyH_NJ2GF02gGJrCYY5AEU57A@mail.gmail.com>
References: <CAGyA+HPAEN+3FqKYWCyVgZfB+YX8nqtE+KRn_Yj_DGFQPQNjvA@mail.gmail.com>
	<56B8B3BA.4040306@gmail.com>
	<CAGyA+HNmP5NO+Bg=wA8XPJisBMekroEUASkjsgkv_GrLJ1G6Ag@mail.gmail.com>
	<56BA02A8.2070608@unipa.it>
	<ACD1644AA6C67E4FBD0C350625508EC810F55DA0@FHSDB2D11-2.csu.mcmaster.ca>
	<56BA06FA.9060005@unipa.it>
	<CAGx1TMC9wsJHsK3-NQHmvRva4x1V1qwKWq37nZsmG-nGEcrOzw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F55E86@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMBzcc8ma-19+ZebH4Ci-xpDm3fvCxg8o=8sFKO4H45Dw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F563C2@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGyA+HMLYtWcndPc4Mn68FD+o4UWSPk0OAcAiR7VrbDGEagHmw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F56414@FHSDB2D11-2.csu.mcmaster.ca>,
	<CAGyA+HMbJjUiGEfYbcF3TRFPywyH_NJ2GF02gGJrCYY5AEU57A@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F59939@FHSDB2D11-2.csu.mcmaster.ca>

Dear sekhar,

You don't need a C or C++ compiler to use the Rcmdr package. Nor do you need a compiler to install the package on Windows or Mac OS X, for which binary packages are provided by CRAN. Apparently, from your previous question, you're using a Windows system, and so you don't need a C or C++ compiler, unless for some reason you want to install the package from source (because there is a single small C program in the sources for the package).

Why do you ask?

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Sekhar Venkatesan [venkatesansekhar at gmail.com]
Sent: February 21, 2016 7:49 AM
To: R-help at r-project.org
Subject: Re: [R] Help required for Rcmdr

Dear Sirs,
just wanted to check whether C+ or C++ software is required to be in the
installed in the laptop in order to use Rcmdr
regards
sekhar

On Wed, Feb 10, 2016 at 10:17 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Sekhar,
>
> > -----Original Message-----
> > From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com]
> > Sent: February 10, 2016 11:37 AM
> > To: Fox, John <jfox at mcmaster.ca>
> > Subject: RE: [R] Help required for Rcmdr
> >
> > Tks and sorry for inadvertently sending to u alone
>
> And you apparently just did that again, so again I'm cc'ing to r-help.
>
> > In any case I hv tried all
> > over again but to no avail Regards Sekhar
>
> I assume that  by "tried all over again" you mean you tried again with an
> HTTP rather than HTTPS CRAN mirror and that didn't work.
>
> I'm afraid that I'm out of ideas.
>
> Maybe someone else will have a suggestion.
>
> John
>
> >
> > On Feb 10, 2016 9:59 PM, "Fox, John" <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Sekhar,
> >
> >       I'm sorry that you're experiencing these problems. Although you
> > haven't said so directly, I assume that you aren't able to use
> install.packages()
> > to install *any* CRAN packages, not just the Rcmdr package.
> >
> >       Downloading and unpacking the Rcmdr zip file doesn't install the
> > package. You can install the zip-file binary package from the R Windows
> GUI
> > via the "Packages > Install package(s) from local zip files" menu, but
> that too
> > won't really help because it won't install the many CRAN packages on
> which
> > the Rcmdr depends.
> >
> >       As I said earlier, my guess is that you're experiencing a problem
> with
> > a firewall, proxy server, or HTTPS. If the latter (which was Vito's
> problem),
> > you can easily solve the problem by using an HTTP CRAN server in
> preference
> > to the default HTTPS:
> >
> >       Enter the command chooseCRANmirror(useHTTPS=FALSE) at the R
> > Console > prompt and select a CRAN mirror -- I suggest the first
> (0-Cloud)
> > mirror. Then issue the command install.packages("Rcmdr"), as before.
> >
> >       If that doesn't work, I'm afraid I don't have other suggestions.
> >
> >       You appear to have sent this message only to me, not to r-help.
> That
> > not a good idea for several reasons, not least of which is that people
> who
> > have other suggestions won't see your message. I'm cc'ing this response
> to r-
> > help.
> >
> >       Best,
> >        John
> >
> >       > -----Original Message-----
> >       > From: Sekhar Venkatesan [mailto:venkatesansekhar at gmail.com
> > <mailto:venkatesansekhar at gmail.com> ]
> >       > Sent: February 10, 2016 12:03 AM
> >       > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> >       > Subject: Re: [R] Help required for Rcmdr
> >       >
> >       > Dear Sirs,
> >       > Thanks to everyone for trying to help me. i have tried several
> CRAN
> > mirrors
> >       > but to no help. I am getting the Zip file for Rcmdr and can also
> unzip
> > the
> >       > same. However, after that i am unable to open the Rcmdr console.
> >       > that is the problem.
> >       > regards
> >       > sekhar
> >       >
> >       > On Tue, Feb 9, 2016 at 10:00 PM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>
> >       > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > > wrote:
> >       >
> >       >
> >       >       Hi Rich,
> >       >
> >       >       > -----Original Message-----
> >       >       > From: Richard M. Heiberger [mailto:rmh at temple.edu
> > <mailto:rmh at temple.edu>
> >       > <mailto:rmh at temple.edu <mailto:rmh at temple.edu> > ]
> >       >       > Sent: February 9, 2016 4:57 PM
> >       >       > To: Vito M. R. Muggeo <vito.muggeo at unipa.it
> > <mailto:vito.muggeo at unipa.it>
> >       > <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
> >       >       > Cc: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca
> >
> > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > >;
> >       > Sekhar Venkatesan
> >       >       > <venkatesansekhar at gmail.com
> > <mailto:venkatesansekhar at gmail.com>
> >       > <mailto:venkatesansekhar at gmail.com
> > <mailto:venkatesansekhar at gmail.com> > >; Duncan Murdoch
> >       >       > <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>
> >       > <mailto:murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com> > >; R-help at r-project.org <mailto:R-
> > help at r-project.org>  <mailto:R- <mailto:R->
> >       > help at r-project.org <mailto:help at r-project.org> > ; R-windows at r-
> >       >       > project.org <http://project.org>  <http://project.org>
> >       >       > Subject: Re: [R] Help required for Rcmdr
> >       >       >
> >       >       > Several of my students have had this type of difficulty
> with
> > Rstudio.
> >       >       >
> >       >
> >       >       Good to know, but the original poster tried both with the R
> > Windows
> >       > SDI and MDI.
> >       >
> >       >       Best,
> >       >        John
> >       >
> >       >
> >       >       > Rstudio masks install.packages with a similarly named
> function
> > in an
> >       >       > environment that does not appear in either
> > conflicts(details=TRUE)
> >       > or in
> >       >       > search().
> >       >       >
> >       >       > The workaround is an explicit call to utils
> >       >       >
> >       >       > utils::install.packages("package.name <
> http://package.name>
> > <http://package.name> ")
> >       >       >
> >       >       > Rich
> >       >       >
> >       >       > On Tue, Feb 9, 2016 at 10:34 AM, Vito M. R. Muggeo
> >       > <vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it>
> > <mailto:vito.muggeo at unipa.it <mailto:vito.muggeo at unipa.it> > >
> >       >       > wrote:
> >       >       > > dear John,
> >       >       > > Thanks for your prompt reply
> >       >       > >
> >       >       > > Il 09/02/2016 16.23, Fox, John ha scritto:
> >       >       > >>
> >       >       > >> Dear Vito,
> >       >       > >>
> >       >       > >> I've never experienced this problem myself in a
> general
> > way,
> >       >       > >
> >       >       > > Me too. I have always installed R packages
> > straightforwardly..
> >       >       > >
> >       >       > > and I'm sure that Windows users of R call
> install.packages()
> > all the
> >       >       > > time to install packages from CRAN mirrors.
> >       >       > > Of course..
> >       >       > >
> >       >       > > So the question to ask, I think, is what's preventing
> >       >       > > install.packages() from working in your case --
> possibly an
> >       > Internet
> >       >       > > connectivity problem due to a firewall, proxy server,
> use of
> > https,
> >       > etc.
> >       >       > > I'm sure that others more knowledgeable about these
> issues
> >       > than I am
> >       >       > > will be able to make more specific suggestions for
> fixing the
> >       > problem.
> >       >       > >
> >       >       > > However I have just checked that it works with *http*
> > servers
> >       > (but not
> >       >       > > for any other *https*..)
> >       >       > >
> >       >       > > Thanks for your support,
> >       >       > > best,
> >       >       > > vito
> >       >       > >
> >       >       > >
> >       >       > >>
> >       >       > >> Best,
> >       >       > >>   John
> >       >       > >>
> >       >       > >> -----------------------------
> >       >       > >> John Fox, Professor
> >       >       > >> McMaster University
> >       >       > >> Hamilton, Ontario
> >       >       > >> Canada L8S 4M4
> >       >       > >> web: socserv.mcmaster.ca/jfox
> > <http://socserv.mcmaster.ca/jfox>
> >       > <http://socserv.mcmaster.ca/jfox>
> >       >       > >>
> >       >       > >>
> >       >       > >> ________________________________________
> >       >       > >> From: R-help [r-help-bounces at r-project.org <mailto:r-
> > help-bounces at r-project.org>  <mailto:r-help- <mailto:r-help->
> >       > bounces at r-project.org <mailto:bounces at r-project.org> > ] on
> > behalf of Vito M. R.
> >       >       > >> Muggeo [vito.muggeo at unipa.it
> > <mailto:vito.muggeo at unipa.it>  <mailto:vito.muggeo at unipa.it
> > <mailto:vito.muggeo at unipa.it> >
> >       > ]
> >       >       > >> Sent: February 9, 2016 10:15 AM
> >       >       > >> To: Sekhar Venkatesan; Duncan Murdoch; R-help at r-
> > project.org <mailto:R-help at r-project.org>
> >       > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >
> >       >       > >> Cc: R-windows at r-project.org <mailto:R-windows at r-
> > project.org>  <mailto:R-windows at r- <mailto:R-windows at r->
> >       > project.org <http://project.org> >
> >       >       > >> Subject: Re: [R] Help required for Rcmdr
> >       >       > >>
> >       >       > >> dear all,
> >       >       > >> I don't know if that problem is related to the Rcmdr
> > package
> >       > itself..
> >       >       > >> (Sekhar try to install any other packages..)
> >       >       > >>
> >       >       > >> I am experiencing the same problem, in that when
> typing
> >       >       > >>
> >       >       > >>   > install.packages("_ANY_PACKAGE_")
> >       >       > >>
> >       >       > >> I get the message
> >       >       > >> Warning message:
> >       >       > >> package ?_ANY_PACKAGE_? is not available (for R
> version
> > 3.2.3)
> >       >       > >>
> >       >       > >> But I can download the .zip file and unzip it..
> >       >       > >>
> >       >       > >> I tried different CRAN mirrors...
> >       >       > >>
> >       >       > >> best,
> >       >       > >> vito
> >       >       > >>
> >       >       > >>
> >       >       > >> Il 09/02/2016 12.44, Sekhar Venkatesan ha scritto:
> >       >       > >>>
> >       >       > >>> Dear Mr. Murdoch,
> >       >       > >>> I am extremely sorry to have sent the mail to you
> instead
> > of R-
> >       > help.
> >       >       > >>> Thanks
> >       >       > >>> for directing me.
> >       >       > >>> I have downloaded R 3.2.3 version. After that i
> asked for
> >       >       > >>> install.packages("Rcmdr") . It says that Rcmdr is not
> > available
> >       > with
> >       >       > >>> version 3.2.3. On looking at the pdf file for
> getting started
> > with
> >       >       > >>> R, i found that i should download with SDI Graphical
> > interface
> >       > which
> >       >       > >>> I did once again but still i could not get the Rcmdr
> console.
> >       >       > >>> I attended a workshop where the faculty brought out
> the
> > R
> >       > console as
> >       >       > >>> well as the R-commander console where i could import
> > files
> >       > and also
> >       >       > >>> do all the statistics easily. I am not getting the R-
> > commander
> >       > console.
> >       >       > >>> Shall be grateful if i could get help on getting the
> R-
> > commander
> >       >       > >>> console with the user friendly way of doing the
> statistical
> >       > operations.
> >       >       > >>> Thanks and regards,
> >       >       > >>> Once again apologize to Dr. Duncan Murdoch for
> > disturbing
> >       > him.
> >       >       > >>> Sekhar
> >       >       > >>>
> >       >       > >>> On Mon, Feb 8, 2016 at 8:56 PM, Duncan Murdoch
> >       >       > >>> <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>
> >       > <mailto:murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com> > >
> >       >       > >>> wrote:
> >       >       > >>>
> >       >       > >>>> On 08/02/2016 8:56 AM, Sekhar Venkatesan wrote:
> >       >       > >>>>
> >       >       > >>>>> Dear Sirs,
> >       >       > >>>>> I have downloaded R 3.2.3 version from the CRAN
> site. I
> >       > have tried
> >       >       > >>>>> to download with both MDI and SDI user interface.
> But
> >       > Rcmdr is not
> >       >       > >>>>> opening in as a console  along with R console.
> Help is
> >       > required to
> >       >       > >>>>> open Rcmdr. I have tried install.packages("Rcmdr"),
> >       > library(Rcmdr)
> >       >       > >>>>> etc but to no avail.
> >       >       > >>>>> thanks
> >       >       > >>>>> Sekhar
> >       >       > >>>>> Delhi
> >       >       > >>>>> India
> >       >       > >>>>>
> >       >       > >>>>> This is the wrong email address for help.  Please
> write
> > to R-
> >       > help,
> >       >       > >>>>> and
> >       >       > >>>>
> >       >       > >>>> describe what happens when you try the commands
> > that are
> >       > failing.
> >       >       > >>>>
> >       >       > >>>> Duncan Murdoch
> >       >       > >>>>
> >       >       > >>>
> >       >       > >>>        [[alternative HTML version deleted]]
> >       >       > >>>
> >       >       > >>>
> > ______________________________________________
> >       >       > >>> R-help at r-project.org <mailto:R-help at r-project.org>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> >       > list -- To UNSUBSCRIBE and more, see
> >       >       > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >       >       > >>> PLEASE do read the posting guide
> >       >       > >>> http://www.R-project.org/posting-guide.html
> >       >       > >>> and provide commented, minimal, self-contained,
> >       > reproducible code.
> >       >       > >>>
> >       >       > >>
> >       >       > >> --
> >       >       > >>
> > ==============================================
> >       >       > >> Vito M.R. Muggeo
> >       >       > >> Dip.to Sc Statist e Matem `Vianelli'
> >       >       > >> Universit? di Palermo
> >       >       > >> viale delle Scienze, edificio 13
> >       >       > >> 90128 Palermo - ITALY
> >       >       > >> tel: 091 23895240
> >       >       > >> fax: 091 485726
> >       >       > >> http://dssm.unipa.it/vmuggeo
> >       >       > >> Associate Editor, Statistical Modelling
> >       >       > >>
> >       >       > >>
> > ______________________________________________
> >       >       > >> R-help at r-project.org <mailto:R-help at r-project.org>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> list
> >       > -- To UNSUBSCRIBE and more, see
> >       >       > >> https://stat.ethz.ch/mailman/listinfo/r-help
> >       >       > >> PLEASE do read the posting guide
> >       >       > >> http://www.R-project.org/posting-guide.html
> >       >       > >> and provide commented, minimal, self-contained,
> > reproducible
> >       > code.
> >       >       > >>
> >       >       > >
> >       >       > > --
> >       >       > > ==============================================
> >       >       > > Vito M.R. Muggeo
> >       >       > > Dip.to Sc Statist e Matem `Vianelli'
> >       >       > > Universit? di Palermo
> >       >       > > viale delle Scienze, edificio 13
> >       >       > > 90128 Palermo - ITALY
> >       >       > > tel: 091 23895240
> >       >       > > fax: 091 485726
> >       >       > > http://dssm.unipa.it/vmuggeo
> >       >       > > Associate Editor, Statistical Modelling
> >       >       > >
> >       >       > > ______________________________________________
> >       >       > > R-help at r-project.org <mailto:R-help at r-project.org>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> >  mailing
> list -
> >       > - To UNSUBSCRIBE and more, see
> >       >       > > https://stat.ethz.ch/mailman/listinfo/r-help
> >       >       > > PLEASE do read the posting guide
> >       >       > > http://www.R-project.org/posting-guide.html
> >       >       > > and provide commented, minimal, self-contained,
> > reproducible
> >       > code.
> >       >
> >       >
> >
> >
>
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ssefick at gmail.com  Mon Feb 22 14:58:51 2016
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 22 Feb 2016 07:58:51 -0600
Subject: [R] FD package
In-Reply-To: <CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
	<CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
Message-ID: <CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>

If memory serves me, dbFD returns a lot of output. What do you want to
plot? Also, please provide reproducible examples, so that we can help you
solve your R related queries.
kindest regards,

Stephen

On Mon, Feb 22, 2016 at 7:00 AM, Fabio Monteiro <
fabio.monteiro1992 at gmail.com> wrote:

> Hi
>
> thank you for your quick answer
>
> I finally managed to insert everything correctly and dbFD is caltulated.
>
> I'm now trying to plot the results.
>
> My objects are matrices.
>
> x is a functional trait and species matrice. a is the species and samples
>
> Thank you
>
> 2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:
>
> > Hi
> >
> > comments inline
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fabio
> > > Monteiro
> > > Sent: Monday, February 22, 2016 11:51 AM
> > > To: r-help at r-project.org
> > > Subject: [R] FD package
> > >
> > > Hi.
> > >
> > > First i would like to say that i'm really new in R. I recently started
> > > working with R and i'm using the FD package.
> > >
> > > I'm having some errors that doesn't make any sense.
> > >
> > > I have 2 matrix, one is the species with functional traits and the
> > > second one is the species and abundances.
> >
> > Your objects are matrices or data frames? From docs dbFD expects various
> > inputs byt they have to be properly formatted.
> >
> > >
> > > When I try to run the dbFD to calculate the functional diversity, the
> > > error is the number of species is different in x and a.
> > >
> > > I checked a lot of times and the number of species is the same and
> > > there are no mistakes in their names like spaces or caps.
> >
> > How did you checked?
> >
> > dim(trait) and  dim(abund)
> >
> > shall give you the same number of rows in traits as columns in abund.
> >
> > If trait is vector, you need to use length instead of dim.
> >
> > >
> > > Can you help me?
> >
> > Without better description of your objects and code you used you hardly
> > get any answer. You can start by using examples from help page, which
> shall
> > work and see how your data differ from those examples.
> >
> > Cheers
> > Petr
> >
> >
> > >
> > > F?bio Monteiro
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> > vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> > ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> > intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> > sender. Delete the contents of this e-mail with all attachments and its
> > copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> > authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> > caused by modifications of the e-mail or by delay with transfer of the
> > email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> > contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> > immediately accept such offer; The sender of this e-mail (offer) excludes
> > any acceptance of the offer on the part of the recipient containing any
> > amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> > upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter
> > into any contracts on behalf of the company except for cases in which
> > he/she is expressly authorized to do so in writing, and such
> authorization
> > or power of attorney is submitted to the recipient or the person
> > represented by the recipient, or the existence of such authorization is
> > known to the recipient of the person represented by the recipient.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Mon Feb 22 15:10:34 2016
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 22 Feb 2016 08:10:34 -0600
Subject: [R] FD package
In-Reply-To: <CAG0T74qa6eST6cMiLhWoUiSmz3fTEgg-iEXGoKpheFQVvD33+w@mail.gmail.com>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
	<CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
	<CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>
	<CAG0T74qa6eST6cMiLhWoUiSmz3fTEgg-iEXGoKpheFQVvD33+w@mail.gmail.com>
Message-ID: <CADKEMqhNCc0nH8kuJoUUfTsRjN0_p+4iuP2uJ0NRHMOpEL7wyQ@mail.gmail.com>

Please see ?dput. What you provided is not a minimal, reproducible example
(i.e., there is no R code).

What kind of plot are you trying to plot? hist(data$FRic) will plot your
data. I guess we need more information to be helpful.


On Mon, Feb 22, 2016 at 8:03 AM, Fabio Monteiro <
fabio.monteiro1992 at gmail.com> wrote:

> This is the output.
>
> I want to plot, for example FRic
>
> $nbsp
>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
> com13 com14 com15 com16
>    17    21    18    12    15    20    16    12    18    15    18    16
>  10    11    17    20
> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
> com29 com30 com31 com32
>     9    13    11    10    11    15    12    16    18    18    11    19
>  12    13    13    12
> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
> com45 com46 com47 com48
>    15    11    15     8     7    12    10     9    12    15    13    13
>  15    13    10    16
> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
> com61 com62 com63 com64
>    14    12    14    13    14    13    15    13    11    12    16    13
>   9     8    11    15
> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
> com77 com78 com79 com80
>    13    18    13    15    10    11    12    11    14     8    10    12
>  11    12    14    13
> com81 com82
>     9    12
>
> $sing.sp
>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
> com13 com14 com15 com16
>    17    21    18    12    15    20    16    12    18    15    18    16
>  10    11    17    20
> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
> com29 com30 com31 com32
>     9    13    11    10    11    15    12    16    18    18    11    19
>  12    13    13    12
> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
> com45 com46 com47 com48
>    14    11    15     8     7    12    10     9    12    15    13    13
>  15    13    10    16
> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
> com61 com62 com63 com64
>    14    12    13    13    14    13    15    13    11    12    16    13
>   9     8    11    15
> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
> com77 com78 com79 com80
>    13    17    13    15    10    11    12    11    14     8    10    12
>  11    12    14    13
> com81 com82
>     9    12
>
> $FRic
>         com1         com2         com3         com4         com5
> com6         com7
> 3.669752e-04 6.898164e-04 6.893918e-04 3.935451e-05 1.436140e-04
> 1.012949e-03 2.934536e-04
>         com8         com9        com10        com11        com12
>  com13        com14
> 1.001556e-04 6.425547e-04 1.740235e-04 5.561802e-04 2.964362e-04
> 1.480860e-05 1.060512e-04
>        com15        com16        com17        com18        com19
>  com20        com21
> 4.121157e-04 5.346433e-04 1.108007e-06 5.726895e-05 8.593435e-06
> 1.452446e-05 1.855957e-05
>        com22        com23        com24        com25        com26
>  com27        com28
> 2.128971e-04 8.438329e-05 3.216279e-04 2.529525e-04 4.980317e-04
> 3.111325e-05 6.290088e-04
>        com29        com30        com31        com32        com33
>  com34        com35
> 3.559802e-05 5.907167e-05 8.906878e-05 2.510168e-05 1.929088e-04
> 1.234508e-04 2.784301e-04
>        com36        com37        com38        com39        com40
>  com41        com42
> 1.480560e-08 1.411752e-06 5.576549e-05 2.445569e-05 6.167242e-06
> 1.210002e-04 1.666034e-04
>        com43        com44        com45        com46        com47
>  com48        com49
> 1.203484e-04 7.347513e-05 8.991003e-05 8.691148e-05 6.718789e-05
> 1.357136e-04 1.821851e-04
>        com50        com51        com52        com53        com54
>  com55        com56
> 4.832203e-05 8.391627e-05 2.173971e-04 1.355160e-04 1.304425e-04
> 1.787888e-04 1.759204e-05
>        com57        com58        com59        com60        com61
>  com62        com63
> 9.307474e-05 1.185857e-04 2.776166e-04 1.277143e-04 5.905299e-06
> 9.606009e-08 1.019480e-04
>        com64        com65        com66        com67        com68
>  com69        com70
> 2.395355e-04 2.307081e-04 4.019309e-04 6.874506e-05 1.417622e-04
> 5.675463e-06 9.878848e-05
>        com71        com72        com73        com74        com75
>  com76        com77
> 6.907251e-05 8.938528e-05 2.493585e-04 1.214151e-09 2.419942e-05
> 1.183863e-04 7.457464e-05
>        com78        com79        com80        com81        com82
> 6.284563e-05 1.741100e-04 2.128749e-04 2.920847e-06 9.368270e-05
>
> $qual.FRic
> [1] 0.7035642
>
> $FEve
>      com1      com2      com3      com4      com5      com6      com7
>  com8      com9
> 0.2388515 0.3996566 0.3350494 0.2943431 0.3576785 0.3846561 0.4319967
> 0.5857688 0.4271764
>     com10     com11     com12     com13     com14     com15     com16
> com17     com18
> 0.3288544 0.4625139 0.4810921 0.3041395 0.5820621 0.6313595 0.5406627
> 0.2707035 0.4530424
>     com19     com20     com21     com22     com23     com24     com25
> com26     com27
> 0.3015171 0.5790744 0.7253301 0.5441404 0.4481694 0.6187607 0.5445650
> 0.4955940 0.5116752
>     com28     com29     com30     com31     com32     com33     com34
> com35     com36
> 0.5221560 0.5670513 0.4293040 0.4812907 0.4915317 0.3878949 0.4287726
> 0.2893205 0.5835605
>     com37     com38     com39     com40     com41     com42     com43
> com44     com45
> 0.7896749 0.5482274 0.4015703 0.5990018 0.5431955 0.6251919 0.6023954
> 0.4962892 0.3749658
>     com46     com47     com48     com49     com50     com51     com52
> com53     com54
> 0.4290664 0.4932756 0.5870607 0.3415984 0.3242199 0.4296702 0.4971491
> 0.3272834 0.4865427
>     com55     com56     com57     com58     com59     com60     com61
> com62     com63
> 0.3428716 0.4653631 0.5479140 0.5698272 0.4777804 0.4525375 0.5916255
> 0.4652363 0.4111973
>     com64     com65     com66     com67     com68     com69     com70
> com71     com72
> 0.3987632 0.3856989 0.3064660 0.4717288 0.3534531 0.4285679 0.6087836
> 0.3607790 0.5494437
>     com73     com74     com75     com76     com77     com78     com79
> com80     com81
> 0.4214327 0.4360703 0.3808632 0.2833824 0.2876808 0.3380949 0.3421757
> 0.2249389 0.6562824
>     com82
> 0.6041267
>
> $FDiv
>      com1      com2      com3      com4      com5      com6      com7
>  com8      com9
> 0.7423817 0.7458169 0.8679783 0.8226750 0.8373889 0.7877725 0.8070008
> 0.7379254 0.8131881
>     com10     com11     com12     com13     com14     com15     com16
> com17     com18
> 0.7050804 0.6976598 0.7512530 0.6806472 0.6994011 0.7276620 0.7870732
> 0.8793599 0.7562019
>     com19     com20     com21     com22     com23     com24     com25
> com26     com27
> 0.8983302 0.7681038 0.8163501 0.8198178 0.8489976 0.8922742 0.8442970
> 0.8269863 0.7891795
>     com28     com29     com30     com31     com32     com33     com34
> com35     com36
> 0.7569559 0.8674167 0.7436638 0.7317634 0.9541561 0.7466859 0.7087626
> 0.8006321 0.8511148
>     com37     com38     com39     com40     com41     com42     com43
> com44     com45
> 0.7729260 0.7509163 0.6905947 0.8466404 0.7677596 0.8791198 0.8211045
> 0.7259760 0.7992553
>     com46     com47     com48     com49     com50     com51     com52
> com53     com54
> 0.7573869 0.8788377 0.9036087 0.8287276 0.7762280 0.8064715 0.7775368
> 0.7828276 0.8151245
>     com55     com56     com57     com58     com59     com60     com61
> com62     com63
> 0.7503195 0.9213640 0.9141396 0.9150055 0.8348691 0.7271261 0.7875414
> 0.8338675 0.7070272
>     com64     com65     com66     com67     com68     com69     com70
> com71     com72
> 0.7189990 0.7043998 0.7768710 0.7264939 0.8140790 0.7532290 0.7309884
> 0.9190267 0.8540992
>     com73     com74     com75     com76     com77     com78     com79
> com80     com81
> 0.7531779 0.8520790 0.7649957 0.7319195 0.7578687 0.7915857 0.7600834
> 0.7303097 0.7693079
>     com82
> 0.7487281
>
> $FDis
>       com1       com2       com3       com4       com5       com6
> com7       com8
> 0.19178600 0.15352983 0.23419296 0.20315128 0.18604639 0.14348855
> 0.28989249 0.25752544
>       com9      com10      com11      com12      com13      com14
>  com15      com16
> 0.26174957 0.15962395 0.17907612 0.19642851 0.12827329 0.20114316
> 0.18128942 0.25731184
>      com17      com18      com19      com20      com21      com22
>  com23      com24
> 0.25855225 0.19576353 0.26366092 0.27728602 0.29546846 0.20720052
> 0.27212077 0.30880887
>      com25      com26      com27      com28      com29      com30
>  com31      com32
> 0.29440458 0.25396646 0.25647806 0.23422171 0.25464177 0.24311894
> 0.16182038 0.09958014
>      com33      com34      com35      com36      com37      com38
>  com39      com40
> 0.13095167 0.12983413 0.24224903 0.18239337 0.19817113 0.26320996
> 0.11766508 0.30940641
>      com41      com42      com43      com44      com45      com46
>  com47      com48
> 0.23583814 0.30624876 0.27750572 0.16747032 0.21445188 0.24327116
> 0.20589103 0.27339261
>      com49      com50      com51      com52      com53      com54
>  com55      com56
> 0.23614656 0.23678552 0.25641929 0.26260242 0.22516659 0.25243952
> 0.23674896 0.18732040
>      com57      com58      com59      com60      com61      com62
>  com63      com64
> 0.27202483 0.22947018 0.31342777 0.17997456 0.18461335 0.32429534
> 0.14840674 0.13731830
>      com65      com66      com67      com68      com69      com70
>  com71      com72
> 0.20437128 0.23298402 0.14830718 0.27194825 0.09289396 0.23196338
> 0.17920946 0.25265696
>      com73      com74      com75      com76      com77      com78
>  com79      com80
> 0.23525249 0.22171523 0.21972879 0.23523622 0.25336830 0.22477734
> 0.20430806 0.20674064
>      com81      com82
> 0.14270928 0.22673005
>
> $RaoQ
>       com1       com2       com3       com4       com5       com6
> com7       com8
> 0.05331536 0.03630438 0.07372825 0.06071274 0.05671961 0.05128404
> 0.10541586 0.08965742
>       com9      com10      com11      com12      com13      com14
>  com15      com16
> 0.09102682 0.04333067 0.04941515 0.05495308 0.03115535 0.06048519
> 0.06070379 0.08680368
>      com17      com18      com19      com20      com21      com22
>  com23      com24
> 0.07256118 0.05321952 0.08855815 0.10718949 0.10760039 0.07391960
> 0.09163325 0.11476244
>      com25      com26      com27      com28      com29      com30
>  com31      com32
> 0.10458183 0.08833300 0.07746703 0.07975863 0.08699710 0.07029682
> 0.04116800 0.02091466
>      com33      com34      com35      com36      com37      com38
>  com39      com40
> 0.03452371 0.03102533 0.07072961 0.04601163 0.05125527 0.08872861
> 0.03608639 0.11227991
>      com41      com42      com43      com44      com45      com46
>  com47      com48
> 0.07155343 0.10655043 0.09463142 0.04483107 0.05149290 0.06818611
> 0.05776898 0.08787335
>      com49      com50      com51      com52      com53      com54
>  com55      com56
> 0.06689262 0.06673575 0.07673498 0.08209786 0.06165892 0.07169030
> 0.07207671 0.05351944
>      com57      com58      com59      com60      com61      com62
>  com63      com64
> 0.10496706 0.07830439 0.11178032 0.05616672 0.04961674 0.11105321
> 0.03840657 0.03693797
>      com65      com66      com67      com68      com69      com70
>  com71      com72
> 0.05718178 0.07088485 0.03711119 0.08826702 0.02446860 0.08202483
> 0.05274964 0.07232899
>      com73      com74      com75      com76      com77      com78
>  com79      com80
> 0.06245748 0.05668243 0.06019524 0.07375344 0.07743079 0.06009721
> 0.05757830 0.05642231
>      com81      com82
> 0.03665132 0.06852237
>
> $CWM
>         trait1                        trait2   trait3              trait4
>         trait5
> com1  Demersal Marine, brackish, freshwater  3.361717 Invertebrate Feeder
>        Browser
> com2  Demersal Marine, brackish, freshwater  3.391770 Invertebrate Feeder
>        Browser
> com3  Demersal Marine, brackish, freshwater  3.389626 Invertebrate Feeder
>        Browser
> com4  Demersal Marine, brackish, freshwater  3.437043 Invertebrate Feeder
>        Browser
> com5  Demersal Marine, brackish, freshwater  3.450760 Invertebrate Feeder
>        Browser
> com6  Demersal Marine, brackish, freshwater  3.354952 Invertebrate Feeder
>        Browser
> com7  Demersal Marine, brackish, freshwater  3.389917 Invertebrate Feeder
>        Browser
> com8  Demersal Marine, brackish, freshwater  3.382973 Invertebrate Feeder
>        Browser
> com9  Demersal Marine, brackish, freshwater  3.371722 Invertebrate Feeder
>        Browser
> com10 Demersal Marine, brackish, freshwater  3.371057 Invertebrate Feeder
>        Browser
> com11 Demersal Marine, brackish, freshwater  3.389740 Invertebrate Feeder
>        Browser
> com12 Demersal Marine, brackish, freshwater  3.416626 Invertebrate Feeder
>        Browser
> com13 Demersal Marine, brackish, freshwater  3.348563 Invertebrate Feeder
>        Browser
> com14 Demersal Marine, brackish, freshwater  3.310051 Invertebrate Feeder
>        Browser
> com15 Demersal Marine, brackish, freshwater  3.274433 Invertebrate Feeder
>        Browser
> com16 Demersal Marine, brackish, freshwater  3.366033 Invertebrate Feeder
>        Browser
> com17  Pelagic Marine, brackish, freshwater  3.284144 Invertebrate Feeder
> Browser/Hunter
> com18 Demersal Marine, brackish, freshwater  3.352978 Invertebrate Feeder
>        Browser
> com19 Demersal Marine, brackish, freshwater  3.313528 Invertebrate Feeder
>        Browser
> com20 Demersal Marine, brackish, freshwater  3.368486 Invertebrate Feeder
>        Browser
> com21 Demersal Marine, brackish, freshwater  3.346555 Invertebrate Feeder
>        Browser
> com22 Demersal Marine, brackish, freshwater  3.348779 Invertebrate Feeder
>        Browser
> com23 Demersal Marine, brackish, freshwater  3.316949 Invertebrate Feeder
>        Browser
> com24 Demersal Marine, brackish, freshwater  3.332521 Invertebrate Feeder
>        Browser
> com25 Demersal Marine, brackish, freshwater  3.398814 Invertebrate Feeder
>        Browser
> com26 Demersal Marine, brackish, freshwater  3.281393 Invertebrate Feeder
>        Browser
> com27 Demersal Marine, brackish, freshwater  3.325194 Invertebrate Feeder
>        Browser
> com28 Demersal Marine, brackish, freshwater  3.356956 Invertebrate Feeder
>        Browser
> com29 Demersal Marine, brackish, freshwater  3.282245 Invertebrate Feeder
>        Browser
> com30 Demersal Marine, brackish, freshwater  3.263298 Invertebrate Feeder
>        Browser
> com31 Demersal Marine, brackish, freshwater  3.304036 Invertebrate Feeder
>        Browser
> com32 Demersal              Marine, brackish 3.230522 Invertebrate Feeder
>        Browser
> com33 Demersal Marine, brackish, freshwater  3.347002 Invertebrate Feeder
>        Browser
> com34 Demersal Marine, brackish, freshwater  3.430373 Invertebrate Feeder
>        Browser
> com35 Demersal Marine, brackish, freshwater  3.318061 Invertebrate Feeder
>        Browser
> com36 Demersal Marine, brackish, freshwater  3.334512 Invertebrate Feeder
>        Browser
> com37 Demersal Marine, brackish, freshwater  3.354938 Invertebrate Feeder
>        Browser
> com38 Demersal Marine, brackish, freshwater  3.282320 Invertebrate Feeder
>        Browser
> com39 Demersal Marine, brackish, freshwater  3.307719 Invertebrate Feeder
>        Browser
> com40 Demersal              Marine, brackish 3.343822 Invertebrate Feeder
>        Browser
> com41 Demersal Marine, brackish, freshwater  3.347152 Invertebrate Feeder
>        Browser
> com42 Demersal Marine, brackish, freshwater  3.389799 Invertebrate Feeder
>        Browser
> com43 Demersal Marine, brackish, freshwater  3.400693 Invertebrate Feeder
>        Browser
> com44 Demersal Marine, brackish, freshwater  3.421323 Invertebrate Feeder
>        Browser
> com45 Demersal Marine, brackish, freshwater  3.329006 Invertebrate Feeder
>        Browser
> com46 Demersal Marine, brackish, freshwater  3.316793 Invertebrate Feeder
>        Browser
> com47  Benthic Marine, brackish, freshwater  3.309663 Invertebrate Feeder
>        Browser
> com48 Demersal Marine, brackish, freshwater  3.372207 Invertebrate Feeder
>        Browser
> com49  Benthic Marine, brackish, freshwater  3.332736 Invertebrate Feeder
>        Browser
> com50  Benthic Marine, brackish, freshwater  3.311616 Invertebrate Feeder
>        Browser
> com51 Demersal Marine, brackish, freshwater  3.319775 Invertebrate Feeder
>        Browser
> com52 Demersal Marine, brackish, freshwater  3.277058 Invertebrate Feeder
>        Browser
> com53 Demersal Marine, brackish, freshwater  3.354429 Invertebrate Feeder
>        Browser
> com54 Demersal Marine, brackish, freshwater  3.339532 Invertebrate Feeder
>        Browser
> com55 Demersal Marine, brackish, freshwater  3.357153 Invertebrate Feeder
>        Browser
> com56  Benthic Marine, brackish, freshwater  3.279952 Invertebrate Feeder
>        Browser
> com57  Benthic              Marine, brackish 3.126602 Invertebrate Feeder
>        Browser
> com58  Benthic              Marine, brackish 3.217454 Invertebrate Feeder
>        Browser
> com59 Demersal              Marine, brackish 3.307770 Invertebrate Feeder
>        Browser
> com60 Demersal              Marine, brackish 3.252970 Invertebrate Feeder
>        Browser
> com61 Demersal Marine, brackish, freshwater  3.404601 Invertebrate Feeder
>        Browser
> com62  Pelagic Marine, brackish, freshwater  2.806229 Invertebrate Feeder
>        Browser
> com63 Demersal Marine, brackish, freshwater  3.287427 Invertebrate Feeder
>        Browser
> com64 Demersal Marine, brackish, freshwater  3.292238 Invertebrate Feeder
>        Browser
> com65 Demersal              Marine, brackish 3.265497 Invertebrate Feeder
>        Browser
> com66 Demersal Marine, brackish, freshwater  3.317879 Invertebrate Feeder
>        Browser
> com67 Demersal              Marine, brackish 3.258586 Invertebrate Feeder
>        Browser
> com68 Demersal Marine, brackish, freshwater  3.203772 Invertebrate Feeder
>        Browser
> com69 Demersal Marine, brackish, freshwater  3.289830 Invertebrate Feeder
>        Browser
> com70 Demersal              Marine, brackish 3.326195 Invertebrate Feeder
>        Browser
> com71  Benthic Marine, brackish, freshwater  3.325590 Invertebrate Feeder
>        Browser
> com72  Benthic Marine, brackish, freshwater  3.297994 Invertebrate Feeder
>        Browser
> com73 Demersal Marine, brackish, freshwater  3.331968 Invertebrate Feeder
>        Browser
> com74 Demersal Marine, brackish, freshwater  3.395514 Invertebrate Feeder
>        Browser
> com75 Demersal Marine, brackish, freshwater  3.323936 Invertebrate Feeder
>        Browser
> com76 Demersal Marine, brackish, freshwater  3.201015 Invertebrate Feeder
>        Browser
> com77 Demersal Marine, brackish, freshwater  3.280311 Invertebrate Feeder
>        Browser
> com78 Demersal Marine, brackish, freshwater  3.318771 Invertebrate Feeder
>        Browser
> com79 Demersal Marine, brackish, freshwater  3.318253 Invertebrate Feeder
>        Browser
> com80 Demersal Marine, brackish, freshwater  3.374939 Invertebrate Feeder
>        Browser
> com81 Demersal Marine, brackish, freshwater  3.440927 Invertebrate Feeder
>        Browser
> com82 Demersal Marine, brackish, freshwater  3.381153 Invertebrate Feeder
>        Browser
>          trait6
> com1  0.5 - 1.0
> com2  1.0 - 2.0
> com3  1.0 - 2.0
> com4  1.0 - 2.0
> com5  1.0 - 2.0
> com6  1.0 - 2.0
> com7  1.0 - 2.0
> com8  1.0 - 2.0
> com9  0.5 - 1.0
> com10 1.0 - 2.0
> com11 1.0 - 2.0
> com12 1.0 - 2.0
> com13 0.5 - 1.0
> com14 0.5 - 1.0
> com15 0.5 - 1.0
> com16 0.5 - 1.0
> com17 1.0 - 2.0
> com18 0.5 - 1.0
> com19 0.5 - 1.0
> com20 0.5 - 1.0
> com21 0.5 - 1.0
> com22 0.5 - 1.0
> com23 1.0 - 2.0
> com24 1.0 - 2.0
> com25 1.0 - 2.0
> com26 1.0 - 2.0
> com27 1.0 - 2.0
> com28 0.5 - 1.0
> com29 0.5 - 1.0
> com30 0.5 - 1.0
> com31 0.5 - 1.0
> com32 0.5 - 1.0
> com33 0.5 - 1.0
> com34 1.0 - 2.0
> com35 0.5 - 1.0
> com36 0.5 - 1.0
> com37 1.0 - 2.0
> com38 0.5 - 1.0
> com39 0.5 - 1.0
> com40 0.5 - 1.0
> com41 0.5 - 1.0
> com42 1.0 - 2.0
> com43 1.0 - 2.0
> com44 1.0 - 2.0
> com45     < 0.5
> com46     < 0.5
> com47     < 0.5
> com48     < 0.5
> com49     < 0.5
> com50     < 0.5
> com51     < 0.5
> com52 0.5 - 1.0
> com53 0.5 - 1.0
> com54     < 0.5
> com55     < 0.5
> com56     < 0.5
> com57     < 0.5
> com58     < 0.5
> com59 0.5 - 1.0
> com60 0.5 - 1.0
> com61 1.0 - 2.0
> com62 1.0 - 2.0
> com63 0.5 - 1.0
> com64 0.5 - 1.0
> com65 0.5 - 1.0
> com66 0.5 - 1.0
> com67 0.5 - 1.0
> com68 0.5 - 1.0
> com69 0.5 - 1.0
> com70 0.5 - 1.0
> com71     < 0.5
> com72     < 0.5
> com73     < 0.5
> com74 1.0 - 2.0
> com75 0.5 - 1.0
> com76 0.5 - 1.0
> com77 1.0 - 2.0
> com78 0.5 - 1.0
> com79 0.5 - 1.0
> com80 1.0 - 2.0
> com81 1.0 - 2.0
> com82 1.0 - 2.0
>
> 2016-02-22 13:58 GMT+00:00 stephen sefick <ssefick at gmail.com>:
>
>> If memory serves me, dbFD returns a lot of output. What do you want to
>> plot? Also, please provide reproducible examples, so that we can help you
>> solve your R related queries.
>> kindest regards,
>>
>> Stephen
>>
>> On Mon, Feb 22, 2016 at 7:00 AM, Fabio Monteiro <
>> fabio.monteiro1992 at gmail.com> wrote:
>>
>>> Hi
>>>
>>> thank you for your quick answer
>>>
>>> I finally managed to insert everything correctly and dbFD is caltulated.
>>>
>>> I'm now trying to plot the results.
>>>
>>> My objects are matrices.
>>>
>>> x is a functional trait and species matrice. a is the species and samples
>>>
>>> Thank you
>>>
>>> 2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>>
>>> > Hi
>>> >
>>> > comments inline
>>> >
>>> > > -----Original Message-----
>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Fabio
>>> > > Monteiro
>>> > > Sent: Monday, February 22, 2016 11:51 AM
>>> > > To: r-help at r-project.org
>>> > > Subject: [R] FD package
>>> > >
>>> > > Hi.
>>> > >
>>> > > First i would like to say that i'm really new in R. I recently
>>> started
>>> > > working with R and i'm using the FD package.
>>> > >
>>> > > I'm having some errors that doesn't make any sense.
>>> > >
>>> > > I have 2 matrix, one is the species with functional traits and the
>>> > > second one is the species and abundances.
>>> >
>>> > Your objects are matrices or data frames? From docs dbFD expects
>>> various
>>> > inputs byt they have to be properly formatted.
>>> >
>>> > >
>>> > > When I try to run the dbFD to calculate the functional diversity, the
>>> > > error is the number of species is different in x and a.
>>> > >
>>> > > I checked a lot of times and the number of species is the same and
>>> > > there are no mistakes in their names like spaces or caps.
>>> >
>>> > How did you checked?
>>> >
>>> > dim(trait) and  dim(abund)
>>> >
>>> > shall give you the same number of rows in traits as columns in abund.
>>> >
>>> > If trait is vector, you need to use length instead of dim.
>>> >
>>> > >
>>> > > Can you help me?
>>> >
>>> > Without better description of your objects and code you used you hardly
>>> > get any answer. You can start by using examples from help page, which
>>> shall
>>> > work and see how your data differ from those examples.
>>> >
>>> > Cheers
>>> > Petr
>>> >
>>> >
>>> > >
>>> > > F?bio Monteiro
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>>> > > guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ________________________________
>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>>> > ur?eny pouze jeho adres?t?m.
>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>> kopie
>>> > vyma?te ze sv?ho syst?mu.
>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>> email
>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi
>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>> >
>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> p?ijmout;
>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>>> > p??jemce s dodatkem ?i odchylkou.
>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>> zmocn?n
>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>> tohoto
>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>> >
>>> > This e-mail and any documents attached to it may be confidential and
>>> are
>>> > intended only for its intended recipients.
>>> > If you received this e-mail by mistake, please immediately inform its
>>> > sender. Delete the contents of this e-mail with all attachments and its
>>> > copies from your system.
>>> > If you are not the intended recipient of this e-mail, you are not
>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>> manner.
>>> > The sender of this e-mail shall not be liable for any possible damage
>>> > caused by modifications of the e-mail or by delay with transfer of the
>>> > email.
>>> >
>>> > In case that this e-mail forms part of business dealings:
>>> > - the sender reserves the right to end negotiations about entering
>>> into a
>>> > contract in any time, for any reason, and without stating any
>>> reasoning.
>>> > - if the e-mail contains an offer, the recipient is entitled to
>>> > immediately accept such offer; The sender of this e-mail (offer)
>>> excludes
>>> > any acceptance of the offer on the part of the recipient containing any
>>> > amendment or variation.
>>> > - the sender insists on that the respective contract is concluded only
>>> > upon an express mutual agreement on all its aspects.
>>> > - the sender of this e-mail informs that he/she is not authorized to
>>> enter
>>> > into any contracts on behalf of the company except for cases in which
>>> > he/she is expressly authorized to do so in writing, and such
>>> authorization
>>> > or power of attorney is submitted to the recipient or the person
>>> > represented by the recipient, or the existence of such authorization is
>>> > known to the recipient of the person represented by the recipient.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>>
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>>
>>                                 -K. Mullis
>>
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>>
>>                               -Robert Gentleman
>>
>>
>


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From efisio.solazzo at jrc.ec.europa.eu  Mon Feb 22 16:24:17 2016
From: efisio.solazzo at jrc.ec.europa.eu (efisio solazzo)
Date: Mon, 22 Feb 2016 16:24:17 +0100
Subject: [R] colors in facet ggplot and geom_bar
Message-ID: <56CB2821.6060105@jrc.ec.europa.eu>

Dear,
I wonder if there is a way to 'play' with colors in facet ggplot and 
geom_bar.

With reference to the attached figure, I'd like to
- color the green portion based on a numerical variable (say 1 to 10) on 
all of the four panels and
- color-code the y labels based on the values of the 'bias' (red portion 
of bars) only on the fourth panel.

the code to produce the plot is:

ggplot(Data, aes(x=mod_names, y=value, 
fill=err_type))+geom_bar(stat='identity', position='stack')  +
   facet_wrap(~spec_comp, nrow=1, 
scales="free")                                +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, 
hjust=1.))        +
   theme(axis.title.x = element_blank())+ ylab(units) +
   geom_text ( aes(label=sign.value, y=pos))  +....

where err_type = c('bias', mMSe', 'var')

thanks for any hint.

-- 
Efisio SOLAZZO, Ph.D.
European Commission, Joint Research Centre,
Institute for Environment and Sustainability,
TP123, Via E. Fermi, 2749 I-21027 Ispra (VA), Italy
Tel: +390332789944 Fax: +390332785837

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ex.png
Type: image/png
Size: 53928 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160222/1b8d0e5e/attachment.png>

From jean-externe.maurice at edf.fr  Mon Feb 22 16:24:21 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Mon, 22 Feb 2016 15:24:21 +0000
Subject: [R] Trying to load a FORTRAN dll but unable
Message-ID: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,
With this piece of code, I get the message 824 :

    deelel <- paste(AccesDLL, "/regr.dll",sep="")
    if ( ! is.loaded(deelel))
    {
               dyn.load(deelel)
               if ( ! is.loaded(deelel))
               {
                              cat("824 : ", deelel, "non charg?e\n")
               }
    }


Am I doing something wrong in this code ?
If not, what can prevent a DLL to be loaded ? And first is it a problem if the DLL is has been built on a 32bits Windows system and is used on a 64bits windows system ?

Thanks in advance
Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Feb 22 16:47:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Feb 2016 10:47:41 -0500
Subject: [R] Trying to load a FORTRAN dll but unable
In-Reply-To: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <56CB2D9D.2000103@gmail.com>

On 22/02/2016 10:24 AM, MAURICE Jean - externe wrote:
> Hi,
> With this piece of code, I get the message 824 :
>
>      deelel <- paste(AccesDLL, "/regr.dll",sep="")
>      if ( ! is.loaded(deelel))

The is.loaded function checks for symbols, not libraries.  See 
?is.loaded for examples.


>      {
>                 dyn.load(deelel)
>                 if ( ! is.loaded(deelel))
>                 {
>                                cat("824 : ", deelel, "non charg?e\n")
>                 }
>      }
>
>
> Am I doing something wrong in this code ?
> If not, what can prevent a DLL to be loaded ? And first is it a problem if the DLL is has been built on a 32bits Windows system and is used on a 64bits windows system ?

It doesn't necessarily matter where it was built, but it definitely does 
matter what the target architecture is.  If you are running 32 bit R, 
you'll see "Platform: i386-w64-mingw32/i386 (32-bit)" in the startup 
banner, and you need a 32 bit DLL.  If you are running 64 bit R, you'll 
see "Platform: x86_64-w64-mingw32/x64 (64-bit)", and you need a 64 bit 
DLL.  32 bit Windows can only run 32 bit R, but 64 bit Windows can run 
either architecture.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Mon Feb 22 16:48:39 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 22 Feb 2016 16:48:39 +0100
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <CAM_vju=yNMM3QMdwXW9je1n1-Dkgxzeqg5rM-HGJbpt5Uf8p3Q@mail.gmail.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
	<D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
	<CAM_vjunVforkEJQ2EmN2+2fcCd+coRwDa=1tggzUgCPt8bWCiA@mail.gmail.com>
	<AM3PR06MB099448206FD4337C1758B8D681A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vju=yNMM3QMdwXW9je1n1-Dkgxzeqg5rM-HGJbpt5Uf8p3Q@mail.gmail.com>
Message-ID: <22219.11735.931817.454412@stat.math.ethz.ch>

>>>>> Sarah Goslee <sarah.goslee at gmail.com>
>>>>>     on Fri, 19 Feb 2016 15:22:22 -0500 writes:

    > Ah, my guess about the confusion was wrong, then. You're
    > misunderstanding silhouette() instead.

    >> From ?silhouette:

    >      Observations with a large s(i) (almost 1) are very
    > well clustered, a small s(i) (around 0) means that the
    > observation lies between two clusters, and observations
    > with a negative s(i) are probably placed in the wrong
    > cluster.


    > In more detail, they're looking at different things.
    > clara() assigns each point to a cluster based on the
    > distance to the nearest medoid.

    > silhouette() does something different: instead of
    > comparing the distances to the closest medoid and the next
    > closest medoid, which is what you seem to be assuming,
    > silhouette() looks at the mean distance to ALL other
    > points assigned to that cluster, vs the mean distance to
    > all points in other clusters. The distance to the medoid
    > is irrelevant, except as it is one of the points in that
    > cluster.

    > So a negative silhouette value is entirely possible, and
    > means that the cluster produced doesn't represent the
    > dataset very well.

Indeed ... and this extends to pam(), even; as you say above,
 " silhouette() does something different " :

If your look at the plots of

    example(silhouette)

where the silhouettes of   pam(ruspini, k = k')  ,  k' = 2,..,6
are displayed, or if you directly look at

   plot( silhouette(ruspini, k = 6) )

you will notice that pam() itself can easily lead to negative
silhouette values.

Martin Maechler  [  == maintainer("cluster")  ]

    

    > On Fri, Feb 19, 2016 at 3:04 PM, ABABAEI, Behnam
    > <Behnam.ABABAEI at limagrain.com> wrote:
    >> Sarah, sorry for taking up your time.
    >> 
    >> I totally agree with you about how it works. But please
    >> let's take a look at this part of the description:
    >> 
    >> "Once k representative objects have been selected from
    >> the sub-dataset, each observation of the entire dataset
    >> is assigned to the nearest medoid. The mean (equivalent
    >> to the sum) of the dissimilarities of the observations to
    >> their closest medoid is used as a measure of the quality
    >> of the clustering. The sub-dataset for which the mean (or
    >> sum) is minimal, is retained. A further analysis is
    >> carried out on the final partition."
    >> 
    >> It says each observation is finally assigned to the
    >> closest medoid. The whole clustering process may be
    >> imperfect in terms of isolation of clusters, but each
    >> observation is already assigned to the closest one and
    >> according to the silhouette formula, the silhouette value
    >> cannot be negative, as a must be always less than b.
    >> 
    >> Regards, Behnam.
    >> 
    >> ________________________________________ From: Sarah
    >> Goslee <sarah.goslee at gmail.com> Sent: 19 February 2016
    >> 20:58 To: ABABAEI, Behnam Cc: r-help at r-project.org
    >> Subject: Re: [R] How a clustering algorithm in R can end
    >> up with negative silhouette values?
    >> 
    >> You need to think more carefully about the details of the
    >> clara() method.
    >> 
    >> The algorithm draws repeated samples of sampsize from the
    >> larger dataset, as specified by the arguments to the
    >> function.  It clusters each sample in turn, and saves the
    >> best one.  It uses the medoids from the best one to
    >> assign all of the points to a cluster.
    >> 
    >> But because the clustering is based on a subsample, it
    >> may not be representative of the dataset as a whole, and
    >> may not provide a good clustering overall. Just because
    >> it clusters the subsample well, doesn't mean it clusters
    >> the entirety. The details section of the help describes
    >> this, and the book references goes into more detail.
    >> 
    >> Sarah
    >> 
    >> 
    >> 
    >> On Fri, Feb 19, 2016 at 2:55 PM, ABABAEI, Behnam
    >> <Behnam.ABABAEI at limagrain.com> wrote:
    >>> Hi Sarah,
    >>> 
    >>> Thank you for the response. But it is said in its
    >>> description that after each run (sample), each
    >>> observation in the whole dataset is assigned to the
    >>> closest cluster. So how is it possible for one
    >>> observation to be wrongly allocated, even with clara?
    >>> 
    >>> Behnam
    >>> 
    >>> Behnam
    >>> 
    >>> 
    >>> 
    >>> 
    >>> On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee"
    >>> <sarah.goslee at gmail.com> wrote:
    >>> 
    >>> That means that points have been assigned to the wrong
    >>> groups. This may readily happen with a clustering method
    >>> like cluster::clara() that uses a subset of the data to
    >>> cluster a dataset too large to analyze as a
    >>> unit. Negative silhouette numbers strongly suggest that
    >>> your clustering parameters should be changed.
    >>> 
    >>> Sarah
    >>> 
    >>> On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
    >>> <Behnam.ABABAEI at limagrain.com> wrote:
    >>>> Hi,
    >>>> 
    >>>> 
    >>>> We know that clustering methods in R assign
    >>>> observations to the closest medoids. Hence, it is
    >>>> supposed to be the closest cluster each observation can
    >>>> have. So, I wonder how it is possible to have negative
    >>>> values of silhouette , while we are supposedly assign
    >>>> each observation to the closest cluster and the formula
    >>>> in silhouette method cannot get negative?
    >>>> 
    >>>> 
    >>>> Behnam.
    >>>> 

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From virendra.mishra at mavs.uta.edu  Mon Feb 22 16:00:53 2016
From: virendra.mishra at mavs.uta.edu (Mishra, Virendra R)
Date: Mon, 22 Feb 2016 15:00:53 +0000
Subject: [R] Multivariate multiple linear regression question
In-Reply-To: <56CB0F5B.5080502@yorku.ca>
References: <CAFCvstnibr2nhhvpBrH0u-Zv90YU6BVaC0G8=jNF6iC31-JzSg@mail.gmail.com>,
	<56CB0F5B.5080502@yorku.ca>
Message-ID: <61B1D26F1DC46876.1-e49ebfa3-ed76-449c-8976-320ca7c6e08f@mail.outlook.com>

Thank you Michael for your suggestions. I will try them out and try to understand their interpretations.

Regards

Virendra

Sent from Outlook Mobile<https://aka.ms/blhgte>



On Mon, Feb 22, 2016 at 5:39 AM -0800, "Michael Friendly" <friendly at yorku.ca<mailto:friendly at yorku.ca>> wrote:

Hi Vivendra

A few suggestions:

* You will get more interpretable tests by using Type II (partial) tests
of terms in your model via
library(car)
Manova(MRI_model)
as opposed to the Type I (sequential) tests available from manova()

* You will be able to understand the results better by making heplots via
library(helplots)
heplot(MRI_model)
but you will have to read the associated vignettes to learn how to
interpret them.

* You can test for equality of covariance matrices in the various
groups using heplots::boxM(), new in the development version on
R-Forge
install.packages("heplots", repos="http://R-Forge.R-project.org")
library(helplots)
res <- boxM(MRI_model, group=group)
res
plot(res)

* You can visually assess the correlations in the groups using
car::scatterplot(..., ellipse=TRUE, groups=)

hope this is helpful,
-Michael


On 2/20/2016 12:53 PM, Virendra Mishra wrote:
> Hi R-users,
>
> I have a fairly simple question to ask but I havent yet got an answer to
> the question. I will describe my experiment, analysis and what have I done
> and what is the question in the following paragraphs and I would appreciate
> if anyone could point me to use right statistical tools to answer my
> question.
>
> Experiment:
> I have 2 groups and both groups undergo 2 set of evaluations, one with MRI
> scanner and the other in the lab to test for their behavior. Both these
> evaluations are known to have statistically significant relationship with
> age and gender.
>
> Statistical question of interest:
> Whether there is:
> 1) statistically significant difference between the 2 groups on each
> evaluation ?
> 2) Whether there is any relationship between and within the 2 groups
> between each evaluation
>
> Model:
>
> I model the problem as following:
> MRI_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
> [Age is continuous and gender , Group are factors/categorical]
>
> Lab_measure = Intercept + Slope1 * Age + Slope 2 * Gender + Slope3 * Group
> [Age is continuous and gender , Group are factors/categorical]
>
> In order to obtain the solution in R:
> MRI_model<-lm(cbind(MRI_measure, Lab_measure) ~ age+gender+group,
> data=data)
>
> Result of R:
> manova(MRI_model) suggests that yes indeed all the slopes are significantly
> different than 0 suggesting a relationship between my measures.
>
> Question:
> 1) In order to test whether the difference in the MRI_measure is
> statistically significant different between the 2 groups, I use
> MRI_model$fitted.values for each dependent measure and do a statistical
> test (either t-test or Wilcox) and claim that the difference is
> significant.
> In the paper I write, multivariate multiple linear regression was performed
> for the groups while controlling for age and gender. The regressed out
> MRI_measure was statistically compared to see if the difference is
> different.
>
> I am assuming that the predicted/fitted.values in model are the regressed
> out variables. Can I show this and use this result? Is this right
>
> If no, what is the correct way to statistically compare whether my 2 groups
> differ in their MRI measure and lab measure when controlled for age and
> gender. Any R library, literature, possibly a script will be greatly
> appreciated.
>
> 2) I also want to see if there is any relationship between MRI_measure and
> Lab_measure within the group after they are controlled for age and gender.
> What is the correct way to do this in R?
>
> Further, I also want to see if there is any significantly different
> association between the 2 groups for my set of dependent variables. I am
> thinking this can be done: I first find the correlation between 2 dependent
> variable in each group and test if this correlation is statistically
> different between the 2 groups? Is this logic right? And if it is, how do I
> compare the correlation? If not, what is the right way to do this? Any R
> library, literature, possibly a script will be greatly appreciated.
>
> I do appreciate any reply.
>
> Thanks
>
> Regards
>
> Virendra
>
>        [[alternative HTML version deleted]]
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From fabio.monteiro1992 at gmail.com  Mon Feb 22 15:03:36 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Mon, 22 Feb 2016 14:03:36 +0000
Subject: [R] FD package
In-Reply-To: <CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
	<CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
	<CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>
Message-ID: <CAG0T74qa6eST6cMiLhWoUiSmz3fTEgg-iEXGoKpheFQVvD33+w@mail.gmail.com>

This is the output.

I want to plot, for example FRic

$nbsp
 com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
com13 com14 com15 com16
   17    21    18    12    15    20    16    12    18    15    18    16
 10    11    17    20
com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
com29 com30 com31 com32
    9    13    11    10    11    15    12    16    18    18    11    19
 12    13    13    12
com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
com45 com46 com47 com48
   15    11    15     8     7    12    10     9    12    15    13    13
 15    13    10    16
com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
com61 com62 com63 com64
   14    12    14    13    14    13    15    13    11    12    16    13
9     8    11    15
com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
com77 com78 com79 com80
   13    18    13    15    10    11    12    11    14     8    10    12
 11    12    14    13
com81 com82
    9    12

$sing.sp
 com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
com13 com14 com15 com16
   17    21    18    12    15    20    16    12    18    15    18    16
 10    11    17    20
com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
com29 com30 com31 com32
    9    13    11    10    11    15    12    16    18    18    11    19
 12    13    13    12
com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
com45 com46 com47 com48
   14    11    15     8     7    12    10     9    12    15    13    13
 15    13    10    16
com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
com61 com62 com63 com64
   14    12    13    13    14    13    15    13    11    12    16    13
9     8    11    15
com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
com77 com78 com79 com80
   13    17    13    15    10    11    12    11    14     8    10    12
 11    12    14    13
com81 com82
    9    12

$FRic
        com1         com2         com3         com4         com5
com6         com7
3.669752e-04 6.898164e-04 6.893918e-04 3.935451e-05 1.436140e-04
1.012949e-03 2.934536e-04
        com8         com9        com10        com11        com12
 com13        com14
1.001556e-04 6.425547e-04 1.740235e-04 5.561802e-04 2.964362e-04
1.480860e-05 1.060512e-04
       com15        com16        com17        com18        com19
 com20        com21
4.121157e-04 5.346433e-04 1.108007e-06 5.726895e-05 8.593435e-06
1.452446e-05 1.855957e-05
       com22        com23        com24        com25        com26
 com27        com28
2.128971e-04 8.438329e-05 3.216279e-04 2.529525e-04 4.980317e-04
3.111325e-05 6.290088e-04
       com29        com30        com31        com32        com33
 com34        com35
3.559802e-05 5.907167e-05 8.906878e-05 2.510168e-05 1.929088e-04
1.234508e-04 2.784301e-04
       com36        com37        com38        com39        com40
 com41        com42
1.480560e-08 1.411752e-06 5.576549e-05 2.445569e-05 6.167242e-06
1.210002e-04 1.666034e-04
       com43        com44        com45        com46        com47
 com48        com49
1.203484e-04 7.347513e-05 8.991003e-05 8.691148e-05 6.718789e-05
1.357136e-04 1.821851e-04
       com50        com51        com52        com53        com54
 com55        com56
4.832203e-05 8.391627e-05 2.173971e-04 1.355160e-04 1.304425e-04
1.787888e-04 1.759204e-05
       com57        com58        com59        com60        com61
 com62        com63
9.307474e-05 1.185857e-04 2.776166e-04 1.277143e-04 5.905299e-06
9.606009e-08 1.019480e-04
       com64        com65        com66        com67        com68
 com69        com70
2.395355e-04 2.307081e-04 4.019309e-04 6.874506e-05 1.417622e-04
5.675463e-06 9.878848e-05
       com71        com72        com73        com74        com75
 com76        com77
6.907251e-05 8.938528e-05 2.493585e-04 1.214151e-09 2.419942e-05
1.183863e-04 7.457464e-05
       com78        com79        com80        com81        com82
6.284563e-05 1.741100e-04 2.128749e-04 2.920847e-06 9.368270e-05

$qual.FRic
[1] 0.7035642

$FEve
     com1      com2      com3      com4      com5      com6      com7
 com8      com9
0.2388515 0.3996566 0.3350494 0.2943431 0.3576785 0.3846561 0.4319967
0.5857688 0.4271764
    com10     com11     com12     com13     com14     com15     com16
com17     com18
0.3288544 0.4625139 0.4810921 0.3041395 0.5820621 0.6313595 0.5406627
0.2707035 0.4530424
    com19     com20     com21     com22     com23     com24     com25
com26     com27
0.3015171 0.5790744 0.7253301 0.5441404 0.4481694 0.6187607 0.5445650
0.4955940 0.5116752
    com28     com29     com30     com31     com32     com33     com34
com35     com36
0.5221560 0.5670513 0.4293040 0.4812907 0.4915317 0.3878949 0.4287726
0.2893205 0.5835605
    com37     com38     com39     com40     com41     com42     com43
com44     com45
0.7896749 0.5482274 0.4015703 0.5990018 0.5431955 0.6251919 0.6023954
0.4962892 0.3749658
    com46     com47     com48     com49     com50     com51     com52
com53     com54
0.4290664 0.4932756 0.5870607 0.3415984 0.3242199 0.4296702 0.4971491
0.3272834 0.4865427
    com55     com56     com57     com58     com59     com60     com61
com62     com63
0.3428716 0.4653631 0.5479140 0.5698272 0.4777804 0.4525375 0.5916255
0.4652363 0.4111973
    com64     com65     com66     com67     com68     com69     com70
com71     com72
0.3987632 0.3856989 0.3064660 0.4717288 0.3534531 0.4285679 0.6087836
0.3607790 0.5494437
    com73     com74     com75     com76     com77     com78     com79
com80     com81
0.4214327 0.4360703 0.3808632 0.2833824 0.2876808 0.3380949 0.3421757
0.2249389 0.6562824
    com82
0.6041267

$FDiv
     com1      com2      com3      com4      com5      com6      com7
 com8      com9
0.7423817 0.7458169 0.8679783 0.8226750 0.8373889 0.7877725 0.8070008
0.7379254 0.8131881
    com10     com11     com12     com13     com14     com15     com16
com17     com18
0.7050804 0.6976598 0.7512530 0.6806472 0.6994011 0.7276620 0.7870732
0.8793599 0.7562019
    com19     com20     com21     com22     com23     com24     com25
com26     com27
0.8983302 0.7681038 0.8163501 0.8198178 0.8489976 0.8922742 0.8442970
0.8269863 0.7891795
    com28     com29     com30     com31     com32     com33     com34
com35     com36
0.7569559 0.8674167 0.7436638 0.7317634 0.9541561 0.7466859 0.7087626
0.8006321 0.8511148
    com37     com38     com39     com40     com41     com42     com43
com44     com45
0.7729260 0.7509163 0.6905947 0.8466404 0.7677596 0.8791198 0.8211045
0.7259760 0.7992553
    com46     com47     com48     com49     com50     com51     com52
com53     com54
0.7573869 0.8788377 0.9036087 0.8287276 0.7762280 0.8064715 0.7775368
0.7828276 0.8151245
    com55     com56     com57     com58     com59     com60     com61
com62     com63
0.7503195 0.9213640 0.9141396 0.9150055 0.8348691 0.7271261 0.7875414
0.8338675 0.7070272
    com64     com65     com66     com67     com68     com69     com70
com71     com72
0.7189990 0.7043998 0.7768710 0.7264939 0.8140790 0.7532290 0.7309884
0.9190267 0.8540992
    com73     com74     com75     com76     com77     com78     com79
com80     com81
0.7531779 0.8520790 0.7649957 0.7319195 0.7578687 0.7915857 0.7600834
0.7303097 0.7693079
    com82
0.7487281

$FDis
      com1       com2       com3       com4       com5       com6
com7       com8
0.19178600 0.15352983 0.23419296 0.20315128 0.18604639 0.14348855
0.28989249 0.25752544
      com9      com10      com11      com12      com13      com14
 com15      com16
0.26174957 0.15962395 0.17907612 0.19642851 0.12827329 0.20114316
0.18128942 0.25731184
     com17      com18      com19      com20      com21      com22
 com23      com24
0.25855225 0.19576353 0.26366092 0.27728602 0.29546846 0.20720052
0.27212077 0.30880887
     com25      com26      com27      com28      com29      com30
 com31      com32
0.29440458 0.25396646 0.25647806 0.23422171 0.25464177 0.24311894
0.16182038 0.09958014
     com33      com34      com35      com36      com37      com38
 com39      com40
0.13095167 0.12983413 0.24224903 0.18239337 0.19817113 0.26320996
0.11766508 0.30940641
     com41      com42      com43      com44      com45      com46
 com47      com48
0.23583814 0.30624876 0.27750572 0.16747032 0.21445188 0.24327116
0.20589103 0.27339261
     com49      com50      com51      com52      com53      com54
 com55      com56
0.23614656 0.23678552 0.25641929 0.26260242 0.22516659 0.25243952
0.23674896 0.18732040
     com57      com58      com59      com60      com61      com62
 com63      com64
0.27202483 0.22947018 0.31342777 0.17997456 0.18461335 0.32429534
0.14840674 0.13731830
     com65      com66      com67      com68      com69      com70
 com71      com72
0.20437128 0.23298402 0.14830718 0.27194825 0.09289396 0.23196338
0.17920946 0.25265696
     com73      com74      com75      com76      com77      com78
 com79      com80
0.23525249 0.22171523 0.21972879 0.23523622 0.25336830 0.22477734
0.20430806 0.20674064
     com81      com82
0.14270928 0.22673005

$RaoQ
      com1       com2       com3       com4       com5       com6
com7       com8
0.05331536 0.03630438 0.07372825 0.06071274 0.05671961 0.05128404
0.10541586 0.08965742
      com9      com10      com11      com12      com13      com14
 com15      com16
0.09102682 0.04333067 0.04941515 0.05495308 0.03115535 0.06048519
0.06070379 0.08680368
     com17      com18      com19      com20      com21      com22
 com23      com24
0.07256118 0.05321952 0.08855815 0.10718949 0.10760039 0.07391960
0.09163325 0.11476244
     com25      com26      com27      com28      com29      com30
 com31      com32
0.10458183 0.08833300 0.07746703 0.07975863 0.08699710 0.07029682
0.04116800 0.02091466
     com33      com34      com35      com36      com37      com38
 com39      com40
0.03452371 0.03102533 0.07072961 0.04601163 0.05125527 0.08872861
0.03608639 0.11227991
     com41      com42      com43      com44      com45      com46
 com47      com48
0.07155343 0.10655043 0.09463142 0.04483107 0.05149290 0.06818611
0.05776898 0.08787335
     com49      com50      com51      com52      com53      com54
 com55      com56
0.06689262 0.06673575 0.07673498 0.08209786 0.06165892 0.07169030
0.07207671 0.05351944
     com57      com58      com59      com60      com61      com62
 com63      com64
0.10496706 0.07830439 0.11178032 0.05616672 0.04961674 0.11105321
0.03840657 0.03693797
     com65      com66      com67      com68      com69      com70
 com71      com72
0.05718178 0.07088485 0.03711119 0.08826702 0.02446860 0.08202483
0.05274964 0.07232899
     com73      com74      com75      com76      com77      com78
 com79      com80
0.06245748 0.05668243 0.06019524 0.07375344 0.07743079 0.06009721
0.05757830 0.05642231
     com81      com82
0.03665132 0.06852237

$CWM
        trait1                        trait2   trait3              trait4
      trait5
com1  Demersal Marine, brackish, freshwater  3.361717 Invertebrate Feeder
     Browser
com2  Demersal Marine, brackish, freshwater  3.391770 Invertebrate Feeder
     Browser
com3  Demersal Marine, brackish, freshwater  3.389626 Invertebrate Feeder
     Browser
com4  Demersal Marine, brackish, freshwater  3.437043 Invertebrate Feeder
     Browser
com5  Demersal Marine, brackish, freshwater  3.450760 Invertebrate Feeder
     Browser
com6  Demersal Marine, brackish, freshwater  3.354952 Invertebrate Feeder
     Browser
com7  Demersal Marine, brackish, freshwater  3.389917 Invertebrate Feeder
     Browser
com8  Demersal Marine, brackish, freshwater  3.382973 Invertebrate Feeder
     Browser
com9  Demersal Marine, brackish, freshwater  3.371722 Invertebrate Feeder
     Browser
com10 Demersal Marine, brackish, freshwater  3.371057 Invertebrate Feeder
     Browser
com11 Demersal Marine, brackish, freshwater  3.389740 Invertebrate Feeder
     Browser
com12 Demersal Marine, brackish, freshwater  3.416626 Invertebrate Feeder
     Browser
com13 Demersal Marine, brackish, freshwater  3.348563 Invertebrate Feeder
     Browser
com14 Demersal Marine, brackish, freshwater  3.310051 Invertebrate Feeder
     Browser
com15 Demersal Marine, brackish, freshwater  3.274433 Invertebrate Feeder
     Browser
com16 Demersal Marine, brackish, freshwater  3.366033 Invertebrate Feeder
     Browser
com17  Pelagic Marine, brackish, freshwater  3.284144 Invertebrate Feeder
Browser/Hunter
com18 Demersal Marine, brackish, freshwater  3.352978 Invertebrate Feeder
     Browser
com19 Demersal Marine, brackish, freshwater  3.313528 Invertebrate Feeder
     Browser
com20 Demersal Marine, brackish, freshwater  3.368486 Invertebrate Feeder
     Browser
com21 Demersal Marine, brackish, freshwater  3.346555 Invertebrate Feeder
     Browser
com22 Demersal Marine, brackish, freshwater  3.348779 Invertebrate Feeder
     Browser
com23 Demersal Marine, brackish, freshwater  3.316949 Invertebrate Feeder
     Browser
com24 Demersal Marine, brackish, freshwater  3.332521 Invertebrate Feeder
     Browser
com25 Demersal Marine, brackish, freshwater  3.398814 Invertebrate Feeder
     Browser
com26 Demersal Marine, brackish, freshwater  3.281393 Invertebrate Feeder
     Browser
com27 Demersal Marine, brackish, freshwater  3.325194 Invertebrate Feeder
     Browser
com28 Demersal Marine, brackish, freshwater  3.356956 Invertebrate Feeder
     Browser
com29 Demersal Marine, brackish, freshwater  3.282245 Invertebrate Feeder
     Browser
com30 Demersal Marine, brackish, freshwater  3.263298 Invertebrate Feeder
     Browser
com31 Demersal Marine, brackish, freshwater  3.304036 Invertebrate Feeder
     Browser
com32 Demersal              Marine, brackish 3.230522 Invertebrate Feeder
     Browser
com33 Demersal Marine, brackish, freshwater  3.347002 Invertebrate Feeder
     Browser
com34 Demersal Marine, brackish, freshwater  3.430373 Invertebrate Feeder
     Browser
com35 Demersal Marine, brackish, freshwater  3.318061 Invertebrate Feeder
     Browser
com36 Demersal Marine, brackish, freshwater  3.334512 Invertebrate Feeder
     Browser
com37 Demersal Marine, brackish, freshwater  3.354938 Invertebrate Feeder
     Browser
com38 Demersal Marine, brackish, freshwater  3.282320 Invertebrate Feeder
     Browser
com39 Demersal Marine, brackish, freshwater  3.307719 Invertebrate Feeder
     Browser
com40 Demersal              Marine, brackish 3.343822 Invertebrate Feeder
     Browser
com41 Demersal Marine, brackish, freshwater  3.347152 Invertebrate Feeder
     Browser
com42 Demersal Marine, brackish, freshwater  3.389799 Invertebrate Feeder
     Browser
com43 Demersal Marine, brackish, freshwater  3.400693 Invertebrate Feeder
     Browser
com44 Demersal Marine, brackish, freshwater  3.421323 Invertebrate Feeder
     Browser
com45 Demersal Marine, brackish, freshwater  3.329006 Invertebrate Feeder
     Browser
com46 Demersal Marine, brackish, freshwater  3.316793 Invertebrate Feeder
     Browser
com47  Benthic Marine, brackish, freshwater  3.309663 Invertebrate Feeder
     Browser
com48 Demersal Marine, brackish, freshwater  3.372207 Invertebrate Feeder
     Browser
com49  Benthic Marine, brackish, freshwater  3.332736 Invertebrate Feeder
     Browser
com50  Benthic Marine, brackish, freshwater  3.311616 Invertebrate Feeder
     Browser
com51 Demersal Marine, brackish, freshwater  3.319775 Invertebrate Feeder
     Browser
com52 Demersal Marine, brackish, freshwater  3.277058 Invertebrate Feeder
     Browser
com53 Demersal Marine, brackish, freshwater  3.354429 Invertebrate Feeder
     Browser
com54 Demersal Marine, brackish, freshwater  3.339532 Invertebrate Feeder
     Browser
com55 Demersal Marine, brackish, freshwater  3.357153 Invertebrate Feeder
     Browser
com56  Benthic Marine, brackish, freshwater  3.279952 Invertebrate Feeder
     Browser
com57  Benthic              Marine, brackish 3.126602 Invertebrate Feeder
     Browser
com58  Benthic              Marine, brackish 3.217454 Invertebrate Feeder
     Browser
com59 Demersal              Marine, brackish 3.307770 Invertebrate Feeder
     Browser
com60 Demersal              Marine, brackish 3.252970 Invertebrate Feeder
     Browser
com61 Demersal Marine, brackish, freshwater  3.404601 Invertebrate Feeder
     Browser
com62  Pelagic Marine, brackish, freshwater  2.806229 Invertebrate Feeder
     Browser
com63 Demersal Marine, brackish, freshwater  3.287427 Invertebrate Feeder
     Browser
com64 Demersal Marine, brackish, freshwater  3.292238 Invertebrate Feeder
     Browser
com65 Demersal              Marine, brackish 3.265497 Invertebrate Feeder
     Browser
com66 Demersal Marine, brackish, freshwater  3.317879 Invertebrate Feeder
     Browser
com67 Demersal              Marine, brackish 3.258586 Invertebrate Feeder
     Browser
com68 Demersal Marine, brackish, freshwater  3.203772 Invertebrate Feeder
     Browser
com69 Demersal Marine, brackish, freshwater  3.289830 Invertebrate Feeder
     Browser
com70 Demersal              Marine, brackish 3.326195 Invertebrate Feeder
     Browser
com71  Benthic Marine, brackish, freshwater  3.325590 Invertebrate Feeder
     Browser
com72  Benthic Marine, brackish, freshwater  3.297994 Invertebrate Feeder
     Browser
com73 Demersal Marine, brackish, freshwater  3.331968 Invertebrate Feeder
     Browser
com74 Demersal Marine, brackish, freshwater  3.395514 Invertebrate Feeder
     Browser
com75 Demersal Marine, brackish, freshwater  3.323936 Invertebrate Feeder
     Browser
com76 Demersal Marine, brackish, freshwater  3.201015 Invertebrate Feeder
     Browser
com77 Demersal Marine, brackish, freshwater  3.280311 Invertebrate Feeder
     Browser
com78 Demersal Marine, brackish, freshwater  3.318771 Invertebrate Feeder
     Browser
com79 Demersal Marine, brackish, freshwater  3.318253 Invertebrate Feeder
     Browser
com80 Demersal Marine, brackish, freshwater  3.374939 Invertebrate Feeder
     Browser
com81 Demersal Marine, brackish, freshwater  3.440927 Invertebrate Feeder
     Browser
com82 Demersal Marine, brackish, freshwater  3.381153 Invertebrate Feeder
     Browser
         trait6
com1  0.5 - 1.0
com2  1.0 - 2.0
com3  1.0 - 2.0
com4  1.0 - 2.0
com5  1.0 - 2.0
com6  1.0 - 2.0
com7  1.0 - 2.0
com8  1.0 - 2.0
com9  0.5 - 1.0
com10 1.0 - 2.0
com11 1.0 - 2.0
com12 1.0 - 2.0
com13 0.5 - 1.0
com14 0.5 - 1.0
com15 0.5 - 1.0
com16 0.5 - 1.0
com17 1.0 - 2.0
com18 0.5 - 1.0
com19 0.5 - 1.0
com20 0.5 - 1.0
com21 0.5 - 1.0
com22 0.5 - 1.0
com23 1.0 - 2.0
com24 1.0 - 2.0
com25 1.0 - 2.0
com26 1.0 - 2.0
com27 1.0 - 2.0
com28 0.5 - 1.0
com29 0.5 - 1.0
com30 0.5 - 1.0
com31 0.5 - 1.0
com32 0.5 - 1.0
com33 0.5 - 1.0
com34 1.0 - 2.0
com35 0.5 - 1.0
com36 0.5 - 1.0
com37 1.0 - 2.0
com38 0.5 - 1.0
com39 0.5 - 1.0
com40 0.5 - 1.0
com41 0.5 - 1.0
com42 1.0 - 2.0
com43 1.0 - 2.0
com44 1.0 - 2.0
com45     < 0.5
com46     < 0.5
com47     < 0.5
com48     < 0.5
com49     < 0.5
com50     < 0.5
com51     < 0.5
com52 0.5 - 1.0
com53 0.5 - 1.0
com54     < 0.5
com55     < 0.5
com56     < 0.5
com57     < 0.5
com58     < 0.5
com59 0.5 - 1.0
com60 0.5 - 1.0
com61 1.0 - 2.0
com62 1.0 - 2.0
com63 0.5 - 1.0
com64 0.5 - 1.0
com65 0.5 - 1.0
com66 0.5 - 1.0
com67 0.5 - 1.0
com68 0.5 - 1.0
com69 0.5 - 1.0
com70 0.5 - 1.0
com71     < 0.5
com72     < 0.5
com73     < 0.5
com74 1.0 - 2.0
com75 0.5 - 1.0
com76 0.5 - 1.0
com77 1.0 - 2.0
com78 0.5 - 1.0
com79 0.5 - 1.0
com80 1.0 - 2.0
com81 1.0 - 2.0
com82 1.0 - 2.0

2016-02-22 13:58 GMT+00:00 stephen sefick <ssefick at gmail.com>:

> If memory serves me, dbFD returns a lot of output. What do you want to
> plot? Also, please provide reproducible examples, so that we can help you
> solve your R related queries.
> kindest regards,
>
> Stephen
>
> On Mon, Feb 22, 2016 at 7:00 AM, Fabio Monteiro <
> fabio.monteiro1992 at gmail.com> wrote:
>
>> Hi
>>
>> thank you for your quick answer
>>
>> I finally managed to insert everything correctly and dbFD is caltulated.
>>
>> I'm now trying to plot the results.
>>
>> My objects are matrices.
>>
>> x is a functional trait and species matrice. a is the species and samples
>>
>> Thank you
>>
>> 2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>
>> > Hi
>> >
>> > comments inline
>> >
>> > > -----Original Message-----
>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fabio
>> > > Monteiro
>> > > Sent: Monday, February 22, 2016 11:51 AM
>> > > To: r-help at r-project.org
>> > > Subject: [R] FD package
>> > >
>> > > Hi.
>> > >
>> > > First i would like to say that i'm really new in R. I recently started
>> > > working with R and i'm using the FD package.
>> > >
>> > > I'm having some errors that doesn't make any sense.
>> > >
>> > > I have 2 matrix, one is the species with functional traits and the
>> > > second one is the species and abundances.
>> >
>> > Your objects are matrices or data frames? From docs dbFD expects various
>> > inputs byt they have to be properly formatted.
>> >
>> > >
>> > > When I try to run the dbFD to calculate the functional diversity, the
>> > > error is the number of species is different in x and a.
>> > >
>> > > I checked a lot of times and the number of species is the same and
>> > > there are no mistakes in their names like spaces or caps.
>> >
>> > How did you checked?
>> >
>> > dim(trait) and  dim(abund)
>> >
>> > shall give you the same number of rows in traits as columns in abund.
>> >
>> > If trait is vector, you need to use length instead of dim.
>> >
>> > >
>> > > Can you help me?
>> >
>> > Without better description of your objects and code you used you hardly
>> > get any answer. You can start by using examples from help page, which
>> shall
>> > work and see how your data differ from those examples.
>> >
>> > Cheers
>> > Petr
>> >
>> >
>> > >
>> > > F?bio Monteiro
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > > guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> > ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>> kopie
>> > vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email
>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi
>> > ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout;
>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> > p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n
>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>> tohoto
>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential and are
>> > intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform its
>> > sender. Delete the contents of this e-mail with all attachments and its
>> > copies from your system.
>> > If you are not the intended recipient of this e-mail, you are not
>> > authorized to use, disseminate, copy or disclose this e-mail in any
>> manner.
>> > The sender of this e-mail shall not be liable for any possible damage
>> > caused by modifications of the e-mail or by delay with transfer of the
>> > email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering into
>> a
>> > contract in any time, for any reason, and without stating any reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to
>> > immediately accept such offer; The sender of this e-mail (offer)
>> excludes
>> > any acceptance of the offer on the part of the recipient containing any
>> > amendment or variation.
>> > - the sender insists on that the respective contract is concluded only
>> > upon an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized to
>> enter
>> > into any contracts on behalf of the company except for cases in which
>> > he/she is expressly authorized to do so in writing, and such
>> authorization
>> > or power of attorney is submitted to the recipient or the person
>> > represented by the recipient, or the existence of such authorization is
>> > known to the recipient of the person represented by the recipient.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>

	[[alternative HTML version deleted]]


From g.vegayon at gmail.com  Thu Feb 18 18:50:36 2016
From: g.vegayon at gmail.com (George Vega Yon)
Date: Thu, 18 Feb 2016 09:50:36 -0800
Subject: [R] [R-pkgs] New package 'netdiffuseR: Network Analysis for
	Diffusion	of Innovations'
Message-ID: <CAPJUxXURpuWcsK0qpkXxtFuRM00k_K4tavZ3fAenZ8HZEOupdg@mail.gmail.com>

Dear useRs,

We are happy to announce that the R package 'netdiffuseR: Network
Analysis for Diffusion of Innovations' is now on CRAN
(https://cran.r-project.org/web/packages/netdiffuseR/). From the
package's description:

"Empirical statistical analysis, visualization and simulation of
network models of the diffusion of innovations. The package implements
algorithms for calculating network diffusion statistics such as
transmission rate, hazard rates, exposure models, network threshold
levels, infectiousness (contagion), and susceptibility. The package is
inspired by work published in Valente, et al., (2015)
<DOI:10.1016/j.socscimed.2015.10.001>; Valente (1995)
<ISBN:9781881303213>, Myers (2000) <DOI:10.1086/303110>, Iyengar and
others (2011) <DOI:10.1287/mksc.1100.0566>, Burt (1987)
<DOI:10.1086/228667>; among others."

Some other relevant features:
 - Allows working with relative large graphs via sparse matrices
(easily handles tenths of thousands vertices), and
 - Includes three classical network diffusion of innovations datasets:
Brazilian Farmers, Korean Family Planning and Medical Innovation

The package should be available to be installed via R's
install.packages function in the following hours as CRAN builds
binaries for Windows/OSX and mirrors have them available to be
installed.

For those of you who are interested on taking a deep look on this new
tool, we will be offering a workshop at the 2016 SUNBELT Conference
(http://insna.org/sunbelt2016/) , so we encourage you to sign in!

Best,

George G. Vega Yon
+1 (626) 381 8171
http://www.its.caltech.edu/~gvegayon/

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewmil at dcn.davis.ca.us  Mon Feb 22 17:00:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 22 Feb 2016 08:00:19 -0800
Subject: [R] colors in facet ggplot and geom_bar
In-Reply-To: <56CB2821.6060105@jrc.ec.europa.eu>
References: <56CB2821.6060105@jrc.ec.europa.eu>
Message-ID: <2D56CB6F-6E70-40B9-9DD7-CF849F336D49@dcn.davis.ca.us>

By failing to provide a reproducible example and framing the desired answer as 'any hint' you are effectively limiting yourself to 'any hint' rather than a working example. 

The 'any hint' is that err_type should be a factor with levels in your desired order, and you can then use any of the scale_fill_* functions including scale_colour_manual to specify the colors in the same order as the levels in the factor. 
-- 
Sent from my phone. Please excuse my brevity.

On February 22, 2016 7:24:17 AM PST, efisio solazzo <efisio.solazzo at jrc.ec.europa.eu> wrote:
>Dear,
>I wonder if there is a way to 'play' with colors in facet ggplot and 
>geom_bar.
>
>With reference to the attached figure, I'd like to
>- color the green portion based on a numerical variable (say 1 to 10)
>on 
>all of the four panels and
>- color-code the y labels based on the values of the 'bias' (red
>portion 
>of bars) only on the fourth panel.
>
>the code to produce the plot is:
>
>ggplot(Data, aes(x=mod_names, y=value, 
>fill=err_type))+geom_bar(stat='identity', position='stack')  +
>   facet_wrap(~spec_comp, nrow=1, 
>scales="free")                                +
>   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, 
>hjust=1.))        +
>   theme(axis.title.x = element_blank())+ ylab(units) +
>   geom_text ( aes(label=sign.value, y=pos))  +....
>
>where err_type = c('bias', mMSe', 'var')
>
>thanks for any hint.
>
>-- 
>Efisio SOLAZZO, Ph.D.
>European Commission, Joint Research Centre,
>Institute for Environment and Sustainability,
>TP123, Via E. Fermi, 2749 I-21027 Ispra (VA), Italy
>Tel: +390332789944 Fax: +390332785837
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Feb 22 17:08:58 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 22 Feb 2016 17:08:58 +0100
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <22219.11735.931817.454412@stat.math.ethz.ch>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
	<D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
	<CAM_vjunVforkEJQ2EmN2+2fcCd+coRwDa=1tggzUgCPt8bWCiA@mail.gmail.com>
	<AM3PR06MB099448206FD4337C1758B8D681A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vju=yNMM3QMdwXW9je1n1-Dkgxzeqg5rM-HGJbpt5Uf8p3Q@mail.gmail.com>
	<22219.11735.931817.454412@stat.math.ethz.ch>
Message-ID: <22219.12954.140811.753752@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon, 22 Feb 2016 16:48:39 +0100 writes:

>>>>> Sarah Goslee <sarah.goslee at gmail.com>
>>>>>     on Fri, 19 Feb 2016 15:22:22 -0500 writes:

    >> Ah, my guess about the confusion was wrong, then. You're
    >> misunderstanding silhouette() instead.

    >>> From ?silhouette:

    >> Observations with a large s(i) (almost 1) are very
    >> well clustered, a small s(i) (around 0) means that the
    >> observation lies between two clusters, and observations
    >> with a negative s(i) are probably placed in the wrong
    >> cluster.


    >> In more detail, they're looking at different things.
    >> clara() assigns each point to a cluster based on the
    >> distance to the nearest medoid.

    >> silhouette() does something different: instead of
    >> comparing the distances to the closest medoid and the next
    >> closest medoid, which is what you seem to be assuming,
    >> silhouette() looks at the mean distance to ALL other
    >> points assigned to that cluster, vs the mean distance to
    >> all points in other clusters. The distance to the medoid
    >> is irrelevant, except as it is one of the points in that
    >> cluster.

    >> So a negative silhouette value is entirely possible, and
    >> means that the cluster produced doesn't represent the
    >> dataset very well.

    > Indeed ... and this extends to pam(), even; as you say above,
    > " silhouette() does something different " :

    > If your look at the plots of

    > example(silhouette)

    > where the silhouettes of   pam(ruspini, k = k')  ,  k' = 2,..,6
    > are displayed, or if you directly look at

    > plot( silhouette(ruspini, k = 6) )

oops... that should have been

    plot( silhouette(pam(ruspini, k = 6)) )

    > you will notice that pam() itself can easily lead to negative
    > silhouette values.

    > Martin Maechler  [  == maintainer("cluster")  ]

    

    >> On Fri, Feb 19, 2016 at 3:04 PM, ABABAEI, Behnam
    >> <Behnam.ABABAEI at limagrain.com> wrote:
    >>> Sarah, sorry for taking up your time.
    >>> 
    >>> I totally agree with you about how it works. But please
    >>> let's take a look at this part of the description:
    >>> 
    >>> "Once k representative objects have been selected from
    >>> the sub-dataset, each observation of the entire dataset
    >>> is assigned to the nearest medoid. The mean (equivalent
    >>> to the sum) of the dissimilarities of the observations to
    >>> their closest medoid is used as a measure of the quality
    >>> of the clustering. The sub-dataset for which the mean (or
    >>> sum) is minimal, is retained. A further analysis is
    >>> carried out on the final partition."
    >>> 
    >>> It says each observation is finally assigned to the
    >>> closest medoid. The whole clustering process may be
    >>> imperfect in terms of isolation of clusters, but each
    >>> observation is already assigned to the closest one and
    >>> according to the silhouette formula, the silhouette value
    >>> cannot be negative, as a must be always less than b.
    >>> 
    >>> Regards, Behnam.
    >>> 
    >>> ________________________________________ From: Sarah
    >>> Goslee <sarah.goslee at gmail.com> Sent: 19 February 2016
    >>> 20:58 To: ABABAEI, Behnam Cc: r-help at r-project.org
    >>> Subject: Re: [R] How a clustering algorithm in R can end
    >>> up with negative silhouette values?
    >>> 
    >>> You need to think more carefully about the details of the
    >>> clara() method.
    >>> 
    >>> The algorithm draws repeated samples of sampsize from the
    >>> larger dataset, as specified by the arguments to the
    >>> function.  It clusters each sample in turn, and saves the
    >>> best one.  It uses the medoids from the best one to
    >>> assign all of the points to a cluster.
    >>> 
    >>> But because the clustering is based on a subsample, it
    >>> may not be representative of the dataset as a whole, and
    >>> may not provide a good clustering overall. Just because
    >>> it clusters the subsample well, doesn't mean it clusters
    >>> the entirety. The details section of the help describes
    >>> this, and the book references goes into more detail.
    >>> 
    >>> Sarah
    >>> 
    >>> 
    >>> 
    >>> On Fri, Feb 19, 2016 at 2:55 PM, ABABAEI, Behnam
    >>> <Behnam.ABABAEI at limagrain.com> wrote:
    >>>> Hi Sarah,
    >>>> 
    >>>> Thank you for the response. But it is said in its
    >>>> description that after each run (sample), each
    >>>> observation in the whole dataset is assigned to the
    >>>> closest cluster. So how is it possible for one
    >>>> observation to be wrongly allocated, even with clara?
    >>>> 
    >>>> Behnam
    >>>> 
    >>>> Behnam
    >>>> 
    >>>> 
    >>>> 
    >>>> 
    >>>> On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee"
    >>>> <sarah.goslee at gmail.com> wrote:
    >>>> 
    >>>> That means that points have been assigned to the wrong
    >>>> groups. This may readily happen with a clustering method
    >>>> like cluster::clara() that uses a subset of the data to
    >>>> cluster a dataset too large to analyze as a
    >>>> unit. Negative silhouette numbers strongly suggest that
    >>>> your clustering parameters should be changed.
    >>>> 
    >>>> Sarah
    >>>> 
    >>>> On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
    >>>> <Behnam.ABABAEI at limagrain.com> wrote:
    >>>>> Hi,
    >>>>> 
    >>>>> 
    >>>>> We know that clustering methods in R assign
    >>>>> observations to the closest medoids. Hence, it is
    >>>>> supposed to be the closest cluster each observation can
    >>>>> have. So, I wonder how it is possible to have negative
    >>>>> values of silhouette , while we are supposedly assign
    >>>>> each observation to the closest cluster and the formula
    >>>>> in silhouette method cannot get negative?
    >>>>> 
    >>>>> 
    >>>>> Behnam.
    >>>>> 

    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From jean-externe.maurice at edf.fr  Mon Feb 22 17:35:57 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Mon, 22 Feb 2016 16:35:57 +0000
Subject: [R] Trying to load a FORTRAN dll but unable
In-Reply-To: <56CB2D9D.2000103@gmail.com>
References: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CB2D9D.2000103@gmail.com>
Message-ID: <87afae9bf1bf464ba80e183ae6dc9962@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Murdoch,

Thanks for your quick answer.

First : I have a 32 bits R running on a 64 bits Windows. So I think I can load 32bits DLL ?

I haven't understood what I must give to is.loaded as parameter : the name of the DLL, the full path to it, the name of a routine in it, the value given by dyn.load (in fact this gives an error) ?

About help : the only example, for is.loaded, I found in fullrefman.pdf was about dyn.load but is ununderstandable (?) because we have not the dyn.load command in the example. And if I write ?is.loaded in R I get nothing !!

Best regards
Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From murdoch.duncan at gmail.com  Mon Feb 22 18:26:47 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Feb 2016 12:26:47 -0500
Subject: [R] Trying to load a FORTRAN dll but unable
In-Reply-To: <87afae9bf1bf464ba80e183ae6dc9962@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CB2D9D.2000103@gmail.com>
	<87afae9bf1bf464ba80e183ae6dc9962@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <56CB44D7.2020907@gmail.com>

On 22/02/2016 11:35 AM, MAURICE Jean - externe wrote:
> Hi Murdoch,
>
> Thanks for your quick answer.
>
> First : I have a 32 bits R running on a 64 bits Windows. So I think I can load 32bits DLL ?

Yes.
>
> I haven't understood what I must give to is.loaded as parameter : the name of the DLL, the full path to it, the name of a routine in it, the value given by dyn.load (in fact this gives an error) ?

The name of a routine, e.g.

is.loaded("supsmu")

(which gives FALSE in current R).


>
> About help : the only example, for is.loaded, I found in fullrefman.pdf was about dyn.load but is ununderstandable (?) because we have not the dyn.load command in the example. And if I write ?is.loaded in R I get nothing !!

Sounds as though you are using a very old or broken version of R. What 
does sessionInfo() give?  You should be using R 3.2.3.  If you're using 
an older one, you're on your own.

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Mon Feb 22 18:30:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 22 Feb 2016 09:30:58 -0800
Subject: [R] Reading a datetime vector
In-Reply-To: <1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
References: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
	<1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <EE12C4B2-FD22-45EE-8BA4-FE391DCE9848@dcn.davis.ca.us>

It is not minutes... read the Excel documentation for representing dates... it is days since December 30, 1899 on Windows.  Read the links I provided in my last email. 

Also read ?str ... that function does not return anything... it only prints out information so don't expect to get anything useful by assigning the output of that function to a variable. 

Also read the examples section of the help file ?read.xlsx2 for relevant help. 
-- 
Sent from my phone. Please excuse my brevity.

On February 22, 2016 8:55:34 AM PST, D Wolf <doug45290 at yahoo.com> wrote:
>Hello Everyone,?
>The column begins populated with integers as so:1/1/2013 0:00 in the
>spreadsheet equals 41257 in R's dataframe1/1/2013 0:15 in the
>spreadsheet equals 41257.010416666664 in R's dataframe...41257 must be
>in minutes since 1440min/day * .010416666664 day = 15 minutes. 41257
>minutes is about 29 days: 41257 min / 1440 min/day = 28.65 days. So I
>don't know why the dataframe is showing 41257 for 1/12013 0:00.?
>Oddly, R sees the vector as NULL despite the fact it has integers in
>each record in the column:data_type = str(df2_TZ$DateTimeStamp)
>produces a NULL (empty) variable.?
>
>I tried:
>df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")Sys.setenv(TZ =
>"GMT")testdtm <- as.POSIXct(df2_TZ$DateTimeStamp, format = "%m/%d/%Y
>%H:%M")# Inspect the resulttestdtmstr(testdtm)
>testdtm is a vector filled with NA values, which figures since
>DateTimeStamp is NULL.?
>I noticed in the table on page 32 of the R Help Desk pdf you linked to
>that dp-as.POSIXct(format(dp, tz="GMT")) is the only option listed for
>time zone difference. So I tried:df2_TZ = read.xlsx2("DF_exp.xlsx",
>sheetName = "Sheet1")df2_TZ_seq <- as.POSIXct(format(dt2_TZ, tz="GMT"))
>and got:?Error in format(dt2_TZ, tz = "GMT") : object 'dt2_TZ' not
>found
>Is the vector neither character nor factor, since it's NULL? Where do I
>go from here??
> Thank You,Doug
>
>Hi Doug,What you have done is to ask whether the character string
>"DF_exp.xlsx" is a character string. I think Yogi Berra, were he still
>around, could have told you that. What will give you some useful
>information is:
>str(DF_exp.xlsx)
>which asks for information about the object, not its name.
>Jim
>
>On Friday, February 19, 2016 12:41 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
> 
>
>This is a mailing list. I don't know how you are interacting with it...
>using a website rather than an email program can lead to some confusion
>since there can be many ways to accomplish the task of interacting with
>the mailing list. My email program has a "reply-all" button when I am
>looking at an email. It also has an option to write the email in plain
>text, which often prevents the message from getting corrupted
>(recipient not seeing what you sent to the list).
>
>Using the str function on a literal string (the name of a file) will
>indeed tell you that you gave it a character string. Specifying a
>column in your data might tell you something more interesting... e.g.
>
>str( df2_TZ$DateTimeStamp )
>
>If that says you have character data then Jim Lemon's suggestion would
>be a good next thing to look at. If it is factor data then you should
>use the as.character function on the data column and then follow Jim's
>suggestion. If it is numeric then you probably need to convert it using
>an appropriate origin (e.g. as described at [1] or [2]).
>
>I have had best luck setting the default timezone string when
>converting to POSIXt types... e.g.
>
># specify timezone assumed by input data
>Sys.setenv( TZ="GMT" )
>testdtm <- as.POSIXct( "1/1/2016 00:00", format = "%m/%d/%Y %H:%M" )
># inspect the result
>testdtm
>str( testdtm )
># view data from a different timezone
>Sys.setenv( TZ="Etc/GMT+8" )
># no change to the underlying data, but it prints out differently now
>because the tz attribute is "" which implies using the default TZ
>testdtm
>
>[1] http://blog.mollietaylor.com/2013/08/date-formats-in-r.html
>[2] https://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf
>
>-- 
>Sent from my phone. Please excuse my brevity.
>
>On February 19, 2016 7:48:31 AM PST, D Wolf <doug45290 at yahoo.com>
>wrote:
>Hello Jeff,
>I ran str() on the vector and it returned character.>
>str("DF_exp.xlsx")?chr "DF_exp.xlsx"
>This is my first thread on this forum, and I'm not sure how to reply to
>the thread instead of just sending the reply to your email account; I
>don't see a 'reply' link in the thread.I've read this page and I don't
>think it advises on how to reply in the thread:?R: Posting Guide: How
>to ask good questions that prompt useful answers
>
>| ? |
>| ? |  | ? | ? | ? | ? | ? |
>| R: Posting Guide: How to ask good questions that prompt ...Posting
>Guide: How to ask good questions that prompt useful answers This guide
>is intended to help you get the most out of the R mailing lists, and to
>avoid embarra... |
>|  |
>| View on www.r-project.org | Preview by Yahoo |
>|  |
>| ? |
>
>
>Thank You,Doug Wolfinger
> 
>
>On Friday, February 19, 2016 12:51 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
> 
>
>You are being rather scattershot in your explanation, so I suspect you
>are not being systematic in your troubleshooting. Use the str function
>to examine the data column after you pull it in from excel. It may be
>numeric, factor, or character, and the approach depends on which that
>function returns. 
>-- 
>Sent from my phone. Please excuse my brevity.
>
>On February 18, 2016 1:12:40 PM PST, D Wolf via R-help
><r-help at r-project.org> wrote:
>Hello,I am trying to read a data frame column named DateTimeStamp. The
>time is in GMT in this format: 1/4/2013 23:30
>require(xlsx)
>df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")
>
>It's good to that line. But these three lines, which makes the
>dataframe, converts the column's values to NA:df2_TZ$DateTimeStamp =
>as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")
>
>and...?df2_TZ$DateTimeStamp =
>as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y
>%H:%M:%S")
>
>and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format =
>"%m/%d/%Y %H:%M:%S")
>
>This line returns and error...df2_TZ$DateTimeStamp =
>as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
>"Error in charToDate(x) :??
>character string is not in a standard unambiguous format"
>Additionally, I need to convert from GMT to North American time zones,
>and I think the advice on this page would
>be good for
>that:?http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
>My ultimate goal is to write an R program that finds data in another
>variable in df2_TZ that corresponds to a date and time that match up
>with the date and time in another data frame. For now, any help reading
>the column would be much appreciated.
>Thank You,Doug
> [[alternative HTML version deleted]]
>
>
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>   

	[[alternative HTML version deleted]]


From doug45290 at yahoo.com  Mon Feb 22 17:55:34 2016
From: doug45290 at yahoo.com (D Wolf)
Date: Mon, 22 Feb 2016 16:55:34 +0000 (UTC)
Subject: [R] Reading a datetime vector
In-Reply-To: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
References: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
Message-ID: <1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>

Hello Everyone,?
The column begins populated with integers as so:1/1/2013 0:00 in the spreadsheet equals 41257 in R's dataframe1/1/2013 0:15 in the spreadsheet equals 41257.010416666664 in R's dataframe...41257 must be in minutes since 1440min/day * .010416666664 day = 15 minutes. 41257 minutes is about 29 days: 41257 min / 1440 min/day = 28.65 days. So I don't know why the dataframe is showing 41257 for 1/12013 0:00.?
Oddly, R sees the vector as NULL despite the fact it has integers in each record in the column:data_type = str(df2_TZ$DateTimeStamp) produces a NULL (empty) variable.?

I tried:
df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")Sys.setenv(TZ = "GMT")testdtm <- as.POSIXct(df2_TZ$DateTimeStamp, format = "%m/%d/%Y %H:%M")# Inspect the resulttestdtmstr(testdtm)
testdtm is a vector filled with NA values, which figures since DateTimeStamp is NULL.?
I noticed in the table on page 32 of the R Help Desk pdf you linked to that dp-as.POSIXct(format(dp, tz="GMT")) is the only option listed for time zone difference. So I tried:df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")df2_TZ_seq <- as.POSIXct(format(dt2_TZ, tz="GMT"))
and got:?Error in format(dt2_TZ, tz = "GMT") : object 'dt2_TZ' not found
Is the vector neither character nor factor, since it's NULL? Where do I go from here??
 Thank You,Doug

Hi Doug,What you have done is to ask whether the character string "DF_exp.xlsx" is a character string. I think Yogi Berra, were he still around, could have told you that. What will give you some useful information is:
str(DF_exp.xlsx)
which asks for information about the object, not its name.
Jim

    On Friday, February 19, 2016 12:41 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 This is a mailing list. I don't know how you are interacting with it... using a website rather than an email program can lead to some confusion since there can be many ways to accomplish the task of interacting with the mailing list. My email program has a "reply-all" button when I am looking at an email. It also has an option to write the email in plain text, which often prevents the message from getting corrupted (recipient not seeing what you sent to the list).

Using the str function on a literal string (the name of a file) will indeed tell you that you gave it a character string. Specifying a column in your data might tell you something more interesting... e.g.

str( df2_TZ$DateTimeStamp )

If that says you have character data then Jim Lemon's suggestion would be a good next thing to look at. If it is factor data then you should use the as.character function on the data column and then follow Jim's suggestion. If it is numeric then you probably need to convert it using an appropriate origin (e.g. as described at [1] or [2]).

I have had best luck setting the default timezone string when converting to POSIXt types... e.g.

# specify timezone assumed by input data
Sys.setenv( TZ="GMT" )
testdtm <- as.POSIXct( "1/1/2016 00:00", format = "%m/%d/%Y %H:%M" )
# inspect the result
testdtm
str( testdtm )
# view data from a different timezone
Sys.setenv( TZ="Etc/GMT+8" )
# no change to the underlying data, but it prints out differently now because the tz attribute is "" which implies using the default TZ
testdtm

[1] http://blog.mollietaylor.com/2013/08/date-formats-in-r.html
[2] https://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf

-- 
Sent from my phone. Please excuse my brevity.

On February 19, 2016 7:48:31 AM PST, D Wolf <doug45290 at yahoo.com> wrote:
Hello Jeff,
I ran str() on the vector and it returned character.> str("DF_exp.xlsx")?chr "DF_exp.xlsx"
This is my first thread on this forum, and I'm not sure how to reply to the thread instead of just sending the reply to your email account; I don't see a 'reply' link in the thread.I've read this page and I don't think it advises on how to reply in the thread:?R: Posting Guide: How to ask good questions that prompt useful answers

| ? |
| ? |  | ? | ? | ? | ? | ? |
| R: Posting Guide: How to ask good questions that prompt ...Posting Guide: How to ask good questions that prompt useful answers This guide is intended to help you get the most out of the R mailing lists, and to avoid embarra... |
|  |
| View on www.r-project.org | Preview by Yahoo |
|  |
| ? |


Thank You,Doug Wolfinger
 

    On Friday, February 19, 2016 12:51 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 You are being rather scattershot in your explanation, so I suspect you are not being systematic in your troubleshooting. Use the str function to examine the data column after you pull it in from excel. It may be numeric, factor, or character, and the approach depends on which that function returns. 
-- 
Sent from my phone. Please excuse my brevity.

On February 18, 2016 1:12:40 PM PST, D Wolf via R-help <r-help at r-project.org> wrote:
Hello,I am trying to read a data frame column named DateTimeStamp. The time is in GMT in this format: 1/4/2013 23:30
require(xlsx)
df2_TZ = read.xlsx2("DF_exp.xlsx", sheetName = "Sheet1")

It's good to that line. But these three lines, which makes the dataframe, converts the column's values to NA:df2_TZ$DateTimeStamp = as.POSIXct(df2_TZ$DateTimeStamp, format="%m/%d/%Y %H:%M:%S", tz="GMT")

and...?df2_TZ$DateTimeStamp = as.POSIXct(as.character(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")

and...df2_TZ$DateTimeStamp = as.Date(df2_TZ$DateTimeStamp, format = "%m/%d/%Y %H:%M:%S")

This line returns and error...df2_TZ$DateTimeStamp = as.POSIXct(as.Date(df2_TZ$DateTimeStamp), format = "%m/%d/%Y %H:%M:%S")
"Error in charToDate(x) :??
character string is not in a standard unambiguous format"
Additionally, I need to convert from GMT to North American time zones, and I think the advice on this page would
be good for that:?http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
My ultimate goal is to write an R program that finds data in another variable in df2_TZ that corresponds to a date and time that match up with the date and time in another data frame. For now, any help reading the column would be much appreciated.
Thank You,Doug
 [[alternative HTML version deleted]]


R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   


  
	[[alternative HTML version deleted]]


From fabio.monteiro1992 at gmail.com  Mon Feb 22 17:47:47 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Mon, 22 Feb 2016 16:47:47 +0000
Subject: [R] FD package
In-Reply-To: <CADKEMqhNCc0nH8kuJoUUfTsRjN0_p+4iuP2uJ0NRHMOpEL7wyQ@mail.gmail.com>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
	<CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
	<CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>
	<CAG0T74qa6eST6cMiLhWoUiSmz3fTEgg-iEXGoKpheFQVvD33+w@mail.gmail.com>
	<CADKEMqhNCc0nH8kuJoUUfTsRjN0_p+4iuP2uJ0NRHMOpEL7wyQ@mail.gmail.com>
Message-ID: <CAG0T74rQiZeMQJJT65zmCw+7m0ptip1xJZMr9ARZqK-Sn2ZzgA@mail.gmail.com>

> hist(data$FRic)
Error in data$FRic : object of type 'closure' is not subsettable

2016-02-22 14:10 GMT+00:00 stephen sefick <ssefick at gmail.com>:

> Please see ?dput. What you provided is not a minimal, reproducible example
> (i.e., there is no R code).
>
> What kind of plot are you trying to plot? hist(data$FRic) will plot your
> data. I guess we need more information to be helpful.
>
>
> On Mon, Feb 22, 2016 at 8:03 AM, Fabio Monteiro <
> fabio.monteiro1992 at gmail.com> wrote:
>
>> This is the output.
>>
>> I want to plot, for example FRic
>>
>> $nbsp
>>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
>> com13 com14 com15 com16
>>    17    21    18    12    15    20    16    12    18    15    18    16
>>  10    11    17    20
>> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
>> com29 com30 com31 com32
>>     9    13    11    10    11    15    12    16    18    18    11    19
>>  12    13    13    12
>> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
>> com45 com46 com47 com48
>>    15    11    15     8     7    12    10     9    12    15    13    13
>>  15    13    10    16
>> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
>> com61 com62 com63 com64
>>    14    12    14    13    14    13    15    13    11    12    16    13
>>   9     8    11    15
>> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
>> com77 com78 com79 com80
>>    13    18    13    15    10    11    12    11    14     8    10    12
>>  11    12    14    13
>> com81 com82
>>     9    12
>>
>> $sing.sp
>>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
>> com13 com14 com15 com16
>>    17    21    18    12    15    20    16    12    18    15    18    16
>>  10    11    17    20
>> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
>> com29 com30 com31 com32
>>     9    13    11    10    11    15    12    16    18    18    11    19
>>  12    13    13    12
>> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
>> com45 com46 com47 com48
>>    14    11    15     8     7    12    10     9    12    15    13    13
>>  15    13    10    16
>> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
>> com61 com62 com63 com64
>>    14    12    13    13    14    13    15    13    11    12    16    13
>>   9     8    11    15
>> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
>> com77 com78 com79 com80
>>    13    17    13    15    10    11    12    11    14     8    10    12
>>  11    12    14    13
>> com81 com82
>>     9    12
>>
>> $FRic
>>         com1         com2         com3         com4         com5
>> com6         com7
>> 3.669752e-04 6.898164e-04 6.893918e-04 3.935451e-05 1.436140e-04
>> 1.012949e-03 2.934536e-04
>>         com8         com9        com10        com11        com12
>>  com13        com14
>> 1.001556e-04 6.425547e-04 1.740235e-04 5.561802e-04 2.964362e-04
>> 1.480860e-05 1.060512e-04
>>        com15        com16        com17        com18        com19
>>  com20        com21
>> 4.121157e-04 5.346433e-04 1.108007e-06 5.726895e-05 8.593435e-06
>> 1.452446e-05 1.855957e-05
>>        com22        com23        com24        com25        com26
>>  com27        com28
>> 2.128971e-04 8.438329e-05 3.216279e-04 2.529525e-04 4.980317e-04
>> 3.111325e-05 6.290088e-04
>>        com29        com30        com31        com32        com33
>>  com34        com35
>> 3.559802e-05 5.907167e-05 8.906878e-05 2.510168e-05 1.929088e-04
>> 1.234508e-04 2.784301e-04
>>        com36        com37        com38        com39        com40
>>  com41        com42
>> 1.480560e-08 1.411752e-06 5.576549e-05 2.445569e-05 6.167242e-06
>> 1.210002e-04 1.666034e-04
>>        com43        com44        com45        com46        com47
>>  com48        com49
>> 1.203484e-04 7.347513e-05 8.991003e-05 8.691148e-05 6.718789e-05
>> 1.357136e-04 1.821851e-04
>>        com50        com51        com52        com53        com54
>>  com55        com56
>> 4.832203e-05 8.391627e-05 2.173971e-04 1.355160e-04 1.304425e-04
>> 1.787888e-04 1.759204e-05
>>        com57        com58        com59        com60        com61
>>  com62        com63
>> 9.307474e-05 1.185857e-04 2.776166e-04 1.277143e-04 5.905299e-06
>> 9.606009e-08 1.019480e-04
>>        com64        com65        com66        com67        com68
>>  com69        com70
>> 2.395355e-04 2.307081e-04 4.019309e-04 6.874506e-05 1.417622e-04
>> 5.675463e-06 9.878848e-05
>>        com71        com72        com73        com74        com75
>>  com76        com77
>> 6.907251e-05 8.938528e-05 2.493585e-04 1.214151e-09 2.419942e-05
>> 1.183863e-04 7.457464e-05
>>        com78        com79        com80        com81        com82
>> 6.284563e-05 1.741100e-04 2.128749e-04 2.920847e-06 9.368270e-05
>>
>> $qual.FRic
>> [1] 0.7035642
>>
>> $FEve
>>      com1      com2      com3      com4      com5      com6      com7
>>  com8      com9
>> 0.2388515 0.3996566 0.3350494 0.2943431 0.3576785 0.3846561 0.4319967
>> 0.5857688 0.4271764
>>     com10     com11     com12     com13     com14     com15     com16
>> com17     com18
>> 0.3288544 0.4625139 0.4810921 0.3041395 0.5820621 0.6313595 0.5406627
>> 0.2707035 0.4530424
>>     com19     com20     com21     com22     com23     com24     com25
>> com26     com27
>> 0.3015171 0.5790744 0.7253301 0.5441404 0.4481694 0.6187607 0.5445650
>> 0.4955940 0.5116752
>>     com28     com29     com30     com31     com32     com33     com34
>> com35     com36
>> 0.5221560 0.5670513 0.4293040 0.4812907 0.4915317 0.3878949 0.4287726
>> 0.2893205 0.5835605
>>     com37     com38     com39     com40     com41     com42     com43
>> com44     com45
>> 0.7896749 0.5482274 0.4015703 0.5990018 0.5431955 0.6251919 0.6023954
>> 0.4962892 0.3749658
>>     com46     com47     com48     com49     com50     com51     com52
>> com53     com54
>> 0.4290664 0.4932756 0.5870607 0.3415984 0.3242199 0.4296702 0.4971491
>> 0.3272834 0.4865427
>>     com55     com56     com57     com58     com59     com60     com61
>> com62     com63
>> 0.3428716 0.4653631 0.5479140 0.5698272 0.4777804 0.4525375 0.5916255
>> 0.4652363 0.4111973
>>     com64     com65     com66     com67     com68     com69     com70
>> com71     com72
>> 0.3987632 0.3856989 0.3064660 0.4717288 0.3534531 0.4285679 0.6087836
>> 0.3607790 0.5494437
>>     com73     com74     com75     com76     com77     com78     com79
>> com80     com81
>> 0.4214327 0.4360703 0.3808632 0.2833824 0.2876808 0.3380949 0.3421757
>> 0.2249389 0.6562824
>>     com82
>> 0.6041267
>>
>> $FDiv
>>      com1      com2      com3      com4      com5      com6      com7
>>  com8      com9
>> 0.7423817 0.7458169 0.8679783 0.8226750 0.8373889 0.7877725 0.8070008
>> 0.7379254 0.8131881
>>     com10     com11     com12     com13     com14     com15     com16
>> com17     com18
>> 0.7050804 0.6976598 0.7512530 0.6806472 0.6994011 0.7276620 0.7870732
>> 0.8793599 0.7562019
>>     com19     com20     com21     com22     com23     com24     com25
>> com26     com27
>> 0.8983302 0.7681038 0.8163501 0.8198178 0.8489976 0.8922742 0.8442970
>> 0.8269863 0.7891795
>>     com28     com29     com30     com31     com32     com33     com34
>> com35     com36
>> 0.7569559 0.8674167 0.7436638 0.7317634 0.9541561 0.7466859 0.7087626
>> 0.8006321 0.8511148
>>     com37     com38     com39     com40     com41     com42     com43
>> com44     com45
>> 0.7729260 0.7509163 0.6905947 0.8466404 0.7677596 0.8791198 0.8211045
>> 0.7259760 0.7992553
>>     com46     com47     com48     com49     com50     com51     com52
>> com53     com54
>> 0.7573869 0.8788377 0.9036087 0.8287276 0.7762280 0.8064715 0.7775368
>> 0.7828276 0.8151245
>>     com55     com56     com57     com58     com59     com60     com61
>> com62     com63
>> 0.7503195 0.9213640 0.9141396 0.9150055 0.8348691 0.7271261 0.7875414
>> 0.8338675 0.7070272
>>     com64     com65     com66     com67     com68     com69     com70
>> com71     com72
>> 0.7189990 0.7043998 0.7768710 0.7264939 0.8140790 0.7532290 0.7309884
>> 0.9190267 0.8540992
>>     com73     com74     com75     com76     com77     com78     com79
>> com80     com81
>> 0.7531779 0.8520790 0.7649957 0.7319195 0.7578687 0.7915857 0.7600834
>> 0.7303097 0.7693079
>>     com82
>> 0.7487281
>>
>> $FDis
>>       com1       com2       com3       com4       com5       com6
>> com7       com8
>> 0.19178600 0.15352983 0.23419296 0.20315128 0.18604639 0.14348855
>> 0.28989249 0.25752544
>>       com9      com10      com11      com12      com13      com14
>>  com15      com16
>> 0.26174957 0.15962395 0.17907612 0.19642851 0.12827329 0.20114316
>> 0.18128942 0.25731184
>>      com17      com18      com19      com20      com21      com22
>>  com23      com24
>> 0.25855225 0.19576353 0.26366092 0.27728602 0.29546846 0.20720052
>> 0.27212077 0.30880887
>>      com25      com26      com27      com28      com29      com30
>>  com31      com32
>> 0.29440458 0.25396646 0.25647806 0.23422171 0.25464177 0.24311894
>> 0.16182038 0.09958014
>>      com33      com34      com35      com36      com37      com38
>>  com39      com40
>> 0.13095167 0.12983413 0.24224903 0.18239337 0.19817113 0.26320996
>> 0.11766508 0.30940641
>>      com41      com42      com43      com44      com45      com46
>>  com47      com48
>> 0.23583814 0.30624876 0.27750572 0.16747032 0.21445188 0.24327116
>> 0.20589103 0.27339261
>>      com49      com50      com51      com52      com53      com54
>>  com55      com56
>> 0.23614656 0.23678552 0.25641929 0.26260242 0.22516659 0.25243952
>> 0.23674896 0.18732040
>>      com57      com58      com59      com60      com61      com62
>>  com63      com64
>> 0.27202483 0.22947018 0.31342777 0.17997456 0.18461335 0.32429534
>> 0.14840674 0.13731830
>>      com65      com66      com67      com68      com69      com70
>>  com71      com72
>> 0.20437128 0.23298402 0.14830718 0.27194825 0.09289396 0.23196338
>> 0.17920946 0.25265696
>>      com73      com74      com75      com76      com77      com78
>>  com79      com80
>> 0.23525249 0.22171523 0.21972879 0.23523622 0.25336830 0.22477734
>> 0.20430806 0.20674064
>>      com81      com82
>> 0.14270928 0.22673005
>>
>> $RaoQ
>>       com1       com2       com3       com4       com5       com6
>> com7       com8
>> 0.05331536 0.03630438 0.07372825 0.06071274 0.05671961 0.05128404
>> 0.10541586 0.08965742
>>       com9      com10      com11      com12      com13      com14
>>  com15      com16
>> 0.09102682 0.04333067 0.04941515 0.05495308 0.03115535 0.06048519
>> 0.06070379 0.08680368
>>      com17      com18      com19      com20      com21      com22
>>  com23      com24
>> 0.07256118 0.05321952 0.08855815 0.10718949 0.10760039 0.07391960
>> 0.09163325 0.11476244
>>      com25      com26      com27      com28      com29      com30
>>  com31      com32
>> 0.10458183 0.08833300 0.07746703 0.07975863 0.08699710 0.07029682
>> 0.04116800 0.02091466
>>      com33      com34      com35      com36      com37      com38
>>  com39      com40
>> 0.03452371 0.03102533 0.07072961 0.04601163 0.05125527 0.08872861
>> 0.03608639 0.11227991
>>      com41      com42      com43      com44      com45      com46
>>  com47      com48
>> 0.07155343 0.10655043 0.09463142 0.04483107 0.05149290 0.06818611
>> 0.05776898 0.08787335
>>      com49      com50      com51      com52      com53      com54
>>  com55      com56
>> 0.06689262 0.06673575 0.07673498 0.08209786 0.06165892 0.07169030
>> 0.07207671 0.05351944
>>      com57      com58      com59      com60      com61      com62
>>  com63      com64
>> 0.10496706 0.07830439 0.11178032 0.05616672 0.04961674 0.11105321
>> 0.03840657 0.03693797
>>      com65      com66      com67      com68      com69      com70
>>  com71      com72
>> 0.05718178 0.07088485 0.03711119 0.08826702 0.02446860 0.08202483
>> 0.05274964 0.07232899
>>      com73      com74      com75      com76      com77      com78
>>  com79      com80
>> 0.06245748 0.05668243 0.06019524 0.07375344 0.07743079 0.06009721
>> 0.05757830 0.05642231
>>      com81      com82
>> 0.03665132 0.06852237
>>
>> $CWM
>>         trait1                        trait2   trait3              trait4
>>         trait5
>> com1  Demersal Marine, brackish, freshwater  3.361717 Invertebrate Feeder
>>        Browser
>> com2  Demersal Marine, brackish, freshwater  3.391770 Invertebrate Feeder
>>        Browser
>> com3  Demersal Marine, brackish, freshwater  3.389626 Invertebrate Feeder
>>        Browser
>> com4  Demersal Marine, brackish, freshwater  3.437043 Invertebrate Feeder
>>        Browser
>> com5  Demersal Marine, brackish, freshwater  3.450760 Invertebrate Feeder
>>        Browser
>> com6  Demersal Marine, brackish, freshwater  3.354952 Invertebrate Feeder
>>        Browser
>> com7  Demersal Marine, brackish, freshwater  3.389917 Invertebrate Feeder
>>        Browser
>> com8  Demersal Marine, brackish, freshwater  3.382973 Invertebrate Feeder
>>        Browser
>> com9  Demersal Marine, brackish, freshwater  3.371722 Invertebrate Feeder
>>        Browser
>> com10 Demersal Marine, brackish, freshwater  3.371057 Invertebrate Feeder
>>        Browser
>> com11 Demersal Marine, brackish, freshwater  3.389740 Invertebrate Feeder
>>        Browser
>> com12 Demersal Marine, brackish, freshwater  3.416626 Invertebrate Feeder
>>        Browser
>> com13 Demersal Marine, brackish, freshwater  3.348563 Invertebrate Feeder
>>        Browser
>> com14 Demersal Marine, brackish, freshwater  3.310051 Invertebrate Feeder
>>        Browser
>> com15 Demersal Marine, brackish, freshwater  3.274433 Invertebrate Feeder
>>        Browser
>> com16 Demersal Marine, brackish, freshwater  3.366033 Invertebrate Feeder
>>        Browser
>> com17  Pelagic Marine, brackish, freshwater  3.284144 Invertebrate Feeder
>> Browser/Hunter
>> com18 Demersal Marine, brackish, freshwater  3.352978 Invertebrate Feeder
>>        Browser
>> com19 Demersal Marine, brackish, freshwater  3.313528 Invertebrate Feeder
>>        Browser
>> com20 Demersal Marine, brackish, freshwater  3.368486 Invertebrate Feeder
>>        Browser
>> com21 Demersal Marine, brackish, freshwater  3.346555 Invertebrate Feeder
>>        Browser
>> com22 Demersal Marine, brackish, freshwater  3.348779 Invertebrate Feeder
>>        Browser
>> com23 Demersal Marine, brackish, freshwater  3.316949 Invertebrate Feeder
>>        Browser
>> com24 Demersal Marine, brackish, freshwater  3.332521 Invertebrate Feeder
>>        Browser
>> com25 Demersal Marine, brackish, freshwater  3.398814 Invertebrate Feeder
>>        Browser
>> com26 Demersal Marine, brackish, freshwater  3.281393 Invertebrate Feeder
>>        Browser
>> com27 Demersal Marine, brackish, freshwater  3.325194 Invertebrate Feeder
>>        Browser
>> com28 Demersal Marine, brackish, freshwater  3.356956 Invertebrate Feeder
>>        Browser
>> com29 Demersal Marine, brackish, freshwater  3.282245 Invertebrate Feeder
>>        Browser
>> com30 Demersal Marine, brackish, freshwater  3.263298 Invertebrate Feeder
>>        Browser
>> com31 Demersal Marine, brackish, freshwater  3.304036 Invertebrate Feeder
>>        Browser
>> com32 Demersal              Marine, brackish 3.230522 Invertebrate Feeder
>>        Browser
>> com33 Demersal Marine, brackish, freshwater  3.347002 Invertebrate Feeder
>>        Browser
>> com34 Demersal Marine, brackish, freshwater  3.430373 Invertebrate Feeder
>>        Browser
>> com35 Demersal Marine, brackish, freshwater  3.318061 Invertebrate Feeder
>>        Browser
>> com36 Demersal Marine, brackish, freshwater  3.334512 Invertebrate Feeder
>>        Browser
>> com37 Demersal Marine, brackish, freshwater  3.354938 Invertebrate Feeder
>>        Browser
>> com38 Demersal Marine, brackish, freshwater  3.282320 Invertebrate Feeder
>>        Browser
>> com39 Demersal Marine, brackish, freshwater  3.307719 Invertebrate Feeder
>>        Browser
>> com40 Demersal              Marine, brackish 3.343822 Invertebrate Feeder
>>        Browser
>> com41 Demersal Marine, brackish, freshwater  3.347152 Invertebrate Feeder
>>        Browser
>> com42 Demersal Marine, brackish, freshwater  3.389799 Invertebrate Feeder
>>        Browser
>> com43 Demersal Marine, brackish, freshwater  3.400693 Invertebrate Feeder
>>        Browser
>> com44 Demersal Marine, brackish, freshwater  3.421323 Invertebrate Feeder
>>        Browser
>> com45 Demersal Marine, brackish, freshwater  3.329006 Invertebrate Feeder
>>        Browser
>> com46 Demersal Marine, brackish, freshwater  3.316793 Invertebrate Feeder
>>        Browser
>> com47  Benthic Marine, brackish, freshwater  3.309663 Invertebrate Feeder
>>        Browser
>> com48 Demersal Marine, brackish, freshwater  3.372207 Invertebrate Feeder
>>        Browser
>> com49  Benthic Marine, brackish, freshwater  3.332736 Invertebrate Feeder
>>        Browser
>> com50  Benthic Marine, brackish, freshwater  3.311616 Invertebrate Feeder
>>        Browser
>> com51 Demersal Marine, brackish, freshwater  3.319775 Invertebrate Feeder
>>        Browser
>> com52 Demersal Marine, brackish, freshwater  3.277058 Invertebrate Feeder
>>        Browser
>> com53 Demersal Marine, brackish, freshwater  3.354429 Invertebrate Feeder
>>        Browser
>> com54 Demersal Marine, brackish, freshwater  3.339532 Invertebrate Feeder
>>        Browser
>> com55 Demersal Marine, brackish, freshwater  3.357153 Invertebrate Feeder
>>        Browser
>> com56  Benthic Marine, brackish, freshwater  3.279952 Invertebrate Feeder
>>        Browser
>> com57  Benthic              Marine, brackish 3.126602 Invertebrate Feeder
>>        Browser
>> com58  Benthic              Marine, brackish 3.217454 Invertebrate Feeder
>>        Browser
>> com59 Demersal              Marine, brackish 3.307770 Invertebrate Feeder
>>        Browser
>> com60 Demersal              Marine, brackish 3.252970 Invertebrate Feeder
>>        Browser
>> com61 Demersal Marine, brackish, freshwater  3.404601 Invertebrate Feeder
>>        Browser
>> com62  Pelagic Marine, brackish, freshwater  2.806229 Invertebrate Feeder
>>        Browser
>> com63 Demersal Marine, brackish, freshwater  3.287427 Invertebrate Feeder
>>        Browser
>> com64 Demersal Marine, brackish, freshwater  3.292238 Invertebrate Feeder
>>        Browser
>> com65 Demersal              Marine, brackish 3.265497 Invertebrate Feeder
>>        Browser
>> com66 Demersal Marine, brackish, freshwater  3.317879 Invertebrate Feeder
>>        Browser
>> com67 Demersal              Marine, brackish 3.258586 Invertebrate Feeder
>>        Browser
>> com68 Demersal Marine, brackish, freshwater  3.203772 Invertebrate Feeder
>>        Browser
>> com69 Demersal Marine, brackish, freshwater  3.289830 Invertebrate Feeder
>>        Browser
>> com70 Demersal              Marine, brackish 3.326195 Invertebrate Feeder
>>        Browser
>> com71  Benthic Marine, brackish, freshwater  3.325590 Invertebrate Feeder
>>        Browser
>> com72  Benthic Marine, brackish, freshwater  3.297994 Invertebrate Feeder
>>        Browser
>> com73 Demersal Marine, brackish, freshwater  3.331968 Invertebrate Feeder
>>        Browser
>> com74 Demersal Marine, brackish, freshwater  3.395514 Invertebrate Feeder
>>        Browser
>> com75 Demersal Marine, brackish, freshwater  3.323936 Invertebrate Feeder
>>        Browser
>> com76 Demersal Marine, brackish, freshwater  3.201015 Invertebrate Feeder
>>        Browser
>> com77 Demersal Marine, brackish, freshwater  3.280311 Invertebrate Feeder
>>        Browser
>> com78 Demersal Marine, brackish, freshwater  3.318771 Invertebrate Feeder
>>        Browser
>> com79 Demersal Marine, brackish, freshwater  3.318253 Invertebrate Feeder
>>        Browser
>> com80 Demersal Marine, brackish, freshwater  3.374939 Invertebrate Feeder
>>        Browser
>> com81 Demersal Marine, brackish, freshwater  3.440927 Invertebrate Feeder
>>        Browser
>> com82 Demersal Marine, brackish, freshwater  3.381153 Invertebrate Feeder
>>        Browser
>>          trait6
>> com1  0.5 - 1.0
>> com2  1.0 - 2.0
>> com3  1.0 - 2.0
>> com4  1.0 - 2.0
>> com5  1.0 - 2.0
>> com6  1.0 - 2.0
>> com7  1.0 - 2.0
>> com8  1.0 - 2.0
>> com9  0.5 - 1.0
>> com10 1.0 - 2.0
>> com11 1.0 - 2.0
>> com12 1.0 - 2.0
>> com13 0.5 - 1.0
>> com14 0.5 - 1.0
>> com15 0.5 - 1.0
>> com16 0.5 - 1.0
>> com17 1.0 - 2.0
>> com18 0.5 - 1.0
>> com19 0.5 - 1.0
>> com20 0.5 - 1.0
>> com21 0.5 - 1.0
>> com22 0.5 - 1.0
>> com23 1.0 - 2.0
>> com24 1.0 - 2.0
>> com25 1.0 - 2.0
>> com26 1.0 - 2.0
>> com27 1.0 - 2.0
>> com28 0.5 - 1.0
>> com29 0.5 - 1.0
>> com30 0.5 - 1.0
>> com31 0.5 - 1.0
>> com32 0.5 - 1.0
>> com33 0.5 - 1.0
>> com34 1.0 - 2.0
>> com35 0.5 - 1.0
>> com36 0.5 - 1.0
>> com37 1.0 - 2.0
>> com38 0.5 - 1.0
>> com39 0.5 - 1.0
>> com40 0.5 - 1.0
>> com41 0.5 - 1.0
>> com42 1.0 - 2.0
>> com43 1.0 - 2.0
>> com44 1.0 - 2.0
>> com45     < 0.5
>> com46     < 0.5
>> com47     < 0.5
>> com48     < 0.5
>> com49     < 0.5
>> com50     < 0.5
>> com51     < 0.5
>> com52 0.5 - 1.0
>> com53 0.5 - 1.0
>> com54     < 0.5
>> com55     < 0.5
>> com56     < 0.5
>> com57     < 0.5
>> com58     < 0.5
>> com59 0.5 - 1.0
>> com60 0.5 - 1.0
>> com61 1.0 - 2.0
>> com62 1.0 - 2.0
>> com63 0.5 - 1.0
>> com64 0.5 - 1.0
>> com65 0.5 - 1.0
>> com66 0.5 - 1.0
>> com67 0.5 - 1.0
>> com68 0.5 - 1.0
>> com69 0.5 - 1.0
>> com70 0.5 - 1.0
>> com71     < 0.5
>> com72     < 0.5
>> com73     < 0.5
>> com74 1.0 - 2.0
>> com75 0.5 - 1.0
>> com76 0.5 - 1.0
>> com77 1.0 - 2.0
>> com78 0.5 - 1.0
>> com79 0.5 - 1.0
>> com80 1.0 - 2.0
>> com81 1.0 - 2.0
>> com82 1.0 - 2.0
>>
>> 2016-02-22 13:58 GMT+00:00 stephen sefick <ssefick at gmail.com>:
>>
>>> If memory serves me, dbFD returns a lot of output. What do you want to
>>> plot? Also, please provide reproducible examples, so that we can help you
>>> solve your R related queries.
>>> kindest regards,
>>>
>>> Stephen
>>>
>>> On Mon, Feb 22, 2016 at 7:00 AM, Fabio Monteiro <
>>> fabio.monteiro1992 at gmail.com> wrote:
>>>
>>>> Hi
>>>>
>>>> thank you for your quick answer
>>>>
>>>> I finally managed to insert everything correctly and dbFD is caltulated.
>>>>
>>>> I'm now trying to plot the results.
>>>>
>>>> My objects are matrices.
>>>>
>>>> x is a functional trait and species matrice. a is the species and
>>>> samples
>>>>
>>>> Thank you
>>>>
>>>> 2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>>>
>>>> > Hi
>>>> >
>>>> > comments inline
>>>> >
>>>> > > -----Original Message-----
>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> Fabio
>>>> > > Monteiro
>>>> > > Sent: Monday, February 22, 2016 11:51 AM
>>>> > > To: r-help at r-project.org
>>>> > > Subject: [R] FD package
>>>> > >
>>>> > > Hi.
>>>> > >
>>>> > > First i would like to say that i'm really new in R. I recently
>>>> started
>>>> > > working with R and i'm using the FD package.
>>>> > >
>>>> > > I'm having some errors that doesn't make any sense.
>>>> > >
>>>> > > I have 2 matrix, one is the species with functional traits and the
>>>> > > second one is the species and abundances.
>>>> >
>>>> > Your objects are matrices or data frames? From docs dbFD expects
>>>> various
>>>> > inputs byt they have to be properly formatted.
>>>> >
>>>> > >
>>>> > > When I try to run the dbFD to calculate the functional diversity,
>>>> the
>>>> > > error is the number of species is different in x and a.
>>>> > >
>>>> > > I checked a lot of times and the number of species is the same and
>>>> > > there are no mistakes in their names like spaces or caps.
>>>> >
>>>> > How did you checked?
>>>> >
>>>> > dim(trait) and  dim(abund)
>>>> >
>>>> > shall give you the same number of rows in traits as columns in abund.
>>>> >
>>>> > If trait is vector, you need to use length instead of dim.
>>>> >
>>>> > >
>>>> > > Can you help me?
>>>> >
>>>> > Without better description of your objects and code you used you
>>>> hardly
>>>> > get any answer. You can start by using examples from help page, which
>>>> shall
>>>> > work and see how your data differ from those examples.
>>>> >
>>>> > Cheers
>>>> > Petr
>>>> >
>>>> >
>>>> > >
>>>> > > F?bio Monteiro
>>>> > >
>>>> > >       [[alternative HTML version deleted]]
>>>> > >
>>>> > > ______________________________________________
>>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> > > guide.html
>>>> > > and provide commented, minimal, self-contained, reproducible code.
>>>> >
>>>> > ________________________________
>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>> jsou
>>>> > ur?eny pouze jeho adres?t?m.
>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>>> kopie
>>>> > vyma?te ze sv?ho syst?mu.
>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>>> email
>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>> modifikacemi
>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>> >
>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>> p?ijmout;
>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>>>> > p??jemce s dodatkem ?i odchylkou.
>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>> zmocn?n
>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>>> tohoto
>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>> jejich
>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>> >
>>>> > This e-mail and any documents attached to it may be confidential and
>>>> are
>>>> > intended only for its intended recipients.
>>>> > If you received this e-mail by mistake, please immediately inform its
>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>> its
>>>> > copies from your system.
>>>> > If you are not the intended recipient of this e-mail, you are not
>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>> manner.
>>>> > The sender of this e-mail shall not be liable for any possible damage
>>>> > caused by modifications of the e-mail or by delay with transfer of the
>>>> > email.
>>>> >
>>>> > In case that this e-mail forms part of business dealings:
>>>> > - the sender reserves the right to end negotiations about entering
>>>> into a
>>>> > contract in any time, for any reason, and without stating any
>>>> reasoning.
>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>> excludes
>>>> > any acceptance of the offer on the part of the recipient containing
>>>> any
>>>> > amendment or variation.
>>>> > - the sender insists on that the respective contract is concluded only
>>>> > upon an express mutual agreement on all its aspects.
>>>> > - the sender of this e-mail informs that he/she is not authorized to
>>>> enter
>>>> > into any contracts on behalf of the company except for cases in which
>>>> > he/she is expressly authorized to do so in writing, and such
>>>> authorization
>>>> > or power of attorney is submitted to the recipient or the person
>>>> > represented by the recipient, or the existence of such authorization
>>>> is
>>>> > known to the recipient of the person represented by the recipient.
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>> --
>>> Stephen Sefick
>>> **************************************************
>>> Auburn University
>>> Biological Sciences
>>> 331 Funchess Hall
>>> Auburn, Alabama
>>> 36849
>>> **************************************************
>>> sas0025 at auburn.edu
>>> http://www.auburn.edu/~sas0025
>>> **************************************************
>>>
>>> Let's not spend our time and resources thinking about things that are so
>>> little or so large that all they really do for us is puff us up and make us
>>> feel like gods.  We are mammals, and have not exhausted the annoying little
>>> problems of being mammals.
>>>
>>>                                 -K. Mullis
>>>
>>> "A big computer, a complex algorithm and a long time does not equal
>>> science."
>>>
>>>                               -Robert Gentleman
>>>
>>>
>>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>

	[[alternative HTML version deleted]]


From ulhaqz at gmail.com  Mon Feb 22 19:32:16 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Mon, 22 Feb 2016 23:32:16 +0500
Subject: [R] Grep Help
Message-ID: <CADw4Ckto+ZKZqvLgGKPwcobhr6aE9KFcHiQpiG8pJLOjJ4ahbA@mail.gmail.com>

Hi,

# 1) I have read in a CSV file

df = read.csv(file="GiftCards - v1.csv",stringsAsFactors=FALSE)
head(df)
str(df)

# 2) converted to a tbl_df
df2 = tbl_df(df)

# 3) fixed the names to remove leading "X" character
n = names(df2)
n2 = gsub(pattern="^\\w","\\1",n)
names(df2) = n2

# 4) somehow the col names are character strings, requiring me to use
quotes:
df2$`2006` instead of df2$2006 # ---> PROBLEM 1


# 5) I need to remove the leading $ sign followed by spaces to extract
values. The problem is # it could be a two or three digit number. I am able
to retrieve two digits correctly, but miss # out on the leading third digit.
df2$`2006`= gsub("^(.+)([0-9]{2,3}\\.[0-9]{2})","\\2",df2$`2006`) # -->
Problem 2

# 6) dump for the data frame

df2 <-
structure(list(`2006` = structure(c(3L, 2L, 1L), .Label = c("$
24.81",
"$     39.16", "$   146.20"), class = "factor"), `2007` = structure(c(3L,
2L, 1L), .Label = c("$       26.25", "$     41.95", "$   156.24"
), class = "factor"), `2008` = structure(c(3L, 2L, 1L), .Label = c("$
24.92",
"$     40.54", "$   147.33"), class = "factor"), `2009` = structure(c(3L,
2L, 1L), .Label = c("$       23.63", "$     39.80", "$   139.91"
), class = "factor"), `2010` = structure(c(3L, 2L, 1L), .Label = c("$
24.78",
"$     41.48", "$   145.61"), class = "factor"), `2011` = structure(c(3L,
2L, 1L), .Label = c("$       27.80", "$     43.23", "$   155.43"
), class = "factor"), `2012` = structure(c(3L, 2L, 1L), .Label = c("$
28.79",
"$     43.75", "$   156.86"), class = "factor"), `2013` = structure(c(3L,
2L, 1L), .Label = c("$       29.80", "$     45.16", "$   163.16"
), class = "factor")), .Names = c("2006", "2007", "2008", "2009",
"2010", "2011", "2012", "2013"), class = c("tbl_df", "tbl", "data.frame"
), row.names = c(NA, -3L))



Thanks for the help


Br /

	[[alternative HTML version deleted]]


From xiyanlon at gmail.com  Mon Feb 22 19:46:24 2016
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Tue, 23 Feb 2016 01:46:24 +0700
Subject: [R] How to merge two tables
Message-ID: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>

Dear all,
I am currently studying categorical data analysis, if I have two tables:

R> cross
      sex cross death count
1  FEMALE   WEF   YES    26
2    MALE   WEF   YES    14
3  FEMALE   OGG   YES    32
4    MALE   OGG   YES    43
5  FEMALE   TGA   YES     8
6    MALE   TGA   YES    10
7  FEMALE   WEF    NO     6
8    MALE   WEF    NO     7
9  FEMALE   OGG    NO    26
10   MALE   OGG    NO    12
11 FEMALE   TGA    NO    16
12   MALE   TGA    NO    26

R> age
     sex age death count
1 FEMALE 17Y   YES    16
2   MALE 17Y   YES     4
3 FEMALE 18Y   YES    40
4   MALE 18Y   YES    51
5 FEMALE 17Y    NO    32
6   MALE 17Y    NO    42
7 FEMALE 18Y    NO    26
8   MALE 18Y    NO    15

- How to merge two tables.
- How to expand both tables such as:

sex age cross death
FEMALE 17Y WEF YES
...
FEMALE 18Y TGA NO


Warm regards,
Xiyan Lon

This email has been sent from a virus-free computer protected by Avast.
www.avast.com <https://www.avast.com/sig-email>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Feb 22 19:54:56 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 22 Feb 2016 13:54:56 -0500
Subject: [R] Grep Help
In-Reply-To: <CADw4Ckto+ZKZqvLgGKPwcobhr6aE9KFcHiQpiG8pJLOjJ4ahbA@mail.gmail.com>
References: <CADw4Ckto+ZKZqvLgGKPwcobhr6aE9KFcHiQpiG8pJLOjJ4ahbA@mail.gmail.com>
Message-ID: <1D001549-BDDC-45A0-9503-6681111548A6@utoronto.ca>

I see numerous backticks in your code, not quotes. "`" and "'" are not the same. Backticks are not string delimiters.
As for valid names: look at the help page for make.names().


HTH,
Boris



On Feb 22, 2016, at 1:32 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:

> Hi,
> 
> # 1) I have read in a CSV file
> 
> df = read.csv(file="GiftCards - v1.csv",stringsAsFactors=FALSE)
> head(df)
> str(df)
> 
> # 2) converted to a tbl_df
> df2 = tbl_df(df)
> 
> # 3) fixed the names to remove leading "X" character
> n = names(df2)
> n2 = gsub(pattern="^\\w","\\1",n)
> names(df2) = n2
> 
> # 4) somehow the col names are character strings, requiring me to use
> quotes:
> df2$`2006` instead of df2$2006 # ---> PROBLEM 1
> 
> 
> # 5) I need to remove the leading $ sign followed by spaces to extract
> values. The problem is # it could be a two or three digit number. I am able
> to retrieve two digits correctly, but miss # out on the leading third digit.
> df2$`2006`= gsub("^(.+)([0-9]{2,3}\\.[0-9]{2})","\\2",df2$`2006`) # -->
> Problem 2
> 
> # 6) dump for the data frame
> 
> df2 <-
> structure(list(`2006` = structure(c(3L, 2L, 1L), .Label = c("$
> 24.81",
> "$     39.16", "$   146.20"), class = "factor"), `2007` = structure(c(3L,
> 2L, 1L), .Label = c("$       26.25", "$     41.95", "$   156.24"
> ), class = "factor"), `2008` = structure(c(3L, 2L, 1L), .Label = c("$
> 24.92",
> "$     40.54", "$   147.33"), class = "factor"), `2009` = structure(c(3L,
> 2L, 1L), .Label = c("$       23.63", "$     39.80", "$   139.91"
> ), class = "factor"), `2010` = structure(c(3L, 2L, 1L), .Label = c("$
> 24.78",
> "$     41.48", "$   145.61"), class = "factor"), `2011` = structure(c(3L,
> 2L, 1L), .Label = c("$       27.80", "$     43.23", "$   155.43"
> ), class = "factor"), `2012` = structure(c(3L, 2L, 1L), .Label = c("$
> 28.79",
> "$     43.75", "$   156.86"), class = "factor"), `2013` = structure(c(3L,
> 2L, 1L), .Label = c("$       29.80", "$     45.16", "$   163.16"
> ), class = "factor")), .Names = c("2006", "2007", "2008", "2009",
> "2010", "2011", "2012", "2013"), class = c("tbl_df", "tbl", "data.frame"
> ), row.names = c(NA, -3L))
> 
> 
> 
> Thanks for the help
> 
> 
> Br /
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Feb 22 20:45:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 22 Feb 2016 11:45:31 -0800 (PST)
Subject: [R] How to merge two tables
In-Reply-To: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
References: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1602221135470.24699@pedal.dcn.davis.ca.us>

I can see no coherent way to merge these two tables. They do not appear to 
have consistent definitions for uniqueness of individual rows. Nor do they 
have consistent column definitions. If you think they do, you will need to 
be more clear in your question about how you want them to be merged.

As for expanding, you might try using something like

ageExpand <- age[ rep( seq_along( age[[1]] ), times=age[,"count"] ), 1:3 ]

On Tue, 23 Feb 2016, Xiyan Lon wrote:

> Dear all,
> I am currently studying categorical data analysis, if I have two tables:
>
> R> cross
>      sex cross death count
> 1  FEMALE   WEF   YES    26
> 2    MALE   WEF   YES    14
> 3  FEMALE   OGG   YES    32
> 4    MALE   OGG   YES    43
> 5  FEMALE   TGA   YES     8
> 6    MALE   TGA   YES    10
> 7  FEMALE   WEF    NO     6
> 8    MALE   WEF    NO     7
> 9  FEMALE   OGG    NO    26
> 10   MALE   OGG    NO    12
> 11 FEMALE   TGA    NO    16
> 12   MALE   TGA    NO    26
>
> R> age
>     sex age death count
> 1 FEMALE 17Y   YES    16
> 2   MALE 17Y   YES     4
> 3 FEMALE 18Y   YES    40
> 4   MALE 18Y   YES    51
> 5 FEMALE 17Y    NO    32
> 6   MALE 17Y    NO    42
> 7 FEMALE 18Y    NO    26
> 8   MALE 18Y    NO    15
>
> - How to merge two tables.
> - How to expand both tables such as:
>
> sex age cross death
> FEMALE 17Y WEF YES
> ...
> FEMALE 18Y TGA NO
>
>
> Warm regards,
> Xiyan Lon
>
> This email has been sent from a virus-free computer protected by Avast.
> www.avast.com <https://www.avast.com/sig-email>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Mon Feb 22 20:54:30 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 22 Feb 2016 11:54:30 -0800 (PST)
Subject: [R] FD package
In-Reply-To: <CAG0T74rQiZeMQJJT65zmCw+7m0ptip1xJZMr9ARZqK-Sn2ZzgA@mail.gmail.com>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
	<CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
	<CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>
	<CAG0T74qa6eST6cMiLhWoUiSmz3fTEgg-iEXGoKpheFQVvD33+w@mail.gmail.com>
	<CADKEMqhNCc0nH8kuJoUUfTsRjN0_p+4iuP2uJ0NRHMOpEL7wyQ@mail.gmail.com>
	<CAG0T74rQiZeMQJJT65zmCw+7m0ptip1xJZMr9ARZqK-Sn2ZzgA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1602221147320.24699@pedal.dcn.davis.ca.us>

"data" is the name of a function in base R. It is not a good idea to use 
that as the name of an actual data object (to which the "$" operator is 
being applied here). It is not clear from what you have provided what 
variable names you are working with... you are not communicating yet using 
reproducible examples, so you are depending on our psychic powers to fill 
in the gaps, which is not likely to work reliably. I suspect that Stephen 
used the generic term "data" since he did not know what variable name you 
were actually using.

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

On Mon, 22 Feb 2016, Fabio Monteiro wrote:

>> hist(data$FRic)
> Error in data$FRic : object of type 'closure' is not subsettable
>
> 2016-02-22 14:10 GMT+00:00 stephen sefick <ssefick at gmail.com>:
>
>> Please see ?dput. What you provided is not a minimal, reproducible example
>> (i.e., there is no R code).
>>
>> What kind of plot are you trying to plot? hist(data$FRic) will plot your
>> data. I guess we need more information to be helpful.
>>
>>
>> On Mon, Feb 22, 2016 at 8:03 AM, Fabio Monteiro <
>> fabio.monteiro1992 at gmail.com> wrote:
>>
>>> This is the output.
>>>
>>> I want to plot, for example FRic
>>>
>>> $nbsp
>>>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
>>> com13 com14 com15 com16
>>>    17    21    18    12    15    20    16    12    18    15    18    16
>>>  10    11    17    20
>>> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
>>> com29 com30 com31 com32
>>>     9    13    11    10    11    15    12    16    18    18    11    19
>>>  12    13    13    12
>>> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
>>> com45 com46 com47 com48
>>>    15    11    15     8     7    12    10     9    12    15    13    13
>>>  15    13    10    16
>>> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
>>> com61 com62 com63 com64
>>>    14    12    14    13    14    13    15    13    11    12    16    13
>>>   9     8    11    15
>>> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
>>> com77 com78 com79 com80
>>>    13    18    13    15    10    11    12    11    14     8    10    12
>>>  11    12    14    13
>>> com81 com82
>>>     9    12
>>>
>>> $sing.sp
>>>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
>>> com13 com14 com15 com16
>>>    17    21    18    12    15    20    16    12    18    15    18    16
>>>  10    11    17    20
>>> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
>>> com29 com30 com31 com32
>>>     9    13    11    10    11    15    12    16    18    18    11    19
>>>  12    13    13    12
>>> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
>>> com45 com46 com47 com48
>>>    14    11    15     8     7    12    10     9    12    15    13    13
>>>  15    13    10    16
>>> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
>>> com61 com62 com63 com64
>>>    14    12    13    13    14    13    15    13    11    12    16    13
>>>   9     8    11    15
>>> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
>>> com77 com78 com79 com80
>>>    13    17    13    15    10    11    12    11    14     8    10    12
>>>  11    12    14    13
>>> com81 com82
>>>     9    12
>>>
>>> $FRic
>>>         com1         com2         com3         com4         com5
>>> com6         com7
>>> 3.669752e-04 6.898164e-04 6.893918e-04 3.935451e-05 1.436140e-04
>>> 1.012949e-03 2.934536e-04
>>>         com8         com9        com10        com11        com12
>>>  com13        com14
>>> 1.001556e-04 6.425547e-04 1.740235e-04 5.561802e-04 2.964362e-04
>>> 1.480860e-05 1.060512e-04
>>>        com15        com16        com17        com18        com19
>>>  com20        com21
>>> 4.121157e-04 5.346433e-04 1.108007e-06 5.726895e-05 8.593435e-06
>>> 1.452446e-05 1.855957e-05
>>>        com22        com23        com24        com25        com26
>>>  com27        com28
>>> 2.128971e-04 8.438329e-05 3.216279e-04 2.529525e-04 4.980317e-04
>>> 3.111325e-05 6.290088e-04
>>>        com29        com30        com31        com32        com33
>>>  com34        com35
>>> 3.559802e-05 5.907167e-05 8.906878e-05 2.510168e-05 1.929088e-04
>>> 1.234508e-04 2.784301e-04
>>>        com36        com37        com38        com39        com40
>>>  com41        com42
>>> 1.480560e-08 1.411752e-06 5.576549e-05 2.445569e-05 6.167242e-06
>>> 1.210002e-04 1.666034e-04
>>>        com43        com44        com45        com46        com47
>>>  com48        com49
>>> 1.203484e-04 7.347513e-05 8.991003e-05 8.691148e-05 6.718789e-05
>>> 1.357136e-04 1.821851e-04
>>>        com50        com51        com52        com53        com54
>>>  com55        com56
>>> 4.832203e-05 8.391627e-05 2.173971e-04 1.355160e-04 1.304425e-04
>>> 1.787888e-04 1.759204e-05
>>>        com57        com58        com59        com60        com61
>>>  com62        com63
>>> 9.307474e-05 1.185857e-04 2.776166e-04 1.277143e-04 5.905299e-06
>>> 9.606009e-08 1.019480e-04
>>>        com64        com65        com66        com67        com68
>>>  com69        com70
>>> 2.395355e-04 2.307081e-04 4.019309e-04 6.874506e-05 1.417622e-04
>>> 5.675463e-06 9.878848e-05
>>>        com71        com72        com73        com74        com75
>>>  com76        com77
>>> 6.907251e-05 8.938528e-05 2.493585e-04 1.214151e-09 2.419942e-05
>>> 1.183863e-04 7.457464e-05
>>>        com78        com79        com80        com81        com82
>>> 6.284563e-05 1.741100e-04 2.128749e-04 2.920847e-06 9.368270e-05
>>>
>>> $qual.FRic
>>> [1] 0.7035642
>>>
>>> $FEve
>>>      com1      com2      com3      com4      com5      com6      com7
>>>  com8      com9
>>> 0.2388515 0.3996566 0.3350494 0.2943431 0.3576785 0.3846561 0.4319967
>>> 0.5857688 0.4271764
>>>     com10     com11     com12     com13     com14     com15     com16
>>> com17     com18
>>> 0.3288544 0.4625139 0.4810921 0.3041395 0.5820621 0.6313595 0.5406627
>>> 0.2707035 0.4530424
>>>     com19     com20     com21     com22     com23     com24     com25
>>> com26     com27
>>> 0.3015171 0.5790744 0.7253301 0.5441404 0.4481694 0.6187607 0.5445650
>>> 0.4955940 0.5116752
>>>     com28     com29     com30     com31     com32     com33     com34
>>> com35     com36
>>> 0.5221560 0.5670513 0.4293040 0.4812907 0.4915317 0.3878949 0.4287726
>>> 0.2893205 0.5835605
>>>     com37     com38     com39     com40     com41     com42     com43
>>> com44     com45
>>> 0.7896749 0.5482274 0.4015703 0.5990018 0.5431955 0.6251919 0.6023954
>>> 0.4962892 0.3749658
>>>     com46     com47     com48     com49     com50     com51     com52
>>> com53     com54
>>> 0.4290664 0.4932756 0.5870607 0.3415984 0.3242199 0.4296702 0.4971491
>>> 0.3272834 0.4865427
>>>     com55     com56     com57     com58     com59     com60     com61
>>> com62     com63
>>> 0.3428716 0.4653631 0.5479140 0.5698272 0.4777804 0.4525375 0.5916255
>>> 0.4652363 0.4111973
>>>     com64     com65     com66     com67     com68     com69     com70
>>> com71     com72
>>> 0.3987632 0.3856989 0.3064660 0.4717288 0.3534531 0.4285679 0.6087836
>>> 0.3607790 0.5494437
>>>     com73     com74     com75     com76     com77     com78     com79
>>> com80     com81
>>> 0.4214327 0.4360703 0.3808632 0.2833824 0.2876808 0.3380949 0.3421757
>>> 0.2249389 0.6562824
>>>     com82
>>> 0.6041267
>>>
>>> $FDiv
>>>      com1      com2      com3      com4      com5      com6      com7
>>>  com8      com9
>>> 0.7423817 0.7458169 0.8679783 0.8226750 0.8373889 0.7877725 0.8070008
>>> 0.7379254 0.8131881
>>>     com10     com11     com12     com13     com14     com15     com16
>>> com17     com18
>>> 0.7050804 0.6976598 0.7512530 0.6806472 0.6994011 0.7276620 0.7870732
>>> 0.8793599 0.7562019
>>>     com19     com20     com21     com22     com23     com24     com25
>>> com26     com27
>>> 0.8983302 0.7681038 0.8163501 0.8198178 0.8489976 0.8922742 0.8442970
>>> 0.8269863 0.7891795
>>>     com28     com29     com30     com31     com32     com33     com34
>>> com35     com36
>>> 0.7569559 0.8674167 0.7436638 0.7317634 0.9541561 0.7466859 0.7087626
>>> 0.8006321 0.8511148
>>>     com37     com38     com39     com40     com41     com42     com43
>>> com44     com45
>>> 0.7729260 0.7509163 0.6905947 0.8466404 0.7677596 0.8791198 0.8211045
>>> 0.7259760 0.7992553
>>>     com46     com47     com48     com49     com50     com51     com52
>>> com53     com54
>>> 0.7573869 0.8788377 0.9036087 0.8287276 0.7762280 0.8064715 0.7775368
>>> 0.7828276 0.8151245
>>>     com55     com56     com57     com58     com59     com60     com61
>>> com62     com63
>>> 0.7503195 0.9213640 0.9141396 0.9150055 0.8348691 0.7271261 0.7875414
>>> 0.8338675 0.7070272
>>>     com64     com65     com66     com67     com68     com69     com70
>>> com71     com72
>>> 0.7189990 0.7043998 0.7768710 0.7264939 0.8140790 0.7532290 0.7309884
>>> 0.9190267 0.8540992
>>>     com73     com74     com75     com76     com77     com78     com79
>>> com80     com81
>>> 0.7531779 0.8520790 0.7649957 0.7319195 0.7578687 0.7915857 0.7600834
>>> 0.7303097 0.7693079
>>>     com82
>>> 0.7487281
>>>
>>> $FDis
>>>       com1       com2       com3       com4       com5       com6
>>> com7       com8
>>> 0.19178600 0.15352983 0.23419296 0.20315128 0.18604639 0.14348855
>>> 0.28989249 0.25752544
>>>       com9      com10      com11      com12      com13      com14
>>>  com15      com16
>>> 0.26174957 0.15962395 0.17907612 0.19642851 0.12827329 0.20114316
>>> 0.18128942 0.25731184
>>>      com17      com18      com19      com20      com21      com22
>>>  com23      com24
>>> 0.25855225 0.19576353 0.26366092 0.27728602 0.29546846 0.20720052
>>> 0.27212077 0.30880887
>>>      com25      com26      com27      com28      com29      com30
>>>  com31      com32
>>> 0.29440458 0.25396646 0.25647806 0.23422171 0.25464177 0.24311894
>>> 0.16182038 0.09958014
>>>      com33      com34      com35      com36      com37      com38
>>>  com39      com40
>>> 0.13095167 0.12983413 0.24224903 0.18239337 0.19817113 0.26320996
>>> 0.11766508 0.30940641
>>>      com41      com42      com43      com44      com45      com46
>>>  com47      com48
>>> 0.23583814 0.30624876 0.27750572 0.16747032 0.21445188 0.24327116
>>> 0.20589103 0.27339261
>>>      com49      com50      com51      com52      com53      com54
>>>  com55      com56
>>> 0.23614656 0.23678552 0.25641929 0.26260242 0.22516659 0.25243952
>>> 0.23674896 0.18732040
>>>      com57      com58      com59      com60      com61      com62
>>>  com63      com64
>>> 0.27202483 0.22947018 0.31342777 0.17997456 0.18461335 0.32429534
>>> 0.14840674 0.13731830
>>>      com65      com66      com67      com68      com69      com70
>>>  com71      com72
>>> 0.20437128 0.23298402 0.14830718 0.27194825 0.09289396 0.23196338
>>> 0.17920946 0.25265696
>>>      com73      com74      com75      com76      com77      com78
>>>  com79      com80
>>> 0.23525249 0.22171523 0.21972879 0.23523622 0.25336830 0.22477734
>>> 0.20430806 0.20674064
>>>      com81      com82
>>> 0.14270928 0.22673005
>>>
>>> $RaoQ
>>>       com1       com2       com3       com4       com5       com6
>>> com7       com8
>>> 0.05331536 0.03630438 0.07372825 0.06071274 0.05671961 0.05128404
>>> 0.10541586 0.08965742
>>>       com9      com10      com11      com12      com13      com14
>>>  com15      com16
>>> 0.09102682 0.04333067 0.04941515 0.05495308 0.03115535 0.06048519
>>> 0.06070379 0.08680368
>>>      com17      com18      com19      com20      com21      com22
>>>  com23      com24
>>> 0.07256118 0.05321952 0.08855815 0.10718949 0.10760039 0.07391960
>>> 0.09163325 0.11476244
>>>      com25      com26      com27      com28      com29      com30
>>>  com31      com32
>>> 0.10458183 0.08833300 0.07746703 0.07975863 0.08699710 0.07029682
>>> 0.04116800 0.02091466
>>>      com33      com34      com35      com36      com37      com38
>>>  com39      com40
>>> 0.03452371 0.03102533 0.07072961 0.04601163 0.05125527 0.08872861
>>> 0.03608639 0.11227991
>>>      com41      com42      com43      com44      com45      com46
>>>  com47      com48
>>> 0.07155343 0.10655043 0.09463142 0.04483107 0.05149290 0.06818611
>>> 0.05776898 0.08787335
>>>      com49      com50      com51      com52      com53      com54
>>>  com55      com56
>>> 0.06689262 0.06673575 0.07673498 0.08209786 0.06165892 0.07169030
>>> 0.07207671 0.05351944
>>>      com57      com58      com59      com60      com61      com62
>>>  com63      com64
>>> 0.10496706 0.07830439 0.11178032 0.05616672 0.04961674 0.11105321
>>> 0.03840657 0.03693797
>>>      com65      com66      com67      com68      com69      com70
>>>  com71      com72
>>> 0.05718178 0.07088485 0.03711119 0.08826702 0.02446860 0.08202483
>>> 0.05274964 0.07232899
>>>      com73      com74      com75      com76      com77      com78
>>>  com79      com80
>>> 0.06245748 0.05668243 0.06019524 0.07375344 0.07743079 0.06009721
>>> 0.05757830 0.05642231
>>>      com81      com82
>>> 0.03665132 0.06852237
>>>
>>> $CWM
>>>         trait1                        trait2   trait3              trait4
>>>         trait5
>>> com1  Demersal Marine, brackish, freshwater  3.361717 Invertebrate Feeder
>>>        Browser
>>> com2  Demersal Marine, brackish, freshwater  3.391770 Invertebrate Feeder
>>>        Browser
>>> com3  Demersal Marine, brackish, freshwater  3.389626 Invertebrate Feeder
>>>        Browser
>>> com4  Demersal Marine, brackish, freshwater  3.437043 Invertebrate Feeder
>>>        Browser
>>> com5  Demersal Marine, brackish, freshwater  3.450760 Invertebrate Feeder
>>>        Browser
>>> com6  Demersal Marine, brackish, freshwater  3.354952 Invertebrate Feeder
>>>        Browser
>>> com7  Demersal Marine, brackish, freshwater  3.389917 Invertebrate Feeder
>>>        Browser
>>> com8  Demersal Marine, brackish, freshwater  3.382973 Invertebrate Feeder
>>>        Browser
>>> com9  Demersal Marine, brackish, freshwater  3.371722 Invertebrate Feeder
>>>        Browser
>>> com10 Demersal Marine, brackish, freshwater  3.371057 Invertebrate Feeder
>>>        Browser
>>> com11 Demersal Marine, brackish, freshwater  3.389740 Invertebrate Feeder
>>>        Browser
>>> com12 Demersal Marine, brackish, freshwater  3.416626 Invertebrate Feeder
>>>        Browser
>>> com13 Demersal Marine, brackish, freshwater  3.348563 Invertebrate Feeder
>>>        Browser
>>> com14 Demersal Marine, brackish, freshwater  3.310051 Invertebrate Feeder
>>>        Browser
>>> com15 Demersal Marine, brackish, freshwater  3.274433 Invertebrate Feeder
>>>        Browser
>>> com16 Demersal Marine, brackish, freshwater  3.366033 Invertebrate Feeder
>>>        Browser
>>> com17  Pelagic Marine, brackish, freshwater  3.284144 Invertebrate Feeder
>>> Browser/Hunter
>>> com18 Demersal Marine, brackish, freshwater  3.352978 Invertebrate Feeder
>>>        Browser
>>> com19 Demersal Marine, brackish, freshwater  3.313528 Invertebrate Feeder
>>>        Browser
>>> com20 Demersal Marine, brackish, freshwater  3.368486 Invertebrate Feeder
>>>        Browser
>>> com21 Demersal Marine, brackish, freshwater  3.346555 Invertebrate Feeder
>>>        Browser
>>> com22 Demersal Marine, brackish, freshwater  3.348779 Invertebrate Feeder
>>>        Browser
>>> com23 Demersal Marine, brackish, freshwater  3.316949 Invertebrate Feeder
>>>        Browser
>>> com24 Demersal Marine, brackish, freshwater  3.332521 Invertebrate Feeder
>>>        Browser
>>> com25 Demersal Marine, brackish, freshwater  3.398814 Invertebrate Feeder
>>>        Browser
>>> com26 Demersal Marine, brackish, freshwater  3.281393 Invertebrate Feeder
>>>        Browser
>>> com27 Demersal Marine, brackish, freshwater  3.325194 Invertebrate Feeder
>>>        Browser
>>> com28 Demersal Marine, brackish, freshwater  3.356956 Invertebrate Feeder
>>>        Browser
>>> com29 Demersal Marine, brackish, freshwater  3.282245 Invertebrate Feeder
>>>        Browser
>>> com30 Demersal Marine, brackish, freshwater  3.263298 Invertebrate Feeder
>>>        Browser
>>> com31 Demersal Marine, brackish, freshwater  3.304036 Invertebrate Feeder
>>>        Browser
>>> com32 Demersal              Marine, brackish 3.230522 Invertebrate Feeder
>>>        Browser
>>> com33 Demersal Marine, brackish, freshwater  3.347002 Invertebrate Feeder
>>>        Browser
>>> com34 Demersal Marine, brackish, freshwater  3.430373 Invertebrate Feeder
>>>        Browser
>>> com35 Demersal Marine, brackish, freshwater  3.318061 Invertebrate Feeder
>>>        Browser
>>> com36 Demersal Marine, brackish, freshwater  3.334512 Invertebrate Feeder
>>>        Browser
>>> com37 Demersal Marine, brackish, freshwater  3.354938 Invertebrate Feeder
>>>        Browser
>>> com38 Demersal Marine, brackish, freshwater  3.282320 Invertebrate Feeder
>>>        Browser
>>> com39 Demersal Marine, brackish, freshwater  3.307719 Invertebrate Feeder
>>>        Browser
>>> com40 Demersal              Marine, brackish 3.343822 Invertebrate Feeder
>>>        Browser
>>> com41 Demersal Marine, brackish, freshwater  3.347152 Invertebrate Feeder
>>>        Browser
>>> com42 Demersal Marine, brackish, freshwater  3.389799 Invertebrate Feeder
>>>        Browser
>>> com43 Demersal Marine, brackish, freshwater  3.400693 Invertebrate Feeder
>>>        Browser
>>> com44 Demersal Marine, brackish, freshwater  3.421323 Invertebrate Feeder
>>>        Browser
>>> com45 Demersal Marine, brackish, freshwater  3.329006 Invertebrate Feeder
>>>        Browser
>>> com46 Demersal Marine, brackish, freshwater  3.316793 Invertebrate Feeder
>>>        Browser
>>> com47  Benthic Marine, brackish, freshwater  3.309663 Invertebrate Feeder
>>>        Browser
>>> com48 Demersal Marine, brackish, freshwater  3.372207 Invertebrate Feeder
>>>        Browser
>>> com49  Benthic Marine, brackish, freshwater  3.332736 Invertebrate Feeder
>>>        Browser
>>> com50  Benthic Marine, brackish, freshwater  3.311616 Invertebrate Feeder
>>>        Browser
>>> com51 Demersal Marine, brackish, freshwater  3.319775 Invertebrate Feeder
>>>        Browser
>>> com52 Demersal Marine, brackish, freshwater  3.277058 Invertebrate Feeder
>>>        Browser
>>> com53 Demersal Marine, brackish, freshwater  3.354429 Invertebrate Feeder
>>>        Browser
>>> com54 Demersal Marine, brackish, freshwater  3.339532 Invertebrate Feeder
>>>        Browser
>>> com55 Demersal Marine, brackish, freshwater  3.357153 Invertebrate Feeder
>>>        Browser
>>> com56  Benthic Marine, brackish, freshwater  3.279952 Invertebrate Feeder
>>>        Browser
>>> com57  Benthic              Marine, brackish 3.126602 Invertebrate Feeder
>>>        Browser
>>> com58  Benthic              Marine, brackish 3.217454 Invertebrate Feeder
>>>        Browser
>>> com59 Demersal              Marine, brackish 3.307770 Invertebrate Feeder
>>>        Browser
>>> com60 Demersal              Marine, brackish 3.252970 Invertebrate Feeder
>>>        Browser
>>> com61 Demersal Marine, brackish, freshwater  3.404601 Invertebrate Feeder
>>>        Browser
>>> com62  Pelagic Marine, brackish, freshwater  2.806229 Invertebrate Feeder
>>>        Browser
>>> com63 Demersal Marine, brackish, freshwater  3.287427 Invertebrate Feeder
>>>        Browser
>>> com64 Demersal Marine, brackish, freshwater  3.292238 Invertebrate Feeder
>>>        Browser
>>> com65 Demersal              Marine, brackish 3.265497 Invertebrate Feeder
>>>        Browser
>>> com66 Demersal Marine, brackish, freshwater  3.317879 Invertebrate Feeder
>>>        Browser
>>> com67 Demersal              Marine, brackish 3.258586 Invertebrate Feeder
>>>        Browser
>>> com68 Demersal Marine, brackish, freshwater  3.203772 Invertebrate Feeder
>>>        Browser
>>> com69 Demersal Marine, brackish, freshwater  3.289830 Invertebrate Feeder
>>>        Browser
>>> com70 Demersal              Marine, brackish 3.326195 Invertebrate Feeder
>>>        Browser
>>> com71  Benthic Marine, brackish, freshwater  3.325590 Invertebrate Feeder
>>>        Browser
>>> com72  Benthic Marine, brackish, freshwater  3.297994 Invertebrate Feeder
>>>        Browser
>>> com73 Demersal Marine, brackish, freshwater  3.331968 Invertebrate Feeder
>>>        Browser
>>> com74 Demersal Marine, brackish, freshwater  3.395514 Invertebrate Feeder
>>>        Browser
>>> com75 Demersal Marine, brackish, freshwater  3.323936 Invertebrate Feeder
>>>        Browser
>>> com76 Demersal Marine, brackish, freshwater  3.201015 Invertebrate Feeder
>>>        Browser
>>> com77 Demersal Marine, brackish, freshwater  3.280311 Invertebrate Feeder
>>>        Browser
>>> com78 Demersal Marine, brackish, freshwater  3.318771 Invertebrate Feeder
>>>        Browser
>>> com79 Demersal Marine, brackish, freshwater  3.318253 Invertebrate Feeder
>>>        Browser
>>> com80 Demersal Marine, brackish, freshwater  3.374939 Invertebrate Feeder
>>>        Browser
>>> com81 Demersal Marine, brackish, freshwater  3.440927 Invertebrate Feeder
>>>        Browser
>>> com82 Demersal Marine, brackish, freshwater  3.381153 Invertebrate Feeder
>>>        Browser
>>>          trait6
>>> com1  0.5 - 1.0
>>> com2  1.0 - 2.0
>>> com3  1.0 - 2.0
>>> com4  1.0 - 2.0
>>> com5  1.0 - 2.0
>>> com6  1.0 - 2.0
>>> com7  1.0 - 2.0
>>> com8  1.0 - 2.0
>>> com9  0.5 - 1.0
>>> com10 1.0 - 2.0
>>> com11 1.0 - 2.0
>>> com12 1.0 - 2.0
>>> com13 0.5 - 1.0
>>> com14 0.5 - 1.0
>>> com15 0.5 - 1.0
>>> com16 0.5 - 1.0
>>> com17 1.0 - 2.0
>>> com18 0.5 - 1.0
>>> com19 0.5 - 1.0
>>> com20 0.5 - 1.0
>>> com21 0.5 - 1.0
>>> com22 0.5 - 1.0
>>> com23 1.0 - 2.0
>>> com24 1.0 - 2.0
>>> com25 1.0 - 2.0
>>> com26 1.0 - 2.0
>>> com27 1.0 - 2.0
>>> com28 0.5 - 1.0
>>> com29 0.5 - 1.0
>>> com30 0.5 - 1.0
>>> com31 0.5 - 1.0
>>> com32 0.5 - 1.0
>>> com33 0.5 - 1.0
>>> com34 1.0 - 2.0
>>> com35 0.5 - 1.0
>>> com36 0.5 - 1.0
>>> com37 1.0 - 2.0
>>> com38 0.5 - 1.0
>>> com39 0.5 - 1.0
>>> com40 0.5 - 1.0
>>> com41 0.5 - 1.0
>>> com42 1.0 - 2.0
>>> com43 1.0 - 2.0
>>> com44 1.0 - 2.0
>>> com45     < 0.5
>>> com46     < 0.5
>>> com47     < 0.5
>>> com48     < 0.5
>>> com49     < 0.5
>>> com50     < 0.5
>>> com51     < 0.5
>>> com52 0.5 - 1.0
>>> com53 0.5 - 1.0
>>> com54     < 0.5
>>> com55     < 0.5
>>> com56     < 0.5
>>> com57     < 0.5
>>> com58     < 0.5
>>> com59 0.5 - 1.0
>>> com60 0.5 - 1.0
>>> com61 1.0 - 2.0
>>> com62 1.0 - 2.0
>>> com63 0.5 - 1.0
>>> com64 0.5 - 1.0
>>> com65 0.5 - 1.0
>>> com66 0.5 - 1.0
>>> com67 0.5 - 1.0
>>> com68 0.5 - 1.0
>>> com69 0.5 - 1.0
>>> com70 0.5 - 1.0
>>> com71     < 0.5
>>> com72     < 0.5
>>> com73     < 0.5
>>> com74 1.0 - 2.0
>>> com75 0.5 - 1.0
>>> com76 0.5 - 1.0
>>> com77 1.0 - 2.0
>>> com78 0.5 - 1.0
>>> com79 0.5 - 1.0
>>> com80 1.0 - 2.0
>>> com81 1.0 - 2.0
>>> com82 1.0 - 2.0
>>>
>>> 2016-02-22 13:58 GMT+00:00 stephen sefick <ssefick at gmail.com>:
>>>
>>>> If memory serves me, dbFD returns a lot of output. What do you want to
>>>> plot? Also, please provide reproducible examples, so that we can help you
>>>> solve your R related queries.
>>>> kindest regards,
>>>>
>>>> Stephen
>>>>
>>>> On Mon, Feb 22, 2016 at 7:00 AM, Fabio Monteiro <
>>>> fabio.monteiro1992 at gmail.com> wrote:
>>>>
>>>>> Hi
>>>>>
>>>>> thank you for your quick answer
>>>>>
>>>>> I finally managed to insert everything correctly and dbFD is caltulated.
>>>>>
>>>>> I'm now trying to plot the results.
>>>>>
>>>>> My objects are matrices.
>>>>>
>>>>> x is a functional trait and species matrice. a is the species and
>>>>> samples
>>>>>
>>>>> Thank you
>>>>>
>>>>> 2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>>>>
>>>>> > Hi
>>>>> >
>>>>> > comments inline
>>>>> >
>>>>> > > -----Original Message-----
>>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>> Fabio
>>>>> > > Monteiro
>>>>> > > Sent: Monday, February 22, 2016 11:51 AM
>>>>> > > To: r-help at r-project.org
>>>>> > > Subject: [R] FD package
>>>>> > >
>>>>> > > Hi.
>>>>> > >
>>>>> > > First i would like to say that i'm really new in R. I recently
>>>>> started
>>>>> > > working with R and i'm using the FD package.
>>>>> > >
>>>>> > > I'm having some errors that doesn't make any sense.
>>>>> > >
>>>>> > > I have 2 matrix, one is the species with functional traits and the
>>>>> > > second one is the species and abundances.
>>>>> >
>>>>> > Your objects are matrices or data frames? From docs dbFD expects
>>>>> various
>>>>> > inputs byt they have to be properly formatted.
>>>>> >
>>>>> > >
>>>>> > > When I try to run the dbFD to calculate the functional diversity,
>>>>> the
>>>>> > > error is the number of species is different in x and a.
>>>>> > >
>>>>> > > I checked a lot of times and the number of species is the same and
>>>>> > > there are no mistakes in their names like spaces or caps.
>>>>> >
>>>>> > How did you checked?
>>>>> >
>>>>> > dim(trait) and  dim(abund)
>>>>> >
>>>>> > shall give you the same number of rows in traits as columns in abund.
>>>>> >
>>>>> > If trait is vector, you need to use length instead of dim.
>>>>> >
>>>>> > >
>>>>> > > Can you help me?
>>>>> >
>>>>> > Without better description of your objects and code you used you
>>>>> hardly
>>>>> > get any answer. You can start by using examples from help page, which
>>>>> shall
>>>>> > work and see how your data differ from those examples.
>>>>> >
>>>>> > Cheers
>>>>> > Petr
>>>>> >
>>>>> >
>>>>> > >
>>>>> > > F?bio Monteiro
>>>>> > >
>>>>> > >       [[alternative HTML version deleted]]
>>>>> > >
>>>>> > > ______________________________________________
>>>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>>>>> > > guide.html
>>>>> > > and provide commented, minimal, self-contained, reproducible code.
>>>>> >
>>>>> > ________________________________
>>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>>> jsou
>>>>> > ur?eny pouze jeho adres?t?m.
>>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>>>> kopie
>>>>> > vyma?te ze sv?ho syst?mu.
>>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>>>> email
>>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>>> modifikacemi
>>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>>> >
>>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>>> p?ijmout;
>>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>>>>> > p??jemce s dodatkem ?i odchylkou.
>>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>>> zmocn?n
>>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>>>> tohoto
>>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>>> jejich
>>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>> >
>>>>> > This e-mail and any documents attached to it may be confidential and
>>>>> are
>>>>> > intended only for its intended recipients.
>>>>> > If you received this e-mail by mistake, please immediately inform its
>>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>>> its
>>>>> > copies from your system.
>>>>> > If you are not the intended recipient of this e-mail, you are not
>>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>>> manner.
>>>>> > The sender of this e-mail shall not be liable for any possible damage
>>>>> > caused by modifications of the e-mail or by delay with transfer of the
>>>>> > email.
>>>>> >
>>>>> > In case that this e-mail forms part of business dealings:
>>>>> > - the sender reserves the right to end negotiations about entering
>>>>> into a
>>>>> > contract in any time, for any reason, and without stating any
>>>>> reasoning.
>>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>>> excludes
>>>>> > any acceptance of the offer on the part of the recipient containing
>>>>> any
>>>>> > amendment or variation.
>>>>> > - the sender insists on that the respective contract is concluded only
>>>>> > upon an express mutual agreement on all its aspects.
>>>>> > - the sender of this e-mail informs that he/she is not authorized to
>>>>> enter
>>>>> > into any contracts on behalf of the company except for cases in which
>>>>> > he/she is expressly authorized to do so in writing, and such
>>>>> authorization
>>>>> > or power of attorney is submitted to the recipient or the person
>>>>> > represented by the recipient, or the existence of such authorization
>>>>> is
>>>>> > known to the recipient of the person represented by the recipient.
>>>>> >
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Stephen Sefick
>>>> **************************************************
>>>> Auburn University
>>>> Biological Sciences
>>>> 331 Funchess Hall
>>>> Auburn, Alabama
>>>> 36849
>>>> **************************************************
>>>> sas0025 at auburn.edu
>>>> http://www.auburn.edu/~sas0025
>>>> **************************************************
>>>>
>>>> Let's not spend our time and resources thinking about things that are so
>>>> little or so large that all they really do for us is puff us up and make us
>>>> feel like gods.  We are mammals, and have not exhausted the annoying little
>>>> problems of being mammals.
>>>>
>>>>                                 -K. Mullis
>>>>
>>>> "A big computer, a complex algorithm and a long time does not equal
>>>> science."
>>>>
>>>>                               -Robert Gentleman
>>>>
>>>>
>>>
>>
>>
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>>
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>>
>>                                 -K. Mullis
>>
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>>
>>                               -Robert Gentleman
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From santosh2005 at gmail.com  Mon Feb 22 20:56:55 2016
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 22 Feb 2016 11:56:55 -0800
Subject: [R] ReporteRs R package installation issues in R.3.2.3 (Windows)
In-Reply-To: <56CACA90.7010609@statistik.tu-dortmund.de>
References: <CAN_e6XuPLqz_rMHyqQ4LWWzOzH+u+TiqbeL7AQCZuuSW+rLwnA@mail.gmail.com>
	<56CACA90.7010609@statistik.tu-dortmund.de>
Message-ID: <CAN_e6XsMzMf1n4t9UUPQihxbTBELrQoCjqzoKz=aFtwGeGaUqw@mail.gmail.com>

Thanks so much for your response.. Would try that!
Santosh

On Mon, Feb 22, 2016 at 12:45 AM, Uwe Ligges <
ligges at statistik.tu-dortmund.de> wrote:

> I guess you are using a 64 bit version of R for Windows but you have only
> a 32-bit installation of Java. Please install a 64-bit Java.
>
> Best,
> Uwe Ligges
>
>
>
> On 22.02.2016 09:35, Santosh wrote:
>
>> Dear Rxperts..
>>
>> I tried to install ReporteRs package..in R.3.2.3 (Windows)
>> Below are the error messages...
>>
>> install.packages("ReporteRs",dep=T)
>>>
>> trying URL '
>> http://cran.cnr.berkeley.edu/bin/windows/contrib/3.2/ReporteRs_0.8.2.zip'
>> Content type 'application/zip' length 947836 bytes (925 KB)
>> downloaded 925 KB
>>
>> package ?ReporteRs? successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>
>>  C:\Users\santosh\AppData\Local\Temp\RtmpMlGfvG\downloaded_packages
>>
>> library(ReporteRs)
>>>
>> Loading required package: ReporteRsjars
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>    call: fun(libname, pkgname)
>>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
>> re-installing Java and make sure R and Java have matching architectures.
>> Error: package ?ReporteRsjars? could not be loaded
>>
>> I tried to install ReporteRsJars..
>>
>>> install.packages("ReporteRsjars")
>>>
>> trying URL '
>>
>> http://cran.cnr.berkeley.edu/bin/windows/contrib/3.2/ReporteRsjars_0.0.2.zip
>> '
>> Content type 'application/zip' length 5502826 bytes (5.2 MB)
>> downloaded 5.2 MB
>>
>> package ?ReporteRsjars? successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>          C:\Users\santoshAppData\Local\Temp\RtmpMlGfvG\downloaded_packages
>>
>>>
>>> library(ReporteRsjars)
>>>
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>    call: fun(libname, pkgname)
>>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
>> re-installing Java and make sure R and Java have matching architectures.
>> Error: package or namespace load failed for ?ReporteRsjars?
>>
>>>
>>>
>> rJava and and ReporteRsjars were having issues with loading even though
>> there were shown as successfully installed.
>>
>> Would appreciate your help/solution/ideas in this regard..
>>
>> Thanks much,
>> Santosh
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Mon Feb 22 21:17:48 2016
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 22 Feb 2016 12:17:48 -0800
Subject: [R] Tables, knitr markdown
Message-ID: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>

Dear Rxperts..
I am able to generate tables using Tables R package..
However, when I have been unsuccessful in using kable (from knitr package)
to generate the table in R markdown script..

It's because the output generated by "tabular" in Tables package is of
class "tabular". The kable function in knitr package accepts data.frame.

Is there a way to convert the tabular class objects into data.frame
 objects?

Or is there a way that kable can accept "tabular" class object?


Thanks so much..
Santosh

	[[alternative HTML version deleted]]


From amoy_y at yahoo.com  Mon Feb 22 21:38:25 2016
From: amoy_y at yahoo.com (Amoy Yang)
Date: Mon, 22 Feb 2016 20:38:25 +0000 (UTC)
Subject: [R] lm-step: use train-data model to validate test-data
References: <2079994422.977084.1456173505419.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2079994422.977084.1456173505419.JavaMail.yahoo@mail.yahoo.com>

 I have model-data named as: model that is split as model.T(train) and model.V(test or validation). The least square model (from lm to step) is built withmodel.T and I like to see how model.T is robust by comparing predicted model.V toactual model.V. How do I get score for model.V based on model built on model.T? The code highlighted below does not get what I expected.Please advise! Thanks!
? # score the model 
? score.T <- data.frame(predict(step, model.T))? # get predicted score for train data
? score.V <- data.frame(predict(step, model.V))? # for test data but seems incorrect
? # get the actual values 
? actual.T <- data.frame(model.T$sales) 
? actual.V <- data.frame(model.V$sales) ? # comparison for model.T
? comp.T=cbind(actual.T,round(score.T,digit=2))
? plot(comp.T)? # comparison for model.V (use Model.T to predict Model.V for true validation
? comp.V=cbind(actual.V,round(score.V,digit=2))
? plot(comp.V)
	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Mon Feb 22 21:46:00 2016
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 22 Feb 2016 12:46:00 -0800
Subject: [R] Tables, knitr markdown
In-Reply-To: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
Message-ID: <CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>

Just figured out..

as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)

could work! :)


On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com> wrote:

> Dear Rxperts..
> I am able to generate tables using Tables R package..
> However, when I have been unsuccessful in using kable (from knitr package)
> to generate the table in R markdown script..
>
> It's because the output generated by "tabular" in Tables package is of
> class "tabular". The kable function in knitr package accepts data.frame.
>
> Is there a way to convert the tabular class objects into data.frame
>  objects?
>
> Or is there a way that kable can accept "tabular" class object?
>
>
> Thanks so much..
> Santosh
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Feb 22 22:55:36 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Feb 2016 16:55:36 -0500
Subject: [R] Tables, knitr markdown
In-Reply-To: <CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
	<CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
Message-ID: <56CB83D8.7060208@gmail.com>

On 22/02/2016 3:46 PM, Santosh wrote:
> Just figured out..
>
> as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)
>
> could work! :)

Why do you want to produce Markdown output?  the tables package 
(lowercase t!) can produce output in either LaTeX or HTML.  Just tell 
knitr to leave the output alone, e.g. for PDF output

```{r results="asis"}
require(tables)
tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
latex(tab)
```

or for HTML output

```{r results="asis"}
require(tables)
tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
(Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
html(tab)
```


Duncan Murdoch

>
>
> On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com> wrote:
>
>> Dear Rxperts..
>> I am able to generate tables using Tables R package..
>> However, when I have been unsuccessful in using kable (from knitr package)
>> to generate the table in R markdown script..
>>
>> It's because the output generated by "tabular" in Tables package is of
>> class "tabular". The kable function in knitr package accepts data.frame.
>>
>> Is there a way to convert the tabular class objects into data.frame
>>   objects?
>>
>> Or is there a way that kable can accept "tabular" class object?
>>
>>
>> Thanks so much..
>> Santosh
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From santosh2005 at gmail.com  Tue Feb 23 00:19:33 2016
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 22 Feb 2016 15:19:33 -0800
Subject: [R] Tables, knitr markdown
In-Reply-To: <56CB83D8.7060208@gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
	<CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
	<56CB83D8.7060208@gmail.com>
Message-ID: <CAN_e6XtAcMR+ar-n38EFU5DjqZvXh_41veoA9neKZAqHA3sYoA@mail.gmail.com>

Sorry.. I forgot to mention that I wanted it be published in MS Word,
because it goes into a Report this is prepared using MS Word.

Hence,the above effort.. yes, it's a lot easier to send it to Latex..

I was also wondering if it is possible to add "\hline" separating the
categories in a table..

Using tabular, I get this:

\begin{tabular}{lcccc}
\hline
"Name"  & "Value1" & \multicolumn{1}{c}{"Value2"} \\
\hline
\nopagebreak A1  &   0.06 &   1.2 \\
\nopagebreak A5  &   0.62 &   8.9 \\
\nopagebreak A6  &   0.48 &   4.2 \\
\rule{0pt}{1.7\normalbaselineskip}A2  &   1.50 &   1.27 \\
\nopagebreak A7  &   0.11 &   4.3 \\
\nopagebreak A3  &   0.01 &   3.1 \\
\rule{0pt}{1.7\normalbaselineskip}A4  &   2.19 &   1.0 \\
\nopagebreak B1.  &  0.03 &   2.0 \\
\nopagebreak B2.  &  0.011 &  1.8 \\
\rule{0pt}{1.7\normalbaselineskip}B3  &  0.10 &  2.7 \\
\nopagebreak B4.  &  0.02 &   1.6 \\
\nopagebreak C1.  &  0.01 &   1.1 \\
\hline
\end{tabular}

But, I want in this way.. (with horizontal lines and customized text
inserted at the beginning of a group..

\begin{tabular}{lcccc}
\hline
"Name"  & "Value1" & \multicolumn{1}{c}{"Value2"} \\
\hline
\multicolumn{5}{l}{\textbf{Hardened}}\\
\hline
\nopagebreak A1  &   0.06 &   1.2 \\
\nopagebreak \tA5  &   0.62 &   8.9 \\
\nopagebreak \tA6  &   0.48 &   4.2 \\
\rule{0pt}{1.7\normalbaselineskip}A2  &   1.50 &   1.27 \\
\nopagebreak \tA7  &   0.11 &   4.3 \\
\nopagebreak \tA3  &   0.01 &   3.1 \\
\rule{0pt}{1.7\normalbaselineskip}A4  &   2.19 &   1.0 \\
\hline
\multicolumn{3}{l}{\textbf{Pulverized}}\\
\hline
\nopagebreak B1.  &  0.03 &   2.0 \\
\nopagebreak B2.  &  0.011 &  1.8 \\
\rule{0pt}{1.7\normalbaselineskip}B3  &  0.10 &  2.7 \\
\nopagebreak B4.  &  0.02 &   1.6 \\
\hline
\multicolumn{3}{l}{\textbf{Molten}}\\
\hline
\nopagebreak C1.  &  0.01 &   1.1 \\
\hline
\end{tabular}

Thanks so much for your help!
Santosh

On Mon, Feb 22, 2016 at 1:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 22/02/2016 3:46 PM, Santosh wrote:
>
>> Just figured out..
>>
>> as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)
>>
>> could work! :)
>>
>
> Why do you want to produce Markdown output?  the tables package (lowercase
> t!) can produce output in either LaTeX or HTML.  Just tell knitr to leave
> the output alone, e.g. for PDF output
>
> ```{r results="asis"}
> require(tables)
> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> latex(tab)
> ```
>
> or for HTML output
>
> ```{r results="asis"}
> require(tables)
> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
> (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> html(tab)
> ```
>
>
> Duncan Murdoch
>
>
>>
>> On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com> wrote:
>>
>> Dear Rxperts..
>>> I am able to generate tables using Tables R package..
>>> However, when I have been unsuccessful in using kable (from knitr
>>> package)
>>> to generate the table in R markdown script..
>>>
>>> It's because the output generated by "tabular" in Tables package is of
>>> class "tabular". The kable function in knitr package accepts data.frame.
>>>
>>> Is there a way to convert the tabular class objects into data.frame
>>>   objects?
>>>
>>> Or is there a way that kable can accept "tabular" class object?
>>>
>>>
>>> Thanks so much..
>>> Santosh
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From gergely at snowl.net  Tue Feb 23 00:27:46 2016
From: gergely at snowl.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Mon, 22 Feb 2016 15:27:46 -0800
Subject: [R] Tables, knitr markdown
In-Reply-To: <56CB83D8.7060208@gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
	<CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
	<56CB83D8.7060208@gmail.com>
Message-ID: <CAPvvxJUu1FtcBQ2Fzy50zn72-VObscZPo7Tk0+htwF2yMevMsw@mail.gmail.com>

On Mon, Feb 22, 2016 at 1:55 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> On 22/02/2016 3:46 PM, Santosh wrote:
>>
>> Just figured out..
>>
>> as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)
>>
>> could work! :)
>
>
> Why do you want to produce Markdown output?  the tables package (lowercase t!) can produce output in either LaTeX or HTML.  Just tell knitr to leave the output alone, e.g. for PDF output
>
> ```{r results="asis"}
> require(tables)
> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> latex(tab)
> ```
>
> or for HTML output
>
> ```{r results="asis"}
> require(tables)
> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
> (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> html(tab)
> ```


In case of you would rather generate markdown instead of HTML/LaTeX to
be independent from the resulting output document format, you can give
a try to the "pander" package, which can transform quite many R object
types into markdown, eg:

#> library(tables)
#> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
#+          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
#> pander::pander(tab)

------------------------------------------------------------
     \        \    Sepal.Length\    \    Sepal.Width\    \
  Species     n         mean        sd       mean        sd
------------ ---- ---------------- ---- --------------- ----
  *setosa*    50        5.01       0.35      3.43       0.38

*versicolor*  50        5.94       0.52      2.77       0.31

*virginica*   50        6.59       0.64      2.97       0.32

   *All*     150        5.84       0.83      3.06       0.44
------------------------------------------------------------

Please find more details at
http://rapporter.github.io/pander/#generic-pander-method, or the
knitr+pander vignette at
https://cran.rstudio.com/web/packages/pander/vignettes/knitr.html

Best,
Gergely


>
>
>
>
> Duncan Murdoch
>
>
>>
>>
>> On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com> wrote:
>>
>>> Dear Rxperts..
>>> I am able to generate tables using Tables R package..
>>> However, when I have been unsuccessful in using kable (from knitr package)
>>> to generate the table in R markdown script..
>>>
>>> It's because the output generated by "tabular" in Tables package is of
>>> class "tabular". The kable function in knitr package accepts data.frame.
>>>
>>> Is there a way to convert the tabular class objects into data.frame
>>>   objects?
>>>
>>> Or is there a way that kable can accept "tabular" class object?
>>>
>>>
>>> Thanks so much..
>>> Santosh
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From santosh2005 at gmail.com  Tue Feb 23 00:36:45 2016
From: santosh2005 at gmail.com (Santosh)
Date: Mon, 22 Feb 2016 15:36:45 -0800
Subject: [R] Tables, knitr markdown
In-Reply-To: <CAPvvxJUu1FtcBQ2Fzy50zn72-VObscZPo7Tk0+htwF2yMevMsw@mail.gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
	<CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
	<56CB83D8.7060208@gmail.com>
	<CAPvvxJUu1FtcBQ2Fzy50zn72-VObscZPo7Tk0+htwF2yMevMsw@mail.gmail.com>
Message-ID: <CAN_e6XsCvM+qke+iZALh3TZjrmDBgjmhj5Z_Fe-sfV-mDS5eeg@mail.gmail.com>

Thanks, Gergely.. I wonder if it allows to insert lines etc as sent in
previous email.... which might need some additional preprocessing..

Best,
Santosh

On Mon, Feb 22, 2016 at 3:27 PM, Gergely Dar?czi <gergely at snowl.net> wrote:

> On Mon, Feb 22, 2016 at 1:55 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> >
> > On 22/02/2016 3:46 PM, Santosh wrote:
> >>
> >> Just figured out..
> >>
> >> as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)
> >>
> >> could work! :)
> >
> >
> > Why do you want to produce Markdown output?  the tables package
> (lowercase t!) can produce output in either LaTeX or HTML.  Just tell knitr
> to leave the output alone, e.g. for PDF output
> >
> > ```{r results="asis"}
> > require(tables)
> > tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
> >          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> > latex(tab)
> > ```
> >
> > or for HTML output
> >
> > ```{r results="asis"}
> > require(tables)
> > tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
> > (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> > html(tab)
> > ```
>
>
> In case of you would rather generate markdown instead of HTML/LaTeX to
> be independent from the resulting output document format, you can give
> a try to the "pander" package, which can transform quite many R object
> types into markdown, eg:
>
> #> library(tables)
> #> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
> #+          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
> #> pander::pander(tab)
>
> ------------------------------------------------------------
>      \        \    Sepal.Length\    \    Sepal.Width\    \
>   Species     n         mean        sd       mean        sd
> ------------ ---- ---------------- ---- --------------- ----
>   *setosa*    50        5.01       0.35      3.43       0.38
>
> *versicolor*  50        5.94       0.52      2.77       0.31
>
> *virginica*   50        6.59       0.64      2.97       0.32
>
>    *All*     150        5.84       0.83      3.06       0.44
> ------------------------------------------------------------
>
> Please find more details at
> http://rapporter.github.io/pander/#generic-pander-method, or the
> knitr+pander vignette at
> https://cran.rstudio.com/web/packages/pander/vignettes/knitr.html
>
> Best,
> Gergely
>
>
> >
> >
> >
> >
> > Duncan Murdoch
> >
> >
> >>
> >>
> >> On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com>
> wrote:
> >>
> >>> Dear Rxperts..
> >>> I am able to generate tables using Tables R package..
> >>> However, when I have been unsuccessful in using kable (from knitr
> package)
> >>> to generate the table in R markdown script..
> >>>
> >>> It's because the output generated by "tabular" in Tables package is of
> >>> class "tabular". The kable function in knitr package accepts
> data.frame.
> >>>
> >>> Is there a way to convert the tabular class objects into data.frame
> >>>   objects?
> >>>
> >>> Or is there a way that kable can accept "tabular" class object?
> >>>
> >>>
> >>> Thanks so much..
> >>> Santosh
> >>>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gergely at snowl.net  Tue Feb 23 00:44:23 2016
From: gergely at snowl.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Mon, 22 Feb 2016 15:44:23 -0800
Subject: [R] Tables, knitr markdown
In-Reply-To: <CAN_e6XsCvM+qke+iZALh3TZjrmDBgjmhj5Z_Fe-sfV-mDS5eeg@mail.gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
	<CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
	<56CB83D8.7060208@gmail.com>
	<CAPvvxJUu1FtcBQ2Fzy50zn72-VObscZPo7Tk0+htwF2yMevMsw@mail.gmail.com>
	<CAN_e6XsCvM+qke+iZALh3TZjrmDBgjmhj5Z_Fe-sfV-mDS5eeg@mail.gmail.com>
Message-ID: <CAPvvxJUDJS1gRjJJKf4F=YRw1pE8rpBke15J5YkXJjpd5=1GSw@mail.gmail.com>

On Mon, Feb 22, 2016 at 3:36 PM, Santosh <santosh2005 at gmail.com> wrote:
> Thanks, Gergely.. I wonder if it allows to insert lines etc as sent in
> previous email.... which might need some additional preprocessing..

AFAIK that's not possible, as pandoc's markdown has no markup to add
horizontal/vertical lines in tables as per
http://pandoc.org/README.html#tables
But a possible workaround is to generate HTML and load that in Word/OpenOffice.

>
> Best,
> Santosh
>
>
> On Mon, Feb 22, 2016 at 3:27 PM, Gergely Dar?czi <gergely at snowl.net> wrote:
>>
>> On Mon, Feb 22, 2016 at 1:55 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>> >
>> > On 22/02/2016 3:46 PM, Santosh wrote:
>> >>
>> >> Just figured out..
>> >>
>> >> as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)
>> >>
>> >> could work! :)
>> >
>> >
>> > Why do you want to produce Markdown output?  the tables package
>> > (lowercase t!) can produce output in either LaTeX or HTML.  Just tell knitr
>> > to leave the output alone, e.g. for PDF output
>> >
>> > ```{r results="asis"}
>> > require(tables)
>> > tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>> >          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
>> > latex(tab)
>> > ```
>> >
>> > or for HTML output
>> >
>> > ```{r results="asis"}
>> > require(tables)
>> > tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>> > (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
>> > html(tab)
>> > ```
>>
>>
>> In case of you would rather generate markdown instead of HTML/LaTeX to
>> be independent from the resulting output document format, you can give
>> a try to the "pander" package, which can transform quite many R object
>> types into markdown, eg:
>>
>> #> library(tables)
>> #> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>> #+          (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
>> #> pander::pander(tab)
>>
>> ------------------------------------------------------------
>>      \        \    Sepal.Length\    \    Sepal.Width\    \
>>   Species     n         mean        sd       mean        sd
>> ------------ ---- ---------------- ---- --------------- ----
>>   *setosa*    50        5.01       0.35      3.43       0.38
>>
>> *versicolor*  50        5.94       0.52      2.77       0.31
>>
>> *virginica*   50        6.59       0.64      2.97       0.32
>>
>>    *All*     150        5.84       0.83      3.06       0.44
>> ------------------------------------------------------------
>>
>> Please find more details at
>> http://rapporter.github.io/pander/#generic-pander-method, or the
>> knitr+pander vignette at
>> https://cran.rstudio.com/web/packages/pander/vignettes/knitr.html
>>
>> Best,
>> Gergely
>>
>>
>> >
>> >
>> >
>> >
>> > Duncan Murdoch
>> >
>> >
>> >>
>> >>
>> >> On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com>
>> >> wrote:
>> >>
>> >>> Dear Rxperts..
>> >>> I am able to generate tables using Tables R package..
>> >>> However, when I have been unsuccessful in using kable (from knitr
>> >>> package)
>> >>> to generate the table in R markdown script..
>> >>>
>> >>> It's because the output generated by "tabular" in Tables package is of
>> >>> class "tabular". The kable function in knitr package accepts
>> >>> data.frame.
>> >>>
>> >>> Is there a way to convert the tabular class objects into data.frame
>> >>>   objects?
>> >>>
>> >>> Or is there a way that kable can accept "tabular" class object?
>> >>>
>> >>>
>> >>> Thanks so much..
>> >>> Santosh
>> >>>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From fabio.monteiro1992 at gmail.com  Mon Feb 22 21:39:36 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Mon, 22 Feb 2016 20:39:36 +0000
Subject: [R] FD package
In-Reply-To: <alpine.BSF.2.00.1602221147320.24699@pedal.dcn.davis.ca.us>
References: <CAG0T74rKkwRmmB4ZC7Vhu6j7HW+uRcBF-mpO1jVLyD8vT3XkNA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010673@SRVEXCHMBX.precheza.cz>
	<CAG0T74q6R+AZm-X85QvBLf415GUGrASz7LZ6B8oU96ceJAm8pQ@mail.gmail.com>
	<CADKEMqhuhyJK0KdSEOmSjFpCrCuAeTqpZ=Th2RZrzaZ7_etRag@mail.gmail.com>
	<CAG0T74qa6eST6cMiLhWoUiSmz3fTEgg-iEXGoKpheFQVvD33+w@mail.gmail.com>
	<CADKEMqhNCc0nH8kuJoUUfTsRjN0_p+4iuP2uJ0NRHMOpEL7wyQ@mail.gmail.com>
	<CAG0T74rQiZeMQJJT65zmCw+7m0ptip1xJZMr9ARZqK-Sn2ZzgA@mail.gmail.com>
	<alpine.BSF.2.00.1602221147320.24699@pedal.dcn.davis.ca.us>
Message-ID: <CAG0T74r9Md1vOHGG+QRS1CL6cxwH_E8KofLKv1k0By9bPonoEg@mail.gmail.com>

Im sorry for everything.

I didnt mean to make you loose your time, its just im really new at r and
i'm still trying to understand some things. plus my english is not great :/

I'm really sorry.

My problem is solved, thank you for your help.

Kind regards

F?bio Monteiro

2016-02-22 19:54 GMT+00:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> "data" is the name of a function in base R. It is not a good idea to use
> that as the name of an actual data object (to which the "$" operator is
> being applied here). It is not clear from what you have provided what
> variable names you are working with... you are not communicating yet using
> reproducible examples, so you are depending on our psychic powers to fill
> in the gaps, which is not likely to work reliably. I suspect that Stephen
> used the generic term "data" since he did not know what variable name you
> were actually using.
>
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
> On Mon, 22 Feb 2016, Fabio Monteiro wrote:
>
> hist(data$FRic)
>>>
>> Error in data$FRic : object of type 'closure' is not subsettable
>>
>> 2016-02-22 14:10 GMT+00:00 stephen sefick <ssefick at gmail.com>:
>>
>> Please see ?dput. What you provided is not a minimal, reproducible example
>>> (i.e., there is no R code).
>>>
>>> What kind of plot are you trying to plot? hist(data$FRic) will plot your
>>> data. I guess we need more information to be helpful.
>>>
>>>
>>> On Mon, Feb 22, 2016 at 8:03 AM, Fabio Monteiro <
>>> fabio.monteiro1992 at gmail.com> wrote:
>>>
>>> This is the output.
>>>>
>>>> I want to plot, for example FRic
>>>>
>>>> $nbsp
>>>>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
>>>> com13 com14 com15 com16
>>>>    17    21    18    12    15    20    16    12    18    15    18    16
>>>>  10    11    17    20
>>>> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
>>>> com29 com30 com31 com32
>>>>     9    13    11    10    11    15    12    16    18    18    11    19
>>>>  12    13    13    12
>>>> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
>>>> com45 com46 com47 com48
>>>>    15    11    15     8     7    12    10     9    12    15    13    13
>>>>  15    13    10    16
>>>> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
>>>> com61 com62 com63 com64
>>>>    14    12    14    13    14    13    15    13    11    12    16    13
>>>>   9     8    11    15
>>>> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
>>>> com77 com78 com79 com80
>>>>    13    18    13    15    10    11    12    11    14     8    10    12
>>>>  11    12    14    13
>>>> com81 com82
>>>>     9    12
>>>>
>>>> $sing.sp
>>>>  com1  com2  com3  com4  com5  com6  com7  com8  com9 com10 com11 com12
>>>> com13 com14 com15 com16
>>>>    17    21    18    12    15    20    16    12    18    15    18    16
>>>>  10    11    17    20
>>>> com17 com18 com19 com20 com21 com22 com23 com24 com25 com26 com27 com28
>>>> com29 com30 com31 com32
>>>>     9    13    11    10    11    15    12    16    18    18    11    19
>>>>  12    13    13    12
>>>> com33 com34 com35 com36 com37 com38 com39 com40 com41 com42 com43 com44
>>>> com45 com46 com47 com48
>>>>    14    11    15     8     7    12    10     9    12    15    13    13
>>>>  15    13    10    16
>>>> com49 com50 com51 com52 com53 com54 com55 com56 com57 com58 com59 com60
>>>> com61 com62 com63 com64
>>>>    14    12    13    13    14    13    15    13    11    12    16    13
>>>>   9     8    11    15
>>>> com65 com66 com67 com68 com69 com70 com71 com72 com73 com74 com75 com76
>>>> com77 com78 com79 com80
>>>>    13    17    13    15    10    11    12    11    14     8    10    12
>>>>  11    12    14    13
>>>> com81 com82
>>>>     9    12
>>>>
>>>> $FRic
>>>>         com1         com2         com3         com4         com5
>>>> com6         com7
>>>> 3.669752e-04 6.898164e-04 6.893918e-04 3.935451e-05 1.436140e-04
>>>> 1.012949e-03 2.934536e-04
>>>>         com8         com9        com10        com11        com12
>>>>  com13        com14
>>>> 1.001556e-04 6.425547e-04 1.740235e-04 5.561802e-04 2.964362e-04
>>>> 1.480860e-05 1.060512e-04
>>>>        com15        com16        com17        com18        com19
>>>>  com20        com21
>>>> 4.121157e-04 5.346433e-04 1.108007e-06 5.726895e-05 8.593435e-06
>>>> 1.452446e-05 1.855957e-05
>>>>        com22        com23        com24        com25        com26
>>>>  com27        com28
>>>> 2.128971e-04 8.438329e-05 3.216279e-04 2.529525e-04 4.980317e-04
>>>> 3.111325e-05 6.290088e-04
>>>>        com29        com30        com31        com32        com33
>>>>  com34        com35
>>>> 3.559802e-05 5.907167e-05 8.906878e-05 2.510168e-05 1.929088e-04
>>>> 1.234508e-04 2.784301e-04
>>>>        com36        com37        com38        com39        com40
>>>>  com41        com42
>>>> 1.480560e-08 1.411752e-06 5.576549e-05 2.445569e-05 6.167242e-06
>>>> 1.210002e-04 1.666034e-04
>>>>        com43        com44        com45        com46        com47
>>>>  com48        com49
>>>> 1.203484e-04 7.347513e-05 8.991003e-05 8.691148e-05 6.718789e-05
>>>> 1.357136e-04 1.821851e-04
>>>>        com50        com51        com52        com53        com54
>>>>  com55        com56
>>>> 4.832203e-05 8.391627e-05 2.173971e-04 1.355160e-04 1.304425e-04
>>>> 1.787888e-04 1.759204e-05
>>>>        com57        com58        com59        com60        com61
>>>>  com62        com63
>>>> 9.307474e-05 1.185857e-04 2.776166e-04 1.277143e-04 5.905299e-06
>>>> 9.606009e-08 1.019480e-04
>>>>        com64        com65        com66        com67        com68
>>>>  com69        com70
>>>> 2.395355e-04 2.307081e-04 4.019309e-04 6.874506e-05 1.417622e-04
>>>> 5.675463e-06 9.878848e-05
>>>>        com71        com72        com73        com74        com75
>>>>  com76        com77
>>>> 6.907251e-05 8.938528e-05 2.493585e-04 1.214151e-09 2.419942e-05
>>>> 1.183863e-04 7.457464e-05
>>>>        com78        com79        com80        com81        com82
>>>> 6.284563e-05 1.741100e-04 2.128749e-04 2.920847e-06 9.368270e-05
>>>>
>>>> $qual.FRic
>>>> [1] 0.7035642
>>>>
>>>> $FEve
>>>>      com1      com2      com3      com4      com5      com6      com7
>>>>  com8      com9
>>>> 0.2388515 0.3996566 0.3350494 0.2943431 0.3576785 0.3846561 0.4319967
>>>> 0.5857688 0.4271764
>>>>     com10     com11     com12     com13     com14     com15     com16
>>>> com17     com18
>>>> 0.3288544 0.4625139 0.4810921 0.3041395 0.5820621 0.6313595 0.5406627
>>>> 0.2707035 0.4530424
>>>>     com19     com20     com21     com22     com23     com24     com25
>>>> com26     com27
>>>> 0.3015171 0.5790744 0.7253301 0.5441404 0.4481694 0.6187607 0.5445650
>>>> 0.4955940 0.5116752
>>>>     com28     com29     com30     com31     com32     com33     com34
>>>> com35     com36
>>>> 0.5221560 0.5670513 0.4293040 0.4812907 0.4915317 0.3878949 0.4287726
>>>> 0.2893205 0.5835605
>>>>     com37     com38     com39     com40     com41     com42     com43
>>>> com44     com45
>>>> 0.7896749 0.5482274 0.4015703 0.5990018 0.5431955 0.6251919 0.6023954
>>>> 0.4962892 0.3749658
>>>>     com46     com47     com48     com49     com50     com51     com52
>>>> com53     com54
>>>> 0.4290664 0.4932756 0.5870607 0.3415984 0.3242199 0.4296702 0.4971491
>>>> 0.3272834 0.4865427
>>>>     com55     com56     com57     com58     com59     com60     com61
>>>> com62     com63
>>>> 0.3428716 0.4653631 0.5479140 0.5698272 0.4777804 0.4525375 0.5916255
>>>> 0.4652363 0.4111973
>>>>     com64     com65     com66     com67     com68     com69     com70
>>>> com71     com72
>>>> 0.3987632 0.3856989 0.3064660 0.4717288 0.3534531 0.4285679 0.6087836
>>>> 0.3607790 0.5494437
>>>>     com73     com74     com75     com76     com77     com78     com79
>>>> com80     com81
>>>> 0.4214327 0.4360703 0.3808632 0.2833824 0.2876808 0.3380949 0.3421757
>>>> 0.2249389 0.6562824
>>>>     com82
>>>> 0.6041267
>>>>
>>>> $FDiv
>>>>      com1      com2      com3      com4      com5      com6      com7
>>>>  com8      com9
>>>> 0.7423817 0.7458169 0.8679783 0.8226750 0.8373889 0.7877725 0.8070008
>>>> 0.7379254 0.8131881
>>>>     com10     com11     com12     com13     com14     com15     com16
>>>> com17     com18
>>>> 0.7050804 0.6976598 0.7512530 0.6806472 0.6994011 0.7276620 0.7870732
>>>> 0.8793599 0.7562019
>>>>     com19     com20     com21     com22     com23     com24     com25
>>>> com26     com27
>>>> 0.8983302 0.7681038 0.8163501 0.8198178 0.8489976 0.8922742 0.8442970
>>>> 0.8269863 0.7891795
>>>>     com28     com29     com30     com31     com32     com33     com34
>>>> com35     com36
>>>> 0.7569559 0.8674167 0.7436638 0.7317634 0.9541561 0.7466859 0.7087626
>>>> 0.8006321 0.8511148
>>>>     com37     com38     com39     com40     com41     com42     com43
>>>> com44     com45
>>>> 0.7729260 0.7509163 0.6905947 0.8466404 0.7677596 0.8791198 0.8211045
>>>> 0.7259760 0.7992553
>>>>     com46     com47     com48     com49     com50     com51     com52
>>>> com53     com54
>>>> 0.7573869 0.8788377 0.9036087 0.8287276 0.7762280 0.8064715 0.7775368
>>>> 0.7828276 0.8151245
>>>>     com55     com56     com57     com58     com59     com60     com61
>>>> com62     com63
>>>> 0.7503195 0.9213640 0.9141396 0.9150055 0.8348691 0.7271261 0.7875414
>>>> 0.8338675 0.7070272
>>>>     com64     com65     com66     com67     com68     com69     com70
>>>> com71     com72
>>>> 0.7189990 0.7043998 0.7768710 0.7264939 0.8140790 0.7532290 0.7309884
>>>> 0.9190267 0.8540992
>>>>     com73     com74     com75     com76     com77     com78     com79
>>>> com80     com81
>>>> 0.7531779 0.8520790 0.7649957 0.7319195 0.7578687 0.7915857 0.7600834
>>>> 0.7303097 0.7693079
>>>>     com82
>>>> 0.7487281
>>>>
>>>> $FDis
>>>>       com1       com2       com3       com4       com5       com6
>>>> com7       com8
>>>> 0.19178600 0.15352983 0.23419296 0.20315128 0.18604639 0.14348855
>>>> 0.28989249 0.25752544
>>>>       com9      com10      com11      com12      com13      com14
>>>>  com15      com16
>>>> 0.26174957 0.15962395 0.17907612 0.19642851 0.12827329 0.20114316
>>>> 0.18128942 0.25731184
>>>>      com17      com18      com19      com20      com21      com22
>>>>  com23      com24
>>>> 0.25855225 0.19576353 0.26366092 0.27728602 0.29546846 0.20720052
>>>> 0.27212077 0.30880887
>>>>      com25      com26      com27      com28      com29      com30
>>>>  com31      com32
>>>> 0.29440458 0.25396646 0.25647806 0.23422171 0.25464177 0.24311894
>>>> 0.16182038 0.09958014
>>>>      com33      com34      com35      com36      com37      com38
>>>>  com39      com40
>>>> 0.13095167 0.12983413 0.24224903 0.18239337 0.19817113 0.26320996
>>>> 0.11766508 0.30940641
>>>>      com41      com42      com43      com44      com45      com46
>>>>  com47      com48
>>>> 0.23583814 0.30624876 0.27750572 0.16747032 0.21445188 0.24327116
>>>> 0.20589103 0.27339261
>>>>      com49      com50      com51      com52      com53      com54
>>>>  com55      com56
>>>> 0.23614656 0.23678552 0.25641929 0.26260242 0.22516659 0.25243952
>>>> 0.23674896 0.18732040
>>>>      com57      com58      com59      com60      com61      com62
>>>>  com63      com64
>>>> 0.27202483 0.22947018 0.31342777 0.17997456 0.18461335 0.32429534
>>>> 0.14840674 0.13731830
>>>>      com65      com66      com67      com68      com69      com70
>>>>  com71      com72
>>>> 0.20437128 0.23298402 0.14830718 0.27194825 0.09289396 0.23196338
>>>> 0.17920946 0.25265696
>>>>      com73      com74      com75      com76      com77      com78
>>>>  com79      com80
>>>> 0.23525249 0.22171523 0.21972879 0.23523622 0.25336830 0.22477734
>>>> 0.20430806 0.20674064
>>>>      com81      com82
>>>> 0.14270928 0.22673005
>>>>
>>>> $RaoQ
>>>>       com1       com2       com3       com4       com5       com6
>>>> com7       com8
>>>> 0.05331536 0.03630438 0.07372825 0.06071274 0.05671961 0.05128404
>>>> 0.10541586 0.08965742
>>>>       com9      com10      com11      com12      com13      com14
>>>>  com15      com16
>>>> 0.09102682 0.04333067 0.04941515 0.05495308 0.03115535 0.06048519
>>>> 0.06070379 0.08680368
>>>>      com17      com18      com19      com20      com21      com22
>>>>  com23      com24
>>>> 0.07256118 0.05321952 0.08855815 0.10718949 0.10760039 0.07391960
>>>> 0.09163325 0.11476244
>>>>      com25      com26      com27      com28      com29      com30
>>>>  com31      com32
>>>> 0.10458183 0.08833300 0.07746703 0.07975863 0.08699710 0.07029682
>>>> 0.04116800 0.02091466
>>>>      com33      com34      com35      com36      com37      com38
>>>>  com39      com40
>>>> 0.03452371 0.03102533 0.07072961 0.04601163 0.05125527 0.08872861
>>>> 0.03608639 0.11227991
>>>>      com41      com42      com43      com44      com45      com46
>>>>  com47      com48
>>>> 0.07155343 0.10655043 0.09463142 0.04483107 0.05149290 0.06818611
>>>> 0.05776898 0.08787335
>>>>      com49      com50      com51      com52      com53      com54
>>>>  com55      com56
>>>> 0.06689262 0.06673575 0.07673498 0.08209786 0.06165892 0.07169030
>>>> 0.07207671 0.05351944
>>>>      com57      com58      com59      com60      com61      com62
>>>>  com63      com64
>>>> 0.10496706 0.07830439 0.11178032 0.05616672 0.04961674 0.11105321
>>>> 0.03840657 0.03693797
>>>>      com65      com66      com67      com68      com69      com70
>>>>  com71      com72
>>>> 0.05718178 0.07088485 0.03711119 0.08826702 0.02446860 0.08202483
>>>> 0.05274964 0.07232899
>>>>      com73      com74      com75      com76      com77      com78
>>>>  com79      com80
>>>> 0.06245748 0.05668243 0.06019524 0.07375344 0.07743079 0.06009721
>>>> 0.05757830 0.05642231
>>>>      com81      com82
>>>> 0.03665132 0.06852237
>>>>
>>>> $CWM
>>>>         trait1                        trait2   trait3
>>>> trait4
>>>>         trait5
>>>> com1  Demersal Marine, brackish, freshwater  3.361717 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com2  Demersal Marine, brackish, freshwater  3.391770 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com3  Demersal Marine, brackish, freshwater  3.389626 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com4  Demersal Marine, brackish, freshwater  3.437043 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com5  Demersal Marine, brackish, freshwater  3.450760 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com6  Demersal Marine, brackish, freshwater  3.354952 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com7  Demersal Marine, brackish, freshwater  3.389917 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com8  Demersal Marine, brackish, freshwater  3.382973 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com9  Demersal Marine, brackish, freshwater  3.371722 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com10 Demersal Marine, brackish, freshwater  3.371057 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com11 Demersal Marine, brackish, freshwater  3.389740 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com12 Demersal Marine, brackish, freshwater  3.416626 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com13 Demersal Marine, brackish, freshwater  3.348563 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com14 Demersal Marine, brackish, freshwater  3.310051 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com15 Demersal Marine, brackish, freshwater  3.274433 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com16 Demersal Marine, brackish, freshwater  3.366033 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com17  Pelagic Marine, brackish, freshwater  3.284144 Invertebrate
>>>> Feeder
>>>> Browser/Hunter
>>>> com18 Demersal Marine, brackish, freshwater  3.352978 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com19 Demersal Marine, brackish, freshwater  3.313528 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com20 Demersal Marine, brackish, freshwater  3.368486 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com21 Demersal Marine, brackish, freshwater  3.346555 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com22 Demersal Marine, brackish, freshwater  3.348779 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com23 Demersal Marine, brackish, freshwater  3.316949 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com24 Demersal Marine, brackish, freshwater  3.332521 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com25 Demersal Marine, brackish, freshwater  3.398814 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com26 Demersal Marine, brackish, freshwater  3.281393 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com27 Demersal Marine, brackish, freshwater  3.325194 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com28 Demersal Marine, brackish, freshwater  3.356956 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com29 Demersal Marine, brackish, freshwater  3.282245 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com30 Demersal Marine, brackish, freshwater  3.263298 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com31 Demersal Marine, brackish, freshwater  3.304036 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com32 Demersal              Marine, brackish 3.230522 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com33 Demersal Marine, brackish, freshwater  3.347002 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com34 Demersal Marine, brackish, freshwater  3.430373 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com35 Demersal Marine, brackish, freshwater  3.318061 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com36 Demersal Marine, brackish, freshwater  3.334512 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com37 Demersal Marine, brackish, freshwater  3.354938 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com38 Demersal Marine, brackish, freshwater  3.282320 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com39 Demersal Marine, brackish, freshwater  3.307719 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com40 Demersal              Marine, brackish 3.343822 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com41 Demersal Marine, brackish, freshwater  3.347152 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com42 Demersal Marine, brackish, freshwater  3.389799 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com43 Demersal Marine, brackish, freshwater  3.400693 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com44 Demersal Marine, brackish, freshwater  3.421323 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com45 Demersal Marine, brackish, freshwater  3.329006 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com46 Demersal Marine, brackish, freshwater  3.316793 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com47  Benthic Marine, brackish, freshwater  3.309663 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com48 Demersal Marine, brackish, freshwater  3.372207 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com49  Benthic Marine, brackish, freshwater  3.332736 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com50  Benthic Marine, brackish, freshwater  3.311616 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com51 Demersal Marine, brackish, freshwater  3.319775 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com52 Demersal Marine, brackish, freshwater  3.277058 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com53 Demersal Marine, brackish, freshwater  3.354429 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com54 Demersal Marine, brackish, freshwater  3.339532 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com55 Demersal Marine, brackish, freshwater  3.357153 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com56  Benthic Marine, brackish, freshwater  3.279952 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com57  Benthic              Marine, brackish 3.126602 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com58  Benthic              Marine, brackish 3.217454 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com59 Demersal              Marine, brackish 3.307770 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com60 Demersal              Marine, brackish 3.252970 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com61 Demersal Marine, brackish, freshwater  3.404601 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com62  Pelagic Marine, brackish, freshwater  2.806229 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com63 Demersal Marine, brackish, freshwater  3.287427 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com64 Demersal Marine, brackish, freshwater  3.292238 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com65 Demersal              Marine, brackish 3.265497 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com66 Demersal Marine, brackish, freshwater  3.317879 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com67 Demersal              Marine, brackish 3.258586 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com68 Demersal Marine, brackish, freshwater  3.203772 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com69 Demersal Marine, brackish, freshwater  3.289830 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com70 Demersal              Marine, brackish 3.326195 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com71  Benthic Marine, brackish, freshwater  3.325590 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com72  Benthic Marine, brackish, freshwater  3.297994 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com73 Demersal Marine, brackish, freshwater  3.331968 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com74 Demersal Marine, brackish, freshwater  3.395514 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com75 Demersal Marine, brackish, freshwater  3.323936 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com76 Demersal Marine, brackish, freshwater  3.201015 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com77 Demersal Marine, brackish, freshwater  3.280311 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com78 Demersal Marine, brackish, freshwater  3.318771 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com79 Demersal Marine, brackish, freshwater  3.318253 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com80 Demersal Marine, brackish, freshwater  3.374939 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com81 Demersal Marine, brackish, freshwater  3.440927 Invertebrate
>>>> Feeder
>>>>        Browser
>>>> com82 Demersal Marine, brackish, freshwater  3.381153 Invertebrate
>>>> Feeder
>>>>        Browser
>>>>          trait6
>>>> com1  0.5 - 1.0
>>>> com2  1.0 - 2.0
>>>> com3  1.0 - 2.0
>>>> com4  1.0 - 2.0
>>>> com5  1.0 - 2.0
>>>> com6  1.0 - 2.0
>>>> com7  1.0 - 2.0
>>>> com8  1.0 - 2.0
>>>> com9  0.5 - 1.0
>>>> com10 1.0 - 2.0
>>>> com11 1.0 - 2.0
>>>> com12 1.0 - 2.0
>>>> com13 0.5 - 1.0
>>>> com14 0.5 - 1.0
>>>> com15 0.5 - 1.0
>>>> com16 0.5 - 1.0
>>>> com17 1.0 - 2.0
>>>> com18 0.5 - 1.0
>>>> com19 0.5 - 1.0
>>>> com20 0.5 - 1.0
>>>> com21 0.5 - 1.0
>>>> com22 0.5 - 1.0
>>>> com23 1.0 - 2.0
>>>> com24 1.0 - 2.0
>>>> com25 1.0 - 2.0
>>>> com26 1.0 - 2.0
>>>> com27 1.0 - 2.0
>>>> com28 0.5 - 1.0
>>>> com29 0.5 - 1.0
>>>> com30 0.5 - 1.0
>>>> com31 0.5 - 1.0
>>>> com32 0.5 - 1.0
>>>> com33 0.5 - 1.0
>>>> com34 1.0 - 2.0
>>>> com35 0.5 - 1.0
>>>> com36 0.5 - 1.0
>>>> com37 1.0 - 2.0
>>>> com38 0.5 - 1.0
>>>> com39 0.5 - 1.0
>>>> com40 0.5 - 1.0
>>>> com41 0.5 - 1.0
>>>> com42 1.0 - 2.0
>>>> com43 1.0 - 2.0
>>>> com44 1.0 - 2.0
>>>> com45     < 0.5
>>>> com46     < 0.5
>>>> com47     < 0.5
>>>> com48     < 0.5
>>>> com49     < 0.5
>>>> com50     < 0.5
>>>> com51     < 0.5
>>>> com52 0.5 - 1.0
>>>> com53 0.5 - 1.0
>>>> com54     < 0.5
>>>> com55     < 0.5
>>>> com56     < 0.5
>>>> com57     < 0.5
>>>> com58     < 0.5
>>>> com59 0.5 - 1.0
>>>> com60 0.5 - 1.0
>>>> com61 1.0 - 2.0
>>>> com62 1.0 - 2.0
>>>> com63 0.5 - 1.0
>>>> com64 0.5 - 1.0
>>>> com65 0.5 - 1.0
>>>> com66 0.5 - 1.0
>>>> com67 0.5 - 1.0
>>>> com68 0.5 - 1.0
>>>> com69 0.5 - 1.0
>>>> com70 0.5 - 1.0
>>>> com71     < 0.5
>>>> com72     < 0.5
>>>> com73     < 0.5
>>>> com74 1.0 - 2.0
>>>> com75 0.5 - 1.0
>>>> com76 0.5 - 1.0
>>>> com77 1.0 - 2.0
>>>> com78 0.5 - 1.0
>>>> com79 0.5 - 1.0
>>>> com80 1.0 - 2.0
>>>> com81 1.0 - 2.0
>>>> com82 1.0 - 2.0
>>>>
>>>> 2016-02-22 13:58 GMT+00:00 stephen sefick <ssefick at gmail.com>:
>>>>
>>>> If memory serves me, dbFD returns a lot of output. What do you want to
>>>>> plot? Also, please provide reproducible examples, so that we can help
>>>>> you
>>>>> solve your R related queries.
>>>>> kindest regards,
>>>>>
>>>>> Stephen
>>>>>
>>>>> On Mon, Feb 22, 2016 at 7:00 AM, Fabio Monteiro <
>>>>> fabio.monteiro1992 at gmail.com> wrote:
>>>>>
>>>>> Hi
>>>>>>
>>>>>> thank you for your quick answer
>>>>>>
>>>>>> I finally managed to insert everything correctly and dbFD is
>>>>>> caltulated.
>>>>>>
>>>>>> I'm now trying to plot the results.
>>>>>>
>>>>>> My objects are matrices.
>>>>>>
>>>>>> x is a functional trait and species matrice. a is the species and
>>>>>> samples
>>>>>>
>>>>>> Thank you
>>>>>>
>>>>>> 2016-02-22 12:19 GMT+00:00 PIKAL Petr <petr.pikal at precheza.cz>:
>>>>>>
>>>>>> > Hi
>>>>>> >
>>>>>> > comments inline
>>>>>> >
>>>>>> > > -----Original Message-----
>>>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>>> Fabio
>>>>>> > > Monteiro
>>>>>> > > Sent: Monday, February 22, 2016 11:51 AM
>>>>>> > > To: r-help at r-project.org
>>>>>> > > Subject: [R] FD package
>>>>>> > >
>>>>>> > > Hi.
>>>>>> > >
>>>>>> > > First i would like to say that i'm really new in R. I recently
>>>>>> started
>>>>>> > > working with R and i'm using the FD package.
>>>>>> > >
>>>>>> > > I'm having some errors that doesn't make any sense.
>>>>>> > >
>>>>>> > > I have 2 matrix, one is the species with functional traits and the
>>>>>> > > second one is the species and abundances.
>>>>>> >
>>>>>> > Your objects are matrices or data frames? From docs dbFD expects
>>>>>> various
>>>>>> > inputs byt they have to be properly formatted.
>>>>>> >
>>>>>> > >
>>>>>> > > When I try to run the dbFD to calculate the functional diversity,
>>>>>> the
>>>>>> > > error is the number of species is different in x and a.
>>>>>> > >
>>>>>> > > I checked a lot of times and the number of species is the same and
>>>>>> > > there are no mistakes in their names like spaces or caps.
>>>>>> >
>>>>>> > How did you checked?
>>>>>> >
>>>>>> > dim(trait) and  dim(abund)
>>>>>> >
>>>>>> > shall give you the same number of rows in traits as columns in
>>>>>> abund.
>>>>>> >
>>>>>> > If trait is vector, you need to use length instead of dim.
>>>>>> >
>>>>>> > >
>>>>>> > > Can you help me?
>>>>>> >
>>>>>> > Without better description of your objects and code you used you
>>>>>> hardly
>>>>>> > get any answer. You can start by using examples from help page,
>>>>>> which
>>>>>> shall
>>>>>> > work and see how your data differ from those examples.
>>>>>> >
>>>>>> > Cheers
>>>>>> > Petr
>>>>>> >
>>>>>> >
>>>>>> > >
>>>>>> > > F?bio Monteiro
>>>>>> > >
>>>>>> > >       [[alternative HTML version deleted]]
>>>>>> > >
>>>>>> > > ______________________________________________
>>>>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> > > PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-
>>>>>> > > guide.html
>>>>>> > > and provide commented, minimal, self-contained, reproducible code.
>>>>>> >
>>>>>> > ________________________________
>>>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>>>> jsou
>>>>>> > ur?eny pouze jeho adres?t?m.
>>>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>>>>>> jeho
>>>>>> kopie
>>>>>> > vyma?te ze sv?ho syst?mu.
>>>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>>>>> email
>>>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>>>> modifikacemi
>>>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>>>> >
>>>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>>>> p?ijmout;
>>>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>>>>>> strany
>>>>>> > p??jemce s dodatkem ?i odchylkou.
>>>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>>>> zmocn?n
>>>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>>>>> tohoto
>>>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>>>> jejich
>>>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>>>
>>>>>> >
>>>>>> > This e-mail and any documents attached to it may be confidential and
>>>>>> are
>>>>>> > intended only for its intended recipients.
>>>>>> > If you received this e-mail by mistake, please immediately inform
>>>>>> its
>>>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>>>> its
>>>>>> > copies from your system.
>>>>>> > If you are not the intended recipient of this e-mail, you are not
>>>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>>>> manner.
>>>>>> > The sender of this e-mail shall not be liable for any possible
>>>>>> damage
>>>>>> > caused by modifications of the e-mail or by delay with transfer of
>>>>>> the
>>>>>> > email.
>>>>>> >
>>>>>> > In case that this e-mail forms part of business dealings:
>>>>>> > - the sender reserves the right to end negotiations about entering
>>>>>> into a
>>>>>> > contract in any time, for any reason, and without stating any
>>>>>> reasoning.
>>>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>>>> excludes
>>>>>> > any acceptance of the offer on the part of the recipient containing
>>>>>> any
>>>>>> > amendment or variation.
>>>>>> > - the sender insists on that the respective contract is concluded
>>>>>> only
>>>>>> > upon an express mutual agreement on all its aspects.
>>>>>> > - the sender of this e-mail informs that he/she is not authorized to
>>>>>> enter
>>>>>> > into any contracts on behalf of the company except for cases in
>>>>>> which
>>>>>> > he/she is expressly authorized to do so in writing, and such
>>>>>> authorization
>>>>>> > or power of attorney is submitted to the recipient or the person
>>>>>> > represented by the recipient, or the existence of such authorization
>>>>>> is
>>>>>> > known to the recipient of the person represented by the recipient.
>>>>>> >
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Stephen Sefick
>>>>> **************************************************
>>>>> Auburn University
>>>>> Biological Sciences
>>>>> 331 Funchess Hall
>>>>> Auburn, Alabama
>>>>> 36849
>>>>> **************************************************
>>>>> sas0025 at auburn.edu
>>>>> http://www.auburn.edu/~sas0025
>>>>> **************************************************
>>>>>
>>>>> Let's not spend our time and resources thinking about things that are
>>>>> so
>>>>> little or so large that all they really do for us is puff us up and
>>>>> make us
>>>>> feel like gods.  We are mammals, and have not exhausted the annoying
>>>>> little
>>>>> problems of being mammals.
>>>>>
>>>>>                                 -K. Mullis
>>>>>
>>>>> "A big computer, a complex algorithm and a long time does not equal
>>>>> science."
>>>>>
>>>>>                               -Robert Gentleman
>>>>>
>>>>>
>>>>>
>>>>
>>>
>>> --
>>> Stephen Sefick
>>> **************************************************
>>> Auburn University
>>> Biological Sciences
>>> 331 Funchess Hall
>>> Auburn, Alabama
>>> 36849
>>> **************************************************
>>> sas0025 at auburn.edu
>>> http://www.auburn.edu/~sas0025
>>> **************************************************
>>>
>>> Let's not spend our time and resources thinking about things that are so
>>> little or so large that all they really do for us is puff us up and make
>>> us
>>> feel like gods.  We are mammals, and have not exhausted the annoying
>>> little
>>> problems of being mammals.
>>>
>>>                                 -K. Mullis
>>>
>>> "A big computer, a complex algorithm and a long time does not equal
>>> science."
>>>
>>>                               -Robert Gentleman
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

	[[alternative HTML version deleted]]


From alnazer.elbedairy at gmail.com  Tue Feb 23 00:38:16 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Mon, 22 Feb 2016 15:38:16 -0800
Subject: [R] majority guessing
Message-ID: <CAD2s_FQxdx29dpBGY_e4Of4-hEce6orsAikMTW5FsE7mgbqeSw@mail.gmail.com>

dear there
what the steps I can find the knn by using majority guessing.
thanks.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Feb 23 02:51:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Feb 2016 20:51:41 -0500
Subject: [R] Tables, knitr markdown
In-Reply-To: <CAN_e6XtAcMR+ar-n38EFU5DjqZvXh_41veoA9neKZAqHA3sYoA@mail.gmail.com>
References: <CAN_e6Xvn83BH810qTOa-3TwhAbmidVV2x5psHJw-KMLS-TMW5w@mail.gmail.com>
	<CAN_e6XvDcnkcqc+bkubH1qKO1pNFhxvytvC3XnE20L4vXW1UUA@mail.gmail.com>
	<56CB83D8.7060208@gmail.com>
	<CAN_e6XtAcMR+ar-n38EFU5DjqZvXh_41veoA9neKZAqHA3sYoA@mail.gmail.com>
Message-ID: <56CBBB2D.2090102@gmail.com>

On 22/02/2016 6:19 PM, Santosh wrote:
> Sorry.. I forgot to mention that I wanted it be published in MS Word,
> because it goes into a Report this is prepared using MS Word.

I can't help you with that.

>
> Hence,the above effort.. yes, it's a lot easier to send it to Latex..
>
> I was also wondering if it is possible to add "\hline" separating the
> categories in a table..
>
> Using tabular, I get this:
>
> \begin{tabular}{lcccc}
> \hline
> "Name"  & "Value1" & \multicolumn{1}{c}{"Value2"} \\
> \hline
> \nopagebreak A1  &   0.06 &   1.2 \\
> \nopagebreak A5  &   0.62 &   8.9 \\
> \nopagebreak A6  &   0.48 &   4.2 \\
> \rule{0pt}{1.7\normalbaselineskip}A2  &   1.50 &   1.27 \\
> \nopagebreak A7  &   0.11 &   4.3 \\
> \nopagebreak A3  &   0.01 &   3.1 \\
> \rule{0pt}{1.7\normalbaselineskip}A4  &   2.19 &   1.0 \\
> \nopagebreak B1.  &  0.03 &   2.0 \\
> \nopagebreak B2.  &  0.011 &  1.8 \\
> \rule{0pt}{1.7\normalbaselineskip}B3  &  0.10 &  2.7 \\
> \nopagebreak B4.  &  0.02 &   1.6 \\
> \nopagebreak C1.  &  0.01 &   1.1 \\
> \hline
> \end{tabular}
>
> But, I want in this way.. (with horizontal lines and customized text
> inserted at the beginning of a group..
>

If you wanted LaTeX output, you could do this like the example at the 
end of section 2.1.5 in the vignette.  (You might want to combine that 
with subsetting as in section 3.3.)

Duncan Murdoch

> \begin{tabular}{lcccc}
> \hline
> "Name"  & "Value1" & \multicolumn{1}{c}{"Value2"} \\
> \hline
> \multicolumn{5}{l}{\textbf{Hardened}}\\
> \hline
> \nopagebreak A1  &   0.06 &   1.2 \\
> \nopagebreak \tA5  &   0.62 &   8.9 \\
> \nopagebreak \tA6  &   0.48 &   4.2 \\
> \rule{0pt}{1.7\normalbaselineskip}A2  &   1.50 &   1.27 \\
> \nopagebreak \tA7  &   0.11 &   4.3 \\
> \nopagebreak \tA3  &   0.01 &   3.1 \\
> \rule{0pt}{1.7\normalbaselineskip}A4  &   2.19 &   1.0 \\
> \hline
> \multicolumn{3}{l}{\textbf{Pulverized}}\\
> \hline
> \nopagebreak B1.  &  0.03 &   2.0 \\
> \nopagebreak B2.  &  0.011 &  1.8 \\
> \rule{0pt}{1.7\normalbaselineskip}B3  &  0.10 &  2.7 \\
> \nopagebreak B4.  &  0.02 &   1.6 \\
> \hline
> \multicolumn{3}{l}{\textbf{Molten}}\\
> \hline
> \nopagebreak C1.  &  0.01 &   1.1 \\
> \hline
> \end{tabular}
>
> Thanks so much for your help!
> Santosh
>
> On Mon, Feb 22, 2016 at 1:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 22/02/2016 3:46 PM, Santosh wrote:
>>
>>> Just figured out..
>>>
>>> as.data.frame(as.matrix(<tabular_object>),stringsAsFactors=F)
>>>
>>> could work! :)
>>>
>>
>> Why do you want to produce Markdown output?  the tables package (lowercase
>> t!) can produce output in either LaTeX or HTML.  Just tell knitr to leave
>> the output alone, e.g. for PDF output
>>
>> ```{r results="asis"}
>> require(tables)
>> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>>           (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
>> latex(tab)
>> ```
>>
>> or for HTML output
>>
>> ```{r results="asis"}
>> require(tables)
>> tab <- tabular( (Species + 1) ~ (n=1) + Format(digits=2)*
>> (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )
>> html(tab)
>> ```
>>
>>
>> Duncan Murdoch
>>
>>
>>>
>>> On Mon, Feb 22, 2016 at 12:17 PM, Santosh <santosh2005 at gmail.com> wrote:
>>>
>>> Dear Rxperts..
>>>> I am able to generate tables using Tables R package..
>>>> However, when I have been unsuccessful in using kable (from knitr
>>>> package)
>>>> to generate the table in R markdown script..
>>>>
>>>> It's because the output generated by "tabular" in Tables package is of
>>>> class "tabular". The kable function in knitr package accepts data.frame.
>>>>
>>>> Is there a way to convert the tabular class objects into data.frame
>>>>    objects?
>>>>
>>>> Or is there a way that kable can accept "tabular" class object?
>>>>
>>>>
>>>> Thanks so much..
>>>> Santosh
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From venkynov10 at gmail.com  Tue Feb 23 06:44:53 2016
From: venkynov10 at gmail.com (Venky)
Date: Tue, 23 Feb 2016 11:14:53 +0530
Subject: [R] Fwd: Shiny-Wordcloud
In-Reply-To: <CAAM-fZ7J00US3+CNdqQ99eAbM0zoNr2YWe01Vkt0Dvyk0+uGuw@mail.gmail.com>
References: <CAAM-fZ7J00US3+CNdqQ99eAbM0zoNr2YWe01Vkt0Dvyk0+uGuw@mail.gmail.com>
Message-ID: <CAAM-fZ6hScmvHGxqHN_GPLU9GLwZC2hdAriVbw=kHD36taU6ug@mail.gmail.com>

Hi R users,

I need Shiny *server and UI* code for creating Uni gram,Bi gram,and Trig
ram.
 for Word cloud from my desktop data.

I gone through this link: http://shiny.rstudio.com/gallery/word-cloud.html

It contains the source data from some where, but i need to use these word
cloud for my *DESKTOP* data

in this example (http://shiny.rstudio.com/gallery/word-cloud.html)  *"A mid
Summer night dreams",The merchant of Venice "* is drop down

In that drop-down i need to set my own Desktop file (csv) variable to show
the word cloud.

*For example*

column  1                         column 2                           column
3

what are you?               am fine                        i am from Chennai
Who are you?               Thanking you               my name is venky
bye take care                i will do that                please give me


I want to create column 1 word cloud instead of *A mid Summer night
dreams",*
and column 2 word cloud  instead of* The merchant of Venice from the * (
http://shiny.rstudio.com/gallery/word-cloud.html)

I need to create word cloud for separate,separate columns

Please help me to figure out this one




Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Tue Feb 23 06:45:58 2016
From: venkynov10 at gmail.com (Venky)
Date: Tue, 23 Feb 2016 11:15:58 +0530
Subject: [R] Password-Shiny
Message-ID: <CAAM-fZ6LcrQnyKrxGkqj5cD3c5qX--9coLFMkfTfuhvfqXwrgA@mail.gmail.com>

Hi R users,

Please anyone help me how to create password access in shiny


Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Feb 23 08:30:27 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 23 Feb 2016 18:30:27 +1100
Subject: [R] How to merge two tables
In-Reply-To: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
References: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
Message-ID: <CA+8X3fUH1uhiYjQrK+euV8_X7FGD9h4C8o3y38bLQSSzKsksVQ@mail.gmail.com>

Hi Xiyan,
It looks like your tables have different numbers of cases. There are:

66 DEAD FEMALES in "cross"
56 DEAD FEMALES in "age"

48 NON-DEAD FEMALES in "cross"
58 NON-DEAD FEMALES in "age"

and so on. Perhaps there is some mistake with the counts. If this is the
problem you could expand the counts to individual lines in a merged data
frame using the sex and death information.

Jim

On Tue, Feb 23, 2016 at 5:46 AM, Xiyan Lon <xiyanlon at gmail.com> wrote:

> Dear all,
> I am currently studying categorical data analysis, if I have two tables:
>
> R> cross
>       sex cross death count
> 1  FEMALE   WEF   YES    26
> 2    MALE   WEF   YES    14
> 3  FEMALE   OGG   YES    32
> 4    MALE   OGG   YES    43
> 5  FEMALE   TGA   YES     8
> 6    MALE   TGA   YES    10
> 7  FEMALE   WEF    NO     6
> 8    MALE   WEF    NO     7
> 9  FEMALE   OGG    NO    26
> 10   MALE   OGG    NO    12
> 11 FEMALE   TGA    NO    16
> 12   MALE   TGA    NO    26
>
> R> age
>      sex age death count
> 1 FEMALE 17Y   YES    16
> 2   MALE 17Y   YES     4
> 3 FEMALE 18Y   YES    40
> 4   MALE 18Y   YES    51
> 5 FEMALE 17Y    NO    32
> 6   MALE 17Y    NO    42
> 7 FEMALE 18Y    NO    26
> 8   MALE 18Y    NO    15
>
> - How to merge two tables.
> - How to expand both tables such as:
>
> sex age cross death
> FEMALE 17Y WEF YES
> ...
> FEMALE 18Y TGA NO
>
>
> Warm regards,
> Xiyan Lon
>
> This email has been sent from a virus-free computer protected by Avast.
> www.avast.com <https://www.avast.com/sig-email>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Feb 23 08:49:23 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 23 Feb 2016 08:49:23 +0100
Subject: [R] How a clustering algorithm in R can end up with negative
 silhouette values?
In-Reply-To: <D5929231F0B1A625.1-242ae78d-388b-443d-a9c1-0307ef81f11c@mail.outlook.com>
References: <AM3PR06MB09945C491C68FDD7B9C3A92D81A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vjumDENQuOuoSvwciakj0raDipQMkw7-r6FLBp2HFAeDWgA@mail.gmail.com>
	<D5929231F0B1A625.1-2aa1a1ba-ed8a-4e65-aa93-e4cdbf0c79ff@mail.outlook.com>
	<CAM_vjunVforkEJQ2EmN2+2fcCd+coRwDa=1tggzUgCPt8bWCiA@mail.gmail.com>
	<AM3PR06MB099448206FD4337C1758B8D681A00@AM3PR06MB0994.eurprd06.prod.outlook.com>
	<CAM_vju=yNMM3QMdwXW9je1n1-Dkgxzeqg5rM-HGJbpt5Uf8p3Q@mail.gmail.com>
	<22219.11735.931817.454412@stat.math.ethz.ch>
	<22219.12954.140811.753752@stat.math.ethz.ch>
	<D5929231F0B1A625.1-242ae78d-388b-443d-a9c1-0307ef81f11c@mail.outlook.com>
Message-ID: <22220.3843.102259.511411@stat.math.ethz.ch>

>>>>> ABABAEI, Behnam <Behnam.ABABAEI at limagrain.com>
>>>>>     on Mon, 22 Feb 2016 16:15:32 +0000 writes:

    > Thank you Martin.
    > I finally came up with this idea: use clara with 100 samples of the size of 1000, then use the clusters as initial runs for kmeans. I think this combines the advantages of clara and kmeans. It gives more distinct clusters than kmeans alone, less time required compared to kmeans alone, and no need for large samples for clara, which take too long to process.

    > Yet I cannot prove which one is better. Clara alone, or that combination method?! Do you have any suggestion?

[Replying to the mailing list, this should have been kept there]

Just a gut feeling:

Clara alone will be simpler and faster, and I cannot see that
extra kmeans iterations would in general be beneficial.

As I said earlier in this thread, I *would* strongly consider using
rngR = TRUE  and more than one (random) run so you get a feeling
about the influence of the random sample at start.
In addition, from the several runs, you could keep the best one.

Martin

    > Best,

    > Behnam



    > On Mon, Feb 22, 2016 at 8:09 AM -0800, "Martin Maechler" <maechler at stat.math.ethz.ch<mailto:maechler at stat.math.ethz.ch>> wrote:

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon, 22 Feb 2016 16:48:39 +0100 writes:

>>>>> Sarah Goslee <sarah.goslee at gmail.com>
>>>>>     on Fri, 19 Feb 2016 15:22:22 -0500 writes:

    >>> Ah, my guess about the confusion was wrong, then. You're
    >>> misunderstanding silhouette() instead.

    >>>> From ?silhouette:

    >>> Observations with a large s(i) (almost 1) are very
    >>> well clustered, a small s(i) (around 0) means that the
    >>> observation lies between two clusters, and observations
    >>> with a negative s(i) are probably placed in the wrong
    >>> cluster.


    >>> In more detail, they're looking at different things.
    >>> clara() assigns each point to a cluster based on the
    >>> distance to the nearest medoid.

    >>> silhouette() does something different: instead of
    >>> comparing the distances to the closest medoid and the next
    >>> closest medoid, which is what you seem to be assuming,
    >>> silhouette() looks at the mean distance to ALL other
    >>> points assigned to that cluster, vs the mean distance to
    >>> all points in other clusters. The distance to the medoid
    >>> is irrelevant, except as it is one of the points in that
    >>> cluster.

    >>> So a negative silhouette value is entirely possible, and
    >>> means that the cluster produced doesn't represent the
    >>> dataset very well.

    >> Indeed ... and this extends to pam(), even; as you say above,
    >> " silhouette() does something different " :

    >> If your look at the plots of

    >> example(silhouette)

    >> where the silhouettes of   pam(ruspini, k = k')  ,  k' = 2,..,6
    >> are displayed, or if you directly look at

    >> plot( silhouette(ruspini, k = 6) )

    > oops... that should have been

    > plot( silhouette(pam(ruspini, k = 6)) )

    >> you will notice that pam() itself can easily lead to negative
    >> silhouette values.

    >> Martin Maechler  [  == maintainer("cluster")  ]



    >>> On Fri, Feb 19, 2016 at 3:04 PM, ABABAEI, Behnam
    >>> <Behnam.ABABAEI at limagrain.com> wrote:
    >>>> Sarah, sorry for taking up your time.
    >>>> 
    >>>> I totally agree with you about how it works. But please
    >>>> let's take a look at this part of the description:
    >>>> 
    >>>> "Once k representative objects have been selected from
    >>>> the sub-dataset, each observation of the entire dataset
    >>>> is assigned to the nearest medoid. The mean (equivalent
    >>>> to the sum) of the dissimilarities of the observations to
    >>>> their closest medoid is used as a measure of the quality
    >>>> of the clustering. The sub-dataset for which the mean (or
    >>>> sum) is minimal, is retained. A further analysis is
    >>>> carried out on the final partition."
    >>>> 
    >>>> It says each observation is finally assigned to the
    >>>> closest medoid. The whole clustering process may be
    >>>> imperfect in terms of isolation of clusters, but each
    >>>> observation is already assigned to the closest one and
    >>>> according to the silhouette formula, the silhouette value
    >>>> cannot be negative, as a must be always less than b.
    >>>> 
    >>>> Regards, Behnam.
    >>>> 
    >>>> ________________________________________ From: Sarah
    >>>> Goslee <sarah.goslee at gmail.com> Sent: 19 February 2016
    >>>> 20:58 To: ABABAEI, Behnam Cc: r-help at r-project.org
    >>>> Subject: Re: [R] How a clustering algorithm in R can end
    >>>> up with negative silhouette values?
    >>>> 
    >>>> You need to think more carefully about the details of the
    >>>> clara() method.
    >>>> 
    >>>> The algorithm draws repeated samples of sampsize from the
    >>>> larger dataset, as specified by the arguments to the
    >>>> function.  It clusters each sample in turn, and saves the
    >>>> best one.  It uses the medoids from the best one to
    >>>> assign all of the points to a cluster.
    >>>> 
    >>>> But because the clustering is based on a subsample, it
    >>>> may not be representative of the dataset as a whole, and
    >>>> may not provide a good clustering overall. Just because
    >>>> it clusters the subsample well, doesn't mean it clusters
    >>>> the entirety. The details section of the help describes
    >>>> this, and the book references goes into more detail.
    >>>> 
    >>>> Sarah
    >>>> 
    >>>> 
    >>>> 
    >>>> On Fri, Feb 19, 2016 at 2:55 PM, ABABAEI, Behnam
    >>>> <Behnam.ABABAEI at limagrain.com> wrote:
    >>>>> Hi Sarah,
    >>>>> 
    >>>>> Thank you for the response. But it is said in its
    >>>>> description that after each run (sample), each
    >>>>> observation in the whole dataset is assigned to the
    >>>>> closest cluster. So how is it possible for one
    >>>>> observation to be wrongly allocated, even with clara?
    >>>>> 
    >>>>> Behnam
    >>>>> 
    >>>>> Behnam
    >>>>> 
    >>>>> 
    >>>>> 
    >>>>> 
    >>>>> On Fri, Feb 19, 2016 at 11:48 AM -0800, "Sarah Goslee"
    >>>>> <sarah.goslee at gmail.com> wrote:
    >>>>> 
    >>>>> That means that points have been assigned to the wrong
    >>>>> groups. This may readily happen with a clustering method
    >>>>> like cluster::clara() that uses a subset of the data to
    >>>>> cluster a dataset too large to analyze as a
    >>>>> unit. Negative silhouette numbers strongly suggest that
    >>>>> your clustering parameters should be changed.
    >>>>> 
    >>>>> Sarah
    >>>>> 
    >>>>> On Fri, Feb 19, 2016 at 6:33 AM, ABABAEI, Behnam
    >>>>> <Behnam.ABABAEI at limagrain.com> wrote:
    >>>>>> Hi,
    >>>>>> 
    >>>>>> 
    >>>>>> We know that clustering methods in R assign
    >>>>>> observations to the closest medoids. Hence, it is
    >>>>>> supposed to be the closest cluster each observation can
    >>>>>> have. So, I wonder how it is possible to have negative
    >>>>>> values of silhouette , while we are supposedly assign
    >>>>>> each observation to the closest cluster and the formula
    >>>>>> in silhouette method cannot get negative?
    >>>>>> 
    >>>>>> 
    >>>>>> Behnam.


From drjimlemon at gmail.com  Tue Feb 23 10:02:05 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 23 Feb 2016 20:02:05 +1100
Subject: [R] Reading a datetime vector
In-Reply-To: <1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
References: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
	<1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fVidTEi5OJpWuBo5QDuzjrNmrx7XL3EE3s9RMi5hCHJzw@mail.gmail.com>

Hi Doug,
It is difficult for us to work out what is happening as we don't have
access to a toy data set that we can play with. Excel spreadsheets are one
of those things that you can't just attach to your email to the help list.
If there is somewhere you can leave a _small_ Excel sample file (take the
first 10 rows, say) that we can download (Google Drive, Dropbox?) and
include the URL in your email, maybe someone can offer more than guesses.

Jim

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Feb 23 11:14:32 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 Feb 2016 11:14:32 +0100
Subject: [R] Reading a datetime vector
In-Reply-To: <EE12C4B2-FD22-45EE-8BA4-FE391DCE9848@dcn.davis.ca.us>
References: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
	<1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
	<EE12C4B2-FD22-45EE-8BA4-FE391DCE9848@dcn.davis.ca.us>
Message-ID: <F7BF3892-1033-4541-BD4E-77497CF1F14E@gmail.com>


On 22 Feb 2016, at 18:30 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> .. read the Excel documentation for representing dates... it is days since December 30, 1899 on Windows.

I seem to recall that that is actually only true for dates after March 1, 1900. (The reason that it is not counting December 31st being that someone thought that 1900 was a leap year.) 

<Checks Wikipedia: Yep, 1900 is still a leap year in Excel. The original perpetrator was Lotus 1-2-3 and Microsoft went for but-compatibility.>

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From james.foadi at diamond.ac.uk  Tue Feb 23 11:42:14 2016
From: james.foadi at diamond.ac.uk (james.foadi at diamond.ac.uk)
Date: Tue, 23 Feb 2016 10:42:14 +0000
Subject: [R] multiple linear regression with quadratic function
Message-ID: <DDDDFD4A9D76184F8562ACE0629AD471E7053237@EXCHMBX03.fed.cclrc.ac.uk>

Dear R community,
this is probably a well-known topic to some of you, but I am not well into it
and would like some clarifications or even jus some suggestions.

I have a quadratic scalar field:

        F(x,y)=K*exp(-(a*x^2+b*y^2+c*x*y))

I also have a random set of positive x,y values and related F(x,y) values.
It seems reasonable to estimate the parameters K, a, b, c with a linear regression,
using the log of both sides of the equation.

What worries me, though, is the interaction term, c*x*y.

Are there well-known issues on the application of linear regression to cases like this one?

Thanks in advance for your answers.

James

-- 
This e-mail and any attachments may contain confidential...{{dropped:16}}


From pdalgd at gmail.com  Tue Feb 23 11:59:10 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 Feb 2016 11:59:10 +0100
Subject: [R] multiple linear regression with quadratic function
In-Reply-To: <DDDDFD4A9D76184F8562ACE0629AD471E7053237@EXCHMBX03.fed.cclrc.ac.uk>
References: <DDDDFD4A9D76184F8562ACE0629AD471E7053237@EXCHMBX03.fed.cclrc.ac.uk>
Message-ID: <E0A39DA8-D1B3-4D9F-8FB6-992DC4E1433E@gmail.com>

That's pretty standard. Some call it "response surface analysis". Of course you need to check assumptions like homoscedasticity on the log scale, etc.

It's not really an R question, specifically; so stats.stackexchange.com is a better avenue for more detailed discussions. As far as R goes, you just need to be aware that, due to an ancien misfeature, terms like x^2 need to be protected by writing I(x^2). 

-pd

On 23 Feb 2016, at 11:42 , <james.foadi at diamond.ac.uk> <james.foadi at diamond.ac.uk> wrote:

> Dear R community,
> this is probably a well-known topic to some of you, but I am not well into it
> and would like some clarifications or even jus some suggestions.
> 
> I have a quadratic scalar field:
> 
>        F(x,y)=K*exp(-(a*x^2+b*y^2+c*x*y))
> 
> I also have a random set of positive x,y values and related F(x,y) values.
> It seems reasonable to estimate the parameters K, a, b, c with a linear regression,
> using the log of both sides of the equation.
> 
> What worries me, though, is the interaction term, c*x*y.
> 
> Are there well-known issues on the application of linear regression to cases like this one?
> 
> Thanks in advance for your answers.
> 
> James
> 
> -- 
> This e-mail and any attachments may contain confidential...{{dropped:16}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Roger.Bivand at nhh.no  Tue Feb 23 12:50:35 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 23 Feb 2016 11:50:35 +0000
Subject: [R] GIS Analyses for Economics and Marketing
References: <CACgt3o=z5Pe8rRgvUnGrBDa90jE-Np+-kdGWcvuf9fV3-C71gA@mail.gmail.com>
Message-ID: <loom.20160223T124613-137@post.gmane.org>

Domagoj Culinovic <culinovic.domagoj <at> gmail.com> writes:

> 
> I am Phdoctorate Candidate at Faculty of economics.
> Also i am using GIS last 26 years, but lat 3 year i am focused on QGIS.
> My earea of interests are GIS in Economics and marketing, and now i am
> combine R and QGIS to have results.

It may be more relevant to post in R-sig-geo than here, given the specific
nature of your question.

You might also look at materials used in connection with GEOSTAT courses:

http://geostat-course.org/

The next course is in Albacete, Spain (the host of the useR! 2013
conference). These materials are mostly related to environmental questions,
but the techniques used are similar.

Roger

> Can someone help me with some tutorials, training materials or course
> examples in area GIS for Marketing or Economics based on QGIS (with Grass
> or any other plugins), and some examples of financial analyses based on
> historical data in using GIS(for exaple to analyse comunity budget spends
> in last 15 years based on GIS data).


From ajdamico at gmail.com  Tue Feb 23 13:49:00 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 23 Feb 2016 07:49:00 -0500
Subject: [R] .Internal(La_rs(x,
 FALSE)) crashes R after long (reproducible) script on windows only
Message-ID: <CAOwvMDy9a5f2FYeu-K1FtbNW-kOd99xL=tG6JxxMcXJcVUY23w@mail.gmail.com>

hi, does anybody have a clue why .Internal(La_rs(x,FALSE)) is getting
corrupted (actual detonation occurs within La_solve_cmplx within Lapack.c)
on windows but not mac/unix?

i have provided two (long) scripts that reproduce the problem and a third
script modified to trigger the crash that unfortunately does not reproduce
the problem

http://stackoverflow.com/questions/35447971/internalla-rsx-false-crashes-r-after-long-reproducible-script-on-windows

thanks

	[[alternative HTML version deleted]]


From bob at rudis.net  Tue Feb 23 14:10:59 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 23 Feb 2016 08:10:59 -0500
Subject: [R] Password-Shiny
In-Reply-To: <CAAM-fZ6LcrQnyKrxGkqj5cD3c5qX--9coLFMkfTfuhvfqXwrgA@mail.gmail.com>
References: <CAAM-fZ6LcrQnyKrxGkqj5cD3c5qX--9coLFMkfTfuhvfqXwrgA@mail.gmail.com>
Message-ID: <CAJ4QxaMOD75jUXZuHuuj9o8b1WFy93j1WJVtACPLDVT9rJZD0Q@mail.gmail.com>

What would cause you to think this mailing list is a free code-writing
service? Perhaps post your question on Amazon's Mechanical Turk
service?

Alternatively: purchase a license for Shiny Server Pro.

On Tue, Feb 23, 2016 at 12:45 AM, Venky <venkynov10 at gmail.com> wrote:
> Hi R users,
>
> Please anyone help me how to create password access in shiny
>
>
> Thanks and Regards
> Venkatesan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Feb 23 14:22:52 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 23 Feb 2016 08:22:52 -0500
Subject: [R] .Internal(La_rs(x,
 FALSE)) crashes R after long (reproducible) script on windows only
In-Reply-To: <CAOwvMDy9a5f2FYeu-K1FtbNW-kOd99xL=tG6JxxMcXJcVUY23w@mail.gmail.com>
References: <CAOwvMDy9a5f2FYeu-K1FtbNW-kOd99xL=tG6JxxMcXJcVUY23w@mail.gmail.com>
Message-ID: <56CC5D2C.9040405@gmail.com>

On 23/02/2016 7:49 AM, Anthony Damico wrote:
> hi, does anybody have a clue why .Internal(La_rs(x,FALSE)) is getting
> corrupted (actual detonation occurs within La_solve_cmplx within Lapack.c)
> on windows but not mac/unix?
>
> i have provided two (long) scripts that reproduce the problem and a third
> script modified to trigger the crash that unfortunately does not reproduce
> the problem
>
> http://stackoverflow.com/questions/35447971/internalla-rsx-false-crashes-r-after-long-reproducible-script-on-windows

Just two comments:

  - Your post suggests you're calling .Internal() yourself, but that's 
not the case.  So your question should be about why eigen() crashes R.

  - If you need a long script to trigger the error, I'd assume there's 
something wrong in that script. Your script uses several contributed 
packages, so the problem could be there. Shorten it to a minimal 
reproducible example that doesn't use any contributed packages.  If you 
can't leave out the packages, try to reduce it to just one, and ask the 
maintainer of that package about it.

Duncan Murdoch


From mdsumner at gmail.com  Tue Feb 23 14:24:42 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 23 Feb 2016 13:24:42 +0000
Subject: [R] Password-Shiny
In-Reply-To: <CAJ4QxaMOD75jUXZuHuuj9o8b1WFy93j1WJVtACPLDVT9rJZD0Q@mail.gmail.com>
References: <CAAM-fZ6LcrQnyKrxGkqj5cD3c5qX--9coLFMkfTfuhvfqXwrgA@mail.gmail.com>
	<CAJ4QxaMOD75jUXZuHuuj9o8b1WFy93j1WJVtACPLDVT9rJZD0Q@mail.gmail.com>
Message-ID: <CAAcGz99wH5D22dsVX5T85UZ+ET7g0GCXqFerHKA2YpWr1iBadQ@mail.gmail.com>

On Wed, 24 Feb 2016 at 00:18 boB Rudis <bob at rudis.net> wrote:

> What would cause you to think this mailing list is a free code-writing
> service? Perhaps post your question on Amazon's Mechanical Turk
> service?
>
> Alternatively: purchase a license for Shiny Server Pro.
>
> On Tue, Feb 23, 2016 at 12:45 AM, Venky <venkynov10 at gmail.com> wrote:
> > Hi R users,
> >
> > Please anyone help me how to create password access in shiny
> >
>

It's not clear to me if you are asking about a "Pro" service specifically
(though if so I have learnt something), or just this:

http://shiny.rstudio.com/reference/shiny/latest/passwordInput.html

Either way r-help is not yet the place for extensions as way out as Shiny,
try here:

http://shiny.rstudio.com/help/

Cheers, Mike.


> >
> > Thanks and Regards
> > Venkatesan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From dkrstajic at hotmail.com  Tue Feb 23 14:45:36 2016
From: dkrstajic at hotmail.com (Damjan Krstajic)
Date: Tue, 23 Feb 2016 13:45:36 +0000
Subject: [R] survival datasets
Message-ID: <VI1PR04MB1085D263C01822AC2A86E7CBB4A40@VI1PR04MB1085.eurprd04.prod.outlook.com>

Dear All,


I am performing a research and I would like to use as many publicly available survival datasets as possible. There are some in the survival R package like pbc and bladder. I am only interested for (time,event) values from public datasets.


I would be grafeful if someone can send me some links.


Thanks in advance.

DK

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Tue Feb 23 14:50:04 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 23 Feb 2016 08:50:04 -0500
Subject: [R] How to merge two tables
In-Reply-To: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
References: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
Message-ID: <56CC638C.3000500@yorku.ca>

Hi Xiyan,

You don't show your original data, so
* If you produced `cross` and `age` tables by summing the counts from a 
single larger data set, go back to that and do it again. but now include 
age/

* Otherwise, you can use vcdeExtra::expand.dft()` on both of these data 
sets to expand to individual observations, and merge those.

In general, you'll get better replies by including a reproducible 
example, rather than summary output from the console.

-Michael


On 2/22/2016 1:46 PM, Xiyan Lon wrote:
> Dear all,
> I am currently studying categorical data analysis, if I have two tables:
>
> R> cross
>        sex cross death count
> 1  FEMALE   WEF   YES    26
> 2    MALE   WEF   YES    14
> 3  FEMALE   OGG   YES    32
> 4    MALE   OGG   YES    43
> 5  FEMALE   TGA   YES     8
> 6    MALE   TGA   YES    10
> 7  FEMALE   WEF    NO     6
> 8    MALE   WEF    NO     7
> 9  FEMALE   OGG    NO    26
> 10   MALE   OGG    NO    12
> 11 FEMALE   TGA    NO    16
> 12   MALE   TGA    NO    26
>
> R> age
>       sex age death count
> 1 FEMALE 17Y   YES    16
> 2   MALE 17Y   YES     4
> 3 FEMALE 18Y   YES    40
> 4   MALE 18Y   YES    51
> 5 FEMALE 17Y    NO    32
> 6   MALE 17Y    NO    42
> 7 FEMALE 18Y    NO    26
> 8   MALE 18Y    NO    15
>
> - How to merge two tables.
> - How to expand both tables such as:
>
> sex age cross death
> FEMALE 17Y WEF YES
> ...
> FEMALE 18Y TGA NO
>
>
> Warm regards,
> Xiyan Lon
>
> This email has been sent from a virus-free computer protected by Avast.
> www.avast.com <https://www.avast.com/sig-email>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> 	[[alternative HTML version deleted]]
>


From friendly at yorku.ca  Tue Feb 23 14:50:04 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 23 Feb 2016 08:50:04 -0500
Subject: [R] How to merge two tables
In-Reply-To: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
References: <CA+qbi2PcB0cNdCCKEu0dkPYWa-+a7HsJy8enKD-ZrPKrm84K_Q@mail.gmail.com>
Message-ID: <56CC638C.3000500@yorku.ca>

Hi Xiyan,

You don't show your original data, so
* If you produced `cross` and `age` tables by summing the counts from a 
single larger data set, go back to that and do it again. but now include 
age/

* Otherwise, you can use vcdeExtra::expand.dft()` on both of these data 
sets to expand to individual observations, and merge those.

In general, you'll get better replies by including a reproducible 
example, rather than summary output from the console.

-Michael


On 2/22/2016 1:46 PM, Xiyan Lon wrote:
> Dear all,
> I am currently studying categorical data analysis, if I have two tables:
>
> R> cross
>        sex cross death count
> 1  FEMALE   WEF   YES    26
> 2    MALE   WEF   YES    14
> 3  FEMALE   OGG   YES    32
> 4    MALE   OGG   YES    43
> 5  FEMALE   TGA   YES     8
> 6    MALE   TGA   YES    10
> 7  FEMALE   WEF    NO     6
> 8    MALE   WEF    NO     7
> 9  FEMALE   OGG    NO    26
> 10   MALE   OGG    NO    12
> 11 FEMALE   TGA    NO    16
> 12   MALE   TGA    NO    26
>
> R> age
>       sex age death count
> 1 FEMALE 17Y   YES    16
> 2   MALE 17Y   YES     4
> 3 FEMALE 18Y   YES    40
> 4   MALE 18Y   YES    51
> 5 FEMALE 17Y    NO    32
> 6   MALE 17Y    NO    42
> 7 FEMALE 18Y    NO    26
> 8   MALE 18Y    NO    15
>
> - How to merge two tables.
> - How to expand both tables such as:
>
> sex age cross death
> FEMALE 17Y WEF YES
> ...
> FEMALE 18Y TGA NO
>
>
> Warm regards,
> Xiyan Lon
>
> This email has been sent from a virus-free computer protected by Avast.
> www.avast.com <https://www.avast.com/sig-email>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> 	[[alternative HTML version deleted]]
>


From danprec at hotmail.com  Tue Feb 23 11:34:54 2016
From: danprec at hotmail.com (Daniel Preciado)
Date: Tue, 23 Feb 2016 11:34:54 +0100
Subject: [R] lme() - MEEM error (singularity in Backsolve) due to
 user-specified contrasts amount
Message-ID: <BLU436-SMTP143B6B6CF58A6851321DF3FA0A40@phx.gbl>

Hello all, 

I posted this question also in Stackoverflow, but in hindsight I realise it probably fits better here. I am trying to use lme() to fit and compare different models to data from an experiment in a repeated measures design. My dependent variable is response time (RT, in milliseconds); and I have 2 factors: F_A (2 levels) and F_B (3 Levels). For F_B, I have specified the following contrasts:
F_B_C1 <- c(1, -1, 0)      # Contrast prize 1 and 2 levels
F_B_C2 <- c(1, 0, -1)      # Contrast prize 1 with Neutral (no prize)
F_B_C3 <- c(1, 0, -1)      # Contrast prize 2 with Neutral (no prize)
F_B_C4 <- c(1, 1, -2)      # Contrast prize with Neutral
contrasts(Data$F_B, how.many=4) <- cbind(F_B_C1, F_B_C2, F_B_C3, F_B_C4) 
Conditions 1 and 2 are 2 levels of the same manipulation, condition 3 is a neutral control. I am interested in the effect of each level (individually) on RT, and overall in the difference between the experimental manipulation (pooling the first 2 conditions of factor B) and the control condition (final condition of factor B).

I defined the lme() models step-wise, starting with a Baseline model, and then updating that one to include each factor individually, and finally the interaction:
RT_Base <- lme(RT ~ 1, random = ~1|SubjID/F_A/F_B, data=Data, method="ML")  #Baseline model
RT_F_A <- update(RT_Base, .~. + F_A)            #Baseline + F_A
RT_F_B <- update(RT_F_A, .~. + F_B)             #(Baseline+F_A) + F_B
RT_Full <- update(RT_F_B, .~. + F_A:F_B)        #Full model (+ interaction)
However, when I execute the code involving F_B, I get an 
"Error in MEEM (...): Singularity in Backsolve at level 0, block 1). 
I can still inspect the results of the model, but I would like to understand where is this error coming from, what does it mean, and how to avoid it. Furthermore, I realized that if I reduce the amount of contrasts to the default 2, the code runs without any error, so I can only assume that it has something to do with the user-specified comparison pairs. Also, the specified contrasts are not displayed (only the default first 2).

I also read in some answer that the intercept needed to be suppressed in order to prevent this error (by adding RT ~ 0+Factors to the model formulae). I tried that, but it produces the same error. 

I would appreciate any feedback regarding this, Thanks!



	[[alternative HTML version deleted]]


From rachanabagde1996 at gmail.com  Tue Feb 23 13:38:09 2016
From: rachanabagde1996 at gmail.com (Rachana Bagde)
Date: Tue, 23 Feb 2016 18:08:09 +0530
Subject: [R] Query in R.
Message-ID: <CALEe9tGgP7VGvwx1XG+heHh4HmAzRymy8H8rWi2WmkKw_zwoJg@mail.gmail.com>

Can anyone please solve this query.

http://stackoverflow.com/questions/35577484/cpquery-of-bnlearn-gives-0-for-every-event-and-evidence-in-r

Thanks.

	[[alternative HTML version deleted]]


From fosu77 at gmail.com  Tue Feb 23 07:23:58 2016
From: fosu77 at gmail.com (Kwabena Fosu-Amankwah)
Date: Mon, 22 Feb 2016 22:23:58 -0800
Subject: [R] Code for finding successive mean
Message-ID: <CAA0akYxvF_H7MvsvrUP9pZhAnqTihZv4wv8-Ez=oV4jEfWK71Q@mail.gmail.com>

Hi am Kwabena,

I would be very grateful if someone can help me with the code or script on
how to find successive mean at 30 minutes interval for the set of data
below:

Date/Time PR     SW TP  SM SHF CO2
28.11.2011 17:39:49 978.4 13.15 30.5 20 NA NA
28.11.2011 17:50:00 978.5 13.11 30.4 20 NA NA
28.11.2011 18:00:00 978.8 13.14 30.3 20 NA NA
28.11.2011 18:10:00 979 13.07 30.1 20 NA NA
28.11.2011 18:20:00 979.2 13.1 30 20 NA NA
28.11.2011 18:30:00 979.4 13.09 29.8 20 NA NA
28.11.2011 18:40:00 979.5 13.08 29.6 20 NA NA
28.11.2011 18:50:00 979.5 13.06 29.5 20 NA NA
28.11.2011 19:00:00 979.6 13.06 29.4 20 NA NA
28.11.2011 19:10:00 979.7 13.05 29.3 20 NA NA
28.11.2011 19:20:00 979.9 13.03 29.2 20 NA NA
28.11.2011 19:30:00 980 13 29.1 20 NA NA
28.11.2011 19:40:00 980 13.03 29 20 NA NA
28.11.2011 19:50:00 980.1 13.03 28.9 20 NA NA
28.11.2011 20:00:00 980.3 13      28.8 20 NA NA
28.11.2011 20:10:00 980.5 12.97 28.7 20 NA NA
28.11.2011 20:20:00 980.8 12.96 28.6 20 NA NA
28.11.2011 20:30:00 981.1 12.95 28.5 20 NA NA
28.11.2011 20:40:00 981.1 12.95 28.4 20 NA NA
28.11.2011 20:50:00 981.2 12.94 28.3 20 NA NA
28.11.2011 21:00:00 981.3 12.93 28.2 20 NA NA
28.11.2011 21:10:00 981.3 12.92 28.1 20 NA NA
28.11.2011 21:20:00 981.5 12.9 28 20 NA NA
28.11.2011 21:30:00 981.6 12.9    27.9 20 NA NA
28.11.2011 21:40:00 981.7 12.88 27.9 20 NA NA
28.11.2011 21:50:00 981.7 12.87 27.8 20 NA NA
28.11.2011 22:00:00 981.7 12.86 27.7 20 NA NA
28.11.2011 22:10:00 981.8 12.85 27.6 20 NA NA
28.11.2011 22:20:00 981.8 12.84 27.5 20 NA NA
28.11.2011 22:30:00 981.8 12.83 27.5 20 NA NA

Thank you

	[[alternative HTML version deleted]]


From shivi.bhatia at safexpress.com  Tue Feb 23 08:34:08 2016
From: shivi.bhatia at safexpress.com (SHIVI BHATIA)
Date: Tue, 23 Feb 2016 13:04:08 +0530
Subject: [R] Warning Message With WordCloud
Message-ID: <000b01d16e0c$87ab52f0$9701f8d0$@safexpress.com>

Dear Team,

 

I am working on Wordcloud package for one of my projects. While it running
fine it is not showing the top most values in the output as it should. I
have ran it earlier and it was fine but now there seems to be an issue. 

 

The wordcloud image shows the values which are appearing only once or twice.
Below is the code I have used:

 

wordcloud(nnn,freq,random.order =F,colors=brewer.pal(8,"Dark2"),

          scale = c(5.5,0.5),min.freq = 50,

          max.words = Inf) 

 

There are words which are repetitive like 1000 times but none of those
appear. Not sure where I doing it wrong have checked multiple stats exchange
forum and help in r on wordcloud. 

 

This is really urgent. I have tried installing tm package. 

 

Thanks, Shivi

Mb: 9891002021

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160223/ec44bbd5/attachment.pl>

From pawel.a.broda at gmail.com  Tue Feb 23 08:44:40 2016
From: pawel.a.broda at gmail.com (=?UTF-8?Q?Pawe=C5=82_Broda?=)
Date: Mon, 22 Feb 2016 23:44:40 -0800 (PST)
Subject: [R] Password-Shiny
In-Reply-To: <CAAM-fZ6LcrQnyKrxGkqj5cD3c5qX--9coLFMkfTfuhvfqXwrgA@mail.gmail.com>
References: <CAAM-fZ6LcrQnyKrxGkqj5cD3c5qX--9coLFMkfTfuhvfqXwrgA@mail.gmail.com>
Message-ID: <080750a1-5cac-4737-a270-8a8d429e9e2d@googlegroups.com>

You could try methods from this blog post: 
http://ipub.com/shiny-password-protect/ 

From rickwargo at epicminds.com  Mon Feb 22 19:03:18 2016
From: rickwargo at epicminds.com (Rick Wargo)
Date: Mon, 22 Feb 2016 18:03:18 +0000
Subject: [R] [R-pkgs] New Package: lrequire v0.1.3 - use modules to
 encapsulate and cache your R scripts
Message-ID: <D7A2070C-E8E1-4645-BAFB-28E9BF19C653@wargo.net>

Dear R Users,

I am happy to announce the initial release (v0.1.3) of lrequire<https://cran.r-project.org/web/packages/lrequire/>, now available on CRAN.

https://cran.r-project.org/web/packages/lrequire/

lrequire supports modularization of R Scripts, enabling encapsulation of information and caching of scripts. This is very similar to the require()<https://nodejs.org/api/modules.html> support in node.js<https://nodejs.org/>.

Use of lrequire encourages separation of responsibility and using modules to encapsulate specific functionality. This leads to more easily-maintained scripts and encourages reuse.
lrequire also cache loaded modules (scripts) such that the next load (source) of the script does not execute its contents, unless specified. For example, if a module is built around sourcing a slowly-changing dataset that is time-consuming to retrieve, frequent reloads of the module will only return the cached copy of the data, saving the time expense. I found this very useful for developing dashboard components ? lrequire permitted me the freedom to keep tweaking the UI without having to wait for the live reload of the data.

How It Works

Goal: build a reusable module to welcome an individual. Any environment artifacts necessary to build that module are encapsulated in the lrequire() call and only the functionality is returned.

For example:

________________________________

File: welcome.R

data.that.will.not.be.exposed <- 'some work'

hello <- function(person.name) {
  return (paste0('Hello, ', person.name, '!'))
}

module.exports = hello

________________________________

File: main.R

hello <- lrequire(welcome)

hello('Rick')

________________________________

Note that the variable declared in welcome.R will not be visible in main.R only the hello() function. Multiple pieces of information can be exposed by returning a list() object in module.exports. Refer to the documentation for details.

All the best,
Rick Wargo
https://linkedin.com/in/rickwargo/
https://www.rickwargo.com/
@rickwargo


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From aleminesh57 at gmail.com  Tue Feb 23 09:37:13 2016
From: aleminesh57 at gmail.com (Betty Betty)
Date: Tue, 23 Feb 2016 09:37:13 +0100
Subject: [R] mvProbit error message
Message-ID: <CAOA_h3+9kKrALJMio3W6GNhfxugaynHm=HjeCx1mTiTXAZexMw@mail.gmail.com>

Dear All,
I am running the mvProbit model to estimate five equation probit models. In
my data all the dependent variables are dichotomous with values 0/1 and
lables TRUE/FALSE. The explanatory variables are composed of catagorical
and countinous variables. I specified the model as follows

Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~ x1+x2+x3+......+.x11,data=mydata)
summary(Result)

However, i get an error message "...Error in mvProbit(cbind(y1,y2,y3,y4,y5)
~:all dependent variables must be either 0,1,TRUE, or FALSE)

I have checked all the dependent variables and it is coded 0/1 and lables
TRUE/FALSE.
Ofcourse there are two missing observation and I attempted to handle that
with na.action=na.omit but even that didnt solve the problem. My second
attempt was to tell r that the dichotomous dependent variables and the
catagorical independent variables as factor as follows

mydata$y1<-factor(mydata$y1)
...
...
..
.
mydata$x3<-factor(mydata$x3)
But still problem not solved. How would I solve this problem?
Thank you!

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Feb 23 15:50:12 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 23 Feb 2016 09:50:12 -0500
Subject: [R] Query in R.
In-Reply-To: <CALEe9tGgP7VGvwx1XG+heHh4HmAzRymy8H8rWi2WmkKw_zwoJg@mail.gmail.com>
References: <CALEe9tGgP7VGvwx1XG+heHh4HmAzRymy8H8rWi2WmkKw_zwoJg@mail.gmail.com>
Message-ID: <56CC71A4.2080201@gmail.com>

On 23/02/2016 7:38 AM, Rachana Bagde wrote:
> Can anyone please solve this query.
>
> http://stackoverflow.com/questions/35577484/cpquery-of-bnlearn-gives-0-for-every-event-and-evidence-in-r


This is just spam.  If you want to ask a question here, please take the 
time to formulate it properly.

Duncan Murdoch


From petr.pikal at precheza.cz  Tue Feb 23 15:53:11 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 23 Feb 2016 14:53:11 +0000
Subject: [R] mvProbit error message
In-Reply-To: <CAOA_h3+9kKrALJMio3W6GNhfxugaynHm=HjeCx1mTiTXAZexMw@mail.gmail.com>
References: <CAOA_h3+9kKrALJMio3W6GNhfxugaynHm=HjeCx1mTiTXAZexMw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010B53@SRVEXCHMBX.precheza.cz>

Hi

It shall work, I do not see any problem in the code. So you have to persuade us that you checked your data properly e.g. by posting result of

str(mydata)

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Betty
> Betty
> Sent: Tuesday, February 23, 2016 9:37 AM
> To: r-help at r-project.org
> Subject: [R] mvProbit error message
>
> Dear All,
> I am running the mvProbit model to estimate five equation probit
> models. In my data all the dependent variables are dichotomous with
> values 0/1 and lables TRUE/FALSE. The explanatory variables are
> composed of catagorical and countinous variables. I specified the model
> as follows
>
> Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~
> x1+x2+x3+......+.x11,data=mydata)
> summary(Result)
>
> However, i get an error message "...Error in
> mvProbit(cbind(y1,y2,y3,y4,y5) ~:all dependent variables must be either
> 0,1,TRUE, or FALSE)
>
> I have checked all the dependent variables and it is coded 0/1 and
> lables TRUE/FALSE.
> Ofcourse there are two missing observation and I attempted to handle
> that with na.action=na.omit but even that didnt solve the problem. My
> second attempt was to tell r that the dichotomous dependent variables
> and the catagorical independent variables as factor as follows
>
> mydata$y1<-factor(mydata$y1)
> ...
> ...
> ..
> .
> mydata$x3<-factor(mydata$x3)
> But still problem not solved. How would I solve this problem?
> Thank you!
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ajdamico at gmail.com  Tue Feb 23 16:03:28 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 23 Feb 2016 10:03:28 -0500
Subject: [R] .Internal(La_rs(x,
 FALSE)) crashes R after long (reproducible) script on windows only
In-Reply-To: <56CC5D2C.9040405@gmail.com>
References: <CAOwvMDy9a5f2FYeu-K1FtbNW-kOd99xL=tG6JxxMcXJcVUY23w@mail.gmail.com>
	<56CC5D2C.9040405@gmail.com>
Message-ID: <CAOwvMDx234W-3V63h+41-ob5C4LXd-_o+8qZMT4LaPONQSnOMQ@mail.gmail.com>

hi, thank you,

at the point that the corruption exists, the line
`.Internal(La_rs(x,FALSE))` actually breaks without needing `eigen`

i have provided a reproducible example but agree it might not be minimal --
i did try removing various sections, each time the bug unfortunately
vanished.  note the february 22nd edit: even interspersing the script with
the line that triggers the crash prevents the crash in the first place!

i think this occurs in C and not R, and would appreciate pointers about how
one might do that?  the only advice i've have is rebuilding R with a debug
build and gdb, but this seems like a huge lift --  are there any shortcuts
here for someone mostly unfamiliar with C code and even setup?  general
advice on this thread might also help me crack this case  :)

stackoverflow.com/questions/35455135/general-suggestions-on-debugging-internal-in-r

thanks for your time

On Tue, Feb 23, 2016 at 8:22 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/02/2016 7:49 AM, Anthony Damico wrote:
>
>> hi, does anybody have a clue why .Internal(La_rs(x,FALSE)) is getting
>> corrupted (actual detonation occurs within La_solve_cmplx within Lapack.c)
>> on windows but not mac/unix?
>>
>> i have provided two (long) scripts that reproduce the problem and a third
>> script modified to trigger the crash that unfortunately does not reproduce
>> the problem
>>
>>
>> http://stackoverflow.com/questions/35447971/internalla-rsx-false-crashes-r-after-long-reproducible-script-on-windows
>>
>
> Just two comments:
>
>  - Your post suggests you're calling .Internal() yourself, but that's not
> the case.  So your question should be about why eigen() crashes R.
>
>  - If you need a long script to trigger the error, I'd assume there's
> something wrong in that script. Your script uses several contributed
> packages, so the problem could be there. Shorten it to a minimal
> reproducible example that doesn't use any contributed packages.  If you
> can't leave out the packages, try to reduce it to just one, and ask the
> maintainer of that package about it.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Feb 23 16:13:53 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 23 Feb 2016 15:13:53 +0000
Subject: [R] Code for finding successive mean
In-Reply-To: <CAA0akYxvF_H7MvsvrUP9pZhAnqTihZv4wv8-Ez=oV4jEfWK71Q@mail.gmail.com>
References: <CAA0akYxvF_H7MvsvrUP9pZhAnqTihZv4wv8-Ez=oV4jEfWK71Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010B8B@SRVEXCHMBX.precheza.cz>

Hi

see ?cutPOSIXt help page.

something like

aggregate(yourdata, list(cut(datetime, "30 mins")), mean)

shall do the trick.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kwabena
> Fosu-Amankwah
> Sent: Tuesday, February 23, 2016 7:24 AM
> To: r-help at r-project.org
> Subject: [R] Code for finding successive mean
>
> Hi am Kwabena,
>
> I would be very grateful if someone can help me with the code or script
> on how to find successive mean at 30 minutes interval for the set of
> data
> below:
>
> Date/Time PR     SW TP  SM SHF CO2
> 28.11.2011 17:39:49 978.4 13.15 30.5 20 NA NA
> 28.11.2011 17:50:00 978.5 13.11 30.4 20 NA NA
> 28.11.2011 18:00:00 978.8 13.14 30.3 20 NA NA
> 28.11.2011 18:10:00 979 13.07 30.1 20 NA NA
> 28.11.2011 18:20:00 979.2 13.1 30 20 NA NA
> 28.11.2011 18:30:00 979.4 13.09 29.8 20 NA NA
> 28.11.2011 18:40:00 979.5 13.08 29.6 20 NA NA
> 28.11.2011 18:50:00 979.5 13.06 29.5 20 NA NA
> 28.11.2011 19:00:00 979.6 13.06 29.4 20 NA NA
> 28.11.2011 19:10:00 979.7 13.05 29.3 20 NA NA
> 28.11.2011 19:20:00 979.9 13.03 29.2 20 NA NA
> 28.11.2011 19:30:00 980 13 29.1 20 NA NA
> 28.11.2011 19:40:00 980 13.03 29 20 NA NA
> 28.11.2011 19:50:00 980.1 13.03 28.9 20 NA NA
> 28.11.2011 20:00:00 980.3 13      28.8 20 NA NA
> 28.11.2011 20:10:00 980.5 12.97 28.7 20 NA NA
> 28.11.2011 20:20:00 980.8 12.96 28.6 20 NA NA
> 28.11.2011 20:30:00 981.1 12.95 28.5 20 NA NA
> 28.11.2011 20:40:00 981.1 12.95 28.4 20 NA NA
> 28.11.2011 20:50:00 981.2 12.94 28.3 20 NA NA
> 28.11.2011 21:00:00 981.3 12.93 28.2 20 NA NA
> 28.11.2011 21:10:00 981.3 12.92 28.1 20 NA NA
> 28.11.2011 21:20:00 981.5 12.9 28 20 NA NA
> 28.11.2011 21:30:00 981.6 12.9    27.9 20 NA NA
> 28.11.2011 21:40:00 981.7 12.88 27.9 20 NA NA
> 28.11.2011 21:50:00 981.7 12.87 27.8 20 NA NA
> 28.11.2011 22:00:00 981.7 12.86 27.7 20 NA NA
> 28.11.2011 22:10:00 981.8 12.85 27.6 20 NA NA
> 28.11.2011 22:20:00 981.8 12.84 27.5 20 NA NA
> 28.11.2011 22:30:00 981.8 12.83 27.5 20 NA NA
>
> Thank you
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Tue Feb 23 17:05:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Feb 2016 08:05:54 -0800
Subject: [R] multiple linear regression with quadratic function
In-Reply-To: <DDDDFD4A9D76184F8562ACE0629AD471E7053237@EXCHMBX03.fed.cclrc.ac.uk>
References: <DDDDFD4A9D76184F8562ACE0629AD471E7053237@EXCHMBX03.fed.cclrc.ac.uk>
Message-ID: <CAGxFJbQ=70Lb-_HTU60HdjsRvZ0Jvd9f_3vav-i5H_9fKanopw@mail.gmail.com>

Inline.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 23, 2016 at 2:42 AM,  <james.foadi at diamond.ac.uk> wrote:
> Dear R community,
> this is probably a well-known topic to some of you, but I am not well into it
> and would like some clarifications or even jus some suggestions.
>
> I have a quadratic scalar field:
>
>         F(x,y)=K*exp(-(a*x^2+b*y^2+c*x*y))
>
> I also have a random set of positive x,y values and related F(x,y) values.
> It seems reasonable to estimate the parameters K, a, b, c with a linear regression,
> using the log of both sides of the equation.

Not necessarily. It depends on how the error term enters the model.

I suggest you consult with a local statistician or post as Peter
suggested. You appear to be out of your statistical depth here.


>
> What worries me, though, is the interaction term, c*x*y.
>
> Are there well-known issues on the application of linear regression to cases like this one?
>
> Thanks in advance for your answers.
>
> James
>
> --
> This e-mail and any attachments may contain confidenti...{{dropped:8}}


From bgunter.4567 at gmail.com  Tue Feb 23 17:10:35 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Feb 2016 08:10:35 -0800
Subject: [R] lme() - MEEM error (singularity in Backsolve) due to
 user-specified contrasts amount
In-Reply-To: <BLU436-SMTP143B6B6CF58A6851321DF3FA0A40@phx.gbl>
References: <BLU436-SMTP143B6B6CF58A6851321DF3FA0A40@phx.gbl>
Message-ID: <CAGxFJbQRcCdG=1KnoJdTWo=_aF79qQftGXDE8Gmb2xdn+12_KA@mail.gmail.com>

You are probably overfitting.

This *IS* a statistical and not an R issue, and so does not belong
here. You MAY get useful help by posting on the R-SIG-mixed-models
list, however. But PLEASE post in *plain text*, not HTML, as the
posting guide asks.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 23, 2016 at 2:34 AM, Daniel Preciado <danprec at hotmail.com> wrote:
> Hello all,
>
> I posted this question also in Stackoverflow, but in hindsight I realise it probably fits better here. I am trying to use lme() to fit and compare different models to data from an experiment in a repeated measures design. My dependent variable is response time (RT, in milliseconds); and I have 2 factors: F_A (2 levels) and F_B (3 Levels). For F_B, I have specified the following contrasts:
> F_B_C1 <- c(1, -1, 0)      # Contrast prize 1 and 2 levels
> F_B_C2 <- c(1, 0, -1)      # Contrast prize 1 with Neutral (no prize)
> F_B_C3 <- c(1, 0, -1)      # Contrast prize 2 with Neutral (no prize)
> F_B_C4 <- c(1, 1, -2)      # Contrast prize with Neutral
> contrasts(Data$F_B, how.many=4) <- cbind(F_B_C1, F_B_C2, F_B_C3, F_B_C4)
> Conditions 1 and 2 are 2 levels of the same manipulation, condition 3 is a neutral control. I am interested in the effect of each level (individually) on RT, and overall in the difference between the experimental manipulation (pooling the first 2 conditions of factor B) and the control condition (final condition of factor B).
>
> I defined the lme() models step-wise, starting with a Baseline model, and then updating that one to include each factor individually, and finally the interaction:
> RT_Base <- lme(RT ~ 1, random = ~1|SubjID/F_A/F_B, data=Data, method="ML")  #Baseline model
> RT_F_A <- update(RT_Base, .~. + F_A)            #Baseline + F_A
> RT_F_B <- update(RT_F_A, .~. + F_B)             #(Baseline+F_A) + F_B
> RT_Full <- update(RT_F_B, .~. + F_A:F_B)        #Full model (+ interaction)
> However, when I execute the code involving F_B, I get an
> "Error in MEEM (...): Singularity in Backsolve at level 0, block 1).
> I can still inspect the results of the model, but I would like to understand where is this error coming from, what does it mean, and how to avoid it. Furthermore, I realized that if I reduce the amount of contrasts to the default 2, the code runs without any error, so I can only assume that it has something to do with the user-specified comparison pairs. Also, the specified contrasts are not displayed (only the default first 2).
>
> I also read in some answer that the intercept needed to be suppressed in order to prevent this error (by adding RT ~ 0+Factors to the model formulae). I tried that, but it produces the same error.
>
> I would appreciate any feedback regarding this, Thanks!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Feb 23 17:23:30 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 23 Feb 2016 11:23:30 -0500
Subject: [R] Warning Message With WordCloud
In-Reply-To: <000b01d16e0c$87ab52f0$9701f8d0$@safexpress.com>
References: <000b01d16e0c$87ab52f0$9701f8d0$@safexpress.com>
Message-ID: <F80B6E8C-670A-4A7F-9EB6-76EB8AF793E9@utoronto.ca>

Assuming you have confirmed that your function parameters are correct, the problem likely lies with your data. Therefore a good strategy is to revert to a known good state and systematically work from there. Start from your working example and gradually change that into your real data, evaluating each step in turn.


B.


On Feb 23, 2016, at 2:34 AM, SHIVI BHATIA <shivi.bhatia at safexpress.com> wrote:

> Dear Team,
> 
> 
> 
> I am working on Wordcloud package for one of my projects. While it running
> fine it is not showing the top most values in the output as it should. I
> have ran it earlier and it was fine but now there seems to be an issue. 
> 
> 
> 
> The wordcloud image shows the values which are appearing only once or twice.
> Below is the code I have used:
> 
> 
> 
> wordcloud(nnn,freq,random.order =F,colors=brewer.pal(8,"Dark2"),
> 
>          scale = c(5.5,0.5),min.freq = 50,
> 
>          max.words = Inf) 
> 
> 
> 
> There are words which are repetitive like 1000 times but none of those
> appear. Not sure where I doing it wrong have checked multiple stats exchange
> forum and help in r on wordcloud. 
> 
> 
> 
> This is really urgent. I have tried installing tm package. 
> 
> 
> 
> Thanks, Shivi
> 
> Mb: 9891002021
> 
> 
> 
> This e-mail is confidential. It may also be legally privileged. If you are not the addressee you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return e-mail. Internet communications cannot be guaranteed to be timely, secure, error or virus-free. The sender does not accept liability for any errors or omissions.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aporter at theplanetforward.com  Tue Feb 23 17:02:28 2016
From: aporter at theplanetforward.com (Ashley Porter)
Date: Tue, 23 Feb 2016 10:02:28 -0600
Subject: [R] R Software Program Help
Message-ID: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>

Good Morning,

I wanted to reach out as I am looking to learn more about the R Project / R
Statistical Programming software, particularly as it's been utilizing in
power plant industries. I work in the energy industry and my clients are
starting to look for Risk Analysts proficient in this tool, and I find
myself unaware of what this tool is. Any information or help would be
greatly appreciated.

Warmly,


*Ashley Porter | Director of Recruiting*
D: 708-505-4087 *|* C: 708-705-0802* |* aporter at theplanetforward.com
888-845-2539 *|* F: 708-682-3073 *|* www.theplanetforward.com
800 Hillgrove Avenue, Suite 200, Western Springs, IL 60558
http://www.linkedin.com/in/ashleymarieporter

*Follow Us*:
<https://www.linkedin.com/company/planet-forward?trk=company_name>
<https://www.facebook.com/theplanetforward>
<https://twitter.com/planetforward1>

*Planet Forward Jobs*: http://www.theplanetforward.com/jobs/

Chicago | Cleveland | San Francisco | Pensacola | London



Sent with MailTrack
<https://mailtrack.io/install?source=signature&lang=en&referral=aporter at theplanetforward.com&idSignature=22>

	[[alternative HTML version deleted]]


From eikethaysen at gmail.com  Tue Feb 23 17:00:14 2016
From: eikethaysen at gmail.com (Eike Marie Thaysen)
Date: Tue, 23 Feb 2016 17:00:14 +0100
Subject: [R] axis break in R
Message-ID: <CAJx9nazHMwUnquF1BrwAVHE9CmRmGJ1xW0yTgkLUcsyHUHYMyg@mail.gmail.com>

Hello,
I want to break the y-axis on one of my plots. I read this is possible- but
apparently only with the plotrix package that requieres R version 3.6-1? I
cannot seem to find that version on the R homepage.. it is a version you
have to pay for? Are there any other possebilities to do it (I am currently
running (for R version 3.1.2) )
Thank you,
Eike

	[[alternative HTML version deleted]]


From scolwell at uoguelph.ca  Tue Feb 23 18:10:07 2016
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Tue, 23 Feb 2016 12:10:07 -0500 (EST)
Subject: [R] R packages for Mac Users
In-Reply-To: <173185594.2610855.1456247346907.JavaMail.zimbra@uoguelph.ca>
Message-ID: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>


Hello,

Does anyone know if all the R packages that are available for Windows users are also available for Mac users? 

Thank you,

Scott

-- 
Scott R. Colwell, Ph.D.
Associate Professor, Dept. of Mkt/Cons Studies
Adjunct Professor, Dept. of Psychology
University of Guelph
Guelph, Ontario, Canada, N1G 2W1


From NordlDJ at dshs.wa.gov  Tue Feb 23 18:10:03 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 23 Feb 2016 17:10:03 +0000
Subject: [R] R Software Program Help
In-Reply-To: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>
References: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662EDFB38B@WAXMXOLYMB025.WAX.wa.lcl>

If you google "R Statistical Programming software" you will find all the information you could possibly want.  In particular, for your purposes you should probably start with 

https://www.r-project.org/

and read the "About" section.  Then follow other links as needed. 

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashley
> Porter
> Sent: Tuesday, February 23, 2016 8:02 AM
> To: r-help at r-project.org
> Subject: [R] R Software Program Help
> 
> Good Morning,
> 
> I wanted to reach out as I am looking to learn more about the R Project / R
> Statistical Programming software, particularly as it's been utilizing in power
> plant industries. I work in the energy industry and my clients are starting to
> look for Risk Analysts proficient in this tool, and I find myself unaware of
> what this tool is. Any information or help would be greatly appreciated.
> 
> Warmly,
> 
> 
> *Ashley Porter | Director of Recruiting*
> D: 708-505-4087 *|* C: 708-705-0802* |* aporter at theplanetforward.com
> 888-845-2539 *|* F: 708-682-3073 *|* www.theplanetforward.com
> 800 Hillgrove Avenue, Suite 200, Western Springs, IL 60558
> http://www.linkedin.com/in/ashleymarieporter
> 
> *Follow Us*:
> <https://www.linkedin.com/company/planet-
> forward?trk=company_name>
> <https://www.facebook.com/theplanetforward>
> <https://twitter.com/planetforward1>
> 
> *Planet Forward Jobs*: http://www.theplanetforward.com/jobs/
> 
> Chicago | Cleveland | San Francisco | Pensacola | London
> 
> 
> 
> Sent with MailTrack
> <https://mailtrack.io/install?source=signature&lang=en&referral=aporter at t
> heplanetforward.com&idSignature=22>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Tue Feb 23 18:16:25 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 23 Feb 2016 11:16:25 -0600
Subject: [R] R Software Program Help
In-Reply-To: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>
References: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>
Message-ID: <CAAJSdjiPdQhcNf6OqerYhWQL6ReNE9Q7BKA9E1UO5ftpo40U9Q@mail.gmail.com>

On Tue, Feb 23, 2016 at 10:02 AM, Ashley Porter <
aporter at theplanetforward.com> wrote:

> Good Morning,
>
> I wanted to reach out as I am looking to learn more about the R Project / R
> Statistical Programming software, particularly as it's been utilizing in
> power plant industries. I work in the energy industry and my clients are
> starting to look for Risk Analysts proficient in this tool, and I find
> myself unaware of what this tool is. Any information or help would be
> greatly appreciated.
>
> Warmly,
>
>
> *Ashley Porter | Director of Recruiting*
>

?In a nutshell, it is a algorithmic programming language? with an emphasis
on statistics. If you have heard of the SAS language, R is used for similar
needs. One of the main pluses of R is CRAN - The Comprehensive R Archive
Network. This is a large set of statistical packages, which can be used as
a library. A good web site is https://cran.revolutionanalytics.com/ to
start. A search of "r language review" will get you some good hits from
sites such as InfoWorld and NY Times as well as the usual "geek" sites.


-- 
The man has the intellect of a lobotomized turtle.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From Douglas.Federman at utoledo.edu  Tue Feb 23 18:11:18 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Tue, 23 Feb 2016 17:11:18 +0000
Subject: [R] axis break in R
In-Reply-To: <CAJx9nazHMwUnquF1BrwAVHE9CmRmGJ1xW0yTgkLUcsyHUHYMyg@mail.gmail.com>
References: <CAJx9nazHMwUnquF1BrwAVHE9CmRmGJ1xW0yTgkLUcsyHUHYMyg@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AFF2BB3@msgdb20.utad.utoledo.edu>


The current version of R is 3.2.3 and is available on the website.  You should update.  The current version of plotrix is 3.6-1

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eike Marie Thaysen
Sent: Tuesday, February 23, 2016 11:00 AM
To: r-help at r-project.org
Subject: [R] axis break in R

Hello,
I want to break the y-axis on one of my plots. I read this is possible- but
apparently only with the plotrix package that requieres R version 3.6-1? I
cannot seem to find that version on the R homepage.. it is a version you
have to pay for? Are there any other possebilities to do it (I am currently
running (for R version 3.1.2) )
Thank you,
Eike

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Feb 23 18:23:15 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 23 Feb 2016 11:23:15 -0600
Subject: [R] R packages for Mac Users
In-Reply-To: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
References: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
Message-ID: <38E38312-CD51-4AAB-94B0-7D66851B51F4@me.com>


> On Feb 23, 2016, at 11:10 AM, Scott Colwell <scolwell at uoguelph.ca> wrote:
> 
> 
> Hello,
> 
> Does anyone know if all the R packages that are available for Windows users are also available for Mac users? 
> 
> Thank you,
> 
> Scott


Hi,

In general, yes, if the package is available from CRAN, but there are some exceptions, where you may have to install a package from source, rather than from a pre-compiled binary. In that case, if the package is "pure R", there should not be any issues. If there is C/C++ or FORTRAN source code in the package, you will need to have additional tools installed on your Mac (e.g. XCode, etc.) to install the package.

You can check the CRAN page for a particular package and see what is available.

Some packages are not on CRAN and may be available via other sources, like GitHub, etc. You would have to look at each, to get a sense for any issues there.

There are also two Mac specific resources that you should be aware of, if not already:

  R for Mac OS X FAQ:
  https://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html

  R-SIG-Mac:
  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

Regards,

Marc Schwartz


From pdalgd at gmail.com  Tue Feb 23 18:23:43 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 Feb 2016 18:23:43 +0100
Subject: [R] R Software Program Help
In-Reply-To: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>
References: <CADjbgi5yUREbS3=RXNvLAr1azA6-Oj75vj5H+10Ozy5FS0MWOA@mail.gmail.com>
Message-ID: <A4CA4A93-2E3C-4FC6-A670-5F85BD0BA266@gmail.com>


On 23 Feb 2016, at 17:02 , Ashley Porter <aporter at theplanetforward.com> wrote:

> Good Morning,
> 
> I wanted to reach out as I am looking to learn more about the R Project / R
> Statistical Programming software, particularly as it's been utilizing in
> power plant industries. I work in the energy industry and my clients are
> starting to look for Risk Analysts proficient in this tool, and I find
> myself unaware of what this tool is. Any information or help would be
> greatly appreciated.
> 

Well, from your perspective, R is basically like SAS or Stata, just more flexible; maybe more challenging to master, but also quite a bit more fun. 

R is gaining quite some traction in the Data Science and Machine Learning areas, mainly due to visualization tools and data munging facilities, but also due to availability of a wide variety of modern statistical procedures. It has for quite some time been the weapon of choice when attacking methodology issues in Statistics at the research level.

- Peter D.


> Warmly,
> 
> 
> *Ashley Porter | Director of Recruiting*
> D: 708-505-4087 *|* C: 708-705-0802* |* aporter at theplanetforward.com
> 888-845-2539 *|* F: 708-682-3073 *|* www.theplanetforward.com
> 800 Hillgrove Avenue, Suite 200, Western Springs, IL 60558
> http://www.linkedin.com/in/ashleymarieporter
> 
> *Follow Us*:
> <https://www.linkedin.com/company/planet-forward?trk=company_name>
> <https://www.facebook.com/theplanetforward>
> <https://twitter.com/planetforward1>
> 
> *Planet Forward Jobs*: http://www.theplanetforward.com/jobs/
> 
> Chicago | Cleveland | San Francisco | Pensacola | London
> 
> 
> 
> Sent with MailTrack
> <https://mailtrack.io/install?source=signature&lang=en&referral=aporter at theplanetforward.com&idSignature=22>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Tue Feb 23 18:28:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 Feb 2016 18:28:06 +0100
Subject: [R] R packages for Mac Users
In-Reply-To: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
References: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
Message-ID: <617AC344-B7B5-4F0D-BD4E-FA85E46EB8E1@gmail.com>


On 23 Feb 2016, at 18:10 , Scott Colwell <scolwell at uoguelph.ca> wrote:

> 
> Hello,
> 
> Does anyone know if all the R packages that are available for Windows users are also available for Mac users? 
> 

In a word: Yes.

In two words: Yes, mostly.

As long as a package doesn't rely on Windows-specific features, or on interfacing to programs that are only available for Windows, it will usually work on Mac or Linux or ... as well.

-pd


> Thank you,
> 
> Scott
> 
> -- 
> Scott R. Colwell, Ph.D.
> Associate Professor, Dept. of Mkt/Cons Studies
> Adjunct Professor, Dept. of Psychology
> University of Guelph
> Guelph, Ontario, Canada, N1G 2W1
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Tue Feb 23 19:12:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 23 Feb 2016 10:12:11 -0800
Subject: [R] R packages for Mac Users
In-Reply-To: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
References: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
Message-ID: <E0EED6BB-B17F-48F9-BE2E-DF89179DD1FB@dcn.davis.ca.us>

"All" is a pretty stringent test for a herd of cats.  If you constrain to packages on CRAN, there are currently about 300 binaries for Windows that don't show up in the Mac list, and about 40 that are in the Mac list but not the Windows list. There are about 8000 total.  Many times the non matched packages are OS specific and it would not make sense for them to be on both systems. 
-- 
Sent from my phone. Please excuse my brevity.

On February 23, 2016 9:10:07 AM PST, Scott Colwell <scolwell at uoguelph.ca> wrote:
>
>Hello,
>
>Does anyone know if all the R packages that are available for Windows
>users are also available for Mac users? 
>
>Thank you,
>
>Scott
>
>-- 
>Scott R. Colwell, Ph.D.
>Associate Professor, Dept. of Mkt/Cons Studies
>Adjunct Professor, Dept. of Psychology
>University of Guelph
>Guelph, Ontario, Canada, N1G 2W1
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Feb 23 19:25:23 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 Feb 2016 19:25:23 +0100
Subject: [R] R packages for Mac Users
In-Reply-To: <E0EED6BB-B17F-48F9-BE2E-DF89179DD1FB@dcn.davis.ca.us>
References: <32370033.2613787.1456247407512.JavaMail.zimbra@uoguelph.ca>
	<E0EED6BB-B17F-48F9-BE2E-DF89179DD1FB@dcn.davis.ca.us>
Message-ID: <86B41316-BEBB-4C6E-A65A-5086893413B0@gmail.com>


> On 23 Feb 2016, at 19:12 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> "All" is a pretty stringent test for a herd of cats.

Hehehe...

[Fades to a grin, leaving only a paw print.]

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From torvon at gmail.com  Tue Feb 23 20:13:01 2016
From: torvon at gmail.com (Torvon)
Date: Tue, 23 Feb 2016 20:13:01 +0100
Subject: [R] Loading large .pxt and .asc datasets causes issues.
Message-ID: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>

Hi,

I want to load a dataset into R. This dataset is available in two formats:
.XPT and .ASC. The dataset is available at
http://www.cdc.gov/brfss/annual_data/annual_2006.htm.

They are about 40mb zipped, and about 500mb unzipped.

I can get the .xpt data to load, using:

> library(hmisc)
> data <- sasxport.get("CDBRFS06.XPT")

The data look fine, no error messages. However, the data only contains 302
columns, which is less than it should have (according to the
documentation). It does not contain my variables of interest, so either the
documentation or the data file is wrong, and I want to make sure it's not
the data file.

Hence I wanted to see if I get the same results loading the .ASC file.
However, multiple ways to do so have failed.

> library(adehabitat)
> import.asc("CDBRFS06.asc")

Results in:
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
: scan() expected 'a real', got '1191.8808943.38209868648.960119'

> library(SDMTools)
> read.asc("CDBRFS06.asc")

Results in:
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
: scan() expected 'a real', got '1191.8808943.38209868648.960119' In
addition: Warning messages: 1: In scan(file, what, nmax, sep, dec, quote,
skip, nlines, na.strings, : number of items read is not a multiple of the
number of columns 2: In scan(file, what, nmax, sep, dec, quote, skip,
nlines, na.strings, : number of items read is not a multiple of the number
of columns 3: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
na.strings, : number of items read is not a multiple of the number of
columns 4: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
na.strings, : number of items read is not a multiple of the number of
columns 5: In scan(file, nmax = nl * nc, skip = 6, quiet = TRUE) : NAs
introduced by coercion to integer range

Thank you for your help.
   Eiko

	[[alternative HTML version deleted]]


From rhelp at eoos.dds.nl  Tue Feb 23 22:07:52 2016
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Tue, 23 Feb 2016 22:07:52 +0100
Subject: [R] Loading large .pxt and .asc datasets causes issues.
In-Reply-To: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>
References: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>
Message-ID: <56CCCA28.7060203@eoos.dds.nl>

First, the file does contain 302 columns; the variable layout 
(http://www.cdc.gov/brfss/annual_data/2006/varlayout_table_06.htm) 
contains 302 columns. So, reading the SASS file probably works correctly.

Second, the read.asc function you use is for reading geographic raster 
files, not fixed width files.

Below, I show how you could read the file using the LaF package (sorry 
for the long dump of variable files; copy-pasted them from the page 
linked to above):

columns <- "StartingColumn  VariableName    FieldLength
1    _STATE    2
3    _GEOSTR    2
5    _DENSTR2    1
6    PRECALL    1
7    REPNUM    5
12    REPDEPTH    2
14    FMONTH    2
16    IDATE    8
16    IMONTH    2
18    IDAY    2
20    IYEAR    4
24    INTVID    3
27    DISPCODE    3
30    SEQNO    10
30    _PSU    10
40    NATTMPTS    2
42    NRECSEL    6
48    NRECSTR    9
57    CTELENUM    1
58    CELLFON1    1
59    PVTRESID    1
60    NUMADULT    2
62    NUMMEN    2
64    NUMWOMEN    2
73    GENHLTH    1
74    PHYSHLTH    2
76    MENTHLTH    2
78    POORHLTH    2
80    HLTHPLAN    1
81    PERSDOC2    1
82    MEDCOST    1
83    CHECKUP    1
84    EXERANY2    1
85    DIABETE2    1
86    LASTDEN3    1
87    RMVTETH3    1
88    DENCLEAN    1
89    CVDINFR3    1
90    CVDCRHD3    1
91    CVDSTRK3    1
92    ASTHMA2    1
93    ASTHNOW    1
94    QLACTLM2    1
95    USEEQUIP    1
96    SMOKE100    1
97    SMOKDAY2    1
98    STOPSMK2    1
99    AGE    2
101    HISPANC2    1
102    MRACE    6
108    ORACE2    1
109    MARITAL    1
110    CHILDREN    2
112    EDUCA    1
113    EMPLOY    1
114    INCOME2    2
116    WEIGHT2    4
120    HEIGHT3    4
124    CTYCODE    3
132    NUMHHOL2    1
133    NUMPHON2    1
134    TELSERV2    1
135    SEX    1
136    PREGNANT    1
137    VETERAN    1
138    DRNKANY4    1
139    ALCDAY4    3
142    AVEDRNK2    2
144    DRNK3GE5    2
146    MAXDRNKS    2
148    FLUSHOT3    1
149    FLUSPRY2    1
162    PNEUVAC3    1
163    HEPBVAC    1
164    HEPBRSN    1
165    FALL3MN2    2
167    FALLINJ2    2
169    SEATBELT    1
170    DRINKDRI    2
172    HADMAM    1
173    HOWLONG    1
174    PROFEXAM    1
175    LENGEXAM    1
176    HADPAP2    1
177    LASTPAP2    1
178    HADHYST2    1
179    PSATEST    1
180    PSATIME    1
181    DIGRECEX    1
182    DRETIME    1
183    PROSTATE    1
184    BLDSTOOL    1
185    LSTBLDS2    1
186    HADSIGM3    1
187    LASTSIG2    1
188    HIVTST5    1
189    HIVTSTD2    6
195    WHRTST7    2
197    HIVRDTST    1
198    EMTSUPRT    1
199    LSATISFY    1
200    RCSBIRTH    6
206    RCSGENDR    1
207    RCHISLAT    1
208    RCSRACE    6
214    RCSBRACE    1
215    RCSRELN1    1
216    DRHPCH    1
217    HAVHPCH    1
218    CIFLUSH2    1
219    RCVFVCH2    6
225    RNOFVCH2    2
227    CASTHDX2    1
228    CASTHNO2    1
229    DIABAGE2    2
231    INSULIN    1
232    DIABPILL    1
233    BLDSUGAR    3
236    FEETCHK2    3
239    FEETSORE    1
240    DOCTDIAB    2
242    CHKHEMO3    2
244    FEETCHK    2
246    EYEEXAM    1
247    DIABEYE    1
248    DIABEDU    1
249    VIDFCLT2    1
250    VIREDIF2    1
251    VIPRFVS2    1
252    VINOCRE2    2
254    VIEYEXM2    1
255    VIINSUR2    1
256    VICTRCT2    1
257    VIGLUMA2    1
258    VIMACDG2    1
259    VIATWRK2    1
260    PAINACT2    2
262    QLMENTL2    2
264    QLSTRES2    2
266    QLREST2    2
268    QLHLTH2    2
270    ASTHMAGE    2
272    ASATTACK    1
273    ASERVIST    2
275    ASDRVIST    2
277    ASRCHKUP    2
279    ASACTLIM    3
282    ASYMPTOM    1
283    ASNOSLEP    1
284    ASTHMED2    1
285    ASINHALR    1
286    BRTHCNT3    1
287    TYPCNTR4    2
289    NOBCUSE2    2
291    FPCHLDFT    1
292    FPCHLDHS    1
293    VITAMINS    1
294    MULTIVIT    1
295    FOLICACD    1
296    TAKEVIT    3
299    RECOMMEN    1
300    HOUSESMK    1
301    INDOORS    1
302    SMKPUBLC    1
303    SMKWORK    1
304    IAQHTSRC    1
305    IAQGASAP    1
306    IAQHTDYS    3
309    IAQCODTR    1
310    IAQMOLD    1
311    HEWTRSRC    1
312    HEWTRDRK    1
313    HECHMHOM    3
316    HECHMYRD    3
319    RRCLASS2    1
320    RRCOGNT2    1
321    RRATWORK    1
322    RRHCARE2    1
323    RRPHYSM1    1
324    RREMTSM1    1
325    ADPLEASR    2
327    ADDOWN    2
329    ADSLEEP    2
331    ADENERGY    2
333    ADEAT    2
335    ADFAIL    2
337    ADTHINK    2
339    ADMOVE    2
341    ADANXEV    1
342    ADDEPEV    1
343    SVSAFE    1
344    SVSEXTCH    1
345    SVNOTCH    1
346    SVEHDSE1    1
347    SVHDSX12    1
348    SVEANOS1    1
349    SVNOSX12    1
350    SVRELAT2    2
352    SVGENDER    1
353    IPVSAFE    1
354    IPVTHRAT    1
355    IPVPHYV1    1
356    IPVPHHRT    1
357    IPVUWSEX    1
358    IPVPVL12    1
359    IPVSXINJ    1
360    IPVRELT1    2
362    GPWELPRD    1
363    GPVACPLN    1
364    GP3DYWTR    1
365    GP3DYFOD    1
366    GP3DYPRS    1
367    GPBATRAD    1
368    GPFLSLIT    1
369    GPMNDEVC    1
370    GPNOTEVC    2
372    GPEMRCOM    1
373    GPEMRINF    1
741    QSTVER    1
742    QSTLANG    2
800    _STSTR    5
805    _STRWT    10
815    _RAW    10
825    _WT2    10
835    _POSTSTR    10
845    _FINALWT    10
935    _REGION    2
937    _AGEG_    2
939    _SEXG_    1
940    _RACEG3_    1
941    _RACEG4_    1
942    _IMPAGE    2
944    _IMPNPH    1
945    _ITSCF1    10
955    _ITSCF2    10
965    _ITSPOST    10
975    _ITSFINL    10
993    MSCODE    1
994    CRACEORG    6
1000    CRACEASC    6
1006    _CRACE    2
1008    _CSEXG_    1
1009    _CRACEG_    1
1010    _CAGEG_    3
1033    _RAWCH    10
1063    _WT2CH    10
1093    _POSTCH    10
1123    _CHILDWT    10
1133    _RAWHH    10
1143    _WT2HH    10
1153    _POSTHH    10
1163    _HOUSEWT    10
1173    _RFHLTH    1
1174    _TOTINDA    1
1175    _EXTETH2    1
1176    _ALTETH2    1
1177    _DENVST1    1
1178    _LTASTHM    1
1179    _CASTHMA    1
1180    _ASTHMST    1
1181    _SMOKER3    1
1182    _RFSMOK3    1
1183    MRACEORG    6
1189    MRACEASC    6
1195    _PRACE    2
1197    _MRACE    2
1199    _RACEG2    1
1200    _RACEGR2    1
1201    _RACE_G    1
1202    _CNRACE    1
1203    _CNRACEC    1
1204    RACE2    1
1205    _AGEG5YR    2
1207    _AGE65YR    1
1208    _AGE_G    1
1209    HTIN3    3
1212    HTM3    3
1215    WTKG2    5
1220    _BMI4    4
1224    _BMI4CAT    1
1225    _RFBMI4    1
1226    _CHLDCNT    1
1227    _EDUCAG    1
1228    _INCOMG    1
1229    DROCDY2_    3
1232    _RFBING4    1
1233    _DRNKDY3    4
1237    _DRNKMO3    4
1241    _RFDRHV3    1
1242    _RFDRMN3    1
1243    _RFDRWM3    1
1244    _FLSHOT3    1
1245    _PNEUMO2    1
1246    _RFSEAT2    1
1247    _RFSEAT3    1
1248    _RFMAM2Y    1
1249    _MAM502Y    1
1250    _RFPAP32    1
1251    _RFPSA2Y    1
1252    _RFBLDST    1
1253    _RFSIGM2    1
1254    _AIDTST2    1"
columns <- read.table(textConnection(columns), header=TRUE, 
stringsAsFactors = FALSE)

library(LaF)

laf <- laf_open_fwf(filename = "CDBRFS06.ASC", column_names = 
columns$VariableName,
   column_widths = columns$FieldLength, column_types = rep("character", 
nrow(columns)))

# You now have a connection to the file; you can index this connection 
as you would a data.frame
# read all data
data <- laf[,]
# read the first 5 columns
data <- laf[, 1:5]
# read a random sample of rows
data <- laf[sample(nrow(laf), 10), ]


HTH,

Jan


On 23-02-16 20:13, Torvon wrote:
> Hi,
>
> I want to load a dataset into R. This dataset is available in two formats:
> .XPT and .ASC. The dataset is available at
> http://www.cdc.gov/brfss/annual_data/annual_2006.htm.
>
> They are about 40mb zipped, and about 500mb unzipped.
>
> I can get the .xpt data to load, using:
>
>> library(hmisc)
>> data <- sasxport.get("CDBRFS06.XPT")
> The data look fine, no error messages. However, the data only contains 302
> columns, which is less than it should have (according to the
> documentation). It does not contain my variables of interest, so either the
> documentation or the data file is wrong, and I want to make sure it's not
> the data file.
>
> Hence I wanted to see if I get the same results loading the .ASC file.
> However, multiple ways to do so have failed.
>
>> library(adehabitat)
>> import.asc("CDBRFS06.asc")
> Results in:
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
> : scan() expected 'a real', got '1191.8808943.38209868648.960119'
>
>> library(SDMTools)
>> read.asc("CDBRFS06.asc")
> Results in:
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
> : scan() expected 'a real', got '1191.8808943.38209868648.960119' In
> addition: Warning messages: 1: In scan(file, what, nmax, sep, dec, quote,
> skip, nlines, na.strings, : number of items read is not a multiple of the
> number of columns 2: In scan(file, what, nmax, sep, dec, quote, skip,
> nlines, na.strings, : number of items read is not a multiple of the number
> of columns 3: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
> na.strings, : number of items read is not a multiple of the number of
> columns 4: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
> na.strings, : number of items read is not a multiple of the number of
> columns 5: In scan(file, nmax = nl * nc, skip = 6, quiet = TRUE) : NAs
> introduced by coercion to integer range
>
> Thank you for your help.
>     Eiko
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Feb 23 22:34:17 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Feb 2016 08:34:17 +1100
Subject: [R] axis break in R
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61AFF2BB3@msgdb20.utad.utoledo.edu>
References: <CAJx9nazHMwUnquF1BrwAVHE9CmRmGJ1xW0yTgkLUcsyHUHYMyg@mail.gmail.com>
	<F1065E5D886F4D429259CDEAE3F83CB61AFF2BB3@msgdb20.utad.utoledo.edu>
Message-ID: <CA+8X3fW13--v2zxMgU6CVX=TG6ZOPOuqe5LfnOz1QZEq+0WSqQ@mail.gmail.com>

Hi Eike,
I think that plotrix v3.6-1 should run on R v 3.1.2.

Jim

On Wed, Feb 24, 2016 at 4:11 AM, Federman, Douglas <
Douglas.Federman at utoledo.edu> wrote:

>
> The current version of R is 3.2.3 and is available on the website.  You
> should update.  The current version of plotrix is 3.6-1
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eike
> Marie Thaysen
> Sent: Tuesday, February 23, 2016 11:00 AM
> To: r-help at r-project.org
> Subject: [R] axis break in R
>
> Hello,
> I want to break the y-axis on one of my plots. I read this is possible- but
> apparently only with the plotrix package that requieres R version 3.6-1? I
> cannot seem to find that version on the R homepage.. it is a version you
> have to pay for? Are there any other possebilities to do it (I am currently
> running (for R version 3.1.2) )
> Thank you,
> Eike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Douglas.Federman at utoledo.edu  Tue Feb 23 22:39:32 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Tue, 23 Feb 2016 21:39:32 +0000
Subject: [R] Loading large .pxt and .asc datasets causes issues.
In-Reply-To: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>
References: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AFF2DFE@msgdb20.utad.utoledo.edu>

You might want to look at Anthony Damico's work at

http://www.asdfree.com/search/label/behavioral%20risk%20factor%20surveillance%20system%20%28brfss%29

--
Better name for the general practitioner might be multispecialist. 
~Martin H. Fischer (1879-1962)


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Torvon
Sent: Tuesday, February 23, 2016 2:13 PM
To: r-help at r-project.org
Subject: [R] Loading large .pxt and .asc datasets causes issues.

Hi,

I want to load a dataset into R. This dataset is available in two formats:
.XPT and .ASC. The dataset is available at http://www.cdc.gov/brfss/annual_data/annual_2006.htm.

They are about 40mb zipped, and about 500mb unzipped.

I can get the .xpt data to load, using:

> library(hmisc)
> data <- sasxport.get("CDBRFS06.XPT")

The data look fine, no error messages. However, the data only contains 302 columns, which is less than it should have (according to the documentation). It does not contain my variables of interest, so either the documentation or the data file is wrong, and I want to make sure it's not the data file.

Hence I wanted to see if I get the same results loading the .ASC file.
However, multiple ways to do so have failed.

> library(adehabitat)
> import.asc("CDBRFS06.asc")

Results in:
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
: scan() expected 'a real', got '1191.8808943.38209868648.960119'

> library(SDMTools)
> read.asc("CDBRFS06.asc")

Results in:
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
: scan() expected 'a real', got '1191.8808943.38209868648.960119' In
addition: Warning messages: 1: In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : number of items read is not a multiple of the number of columns 2: In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : number of items read is not a multiple of the number of columns 3: In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : number of items read is not a multiple of the number of columns 4: In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : number of items read is not a multiple of the number of columns 5: In scan(file, nmax = nl * nc, skip = 6, quiet = TRUE) : NAs introduced by coercion to integer range

Thank you for your help.
   Eiko

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Feb 24 00:29:15 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Feb 2016 10:29:15 +1100
Subject: [R] Reading a datetime vector
In-Reply-To: <1550482130.9095046.1456266563364.JavaMail.yahoo@mail.yahoo.com>
References: <CA+8X3fVidTEi5OJpWuBo5QDuzjrNmrx7XL3EE3s9RMi5hCHJzw@mail.gmail.com>
	<1550482130.9095046.1456266563364.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fVKfp8Oo_3_eBGFvFxr=6vJbBV=5abUC_XjET_v-Zx00g@mail.gmail.com>

Doug,
We're getting warm. If we ask really nicely, will you tell us the URL of
the "dropbox folder you are working on"?

Jim


On Wed, Feb 24, 2016 at 9:29 AM, D Wolf <doug45290 at yahoo.com> wrote:

> In addition to my previous message, DF_extract_clean.R is the program in
> the dropbox folder that I am currently working on.
>
> Doug
>
>
> On Tuesday, February 23, 2016 4:02 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Doug,
> It is difficult for us to work out what is happening as we don't have
> access to a toy data set that we can play with. Excel spreadsheets are one
> of those things that you can't just attach to your email to the help list.
> If there is somewhere you can leave a _small_ Excel sample file (take the
> first 10 rows, say) that we can download (Google Drive, Dropbox?) and
> include the URL in your email, maybe someone can offer more than guesses.
>
> Jim
>
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Feb 24 00:32:03 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Feb 2016 10:32:03 +1100
Subject: [R] Reading a datetime vector
In-Reply-To: <CA+8X3fVKfp8Oo_3_eBGFvFxr=6vJbBV=5abUC_XjET_v-Zx00g@mail.gmail.com>
References: <CA+8X3fVidTEi5OJpWuBo5QDuzjrNmrx7XL3EE3s9RMi5hCHJzw@mail.gmail.com>
	<1550482130.9095046.1456266563364.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fVKfp8Oo_3_eBGFvFxr=6vJbBV=5abUC_XjET_v-Zx00g@mail.gmail.com>
Message-ID: <CA+8X3fVDW38trA6Tf-k_vX4PTu+p2-cRej=RL65UYGKiEYxHWA@mail.gmail.com>

Hi again,
My apologies - I didn't see the other email.

JIm

On Wed, Feb 24, 2016 at 10:29 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Doug,
> We're getting warm. If we ask really nicely, will you tell us the URL of
> the "dropbox folder you are working on"?
>
> Jim
>
>
> On Wed, Feb 24, 2016 at 9:29 AM, D Wolf <doug45290 at yahoo.com> wrote:
>
>> In addition to my previous message, DF_extract_clean.R is the program in
>> the dropbox folder that I am currently working on.
>>
>> Doug
>>
>>
>> On Tuesday, February 23, 2016 4:02 AM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>>
>>
>> Hi Doug,
>> It is difficult for us to work out what is happening as we don't have
>> access to a toy data set that we can play with. Excel spreadsheets are one
>> of those things that you can't just attach to your email to the help list.
>> If there is somewhere you can leave a _small_ Excel sample file (take the
>> first 10 rows, say) that we can download (Google Drive, Dropbox?) and
>> include the URL in your email, maybe someone can offer more than guesses.
>>
>> Jim
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From sergio.fonda99 at gmail.com  Wed Feb 24 01:21:43 2016
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Wed, 24 Feb 2016 01:21:43 +0100
Subject: [R] Order output list od TukeyHSD function by "p adj"
Message-ID: <CAJRuHoq54imZaPKWRQ9ifD8w7kGFoZscPmLh_Zey8+Ui4X9m2g@mail.gmail.com>

 Hello, It's already for several hours that I try to order the list
obtained by the function TukeyHSD according to the variable "p adj"
(in ascending order). Unfortunately, without success.
In addition to following two lines of code, that offer the result but
separately so do not correspond to the desired result, I was unable to
go:
DF.5 <-lapply(DF.4, function (x) as.data.frame(x[c("patient:Fold.fac")]))
DF.6 <- DF.5[[1]][order(DF.5[[1]]$patient.Fold.fac.p.adj),]
Please, I ask some help to answer these two questions:
1) is it possible to get directly from the function TukeyHSD sorted
rows by "p adj"?
2) or, may the output list from TukeyHSD() be processed (e.g. by
lapply) to sort its elements according to "p adj"?
I attach at bottom a simulation of a list obtained from TukeyHSD which
should be ordered by "p adj".
Thanks in advance for any suggestion!
Sergio
#
> dput(DF.4)
list(structure(list(patient = structure(c(12289274.0619908, -2380308.48287107,
-14669582.5448618, -4176414.56676197, -18845997.1116238, -31135271.1736146,
28754962.6907435, 14085380.1458817, 1796106.0838909, 0.186808233632622,
0.938592742253258, 0.0922160074633905), .Dim = 3:4, .Dimnames = list(
    c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
    "lwr", "upr", "p adj"))), Fold.fac = structure(c(-12697325.7957036,
-23938561.4288898, -1456090.1625174, 0.0268617694934425), .Dim = c(1L,
4L), .Dimnames = list("middle-low", c("diff", "lwr", "upr", "p adj"
))), `patient:Fold.fac` = structure(c(15369710.0977205, 6521960.91205235,
-4695802.45257667, 4502968.78925385, -16007472.7140147, -8847749.18566819,
-20065512.5502972, -10866741.3084667, -31377182.8117352, -11217763.364629,
-2018992.12279849, -22529433.626067, 9198771.24183052, -11311670.261438,
-20510441.5032685, -12927630.9811041, -21775380.1667723, -33016252.8378897,
-23817481.5960591, -44327923.0993277, -37145090.2644928, -48385962.9356102,
-39187191.6937797, -59697633.1970482, -39538213.749942, -30339442.5081115,
-50849884.01138, -19144769.6082929, -39655211.1115614, -48853982.353392,
43667051.1765452, 34819301.990877, 23624647.9327363, 32823419.1745669,
12312977.6712983, 19449591.8931564, 8254937.83501579, 17453709.0768463,
-3056732.42642223, 17102687.020684, 26301458.2625145, 5791016.75924596,
37542312.0919539, 17031870.5886854, 7833099.34685487, 0.632098034657304,
0.986399530577416, 0.997064140940244, 0.997595806079891, 0.590366152539712,
0.948510666498818, 0.330512619876425, 0.883673837089478, 0.0198821692150445,
0.868982868764254, 0.999952294188371, 0.207190890959777, 0.939934594322161,
0.86529009598038, 0.306625751897378), .Dim = c(15L, 4L), .Dimnames = list(
    c("PARTIAL:low-COMPLETE:low", "NO:low-COMPLETE:low",
"COMPLETE:middle-COMPLETE:low",
    "PARTIAL:middle-COMPLETE:low", "NO:middle-COMPLETE:low",
    "NO:low-PARTIAL:low", "COMPLETE:middle-PARTIAL:low",
"PARTIAL:middle-PARTIAL:low",
    "NO:middle-PARTIAL:low", "COMPLETE:middle-NO:low", "PARTIAL:middle-NO:low",
    "NO:middle-NO:low", "PARTIAL:middle-COMPLETE:middle",
"NO:middle-COMPLETE:middle",
    "NO:middle-PARTIAL:middle"), c("diff", "lwr", "upr", "p adj"
    )))), .Names = c("patient", "Fold.fac", "patient:Fold.fac"
), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula = abundance ~
    patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE),
    structure(list(patient = structure(c(11084928.3849924, -3790273.898858,
    -14875202.2838504, -2565656.8579769, -17440859.1418273, -28525787.5268197,
    24735513.6279617, 9860311.34411127, -1224617.0408811, 0.137587687259541,
    0.791659281224941, 0.028733410253219), .Dim = 3:4, .Dimnames = list(
        c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
        "lwr", "upr", "p adj"))), Fold.fac = structure(c(25003217.9525667,
    15683872.2084017, 34322563.6967316, 1.59282125378191e-07), .Dim = c(1L,
    4L), .Dimnames = list("low-high", c("diff", "lwr", "upr",
    "p adj"))), `patient:Fold.fac` = structure(c(6786144.11764773,
    -14136208.8235292, 15255972.7140153, 30625682.8117357, 21777933.6260674,
    -20922352.9411769, 8469828.59636761, 23839538.6940879, 14991789.5084197,
    29392181.5375445, 44761891.6352649, 35914142.4495966, 15369710.0977203,
    6521960.91205206, -8847749.18566828, -16711562.4882314, -37633915.4294083,
    -8222591.1541805, 7147118.94353984, -1700630.24212845, -44420059.547056,
    -15008735.2718282, 360974.825892106, -8486774.35977618, 5913617.6693487,
    21283327.767069, 12435578.5814008, -8089695.41243546, -16937444.5981037,
    -32307154.6958241, 30283850.7235268, 9361497.78234989, 38734536.5822112,
    54104246.6799315, 45256497.4942632, 2575353.66470216, 31948392.4645634,
    47318102.5622838, 38470353.3766155, 52870745.4057404, 68240455.5034607,
    59392706.3177924, 38829115.6078761, 29981366.4222079, 14611656.3244875,
    0.963180623746077, 0.521122619371869, 0.431445001590424,
    0.00280179326576413, 0.0869916657428951, 0.113173926329674,
    0.908231706478258, 0.0441523667992262, 0.451984651996765,
    0.00489618219443777, 9.080596613531e-07, 0.000195613055067767,
    0.42174023314457, 0.968747601969596, 0.891038899833401), .Dim = c(15L,
    4L), .Dimnames = list(c("PARTIAL:high-COMPLETE:high",
"NO:high-COMPLETE:high",
    "COMPLETE:low-COMPLETE:high", "PARTIAL:low-COMPLETE:high",
    "NO:low-COMPLETE:high", "NO:high-PARTIAL:high", "COMPLETE:low-PARTIAL:high",
    "PARTIAL:low-PARTIAL:high", "NO:low-PARTIAL:high", "COMPLETE:low-NO:high",
    "PARTIAL:low-NO:high", "NO:low-NO:high", "PARTIAL:low-COMPLETE:low",
    "NO:low-COMPLETE:low", "NO:low-PARTIAL:low"), c("diff", "lwr",
    "upr", "p adj")))), .Names = c("patient", "Fold.fac", "patient:Fold.fac"
    ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula = abundance ~
        patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE))
>


From ajdamico at gmail.com  Wed Feb 24 04:02:47 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 23 Feb 2016 22:02:47 -0500
Subject: [R] Loading large .pxt and .asc datasets causes issues.
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61AFF2DFE@msgdb20.utad.utoledo.edu>
References: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>
	<F1065E5D886F4D429259CDEAE3F83CB61AFF2DFE@msgdb20.utad.utoledo.edu>
Message-ID: <CAOwvMDyT=-NwWo3nDROH_nor4qw9UAdctE3+oyAc6_VqQUMFDg@mail.gmail.com>

hi eiko, LaF is incompatible with survey data, that road is a dead-end.
this code below will painlessly load brfss into R, review the link douglas
sent for analysis examples and change `years.to.download <- ` to 2006 only
if you just want a single year of microdata.  glhf


# install.packages( c("MonetDB.R", "MonetDBLite" , "survey" , "SAScii" ,
"descr" , "downloader" , "digest" ) , repos=c("
http://dev.monetdb.org/Assets/R/", "http://cran.rstudio.com/"))

# setInternet2( FALSE )                        # # only windows users need
this line
# options( encoding = "windows-1252" )        # # only macintosh and *nix
users need this line
library(downloader)
# setwd( "C:/My Directory/BRFSS/" )
years.to.download <- 1984:2014
source_url( "
https://raw.githubusercontent.com/ajdamico/asdfree/master/Behavioral%20Risk%20Factor%20Surveillance%20System/download%20all%20microdata.R"
, prompt = FALSE , echo = TRUE )





On Tue, Feb 23, 2016 at 4:39 PM, Federman, Douglas <
Douglas.Federman at utoledo.edu> wrote:

> You might want to look at Anthony Damico's work at
>
>
> http://www.asdfree.com/search/label/behavioral%20risk%20factor%20surveillance%20system%20%28brfss%29
>
> --
> Better name for the general practitioner might be multispecialist.
> ~Martin H. Fischer (1879-1962)
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Torvon
> Sent: Tuesday, February 23, 2016 2:13 PM
> To: r-help at r-project.org
> Subject: [R] Loading large .pxt and .asc datasets causes issues.
>
> Hi,
>
> I want to load a dataset into R. This dataset is available in two formats:
> .XPT and .ASC. The dataset is available at
> http://www.cdc.gov/brfss/annual_data/annual_2006.htm.
>
> They are about 40mb zipped, and about 500mb unzipped.
>
> I can get the .xpt data to load, using:
>
> > library(hmisc)
> > data <- sasxport.get("CDBRFS06.XPT")
>
> The data look fine, no error messages. However, the data only contains 302
> columns, which is less than it should have (according to the
> documentation). It does not contain my variables of interest, so either the
> documentation or the data file is wrong, and I want to make sure it's not
> the data file.
>
> Hence I wanted to see if I get the same results loading the .ASC file.
> However, multiple ways to do so have failed.
>
> > library(adehabitat)
> > import.asc("CDBRFS06.asc")
>
> Results in:
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
> : scan() expected 'a real', got '1191.8808943.38209868648.960119'
>
> > library(SDMTools)
> > read.asc("CDBRFS06.asc")
>
> Results in:
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
> : scan() expected 'a real', got '1191.8808943.38209868648.960119' In
> addition: Warning messages: 1: In scan(file, what, nmax, sep, dec, quote,
> skip, nlines, na.strings, : number of items read is not a multiple of the
> number of columns 2: In scan(file, what, nmax, sep, dec, quote, skip,
> nlines, na.strings, : number of items read is not a multiple of the number
> of columns 3: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
> na.strings, : number of items read is not a multiple of the number of
> columns 4: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
> na.strings, : number of items read is not a multiple of the number of
> columns 5: In scan(file, nmax = nl * nc, skip = 6, quiet = TRUE) : NAs
> introduced by coercion to integer range
>
> Thank you for your help.
>    Eiko
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Feb 24 04:19:38 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Feb 2016 14:19:38 +1100
Subject: [R] Reading a datetime vector
In-Reply-To: <1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
References: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
	<1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fXZYpfkFDZ=313CrdNyKDiBcO3G9sk+uj=hmz8zfmNFqA@mail.gmail.com>

Hi Doug,
I see what the problem is now. When your Excel file is read in with
read.xlsx2, the DateTimeStamp is read as days since Microsoft's time epoch
(see earlier posts on this). As these values are numeric, they cannot be
converted in the same way as a human readable date/time string. The easiest
way I could think of to get around this is to export the XLSX file as CSV.
Then you will have the date/time strings and can convert them to POSIX
date/time values. Note that your format spec was slightly wrong - day is
first.

# first export the EXCEL file as a CSV file then
df2_TZ = read.csv("/media/KINGSTON/DF_exp2.csv",stringsAsFactors=FALSE)
df2_TZ$DateTimeStamp<-strptime(df2_TZ$DateTimeStamp,"%d/%m/%Y %H:%M")
# and I get
df2_TZ$DateTimeStamp
 [1] "2013-01-01 00:00:00 EST" "2013-01-01 01:00:00 EST"
 [3] "2013-01-02 23:15:00 EST" "2013-01-02 23:30:00 EST"
 [5] "2013-01-02 23:45:00 EST" "2013-01-03 00:00:00 EST"
 [7] "2013-01-03 01:00:00 EST" "2013-01-03 01:15:00 EST"
 [9] "2013-01-04 23:00:00 EST" "2014-11-24 15:04:00 EST"
[11] "2013-01-04 23:15:00 EST" "2013-01-04 23:30:00 EST"
[13] "2013-01-05 00:30:00 EST" "2013-01-05 00:45:00 EST"
[15] "2013-01-26 00:00:00 EST" "2013-07-19 15:42:00 EST"

Jim

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Feb 24 05:13:10 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 23 Feb 2016 20:13:10 -0800
Subject: [R] Reading a datetime vector
In-Reply-To: <CA+8X3fXZYpfkFDZ=313CrdNyKDiBcO3G9sk+uj=hmz8zfmNFqA@mail.gmail.com>
References: <05EDCC64-4227-4DFE-8244-734657D6EE1A@dcn.davis.ca.us>
	<1376707536.8128390.1456160134898.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fXZYpfkFDZ=313CrdNyKDiBcO3G9sk+uj=hmz8zfmNFqA@mail.gmail.com>
Message-ID: <AA0F88E5-1AA1-433D-AA0B-984FF703F3A4@dcn.davis.ca.us>

You are overthinking this.  The answer is in the help file for read.xls2.
-- 
Sent from my phone. Please excuse my brevity.

On February 23, 2016 7:19:38 PM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Doug,
>I see what the problem is now. When your Excel file is read in with
>read.xlsx2, the DateTimeStamp is read as days since Microsoft's time
>epoch
>(see earlier posts on this). As these values are numeric, they cannot
>be
>converted in the same way as a human readable date/time string. The
>easiest
>way I could think of to get around this is to export the XLSX file as
>CSV.
>Then you will have the date/time strings and can convert them to POSIX
>date/time values. Note that your format spec was slightly wrong - day
>is
>first.
>
># first export the EXCEL file as a CSV file then
>df2_TZ = read.csv("/media/KINGSTON/DF_exp2.csv",stringsAsFactors=FALSE)
>df2_TZ$DateTimeStamp<-strptime(df2_TZ$DateTimeStamp,"%d/%m/%Y %H:%M")
># and I get
>df2_TZ$DateTimeStamp
> [1] "2013-01-01 00:00:00 EST" "2013-01-01 01:00:00 EST"
> [3] "2013-01-02 23:15:00 EST" "2013-01-02 23:30:00 EST"
> [5] "2013-01-02 23:45:00 EST" "2013-01-03 00:00:00 EST"
> [7] "2013-01-03 01:00:00 EST" "2013-01-03 01:15:00 EST"
> [9] "2013-01-04 23:00:00 EST" "2014-11-24 15:04:00 EST"
>[11] "2013-01-04 23:15:00 EST" "2013-01-04 23:30:00 EST"
>[13] "2013-01-05 00:30:00 EST" "2013-01-05 00:45:00 EST"
>[15] "2013-01-26 00:00:00 EST" "2013-07-19 15:42:00 EST"
>
>Jim
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From niheaven at gmail.com  Wed Feb 24 07:30:34 2016
From: niheaven at gmail.com (Hsiao-nan Cheung)
Date: Wed, 24 Feb 2016 14:30:34 +0800
Subject: [R] RStudio Crashes when using quantmod's chartSeries()
Message-ID: <CAK80y3AwaygtMEP51S9qUfXiuR=1qO_t0sz2Rs7qW7fPUa_bTw@mail.gmail.com>

Dear All,

  When I use quantmod's chartSeries() function, the RStudio crashes. The
code
  is as below.

  library(quantmod)
  getSymbols("IBM")
  chartSeries(IBM)

  Very simple code... And the same function is working well in R Console
(Rgui.exe), i.e.
  there is a plot in the default graphics device. So maybe it's a graphics
  engine error with RStudio?

  I've tried the plot() function, e.g., plot(chartSeries(IBM)), and it
  crashes, too. Nothing improve.

R version is 3.2.3 (MRO 3.2.3), and RStudio version is 0.99.879, quantmod's
is 0.4-5.

  Yours,
  Hsiao-nan Cheung
  2016/2/24

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed Feb 24 07:44:05 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 24 Feb 2016 07:44:05 +0100
Subject: [R] RStudio Crashes when using quantmod's chartSeries()
In-Reply-To: <CAK80y3AwaygtMEP51S9qUfXiuR=1qO_t0sz2Rs7qW7fPUa_bTw@mail.gmail.com>
References: <CAK80y3AwaygtMEP51S9qUfXiuR=1qO_t0sz2Rs7qW7fPUa_bTw@mail.gmail.com>
Message-ID: <56CD5135.3070103@statistik.tu-dortmund.de>

Thanks, but please report problems with RStudio to the RStudio support. 
Neither this list (to which RStudio emplyees may be listening, though) 
nor R-core can help in this case.

Best,
Uwe Ligges




On 24.02.2016 07:30, Hsiao-nan Cheung wrote:
> Dear All,
>
>    When I use quantmod's chartSeries() function, the RStudio crashes. The
> code
>    is as below.
>
>    library(quantmod)
>    getSymbols("IBM")
>    chartSeries(IBM)
>
>    Very simple code... And the same function is working well in R Console
> (Rgui.exe), i.e.
>    there is a plot in the default graphics device. So maybe it's a graphics
>    engine error with RStudio?
>
>    I've tried the plot() function, e.g., plot(chartSeries(IBM)), and it
>    crashes, too. Nothing improve.
>
> R version is 3.2.3 (MRO 3.2.3), and RStudio version is 0.99.879, quantmod's
> is 0.4-5.
>
>    Yours,
>    Hsiao-nan Cheung
>    2016/2/24
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Wed Feb 24 07:48:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Feb 2016 17:48:56 +1100
Subject: [R] Order output list od TukeyHSD function by "p adj"
In-Reply-To: <CAJRuHoq54imZaPKWRQ9ifD8w7kGFoZscPmLh_Zey8+Ui4X9m2g@mail.gmail.com>
References: <CAJRuHoq54imZaPKWRQ9ifD8w7kGFoZscPmLh_Zey8+Ui4X9m2g@mail.gmail.com>
Message-ID: <CA+8X3fX4OKfsZkXds0tbmEhuqD+fOnNpKVwCTHnP2-nkxuswDQ@mail.gmail.com>

Hi Sergio,
I couldn't get your example data to read in, so I have used the example in
the help page:

fm1 <- aov(breaks ~ wool + tension, data = warpbreaks)
hsd.fit<-TukeyHSD(fm1, "tension", ordered = TRUE)
hsd.fit$tension[order(hsd.fit$tension[,4]),]
        diff        lwr      upr       p adj
L-H 14.722222  5.3688015 24.07564 0.001121788
L-M 10.000000  0.6465793 19.35342 0.033626219
M-H  4.722222 -4.6311985 14.07564 0.447421021

Obviously you would have to examine the output of TukeyHSD with str() to
sort out which column to use for ordering.

Jim


On Wed, Feb 24, 2016 at 11:21 AM, Sergio Fonda <sergio.fonda99 at gmail.com>
wrote:

>  Hello, It's already for several hours that I try to order the list
> obtained by the function TukeyHSD according to the variable "p adj"
> (in ascending order). Unfortunately, without success.
> In addition to following two lines of code, that offer the result but
> separately so do not correspond to the desired result, I was unable to
> go:
> DF.5 <-lapply(DF.4, function (x) as.data.frame(x[c("patient:Fold.fac")]))
> DF.6 <- DF.5[[1]][order(DF.5[[1]]$patient.Fold.fac.p.adj),]
> Please, I ask some help to answer these two questions:
> 1) is it possible to get directly from the function TukeyHSD sorted
> rows by "p adj"?
> 2) or, may the output list from TukeyHSD() be processed (e.g. by
> lapply) to sort its elements according to "p adj"?
> I attach at bottom a simulation of a list obtained from TukeyHSD which
> should be ordered by "p adj".
> Thanks in advance for any suggestion!
> Sergio
> #
> > dput(DF.4)
> list(structure(list(patient = structure(c(12289274.0619908,
> -2380308.48287107,
> -14669582.5448618, -4176414.56676197, -18845997.1116238, -31135271.1736146,
> 28754962.6907435, 14085380.1458817, 1796106.0838909, 0.186808233632622,
> 0.938592742253258, 0.0922160074633905), .Dim = 3:4, .Dimnames = list(
>     c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
>     "lwr", "upr", "p adj"))), Fold.fac = structure(c(-12697325.7957036,
> -23938561.4288898, -1456090.1625174, 0.0268617694934425), .Dim = c(1L,
> 4L), .Dimnames = list("middle-low", c("diff", "lwr", "upr", "p adj"
> ))), `patient:Fold.fac` = structure(c(15369710.0977205, 6521960.91205235,
> -4695802.45257667, 4502968.78925385, -16007472.7140147, -8847749.18566819,
> -20065512.5502972, -10866741.3084667, -31377182.8117352, -11217763.364629,
> -2018992.12279849, -22529433.626067, 9198771.24183052, -11311670.261438,
> -20510441.5032685, -12927630.9811041, -21775380.1667723, -33016252.8378897,
> -23817481.5960591, -44327923.0993277, -37145090.2644928, -48385962.9356102,
> -39187191.6937797, -59697633.1970482, -39538213.749942, -30339442.5081115,
> -50849884.01138, -19144769.6082929, -39655211.1115614, -48853982.353392,
> 43667051.1765452, 34819301.990877, 23624647.9327363, 32823419.1745669,
> 12312977.6712983, 19449591.8931564, 8254937.83501579, 17453709.0768463,
> -3056732.42642223, 17102687.020684, 26301458.2625145, 5791016.75924596,
> 37542312.0919539, 17031870.5886854, 7833099.34685487, 0.632098034657304,
> 0.986399530577416, 0.997064140940244, 0.997595806079891, 0.590366152539712,
> 0.948510666498818, 0.330512619876425, 0.883673837089478,
> 0.0198821692150445,
> 0.868982868764254, 0.999952294188371, 0.207190890959777, 0.939934594322161,
> 0.86529009598038, 0.306625751897378), .Dim = c(15L, 4L), .Dimnames = list(
>     c("PARTIAL:low-COMPLETE:low", "NO:low-COMPLETE:low",
> "COMPLETE:middle-COMPLETE:low",
>     "PARTIAL:middle-COMPLETE:low", "NO:middle-COMPLETE:low",
>     "NO:low-PARTIAL:low", "COMPLETE:middle-PARTIAL:low",
> "PARTIAL:middle-PARTIAL:low",
>     "NO:middle-PARTIAL:low", "COMPLETE:middle-NO:low",
> "PARTIAL:middle-NO:low",
>     "NO:middle-NO:low", "PARTIAL:middle-COMPLETE:middle",
> "NO:middle-COMPLETE:middle",
>     "NO:middle-PARTIAL:middle"), c("diff", "lwr", "upr", "p adj"
>     )))), .Names = c("patient", "Fold.fac", "patient:Fold.fac"
> ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula = abundance
> ~
>     patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE),
>     structure(list(patient = structure(c(11084928.3849924, -3790273.898858,
>     -14875202.2838504, -2565656.8579769, -17440859.1418273,
> -28525787.5268197,
>     24735513.6279617, 9860311.34411127, -1224617.0408811,
> 0.137587687259541,
>     0.791659281224941, 0.028733410253219), .Dim = 3:4, .Dimnames = list(
>         c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
>         "lwr", "upr", "p adj"))), Fold.fac = structure(c(25003217.9525667,
>     15683872.2084017, 34322563.6967316, 1.59282125378191e-07), .Dim = c(1L,
>     4L), .Dimnames = list("low-high", c("diff", "lwr", "upr",
>     "p adj"))), `patient:Fold.fac` = structure(c(6786144.11764773,
>     -14136208.8235292, 15255972.7140153, 30625682.8117357,
> 21777933.6260674,
>     -20922352.9411769, 8469828.59636761, 23839538.6940879,
> 14991789.5084197,
>     29392181.5375445, 44761891.6352649, 35914142.4495966, 15369710.0977203,
>     6521960.91205206, -8847749.18566828, -16711562.4882314,
> -37633915.4294083,
>     -8222591.1541805, 7147118.94353984, -1700630.24212845,
> -44420059.547056,
>     -15008735.2718282, 360974.825892106, -8486774.35977618,
> 5913617.6693487,
>     21283327.767069, 12435578.5814008, -8089695.41243546,
> -16937444.5981037,
>     -32307154.6958241, 30283850.7235268, 9361497.78234989,
> 38734536.5822112,
>     54104246.6799315, 45256497.4942632, 2575353.66470216, 31948392.4645634,
>     47318102.5622838, 38470353.3766155, 52870745.4057404, 68240455.5034607,
>     59392706.3177924, 38829115.6078761, 29981366.4222079, 14611656.3244875,
>     0.963180623746077, 0.521122619371869, 0.431445001590424,
>     0.00280179326576413, 0.0869916657428951, 0.113173926329674,
>     0.908231706478258, 0.0441523667992262, 0.451984651996765,
>     0.00489618219443777, 9.080596613531e-07, 0.000195613055067767,
>     0.42174023314457, 0.968747601969596, 0.891038899833401), .Dim = c(15L,
>     4L), .Dimnames = list(c("PARTIAL:high-COMPLETE:high",
> "NO:high-COMPLETE:high",
>     "COMPLETE:low-COMPLETE:high", "PARTIAL:low-COMPLETE:high",
>     "NO:low-COMPLETE:high", "NO:high-PARTIAL:high",
> "COMPLETE:low-PARTIAL:high",
>     "PARTIAL:low-PARTIAL:high", "NO:low-PARTIAL:high",
> "COMPLETE:low-NO:high",
>     "PARTIAL:low-NO:high", "NO:low-NO:high", "PARTIAL:low-COMPLETE:low",
>     "NO:low-COMPLETE:low", "NO:low-PARTIAL:low"), c("diff", "lwr",
>     "upr", "p adj")))), .Names = c("patient", "Fold.fac",
> "patient:Fold.fac"
>     ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
> abundance ~
>         patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE))
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sunnysingha.analytics at gmail.com  Wed Feb 24 08:49:24 2016
From: sunnysingha.analytics at gmail.com (Sandeep Rana)
Date: Wed, 24 Feb 2016 13:19:24 +0530
Subject: [R] issue -- Packages unavailable for R version 3.2.3
Message-ID: <CANOG_FWLvqb9-FFJY6DQhd=anj0BTbesHuE=W2UndbBi-frNvQ@mail.gmail.com>

Hi,

I have newly installed R version 3.2.3 and experiencing an issue where the
packages that I had been using in previous release aren't compatible in the
latest release.
I need you help to suggest how we could force the installation even if its
not supported or what is the workaround to move ahead with it.

Right now, I need to install the package 'sentiment'. Please help.

Regards,

Sandeep S. Rana

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Wed Feb 24 09:47:09 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 24 Feb 2016 08:47:09 +0000
Subject: [R] Trying to load a FORTRAN dll but unable
In-Reply-To: <56CB44D7.2020907@gmail.com>
References: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CB2D9D.2000103@gmail.com>
	<87afae9bf1bf464ba80e183ae6dc9962@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CB44D7.2020907@gmail.com>
Message-ID: <9bf68f36743b4e1abf779c2f1643ca1d@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Murdoch,

is.loaded is now working but the routine I call has a bug so I have to rebuilt it !

I am posting a new question on this mailing list ...

Many thanks for your help
Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From petr.pikal at precheza.cz  Wed Feb 24 10:02:35 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 24 Feb 2016 09:02:35 +0000
Subject: [R] mvProbit error message
In-Reply-To: <CAOA_h3+wKa6=iPb76-EoLuw4h7G_0kBOms98+sUANHNrxsNNhg@mail.gmail.com>
References: <CAOA_h3+9kKrALJMio3W6GNhfxugaynHm=HjeCx1mTiTXAZexMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010B53@SRVEXCHMBX.precheza.cz>
	<CAOA_h3+wKa6=iPb76-EoLuw4h7G_0kBOms98+sUANHNrxsNNhg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010DB2@SRVEXCHMBX.precheza.cz>

Hi

Keep your reply to rhelp list. Others can come with better/more appropriate solution.

Pardon me, but you used

Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~ x1+x2+x3+......+.x11,data=mydata)

but in mydata there are variables tree and nothing (according what you did tell us).

So I am rather confused.

Cheers
Petr

From: Betty Betty [mailto:aleminesh57 at gmail.com]
Sent: Wednesday, February 24, 2016 9:55 AM
To: PIKAL Petr
Subject: Re: [R] mvProbit error message

Thank you very much!
I find the following out put
1.  If I import the data with read.spss(....use.value.lables=FALSE) str(mydata) shows me:

$ tree           : atomic  1 0 1 1 1 1 0 0 1 1 ...
  ..- attr(*, "value.labels")= Named num  1 0
  .. ..- attr(*, "names")= chr  "TRUE" "FALSE"
$ nothing        : atomic  0 0 0 0 0 0 0 1 0 0 ...
  ..- attr(*, "value.labels")= Named num  1 0
  .. ..- attr(*, "names")= chr  "TRUE" "FALSE"
.
2.  If I import data with read.spss(....use.value.lables=TRUE) str(mydata)
shows me:


$ tree           : Factor w/ 2 levels "FALSE","TRUE": 2 1 2 2 2 2 1 1 2 2 ...
$ nothing        : Factor w/ 2 levels "FALSE","TRUE": 1 1 1 1 1 1 1 2 1 1 ...
regards

On Tue, Feb 23, 2016 at 3:53 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

It shall work, I do not see any problem in the code. So you have to persuade us that you checked your data properly e.g. by posting result of

str(mydata)

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Betty
> Betty
> Sent: Tuesday, February 23, 2016 9:37 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] mvProbit error message
>
> Dear All,
> I am running the mvProbit model to estimate five equation probit
> models. In my data all the dependent variables are dichotomous with
> values 0/1 and lables TRUE/FALSE. The explanatory variables are
> composed of catagorical and countinous variables. I specified the model
> as follows
>
> Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~
> x1+x2+x3+......+.x11,data=mydata)
> summary(Result)
>
> However, i get an error message "...Error in
> mvProbit(cbind(y1,y2,y3,y4,y5) ~:all dependent variables must be either
> 0,1,TRUE, or FALSE)
>
> I have checked all the dependent variables and it is coded 0/1 and
> lables TRUE/FALSE.
> Ofcourse there are two missing observation and I attempted to handle
> that with na.action=na.omit but even that didnt solve the problem. My
> second attempt was to tell r that the dichotomous dependent variables
> and the catagorical independent variables as factor as follows
>
> mydata$y1<-factor(mydata$y1)
> ...
> ...
> ..
> .
> mydata$x3<-factor(mydata$x3)
> But still problem not solved. How would I solve this problem?
> Thank you!
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From sigbert at wiwi.hu-berlin.de  Wed Feb 24 10:26:09 2016
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Wed, 24 Feb 2016 10:26:09 +0100
Subject: [R] readRDS problem
Message-ID: <56CD7731.3040404@wiwi.hu-berlin.de>

Hi,

I have two scripts, one creates a data structure (a list of data frames
+ some attributes) and saves it via saveRDS.

The second script reads the RDS file (outside of any function) and

data <- readRDS (name)

works, but

data <<- readRDS (name)

creates the error

Error: cannot change value of locked binding for 'data'

Any idea what goes wrong?

Thanks Sigbert

-- 
http://u.hu-berlin.de/sk

From lists at dewey.myzen.co.uk  Wed Feb 24 10:39:18 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 24 Feb 2016 09:39:18 +0000
Subject: [R] readRDS problem
In-Reply-To: <56CD7731.3040404@wiwi.hu-berlin.de>
References: <56CD7731.3040404@wiwi.hu-berlin.de>
Message-ID: <56CD7A46.9060508@dewey.myzen.co.uk>

Try calling it something other than data.

On 24/02/2016 09:26, Sigbert Klinke wrote:
> Hi,
>
> I have two scripts, one creates a data structure (a list of data frames
> + some attributes) and saves it via saveRDS.
>
> The second script reads the RDS file (outside of any function) and
>
> data <- readRDS (name)
>
> works, but
>
> data <<- readRDS (name)
>
> creates the error
>
> Error: cannot change value of locked binding for 'data'
>
> Any idea what goes wrong?
>
> Thanks Sigbert
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jean-externe.maurice at edf.fr  Wed Feb 24 10:41:07 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 24 Feb 2016 09:41:07 +0000
Subject: [R] first steps to build a FORTRAN DLL used by R
Message-ID: <06061e7df77c4f8e92ec702320ef6332@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,
I am a fortran developper, freelance, hired by a huge company to transform R calculations to FORTRAN. I am discovering R.

Few years ago someone built FORTRAN dll using Lahey Fortran (perhaps only to test his programs) and gfortran. I found two .bat files, one for Lahey :
ECHO compilation fortran LAHEY regression\regr.f
lf95 -dll -ml msvc regr.f >regr.txt
type regr.txt

and one for gfortran :
ECHO creation DLL FORTRAN par R regression\regr.f
C:\utilitaires\R\R-3.1.0\bin\i386\rcmd SHLIB regr.f >creationdllr.txt
TYPE creationdllr.txt

Creationdllr.txt being :
gfortran -m32     -O3  -mtune=core2 -c regr.f -o regr.o
gcc -m32 -shared -s -static-libgcc -o regr.dll tmp.def regr.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/i386 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -lgfortran -LC:/utilitaires/R/R-3.1.0/bin/i386 -lR


Nowadays, the company uses Intel's FORTRAN. I could build a dll with it but R doesn't want to load it ! parameters are : 'keep fortran 77 compatibility' and 'console mode'.

What I would like to know are 'the first steps' or 'building FORTRAN dll's for beginners (dummy ?)' :


1)      Can we use Intel's Fortran or must we use gfortran

2)      If we must use gfortran is it given with R ?

3)      If we can use Intel's Fortran, what are the parameters to use and has someone recommandations to give ?

Thanks in advance for your help
Jean MAURICE in France
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From sigbert at wiwi.hu-berlin.de  Wed Feb 24 11:02:40 2016
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Wed, 24 Feb 2016 11:02:40 +0100
Subject: [R] readRDS problem
In-Reply-To: <56CD7A46.9060508@dewey.myzen.co.uk>
References: <56CD7731.3040404@wiwi.hu-berlin.de>
	<56CD7A46.9060508@dewey.myzen.co.uk>
Message-ID: <56CD7FC0.8040204@wiwi.hu-berlin.de>

Hi,

thanks, using

test <<- readRDS (name)

it worked. But why?

Best Sigbert

Am 24.02.2016 um 10:39 schrieb Michael Dewey:
> Try calling it something other than data.
> 
> On 24/02/2016 09:26, Sigbert Klinke wrote:
>> Hi,
>>
>> I have two scripts, one creates a data structure (a list of data frames
>> + some attributes) and saves it via saveRDS.
>>
>> The second script reads the RDS file (outside of any function) and
>>
>> data <- readRDS (name)
>>
>> works, but
>>
>> data <<- readRDS (name)
>>
>> creates the error
>>
>> Error: cannot change value of locked binding for 'data'
>>
>> Any idea what goes wrong?
>>
>> Thanks Sigbert
>>
> 


-- 
http://u.hu-berlin.de/sk

From petr.pikal at precheza.cz  Wed Feb 24 11:48:50 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 24 Feb 2016 10:48:50 +0000
Subject: [R] mvProbit error message
In-Reply-To: <CAOA_h3LbLqge5V+9uH-HLvhU7qq1QvV9_sRQQHTDba_TszzxBA@mail.gmail.com>
References: <CAOA_h3+9kKrALJMio3W6GNhfxugaynHm=HjeCx1mTiTXAZexMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010B53@SRVEXCHMBX.precheza.cz>
	<CAOA_h3+wKa6=iPb76-EoLuw4h7G_0kBOms98+sUANHNrxsNNhg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010DB2@SRVEXCHMBX.precheza.cz>
	<CAOA_h3LbLqge5V+9uH-HLvhU7qq1QvV9_sRQQHTDba_TszzxBA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010E1D@SRVEXCHMBX.precheza.cz>

Hi

I am not an expert in this area. Your error says

> However, i get an error message "...Error in
> mvProbit(cbind(y1,y2,y3,y4,y5) ~:all dependent variables must be either
> 0,1,TRUE, or FALSE)

str(mydata) tells you that you have factors.
$ tree           : Factor w/ 2 levels "FALSE","TRUE": 2 1 2 2 2 2 1 1 2 2 ...
$ nothing        : Factor w/ 2 levels "FALSE","TRUE": 1 1 1 1 1 1 1 2 1 1 ...
Maybe mvProbit is rather picky about input values.
So I would try to change those factors to its numeric representation by

mydata$tree <- as.numeric(mydata$tree)-1

You can use apply to change several factors to numeric at once.

Cheers
Petr

From: Betty Betty [mailto:aleminesh57 at gmail.com]
Sent: Wednesday, February 24, 2016 10:16 AM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: Re: [R] mvProbit error message

sorry for the confusion. I used y1,y2,.... instead of the real variable names just for emailing purpose (to forward my question in a more clear way). Tree, nothing...are the real variable names in my data set and i actually used
Result<-myProbit(cbind(tree,nothing....)~x1+x2......,data=mydata)

On Wed, Feb 24, 2016 at 10:02 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Keep your reply to rhelp list. Others can come with better/more appropriate solution.

Pardon me, but you used

Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~ x1+x2+x3+......+.x11,data=mydata)

but in mydata there are variables tree and nothing (according what you did tell us).

So I am rather confused.

Cheers
Petr

From: Betty Betty [mailto:aleminesh57 at gmail.com<mailto:aleminesh57 at gmail.com>]
Sent: Wednesday, February 24, 2016 9:55 AM
To: PIKAL Petr
Subject: Re: [R] mvProbit error message

Thank you very much!
I find the following out put
1.  If I import the data with read.spss(....use.value.lables=FALSE) str(mydata) shows me:

$ tree           : atomic  1 0 1 1 1 1 0 0 1 1 ...
  ..- attr(*, "value.labels")= Named num  1 0
  .. ..- attr(*, "names")= chr  "TRUE" "FALSE"
$ nothing        : atomic  0 0 0 0 0 0 0 1 0 0 ...
  ..- attr(*, "value.labels")= Named num  1 0
  .. ..- attr(*, "names")= chr  "TRUE" "FALSE"
.
2.  If I import data with read.spss(....use.value.lables=TRUE) str(mydata)
shows me:


$ tree           : Factor w/ 2 levels "FALSE","TRUE": 2 1 2 2 2 2 1 1 2 2 ...
$ nothing        : Factor w/ 2 levels "FALSE","TRUE": 1 1 1 1 1 1 1 2 1 1 ...
regards

On Tue, Feb 23, 2016 at 3:53 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

It shall work, I do not see any problem in the code. So you have to persuade us that you checked your data properly e.g. by posting result of

str(mydata)

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Betty
> Betty
> Sent: Tuesday, February 23, 2016 9:37 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] mvProbit error message
>
> Dear All,
> I am running the mvProbit model to estimate five equation probit
> models. In my data all the dependent variables are dichotomous with
> values 0/1 and lables TRUE/FALSE. The explanatory variables are
> composed of catagorical and countinous variables. I specified the model
> as follows
>
> Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~
> x1+x2+x3+......+.x11,data=mydata)
> summary(Result)
>
> However, i get an error message "...Error in
> mvProbit(cbind(y1,y2,y3,y4,y5) ~:all dependent variables must be either
> 0,1,TRUE, or FALSE)
>
> I have checked all the dependent variables and it is coded 0/1 and
> lables TRUE/FALSE.
> Ofcourse there are two missing observation and I attempted to handle
> that with na.action=na.omit but even that didnt solve the problem. My
> second attempt was to tell r that the dichotomous dependent variables
> and the catagorical independent variables as factor as follows
>
> mydata$y1<-factor(mydata$y1)
> ...
> ...
> ..
> .
> mydata$x3<-factor(mydata$x3)
> But still problem not solved. How would I solve this problem?
> Thank you!
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From erich.neuwirth at univie.ac.at  Wed Feb 24 12:11:16 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 24 Feb 2016 12:11:16 +0100
Subject: [R] readRDS problem
In-Reply-To: <56CD7FC0.8040204@wiwi.hu-berlin.de>
References: <56CD7731.3040404@wiwi.hu-berlin.de>
	<56CD7A46.9060508@dewey.myzen.co.uk>
	<56CD7FC0.8040204@wiwi.hu-berlin.de>
Message-ID: <73D7CFA8-5BB2-471A-A8AC-E0A3F1DCEA0F@univie.ac.at>

?data
will show you that data is a reserved word!


> On 24 Feb 2016, at 11:02, Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
> 
> Hi,
> 
> thanks, using
> 
> test <<- readRDS (name)
> 
> it worked. But why?
> 
> Best Sigbert
> 
> Am 24.02.2016 um 10:39 schrieb Michael Dewey:
>> Try calling it something other than data.
>> 
>> On 24/02/2016 09:26, Sigbert Klinke wrote:
>>> Hi,
>>> 
>>> I have two scripts, one creates a data structure (a list of data frames
>>> + some attributes) and saves it via saveRDS.
>>> 
>>> The second script reads the RDS file (outside of any function) and
>>> 
>>> data <- readRDS (name)
>>> 
>>> works, but
>>> 
>>> data <<- readRDS (name)
>>> 
>>> creates the error
>>> 
>>> Error: cannot change value of locked binding for 'data'
>>> 
>>> Any idea what goes wrong?
>>> 
>>> Thanks Sigbert
>>> 
>> 
> 
> 
> --
> http://u.hu-berlin.de/sk <http://u.hu-berlin.de/sk>
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160224/de74f9b5/attachment.bin>

From lists at dewey.myzen.co.uk  Wed Feb 24 12:57:00 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 24 Feb 2016 11:57:00 +0000
Subject: [R] readRDS problem
In-Reply-To: <56CD7FC0.8040204@wiwi.hu-berlin.de>
References: <56CD7731.3040404@wiwi.hu-berlin.de>
	<56CD7A46.9060508@dewey.myzen.co.uk>
	<56CD7FC0.8040204@wiwi.hu-berlin.de>
Message-ID: <56CD9A8C.8050108@dewey.myzen.co.uk>

You need to do
help("<-")
for a full explanation but in brief when you do <- it assigns locally 
and since it could not find data locally it makes it for you but when 
you do <<- it tries its very best to find data somewhere. Since data is 
the name of a function which the authors of R have locked it fails.

On 24/02/2016 10:02, Sigbert Klinke wrote:
> Hi,
>
> thanks, using
>
> test <<- readRDS (name)
>
> it worked. But why?
>
> Best Sigbert
>
> Am 24.02.2016 um 10:39 schrieb Michael Dewey:
>> Try calling it something other than data.
>>
>> On 24/02/2016 09:26, Sigbert Klinke wrote:
>>> Hi,
>>>
>>> I have two scripts, one creates a data structure (a list of data frames
>>> + some attributes) and saves it via saveRDS.
>>>
>>> The second script reads the RDS file (outside of any function) and
>>>
>>> data <- readRDS (name)
>>>
>>> works, but
>>>
>>> data <<- readRDS (name)
>>>
>>> creates the error
>>>
>>> Error: cannot change value of locked binding for 'data'
>>>
>>> Any idea what goes wrong?
>>>
>>> Thanks Sigbert
>>>
>>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From istazahn at gmail.com  Wed Feb 24 12:57:24 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 24 Feb 2016 06:57:24 -0500
Subject: [R] issue -- Packages unavailable for R version 3.2.3
In-Reply-To: <CANOG_FWLvqb9-FFJY6DQhd=anj0BTbesHuE=W2UndbBi-frNvQ@mail.gmail.com>
References: <CANOG_FWLvqb9-FFJY6DQhd=anj0BTbesHuE=W2UndbBi-frNvQ@mail.gmail.com>
Message-ID: <CA+vqiLEmYJ10aS8Re0kqB+AQgA9VO75b3ESFRSeaP5R=XGkRQQ@mail.gmail.com>

Installing unsupported packages is usually not a good idea (there is a
reason they were removed...).

But if you must:

install.packages("devtools")
install_version("sentiment", '0.2')

Best,
Ista

On Wed, Feb 24, 2016 at 2:49 AM, Sandeep Rana
<sunnysingha.analytics at gmail.com> wrote:
> Hi,
>
> I have newly installed R version 3.2.3 and experiencing an issue where the
> packages that I had been using in previous release aren't compatible in the
> latest release.
> I need you help to suggest how we could force the installation even if its
> not supported or what is the workaround to move ahead with it.
>
> Right now, I need to install the package 'sentiment'. Please help.
>
> Regards,
>
> Sandeep S. Rana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Feb 24 13:00:14 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Feb 2016 07:00:14 -0500
Subject: [R] readRDS problem
In-Reply-To: <56CD7731.3040404@wiwi.hu-berlin.de>
References: <56CD7731.3040404@wiwi.hu-berlin.de>
Message-ID: <56CD9B4E.70100@gmail.com>

On 24/02/2016 4:26 AM, Sigbert Klinke wrote:
> Hi,
>
> I have two scripts, one creates a data structure (a list of data frames
> + some attributes) and saves it via saveRDS.
>
> The second script reads the RDS file (outside of any function) and
>
> data <- readRDS (name)
>
> works, but
>
> data <<- readRDS (name)
>
> creates the error
>
> Error: cannot change value of locked binding for 'data'
>
> Any idea what goes wrong?

"data <<-" looks for an existing object named data in a parent 
environment and changes it.  But the existing object is in the utils 
namespace, and you're not allowed to change things there.

Duncan Murdoch


From sergio.fonda99 at gmail.com  Wed Feb 24 13:46:53 2016
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Wed, 24 Feb 2016 13:46:53 +0100
Subject: [R] Order output list od TukeyHSD function by "p adj"
In-Reply-To: <CA+8X3fX4OKfsZkXds0tbmEhuqD+fOnNpKVwCTHnP2-nkxuswDQ@mail.gmail.com>
References: <CAJRuHoq54imZaPKWRQ9ifD8w7kGFoZscPmLh_Zey8+Ui4X9m2g@mail.gmail.com>
	<CA+8X3fX4OKfsZkXds0tbmEhuqD+fOnNpKVwCTHnP2-nkxuswDQ@mail.gmail.com>
Message-ID: <CAJRuHopu2uBVwuxt_9VfM5LPfT0PtimEi6gtDosgR3ZKFriWig@mail.gmail.com>

Thank you Jim also for introducing a shorter data frame.
However the HSD output I deal with is derived from a crossing factors
condition.
Could you kindly explain how could I sort results obtained from a

fm1 <- aov(breaks ~ wool * tension, data = warpbreaks)
hsd.fit<-TukeyHSD(fm1, "wool:tension", ordered = TRUE)

which gives the following "crossing" output where "wool:tension" is a string

$`wool:tension`
              diff        lwr      upr     p adj
A:M-B:H  5.2222222 -10.084100 20.52854 0.9114780
A:H-B:H  5.7777778  -9.528544 21.08410 0.8705572
B:L-B:H  9.4444444  -5.861877 24.75077 0.4560950
B:M-B:H 10.0000000  -5.306322 25.30632 0.3918767
A:L-B:H 25.7777778  10.471456 41.08410 0.0001136
A:H-A:M  0.5555556 -14.750766 15.86188 0.9999978
B:L-A:M  4.2222222 -11.084100 19.52854 0.9626541
B:M-A:M  4.7777778 -10.528544 20.08410 0.9377205
A:L-A:M 20.5555556   5.249234 35.86188 0.0029580
B:L-A:H  3.6666667 -11.639655 18.97299 0.9797123
B:M-A:H  4.2222222 -11.084100 19.52854 0.9626541
A:L-A:H 20.0000000   4.693678 35.30632 0.0040955
B:M-B:L  0.5555556 -14.750766 15.86188 0.9999978
A:L-B:L 16.3333333   1.027012 31.63966 0.0302143
A:L-B:M 15.7777778   0.471456 31.08410 0.0398172


How may I order this part of results by "p adj" ?
Thank you again for your patience!
Sergio

2016-02-24 7:48 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Sergio,
> I couldn't get your example data to read in, so I have used the example in
> the help page:
>
> fm1 <- aov(breaks ~ wool + tension, data = warpbreaks)
> hsd.fit<-TukeyHSD(fm1, "tension", ordered = TRUE)
> hsd.fit$tension[order(hsd.fit$tension[,4]),]
>         diff        lwr      upr       p adj
> L-H 14.722222  5.3688015 24.07564 0.001121788
> L-M 10.000000  0.6465793 19.35342 0.033626219
> M-H  4.722222 -4.6311985 14.07564 0.447421021
>
> Obviously you would have to examine the output of TukeyHSD with str() to
> sort out which column to use for ordering.
>
> Jim
>
>
> On Wed, Feb 24, 2016 at 11:21 AM, Sergio Fonda <sergio.fonda99 at gmail.com>
> wrote:
>
>>  Hello, It's already for several hours that I try to order the list
>> obtained by the function TukeyHSD according to the variable "p adj"
>> (in ascending order). Unfortunately, without success.
>> In addition to following two lines of code, that offer the result but
>> separately so do not correspond to the desired result, I was unable to
>> go:
>> DF.5 <-lapply(DF.4, function (x) as.data.frame(x[c("patient:Fold.fac")]))
>> DF.6 <- DF.5[[1]][order(DF.5[[1]]$patient.Fold.fac.p.adj),]
>> Please, I ask some help to answer these two questions:
>> 1) is it possible to get directly from the function TukeyHSD sorted
>> rows by "p adj"?
>> 2) or, may the output list from TukeyHSD() be processed (e.g. by
>> lapply) to sort its elements according to "p adj"?
>> I attach at bottom a simulation of a list obtained from TukeyHSD which
>> should be ordered by "p adj".
>> Thanks in advance for any suggestion!
>> Sergio
>> #
>> > dput(DF.4)
>> list(structure(list(patient = structure(c(12289274.0619908,
>> -2380308.48287107,
>> -14669582.5448618, -4176414.56676197, -18845997.1116238,
>> -31135271.1736146,
>> 28754962.6907435, 14085380.1458817, 1796106.0838909, 0.186808233632622,
>> 0.938592742253258, 0.0922160074633905), .Dim = 3:4, .Dimnames = list(
>>     c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
>>     "lwr", "upr", "p adj"))), Fold.fac = structure(c(-12697325.7957036,
>> -23938561.4288898, -1456090.1625174, 0.0268617694934425), .Dim = c(1L,
>> 4L), .Dimnames = list("middle-low", c("diff", "lwr", "upr", "p adj"
>> ))), `patient:Fold.fac` = structure(c(15369710.0977205, 6521960.91205235,
>> -4695802.45257667, 4502968.78925385, -16007472.7140147, -8847749.18566819,
>> -20065512.5502972, -10866741.3084667, -31377182.8117352, -11217763.364629,
>> -2018992.12279849, -22529433.626067, 9198771.24183052, -11311670.261438,
>> -20510441.5032685, -12927630.9811041, -21775380.1667723,
>> -33016252.8378897,
>> -23817481.5960591, -44327923.0993277, -37145090.2644928,
>> -48385962.9356102,
>> -39187191.6937797, -59697633.1970482, -39538213.749942, -30339442.5081115,
>> -50849884.01138, -19144769.6082929, -39655211.1115614, -48853982.353392,
>> 43667051.1765452, 34819301.990877, 23624647.9327363, 32823419.1745669,
>> 12312977.6712983, 19449591.8931564, 8254937.83501579, 17453709.0768463,
>> -3056732.42642223, 17102687.020684, 26301458.2625145, 5791016.75924596,
>> 37542312.0919539, 17031870.5886854, 7833099.34685487, 0.632098034657304,
>> 0.986399530577416, 0.997064140940244, 0.997595806079891,
>> 0.590366152539712,
>> 0.948510666498818, 0.330512619876425, 0.883673837089478,
>> 0.0198821692150445,
>> 0.868982868764254, 0.999952294188371, 0.207190890959777,
>> 0.939934594322161,
>> 0.86529009598038, 0.306625751897378), .Dim = c(15L, 4L), .Dimnames = list(
>>     c("PARTIAL:low-COMPLETE:low", "NO:low-COMPLETE:low",
>> "COMPLETE:middle-COMPLETE:low",
>>     "PARTIAL:middle-COMPLETE:low", "NO:middle-COMPLETE:low",
>>     "NO:low-PARTIAL:low", "COMPLETE:middle-PARTIAL:low",
>> "PARTIAL:middle-PARTIAL:low",
>>     "NO:middle-PARTIAL:low", "COMPLETE:middle-NO:low",
>> "PARTIAL:middle-NO:low",
>>     "NO:middle-NO:low", "PARTIAL:middle-COMPLETE:middle",
>> "NO:middle-COMPLETE:middle",
>>     "NO:middle-PARTIAL:middle"), c("diff", "lwr", "upr", "p adj"
>>     )))), .Names = c("patient", "Fold.fac", "patient:Fold.fac"
>> ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
>> abundance ~
>>     patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE),
>>     structure(list(patient = structure(c(11084928.3849924,
>> -3790273.898858,
>>     -14875202.2838504, -2565656.8579769, -17440859.1418273,
>> -28525787.5268197,
>>     24735513.6279617, 9860311.34411127, -1224617.0408811,
>> 0.137587687259541,
>>     0.791659281224941, 0.028733410253219), .Dim = 3:4, .Dimnames = list(
>>         c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
>>         "lwr", "upr", "p adj"))), Fold.fac = structure(c(25003217.9525667,
>>     15683872.2084017, 34322563.6967316, 1.59282125378191e-07), .Dim =
>> c(1L,
>>     4L), .Dimnames = list("low-high", c("diff", "lwr", "upr",
>>     "p adj"))), `patient:Fold.fac` = structure(c(6786144.11764773,
>>     -14136208.8235292, 15255972.7140153, 30625682.8117357,
>> 21777933.6260674,
>>     -20922352.9411769, 8469828.59636761, 23839538.6940879,
>> 14991789.5084197,
>>     29392181.5375445, 44761891.6352649, 35914142.4495966,
>> 15369710.0977203,
>>     6521960.91205206, -8847749.18566828, -16711562.4882314,
>> -37633915.4294083,
>>     -8222591.1541805, 7147118.94353984, -1700630.24212845,
>> -44420059.547056,
>>     -15008735.2718282, 360974.825892106, -8486774.35977618,
>> 5913617.6693487,
>>     21283327.767069, 12435578.5814008, -8089695.41243546,
>> -16937444.5981037,
>>     -32307154.6958241, 30283850.7235268, 9361497.78234989,
>> 38734536.5822112,
>>     54104246.6799315, 45256497.4942632, 2575353.66470216,
>> 31948392.4645634,
>>     47318102.5622838, 38470353.3766155, 52870745.4057404,
>> 68240455.5034607,
>>     59392706.3177924, 38829115.6078761, 29981366.4222079,
>> 14611656.3244875,
>>     0.963180623746077, 0.521122619371869, 0.431445001590424,
>>     0.00280179326576413, 0.0869916657428951, 0.113173926329674,
>>     0.908231706478258, 0.0441523667992262, 0.451984651996765,
>>     0.00489618219443777, 9.080596613531e-07, 0.000195613055067767,
>>     0.42174023314457, 0.968747601969596, 0.891038899833401), .Dim = c(15L,
>>     4L), .Dimnames = list(c("PARTIAL:high-COMPLETE:high",
>> "NO:high-COMPLETE:high",
>>     "COMPLETE:low-COMPLETE:high", "PARTIAL:low-COMPLETE:high",
>>     "NO:low-COMPLETE:high", "NO:high-PARTIAL:high",
>> "COMPLETE:low-PARTIAL:high",
>>     "PARTIAL:low-PARTIAL:high", "NO:low-PARTIAL:high",
>> "COMPLETE:low-NO:high",
>>     "PARTIAL:low-NO:high", "NO:low-NO:high", "PARTIAL:low-COMPLETE:low",
>>     "NO:low-COMPLETE:low", "NO:low-PARTIAL:low"), c("diff", "lwr",
>>     "upr", "p adj")))), .Names = c("patient", "Fold.fac",
>> "patient:Fold.fac"
>>     ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
>> abundance ~
>>         patient * Fold.fac, data = x), conf.level = 0.95, ordered =
>> FALSE))
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From aleminesh57 at gmail.com  Wed Feb 24 10:15:33 2016
From: aleminesh57 at gmail.com (Betty Betty)
Date: Wed, 24 Feb 2016 10:15:33 +0100
Subject: [R] mvProbit error message
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010DB2@SRVEXCHMBX.precheza.cz>
References: <CAOA_h3+9kKrALJMio3W6GNhfxugaynHm=HjeCx1mTiTXAZexMw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010B53@SRVEXCHMBX.precheza.cz>
	<CAOA_h3+wKa6=iPb76-EoLuw4h7G_0kBOms98+sUANHNrxsNNhg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010DB2@SRVEXCHMBX.precheza.cz>
Message-ID: <CAOA_h3LbLqge5V+9uH-HLvhU7qq1QvV9_sRQQHTDba_TszzxBA@mail.gmail.com>

sorry for the confusion. I used y1,y2,.... instead of the real variable
names just for emailing purpose (to forward my question in a more clear
way). Tree, nothing...are the real variable names in my data set and i
actually used
Result<-myProbit(cbind(tree,nothing....)~x1+x2......,data=mydata)

On Wed, Feb 24, 2016 at 10:02 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> Keep your reply to rhelp list. Others can come with better/more
> appropriate solution.
>
>
>
> Pardon me, but you used
>
>
>
> Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~ x1+x2+x3+......+.x11,data=mydata)
>
>
>
> but in mydata there are variables tree and nothing (according what you did
> tell us).
>
>
>
> So I am rather confused.
>
>
>
> Cheers
>
> Petr
>
>
>
> *From:* Betty Betty [mailto:aleminesh57 at gmail.com]
> *Sent:* Wednesday, February 24, 2016 9:55 AM
> *To:* PIKAL Petr
> *Subject:* Re: [R] mvProbit error message
>
>
>
> Thank you very much!
>
> I find the following out put
>
> 1.  If I import the data with read.spss(....use.value.lables=FALSE)
> str(mydata) shows me:
>
>
>
> $ tree           : atomic  1 0 1 1 1 1 0 0 1 1 ...
>
>   ..- attr(*, "value.labels")= Named num  1 0
>
>   .. ..- attr(*, "names")= chr  "TRUE" "FALSE"
>
> $ nothing        : atomic  0 0 0 0 0 0 0 1 0 0 ...
>
>   ..- attr(*, "value.labels")= Named num  1 0
>
>   .. ..- attr(*, "names")= chr  "TRUE" "FALSE"
>
> .
>
> 2.  If I import data with read.spss(....use.value.lables=TRUE)
> str(mydata)
>
> shows me:
>
>
>
>
>
> $ tree           : Factor w/ 2 levels "FALSE","TRUE": 2 1 2 2 2 2 1 1 2 2
> ...
>
> $ nothing        : Factor w/ 2 levels "FALSE","TRUE": 1 1 1 1 1 1 1 2 1 1
> ...
>
> regards
>
>
>
> On Tue, Feb 23, 2016 at 3:53 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
> It shall work, I do not see any problem in the code. So you have to
> persuade us that you checked your data properly e.g. by posting result of
>
> str(mydata)
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Betty
> > Betty
> > Sent: Tuesday, February 23, 2016 9:37 AM
> > To: r-help at r-project.org
> > Subject: [R] mvProbit error message
> >
> > Dear All,
> > I am running the mvProbit model to estimate five equation probit
> > models. In my data all the dependent variables are dichotomous with
> > values 0/1 and lables TRUE/FALSE. The explanatory variables are
> > composed of catagorical and countinous variables. I specified the model
> > as follows
> >
> > Result<-mvProbit( cbind(y1,y2,y3,y4,y5) ~
> > x1+x2+x3+......+.x11,data=mydata)
> > summary(Result)
> >
> > However, i get an error message "...Error in
> > mvProbit(cbind(y1,y2,y3,y4,y5) ~:all dependent variables must be either
> > 0,1,TRUE, or FALSE)
> >
> > I have checked all the dependent variables and it is coded 0/1 and
> > lables TRUE/FALSE.
> > Ofcourse there are two missing observation and I attempted to handle
> > that with na.action=na.omit but even that didnt solve the problem. My
> > second attempt was to tell r that the dichotomous dependent variables
> > and the catagorical independent variables as factor as follows
> >
> > mydata$y1<-factor(mydata$y1)
> > ...
> > ...
> > ..
> > .
> > mydata$x3<-factor(mydata$x3)
> > But still problem not solved. How would I solve this problem?
> > Thank you!
> >
>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From alnazer.elbedairy at gmail.com  Tue Feb 23 21:02:40 2016
From: alnazer.elbedairy at gmail.com (Alnazer)
Date: Tue, 23 Feb 2016 14:02:40 -0600
Subject: [R] KNN
Message-ID: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>

How I can use majority guessing function to evaluate KNN, if I have data saved in CSV file

Alnazer Elbedairy


From alnazer.elbedairy at gmail.com  Wed Feb 24 08:22:00 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Tue, 23 Feb 2016 23:22:00 -0800
Subject: [R] Normalization in R
Message-ID: <CAD2s_FQDuAb6-Y4sJWuzXJAKOJFrvd54O005sU1SS2Yt6Pc0TA@mail.gmail.com>

Dear all
anyone know the function or syntax to get the Normalization for Data ?
thanks

	[[alternative HTML version deleted]]


From cj16551 at bristol.ac.uk  Wed Feb 24 12:11:54 2016
From: cj16551 at bristol.ac.uk (Carlos Gracida Juarez)
Date: Wed, 24 Feb 2016 11:11:54 +0000
Subject: [R] Fwd: about dowloading a package.
In-Reply-To: <CABAY9A2pgcM3BHGJqxoCTzSGQdOX=EmWBowKFRs7FTDtQEFovw@mail.gmail.com>
References: <CABAY9A2OAom4qdDYso8uzsUrqm0b9ivVwOW5K_Smffus0eKZ-g@mail.gmail.com>
	<56CC7CE5.7000902@statistik.tu-dortmund.de>
	<CABAY9A2pgcM3BHGJqxoCTzSGQdOX=EmWBowKFRs7FTDtQEFovw@mail.gmail.com>
Message-ID: <CABAY9A33b7dgWOkBtaX-4gvpqLWo4r8yAo8UX6E7b6UCk1ygHQ@mail.gmail.com>

Good morning, I have an issue with my computer in order to download a
package.

I've tried to download the "mosaicData" and by writing the command and
using the install packages tab, and in the first gives ma a warning
indication that the carpet of destiny is not rewritable, and in the second,
asks me about the possibility of open a new file carpet of destination, but
doesn't allows me to make it.

I hope you can help me, I'm new in the use of Rstudio.

Thanks,

Carlos Gracida


---------- Forwarded message ----------
From: Carlos Gracida Juarez <cj16551 at bristol.ac.uk>
Date: 23 February 2016 at 15:42
Subject: Re: about dowloading a package.
To: Uwe Ligges <ligges at statistik.tu-dortmund.de>


Thanks for your help,

I will follow your indications,

Cheers,

Carlos Gracida

On 23 February 2016 at 15:38, Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

>
>
> On 23.02.2016 16:34, Carlos Gracida Juarez wrote:
>
>> Hi, I am new in the use of R, and I am following a tutorial for learning,
>>
>> I have tried to download a pair of packages and has not been possible,
>> could you send me the indications about "how to download a package and
>> the file extensions I have to chose?
>>
>> I haven't found a helpful answer in the FAQ section.
>>
>> Thanks a lot for your help.
>>
>> Carlos Gracida
>>
>
>
> Use R to install a package, it chooses the right file for you:
>
> install.packages("nameOfPackage")
>
> And for furture questions, please ask on R-help after reading its posting
> guide. This list is intended for development purposes.
>
>
> Best,
> Uwe Ligges
>

	[[alternative HTML version deleted]]


From doug45290 at yahoo.com  Tue Feb 23 23:29:23 2016
From: doug45290 at yahoo.com (D Wolf)
Date: Tue, 23 Feb 2016 22:29:23 +0000 (UTC)
Subject: [R] Reading a datetime vector
In-Reply-To: <CA+8X3fVidTEi5OJpWuBo5QDuzjrNmrx7XL3EE3s9RMi5hCHJzw@mail.gmail.com>
References: <CA+8X3fVidTEi5OJpWuBo5QDuzjrNmrx7XL3EE3s9RMi5hCHJzw@mail.gmail.com>
Message-ID: <1550482130.9095046.1456266563364.JavaMail.yahoo@mail.yahoo.com>

In addition to my previous message, DF_extract_clean.R is the program in the dropbox folder that I am currently working on.
Doug 

    On Tuesday, February 23, 2016 4:02 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Doug,It is difficult for us to work out what is happening as we don't have access to a toy data set that we can play with. Excel spreadsheets are one of those things that you can't just attach to your email to the help list. If there is somewhere you can leave a _small_ Excel sample file (take the first 10 rows, say) that we can download (Google Drive, Dropbox?) and include the URL in your email, maybe someone can offer more than guesses.
Jim


   
	[[alternative HTML version deleted]]


From heathermichel at rocketmail.com  Wed Feb 24 06:33:08 2016
From: heathermichel at rocketmail.com (HEATHER MICHEL)
Date: Wed, 24 Feb 2016 05:33:08 +0000 (UTC)
Subject: [R] R 3.2.3 on Win8; mkdir command produces error
In-Reply-To: <60879E2D775.00000796jrkrideau@inbox.com>
References: <879632620.1043610.1455478822248.javamail.yahoo.ref@mail.yahoo.com>
	<1001578271.3233546.1455493834255.javamail.yahoo@mail.yahoo.com>
	<262825107.3212829.1455493360506.javamail.yahoo@mail.yahoo.com>
	<5cc0a6e5610.00000250jrkrideau@inbox.com>
	<879632620.1043610.1455478822248.javamail.yahoo@mail.yahoo.com>
	<CA+vqiLEUuF9wQEzhVXNQBbowuc+9K1ohd7gYfR2Y196pieNX5g@mail.gmail.com>
	<60879E2D775.00000796jrkrideau@inbox.com>
Message-ID: <407526009.1756151.1456291988464.JavaMail.yahoo@mail.yahoo.com>

I found another MOOC that teaches R at a more basic level than the one I am currently taking. Actually, it was suggested by a classmate who discovered it in her search for how to accomplish this homework assignment. It pointed me to?http://www.statmethods.net/interface/workspace.html?which has a very important statement that pertained to my issue:IMPORTANT NOTE FOR WINDOWS USERS:?
???R?gets confused if you use a path in your code like
???????c:\mydocuments\myfile.txt
???This is because R sees "\" as an escape character. Instead, use?
???????c:\\my documents\\myfile.txt
???????c:/mydocuments/myfile.txt
???Either will work. I use the second convention throughout this website.

This solved my initial problem with calling the correct directory for R to read from. 

    On Monday, February 15, 2016 4:04 PM, John Kane <jrkrideau at inbox.com> wrote:
 

 John Kane
Kingston ON Canada

-----Original Message-----
From: istazahn at gmail.com
Sent: Mon, 15 Feb 2016 11:06:47 -0500
To: jrkrideau at inbox.com
Subject: Re: [R] R 3.2.3 on Win8; mkdir command produces error

 On Feb 15, 2016 8:53 AM, "John Kane" <jrkrideau at inbox.com> wrote:
 >
 > I'd say that Boris Steipe's suggestion is the most likely answer to the problem.? Also, it's been a long time since I used Windows (deo gratias) but that path name does not look right. I think I would have expected something more like:
 >
 > "C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv"
 >
 > Any comments from Windows users?
 >
 > However,? you cannot "load" a .csv file. "load" is intended to load a compiled .Rdata file as I understand it. It may do more but that's all I've ever used it for.
 >
 > You probably want:
 > dat1? <-? read.csv("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv")
 >
 > Depending on how the data file is set up you may need to add various options to the read.csv file.
 >
 > read.csv()? assumes that the file has headers? for the columns and that the separator between the columns is a blank space or spaces.
 >
 > Let's say the separator is a tab and there are no headers you would need to change the read.csv() to
 > xx? <-? read.csv("load("C:/Users/rhmichel/rprog-data-specdata/specdata/001.csv", sep = "\t", header = FALSE)
 >
 > You need to open the data file in a text editor, Notebook will do, and see what it looks like if my two suggestions, or combinations thereof, don't work.
 >
 > Then do a ?read.csv or perhaps a ?read.table try to figure out what the cryptic help documentation tells you. The solution will be there, it just often is not obvious.. read.csv() is simply a subset of? the more powerful read.table().
 >
 > I have great sympathy for you. For the first six months of using R, I seemed to? spend more time trying to get the data into R than working on the problem. Just to be encouraging. :).
 >
 > BTW if the instructor did not suggest it, I would recommend downloading and installing RStudio. https://www.rstudio.com/products/rstudio/download/ [https://www.rstudio.com/products/rstudio/download/] . It is an excellent IDE and makes working with R much easier.
 >
 > @Ista
 > While I agree that Heather should ask her instructor for help, I don't see assisting a student getting data into R as helping with a programming assignment. Perhaps at the margins but that is all.

??? I don't have any objection except the practical concern that people on this list guessing what the problem might be is less likely to lead to a satisfactory answer than asking the instructor. IMO the answers provided so far may have actually increased the OP's confusion. Asking the instructor directly seems to me more likely to produce an illuminating response. 

??? Best,
 Ista


Good point but we already started confusing her :(
??? >
 > John Kane
 > Kingston ON Canada
 >
 >
 > > -----Original Message-----
 > > From: r-help at r-project.org
 > > Sent: Sun, 14 Feb 2016 23:50:34 +0000 (UTC)
 > > To: r-help at r-project.org
 > > Subject: Re: [R] R 3.2.3 on Win8; mkdir command produces error
 > >
 > > As a follow-up to my request for help this morning, I have watched
 > > tutorials on R all afternoon. Many topics come close to my problem, but
 > > none specifically address my situation where "specdata" is not a text
 > > file but a list of small files in a folder.I found a command that should
 > > be more right than mkdir, but it still won't work for my assignment. What
 > > argument am I getting wrong?To recap, I can't access in R my data files
 > > that are on my desktop. I need more understanding about how directories
 > > transfer between Windows and R.
 > >> dir.create('specdata')
 > >
 > >? > dir.exists("specdata")[1] TRUE
 > Error:
 > >> bad restore file magic number (file may be corrupted) -- no data
 > >> loadedIn addition: Warning message:file ?001.csv? has magic number
 > >> '"Date'? Use of save versions prior to 2 is deprecated
 > >> pollutantmean("C:\Users\rhmichel\Desktop\rprog-data-specdata\specdata",
 > >> "sulfate", 1:10)Error: '\U' used without hex digits in character string
 > >> starting ""C:\U">
 > > Thank you for any help you can provide me,Heather Michel
 > >? ? ?On Sunday, February 14, 2016 2:40 PM, HEATHER MICHEL
 > > <heathermichel at rocketmail.com> wrote:
 > >
 > >
 > >? I am trying to complete a homework assignment, but I know very little
 > > about R.The assignment says, "For this programming assignment you will
 > > need to unzip this file and create the directory 'specdata".I unzipped
 > > the file on my desktop, and my computer automatically created a new
 > > folder which I renamed "specdata."However, when I try to make this
 > > directory within R using mkdir, I get this:
 > >> mkdir (specdata)Error: could not find function "mkdir"> ?mkdirNo
 > >> documentation for ?mkdir? in specified packages and libraries:you could
 > >> try ???mkdir?> ??mkdir> pwdError: object 'pwd' not found
 > >
 > > This makes me believe that some of the old command names have been
 > > updated in this version that is only 2 months old. Of course, the
 > > lectures I took notes on used an older version of R and were created more
 > > than 2 months ago.
 > > Please tell me the command I should be using to create a directory named
 > > 'specdata' in R 3.2.3
 > > Heather Michel
 > >
 > >
 > >? ? ? ?[[alternative HTML version deleted]]
 > >
 > > ______________________________________________
 > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > > PLEASE do read the posting guide
 > > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > > and provide commented, minimal, self-contained, reproducible code.
 >
 > ____________________________________________________________
 > FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 > Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] to find out more!
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.




  
	[[alternative HTML version deleted]]


From miceli.leonardo at gmail.com  Tue Feb 23 23:31:11 2016
From: miceli.leonardo at gmail.com (Leonardo Miceli)
Date: Tue, 23 Feb 2016 19:31:11 -0300
Subject: [R] RSQLite: rounding
Message-ID: <56CCDDAF.4080502@gmail.com>


Does anybody here had any problem with rounding using RSQLite?

I have a query which return around 100 thousands records of double 
precision numeric values.

The query returns the numbers with 1 digit precision. But when I run the 
same query but constrains the number of recorded values returned, by 
around 30 records, the precision of the the values is the correct 3 digits!

It is not a matter of formatting, I checked it out. It's really a 
different number returned by the same query only the amount of returned 
data was set different.

Any tips? Something like that had happened to you?

By the way, I put the query below just to see Its simplicity...


 > library(RSQLite)


 > qry1 <- "SELECT * FROM tbFutcotes WHERE Dt >= '1996-01-01' AND 
FK_tbFutureContracts_PK LIKE '%DI1%'"

 > qry2 <- "SELECT * FROM tbFutcotes WHERE Dt >= '2016-02-22' AND 
FK_tbFutureContracts_PK LIKE '%DI1%'"


 > x1 <- dbGetQuery(con, qry1)

 > x2 <- dbGetQuery(con, qry2)


	[[alternative HTML version deleted]]


From pkost at uth.gr  Wed Feb 24 13:08:43 2016
From: pkost at uth.gr (Polychronis KOSTOULAS)
Date: Wed, 24 Feb 2016 14:08:43 +0200
Subject: [R] Double AND within an IF statement
Message-ID: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>


Hi there,

apologies if this is easy. I want to write this condition:

If age is more than 4 years and less or equal to 8 years and infection  
is positive then replacement is 2.

Can you help me the double END?

Thanks,
Polychronis


From Sandeep.Singha at acrotrend.com  Wed Feb 24 08:47:38 2016
From: Sandeep.Singha at acrotrend.com (Sandeep Singha)
Date: Wed, 24 Feb 2016 07:47:38 +0000
Subject: [R] issue -- packages unavailable for R version -- 3.2.3
Message-ID: <AM4PR07MB1409FED1771DFB6D99B7475D9FA50@AM4PR07MB1409.eurprd07.prod.outlook.com>

Hi,

I have newly installed R version 3.2.3 and experiencing an issue where the packages that I had been using in previous release aren't compatible in the latest release.


I need you help to suggest how we could force the installation even if its not supported or what is the workaround to move ahead with it.


Right now, I need to install the package 'sentiment'. Please help.


Regards,

Sandeep S. Rana

sandeep.singha at acrotrend.com

Data Analyst

Acrotrend - Customer Insights & Analytics

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Feb 24 14:42:51 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 24 Feb 2016 13:42:51 +0000
Subject: [R] Normalization in R
In-Reply-To: <CAD2s_FQDuAb6-Y4sJWuzXJAKOJFrvd54O005sU1SS2Yt6Pc0TA@mail.gmail.com>
References: <CAD2s_FQDuAb6-Y4sJWuzXJAKOJFrvd54O005sU1SS2Yt6Pc0TA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010EFD@SRVEXCHMBX.precheza.cz>

Hi

What do you mean by normalisation?

Something like

http://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range

or

http://stackoverflow.com/questions/15215457/standardize-data-columns-in-r

or

https://stat.ethz.ch/pipermail/r-help//2012-October/336676.html

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alnazer
> Elbedairy
> Sent: Wednesday, February 24, 2016 8:22 AM
> To: R-help at r-project.org
> Subject: [R] Normalization in R
>
> Dear all
> anyone know the function or syntax to get the Normalization for Data ?
> thanks
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Feb 24 14:50:14 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 24 Feb 2016 13:50:14 +0000
Subject: [R] Double AND within an IF statement
In-Reply-To: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5010F11@SRVEXCHMBX.precheza.cz>

Hi

if((age>4 & age<8) & (infection >0)) a<-2

Wait,  are you sure you are using R? Maybe you want ifelse.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Polychronis KOSTOULAS
> Sent: Wednesday, February 24, 2016 1:09 PM
> To: r-help at r-project.org
> Subject: [R] Double AND within an IF statement
>
>
> Hi there,
>
> apologies if this is easy. I want to write this condition:
>
> If age is more than 4 years and less or equal to 8 years and infection
> is positive then replacement is 2.
>
> Can you help me the double END?
>
> Thanks,
> Polychronis
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sergio.fonda99 at gmail.com  Wed Feb 24 14:54:23 2016
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Wed, 24 Feb 2016 14:54:23 +0100
Subject: [R] Normalization in R
In-Reply-To: <CAD2s_FQDuAb6-Y4sJWuzXJAKOJFrvd54O005sU1SS2Yt6Pc0TA@mail.gmail.com>
References: <CAD2s_FQDuAb6-Y4sJWuzXJAKOJFrvd54O005sU1SS2Yt6Pc0TA@mail.gmail.com>
Message-ID: <CAJRuHoq3bC=y8G9DEyuKxq=trmy3=t-WgdxCcngjfeySkXSqRA@mail.gmail.com>

If you intend "standardization, use

scale(x, center = TRUE, scale = TRUE),

center for zero mean scale for SD=1

Best regards,

Sergio



2016-02-24 8:22 GMT+01:00 Alnazer Elbedairy <alnazer.elbedairy at gmail.com>:

> Dear all
> anyone know the function or syntax to get the Normalization for Data ?
> thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Feb 24 14:58:55 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 24 Feb 2016 08:58:55 -0500
Subject: [R] issue -- packages unavailable for R version -- 3.2.3
In-Reply-To: <AM4PR07MB1409FED1771DFB6D99B7475D9FA50@AM4PR07MB1409.eurprd07.prod.outlook.com>
References: <AM4PR07MB1409FED1771DFB6D99B7475D9FA50@AM4PR07MB1409.eurprd07.prod.outlook.com>
Message-ID: <CA+vqiLGj_Ssk0pvAp9teOG3i8Q=binKU4fvMYT2mYidGSoFTsg@mail.gmail.com>

Posting the same question in the space of a few hours is considered by many
to be very rude behavior. I have already replied to your previous message.

--Ista
On Feb 24, 2016 8:41 AM, "Sandeep Singha" <Sandeep.Singha at acrotrend.com>
wrote:

> Hi,
>
> I have newly installed R version 3.2.3 and experiencing an issue where the
> packages that I had been using in previous release aren't compatible in the
> latest release.
>
>
> I need you help to suggest how we could force the installation even if its
> not supported or what is the workaround to move ahead with it.
>
>
> Right now, I need to install the package 'sentiment'. Please help.
>
>
> Regards,
>
> Sandeep S. Rana
>
> sandeep.singha at acrotrend.com
>
> Data Analyst
>
> Acrotrend - Customer Insights & Analytics
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Wed Feb 24 15:02:37 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 24 Feb 2016 14:02:37 +0000
Subject: [R] Trying to load a FORTRAN dll but unable
In-Reply-To: <56CB44D7.2020907@gmail.com>
References: <9f67031028e040bd9fbded571fa6d70c@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CB2D9D.2000103@gmail.com>
	<87afae9bf1bf464ba80e183ae6dc9962@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CB44D7.2020907@gmail.com>
Message-ID: <17130505de2140da909daa7f44b70dd5@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Murdoch,

I solved my problem ! 

In fact, the problem is coming from Intel?s FORTRAN and a little from R :

You must tell FORTRAN that parameters are sent by reference and R can only work with routine names in lower case and ending with ?_? (and this underscore must not be written in the .fortran call). So in each function in Fortran you must add these lines :

!DEC$ ATTRIBUTES DLLEXPORT :: mordor_rec_OM
!DEC$ ATTRIBUTES ALIAS:"mordor_rec_om_" :: mordor_rec_OM
!DEC$ ATTRIBUTES C,REFERENCE :: mordor_rec_OM         ! Pour "R"

I am happy !!

Thank you for your help

Jean



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From bob at rudis.net  Wed Feb 24 15:02:39 2016
From: bob at rudis.net (boB Rudis)
Date: Wed, 24 Feb 2016 09:02:39 -0500
Subject: [R] issue -- Packages unavailable for R version 3.2.3
In-Reply-To: <CA+vqiLEmYJ10aS8Re0kqB+AQgA9VO75b3ESFRSeaP5R=XGkRQQ@mail.gmail.com>
References: <CANOG_FWLvqb9-FFJY6DQhd=anj0BTbesHuE=W2UndbBi-frNvQ@mail.gmail.com>
	<CA+vqiLEmYJ10aS8Re0kqB+AQgA9VO75b3ESFRSeaP5R=XGkRQQ@mail.gmail.com>
Message-ID: <CAJ4QxaNHbLN6H_BYHWhpYgN010a8K2mt5aQC9ZNjQyBUuWr=2g@mail.gmail.com>

Will you be able to fix the issues that crop up (or even notice the
issues) for these unsupported packages? (There _is_ a reason they
aren't in CRAN anymore.) That particular one (which is, indeed,
archived in CRAN) also depends on Rstem, which is also archived on
CRAN, and now (according to CRAN) "only available on OmegaHat" (though
older versions in the archive). OmegaHat has been down for a bit, too
(including today).

Basing a business practice on these packages seems to be--at best--an
unwise idea.

I'd suggest moving back to a version of R that those pkgs are able to
run on (probably best in a VM) and use Ista's suggestion or something
like MRAN to get specific versions then freeze that VM for future use.

On Wed, Feb 24, 2016 at 6:57 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Installing unsupported packages is usually not a good idea (there is a
> reason they were removed...).
>
> But if you must:
>
> install.packages("devtools")
> install_version("sentiment", '0.2')
>
> Best,
> Ista
>
> On Wed, Feb 24, 2016 at 2:49 AM, Sandeep Rana
> <sunnysingha.analytics at gmail.com> wrote:
>> Hi,
>>
>> I have newly installed R version 3.2.3 and experiencing an issue where the
>> packages that I had been using in previous release aren't compatible in the
>> latest release.
>> I need you help to suggest how we could force the installation even if its
>> not supported or what is the workaround to move ahead with it.
>>
>> Right now, I need to install the package 'sentiment'. Please help.
>>
>> Regards,
>>
>> Sandeep S. Rana
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From torvon at gmail.com  Wed Feb 24 15:08:47 2016
From: torvon at gmail.com (Torvon)
Date: Wed, 24 Feb 2016 15:08:47 +0100
Subject: [R] Loading large .pxt and .asc datasets causes issues.
In-Reply-To: <CAOwvMDyT=-NwWo3nDROH_nor4qw9UAdctE3+oyAc6_VqQUMFDg@mail.gmail.com>
References: <CACm_P7oDW8_sCbUdaQG6Obq+D6quA9XPTThwYO3tEb+6jFn7jg@mail.gmail.com>
	<F1065E5D886F4D429259CDEAE3F83CB61AFF2DFE@msgdb20.utad.utoledo.edu>
	<CAOwvMDyT=-NwWo3nDROH_nor4qw9UAdctE3+oyAc6_VqQUMFDg@mail.gmail.com>
Message-ID: <CACm_P7ry34vsozu+sC+QE-7g8Hz0cEsh=VxX=YojKG4AoXrmyg@mail.gmail.com>

This is incredibly helpful, thank you all!

On 24 February 2016 at 04:02, Anthony Damico <ajdamico at gmail.com> wrote:

> hi eiko, LaF is incompatible with survey data, that road is a dead-end.
> this code below will painlessly load brfss into R, review the link douglas
> sent for analysis examples and change `years.to.download <- ` to 2006 only
> if you just want a single year of microdata.  glhf
>
>
> # install.packages( c("MonetDB.R", "MonetDBLite" , "survey" , "SAScii" ,
> "descr" , "downloader" , "digest" ) , repos=c("
> http://dev.monetdb.org/Assets/R/", "http://cran.rstudio.com/"))
>
> # setInternet2( FALSE )                        # # only windows users need
> this line
> # options( encoding = "windows-1252" )        # # only macintosh and *nix
> users need this line
> library(downloader)
> # setwd( "C:/My Directory/BRFSS/" )
> years.to.download <- 1984:2014
> source_url( "
> https://raw.githubusercontent.com/ajdamico/asdfree/master/Behavioral%20Risk%20Factor%20Surveillance%20System/download%20all%20microdata.R"
> , prompt = FALSE , echo = TRUE )
>
>
>
>
>
> On Tue, Feb 23, 2016 at 4:39 PM, Federman, Douglas <
> Douglas.Federman at utoledo.edu> wrote:
>
>> You might want to look at Anthony Damico's work at
>>
>>
>> http://www.asdfree.com/search/label/behavioral%20risk%20factor%20surveillance%20system%20%28brfss%29
>>
>> --
>> Better name for the general practitioner might be multispecialist.
>> ~Martin H. Fischer (1879-1962)
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Torvon
>> Sent: Tuesday, February 23, 2016 2:13 PM
>> To: r-help at r-project.org
>> Subject: [R] Loading large .pxt and .asc datasets causes issues.
>>
>> Hi,
>>
>> I want to load a dataset into R. This dataset is available in two formats:
>> .XPT and .ASC. The dataset is available at
>> http://www.cdc.gov/brfss/annual_data/annual_2006.htm.
>>
>> They are about 40mb zipped, and about 500mb unzipped.
>>
>> I can get the .xpt data to load, using:
>>
>> > library(hmisc)
>> > data <- sasxport.get("CDBRFS06.XPT")
>>
>> The data look fine, no error messages. However, the data only contains
>> 302 columns, which is less than it should have (according to the
>> documentation). It does not contain my variables of interest, so either the
>> documentation or the data file is wrong, and I want to make sure it's not
>> the data file.
>>
>> Hence I wanted to see if I get the same results loading the .ASC file.
>> However, multiple ways to do so have failed.
>>
>> > library(adehabitat)
>> > import.asc("CDBRFS06.asc")
>>
>> Results in:
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
>> : scan() expected 'a real', got '1191.8808943.38209868648.960119'
>>
>> > library(SDMTools)
>> > read.asc("CDBRFS06.asc")
>>
>> Results in:
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
>> : scan() expected 'a real', got '1191.8808943.38209868648.960119' In
>> addition: Warning messages: 1: In scan(file, what, nmax, sep, dec, quote,
>> skip, nlines, na.strings, : number of items read is not a multiple of the
>> number of columns 2: In scan(file, what, nmax, sep, dec, quote, skip,
>> nlines, na.strings, : number of items read is not a multiple of the number
>> of columns 3: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
>> na.strings, : number of items read is not a multiple of the number of
>> columns 4: In scan(file, what, nmax, sep, dec, quote, skip, nlines,
>> na.strings, : number of items read is not a multiple of the number of
>> columns 5: In scan(file, nmax = nl * nc, skip = 6, quiet = TRUE) : NAs
>> introduced by coercion to integer range
>>
>> Thank you for your help.
>>    Eiko
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Feb 24 15:52:49 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 24 Feb 2016 15:52:49 +0100
Subject: [R] issue -- Packages unavailable for R version 3.2.3
In-Reply-To: <CAJ4QxaNHbLN6H_BYHWhpYgN010a8K2mt5aQC9ZNjQyBUuWr=2g@mail.gmail.com>
References: <CANOG_FWLvqb9-FFJY6DQhd=anj0BTbesHuE=W2UndbBi-frNvQ@mail.gmail.com>
	<CA+vqiLEmYJ10aS8Re0kqB+AQgA9VO75b3ESFRSeaP5R=XGkRQQ@mail.gmail.com>
	<CAJ4QxaNHbLN6H_BYHWhpYgN010a8K2mt5aQC9ZNjQyBUuWr=2g@mail.gmail.com>
Message-ID: <26F84338-5461-42D2-A3FC-BAD4B18AFDFF@gmail.com>

Hmm, well.... I probably wouldn't suggest that you roll 3 years worth of bugs in R back in, but it obviously is a conundrum, whether to do that or to fix issues that have cropped up in a package over three years. 

The author seems to have a beef with CRAN (we saw an outburst less than a week ago), but from what I gather, Rstem got rolled into RTextTools, which _is_ on CRAN, so you might get away with installing that, then get the sentiment-tarball from CRAN, unpack it, modify dependencies, and see whether sentiment installs from its local directory. (You can also get it from the author's github, but that hasn't been touch for three years either, and modifying probably isn't easier that way.)

It's not unlikely that you will need a copy of "Writing R Extensions" at hand.

-pd


On 24 Feb 2016, at 15:02 , boB Rudis <bob at rudis.net> wrote:

> Will you be able to fix the issues that crop up (or even notice the
> issues) for these unsupported packages? (There _is_ a reason they
> aren't in CRAN anymore.) That particular one (which is, indeed,
> archived in CRAN) also depends on Rstem, which is also archived on
> CRAN, and now (according to CRAN) "only available on OmegaHat" (though
> older versions in the archive). OmegaHat has been down for a bit, too
> (including today).
> 
> Basing a business practice on these packages seems to be--at best--an
> unwise idea.
> 
> I'd suggest moving back to a version of R that those pkgs are able to
> run on (probably best in a VM) and use Ista's suggestion or something
> like MRAN to get specific versions then freeze that VM for future use.
> 
> On Wed, Feb 24, 2016 at 6:57 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Installing unsupported packages is usually not a good idea (there is a
>> reason they were removed...).
>> 
>> But if you must:
>> 
>> install.packages("devtools")
>> install_version("sentiment", '0.2')
>> 
>> Best,
>> Ista
>> 
>> On Wed, Feb 24, 2016 at 2:49 AM, Sandeep Rana
>> <sunnysingha.analytics at gmail.com> wrote:
>>> Hi,
>>> 
>>> I have newly installed R version 3.2.3 and experiencing an issue where the
>>> packages that I had been using in previous release aren't compatible in the
>>> latest release.
>>> I need you help to suggest how we could force the installation even if its
>>> not supported or what is the workaround to move ahead with it.
>>> 
>>> Right now, I need to install the package 'sentiment'. Please help.
>>> 
>>> Regards,
>>> 
>>> Sandeep S. Rana
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bob at rudis.net  Wed Feb 24 16:05:37 2016
From: bob at rudis.net (boB Rudis)
Date: Wed, 24 Feb 2016 10:05:37 -0500
Subject: [R] issue -- Packages unavailable for R version 3.2.3
In-Reply-To: <26F84338-5461-42D2-A3FC-BAD4B18AFDFF@gmail.com>
References: <CANOG_FWLvqb9-FFJY6DQhd=anj0BTbesHuE=W2UndbBi-frNvQ@mail.gmail.com>
	<CA+vqiLEmYJ10aS8Re0kqB+AQgA9VO75b3ESFRSeaP5R=XGkRQQ@mail.gmail.com>
	<CAJ4QxaNHbLN6H_BYHWhpYgN010a8K2mt5aQC9ZNjQyBUuWr=2g@mail.gmail.com>
	<26F84338-5461-42D2-A3FC-BAD4B18AFDFF@gmail.com>
Message-ID: <CAJ4QxaOnaapvsn0mVLmVxKp0hN05PnrRHuThaRQ5s9vP4BhLbQ@mail.gmail.com>

>'It's not unlikely that you will need a copy of "Writing R Extensions" at hand.'

+ a few bottles of Scotch.

It might be worth approaching rOpenSci https://ropensci.org/ to take
over resurrection/maintenance of this.

But, it seems others are in your predicament:

https://www.researchgate.net/post/Does_anyone_know_of_an_alternative_R_package_for_sentiment_analysis

so there may be others you can reach out to for alternatives.


From sarah.goslee at gmail.com  Wed Feb 24 16:06:28 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 24 Feb 2016 10:06:28 -0500
Subject: [R] RSQLite: rounding
In-Reply-To: <56CCDDAF.4080502@gmail.com>
References: <56CCDDAF.4080502@gmail.com>
Message-ID: <CAM_vjukTQzUpOQrkh4FWpU8KG-Cq2xXDZzpa0_F6TkEtjnaY_Q@mail.gmail.com>

How did you "check it out"? I still suspect a formatting issue.

Please use dput() to provide a bit of data from each, eg
dput(head(x1))
dput(head(x2))

Sarah

On Tue, Feb 23, 2016 at 5:31 PM, Leonardo Miceli
<miceli.leonardo at gmail.com> wrote:
>
> Does anybody here had any problem with rounding using RSQLite?
>
> I have a query which return around 100 thousands records of double
> precision numeric values.
>
> The query returns the numbers with 1 digit precision. But when I run the
> same query but constrains the number of recorded values returned, by
> around 30 records, the precision of the the values is the correct 3 digits!
>
> It is not a matter of formatting, I checked it out. It's really a
> different number returned by the same query only the amount of returned
> data was set different.
>
> Any tips? Something like that had happened to you?
>
> By the way, I put the query below just to see Its simplicity...
>
>
>  > library(RSQLite)
>
>
>  > qry1 <- "SELECT * FROM tbFutcotes WHERE Dt >= '1996-01-01' AND
> FK_tbFutureContracts_PK LIKE '%DI1%'"
>
>  > qry2 <- "SELECT * FROM tbFutcotes WHERE Dt >= '2016-02-22' AND
> FK_tbFutureContracts_PK LIKE '%DI1%'"
>
>
>  > x1 <- dbGetQuery(con, qry1)
>
>  > x2 <- dbGetQuery(con, qry2)
>


From abdel.halloway at gmail.com  Wed Feb 24 16:21:55 2016
From: abdel.halloway at gmail.com (Abdel Halloway)
Date: Wed, 24 Feb 2016 09:21:55 -0600
Subject: [R] Problems with the deSolve package
In-Reply-To: <DUB119-W21FE0AE8575EB6A266E3F9AEA30@phx.gbl>
References: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>
	<CANKjaMfwdqPXnd=DbHCJkgb5c6YpdmbZx9SA3Kz2CsQcdxdZMw@mail.gmail.com>
	<DUB119-W21FE0AE8575EB6A266E3F9AEA30@phx.gbl>
Message-ID: <CANKjaMdaWBOkZb-_hbK_nZovMh9Ef9WpwpG33ZsheU5O7JNkLA@mail.gmail.com>

I think your delta is too high. If you reduce your delta (0.1 for example),
you should be able to get good results.

On Mon, Feb 22, 2016 at 3:37 AM, Alexandre Suire <alexandresuire at hotmail.fr>
wrote:

> Hello Abdel,
>
> I'm trying to model the spread of two viruses between different states,
> which are i1 and i2, and i12 if you got both viruses, but you can go back
> to the previous state with given probabilities (alpha, beta). The gamma
> probabilities are just additional infection (without contact) and delta an
> interaction factor between virus 1 and 2.
>
> I tried lowering the time steps, and, as you said, i1 and i2 are going
> negative, but it stops after a few steps. In effect, that's not what I'm
> looking for. I just want to model the dynamic of this system, and do some
> king of sensitivity analysis. I tried different set of parameters, but it
> still gives me the same error message. Maybe this has to do with my
> equations ? But I really doubt it.
>
> Thank you for your time
> Alex
>
> ------------------------------
> From: abdel.halloway at gmail.com
> Date: Sat, 20 Feb 2016 11:01:00 -0600
> Subject: Re: [R] Problems with the deSolve package
> To: alexandresuire at hotmail.fr
> CC: r-help at r-project.org
>
>
> I think your parameters are off. If you look at the simul data frame, it
> gives you a bunch of NaNs after the first initialization. If you put lower
> the timesteps s.t.
>
> > times<-seq(0,200, by=0.01)
>
> it begins to run but soon your values diverge, i1 & i2 going negative
> while i12 goes way high. Not sure what you are modeling but I assume those
> values aren't to be like that. Try again with different parameters and see.
>
> On Fri, Feb 19, 2016 at 2:42 AM, Alexandre Suire <
> alexandresuire at hotmail.fr> wrote:
>
> Hello R-users,
>
> I'm trying to build a SIR-like model under R,
> using the "deSolve" package. I'm trying to do simulations of its dynamic
>  over time, with three differential equations. I'm also looking to
> calculate the equilibrium state.
>
> So far, my code looks like this
>
> library(deSolve)
> #This is my system, with three differential equations
> system<-function(times, init, parameters){
> with(as.list(c(init, parameters)),{
>
> di1_dt=(alpha1*(N-i1-i2-i12)*(i1+i12))+(beta2*i12+gamma1*(N-i1-i2-i12))-(beta1*i1)-(delta*alpha2*i1*(i2+i12))
>
> di2_dt=(alpha2*(N-i1-i2-i12)*(i2+i12))+(beta1*i12+gamma2*(N-i1-i2-i12))-(beta2*i2)-(delta*alpha1*i2*(i1+i12))
>
> di12_dt=(delta*alpha2*i1*(i12+i2))+(delta*alpha1*i2*(i12*i1))+(delta*gamma1*i1)+(delta*gamma2*i2)-((beta1+beta2)*i12)
> return(list(c(di1_dt,di2_dt,di12_dt)))
> })
> }
>
> # Initials values and parameters
> init<-c(i1=10, i2=10, i12=0)
> parameters<-c(alpha1=0.7, alpha2=0.5, beta1=0.5, beta2=0.3, gamma1=0.5,
> gamma2=0.5, delta=0.5, N=100)
> times<-seq(0,200, by=1)
> simul <- as.data.frame(ode(y = init, times = times, func = system, parms =
> parameters, method="ode45"))
> simul$time <- NULL
> head(simul,200)
>
> #Plotting the results
> matplot(times,
>  simul, type = "l", xlab = "Time", ylab = "i1 i2 i12", main =
> "Simulation", lwd = 2, lty = 2, bty = "l", col=c("darkblue",
> "darkred","mediumseagreen"))
> legend("bottomright", c("i1", "i2","i12"), lty=2,lwd=2, col =
> c("darkblue", "darkred", "mediumseagreen"))
>
> At
>  first, I just tried studying with only the first two equations, and it
> seems to work completely fine, but when I wanted to add the 3rd
> equation, I sometimes get this message, even when I juggle the
> parameters, when i launch the line:
> #simul <- as.data.frame(ode(y = init, times = times, func = system, parms
> = parameters))
> Warning messages:
> 1: In lsode(y, times, func, parms, mf = 10, ...) :
>   an excessive amount of work (> maxsteps ) was done, but integration was
> not successful - increase maxsteps
> 2: In lsode(y, times, func, parms, mf = 10, ...) :
>   Returning early. Results are accurate, as far as they go
>
> Have I overlooked something ? I tried to use methods="ode45" and
> methods="adams", without any sucess.
> Thank you for your time
> Alex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Feb 24 16:46:37 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Feb 2016 15:46:37 +0000
Subject: [R] KNN
In-Reply-To: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70D505@mb02.ads.tamu.edu>

Your question is too vague. What do you know about R? What do you know about KNN? What have you tried so far? You need to teach yourself enough about R to ask a more specific question. To get started, read some of these:

Contributed Documentation (https://cran.r-project.org/other-docs.html)
* "Using R for Data Analysis and Graphics - Introduction, Examples and Commentary" by John Maindonald (https://cran.r-project.org/doc/contrib/usingR.pdf) 
* "R for Beginners" by Emmanuel Paradis 
  (https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf)
* "Kickstarting R (version 1.6)" compiled by Jim Lemon
  (https://cran.r-project.org/doc/contrib/Lemon-kickstart/index.html)

Then some of these
* Data Mining Algorithms In R/Classification/kNN
  (https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/kNN)
* Machine Learning in R for beginners
  (https://www.datacamp.com/community/tutorials/machine-learning-in-r)
* Best way to learn kNN Algorithm using R Programming
  (http://www.analyticsvidhya.com/blog/2015/08/learning-concept-knn-algorithms-programming/)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alnazer
Sent: Tuesday, February 23, 2016 2:03 PM
To: r-help at r-project.org
Subject: [R] KNN

How I can use majority guessing function to evaluate KNN, if I have data saved in CSV file

Alnazer Elbedairy

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From abdel.halloway at gmail.com  Wed Feb 24 16:46:22 2016
From: abdel.halloway at gmail.com (Abdel Halloway)
Date: Wed, 24 Feb 2016 09:46:22 -0600
Subject: [R] Problems with the deSolve package
In-Reply-To: <CANKjaMdaWBOkZb-_hbK_nZovMh9Ef9WpwpG33ZsheU5O7JNkLA@mail.gmail.com>
References: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>
	<CANKjaMfwdqPXnd=DbHCJkgb5c6YpdmbZx9SA3Kz2CsQcdxdZMw@mail.gmail.com>
	<DUB119-W21FE0AE8575EB6A266E3F9AEA30@phx.gbl>
	<CANKjaMdaWBOkZb-_hbK_nZovMh9Ef9WpwpG33ZsheU5O7JNkLA@mail.gmail.com>
Message-ID: <CANKjaMckMnufs4c668nT8FGojbCyVfV_fx1-QGzNknHJSGGKqQ@mail.gmail.com>

Okay, so if delta is high (say 0.5), the betas have to be extremely high
(around 5) to get good results. If delta is around 0.1, you can get good
results with smaller betas.

On Wed, Feb 24, 2016 at 9:21 AM, Abdel Halloway <abdel.halloway at gmail.com>
wrote:

> I think your delta is too high. If you reduce your delta (0.1 for
> example), you should be able to get good results.
>
> On Mon, Feb 22, 2016 at 3:37 AM, Alexandre Suire <
> alexandresuire at hotmail.fr> wrote:
>
>> Hello Abdel,
>>
>> I'm trying to model the spread of two viruses between different states,
>> which are i1 and i2, and i12 if you got both viruses, but you can go back
>> to the previous state with given probabilities (alpha, beta). The gamma
>> probabilities are just additional infection (without contact) and delta an
>> interaction factor between virus 1 and 2.
>>
>> I tried lowering the time steps, and, as you said, i1 and i2 are going
>> negative, but it stops after a few steps. In effect, that's not what I'm
>> looking for. I just want to model the dynamic of this system, and do some
>> king of sensitivity analysis. I tried different set of parameters, but it
>> still gives me the same error message. Maybe this has to do with my
>> equations ? But I really doubt it.
>>
>> Thank you for your time
>> Alex
>>
>> ------------------------------
>> From: abdel.halloway at gmail.com
>> Date: Sat, 20 Feb 2016 11:01:00 -0600
>> Subject: Re: [R] Problems with the deSolve package
>> To: alexandresuire at hotmail.fr
>> CC: r-help at r-project.org
>>
>>
>> I think your parameters are off. If you look at the simul data frame, it
>> gives you a bunch of NaNs after the first initialization. If you put lower
>> the timesteps s.t.
>>
>> > times<-seq(0,200, by=0.01)
>>
>> it begins to run but soon your values diverge, i1 & i2 going negative
>> while i12 goes way high. Not sure what you are modeling but I assume those
>> values aren't to be like that. Try again with different parameters and see.
>>
>> On Fri, Feb 19, 2016 at 2:42 AM, Alexandre Suire <
>> alexandresuire at hotmail.fr> wrote:
>>
>> Hello R-users,
>>
>> I'm trying to build a SIR-like model under R,
>> using the "deSolve" package. I'm trying to do simulations of its dynamic
>>  over time, with three differential equations. I'm also looking to
>> calculate the equilibrium state.
>>
>> So far, my code looks like this
>>
>> library(deSolve)
>> #This is my system, with three differential equations
>> system<-function(times, init, parameters){
>> with(as.list(c(init, parameters)),{
>>
>> di1_dt=(alpha1*(N-i1-i2-i12)*(i1+i12))+(beta2*i12+gamma1*(N-i1-i2-i12))-(beta1*i1)-(delta*alpha2*i1*(i2+i12))
>>
>> di2_dt=(alpha2*(N-i1-i2-i12)*(i2+i12))+(beta1*i12+gamma2*(N-i1-i2-i12))-(beta2*i2)-(delta*alpha1*i2*(i1+i12))
>>
>> di12_dt=(delta*alpha2*i1*(i12+i2))+(delta*alpha1*i2*(i12*i1))+(delta*gamma1*i1)+(delta*gamma2*i2)-((beta1+beta2)*i12)
>> return(list(c(di1_dt,di2_dt,di12_dt)))
>> })
>> }
>>
>> # Initials values and parameters
>> init<-c(i1=10, i2=10, i12=0)
>> parameters<-c(alpha1=0.7, alpha2=0.5, beta1=0.5, beta2=0.3, gamma1=0.5,
>> gamma2=0.5, delta=0.5, N=100)
>> times<-seq(0,200, by=1)
>> simul <- as.data.frame(ode(y = init, times = times, func = system, parms
>> = parameters, method="ode45"))
>> simul$time <- NULL
>> head(simul,200)
>>
>> #Plotting the results
>> matplot(times,
>>  simul, type = "l", xlab = "Time", ylab = "i1 i2 i12", main =
>> "Simulation", lwd = 2, lty = 2, bty = "l", col=c("darkblue",
>> "darkred","mediumseagreen"))
>> legend("bottomright", c("i1", "i2","i12"), lty=2,lwd=2, col =
>> c("darkblue", "darkred", "mediumseagreen"))
>>
>> At
>>  first, I just tried studying with only the first two equations, and it
>> seems to work completely fine, but when I wanted to add the 3rd
>> equation, I sometimes get this message, even when I juggle the
>> parameters, when i launch the line:
>> #simul <- as.data.frame(ode(y = init, times = times, func = system, parms
>> = parameters))
>> Warning messages:
>> 1: In lsode(y, times, func, parms, mf = 10, ...) :
>>   an excessive amount of work (> maxsteps ) was done, but integration was
>> not successful - increase maxsteps
>> 2: In lsode(y, times, func, parms, mf = 10, ...) :
>>   Returning early. Results are accurate, as far as they go
>>
>> Have I overlooked something ? I tried to use methods="ode45" and
>> methods="adams", without any sucess.
>> Thank you for your time
>> Alex
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 24 16:55:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 07:55:34 -0800
Subject: [R] issue -- packages unavailable for R version -- 3.2.3
In-Reply-To: <AM4PR07MB1409FED1771DFB6D99B7475D9FA50@AM4PR07MB1409.eurprd07.prod.outlook.com>
References: <AM4PR07MB1409FED1771DFB6D99B7475D9FA50@AM4PR07MB1409.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbQU+PEK=4hf0Ch4mkdpaz5krgouz+Sr7Wu4CU2MN=ErmQ@mail.gmail.com>

?update.packages


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 23, 2016 at 11:47 PM, Sandeep Singha
<Sandeep.Singha at acrotrend.com> wrote:
> Hi,
>
> I have newly installed R version 3.2.3 and experiencing an issue where the packages that I had been using in previous release aren't compatible in the latest release.
>
>
> I need you help to suggest how we could force the installation even if its not supported or what is the workaround to move ahead with it.
>
>
> Right now, I need to install the package 'sentiment'. Please help.
>
>
> Regards,
>
> Sandeep S. Rana
>
> sandeep.singha at acrotrend.com
>
> Data Analyst
>
> Acrotrend - Customer Insights & Analytics
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Feb 24 17:02:28 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Feb 2016 16:02:28 +0000
Subject: [R] Order output list od TukeyHSD function by "p adj"
In-Reply-To: <CAJRuHopu2uBVwuxt_9VfM5LPfT0PtimEi6gtDosgR3ZKFriWig@mail.gmail.com>
References: <CAJRuHoq54imZaPKWRQ9ifD8w7kGFoZscPmLh_Zey8+Ui4X9m2g@mail.gmail.com>
	<CA+8X3fX4OKfsZkXds0tbmEhuqD+fOnNpKVwCTHnP2-nkxuswDQ@mail.gmail.com>
	<CAJRuHopu2uBVwuxt_9VfM5LPfT0PtimEi6gtDosgR3ZKFriWig@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70D542@mb02.ads.tamu.edu>

hsd.fit is list containing 1 element, a matrix called "wool:tension". It will be simpler if you extract the matrix and then use order() to get the matrix sorted by p adj:

> table <- hsd.fit[["wool:tension"]]
> table[order(table[, 'p adj']), ]
              diff        lwr      upr        p adj
A:L-B:H 25.7777778  10.471456 41.08410 0.0001136469
A:L-A:M 20.5555556   5.249234 35.86188 0.0029580438
A:L-A:H 20.0000000   4.693678 35.30632 0.0040954674
A:L-B:L 16.3333333   1.027012 31.63966 0.0302143219
A:L-B:M 15.7777778   0.471456 31.08410 0.0398172376
B:M-B:H 10.0000000  -5.306322 25.30632 0.3918766902
B:L-B:H  9.4444444  -5.861877 24.75077 0.4560949981
A:H-B:H  5.7777778  -9.528544 21.08410 0.8705571533
A:M-B:H  5.2222222 -10.084100 20.52854 0.9114780002
B:M-A:M  4.7777778 -10.528544 20.08410 0.9377205494
B:L-A:M  4.2222222 -11.084100 19.52854 0.9626540845
B:M-A:H  4.2222222 -11.084100 19.52854 0.9626540845
B:L-A:H  3.6666667 -11.639655 18.97299 0.9797122861
A:H-A:M  0.5555556 -14.750766 15.86188 0.9999978240
B:M-B:L  0.5555556 -14.750766 15.86188 0.9999978240

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sergio Fonda
Sent: Wednesday, February 24, 2016 6:47 AM
To: Jim Lemon
Cc: r-help at r-project.org
Subject: Re: [R] Order output list od TukeyHSD function by "p adj"

Thank you Jim also for introducing a shorter data frame.
However the HSD output I deal with is derived from a crossing factors
condition.
Could you kindly explain how could I sort results obtained from a

fm1 <- aov(breaks ~ wool * tension, data = warpbreaks)
hsd.fit<-TukeyHSD(fm1, "wool:tension", ordered = TRUE)

which gives the following "crossing" output where "wool:tension" is a string

$`wool:tension`
              diff        lwr      upr     p adj
A:M-B:H  5.2222222 -10.084100 20.52854 0.9114780
A:H-B:H  5.7777778  -9.528544 21.08410 0.8705572
B:L-B:H  9.4444444  -5.861877 24.75077 0.4560950
B:M-B:H 10.0000000  -5.306322 25.30632 0.3918767
A:L-B:H 25.7777778  10.471456 41.08410 0.0001136
A:H-A:M  0.5555556 -14.750766 15.86188 0.9999978
B:L-A:M  4.2222222 -11.084100 19.52854 0.9626541
B:M-A:M  4.7777778 -10.528544 20.08410 0.9377205
A:L-A:M 20.5555556   5.249234 35.86188 0.0029580
B:L-A:H  3.6666667 -11.639655 18.97299 0.9797123
B:M-A:H  4.2222222 -11.084100 19.52854 0.9626541
A:L-A:H 20.0000000   4.693678 35.30632 0.0040955
B:M-B:L  0.5555556 -14.750766 15.86188 0.9999978
A:L-B:L 16.3333333   1.027012 31.63966 0.0302143
A:L-B:M 15.7777778   0.471456 31.08410 0.0398172


How may I order this part of results by "p adj" ?
Thank you again for your patience!
Sergio

2016-02-24 7:48 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Sergio,
> I couldn't get your example data to read in, so I have used the example in
> the help page:
>
> fm1 <- aov(breaks ~ wool + tension, data = warpbreaks)
> hsd.fit<-TukeyHSD(fm1, "tension", ordered = TRUE)
> hsd.fit$tension[order(hsd.fit$tension[,4]),]
>         diff        lwr      upr       p adj
> L-H 14.722222  5.3688015 24.07564 0.001121788
> L-M 10.000000  0.6465793 19.35342 0.033626219
> M-H  4.722222 -4.6311985 14.07564 0.447421021
>
> Obviously you would have to examine the output of TukeyHSD with str() to
> sort out which column to use for ordering.
>
> Jim
>
>
> On Wed, Feb 24, 2016 at 11:21 AM, Sergio Fonda <sergio.fonda99 at gmail.com>
> wrote:
>
>>  Hello, It's already for several hours that I try to order the list
>> obtained by the function TukeyHSD according to the variable "p adj"
>> (in ascending order). Unfortunately, without success.
>> In addition to following two lines of code, that offer the result but
>> separately so do not correspond to the desired result, I was unable to
>> go:
>> DF.5 <-lapply(DF.4, function (x) as.data.frame(x[c("patient:Fold.fac")]))
>> DF.6 <- DF.5[[1]][order(DF.5[[1]]$patient.Fold.fac.p.adj),]
>> Please, I ask some help to answer these two questions:
>> 1) is it possible to get directly from the function TukeyHSD sorted
>> rows by "p adj"?
>> 2) or, may the output list from TukeyHSD() be processed (e.g. by
>> lapply) to sort its elements according to "p adj"?
>> I attach at bottom a simulation of a list obtained from TukeyHSD which
>> should be ordered by "p adj".
>> Thanks in advance for any suggestion!
>> Sergio
>> #
>> > dput(DF.4)
>> list(structure(list(patient = structure(c(12289274.0619908,
>> -2380308.48287107,
>> -14669582.5448618, -4176414.56676197, -18845997.1116238,
>> -31135271.1736146,
>> 28754962.6907435, 14085380.1458817, 1796106.0838909, 0.186808233632622,
>> 0.938592742253258, 0.0922160074633905), .Dim = 3:4, .Dimnames = list(
>>     c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
>>     "lwr", "upr", "p adj"))), Fold.fac = structure(c(-12697325.7957036,
>> -23938561.4288898, -1456090.1625174, 0.0268617694934425), .Dim = c(1L,
>> 4L), .Dimnames = list("middle-low", c("diff", "lwr", "upr", "p adj"
>> ))), `patient:Fold.fac` = structure(c(15369710.0977205, 6521960.91205235,
>> -4695802.45257667, 4502968.78925385, -16007472.7140147, -8847749.18566819,
>> -20065512.5502972, -10866741.3084667, -31377182.8117352, -11217763.364629,
>> -2018992.12279849, -22529433.626067, 9198771.24183052, -11311670.261438,
>> -20510441.5032685, -12927630.9811041, -21775380.1667723,
>> -33016252.8378897,
>> -23817481.5960591, -44327923.0993277, -37145090.2644928,
>> -48385962.9356102,
>> -39187191.6937797, -59697633.1970482, -39538213.749942, -30339442.5081115,
>> -50849884.01138, -19144769.6082929, -39655211.1115614, -48853982.353392,
>> 43667051.1765452, 34819301.990877, 23624647.9327363, 32823419.1745669,
>> 12312977.6712983, 19449591.8931564, 8254937.83501579, 17453709.0768463,
>> -3056732.42642223, 17102687.020684, 26301458.2625145, 5791016.75924596,
>> 37542312.0919539, 17031870.5886854, 7833099.34685487, 0.632098034657304,
>> 0.986399530577416, 0.997064140940244, 0.997595806079891,
>> 0.590366152539712,
>> 0.948510666498818, 0.330512619876425, 0.883673837089478,
>> 0.0198821692150445,
>> 0.868982868764254, 0.999952294188371, 0.207190890959777,
>> 0.939934594322161,
>> 0.86529009598038, 0.306625751897378), .Dim = c(15L, 4L), .Dimnames = list(
>>     c("PARTIAL:low-COMPLETE:low", "NO:low-COMPLETE:low",
>> "COMPLETE:middle-COMPLETE:low",
>>     "PARTIAL:middle-COMPLETE:low", "NO:middle-COMPLETE:low",
>>     "NO:low-PARTIAL:low", "COMPLETE:middle-PARTIAL:low",
>> "PARTIAL:middle-PARTIAL:low",
>>     "NO:middle-PARTIAL:low", "COMPLETE:middle-NO:low",
>> "PARTIAL:middle-NO:low",
>>     "NO:middle-NO:low", "PARTIAL:middle-COMPLETE:middle",
>> "NO:middle-COMPLETE:middle",
>>     "NO:middle-PARTIAL:middle"), c("diff", "lwr", "upr", "p adj"
>>     )))), .Names = c("patient", "Fold.fac", "patient:Fold.fac"
>> ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
>> abundance ~
>>     patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE),
>>     structure(list(patient = structure(c(11084928.3849924,
>> -3790273.898858,
>>     -14875202.2838504, -2565656.8579769, -17440859.1418273,
>> -28525787.5268197,
>>     24735513.6279617, 9860311.34411127, -1224617.0408811,
>> 0.137587687259541,
>>     0.791659281224941, 0.028733410253219), .Dim = 3:4, .Dimnames = list(
>>         c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
>>         "lwr", "upr", "p adj"))), Fold.fac = structure(c(25003217.9525667,
>>     15683872.2084017, 34322563.6967316, 1.59282125378191e-07), .Dim =
>> c(1L,
>>     4L), .Dimnames = list("low-high", c("diff", "lwr", "upr",
>>     "p adj"))), `patient:Fold.fac` = structure(c(6786144.11764773,
>>     -14136208.8235292, 15255972.7140153, 30625682.8117357,
>> 21777933.6260674,
>>     -20922352.9411769, 8469828.59636761, 23839538.6940879,
>> 14991789.5084197,
>>     29392181.5375445, 44761891.6352649, 35914142.4495966,
>> 15369710.0977203,
>>     6521960.91205206, -8847749.18566828, -16711562.4882314,
>> -37633915.4294083,
>>     -8222591.1541805, 7147118.94353984, -1700630.24212845,
>> -44420059.547056,
>>     -15008735.2718282, 360974.825892106, -8486774.35977618,
>> 5913617.6693487,
>>     21283327.767069, 12435578.5814008, -8089695.41243546,
>> -16937444.5981037,
>>     -32307154.6958241, 30283850.7235268, 9361497.78234989,
>> 38734536.5822112,
>>     54104246.6799315, 45256497.4942632, 2575353.66470216,
>> 31948392.4645634,
>>     47318102.5622838, 38470353.3766155, 52870745.4057404,
>> 68240455.5034607,
>>     59392706.3177924, 38829115.6078761, 29981366.4222079,
>> 14611656.3244875,
>>     0.963180623746077, 0.521122619371869, 0.431445001590424,
>>     0.00280179326576413, 0.0869916657428951, 0.113173926329674,
>>     0.908231706478258, 0.0441523667992262, 0.451984651996765,
>>     0.00489618219443777, 9.080596613531e-07, 0.000195613055067767,
>>     0.42174023314457, 0.968747601969596, 0.891038899833401), .Dim = c(15L,
>>     4L), .Dimnames = list(c("PARTIAL:high-COMPLETE:high",
>> "NO:high-COMPLETE:high",
>>     "COMPLETE:low-COMPLETE:high", "PARTIAL:low-COMPLETE:high",
>>     "NO:low-COMPLETE:high", "NO:high-PARTIAL:high",
>> "COMPLETE:low-PARTIAL:high",
>>     "PARTIAL:low-PARTIAL:high", "NO:low-PARTIAL:high",
>> "COMPLETE:low-NO:high",
>>     "PARTIAL:low-NO:high", "NO:low-NO:high", "PARTIAL:low-COMPLETE:low",
>>     "NO:low-COMPLETE:low", "NO:low-PARTIAL:low"), c("diff", "lwr",
>>     "upr", "p adj")))), .Names = c("patient", "Fold.fac",
>> "patient:Fold.fac"
>>     ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
>> abundance ~
>>         patient * Fold.fac, data = x), conf.level = 0.95, ordered =
>> FALSE))
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rsherry8 at comcast.net  Wed Feb 24 17:10:11 2016
From: rsherry8 at comcast.net (Robert Sherry)
Date: Wed, 24 Feb 2016 11:10:11 -0500
Subject: [R] Double AND within an IF statement
In-Reply-To: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
Message-ID: <56CDD5E3.9020603@comcast.net>

This should work:
     if ( age > 4 && age < 8 && infection > 0 ) replacement = 2

Bob

On 2/24/2016 7:08 AM, Polychronis KOSTOULAS wrote:
>
> Hi there,
>
> apologies if this is easy. I want to write this condition:
>
> If age is more than 4 years and less or equal to 8 years and infection 
> is positive then replacement is 2.
>
> Can you help me the double END?
>
> Thanks,
> Polychronis
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Wed Feb 24 17:18:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 08:18:03 -0800
Subject: [R] Double AND within an IF statement
In-Reply-To: <56CDD5E3.9020603@comcast.net>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
	<56CDD5E3.9020603@comcast.net>
Message-ID: <CAGxFJbQM0difcija8b3BiAc18KDFjc_q0eBum1icP34yv-KSUA@mail.gmail.com>

Almost surely no.

You are confusing "&&" with "&"

?"&"

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 8:10 AM, Robert Sherry <rsherry8 at comcast.net> wrote:
> This should work:
>     if ( age > 4 && age < 8 && infection > 0 ) replacement = 2
>
> Bob
>
> On 2/24/2016 7:08 AM, Polychronis KOSTOULAS wrote:
>>
>>
>> Hi there,
>>
>> apologies if this is easy. I want to write this condition:
>>
>> If age is more than 4 years and less or equal to 8 years and infection is
>> positive then replacement is 2.
>>
>> Can you help me the double END?
>>
>> Thanks,
>> Polychronis
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Feb 24 17:24:34 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Feb 2016 11:24:34 -0500
Subject: [R] Double AND within an IF statement
In-Reply-To: <CAGxFJbQM0difcija8b3BiAc18KDFjc_q0eBum1icP34yv-KSUA@mail.gmail.com>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
	<56CDD5E3.9020603@comcast.net>
	<CAGxFJbQM0difcija8b3BiAc18KDFjc_q0eBum1icP34yv-KSUA@mail.gmail.com>
Message-ID: <56CDD942.4070103@gmail.com>

On 24/02/2016 11:18 AM, Bert Gunter wrote:
> Almost surely no.
>
> You are confusing "&&" with "&"
>
> ?"&"

I think Bob had it right...

Duncan Murdoch

> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 24, 2016 at 8:10 AM, Robert Sherry <rsherry8 at comcast.net> wrote:
> > This should work:
> >     if ( age > 4 && age < 8 && infection > 0 ) replacement = 2
> >
> > Bob
> >
> > On 2/24/2016 7:08 AM, Polychronis KOSTOULAS wrote:
> >>
> >>
> >> Hi there,
> >>
> >> apologies if this is easy. I want to write this condition:
> >>
> >> If age is more than 4 years and less or equal to 8 years and infection is
> >> positive then replacement is 2.
> >>
> >> Can you help me the double END?
> >>
> >> Thanks,
> >> Polychronis
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Feb 24 17:27:20 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 08:27:20 -0800
Subject: [R] Double AND within an IF statement
In-Reply-To: <56CDD942.4070103@gmail.com>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
	<56CDD5E3.9020603@comcast.net>
	<CAGxFJbQM0difcija8b3BiAc18KDFjc_q0eBum1icP34yv-KSUA@mail.gmail.com>
	<56CDD942.4070103@gmail.com>
Message-ID: <CAGxFJbTxAhEhNfTq10Rqc-ytSQ=UypoEdhExQM3+ZqwC3gtxaw@mail.gmail.com>

I would have assumed that age, etc. were vectors; but that's why I
said "almost" surely.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 8:24 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/02/2016 11:18 AM, Bert Gunter wrote:
>>
>> Almost surely no.
>>
>> You are confusing "&&" with "&"
>>
>> ?"&"
>
>
> I think Bob had it right...
>
> Duncan Murdoch
>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Feb 24, 2016 at 8:10 AM, Robert Sherry <rsherry8 at comcast.net>
>> wrote:
>> > This should work:
>> >     if ( age > 4 && age < 8 && infection > 0 ) replacement = 2
>> >
>> > Bob
>> >
>> > On 2/24/2016 7:08 AM, Polychronis KOSTOULAS wrote:
>> >>
>> >>
>> >> Hi there,
>> >>
>> >> apologies if this is easy. I want to write this condition:
>> >>
>> >> If age is more than 4 years and less or equal to 8 years and infection
>> >> is
>> >> positive then replacement is 2.
>> >>
>> >> Can you help me the double END?
>> >>
>> >> Thanks,
>> >> Polychronis
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From murdoch.duncan at gmail.com  Wed Feb 24 17:31:33 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Feb 2016 11:31:33 -0500
Subject: [R] Double AND within an IF statement
In-Reply-To: <CAGxFJbTxAhEhNfTq10Rqc-ytSQ=UypoEdhExQM3+ZqwC3gtxaw@mail.gmail.com>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
	<56CDD5E3.9020603@comcast.net>
	<CAGxFJbQM0difcija8b3BiAc18KDFjc_q0eBum1icP34yv-KSUA@mail.gmail.com>
	<56CDD942.4070103@gmail.com>
	<CAGxFJbTxAhEhNfTq10Rqc-ytSQ=UypoEdhExQM3+ZqwC3gtxaw@mail.gmail.com>
Message-ID: <56CDDAE5.9070800@gmail.com>

On 24/02/2016 11:27 AM, Bert Gunter wrote:
> I would have assumed that age, etc. were vectors; but that's why I
> said "almost" surely.

Okay, so you were confusing if () with ifelse().

Duncan Murdoch

>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 24, 2016 at 8:24 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 24/02/2016 11:18 AM, Bert Gunter wrote:
> >>
> >> Almost surely no.
> >>
> >> You are confusing "&&" with "&"
> >>
> >> ?"&"
> >
> >
> > I think Bob had it right...
> >
> > Duncan Murdoch
> >
> >> -- Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Feb 24, 2016 at 8:10 AM, Robert Sherry <rsherry8 at comcast.net>
> >> wrote:
> >> > This should work:
> >> >     if ( age > 4 && age < 8 && infection > 0 ) replacement = 2
> >> >
> >> > Bob
> >> >
> >> > On 2/24/2016 7:08 AM, Polychronis KOSTOULAS wrote:
> >> >>
> >> >>
> >> >> Hi there,
> >> >>
> >> >> apologies if this is easy. I want to write this condition:
> >> >>
> >> >> If age is more than 4 years and less or equal to 8 years and infection
> >> >> is
> >> >> positive then replacement is 2.
> >> >>
> >> >> Can you help me the double END?
> >> >>
> >> >> Thanks,
> >> >> Polychronis
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >


From lists at dewey.myzen.co.uk  Wed Feb 24 17:33:59 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 24 Feb 2016 16:33:59 +0000
Subject: [R] Fwd: about dowloading a package.
In-Reply-To: <CABAY9A33b7dgWOkBtaX-4gvpqLWo4r8yAo8UX6E7b6UCk1ygHQ@mail.gmail.com>
References: <CABAY9A2OAom4qdDYso8uzsUrqm0b9ivVwOW5K_Smffus0eKZ-g@mail.gmail.com>
	<56CC7CE5.7000902@statistik.tu-dortmund.de>
	<CABAY9A2pgcM3BHGJqxoCTzSGQdOX=EmWBowKFRs7FTDtQEFovw@mail.gmail.com>
	<CABAY9A33b7dgWOkBtaX-4gvpqLWo4r8yAo8UX6E7b6UCk1ygHQ@mail.gmail.com>
Message-ID: <56CDDB77.9010407@dewey.myzen.co.uk>

Dear Carlos

On 24/02/2016 11:11, Carlos Gracida Juarez wrote:
> Good morning, I have an issue with my computer in order to download a
> package.
>
> I've tried to download the "mosaicData" and by writing the command and
> using the install packages tab, and in the first gives ma a warning
> indication that the carpet of destiny is not rewritable,

You mean the destination directory I think (it would be better to give 
us the exact error message even if it is in Spanish)

  and in the second,
> asks me about the possibility of open a new file carpet of destination, but
> doesn't allows me to make it.

You probably need extra permissions to do that or administrator 
privileges but without more details about your system that is just a guess.
sessionInfo()
would give information which might help respondents.

> I hope you can help me, I'm new in the use of Rstudio.

You might get a better answer on their help forums as not everyone here 
uses Rstudio

>
> Thanks,
>
> Carlos Gracida
>
>
> ---------- Forwarded message ----------
> From: Carlos Gracida Juarez <cj16551 at bristol.ac.uk>
> Date: 23 February 2016 at 15:42
> Subject: Re: about dowloading a package.
> To: Uwe Ligges <ligges at statistik.tu-dortmund.de>
>
>
> Thanks for your help,
>
> I will follow your indications,
>
> Cheers,
>
> Carlos Gracida
>
> On 23 February 2016 at 15:38, Uwe Ligges <ligges at statistik.tu-dortmund.de>
> wrote:
>
>>
>>
>> On 23.02.2016 16:34, Carlos Gracida Juarez wrote:
>>
>>> Hi, I am new in the use of R, and I am following a tutorial for learning,
>>>
>>> I have tried to download a pair of packages and has not been possible,
>>> could you send me the indications about "how to download a package and
>>> the file extensions I have to chose?
>>>
>>> I haven't found a helpful answer in the FAQ section.
>>>
>>> Thanks a lot for your help.
>>>
>>> Carlos Gracida
>>>
>>
>>
>> Use R to install a package, it chooses the right file for you:
>>
>> install.packages("nameOfPackage")
>>
>> And for furture questions, please ask on R-help after reading its posting
>> guide. This list is intended for development purposes.
>>
>>
>> Best,
>> Uwe Ligges
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Wed Feb 24 17:36:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 08:36:18 -0800
Subject: [R] Double AND within an IF statement
In-Reply-To: <56CDDAE5.9070800@gmail.com>
References: <20160224140843.Horde.BDuRS_p7A-Jfchj51Lc1nw1@webmail.uth.gr>
	<56CDD5E3.9020603@comcast.net>
	<CAGxFJbQM0difcija8b3BiAc18KDFjc_q0eBum1icP34yv-KSUA@mail.gmail.com>
	<56CDD942.4070103@gmail.com>
	<CAGxFJbTxAhEhNfTq10Rqc-ytSQ=UypoEdhExQM3+ZqwC3gtxaw@mail.gmail.com>
	<56CDDAE5.9070800@gmail.com>
Message-ID: <CAGxFJbSYMB-ROumv5Zy1zWqJy0ONRYoEbjRpQAEOujH3NLmOWQ@mail.gmail.com>

Yes!

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 8:31 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/02/2016 11:27 AM, Bert Gunter wrote:
>>
>> I would have assumed that age, etc. were vectors; but that's why I
>> said "almost" surely.
>
>
> Okay, so you were confusing if () with ifelse().
>
> Duncan Murdoch
>
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Feb 24, 2016 at 8:24 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>> > On 24/02/2016 11:18 AM, Bert Gunter wrote:
>> >>
>> >> Almost surely no.
>> >>
>> >> You are confusing "&&" with "&"
>> >>
>> >> ?"&"
>> >
>> >
>> > I think Bob had it right...
>> >
>> > Duncan Murdoch
>> >
>> >> -- Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Wed, Feb 24, 2016 at 8:10 AM, Robert Sherry <rsherry8 at comcast.net>
>> >> wrote:
>> >> > This should work:
>> >> >     if ( age > 4 && age < 8 && infection > 0 ) replacement = 2
>> >> >
>> >> > Bob
>> >> >
>> >> > On 2/24/2016 7:08 AM, Polychronis KOSTOULAS wrote:
>> >> >>
>> >> >>
>> >> >> Hi there,
>> >> >>
>> >> >> apologies if this is easy. I want to write this condition:
>> >> >>
>> >> >> If age is more than 4 years and less or equal to 8 years and
>> >> >> infection
>> >> >> is
>> >> >> positive then replacement is 2.
>> >> >>
>> >> >> Can you help me the double END?
>> >> >>
>> >> >> Thanks,
>> >> >> Polychronis
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >>
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From axel.urbiz at gmail.com  Wed Feb 24 17:45:24 2016
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Wed, 24 Feb 2016 11:45:24 -0500
Subject: [R] Sorting in trees problem
Message-ID: <CAAyVsXKNN-O7binrG-up6y23jEQ8fcgosAEabYWaNbBs71cxHA@mail.gmail.com>

Hello,

As decision trees require sorting the variable used for splitting a given
node, I'm trying to avoid having this recurrent sorting by only sorting all
numeric variable first (and only once).

My attempt in doing this is shown in "Solution 2" below, but although I get
the desired result I think the %in% operation may be a costly one (and may
even offset the benefits of pre-sorting).

Any alternative solutions would be highly appreciated.

### Sample data

set.seed(1)
df <- data.frame(x1 = rnorm(20), x2 = rnorm(20))
w <- rep(1L, nrow(df))
# w == 1L denote observation present in the current node
w[c(1, 8, 10)] <- 0L

### The problem: sort x1 within observations present in the current node

### Solution 1: slow for repeated sorting
nodeObsInd <- which(w == 1L)
sol1 <- df[nodeObsInd, ]
sol1 <- sol1[order(sol1$x1), ]$x1

### Solution 2: sort all variables initially only.

sort_fun <- function(x)
{
  index <- order(x)
  x <- x[index]
  data.frame(x, index) # the index gives original position of the obs
}

s_df <- lapply(df, function(x) sort_fun(x))
sol2 <- s_df[[1]][s_df$x1$index %in% nodeObsInd, ]

### check same result

all.equal(sol1, sol2$x)




Regards,
Axel.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 24 17:57:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 08:57:26 -0800
Subject: [R] Sorting in trees problem
In-Reply-To: <CAAyVsXKNN-O7binrG-up6y23jEQ8fcgosAEabYWaNbBs71cxHA@mail.gmail.com>
References: <CAAyVsXKNN-O7binrG-up6y23jEQ8fcgosAEabYWaNbBs71cxHA@mail.gmail.com>
Message-ID: <CAGxFJbQ+fBF9_z_-1Tf9VBbDprxqW3Fez1LmdFcO08HVv=cYtw@mail.gmail.com>

"%in%" is a wrapper for match(), which uses hashing I believe
(correction welcome!),and so is generally very fast.

See ?Rprof  for profiling R code to get timings. (Haven't used it
myself, so not sure how useful it would be for this situation).

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 8:45 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> Hello,
>
> As decision trees require sorting the variable used for splitting a given
> node, I'm trying to avoid having this recurrent sorting by only sorting all
> numeric variable first (and only once).
>
> My attempt in doing this is shown in "Solution 2" below, but although I get
> the desired result I think the %in% operation may be a costly one (and may
> even offset the benefits of pre-sorting).
>
> Any alternative solutions would be highly appreciated.
>
> ### Sample data
>
> set.seed(1)
> df <- data.frame(x1 = rnorm(20), x2 = rnorm(20))
> w <- rep(1L, nrow(df))
> # w == 1L denote observation present in the current node
> w[c(1, 8, 10)] <- 0L
>
> ### The problem: sort x1 within observations present in the current node
>
> ### Solution 1: slow for repeated sorting
> nodeObsInd <- which(w == 1L)
> sol1 <- df[nodeObsInd, ]
> sol1 <- sol1[order(sol1$x1), ]$x1
>
> ### Solution 2: sort all variables initially only.
>
> sort_fun <- function(x)
> {
>   index <- order(x)
>   x <- x[index]
>   data.frame(x, index) # the index gives original position of the obs
> }
>
> s_df <- lapply(df, function(x) sort_fun(x))
> sol2 <- s_df[[1]][s_df$x1$index %in% nodeObsInd, ]
>
> ### check same result
>
> all.equal(sol1, sol2$x)
>
>
>
>
> Regards,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Wed Feb 24 18:09:43 2016
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Wed, 24 Feb 2016 18:09:43 +0100
Subject: [R] Order output list od TukeyHSD function by "p adj"
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70D542@mb02.ads.tamu.edu>
References: <CAJRuHoq54imZaPKWRQ9ifD8w7kGFoZscPmLh_Zey8+Ui4X9m2g@mail.gmail.com>
	<CA+8X3fX4OKfsZkXds0tbmEhuqD+fOnNpKVwCTHnP2-nkxuswDQ@mail.gmail.com>
	<CAJRuHopu2uBVwuxt_9VfM5LPfT0PtimEi6gtDosgR3ZKFriWig@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70D542@mb02.ads.tamu.edu>
Message-ID: <CAJRuHopcb=CXU0Nq8PQK1kxmrr1x5rrPPrbncPR-PqP+xVpxaQ@mail.gmail.com>

Thanks for your very useful help!
It's working on my data (apply() to a list of lists ....)

All the best
Sergio


2016-02-24 17:02 GMT+01:00 David L Carlson <dcarlson at tamu.edu>:

> hsd.fit is list containing 1 element, a matrix called "wool:tension". It
> will be simpler if you extract the matrix and then use order() to get the
> matrix sorted by p adj:
>
> > table <- hsd.fit[["wool:tension"]]
> > table[order(table[, 'p adj']), ]
>               diff        lwr      upr        p adj
> A:L-B:H 25.7777778  10.471456 41.08410 0.0001136469
> A:L-A:M 20.5555556   5.249234 35.86188 0.0029580438
> A:L-A:H 20.0000000   4.693678 35.30632 0.0040954674
> A:L-B:L 16.3333333   1.027012 31.63966 0.0302143219
> A:L-B:M 15.7777778   0.471456 31.08410 0.0398172376
> B:M-B:H 10.0000000  -5.306322 25.30632 0.3918766902
> B:L-B:H  9.4444444  -5.861877 24.75077 0.4560949981
> A:H-B:H  5.7777778  -9.528544 21.08410 0.8705571533
> A:M-B:H  5.2222222 -10.084100 20.52854 0.9114780002
> B:M-A:M  4.7777778 -10.528544 20.08410 0.9377205494
> B:L-A:M  4.2222222 -11.084100 19.52854 0.9626540845
> B:M-A:H  4.2222222 -11.084100 19.52854 0.9626540845
> B:L-A:H  3.6666667 -11.639655 18.97299 0.9797122861
> A:H-A:M  0.5555556 -14.750766 15.86188 0.9999978240
> B:M-B:L  0.5555556 -14.750766 15.86188 0.9999978240
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sergio
> Fonda
> Sent: Wednesday, February 24, 2016 6:47 AM
> To: Jim Lemon
> Cc: r-help at r-project.org
> Subject: Re: [R] Order output list od TukeyHSD function by "p adj"
>
> Thank you Jim also for introducing a shorter data frame.
> However the HSD output I deal with is derived from a crossing factors
> condition.
> Could you kindly explain how could I sort results obtained from a
>
> fm1 <- aov(breaks ~ wool * tension, data = warpbreaks)
> hsd.fit<-TukeyHSD(fm1, "wool:tension", ordered = TRUE)
>
> which gives the following "crossing" output where "wool:tension" is a
> string
>
> $`wool:tension`
>               diff        lwr      upr     p adj
> A:M-B:H  5.2222222 -10.084100 20.52854 0.9114780
> A:H-B:H  5.7777778  -9.528544 21.08410 0.8705572
> B:L-B:H  9.4444444  -5.861877 24.75077 0.4560950
> B:M-B:H 10.0000000  -5.306322 25.30632 0.3918767
> A:L-B:H 25.7777778  10.471456 41.08410 0.0001136
> A:H-A:M  0.5555556 -14.750766 15.86188 0.9999978
> B:L-A:M  4.2222222 -11.084100 19.52854 0.9626541
> B:M-A:M  4.7777778 -10.528544 20.08410 0.9377205
> A:L-A:M 20.5555556   5.249234 35.86188 0.0029580
> B:L-A:H  3.6666667 -11.639655 18.97299 0.9797123
> B:M-A:H  4.2222222 -11.084100 19.52854 0.9626541
> A:L-A:H 20.0000000   4.693678 35.30632 0.0040955
> B:M-B:L  0.5555556 -14.750766 15.86188 0.9999978
> A:L-B:L 16.3333333   1.027012 31.63966 0.0302143
> A:L-B:M 15.7777778   0.471456 31.08410 0.0398172
>
>
> How may I order this part of results by "p adj" ?
> Thank you again for your patience!
> Sergio
>
> 2016-02-24 7:48 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:
>
> > Hi Sergio,
> > I couldn't get your example data to read in, so I have used the example
> in
> > the help page:
> >
> > fm1 <- aov(breaks ~ wool + tension, data = warpbreaks)
> > hsd.fit<-TukeyHSD(fm1, "tension", ordered = TRUE)
> > hsd.fit$tension[order(hsd.fit$tension[,4]),]
> >         diff        lwr      upr       p adj
> > L-H 14.722222  5.3688015 24.07564 0.001121788
> > L-M 10.000000  0.6465793 19.35342 0.033626219
> > M-H  4.722222 -4.6311985 14.07564 0.447421021
> >
> > Obviously you would have to examine the output of TukeyHSD with str() to
> > sort out which column to use for ordering.
> >
> > Jim
> >
> >
> > On Wed, Feb 24, 2016 at 11:21 AM, Sergio Fonda <sergio.fonda99 at gmail.com
> >
> > wrote:
> >
> >>  Hello, It's already for several hours that I try to order the list
> >> obtained by the function TukeyHSD according to the variable "p adj"
> >> (in ascending order). Unfortunately, without success.
> >> In addition to following two lines of code, that offer the result but
> >> separately so do not correspond to the desired result, I was unable to
> >> go:
> >> DF.5 <-lapply(DF.4, function (x)
> as.data.frame(x[c("patient:Fold.fac")]))
> >> DF.6 <- DF.5[[1]][order(DF.5[[1]]$patient.Fold.fac.p.adj),]
> >> Please, I ask some help to answer these two questions:
> >> 1) is it possible to get directly from the function TukeyHSD sorted
> >> rows by "p adj"?
> >> 2) or, may the output list from TukeyHSD() be processed (e.g. by
> >> lapply) to sort its elements according to "p adj"?
> >> I attach at bottom a simulation of a list obtained from TukeyHSD which
> >> should be ordered by "p adj".
> >> Thanks in advance for any suggestion!
> >> Sergio
> >> #
> >> > dput(DF.4)
> >> list(structure(list(patient = structure(c(12289274.0619908,
> >> -2380308.48287107,
> >> -14669582.5448618, -4176414.56676197, -18845997.1116238,
> >> -31135271.1736146,
> >> 28754962.6907435, 14085380.1458817, 1796106.0838909, 0.186808233632622,
> >> 0.938592742253258, 0.0922160074633905), .Dim = 3:4, .Dimnames = list(
> >>     c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
> >>     "lwr", "upr", "p adj"))), Fold.fac = structure(c(-12697325.7957036,
> >> -23938561.4288898, -1456090.1625174, 0.0268617694934425), .Dim = c(1L,
> >> 4L), .Dimnames = list("middle-low", c("diff", "lwr", "upr", "p adj"
> >> ))), `patient:Fold.fac` = structure(c(15369710.0977205,
> 6521960.91205235,
> >> -4695802.45257667, 4502968.78925385, -16007472.7140147,
> -8847749.18566819,
> >> -20065512.5502972, -10866741.3084667, -31377182.8117352,
> -11217763.364629,
> >> -2018992.12279849, -22529433.626067, 9198771.24183052, -11311670.261438,
> >> -20510441.5032685, -12927630.9811041, -21775380.1667723,
> >> -33016252.8378897,
> >> -23817481.5960591, -44327923.0993277, -37145090.2644928,
> >> -48385962.9356102,
> >> -39187191.6937797, -59697633.1970482, -39538213.749942,
> -30339442.5081115,
> >> -50849884.01138, -19144769.6082929, -39655211.1115614, -48853982.353392,
> >> 43667051.1765452, 34819301.990877, 23624647.9327363, 32823419.1745669,
> >> 12312977.6712983, 19449591.8931564, 8254937.83501579, 17453709.0768463,
> >> -3056732.42642223, 17102687.020684, 26301458.2625145, 5791016.75924596,
> >> 37542312.0919539, 17031870.5886854, 7833099.34685487, 0.632098034657304,
> >> 0.986399530577416, 0.997064140940244, 0.997595806079891,
> >> 0.590366152539712,
> >> 0.948510666498818, 0.330512619876425, 0.883673837089478,
> >> 0.0198821692150445,
> >> 0.868982868764254, 0.999952294188371, 0.207190890959777,
> >> 0.939934594322161,
> >> 0.86529009598038, 0.306625751897378), .Dim = c(15L, 4L), .Dimnames =
> list(
> >>     c("PARTIAL:low-COMPLETE:low", "NO:low-COMPLETE:low",
> >> "COMPLETE:middle-COMPLETE:low",
> >>     "PARTIAL:middle-COMPLETE:low", "NO:middle-COMPLETE:low",
> >>     "NO:low-PARTIAL:low", "COMPLETE:middle-PARTIAL:low",
> >> "PARTIAL:middle-PARTIAL:low",
> >>     "NO:middle-PARTIAL:low", "COMPLETE:middle-NO:low",
> >> "PARTIAL:middle-NO:low",
> >>     "NO:middle-NO:low", "PARTIAL:middle-COMPLETE:middle",
> >> "NO:middle-COMPLETE:middle",
> >>     "NO:middle-PARTIAL:middle"), c("diff", "lwr", "upr", "p adj"
> >>     )))), .Names = c("patient", "Fold.fac", "patient:Fold.fac"
> >> ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
> >> abundance ~
> >>     patient * Fold.fac, data = x), conf.level = 0.95, ordered = FALSE),
> >>     structure(list(patient = structure(c(11084928.3849924,
> >> -3790273.898858,
> >>     -14875202.2838504, -2565656.8579769, -17440859.1418273,
> >> -28525787.5268197,
> >>     24735513.6279617, 9860311.34411127, -1224617.0408811,
> >> 0.137587687259541,
> >>     0.791659281224941, 0.028733410253219), .Dim = 3:4, .Dimnames = list(
> >>         c("PARTIAL-COMPLETE", "NO-COMPLETE", "NO-PARTIAL"), c("diff",
> >>         "lwr", "upr", "p adj"))), Fold.fac =
> structure(c(25003217.9525667,
> >>     15683872.2084017, 34322563.6967316, 1.59282125378191e-07), .Dim =
> >> c(1L,
> >>     4L), .Dimnames = list("low-high", c("diff", "lwr", "upr",
> >>     "p adj"))), `patient:Fold.fac` = structure(c(6786144.11764773,
> >>     -14136208.8235292, 15255972.7140153, 30625682.8117357,
> >> 21777933.6260674,
> >>     -20922352.9411769, 8469828.59636761, 23839538.6940879,
> >> 14991789.5084197,
> >>     29392181.5375445, 44761891.6352649, 35914142.4495966,
> >> 15369710.0977203,
> >>     6521960.91205206, -8847749.18566828, -16711562.4882314,
> >> -37633915.4294083,
> >>     -8222591.1541805, 7147118.94353984, -1700630.24212845,
> >> -44420059.547056,
> >>     -15008735.2718282, 360974.825892106, -8486774.35977618,
> >> 5913617.6693487,
> >>     21283327.767069, 12435578.5814008, -8089695.41243546,
> >> -16937444.5981037,
> >>     -32307154.6958241, 30283850.7235268, 9361497.78234989,
> >> 38734536.5822112,
> >>     54104246.6799315, 45256497.4942632, 2575353.66470216,
> >> 31948392.4645634,
> >>     47318102.5622838, 38470353.3766155, 52870745.4057404,
> >> 68240455.5034607,
> >>     59392706.3177924, 38829115.6078761, 29981366.4222079,
> >> 14611656.3244875,
> >>     0.963180623746077, 0.521122619371869, 0.431445001590424,
> >>     0.00280179326576413, 0.0869916657428951, 0.113173926329674,
> >>     0.908231706478258, 0.0441523667992262, 0.451984651996765,
> >>     0.00489618219443777, 9.080596613531e-07, 0.000195613055067767,
> >>     0.42174023314457, 0.968747601969596, 0.891038899833401), .Dim =
> c(15L,
> >>     4L), .Dimnames = list(c("PARTIAL:high-COMPLETE:high",
> >> "NO:high-COMPLETE:high",
> >>     "COMPLETE:low-COMPLETE:high", "PARTIAL:low-COMPLETE:high",
> >>     "NO:low-COMPLETE:high", "NO:high-PARTIAL:high",
> >> "COMPLETE:low-PARTIAL:high",
> >>     "PARTIAL:low-PARTIAL:high", "NO:low-PARTIAL:high",
> >> "COMPLETE:low-NO:high",
> >>     "PARTIAL:low-NO:high", "NO:low-NO:high", "PARTIAL:low-COMPLETE:low",
> >>     "NO:low-COMPLETE:low", "NO:low-PARTIAL:low"), c("diff", "lwr",
> >>     "upr", "p adj")))), .Names = c("patient", "Fold.fac",
> >> "patient:Fold.fac"
> >>     ), class = c("TukeyHSD", "multicomp"), orig.call = aov(formula =
> >> abundance ~
> >>         patient * Fold.fac, data = x), conf.level = 0.95, ordered =
> >> FALSE))
> >> >
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Wed Feb 24 20:03:31 2016
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 24 Feb 2016 11:03:31 -0800
Subject: [R] Use of "quote" in Windows and Linux..
Message-ID: <CAN_e6XsZ-HDe5XeKtzaBqDLoSTWPXboYErkXGt8QGopLSL_Avw@mail.gmail.com>

Dear Rxperts..

I noticed a puzzling behavior of  'quote' in Linux and Windows environment
based RStudio..

In Linux based RStudio ,

a1 <- quote(ID)

The error message I get is:

<simpleError in doTryCatch(return(expr), name, parentenv, handler): object
'ID' not found>
<simpleError in is.scalar(val): object 'ID' not found>
<simpleError in is(obj, "ore.frame"): object 'ID' not found>


I dont get any error message when I do the same in Windows 7 based RStudio..


Could you please suggest how to use quote in Linux environment..and explain
why there is such a difference?

Thanks much in advance!!

Santosh

	[[alternative HTML version deleted]]


From miceli.leonardo at gmail.com  Wed Feb 24 19:27:29 2016
From: miceli.leonardo at gmail.com (Leonardo Miceli)
Date: Wed, 24 Feb 2016 15:27:29 -0300
Subject: [R] RSQLite: rounding
In-Reply-To: <CAM_vjukTQzUpOQrkh4FWpU8KG-Cq2xXDZzpa0_F6TkEtjnaY_Q@mail.gmail.com>
References: <56CCDDAF.4080502@gmail.com>
	<CAM_vjukTQzUpOQrkh4FWpU8KG-Cq2xXDZzpa0_F6TkEtjnaY_Q@mail.gmail.com>
Message-ID: <CAA205UjCdVYv9MPg2Srkj3x041dEzFf1kHAffnYWVYET0AxKMA@mail.gmail.com>

Hi Sarah

I didn't know the function dput!

I checked the formatting issue by doing simple arithmetic operations on the
data. But with the dput function these issue turned much more clear.

Here goes the result... I just change the "head" by the "tail" function, so
we must have exactly the same data. Unfortunately It is not what happened!

I turned very uncomfortable with the RSQLite package, I can not work with
these mistrustfulness... Think about building a R function to break RSQLite
querys results in small pieces and stack all again in a data.frame! It's
really not something I wish

thank you

summarizing, for example:

High = c(15L     , 15L,    15L,   16L,    16L,    16L) # from dput(tail(x1))
High = c(15.77, 15.89, 15.94, 16.06, 16.05, 16.29) # from dput(tail(x2))

> dput(tail(x1))
structure(list(Dt = c("2016-02-23", "2016-02-23", "2016-02-23",
"2016-02-23", "2016-02-23", "2016-02-23"), FK_tbFutureContracts_PK =
c("DI1 at BVMF@2022 at 1",
"DI1 at BVMF@2023 at 1", "DI1 at BVMF@2024 at 1", "DI1 at BVMF@2025 at 1", "DI1 at BVMF@2026 at 1",
"DI1 at BVMF@2027 at 1"), Sequence = c("F22 ", "F23 ", "F24 ", "F25 ",
"F26 ", "F27 "), Serie = c(33L, 35L, 37L, 39L, 40L, 41L), DaysToMaturity =
c(2141L,
2505L, 2870L, 3236L, 3601L, 3968L), BusinessDayToMaturity = c(1471L,
1722L, 1971L, 2225L, 2478L, 2728L), Open = c(15L, 15L, 15L, 15L,
16L, 16L), High = c(15L, 15L, 15L, 16L, 16L, 16L), Low = c(15L,
15L, 15L, 15L, 16L, 16L), Last = c(15L, 15L, 15L, 16L, 16L, 16L
), Settle = c(42730.93, 36721, 31529.52, 26990.28, 23137.84,
19629.27), Average = c(15.656, 15.775, 15.88, 15.923, 16.028,
16.159), Open_Interest = c(27856L, 261570L, 40600L, 340472L,
53640L, 80156L), Traded_Contracts = c(1025L, 18467L, 820L, 28044L,
720L, 12570L), Trades = c(77L, 1645L, 61L, 2073L, 23L, 140L),
    Volume = c(43851219, 678739310, 25892492, 760790054, 16690664,
    248374870), ContractSize = c(1e+07, 1e+07, 1e+07, 1e+07,
    1e+07, 1e+07)), .Names = c("Dt", "FK_tbFutureContracts_PK",
"Sequence", "Serie", "DaysToMaturity", "BusinessDayToMaturity",
"Open", "High", "Low", "Last", "Settle", "Average", "Open_Interest",
"Traded_Contracts", "Trades", "Volume", "ContractSize"), row.names =
92513:92518, class = "data.frame")

> dput(tail(x2))
structure(list(Dt = c("2016-02-23", "2016-02-23", "2016-02-23",
"2016-02-23", "2016-02-23", "2016-02-23"), FK_tbFutureContracts_PK =
c("DI1 at BVMF@2022 at 1",
"DI1 at BVMF@2023 at 1", "DI1 at BVMF@2024 at 1", "DI1 at BVMF@2025 at 1", "DI1 at BVMF@2026 at 1",
"DI1 at BVMF@2027 at 1"), Sequence = c("F22 ", "F23 ", "F24 ", "F25 ",
"F26 ", "F27 "), Serie = c(33L, 35L, 37L, 39L, 40L, 41L), DaysToMaturity =
c(2141L,
2505L, 2870L, 3236L, 3601L, 3968L), BusinessDayToMaturity = c(1471L,
1722L, 1971L, 2225L, 2478L, 2728L), Open = c(15.53, 15.61, 15.66,
15.75, 16.01, 16.12), High = c(15.77, 15.89, 15.94, 16.06, 16.05,
16.29), Low = c(15.53, 15.55, 15.66, 15.7, 16.01, 16.11), Last = c(15.68,
15.82, 15.88, 16.02, 16.03, 16.2), Settle = c(42730.93, 36721,
31529.52, 26990.28, 23137.84, 19629.27), Average = c(15.656,
15.775, 15.88, 15.923, 16.028, 16.159), Open_Interest = c(27856L,
261570L, 40600L, 340472L, 53640L, 80156L), Traded_Contracts = c(1025L,
18467L, 820L, 28044L, 720L, 12570L), Trades = c(77L, 1645L, 61L,
2073L, 23L, 140L), Volume = c(43851219, 678739310, 25892492,
760790054, 16690664, 248374870), ContractSize = c(10000000L,
10000000L, 10000000L, 10000000L, 10000000L, 10000000L)), .Names = c("Dt",
"FK_tbFutureContracts_PK", "Sequence", "Serie", "DaysToMaturity",
"BusinessDayToMaturity", "Open", "High", "Low", "Last", "Settle",
"Average", "Open_Interest", "Traded_Contracts", "Trades", "Volume",
"ContractSize"), row.names = 66:71, class = "data.frame")

2016-02-24 12:06 GMT-03:00 Sarah Goslee <sarah.goslee at gmail.com>:

> How did you "check it out"? I still suspect a formatting issue.
>
> Please use dput() to provide a bit of data from each, eg
> dput(head(x1))
> dput(head(x2))
>
> Sarah
>
> On Tue, Feb 23, 2016 at 5:31 PM, Leonardo Miceli
> <miceli.leonardo at gmail.com> wrote:
> >
> > Does anybody here had any problem with rounding using RSQLite?
> >
> > I have a query which return around 100 thousands records of double
> > precision numeric values.
> >
> > The query returns the numbers with 1 digit precision. But when I run the
> > same query but constrains the number of recorded values returned, by
> > around 30 records, the precision of the the values is the correct 3
> digits!
> >
> > It is not a matter of formatting, I checked it out. It's really a
> > different number returned by the same query only the amount of returned
> > data was set different.
> >
> > Any tips? Something like that had happened to you?
> >
> > By the way, I put the query below just to see Its simplicity...
> >
> >
> >  > library(RSQLite)
> >
> >
> >  > qry1 <- "SELECT * FROM tbFutcotes WHERE Dt >= '1996-01-01' AND
> > FK_tbFutureContracts_PK LIKE '%DI1%'"
> >
> >  > qry2 <- "SELECT * FROM tbFutcotes WHERE Dt >= '2016-02-22' AND
> > FK_tbFutureContracts_PK LIKE '%DI1%'"
> >
> >
> >  > x1 <- dbGetQuery(con, qry1)
> >
> >  > x2 <- dbGetQuery(con, qry2)
> >
>

	[[alternative HTML version deleted]]


From joanna.t.q.nguyen at gmail.com  Wed Feb 24 19:35:30 2016
From: joanna.t.q.nguyen at gmail.com (Joanna Nguyen)
Date: Wed, 24 Feb 2016 13:35:30 -0500
Subject: [R] how to split and use notation fro stacked data
Message-ID: <CAJt7GmC2XOBTZ6Svg2nCWVckX3Qv1XH55Zew3FuTrtfy1eYB0Q@mail.gmail.com>

I have a data set as below

"temperature" "gender" "hr"
96.3 1 70
96.7 1 71
96.9 1 74
96.4 2 69
96.7 2 62
96.8 2 75

Gender code (1) means males and Gender code (2) means females.
I have to split the data by gender and then perform a* two-sample tes*t to
see whether the population means are equivalent. When using a function to
solve this I should use the *notation for stacked data*. I *cannot assume
equal variances*
How can I code them?  I am just a beginner for R programming
Thanks
-- 
Joanna Thuc Quyen Nguyen

	[[alternative HTML version deleted]]


From hodarahmati68 at yahoo.com  Wed Feb 24 15:38:59 2016
From: hodarahmati68 at yahoo.com (hoda rahmati)
Date: Wed, 24 Feb 2016 14:38:59 +0000 (UTC)
Subject: [R] adding a column to data frame solving the replacement problem
References: <1491467038.9395502.1456324739104.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1491467038.9395502.1456324739104.JavaMail.yahoo@mail.yahoo.com>

Hi all,?

I have a data set (mydata) containing 471 variables. One of the columns looks as below?

$ Sequence : Factor w/ 3 levels "","%Seq%gre",..: 2 2 2 2 2 2 2 2 2 2 ...?

sequence contains %Seq%gre and %Seq%tse and I extract only %Seq%tse and add it to my variables and plot a scatterplot of mydata. I use table and the result is: table(mydata$Sequence)?
?%Seq%gre %Seq%tse?
? ? ? ? ? 1 ? ? ? ? ? 25520 ? ? ? ? ?243744?
in the next step I ?want to add a column to my main data set (mydata) containing only %Seq%tse, however when I use the following command there's an error telling me:?
Error in `$<-.data.frame`(`*tmp*`, "NewColumn", value = c(3L, 3L, 3L, ?:?
? replacement has 243744 rows, data has 269265?
How can I add this column correctly to mydata??
Thanks for any help
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 24 20:43:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 11:43:27 -0800
Subject: [R] how to split and use notation fro stacked data
In-Reply-To: <CAJt7GmC2XOBTZ6Svg2nCWVckX3Qv1XH55Zew3FuTrtfy1eYB0Q@mail.gmail.com>
References: <CAJt7GmC2XOBTZ6Svg2nCWVckX3Qv1XH55Zew3FuTrtfy1eYB0Q@mail.gmail.com>
Message-ID: <CAGxFJbR6QK-buZGpJry+gFJuqxyxuQkMz+5SnPRMH15PK8UAgg@mail.gmail.com>

Sounds like a homework problem. If so, this list has a "no homework"
policy and you should ask your professor or the TA for help.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 10:35 AM, Joanna Nguyen
<joanna.t.q.nguyen at gmail.com> wrote:
> I have a data set as below
>
> "temperature" "gender" "hr"
> 96.3 1 70
> 96.7 1 71
> 96.9 1 74
> 96.4 2 69
> 96.7 2 62
> 96.8 2 75
>
> Gender code (1) means males and Gender code (2) means females.
> I have to split the data by gender and then perform a* two-sample tes*t to
> see whether the population means are equivalent. When using a function to
> solve this I should use the *notation for stacked data*. I *cannot assume
> equal variances*
> How can I code them?  I am just a beginner for R programming
> Thanks
> --
> Joanna Thuc Quyen Nguyen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Feb 24 21:32:32 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 25 Feb 2016 09:32:32 +1300
Subject: [R] readRDS problem
In-Reply-To: <73D7CFA8-5BB2-471A-A8AC-E0A3F1DCEA0F@univie.ac.at>
References: <56CD7731.3040404@wiwi.hu-berlin.de>
	<56CD7A46.9060508@dewey.myzen.co.uk>
	<56CD7FC0.8040204@wiwi.hu-berlin.de>
	<73D7CFA8-5BB2-471A-A8AC-E0A3F1DCEA0F@univie.ac.at>
Message-ID: <56CE1360.3090402@auckland.ac.nz>

On 25/02/16 00:11, Erich Neuwirth wrote:
> ?data
> will show you that data is a reserved word!

That is simply not true.  There is no mention in help for data of "data" 
being a reserved word.

Moreover, if "data" *were* a reserved word " <- " wouldn't work either.

Compare:

     data <- 42 # No problema.
and
     TRUE <- 42 # Throws an error; "TRUE" really *is* a reserved word.

The real explanation is more subtle; it involves "locking" and the 
rather intricate behaviour of "<<-", which I do no claim to understand.

The best advice is: DON'T USE "<<-" !!!

See fortune("dumb down").

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From NordlDJ at dshs.wa.gov  Wed Feb 24 21:39:17 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 24 Feb 2016 20:39:17 +0000
Subject: [R] how to split and use notation fro stacked data
In-Reply-To: <CAJt7GmC2XOBTZ6Svg2nCWVckX3Qv1XH55Zew3FuTrtfy1eYB0Q@mail.gmail.com>
References: <CAJt7GmC2XOBTZ6Svg2nCWVckX3Qv1XH55Zew3FuTrtfy1eYB0Q@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27663092A26E@WAXMXOLYMB026.WAX.wa.lcl>

I will suggest that you read the documentation on t.test. 

?t.test


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Joanna
> Nguyen
> Sent: Wednesday, February 24, 2016 10:36 AM
> To: r-help at r-project.org
> Subject: [R] how to split and use notation fro stacked data
> 
> I have a data set as below
> 
> "temperature" "gender" "hr"
> 96.3 1 70
> 96.7 1 71
> 96.9 1 74
> 96.4 2 69
> 96.7 2 62
> 96.8 2 75
> 
> Gender code (1) means males and Gender code (2) means females.
> I have to split the data by gender and then perform a* two-sample tes*t to
> see whether the population means are equivalent. When using a function
> to solve this I should use the *notation for stacked data*. I *cannot assume
> equal variances* How can I code them?  I am just a beginner for R
> programming Thanks
> --
> Joanna Thuc Quyen Nguyen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Feb 24 21:47:25 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 25 Feb 2016 09:47:25 +1300
Subject: [R] [FORGED]  Use of "quote" in Windows and Linux..
In-Reply-To: <CAN_e6XsZ-HDe5XeKtzaBqDLoSTWPXboYErkXGt8QGopLSL_Avw@mail.gmail.com>
References: <CAN_e6XsZ-HDe5XeKtzaBqDLoSTWPXboYErkXGt8QGopLSL_Avw@mail.gmail.com>
Message-ID: <56CE16DD.6040002@auckland.ac.nz>


(1) Do not post in html.

(2) This is the R-help forum, not the Rstudio help forum.

(3) The call

     a1 <- quote(ID)

works just fine under R (not Rstudio) on my Linux box.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 25/02/16 08:03, Santosh wrote:
> Dear Rxperts..
>
> I noticed a puzzling behavior of  'quote' in Linux and Windows environment
> based RStudio..
>
> In Linux based RStudio ,
>
> a1 <- quote(ID)
>
> The error message I get is:
>
> <simpleError in doTryCatch(return(expr), name, parentenv, handler): object
> 'ID' not found>
> <simpleError in is.scalar(val): object 'ID' not found>
> <simpleError in is(obj, "ore.frame"): object 'ID' not found>
>
>
> I dont get any error message when I do the same in Windows 7 based RStudio..
>
>
> Could you please suggest how to use quote in Linux environment..and explain
> why there is such a difference?
>
> Thanks much in advance!!


From istazahn at gmail.com  Wed Feb 24 21:52:17 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 24 Feb 2016 15:52:17 -0500
Subject: [R] [FORGED] Use of "quote" in Windows and Linux..
In-Reply-To: <56CE16DD.6040002@auckland.ac.nz>
References: <CAN_e6XsZ-HDe5XeKtzaBqDLoSTWPXboYErkXGt8QGopLSL_Avw@mail.gmail.com>
	<56CE16DD.6040002@auckland.ac.nz>
Message-ID: <CA+vqiLGpWVLX8ihzEeCufHOnwo0POQSnxVCiTwwT5RgX9oHmXA@mail.gmail.com>

On Wed, Feb 24, 2016 at 3:47 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> (1) Do not post in html.
>
> (2) This is the R-help forum, not the Rstudio help forum.
>
> (3) The call
>
>     a1 <- quote(ID)
>
> works just fine under R (not Rstudio) on my Linux box.

Works fine on my Linux machine too, even in Rstudio.

>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> On 25/02/16 08:03, Santosh wrote:
>>
>> Dear Rxperts..
>>
>> I noticed a puzzling behavior of  'quote' in Linux and Windows environment
>> based RStudio..
>>
>> In Linux based RStudio ,
>>
>> a1 <- quote(ID)
>>
>> The error message I get is:
>>
>> <simpleError in doTryCatch(return(expr), name, parentenv, handler): object
>> 'ID' not found>
>> <simpleError in is.scalar(val): object 'ID' not found>
>> <simpleError in is(obj, "ore.frame"): object 'ID' not found>
>>
>>
>> I dont get any error message when I do the same in Windows 7 based
>> RStudio..
>>
>>
>> Could you please suggest how to use quote in Linux environment..and
>> explain
>> why there is such a difference?
>>
>> Thanks much in advance!!
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From santosh2005 at gmail.com  Wed Feb 24 22:12:43 2016
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 24 Feb 2016 13:12:43 -0800
Subject: [R] [FORGED] Use of "quote" in Windows and Linux..
In-Reply-To: <CA+vqiLGpWVLX8ihzEeCufHOnwo0POQSnxVCiTwwT5RgX9oHmXA@mail.gmail.com>
References: <CAN_e6XsZ-HDe5XeKtzaBqDLoSTWPXboYErkXGt8QGopLSL_Avw@mail.gmail.com>
	<56CE16DD.6040002@auckland.ac.nz>
	<CA+vqiLGpWVLX8ihzEeCufHOnwo0POQSnxVCiTwwT5RgX9oHmXA@mail.gmail.com>
Message-ID: <CAN_e6XuDTEHdRQAzDsJtpYEmTF9gJa4rQ_sGGwjb5xHPXdOk6g@mail.gmail.com>

Thanks all for your response.
I didn't realize I posted in HTML.. I just typed an email as I usually
do... how do I know whether it was sent in HTML? I had not changed any
settings to send out in HTML format..
Seems like you got the impression based on  the HTML tag like message of
"simpleError"....

Anyway.. thanks for your help/response. again.

Regards,
Santosh

On Wed, Feb 24, 2016 at 12:52 PM, Ista Zahn <istazahn at gmail.com> wrote:

> On Wed, Feb 24, 2016 at 3:47 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >
> > (1) Do not post in html.
> >
> > (2) This is the R-help forum, not the Rstudio help forum.
> >
> > (3) The call
> >
> >     a1 <- quote(ID)
> >
> > works just fine under R (not Rstudio) on my Linux box.
>
> Works fine on my Linux machine too, even in Rstudio.
>
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > On 25/02/16 08:03, Santosh wrote:
> >>
> >> Dear Rxperts..
> >>
> >> I noticed a puzzling behavior of  'quote' in Linux and Windows
> environment
> >> based RStudio..
> >>
> >> In Linux based RStudio ,
> >>
> >> a1 <- quote(ID)
> >>
> >> The error message I get is:
> >>
> >> <simpleError in doTryCatch(return(expr), name, parentenv, handler):
> object
> >> 'ID' not found>
> >> <simpleError in is.scalar(val): object 'ID' not found>
> >> <simpleError in is(obj, "ore.frame"): object 'ID' not found>
> >>
> >>
> >> I dont get any error message when I do the same in Windows 7 based
> >> RStudio..
> >>
> >>
> >> Could you please suggest how to use quote in Linux environment..and
> >> explain
> >> why there is such a difference?
> >>
> >> Thanks much in advance!!
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sam at mcneilco.com  Wed Feb 24 20:19:41 2016
From: sam at mcneilco.com (Samuel Meyer)
Date: Wed, 24 Feb 2016 11:19:41 -0800
Subject: [R] png: cannot load any more object with static TLS
Message-ID: <CABZ1+ASVTTDxOz=S-uB=+V3JLFtW7n-ZLc61yEOHyU0WU-8=qA@mail.gmail.com>

Hi all,

I have an issue running png after loading various packages. After running

library(drc)
library(RCurl)
library(XLConnect)
library(ROracle)
png("test.png")
dev.off()

The file fails to write, and I get

Warning messages:
1: In png("test.png") :
  unable to load shared object '/usr/lib64/R/library/grDevices/libs//cairo.so':
  dlopen: cannot load any more object with static TLS
2: In png("test.png") : failed to load cairo DLL

This only occurs on Suse Enterprise 12 for me.

Given time spent reading about a similar error message in Matlab, this
seems like a deeper problem that I am going to have a hard time
solving.

 http://stackoverflow.com/questions/19268293/matlab-error-cannot-open-with-static-tls

Are there R installation changes I could make to fix this? Or is this
an issue with the packages? If I run png("test.png") first, it works,
but would that cause other errors in the future?

Also, I can get the same error using slightly different packages:

library(drc)
library(data.table)
library(RCurl)
library(rJava)
library(ROracle)
fread("column1,column2\n1,2")
getURL("http://www.example.com")
png("test.png")
dev.off()

Thank you for any insights,
Sam Meyer


From valkremk at gmail.com  Thu Feb 25 03:57:25 2016
From: valkremk at gmail.com (Val)
Date: Wed, 24 Feb 2016 20:57:25 -0600
Subject: [R] subsetting
Message-ID: <CAJOiR6Z2QJdQrQvXrCPCjeQ475Kj8sRvVqp4x=-WvkNf_iUptA@mail.gmail.com>

Hi all,

One of the the columns of a data frame has a value such like

AAAAS-2001-yy
AAAAS-2004-xx
FFFFF-2007-SS
and so on

based on this column (variable) I want  subset a data frame  where the
middle value of this variable is between 2001 to 2004.
THE END RESULT THE DATA FRAME  WILL BE THIS.

AAAAS-2001-yy
AAAAS-2004-xx


THANK YOU IN ADVANCE

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb 25 04:31:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 19:31:40 -0800
Subject: [R] subsetting
In-Reply-To: <CAJOiR6Z2QJdQrQvXrCPCjeQ475Kj8sRvVqp4x=-WvkNf_iUptA@mail.gmail.com>
References: <CAJOiR6Z2QJdQrQvXrCPCjeQ475Kj8sRvVqp4x=-WvkNf_iUptA@mail.gmail.com>
Message-ID: <CAGxFJbRYeQSqd6roMJdmKRFOC2ekXQxX-d2B1JoyA42UjBucMA@mail.gmail.com>

Have you gone through any R tutorials yet? I didn't entirely
understand your question (and so cannot answer), but this sounds like
a basic subsetting/data wrangling task that you should know how to do
if you have gone through a basic tutorial or two.

See also ?subset, ?"[" (basic indexing) and possibly also the plyR,
dplyr, or data.table packages that provide what some consider more
convenient and/or faster interfaces to these sorts of tasks.

See also: http://vita.had.co.nz/papers/tidy-data.pdf

for a nice article on "tidying" data (using plyr/dplyr).



Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 6:57 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
>
> One of the the columns of a data frame has a value such like
>
> AAAAS-2001-yy
> AAAAS-2004-xx
> FFFFF-2007-SS
> and so on
>
> based on this column (variable) I want  subset a data frame  where the
> middle value of this variable is between 2001 to 2004.
> THE END RESULT THE DATA FRAME  WILL BE THIS.
>
> AAAAS-2001-yy
> AAAAS-2004-xx
>
>
> THANK YOU IN ADVANCE
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rlderickson at gmail.com  Thu Feb 25 04:37:22 2016
From: rlderickson at gmail.com (Ryan Derickson)
Date: Wed, 24 Feb 2016 22:37:22 -0500
Subject: [R] subsetting
In-Reply-To: <CAGxFJbRYeQSqd6roMJdmKRFOC2ekXQxX-d2B1JoyA42UjBucMA@mail.gmail.com>
References: <CAJOiR6Z2QJdQrQvXrCPCjeQ475Kj8sRvVqp4x=-WvkNf_iUptA@mail.gmail.com>
	<CAGxFJbRYeQSqd6roMJdmKRFOC2ekXQxX-d2B1JoyA42UjBucMA@mail.gmail.com>
Message-ID: <CALSCBYoRtpwSTcHXQoLk50QJdn9cspfYSzipJkEGFrq3YCDNUQ@mail.gmail.com>

A combination of subsetting and ?substr should get you close to a solution.
If the middle sequence you referenced isn't always the same distance from
the first character, you may have to involve regular expressions to find
"the middle".

On Wednesday, February 24, 2016, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Have you gone through any R tutorials yet? I didn't entirely
> understand your question (and so cannot answer), but this sounds like
> a basic subsetting/data wrangling task that you should know how to do
> if you have gone through a basic tutorial or two.
>
> See also ?subset, ?"[" (basic indexing) and possibly also the plyR,
> dplyr, or data.table packages that provide what some consider more
> convenient and/or faster interfaces to these sorts of tasks.
>
> See also: http://vita.had.co.nz/papers/tidy-data.pdf
>
> for a nice article on "tidying" data (using plyr/dplyr).
>
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 24, 2016 at 6:57 PM, Val <valkremk at gmail.com <javascript:;>>
> wrote:
> > Hi all,
> >
> > One of the the columns of a data frame has a value such like
> >
> > AAAAS-2001-yy
> > AAAAS-2004-xx
> > FFFFF-2007-SS
> > and so on
> >
> > based on this column (variable) I want  subset a data frame  where the
> > middle value of this variable is between 2001 to 2004.
> > THE END RESULT THE DATA FRAME  WILL BE THIS.
> >
> > AAAAS-2001-yy
> > AAAAS-2004-xx
> >
> >
> > THANK YOU IN ADVANCE
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Thu Feb 25 04:59:43 2016
From: valkremk at gmail.com (Val)
Date: Wed, 24 Feb 2016 21:59:43 -0600
Subject: [R] subsetting
In-Reply-To: <CAGxFJbRYeQSqd6roMJdmKRFOC2ekXQxX-d2B1JoyA42UjBucMA@mail.gmail.com>
References: <CAJOiR6Z2QJdQrQvXrCPCjeQ475Kj8sRvVqp4x=-WvkNf_iUptA@mail.gmail.com>
	<CAGxFJbRYeQSqd6roMJdmKRFOC2ekXQxX-d2B1JoyA42UjBucMA@mail.gmail.com>
Message-ID: <CAJOiR6aiO5zu0ApfRQSieMqaWghvR+4ojJk3VM+FWwTa3-K-7A@mail.gmail.com>

Thank you for the info. I did solve it using
unlist lapply strsplit  functions.


On Wed, Feb 24, 2016 at 9:31 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Have you gone through any R tutorials yet? I didn't entirely
> understand your question (and so cannot answer), but this sounds like
> a basic subsetting/data wrangling task that you should know how to do
> if you have gone through a basic tutorial or two.
>
> See also ?subset, ?"[" (basic indexing) and possibly also the plyR,
> dplyr, or data.table packages that provide what some consider more
> convenient and/or faster interfaces to these sorts of tasks.
>
> See also: http://vita.had.co.nz/papers/tidy-data.pdf
>
> for a nice article on "tidying" data (using plyr/dplyr).
>
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 24, 2016 at 6:57 PM, Val <valkremk at gmail.com> wrote:
> > Hi all,
> >
> > One of the the columns of a data frame has a value such like
> >
> > AAAAS-2001-yy
> > AAAAS-2004-xx
> > FFFFF-2007-SS
> > and so on
> >
> > based on this column (variable) I want  subset a data frame  where the
> > middle value of this variable is between 2001 to 2004.
> > THE END RESULT THE DATA FRAME  WILL BE THIS.
> >
> > AAAAS-2001-yy
> > AAAAS-2004-xx
> >
> >
> > THANK YOU IN ADVANCE
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Feb 25 05:18:44 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 25 Feb 2016 15:18:44 +1100
Subject: [R] KNN
In-Reply-To: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
Message-ID: <CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>

Hi Alnazar,
I looked at your question yesterday and was unable to find what a
"majority guessing" function is. I think it may be related to the
"Pandemonium" model of decision making, but that doesn't get me very
far. Could you give us a hint as to what this function is?

Jim


On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com> wrote:
> How I can use majority guessing function to evaluate KNN, if I have data saved in CSV file
>
> Alnazer Elbedairy
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hui.chen at 3dmedcare.com  Thu Feb 25 04:49:06 2016
From: hui.chen at 3dmedcare.com (hui.chen)
Date: Thu, 25 Feb 2016 11:49:06 +0800
Subject: [R] about  Area Graphs
Message-ID: <000701d16f7f$79e3ff90$6dabfeb0$@3dmedcare.com>

Dear Sir/Madam:
Your web of "R Graphical Manual" is so wonderful! But the
URL(http://rgm.ogalab.net/RGM) cannot be found now, may I ask for your new
URL?
Thx for your reply!
 
Sincerely yours,
Abigail Chen
 
 

 


	[[alternative HTML version deleted]]


From alnazer.elbedairy at gmail.com  Thu Feb 25 07:30:51 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Wed, 24 Feb 2016 22:30:51 -0800
Subject: [R] KNN
In-Reply-To: <CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
	<CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
Message-ID: <CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>

Dear Jim
thanks you for your kind help.
KNN - is K- Nearest Neighbor, is a technique used in Machine Learning.
attached you will find a CSV file dataset, my question is :
use the attached Dataset, Use majority guessing technique to evaluate KNN ?
this is the solution I came up with, but I didn't work :-
majorityGuessing <- function(trainingData,categories)
{GuessMPG <- sample(1:length (categories-1, nrow(testingData),replace=T)
return(GuessMPG)



On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Alnazar,
> I looked at your question yesterday and was unable to find what a
> "majority guessing" function is. I think it may be related to the
> "Pandemonium" model of decision making, but that doesn't get me very
> far. Could you give us a hint as to what this function is?
>
>
>
On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Alnazar,
> I looked at your question yesterday and was unable to find what a
> "majority guessing" function is. I think it may be related to the
> "Pandemonium" model of decision making, but that doesn't get me very
> far. Could you give us a hint as to what this function is?
>
> Jim
>
>
> On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com>
> wrote:
> > How I can use majority guessing function to evaluate KNN, if I have data
> saved in CSV file
> >
> > Alnazer Elbedairy
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

From bhh at xs4all.nl  Thu Feb 25 07:49:42 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 25 Feb 2016 07:49:42 +0100
Subject: [R] [FORGED] Use of "quote" in Windows and Linux..
In-Reply-To: <CAN_e6XuDTEHdRQAzDsJtpYEmTF9gJa4rQ_sGGwjb5xHPXdOk6g@mail.gmail.com>
References: <CAN_e6XsZ-HDe5XeKtzaBqDLoSTWPXboYErkXGt8QGopLSL_Avw@mail.gmail.com>
	<56CE16DD.6040002@auckland.ac.nz>
	<CA+vqiLGpWVLX8ihzEeCufHOnwo0POQSnxVCiTwwT5RgX9oHmXA@mail.gmail.com>
	<CAN_e6XuDTEHdRQAzDsJtpYEmTF9gJa4rQ_sGGwjb5xHPXdOk6g@mail.gmail.com>
Message-ID: <1492BF4E-D0A0-4888-BC37-9F0A6FD08938@xs4all.nl>


> On 24 Feb 2016, at 22:12, Santosh <santosh2005 at gmail.com> wrote:
> 
> Thanks all for your response.
> I didn't realize I posted in HTML.. I just typed an email as I usually
> do... how do I know whether it was sent in HTML? I had not changed any
> settings to send out in HTML format..
> Seems like you got the impression based on  the HTML tag like message of
> "simpleError"....
> 

No that is not the reason.
The mail server of the R-help list sees that a message has an HTML version.
You can check by looking at:  https://stat.ethz.ch/pipermail/r-help/2016-February/436464.html

We, who send mails in plain text format, see  the line

[[alternative HTML version deleted]]

at the end of a message if that message us a HTML version.

You'll have to look in the settings and/or preferences of your email client to see how to turn off HTML formatted mail.

Berend


From bgunter.4567 at gmail.com  Thu Feb 25 08:19:15 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Feb 2016 23:19:15 -0800
Subject: [R] about Area Graphs
In-Reply-To: <000701d16f7f$79e3ff90$6dabfeb0$@3dmedcare.com>
References: <000701d16f7f$79e3ff90$6dabfeb0$@3dmedcare.com>
Message-ID: <CAGxFJbQZTkCHzvp3G+u--r6iE=0Z_C1VZeVOtNqcg96CSzHqvA@mail.gmail.com>

I am not sure this is the right place to get help on this. The manual
was not actually part of R, I believe.

If you do not succeed in getting help here, you might try contacting
David Smith of Revolution Analytics (now part of Microsoft), who
blogged on this some years ago.

But there are very likely many newer and maybe better resources on
graphics in R. Try searching at the Rseek website, Rseek.org on "R
graphics tutorials" or something similar.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 24, 2016 at 7:49 PM, hui.chen <hui.chen at 3dmedcare.com> wrote:
> Dear Sir/Madam:
> Your web of "R Graphical Manual" is so wonderful! But the
> URL(http://rgm.ogalab.net/RGM) cannot be found now, may I ask for your new
> URL?
> Thx for your reply!
>
> Sincerely yours,
> Abigail Chen
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Feb 25 08:39:37 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 25 Feb 2016 07:39:37 +0000
Subject: [R] adding a column to data frame solving the replacement
 problem
In-Reply-To: <1491467038.9395502.1456324739104.JavaMail.yahoo@mail.yahoo.com>
References: <1491467038.9395502.1456324739104.JavaMail.yahoo.ref@mail.yahoo.com>
	<1491467038.9395502.1456324739104.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011129@SRVEXCHMBX.precheza.cz>

Hi

It seems to me that you misunderstand how objects (data.frames) in R work.

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hoda
> rahmati via R-help
> Sent: Wednesday, February 24, 2016 3:39 PM
> To: r-help at r-project.org
> Subject: [R] adding a column to data frame solving the replacement
> problem
>
> Hi all,
>
> I have a data set (mydata) containing 471 variables. One of the columns
> looks as below
>
> $ Sequence : Factor w/ 3 levels "","%Seq%gre",..: 2 2 2 2 2 2 2 2 2 2

There is also missing value in this column. I am not sure if it is intended, it is your decision. To get missing values as really missing when importing data you shall explicitly use na identifier in read command, something like.

mydata <- read.*(something, na.string="")

from help page:
na.strings
a character vector of strings which are to be interpreted as NA values. Blank fields are also considered to be missing values in logical, integer, numeric and complex fields.

> ...
>
> sequence contains %Seq%gre and %Seq%tse and I extract only %Seq%tse and
> add it to my variables and plot a scatterplot of mydata. I use table
> and the result is: table(mydata$Sequence)
>  %Seq%gre %Seq%tse
>           1           25520          243744 in the next step I  want to
> add a column to my main data set (mydata) containing only %Seq%tse,
> however when I use the following command there's an error telling me:
> Error in `$<-.data.frame`(`*tmp*`, "NewColumn", value = c(3L, 3L, 3L,
>  :
>   replacement has 243744 rows, data has 269265 How can I add this
> column correctly to mydata? Thanks for any help

There is no command in your mail. However all columns in data frame has to have the same length, so when you add shorter vector it is recycled without error.

see
iris$aaa <- letters[1:5]
head(iris,10)

This simple command does not produce error.

I can get similar error

> iris[iris$aaa=="c", 1]<- iris[,2]

Error in `[<-.data.frame`(`*tmp*`, iris$aaa == "c", 1, value = c(3.5,  :
  replacement has 150 rows, data has 30

this results from operation in which I try add longer vector to shorter data frame.

To get more specific answer, you shall add exact command you used (maybe also a toy working example).


>       [[alternative HTML version deleted]]

And you shall post in plain text, not HTML.

Cheers
Petr

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From thpe at simecol.de  Thu Feb 25 09:08:16 2016
From: thpe at simecol.de (Thomas Petzoldt)
Date: Thu, 25 Feb 2016 09:08:16 +0100
Subject: [R] Problems with the deSolve package
In-Reply-To: <CANKjaMckMnufs4c668nT8FGojbCyVfV_fx1-QGzNknHJSGGKqQ@mail.gmail.com>
References: <DUB119-W31D1E2CC45343BA20EBD5DAEA00@phx.gbl>
	<CANKjaMfwdqPXnd=DbHCJkgb5c6YpdmbZx9SA3Kz2CsQcdxdZMw@mail.gmail.com>
	<DUB119-W21FE0AE8575EB6A266E3F9AEA30@phx.gbl>
	<CANKjaMdaWBOkZb-_hbK_nZovMh9Ef9WpwpG33ZsheU5O7JNkLA@mail.gmail.com>
	<CANKjaMckMnufs4c668nT8FGojbCyVfV_fx1-QGzNknHJSGGKqQ@mail.gmail.com>
Message-ID: <56CEB670.6020300@simecol.de>

Hi,

to diagnose your problem, I tried the model with your original 
parameters, using a Runge-Kutta fixed step integrator and smaller time 
steps. You may try to make them even smaller.

rk4 has no warranted accuracy, so it is less reliable than "lsoda" etc. 
However, it can be useful for debugging, because it runs constantly 
through, even if NA or NaN's occur. We see that the states grow 
drastically to extremely high (or even negative) values.

This points indeed to unrealistic parameter values, or to a 
model-misspecification, which means that necessary feedback mechanisms 
are missing, so that i12 can grow, even if nothing is left (i1, i2) from 
which it can grow from.

Regards, Thomas



init <- c(i1=10, i2=10, i12=0)
parameters <- c(alpha1=0.7, alpha2=0.5, beta1=0.5, beta2=0.3,
   gamma1=0.5, gamma2=0.5, delta=0.5, N=100)
times <- seq(0, 10, by=.01)

simul <- as.data.frame(ode(y = init, times = times, func = system,
   parms = parameters, method="rk4"))

head(simul, 200)
     time            i1            i2          i12
1   0.00  1.000000e+01  1.000000e+01 0.000000e+00
2   0.01  1.685572e+01  1.433028e+01 6.451953e-01
3   0.02  2.567008e+01  1.875164e+01 4.259949e+00
4   0.03  3.251911e+01  2.091655e+01 4.215409e+01
5   0.04 -1.270280e+00 -1.988876e+00 1.581789e+02
6   0.05 -8.108876e+02 -4.992572e+02 2.631133e+04
7   0.06 -4.166359e+73 -2.975971e+73 6.427467e+98
8   0.07           NaN           NaN          NaN
9   0.08           NaN           NaN          NaN

...



-- 
Dr. Thomas Petzoldt
Technische Universitaet Dresden
Faculty of Environmental Sciences
Institute of Hydrobiology
01062 Dresden, Germany

E-Mail: thomas.petzoldt at tu-dresden.de
http://tu-dresden.de/Members/thomas.petzoldt


From efisio.solazzo at jrc.ec.europa.eu  Thu Feb 25 10:46:12 2016
From: efisio.solazzo at jrc.ec.europa.eu (efisio solazzo)
Date: Thu, 25 Feb 2016 10:46:12 +0100
Subject: [R] colors in facet ggplot and geom_bar
In-Reply-To: <2D56CB6F-6E70-40B9-9DD7-CF849F336D49@dcn.davis.ca.us>
References: <56CB2821.6060105@jrc.ec.europa.eu>
	<2D56CB6F-6E70-40B9-9DD7-CF849F336D49@dcn.davis.ca.us>
Message-ID: <56CECD64.7080709@jrc.ec.europa.eu>

Dear,
     Ok...I thought a hint would have been sufficient, but I'm still stuck.

based on the 'Data' dataframe:

Data
    mod_names err_type        value spec_comp sign.value          pos
1       mod1      var 2.970681e-03        ID          - 1.485341e-03
2       mod1     mMSE 1.881598e-01        ID            9.705057e-02
3       mod2      var 2.999713e-02        ID          - 1.499856e-02
4       mod2     mMSE 3.055899e-01        ID            1.827921e-01
5       mod3      var 1.570650e-01        ID          + 7.853252e-02
6       mod3     mMSE 2.430458e-01        ID            2.785880e-01
7       mod4      var 2.439812e-02        ID          + 1.219906e-02
8       mod4     mMSE 1.439277e-01        ID            9.636199e-02
9       mod1      var 6.476435e-01        DU          - 3.238218e-01
10      mod1     mMSE 1.575243e+00        DU            1.435265e+00
11      mod2      var 1.394583e-02        DU          - 6.972916e-03
12      mod2     mMSE 1.269346e+01        DU            6.360675e+00
13      mod3      var 1.338403e+00        DU          + 6.692017e-01
14      mod3     mMSE 8.775683e+00        DU            5.726245e+00
15      mod4      var 5.583281e-02        DU          - 2.791641e-02
16      mod4     mMSE 3.591430e+00        DU            1.851548e+00
17      mod1      var 2.810587e-01        SY          + 1.405294e-01
18      mod1     mMSE 8.157692e-01        SY            6.889433e-01
19      mod2      var 1.747732e-01        SY          + 8.738661e-02
20      mod2     mMSE 9.926385e-01        SY            6.710925e-01
21      mod3      var 1.113529e-01        SY          + 5.567645e-02
22      mod3     mMSE 6.747922e-01        SY            4.487490e-01
23      mod4      var 2.017077e+00        SY          + 1.008539e+00
24      mod4     mMSE 1.231198e+00        SY            2.632676e+00
25      mod1     bias 7.167534e+01        LT          + 3.583767e+01
26      mod1      var 3.287647e-06        LT          - 7.167534e+01
27      mod1     mMSE 2.113895e+00        LT            7.273229e+01
28      mod2     bias 5.979827e+01        LT          + 2.989914e+01
29      mod2      var 8.464560e-04        LT          - 5.979869e+01
30      mod2     mMSE 9.425981e-01        LT            6.027042e+01
31      mod3     bias 5.604628e+00        LT          + 2.802314e+00
32      mod3      var 4.698450e-02        LT          - 5.628121e+00
33      mod3     mMSE 6.434771e-01        LT            5.973351e+00
34      mod4     bias 1.614153e+02        LT          + 8.070763e+01
35      mod4      var 4.131887e+00        LT          + 1.634812e+02
36      mod4     mMSE 5.797821e+00        LT            1.684461e+02

I run the command:

ggplot(Data, aes(x=mod_names, y=value,
fill=err_type))+geom_bar(stat='identity', position='stack')  +
    facet_wrap(~spec_comp, nrow=1,
scales="free")                                +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5,
hjust=1.))        +
    theme(axis.title.x = element_blank())+ ylab(units) +
    geom_text ( aes(label=sign.value, y=pos))  +....

where err_type = c('bias', mMSe', 'var'). My questions are
1.  how to color-code only the mMSE portion of the bars based on a range of values 'r' from -1 to 1 (basically the correlation coefficient):

r
        ID  DU   SY   LT
mod1 -0.5 0.5  0.4 -0.1
mod2  0.6 0.2 -0.2  0.9
mod3  0.5 0.5  0.9 -1.0
mod4  0.4 0.3  0.2  0.0

2. and how to color-code the x-labels of the last panel (the LT one) based on the values of 'bias'.

Thanks a lot for your help.




On 22/02/2016 17:00, Jeff Newmiller wrote:
> By failing to provide a reproducible example and framing the desired 
> answer as 'any hint' you are effectively limiting yourself to 'any 
> hint' rather than a working example.
>
> The 'any hint' is that err_type should be a factor with levels in your 
> desired order, and you can then use any of the scale_fill_* functions 
> including scale_colour_manual to specify the colors in the same order 
> as the levels in the factor.
> -- 
> Sent from my phone. Please excuse my brevity.
>
> On February 22, 2016 7:24:17 AM PST, efisio solazzo 
> <efisio.solazzo at jrc.ec.europa.eu> wrote:
>
>     Dear,
>     I wonder if there is a way to 'play' with colors in facet ggplot and
>     geom_bar.
>
>     With reference to the attached figure, I'd like to
>     - color the green portion based on a numerical variable (say 1 to 10) on
>     all of the four panels and
>     - color-code the y labels based on the values of the 'bias' (red portion
>     of bars) only on the fourth panel.
>
>     the code to produce the plot is:
>
>     ggplot(Data, aes(x=mod_names, y=value,
>     fill=err_type))+geom_bar(stat='identity', position='stack')  +
>         facet_wrap(~spec_comp, nrow=1,
>     scales="free")                                +
>         theme(axis.text.x = element_text(angle = 90, vjust = 0.5,
>     hjust=1.))        +
>         theme(axis.title.x = element_blank())+ ylab(units) +
>         geom_text ( aes(label=sign.value, y=pos))  +....
>
>     where err_type = c('bias', mMSe', 'var')
>
>     thanks for any hint.
>


-- 
Efisio SOLAZZO, Ph.D.
European Commission, Joint Research Centre,
Institute for Environment and Sustainability,
TP123, Via E. Fermi, 2749 I-21027 Ispra (VA), Italy
Tel: +390332789944 Fax: +390332785837


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Feb 25 11:15:23 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 25 Feb 2016 21:15:23 +1100
Subject: [R] KNN
In-Reply-To: <CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
	<CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
	<CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>
Message-ID: <CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>

Hi Alnazer,
I'm not surprised that it didn't do what you expected. Even if I clean
up the code so that it will actually run:

majorityGuessing<-function(trainingData,categories) {
 GuessMPG<-sample(1:length(categories),nrow(trainingData),replace=TRUE)
 return(GuessMPG)
}

and call it like this (assuming that you are trying to do something
like guessing MPG from the number of cylinders):

auto<-read.csv("auto.csv")
majorityGuessing(auto$MPG,unique(auto$CYLINDERS))

the result is just a sample of 398 integers ranging from 1 to 5, which
is not even a guess. Unfortunately, I can't work out what metric you
want to select "nearest neighbors", but perhaps someone else can.

Jim

On Thu, Feb 25, 2016 at 5:30 PM, Alnazer Elbedairy
<alnazer.elbedairy at gmail.com> wrote:
> Dear Jim
> thanks you for your kind help.
> KNN - is K- Nearest Neighbor, is a technique used in Machine Learning.
> attached you will find a CSV file dataset, my question is :
> use the attached Dataset, Use majority guessing technique to evaluate KNN ?
> this is the solution I came up with, but I didn't work :-
> majorityGuessing <- function(trainingData,categories)
> {GuessMPG <- sample(1:length (categories-1, nrow(testingData),replace=T)
> return(GuessMPG)
>
>
>
> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Alnazar,
>> I looked at your question yesterday and was unable to find what a
>> "majority guessing" function is. I think it may be related to the
>> "Pandemonium" model of decision making, but that doesn't get me very
>> far. Could you give us a hint as to what this function is?
>>
>>
>
> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Alnazar,
>> I looked at your question yesterday and was unable to find what a
>> "majority guessing" function is. I think it may be related to the
>> "Pandemonium" model of decision making, but that doesn't get me very
>> far. Could you give us a hint as to what this function is?
>>
>> Jim
>>
>>
>> On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com>
>> wrote:
>> > How I can use majority guessing function to evaluate KNN, if I have data
>> > saved in CSV file
>> >
>> > Alnazer Elbedairy
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From catalinroibu at gmail.com  Thu Feb 25 12:36:42 2016
From: catalinroibu at gmail.com (catalin roibu)
Date: Thu, 25 Feb 2016 13:36:42 +0200
Subject: [R] distribution freq
Message-ID: <CAEW+BD+P8fhiFoWWmB+XPz7aY6-6A6mi7UkauATpQYi8NEX99A@mail.gmail.com>

Dear all!

I want to apply gamma distribution to a data set. I obtained ty pdf values
and I want to transform this values in absolute frequencies. I used dgamma,
without success. Please help me to solve this problem.

Best regards!

CR
-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb 25 12:46:35 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 25 Feb 2016 06:46:35 -0500
Subject: [R] distribution freq
In-Reply-To: <CAEW+BD+P8fhiFoWWmB+XPz7aY6-6A6mi7UkauATpQYi8NEX99A@mail.gmail.com>
References: <CAEW+BD+P8fhiFoWWmB+XPz7aY6-6A6mi7UkauATpQYi8NEX99A@mail.gmail.com>
Message-ID: <56CEE99B.6020108@gmail.com>

On 25/02/2016 6:36 AM, catalin roibu wrote:
> Dear all!
>
> I want to apply gamma distribution to a data set. I obtained ty pdf values
> and I want to transform this values in absolute frequencies. I used dgamma,
> without success. Please help me to solve this problem.

It's not clear what you want to do here.  Could you put together a short 
example showing what input you have and what output you'd like?

Duncan Murdoch


From jean-externe.maurice at edf.fr  Thu Feb 25 15:42:36 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Thu, 25 Feb 2016 14:42:36 +0000
Subject: [R] getDLLRegisteredRoutines
Message-ID: <54049d91fe074d4db49497bc37c45c95@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,

I have built a DLL with some routines using Intel's FORTRAN. I can use the routines within a R script.

I would like to have the list of all the routines in the DLL. I found getDLLRegisteredRoutines but it answers data frame with 0 column and 0 lines.

What is wrong ?

Thanks in advance
Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From dcarlson at tamu.edu  Thu Feb 25 15:49:06 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 25 Feb 2016 14:49:06 +0000
Subject: [R] KNN
In-Reply-To: <CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
	<CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
	<CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>
	<CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70D970@mb02.ads.tamu.edu>

Perhaps Alnazer is trying to implement "majority vote" kNN:

>From Wikipedia
(https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm):

In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.

But as Jim said, your function does not do this. It does not even run kNN. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Thursday, February 25, 2016 4:15 AM
To: Alnazer Elbedairy
Cc: r-help mailing list
Subject: Re: [R] KNN

Hi Alnazer,
I'm not surprised that it didn't do what you expected. Even if I clean
up the code so that it will actually run:

majorityGuessing<-function(trainingData,categories) {
 GuessMPG<-sample(1:length(categories),nrow(trainingData),replace=TRUE)
 return(GuessMPG)
}

and call it like this (assuming that you are trying to do something
like guessing MPG from the number of cylinders):

auto<-read.csv("auto.csv")
majorityGuessing(auto$MPG,unique(auto$CYLINDERS))

the result is just a sample of 398 integers ranging from 1 to 5, which
is not even a guess. Unfortunately, I can't work out what metric you
want to select "nearest neighbors", but perhaps someone else can.

Jim

On Thu, Feb 25, 2016 at 5:30 PM, Alnazer Elbedairy
<alnazer.elbedairy at gmail.com> wrote:
> Dear Jim
> thanks you for your kind help.
> KNN - is K- Nearest Neighbor, is a technique used in Machine Learning.
> attached you will find a CSV file dataset, my question is :
> use the attached Dataset, Use majority guessing technique to evaluate KNN ?
> this is the solution I came up with, but I didn't work :-
> majorityGuessing <- function(trainingData,categories)
> {GuessMPG <- sample(1:length (categories-1, nrow(testingData),replace=T)
> return(GuessMPG)
>
>
>
> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Alnazar,
>> I looked at your question yesterday and was unable to find what a
>> "majority guessing" function is. I think it may be related to the
>> "Pandemonium" model of decision making, but that doesn't get me very
>> far. Could you give us a hint as to what this function is?
>>
>>
>
> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Alnazar,
>> I looked at your question yesterday and was unable to find what a
>> "majority guessing" function is. I think it may be related to the
>> "Pandemonium" model of decision making, but that doesn't get me very
>> far. Could you give us a hint as to what this function is?
>>
>> Jim
>>
>>
>> On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com>
>> wrote:
>> > How I can use majority guessing function to evaluate KNN, if I have data
>> > saved in CSV file
>> >
>> > Alnazer Elbedairy
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From fabio.monteiro1992 at gmail.com  Thu Feb 25 13:31:00 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Thu, 25 Feb 2016 12:31:00 +0000
Subject: [R] Scaling x axis
Message-ID: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>

Hi

i'm trying to plot my data in R and i can't manage to scale the x axis.

My x axis are dates, months and years, and when I plot I only have the x
axis like this (2002, 2004, 2006, 2008, 2010).

I whant every date in the axis not only those years, i want to see every
point with the respectively date in the axis.

How can I do that?

Kind regards

F?bio monteiro

	[[alternative HTML version deleted]]


From alnazer.elbedairy at gmail.com  Thu Feb 25 16:23:00 2016
From: alnazer.elbedairy at gmail.com (Alnazer)
Date: Thu, 25 Feb 2016 09:23:00 -0600
Subject: [R] KNN
In-Reply-To: <CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
	<CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
	<CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>
	<CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>
Message-ID: <96667731-84DE-4F27-91CB-BC09D20F31D8@gmail.com>

Appreciated Jim.

Alnazer Elbedairy


> On Feb 25, 2016, at 4:15 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Alnazer,
> I'm not surprised that it didn't do what you expected. Even if I clean
> up the code so that it will actually run:
> 
> majorityGuessing<-function(trainingData,categories) {
> GuessMPG<-sample(1:length(categories),nrow(trainingData),replace=TRUE)
> return(GuessMPG)
> }
> 
> and call it like this (assuming that you are trying to do something
> like guessing MPG from the number of cylinders):
> 
> auto<-read.csv("auto.csv")
> majorityGuessing(auto$MPG,unique(auto$CYLINDERS))
> 
> the result is just a sample of 398 integers ranging from 1 to 5, which
> is not even a guess. Unfortunately, I can't work out what metric you
> want to select "nearest neighbors", but perhaps someone else can.
> 
> Jim
> 
> On Thu, Feb 25, 2016 at 5:30 PM, Alnazer Elbedairy
> <alnazer.elbedairy at gmail.com> wrote:
>> Dear Jim
>> thanks you for your kind help.
>> KNN - is K- Nearest Neighbor, is a technique used in Machine Learning.
>> attached you will find a CSV file dataset, my question is :
>> use the attached Dataset, Use majority guessing technique to evaluate KNN ?
>> this is the solution I came up with, but I didn't work :-
>> majorityGuessing <- function(trainingData,categories)
>> {GuessMPG <- sample(1:length (categories-1, nrow(testingData),replace=T)
>> return(GuessMPG)
>> 
>> 
>> 
>>> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> 
>>> Hi Alnazar,
>>> I looked at your question yesterday and was unable to find what a
>>> "majority guessing" function is. I think it may be related to the
>>> "Pandemonium" model of decision making, but that doesn't get me very
>>> far. Could you give us a hint as to what this function is?
>> 
>>> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> 
>>> Hi Alnazar,
>>> I looked at your question yesterday and was unable to find what a
>>> "majority guessing" function is. I think it may be related to the
>>> "Pandemonium" model of decision making, but that doesn't get me very
>>> far. Could you give us a hint as to what this function is?
>>> 
>>> Jim
>>> 
>>> 
>>> On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com>
>>> wrote:
>>>> How I can use majority guessing function to evaluate KNN, if I have data
>>>> saved in CSV file
>>>> 
>>>> Alnazer Elbedairy
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb 25 16:24:38 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 25 Feb 2016 10:24:38 -0500
Subject: [R] getDLLRegisteredRoutines
In-Reply-To: <54049d91fe074d4db49497bc37c45c95@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <54049d91fe074d4db49497bc37c45c95@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <56CF1CB6.60900@gmail.com>

On 25/02/2016 9:42 AM, MAURICE Jean - externe wrote:
> Hi,
>
> I have built a DLL with some routines using Intel's FORTRAN. I can use the routines within a R script.
>
> I would like to have the list of all the routines in the DLL. I found getDLLRegisteredRoutines but it answers data frame with 0 column and 0 lines.
>
> What is wrong ?

You didn't register them.  See section 5.4 in Writing R Extensions for 
details on how to do that.

R doesn't have a function to list all exports from a DLL.  There are 
various external tools to do that.  "pedump.exe" and "nm.exe" are 
included in the Rtools  collection.  (I usually use pedump; I forget 
whether nm works on .dll files, or only .so files.)

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Feb 25 16:28:12 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 25 Feb 2016 10:28:12 -0500
Subject: [R] Scaling x axis
In-Reply-To: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>
References: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>
Message-ID: <56CF1D8C.8000308@gmail.com>

On 25/02/2016 7:31 AM, Fabio Monteiro wrote:
> Hi
>
> i'm trying to plot my data in R and i can't manage to scale the x axis.
>
> My x axis are dates, months and years, and when I plot I only have the x
> axis like this (2002, 2004, 2006, 2008, 2010).
>
> I whant every date in the axis not only those years, i want to see every
> point with the respectively date in the axis.
>
> How can I do that?

Plot it with axes = FALSE, and then add each axis using the Axis() (or 
axis() or axis.Date() or...) function.

Duncan Murdoch


From petr.pikal at precheza.cz  Thu Feb 25 16:29:53 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 25 Feb 2016 15:29:53 +0000
Subject: [R] Scaling x axis
In-Reply-To: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>
References: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C501138E@SRVEXCHMBX.precheza.cz>

Hi

you do not say which type of plot you use so I presume it is some base plot.

you can use axes=FALSE when you plot your data and change axis by

axis(....)

command
see
?axis

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fabio
> Monteiro
> Sent: Thursday, February 25, 2016 1:31 PM
> To: r-help at r-project.org
> Subject: [R] Scaling x axis
>
> Hi
>
> i'm trying to plot my data in R and i can't manage to scale the x axis.
>
> My x axis are dates, months and years, and when I plot I only have the
> x axis like this (2002, 2004, 2006, 2008, 2010).
>
> I whant every date in the axis not only those years, i want to see
> every point with the respectively date in the axis.
>
> How can I do that?
>
> Kind regards
>
> F?bio monteiro
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From btupper at bigelow.org  Thu Feb 25 16:32:14 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 25 Feb 2016 10:32:14 -0500
Subject: [R] KNN
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70D970@mb02.ads.tamu.edu>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
	<CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
	<CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>
	<CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70D970@mb02.ads.tamu.edu>
Message-ID: <2A9C5557-08D2-458E-A293-AC623102A69B@bigelow.org>

Hi,

Do the knn() or knn1() functions in the 'class' package serve your purpose?

https://cran.r-project.org/web/packages/class/index.html

Ben
 
> On Feb 25, 2016, at 9:49 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Perhaps Alnazer is trying to implement "majority vote" kNN:
> 
>> From Wikipedia
> (https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm):
> 
> In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.
> 
> But as Jim said, your function does not do this. It does not even run kNN. 
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Thursday, February 25, 2016 4:15 AM
> To: Alnazer Elbedairy
> Cc: r-help mailing list
> Subject: Re: [R] KNN
> 
> Hi Alnazer,
> I'm not surprised that it didn't do what you expected. Even if I clean
> up the code so that it will actually run:
> 
> majorityGuessing<-function(trainingData,categories) {
> GuessMPG<-sample(1:length(categories),nrow(trainingData),replace=TRUE)
> return(GuessMPG)
> }
> 
> and call it like this (assuming that you are trying to do something
> like guessing MPG from the number of cylinders):
> 
> auto<-read.csv("auto.csv")
> majorityGuessing(auto$MPG,unique(auto$CYLINDERS))
> 
> the result is just a sample of 398 integers ranging from 1 to 5, which
> is not even a guess. Unfortunately, I can't work out what metric you
> want to select "nearest neighbors", but perhaps someone else can.
> 
> Jim
> 
> On Thu, Feb 25, 2016 at 5:30 PM, Alnazer Elbedairy
> <alnazer.elbedairy at gmail.com> wrote:
>> Dear Jim
>> thanks you for your kind help.
>> KNN - is K- Nearest Neighbor, is a technique used in Machine Learning.
>> attached you will find a CSV file dataset, my question is :
>> use the attached Dataset, Use majority guessing technique to evaluate KNN ?
>> this is the solution I came up with, but I didn't work :-
>> majorityGuessing <- function(trainingData,categories)
>> {GuessMPG <- sample(1:length (categories-1, nrow(testingData),replace=T)
>> return(GuessMPG)
>> 
>> 
>> 
>> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> 
>>> Hi Alnazar,
>>> I looked at your question yesterday and was unable to find what a
>>> "majority guessing" function is. I think it may be related to the
>>> "Pandemonium" model of decision making, but that doesn't get me very
>>> far. Could you give us a hint as to what this function is?
>>> 
>>> 
>> 
>> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> 
>>> Hi Alnazar,
>>> I looked at your question yesterday and was unable to find what a
>>> "majority guessing" function is. I think it may be related to the
>>> "Pandemonium" model of decision making, but that doesn't get me very
>>> far. Could you give us a hint as to what this function is?
>>> 
>>> Jim
>>> 
>>> 
>>> On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com>
>>> wrote:
>>>> How I can use majority guessing function to evaluate KNN, if I have data
>>>> saved in CSV file
>>>> 
>>>> Alnazer Elbedairy
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From alnazer.elbedairy at gmail.com  Thu Feb 25 17:58:57 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Thu, 25 Feb 2016 08:58:57 -0800
Subject: [R] KNN
In-Reply-To: <2A9C5557-08D2-458E-A293-AC623102A69B@bigelow.org>
References: <1B182E91-9ECA-4F29-8476-4D178AC9E3C0@gmail.com>
	<CA+8X3fW68LH2e0ARBfAmQnUXJL8-ZBznh_1zC3UsYB_44HxX_w@mail.gmail.com>
	<CAD2s_FTr0YR6DJqHqnLzO8cJnB4=9ZsjyxeTwJtOUOZ5HY+fxw@mail.gmail.com>
	<CA+8X3fWj2aRAqa-6hm9PVqVnXq-gbnvcH8b=7XeZcxGbfgfcvg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D70D970@mb02.ads.tamu.edu>
	<2A9C5557-08D2-458E-A293-AC623102A69B@bigelow.org>
Message-ID: <CAD2s_FRAGtO1RJDCuc6PWjovoCiUb0es84Duhhh49Uk1HafcCw@mail.gmail.com>

Dear All
Divide (same dataset) into 10 folds
fold1 <- nautaData[1:39]
fold2 <- nautaData[40:79]
fold3 <- nautaData[80:119]
fold4 <- nautaData[120:159]
fold5 <- nautaData[160:199]
fold6 <- nautaData[200:239]
fold7 <- nautaData[240:279]
fold8 <- nautaData[280:319]
fold9 <- nautaData[320:359]
fold10 <- nautaData[360:398]
 then
1- conduct 10 fold cross validation on KNN and magorityGuessing function
2- print classification error for both KNN and MPG for every fold
3- print confusion matrix for KNN during each fold
 thank you for help

On Thu, Feb 25, 2016 at 7:32 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> Do the knn() or knn1() functions in the 'class' package serve your purpose?
>
> https://cran.r-project.org/web/packages/class/index.html
>
> Ben
>
> > On Feb 25, 2016, at 9:49 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> >
> > Perhaps Alnazer is trying to implement "majority vote" kNN:
> >
> >> From Wikipedia
> > (https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm):
> >
> > In k-NN classification, the output is a class membership. An object is
> classified by a majority vote of its neighbors, with the object being
> assigned to the class most common among its k nearest neighbors (k is a
> positive integer, typically small). If k = 1, then the object is simply
> assigned to the class of that single nearest neighbor.
> >
> > But as Jim said, your function does not do this. It does not even run
> kNN.
> >
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim
> Lemon
> > Sent: Thursday, February 25, 2016 4:15 AM
> > To: Alnazer Elbedairy
> > Cc: r-help mailing list
> > Subject: Re: [R] KNN
> >
> > Hi Alnazer,
> > I'm not surprised that it didn't do what you expected. Even if I clean
> > up the code so that it will actually run:
> >
> > majorityGuessing<-function(trainingData,categories) {
> > GuessMPG<-sample(1:length(categories),nrow(trainingData),replace=TRUE)
> > return(GuessMPG)
> > }
> >
> > and call it like this (assuming that you are trying to do something
> > like guessing MPG from the number of cylinders):
> >
> > auto<-read.csv("auto.csv")
> > majorityGuessing(auto$MPG,unique(auto$CYLINDERS))
> >
> > the result is just a sample of 398 integers ranging from 1 to 5, which
> > is not even a guess. Unfortunately, I can't work out what metric you
> > want to select "nearest neighbors", but perhaps someone else can.
> >
> > Jim
> >
> > On Thu, Feb 25, 2016 at 5:30 PM, Alnazer Elbedairy
> > <alnazer.elbedairy at gmail.com> wrote:
> >> Dear Jim
> >> thanks you for your kind help.
> >> KNN - is K- Nearest Neighbor, is a technique used in Machine Learning.
> >> attached you will find a CSV file dataset, my question is :
> >> use the attached Dataset, Use majority guessing technique to evaluate
> KNN ?
> >> this is the solution I came up with, but I didn't work :-
> >> majorityGuessing <- function(trainingData,categories)
> >> {GuessMPG <- sample(1:length (categories-1, nrow(testingData),replace=T)
> >> return(GuessMPG)
> >>
> >>
> >>
> >> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>
> >>> Hi Alnazar,
> >>> I looked at your question yesterday and was unable to find what a
> >>> "majority guessing" function is. I think it may be related to the
> >>> "Pandemonium" model of decision making, but that doesn't get me very
> >>> far. Could you give us a hint as to what this function is?
> >>>
> >>>
> >>
> >> On Wed, Feb 24, 2016 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>
> >>> Hi Alnazar,
> >>> I looked at your question yesterday and was unable to find what a
> >>> "majority guessing" function is. I think it may be related to the
> >>> "Pandemonium" model of decision making, but that doesn't get me very
> >>> far. Could you give us a hint as to what this function is?
> >>>
> >>> Jim
> >>>
> >>>
> >>> On Wed, Feb 24, 2016 at 7:02 AM, Alnazer <alnazer.elbedairy at gmail.com>
> >>> wrote:
> >>>> How I can use majority guessing function to evaluate KNN, if I have
> data
> >>>> saved in CSV file
> >>>>
> >>>> Alnazer Elbedairy
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>

	[[alternative HTML version deleted]]


From bhava20april at gmail.com  Thu Feb 25 17:11:10 2016
From: bhava20april at gmail.com (Bhavani Akila)
Date: Thu, 25 Feb 2016 21:41:10 +0530
Subject: [R] Need help in installing packages in R
Message-ID: <CA+dSo4BbZ4At5Xorj8mjOzfMovggjoX__M8fPPJf0xCpH5kOaA@mail.gmail.com>

Hi,

I have just started learning about "R" programming language. I tried to
connect it to SQL server using "RODBC". On trying to install packages in R
with the command
Eg., 'Install.Packages=="RODBC"', the zip file is not getting downloaded as
am not able to access to the webpage since am working in a restricted
environment.

I have some how managed to get the zip file, but I have no idea how to
install it into my system(Because on installing using "R Console", it
itself is getting unpacked and getting installed in a specific location)

Can I just install by unzipping and placing the file in some random
location and connect R with SQL or is there any procedure to install the
package?

Kindly help me install "R Packages" without the use of "R Console"(With the
use of zip file).

Thanks in advance..!!! ??
-- 

Bhavani.P

	[[alternative HTML version deleted]]


From katharine.miller at noaa.gov  Thu Feb 25 19:53:40 2016
From: katharine.miller at noaa.gov (Katharine Miller - NOAA Federal)
Date: Thu, 25 Feb 2016 09:53:40 -0900
Subject: [R] Specify order of groups negative binomial (glm.nb)
Message-ID: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>

Hi,
I am using the glm.nb function to evaluate differences in the catch of
individual species of fish across three river tributaries.  The dependent
variable is catch per unit effort (CPUE), and the independent variable is
the the tributary (Trib_cat).  CPUE is derived from the fish counts divided
by the effort, so the response is not a count per se, but I think the
negative binomial is appropriate because of the large numbers of zeros in
the dependent variable. Trib_cat is a column with 1, 2, or 3 depending on
which tributary it is representing.

I have the following code:

dataS<-read.table("OtherSpecies.txt", sep="", header=T)

dataS <- within(dataS, {
  Trib_cat <- factor(Trib_cat, levels = 1:3, labels = c("MM", "NM", "SM"))
  Year<-factor(Year)
})

## separate out the species of interest
coregonid<-subset(dataS, Spec_age=="Coregonid")

fit.CT<-glm.nb(CPUE ~ Trib_cat, data=coregonid, link = log)
summary(fit.CT)

The result comes out like this:
Call:
glm.nb(formula = CPUE ~ Trib_cat, data = coregonid4, init.theta =
0.1723775759,
    link = log)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-0.9239  -0.8055  -0.6687  -0.6286   2.9020

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -0.7805     0.2497  -3.125  0.00178 **
Trib_catNM   -0.2140     0.3485  -0.614  0.53921
Trib_catSM    0.7393     0.3296   2.243  0.02488 *
---

This gives me the difference in CPUE between the NM and SM tributaries
compared to the MM tributary  (acting here as the reference group).  What I
need is to compare all of the tributaries with all the others - so I need
to run the model twice with a different reference group on the second run.
  I can do this by changing the numbering of the Trib_cat field  in the
underlying database (e.g. changing MM from 1 to 3, SM from 2 to 1, etc) and
re-running the model, but I, as I have a number of species to do this for,
I was wondering if there was an easier way to specify which group to use as
the reference group when calling the model.

Thanks for any help.

	[[alternative HTML version deleted]]


From Nazatulshima.Hassan at liverpool.ac.uk  Thu Feb 25 16:59:33 2016
From: Nazatulshima.Hassan at liverpool.ac.uk (Hassan, Nazatulshima)
Date: Thu, 25 Feb 2016 15:59:33 +0000
Subject: [R] bootstrap glm
Message-ID: <B653E9EFB809DA4ABF9EFA0944845675059F78CF@BHEXMBX2.livad.liv.ac.uk>

Hi

I have a data with an outcome,Y and 10 predictors (X1-X10).
My aim is to fit a logistic model to each of the predictors and calculate the deviance difference (dDeviance).
And later on bootstrapping the dDeviance for 100 times (R=100).
I tried the following function. It is calculating the original dDeviance correctly. But, when I checked the mean bootstrap values, it differs greatly from the original.
I suspect I made a mistake with the bootstrapping function, which I need help with.
I attached the script if you need to look at it.

Thank you in advance.


set.seed(111)

yfunction <- function(data,indices)
{
glm.snp1 <- glm(Y~data[indices], family="binomial", data=datasim)
null <- glm.snp1$null.deviance
residual <- glm.snp1$deviance
dDeviance <-(null-residual)
return(dDeviance)
}

mybootstrap <- function(data)
{
boot(data,yfunction, R=100)
}

resulty <- lapply(datasim[,-1],function(x)mybootstrap(x))
bootresult <- sapply(datasim[,-1],function(x)mybootstrap(x)$t)
colMeans(bootresult)



-shima-


From bgunter.4567 at gmail.com  Thu Feb 25 21:48:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 25 Feb 2016 12:48:19 -0800
Subject: [R] Specify order of groups negative binomial (glm.nb)
In-Reply-To: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
References: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
Message-ID: <CAGxFJbQnvv7WYLP7d+g6kmUi+ciFQa+mCP9PdnEyJLMG_x3deg@mail.gmail.com>

You can re-set the contrasts for the factor, though whether this is
"easier" is a matter of personal preference.

See ?C or ?contrasts, which I understand to be alternative ways of
doing the same thing (and would appreciate correction is this is
wrong). Or this can be done through the "contrasts" argument of
glm.nb.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 25, 2016 at 10:53 AM, Katharine Miller - NOAA Federal
<katharine.miller at noaa.gov> wrote:
> Hi,
> I am using the glm.nb function to evaluate differences in the catch of
> individual species of fish across three river tributaries.  The dependent
> variable is catch per unit effort (CPUE), and the independent variable is
> the the tributary (Trib_cat).  CPUE is derived from the fish counts divided
> by the effort, so the response is not a count per se, but I think the
> negative binomial is appropriate because of the large numbers of zeros in
> the dependent variable. Trib_cat is a column with 1, 2, or 3 depending on
> which tributary it is representing.
>
> I have the following code:
>
> dataS<-read.table("OtherSpecies.txt", sep="", header=T)
>
> dataS <- within(dataS, {
>   Trib_cat <- factor(Trib_cat, levels = 1:3, labels = c("MM", "NM", "SM"))
>   Year<-factor(Year)
> })
>
> ## separate out the species of interest
> coregonid<-subset(dataS, Spec_age=="Coregonid")
>
> fit.CT<-glm.nb(CPUE ~ Trib_cat, data=coregonid, link = log)
> summary(fit.CT)
>
> The result comes out like this:
> Call:
> glm.nb(formula = CPUE ~ Trib_cat, data = coregonid4, init.theta =
> 0.1723775759,
>     link = log)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -0.9239  -0.8055  -0.6687  -0.6286   2.9020
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -0.7805     0.2497  -3.125  0.00178 **
> Trib_catNM   -0.2140     0.3485  -0.614  0.53921
> Trib_catSM    0.7393     0.3296   2.243  0.02488 *
> ---
>
> This gives me the difference in CPUE between the NM and SM tributaries
> compared to the MM tributary  (acting here as the reference group).  What I
> need is to compare all of the tributaries with all the others - so I need
> to run the model twice with a different reference group on the second run.
>   I can do this by changing the numbering of the Trib_cat field  in the
> underlying database (e.g. changing MM from 1 to 3, SM from 2 to 1, etc) and
> re-running the model, but I, as I have a number of species to do this for,
> I was wondering if there was an easier way to specify which group to use as
> the reference group when calling the model.
>
> Thanks for any help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Thu Feb 25 22:08:07 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 26 Feb 2016 10:08:07 +1300
Subject: [R] [FORGED]  Need help in installing packages in R
In-Reply-To: <CA+dSo4BbZ4At5Xorj8mjOzfMovggjoX__M8fPPJf0xCpH5kOaA@mail.gmail.com>
References: <CA+dSo4BbZ4At5Xorj8mjOzfMovggjoX__M8fPPJf0xCpH5kOaA@mail.gmail.com>
Message-ID: <56CF6D37.4070709@auckland.ac.nz>

On 26/02/16 05:11, Bhavani Akila wrote:
> Hi,
>
> I have just started learning about "R" programming language. I tried to
> connect it to SQL server using "RODBC". On trying to install packages in R
> with the command
> Eg., 'Install.Packages=="RODBC"', the zip file is not getting downloaded as
> am not able to access to the webpage since am working in a restricted
> environment.
>
> I have some how managed to get the zip file, but I have no idea how to
> install it into my system(Because on installing using "R Console", it
> itself is getting unpacked and getting installed in a specific location)
>
> Can I just install by unzipping and placing the file in some random
> location and connect R with SQL or is there any procedure to install the
> package?
>
> Kindly help me install "R Packages" without the use of "R Console"(With the
> use of zip file).
>
> Thanks in advance..!!! ??


Read the help for install.packages.  Essentially it says to

(a) set repos=NULL
(b) set pkgs equal to the file path to the source of the package that
     you wish to install

If, as is likely, you are using Windoze, then (I believe) there is a 
point-and-click facility for installing packages "from local zip files".

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From mashranga at yahoo.com  Thu Feb 25 22:15:04 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 25 Feb 2016 21:15:04 +0000 (UTC)
Subject: [R] Get object name inside lapply
References: <333399685.10399059.1456434904669.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <333399685.10399059.1456434904669.JavaMail.yahoo@mail.yahoo.com>

Hello,?
I want to get object name of a list inside lapply
> c<-list(a=seq(1:5),b=seq(10:20))> lapply(c,names)$aNULL
$bNULL
Why NULL ??
but i am expecting the names of object . Any help will be appreciated .?
I want to grab the names of object inside lapply for further process.?
Thanks .?

?Tanvir Ahamed 
   G?teborg, Sweden     |  mashranga at yahoo.com
	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Feb 25 22:19:40 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Feb 2016 15:19:40 -0600
Subject: [R] Specify order of groups negative binomial (glm.nb)
In-Reply-To: <CAGxFJbQnvv7WYLP7d+g6kmUi+ciFQa+mCP9PdnEyJLMG_x3deg@mail.gmail.com>
References: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
	<CAGxFJbQnvv7WYLP7d+g6kmUi+ciFQa+mCP9PdnEyJLMG_x3deg@mail.gmail.com>
Message-ID: <EFC269DC-A2EC-4520-88C0-2B366AE7DCDF@me.com>

Hi,

Well...as I understand the question:

If Katharine wants to use treatment contrasts, which are the default, the easiest thing to do may be use to ?relevel to specify the reference level for the IV factor.

However, as Bert notes, there are other contrasts that can be used, which would affect the interpretation of the comparisons of the factor levels and the help pages that he references would cover a high level review of the options, with more detail provided in the reference therein.

Also, if there is an excess of zeroes, you may need to consider the use of a zero inflated model and the 'pscl' package on CRAN is worthy of consideration, along with its vignette on count regression models:

https://cran.r-project.org/web/packages/pscl/
https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf

The ?vuong test in that package can also be helpful for comparing zero-inflated models with non zero-inflated models.

Regards,

Marc Schwartz


> On Feb 25, 2016, at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> You can re-set the contrasts for the factor, though whether this is
> "easier" is a matter of personal preference.
> 
> See ?C or ?contrasts, which I understand to be alternative ways of
> doing the same thing (and would appreciate correction is this is
> wrong). Or this can be done through the "contrasts" argument of
> glm.nb.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Feb 25, 2016 at 10:53 AM, Katharine Miller - NOAA Federal
> <katharine.miller at noaa.gov> wrote:
>> Hi,
>> I am using the glm.nb function to evaluate differences in the catch of
>> individual species of fish across three river tributaries.  The dependent
>> variable is catch per unit effort (CPUE), and the independent variable is
>> the the tributary (Trib_cat).  CPUE is derived from the fish counts divided
>> by the effort, so the response is not a count per se, but I think the
>> negative binomial is appropriate because of the large numbers of zeros in
>> the dependent variable. Trib_cat is a column with 1, 2, or 3 depending on
>> which tributary it is representing.
>> 
>> I have the following code:
>> 
>> dataS<-read.table("OtherSpecies.txt", sep="", header=T)
>> 
>> dataS <- within(dataS, {
>>  Trib_cat <- factor(Trib_cat, levels = 1:3, labels = c("MM", "NM", "SM"))
>>  Year<-factor(Year)
>> })
>> 
>> ## separate out the species of interest
>> coregonid<-subset(dataS, Spec_age=="Coregonid")
>> 
>> fit.CT<-glm.nb(CPUE ~ Trib_cat, data=coregonid, link = log)
>> summary(fit.CT)
>> 
>> The result comes out like this:
>> Call:
>> glm.nb(formula = CPUE ~ Trib_cat, data = coregonid4, init.theta =
>> 0.1723775759,
>>    link = log)
>> 
>> Deviance Residuals:
>>    Min       1Q   Median       3Q      Max
>> -0.9239  -0.8055  -0.6687  -0.6286   2.9020
>> 
>> Coefficients:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)  -0.7805     0.2497  -3.125  0.00178 **
>> Trib_catNM   -0.2140     0.3485  -0.614  0.53921
>> Trib_catSM    0.7393     0.3296   2.243  0.02488 *
>> ---
>> 
>> This gives me the difference in CPUE between the NM and SM tributaries
>> compared to the MM tributary  (acting here as the reference group).  What I
>> need is to compare all of the tributaries with all the others - so I need
>> to run the model twice with a different reference group on the second run.
>>  I can do this by changing the numbering of the Trib_cat field  in the
>> underlying database (e.g. changing MM from 1 to 3, SM from 2 to 1, etc) and
>> re-running the model, but I, as I have a number of species to do this for,
>> I was wondering if there was an easier way to specify which group to use as
>> the reference group when calling the model.
>> 
>> Thanks for any help.


From fransiepansiekevertje at gmail.com  Thu Feb 25 22:22:13 2016
From: fransiepansiekevertje at gmail.com (Frans Marcelissen)
Date: Thu, 25 Feb 2016 22:22:13 +0100
Subject: [R] Need help in installing packages in R
In-Reply-To: <CA+dSo4BbZ4At5Xorj8mjOzfMovggjoX__M8fPPJf0xCpH5kOaA@mail.gmail.com>
References: <CA+dSo4BbZ4At5Xorj8mjOzfMovggjoX__M8fPPJf0xCpH5kOaA@mail.gmail.com>
Message-ID: <CAFFQM6ac6Hf9HFmUvB9UZmTfV-k-10MgbPGmL9ZOyN3=yLQ1oA@mail.gmail.com>

Three remarks:
1. 'Install.Packages=="RODBC"' does nothing. Where did you find that? The
command is
install.packages("RODBC")
2. Sometimes it is a good idea to start reading a manual.
3. Please do not post in html

Frans

2016-02-25 17:11 GMT+01:00 Bhavani Akila <bhava20april at gmail.com>:

> Hi,
>
> I have just started learning about "R" programming language. I tried to
> connect it to SQL server using "RODBC". On trying to install packages in R
> with the command
> Eg., 'Install.Packages=="RODBC"', the zip file is not getting downloaded as
> am not able to access to the webpage since am working in a restricted
> environment.
>
> I have some how managed to get the zip file, but I have no idea how to
> install it into my system(Because on installing using "R Console", it
> itself is getting unpacked and getting installed in a specific location)
>
> Can I just install by unzipping and placing the file in some random
> location and connect R with SQL or is there any procedure to install the
> package?
>
> Kindly help me install "R Packages" without the use of "R Console"(With the
> use of zip file).
>
> Thanks in advance..!!! ??
> --
>
> Bhavani.P
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Thu Feb 25 22:27:31 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Thu, 25 Feb 2016 21:27:31 +0000 (UTC)
Subject: [R] Get object name inside lapply
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>

Hello, 

I want to get object name of a list inside lapply 

> c<-list(a=seq(1:5),b=seq(10:20)) 
> lapply(c,names) 
$a 
NULL 

$b 
NULL 

Why NULL ? 

but i am expecting the names of object . Any help will be appreciated . 

I want to grab the names of object inside lapply for further process. 

Thanks . 

 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com


From sarah.goslee at gmail.com  Thu Feb 25 22:45:11 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 25 Feb 2016 16:45:11 -0500
Subject: [R] Get object name inside lapply
In-Reply-To: <333399685.10399059.1456434904669.JavaMail.yahoo@mail.yahoo.com>
References: <333399685.10399059.1456434904669.JavaMail.yahoo.ref@mail.yahoo.com>
	<333399685.10399059.1456434904669.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM_vjun38Yrk3gAUBz9ELY+ZUArG75gTwTCM_KkObj7wkG6fOA@mail.gmail.com>

Posting in HTML makes it much harder for people to figure out your code.

Maybe this will help:

> c<-list(a=seq(1:5),b=seq(10:20))

> c[[1]]
[1] 1 2 3 4 5
> c[[2]]
 [1]  1  2  3  4  5  6  7  8  9 10 11

> names(c[[1]])
NULL
> names(c[[2]])
NULL

On Thu, Feb 25, 2016 at 4:15 PM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Hello,
> I want to get object name of a list inside lapply
>> c<-list(a=seq(1:5),b=seq(10:20))> lapply(c,names)$aNULL
> $bNULL
> Why NULL ?
> but i am expecting the names of object . Any help will be appreciated .
> I want to grab the names of object inside lapply for further process.
> Thanks .
>
>  Tanvir Ahamed
>    G?teborg, Sweden     |  mashranga at yahoo.com
>         [[alternative HTML version deleted]]
>


From ligges at statistik.tu-dortmund.de  Thu Feb 25 23:25:43 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 25 Feb 2016 23:25:43 +0100
Subject: [R] Get object name inside lapply
In-Reply-To: <813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
	<813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56CF7F67.4020503@statistik.tu-dortmund.de>



On 25.02.2016 22:27, Mohammad Tanvir Ahamed via R-help wrote:
> Hello,
>
> I want to get object name of a list inside lapply
>
>> c<-list(a=seq(1:5),b=seq(10:20))
>> lapply(c,names)
> $a
> NULL
>
> $b
> NULL
>
> Why NULL ?

Why should it? seq(1:5) has no names, nor has seq(10:20).

Best,
Uwe Ligges





>
> but i am expecting the names of object . Any help will be appreciated .
>
> I want to grab the names of object inside lapply for further process.
>
> Thanks .
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From huzefa.khalil at umich.edu  Thu Feb 25 23:37:27 2016
From: huzefa.khalil at umich.edu (Huzefa Khalil)
Date: Thu, 25 Feb 2016 17:37:27 -0500
Subject: [R] Get object name inside lapply
In-Reply-To: <56CF7F67.4020503@statistik.tu-dortmund.de>
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
	<813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
	<56CF7F67.4020503@statistik.tu-dortmund.de>
Message-ID: <CADsG8gNAX3arJGX=_SzXJ+mn7d=Nv6_KjFXErwQRaSfzRKNUig@mail.gmail.com>

If you want the object names, you should use lapply over the names:

lapply(names(c), function(x) {c[[x]]})

On Thu, Feb 25, 2016 at 5:25 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 25.02.2016 22:27, Mohammad Tanvir Ahamed via R-help wrote:
>
>> Hello,
>>
>> I want to get object name of a list inside lapply
>>
>> c<-list(a=seq(1:5),b=seq(10:20))
>>> lapply(c,names)
>>>
>> $a
>> NULL
>>
>> $b
>> NULL
>>
>> Why NULL ?
>>
>
> Why should it? seq(1:5) has no names, nor has seq(10:20).
>
> Best,
> Uwe Ligges
>
>
>
>
>
>
>> but i am expecting the names of object . Any help will be appreciated .
>>
>> I want to grab the names of object inside lapply for further process.
>>
>> Thanks .
>>
>>
>> Tanvir Ahamed
>> G?teborg, Sweden  |  mashranga at yahoo.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Feb 26 00:12:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 25 Feb 2016 15:12:31 -0800
Subject: [R] Specify order of groups negative binomial (glm.nb)
In-Reply-To: <EFC269DC-A2EC-4520-88C0-2B366AE7DCDF@me.com>
References: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
	<CAGxFJbQnvv7WYLP7d+g6kmUi+ciFQa+mCP9PdnEyJLMG_x3deg@mail.gmail.com>
	<EFC269DC-A2EC-4520-88C0-2B366AE7DCDF@me.com>
Message-ID: <CAGxFJbSJ_w5KjEp7KtAxFCYbyXkq3ALMobZ4mhAv8sp57PN5Bg@mail.gmail.com>

Ah yes. Forgot about relevel().  That would  be simpler.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 25, 2016 at 1:19 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Hi,
>
> Well...as I understand the question:
>
> If Katharine wants to use treatment contrasts, which are the default, the easiest thing to do may be use to ?relevel to specify the reference level for the IV factor.
>
> However, as Bert notes, there are other contrasts that can be used, which would affect the interpretation of the comparisons of the factor levels and the help pages that he references would cover a high level review of the options, with more detail provided in the reference therein.
>
> Also, if there is an excess of zeroes, you may need to consider the use of a zero inflated model and the 'pscl' package on CRAN is worthy of consideration, along with its vignette on count regression models:
>
> https://cran.r-project.org/web/packages/pscl/
> https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf
>
> The ?vuong test in that package can also be helpful for comparing zero-inflated models with non zero-inflated models.
>
> Regards,
>
> Marc Schwartz
>
>
>> On Feb 25, 2016, at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> You can re-set the contrasts for the factor, though whether this is
>> "easier" is a matter of personal preference.
>>
>> See ?C or ?contrasts, which I understand to be alternative ways of
>> doing the same thing (and would appreciate correction is this is
>> wrong). Or this can be done through the "contrasts" argument of
>> glm.nb.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Feb 25, 2016 at 10:53 AM, Katharine Miller - NOAA Federal
>> <katharine.miller at noaa.gov> wrote:
>>> Hi,
>>> I am using the glm.nb function to evaluate differences in the catch of
>>> individual species of fish across three river tributaries.  The dependent
>>> variable is catch per unit effort (CPUE), and the independent variable is
>>> the the tributary (Trib_cat).  CPUE is derived from the fish counts divided
>>> by the effort, so the response is not a count per se, but I think the
>>> negative binomial is appropriate because of the large numbers of zeros in
>>> the dependent variable. Trib_cat is a column with 1, 2, or 3 depending on
>>> which tributary it is representing.
>>>
>>> I have the following code:
>>>
>>> dataS<-read.table("OtherSpecies.txt", sep="", header=T)
>>>
>>> dataS <- within(dataS, {
>>>  Trib_cat <- factor(Trib_cat, levels = 1:3, labels = c("MM", "NM", "SM"))
>>>  Year<-factor(Year)
>>> })
>>>
>>> ## separate out the species of interest
>>> coregonid<-subset(dataS, Spec_age=="Coregonid")
>>>
>>> fit.CT<-glm.nb(CPUE ~ Trib_cat, data=coregonid, link = log)
>>> summary(fit.CT)
>>>
>>> The result comes out like this:
>>> Call:
>>> glm.nb(formula = CPUE ~ Trib_cat, data = coregonid4, init.theta =
>>> 0.1723775759,
>>>    link = log)
>>>
>>> Deviance Residuals:
>>>    Min       1Q   Median       3Q      Max
>>> -0.9239  -0.8055  -0.6687  -0.6286   2.9020
>>>
>>> Coefficients:
>>>            Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)  -0.7805     0.2497  -3.125  0.00178 **
>>> Trib_catNM   -0.2140     0.3485  -0.614  0.53921
>>> Trib_catSM    0.7393     0.3296   2.243  0.02488 *
>>> ---
>>>
>>> This gives me the difference in CPUE between the NM and SM tributaries
>>> compared to the MM tributary  (acting here as the reference group).  What I
>>> need is to compare all of the tributaries with all the others - so I need
>>> to run the model twice with a different reference group on the second run.
>>>  I can do this by changing the numbering of the Trib_cat field  in the
>>> underlying database (e.g. changing MM from 1 to 3, SM from 2 to 1, etc) and
>>> re-running the model, but I, as I have a number of species to do this for,
>>> I was wondering if there was an easier way to specify which group to use as
>>> the reference group when calling the model.
>>>
>>> Thanks for any help.
>


From r.turner at auckland.ac.nz  Fri Feb 26 00:19:47 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 26 Feb 2016 12:19:47 +1300
Subject: [R] Get object name inside lapply
In-Reply-To: <CADsG8gNAX3arJGX=_SzXJ+mn7d=Nv6_KjFXErwQRaSfzRKNUig@mail.gmail.com>
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
	<813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
	<56CF7F67.4020503@statistik.tu-dortmund.de>
	<CADsG8gNAX3arJGX=_SzXJ+mn7d=Nv6_KjFXErwQRaSfzRKNUig@mail.gmail.com>
Message-ID: <56CF8C13.2040407@auckland.ac.nz>

On 26/02/16 11:37, Huzefa Khalil wrote:
> If you want the object names, you should use lapply over the names:
>
> lapply(names(c), function(x) {c[[x]]})

This makes no sense at all to me; you get the same result simply by 
typing "c".

If the OP's message is interpreted literally, all he needs to do is type 
"names(c)".  But this may not be what he *really* wants.  It's hard to tell.

Note that "c" is *not* a good name for a data set, since it is the name 
of an (important) base function.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From alnazer.elbedairy at gmail.com  Fri Feb 26 00:35:14 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Thu, 25 Feb 2016 15:35:14 -0800
Subject: [R] PDF form Rstudio
Message-ID: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>

Dear All
I did the following steps to get a PDF file from Rstudio
1- activate Rmarkdown
2- save file as (name.Rmd)
3- use chunk for each step
4- go to Knit - PDF to save a file as PDF but I got an error
any help please

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Fri Feb 26 00:58:01 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 25 Feb 2016 17:58:01 -0600
Subject: [R] PDF form Rstudio
In-Reply-To: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
Message-ID: <CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>

What's the error?  You have to show it and the Rmd too, please.



On Thu, Feb 25, 2016 at 5:35 PM, Alnazer Elbedairy <
alnazer.elbedairy at gmail.com> wrote:

> Dear All
> I did the following steps to get a PDF file from Rstudio
> 1- activate Rmarkdown
> 2- save file as (name.Rmd)
> 3- use chunk for each step
> 4- go to Knit - PDF to save a file as PDF but I got an error
> any help please
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From aajains at gmail.com  Thu Feb 25 22:54:24 2016
From: aajains at gmail.com (Aashish Jain)
Date: Thu, 25 Feb 2016 15:54:24 -0600
Subject: [R] Get object name inside lapply
In-Reply-To: <813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
	<813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACE+iTeSQrDyOUOsW3zu=EA-Xt0+VE_AmVo+QGEEBRO7USWAoA@mail.gmail.com>

Why don't you simply use names(c) to get the names of all objects? If, for
your purposes, you still want the "names" function inside lapply, you can
use the following:
unlist(lapply(1:length(c), function(x) names(c[x])))
This will produce exactly same output as names(c) would. When you use
lapply(c, names) then it basically does this: names(c[[1]]) for first
member of the list, and that results to NULL. However, names(c[1]) gives
you "a".

Hope that helps.

On Thu, Feb 25, 2016 at 3:27 PM, Mohammad Tanvir Ahamed via R-help <
r-help at r-project.org> wrote:

> Hello,
>
> I want to get object name of a list inside lapply
>
> > c<-list(a=seq(1:5),b=seq(10:20))
> > lapply(c,names)
> $a
> NULL
>
> $b
> NULL
>
> Why NULL ?
>
> but i am expecting the names of object . Any help will be appreciated .
>
> I want to grab the names of object inside lapply for further process.
>
> Thanks .
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ben.bighair at gmail.com  Thu Feb 25 22:43:05 2016
From: ben.bighair at gmail.com (Ben Tupper)
Date: Thu, 25 Feb 2016 16:43:05 -0500
Subject: [R] Get object name inside lapply
In-Reply-To: <813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
	<813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D2B0D31C-CD64-4D7B-86A2-6E05A643CE36@gmail.com>

Hi,

Using your example (note I called the list 'z')...

z <-list(a = seq(1:5), b = seq(10:20))

I picture lapply as extracting each element of z like this z[[i]] - the `[[` extracts the ith value from the context of residing in a list - hence it's name is 'lost' in the new context.  That's different than z[i] which extracts a list of elements.  Try..

z[['a']]  vs. z['a']

As an alternative and depending upon what you really want to do, you could iterate through the names of the list, and pass the list as a parameter.  

r <- lapply(names(z),
    function(nm, dat = NULL){
        sprintf("%s has %i elements", nm, length(dat[[nm]]) )
    },
    dat = z)
r
[[1]]
[1] "a has 5 elements"

[[2]]
[1] "b has 11 elements"

Ben

> On Feb 25, 2016, at 4:27 PM, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
> 
> Hello, 
> 
> I want to get object name of a list inside lapply 
> 
>> c<-list(a=seq(1:5),b=seq(10:20)) 
>> lapply(c,names) 
> $a 
> NULL 
> 
> $b 
> NULL 
> 
> Why NULL ? 
> 
> but i am expecting the names of object . Any help will be appreciated . 
> 
> I want to grab the names of object inside lapply for further process. 
> 
> Thanks . 
> 
> 
> Tanvir Ahamed 
> G?teborg, Sweden  |  mashranga at yahoo.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From katharine.miller at noaa.gov  Fri Feb 26 02:44:31 2016
From: katharine.miller at noaa.gov (Katharine Miller - NOAA Federal)
Date: Thu, 25 Feb 2016 16:44:31 -0900
Subject: [R] Specify order of groups negative binomial (glm.nb)
In-Reply-To: <CAGxFJbSJ_w5KjEp7KtAxFCYbyXkq3ALMobZ4mhAv8sp57PN5Bg@mail.gmail.com>
References: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
	<CAGxFJbQnvv7WYLP7d+g6kmUi+ciFQa+mCP9PdnEyJLMG_x3deg@mail.gmail.com>
	<EFC269DC-A2EC-4520-88C0-2B366AE7DCDF@me.com>
	<CAGxFJbSJ_w5KjEp7KtAxFCYbyXkq3ALMobZ4mhAv8sp57PN5Bg@mail.gmail.com>
Message-ID: <CACnUi68T0yrjGqwfVzOP1hiYNu=9VJZmJ0wBjiK5jfOt=YPjng@mail.gmail.com>

Yes.  relevel looks good!  I will give that a try.

Thanks!

Katharine B. Miller, PhD
Research Fisheries Biologist
NMFS, Alaska Fisheries Science Center
17109 Lena Loop Rd
Juneau, AK 99801
(907) 789-6410
(907) 789-6094 (fax)




On Thu, Feb 25, 2016 at 2:12 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Ah yes. Forgot about relevel().  That would  be simpler.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Feb 25, 2016 at 1:19 PM, Marc Schwartz <marc_schwartz at me.com>
> wrote:
> > Hi,
> >
> > Well...as I understand the question:
> >
> > If Katharine wants to use treatment contrasts, which are the default,
> the easiest thing to do may be use to ?relevel to specify the reference
> level for the IV factor.
> >
> > However, as Bert notes, there are other contrasts that can be used,
> which would affect the interpretation of the comparisons of the factor
> levels and the help pages that he references would cover a high level
> review of the options, with more detail provided in the reference therein.
> >
> > Also, if there is an excess of zeroes, you may need to consider the use
> of a zero inflated model and the 'pscl' package on CRAN is worthy of
> consideration, along with its vignette on count regression models:
> >
> > https://cran.r-project.org/web/packages/pscl/
> > https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf
> >
> > The ?vuong test in that package can also be helpful for comparing
> zero-inflated models with non zero-inflated models.
> >
> > Regards,
> >
> > Marc Schwartz
> >
> >
> >> On Feb 25, 2016, at 2:48 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> You can re-set the contrasts for the factor, though whether this is
> >> "easier" is a matter of personal preference.
> >>
> >> See ?C or ?contrasts, which I understand to be alternative ways of
> >> doing the same thing (and would appreciate correction is this is
> >> wrong). Or this can be done through the "contrasts" argument of
> >> glm.nb.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Thu, Feb 25, 2016 at 10:53 AM, Katharine Miller - NOAA Federal
> >> <katharine.miller at noaa.gov> wrote:
> >>> Hi,
> >>> I am using the glm.nb function to evaluate differences in the catch of
> >>> individual species of fish across three river tributaries.  The
> dependent
> >>> variable is catch per unit effort (CPUE), and the independent variable
> is
> >>> the the tributary (Trib_cat).  CPUE is derived from the fish counts
> divided
> >>> by the effort, so the response is not a count per se, but I think the
> >>> negative binomial is appropriate because of the large numbers of zeros
> in
> >>> the dependent variable. Trib_cat is a column with 1, 2, or 3 depending
> on
> >>> which tributary it is representing.
> >>>
> >>> I have the following code:
> >>>
> >>> dataS<-read.table("OtherSpecies.txt", sep="", header=T)
> >>>
> >>> dataS <- within(dataS, {
> >>>  Trib_cat <- factor(Trib_cat, levels = 1:3, labels = c("MM", "NM",
> "SM"))
> >>>  Year<-factor(Year)
> >>> })
> >>>
> >>> ## separate out the species of interest
> >>> coregonid<-subset(dataS, Spec_age=="Coregonid")
> >>>
> >>> fit.CT<-glm.nb(CPUE ~ Trib_cat, data=coregonid, link = log)
> >>> summary(fit.CT)
> >>>
> >>> The result comes out like this:
> >>> Call:
> >>> glm.nb(formula = CPUE ~ Trib_cat, data = coregonid4, init.theta =
> >>> 0.1723775759,
> >>>    link = log)
> >>>
> >>> Deviance Residuals:
> >>>    Min       1Q   Median       3Q      Max
> >>> -0.9239  -0.8055  -0.6687  -0.6286   2.9020
> >>>
> >>> Coefficients:
> >>>            Estimate Std. Error z value Pr(>|z|)
> >>> (Intercept)  -0.7805     0.2497  -3.125  0.00178 **
> >>> Trib_catNM   -0.2140     0.3485  -0.614  0.53921
> >>> Trib_catSM    0.7393     0.3296   2.243  0.02488 *
> >>> ---
> >>>
> >>> This gives me the difference in CPUE between the NM and SM tributaries
> >>> compared to the MM tributary  (acting here as the reference group).
> What I
> >>> need is to compare all of the tributaries with all the others - so I
> need
> >>> to run the model twice with a different reference group on the second
> run.
> >>>  I can do this by changing the numbering of the Trib_cat field  in the
> >>> underlying database (e.g. changing MM from 1 to 3, SM from 2 to 1,
> etc) and
> >>> re-running the model, but I, as I have a number of species to do this
> for,
> >>> I was wondering if there was an easier way to specify which group to
> use as
> >>> the reference group when calling the model.
> >>>
> >>> Thanks for any help.
> >
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Feb 26 03:24:05 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 26 Feb 2016 13:24:05 +1100
Subject: [R] Scaling x axis
In-Reply-To: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>
References: <CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw@mail.gmail.com>
Message-ID: <CA+8X3fUtCOKp5bowqvE-LyzwG7zUsy1v1xTvaUaL8nScK88hhg@mail.gmail.com>

Hi Fabio,
If you have more than a few dates on the X axis you may get
overlapping tick labels. As an example, take a plot of the winning
parties of by-elections held in Australia in the 21st century by the
dates of the elections:

be_dates<-as.Date(c("5/12/2015","19/09/2015","8/2/2014",
 "5/12/2009","6/9/2008","6/9/2008","28/6/2008","19/3/2005","19/10/2002",
 "14/7/2001","17/3/2001","12/8/2000"),"%d/%m/%Y")
be_parties<-factor(c("Lib","Lib","Lab","Lib","Ind","Lib","Nat",
 "Lab","Grn","Lib","Lab","Lab"))
par(mar=c(6,4,4,2))
plot(be_dates,be_parties,xaxt="n",yaxt="n",
 xlab="",ylab="Winning party",pch=as.numeric(be_parties))
require(plotrix)
staxlab(1,at=be_dates,labels=format(be_dates,"%d/%m/%Y"),nlines=4)
axis(2,at=1:5,labels=levels(be_parties))
mtext("By-election dates",side=1,line=4)

As you can see, most dates would overlap other dates using the standard axis.

Jim

On Thu, Feb 25, 2016 at 11:31 PM, Fabio Monteiro
<fabio.monteiro1992 at gmail.com> wrote:
> Hi
>
> i'm trying to plot my data in R and i can't manage to scale the x axis.
>
> My x axis are dates, months and years, and when I plot I only have the x
> axis like this (2002, 2004, 2006, 2008, 2010).
>
> I whant every date in the axis not only those years, i want to see every
> point with the respectively date in the axis.
>
> How can I do that?
>
> Kind regards
>
> F?bio monteiro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alnazer.elbedairy at gmail.com  Fri Feb 26 05:13:25 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Thu, 25 Feb 2016 20:13:25 -0800
Subject: [R] PDF form Rstudio
In-Reply-To: <CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
Message-ID: <CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>

these are errors I got

processing file: Lab3 at M.Rmd
  |....                                                             |   6%
  ordinary text without R code

  |........                                                         |  12%
label: unnamed-chunk-1
  |...........                                                      |  18%
  ordinary text without R code

  |...............                                                  |  24%
label: unnamed-chunk-2
  |...................                                              |  29%
  ordinary text without R code

  |.......................                                          |  35%
label: unnamed-chunk-3
  |...........................                                      |  41%
  ordinary text without R code

  |...............................                                  |  47%
label: unnamed-chunk-4

Quitting from lines 42-48 (Lab3 at M.Rmd)
Error in `$<-.data.frame`(`*tmp*`, "HorsePower", value = numeric(0)) :
  replacement has 0 rows, data has 398
Calls: <Anonymous> ... withVisible -> eval -> eval -> $<- -> $<-.data.frame
Execution halted

No TeX installation detected (TeX is required to create PDF output). You
should install a recommended TeX distribution for your platform:

  Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
  (NOTE: Be sure to download the Complete rather than Basic installation)

  Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
  (NOTE: Download with Safari rather than Chrome _strongly_ recommended)

  Linux: Use system package manager

On Thu, Feb 25, 2016 at 3:58 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> What's the error?  You have to show it and the Rmd too, please.
>
>
>
> On Thu, Feb 25, 2016 at 5:35 PM, Alnazer Elbedairy <
> alnazer.elbedairy at gmail.com> wrote:
>
>> Dear All
>> I did the following steps to get a PDF file from Rstudio
>> 1- activate Rmarkdown
>> 2- save file as (name.Rmd)
>> 3- use chunk for each step
>> 4- go to Knit - PDF to save a file as PDF but I got an error
>> any help please
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>

	[[alternative HTML version deleted]]


From Peter.Alspach at plantandfood.co.nz  Fri Feb 26 05:22:55 2016
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Fri, 26 Feb 2016 17:22:55 +1300
Subject: [R] PDF form Rstudio
In-Reply-To: <CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
	<CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>

So, do you have MikTeK installed (assuming you are using Windows)?

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alnazer Elbedairy
Sent: Friday, 26 February 2016 5:13 p.m.
To: Erin Hodgess <erinm.hodgess at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] PDF form Rstudio

these are errors I got

processing file: Lab3 at M.Rmd
  |....                                                             |   6%
  ordinary text without R code

  |........                                                         |  12%
label: unnamed-chunk-1
  |...........                                                      |  18%
  ordinary text without R code

  |...............                                                  |  24%
label: unnamed-chunk-2
  |...................                                              |  29%
  ordinary text without R code

  |.......................                                          |  35%
label: unnamed-chunk-3
  |...........................                                      |  41%
  ordinary text without R code

  |...............................                                  |  47%
label: unnamed-chunk-4

Quitting from lines 42-48 (Lab3 at M.Rmd)
Error in `$<-.data.frame`(`*tmp*`, "HorsePower", value = numeric(0)) :
  replacement has 0 rows, data has 398
Calls: <Anonymous> ... withVisible -> eval -> eval -> $<- -> $<-.data.frame Execution halted

No TeX installation detected (TeX is required to create PDF output). You should install a recommended TeX distribution for your platform:

  Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
  (NOTE: Be sure to download the Complete rather than Basic installation)

  Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
  (NOTE: Download with Safari rather than Chrome _strongly_ recommended)

  Linux: Use system package manager

On Thu, Feb 25, 2016 at 3:58 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> What's the error?  You have to show it and the Rmd too, please.
>
>
>
> On Thu, Feb 25, 2016 at 5:35 PM, Alnazer Elbedairy < 
> alnazer.elbedairy at gmail.com> wrote:
>
>> Dear All
>> I did the following steps to get a PDF file from Rstudio
>> 1- activate Rmarkdown
>> 2- save file as (name.Rmd)
>> 3- use chunk for each step
>> 4- go to Knit - PDF to save a file as PDF but I got an error any help 
>> please
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics University of Houston - 
> Downtown
> mailto: erinm.hodgess at gmail.com
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From ulrik.stervbo at gmail.com  Fri Feb 26 05:35:24 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 26 Feb 2016 04:35:24 +0000
Subject: [R] PDF form Rstudio
In-Reply-To: <E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
	<CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
	<E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>
Message-ID: <CAKVAULOoXeQLRqqW9bQ30e=j9=2R8entx2qwHsiOOtDjS85UUQ@mail.gmail.com>

This message tells you what is wrong and the solution:

No TeX installation detected (TeX is required to create PDF output). You
should install a recommended TeX distribution for your platform:

LaTeX is used to generate the pdfs, to you need to have installed on your
system. To avoid problems later, it is better to install the full TeX.

Hope this helps
Ulrik

On Fri, 26 Feb 2016 at 05:25 Peter Alspach <Peter.Alspach at plantandfood.co.nz>
wrote:

> So, do you have MikTeK installed (assuming you are using Windows)?
>
> Peter Alspach
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alnazer
> Elbedairy
> Sent: Friday, 26 February 2016 5:13 p.m.
> To: Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] PDF form Rstudio
>
> these are errors I got
>
> processing file: Lab3 at M.Rmd
>   |....                                                             |   6%
>   ordinary text without R code
>
>   |........                                                         |  12%
> label: unnamed-chunk-1
>   |...........                                                      |  18%
>   ordinary text without R code
>
>   |...............                                                  |  24%
> label: unnamed-chunk-2
>   |...................                                              |  29%
>   ordinary text without R code
>
>   |.......................                                          |  35%
> label: unnamed-chunk-3
>   |...........................                                      |  41%
>   ordinary text without R code
>
>   |...............................                                  |  47%
> label: unnamed-chunk-4
>
> Quitting from lines 42-48 (Lab3 at M.Rmd)
> Error in `$<-.data.frame`(`*tmp*`, "HorsePower", value = numeric(0)) :
>   replacement has 0 rows, data has 398
> Calls: <Anonymous> ... withVisible -> eval -> eval -> $<- ->
> $<-.data.frame Execution halted
>
> No TeX installation detected (TeX is required to create PDF output). You
> should install a recommended TeX distribution for your platform:
>
>   Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
>   (NOTE: Be sure to download the Complete rather than Basic installation)
>
>   Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
>   (NOTE: Download with Safari rather than Chrome _strongly_ recommended)
>
>   Linux: Use system package manager
>
> On Thu, Feb 25, 2016 at 3:58 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
> > What's the error?  You have to show it and the Rmd too, please.
> >
> >
> >
> > On Thu, Feb 25, 2016 at 5:35 PM, Alnazer Elbedairy <
> > alnazer.elbedairy at gmail.com> wrote:
> >
> >> Dear All
> >> I did the following steps to get a PDF file from Rstudio
> >> 1- activate Rmarkdown
> >> 2- save file as (name.Rmd)
> >> 3- use chunk for each step
> >> 4- go to Knit - PDF to save a file as PDF but I got an error any help
> >> please
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics University of Houston -
> > Downtown
> > mailto: erinm.hodgess at gmail.com
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be ...{{dropped:14}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Fri Feb 26 05:52:37 2016
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Fri, 26 Feb 2016 06:52:37 +0200
Subject: [R] PDF form Rstudio
In-Reply-To: <CAKVAULOoXeQLRqqW9bQ30e=j9=2R8entx2qwHsiOOtDjS85UUQ@mail.gmail.com>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
	<CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
	<E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>
	<CAKVAULOoXeQLRqqW9bQ30e=j9=2R8entx2qwHsiOOtDjS85UUQ@mail.gmail.com>
Message-ID: <CAGh51gT5=4ssegfeD991nxBVdmszYaAxA4RuH-6_=871_f4rng@mail.gmail.com>

Hi,

If you are using Rstudio, why not using sweave function! I think this can
fix your problem since you don't have miktex on your window machine.

Cheers.
On Feb 26, 2016 6:37 AM, "Ulrik Stervbo" <ulrik.stervbo at gmail.com> wrote:

> This message tells you what is wrong and the solution:
>
> No TeX installation detected (TeX is required to create PDF output). You
> should install a recommended TeX distribution for your platform:
>
> LaTeX is used to generate the pdfs, to you need to have installed on your
> system. To avoid problems later, it is better to install the full TeX.
>
> Hope this helps
> Ulrik
>
> On Fri, 26 Feb 2016 at 05:25 Peter Alspach <
> Peter.Alspach at plantandfood.co.nz>
> wrote:
>
> > So, do you have MikTeK installed (assuming you are using Windows)?
> >
> > Peter Alspach
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alnazer
> > Elbedairy
> > Sent: Friday, 26 February 2016 5:13 p.m.
> > To: Erin Hodgess <erinm.hodgess at gmail.com>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] PDF form Rstudio
> >
> > these are errors I got
> >
> > processing file: Lab3 at M.Rmd
> >   |....                                                             |
>  6%
> >   ordinary text without R code
> >
> >   |........                                                         |
> 12%
> > label: unnamed-chunk-1
> >   |...........                                                      |
> 18%
> >   ordinary text without R code
> >
> >   |...............                                                  |
> 24%
> > label: unnamed-chunk-2
> >   |...................                                              |
> 29%
> >   ordinary text without R code
> >
> >   |.......................                                          |
> 35%
> > label: unnamed-chunk-3
> >   |...........................                                      |
> 41%
> >   ordinary text without R code
> >
> >   |...............................                                  |
> 47%
> > label: unnamed-chunk-4
> >
> > Quitting from lines 42-48 (Lab3 at M.Rmd)
> > Error in `$<-.data.frame`(`*tmp*`, "HorsePower", value = numeric(0)) :
> >   replacement has 0 rows, data has 398
> > Calls: <Anonymous> ... withVisible -> eval -> eval -> $<- ->
> > $<-.data.frame Execution halted
> >
> > No TeX installation detected (TeX is required to create PDF output). You
> > should install a recommended TeX distribution for your platform:
> >
> >   Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
> >   (NOTE: Be sure to download the Complete rather than Basic installation)
> >
> >   Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
> >   (NOTE: Download with Safari rather than Chrome _strongly_ recommended)
> >
> >   Linux: Use system package manager
> >
> > On Thu, Feb 25, 2016 at 3:58 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> > wrote:
> >
> > > What's the error?  You have to show it and the Rmd too, please.
> > >
> > >
> > >
> > > On Thu, Feb 25, 2016 at 5:35 PM, Alnazer Elbedairy <
> > > alnazer.elbedairy at gmail.com> wrote:
> > >
> > >> Dear All
> > >> I did the following steps to get a PDF file from Rstudio
> > >> 1- activate Rmarkdown
> > >> 2- save file as (name.Rmd)
> > >> 3- use chunk for each step
> > >> 4- go to Knit - PDF to save a file as PDF but I got an error any help
> > >> please
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >
> > >
> > > --
> > > Erin Hodgess
> > > Associate Professor
> > > Department of Mathematical and Statistics University of Houston -
> > > Downtown
> > > mailto: erinm.hodgess at gmail.com
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > The contents of this e-mail are confidential and may be ...{{dropped:14}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Feb 26 06:54:18 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 26 Feb 2016 05:54:18 +0000
Subject: [R] PDF form Rstudio
In-Reply-To: <CAGh51gT5=4ssegfeD991nxBVdmszYaAxA4RuH-6_=871_f4rng@mail.gmail.com>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
	<CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
	<E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>
	<CAKVAULOoXeQLRqqW9bQ30e=j9=2R8entx2qwHsiOOtDjS85UUQ@mail.gmail.com>
	<CAGh51gT5=4ssegfeD991nxBVdmszYaAxA4RuH-6_=871_f4rng@mail.gmail.com>
Message-ID: <CAKVAULOs7haATDNRkN+Q0TsXvRPc38AKwo4Bu_-Kc7MC59S-EA@mail.gmail.com>

My understanding is that Sweave also depends on LaTeX to generate pdfs, so
I am not sure Sweave is the solution.

On Fri, 26 Feb 2016 at 05:52 Frederic Ntirenganya <ntfredo at gmail.com> wrote:

> Hi,
>
> If you are using Rstudio, why not using sweave function! I think this can
> fix your problem since you don't have miktex on your window machine.
>
> Cheers.
> On Feb 26, 2016 6:37 AM, "Ulrik Stervbo" <ulrik.stervbo at gmail.com> wrote:
>
>> This message tells you what is wrong and the solution:
>>
>> No TeX installation detected (TeX is required to create PDF output). You
>> should install a recommended TeX distribution for your platform:
>>
>> LaTeX is used to generate the pdfs, to you need to have installed on your
>> system. To avoid problems later, it is better to install the full TeX.
>>
>> Hope this helps
>> Ulrik
>>
>> On Fri, 26 Feb 2016 at 05:25 Peter Alspach <
>> Peter.Alspach at plantandfood.co.nz>
>> wrote:
>>
>> > So, do you have MikTeK installed (assuming you are using Windows)?
>> >
>> > Peter Alspach
>> >
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alnazer
>> > Elbedairy
>> > Sent: Friday, 26 February 2016 5:13 p.m.
>> > To: Erin Hodgess <erinm.hodgess at gmail.com>
>> > Cc: r-help mailing list <r-help at r-project.org>
>> > Subject: Re: [R] PDF form Rstudio
>> >
>> > these are errors I got
>> >
>> > processing file: Lab3 at M.Rmd
>> >   |....                                                             |
>>  6%
>> >   ordinary text without R code
>> >
>> >   |........                                                         |
>> 12%
>> > label: unnamed-chunk-1
>> >   |...........                                                      |
>> 18%
>> >   ordinary text without R code
>> >
>> >   |...............                                                  |
>> 24%
>> > label: unnamed-chunk-2
>> >   |...................                                              |
>> 29%
>> >   ordinary text without R code
>> >
>> >   |.......................                                          |
>> 35%
>> > label: unnamed-chunk-3
>> >   |...........................                                      |
>> 41%
>> >   ordinary text without R code
>> >
>> >   |...............................                                  |
>> 47%
>> > label: unnamed-chunk-4
>> >
>> > Quitting from lines 42-48 (Lab3 at M.Rmd)
>> > Error in `$<-.data.frame`(`*tmp*`, "HorsePower", value = numeric(0)) :
>> >   replacement has 0 rows, data has 398
>> > Calls: <Anonymous> ... withVisible -> eval -> eval -> $<- ->
>> > $<-.data.frame Execution halted
>> >
>> > No TeX installation detected (TeX is required to create PDF output). You
>> > should install a recommended TeX distribution for your platform:
>> >
>> >   Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
>> >   (NOTE: Be sure to download the Complete rather than Basic
>> installation)
>> >
>> >   Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
>> >   (NOTE: Download with Safari rather than Chrome _strongly_ recommended)
>> >
>> >   Linux: Use system package manager
>> >
>> > On Thu, Feb 25, 2016 at 3:58 PM, Erin Hodgess <erinm.hodgess at gmail.com>
>> > wrote:
>> >
>> > > What's the error?  You have to show it and the Rmd too, please.
>> > >
>> > >
>> > >
>> > > On Thu, Feb 25, 2016 at 5:35 PM, Alnazer Elbedairy <
>> > > alnazer.elbedairy at gmail.com> wrote:
>> > >
>> > >> Dear All
>> > >> I did the following steps to get a PDF file from Rstudio
>> > >> 1- activate Rmarkdown
>> > >> 2- save file as (name.Rmd)
>> > >> 3- use chunk for each step
>> > >> 4- go to Knit - PDF to save a file as PDF but I got an error any help
>> > >> please
>> > >>
>> > >>         [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >>
>> > >
>> > >
>> > >
>> > > --
>> > > Erin Hodgess
>> > > Associate Professor
>> > > Department of Mathematical and Statistics University of Houston -
>> > > Downtown
>> > > mailto: erinm.hodgess at gmail.com
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> > The contents of this e-mail are confidential and may be
>> ...{{dropped:14}}
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From thpe at simecol.de  Fri Feb 26 08:10:19 2016
From: thpe at simecol.de (Thomas Petzoldt)
Date: Fri, 26 Feb 2016 08:10:19 +0100
Subject: [R] PDF form Rstudio
In-Reply-To: <CAKVAULOs7haATDNRkN+Q0TsXvRPc38AKwo4Bu_-Kc7MC59S-EA@mail.gmail.com>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
	<CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
	<E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>
	<CAKVAULOoXeQLRqqW9bQ30e=j9=2R8entx2qwHsiOOtDjS85UUQ@mail.gmail.com>
	<CAGh51gT5=4ssegfeD991nxBVdmszYaAxA4RuH-6_=871_f4rng@mail.gmail.com>
	<CAKVAULOs7haATDNRkN+Q0TsXvRPc38AKwo4Bu_-Kc7MC59S-EA@mail.gmail.com>
Message-ID: <56CFFA5B.8080701@simecol.de>

Yes, you are right. Sweave depends on Latex too, so its no workaround in 
this case.

Hope it helps, thpe

Am 26.02.2016 um 06:54 schrieb Ulrik Stervbo:
> My understanding is that Sweave also depends on LaTeX to generate pdfs, so
> I am not sure Sweave is the solution.
>

Just follow the advice given in the error message:

>>>> No TeX installation detected (TeX is required to create PDF output). You
>>>> should install a recommended TeX distribution for your platform:
>>>>
>>>>    Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
>>>>    (NOTE: Be sure to download the Complete rather than Basic
>>> installation)
>>>>
>>>>    Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
>>>>    (NOTE: Download with Safari rather than Chrome _strongly_ recommended)
>>>>
>>>>    Linux: Use system package manager
>>>>


From jean-externe.maurice at edf.fr  Fri Feb 26 09:23:43 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Fri, 26 Feb 2016 08:23:43 +0000
Subject: [R] getDLLRegisteredRoutines
In-Reply-To: <56CF1CB6.60900@gmail.com>
References: <54049d91fe074d4db49497bc37c45c95@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CF1CB6.60900@gmail.com>
Message-ID: <9afd1467754c4396aaa91fb3bb725609@NOEINTPEXMU007.NEOPROD.EDF.FR>

I tried pedump : it's ok.

Now I am going to try to understand section 5.4 !

Thanks
Jean

-----Message d'origine-----
De?: murdoch.duncan at gmail.com [mailto:murdoch.duncan at gmail.com] 
Envoy??: jeudi 25 f?vrier 2016 16:25
??: MAURICE Jean - externe; r-help at r-project.org
Objet?: Re: [R] getDLLRegisteredRoutines

On 25/02/2016 9:42 AM, MAURICE Jean - externe wrote:
> Hi,
>
> I have built a DLL with some routines using Intel's FORTRAN. I can use the routines within a R script.
>
> I would like to have the list of all the routines in the DLL. I found getDLLRegisteredRoutines but it answers data frame with 0 column and 0 lines.
>
> What is wrong ?

You didn't register them.  See section 5.4 in Writing R Extensions for details on how to do that.

R doesn't have a function to list all exports from a DLL.  There are various external tools to do that.  "pedump.exe" and "nm.exe" are included in the Rtools  collection.  (I usually use pedump; I forget whether nm works on .dll files, or only .so files.)

Duncan Murdoch



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.


From jean-externe.maurice at edf.fr  Fri Feb 26 09:42:17 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Fri, 26 Feb 2016 08:42:17 +0000
Subject: [R] getDLLRegisteredRoutines
In-Reply-To: <56CF1CB6.60900@gmail.com>
References: <54049d91fe074d4db49497bc37c45c95@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<56CF1CB6.60900@gmail.com>
Message-ID: <5bcb7c53efc94d8cb05a15f66eacd2c9@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Murdoch,

I browsed (read) section 5.4. I have understood that 
  - using PACKAGE= will reduce execution time and it is not a great work (good results for simple work)
  - R Windows manage a little cache so if I call a routine in a DLL within an R loop, it will be 'fast'
  - if we have a problem with speed then we can spend some times to registered the routines, but it can be done later, after testing.

Am I correct (did I understood well ?)

Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From pdalgd at gmail.com  Fri Feb 26 11:00:54 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 26 Feb 2016 11:00:54 +0100
Subject: [R] Get object name inside lapply
In-Reply-To: <D2B0D31C-CD64-4D7B-86A2-6E05A643CE36@gmail.com>
References: <813312413.10306540.1456435651350.JavaMail.yahoo.ref@mail.yahoo.com>
	<813312413.10306540.1456435651350.JavaMail.yahoo@mail.yahoo.com>
	<D2B0D31C-CD64-4D7B-86A2-6E05A643CE36@gmail.com>
Message-ID: <2CBDCE0D-7320-4327-8FE1-0F1F6DCC3B8D@gmail.com>


On 25 Feb 2016, at 22:43 , Ben Tupper <ben.bighair at gmail.com> wrote:

> Hi,
> 
> Using your example (note I called the list 'z')...
> 
> z <-list(a = seq(1:5), b = seq(10:20))
> 
> I picture lapply as extracting each element of z like this z[[i]] - the `[[` extracts the ith value from the context of residing in a list - hence it's name is 'lost' in the new context.  That's different than z[i] which extracts a list of elements.  Try..
> 
> z[['a']]  vs. z['a']
> 

Exactly. lapply applies the function to each _element_ in turn, not to a list containing one element. To further understand why the names do not carry onto elements, contemplate things like 

z <- list(a=c(b=1))
names(z[[1]])


> As an alternative and depending upon what you really want to do, you could iterate through the names of the list, and pass the list as a parameter.  
> 
> r <- lapply(names(z),
>    function(nm, dat = NULL){
>        sprintf("%s has %i elements", nm, length(dat[[nm]]) )
>    },
>    dat = z)
> r
> [[1]]
> [1] "a has 5 elements"
> 
> [[2]]
> [1] "b has 11 elements"
> 


Or, 

> mapply(z,names(z), FUN=function(e,n) sprintf("%s has %i elements", n, length(e))) 
                  a                   b 
 "a has 5 elements" "b has 11 elements" 

and variation thereof.

-pd



> Ben
> 
>> On Feb 25, 2016, at 4:27 PM, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
>> 
>> Hello, 
>> 
>> I want to get object name of a list inside lapply 
>> 
>>> c<-list(a=seq(1:5),b=seq(10:20)) 
>>> lapply(c,names) 
>> $a 
>> NULL 
>> 
>> $b 
>> NULL 
>> 
>> Why NULL ? 
>> 
>> but i am expecting the names of object . Any help will be appreciated . 
>> 
>> I want to grab the names of object inside lapply for further process. 
>> 
>> Thanks . 
>> 
>> 
>> Tanvir Ahamed 
>> G?teborg, Sweden  |  mashranga at yahoo.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ferri.leberl at gmx.at  Fri Feb 26 11:06:55 2016
From: ferri.leberl at gmx.at (Ferri Leberl)
Date: Fri, 26 Feb 2016 11:06:55 +0100
Subject: [R] write.table: adapt end of line
Message-ID: <trinity-b7ab7834-b2cd-441b-81f7-f14a43c542e4-1456481215698@3capp-gmx-bs33>



Hi everyone!
?
I want to include a table into LaTeX. I have a fitting environment and don't want to deal with xtable, so only the core of the table should be exported with something like
?
write.table(liste,"empf.csv",sep="&",quote=FALSE,row.names=F)
?
What I need is a way to end every row with?\\\hline. If I simply enlarge the table by a column with this content, I will obviously end up with a & too much in every row.
?
Can anyone tell me a solution?
?
Thank you in advance!
?
Yours,
Ferri


From ligges at statistik.tu-dortmund.de  Fri Feb 26 11:15:24 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 26 Feb 2016 11:15:24 +0100
Subject: [R] write.table: adapt end of line
In-Reply-To: <trinity-b7ab7834-b2cd-441b-81f7-f14a43c542e4-1456481215698@3capp-gmx-bs33>
References: <trinity-b7ab7834-b2cd-441b-81f7-f14a43c542e4-1456481215698@3capp-gmx-bs33>
Message-ID: <56D025BC.9070606@statistik.tu-dortmund.de>

writeLines(paste(do.call(paste, c(liste, sep=" & ")), "\\\\\\hline"), 
con = "empf.csv")

Best,
Uwe Ligges



On 26.02.2016 11:06, Ferri Leberl wrote:
>
>
> Hi everyone!
>
> I want to include a table into LaTeX. I have a fitting environment and don't want to deal with xtable, so only the core of the table should be exported with something like
>
> write.table(liste,"empf.csv",sep="&",quote=FALSE,row.names=F)
>
> What I need is a way to end every row with \\\hline. If I simply enlarge the table by a column with this content, I will obviously end up with a & too much in every row.
>
> Can anyone tell me a solution?
>
> Thank you in advance!
>
> Yours,
> Ferri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Fri Feb 26 12:24:38 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 26 Feb 2016 11:24:38 +0000
Subject: [R] write.table: adapt end of line
In-Reply-To: <56D025BC.9070606@statistik.tu-dortmund.de>
References: <trinity-b7ab7834-b2cd-441b-81f7-f14a43c542e4-1456481215698@3capp-gmx-bs33>
	<56D025BC.9070606@statistik.tu-dortmund.de>
Message-ID: <CAKVAULPxB-sv3czFcNR1tkdJqViApb0rfwg05Oodx5HSRiBZOw@mail.gmail.com>

You could also use kable from the Knitr package

Best,
Ulrik

On Fri, 26 Feb 2016 at 11:17 Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

> writeLines(paste(do.call(paste, c(liste, sep=" & ")), "\\\\\\hline"),
> con = "empf.csv")
>
> Best,
> Uwe Ligges
>
>
>
> On 26.02.2016 11:06, Ferri Leberl wrote:
> >
> >
> > Hi everyone!
> >
> > I want to include a table into LaTeX. I have a fitting environment and
> don't want to deal with xtable, so only the core of the table should be
> exported with something like
> >
> > write.table(liste,"empf.csv",sep="&",quote=FALSE,row.names=F)
> >
> > What I need is a way to end every row with \\\hline. If I simply enlarge
> the table by a column with this content, I will obviously end up with a &
> too much in every row.
> >
> > Can anyone tell me a solution?
> >
> > Thank you in advance!
> >
> > Yours,
> > Ferri
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gdraisma at xs4all.nl  Fri Feb 26 12:52:42 2016
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Fri, 26 Feb 2016 12:52:42 +0100
Subject: [R] Scaling x axis
Message-ID: <56D03C8A.3070905@xs4all.nl>

Ha Fabio,
With lattice' xyplot you can do
-----
library(lattice)
x<-as.Date(rnorm(10)*10,origin="2016-1-1")
y<-5+rnorm(10)
xyplot(y~x,type="h",scales=list(x=list(at=x,rot=90)))
-----

And yes, labels may overlap, even with rotation.

Gerrit.

> Message: 5
> Date: Thu, 25 Feb 2016 12:31:00 +0000
> From: Fabio Monteiro <fabio.monteiro1992 at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Scaling x axis
> Message-ID:
> 	<CAG0T74qTJR0W-swm56Uxf3uHiWnxk8LB=4DfrzTpXnU8T6yksw at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hi
>
> i'm trying to plot my data in R and i can't manage to scale the x axis.
>
> My x axis are dates, months and years, and when I plot I only have the x
> axis like this (2002, 2004, 2006, 2008, 2010).
>
> I whant every date in the axis not only those years, i want to see every
> point with the respectively date in the axis.
>
> How can I do that?
>
> Kind regards
>
> F?bio monteiro
>
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------


From tring at gvdnet.dk  Fri Feb 26 13:08:58 2016
From: tring at gvdnet.dk (Troels Ring)
Date: Fri, 26 Feb 2016 13:08:58 +0100
Subject: [R] formatting expressoion(paste with line shift
Message-ID: <56D0405A.1060103@gvdnet.dk>

Dear friends - I find it difficult to get formatting right when 
expressions are made on several lines. Sorry not to find the right 
documentation.
R version 3.2.1 Windows 7



(pHi <- seq(1,8))
#This gets formatted well but I want subscript for 2 in pCO2
  plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
main=paste("Theoretical experiment using SID = 0.13 M\n"," ATOT = 0.2 M, 
pKa = 6.8, and pCO[2] = 40"))

#but this gets a very unhelpful format

plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
main=expression(paste("Theoretical experiment using ", pCO[2], "= 40, 
SID = 0.13 M\n"," ATOT = 0.2 M, and pKa = 6.8",
  )))

All best wishes
Troels
Aalborg
Denmark


From murdoch.duncan at gmail.com  Fri Feb 26 13:37:24 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Feb 2016 07:37:24 -0500
Subject: [R] formatting expressoion(paste with line shift
In-Reply-To: <56D0405A.1060103@gvdnet.dk>
References: <56D0405A.1060103@gvdnet.dk>
Message-ID: <56D04704.6020705@gmail.com>

On 26/02/2016 7:08 AM, Troels Ring wrote:
> (pHi <- seq(1,8))
> #This gets formatted well but I want subscript for 2 in pCO2
>    plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
> main=paste("Theoretical experiment using SID = 0.13 M\n"," ATOT = 0.2 M,
> pKa = 6.8, and pCO[2] = 40"))
>
> #but this gets a very unhelpful format
>
> plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
> main=expression(paste("Theoretical experiment using ", pCO[2], "= 40,
> SID = 0.13 M\n"," ATOT = 0.2 M, and pKa = 6.8",
>    )))

As the docs say, control chars like \n are ignored in plotmath.  You can 
probably put something together using atop(), though the resizing will 
be problematic.  I'd suggest that you just use mtext() to write each of 
the three lines of output:

plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
main="")
mtext(expression(paste("Theoretical experiment using ", pCO[2], "= 
40")), 3, line = 3)
mtext("SID = 0.13 M", 3, line = 2)
mtext("ATOT = 0.2 M and pKa = 6.8", 3, line = 1)

You can move things around by changing the "line = " args, and add cex 
if you want bigger text, etc.

Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Feb 26 13:41:47 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Feb 2016 07:41:47 -0500
Subject: [R] distribution freq
In-Reply-To: <CAEW+BDL6d8SrYCSxrpiwjFi=C4vUY8ST6rXfVMe4aw8pOGvGVg@mail.gmail.com>
References: <CAEW+BD+P8fhiFoWWmB+XPz7aY6-6A6mi7UkauATpQYi8NEX99A@mail.gmail.com>
	<56CEE99B.6020108@gmail.com>
	<CAEW+BDL6d8SrYCSxrpiwjFi=C4vUY8ST6rXfVMe4aw8pOGvGVg@mail.gmail.com>
Message-ID: <56D0480B.409@gmail.com>

On 26/02/2016 4:09 AM, catalin roibu wrote:
> I'm working in forestry research and need the fitting distribution for
> forest structure in relation with diameter.
> The tree diameter have been lumped into 4 cm diameter classes, forming the
> diameter experimental distribution.
> For fitting I used the gamma distribution and I obtained the distribution
> parameters (scale and rate). After that I used the dgamma function and I
> have the pdf values. My question is how to obtain fitted absolute frequency
> to compare with the true frequency?

Since you're lumping into classes, you don't want the density, you want 
differences in the cumulative probability.  So if your class runs from 4 
to 8 cm, use something like

pgamma(8, shape, rate) - pgamma(4, shape, rate)

or the equivalent but a little obscure

diff(pgamma(c(8, 4), shape, rate))

Duncan Murdoch

P.S. Please keep discussion on the mailing list.  I've cc'd this 
response there.


From murdoch.duncan at gmail.com  Fri Feb 26 13:47:59 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Feb 2016 07:47:59 -0500
Subject: [R] formatting expressoion(paste with line shift
In-Reply-To: <56D04704.6020705@gmail.com>
References: <56D0405A.1060103@gvdnet.dk> <56D04704.6020705@gmail.com>
Message-ID: <56D0497F.1010803@gmail.com>

On 26/02/2016 7:37 AM, Duncan Murdoch wrote:
> On 26/02/2016 7:08 AM, Troels Ring wrote:
>> (pHi <- seq(1,8))
>> #This gets formatted well but I want subscript for 2 in pCO2
>>     plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
>> main=paste("Theoretical experiment using SID = 0.13 M\n"," ATOT = 0.2 M,
>> pKa = 6.8, and pCO[2] = 40"))
>>
>> #but this gets a very unhelpful format
>>
>> plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
>> main=expression(paste("Theoretical experiment using ", pCO[2], "= 40,
>> SID = 0.13 M\n"," ATOT = 0.2 M, and pKa = 6.8",
>>     )))
>
> As the docs say, control chars like \n are ignored in plotmath.  You can
> probably put something together using atop(), though the resizing will
> be problematic.  I'd suggest that you just use mtext() to write each of
> the three lines of output:
>
> plot(pHi,type="s",axes=FALSE,xlab="",lwd=4,
> main="")
> mtext(expression(paste("Theoretical experiment using ", pCO[2], "=
> 40")), 3, line = 3)
> mtext("SID = 0.13 M", 3, line = 2)
> mtext("ATOT = 0.2 M and pKa = 6.8", 3, line = 1)
>
> You can move things around by changing the "line = " args, and add cex
> if you want bigger text, etc.
>

One thing I forgot to add:  if you want to match the look to other 
plots, see ?title.  The default settings for the main title are 
par(c("font.main", "cex.main", "col.main")).

Duncan Murdoch


From friendly at yorku.ca  Fri Feb 26 14:31:39 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 26 Feb 2016 08:31:39 -0500
Subject: [R] Specify order of groups negative binomial (glm.nb)
In-Reply-To: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
References: <CACnUi6_e_nXPx9mLdmUAxsdby+UmsN6wLZnz=68O1pO+jaPjjw@mail.gmail.com>
Message-ID: <56D053BB.30701@yorku.ca>

On 2/25/2016 1:53 PM, Katharine Miller - NOAA Federal wrote:
>   The dependent
> variable is catch per unit effort (CPUE), and the independent variable is
> the the tributary (Trib_cat).  CPUE is derived from the fish counts divided
> by the effort, so the response is not a count per se, but I think the
> negative binomial is appropriate because of the large numbers of zeros in
> the dependent variable.

You probably shouldn't be dividing by effort -- better to use effort as 
an offset (but I'm not certain that glm.nb supports that)

For the excess zeros, consider using a zero-inflated NB or a hurdle NB
model from the pscl package or countreg package (only on R-Forge)

-Michael


From hodarahmati68 at yahoo.com  Fri Feb 26 15:01:04 2016
From: hodarahmati68 at yahoo.com (hoda rahmati)
Date: Fri, 26 Feb 2016 14:01:04 +0000 (UTC)
Subject: [R] Fw: adding a column to data frame solving the replacement
 problem
In-Reply-To: <547777755.10571385.1456494807758.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011129@SRVEXCHMBX.precheza.cz>
	<1195882623.95524.1456492665454.JavaMail.yahoo@mail.yahoo.com>
	<547777755.10571385.1456494807758.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1614673518.10558942.1456495264623.JavaMail.yahoo@mail.yahoo.com>





     On Friday, February 26, 2016 2:17 PM, hoda rahmati <hodarahmati68 at yahoo.com> wrote:
 

 Hi,Thank you for your answer and sorry that I forgot to add the command I used, the command is:mydata$NewColumn <-- mydata$Sequence[mydata$Sequence=="%Seq%tse"and then the Error that I got.what I want to do after adding the new column is to plot the other two variables I have in my data frame(mydata) according to the color, and the color I want is just for "%Seq%tse"?.do you have any idea?
Thanks Hoda 



       On Thursday, February 25, 2016 8:39 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 

 Hi

It seems to me that you misunderstand how objects (data.frames) in R work.

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hoda
> rahmati via R-help
> Sent: Wednesday, February 24, 2016 3:39 PM
> To: r-help at r-project.org
> Subject: [R] adding a column to data frame solving the replacement
> problem
>
> Hi all,
>
> I have a data set (mydata) containing 471 variables. One of the columns
> looks as below
>
> $ Sequence : Factor w/ 3 levels "","%Seq%gre",..: 2 2 2 2 2 2 2 2 2 2

There is also missing value in this column. I am not sure if it is intended, it is your decision. To get missing values as really missing when importing data you shall explicitly use na identifier in read command, something like.

mydata <- read.*(something, na.string="")

from help page:
na.strings
a character vector of strings which are to be interpreted as NA values. Blank fields are also considered to be missing values in logical, integer, numeric and complex fields.

> ...
>
> sequence contains %Seq%gre and %Seq%tse and I extract only %Seq%tse and
> add it to my variables and plot a scatterplot of mydata. I use table
> and the result is: table(mydata$Sequence)
>? %Seq%gre %Seq%tse
>? ? ? ? ? 1? ? ? ? ? 25520? ? ? ? ? 243744 in the next step I? want to
> add a column to my main data set (mydata) containing only %Seq%tse,
> however when I use the following command there's an error telling me:
> Error in `$<-.data.frame`(`*tmp*`, "NewColumn", value = c(3L, 3L, 3L,
>? :
>? replacement has 243744 rows, data has 269265 How can I add this
> column correctly to mydata? Thanks for any help

There is no command in your mail. However all columns in data frame has to have the same length, so when you add shorter vector it is recycled without error.

see
iris$aaa <- letters[1:5]
head(iris,10)

This simple command does not produce error.

I can get similar error

> iris[iris$aaa=="c", 1]<- iris[,2]

Error in `[<-.data.frame`(`*tmp*`, iris$aaa == "c", 1, value = c(3.5,? :
? replacement has 150 rows, data has 30

this results from operation in which I try add longer vector to shorter data frame.

To get more specific answer, you shall add exact command you used (maybe also a toy working example).


>? ? ? [[alternative HTML version deleted]]

And you shall post in plain text, not HTML.

Cheers
Petr

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


  
	[[alternative HTML version deleted]]


From catalinroibu at gmail.com  Fri Feb 26 16:08:58 2016
From: catalinroibu at gmail.com (catalin roibu)
Date: Fri, 26 Feb 2016 17:08:58 +0200
Subject: [R] distribution freq
In-Reply-To: <56D0480B.409@gmail.com>
References: <CAEW+BD+P8fhiFoWWmB+XPz7aY6-6A6mi7UkauATpQYi8NEX99A@mail.gmail.com>
	<56CEE99B.6020108@gmail.com>
	<CAEW+BDL6d8SrYCSxrpiwjFi=C4vUY8ST6rXfVMe4aw8pOGvGVg@mail.gmail.com>
	<56D0480B.409@gmail.com>
Message-ID: <CAEW+BDJTJq3QYj_0sk2KXCkxNrqEJhx=eHdQAmjr+SBgGWf=Rg@mail.gmail.com>

Thank you very much for your response.

But the problem still remained. I obtained my distribution parameters for
all diameter data (without lump).I sow that you create the fitted freq
using a difference from the neighborhood classes  (8-4), but I have a huge
interval from 96 fo 4. If I put diff(pgamma(c(96,8), shape, rate)) I
obtaining the same values for all classes.

Thank you very much for your help!

Best regards!


On 26 February 2016 at 14:41, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 26/02/2016 4:09 AM, catalin roibu wrote:
>
>> I'm working in forestry research and need the fitting distribution for
>> forest structure in relation with diameter.
>> The tree diameter have been lumped into 4 cm diameter classes, forming the
>> diameter experimental distribution.
>> For fitting I used the gamma distribution and I obtained the distribution
>> parameters (scale and rate). After that I used the dgamma function and I
>> have the pdf values. My question is how to obtain fitted absolute
>> frequency
>> to compare with the true frequency?
>>
>
> Since you're lumping into classes, you don't want the density, you want
> differences in the cumulative probability.  So if your class runs from 4 to
> 8 cm, use something like
>
> pgamma(8, shape, rate) - pgamma(4, shape, rate)
>
> or the equivalent but a little obscure
>
> diff(pgamma(c(8, 4), shape, rate))
>
> Duncan Murdoch
>
> P.S. Please keep discussion on the mailing list.  I've cc'd this response
> there.
>
>
>


-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb 26 16:11:53 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Feb 2016 10:11:53 -0500
Subject: [R] distribution freq
In-Reply-To: <CAEW+BDJTJq3QYj_0sk2KXCkxNrqEJhx=eHdQAmjr+SBgGWf=Rg@mail.gmail.com>
References: <CAEW+BD+P8fhiFoWWmB+XPz7aY6-6A6mi7UkauATpQYi8NEX99A@mail.gmail.com>
	<56CEE99B.6020108@gmail.com>
	<CAEW+BDL6d8SrYCSxrpiwjFi=C4vUY8ST6rXfVMe4aw8pOGvGVg@mail.gmail.com>
	<56D0480B.409@gmail.com>
	<CAEW+BDJTJq3QYj_0sk2KXCkxNrqEJhx=eHdQAmjr+SBgGWf=Rg@mail.gmail.com>
Message-ID: <56D06B39.1000206@gmail.com>

On 26/02/2016 10:08 AM, catalin roibu wrote:
> Thank you very much for your response.
>
> But the problem still remained. I obtained my distribution parameters 
> for all diameter data (without lump).I sow that you create the fitted 
> freq using a difference from the neighborhood classes  (8-4), but I 
> have a huge interval from 96 fo 4. If I put diff(pgamma(c(96,8), 
> shape, rate)) I obtaining the same values for all classes.

Please post some sample data and the calculations you're trying to do.  
(And please try to post in plain text; code tends to be unreadable if 
posted in HTML.)

Duncan Murdoch


From lars52r at gmail.com  Fri Feb 26 17:32:45 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Fri, 26 Feb 2016 11:32:45 -0500
Subject: [R] Annoying startup error message
Message-ID: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>

Hello,

Just installed R version 3.2.3, and I'm getting the error message below
every time I start R. I had SparkR installed in the prior version. I
googled this problem, but didn;t find anything useful.

Any help would be very appreciated.

Error in library(SparkR) : there is no package called ?SparkR?
[R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]


Best,
Lars.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Feb 26 17:53:40 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 26 Feb 2016 16:53:40 +0000
Subject: [R] Annoying startup error message
In-Reply-To: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
Message-ID: <CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>

Hi Lars,

The error tells you that SparkR is not installed.

I believe you can install it like this:

library(devtools)
install_github("amplab-extras/SparkR-pkg", subdir="pkg")

I took it from https://github.com/amplab-extras/SparkR-pkg and I haven't
tried it myself.

Hope this helps,
Ulrik

On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:

> Hello,
>
> Just installed R version 3.2.3, and I'm getting the error message below
> every time I start R. I had SparkR installed in the prior version. I
> googled this problem, but didn;t find anything useful.
>
> Any help would be very appreciated.
>
> Error in library(SparkR) : there is no package called ?SparkR?
> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
>
>
> Best,
> Lars.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From lars52r at gmail.com  Fri Feb 26 18:01:38 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Fri, 26 Feb 2016 12:01:38 -0500
Subject: [R] Annoying startup error message
In-Reply-To: <CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
	<CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
Message-ID: <CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>

Thank you Ulrik. I actually don't want to install SparkR, just don't want
to have that error message when R starts. For some reason, R is trying to
load the package every time it starts...

Thanks
Lars.

On Fri, Feb 26, 2016 at 11:53 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Lars,
>
> The error tells you that SparkR is not installed.
>
> I believe you can install it like this:
>
> library(devtools)
> install_github("amplab-extras/SparkR-pkg", subdir="pkg")
>
> I took it from https://github.com/amplab-extras/SparkR-pkg and I haven't
> tried it myself.
>
> Hope this helps,
> Ulrik
>
> On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:
>
>> Hello,
>>
>> Just installed R version 3.2.3, and I'm getting the error message below
>> every time I start R. I had SparkR installed in the prior version. I
>> googled this problem, but didn;t find anything useful.
>>
>> Any help would be very appreciated.
>>
>> Error in library(SparkR) : there is no package called ?SparkR?
>> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
>>
>>
>> Best,
>> Lars.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From s.atasever at gmail.com  Fri Feb 26 10:53:04 2016
From: s.atasever at gmail.com (Sema Atasever)
Date: Fri, 26 Feb 2016 11:53:04 +0200
Subject: [R] Calculate negative log of the E-Values in R
Message-ID: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>

Dear Authorized Sir / Madam,

If you don't mind, I want to ask how can i calculate negative log of the
E-Values in R.

*For Example: *
What is the negative log of the 4e-108?

I would appreciate if you could advise me some methods.

Thanks in advance.

	[[alternative HTML version deleted]]


From krolinarias at gmail.com  Fri Feb 26 15:17:51 2016
From: krolinarias at gmail.com (=?UTF-8?Q?Carolina_Arias_Mu=C3=B1oz?=)
Date: Fri, 26 Feb 2016 15:17:51 +0100
Subject: [R] rgrass7 problem
Message-ID: <CAK1cO7edmHtc1p=aXrSXyZTUUpMGQFmg=ZeKi1FUciVEzgZLCw@mail.gmail.com>

Hello

I am trying to use "readRAST" in GRASS, but I am keep getting the same
error:

*Error: 'checkCRSArgs' is not an exported object from 'namespace:rgdal'*

Probably a problem of the rgdal library?

Thank you.

*___________________________________________________________________*

*Carolina Arias Mu?oz*
PhD Student

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Feb 26 18:07:45 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 26 Feb 2016 12:07:45 -0500
Subject: [R] Annoying startup error message
In-Reply-To: <CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
	<CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
	<CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>
Message-ID: <CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>

Perhaps you at one point added it to your .RProfile so the package is
loaded at startup. You can check by starting R from the command line
with
R --vanilla
which doesn't load any of the profile files.

https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html

Sarah

On Fri, Feb 26, 2016 at 12:01 PM, Lars Bishop <lars52r at gmail.com> wrote:
> Thank you Ulrik. I actually don't want to install SparkR, just don't want
> to have that error message when R starts. For some reason, R is trying to
> load the package every time it starts...
>
> Thanks
> Lars.
>
> On Fri, Feb 26, 2016 at 11:53 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
>> Hi Lars,
>>
>> The error tells you that SparkR is not installed.
>>
>> I believe you can install it like this:
>>
>> library(devtools)
>> install_github("amplab-extras/SparkR-pkg", subdir="pkg")
>>
>> I took it from https://github.com/amplab-extras/SparkR-pkg and I haven't
>> tried it myself.
>>
>> Hope this helps,
>> Ulrik
>>
>> On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:
>>
>>> Hello,
>>>
>>> Just installed R version 3.2.3, and I'm getting the error message below
>>> every time I start R. I had SparkR installed in the prior version. I
>>> googled this problem, but didn;t find anything useful.
>>>
>>> Any help would be very appreciated.
>>>
>>> Error in library(SparkR) : there is no package called ?SparkR?
>>> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
>>>
>>>
>>> Best,
>>> Lars.
>>>


From ligges at statistik.tu-dortmund.de  Fri Feb 26 18:14:38 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 26 Feb 2016 18:14:38 +0100
Subject: [R] Calculate negative log of the E-Values in R
In-Reply-To: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>
References: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>
Message-ID: <56D087FE.2010606@statistik.tu-dortmund.de>



On 26.02.2016 10:53, Sema Atasever wrote:
> Dear Authorized Sir / Madam,
>
> If you don't mind, I want to ask how can i calculate negative log of the
> E-Values in R.
>
> *For Example: *
> What is the negative log of the 4e-108?

what about

log(4e-108)

?

(although I wonder if this is numerical sensible at all...).

Or do you want to know that

4e-108 == 4*10^(-108)

?


Best,
Uwe Ligges


>
> I would appreciate if you could advise me some methods.
>
> Thanks in advance.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From francescobryanromano at gmail.com  Fri Feb 26 18:16:07 2016
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Fri, 26 Feb 2016 18:16:07 +0100
Subject: [R] Calculate negative log of the E-Values in R
In-Reply-To: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>
References: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>
Message-ID: <CABZN5+ErkNZozVVR1zUYvRFiuXUoaVJVV5htN2CTn9dRKAzAeA@mail.gmail.com>

Sema, E is just a computer way of saying 0. For the purpose of statistical
analysis, if you can't compute a calculation with E values (i.e. 0),
substitute all E values with a usable constant, say 50. I stumbled across a
few websites lately that did this.

Frank Romano Ph.D.

*Academia.edu*
https://sheffield.academia.edu/FrancescoRomano


On Fri, Feb 26, 2016 at 10:53 AM, Sema Atasever <s.atasever at gmail.com>
wrote:

> Dear Authorized Sir / Madam,
>
> If you don't mind, I want to ask how can i calculate negative log of the
> E-Values in R.
>
> *For Example: *
> What is the negative log of the 4e-108?
>
> I would appreciate if you could advise me some methods.
>
> Thanks in advance.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



--

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb 26 20:11:36 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Feb 2016 14:11:36 -0500
Subject: [R] Annoying startup error message
In-Reply-To: <CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
	<CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
	<CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>
	<CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>
Message-ID: <56D0A368.5000601@gmail.com>

On 26/02/2016 12:07 PM, Sarah Goslee wrote:
> Perhaps you at one point added it to your .RProfile so the package is
> loaded at startup. You can check by starting R from the command line
> with
> R --vanilla
> which doesn't load any of the profile files.
>
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html

Another possibility is that SparkR defines some S4 classes, and you have 
an object of that type in your workspace.  To read it might need SparkR 
installed.

The solution here is to run R --vanilla as above, or to delete the 
object from the workspace, or the whole workspace.

Duncan Murdoch

>
> Sarah
>
> On Fri, Feb 26, 2016 at 12:01 PM, Lars Bishop <lars52r at gmail.com> wrote:
> > Thank you Ulrik. I actually don't want to install SparkR, just don't want
> > to have that error message when R starts. For some reason, R is trying to
> > load the package every time it starts...
> >
> > Thanks
> > Lars.
> >
> > On Fri, Feb 26, 2016 at 11:53 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> > wrote:
> >
> >> Hi Lars,
> >>
> >> The error tells you that SparkR is not installed.
> >>
> >> I believe you can install it like this:
> >>
> >> library(devtools)
> >> install_github("amplab-extras/SparkR-pkg", subdir="pkg")
> >>
> >> I took it from https://github.com/amplab-extras/SparkR-pkg and I haven't
> >> tried it myself.
> >>
> >> Hope this helps,
> >> Ulrik
> >>
> >> On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:
> >>
> >>> Hello,
> >>>
> >>> Just installed R version 3.2.3, and I'm getting the error message below
> >>> every time I start R. I had SparkR installed in the prior version. I
> >>> googled this problem, but didn;t find anything useful.
> >>>
> >>> Any help would be very appreciated.
> >>>
> >>> Error in library(SparkR) : there is no package called ?SparkR?
> >>> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
> >>>
> >>>
> >>> Best,
> >>> Lars.
> >>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alnazer.elbedairy at gmail.com  Fri Feb 26 20:28:56 2016
From: alnazer.elbedairy at gmail.com (Alnazer Elbedairy)
Date: Fri, 26 Feb 2016 11:28:56 -0800
Subject: [R] PDF form Rstudio
In-Reply-To: <56CFFA5B.8080701@simecol.de>
References: <CAD2s_FQD0RrXvd_osgpN8wUyzGCasEuGxCEoO0Q16w++9pWMOA@mail.gmail.com>
	<CACxE24m0dsMEg0O8x+Gb0ZVYfBoyYitsTCe+wnLdy8EVtYE2BQ@mail.gmail.com>
	<CAD2s_FTSbA6xUngR89OWyO8xGwCfCj6OUS-+dXEs5Hh7OemScA@mail.gmail.com>
	<E41B375B7520DE4A8C60781AC60B75452C3766FFD0@AKLEXM01.PFR.CO.NZ>
	<CAKVAULOoXeQLRqqW9bQ30e=j9=2R8entx2qwHsiOOtDjS85UUQ@mail.gmail.com>
	<CAGh51gT5=4ssegfeD991nxBVdmszYaAxA4RuH-6_=871_f4rng@mail.gmail.com>
	<CAKVAULOs7haATDNRkN+Q0TsXvRPc38AKwo4Bu_-Kc7MC59S-EA@mail.gmail.com>
	<56CFFA5B.8080701@simecol.de>
Message-ID: <CAD2s_FTOKzrg_wJVP6m8VOVkQ7KN0icHsdCppBgBX0BYNGQH4g@mail.gmail.com>

installed, but you have to install TEXmaker too, it works now, thank you
guys

On Thu, Feb 25, 2016 at 11:10 PM, Thomas Petzoldt <thpe at simecol.de> wrote:

> Yes, you are right. Sweave depends on Latex too, so its no workaround in
> this case.
>
> Hope it helps, thpe
>
> Am 26.02.2016 um 06:54 schrieb Ulrik Stervbo:
>
>> My understanding is that Sweave also depends on LaTeX to generate pdfs, so
>> I am not sure Sweave is the solution.
>>
>>
> Just follow the advice given in the error message:
>
> No TeX installation detected (TeX is required to create PDF output). You
>>>>> should install a recommended TeX distribution for your platform:
>>>>>
>>>>>    Windows: MiKTeX (Complete) - http://miktex.org/2.9/setup
>>>>>    (NOTE: Be sure to download the Complete rather than Basic
>>>>>
>>>> installation)
>>>>
>>>>>
>>>>>    Mac OS X: TexLive 2013 (Full) - http://tug.org/mactex/
>>>>>    (NOTE: Download with Safari rather than Chrome _strongly_
>>>>> recommended)
>>>>>
>>>>>    Linux: Use system package manager
>>>>>
>>>>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Feb 26 20:48:10 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 26 Feb 2016 20:48:10 +0100
Subject: [R] Calculate negative log of the E-Values in R
In-Reply-To: <CABZN5+ErkNZozVVR1zUYvRFiuXUoaVJVV5htN2CTn9dRKAzAeA@mail.gmail.com>
References: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>
	<CABZN5+ErkNZozVVR1zUYvRFiuXUoaVJVV5htN2CTn9dRKAzAeA@mail.gmail.com>
Message-ID: <BB75D04B-DB2D-4369-8C64-3DF457E72158@gmail.com>

I do hope that was a joke!

-pd

> On 26 Feb 2016, at 18:16 , Francesco Romano <francescobryanromano at gmail.com> wrote:
> 
> Sema, E is just a computer way of saying 0. For the purpose of statistical
> analysis, if you can't compute a calculation with E values (i.e. 0),
> substitute all E values with a usable constant, say 50. I stumbled across a
> few websites lately that did this.
> 
> Frank Romano Ph.D.
> 
> *Academia.edu*
> https://sheffield.academia.edu/FrancescoRomano
> 
> 
> On Fri, Feb 26, 2016 at 10:53 AM, Sema Atasever <s.atasever at gmail.com>
> wrote:
> 
>> Dear Authorized Sir / Madam,
>> 
>> If you don't mind, I want to ask how can i calculate negative log of the
>> E-Values in R.
>> 
>> *For Example: *
>> What is the negative log of the 4e-108?
>> 
>> I would appreciate if you could advise me some methods.
>> 
>> Thanks in advance.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> --
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lars52r at gmail.com  Fri Feb 26 21:36:36 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Fri, 26 Feb 2016 15:36:36 -0500
Subject: [R] Annoying startup error message
In-Reply-To: <56D0A368.5000601@gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
	<CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
	<CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>
	<CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>
	<56D0A368.5000601@gmail.com>
Message-ID: <CAO7OmOi=hBBxfHS-4VtbA-VQTifT+h9vsoEhYv+WrcUBrQPhsA@mail.gmail.com>

I understand the solution would be to unset my "SPARK_HOME" environment
variable. I can do this with Sys.unsetenv() but it does not unset
permanently (only in the session). How can I unset permanently?

Sys.getenv("SPARK_HOME")
[1] "/Users/lars/Downloads/spark-1.6.0-bin-hadoop2.6/bin/spark"

Sys.unsetenv("SPARK_HOME")
Sys.getenv("SPARK_HOME")
[1] ""


Thanks again for you help!
Lars.

On Fri, Feb 26, 2016 at 2:11 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 26/02/2016 12:07 PM, Sarah Goslee wrote:
>
>> Perhaps you at one point added it to your .RProfile so the package is
>> loaded at startup. You can check by starting R from the command line
>> with
>> R --vanilla
>> which doesn't load any of the profile files.
>>
>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html
>>
>
> Another possibility is that SparkR defines some S4 classes, and you have
> an object of that type in your workspace.  To read it might need SparkR
> installed.
>
> The solution here is to run R --vanilla as above, or to delete the object
> from the workspace, or the whole workspace.
>
> Duncan Murdoch
>
>
>> Sarah
>>
>> On Fri, Feb 26, 2016 at 12:01 PM, Lars Bishop <lars52r at gmail.com> wrote:
>> > Thank you Ulrik. I actually don't want to install SparkR, just don't
>> want
>> > to have that error message when R starts. For some reason, R is trying
>> to
>> > load the package every time it starts...
>> >
>> > Thanks
>> > Lars.
>> >
>> > On Fri, Feb 26, 2016 at 11:53 AM, Ulrik Stervbo <
>> ulrik.stervbo at gmail.com>
>> > wrote:
>> >
>> >> Hi Lars,
>> >>
>> >> The error tells you that SparkR is not installed.
>> >>
>> >> I believe you can install it like this:
>> >>
>> >> library(devtools)
>> >> install_github("amplab-extras/SparkR-pkg", subdir="pkg")
>> >>
>> >> I took it from https://github.com/amplab-extras/SparkR-pkg and I
>> haven't
>> >> tried it myself.
>> >>
>> >> Hope this helps,
>> >> Ulrik
>> >>
>> >> On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> Just installed R version 3.2.3, and I'm getting the error message
>> below
>> >>> every time I start R. I had SparkR installed in the prior version. I
>> >>> googled this problem, but didn;t find anything useful.
>> >>>
>> >>> Any help would be very appreciated.
>> >>>
>> >>> Error in library(SparkR) : there is no package called ?SparkR?
>> >>> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
>> >>>
>> >>>
>> >>> Best,
>> >>> Lars.
>> >>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Fri Feb 26 21:48:33 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 26 Feb 2016 15:48:33 -0500
Subject: [R] Calculate negative log of the E-Values in R
In-Reply-To: <CABZN5+ErkNZozVVR1zUYvRFiuXUoaVJVV5htN2CTn9dRKAzAeA@mail.gmail.com>
References: <CAAir+Cr259hLxvManv1bj+Aj1HELXT+5ZbNggDn8T3AsmAnQJA@mail.gmail.com>
	<CABZN5+ErkNZozVVR1zUYvRFiuXUoaVJVV5htN2CTn9dRKAzAeA@mail.gmail.com>
Message-ID: <56D073DD020000CB0014B545@smtp.medicine.umaryland.edu>

Actually  E is not "just a computer way of saying 0". The E represents a power of 10, thus E-1 = 0.1 e-2=0.01; E therefore is not zero. Because computers generally can not perform exact calculations (for reasons including the fact that our number system is base 10 and a computer's is generally base 2) what might otherwise be a zero is often represented by a very small number such as the one you listed. 4E-108 would be 4x10^-108, a very small number indeed that is (for most but not all purposes) the same as zero.
John 

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Feb 26, 2016, at 12:29 PM, Francesco Romano <francescobryanromano at gmail.com> wrote:
> 
> Sema, E is just a computer way of saying 0. For the purpose of statistical
> analysis, if you can't compute a calculation with E values (i.e. 0),
> substitute all E values with a usable constant, say 50. I stumbled across a
> few websites lately that did this.
> 
> Frank Romano Ph.D.
> 
> *Academia.edu*
> https://sheffield.academia.edu/FrancescoRomano
> 
> 
> On Fri, Feb 26, 2016 at 10:53 AM, Sema Atasever <s.atasever at gmail.com>
> wrote:
> 
>> Dear Authorized Sir / Madam,
>> 
>> If you don't mind, I want to ask how can i calculate negative log of the
>> E-Values in R.
>> 
>> *For Example: *
>> What is the negative log of the 4e-108?
>> 
>> I would appreciate if you could advise me some methods.
>> 
>> Thanks in advance.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> --
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From murdoch.duncan at gmail.com  Fri Feb 26 23:53:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Feb 2016 17:53:06 -0500
Subject: [R] Annoying startup error message
In-Reply-To: <CAO7OmOi=hBBxfHS-4VtbA-VQTifT+h9vsoEhYv+WrcUBrQPhsA@mail.gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
	<CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
	<CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>
	<CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>
	<56D0A368.5000601@gmail.com>
	<CAO7OmOi=hBBxfHS-4VtbA-VQTifT+h9vsoEhYv+WrcUBrQPhsA@mail.gmail.com>
Message-ID: <56D0D752.8000508@gmail.com>

On 26/02/2016 3:36 PM, Lars Bishop wrote:
> I understand the solution would be to unset my "SPARK_HOME" environment
> variable. I can do this with Sys.unsetenv() but it does not unset
> permanently (only in the session). How can I unset permanently?
>
> Sys.getenv("SPARK_HOME")
> [1] "/Users/lars/Downloads/spark-1.6.0-bin-hadoop2.6/bin/spark"
>
> Sys.unsetenv("SPARK_HOME")
> Sys.getenv("SPARK_HOME")
> [1] ""
>

R doesn't look at that variable, so that would not be the cause.

Duncan Murdoch

>
> Thanks again for you help!
> Lars.
>
> On Fri, Feb 26, 2016 at 2:11 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 26/02/2016 12:07 PM, Sarah Goslee wrote:
>>
>>> Perhaps you at one point added it to your .RProfile so the package is
>>> loaded at startup. You can check by starting R from the command line
>>> with
>>> R --vanilla
>>> which doesn't load any of the profile files.
>>>
>>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html
>>>
>>
>> Another possibility is that SparkR defines some S4 classes, and you have
>> an object of that type in your workspace.  To read it might need SparkR
>> installed.
>>
>> The solution here is to run R --vanilla as above, or to delete the object
>> from the workspace, or the whole workspace.
>>
>> Duncan Murdoch
>>
>>
>>> Sarah
>>>
>>> On Fri, Feb 26, 2016 at 12:01 PM, Lars Bishop <lars52r at gmail.com> wrote:
>>>> Thank you Ulrik. I actually don't want to install SparkR, just don't
>>> want
>>>> to have that error message when R starts. For some reason, R is trying
>>> to
>>>> load the package every time it starts...
>>>>
>>>> Thanks
>>>> Lars.
>>>>
>>>> On Fri, Feb 26, 2016 at 11:53 AM, Ulrik Stervbo <
>>> ulrik.stervbo at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Lars,
>>>>>
>>>>> The error tells you that SparkR is not installed.
>>>>>
>>>>> I believe you can install it like this:
>>>>>
>>>>> library(devtools)
>>>>> install_github("amplab-extras/SparkR-pkg", subdir="pkg")
>>>>>
>>>>> I took it from https://github.com/amplab-extras/SparkR-pkg and I
>>> haven't
>>>>> tried it myself.
>>>>>
>>>>> Hope this helps,
>>>>> Ulrik
>>>>>
>>>>> On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Just installed R version 3.2.3, and I'm getting the error message
>>> below
>>>>>> every time I start R. I had SparkR installed in the prior version. I
>>>>>> googled this problem, but didn;t find anything useful.
>>>>>>
>>>>>> Any help would be very appreciated.
>>>>>>
>>>>>> Error in library(SparkR) : there is no package called ?SparkR?
>>>>>> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
>>>>>>
>>>>>>
>>>>>> Best,
>>>>>> Lars.
>>>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>


From lars52r at gmail.com  Fri Feb 26 18:47:21 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Fri, 26 Feb 2016 12:47:21 -0500
Subject: [R] Annoying startup error message
In-Reply-To: <CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>
References: <CAO7OmOjgy1xBB7_=40LRS21P8zKiz0NOxuym9mGO+UObVyTwDA@mail.gmail.com>
	<CAKVAULMB7D6wJFKPOSPkNfsKSOwg8DEbq3=Zx-v8LbgVLr0jGw@mail.gmail.com>
	<CAO7OmOjd__pyQgJX+EjvNvxJwasUArN=n_X98eoCT941CRNORA@mail.gmail.com>
	<CAM_vjun47hUjTqCPqj_K4fHuRPEmC+fvNjPFiH134LMjy86hhg@mail.gmail.com>
Message-ID: <CAO7OmOh23kFbgU4MNBqcktPpepQ=PfQHAmN1=yZk986eXsn7_w@mail.gmail.com>

yes! Thanks!

On Fri, Feb 26, 2016 at 12:07 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Perhaps you at one point added it to your .RProfile so the package is
> loaded at startup. You can check by starting R from the command line
> with
> R --vanilla
> which doesn't load any of the profile files.
>
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html
>
> Sarah
>
> On Fri, Feb 26, 2016 at 12:01 PM, Lars Bishop <lars52r at gmail.com> wrote:
> > Thank you Ulrik. I actually don't want to install SparkR, just don't want
> > to have that error message when R starts. For some reason, R is trying to
> > load the package every time it starts...
> >
> > Thanks
> > Lars.
> >
> > On Fri, Feb 26, 2016 at 11:53 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com
> >
> > wrote:
> >
> >> Hi Lars,
> >>
> >> The error tells you that SparkR is not installed.
> >>
> >> I believe you can install it like this:
> >>
> >> library(devtools)
> >> install_github("amplab-extras/SparkR-pkg", subdir="pkg")
> >>
> >> I took it from https://github.com/amplab-extras/SparkR-pkg and I
> haven't
> >> tried it myself.
> >>
> >> Hope this helps,
> >> Ulrik
> >>
> >> On Fri, 26 Feb 2016 at 17:40 Lars Bishop <lars52r at gmail.com> wrote:
> >>
> >>> Hello,
> >>>
> >>> Just installed R version 3.2.3, and I'm getting the error message below
> >>> every time I start R. I had SparkR installed in the prior version. I
> >>> googled this problem, but didn;t find anything useful.
> >>>
> >>> Any help would be very appreciated.
> >>>
> >>> Error in library(SparkR) : there is no package called ?SparkR?
> >>> [R.app GUI 1.66 (7060) x86_64-apple-darwin13.4.0]
> >>>
> >>>
> >>> Best,
> >>> Lars.
> >>>
>

	[[alternative HTML version deleted]]


From girit at comcast.net  Sat Feb 27 00:51:07 2016
From: girit at comcast.net (Cem Girit)
Date: Fri, 26 Feb 2016 18:51:07 -0500
Subject: [R] Error : package 'xxx' was built before R 3.0.0: please
	re-install it
Message-ID: <00a701d170f0$91915da0$b4b418e0$@comcast.net>

Hello,

 

Here are the steps to the error:

 

1.       Uninstall R version 2.x.y.

2.       Install the latest version (3.2.3) of R. 

3.       Copy all my libraries that were not in the new version into the new
R library.

4.       Run  "> update.packages(checkBuilt=TRUE, ask=FALSE)" under
R-Studio. 

 

                Many packages were updated but for some I received:

 

                "Error : package 'xxx' was built before R 3.0.0: please
re-install it" error. 

 

                Here is an example:

 

* installing *source* package 'agricolae' ...

* package 'agricolae' successfully unpacked and MD5 sums checked

** R

** data

** inst

** preparing package for lazy loading

Error : package 'spdep' was built before R 3.0.0: please re-install it

ERROR: lazy loading failed for package 'agricolae'

* removing 'C:/Program Files/R/R-3.2.3/library/agricolae'

Warning in install.packages :

  running command '"C:/PROGRA~1/R/R-32~1.3/bin/i386/R" CMD INSTALL -l
"C:\Program Files\R\R-3.2.3\library"
C:\Users\user\AppData\Local\Temp\RtmpG8mSYd/downloaded_packages/agricolae_1.
2-3.tar.gz' had status 1

Warning in install.packages :

  installation of package 'agricolae' had non-zero exit status

 

The downloaded source packages are in

 
'C:\Users\user\AppData\Local\Temp\RtmpG8mSYd\downloaded_packages'

 

                If I try to install "spdep" package first I get the
following error:

 

 

> install.packages("spdep")
also installing the dependency 'sp'
 
Packages which are only available in source form, and may need compilation
of C/C++/Fortran:
  'sp' 'spdep'
  These will not be installed

 

How can I fix such errors? I can  

 
                    Thank you.
 
Cem

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Feb 27 01:10:13 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 27 Feb 2016 01:10:13 +0100
Subject: [R] Error : package 'xxx' was built before R 3.0.0: please
 re-install it
In-Reply-To: <00a701d170f0$91915da0$b4b418e0$@comcast.net>
References: <00a701d170f0$91915da0$b4b418e0$@comcast.net>
Message-ID: <56D0E965.6060102@statistik.tu-dortmund.de>

Which mirror are you using?

spdep is availabe in binary form for Windows and R-3.2.3 and should be 
installed without the need for compilation.

Best,
Uwe Ligges



On 27.02.2016 00:51, Cem Girit wrote:
> Hello,
>
>
>
> Here are the steps to the error:
>
>
>
> 1.       Uninstall R version 2.x.y.
>
> 2.       Install the latest version (3.2.3) of R.
>
> 3.       Copy all my libraries that were not in the new version into the new
> R library.
>
> 4.       Run  "> update.packages(checkBuilt=TRUE, ask=FALSE)" under
> R-Studio.
>
>
>
>                  Many packages were updated but for some I received:
>
>
>
>                  "Error : package 'xxx' was built before R 3.0.0: please
> re-install it" error.
>
>
>
>                  Here is an example:
>
>
>
> * installing *source* package 'agricolae' ...
>
> * package 'agricolae' successfully unpacked and MD5 sums checked
>
> ** R
>
> ** data
>
> ** inst
>
> ** preparing package for lazy loading
>
> Error : package 'spdep' was built before R 3.0.0: please re-install it
>
> ERROR: lazy loading failed for package 'agricolae'
>
> * removing 'C:/Program Files/R/R-3.2.3/library/agricolae'
>
> Warning in install.packages :
>
>    running command '"C:/PROGRA~1/R/R-32~1.3/bin/i386/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.2.3\library"
> C:\Users\user\AppData\Local\Temp\RtmpG8mSYd/downloaded_packages/agricolae_1.
> 2-3.tar.gz' had status 1
>
> Warning in install.packages :
>
>    installation of package 'agricolae' had non-zero exit status
>
>
>
> The downloaded source packages are in
>
>
> 'C:\Users\user\AppData\Local\Temp\RtmpG8mSYd\downloaded_packages'
>
>
>
>                  If I try to install "spdep" package first I get the
> following error:
>
>
>
>
>
>> install.packages("spdep")
> also installing the dependency 'sp'
>
> Packages which are only available in source form, and may need compilation
> of C/C++/Fortran:
>    'sp' 'spdep'
>    These will not be installed
>
>
>
> How can I fix such errors? I can
>
>
>                      Thank you.
>
> Cem
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Feb 27 01:18:10 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Feb 2016 16:18:10 -0800
Subject: [R] Error : package 'xxx' was built before R 3.0.0: please
	re-install it
In-Reply-To: <00a701d170f0$91915da0$b4b418e0$@comcast.net>
References: <00a701d170f0$91915da0$b4b418e0$@comcast.net>
Message-ID: <0DFEDAA4-C13D-4C7B-B40A-55ECE7A38F15@comcast.net>


> On Feb 26, 2016, at 3:51 PM, Cem Girit <girit at comcast.net> wrote:
> 
> Hello,
> 
> 
> 
> Here are the steps to the error:
> 
> 
> 
> 1.       Uninstall R version 2.x.y.
> 
> 2.       Install the latest version (3.2.3) of R. 
> 
> 3.       Copy all my libraries that were not in the new version into the new
> R library.
> 
> 4.       Run  "> update.packages(checkBuilt=TRUE, ask=FALSE)" under
> R-Studio. 
> 
> 
> 
>                Many packages were updated but for some I received:
> 
> 
> 
>                "Error : package 'xxx' was built before R 3.0.0: please
> re-install it" error. 
> 
> 
> 
>                Here is an example:
> 
> 
> 
> * installing *source* package 'agricolae' ...
> 
> * package 'agricolae' successfully unpacked and MD5 sums checked
> 
> ** R
> 
> ** data
> 
> ** inst
> 
> ** preparing package for lazy loading
> 
> Error : package 'spdep' was built before R 3.0.0: please re-install it
> 
> ERROR: lazy loading failed for package 'agricolae'

You were trying to install pkg:agricolae before one of its dependencies was updated. I think they get updated alphabetically.  So you may need to re-run the update.packages command multiple times so that the required updates are available.


> 
> * removing 'C:/Program Files/R/R-3.2.3/library/agricolae'
> 
> Warning in install.packages :
> 
>  running command '"C:/PROGRA~1/R/R-32~1.3/bin/i386/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.2.3\library"
> C:\Users\user\AppData\Local\Temp\RtmpG8mSYd/downloaded_packages/agricolae_1.
> 2-3.tar.gz' had status 1
> 
> Warning in install.packages :
> 
>  installation of package 'agricolae' had non-zero exit status
> 
> 
> 
> The downloaded source packages are in
> 
> 
> 'C:\Users\user\AppData\Local\Temp\RtmpG8mSYd\downloaded_packages'
> 
> 
> 
>                If I try to install "spdep" package first I get the
> following error:
> 
> 
> 
> 
> 
>> install.packages("spdep")
> also installing the dependency 'sp'
> 
> Packages which are only available in source form, and may need compilation
> of C/C++/Fortran:
>  'sp' 'spdep'

Seems fairly self-explanatory. You need to install the source version of the packages named. See the appropriate section of the "R Installation and Administration Manual".


>  These will not be installed
> 
> How can I fix such errors? 


-- 
David Winsemius
Alameda, CA, USA


From erinm.hodgess at gmail.com  Sat Feb 27 05:38:33 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 26 Feb 2016 22:38:33 -0600
Subject: [R] calling R functions from Fortran via RInside?
Message-ID: <CACxE24ncZBvON8SLSF1J+5yjT0U2bhN1uoafDEbAr_DSh+Zr6g@mail.gmail.com>

Hello everyone.

Hope you are having a nice weekend.

Is it possible to call R functions from a Fortran program, possibly via
RInside and Rcpp, please?

I tried the following that I saw on stack overflow.  Here is the cpp:

#include <iostream>
#include <RInside.h>

void helloR_(int argc, char *argv[], const char *msg);

extern "C" void helloR(int argc, char *argv[], const char *msg) {

    // create an embedded R instance
    RInside R(argc, argv);

    // convert to string for RInside assignment
    std::string txt = std::string(msg);

    // C++ Notice
    std::cout << "This is C++, " << txt << std::endl;

    // Assign string to R object
    R.assign(txt, "txt");

    // eval the string, give R notice
    R.parseEvalQ("cat('This is R, ', txt, '\n')");
}

And here is the Fortran code:

 PROGRAM MAIN
    USE iso_c_binding
    IMPLICIT NONE
    INTEGER :: argc
    CHARACTER(len=32) :: arg
    CHARACTER(len=32) :: msg

    INTERFACE
      SUBROUTINE R_FUN(argc, arg, msg) bind(C, name="helloR")
        USE iso_c_binding
        INTEGER(kind=c_int), INTENT(IN) :: argc
        CHARACTER(kind=c_char), INTENT(IN) :: arg(*)
        CHARACTER(kind = C_CHAR), INTENT(IN) :: msg(*)
      END SUBROUTINE R_FUN
    END INTERFACE

    print *, "Fortran Calling RInside"
    CALL R_FUN (argc, arg, "Hello World"//C_NULL_CHAR)

  END PROGRAM MAIN

I compiled each, did the linking (according to the stack overflow), but the
program locked up when I ran it.

This is on an Ubuntu 15.10 laptop, R 3.2.3

Thank you,
Sincerely,
Erin



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Sat Feb 27 05:59:35 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 26 Feb 2016 22:59:35 -0600
Subject: [R] calling R functions from Fortran via RInside?
In-Reply-To: <CACxE24ncZBvON8SLSF1J+5yjT0U2bhN1uoafDEbAr_DSh+Zr6g@mail.gmail.com>
References: <CACxE24ncZBvON8SLSF1J+5yjT0U2bhN1uoafDEbAr_DSh+Zr6g@mail.gmail.com>
Message-ID: <CACxE24kMEvJ5TjvRGWfUKeH_Q=Js5MaRqGnXnJyt-fO2AkaSzQ@mail.gmail.com>

Please ignore previous message.  I recompiled, and linked.  Then things
worked.  For what it's worth, here are the steps.



* g++ testC.cpp -c
-I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/include
-I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include
-I/usr/share/R/include*g++ -o fcr testF.o testC.o -L/usr/lib/R/lib -lR -L
/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib -lRInside
-L/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
-Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib/
-lRInside
-Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
-lgfortran

 ./fcr
 Fortran Calling RInside
This is C++, Hello World
This is R,  Hello World


On Fri, Feb 26, 2016 at 10:38 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello everyone.
>
> Hope you are having a nice weekend.
>
> Is it possible to call R functions from a Fortran program, possibly via
> RInside and Rcpp, please?
>
> I tried the following that I saw on stack overflow.  Here is the cpp:
>
> #include <iostream>
> #include <RInside.h>
>
> void helloR_(int argc, char *argv[], const char *msg);
>
> extern "C" void helloR(int argc, char *argv[], const char *msg) {
>
>     // create an embedded R instance
>     RInside R(argc, argv);
>
>     // convert to string for RInside assignment
>     std::string txt = std::string(msg);
>
>     // C++ Notice
>     std::cout << "This is C++, " << txt << std::endl;
>
>     // Assign string to R object
>     R.assign(txt, "txt");
>
>     // eval the string, give R notice
>     R.parseEvalQ("cat('This is R, ', txt, '\n')");
> }
>
> And here is the Fortran code:
>
>  PROGRAM MAIN
>     USE iso_c_binding
>     IMPLICIT NONE
>     INTEGER :: argc
>     CHARACTER(len=32) :: arg
>     CHARACTER(len=32) :: msg
>
>     INTERFACE
>       SUBROUTINE R_FUN(argc, arg, msg) bind(C, name="helloR")
>         USE iso_c_binding
>         INTEGER(kind=c_int), INTENT(IN) :: argc
>         CHARACTER(kind=c_char), INTENT(IN) :: arg(*)
>         CHARACTER(kind = C_CHAR), INTENT(IN) :: msg(*)
>       END SUBROUTINE R_FUN
>     END INTERFACE
>
>     print *, "Fortran Calling RInside"
>     CALL R_FUN (argc, arg, "Hello World"//C_NULL_CHAR)
>
>   END PROGRAM MAIN
>
> I compiled each, did the linking (according to the stack overflow), but
> the program locked up when I ran it.
>
> This is on an Ubuntu 15.10 laptop, R 3.2.3
>
> Thank you,
> Sincerely,
> Erin
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Sat Feb 27 06:23:37 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 27 Feb 2016 16:23:37 +1100
Subject: [R] FW:  dotplot
References: <CAHLnnda-2Vx8mOHMu-iG0yLsNKe_sJG80gCks17=2p5FG4vfhw@mail.gmail.com>	<5557A665.1060605@frontier.com>
	<5557AC5C.4090509@frontier.com> 
Message-ID: <000001d1711f$02d62ad0$08828070$@bigpond.com>

Forgot to send to list

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Sunday, 17 May 2015 10:49
To: R
Subject: RE: [R] dotplot

if this is using lattice panel.dotplot gives the clues
The vertical lines are inserted by panel abline.

You can make your own panel.dotplot function by removing panel.abline which
uses col.line for the vertical line colour
 
A quick fix is by making col.line = "transparent". If you want to add lines
this may cause trouble for you

dotplot(val ~ lot, tmp,
        col.line = "transparent",
        ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
        pch=tmp$sybm, col=tmp$color)

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel
Nordlund
Sent: Sunday, 17 May 2015 06:45
To: r-help at r-project.org
Cc: SAS-L at LISTSERV.UGA.EDU
Subject: Re: [R] dotplot

On 5/16/2015 1:19 PM, Daniel Nordlund wrote:
> On 5/16/2015 12:32 PM, li li wrote:
>> Hi all,
>>    I wrote the following code and have two questions:
>>    (1) As you can see, I would like different colors for different
>> types. It does not come out that way in the graph from this code.
>> Anyone know how to fix this?
>>     (2) How do I made the lots number on x axis eligible to read?
>>     (3) How do I remove the verticle line in the graph.
>>      Thanks for your help.
>>        Hanna
>>
>>
>> lot <- as.character(c("D1300000" ,"D1300005" ,"D1300010", "D1300015",
>> "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045"))
>>
>> val <- rnorm(30)
>> type <- rep(1:3,each=10)
>> tmp <- as.data.frame(cbind(val, type, lot))
>> tmp$sybm <- rep(c(1, 12, 16), each=10)
>> tmp$color <- rep(c("blue", "red", "green"), each=10)
>> tmp$val <- as.numeric(tmp$val)
>> dotplot(val ~ lot, tmp,
>>          ylab = "values", xlab="lot", aspect=1,
>>          pch=tmp$sybm, color=tmp$color)
>>
>
> Li Li,
>
> 1. if the dotplot function you are referring to is from the lattice
> package, then the correct name for the "color" parameter is col.  You
> could just use col=type to get different colors but you won't have
> control over the colors chosen.  I created a vector, color, specifying
> the colors and the order they will be applied.
>
> 2.  the scales parameter is what you are looking for.  The parameter is
> looking for a list which consists of name=value pairs. You can rotate
> the labels by a specified number of degrees.  In my example, I chose 30
> degrees, rot=30.
>
> 3. I don't know how to eliminate the vertical lines, but if you read the
> lattice documentation, you will find it (if it is possible).
>
> color=c("blue", "red", "green")
> dotplot(val ~ lot, tmp,
>          ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
>          pch=tmp$sybm, col=color)
>
>
> Hope this is helpful,
>
> Dan
>

I apologize; my use of the color vector was incorrect.  You could just 
use the tmp$color values with the correct color parameter name.  Like

dotplot(val ~ lot, tmp,
         ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
         pch=tmp$sybm, col=tmp$color)


Dan



-- 
Daniel Nordlund
Bothell, WA USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From doorz at xs4all.nl  Sat Feb 27 10:38:14 2016
From: doorz at xs4all.nl (doorz)
Date: Sat, 27 Feb 2016 10:38:14 +0100
Subject: [R] Predicting correlated responses using canonical correlations in
 multivariate least squares
Message-ID: <29cfcf3cdd2539a6b803aede5bf036ee@xs4all.nl>

I have a considerable interest in trying to improve the predictions from 
10+ highly correlated predictors to two (2) highly correlated responses.

OLS does not allow me to take into account the correlation between the 
responses. Multivariate can take into account the correlations between 
the predictors.

I have tried to use canonical correlations (R function cancor). 
Canonical correlations nicely show the interrelations between the 
responses and predictors. Predicting the responses using cancor is a 
different matter. There is no predict method that supports cancor. 
Simple backsubstition leads to improved correlations but poor pairwise 
correspondence. (R code I use is below, for a 2 predictor, 2 response 
set of data, this is a book example (Frets, 1921 headsize data), my data 
is similar but can't be summarized in this post as easily)

The 1997 paper by Breiman and Friedman gives a procedure using shrinkage 
on least squares estimates obtained from canonical variates and their 
origins (the responses). They call this Curds and Whey. See  this post.

ftp://ftp.cis.upenn.edu/pub/datamining/public_html/ReadingGroup/papers/multiResponse.pdf

There is a master thesis (Kidd) which uses the above and promises an R 
package to handle the curds and whey procedures. That R package does not 
seem to have been made public though. See here:

http://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=3183&context=etd

Since the Breimam and Friedman paper is almost 20 years old I am 
wondering about their procedure. One would think that it would have been 
adopted if it is as powerful as it is claimed to be since correlated 
dependents are quite common. Is there a flaw in it that I do not know 
of? Is there anything better available today?

Any tips are most welcome.

Regards,
Alex van der Spek

#! usr/env/bin R
#CCA example try out
#Use data on head size of sons/brothers length and breadth
#Taken from the book by Everitt

#Clean slate
rm(list=ls())

## Panel function, put histograms on the diagonal
panel.hist <- function(x, ...)
{
     usr <- par("usr"); on.exit(par(usr))
     par(usr = c(usr[1:2], 0, 1.5) )
     h <- hist(x, plot = FALSE, breaks=21)
     breaks <- h$breaks; nB <- length(breaks)
     y <- h$counts; y <- y/max(y)
     rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
}

## Panel function, put correlation in top
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
     usr <- par("usr"); on.exit(par(usr))
     par(usr = c(0, 1, 0, 1))
     r <- abs(cor(x, y))
     txt <- format(c(r, 0.123456789), digits=digits)[1]
     txt <- paste(prefix, txt, sep="")
     if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
     text(0.5, 0.5, txt, cex = cex.cor * r)
}

#Bring up file selection box, set working directory and get base name
fn <- file.choose()
fs <- basename(fn)
fp <- dirname(fn)

#Read data in by csv
hs.r <- read.csv(fn)


#This is the entire data set, 25 points, two predictors (x) and two 
responses (y)
> head(hs.r, 25)
     x1  x2  y1  y2
1  191 155 179 145
2  195 149 201 152
3  181 148 185 149
4  183 153 188 149
5  176 144 171 142
6  208 157 192 152
7  189 150 190 149
8  197 159 189 152
9  188 152 197 159
10 192 150 187 151
11 179 158 186 148
12 183 147 174 147
13 174 150 185 152
14 190 159 195 157
15 188 151 187 158
16 163 137 161 130
17 195 155 183 158
18 186 153 173 148
19 181 145 182 146
20 175 140 165 137
21 192 154 185 152
22 174 143 178 147
23 176 139 176 143
24 197 167 200 158
25 190 163 187 150


#Make a scatter plot matrix
pairs(hs.r ,lower.panel = panel.smooth, upper.panel = panel.cor, 
diag.panel = panel.hist)

#Sweep out summary stats
hs.s <- scale(hs.r, center=F, scale=T)
hs.c <- scale(hs.r, center=T, scale=F)
hs.a <- scale(hs.r, center=T, scale=T)

#Make a scatter plot matrix of centered and scaled, standardized data
pairs(hs.a ,lower.panel = panel.smooth, upper.panel = panel.cor, 
diag.panel = panel.hist)
hs.1 <- hs.a[,1:2]
hs.2 <- hs.a[,3:4]

cc <- cancor(hs.1, hs.2, xcenter=F, ycenter=F)

#Compute the decompositon
#u1 <- cc$xcoef[1,1] * hs.1[,'x1'] + cc$xcoef[1,2] * hs.1[,'x2']
#v1 <- cc$ycoef[1,1] * hs.2[,'y1'] + cc$ycoef[1,2] * hs.2[,'y2']
#u2 <- cc$xcoef[2,1] * hs.1[,'x1'] + cc$xcoef[2,2] * hs.1[,'x2']
#v2 <- cc$ycoef[2,1] * hs.2[,'y1'] + cc$ycoef[2,2] * hs.2[,'y2']

#Quicker and better
uu <- hs.1 %*% cc$xcoef
vv <- hs.2 %*% cc$ycoef

#Store in a dataframe
uv <- data.frame(u1=uu[,1], v1=vv[,1], u2=uu[,2], v2=vv[,2])

#Make a scatter plot matrix
pairs(uv ,lower.panel = panel.smooth, upper.panel = panel.cor, 
diag.panel = panel.hist)

#Make a linear model, the significant coefs will prove to be the 
eigenvalues
lm.uv <- lm(cbind(u1, u2) ~ v1 + v2 - 1, data = uv)
summary(lm.uv)

#Notation  x * k * A  == y * B, solve for y
A <- cc$xcoef
B <- cc$ycoef
r <- cc$cor

#Compute the back substitioon
C <-  A %*% diag(r) %*% solve(B)

yy <- hs.1 %*% C
colnames(yy) <- c('yy1', 'yy2')

#Show how this relates to the original responses, not bad
pairs(cbind(hs.1, hs.2, yy), lower.panel = panel.smooth, upper.panel = 
panel.cor, d

#But pairwise the correspondence is poor.
head(cbind(hs.2, yy)

> head(cbind(hs.2, yy))
              y1          y2         yy1          yy2
[1,] -0.4820596 -0.63189808  0.43234091  0.434382250
[2,]  1.7091204  0.41132988  0.30938540  0.259340111
[3,]  0.1155349 -0.03576782 -0.36892523 -0.368659286
[4,]  0.4143322 -0.03576782 -0.02725575 -0.005036034
[5,] -1.2788523 -1.07899577 -0.79475501 -0.798376574
[6,]  0.8127286  0.41132988  1.29559865  1.241261763


From roger.bivand at nhh.no  Sat Feb 27 12:13:14 2016
From: roger.bivand at nhh.no (Roger Bivand)
Date: Sat, 27 Feb 2016 11:13:14 +0000
Subject: [R] rgrass7 problem
References: <CAK1cO7edmHtc1p=aXrSXyZTUUpMGQFmg=ZeKi1FUciVEzgZLCw@mail.gmail.com>
Message-ID: <loom.20160227T120810-940@post.gmane.org>

Carolina Arias Mu?oz <krolinarias <at> gmail.com> writes:

> 
> Hello
> 
> I am trying to use "readRAST" in GRASS, but I am keep getting the same
> error:
> 
> *Error: 'checkCRSArgs' is not an exported object from 'namespace:rgdal'*
> 
> Probably a problem of the rgdal library?

Speculation of this kind is never sensible.

This is not a helpful list in your case. Attention to what you are doing
would indicate that:

http://lists.osgeo.org/mailman/listinfo/grass-stats

is the most direct route to a sensible answer. You need to make that posting
much more informative - we can guess that you are using GRASS 7 (but not
which release) and rgrass7 (not which version), but have no idea of your OS,
or of other output of sessionInfo() in R.

Do not post HTML-formatted - plain text is preferred.

Roger

> 
> Thank you.
> 
> *___________________________________________________________________*
> 
> *Carolina Arias Mu?oz*
> PhD Student
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help <at> r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From asma.rabe at gmail.com  Sat Feb 27 15:04:26 2016
From: asma.rabe at gmail.com (asma.rabe at gmail.com)
Date: Sat, 27 Feb 2016 23:04:26 +0900
Subject: [R] Convert list to data frame
Message-ID: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>

Hi,

I  read data from file as follows

Data<-read.table("file.txt",header=T,sep="\t")

mode(Data)
list

I want to convert data to data frame, I tried the following:

as.data.frame(Data)
data.frame(Data)

But the Data did not change

When I tried
as.data.frame(unlist(Data))

The Data converted to a vector not to a data frame. Any idea ?

Thank you in advance


Sent from my iPhone


From ivan.calandra at univ-reims.fr  Sat Feb 27 15:56:15 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Sat, 27 Feb 2016 15:56:15 +0100
Subject: [R] Convert list to data frame
In-Reply-To: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>
References: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>
Message-ID: <56D1B90F.5000001@univ-reims.fr>

Hi,

I have seen this question a few days/weeks ago...

Data.frames are special list, so it's normal.
Read the help for read.table(), especially the "value" section (where 
the output of the function is described). And read also some 
introductory material, where the different data types are explained.

HTH,
Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 27/02/2016 15:04, asma.rabe at gmail.com a ?crit :
> Hi,
>
> I  read data from file as follows
>
> Data<-read.table("file.txt",header=T,sep="\t")
>
> mode(Data)
> list
>
> I want to convert data to data frame, I tried the following:
>
> as.data.frame(Data)
> data.frame(Data)
>
> But the Data did not change
>
> When I tried
> as.data.frame(unlist(Data))
>
> The Data converted to a vector not to a data frame. Any idea ?
>
> Thank you in advance
>
>
> Sent from my iPhone
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kmezhoud at gmail.com  Sat Feb 27 16:52:06 2016
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Sat, 27 Feb 2016 16:52:06 +0100
Subject: [R] Convert list to data frame
In-Reply-To: <56D1B90F.5000001@univ-reims.fr>
References: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>
	<56D1B90F.5000001@univ-reims.fr>
Message-ID: <CALJKBv9aSqaaw1qUb1jryZvbn6cR3Fbx659K4eb1E0PW=6EQkw@mail.gmail.com>

To known the format of your object, please use
class(Data)
str(Data)

Be sure to have regular space between strings in your file.txt.
Karim

On Sat, Feb 27, 2016 at 3:56 PM, Ivan Calandra <ivan.calandra at univ-reims.fr>
wrote:

> Hi,
>
> I have seen this question a few days/weeks ago...
>
> Data.frames are special list, so it's normal.
> Read the help for read.table(), especially the "value" section (where the
> output of the function is described). And read also some introductory
> material, where the different data types are explained.
>
> HTH,
> Ivan
>
> --
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
>
> Le 27/02/2016 15:04, asma.rabe at gmail.com a ?crit :
>
>> Hi,
>>
>> I  read data from file as follows
>>
>> Data<-read.table("file.txt",header=T,sep="\t")
>>
>> mode(Data)
>> list
>>
>> I want to convert data to data frame, I tried the following:
>>
>> as.data.frame(Data)
>> data.frame(Data)
>>
>> But the Data did not change
>>
>> When I tried
>> as.data.frame(unlist(Data))
>>
>> The Data converted to a vector not to a data frame. Any idea ?
>>
>> Thank you in advance
>>
>>
>> Sent from my iPhone
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Feb 27 18:27:40 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 27 Feb 2016 09:27:40 -0800
Subject: [R] Convert list to data frame
In-Reply-To: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>
References: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>
Message-ID: <4D242EF2-7EA6-4620-83DF-79DC50A3B379@comcast.net>


> On Feb 27, 2016, at 6:04 AM, <asma.rabe at gmail.com> <asma.rabe at gmail.com> wrote:
> 
> Hi,
> 
> I  read data from file as follows
> 
> Data<-read.table("file.txt",header=T,sep="\t")
> 
> mode(Data)
> list
> 
> I want to convert data to data frame,

It is already a dataframe. That is the class of object that read.table returns.


> I tried the following:
> 
> as.data.frame(Data)
> data.frame(Data)
> 
> But the Data did not change

R is a functional language. Simply applying a function does NOT alter the value of the arguments. Need to use assignment. If Data had not been a dataframe already and it had been a list with values whose lengths were equal, then you would have needed to perform:

Data <- data.frame(Data)


> 
> When I tried
> as.data.frame(unlist(Data))
> 
> The Data converted to a vector not to a data frame. Any idea ?
> 
> 


David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sat Feb 27 18:50:51 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 27 Feb 2016 09:50:51 -0800
Subject: [R] Convert list to data frame
In-Reply-To: <CALJKBv9aSqaaw1qUb1jryZvbn6cR3Fbx659K4eb1E0PW=6EQkw@mail.gmail.com>
References: <8444A20F-48FE-4DC2-B90B-7566AFF54448@gmail.com>
	<56D1B90F.5000001@univ-reims.fr>
	<CALJKBv9aSqaaw1qUb1jryZvbn6cR3Fbx659K4eb1E0PW=6EQkw@mail.gmail.com>
Message-ID: <34F539B6-DCFE-46DE-9EE0-17CA9B099D7A@dcn.davis.ca.us>

I think the advice about the file format is an track, but you imply modifying the file as a solution but that is probably not the best approach. Using a decent text editor that shows you what invisible characters are in the file can guide you in adjusting the arguments to read.table. for example,  the OP specified tab separators between fields, as Excel might put between fields in a text file. However, that is not a universal standard for text files so if spaces are used then removing the sep argument from the read.table call might help. 
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2016 7:52:06 AM PST, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>To known the format of your object, please use
>class(Data)
>str(Data)
>
>Be sure to have regular space between strings in your file.txt.
>Karim
>
>On Sat, Feb 27, 2016 at 3:56 PM, Ivan Calandra
><ivan.calandra at univ-reims.fr>
>wrote:
>
>> Hi,
>>
>> I have seen this question a few days/weeks ago...
>>
>> Data.frames are special list, so it's normal.
>> Read the help for read.table(), especially the "value" section (where
>the
>> output of the function is described). And read also some introductory
>> material, where the different data types are explained.
>>
>> HTH,
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>>
>> Le 27/02/2016 15:04, asma.rabe at gmail.com a ?crit :
>>
>>> Hi,
>>>
>>> I  read data from file as follows
>>>
>>> Data<-read.table("file.txt",header=T,sep="\t")
>>>
>>> mode(Data)
>>> list
>>>
>>> I want to convert data to data frame, I tried the following:
>>>
>>> as.data.frame(Data)
>>> data.frame(Data)
>>>
>>> But the Data did not change
>>>
>>> When I tried
>>> as.data.frame(unlist(Data))
>>>
>>> The Data converted to a vector not to a data frame. Any idea ?
>>>
>>> Thank you in advance
>>>
>>>
>>> Sent from my iPhone
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Sat Feb 27 19:34:46 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 27 Feb 2016 13:34:46 -0500
Subject: [R] Predicting correlated responses using canonical
 correlations in multivariate least squares
In-Reply-To: <29cfcf3cdd2539a6b803aede5bf036ee@xs4all.nl>
References: <29cfcf3cdd2539a6b803aede5bf036ee@xs4all.nl>
Message-ID: <56D1EC46.8030500@yorku.ca>

Hi Alex,

Thanks for the detailed explanation and the reproducible example.
But it is still not clear exactly what you wish to accomplish.

You know how to calculate the scores on the canonical variates.
These could be considered 'predicted scores', but in canonical
space.  What's wrong with that?
But it seems that what you want are predicted values
for y1, y2, ... from the canonical variates for the x variables ???

I don't think your question is sufficiently well-posed, but you
might look at the literature on *redundancy analysis*, which takes
the symmetric (Y, X) canonical correlation problem and re-formulates
it into questions of how well the Ys (or Xs) are predicted.

Is the problem just that the predictors and the responses
are both highly correlated within each set?  If so, you
should probably find that there is only one strong canonical
correlation, as in your example, and be done with it.
You might also find that an HE plot (library (heplots))
is illuminating.

The Breiman/Friedman paper you refer to can't be read on my
system, and, in any case, applying shrinkage to the problem
is something to consider once you have your ducks in order.

best,
-Michael



On 2/27/2016 4:38 AM, doorz wrote:
> I have a considerable interest in trying to improve the predictions from
> 10+ highly correlated predictors to two (2) highly correlated responses.
>
> OLS does not allow me to take into account the correlation between the
> responses. Multivariate can take into account the correlations between
> the predictors.
>
> I have tried to use canonical correlations (R function cancor).
> Canonical correlations nicely show the interrelations between the
> responses and predictors. Predicting the responses using cancor is a
> different matter. There is no predict method that supports cancor.
> Simple backsubstition leads to improved correlations but poor pairwise
> correspondence. (R code I use is below, for a 2 predictor, 2 response
> set of data, this is a book example (Frets, 1921 headsize data), my data
> is similar but can't be summarized in this post as easily)
>
> The 1997 paper by Breiman and Friedman gives a procedure using shrinkage
> on least squares estimates obtained from canonical variates and their
> origins (the responses). They call this Curds and Whey. See  this post.
>
> ftp://ftp.cis.upenn.edu/pub/datamining/public_html/ReadingGroup/papers/multiResponse.pdf
>
>
> There is a master thesis (Kidd) which uses the above and promises an R
> package to handle the curds and whey procedures. That R package does not
> seem to have been made public though. See here:
>
> http://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=3183&context=etd
>
> Since the Breimam and Friedman paper is almost 20 years old I am
> wondering about their procedure. One would think that it would have been
> adopted if it is as powerful as it is claimed to be since correlated
> dependents are quite common. Is there a flaw in it that I do not know
> of? Is there anything better available today?
>
> Any tips are most welcome.
>
> Regards,
> Alex van der Spek
>
> #! usr/env/bin R
> #CCA example try out
> #Use data on head size of sons/brothers length and breadth
> #Taken from the book by Everitt
>
> #Clean slate
> rm(list=ls())
>
> ## Panel function, put histograms on the diagonal
> panel.hist <- function(x, ...)
> {
>      usr <- par("usr"); on.exit(par(usr))
>      par(usr = c(usr[1:2], 0, 1.5) )
>      h <- hist(x, plot = FALSE, breaks=21)
>      breaks <- h$breaks; nB <- length(breaks)
>      y <- h$counts; y <- y/max(y)
>      rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
> }
>
> ## Panel function, put correlation in top
> panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
> {
>      usr <- par("usr"); on.exit(par(usr))
>      par(usr = c(0, 1, 0, 1))
>      r <- abs(cor(x, y))
>      txt <- format(c(r, 0.123456789), digits=digits)[1]
>      txt <- paste(prefix, txt, sep="")
>      if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
>      text(0.5, 0.5, txt, cex = cex.cor * r)
> }
>
> #Bring up file selection box, set working directory and get base name
> fn <- file.choose()
> fs <- basename(fn)
> fp <- dirname(fn)
>
> #Read data in by csv
> hs.r <- read.csv(fn)
>
>
> #This is the entire data set, 25 points, two predictors (x) and two
> responses (y)
>> head(hs.r, 25)
>      x1  x2  y1  y2
> 1  191 155 179 145
> 2  195 149 201 152
> 3  181 148 185 149
> 4  183 153 188 149
> 5  176 144 171 142
> 6  208 157 192 152
> 7  189 150 190 149
> 8  197 159 189 152
> 9  188 152 197 159
> 10 192 150 187 151
> 11 179 158 186 148
> 12 183 147 174 147
> 13 174 150 185 152
> 14 190 159 195 157
> 15 188 151 187 158
> 16 163 137 161 130
> 17 195 155 183 158
> 18 186 153 173 148
> 19 181 145 182 146
> 20 175 140 165 137
> 21 192 154 185 152
> 22 174 143 178 147
> 23 176 139 176 143
> 24 197 167 200 158
> 25 190 163 187 150
>
>
> #Make a scatter plot matrix
> pairs(hs.r ,lower.panel = panel.smooth, upper.panel = panel.cor,
> diag.panel = panel.hist)
>
> #Sweep out summary stats
> hs.s <- scale(hs.r, center=F, scale=T)
> hs.c <- scale(hs.r, center=T, scale=F)
> hs.a <- scale(hs.r, center=T, scale=T)
>
> #Make a scatter plot matrix of centered and scaled, standardized data
> pairs(hs.a ,lower.panel = panel.smooth, upper.panel = panel.cor,
> diag.panel = panel.hist)
> hs.1 <- hs.a[,1:2]
> hs.2 <- hs.a[,3:4]
>
> cc <- cancor(hs.1, hs.2, xcenter=F, ycenter=F)
>
> #Compute the decompositon
> #u1 <- cc$xcoef[1,1] * hs.1[,'x1'] + cc$xcoef[1,2] * hs.1[,'x2']
> #v1 <- cc$ycoef[1,1] * hs.2[,'y1'] + cc$ycoef[1,2] * hs.2[,'y2']
> #u2 <- cc$xcoef[2,1] * hs.1[,'x1'] + cc$xcoef[2,2] * hs.1[,'x2']
> #v2 <- cc$ycoef[2,1] * hs.2[,'y1'] + cc$ycoef[2,2] * hs.2[,'y2']
>
> #Quicker and better
> uu <- hs.1 %*% cc$xcoef
> vv <- hs.2 %*% cc$ycoef
>
> #Store in a dataframe
> uv <- data.frame(u1=uu[,1], v1=vv[,1], u2=uu[,2], v2=vv[,2])
>
> #Make a scatter plot matrix
> pairs(uv ,lower.panel = panel.smooth, upper.panel = panel.cor,
> diag.panel = panel.hist)
>
> #Make a linear model, the significant coefs will prove to be the
> eigenvalues
> lm.uv <- lm(cbind(u1, u2) ~ v1 + v2 - 1, data = uv)
> summary(lm.uv)
>
> #Notation  x * k * A  == y * B, solve for y
> A <- cc$xcoef
> B <- cc$ycoef
> r <- cc$cor
>
> #Compute the back substitioon
> C <-  A %*% diag(r) %*% solve(B)
>
> yy <- hs.1 %*% C
> colnames(yy) <- c('yy1', 'yy2')
>
> #Show how this relates to the original responses, not bad
> pairs(cbind(hs.1, hs.2, yy), lower.panel = panel.smooth, upper.panel =
> panel.cor, d
>
> #But pairwise the correspondence is poor.
> head(cbind(hs.2, yy)
>
>> head(cbind(hs.2, yy))
>               y1          y2         yy1          yy2
> [1,] -0.4820596 -0.63189808  0.43234091  0.434382250
> [2,]  1.7091204  0.41132988  0.30938540  0.259340111
> [3,]  0.1155349 -0.03576782 -0.36892523 -0.368659286
> [4,]  0.4143322 -0.03576782 -0.02725575 -0.005036034
> [5,] -1.2788523 -1.07899577 -0.79475501 -0.798376574
> [6,]  0.8127286  0.41132988  1.29559865  1.241261763
>


From friendly at yorku.ca  Sat Feb 27 20:04:23 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 27 Feb 2016 14:04:23 -0500
Subject: [R] Predicting correlated responses using canonical
 correlations in multivariate least squares
In-Reply-To: <56D1EC46.8030500@yorku.ca>
References: <29cfcf3cdd2539a6b803aede5bf036ee@xs4all.nl>
	<56D1EC46.8030500@yorku.ca>
Message-ID: <56D1F337.10804@yorku.ca>

On 2/27/2016 1:34 PM, Michael Friendly wrote:
> You might also find that an HE plot (library (heplots))
> is illuminating.

Follow-up:  Try the following with your example

library(heplots)
hs.mod <- lm(cbind(y1, y2) ~ x1 + x2, data=hs.r)
heplot(hs.mod, fill=TRUE)

uv.mod <- lm(cbind(u1, u2) ~ v1 + v2, data = uv)
heplot(uv.mod, fill=TRUE, asp=1)

In the first plot, x1, x2 are highly correlated, but neither is 
individually significant in predicting y1, y2 by Roy's test.

The second plot is the transformation to canonical space,
where (u1, u2), (v1, v2) are uncorrelated and v1 is a highly
significant predictor of u1.

-Michael


From erinm.hodgess at gmail.com  Sat Feb 27 21:00:23 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 27 Feb 2016 14:00:23 -0600
Subject: [R] Using Fortran with MPI, RInside, and calling R functions
Message-ID: <CACxE24nnG2UG+i9sTEfyqzPJ9z78=fjdO0Pske6150piLp9o0Q@mail.gmail.com>

Hello again.

This time, I would like to add MPI to my Fortran program.  Here are the
Fortran and C++ codes:

program buzzy
   use iso_c_binding
  implicit none
  include '/opt/openmpi/include/mpif.h'




  integer :: rank,size,ierror,tag,status(MPI_STATUS_SIZE), i,np
  integer :: argc = 1000000
  real :: x,tot1
  character(len=32) :: argv


      INTERFACE
         SUBROUTINE R_FUN(argc,argv) bind(C, name="buzzyC")
           use iso_c_binding
        character(kind=c_char), INTENT(INOUT) :: argv
        INTEGER(kind=c_int), INTENT(IN) :: argc

      END SUBROUTINE R_FUN
    END INTERFACE

      call MPI_INIT(ierror)
      call MPI_COMM_SIZE(MPI_COMM_WORLD,size,ierror)
      call MPI_COMM_RANK(MPI_COMM_WORLD,rank,ierror)




        print *, "Fortran Calling RInside",rank
    CALL R_FUN (argc,argv)
    print *,rank

    call MPI_FINALIZE(ierror)

  end program buzzy

and

#include <iostream>
#include <RInside.h>

void buzzyC_(int argc,char *argv[]);

extern "C" void buzzyC(int argc,char *argv[]) {

    // create an embedded R instance
  RInside R(argc,argv);

    // convert to string for RInside assignment


    // eval the string, give R notice
  R.parseEvalQ("cat(mean(rnorm(argc))");
}

Now my steps for compiling and linking are the following:

erin at erin-Bonobo-Extreme:~$ mpif90 -c buzzy.f90
erin at erin-Bonobo-Extreme:~$ mpic++ buzzyC.cpp -c
-I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/include
-I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include
-I/usr/share/R/include -libstdc++
erin at erin-Bonobo-Extreme:~$ mpifort -o fcra buzzy.o buzzyC.o
-L/usr/lib/R/lib -lR -L
/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib -lRInside
-L/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
-Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib/
-lRInside
-Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/ -lstdc++
/usr/lib/x86_64-linux-gnu/libstdc++.so.6

So far so good
But when I run this, disaster strikes:

erin at erin-Bonobo-Extreme:~$ mpirun -np 4 ./fcra
 Fortran Calling RInside           0
 Fortran Calling RInside           1
 Fortran Calling RInside           3
 Fortran Calling RInside           2

Program received signal SIGSEGV: Segmentation fault - invalid memory
reference.

Backtrace for this error:

Program received signal SIGSEGV: Segmentation fault - invalid memory
reference.

Backtrace for this error:
#0  0x7FC59706CE48
#1  0x7FC59706BFD0
#2  0x7FC596AA52EF
#3  0x7FC596AFB69A
#4  0x7FC597C5E8E8
#5  0x7FC5979671E8
#6  0x7FC5979677A1
#7  0x402A55 in buzzyC
#8  0x402891 in MAIN__ at buzzy.f90:?
#0  0x7F2482294E48
#1  0x7F2482293FD0
#2  0x7F2481CCD2EF
#3  0x7F2481D2369A
#4  0x7F2482E868E8
#5  0x7F2482B8F1E8
#6  0x7F2482B8F7A1
#7  0x402A55 in buzzyC
#8  0x402891 in MAIN__ at buzzy.f90:?
--------------------------------------------------------------------------
mpirun noticed that process rank 1 with PID 2188 on node
erin-Bonobo-Extreme exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
erin at erin-Bonobo-Extreme:~$

Maybe I should be asking:  is this even possible, please?

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Feb 27 21:15:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 27 Feb 2016 12:15:58 -0800
Subject: [R] Using Fortran with MPI, RInside, and calling R functions
In-Reply-To: <CACxE24nnG2UG+i9sTEfyqzPJ9z78=fjdO0Pske6150piLp9o0Q@mail.gmail.com>
References: <CACxE24nnG2UG+i9sTEfyqzPJ9z78=fjdO0Pske6150piLp9o0Q@mail.gmail.com>
Message-ID: <FD42D756-22C7-4E62-A8F0-49FA5B95DD30@dcn.davis.ca.us>

This is off topic here... wrong audience.  Read the Posting Guide. 
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2016 12:00:23 PM PST, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello again.
>
>This time, I would like to add MPI to my Fortran program.  Here are the
>Fortran and C++ codes:
>
>program buzzy
>   use iso_c_binding
>  implicit none
>  include '/opt/openmpi/include/mpif.h'
>
>
>
>
>  integer :: rank,size,ierror,tag,status(MPI_STATUS_SIZE), i,np
>  integer :: argc = 1000000
>  real :: x,tot1
>  character(len=32) :: argv
>
>
>      INTERFACE
>         SUBROUTINE R_FUN(argc,argv) bind(C, name="buzzyC")
>           use iso_c_binding
>        character(kind=c_char), INTENT(INOUT) :: argv
>        INTEGER(kind=c_int), INTENT(IN) :: argc
>
>      END SUBROUTINE R_FUN
>    END INTERFACE
>
>      call MPI_INIT(ierror)
>      call MPI_COMM_SIZE(MPI_COMM_WORLD,size,ierror)
>      call MPI_COMM_RANK(MPI_COMM_WORLD,rank,ierror)
>
>
>
>
>        print *, "Fortran Calling RInside",rank
>    CALL R_FUN (argc,argv)
>    print *,rank
>
>    call MPI_FINALIZE(ierror)
>
>  end program buzzy
>
>and
>
>#include <iostream>
>#include <RInside.h>
>
>void buzzyC_(int argc,char *argv[]);
>
>extern "C" void buzzyC(int argc,char *argv[]) {
>
>    // create an embedded R instance
>  RInside R(argc,argv);
>
>    // convert to string for RInside assignment
>
>
>    // eval the string, give R notice
>  R.parseEvalQ("cat(mean(rnorm(argc))");
>}
>
>Now my steps for compiling and linking are the following:
>
>erin at erin-Bonobo-Extreme:~$ mpif90 -c buzzy.f90
>erin at erin-Bonobo-Extreme:~$ mpic++ buzzyC.cpp -c
>-I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/include
>-I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include
>-I/usr/share/R/include -libstdc++
>erin at erin-Bonobo-Extreme:~$ mpifort -o fcra buzzy.o buzzyC.o
>-L/usr/lib/R/lib -lR -L
>/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib -lRInside
>-L/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
>-Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib/
>-lRInside
>-Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
>-lstdc++
>/usr/lib/x86_64-linux-gnu/libstdc++.so.6
>
>So far so good
>But when I run this, disaster strikes:
>
>erin at erin-Bonobo-Extreme:~$ mpirun -np 4 ./fcra
> Fortran Calling RInside           0
> Fortran Calling RInside           1
> Fortran Calling RInside           3
> Fortran Calling RInside           2
>
>Program received signal SIGSEGV: Segmentation fault - invalid memory
>reference.
>
>Backtrace for this error:
>
>Program received signal SIGSEGV: Segmentation fault - invalid memory
>reference.
>
>Backtrace for this error:
>#0  0x7FC59706CE48
>#1  0x7FC59706BFD0
>#2  0x7FC596AA52EF
>#3  0x7FC596AFB69A
>#4  0x7FC597C5E8E8
>#5  0x7FC5979671E8
>#6  0x7FC5979677A1
>#7  0x402A55 in buzzyC
>#8  0x402891 in MAIN__ at buzzy.f90:?
>#0  0x7F2482294E48
>#1  0x7F2482293FD0
>#2  0x7F2481CCD2EF
>#3  0x7F2481D2369A
>#4  0x7F2482E868E8
>#5  0x7F2482B8F1E8
>#6  0x7F2482B8F7A1
>#7  0x402A55 in buzzyC
>#8  0x402891 in MAIN__ at buzzy.f90:?
>--------------------------------------------------------------------------
>mpirun noticed that process rank 1 with PID 2188 on node
>erin-Bonobo-Extreme exited on signal 11 (Segmentation fault).
>--------------------------------------------------------------------------
>erin at erin-Bonobo-Extreme:~$
>
>Maybe I should be asking:  is this even possible, please?
>
>Thanks,
>Erin
>
>
>-- 
>Erin Hodgess
>Associate Professor
>Department of Mathematical and Statistics
>University of Houston - Downtown
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Sat Feb 27 21:30:15 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 27 Feb 2016 14:30:15 -0600
Subject: [R] Using Fortran with MPI, RInside, and calling R functions
In-Reply-To: <FD42D756-22C7-4E62-A8F0-49FA5B95DD30@dcn.davis.ca.us>
References: <CACxE24nnG2UG+i9sTEfyqzPJ9z78=fjdO0Pske6150piLp9o0Q@mail.gmail.com>
	<FD42D756-22C7-4E62-A8F0-49FA5B95DD30@dcn.davis.ca.us>
Message-ID: <CACxE24=urm4gLnJ=n41vW+i+PvE6BOuMv3bxdgTF6Sfy3q_EiQ@mail.gmail.com>

Sorry...thought it was ok since it uses RInside and Rcpp.


On Sat, Feb 27, 2016 at 2:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This is off topic here... wrong audience. Read the Posting Guide.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 27, 2016 12:00:23 PM PST, Erin Hodgess <
> erinm.hodgess at gmail.com> wrote:
>
>> Hello again.
>>
>> This time, I would like to add MPI to my Fortran program.  Here are the
>> Fortran and C++ codes:
>>
>> program buzzy
>>    use iso_c_binding
>>   implicit none
>>   include '/opt/openmpi/include/mpif.h'
>>
>>
>>
>>
>>   integer :: rank,size,ierror,tag,status(MPI_STATUS_SIZE), i,np
>>   integer :: argc = 1000000
>>   real :: x,tot1
>>   character(len=32) :: argv
>>
>>
>>       INTERFACE
>>          SUBROUTINE R_FUN(argc,argv) bind(C, name="buzzyC")
>>            use iso_c_binding
>>         character(kind=c_char), INTENT(INOUT) :: argv
>>         INTEGER(kind=c_int), INTENT(IN) :: argc
>>
>>       END SUBROUTINE R_FUN
>>     END INTERFACE
>>
>>       call MPI_INIT(ierror)
>>       call MPI_COMM_SIZE(MPI_COMM_WORLD,size,ierror)
>>       call MPI_COMM_RANK(MPI_COMM_WORLD,rank,ierror)
>>
>>
>>
>>
>>         print *, "Fortran Calling RInside",rank
>>     CALL
>> R_FUN (argc,argv)
>>     print *,rank
>>
>>     call MPI_FINALIZE(ierror)
>>
>>   end program buzzy
>>
>> and
>>
>> #include <iostream>
>> #include <RInside.h>
>>
>> void buzzyC_(int argc,char *argv[]);
>>
>> extern "C" void buzzyC(int argc,char *argv[]) {
>>
>>     // create an embedded R instance
>>   RInside R(argc,argv);
>>
>>     // convert to string for RInside assignment
>>
>>
>>     // eval the string, give R notice
>>   R.parseEvalQ("cat(mean(rnorm(argc))");
>> }
>>
>> Now my steps for compiling and linking are the following:
>>
>> erin at erin-Bonobo-Extreme:~$ mpif90 -c buzzy.f90
>> erin at erin-Bonobo-Extreme:~$ mpic++ buzzyC.cpp -c
>> -I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/include
>> -I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include
>> -I/usr/share/R/include -libstdc++
>> erin at erin-Bonobo-Extreme:~$ mpifort -o fcra buzzy.o buzzyC.o
>> -L/usr/lib/R/lib -lR
>> -L
>> /home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib -lRInside
>> -L/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
>> -Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib/
>> -lRInside
>> -Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/ -lstdc++
>> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
>>
>> So far so good
>> But when I run this, disaster strikes:
>>
>> erin at erin-Bonobo-Extreme:~$ mpirun -np 4 ./fcra
>>  Fortran Calling RInside           0
>>  Fortran Calling RInside           1
>>  Fortran Calling RInside           3
>>  Fortran Calling RInside           2
>>
>> Program received signal SIGSEGV: Segmentation fault - invalid memory
>> reference.
>>
>> Backtrace for this error:
>>
>> Program received signal SIGSEGV: Segmentation fault - invalid memory
>> reference.
>>
>> Backtrace for this error:
>> #0  0x7FC59706CE48
>> #1  0x7FC59706BFD0
>> #2  0x7FC596AA52EF
>> #3
>> 0x7FC596AFB69A
>> #4  0x7FC597C5E8E8
>> #5  0x7FC5979671E8
>> #6  0x7FC5979677A1
>> #7  0x402A55 in buzzyC
>> #8  0x402891 in MAIN__ at buzzy.f90:?
>> #0  0x7F2482294E48
>> #1  0x7F2482293FD0
>> #2  0x7F2481CCD2EF
>> #3  0x7F2481D2369A
>> #4  0x7F2482E868E8
>> #5  0x7F2482B8F1E8
>> #6  0x7F2482B8F7A1
>> #7  0x402A55 in buzzyC
>> #8  0x402891 in MAIN__ at buzzy.f90:?
>> ------------------------------
>>
>> mpirun noticed that process rank 1 with PID 2188 on node
>> erin-Bonobo-Extreme exited on signal 11 (Segmentation fault).
>> ------------------------------
>>
>> erin at erin-Bonobo-Extreme:~$
>>
>> Maybe I should be asking:  is this even possible, please?
>>
>> Thanks,
>> Erin
>>
>>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Feb 27 21:39:03 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 27 Feb 2016 21:39:03 +0100
Subject: [R] Using Fortran with MPI, RInside, and calling R functions
In-Reply-To: <CACxE24=urm4gLnJ=n41vW+i+PvE6BOuMv3bxdgTF6Sfy3q_EiQ@mail.gmail.com>
References: <CACxE24nnG2UG+i9sTEfyqzPJ9z78=fjdO0Pske6150piLp9o0Q@mail.gmail.com>
	<FD42D756-22C7-4E62-A8F0-49FA5B95DD30@dcn.davis.ca.us>
	<CACxE24=urm4gLnJ=n41vW+i+PvE6BOuMv3bxdgTF6Sfy3q_EiQ@mail.gmail.com>
Message-ID: <55770345-946B-4095-93D9-3D9533F28C4E@gmail.com>

Yeah, well, not much harm done, but once compilers are involved, r-devel is usually preferred over r-help.

-pd

> On 27 Feb 2016, at 21:30 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> Sorry...thought it was ok since it uses RInside and Rcpp.
> 
> 
> On Sat, Feb 27, 2016 at 2:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> This is off topic here... wrong audience. Read the Posting Guide.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On February 27, 2016 12:00:23 PM PST, Erin Hodgess <
>> erinm.hodgess at gmail.com> wrote:
>> 
>>> Hello again.
>>> 
>>> This time, I would like to add MPI to my Fortran program.  Here are the
>>> Fortran and C++ codes:
>>> 
>>> program buzzy
>>>   use iso_c_binding
>>>  implicit none
>>>  include '/opt/openmpi/include/mpif.h'
>>> 
>>> 
>>> 
>>> 
>>>  integer :: rank,size,ierror,tag,status(MPI_STATUS_SIZE), i,np
>>>  integer :: argc = 1000000
>>>  real :: x,tot1
>>>  character(len=32) :: argv
>>> 
>>> 
>>>      INTERFACE
>>>         SUBROUTINE R_FUN(argc,argv) bind(C, name="buzzyC")
>>>           use iso_c_binding
>>>        character(kind=c_char), INTENT(INOUT) :: argv
>>>        INTEGER(kind=c_int), INTENT(IN) :: argc
>>> 
>>>      END SUBROUTINE R_FUN
>>>    END INTERFACE
>>> 
>>>      call MPI_INIT(ierror)
>>>      call MPI_COMM_SIZE(MPI_COMM_WORLD,size,ierror)
>>>      call MPI_COMM_RANK(MPI_COMM_WORLD,rank,ierror)
>>> 
>>> 
>>> 
>>> 
>>>        print *, "Fortran Calling RInside",rank
>>>    CALL
>>> R_FUN (argc,argv)
>>>    print *,rank
>>> 
>>>    call MPI_FINALIZE(ierror)
>>> 
>>>  end program buzzy
>>> 
>>> and
>>> 
>>> #include <iostream>
>>> #include <RInside.h>
>>> 
>>> void buzzyC_(int argc,char *argv[]);
>>> 
>>> extern "C" void buzzyC(int argc,char *argv[]) {
>>> 
>>>    // create an embedded R instance
>>>  RInside R(argc,argv);
>>> 
>>>    // convert to string for RInside assignment
>>> 
>>> 
>>>    // eval the string, give R notice
>>>  R.parseEvalQ("cat(mean(rnorm(argc))");
>>> }
>>> 
>>> Now my steps for compiling and linking are the following:
>>> 
>>> erin at erin-Bonobo-Extreme:~$ mpif90 -c buzzy.f90
>>> erin at erin-Bonobo-Extreme:~$ mpic++ buzzyC.cpp -c
>>> -I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/include
>>> -I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include
>>> -I/usr/share/R/include -libstdc++
>>> erin at erin-Bonobo-Extreme:~$ mpifort -o fcra buzzy.o buzzyC.o
>>> -L/usr/lib/R/lib -lR
>>> -L
>>> /home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib -lRInside
>>> -L/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
>>> -Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib/
>>> -lRInside
>>> -Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/ -lstdc++
>>> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
>>> 
>>> So far so good
>>> But when I run this, disaster strikes:
>>> 
>>> erin at erin-Bonobo-Extreme:~$ mpirun -np 4 ./fcra
>>> Fortran Calling RInside           0
>>> Fortran Calling RInside           1
>>> Fortran Calling RInside           3
>>> Fortran Calling RInside           2
>>> 
>>> Program received signal SIGSEGV: Segmentation fault - invalid memory
>>> reference.
>>> 
>>> Backtrace for this error:
>>> 
>>> Program received signal SIGSEGV: Segmentation fault - invalid memory
>>> reference.
>>> 
>>> Backtrace for this error:
>>> #0  0x7FC59706CE48
>>> #1  0x7FC59706BFD0
>>> #2  0x7FC596AA52EF
>>> #3
>>> 0x7FC596AFB69A
>>> #4  0x7FC597C5E8E8
>>> #5  0x7FC5979671E8
>>> #6  0x7FC5979677A1
>>> #7  0x402A55 in buzzyC
>>> #8  0x402891 in MAIN__ at buzzy.f90:?
>>> #0  0x7F2482294E48
>>> #1  0x7F2482293FD0
>>> #2  0x7F2481CCD2EF
>>> #3  0x7F2481D2369A
>>> #4  0x7F2482E868E8
>>> #5  0x7F2482B8F1E8
>>> #6  0x7F2482B8F7A1
>>> #7  0x402A55 in buzzyC
>>> #8  0x402891 in MAIN__ at buzzy.f90:?
>>> ------------------------------
>>> 
>>> mpirun noticed that process rank 1 with PID 2188 on node
>>> erin-Bonobo-Extreme exited on signal 11 (Segmentation fault).
>>> ------------------------------
>>> 
>>> erin at erin-Bonobo-Extreme:~$
>>> 
>>> Maybe I should be asking:  is this even possible, please?
>>> 
>>> Thanks,
>>> Erin
>>> 
>>> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From erinm.hodgess at gmail.com  Sat Feb 27 21:40:27 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 27 Feb 2016 14:40:27 -0600
Subject: [R] Using Fortran with MPI, RInside, and calling R functions
In-Reply-To: <55770345-946B-4095-93D9-3D9533F28C4E@gmail.com>
References: <CACxE24nnG2UG+i9sTEfyqzPJ9z78=fjdO0Pske6150piLp9o0Q@mail.gmail.com>
	<FD42D756-22C7-4E62-A8F0-49FA5B95DD30@dcn.davis.ca.us>
	<CACxE24=urm4gLnJ=n41vW+i+PvE6BOuMv3bxdgTF6Sfy3q_EiQ@mail.gmail.com>
	<55770345-946B-4095-93D9-3D9533F28C4E@gmail.com>
Message-ID: <CACxE24kq1fbseYj9FYf3HD+FqGP37PX4rp5GuBVo+9MvcY7SRg@mail.gmail.com>

Got it.  thanks.


On Sat, Feb 27, 2016 at 2:39 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> Yeah, well, not much harm done, but once compilers are involved, r-devel
> is usually preferred over r-help.
>
> -pd
>
> > On 27 Feb 2016, at 21:30 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> >
> > Sorry...thought it was ok since it uses RInside and Rcpp.
> >
> >
> > On Sat, Feb 27, 2016 at 2:15 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> >> This is off topic here... wrong audience. Read the Posting Guide.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On February 27, 2016 12:00:23 PM PST, Erin Hodgess <
> >> erinm.hodgess at gmail.com> wrote:
> >>
> >>> Hello again.
> >>>
> >>> This time, I would like to add MPI to my Fortran program.  Here are the
> >>> Fortran and C++ codes:
> >>>
> >>> program buzzy
> >>>   use iso_c_binding
> >>>  implicit none
> >>>  include '/opt/openmpi/include/mpif.h'
> >>>
> >>>
> >>>
> >>>
> >>>  integer :: rank,size,ierror,tag,status(MPI_STATUS_SIZE), i,np
> >>>  integer :: argc = 1000000
> >>>  real :: x,tot1
> >>>  character(len=32) :: argv
> >>>
> >>>
> >>>      INTERFACE
> >>>         SUBROUTINE R_FUN(argc,argv) bind(C, name="buzzyC")
> >>>           use iso_c_binding
> >>>        character(kind=c_char), INTENT(INOUT) :: argv
> >>>        INTEGER(kind=c_int), INTENT(IN) :: argc
> >>>
> >>>      END SUBROUTINE R_FUN
> >>>    END INTERFACE
> >>>
> >>>      call MPI_INIT(ierror)
> >>>      call MPI_COMM_SIZE(MPI_COMM_WORLD,size,ierror)
> >>>      call MPI_COMM_RANK(MPI_COMM_WORLD,rank,ierror)
> >>>
> >>>
> >>>
> >>>
> >>>        print *, "Fortran Calling RInside",rank
> >>>    CALL
> >>> R_FUN (argc,argv)
> >>>    print *,rank
> >>>
> >>>    call MPI_FINALIZE(ierror)
> >>>
> >>>  end program buzzy
> >>>
> >>> and
> >>>
> >>> #include <iostream>
> >>> #include <RInside.h>
> >>>
> >>> void buzzyC_(int argc,char *argv[]);
> >>>
> >>> extern "C" void buzzyC(int argc,char *argv[]) {
> >>>
> >>>    // create an embedded R instance
> >>>  RInside R(argc,argv);
> >>>
> >>>    // convert to string for RInside assignment
> >>>
> >>>
> >>>    // eval the string, give R notice
> >>>  R.parseEvalQ("cat(mean(rnorm(argc))");
> >>> }
> >>>
> >>> Now my steps for compiling and linking are the following:
> >>>
> >>> erin at erin-Bonobo-Extreme:~$ mpif90 -c buzzy.f90
> >>> erin at erin-Bonobo-Extreme:~$ mpic++ buzzyC.cpp -c
> >>> -I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/include
> >>> -I/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include
> >>> -I/usr/share/R/include -libstdc++
> >>> erin at erin-Bonobo-Extreme:~$ mpifort -o fcra buzzy.o buzzyC.o
> >>> -L/usr/lib/R/lib -lR
> >>> -L
> >>> /home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib -lRInside
> >>> -L/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
> >>> -Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/RInside/lib/
> >>> -lRInside
> >>> -Wl,-rpath,/home/erin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/
> -lstdc++
> >>> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> >>>
> >>> So far so good
> >>> But when I run this, disaster strikes:
> >>>
> >>> erin at erin-Bonobo-Extreme:~$ mpirun -np 4 ./fcra
> >>> Fortran Calling RInside           0
> >>> Fortran Calling RInside           1
> >>> Fortran Calling RInside           3
> >>> Fortran Calling RInside           2
> >>>
> >>> Program received signal SIGSEGV: Segmentation fault - invalid memory
> >>> reference.
> >>>
> >>> Backtrace for this error:
> >>>
> >>> Program received signal SIGSEGV: Segmentation fault - invalid memory
> >>> reference.
> >>>
> >>> Backtrace for this error:
> >>> #0  0x7FC59706CE48
> >>> #1  0x7FC59706BFD0
> >>> #2  0x7FC596AA52EF
> >>> #3
> >>> 0x7FC596AFB69A
> >>> #4  0x7FC597C5E8E8
> >>> #5  0x7FC5979671E8
> >>> #6  0x7FC5979677A1
> >>> #7  0x402A55 in buzzyC
> >>> #8  0x402891 in MAIN__ at buzzy.f90:?
> >>> #0  0x7F2482294E48
> >>> #1  0x7F2482293FD0
> >>> #2  0x7F2481CCD2EF
> >>> #3  0x7F2481D2369A
> >>> #4  0x7F2482E868E8
> >>> #5  0x7F2482B8F1E8
> >>> #6  0x7F2482B8F7A1
> >>> #7  0x402A55 in buzzyC
> >>> #8  0x402891 in MAIN__ at buzzy.f90:?
> >>> ------------------------------
> >>>
> >>> mpirun noticed that process rank 1 with PID 2188 on node
> >>> erin-Bonobo-Extreme exited on signal 11 (Segmentation fault).
> >>> ------------------------------
> >>>
> >>> erin at erin-Bonobo-Extreme:~$
> >>>
> >>> Maybe I should be asking:  is this even possible, please?
> >>>
> >>> Thanks,
> >>> Erin
> >>>
> >>>
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics
> > University of Houston - Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jdthorpe at gmail.com  Sat Feb 27 23:52:29 2016
From: jdthorpe at gmail.com (Jason Thorpe)
Date: Sat, 27 Feb 2016 14:52:29 -0800
Subject: [R] Why does match() treat NaN's as compables; Bug or Feature?
Message-ID: <CAOxuTqjnZm7V24sk1qJ=8kUEW=wLGDenU_yfc-tPUu+pjS87xg@mail.gmail.com>

For some reason `match()` treats `NaN`'s as comparables by default:

> x <- c(1,2,3,NaN,4,5)
> match(x,x)
[1] 1 2 3 4 5 6

which I can override when using `match()` directly:

> match(x,x,incomparables=NaN)
[1]  1  2  3 NA  5  6

but not necessarily when calling a function that uses `match()` internally:

> stats::ecdf(x)(x)
[1] 0.2 0.4 0.6 0.8 0.8 1.0

Obviously there are workarounds for any given scenario, but the bigger
problem is that this behavior causes difficult to discover bugs.  For
example, the behavior of stats::ecdf is definitely a bug introduced by it's
use of `match()` (unless you think NaN == 4 is correct).

Is there a good reason that NaN's are treated as comparables by match(), or
his this a bug?

For reference, I'm using R version 3.2.3

-Jason

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sun Feb 28 00:20:35 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 27 Feb 2016 18:20:35 -0500
Subject: [R] is this an R bug or a DBI bug?
Message-ID: <CAOwvMDykPZYJzynHYdT8wDp7GOGfCQ2vCtb8dZzNVnZXHG_NcQ@mail.gmail.com>

this happens with both SQLite and MonetDBLite, so i assume it is not an
RSQLite bug.

notice the gc() in the no-crash version..

thanks


    # initiate R with "C:\Program Files\R\R-3.2.3\bin\x64\Rterm.exe"
--max-mem-size=35M
    library(RSQLite)
    db <- dbConnect( SQLite() )
    for( i in 1:1000 ) { dbWriteTable( db , 'x' , mtcars , append = TRUE ) }
    # CRASH


    # initiate R with "C:\Program Files\R\R-3.2.3\bin\x64\Rterm.exe"
--max-mem-size=35M
    library(RSQLite)
    db <- dbConnect( SQLite() )
    for( i in 1:1000 ) { dbWriteTable( db , 'x' , mtcars , append = TRUE )
; gc() }
    # no crash




================


> sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RSQLite_1.0.0 DBI_0.3.1

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Feb 28 00:34:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 27 Feb 2016 15:34:34 -0800
Subject: [R] Why does match() treat NaN's as compables; Bug or Feature?
In-Reply-To: <CAOxuTqjnZm7V24sk1qJ=8kUEW=wLGDenU_yfc-tPUu+pjS87xg@mail.gmail.com>
References: <CAOxuTqjnZm7V24sk1qJ=8kUEW=wLGDenU_yfc-tPUu+pjS87xg@mail.gmail.com>
Message-ID: <CAGxFJbRtWHcA3hBkipRw+zac4DYb5W8EJx6JRcjKdUhz42i1QA@mail.gmail.com>

If I understand you correctly, the "bug" is that you do not understand
match(). See inline comment below and note carefully the "Value"
section of ?match.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 27, 2016 at 2:52 PM, Jason Thorpe <jdthorpe at gmail.com> wrote:
> For some reason `match()` treats `NaN`'s as comparables by default:
>
>> x <- c(1,2,3,NaN,4,5)
>> match(x,x)
> [1] 1 2 3 4 5 6
>
> which I can override when using `match()` directly:
>
>> match(x,x,incomparables=NaN)
> [1]  1  2  3 NA  5  6
>
> but not necessarily when calling a function that uses `match()` internally:
>
>> stats::ecdf(x)(x)
> [1] 0.2 0.4 0.6 0.8 0.8 1.0
>
> Obviously there are workarounds for any given scenario, but the bigger
> problem is that this behavior causes difficult to discover bugs.  For
> example, the behavior of stats::ecdf is definitely a bug introduced by it's
> use of `match()` (unless you think NaN == 4 is correct).

No, you misunderstand. match() returns the POSITION of the match, and
clearly NaN in the 4th position of table =x matches NaN in x. e.g.

> match(c(x,NaN),x)
[1] 1 2 3 4 5 6 4



>
> Is there a good reason that NaN's are treated as comparables by match(), or
> his this a bug?
>
> For reference, I'm using R version 3.2.3
>
> -Jason
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Feb 28 01:06:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 27 Feb 2016 16:06:41 -0800
Subject: [R] Why does match() treat NaN's as compables; Bug or Feature?
In-Reply-To: <CAGxFJbRtWHcA3hBkipRw+zac4DYb5W8EJx6JRcjKdUhz42i1QA@mail.gmail.com>
References: <CAOxuTqjnZm7V24sk1qJ=8kUEW=wLGDenU_yfc-tPUu+pjS87xg@mail.gmail.com>
	<CAGxFJbRtWHcA3hBkipRw+zac4DYb5W8EJx6JRcjKdUhz42i1QA@mail.gmail.com>
Message-ID: <9D335576-BC0B-4E89-9F96-C9766F96A98A@dcn.davis.ca.us>

That is one valid point, but according to IEEE754 "a comparison with NaN always returns an unordered result" which it doesn't do unless the incomparables argument to match is specified. Ick.
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2016 3:34:34 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>If I understand you correctly, the "bug" is that you do not understand
>match(). See inline comment below and note carefully the "Value"
>section of ?match.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sat, Feb 27, 2016 at 2:52 PM, Jason Thorpe <jdthorpe at gmail.com>
>wrote:
>> For some reason `match()` treats `NaN`'s as comparables by default:
>>
>>> x <- c(1,2,3,NaN,4,5)
>>> match(x,x)
>> [1] 1 2 3 4 5 6
>>
>> which I can override when using `match()` directly:
>>
>>> match(x,x,incomparables=NaN)
>> [1]  1  2  3 NA  5  6
>>
>> but not necessarily when calling a function that uses `match()`
>internally:
>>
>>> stats::ecdf(x)(x)
>> [1] 0.2 0.4 0.6 0.8 0.8 1.0
>>
>> Obviously there are workarounds for any given scenario, but the
>bigger
>> problem is that this behavior causes difficult to discover bugs.  For
>> example, the behavior of stats::ecdf is definitely a bug introduced
>by it's
>> use of `match()` (unless you think NaN == 4 is correct).
>
>No, you misunderstand. match() returns the POSITION of the match, and
>clearly NaN in the 4th position of table =x matches NaN in x. e.g.
>
>> match(c(x,NaN),x)
>[1] 1 2 3 4 5 6 4
>
>
>
>>
>> Is there a good reason that NaN's are treated as comparables by
>match(), or
>> his this a bug?
>>
>> For reference, I'm using R version 3.2.3
>>
>> -Jason
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Sun Feb 28 03:23:36 2016
From: sewashm at gmail.com (Ashta)
Date: Sat, 27 Feb 2016 20:23:36 -0600
Subject: [R] flag a record
Message-ID: <CADDFq32b7mUpj5uYBvFD88UVQyQnk9ag6u3T6L2zp35Uv4DK6Q@mail.gmail.com>

 Hi all,

 I have a data set represented by the following sample.

I want flag records of an individual as "N", if  if the tag column of
an individual  is equal to zero for the last  two years. So in the
following example, Alex1 records are flagged as "y",  On the other
hand Carla's records are flagged as "N" because all values of tag  for
Carla are zero. Another typical example is that Jon,  although the tag
values of Jon are greater than 0 it is flagged as "N", because his
record  are more than two years old.

DF <- read.table(textConnection(" Name  year  tag
Alex1    2011         0
Alex1    2012         1
Alex1    2013         0
Alex1    2014         1

Carla     2013      0
Carla     2014      0
Carla     2015      0
Carla     2012      0

Tom     2014       1
Tom     2015       1

 Jon      2010      1
 Jon     2011       1    "),header = TRUE)

I want create another variable " Flag  with value Y or  N"  if an
individual has a  value greater than 0 in the tag column  for the last
two years  then  the flag value will be y otherwise  it n.


the outcome will be
  name   year      tag    Flag
Alex1    2011         0      y
Alex1    2012         1      y
Alex1    2013         0      y
Alex1    2014         1      y

Carla     2013      0         n
Carla     2014      0         n
Carla     2015      0         n
Carla     2012      0         n

Tom     2014       1          y
Tom     2015       1          y

 Jon     2010       1          n
 Jon     2011       1           n

Thank you in advance


From bgunter.4567 at gmail.com  Sun Feb 28 04:06:05 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 27 Feb 2016 19:06:05 -0800
Subject: [R] Why does match() treat NaN's as compables; Bug or Feature?
In-Reply-To: <CAOxuTqhcyXupTi5707MA+OHDbsWptDpfa7gOvHMsGVAWYym5Mg@mail.gmail.com>
References: <CAOxuTqjnZm7V24sk1qJ=8kUEW=wLGDenU_yfc-tPUu+pjS87xg@mail.gmail.com>
	<CAGxFJbRtWHcA3hBkipRw+zac4DYb5W8EJx6JRcjKdUhz42i1QA@mail.gmail.com>
	<CAOxuTqhcyXupTi5707MA+OHDbsWptDpfa7gOvHMsGVAWYym5Mg@mail.gmail.com>
Message-ID: <CAGxFJbTx0Z51Ak_EVo3NzZ85xA_B+=8h8+JR+8dAPZLtEnu7TQ@mail.gmail.com>

(on list, since others might not have gotten it either).

OK, I get it now. It was I who misunderstood.

But isn't the bug in the **misuse** of match() in ecdf() (by failing
to specify the nomatch argument). Jeff says comparisons with NaN
should return an unordered result, which NaN is afaics:

> NaN < 0
[1] NA
> NaN > 0
[1] NA

match() just does its thing:

> match(c(NA,NaN),c(1,2,NA,3,4,NaN,5))
[1] 3 6

It's up to the caller to use it correctly, which apparently ecdf() fails to do.

Am I missing something here?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 27, 2016 at 3:49 PM, Jason Thorpe <jdthorpe at gmail.com> wrote:
> The bug is that NaN is not part of any cumulative distribution...
>
> -Jason
> sent from my mobile device
>
> On Feb 27, 2016 3:34 PM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:
>>
>> If I understand you correctly, the "bug" is that you do not understand
>> match(). See inline comment below and note carefully the "Value"
>> section of ?match.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Feb 27, 2016 at 2:52 PM, Jason Thorpe <jdthorpe at gmail.com> wrote:
>> > For some reason `match()` treats `NaN`'s as comparables by default:
>> >
>> >> x <- c(1,2,3,NaN,4,5)
>> >> match(x,x)
>> > [1] 1 2 3 4 5 6
>> >
>> > which I can override when using `match()` directly:
>> >
>> >> match(x,x,incomparables=NaN)
>> > [1]  1  2  3 NA  5  6
>> >
>> > but not necessarily when calling a function that uses `match()`
>> > internally:
>> >
>> >> stats::ecdf(x)(x)
>> > [1] 0.2 0.4 0.6 0.8 0.8 1.0
>> >
>> > Obviously there are workarounds for any given scenario, but the bigger
>> > problem is that this behavior causes difficult to discover bugs.  For
>> > example, the behavior of stats::ecdf is definitely a bug introduced by
>> > it's
>> > use of `match()` (unless you think NaN == 4 is correct).
>>
>> No, you misunderstand. match() returns the POSITION of the match, and
>> clearly NaN in the 4th position of table =x matches NaN in x. e.g.
>>
>> > match(c(x,NaN),x)
>> [1] 1 2 3 4 5 6 4
>>
>>
>>
>> >
>> > Is there a good reason that NaN's are treated as comparables by match(),
>> > or
>> > his this a bug?
>> >
>> > For reference, I'm using R version 3.2.3
>> >
>> > -Jason
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Feb 28 08:46:45 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 28 Feb 2016 18:46:45 +1100
Subject: [R] flag a record
In-Reply-To: <CADDFq32b7mUpj5uYBvFD88UVQyQnk9ag6u3T6L2zp35Uv4DK6Q@mail.gmail.com>
References: <CADDFq32b7mUpj5uYBvFD88UVQyQnk9ag6u3T6L2zp35Uv4DK6Q@mail.gmail.com>
Message-ID: <CA+8X3fUKTnnHWTyuXguGLGAsu42vYZPWjAN0W_-xks7iFRdDhw@mail.gmail.com>

Hi Ashta,
This does not seem too difficult:

DF$flag<-"n"
for(thisname in unique(DF$Name)) {
 if(any(DF$year[DF$Name == thisname] %in% c(2014,2015) &
  DF$tag[DF$Name == thisname]))
  DF$flag[DF$Name == thisname]<-"y"
}

Jim

On Sun, Feb 28, 2016 at 1:23 PM, Ashta <sewashm at gmail.com> wrote:
>  Hi all,
>
>  I have a data set represented by the following sample.
>
> I want flag records of an individual as "N", if  if the tag column of
> an individual  is equal to zero for the last  two years. So in the
> following example, Alex1 records are flagged as "y",  On the other
> hand Carla's records are flagged as "N" because all values of tag  for
> Carla are zero. Another typical example is that Jon,  although the tag
> values of Jon are greater than 0 it is flagged as "N", because his
> record  are more than two years old.
>
> DF <- read.table(textConnection(" Name  year  tag
> Alex1    2011         0
> Alex1    2012         1
> Alex1    2013         0
> Alex1    2014         1
>
> Carla     2013      0
> Carla     2014      0
> Carla     2015      0
> Carla     2012      0
>
> Tom     2014       1
> Tom     2015       1
>
>  Jon      2010      1
>  Jon     2011       1    "),header = TRUE)
>
> I want create another variable " Flag  with value Y or  N"  if an
> individual has a  value greater than 0 in the tag column  for the last
> two years  then  the flag value will be y otherwise  it n.
>
>
> the outcome will be
>   name   year      tag    Flag
> Alex1    2011         0      y
> Alex1    2012         1      y
> Alex1    2013         0      y
> Alex1    2014         1      y
>
> Carla     2013      0         n
> Carla     2014      0         n
> Carla     2015      0         n
> Carla     2012      0         n
>
> Tom     2014       1          y
> Tom     2015       1          y
>
>  Jon     2010       1          n
>  Jon     2011       1           n
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From helmut.schuetz at bebac.at  Sun Feb 28 14:02:02 2016
From: helmut.schuetz at bebac.at (Helmut Schuetz)
Date: Sun, 28 Feb 2016 14:02:02 +0100
Subject: [R] Color of points in legend() ignored if plotting to PNG
Message-ID: <56D2EFCA.4020305@bebac.at>

Dear all,

if I plot to a PNG, the color of filled points (pch 21:25) in legend() is ignored (i.e., only the background color is used). It does not matter whether I specify the default png(bg="white") or png(bg="transparent").

The example below

x <- rnorm(10)
y <- rnorm(10)
plot(x, y, pch = 21, cex = 1.5,
   xlim = range(x, y) * 1.2, ylim = range(x, y)*1.2,
   col = "black", bg = "lightgrey")
legend("topleft", legend = "foo", inset = 0.02,
   bg = "white", pch = 21, pt.cex = 1.5,
   col = "black", pt.bg = "lightgrey")

works as desired on windows(...) but fails to show the color in the legend on png(...).

Any suggestions?
Helmut

Environment: x86_64-w64-mingw32/x64 (64-bit), R 3.2.3

-- 
Ing. Helmut Schuetz
BEBAC - Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
VAT No  ATU61115625
DUNS    300370568
tel     +43 1 2311746
mobile  +43 699 10792458
e-mail  helmut.schuetz at bebac.at
web     http://bebac.at/
contact http://bebac.at/Contact.htm
forum   http://forum.bebac.at/

This e-mail is confidential and may also be legally privileged. If you
are not the intended recipient please reply to sender, do not disclose
its contents to any person and delete the e-mail. Any unauthorized
review, use, disclosure, copying or distribution is strictly prohibited.


From ajdamico at gmail.com  Sun Feb 28 14:36:36 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 28 Feb 2016 08:36:36 -0500
Subject: [R] is this an R bug or a DBI bug?
In-Reply-To: <CAOwvMDykPZYJzynHYdT8wDp7GOGfCQ2vCtb8dZzNVnZXHG_NcQ@mail.gmail.com>
References: <CAOwvMDykPZYJzynHYdT8wDp7GOGfCQ2vCtb8dZzNVnZXHG_NcQ@mail.gmail.com>
Message-ID: <CAOwvMDxev=OgK4vaeyuHQHwA6jZa5dfDv89hvZktv-zS-CbY-Q@mail.gmail.com>

tested this out on 3.2.0, 3.2.1, and 3.2.2 -- only happens on 3.2.3, so i
assume it was an R bug not a DBI bug.  submitted here:

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16734




On Sat, Feb 27, 2016 at 6:20 PM, Anthony Damico <ajdamico at gmail.com> wrote:

> this happens with both SQLite and MonetDBLite, so i assume it is not an
> RSQLite bug.
>
> notice the gc() in the no-crash version..
>
> thanks
>
>
>     # initiate R with "C:\Program Files\R\R-3.2.3\bin\x64\Rterm.exe"
> --max-mem-size=35M
>     library(RSQLite)
>     db <- dbConnect( SQLite() )
>     for( i in 1:1000 ) { dbWriteTable( db , 'x' , mtcars , append = TRUE )
> }
>     # CRASH
>
>
>     # initiate R with "C:\Program Files\R\R-3.2.3\bin\x64\Rterm.exe"
> --max-mem-size=35M
>     library(RSQLite)
>     db <- dbConnect( SQLite() )
>     for( i in 1:1000 ) { dbWriteTable( db , 'x' , mtcars , append = TRUE )
> ; gc() }
>     # no crash
>
>
>
>
> ================
>
>
> > sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] RSQLite_1.0.0 DBI_0.3.1
>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Feb 28 15:45:09 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 28 Feb 2016 09:45:09 -0500
Subject: [R] Color of points in legend() ignored if plotting to PNG
In-Reply-To: <56D2EFCA.4020305@bebac.at>
References: <56D2EFCA.4020305@bebac.at>
Message-ID: <1D68B65E-20E7-4F18-8DC7-3BD8331A39F8@utoronto.ca>

Works for me on Mac OS...

R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.9.5 (Mavericks)
[...]



On Feb 28, 2016, at 8:02 AM, Helmut Schuetz <helmut.schuetz at bebac.at> wrote:

> Dear all,
> 
> if I plot to a PNG, the color of filled points (pch 21:25) in legend() is ignored (i.e., only the background color is used). It does not matter whether I specify the default png(bg="white") or png(bg="transparent").
> 
> The example below
> 
> x <- rnorm(10)
> y <- rnorm(10)
> plot(x, y, pch = 21, cex = 1.5,
>  xlim = range(x, y) * 1.2, ylim = range(x, y)*1.2,
>  col = "black", bg = "lightgrey")
> legend("topleft", legend = "foo", inset = 0.02,
>  bg = "white", pch = 21, pt.cex = 1.5,
>  col = "black", pt.bg = "lightgrey")
> 
> works as desired on windows(...) but fails to show the color in the legend on png(...).
> 
> Any suggestions?
> Helmut
> 
> Environment: x86_64-w64-mingw32/x64 (64-bit), R 3.2.3
> 
> -- 
> Ing. Helmut Schuetz
> BEBAC - Consultancy Services for
> Bioequivalence and Bioavailability Studies
> Neubaugasse 36/11
> 1070 Vienna, Austria
> VAT No  ATU61115625
> DUNS    300370568
> tel     +43 1 2311746
> mobile  +43 699 10792458
> e-mail  helmut.schuetz at bebac.at
> web     http://bebac.at/
> contact http://bebac.at/Contact.htm
> forum   http://forum.bebac.at/
> 
> This e-mail is confidential and may also be legally privileged. If you
> are not the intended recipient please reply to sender, do not disclose
> its contents to any person and delete the e-mail. Any unauthorized
> review, use, disclosure, copying or distribution is strictly prohibited.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Sun Feb 28 16:34:52 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 28 Feb 2016 10:34:52 -0500
Subject: [R] axis break in R
In-Reply-To: <CAJx9nazHMwUnquF1BrwAVHE9CmRmGJ1xW0yTgkLUcsyHUHYMyg@mail.gmail.com>
References: <CAJx9nazHMwUnquF1BrwAVHE9CmRmGJ1xW0yTgkLUcsyHUHYMyg@mail.gmail.com>
Message-ID: <56D3139C.2030406@yahoo.fr>

Hi Eike,

I didn't know how to do, so it was a nice exercise. Here is a solution 
using plot(). I have made a function plot.break(); the name of 
parameters of the function are self-explained (I think), but tell me if 
you need more explanation.
You can add any parameters of the plot() function.

I have made this function very fast and it is not fully tested. If you 
see a problem, do not hesitate to tell me.

Sincerely

Marc

plot.break <- function(x, y, at.cut, at.continue, add.cut,
                        number.ticks.bottom, number.ticks.up,
                        min.y, max.y, ...) {

   p.plot <- list(...)
   p.plot <- modifyList(list(x = x, y=ifelse(y>at.cut, 
y-at.continue+add.cut, y),
                             bty="n", type="p", las=1,
                             ylim=c(min.y, max.y-at.continue+add.cut), 
yaxt="n", xlab="x", ylab="y"),
                        p.plot)
   do.call(plot, p.plot)
   y.axis <- c(seq(from=0, to=at.cut, length=number.ticks.bottom),
               seq(from=at.cut+add.cut, to=ScalePreviousPlot()$ylim[2], 
length=number.ticks.up))
   axis(2, at=y.axis,
        labels=ifelse(y.axis>at.cut, y.axis+at.continue-add.cut, y.axis),
        las=1)
   par(xpd=TRUE)

   x.left <- 
ScalePreviousPlot()$xlim[1]-0.05*ScalePreviousPlot()$xlim["range"]
   x.right <- 
ScalePreviousPlot()$xlim[1]+0.00*ScalePreviousPlot()$xlim["range"]

   polygon(x=c(x.left, x.right, x.right, x.left, x.left),
           y=c(at.cut+0.5, at.cut+0.5, at.cut+add.cut-0.5, 
at.cut+add.cut-0.5, at.cut+0.5),
           col="white", border=NA)
}

x <- 1:10
y <- c(rnorm(5, 10, 5), rnorm(5, 100, 5))

library(HelpersMG)
at.cut <- 20
at.continue <- 60
add.cut <- 5
number.ticks.bottom <- 3
number.ticks.up <- 5
min.y <- 0
max.y <- 120

plot.break(x = x, y=y, at.cut= 20,
            at.continue= 60,
            add.cut= 5,
            number.ticks.bottom= 3,
            number.ticks.up= 5,
            min.y= 0,
            max.y= 120, xlab="Value x")


Le 23/02/2016 11:00, Eike Marie Thaysen a ?crit :
> Hello,
> I want to break the y-axis on one of my plots. I read this is possible- but
> apparently only with the plotrix package that requieres R version 3.6-1? I
> cannot seem to find that version on the R homepage.. it is a version you
> have to pay for? Are there any other possebilities to do it (I am currently
> running (for R version 3.1.2) )
> Thank you,
> Eike
>
>


From matej.matjasec at gmail.com  Sun Feb 28 10:03:28 2016
From: matej.matjasec at gmail.com (=?UTF-8?Q?Matej_Matja=C5=A1ec?=)
Date: Sun, 28 Feb 2016 10:03:28 +0100
Subject: [R] manage algorithm in R studio
Message-ID: <CAAXvaoOJop6=4+C84uFaAf8qwifCqafg_LE_tQ5vUqdxg-0-ug@mail.gmail.com>

Hello,

I need some instruction about R studio library, that using algorithm
Needleman - Wunsch and Smith - Waterman. How can I present this algorithm
in R, calculate maximum score sequence alignment ?

It is possible that things in R?

Thank you very much in advance for your reply.

Greetings, Matej

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb 28 18:44:37 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 Feb 2016 09:44:37 -0800
Subject: [R] manage algorithm in R studio
In-Reply-To: <CAAXvaoOJop6=4+C84uFaAf8qwifCqafg_LE_tQ5vUqdxg-0-ug@mail.gmail.com>
References: <CAAXvaoOJop6=4+C84uFaAf8qwifCqafg_LE_tQ5vUqdxg-0-ug@mail.gmail.com>
Message-ID: <C9AE1B24-D029-41D5-A742-EC592E7E5DF3@dcn.davis.ca.us>

Quite possibly, if Google is to be trusted. 
-- 
Sent from my phone. Please excuse my brevity.

On February 28, 2016 1:03:28 AM PST, "Matej Matja?ec" <matej.matjasec at gmail.com> wrote:
>Hello,
>
>I need some instruction about R studio library, that using algorithm
>Needleman - Wunsch and Smith - Waterman. How can I present this
>algorithm
>in R, calculate maximum score sequence alignment ?
>
>It is possible that things in R?
>
>Thank you very much in advance for your reply.
>
>Greetings, Matej
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Feb 28 21:04:38 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 28 Feb 2016 15:04:38 -0500
Subject: [R] manage algorithm in R studio
In-Reply-To: <C9AE1B24-D029-41D5-A742-EC592E7E5DF3@dcn.davis.ca.us>
References: <CAAXvaoOJop6=4+C84uFaAf8qwifCqafg_LE_tQ5vUqdxg-0-ug@mail.gmail.com>
	<C9AE1B24-D029-41D5-A742-EC592E7E5DF3@dcn.davis.ca.us>
Message-ID: <01098054-BDEE-4B85-BFD5-E65E159AA9BC@utoronto.ca>

This is probably fun to write, but it's been done many times before. For practical purposes, use the pairwiseAlignment() function in the Biostrings package, distributed by the bioconductor project.

cf.: https://www.bioconductor.org/packages/3.3/bioc/vignettes/Biostrings/inst/doc/PairwiseAlignments.pdf

Cheers,
Boris



On Feb 28, 2016, at 12:44 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Quite possibly, if Google is to be trusted. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 28, 2016 1:03:28 AM PST, "Matej Matja?ec" <matej.matjasec at gmail.com> wrote:
>> Hello,
>> 
>> I need some instruction about R studio library, that using algorithm
>> Needleman - Wunsch and Smith - Waterman. How can I present this
>> algorithm
>> in R, calculate maximum score sequence alignment ?
>> 
>> It is possible that things in R?
>> 
>> Thank you very much in advance for your reply.
>> 
>> Greetings, Matej
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Mon Feb 29 00:23:31 2016
From: sewashm at gmail.com (Ashta)
Date: Sun, 28 Feb 2016 17:23:31 -0600
Subject: [R] flag a record
In-Reply-To: <CA+8X3fUKTnnHWTyuXguGLGAsu42vYZPWjAN0W_-xks7iFRdDhw@mail.gmail.com>
References: <CADDFq32b7mUpj5uYBvFD88UVQyQnk9ag6u3T6L2zp35Uv4DK6Q@mail.gmail.com>
	<CA+8X3fUKTnnHWTyuXguGLGAsu42vYZPWjAN0W_-xks7iFRdDhw@mail.gmail.com>
Message-ID: <CADDFq31dgReJ2QZEdbWue-pJxr_5+231PUuyY159DumitzSk-g@mail.gmail.com>

Thank you very much Jim!
It is working fine!!

On Sun, Feb 28, 2016 at 1:46 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Ashta,
> This does not seem too difficult:
>
> DF$flag<-"n"
> for(thisname in unique(DF$Name)) {
>  if(any(DF$year[DF$Name == thisname] %in% c(2014,2015) &
>   DF$tag[DF$Name == thisname]))
>   DF$flag[DF$Name == thisname]<-"y"
> }
>
> Jim
>
> On Sun, Feb 28, 2016 at 1:23 PM, Ashta <sewashm at gmail.com> wrote:
>>  Hi all,
>>
>>  I have a data set represented by the following sample.
>>
>> I want flag records of an individual as "N", if  if the tag column of
>> an individual  is equal to zero for the last  two years. So in the
>> following example, Alex1 records are flagged as "y",  On the other
>> hand Carla's records are flagged as "N" because all values of tag  for
>> Carla are zero. Another typical example is that Jon,  although the tag
>> values of Jon are greater than 0 it is flagged as "N", because his
>> record  are more than two years old.
>>
>> DF <- read.table(textConnection(" Name  year  tag
>> Alex1    2011         0
>> Alex1    2012         1
>> Alex1    2013         0
>> Alex1    2014         1
>>
>> Carla     2013      0
>> Carla     2014      0
>> Carla     2015      0
>> Carla     2012      0
>>
>> Tom     2014       1
>> Tom     2015       1
>>
>>  Jon      2010      1
>>  Jon     2011       1    "),header = TRUE)
>>
>> I want create another variable " Flag  with value Y or  N"  if an
>> individual has a  value greater than 0 in the tag column  for the last
>> two years  then  the flag value will be y otherwise  it n.
>>
>>
>> the outcome will be
>>   name   year      tag    Flag
>> Alex1    2011         0      y
>> Alex1    2012         1      y
>> Alex1    2013         0      y
>> Alex1    2014         1      y
>>
>> Carla     2013      0         n
>> Carla     2014      0         n
>> Carla     2015      0         n
>> Carla     2012      0         n
>>
>> Tom     2014       1          y
>> Tom     2015       1          y
>>
>>  Jon     2010       1          n
>>  Jon     2011       1           n
>>
>> Thank you in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Feb 29 08:56:11 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 29 Feb 2016 18:56:11 +1100
Subject: [R] Color of points in legend() ignored if plotting to PNG
In-Reply-To: <1D68B65E-20E7-4F18-8DC7-3BD8331A39F8@utoronto.ca>
References: <56D2EFCA.4020305@bebac.at>
	<1D68B65E-20E7-4F18-8DC7-3BD8331A39F8@utoronto.ca>
Message-ID: <CA+8X3fUm--D7RYePB+b6tNXWkzwNOH4VkMEDmwFGOkgj_AiuCQ@mail.gmail.com>

Works on linux

R version 3.2.3 (2015-12-10)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Fedora 23 (Twenty Three)

Jim

On Mon, Feb 29, 2016 at 1:45 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Works for me on Mac OS...
>
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.9.5 (Mavericks)
> [...]
>
>
>
> On Feb 28, 2016, at 8:02 AM, Helmut Schuetz <helmut.schuetz at bebac.at> wrote:
>
>> Dear all,
>>
>> if I plot to a PNG, the color of filled points (pch 21:25) in legend() is ignored (i.e., only the background color is used). It does not matter whether I specify the default png(bg="white") or png(bg="transparent").
>>
>> The example below
>>
>> x <- rnorm(10)
>> y <- rnorm(10)
>> plot(x, y, pch = 21, cex = 1.5,
>>  xlim = range(x, y) * 1.2, ylim = range(x, y)*1.2,
>>  col = "black", bg = "lightgrey")
>> legend("topleft", legend = "foo", inset = 0.02,
>>  bg = "white", pch = 21, pt.cex = 1.5,
>>  col = "black", pt.bg = "lightgrey")
>>
>> works as desired on windows(...) but fails to show the color in the legend on png(...).
>>
>> Any suggestions?
>> Helmut
>>
>> Environment: x86_64-w64-mingw32/x64 (64-bit), R 3.2.3
>>
>> --
>> Ing. Helmut Schuetz
>> BEBAC - Consultancy Services for
>> Bioequivalence and Bioavailability Studies
>> Neubaugasse 36/11
>> 1070 Vienna, Austria
>> VAT No  ATU61115625
>> DUNS    300370568
>> tel     +43 1 2311746
>> mobile  +43 699 10792458
>> e-mail  helmut.schuetz at bebac.at
>> web     http://bebac.at/
>> contact http://bebac.at/Contact.htm
>> forum   http://forum.bebac.at/
>>
>> This e-mail is confidential and may also be legally privileged. If you
>> are not the intended recipient please reply to sender, do not disclose
>> its contents to any person and delete the e-mail. Any unauthorized
>> review, use, disclosure, copying or distribution is strictly prohibited.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Feb 29 09:25:39 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Feb 2016 08:25:39 +0000
Subject: [R] Color of points in legend() ignored if plotting to PNG
In-Reply-To: <56D2EFCA.4020305@bebac.at>
References: <56D2EFCA.4020305@bebac.at>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011B23@SRVEXCHMBX.precheza.cz>

Hi

Works on WXP too.

platform       i386-w64-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status         Under development (unstable)
major          3
minor          3.0
year           2015
month          06
day            15
svn rev        68521
language       R
version.string R Under development (unstable) (2015-06-15 r68521)
nickname       Unsuffered Consequences

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Helmut
> Schuetz
> Sent: Sunday, February 28, 2016 2:02 PM
> To: r-help at r-project.org
> Subject: [R] Color of points in legend() ignored if plotting to PNG
>
> Dear all,
>
> if I plot to a PNG, the color of filled points (pch 21:25) in legend()
> is ignored (i.e., only the background color is used). It does not
> matter whether I specify the default png(bg="white") or
> png(bg="transparent").
>
> The example below
>
> x <- rnorm(10)
> y <- rnorm(10)
> plot(x, y, pch = 21, cex = 1.5,
>    xlim = range(x, y) * 1.2, ylim = range(x, y)*1.2,
>    col = "black", bg = "lightgrey")
> legend("topleft", legend = "foo", inset = 0.02,
>    bg = "white", pch = 21, pt.cex = 1.5,
>    col = "black", pt.bg = "lightgrey")
>
> works as desired on windows(...) but fails to show the color in the
> legend on png(...).
>
> Any suggestions?
> Helmut
>
> Environment: x86_64-w64-mingw32/x64 (64-bit), R 3.2.3
>
> --
> Ing. Helmut Schuetz
> BEBAC - Consultancy Services for
> Bioequivalence and Bioavailability Studies Neubaugasse 36/11 1070
> Vienna, Austria VAT No  ATU61115625
> DUNS    300370568
> tel     +43 1 2311746
> mobile  +43 699 10792458
> e-mail  helmut.schuetz at bebac.at
> web     http://bebac.at/
> contact http://bebac.at/Contact.htm
> forum   http://forum.bebac.at/
>
> This e-mail is confidential and may also be legally privileged. If you
> are not the intended recipient please reply to sender, do not disclose
> its contents to any person and delete the e-mail. Any unauthorized
> review, use, disclosure, copying or distribution is strictly
> prohibited.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From kmnanus at gmail.com  Mon Feb 29 00:08:56 2016
From: kmnanus at gmail.com (KMNanus)
Date: Sun, 28 Feb 2016 18:08:56 -0500
Subject: [R] receiving Error: unexpected '='
Message-ID: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>

I?m a newbie and trying to execute this simple function in order to change wk 5 NA?s to wk 4 values for the dataset (ken) below.  Can someone pls tell me what I?m doing wrong?  The error msg is ?"rror: unexpected input in "new_week <- function(x,y) { ?
Even the ?E? is missing in the word ?Error."

new_week <- function(x,y) {
if x[is.na(x)] {
x = y
}
}

patient	wk1	wk2	wk3	wk4	wk5
A	1	2	4	6	8
B	2	3	NA	3	17
C	3	4	5	11	NA
D	4	NA	6	12	11
E	5	6	7	NA	21
F	6	7	8	3	NA
G	7	8	9	7	NA



Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From hiroysato at gmail.com  Mon Feb 29 09:43:48 2016
From: hiroysato at gmail.com (Hiroyuki Sato)
Date: Mon, 29 Feb 2016 08:43:48 +0000
Subject: [R] create function for compare two dataframe.
Message-ID: <CA+Tq-RoFXLRWzzAidAZ6_wgjBSHZSm_bkTgv-FZ3UUPfUiYr-A@mail.gmail.com>

Hello

I would like to create a funciton which is create new dataframe
for compare reslut of two dataframes.

  No.  COLUMN DF1  DF2
  "1"  "VAL1" "2"  "0" # <- compare ID1,VAL1
  "2"  "VAL2" "3"  "2" # <- comapre ID2,VAL2
  "3"  "VAL3" "4"  "2" # <- compare ID3,VAL3

s1 <- read.table("sample1.txt",header=T,sep=',')
s2 <- read.table("sample2.txt",header=T,sep=',')
comp_data(df1,df2)

sample1.txt
  ID,VAL1,VAL2,VAL3
  ID1,2,2,3
  ID2,0,3,3
  ID3,0,2,4

sample2.txt
  ID1,0,2,3
  ID2,0,2,3
  ID3,0,2,2

I created the functions, but I got the following error.
Could you tell me how to add new frame data?
Or alternative way?

  1: In `[<-.factor`(`*tmp*`, ri, value = "3") :
    invalid factor level, NA generated
  2: In `[<-.factor`(`*tmp*`, ri, value = "VAL3") :
    invalid factor level, NA generated
  3: In `[<-.factor`(`*tmp*`, ri, value = "4") :
    invalid factor level, NA generated



  comp_data <- function(df1,df2) {
    #
    # create null data.frame
    out <- data.frame(matrix(rep(NA,4),nrow=1))[numeric(0), ]
    colnames(out) <- c("ID","Site","df1","df2")

    # column names
    col_names <- colnames(df1)

    # col_size
    col_size <- ncol(df1)
    row_size <- nrow(df1)

    for( col in 2:col_size ){
      for( row in 1:row_size ){
        if( df1[row,col] != df2[row,col] ){
          out <-
rbind(out,c(df1[row,1],col_names[col],df1[row,col],df2[row,col]))
        }
      }
    }
    out
  }

Best regards.

	[[alternative HTML version deleted]]


From ross.chapman at ecogeonomix.com  Mon Feb 29 09:46:25 2016
From: ross.chapman at ecogeonomix.com (ross.chapman at ecogeonomix.com)
Date: Mon, 29 Feb 2016 19:46:25 +1100
Subject: [R] bnlearn and TAN network
Message-ID: <000e01d172cd$acbbb560$06332020$@ecogeonomix.com>

Hi all,

 

I have created a TAN network using bnlearn in R using the commands:

 

TAN <- tree.bayes(training.data,"classFFB")

fitted <- bn.fit(TAN,training.data,method="bayes")

 

where training.data is a dataframe with 6 variables.

 

I have produced a plot of the network using graphviz.plot:

graphviz.plot(TAN)

 

The graph shows arcs between each of the variables and the output node
(classFFB) along with internal nodes showing parent/child relations between
4 nodes.

 

However, when I look at the model in the TAN object and the conditional
probabilities in the fitted object, there is only one direct arc leading to
output node (classFFB) through a variable EST, all other relations act
through that arc.

 

Am I correct in interpreting that the all direct nodes except for
EST->classFFB which are shown in the graphviz.plot are not retained once the
model is trained. In which case, is there a way of showing the network after
training?

 

Thanks in advance

 

Ross


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 29 10:15:57 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Feb 2016 09:15:57 +0000
Subject: [R] create function for compare two dataframe.
In-Reply-To: <CA+Tq-RoFXLRWzzAidAZ6_wgjBSHZSm_bkTgv-FZ3UUPfUiYr-A@mail.gmail.com>
References: <CA+Tq-RoFXLRWzzAidAZ6_wgjBSHZSm_bkTgv-FZ3UUPfUiYr-A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011BB5@SRVEXCHMBX.precheza.cz>

Hi

You does not need to create function, you can use functions already available.

> s1<- read.table("clipboard", header=T, sep=",")
> s2<- read.table("clipboard", sep=",")

You presented second table without names.
> names(s2) <- names(s1)

> s1
     ID VAL1 VAL2 VAL3
1   ID1    2    2    3
2   ID2    0    3    3
3   ID3    0    2    4
> s2
     ID VAL1 VAL2 VAL3
1   ID1    0    2    3
2   ID2    0    2    3
3   ID3    0    2    2

You need to add a column in which you specify data frame and merge them
> s1$dat<-"df1"
> s2$dat<-"df2"
> s<-merge(s1,s2, all=T)

Now you need to reshape your data

> library(reshape2)

> s.m<-melt(s)
Using ID, dat as id variables
> s.m
      ID dat variable value
1    ID1 df1     VAL1     2
2    ID2 df2     VAL1     0
3    ID2 df1     VAL1     0
4    ID3 df2     VAL1     0
5    ID3 df1     VAL1     0
6    ID1 df2     VAL1     0
7    ID1 df1     VAL2     2
8    ID2 df2     VAL2     2
9    ID2 df1     VAL2     3
10   ID3 df2     VAL2     2
11   ID3 df1     VAL2     2
12   ID1 df2     VAL2     2
13   ID1 df1     VAL3     3
14   ID2 df2     VAL3     3
15   ID2 df1     VAL3     3
16   ID3 df2     VAL3     2
17   ID3 df1     VAL3     4
18   ID1 df2     VAL3     3

And cast the new structure.
> dcast(s.m, ID+variable~dat)
      ID variable df1 df2
1    ID1     VAL1   2  NA
2    ID1     VAL2   2  NA
3    ID1     VAL3   3  NA
4    ID2     VAL1   0   0
5    ID2     VAL2   3   2
6    ID2     VAL3   3   3
7    ID3     VAL1   0   0
8    ID3     VAL2   2   2
9    ID3     VAL3   4   2
10   ID1     VAL1  NA   0
11   ID1     VAL2  NA   2
12   ID1     VAL3  NA   3

This was the point that I was rather surprised but I found a reason. Your ID variable does not have 3 but four values - although ID1 looks the same, in one there is an extra space, therefore you have different ID1 in s1 from ID1 in s2.

That is why it is recommended to use dput() for exchanging data with others.

> str(s)
'data.frame':   6 obs. of  5 variables:
 $ ID  : Factor w/ 4 levels "  ID1","  ID2",..: 1 2 2 3 3 4
 $ VAL1: int  2 0 0 0 0 0
 $ VAL2: int  2 2 3 2 2 2
 $ VAL3: int  3 3 3 2 4 3
 $ dat : chr  "df1" "df2" "df1" "df2" ...

> s1$ID
[1]   ID1   ID2   ID3
Levels:   ID1   ID2   ID3
> s2$ID
[1] ID1     ID2   ID3
Levels:   ID2   ID3 ID1

> str(s1)
'data.frame':   3 obs. of  5 variables:
 $ ID  : Factor w/ 3 levels "  ID1","  ID2",..: 1 2 3
 $ VAL1: int  2 0 0
 $ VAL2: int  2 3 2
 $ VAL3: int  3 3 4
 $ dat : chr  "df1" "df1" "df1"
> str(s2)
'data.frame':   3 obs. of  5 variables:
 $ ID  : Factor w/ 3 levels "  ID2","  ID3",..: 3 1 2
 $ VAL1: int  0 0 0
 $ VAL2: int  2 2 2
 $ VAL3: int  3 3 2
 $ dat : chr  "df2" "df2" "df2"
>

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Hiroyuki Sato
> Sent: Monday, February 29, 2016 9:44 AM
> To: r-help at r-project.org
> Subject: [R] create function for compare two dataframe.
>
> Hello
>
> I would like to create a funciton which is create new dataframe for
> compare reslut of two dataframes.
>
>   No.  COLUMN DF1  DF2
>   "1"  "VAL1" "2"  "0" # <- compare ID1,VAL1
>   "2"  "VAL2" "3"  "2" # <- comapre ID2,VAL2
>   "3"  "VAL3" "4"  "2" # <- compare ID3,VAL3
>
> s1 <- read.table("sample1.txt",header=T,sep=',')
> s2 <- read.table("sample2.txt",header=T,sep=',')
> comp_data(df1,df2)
>
> sample1.txt
>   ID,VAL1,VAL2,VAL3
>   ID1,2,2,3
>   ID2,0,3,3
>   ID3,0,2,4
>
> sample2.txt
>   ID1,0,2,3
>   ID2,0,2,3
>   ID3,0,2,2
>
> I created the functions, but I got the following error.
> Could you tell me how to add new frame data?
> Or alternative way?
>
>   1: In `[<-.factor`(`*tmp*`, ri, value = "3") :
>     invalid factor level, NA generated
>   2: In `[<-.factor`(`*tmp*`, ri, value = "VAL3") :
>     invalid factor level, NA generated
>   3: In `[<-.factor`(`*tmp*`, ri, value = "4") :
>     invalid factor level, NA generated
>
>
>
>   comp_data <- function(df1,df2) {
>     #
>     # create null data.frame
>     out <- data.frame(matrix(rep(NA,4),nrow=1))[numeric(0), ]
>     colnames(out) <- c("ID","Site","df1","df2")
>
>     # column names
>     col_names <- colnames(df1)
>
>     # col_size
>     col_size <- ncol(df1)
>     row_size <- nrow(df1)
>
>     for( col in 2:col_size ){
>       for( row in 1:row_size ){
>         if( df1[row,col] != df2[row,col] ){
>           out <-
> rbind(out,c(df1[row,1],col_names[col],df1[row,col],df2[row,col]))
>         }
>       }
>     }
>     out
>   }
>
> Best regards.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marco.scutari at gmail.com  Mon Feb 29 10:23:49 2016
From: marco.scutari at gmail.com (Marco Scutari)
Date: Mon, 29 Feb 2016 09:23:49 +0000
Subject: [R] bnlearn and TAN network
In-Reply-To: <000e01d172cd$acbbb560$06332020$@ecogeonomix.com>
References: <000e01d172cd$acbbb560$06332020$@ecogeonomix.com>
Message-ID: <CA+RJqXXUB07g9E6i49YBFWmeSqXafcfuLV5TFXQjp37EbFaZew@mail.gmail.com>

Hi Ross,

On 29 February 2016 at 08:46,  <ross.chapman at ecogeonomix.com> wrote:
> The graph shows arcs between each of the variables and the output node
> (classFFB) along with internal nodes showing parent/child relations between
> 4 nodes.

Yes, that is as expected.

> However, when I look at the model in the TAN object and the conditional
> probabilities in the fitted object, there is only one direct arc leading to
> output node (classFFB) through a variable EST, all other relations act
> through that arc.

I am not sure how that could possibly happen, could you share the
print outut for a few nodes so that I can get some idea of what it is
going on?

> Am I correct in interpreting that the all direct nodes except for
> EST->classFFB which are shown in the graphviz.plot are not retained once the
> model is trained. In which case, is there a way of showing the network after
> training?

TAN does not do any sort of feature selection, so all the nodes should
be there. As for "showing the network after training", what kind of
plot are you looking for?

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From marco.scutari at gmail.com  Mon Feb 29 10:32:14 2016
From: marco.scutari at gmail.com (Marco Scutari)
Date: Mon, 29 Feb 2016 09:32:14 +0000
Subject: [R] Query in R.
In-Reply-To: <CALEe9tGgP7VGvwx1XG+heHh4HmAzRymy8H8rWi2WmkKw_zwoJg@mail.gmail.com>
References: <CALEe9tGgP7VGvwx1XG+heHh4HmAzRymy8H8rWi2WmkKw_zwoJg@mail.gmail.com>
Message-ID: <CA+RJqXXp2gme=SJuYw-VKMXOGwyVWo7ueDpLxLx06vJhZsX07g@mail.gmail.com>

Hi Rachana,

On 23 February 2016 at 12:38, Rachana Bagde <rachanabagde1996 at gmail.com> wrote:
> Can anyone please solve this query.
>
> http://stackoverflow.com/questions/35577484/cpquery-of-bnlearn-gives-0-for-every-event-and-evidence-in-r

I think there are several problems with your code.

1) Your variables are continuous, why are you fitting a naive Bayes classifier?

2) Assuming your variables are continuous, any single value for C is
going to have zero probability (the density may be positive, though).

3) Assuming you really want to fit a classifier, you should discretize
the variables into intervals first.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From jholtman at gmail.com  Mon Feb 29 10:43:06 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 29 Feb 2016 04:43:06 -0500
Subject: [R] receiving Error: unexpected '='
In-Reply-To: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
References: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
Message-ID: <CAAxdm-71EPyzfLuA671iwBL8pb9=QiWQW1rPgk+j-14R20jS3g@mail.gmail.com>

Your syntax on the 'if' is wrong; you need 'if (..expression..)' -- you are
missing the parentheses.  Also read up on functions; any changes are local
-- you cannot change values outside the environment.  You should just
return values.  You also probably need to pass in the dataframe you want to
make changes to.

Probably what you want is:

new_week <- function(df, x, y){
   # x & y are character strings with the names of the columns to
check/change
   df[[x]][is.na(df[[x]])] <- df[[y]][is.na(df[[x]])]
   df  # return value
}

# then call with assignment of the result
df <- new_week(df, 'wk5', 'wk4')




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Feb 28, 2016 at 6:08 PM, KMNanus <kmnanus at gmail.com> wrote:

> I?m a newbie and trying to execute this simple function in order to change
> wk 5 NA?s to wk 4 values for the dataset (ken) below.  Can someone pls tell
> me what I?m doing wrong?  The error msg is ?"rror: unexpected input in
> "new_week <- function(x,y) { ?
> Even the ?E? is missing in the word ?Error."
>
> new_week <- function(x,y) {
> if x[is.na(x)] {
> x = y
> }
> }
>
> patient wk1     wk2     wk3     wk4     wk5
> A       1       2       4       6       8
> B       2       3       NA      3       17
> C       3       4       5       11      NA
> D       4       NA      6       12      11
> E       5       6       7       NA      21
> F       6       7       8       3       NA
> G       7       8       9       7       NA
>
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 29 10:46:05 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Feb 2016 09:46:05 +0000
Subject: [R] receiving Error: unexpected '='
In-Reply-To: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
References: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011BE7@SRVEXCHMBX.precheza.cz>

Hi.

It seems to me that you are doing wrong almost everything, sorry.

First to your syntax error. "if" is the function and it needs to be called as such.

new_week <- function(x,y) {
if (x[is.na(x)]) {
x = y
}
}

But if you resolve this you would get

> new_week(s1$wk5, s1$wk4)
Error in if (x[is.na(x)]) { : argument is not interpretable as logical
In addition: Warning message:
In if (x[is.na(x)]) { :
  the condition has length > 1 and only the first element will be used

"if" expects logical input but x[is.na(x)] is not logical, it is a selection of values based on logical condition.

But there are more conceptual mistakes. It is not a good idea try to change values of the object inside function. It can be done with ?<<- but I vote strongly against it.

I would change values on fly by
n <- which(is.na(ken$wk5))
ken$wk5[n] <- ken$wk4[n]

or

ken[,6] <- ifelse(is.na(ken[,6]), ken[,5], ken[,6])

or you can put it in function
new_week <- function(colin, colout) {
 ifelse(is.na(ken[,colin]), ken[,colout], ken[,colin])}
}

but there is not much sense in it, as you need to call it like.

ken$wk5 <- new_week(6,5)

Of course, you can modify this function to accept character vectors as subscripts but as I pointed out it does not make much sense to put such simple operation to a function.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of KMNanus
> Sent: Monday, February 29, 2016 12:09 AM
> To: r-help at r-project.org
> Subject: [R] receiving Error: unexpected '='
>
> I?m a newbie and trying to execute this simple function in order to
> change wk 5 NA?s to wk 4 values for the dataset (ken) below.  Can
> someone pls tell me what I?m doing wrong?  The error msg is ?"rror:
> unexpected input in "new_week <- function(x,y) { ? Even the ?E? is
> missing in the word ?Error."
>
> new_week <- function(x,y) {
> if x[is.na(x)] {
> x = y
> }
> }
>
> patient       wk1     wk2     wk3     wk4     wk5
> A     1       2       4       6       8
> B     2       3       NA      3       17
> C     3       4       5       11      NA
> D     4       NA      6       12      11
> E     5       6       7       NA      21
> F     6       7       8       3       NA
> G     7       8       9       7       NA
>
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ross.chapman at ecogeonomix.com  Mon Feb 29 10:51:25 2016
From: ross.chapman at ecogeonomix.com (ross.chapman at ecogeonomix.com)
Date: Mon, 29 Feb 2016 20:51:25 +1100
Subject: [R] bnlearn and TAN network
In-Reply-To: <CA+RJqXXUB07g9E6i49YBFWmeSqXafcfuLV5TFXQjp37EbFaZew@mail.gmail.com>
References: <000e01d172cd$acbbb560$06332020$@ecogeonomix.com>
	<CA+RJqXXUB07g9E6i49YBFWmeSqXafcfuLV5TFXQjp37EbFaZew@mail.gmail.com>
Message-ID: <000301d172d6$c0f0f640$42d2e2c0$@ecogeonomix.com>

Hi Marco

Thanks for your quick response

>-----Original Message-----
>From: Marco Scutari [mailto:marco.scutari at gmail.com] 
>Sent: Monday, 29 February 2016 8:24 PM
>To: ross.chapman at ecogeonomix.com
>Cc: r-help <r-help at r-project.org>
>Subject: Re: [R] bnlearn and TAN network
>
>Hi Ross,
>
>On 29 February 2016 at 08:46,  <ross.chapman at ecogeonomix.com> wrote:
>> The graph shows arcs between each of the variables and the output node
>> (classFFB) along with internal nodes showing parent/child relations 
>> between
>> 4 nodes.
>
>Yes, that is as expected.
>
>> However, when I look at the model in the TAN object and the 
> >conditional probabilities in the fitted object, there is only one 
>> direct arc leading to output node (classFFB) through a variable EST, 
>> all other relations act through that arc.
>
>I am not sure how that could possibly happen, could you share the print outut for a few nodes so that I can get some idea of what it is going on?

When I look at the model in Tan I get this output:

> TAN

  Bayesian network Classifier

  model:
   [classFFB][matureTreeData.ESTATE|classFFB][matureTreeData.YEAR|classFFB:matureTreeData.ESTATE][matureTreeData.SMG|classFFB:matureTreeData.ESTATE]
   [classNPKMg3YW_IN|classFFB:matureTreeData.YEAR][classHarvIntensity|classFFB:matureTreeData.YEAR]
  nodes:                                 6 
  arcs:                                  9 
    undirected arcs:                     0 
    directed arcs:                       9 
  average markov blanket size:           3.00 
  average neighbourhood size:            3.00 
  average branching factor:              1.50 

  learning algorithm:                    TAN Bayes Classifier 
  mutual information estimator:          Maximum Likelihood (disc.) 
  training node:                         classFFB 
  tests used in the learning procedure:  10

The output node is classFFB.  My understanding is that the model only has one node linked directly to the output node: ][matureTreeData.ESTATE|classFFB].

Have I missed something here?

>
>> Am I correct in interpreting that the all direct nodes except for
>> EST->classFFB which are shown in the graphviz.plot are not retained 
>> EST->once the
>> model is trained. In which case, is there a way of showing the network 
>> after training?

>TAN does not do any sort of feature selection, so all the nodes should be there. As for "showing the network after training", what kind of plot are you looking for?

I was looking for  a plot which shows the learned network, an example of which I have attached.



>Cheers,
  >  Marco


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplotdemo.png
Type: image/png
Size: 6430 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160229/7fa207b1/attachment.png>

From marco.scutari at gmail.com  Mon Feb 29 11:11:36 2016
From: marco.scutari at gmail.com (Marco Scutari)
Date: Mon, 29 Feb 2016 10:11:36 +0000
Subject: [R] bnlearn and TAN network
In-Reply-To: <000301d172d6$c0f0f640$42d2e2c0$@ecogeonomix.com>
References: <000e01d172cd$acbbb560$06332020$@ecogeonomix.com>
	<CA+RJqXXUB07g9E6i49YBFWmeSqXafcfuLV5TFXQjp37EbFaZew@mail.gmail.com>
	<000301d172d6$c0f0f640$42d2e2c0$@ecogeonomix.com>
Message-ID: <CA+RJqXXPMqudfAXAtbXFpC9YVG76f4UrOX6-=ccMnLcC60DDfQ@mail.gmail.com>

Hi Ross,

On 29 February 2016 at 09:51,  <ross.chapman at ecogeonomix.com> wrote:
> The output node is classFFB.  My understanding is that the model only
> has one node linked directly to the output node:
> ][matureTreeData.ESTATE|classFFB].

Actually not, e.g.
[matureTreeData.YEAR|classFFB:matureTreeData.ESTATE] means
P(matureTreeData.YEAR | classFFB, matureTreeData.ESTATE). So all
variables depend on classFB.

> I was looking for  a plot which shows the learned network, an example of
> which I have attached.

That is the best you can get from bnlearn at the moment - although it
is possible in theory to produce a graph + barplots plot from
Rgraphviz. I have never managed to make it work, though.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From maechler at stat.math.ethz.ch  Mon Feb 29 11:14:16 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 29 Feb 2016 11:14:16 +0100
Subject: [R] Why does match() treat NaN's as compables; Bug or Feature?
In-Reply-To: <CAGxFJbTx0Z51Ak_EVo3NzZ85xA_B+=8h8+JR+8dAPZLtEnu7TQ@mail.gmail.com>
References: <CAOxuTqjnZm7V24sk1qJ=8kUEW=wLGDenU_yfc-tPUu+pjS87xg@mail.gmail.com>
	<CAGxFJbRtWHcA3hBkipRw+zac4DYb5W8EJx6JRcjKdUhz42i1QA@mail.gmail.com>
	<CAOxuTqhcyXupTi5707MA+OHDbsWptDpfa7gOvHMsGVAWYym5Mg@mail.gmail.com>
	<CAGxFJbTx0Z51Ak_EVo3NzZ85xA_B+=8h8+JR+8dAPZLtEnu7TQ@mail.gmail.com>
Message-ID: <22228.6648.484813.874892@stat.math.ethz.ch>

>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>     on Sat, 27 Feb 2016 19:06:05 -0800 writes:

    > (on list, since others might not have gotten it either).
    > OK, I get it now. It was I who misunderstood.

    > But isn't the bug in the **misuse** of match() in ecdf()
    > (by failing to specify the nomatch argument). Jeff says
    > comparisons with NaN should return an unordered result,
    > which NaN is afaics:

    >> NaN < 0
    > [1] NA
    >> NaN > 0
    > [1] NA

    > match() just does its thing:

    >> match(c(NA,NaN),c(1,2,NA,3,4,NaN,5))
    > [1] 3 6

    > It's up to the caller to use it correctly, which
    > apparently ecdf() fails to do.

    > Am I missing something here?

not much, if any.  

Let me still clarify :

1) This has *nothing* to do with match, and I am confused
   why nobody has mentioned this till now.

2) In

  x <- c(1,2,NA,3,4,NaN,5)
  Fn <- ecdf(x)

 there is no error: ecdf() does drop all NA/NaN from its input on purpose
 and returns the empirical CDF of the other elements:
 so Fn is identical (practically, not strictly formally) to

  Fn. <- ecdf(1:5)


3) The bug is really in the underlying C code of  approx() / approxfun()
   on which ecdf() and notably the function it creates (!)
   relies :

    > L <- approxfun(1:6, 1:6, method = "constant")
    > L( (2:10)/2)
    [1] 1 1 2 2 3 3 4 4 5
    > L( c(NaN, NA, 2:10)/2)
    [1]  5 NA  1  1  2  2  3  3  4  4  5

4) A fix for this bug has been committed to R-devel already, a
   a minute ago. [svn rev 70239]


Martin Maechler,
ETH Zurich









    > Bert Gunter

    > "The trouble with having an open mind is that people keep
    > coming along and sticking things into it."  -- Opus (aka
    > Berkeley Breathed in his "Bloom County" comic strip )


    > On Sat, Feb 27, 2016 at 3:49 PM, Jason Thorpe
    > <jdthorpe at gmail.com> wrote:
    >> The bug is that NaN is not part of any cumulative
    >> distribution...
    >> 
    >> -Jason sent from my mobile device
    >> 
    >> On Feb 27, 2016 3:34 PM, "Bert Gunter"
    >> <bgunter.4567 at gmail.com> wrote:
    >>> 
    >>> If I understand you correctly, the "bug" is that you do
    >>> not understand match(). See inline comment below and
    >>> note carefully the "Value" section of ?match.
    >>> 
    >>> Cheers, Bert
    >>> 
    >>> Bert Gunter
    >>> 
    >>> "The trouble with having an open mind is that people
    >>> keep coming along and sticking things into it."  -- Opus
    >>> (aka Berkeley Breathed in his "Bloom County" comic strip
    >>> )
    >>> 
    >>> 
    >>> On Sat, Feb 27, 2016 at 2:52 PM, Jason Thorpe
    >>> <jdthorpe at gmail.com> wrote: > For some reason `match()`
    >>> treats `NaN`'s as comparables by default:
    >>> >
    >>> >> x <- c(1,2,3,NaN,4,5) >> match(x,x) > [1] 1 2 3 4 5 6
    >>> >
    >>> > which I can override when using `match()` directly:
    >>> >
    >>> >> match(x,x,incomparables=NaN) > [1] 1 2 3 NA 5 6
    >>> >
    >>> > but not necessarily when calling a function that uses
    >>> `match()` > internally:
    >>> >
    >>> >> stats::ecdf(x)(x) > [1] 0.2 0.4 0.6 0.8 0.8 1.0
    >>> >
    >>> > Obviously there are workarounds for any given
    >>> scenario, but the bigger > problem is that this behavior
    >>> causes difficult to discover bugs.  For > example, the
    >>> behavior of stats::ecdf is definitely a bug introduced
    >>> by > it's > use of `match()` (unless you think NaN == 4
    >>> is correct).
    >>> 
    >>> No, you misunderstand. match() returns the POSITION of
    >>> the match, and clearly NaN in the 4th position of table
    >>> =x matches NaN in x. e.g.
    >>> 
    >>> > match(c(x,NaN),x) [1] 1 2 3 4 5 6 4
    >>> 
    >>> 
    >>> 
    >>> >
    >>> > Is there a good reason that NaN's are treated as
    >>> comparables by match(), > or > his this a bug?
    >>> >
    >>> > For reference, I'm using R version 3.2.3
    >>> >
    >>> > -Jason
    >>> >
    >>> > [[alternative HTML version deleted]]
    >>> >
    >>> > ______________________________________________ >
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >>> more, see > https://stat.ethz.ch/mailman/listinfo/r-help
    >>> > PLEASE do read the posting guide >
    >>> http://www.R-project.org/posting-guide.html > and
    >>> provide commented, minimal, self-contained, reproducible
    >>> code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Feb 29 11:17:51 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 29 Feb 2016 02:17:51 -0800
Subject: [R] receiving Error: unexpected '='
In-Reply-To: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
References: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
Message-ID: <2050E961-4D6D-4291-B5FB-BD58BA04A740@dcn.davis.ca.us>

"if" is not vectorized... it only works on length 1 test values. However,  if you do use it,  it absolutely requires parentheses... if ( test ) { truecode }.

I think you want "ifelse" which is vectorized... something like

ifelse( is.na( x ), y, x )

Read the help pages ?if and ?ifelse. 

I don't know about the missing "E" in the error message... you might have corrupted your code with unicode or other non-ASCII characters by using a word processor rather than a text editor. 
-- 
Sent from my phone. Please excuse my brevity.

On February 28, 2016 3:08:56 PM PST, KMNanus <kmnanus at gmail.com> wrote:
>I?m a newbie and trying to execute this simple function in order to
>change wk 5 NA?s to wk 4 values for the dataset (ken) below.  Can
>someone pls tell me what I?m doing wrong?  The error msg is ?"rror:
>unexpected input in "new_week <- function(x,y) { ?
>Even the ?E? is missing in the word ?Error."
>
>new_week <- function(x,y) {
>if x[is.na(x)] {
>x = y
>}
>}
>
>patient	wk1	wk2	wk3	wk4	wk5
>A	1	2	4	6	8
>B	2	3	NA	3	17
>C	3	4	5	11	NA
>D	4	NA	6	12	11
>E	5	6	7	NA	21
>F	6	7	8	3	NA
>G	7	8	9	7	NA
>
>
>
>Ken
>kmnanus at gmail.com
>914-450-0816 (tel)
>347-730-4813 (fax)
>
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From hiroysato at gmail.com  Mon Feb 29 12:04:27 2016
From: hiroysato at gmail.com (Hiroyuki Sato)
Date: Mon, 29 Feb 2016 11:04:27 +0000
Subject: [R] create function for compare two dataframe.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011BB5@SRVEXCHMBX.precheza.cz>
References: <CA+Tq-RoFXLRWzzAidAZ6_wgjBSHZSm_bkTgv-FZ3UUPfUiYr-A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011BB5@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+Tq-Roy+qbXRdy_x4p5qGN7L+jm__LNVqX03koy3GewsQAFwA@mail.gmail.com>

Hello Petr.

Thank you for replying.
Your step is better than my step!.

I added one step

> s.dcast <- dcast(s.m, ID+variable~dat)
> subset(s.dcast,df1!=df2)
   ID variable df1 df2
1 ID1     VAL1   2   0
5 ID2     VAL2   3   2
9 ID3     VAL3   4   2

This output is what I wanted!!.


P.S.

When I asked this question, I used indent for readability.
So maybe it was added extra space.
I executed same command. It has no extra space.

> str(s1)
'data.frame': 3 obs. of  4 variables:
 $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
 $ VAL1: int  2 0 0
 $ VAL2: int  2 3 2
 $ VAL3: int  3 3 4
> str(s2)
'data.frame': 3 obs. of  4 variables:
 $ ID  : Factor w/ 3 levels "ID1","ID2","ID3": 1 2 3
 $ VAL1: int  0 0 0
 $ VAL2: int  2 2 2
 $ VAL3: int  3 3 2

Best regards.


2016?2?29?(?) 18:16 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> You does not need to create function, you can use functions already
> available.
>
> > s1<- read.table("clipboard", header=T, sep=",")
> > s2<- read.table("clipboard", sep=",")
>
> You presented second table without names.
> > names(s2) <- names(s1)
>
> > s1
>      ID VAL1 VAL2 VAL3
> 1   ID1    2    2    3
> 2   ID2    0    3    3
> 3   ID3    0    2    4
> > s2
>      ID VAL1 VAL2 VAL3
> 1   ID1    0    2    3
> 2   ID2    0    2    3
> 3   ID3    0    2    2
>
> You need to add a column in which you specify data frame and merge them
> > s1$dat<-"df1"
> > s2$dat<-"df2"
> > s<-merge(s1,s2, all=T)
>
> Now you need to reshape your data
>
> > library(reshape2)
>
> > s.m<-melt(s)
> Using ID, dat as id variables
> > s.m
>       ID dat variable value
> 1    ID1 df1     VAL1     2
> 2    ID2 df2     VAL1     0
> 3    ID2 df1     VAL1     0
> 4    ID3 df2     VAL1     0
> 5    ID3 df1     VAL1     0
> 6    ID1 df2     VAL1     0
> 7    ID1 df1     VAL2     2
> 8    ID2 df2     VAL2     2
> 9    ID2 df1     VAL2     3
> 10   ID3 df2     VAL2     2
> 11   ID3 df1     VAL2     2
> 12   ID1 df2     VAL2     2
> 13   ID1 df1     VAL3     3
> 14   ID2 df2     VAL3     3
> 15   ID2 df1     VAL3     3
> 16   ID3 df2     VAL3     2
> 17   ID3 df1     VAL3     4
> 18   ID1 df2     VAL3     3
>
> And cast the new structure.
> > dcast(s.m, ID+variable~dat)
>       ID variable df1 df2
> 1    ID1     VAL1   2  NA
> 2    ID1     VAL2   2  NA
> 3    ID1     VAL3   3  NA
> 4    ID2     VAL1   0   0
> 5    ID2     VAL2   3   2
> 6    ID2     VAL3   3   3
> 7    ID3     VAL1   0   0
> 8    ID3     VAL2   2   2
> 9    ID3     VAL3   4   2
> 10   ID1     VAL1  NA   0
> 11   ID1     VAL2  NA   2
> 12   ID1     VAL3  NA   3
>
> This was the point that I was rather surprised but I found a reason. Your
> ID variable does not have 3 but four values - although ID1 looks the same,
> in one there is an extra space, therefore you have different ID1 in s1 from
> ID1 in s2.
>
> That is why it is recommended to use dput() for exchanging data with
> others.
>
> > str(s)
> 'data.frame':   6 obs. of  5 variables:
>  $ ID  : Factor w/ 4 levels "  ID1","  ID2",..: 1 2 2 3 3 4
>  $ VAL1: int  2 0 0 0 0 0
>  $ VAL2: int  2 2 3 2 2 2
>  $ VAL3: int  3 3 3 2 4 3
>  $ dat : chr  "df1" "df2" "df1" "df2" ...
>
> > s1$ID
> [1]   ID1   ID2   ID3
> Levels:   ID1   ID2   ID3
> > s2$ID
> [1] ID1     ID2   ID3
> Levels:   ID2   ID3 ID1
>
> > str(s1)
> 'data.frame':   3 obs. of  5 variables:
>  $ ID  : Factor w/ 3 levels "  ID1","  ID2",..: 1 2 3
>  $ VAL1: int  2 0 0
>  $ VAL2: int  2 3 2
>  $ VAL3: int  3 3 4
>  $ dat : chr  "df1" "df1" "df1"
> > str(s2)
> 'data.frame':   3 obs. of  5 variables:
>  $ ID  : Factor w/ 3 levels "  ID2","  ID3",..: 3 1 2
>  $ VAL1: int  0 0 0
>  $ VAL2: int  2 2 2
>  $ VAL3: int  3 3 2
>  $ dat : chr  "df2" "df2" "df2"
> >
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Hiroyuki Sato
> > Sent: Monday, February 29, 2016 9:44 AM
> > To: r-help at r-project.org
> > Subject: [R] create function for compare two dataframe.
> >
> > Hello
> >
> > I would like to create a funciton which is create new dataframe for
> > compare reslut of two dataframes.
> >
> >   No.  COLUMN DF1  DF2
> >   "1"  "VAL1" "2"  "0" # <- compare ID1,VAL1
> >   "2"  "VAL2" "3"  "2" # <- comapre ID2,VAL2
> >   "3"  "VAL3" "4"  "2" # <- compare ID3,VAL3
> >
> > s1 <- read.table("sample1.txt",header=T,sep=',')
> > s2 <- read.table("sample2.txt",header=T,sep=',')
> > comp_data(df1,df2)
> >
> > sample1.txt
> >   ID,VAL1,VAL2,VAL3
> >   ID1,2,2,3
> >   ID2,0,3,3
> >   ID3,0,2,4
> >
> > sample2.txt
> >   ID1,0,2,3
> >   ID2,0,2,3
> >   ID3,0,2,2
> >
> > I created the functions, but I got the following error.
> > Could you tell me how to add new frame data?
> > Or alternative way?
> >
> >   1: In `[<-.factor`(`*tmp*`, ri, value = "3") :
> >     invalid factor level, NA generated
> >   2: In `[<-.factor`(`*tmp*`, ri, value = "VAL3") :
> >     invalid factor level, NA generated
> >   3: In `[<-.factor`(`*tmp*`, ri, value = "4") :
> >     invalid factor level, NA generated
> >
> >
> >
> >   comp_data <- function(df1,df2) {
> >     #
> >     # create null data.frame
> >     out <- data.frame(matrix(rep(NA,4),nrow=1))[numeric(0), ]
> >     colnames(out) <- c("ID","Site","df1","df2")
> >
> >     # column names
> >     col_names <- colnames(df1)
> >
> >     # col_size
> >     col_size <- ncol(df1)
> >     row_size <- nrow(df1)
> >
> >     for( col in 2:col_size ){
> >       for( row in 1:row_size ){
> >         if( df1[row,col] != df2[row,col] ){
> >           out <-
> > rbind(out,c(df1[row,1],col_names[col],df1[row,col],df2[row,col]))
> >         }
> >       }
> >     }
> >     out
> >   }
> >
> > Best regards.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Mon Feb 29 12:09:14 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 29 Feb 2016 12:09:14 +0100
Subject: [R] Version 3.2.3: package not available error with https
Message-ID: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>

Hi,

I recently installed version 3.2.3.  When I call

install.packages("RCurl")

I get a pop-up menu labelled "HTTPS CRAN Mirror" with a shortish list of
mirrors.  However, I don't seem to be able to reach any of these
mirrors, and always get an error like the following

Error in download.file(url, destfile = f, quiet = TRUE) : 
  unsupported URL scheme
Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
  unsupported URL scheme
Warning message:
package ?RCurl? is not available (for R version 3.2.3) 

If I choose the menu entry "(HTTP mirrors)" I get the list of HTTP
mirrors with which I am familiar from previous versions of R.  These
mirrors I can reach.

I assume I have some local, probably firewall-related problem, but can
someone confirm that the HTTPS mirrors do indeed work?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From pnsinha68 at gmail.com  Mon Feb 29 13:22:17 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Mon, 29 Feb 2016 17:52:17 +0530
Subject: [R] plot of different groups
Message-ID: <CADcgpJc6yAYTynyonAcLUL1cFMD-tDChOu_o8Bzuc8UQ_y4gYA@mail.gmail.com>

I have the following fields in table:
height, weight, gender
i want to plot height and weight of gender(males and females). The data
points needs to be marked in two different colors.
Regards
parth

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Feb 29 13:30:50 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 29 Feb 2016 13:30:50 +0100
Subject: [R] Version 3.2.3: package not available error with https
In-Reply-To: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
References: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <22228.14842.248708.295732@stat.math.ethz.ch>

>>>>> Loris Bennett <loris.bennett at fu-berlin.de>
>>>>>     on Mon, 29 Feb 2016 12:09:14 +0100 writes:

    > Hi, I recently installed version 3.2.3.  When I call

    > install.packages("RCurl")

    > I get a pop-up menu labelled "HTTPS CRAN Mirror" with a
    > shortish list of mirrors.  However, I don't seem to be
    > able to reach any of these mirrors, and always get an
    > error like the following

    > Error in download.file(url, destfile = f, quiet = TRUE) :
    > unsupported URL scheme Warning: unable to access index for
    > repository https://cran.uni-muenster.de/src/contrib:
    > unsupported URL scheme Warning message: package ?RCurl? is
    > not available (for R version 3.2.3)

    > If I choose the menu entry "(HTTP mirrors)" I get the list
    > of HTTP mirrors with which I am familiar from previous
    > versions of R.  These mirrors I can reach.

    > I assume I have some local, probably firewall-related
    > problem, 

yes.  I assume other may help you *if* give a bit more
information than just your version of R.

    > but can someone confirm that the HTTPS mirrors do indeed work?

Sure, I confirm.  They are nowadays used by default by probably
100s of 1000s of R users.

Martin Maechler, ETH Zurich

    > Cheers,

    > Loris

    > -- 
    > Dr. Loris Bennett (Mr.)  ZEDAT, Freie Universit?t Berlin
    > Email loris.bennett at fu-berlin.de

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Feb 29 13:38:45 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Feb 2016 07:38:45 -0500
Subject: [R] Version 3.2.3: package not available error with https
In-Reply-To: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
References: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <56D43BD5.2020102@gmail.com>

On 29/02/2016 6:09 AM, Loris Bennett wrote:
> Hi,
>
> I recently installed version 3.2.3.  When I call
>
> install.packages("RCurl")
>
> I get a pop-up menu labelled "HTTPS CRAN Mirror" with a shortish list of
> mirrors.  However, I don't seem to be able to reach any of these
> mirrors, and always get an error like the following
>
> Error in download.file(url, destfile = f, quiet = TRUE) :
>    unsupported URL scheme
> Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
>    unsupported URL scheme

That error message suggests the problem is in your build, e.g. possibly 
an out of date or missing libcurl.  What does capabilities("libcurl") say?

Duncan Murdoch


> Warning message:
> package ?RCurl? is not available (for R version 3.2.3)
>
> If I choose the menu entry "(HTTP mirrors)" I get the list of HTTP
> mirrors with which I am familiar from previous versions of R.  These
> mirrors I can reach.
>
> I assume I have some local, probably firewall-related problem, but can
> someone confirm that the HTTPS mirrors do indeed work?
>
> Cheers,
>
> Loris
>


From boris.steipe at utoronto.ca  Mon Feb 29 13:53:34 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 29 Feb 2016 07:53:34 -0500
Subject: [R] plot of different groups
In-Reply-To: <CADcgpJc6yAYTynyonAcLUL1cFMD-tDChOu_o8Bzuc8UQ_y4gYA@mail.gmail.com>
References: <CADcgpJc6yAYTynyonAcLUL1cFMD-tDChOu_o8Bzuc8UQ_y4gYA@mail.gmail.com>
Message-ID: <E7A110C7-5A45-4A28-94F2-888AED9CD5C8@utoronto.ca>

You need to pass a suitably constructed vector of color values to plot() via the parameter "col". Read the section on "Color Specification" for the par() function for details. Also read up on the parameter "pch" for which symbol to use, a filled circle will usually work well. See the help for points() for details. ifelse() will help you construct the vector. 

B.

On Feb 29, 2016, at 7:22 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:

> I have the following fields in table:
> height, weight, gender
> i want to plot height and weight of gender(males and females). The data
> points needs to be marked in two different colors.
> Regards
> parth
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Mon Feb 29 14:32:32 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 29 Feb 2016 14:32:32 +0100
Subject: [R] Version 3.2.3: package not available error with https
In-Reply-To: <56D43BD5.2020102@gmail.com> (Duncan Murdoch's message of "Mon,
	29 Feb 2016 07:38:45 -0500")
References: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
	<56D43BD5.2020102@gmail.com>
Message-ID: <87io17tzf3.fsf@hornfels.zedat.fu-berlin.de>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 29/02/2016 6:09 AM, Loris Bennett wrote:
>> Hi,
>>
>> I recently installed version 3.2.3.  When I call
>>
>> install.packages("RCurl")
>>
>> I get a pop-up menu labelled "HTTPS CRAN Mirror" with a shortish list of
>> mirrors.  However, I don't seem to be able to reach any of these
>> mirrors, and always get an error like the following
>>
>> Error in download.file(url, destfile = f, quiet = TRUE) :
>>    unsupported URL scheme
>> Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
>>    unsupported URL scheme
>
> That error message suggests the problem is in your build, e.g. possibly an out
> of date or missing libcurl.  What does capabilities("libcurl") say?

FALSE

It seems that R needs libcurl 7.28.0, but my platform (Scientific Linux
6.7) only provides version 7.19.7.

Thanks for the pointer.

Loris

> Duncan Murdoch
>
>
>> Warning message:
>> package ?RCurl? is not available (for R version 3.2.3)
>>
>> If I choose the menu entry "(HTTP mirrors)" I get the list of HTTP
>> mirrors with which I am familiar from previous versions of R.  These
>> mirrors I can reach.
>>
>> I assume I have some local, probably firewall-related problem, but can
>> someone confirm that the HTTPS mirrors do indeed work?
>>
>> Cheers,
>>
>> Loris
>>

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From divakarreddy.a at gmail.com  Mon Feb 29 14:40:07 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Mon, 29 Feb 2016 06:40:07 -0700
Subject: [R] Version 3.2.3: package not available error with https
In-Reply-To: <87io17tzf3.fsf@hornfels.zedat.fu-berlin.de>
References: <87vb57u61x.fsf@hornfels.zedat.fu-berlin.de>
	<56D43BD5.2020102@gmail.com>
	<87io17tzf3.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CALEm3d2q3nxf7aFr0uPxTuskrrKUL7eY9AYQ8xmQqDAPcbzA7g@mail.gmail.com>

Hi,

I'm not sure about your OS but I fixed while installing below packages on
CentOS for RCurl

yum install curl
yum install curl-devel

Thanks,
Divakar

On Mon, Feb 29, 2016 at 6:32 AM, Loris Bennett <loris.bennett at fu-berlin.de>
wrote:

> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
> > On 29/02/2016 6:09 AM, Loris Bennett wrote:
> >> Hi,
> >>
> >> I recently installed version 3.2.3.  When I call
> >>
> >> install.packages("RCurl")
> >>
> >> I get a pop-up menu labelled "HTTPS CRAN Mirror" with a shortish list of
> >> mirrors.  However, I don't seem to be able to reach any of these
> >> mirrors, and always get an error like the following
> >>
> >> Error in download.file(url, destfile = f, quiet = TRUE) :
> >>    unsupported URL scheme
> >> Warning: unable to access index for repository
> https://cran.uni-muenster.de/src/contrib:
> >>    unsupported URL scheme
> >
> > That error message suggests the problem is in your build, e.g. possibly
> an out
> > of date or missing libcurl.  What does capabilities("libcurl") say?
>
> FALSE
>
> It seems that R needs libcurl 7.28.0, but my platform (Scientific Linux
> 6.7) only provides version 7.19.7.
>
> Thanks for the pointer.
>
> Loris
>
> > Duncan Murdoch
> >
> >
> >> Warning message:
> >> package ?RCurl? is not available (for R version 3.2.3)
> >>
> >> If I choose the menu entry "(HTTP mirrors)" I get the list of HTTP
> >> mirrors with which I am familiar from previous versions of R.  These
> >> mirrors I can reach.
> >>
> >> I assume I have some local, probably firewall-related problem, but can
> >> someone confirm that the HTTPS mirrors do indeed work?
> >>
> >> Cheers,
> >>
> >> Loris
> >>
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Feb 29 15:50:17 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 29 Feb 2016 14:50:17 +0000
Subject: [R] Color of points in legend() ignored if plotting to PNG
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011B23@SRVEXCHMBX.precheza.cz>
References: <56D2EFCA.4020305@bebac.at>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5011B23@SRVEXCHMBX.precheza.cz>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D70E3A9@mb02.ads.tamu.edu>

Using

png("foo.png", 1200, 1200, res=200)
x <- rnorm(10)
y <- rnorm(10)
plot(x, y, pch = 21, cex = 1.5,
   xlim = range(x, y) * 1.2, ylim = range(x, y)*1.2,
   col = "black", bg = "lightgrey")
legend("topleft", legend = "foo", inset = 0.02,
   bg = "white", pch = 21, pt.cex = 1.5,
   col = "black", pt.bg = "lightgrey")
dev.off()

I'm not having any problem getting the grey on Win 8.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Monday, February 29, 2016 2:26 AM
To: Helmut Schuetz; r-help at r-project.org
Subject: Re: [R] Color of points in legend() ignored if plotting to PNG

Hi

Works on WXP too.

platform       i386-w64-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status         Under development (unstable)
major          3
minor          3.0
year           2015
month          06
day            15
svn rev        68521
language       R
version.string R Under development (unstable) (2015-06-15 r68521)
nickname       Unsuffered Consequences

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Helmut
> Schuetz
> Sent: Sunday, February 28, 2016 2:02 PM
> To: r-help at r-project.org
> Subject: [R] Color of points in legend() ignored if plotting to PNG
>
> Dear all,
>
> if I plot to a PNG, the color of filled points (pch 21:25) in legend()
> is ignored (i.e., only the background color is used). It does not
> matter whether I specify the default png(bg="white") or
> png(bg="transparent").
>
> The example below
>
> x <- rnorm(10)
> y <- rnorm(10)
> plot(x, y, pch = 21, cex = 1.5,
>    xlim = range(x, y) * 1.2, ylim = range(x, y)*1.2,
>    col = "black", bg = "lightgrey")
> legend("topleft", legend = "foo", inset = 0.02,
>    bg = "white", pch = 21, pt.cex = 1.5,
>    col = "black", pt.bg = "lightgrey")
>
> works as desired on windows(...) but fails to show the color in the
> legend on png(...).
>
> Any suggestions?
> Helmut
>
> Environment: x86_64-w64-mingw32/x64 (64-bit), R 3.2.3
>
> --
> Ing. Helmut Schuetz
> BEBAC - Consultancy Services for
> Bioequivalence and Bioavailability Studies Neubaugasse 36/11 1070
> Vienna, Austria VAT No  ATU61115625
> DUNS    300370568
> tel     +43 1 2311746
> mobile  +43 699 10792458
> e-mail  helmut.schuetz at bebac.at
> web     http://bebac.at/
> contact http://bebac.at/Contact.htm
> forum   http://forum.bebac.at/
>
> This e-mail is confidential and may also be legally privileged. If you
> are not the intended recipient please reply to sender, do not disclose
> its contents to any person and delete the e-mail. Any unauthorized
> review, use, disclosure, copying or distribution is strictly
> prohibited.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From Kristina.Loderer at psy.lmu.de  Sun Feb 28 19:25:23 2016
From: Kristina.Loderer at psy.lmu.de (Kristina Loderer)
Date: Sun, 28 Feb 2016 19:25:23 +0100
Subject: [R] R package for bootstrapping a mixed-design (between-within)
 MANOVA
Message-ID: <56D349A3020000D90003B8DD@f11-gwia-1.fak11.uni-muenchen.de>

Dear all,

new to R  - I have tried to search different package manuals, but seem
to be unable to find what I want...is there an R package that allows me
to compute bootstrapped MANOVAs for multivariate analysis containing two
factors, one of them being a repeated measures (within) factor, the
other one a simple between-subjects factor? I am interested in
bootstrapping F-values for potential interaction effects (using Pillai's
trace criterion) of both factors across a set of dependent variables.


Thanks!
Kristina

-----------------------------------------
Kristina Loderer
Ludwig-Maximilians-Universit?t M?nchen
Department Psychologie
Leopoldstr. 13
D-80802 M?nchen

Telefon: +49 (89) 2180-6047
Email: Kristina.Loderer at psy.lmu.de

-----------------------------------------


From bgunter.4567 at gmail.com  Mon Feb 29 17:07:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 08:07:40 -0800
Subject: [R] plot of different groups
In-Reply-To: <E7A110C7-5A45-4A28-94F2-888AED9CD5C8@utoronto.ca>
References: <CADcgpJc6yAYTynyonAcLUL1cFMD-tDChOu_o8Bzuc8UQ_y4gYA@mail.gmail.com>
	<E7A110C7-5A45-4A28-94F2-888AED9CD5C8@utoronto.ca>
Message-ID: <CAGxFJbSAs7p9tgi84wqdg8hDwQsqZZg_ot8C=V=fp-PRKRY60Q@mail.gmail.com>

... and if this is homework (it looks like it), you should know that
there is a no homework policy on this list.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 29, 2016 at 4:53 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> You need to pass a suitably constructed vector of color values to plot() via the parameter "col". Read the section on "Color Specification" for the par() function for details. Also read up on the parameter "pch" for which symbol to use, a filled circle will usually work well. See the help for points() for details. ifelse() will help you construct the vector.
>
> B.
>
> On Feb 29, 2016, at 7:22 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:
>
>> I have the following fields in table:
>> height, weight, gender
>> i want to plot height and weight of gender(males and females). The data
>> points needs to be marked in two different colors.
>> Regards
>> parth
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stbarningham at gmail.com  Mon Feb 29 16:20:52 2016
From: stbarningham at gmail.com (Thomas Barningham)
Date: Mon, 29 Feb 2016 12:20:52 -0300
Subject: [R] removing data based on date pairs in a separate data frame
Message-ID: <CAM5qaWcf2eqfANrSAno1OtZJwi89DKURLBzeYdj-CYG=ORjRdQ@mail.gmail.com>

Dear R users,

I have two data frames.

The first contains a date/time column and the concentration of a species:

head(mydata)
                         date                species
1      2016-01-31 23:59:53	-559.17		
2      2016-02-01 00:00:53	-556.68			
3      2016-02-01 00:01:53	-554.89		
4      2016-02-01 00:02:53	-556.72	
5      2016-02-01 00:03:53	-557.36		
6      2016-02-01 00:13:53	-561.42	


The second contains a list of start and end date pairs:

head(mydata_flag)
 	start_date	                end_date
1     2016-02-01 00:01:00	2016-02-01 00:03:00
2     2016-02-01 00:10:00	2016-02-01 00:15:00

I need to loop through all pairs of dates in the mydata_flag data
frame and then remove any data in the mydata data frame that is
between each of the date pairs.

The result for what I've presented here would look something like this:
                                  date       species
1	2016-01-31 23:59:53	-559.17		
2 	2016-02-01 00:00:53	-556.68			
3 	2016-02-01 00:03:53	-557.36		

I've searched high and low for answer to this. I know it's a
subsetting problem but I don't know how to approach it. Subset answers
tend to have one start end date pair and keep the data between the
dates. I need to remove data between the dates and I have a full data
frame of date/time pairs to consider. For background info: this is to
flag bad atmospheric data between times that there were known
instrumentation issues.

Thanks in advance,

Thomas

-- 
Thomas Barningham
Centre for Ocean and Atmospheric Sciences
School of Environmental Sciences
University of East Anglia
Norwich Research Park
Norwich
NR4 7TJ


From T.J.Pirie at pgr.reading.ac.uk  Mon Feb 29 14:08:23 2016
From: T.J.Pirie at pgr.reading.ac.uk (Tara Jane Pirie)
Date: Mon, 29 Feb 2016 13:08:23 +0000
Subject: [R] Help with SpaceCAP
Message-ID: <DB4PR01MB1570281BD7910608601358DA6BA0@DB4PR01MB157.eurprd01.prod.exchangelabs.com>


Hi there,

I am trying to load csv files into the spacecap program in R, but I keep getting either or both of the following error messages:


Error - mismatch in animal capture details and trap deployment details files : location id 29
not deployed on SO 22

Error in if (locso[loc, so + 3] == 0) { :
  missing value where TRUE/FALSE needed

I have checked the headings and only have 3 columns for the capture file and have double checked the trap locs. I have checked the working days for the flagged trap locations, but they are showing "1".

Please can you help me understand why I am getting these messages. I have attached the files I have been trying to upload.


Kind regards
Tara Pirie

Doctoral researcher - University of Reading
People and Wildlife Research group

Tel: +44 (0) 7340967711

From urayearth at gmail.com  Mon Feb 29 15:24:33 2016
From: urayearth at gmail.com (Fernando McRayearth)
Date: Mon, 29 Feb 2016 14:24:33 +0000
Subject: [R]  Loop Help
Message-ID: <56d454a1.e83cc20a.2a8a.ffffcfff@mx.google.com>

Need to create ascii maps for 10 species by writing a loop. So i have to have the vectors ready in the Global Environment, and the "raster map" so the information can be added. 

when writing the loop I am using the "paste" function because the only thing that changes in the vector is the name of the specie ( ens_KAPPA_F45_Ambystoma.altamirani, ens_KAPPA_F45_Ambystoma.lermaense), now the issue is that the result returns it like this "Ambystoma.lermaense" , and i don't know how to bring the vector without the "". any suggestions? thanks. 


CURRENT CODE NOT WORKING 
for (i in 1:length(amph_nome)){
orden=match(testo,0:93831)
amf1=paste("ens_KAPPA_F45_",amph_nome[i],sep="")

amf3=amf2[orden]
r1=Map
values(r1)=amf2
}


IF I WAS TO DO IT ONE BY ONE THIS VERSION WORKS 

orden=match(testo,0:93831)
amf0=ens_KAPPA_F45_Ambystoma.altamirani[orden]
r1=Map
values(r1)=amf0

writeRaster(r1, filename = "r1.asc",dataType=ascii,overwrite=TRUE)

Sent from Mail for Windows 10


	[[alternative HTML version deleted]]


From vmujumdar2 at sapient.com  Mon Feb 29 17:37:44 2016
From: vmujumdar2 at sapient.com (Vishal Vinayak Mujumdar 2)
Date: Mon, 29 Feb 2016 16:37:44 +0000
Subject: [R] Query - 'R' for commercial use
Message-ID: <108CDE6EAA9119408717BA20A1D5363A01579307@DLUMAIL01.sapient.com>

Hello Sir,

We are planning to recommend 'R' as solution for Micro Services  implementation in one of the ongoing project.

Please can you assist us with providing information pertaining to license cost , commercial use , usage , warranty etc.

Thanks & Regards,
Vishal Vinayak Mujumdar
Specialist - Integration
SCG Integration  Confluence<https://tools.sapient.com/confluence/display/ISCGCI/Integration+SCG+Home>  | VOX<https://vox.sapient.com/groups/enterprise-integration-shared-services>
Cell +1-617-331-4797
------
SapientNitro


The information transmitted is intended only for the per...{{dropped:12}}


From dwinsemius at comcast.net  Mon Feb 29 18:03:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 Feb 2016 09:03:12 -0800
Subject: [R] Loop Help
In-Reply-To: <56d454a1.e83cc20a.2a8a.ffffcfff@mx.google.com>
References: <56d454a1.e83cc20a.2a8a.ffffcfff@mx.google.com>
Message-ID: <8E5BE279-F71B-4643-9EF0-6F991D13707B@comcast.net>


> On Feb 29, 2016, at 6:24 AM, Fernando McRayearth <urayearth at gmail.com> wrote:
> 
> Need to create ascii maps for 10 species by writing a loop. So i have to have the vectors ready in the Global Environment, and the "raster map" so the information can be added. 
> 
> when writing the loop I am using the "paste" function because the only thing that changes in the vector is the name of the specie ( ens_KAPPA_F45_Ambystoma.altamirani, ens_KAPPA_F45_Ambystoma.lermaense), now the issue is that the result returns it like this "Ambystoma.lermaense" , and i don't know how to bring the vector without the "". any suggestions? thanks. 
> 
> 
> CURRENT CODE NOT WORKING 
> for (i in 1:length(amph_nome)){
> orden=match(testo,0:93831)
> amf1=paste("ens_KAPPA_F45_",amph_nome[i],sep="")

You are trying to use R as a macro language, a common source of difficulty for persons coming from other language backgrounds. If you have committed to this course (instead of using R's capacities to handle lists) then you will nee to use the `get` function which returns a data-objent when given a character vector name.

working <- get(amf1)

> 
> #amf3=amf2[orden]

# Perhaps (only guessing since you do not describe the algorithm desired
# and `Map` is not defined in your code and on my machine `Map` is a "funprog"-function

amf0 <- working[ orden ]


> r1=Map
> values(r1)=amf2
> }
> 
> 
> IF I WAS TO DO IT ONE BY ONE THIS VERSION WORKS 
> 
> orden=match(testo,0:93831)
> amf0=ens_KAPPA_F45_Ambystoma.altamirani[orden]
> r1=Map
> values(r1)=amf0
> 
> writeRaster(r1, filename = "r1.asc",dataType=ascii,overwrite=TRUE)
> 
> Sent from Mail for Windows 10
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Feb 29 18:04:42 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 Feb 2016 09:04:42 -0800
Subject: [R] Query - 'R' for commercial use
In-Reply-To: <108CDE6EAA9119408717BA20A1D5363A01579307@DLUMAIL01.sapient.com>
References: <108CDE6EAA9119408717BA20A1D5363A01579307@DLUMAIL01.sapient.com>
Message-ID: <CDBF3246-EA00-4140-8DF0-C249F65A8469@comcast.net>


> On Feb 29, 2016, at 8:37 AM, Vishal Vinayak Mujumdar 2 <vmujumdar2 at sapient.com> wrote:
> 
> Hello Sir,
> 
> We are planning to recommend 'R' as solution for Micro Services  implementation in one of the ongoing project.
> 
> Please can you assist us with providing information pertaining to license cost , commercial use , usage , warranty etc.


Cost == 0

At a running R console, type these characters:

license()


> 
> Thanks & Regards,
> Vishal Vinayak Mujumdar
> Specialist - Integration
> SCG Integration  Confluence<https://tools.sapient.com/confluence/display/ISCGCI/Integration+SCG+Home>  | VOX<https://vox.sapient.com/groups/enterprise-integration-shared-services>
> Cell +1-617-331-4797
> ------
> SapientNitro
> 
> 
> The information transmitted is intended only for the per...{{dropped:12}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Mon Feb 29 18:26:58 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 09:26:58 -0800
Subject: [R] Help with SpaceCAP
In-Reply-To: <DB4PR01MB1570281BD7910608601358DA6BA0@DB4PR01MB157.eurprd01.prod.exchangelabs.com>
References: <DB4PR01MB1570281BD7910608601358DA6BA0@DB4PR01MB157.eurprd01.prod.exchangelabs.com>
Message-ID: <CAGxFJbRP3Pa9Z9CZ-H_YMd8pvVrmoFvtRwhz7u0r9P5sO8x7iA@mail.gmail.com>

The email server for this list filters out most attachments, including yours.

.txt attachments are generally permitted. As you seem to have
successfully read the files into R, use dput() to include (a small
portion if the data are numerous) of the data in your email. Before
doing so, however, examine your data frame with str().

?dput
?str

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 29, 2016 at 5:08 AM, Tara Jane Pirie
<T.J.Pirie at pgr.reading.ac.uk> wrote:
>
> Hi there,
>
> I am trying to load csv files into the spacecap program in R, but I keep getting either or both of the following error messages:
>
>
> Error - mismatch in animal capture details and trap deployment details files : location id 29
> not deployed on SO 22
>
> Error in if (locso[loc, so + 3] == 0) { :
>   missing value where TRUE/FALSE needed
>
> I have checked the headings and only have 3 columns for the capture file and have double checked the trap locs. I have checked the working days for the flagged trap locations, but they are showing "1".
>
> Please can you help me understand why I am getting these messages. I have attached the files I have been trying to upload.
>
>
> Kind regards
> Tara Pirie
>
> Doctoral researcher - University of Reading
> People and Wildlife Research group
>
> Tel: +44 (0) 7340967711
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Mon Feb 29 18:28:42 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 29 Feb 2016 11:28:42 -0600
Subject: [R] Query - 'R' for commercial use
In-Reply-To: <108CDE6EAA9119408717BA20A1D5363A01579307@DLUMAIL01.sapient.com>
References: <108CDE6EAA9119408717BA20A1D5363A01579307@DLUMAIL01.sapient.com>
Message-ID: <CAAJSdjgXxhEBdm=vt=hDbz3A130Vhxf1cWyXQCHv3mmBQfLsPw@mail.gmail.com>

On Mon, Feb 29, 2016 at 10:37 AM, Vishal Vinayak Mujumdar 2 <
vmujumdar2 at sapient.com> wrote:

> Hello Sir,
>
> We are planning to recommend 'R' as solution for Micro Services
> implementation in one of the ongoing project.


?Sounds good to me.?



>


> Please can you assist us with providing information pertaining to license
> cost , commercial use , usage , warranty etc.
>

?licensing cost: completely free. The source is licensed under the GPL
version 2 or 3.

Commercial use: Allowed. Again ,no cost.? However, as an aside, remember
that R is a _interpreter_ and not a _compiler_. This means that your
customers, if any, must receive the source in order to execute it. This may
be a consideration. Or, if this is via a "web" site as a service, it may
not. Internal use would not be any concern.

?Usage: Don't do evil! is about the only "usage". But, in reality, you can
use it however you want within its capabilities. I wouldn't used it to do
real time work, personally. If you want to use it as control software for a
nuclear reactor, please tell me so I can get a dosage meter to wear.

Warranty: If it breaks, you get to keep both pieces. That is, there is _no_
warranty at all. You _might_ be able to find a R consulting company which
will give you some sort of contract and include some sort of warranty. But
that is up to the consultant or consulting company. There is a bug
reporting system _for the community_. Which means that you can report a
bug, but there is no guarantee that anyone will every address it. OK, this
is latter _very_ unlikely to occur because the programmers et al. behind R
are conscientious, caring people.? If you need a warranty, you'll need "3rd
party maintenance", if there is such from anyone.

Having said the above, there is no "damn it, I'm paying ???? for support
and I demand!! a fix NOW!" option (I've overhead this type of comment) .
I've even read message on some mailing lists similar to "I posted a
question 5 hours ago! Where's my answer? I'm in a hurry!!!! Don't you
people pay any attention?" That doesn't go over well here either.



>
> Thanks & Regards,
> Vishal Vinayak Mujumdar
> Specialist - Integration
> SCG Integration  Confluence<
> https://tools.sapient.com/confluence/display/ISCGCI/Integration+SCG+Home>
> | VOX<
> https://vox.sapient.com/groups/enterprise-integration-shared-services>
> Cell +1-617-331-4797
> ------
> SapientNitro
>


-- 
The man has the intellect of a lobotomized turtle.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 29 18:33:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 09:33:11 -0800
Subject: [R] removing data based on date pairs in a separate data frame
In-Reply-To: <CAM5qaWcf2eqfANrSAno1OtZJwi89DKURLBzeYdj-CYG=ORjRdQ@mail.gmail.com>
References: <CAM5qaWcf2eqfANrSAno1OtZJwi89DKURLBzeYdj-CYG=ORjRdQ@mail.gmail.com>
Message-ID: <CAGxFJbQeBqFXNm352pUCD_x5_aJW7Em+YHOsAXPX8ezm+Q5Tew@mail.gmail.com>

What is the format of your date columns? -- character, factor, POSIXxx,... ??

See ?str

to find out.

(Reply to the list, not just me; others are far more facile at dates than I am).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 29, 2016 at 7:20 AM, Thomas Barningham
<stbarningham at gmail.com> wrote:
> Dear R users,
>
> I have two data frames.
>
> The first contains a date/time column and the concentration of a species:
>
> head(mydata)
>                          date                species
> 1      2016-01-31 23:59:53      -559.17
> 2      2016-02-01 00:00:53      -556.68
> 3      2016-02-01 00:01:53      -554.89
> 4      2016-02-01 00:02:53      -556.72
> 5      2016-02-01 00:03:53      -557.36
> 6      2016-02-01 00:13:53      -561.42
>
>
> The second contains a list of start and end date pairs:
>
> head(mydata_flag)
>         start_date                      end_date
> 1     2016-02-01 00:01:00       2016-02-01 00:03:00
> 2     2016-02-01 00:10:00       2016-02-01 00:15:00
>
> I need to loop through all pairs of dates in the mydata_flag data
> frame and then remove any data in the mydata data frame that is
> between each of the date pairs.
>
> The result for what I've presented here would look something like this:
>                                   date       species
> 1       2016-01-31 23:59:53     -559.17
> 2       2016-02-01 00:00:53     -556.68
> 3       2016-02-01 00:03:53     -557.36
>
> I've searched high and low for answer to this. I know it's a
> subsetting problem but I don't know how to approach it. Subset answers
> tend to have one start end date pair and keep the data between the
> dates. I need to remove data between the dates and I have a full data
> frame of date/time pairs to consider. For background info: this is to
> flag bad atmospheric data between times that there were known
> instrumentation issues.
>
> Thanks in advance,
>
> Thomas
>
> --
> Thomas Barningham
> Centre for Ocean and Atmospheric Sciences
> School of Environmental Sciences
> University of East Anglia
> Norwich Research Park
> Norwich
> NR4 7TJ
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From raviteja2504 at gmail.com  Mon Feb 29 18:33:38 2016
From: raviteja2504 at gmail.com (Ravi Teja)
Date: Mon, 29 Feb 2016 23:03:38 +0530
Subject: [R] How to plot Geohash on a Map using R
Message-ID: <CADeUTLL5McDT3zgtaJHtWn_pixVUcaM_5iw97C6X=GHFG6oOsA@mail.gmail.com>

Hi,

I want to plot the following Geo-hashes on a map with labels as the
percentage against each Geohash.

Geohash % distribution
ttngh 26.14%
ttnfu 17.67%
ttng5 12.31%
ttnfg 11.50%
ttnfv 14.10%
ttngk 7.33%
ttngm 2.14%
ttngj 6.06%
ttnft 1.32%
ttngs 0.75%
ttngn 0.27%
ttng7 0.20%
ttnge 0.15%
ttnfe 0.00%
ttnfs 0.04%
ttnfy 0.01%
Please let me know how this can be achieved.

Thanks,
Ravi

	[[alternative HTML version deleted]]


From careyshan at gmail.com  Mon Feb 29 18:37:23 2016
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 29 Feb 2016 17:37:23 +0000
Subject: [R] divide polygon shapefile into 3 equal areas
Message-ID: <CA+jRDxAaG0fFyUJV29BrkfvTN7JimdSA9FM992Nkdk6gSB_=QA@mail.gmail.com>

Hi,

Is it possible to divide a polygon into 3 equal areas using R?

I cant seem to be able to do it in QGIS.

Thanks

-- 
Shane

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 29 18:42:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 09:42:14 -0800
Subject: [R] divide polygon shapefile into 3 equal areas
In-Reply-To: <CA+jRDxAaG0fFyUJV29BrkfvTN7JimdSA9FM992Nkdk6gSB_=QA@mail.gmail.com>
References: <CA+jRDxAaG0fFyUJV29BrkfvTN7JimdSA9FM992Nkdk6gSB_=QA@mail.gmail.com>
Message-ID: <CAGxFJbTyNbe1PpWuZFK_pkEnq6Wg4LJu9V3P81zj06LKXNcbzA@mail.gmail.com>

The r-sig-geo list might be a better place for this post.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 29, 2016 at 9:37 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> Is it possible to divide a polygon into 3 equal areas using R?
>
> I cant seem to be able to do it in QGIS.
>
> Thanks
>
> --
> Shane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Feb 29 18:42:55 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 09:42:55 -0800
Subject: [R] How to plot Geohash on a Map using R
In-Reply-To: <CADeUTLL5McDT3zgtaJHtWn_pixVUcaM_5iw97C6X=GHFG6oOsA@mail.gmail.com>
References: <CADeUTLL5McDT3zgtaJHtWn_pixVUcaM_5iw97C6X=GHFG6oOsA@mail.gmail.com>
Message-ID: <CAGxFJbQ3aXRQTOd3qmxE4Owkikh4H0Eoj=Q2kX29_t6=2=4ZPg@mail.gmail.com>

The r-sig-geo list might be a better place for this post.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 29, 2016 at 9:33 AM, Ravi Teja <raviteja2504 at gmail.com> wrote:
> Hi,
>
> I want to plot the following Geo-hashes on a map with labels as the
> percentage against each Geohash.
>
> Geohash % distribution
> ttngh 26.14%
> ttnfu 17.67%
> ttng5 12.31%
> ttnfg 11.50%
> ttnfv 14.10%
> ttngk 7.33%
> ttngm 2.14%
> ttngj 6.06%
> ttnft 1.32%
> ttngs 0.75%
> ttngn 0.27%
> ttng7 0.20%
> ttnge 0.15%
> ttnfe 0.00%
> ttnfs 0.04%
> ttnfy 0.01%
> Please let me know how this can be achieved.
>
> Thanks,
> Ravi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Mon Feb 29 18:51:30 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 29 Feb 2016 17:51:30 +0000
Subject: [R] divide polygon shapefile into 3 equal areas
In-Reply-To: <bd317c1a29094d32b8405fe2fb241465@EX-0-HT0.lancs.local>
References: <bd317c1a29094d32b8405fe2fb241465@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMSAVfA49ypiOSxs2VUQCAhueUbOFamVc2MzZ-4VqA=-A@mail.gmail.com>

On Mon, Feb 29, 2016 at 5:37 PM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> Is it possible to divide a polygon into 3 equal areas using R?

 Yes, in an infinite number of ways. Want to narrow it down?

 Specifically, you could slice it vertically, horizontally, or at any
angle between. You could chop it into squares and reassign them (did
you want **contiguous** areas?). You could choose a point and three
radii angles that divide the polygon into 3 equal areas in an infinite
number of ways.

 The rgeos package will help you chop polygons up, and then uniroot
can find the coordinates of lines or radii of angles that chop the
polygon first into 1/3 & 2/3 then chop the 2/3 into 1/2 and 1/2,
giving you three equal pieces.

> I cant seem to be able to do it in QGIS.

 If it can be done in R it can be done in Python and then it can be
done in QGIS...

Barry


From careyshan at gmail.com  Mon Feb 29 18:57:52 2016
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 29 Feb 2016 17:57:52 +0000
Subject: [R] divide polygon shapefile into 3 equal areas
In-Reply-To: <CANVKczMSAVfA49ypiOSxs2VUQCAhueUbOFamVc2MzZ-4VqA=-A@mail.gmail.com>
References: <bd317c1a29094d32b8405fe2fb241465@EX-0-HT0.lancs.local>
	<CANVKczMSAVfA49ypiOSxs2VUQCAhueUbOFamVc2MzZ-4VqA=-A@mail.gmail.com>
Message-ID: <CA+jRDxBwYasEFBjvEE7xxtqPmMyofqX_vGNtTiRx57KyH9izkg@mail.gmail.com>

ok thanks!!

I would like to slice it vertically and have 3 distinct areas of equal
area. So I need to chop it up into 3 areas of equal size essentially.

There is no tool to do it in QGIS!!

Thanks

On Mon, Feb 29, 2016 at 5:51 PM, Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

> On Mon, Feb 29, 2016 at 5:37 PM, Shane Carey <careyshan at gmail.com> wrote:
> > Hi,
> >
> > Is it possible to divide a polygon into 3 equal areas using R?
>
>  Yes, in an infinite number of ways. Want to narrow it down?
>
>  Specifically, you could slice it vertically, horizontally, or at any
> angle between. You could chop it into squares and reassign them (did
> you want **contiguous** areas?). You could choose a point and three
> radii angles that divide the polygon into 3 equal areas in an infinite
> number of ways.
>
>  The rgeos package will help you chop polygons up, and then uniroot
> can find the coordinates of lines or radii of angles that chop the
> polygon first into 1/3 & 2/3 then chop the 2/3 into 1/2 and 1/2,
> giving you three equal pieces.
>
> > I cant seem to be able to do it in QGIS.
>
>  If it can be done in R it can be done in Python and then it can be
> done in QGIS...
>
> Barry
>



-- 
Shane

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Feb 29 19:14:24 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 29 Feb 2016 13:14:24 -0500
Subject: [R] divide polygon shapefile into 3 equal areas
In-Reply-To: <CA+jRDxBwYasEFBjvEE7xxtqPmMyofqX_vGNtTiRx57KyH9izkg@mail.gmail.com>
References: <bd317c1a29094d32b8405fe2fb241465@EX-0-HT0.lancs.local>
	<CANVKczMSAVfA49ypiOSxs2VUQCAhueUbOFamVc2MzZ-4VqA=-A@mail.gmail.com>
	<CA+jRDxBwYasEFBjvEE7xxtqPmMyofqX_vGNtTiRx57KyH9izkg@mail.gmail.com>
Message-ID: <E3085B62-3B30-4169-AB36-6DF7C410F074@utoronto.ca>

Sounds like a fun little bit of code to write:

 - write a function that will return the area of a slice as a function of a parameter X that can vary between some bounds on your shape: left to right, or top to bottom etc. E.g. if you want to slice vertically, this could be the area of the part of your polygon between the leftmost point and a vertical line at X. (Adapt from here perhaps: https://stat.ethz.ch/pipermail/r-sig-geo/2015-July/023168.html)
 - find the roots of that function for f(X, shape) - 1/3 * totalArea and f(X, shape) - 2/3 * totalArea
   (https://stat.ethz.ch/R-manual/R-devel/library/stats/html/uniroot.html )

B.

On Feb 29, 2016, at 12:57 PM, Shane Carey <careyshan at gmail.com> wrote:

> ok thanks!!
> 
> I would like to slice it vertically and have 3 distinct areas of equal
> area. So I need to chop it up into 3 areas of equal size essentially.
> 
> There is no tool to do it in QGIS!!
> 
> Thanks
> 
> On Mon, Feb 29, 2016 at 5:51 PM, Barry Rowlingson <
> b.rowlingson at lancaster.ac.uk> wrote:
> 
>> On Mon, Feb 29, 2016 at 5:37 PM, Shane Carey <careyshan at gmail.com> wrote:
>>> Hi,
>>> 
>>> Is it possible to divide a polygon into 3 equal areas using R?
>> 
>> Yes, in an infinite number of ways. Want to narrow it down?
>> 
>> Specifically, you could slice it vertically, horizontally, or at any
>> angle between. You could chop it into squares and reassign them (did
>> you want **contiguous** areas?). You could choose a point and three
>> radii angles that divide the polygon into 3 equal areas in an infinite
>> number of ways.
>> 
>> The rgeos package will help you chop polygons up, and then uniroot
>> can find the coordinates of lines or radii of angles that chop the
>> polygon first into 1/3 & 2/3 then chop the 2/3 into 1/2 and 1/2,
>> giving you three equal pieces.
>> 
>>> I cant seem to be able to do it in QGIS.
>> 
>> If it can be done in R it can be done in Python and then it can be
>> done in QGIS...
>> 
>> Barry
>> 
> 
> 
> 
> -- 
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Mon Feb 29 19:35:09 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 29 Feb 2016 18:35:09 +0000
Subject: [R] divide polygon shapefile into 3 equal areas
In-Reply-To: <3d15e142d9804f4b89ac3cf4090e00d6@EX-0-HT0.lancs.local>
References: <bd317c1a29094d32b8405fe2fb241465@EX-0-HT0.lancs.local>
	<CANVKczMSAVfA49ypiOSxs2VUQCAhueUbOFamVc2MzZ-4VqA=-A@mail.gmail.com>
	<CA+jRDxBwYasEFBjvEE7xxtqPmMyofqX_vGNtTiRx57KyH9izkg@mail.gmail.com>
	<3d15e142d9804f4b89ac3cf4090e00d6@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOj4hxNGp9xGN38wMxbZFv0mLzHSJh2gM82tTinOQgMHA@mail.gmail.com>

This probably on the limit of acceptable LOCs on this list but here goes:

makeVchopper <- function(pol){
    bb = bbox(pol)
    delta = (bb[2,2] - bb[2,1])/10
    xmin = bb[1,1]-delta
    ymin = bb[2,1]-delta
    ymax = bb[2,2]+delta

    choppoly = function(xmax){
        readWKT(sprintf("POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))",
                        xmin,ymin, xmin,ymax, xmax,ymax, xmax,ymin, xmin,ymin))
    }
    choppoly
}

slicer <- function(pol, xmin, xmax){
    bb = bbox(pol)
    delta = (bb[2,2] - bb[2,1])/10
    ymax = bb[2,2] + delta
    ymin = bb[2,1] - delta
    r = readWKT(sprintf("POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))",
        xmin,ymin, xmin,ymax, xmax,ymax, xmax,ymin, xmin,ymin))
    gIntersection(pol,r)
}

chop_thirds <- function(pol, fractions=c(1/3, 2/3)){
    chopper = makeVchopper(pol)
    bb = bbox(pol)
    xmin = bb[1,1]
    xmax = bb[1,2]

    totalArea = gArea(pol)

    chopped_area = function(x){
        gArea(gIntersection(chopper(x),pol))
    }

    edges = lapply(fractions, function(fraction){
        target = totalArea * fraction
        target_function = function(x){
            chopped_area(x) - target
        }
        uniroot(target_function, lower=xmin, upper=xmax)$root
    })

    xdelta = (xmax-xmin)/10
    chops = matrix(c(xmin-xdelta, rep(edges,rep(2,length(edges))),
xmax+xdelta), ncol=2, byrow=TRUE)
    apply(chops, 1, function(edges){
        slicer(pol, edges[1], edges[2])
    })

}

Usage:

library(rgeos)
library(sp)
# sample data
pol <- readWKT(paste("POLYGON((-180 -20, -140 55, 10 0, -140 -60, -180
-20),","(-150 -20, -100 -10, -110 20, -150 -20))"))
plot(pol)

# now split

parts = chop_thirds(pol)
plot(pol)
plot(parts[[1]], add=TRUE, col=1)
plot(parts[[2]], add=TRUE, col=2)
plot(parts[[3]], add=TRUE, col=3)


if not convinced:

> gArea(parts[[1]])
[1] 3375
> gArea(parts[[2]])
[1] 3375.001
> gArea(parts[[3]])
[1] 3374.999

Can easily chop into quarters too... There's some redundancy in the
code, and I'm sure it can be improved...

Barry




On Mon, Feb 29, 2016 at 6:14 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Sounds like a fun little bit of code to write:
>
>  - write a function that will return the area of a slice as a function of a parameter X that can vary between some bounds on your shape: left to right, or top to bottom etc. E.g. if you want to slice vertically, this could be the area of the part of your polygon between the leftmost point and a vertical line at X. (Adapt from here perhaps: https://stat.ethz.ch/pipermail/r-sig-geo/2015-July/023168.html)
>  - find the roots of that function for f(X, shape) - 1/3 * totalArea and f(X, shape) - 2/3 * totalArea
>    (https://stat.ethz.ch/R-manual/R-devel/library/stats/html/uniroot.html )
>
> B.
>
> On Feb 29, 2016, at 12:57 PM, Shane Carey <careyshan at gmail.com> wrote:
>
>> ok thanks!!
>>
>> I would like to slice it vertically and have 3 distinct areas of equal
>> area. So I need to chop it up into 3 areas of equal size essentially.
>>
>> There is no tool to do it in QGIS!!
>>
>> Thanks
>>
>> On Mon, Feb 29, 2016 at 5:51 PM, Barry Rowlingson <
>> b.rowlingson at lancaster.ac.uk> wrote:
>>
>>> On Mon, Feb 29, 2016 at 5:37 PM, Shane Carey <careyshan at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> Is it possible to divide a polygon into 3 equal areas using R?
>>>
>>> Yes, in an infinite number of ways. Want to narrow it down?
>>>
>>> Specifically, you could slice it vertically, horizontally, or at any
>>> angle between. You could chop it into squares and reassign them (did
>>> you want **contiguous** areas?). You could choose a point and three
>>> radii angles that divide the polygon into 3 equal areas in an infinite
>>> number of ways.
>>>
>>> The rgeos package will help you chop polygons up, and then uniroot
>>> can find the coordinates of lines or radii of angles that chop the
>>> polygon first into 1/3 & 2/3 then chop the 2/3 into 1/2 and 1/2,
>>> giving you three equal pieces.
>>>
>>>> I cant seem to be able to do it in QGIS.
>>>
>>> If it can be done in R it can be done in Python and then it can be
>>> done in QGIS...
>>>
>>> Barry
>>>
>>
>>
>>
>> --
>> Shane
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Feb 29 19:44:49 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 29 Feb 2016 10:44:49 -0800
Subject: [R] removing data based on date pairs in a separate data frame
In-Reply-To: <CAM5qaWcf2eqfANrSAno1OtZJwi89DKURLBzeYdj-CYG=ORjRdQ@mail.gmail.com>
References: <CAM5qaWcf2eqfANrSAno1OtZJwi89DKURLBzeYdj-CYG=ORjRdQ@mail.gmail.com>
Message-ID: <CAF8bMcY_HLQkp1-ZgwW35s4HerS+Q26PfDRq3-mSP36Fkm4V_w@mail.gmail.com>

If your start/end pairs are not overlapping you can use findInterval() to
do this
pretty quickly.  E.g.,
isInABound <- function (x, low, high)
{
    stopifnot(length(low) == length(high))
    bounds <- rep(low, each = 2)
    bounds[seq(2, length(bounds), by = 2)] <- high
    stopifnot(!is.unsorted(bounds))
    findInterval(x, bounds)%%2 == 1
}
> i <- isInABound(mydata$date, mydata_flag$start_date, mydata_flag$end_date)
> mydata[!i,]
                 date species
1 2016-01-31 23:59:53 -559.17
2 2016-02-01 00:00:53 -556.68
5 2016-02-01 00:03:53 -557.36



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Feb 29, 2016 at 7:20 AM, Thomas Barningham <stbarningham at gmail.com>
wrote:

> Dear R users,
>
> I have two data frames.
>
> The first contains a date/time column and the concentration of a species:
>
> head(mydata)
>                          date                species
> 1      2016-01-31 23:59:53      -559.17
> 2      2016-02-01 00:00:53      -556.68
> 3      2016-02-01 00:01:53      -554.89
> 4      2016-02-01 00:02:53      -556.72
> 5      2016-02-01 00:03:53      -557.36
> 6      2016-02-01 00:13:53      -561.42
>
>
> The second contains a list of start and end date pairs:
>
> head(mydata_flag)
>         start_date                      end_date
> 1     2016-02-01 00:01:00       2016-02-01 00:03:00
> 2     2016-02-01 00:10:00       2016-02-01 00:15:00
>
> I need to loop through all pairs of dates in the mydata_flag data
> frame and then remove any data in the mydata data frame that is
> between each of the date pairs.
>
> The result for what I've presented here would look something like this:
>                                   date       species
> 1       2016-01-31 23:59:53     -559.17
> 2       2016-02-01 00:00:53     -556.68
> 3       2016-02-01 00:03:53     -557.36
>
> I've searched high and low for answer to this. I know it's a
> subsetting problem but I don't know how to approach it. Subset answers
> tend to have one start end date pair and keep the data between the
> dates. I need to remove data between the dates and I have a full data
> frame of date/time pairs to consider. For background info: this is to
> flag bad atmospheric data between times that there were known
> instrumentation issues.
>
> Thanks in advance,
>
> Thomas
>
> --
> Thomas Barningham
> Centre for Ocean and Atmospheric Sciences
> School of Environmental Sciences
> University of East Anglia
> Norwich Research Park
> Norwich
> NR4 7TJ
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rafaelcarneirocosta.rc at gmail.com  Mon Feb 29 20:08:53 2016
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Mon, 29 Feb 2016 16:08:53 -0300
Subject: [R] Seasonal Cointegration
Message-ID: <CAOy3Z4DnpkqcEejBtJYZhFvm1+MZfd-yK9UeuzE0pm=AsVLW=Q@mail.gmail.com>

Dear R users,

Where can I find the codes to Seasonal Coitegration tests (known as EGHL
test)? This test was presented on paper ?Seasonal Cointegration: The
Japanese Consumption Function.? (Engle, R.F., C.W.J. Granger, S. Hylleberg,
and H.S. Lee; 1993).

I am looking forward  any help.

Thanks in advance ,

Rafael Costa.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Feb 29 20:14:18 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 29 Feb 2016 14:14:18 -0500
Subject: [R] Seasonal Cointegration
In-Reply-To: <CAOy3Z4DnpkqcEejBtJYZhFvm1+MZfd-yK9UeuzE0pm=AsVLW=Q@mail.gmail.com>
References: <CAOy3Z4DnpkqcEejBtJYZhFvm1+MZfd-yK9UeuzE0pm=AsVLW=Q@mail.gmail.com>
Message-ID: <CAM_vju=yZmx7z8MzsmzMxU+JksqhvUJ+WFetvpGvc+k6NB0nvg@mail.gmail.com>

Checking Rseek.org turns up this discussion thread:
http://blog.gmane.org/gmane.comp.lang.r.r-metrics/month=20130601
which talks about the lack of that method in R.

Sarah

On Mon, Feb 29, 2016 at 2:08 PM, Rafael Costa
<rafaelcarneirocosta.rc at gmail.com> wrote:
> Dear R users,
>
> Where can I find the codes to Seasonal Coitegration tests (known as EGHL
> test)? This test was presented on paper ?Seasonal Cointegration: The
> Japanese Consumption Function.? (Engle, R.F., C.W.J. Granger, S. Hylleberg,
> and H.S. Lee; 1993).
>
> I am looking forward  any help.
>
> Thanks in advance ,
>
> Rafael Costa.
>


From gublaghose at gmail.com  Mon Feb 29 18:51:46 2016
From: gublaghose at gmail.com (Amur Ghose)
Date: Mon, 29 Feb 2016 23:21:46 +0530
Subject: [R] Packages for modelling microelectronic devices
Message-ID: <CAP7avEpVsenUdA9VHYr=egkGvjMcwemg4xhKchRhEpwK_crOMA@mail.gmail.com>

Hi,

Are there any R packages for modelling diodes, BJTs, MOSFETs and other
microelectronic devices ? I found a few for generic circuits and
that's about it.

I am trying to create a package of my own for these devices (
https://github.com/AmurG/transistor ) and would like to know if there
is any existing code in R ( or python ) that I could reference.


From bgunter.4567 at gmail.com  Mon Feb 29 20:54:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 11:54:45 -0800
Subject: [R] Packages for modelling microelectronic devices
In-Reply-To: <CAP7avEpVsenUdA9VHYr=egkGvjMcwemg4xhKchRhEpwK_crOMA@mail.gmail.com>
References: <CAP7avEpVsenUdA9VHYr=egkGvjMcwemg4xhKchRhEpwK_crOMA@mail.gmail.com>
Message-ID: <CAGxFJbTKm1J00MJatQzLTc9kszqvyc72R_Y0byoCgt=+vDh6xQ@mail.gmail.com>

Doubtful, but try searching on the rseek.org site.

Most R packages are concerned with the analysis and visualization of
(statistical) data. This sounds like more of a Matlab type capability
for deterministic modeling. But I am wholly ignorant about this, and
so may well be wrong. Ergo the search recommendation.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 29, 2016 at 9:51 AM, Amur Ghose <gublaghose at gmail.com> wrote:
> Hi,
>
> Are there any R packages for modelling diodes, BJTs, MOSFETs and other
> microelectronic devices ? I found a few for generic circuits and
> that's about it.
>
> I am trying to create a package of my own for these devices (
> https://github.com/AmurG/transistor ) and would like to know if there
> is any existing code in R ( or python ) that I could reference.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amwootte at ncsu.edu  Mon Feb 29 21:30:14 2016
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Mon, 29 Feb 2016 15:30:14 -0500
Subject: [R] legend for vectorplot in rasterVis
Message-ID: <CAOV3wDDn-oNOEuJzSQQrWaDDwoji1eXt=juCDhTuMLNc3GxZQw@mail.gmail.com>

All,

Your help with this is greatly appreciated!

I'm working with the vectorplot function in rasterVis to produce wind
vector maps (pretty much like the code in here -
https://rpubs.com/alobo/vectorplot), but I was wondering about a legend.

The vectors that vectorplot produces are wonderful.  What I'm trying to do
is get a scale legend to go with it.  In other words, have a vector outside
the main plot which provides a point of reference for the vectors in the
plot.  Something alike to what GrADS does (for those familiar), is what I'm
hoping to get to (for an example, the first chart on this page
http://www.wishingwork.com/grads/graphics-controls/vector-graphics.html)

I haven't seen this done yet with R, at least not from what I could find
with all the forums.  If anyone has an idea on how to do this, I
tremendously appreciate it!

Thanks all!

Adrienne

-- 
Adrienne Wootten
Ph.D Candidate / Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb 29 21:48:46 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 29 Feb 2016 12:48:46 -0800
Subject: [R] Packages for modelling microelectronic devices
In-Reply-To: <CAP7avEpVsenUdA9VHYr=egkGvjMcwemg4xhKchRhEpwK_crOMA@mail.gmail.com>
References: <CAP7avEpVsenUdA9VHYr=egkGvjMcwemg4xhKchRhEpwK_crOMA@mail.gmail.com>
Message-ID: <FF9BB713-AAA1-437E-8804-98803F9EBFA1@dcn.davis.ca.us>

Not aware of any, but there is a way for you to search CRAN:

library(sos)
???"diode"
-- 
Sent from my phone. Please excuse my brevity.

On February 29, 2016 9:51:46 AM PST, Amur Ghose <gublaghose at gmail.com> wrote:
>Hi,
>
>Are there any R packages for modelling diodes, BJTs, MOSFETs and other
>microelectronic devices ? I found a few for generic circuits and
>that's about it.
>
>I am trying to create a package of my own for these devices (
>https://github.com/AmurG/transistor ) and would like to know if there
>is any existing code in R ( or python ) that I could reference.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Feb 29 23:01:12 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 29 Feb 2016 16:01:12 -0600
Subject: [R] bootstrap glm
In-Reply-To: <B653E9EFB809DA4ABF9EFA0944845675059F78CF@BHEXMBX2.livad.liv.ac.uk>
References: <B653E9EFB809DA4ABF9EFA0944845675059F78CF@BHEXMBX2.livad.liv.ac.uk>
Message-ID: <CAN5YmCEq9PXvMG-9M7w-8Jr9fDBm3U-65upWuyspHMbNdC8yPg@mail.gmail.com>

?It's helpful if you post example data with your question, so R-help
readers can easily test your code?.  I created a fake data set with two x
variables for testing.  It's also helpful if you list the necessary
packages.  I assume that used the boot package.

You are dealing with two kinds of indices here, and I think you are
confusing them a bit in your code.  One index tells the program which x
columns to fit, another index tells the boot strapping part of the program
which rows to use.  I modified your code to do what I think you are trying
to do.  The results seem reasonable in this example.

Jean

# fake data
n <- 200
datasim <- data.frame(Y=sample(0:1, n, replace=TRUE), X1=rnorm(n),
X2=rnorm(n))

library(boot)

set.seed(111)

yfunction <- function(data, indices) {
  glm.snp1 <- glm(Y ~ ., family="binomial", data=data[indices, ])
  null <- glm.snp1$null.deviance
  residual <- glm.snp1$deviance
  return(null-residual)
}

resulty <- lapply(2:(ncol(datasim)), function(xcol) {
  boot(datasim[, c(1, xcol)], yfunction, R=100)
})

obsresult <- sapply(resulty, "[[", "t0")
bootresult <- sapply(resulty, "[[", "t")

# observed result
obsresult

# naive 95% bootstrap CI
apply(bootresult, 2, quantile, c(0.025, 0.975))


On Thu, Feb 25, 2016 at 9:59 AM, Hassan, Nazatulshima <
Nazatulshima.Hassan at liverpool.ac.uk> wrote:

> Hi
>
> I have a data with an outcome,Y and 10 predictors (X1-X10).
> My aim is to fit a logistic model to each of the predictors and calculate
> the deviance difference (dDeviance).
> And later on bootstrapping the dDeviance for 100 times (R=100).
> I tried the following function. It is calculating the original dDeviance
> correctly. But, when I checked the mean bootstrap values, it differs
> greatly from the original.
> I suspect I made a mistake with the bootstrapping function, which I need
> help with.
> I attached the script if you need to look at it.
>
> Thank you in advance.
>
>
> set.seed(111)
>
> yfunction <- function(data,indices)
> {
> glm.snp1 <- glm(Y~data[indices], family="binomial", data=datasim)
> null <- glm.snp1$null.deviance
> residual <- glm.snp1$deviance
> dDeviance <-(null-residual)
> return(dDeviance)
> }
>
> mybootstrap <- function(data)
> {
> boot(data,yfunction, R=100)
> }
>
> resulty <- lapply(datasim[,-1],function(x)mybootstrap(x))
> bootresult <- sapply(datasim[,-1],function(x)mybootstrap(x)$t)
> colMeans(bootresult)
>
>
>
> -shima-
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb 29 23:07:13 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 29 Feb 2016 14:07:13 -0800
Subject: [R] receiving Error: unexpected '='
In-Reply-To: <5694EECE-7FC8-4F19-86D5-47AE12BBDDD5@gmail.com>
References: <88BC2E47-B202-4D0B-87AA-6066C9075A66@gmail.com>
	<2050E961-4D6D-4291-B5FB-BD58BA04A740@dcn.davis.ca.us>
	<15C9577E-DFEF-43AE-A4F3-94FEAE9D96FD@gmail.com>
	<5694EECE-7FC8-4F19-86D5-47AE12BBDDD5@gmail.com>
Message-ID: <22ECCEFD-458C-493C-A560-D56F7182FE61@dcn.davis.ca.us>

Please keep the mailing list cc'd.

Why? Because that is what you are giving it... vectors, and that is how it is defined to work. Type 

?ifelse

at the R console and read the help. 

There are several ways to modify a data frame.  Some are

ken$wk5 <- ifelse( is.na( ken$wk5 ), ken$wk4, ken$wk5 )

ken$wk5 <- with( ken, ifelse( is.na( wk5 ), wk4, wk5 ) )

ken  <- within( ken, {
     wk5 <- ifelse( is.na( wk5 ), wk4, wk5 )
})

The ? shortcut to help is your friend. 
-- 
Sent from my phone. Please excuse my brevity.

On February 29, 2016 1:34:56 PM PST, KMNanus <kmnanus at gmail.com> wrote:
>Jeff - 
>
>Can you explain why ?ifelse? returns a vector?
>
>When I call > ken2 <- ifelse(is.na(ken$wk5), ken$wk4, ken$wk5)
>
>this is what?s returned - the values are correct but, obviously, I have
>to put it back into the df.
>
>> ken2
>[1]  8 17 11 11 21  3  7
>
>Ken
>kmnanus at gmail.com
>914-450-0816 (tel)
>347-730-4813 (fax)
>
>
>
>> On Feb 29, 2016, at 4:15 PM, KMNanus <kmnanus at gmail.com> wrote:
>> 
>> Jeff - 
>> 
>> ifelse is clearly the answer.  It works nicely and returns a vector
>which I can then reinsert into the data frame.  Is there a way that I
>can combine both steps - replacement of the NA?s and reinsertion into
>the data frame - at one time or am I better off just writing a function
>to do that?
>> 
>> 
>> Ken
>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> <image001.jpg>
>> 
>>> On Feb 29, 2016, at 5:17 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
>>> 
>>> "if" is not vectorized... it only works on length 1 test values.
>However, if you do use it, it absolutely requires parentheses... if (
>test ) { truecode }.
>>> 
>>> I think you want "ifelse" which is vectorized... something like
>>> 
>>> ifelse( is.na <http://is.na/>( x ), y, x )
>>> 
>>> Read the help pages ?if and ?ifelse. 
>>> 
>>> I don't know about the missing "E" in the error message... you might
>have corrupted your code with unicode or other non-ASCII characters by
>using a word processor rather than a text editor. 
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On February 28, 2016 3:08:56 PM PST, KMNanus <kmnanus at gmail.com
><mailto:kmnanus at gmail.com>> wrote:
>>> I?m a newbie and trying to execute this simple function in order to
>change wk 5 NA?s to wk 4 values for the dataset (ken) below.  Can
>someone pls tell me what I?m doing wrong?  The error msg is ?"rror:
>unexpected input in "new_week <- function(x,y) { ?
>>> Even the ?E? is missing in the word ?Error."
>>> 
>>> new_week <- function(x,y) {
>>> if x[is.na <http://is.na/>(x)] {
>>> x = y
>>> }
>>> }
>>> 
>>> patient wk1 wk2 wk3 wk4 wk5
>>> A 1 2 4 6 8
>>> B 2 3 NA 3 17
>>> C 3 4 5 11 NA
>>> D 4 NA 6 12 11
>>> E 5 6 7 NA 21
>>> F 6 7 8 3 NA
>>> G 7 8 9 7 NA
>>> 
>>> 
>>> 
>>> Ken
>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>> 914-450-0816 (tel)
>>> 347-730-4813 (fax)
>>> 
>>> 
>>> 
>>> 
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
><http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>> 

	[[alternative HTML version deleted]]


From caciquesamurai at gmail.com  Mon Feb 29 21:12:00 2016
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Mon, 29 Feb 2016 17:12:00 -0300
Subject: [R] Special sequence
Message-ID: <CAGtwFe2RwoJvSm4_4bgPQ=Y23TxC-MS9F2T=1ZkoZkJVZFCf0Q@mail.gmail.com>

Hello Helpers!

How to create a number sequence from1 to 3000, but usigm four numbers
like 0001, 0002...0102...3000.

Thanks in advanced,

Raoni

-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From sarah.goslee at gmail.com  Mon Feb 29 23:43:14 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 29 Feb 2016 17:43:14 -0500
Subject: [R] Special sequence
In-Reply-To: <CAGtwFe2RwoJvSm4_4bgPQ=Y23TxC-MS9F2T=1ZkoZkJVZFCf0Q@mail.gmail.com>
References: <CAGtwFe2RwoJvSm4_4bgPQ=Y23TxC-MS9F2T=1ZkoZkJVZFCf0Q@mail.gmail.com>
Message-ID: <CAM_vjumpaey10em32R2+2MQ7jtiYwK+2svZ1JtYFgO6U_uqjMA@mail.gmail.com>

> fourseq <- sprintf("%04d", 1:3000)
> head(fourseq)
[1] "0001" "0002" "0003" "0004" "0005" "0006"
> tail(fourseq)
[1] "2995" "2996" "2997" "2998" "2999" "3000"

Note that it has to be character to maintain the initial zeroes.

Sarah

On Mon, Feb 29, 2016 at 3:12 PM, Cacique Samurai
<caciquesamurai at gmail.com> wrote:
> Hello Helpers!
>
> How to create a number sequence from1 to 3000, but usigm four numbers
> like 0001, 0002...0102...3000.
>
> Thanks in advanced,
>
> Raoni
>


From Douglas.Federman at utoledo.edu  Mon Feb 29 23:58:46 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Mon, 29 Feb 2016 22:58:46 +0000
Subject: [R] Special sequence
In-Reply-To: <CAGtwFe2RwoJvSm4_4bgPQ=Y23TxC-MS9F2T=1ZkoZkJVZFCf0Q@mail.gmail.com>
References: <CAGtwFe2RwoJvSm4_4bgPQ=Y23TxC-MS9F2T=1ZkoZkJVZFCf0Q@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AFF5C46@msgdb20.utad.utoledo.edu>

You might look at the sprint function which is in base R

--
Better name for the general practitioner might be multispecialist. 
~Martin H. Fischer (1879-1962)


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cacique Samurai
Sent: Monday, February 29, 2016 3:12 PM
To: R help <r-help at r-project.org>
Subject: [R] Special sequence

Hello Helpers!

How to create a number sequence from1 to 3000, but usigm four numbers like 0001, 0002...0102...3000.

Thanks in advanced,

Raoni

--
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes Universidade Federal de Minas Gerais - UFMG Brasil rodrigues.raoni at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From John.Janmaat at ubc.ca  Mon Feb 29 23:54:56 2016
From: John.Janmaat at ubc.ca (Janmaat, John)
Date: Mon, 29 Feb 2016 22:54:56 +0000
Subject: [R] Copula Regression
Message-ID: <063E7F85C84B8C44A6D1A1C47E8728761BCC35DB@exch-ok-mbx01p.ead.ubc.ca>

Hello,

I'm trying to figure out how to run copula regressions in R.  I see a couple of packages that do specific versions, but I am hoping to be a bit more flexible.

My specific problem involves two ordered regressions (four levels each) that may be correlated.  Is there a package out there that can do copula regressions with arbitrary marginals?  Alternatively, is there a way to trick functions like GLM into returning observation specific CDF values given a guess for the parameters?

I would prefer to avoid coding this up, as I expect the more tested code I can use, the less likelihood for my own errors to mess up the results.

Thanks,

John.

----------
Dr. John Janmaat
Economics (Unit 8), IK Barber School of Arts and Sciences
The University of British Columbia
3333 University Way, Kelowna, BC


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 29 17:17:42 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Feb 2016 08:17:42 -0800
Subject: [R] R package for bootstrapping a mixed-design (between-within)
	MANOVA
In-Reply-To: <56D349A3020000D90003B8DD@f11-gwia-1.fak11.uni-muenchen.de>
References: <56D349A3020000D90003B8DD@f11-gwia-1.fak11.uni-muenchen.de>
Message-ID: <CAGxFJbQgMXapvGeJSGVFWYL707YP0H7qB5t6otnEewUV8ta92Q@mail.gmail.com>

R is a programming LANGUAGE. You can always write your own code (it is
not clear exactly how you would bootstrap, as this is not an iid error
structure), and there are many online courses and tutorials to help
you do so.  See here for some suggestions:
https://www.rstudio.com/resources/training/online-learning/#R

the Rseek.org website can also be useful to search for R packages and functions.

Finally, you might try posting to the r-sig-mixed-models list, as this
appears to be more directly relevant to your task.

HTH.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 28, 2016 at 10:25 AM, Kristina Loderer
<Kristina.Loderer at psy.lmu.de> wrote:
> Dear all,
>
> new to R  - I have tried to search different package manuals, but seem
> to be unable to find what I want...is there an R package that allows me
> to compute bootstrapped MANOVAs for multivariate analysis containing two
> factors, one of them being a repeated measures (within) factor, the
> other one a simple between-subjects factor? I am interested in
> bootstrapping F-values for potential interaction effects (using Pillai's
> trace criterion) of both factors across a set of dependent variables.
>
>
> Thanks!
> Kristina
>
> -----------------------------------------
> Kristina Loderer
> Ludwig-Maximilians-Universit?t M?nchen
> Department Psychologie
> Leopoldstr. 13
> D-80802 M?nchen
>
> Telefon: +49 (89) 2180-6047
> Email: Kristina.Loderer at psy.lmu.de
>
> -----------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


