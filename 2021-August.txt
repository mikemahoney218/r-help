From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Sun Aug  1 18:59:02 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Sun, 1 Aug 2021 16:59:02 +0000 (UTC)
Subject: [R] Help needed with gender_df
References: <93442086.1530709.1627837142818.ref@mail.yahoo.com>
Message-ID: <93442086.1530709.1627837142818@mail.yahoo.com>

Hello,?
when using the following code -?
gender_df(Test1, name_col = "First", year_col = "Year")

for the file attached below, I get the following result -?
# A tibble: 0 x 6# ... with 6 variables: name <chr>, proportion_male <dbl>, proportion_female <dbl>, gender <lgl>,#? ?year_min <dbl>, year_max <dbl>






| First |  | Year |
| Post R |  | 2012 |
| Kotulska K | 2012 |
| Zi W |  | 2012 |
| Suzuki K |  | 2012 |
| Lynch DR |  | 2012 |
| Paganoni S | 2012 |
| Nourbakhsh B | 2012 |
| Croop R |  | 2012 |
| Bril V |  | 2012 |
| Tan AH |  | 2012 |
| Benedict RHB | 2012 |
| Langeskov-Christensen M | 2012 |
| Chiaravalloti ND | 2012 |
| Zhang Y |  | 2012 |
| Bovis F |  | 2012 |
| Soul JS |  | 2012 |
| Mantegazza R | 2012 |
| Heatwole C | 2012 |
| Molhemi F | 2012 |
| Aggarwal R | 2012 |
| Chung JW |  | 2012 |
| Obermann M | 2012 |
| Albert V |  | 2012 |
| Picillo M |  | 2012 |
| Palace J |  | 2012 |
| Bogan RK |  | 2012 |
| Shoamanesh A | 2012 |
| Jaeckle KA | 2012 |
| Sakamoto S | 2012 |
| Barohn RJ |  | 2012 |
| Fehlings MG | 2012 |
| Barbieri F |  | 2012 |
| Klopstock T | 2012 |
| Martin AK |  | 2012 |
| Griffith R |  | 2012 |
| Maas RPPWM | 2012 |
| Santhosh AP | 2012 |
| Macdonald-Laurs E | 2012 |
| Guinchard M | 2012 |
| Luijten SPR | 2012 |
| Pagan FL |  | 2012 |
| Takeda A |  | 2012 |
| Shin YW |  | 2012 |
| DeLuca J |  | 2012 |
| Zhong F |  | 2012 |
| Toyoda K |  | 2012 |
| Song J |  | 2012 |
| Pan Y |  | 2012 |
| Molloy EN | 2012 |
| Heit JJ |  | 2012 |
| Bird LM |  | 2012 |
| Wu X |  | 2012 |
| Naismith RT | 2012 |
| Yaghi S |  | 2012 |
| Tekeoglu Tosun A | 2012 |
| Vieira-Yano B | 2012 |
| Malt?te D |  | 2012 |
| Gillving M |  | 2012 |
| Sylaja PN |  | 2012 |
| Sawada H |  | 2012 |
| van Dalen JW | 2012 |
| Meador KJ | 2012 |
| Cheshmavar M | 2012 |
| Liu MN |  | 2012 |
| Paprad T |  | 2012 |
| Hogue CW | 2012 |
| Filipovi? TN | 2012 |
| Weiss MD |  | 2012 |
| Bril V |  | 2012 |
| Ishigooka J | 2012 |
| Zhao J |  | 2012 |
| Christensen CE | 2012 |
| Zhang P |  | 2012 |
| Ford JH |  | 2012 |
| Ter Meulen BC | 2012 |
| Giannoni A | 2012 |
| Kuester-Gruber S | 2012 |
| Kumar A |  | 2012 |
| Dominiak M | 2012 |
| Mintun MA | 2012 |
| Guttuso T Jr | 2012 |
| Al-Karagholi MA | 2012 |
| De Icco R |  | 2012 |
| Akhbari Ziegler S | 2012 |
| Hirata K |  | 2012 |
| Schreiner L | 2012 |
| Xiao M |  | 2012 |
| Younis S |  | 2012 |
| Kazemi Z |  | 2012 |
| Johnstone A | 2012 |
| Amatachaya S | 2012 |
| Toyoda K |  | 2012 |
| Fageera W | 2012 |
| Rahn AC |  | 2012 |
| Geed S |  | 2012 |
| El-Hagrassy M | 2012 |
| Cheng C |  | 2012 |
| Kashimura M | 2012 |
| Halakoo S |  | 2012 |
| He W |  | 2012 |
| Deng Y |  | 2012 |
| Gong Y |  | 2012 |
| Vahlberg B | 2012 |
| Bazi A |  | 2012 |
| Hulbert S |  | 2012 |
| Bock JM |  | 2012 |
| Lin CH |  | 2012 |
| Voldsbekk I | 2012 |
| Langezaal LCM | 2012 |
| Araujo TG |  | 2012 |
| Krynicki CR | 2012 |
| Jakobsen G | 2012 |
| Sadlonova M | 2012 |
| Tariot PN |  | 2012 |
| Lindsay C |  | 2012 |
| Altomare D | 2012 |
| Haendel AD | 2012 |
| Yang R |  | 2012 |
| Quintero-Consuegra MD | 2012 |
| Talbot LA |  | 2012 |
| Broberg L |  | 2012 |
| Soto-Perez-de-Celis E | 2012 |
| Aguilar-Ferr?ndiz ME | 2012 |
| Cintoli S |  | 2012 |
| Misra UK |  | 2012 |
| Abdullahi SU | 2012 |
| Vukas H |  | 2012 |
| Zhang L |  | 2012 |
| Friedman BW | 2012 |
| Rao B |  | 2012 |
| De Doncker W | 2012 |
| de Almeida CMO | 2012 |
| Hartmann S | 2012 |
| Bouhassira D | 2012 |
| Ord AS |  | 2012 |
| Wiberg S |  | 2012 |
| Aalaei S |  | 2012 |
| Salehi Dehno N | 2012 |
| Suppan M |  | 2012 |
| Sindi S |  | 2012 |
| Lebares CC | 2012 |
| Sonoda Y |  | 2012 |
| Kortela E |  | 2012 |
| Nelson SE |  | 2012 |
| Dominiak M | 2012 |
| Chen Y |  | 2012 |
| Chen Q |  | 2012 |
| Silberstein SD | 2012 |
| Imamura H | 2012 |
| Moeschler SM | 2012 |
| Geerts M |  | 2012 |
| Wei W |  | 2012 |
| Reid KJ |  | 2012 |
| Hou Y |  | 2012 |
| Zhou Z |  | 2012 |
| Acsadi G |  | 2012 |
| Sterman-Neto H | 2012 |
| Dankiewicz J | 2012 |
| Malavera A | 2012 |
| Rosenberg A | 2012 |
| Asano M |  | 2012 |
| Pett SL |  | 2012 |
| Amato AA |  | 2012 |
| Wouters A | 2012 |
| Phillips MCL | 2012 |
| Mihara M |  | 2012 |
| Kitzman DW | 2012 |
| Chwojnicki K | 2012 |
| Rascol O |  | 2012 |
| Engelter ST | 2012 |
| Taylor PN |  | 2012 |
| Weafer J |  | 2012 |
| Fox RS |  | 2012 |
| Braathen G | 2012 |
| Mahmud R | 2012 |
| Vidoni ED |  | 2012 |
| Zecca C |  | 2012 |
| Haghighi S | 2012 |
| Sandebring-Matton A | 2012 |
| Koh SH |  | 2012 |
| Joosten SA | 2012 |
| Stefani A |  | 2012 |
| Park H |  | 2012 |
| Ali EN |  | 2012 |
| Gudbergsen H | 2012 |
| Moon SY |  | 2012 |
| Bleich-Cohen M | 2012 |
| Wayne PM | 2012 |
| Essmat A |  | 2012 |
| Walgaard C | 2012 |
| Kim HJ |  | 2012 |
| Moncrief GG | 2012 |
| Singh N |  | 2012 |
| Macchi ZA | 2012 |
| Mirpuri P |  | 2012 |
| Rosenthal ES | 2012 |
| Kong Z |  | 2012 |
| Kaarb? MB | 2012 |
| Xiao S |  | 2012 |
| Cheng HR |  | 2012 |



	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  1 19:49:20 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 1 Aug 2021 18:49:20 +0100
Subject: [R] Help needed with gender_df
In-Reply-To: <93442086.1530709.1627837142818@mail.yahoo.com>
References: <93442086.1530709.1627837142818.ref@mail.yahoo.com>
 <93442086.1530709.1627837142818@mail.yahoo.com>
Message-ID: <ed4ddfb4-40bb-8010-5d08-33c3580065ab@sapo.pt>

Hello,

According to the documentation,


This function predicts the gender of a first name given a year or range 
of years in which the person was born.


and your data does not include first names, only names in a form similar 
to Last First_name_initial.


This function/package is not appropriate for your problem.


Hope this helps,

Rui Barradas


?s 17:59 de 01/08/21, bharat rawlley via R-help escreveu:
> Hello,
> when using the following code -
> gender_df(Test1, name_col = "First", year_col = "Year")
> 
> for the file attached below, I get the following result -
> # A tibble: 0 x 6# ... with 6 variables: name <chr>, proportion_male <dbl>, proportion_female <dbl>, gender <lgl>,#? ?year_min <dbl>, year_max <dbl>
> 
> 
> 
> 
> 
> 
> | First |  | Year |
> | Post R |  | 2012 |
> | Kotulska K | 2012 |
> | Zi W |  | 2012 |
> | Suzuki K |  | 2012 |
> | Lynch DR |  | 2012 |
> | Paganoni S | 2012 |
> | Nourbakhsh B | 2012 |
> | Croop R |  | 2012 |
> | Bril V |  | 2012 |
> | Tan AH |  | 2012 |
> | Benedict RHB | 2012 |
> | Langeskov-Christensen M | 2012 |
> | Chiaravalloti ND | 2012 |
> | Zhang Y |  | 2012 |
> | Bovis F |  | 2012 |
> | Soul JS |  | 2012 |
> | Mantegazza R | 2012 |
> | Heatwole C | 2012 |
> | Molhemi F | 2012 |
> | Aggarwal R | 2012 |
> | Chung JW |  | 2012 |
> | Obermann M | 2012 |
> | Albert V |  | 2012 |
> | Picillo M |  | 2012 |
> | Palace J |  | 2012 |
> | Bogan RK |  | 2012 |
> | Shoamanesh A | 2012 |
> | Jaeckle KA | 2012 |
> | Sakamoto S | 2012 |
> | Barohn RJ |  | 2012 |
> | Fehlings MG | 2012 |
> | Barbieri F |  | 2012 |
> | Klopstock T | 2012 |
> | Martin AK |  | 2012 |
> | Griffith R |  | 2012 |
> | Maas RPPWM | 2012 |
> | Santhosh AP | 2012 |
> | Macdonald-Laurs E | 2012 |
> | Guinchard M | 2012 |
> | Luijten SPR | 2012 |
> | Pagan FL |  | 2012 |
> | Takeda A |  | 2012 |
> | Shin YW |  | 2012 |
> | DeLuca J |  | 2012 |
> | Zhong F |  | 2012 |
> | Toyoda K |  | 2012 |
> | Song J |  | 2012 |
> | Pan Y |  | 2012 |
> | Molloy EN | 2012 |
> | Heit JJ |  | 2012 |
> | Bird LM |  | 2012 |
> | Wu X |  | 2012 |
> | Naismith RT | 2012 |
> | Yaghi S |  | 2012 |
> | Tekeoglu Tosun A | 2012 |
> | Vieira-Yano B | 2012 |
> | Malt?te D |  | 2012 |
> | Gillving M |  | 2012 |
> | Sylaja PN |  | 2012 |
> | Sawada H |  | 2012 |
> | van Dalen JW | 2012 |
> | Meador KJ | 2012 |
> | Cheshmavar M | 2012 |
> | Liu MN |  | 2012 |
> | Paprad T |  | 2012 |
> | Hogue CW | 2012 |
> | Filipovi? TN | 2012 |
> | Weiss MD |  | 2012 |
> | Bril V |  | 2012 |
> | Ishigooka J | 2012 |
> | Zhao J |  | 2012 |
> | Christensen CE | 2012 |
> | Zhang P |  | 2012 |
> | Ford JH |  | 2012 |
> | Ter Meulen BC | 2012 |
> | Giannoni A | 2012 |
> | Kuester-Gruber S | 2012 |
> | Kumar A |  | 2012 |
> | Dominiak M | 2012 |
> | Mintun MA | 2012 |
> | Guttuso T Jr | 2012 |
> | Al-Karagholi MA | 2012 |
> | De Icco R |  | 2012 |
> | Akhbari Ziegler S | 2012 |
> | Hirata K |  | 2012 |
> | Schreiner L | 2012 |
> | Xiao M |  | 2012 |
> | Younis S |  | 2012 |
> | Kazemi Z |  | 2012 |
> | Johnstone A | 2012 |
> | Amatachaya S | 2012 |
> | Toyoda K |  | 2012 |
> | Fageera W | 2012 |
> | Rahn AC |  | 2012 |
> | Geed S |  | 2012 |
> | El-Hagrassy M | 2012 |
> | Cheng C |  | 2012 |
> | Kashimura M | 2012 |
> | Halakoo S |  | 2012 |
> | He W |  | 2012 |
> | Deng Y |  | 2012 |
> | Gong Y |  | 2012 |
> | Vahlberg B | 2012 |
> | Bazi A |  | 2012 |
> | Hulbert S |  | 2012 |
> | Bock JM |  | 2012 |
> | Lin CH |  | 2012 |
> | Voldsbekk I | 2012 |
> | Langezaal LCM | 2012 |
> | Araujo TG |  | 2012 |
> | Krynicki CR | 2012 |
> | Jakobsen G | 2012 |
> | Sadlonova M | 2012 |
> | Tariot PN |  | 2012 |
> | Lindsay C |  | 2012 |
> | Altomare D | 2012 |
> | Haendel AD | 2012 |
> | Yang R |  | 2012 |
> | Quintero-Consuegra MD | 2012 |
> | Talbot LA |  | 2012 |
> | Broberg L |  | 2012 |
> | Soto-Perez-de-Celis E | 2012 |
> | Aguilar-Ferr?ndiz ME | 2012 |
> | Cintoli S |  | 2012 |
> | Misra UK |  | 2012 |
> | Abdullahi SU | 2012 |
> | Vukas H |  | 2012 |
> | Zhang L |  | 2012 |
> | Friedman BW | 2012 |
> | Rao B |  | 2012 |
> | De Doncker W | 2012 |
> | de Almeida CMO | 2012 |
> | Hartmann S | 2012 |
> | Bouhassira D | 2012 |
> | Ord AS |  | 2012 |
> | Wiberg S |  | 2012 |
> | Aalaei S |  | 2012 |
> | Salehi Dehno N | 2012 |
> | Suppan M |  | 2012 |
> | Sindi S |  | 2012 |
> | Lebares CC | 2012 |
> | Sonoda Y |  | 2012 |
> | Kortela E |  | 2012 |
> | Nelson SE |  | 2012 |
> | Dominiak M | 2012 |
> | Chen Y |  | 2012 |
> | Chen Q |  | 2012 |
> | Silberstein SD | 2012 |
> | Imamura H | 2012 |
> | Moeschler SM | 2012 |
> | Geerts M |  | 2012 |
> | Wei W |  | 2012 |
> | Reid KJ |  | 2012 |
> | Hou Y |  | 2012 |
> | Zhou Z |  | 2012 |
> | Acsadi G |  | 2012 |
> | Sterman-Neto H | 2012 |
> | Dankiewicz J | 2012 |
> | Malavera A | 2012 |
> | Rosenberg A | 2012 |
> | Asano M |  | 2012 |
> | Pett SL |  | 2012 |
> | Amato AA |  | 2012 |
> | Wouters A | 2012 |
> | Phillips MCL | 2012 |
> | Mihara M |  | 2012 |
> | Kitzman DW | 2012 |
> | Chwojnicki K | 2012 |
> | Rascol O |  | 2012 |
> | Engelter ST | 2012 |
> | Taylor PN |  | 2012 |
> | Weafer J |  | 2012 |
> | Fox RS |  | 2012 |
> | Braathen G | 2012 |
> | Mahmud R | 2012 |
> | Vidoni ED |  | 2012 |
> | Zecca C |  | 2012 |
> | Haghighi S | 2012 |
> | Sandebring-Matton A | 2012 |
> | Koh SH |  | 2012 |
> | Joosten SA | 2012 |
> | Stefani A |  | 2012 |
> | Park H |  | 2012 |
> | Ali EN |  | 2012 |
> | Gudbergsen H | 2012 |
> | Moon SY |  | 2012 |
> | Bleich-Cohen M | 2012 |
> | Wayne PM | 2012 |
> | Essmat A |  | 2012 |
> | Walgaard C | 2012 |
> | Kim HJ |  | 2012 |
> | Moncrief GG | 2012 |
> | Singh N |  | 2012 |
> | Macchi ZA | 2012 |
> | Mirpuri P |  | 2012 |
> | Rosenthal ES | 2012 |
> | Kong Z |  | 2012 |
> | Kaarb? MB | 2012 |
> | Xiao S |  | 2012 |
> | Cheng HR |  | 2012 |
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Sun Aug  1 20:56:37 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Sun, 1 Aug 2021 18:56:37 +0000 (UTC)
Subject: [R] Help needed with gender_df
In-Reply-To: <ed4ddfb4-40bb-8010-5d08-33c3580065ab@sapo.pt>
References: <93442086.1530709.1627837142818.ref@mail.yahoo.com>
 <93442086.1530709.1627837142818@mail.yahoo.com>
 <ed4ddfb4-40bb-8010-5d08-33c3580065ab@sapo.pt>
Message-ID: <1789559256.1536954.1627844197573@mail.yahoo.com>

 That was helpful, thank you very much!?
    On Sunday, 1 August, 2021, 01:49:30 pm GMT-4, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,

According to the documentation,


This function predicts the gender of a first name given a year or range 
of years in which the person was born.


and your data does not include first names, only names in a form similar 
to Last First_name_initial.


This function/package is not appropriate for your problem.


Hope this helps,

Rui Barradas


?s 17:59 de 01/08/21, bharat rawlley via R-help escreveu:
> Hello,
> when using the following code -
> gender_df(Test1, name_col = "First", year_col = "Year")
> 
> for the file attached below, I get the following result -
> # A tibble: 0 x 6# ... with 6 variables: name <chr>, proportion_male <dbl>, proportion_female <dbl>, gender <lgl>,#? ?year_min <dbl>, year_max <dbl>
> 
> 
> 
> 
> 
> 
> | First |? | Year |
> | Post R |? | 2012 |
> | Kotulska K | 2012 |
> | Zi W |? | 2012 |
> | Suzuki K |? | 2012 |
> | Lynch DR |? | 2012 |
> | Paganoni S | 2012 |
> | Nourbakhsh B | 2012 |
> | Croop R |? | 2012 |
> | Bril V |? | 2012 |
> | Tan AH |? | 2012 |
> | Benedict RHB | 2012 |
> | Langeskov-Christensen M | 2012 |
> | Chiaravalloti ND | 2012 |
> | Zhang Y |? | 2012 |
> | Bovis F |? | 2012 |
> | Soul JS |? | 2012 |
> | Mantegazza R | 2012 |
> | Heatwole C | 2012 |
> | Molhemi F | 2012 |
> | Aggarwal R | 2012 |
> | Chung JW |? | 2012 |
> | Obermann M | 2012 |
> | Albert V |? | 2012 |
> | Picillo M |? | 2012 |
> | Palace J |? | 2012 |
> | Bogan RK |? | 2012 |
> | Shoamanesh A | 2012 |
> | Jaeckle KA | 2012 |
> | Sakamoto S | 2012 |
> | Barohn RJ |? | 2012 |
> | Fehlings MG | 2012 |
> | Barbieri F |? | 2012 |
> | Klopstock T | 2012 |
> | Martin AK |? | 2012 |
> | Griffith R |? | 2012 |
> | Maas RPPWM | 2012 |
> | Santhosh AP | 2012 |
> | Macdonald-Laurs E | 2012 |
> | Guinchard M | 2012 |
> | Luijten SPR | 2012 |
> | Pagan FL |? | 2012 |
> | Takeda A |? | 2012 |
> | Shin YW |? | 2012 |
> | DeLuca J |? | 2012 |
> | Zhong F |? | 2012 |
> | Toyoda K |? | 2012 |
> | Song J |? | 2012 |
> | Pan Y |? | 2012 |
> | Molloy EN | 2012 |
> | Heit JJ |? | 2012 |
> | Bird LM |? | 2012 |
> | Wu X |? | 2012 |
> | Naismith RT | 2012 |
> | Yaghi S |? | 2012 |
> | Tekeoglu Tosun A | 2012 |
> | Vieira-Yano B | 2012 |
> | Malt?te D |? | 2012 |
> | Gillving M |? | 2012 |
> | Sylaja PN |? | 2012 |
> | Sawada H |? | 2012 |
> | van Dalen JW | 2012 |
> | Meador KJ | 2012 |
> | Cheshmavar M | 2012 |
> | Liu MN |? | 2012 |
> | Paprad T |? | 2012 |
> | Hogue CW | 2012 |
> | Filipovi? TN | 2012 |
> | Weiss MD |? | 2012 |
> | Bril V |? | 2012 |
> | Ishigooka J | 2012 |
> | Zhao J |? | 2012 |
> | Christensen CE | 2012 |
> | Zhang P |? | 2012 |
> | Ford JH |? | 2012 |
> | Ter Meulen BC | 2012 |
> | Giannoni A | 2012 |
> | Kuester-Gruber S | 2012 |
> | Kumar A |? | 2012 |
> | Dominiak M | 2012 |
> | Mintun MA | 2012 |
> | Guttuso T Jr | 2012 |
> | Al-Karagholi MA | 2012 |
> | De Icco R |? | 2012 |
> | Akhbari Ziegler S | 2012 |
> | Hirata K |? | 2012 |
> | Schreiner L | 2012 |
> | Xiao M |? | 2012 |
> | Younis S |? | 2012 |
> | Kazemi Z |? | 2012 |
> | Johnstone A | 2012 |
> | Amatachaya S | 2012 |
> | Toyoda K |? | 2012 |
> | Fageera W | 2012 |
> | Rahn AC |? | 2012 |
> | Geed S |? | 2012 |
> | El-Hagrassy M | 2012 |
> | Cheng C |? | 2012 |
> | Kashimura M | 2012 |
> | Halakoo S |? | 2012 |
> | He W |? | 2012 |
> | Deng Y |? | 2012 |
> | Gong Y |? | 2012 |
> | Vahlberg B | 2012 |
> | Bazi A |? | 2012 |
> | Hulbert S |? | 2012 |
> | Bock JM |? | 2012 |
> | Lin CH |? | 2012 |
> | Voldsbekk I | 2012 |
> | Langezaal LCM | 2012 |
> | Araujo TG |? | 2012 |
> | Krynicki CR | 2012 |
> | Jakobsen G | 2012 |
> | Sadlonova M | 2012 |
> | Tariot PN |? | 2012 |
> | Lindsay C |? | 2012 |
> | Altomare D | 2012 |
> | Haendel AD | 2012 |
> | Yang R |? | 2012 |
> | Quintero-Consuegra MD | 2012 |
> | Talbot LA |? | 2012 |
> | Broberg L |? | 2012 |
> | Soto-Perez-de-Celis E | 2012 |
> | Aguilar-Ferr?ndiz ME | 2012 |
> | Cintoli S |? | 2012 |
> | Misra UK |? | 2012 |
> | Abdullahi SU | 2012 |
> | Vukas H |? | 2012 |
> | Zhang L |? | 2012 |
> | Friedman BW | 2012 |
> | Rao B |? | 2012 |
> | De Doncker W | 2012 |
> | de Almeida CMO | 2012 |
> | Hartmann S | 2012 |
> | Bouhassira D | 2012 |
> | Ord AS |? | 2012 |
> | Wiberg S |? | 2012 |
> | Aalaei S |? | 2012 |
> | Salehi Dehno N | 2012 |
> | Suppan M |? | 2012 |
> | Sindi S |? | 2012 |
> | Lebares CC | 2012 |
> | Sonoda Y |? | 2012 |
> | Kortela E |? | 2012 |
> | Nelson SE |? | 2012 |
> | Dominiak M | 2012 |
> | Chen Y |? | 2012 |
> | Chen Q |? | 2012 |
> | Silberstein SD | 2012 |
> | Imamura H | 2012 |
> | Moeschler SM | 2012 |
> | Geerts M |? | 2012 |
> | Wei W |? | 2012 |
> | Reid KJ |? | 2012 |
> | Hou Y |? | 2012 |
> | Zhou Z |? | 2012 |
> | Acsadi G |? | 2012 |
> | Sterman-Neto H | 2012 |
> | Dankiewicz J | 2012 |
> | Malavera A | 2012 |
> | Rosenberg A | 2012 |
> | Asano M |? | 2012 |
> | Pett SL |? | 2012 |
> | Amato AA |? | 2012 |
> | Wouters A | 2012 |
> | Phillips MCL | 2012 |
> | Mihara M |? | 2012 |
> | Kitzman DW | 2012 |
> | Chwojnicki K | 2012 |
> | Rascol O |? | 2012 |
> | Engelter ST | 2012 |
> | Taylor PN |? | 2012 |
> | Weafer J |? | 2012 |
> | Fox RS |? | 2012 |
> | Braathen G | 2012 |
> | Mahmud R | 2012 |
> | Vidoni ED |? | 2012 |
> | Zecca C |? | 2012 |
> | Haghighi S | 2012 |
> | Sandebring-Matton A | 2012 |
> | Koh SH |? | 2012 |
> | Joosten SA | 2012 |
> | Stefani A |? | 2012 |
> | Park H |? | 2012 |
> | Ali EN |? | 2012 |
> | Gudbergsen H | 2012 |
> | Moon SY |? | 2012 |
> | Bleich-Cohen M | 2012 |
> | Wayne PM | 2012 |
> | Essmat A |? | 2012 |
> | Walgaard C | 2012 |
> | Kim HJ |? | 2012 |
> | Moncrief GG | 2012 |
> | Singh N |? | 2012 |
> | Macchi ZA | 2012 |
> | Mirpuri P |? | 2012 |
> | Rosenthal ES | 2012 |
> | Kong Z |? | 2012 |
> | Kaarb? MB | 2012 |
> | Xiao S |? | 2012 |
> | Cheng HR |? | 2012 |
> 
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
  
	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Aug  2 04:47:25 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 2 Aug 2021 14:47:25 +1200
Subject: [R] Cumulates of snowfall within a given interval
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC65AC61E@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC65AC61E@ESINO.regionemarche.intra>
Message-ID: <CABcYAdK57wP1XZEzjEDAuNeQOwSziEKyE2r0=7eQ_Q58j7ix_Q@mail.gmail.com>

> x <- c(1,2,3)  # a vector of numbers, such as snowfallsum
> (cx <- cumsum(x)) # a vector of cumulative sums.
1 3 6
> i <- 1 # The starting point.
> j <- 2 # The ending point.
> cx[j] - cx[i-1] # sum of x[i] + ... + x[j]
ERROR!
> cx <- c(0, cx) # Oops, we need this step.
> cx[j+1] - cx[i]

So using c(0,cumsum(x)) you take O(#x) time and O(#x) space and get a data
structure that will answer any (i,j) -> x[i]+...+x[j] query in constant time.

Let's now suppose you fix delta = 3 (days) and some threshold:
indices <- (delta + 1):length(cx)
which(cx[indices] - cx[indices - delta] > threshold)

On Fri, 30 Jul 2021 at 19:24, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear R users,
> I have a data frame with daily snow cumulates (these quantities are known as "hn" and are expressed in cm), from the 1st of December to the 30th of April, for more than twenty years.
>
> I would need to find days when the sum of a given short interval (I might choose two consecutive days, three consecutive days or something like that) is higher than a threshold (it might be 80 cm, or 100 cm).
>
> I am trying with rle, but I really struggle to find an efficient algorithm.
> Could somebody help me with some hints?
>
> Thank you for your attention and your help
> Stefano
>
>
> init_day <- as.POSIXct("2018-02-01", format="%Y-%m-%d", tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-20", format="%Y-%m-%d", tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="1 day"))
> mydf$hn <- c(30, 0, 10, 50, NA, 40, 70, 0, 0, 0 , NA, 10, 50, 30, 30, 10, 0, 0, 90, 0)
>
> - if I choose a threshold of 100 cm in two days, I should get the 6th of February;
> - if I choose a threshold of 80 cm in two days I should get the 6th and the 13th of February, but not the 19th of February because this is a single day;
> - f I choose a threshold of 100 cm in four days, I should get the 12th of February.
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug  2 10:34:28 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 2 Aug 2021 20:34:28 +1200
Subject: [R] 
 Plotting confidence intervals with ggplot, in multiple facets.
In-Reply-To: <030701d77d08$1cc9b330$565d1990$@verizon.net>
References: <20210718181706.03a95d29@rolf-Latitude-E7470>
 <016501d77c08$a6d94b40$f48be1c0$@verizon.net>
 <20210720112405.08ec449e@rolf-Latitude-E7470>
 <030701d77d08$1cc9b330$565d1990$@verizon.net>
Message-ID: <20210802203428.7da847a1@rolf-Latitude-E7470>


I would like to tie off this thread (?!?!) by thanking Jeff Newmiller,
Rui Barradas, Avi Gross and Bill Dunlap for their advice and insight.

I have attached the code that I finally put together, on the basis of
the aforementioned advice, in the file ciPlot.txt.  I have also
attached the necessary data set in the file egDat.txt.

Just in case anyone is interested or in case someone else might benefit
from seeing this code.

cheers,

Rolf Turner
-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ciPlot.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210802/82eed2b3/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: egDat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210802/82eed2b3/attachment-0001.txt>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  2 18:53:34 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 2 Aug 2021 17:53:34 +0100
Subject: [R] 
 Plotting confidence intervals with ggplot, in multiple facets.
In-Reply-To: <20210802203428.7da847a1@rolf-Latitude-E7470>
References: <20210718181706.03a95d29@rolf-Latitude-E7470>
 <016501d77c08$a6d94b40$f48be1c0$@verizon.net>
 <20210720112405.08ec449e@rolf-Latitude-E7470>
 <030701d77d08$1cc9b330$565d1990$@verizon.net>
 <20210802203428.7da847a1@rolf-Latitude-E7470>
Message-ID: <55a53232-7fc1-dbe7-1228-0d968eb953db@sapo.pt>

Hello,

I'm glad it helped.
Here are a couple of ideas for theme.

1) From ?theme:

Theme inheritance
Theme elements inherit properties from other theme elements 
hierarchically. For example, axis.title.x.bottom inherits from 
axis.title.x which inherits from axis.title, which in turn inherits from 
text.


So there is no need for axis.title.x and axis.title.y (or axis.text) and 
  this

   theme_bw() +
   theme(axis.title.x=element_text(size=14),
         axis.title.y=element_text(size=14)) +
   theme(axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14)) +
   theme(panel.border=element_rect(linetype="solid",fill=NA),
         panel.grid.minor=element_blank(),
         panel.grid.major=element_blank())


can be simplified to this


   theme_bw() +
   theme(axis.title=element_text(size=14),
         axis.text=element_text(size=14)) +
   theme(panel.border=element_rect(linetype="solid",fill=NA),
         panel.grid=element_blank())


2) If you are using the same theme repeatedly, why not define a custom 
theme? It's as easy as


theme_custom <- function(){
   theme_bw() %+replace%    #replace elements we want to change
     theme(axis.title=element_text(size=14),
           axis.text=element_text(size=14),
           panel.border=element_rect(linetype="solid",fill=NA),
           panel.grid=element_blank())
}


(It's also possible to just copy&paste the two theme instructions in 
your code, I have rewritten them as one as a matter of habit.)
The plots would then become easier to read and if themes' rules change, 
the theme will be updated in one place only.


Part.a <- ggplot(cidf.a, aes(Ndat, estimate)) +
   geom_errorbar(aes(ymin = lower, ymax = upper), width = 50) +
   geom_point(size = 1) +
   geom_hline(yintercept = 0,col="red") +
   labs(x="",y=Ylab.a) +
   theme_custom()


And the same for Part.b.

Hope this helps,

Rui Barradas


?s 09:34 de 02/08/21, Rolf Turner escreveu:
> 
> I would like to tie off this thread (?!?!) by thanking Jeff Newmiller,
> Rui Barradas, Avi Gross and Bill Dunlap for their advice and insight.
> 
> I have attached the code that I finally put together, on the basis of
> the aforementioned advice, in the file ciPlot.txt.  I have also
> attached the necessary data set in the file egDat.txt.
> 
> Just in case anyone is interested or in case someone else might benefit
> from seeing this code.
> 
> cheers,
> 
> Rolf Turner
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug  2 22:56:16 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 3 Aug 2021 08:56:16 +1200
Subject: [R] 
 Plotting confidence intervals with ggplot, in multiple facets.
In-Reply-To: <55a53232-7fc1-dbe7-1228-0d968eb953db@sapo.pt>
References: <20210718181706.03a95d29@rolf-Latitude-E7470>
 <016501d77c08$a6d94b40$f48be1c0$@verizon.net>
 <20210720112405.08ec449e@rolf-Latitude-E7470>
 <030701d77d08$1cc9b330$565d1990$@verizon.net>
 <20210802203428.7da847a1@rolf-Latitude-E7470>
 <55a53232-7fc1-dbe7-1228-0d968eb953db@sapo.pt>
Message-ID: <20210803085616.1661c7e1@rolf-Latitude-E7470>


On Mon, 2 Aug 2021 17:53:34 +0100
Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> I'm glad it helped.
> Here are a couple of ideas for theme.

<SNIP>

Thanks Rui.  The scope of your knowledge and understanding is simply
amazing!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @tch|rume @end|ng |rom gm@||@com  Sun Aug  1 20:47:34 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Sun, 1 Aug 2021 20:47:34 +0200
Subject: [R] Long Format data
Message-ID: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>

Hello, i hope you are well. May you kindly help me to structure data in the
folder attached herewith in file BOP_All_Countries.csv. I am doing
panel data analysis. *I need it to be structured as it is on the file
R_help.csv.  *

Please kindly see the r-script below *(r_help.R)* that i ran which did not
yield what i wanted.

Thank you in advance.


Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504

From out|ook_789D32266F1FD473 @end|ng |rom out|ook@com  Mon Aug  2 20:25:36 2021
From: out|ook_789D32266F1FD473 @end|ng |rom out|ook@com (Lac Will)
Date: Mon, 2 Aug 2021 18:25:36 +0000
Subject: [R] Generate oauth token using HTTR package in R
Message-ID: <DM6PR02MB4634145115EDFFB48D9CD315EEEF9@DM6PR02MB4634.namprd02.prod.outlook.com>



Novice attempting R, as displayed below, to obtain an oauth token using HTTR package in R and have a status code of 401.

Any insight as to the cause of this error and a resolution?

Thanks in advance.



# Status: 401

library(httr)

base64_value <-
  "123456789="


response16 <-
  httr::POST (url = "https://api.precisely.com/oauth/token" ,
             httr::add_headers(Authorization = paste("Basic", base64_value, sep = "")),
             body = list(grant_type = "client_credentials"),
             encode = "form"
             )

#verbose(data_out = true, data_in = False, info = false, ssl = false)


warn_for_status(response16)
stop_for_status(response16)



























Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug  3 10:05:45 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 3 Aug 2021 18:05:45 +1000
Subject: [R] Long Format data
In-Reply-To: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
References: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
Message-ID: <CA+8X3fXToDQiSw-0MD0KjE8Ei6fTWbXE3wME-aQKxyoKJHB8xQ@mail.gmail.com>

Hi Admire,
Neither the R script nor CSV file was attached to your message. Both
should be plain text files and are unlikely to be rejected by the help
list mail server. Perhaps check your email client.

Jim

On Tue, Aug 3, 2021 at 5:09 PM Admire Tarisirayi Chirume
<atchirume at gmail.com> wrote:
>
> Hello, i hope you are well. May you kindly help me to structure data in the
> folder attached herewith in file BOP_All_Countries.csv. I am doing
> panel data analysis. *I need it to be structured as it is on the file
> R_help.csv.  *
>
> Please kindly see the r-script below *(r_help.R)* that i ran which did not
> yield what i wanted.
>
> Thank you in advance.
>
>
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gm@rk@|ow|er @end|ng |rom out|ook@com  Tue Aug  3 11:39:46 2021
From: gm@rk@|ow|er @end|ng |rom out|ook@com (Mark Fowler)
Date: Tue, 3 Aug 2021 09:39:46 +0000
Subject: [R] Generate oauth token using HTTR package in R
In-Reply-To: <DM6PR02MB4634145115EDFFB48D9CD315EEEF9@DM6PR02MB4634.namprd02.prod.outlook.com>
References: <DM6PR02MB4634145115EDFFB48D9CD315EEEF9@DM6PR02MB4634.namprd02.prod.outlook.com>
Message-ID: <MN2PR07MB72137E38B5CC0E60C5755CE285F09@MN2PR07MB7213.namprd07.prod.outlook.com>

Hi Lac,

The status code means that you were not authorized to access the site, perhaps reflecting some problem with your syntax or your permissions. I note that attempting to simply go to the link to check on it gives status code 405, meaning the typical click on the hypertext is not an accepted method to access the location. Also consider the possibility that the site might be experiencing problems, so even if your syntax was correct it might not work right now. Another possibility is a change to URL syntax (addressing) at the precisely.com end, which appears to have been an issue, but I do not know if it still is.

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10

From: Lac Will<mailto:outlook_789D32266F1FD473 at outlook.com>
Sent: Tuesday, August 3, 2021 4:10 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Generate oauth token using HTTR package in R



Novice attempting R, as displayed below, to obtain an oauth token using HTTR package in R and have a status code of 401.

Any insight as to the cause of this error and a resolution?

Thanks in advance.



# Status: 401

library(httr)

base64_value <-
  "123456789="


response16 <-
  httr::POST (url = "https://api.precisely.com/oauth/token" ,
             httr::add_headers(Authorization = paste("Basic", base64_value, sep = "")),
             body = list(grant_type = "client_credentials"),
             encode = "form"
             )

#verbose(data_out = true, data_in = False, info = false, ssl = false)


warn_for_status(response16)
stop_for_status(response16)



























Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Aug  3 18:20:12 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 3 Aug 2021 17:20:12 +0100
Subject: [R] What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
Message-ID: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>

Short version

Apart from the ability to work with values of p too small to be of much 
practical use what are the advantages and disadvantages of setting this 
to TRUE?

Longer version

I am contemplating upgrading various functions in one of my packages to 
use this and as far as I can see it would only have the advantage of 
allowing people to use very small p-values but before I go ahead have I 
missed anything? I am most concerned with negatives but if there is any 
other advantage I would mention that in the vignette. I am not concerned 
about speed or the extra effort in coding and expanding the documentation.
-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Tue Aug  3 20:20:52 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 3 Aug 2021 18:20:52 +0000 (UTC)
Subject: [R] Help with package EasyPubmed
References: <1046636584.2205366.1628014852065.ref@mail.yahoo.com>
Message-ID: <1046636584.2205366.1628014852065@mail.yahoo.com>

Hello,?
When I try to run the following code using the package Easypubmed, I get a null result -?
> batch_pubmed_download(query_7)
NULL
#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"
However, the exact same search string yields 668 results on Pubmed.?


I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?
Any help would be?greatly appreciated
Thank you!?

	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Tue Aug  3 20:26:40 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 3 Aug 2021 18:26:40 +0000 (UTC)
Subject: [R] Help with package EasyPubmed
In-Reply-To: <1046636584.2205366.1628014852065@mail.yahoo.com>
References: <1046636584.2205366.1628014852065.ref@mail.yahoo.com>
 <1046636584.2205366.1628014852065@mail.yahoo.com>
Message-ID: <712126143.2207911.1628015200446@mail.yahoo.com>

 ?Okay, the following search string resolved my issue? -?
"Cardiology AND randomized controlled trial[Publication type] AND 2011[PDAT]"

Thank you!
    On Tuesday, 3 August, 2021, 02:21:38 pm GMT-4, bharat rawlley via R-help <r-help at r-project.org> wrote:  
 
 Hello,?
When I try to run the following code using the package Easypubmed, I get a null result -?
> batch_pubmed_download(query_7)
NULL
#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"
However, the exact same search string yields 668 results on Pubmed.?


I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?
Any help would be?greatly appreciated
Thank you!?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Aug  3 20:53:28 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 3 Aug 2021 14:53:28 -0400
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
Message-ID: <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>

On 03/08/2021 12:20 p.m., Michael Dewey wrote:
> Short version
> 
> Apart from the ability to work with values of p too small to be of much
> practical use what are the advantages and disadvantages of setting this
> to TRUE?
> 
> Longer version
> 
> I am contemplating upgrading various functions in one of my packages to
> use this and as far as I can see it would only have the advantage of
> allowing people to use very small p-values but before I go ahead have I
> missed anything? I am most concerned with negatives but if there is any
> other advantage I would mention that in the vignette. I am not concerned
> about speed or the extra effort in coding and expanding the documentation.
> 

These are often needed in likelihood problems.  In just about any 
problem where the normal density shows up in the likelihood, you're 
better off working with the log likelihood and setting log = TRUE in 
dnorm, because sometimes you want to evaluate the likelihood very far 
from its mode.

The same sort of thing happens with pnorm for similar reasons.  Some 
likelihoods involve normal integrals and will need it.

I can't think of an example for qnorm off the top of my head, but I 
imagine there are some:  maybe involving simulation way out in the tails.

The main negative about using logs is that they aren't always needed.

Duncan Murdoch


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Aug  3 22:24:08 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 3 Aug 2021 13:24:08 -0700
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>
Message-ID: <CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A@mail.gmail.com>

In maximum likelihood problems, even when the individual density values are
fairly far from zero, their product may underflow to zero.  Optimizers have
problems when there is a large flat area.
   > q <- runif(n=1000, -0.1, +0.1)
   > prod(dnorm(q))
   [1] 0
   > sum(dnorm(q, log=TRUE))
   [1] -920.6556

A more minor advantage for some probability-related functions is speed.
E.g., dnorm(log=TRUE,...) does not need to evaluate exp().
   > q <- runif(1e6, -10, 10)
   > system.time(for(i in 1:100)dnorm(q, log=FALSE))
      user  system elapsed
      9.13    0.11    9.23
   > system.time(for(i in 1:100)dnorm(q, log=TRUE))
      user  system elapsed
      4.60    0.19    4.78

 -Bill

On Tue, Aug 3, 2021 at 11:53 AM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 03/08/2021 12:20 p.m., Michael Dewey wrote:
> > Short version
> >
> > Apart from the ability to work with values of p too small to be of much
> > practical use what are the advantages and disadvantages of setting this
> > to TRUE?
> >
> > Longer version
> >
> > I am contemplating upgrading various functions in one of my packages to
> > use this and as far as I can see it would only have the advantage of
> > allowing people to use very small p-values but before I go ahead have I
> > missed anything? I am most concerned with negatives but if there is any
> > other advantage I would mention that in the vignette. I am not concerned
> > about speed or the extra effort in coding and expanding the
> documentation.
> >
>
> These are often needed in likelihood problems.  In just about any
> problem where the normal density shows up in the likelihood, you're
> better off working with the log likelihood and setting log = TRUE in
> dnorm, because sometimes you want to evaluate the likelihood very far
> from its mode.
>
> The same sort of thing happens with pnorm for similar reasons.  Some
> likelihoods involve normal integrals and will need it.
>
> I can't think of an example for qnorm off the top of my head, but I
> imagine there are some:  maybe involving simulation way out in the tails.
>
> The main negative about using logs is that they aren't always needed.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Aug  4 00:56:08 2021
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 03 Aug 2021 18:56:08 -0400
Subject: [R] Creating a log-transformed histogram of multiclass data
In-Reply-To: <1ac86e67589f13f2e37a83d0b145260e@ontargettek.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <e18d373f5daf2f463abe4c17b82bbe76@ontargettek.com>
 <1ac86e67589f13f2e37a83d0b145260e@ontargettek.com>
Message-ID: <2bc87c25f161bac1d8e5101e20bf2237@ontargettek.com>


# Resending this message since the original email was held in queue by 
the listserv software because of a "suspicious" subject line, and/or 
because of attached .png histogram chart attachments. I'm guessing that 
the listserv software doesn't like multiple image file attachments.


Hi everyone. I'm working on a research model now that is calculating 
anomaly scores (RMSE values) for three distinct groups within a large 
dataset. The anomaly scores are a continuous data type and are quite 
small, ranging from approximately 1e-04 to 1-e07 across a population of 
approximately 1 million observations.

I have all of the summary and descriptive statistics for each of the 
anomaly score distributions across each group label in the dataset, and 
I am able to create some useful histograms showing how each of the three 
groups is uniquely distributed across the range of scores. However, 
because of the large variance within the frequency of score values and 
the high density peaks within much of the anomaly scores, I need to use 
a log transformation within the histogram to show both the log frequency 
count of each binned observation range (y-axis) and a log transformation 
of the binned score values (x-axis) to be able to appropriately 
illustrate the distributions within the data and make it more readily 
understandable.

Fortunately, ggplot2 is really useful for creating some really 
attractive dual-axis log transformed histograms.

However, I cannot figure out a way to create the log transformed 
histograms to show each of my three groups by color within the same 
histogram. I would want it to look like this, BUT use a log 
transformation for each axis. This plot below shows the 3 groups in one 
histogram but uses the default normal values.

For log transformed axis values, the best I can do so far is produce 
three separate histograms, one for each group.



Below is sample R code to illustrate my problem with a 
randomly-generated example dataset and the ggplot2 approaches that I 
have taken so far:

# Sample R code below:

library(ggplot2)
library(dplyr)
library(hrbrthemes)

# I created some simple random sample data to produce an example 
dataset.
# This produces an example dataframe called d, which contains a class 
label IV of either A, B or C for each observation. The target variable 
is the anomaly_score continuous value for each observation.
# There are 300 rows of dummy data in this dataframe.

DV_score_generator = round(runif(300,0.001,0.999), 3)
d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE, 
prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)

# First, I use ggplot to create the normal distribution histogram that 
shows all 3 groups on the same plot, by color.
# Please note that with this small set of randomized sample data it 
doesn't appear to be necessary to use an x and y-axis log transformation 
to show the distribution patterns, but it does becomes an issue with my 
vastly larger and more complex score values in the DV of the actual 
data.

p <- d %>%
ggplot( aes(x=anomaly_score, fill=label)) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +
theme_ipsum() +
labs(fill="")

p

# Produces a normal multiclass histogram.



# Now produce a series of x and y-axis log-transformed histograms, 
producing one histogram for each distinct label class in the dataset:


# Group A, log transformed

ggplot(group_a, aes(x = anomaly_score)) +
      geom_histogram(aes(y = ..count..), binwidth = 0.05,
      colour = "darkgoldenrod1", fill = "darkgoldenrod2") +
      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
+
      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
Counts") +
      ggtitle("Transformed Anomaly Scores - Group A Only")


# Group A transformed histogram is produced here.



# Group B, log transformed

  ggplot(group_b, aes(x = anomaly_score)) +
      geom_histogram(aes(y = ..count..), binwidth = 0.05,
      colour = "green", fill = "darkgreen") +
      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
+
      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
Counts") +
      ggtitle("Transformed Anomaly Scores - Group B Only")

# Group B transformed histogram is produced here.



# Group C, log transformed

  ggplot(group_c, aes(x = anomaly_score)) +
      geom_histogram(aes(y = ..count..), binwidth = 0.05,
      colour = "red", fill = "darkred") +
      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
+
      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
Counts") +
      ggtitle("Transformed Anomaly Scores - Group C Only")

# Group C transformed histogram is produced here.


# End.



Thanks in advance, everyone!


- Tom


Thomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, MS
On Target Technologies, Inc.
Virginia, USA


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Aug  4 01:04:29 2021
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 03 Aug 2021 19:04:29 -0400
Subject: [R] Creating a log-transformed histogram of multiclass data
In-Reply-To: <2bc87c25f161bac1d8e5101e20bf2237@ontargettek.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <e18d373f5daf2f463abe4c17b82bbe76@ontargettek.com>
 <1ac86e67589f13f2e37a83d0b145260e@ontargettek.com>
 <2bc87c25f161bac1d8e5101e20bf2237@ontargettek.com>
Message-ID: <ba170db0581b2b7f5c79448355685e92@ontargettek.com>

Apologies, I left out 3 critical lines of code after the randomized 
sample dataframe is created:

group_a <- d[ which(d$label =='A'), ]
group_b <- d[ which(d$label =='B'), ]
group_c <- d[ which(d$label =='C'), ]





On 2021-08-03 18:56, Tom Woolman wrote:
> # Resending this message since the original email was held in queue by
> the listserv software because of a "suspicious" subject line, and/or
> because of attached .png histogram chart attachments. I'm guessing
> that the listserv software doesn't like multiple image file
> attachments.
> 
> 
> Hi everyone. I'm working on a research model now that is calculating
> anomaly scores (RMSE values) for three distinct groups within a large
> dataset. The anomaly scores are a continuous data type and are quite
> small, ranging from approximately 1e-04 to 1-e07 across a population
> of approximately 1 million observations.
> 
> I have all of the summary and descriptive statistics for each of the
> anomaly score distributions across each group label in the dataset,
> and I am able to create some useful histograms showing how each of the
> three groups is uniquely distributed across the range of scores.
> However, because of the large variance within the frequency of score
> values and the high density peaks within much of the anomaly scores, I
> need to use a log transformation within the histogram to show both the
> log frequency count of each binned observation range (y-axis) and a
> log transformation of the binned score values (x-axis) to be able to
> appropriately illustrate the distributions within the data and make it
> more readily understandable.
> 
> Fortunately, ggplot2 is really useful for creating some really
> attractive dual-axis log transformed histograms.
> 
> However, I cannot figure out a way to create the log transformed
> histograms to show each of my three groups by color within the same
> histogram. I would want it to look like this, BUT use a log
> transformation for each axis. This plot below shows the 3 groups in
> one histogram but uses the default normal values.
> 
> For log transformed axis values, the best I can do so far is produce
> three separate histograms, one for each group.
> 
> 
> 
> Below is sample R code to illustrate my problem with a
> randomly-generated example dataset and the ggplot2 approaches that I
> have taken so far:
> 
> # Sample R code below:
> 
> library(ggplot2)
> library(dplyr)
> library(hrbrthemes)
> 
> # I created some simple random sample data to produce an example 
> dataset.
> # This produces an example dataframe called d, which contains a class
> label IV of either A, B or C for each observation. The target variable
> is the anomaly_score continuous value for each observation.
> # There are 300 rows of dummy data in this dataframe.
> 
> DV_score_generator = round(runif(300,0.001,0.999), 3)
> d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE,
> prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)
> 
> # First, I use ggplot to create the normal distribution histogram that
> shows all 3 groups on the same plot, by color.
> # Please note that with this small set of randomized sample data it
> doesn't appear to be necessary to use an x and y-axis log
> transformation to show the distribution patterns, but it does becomes
> an issue with my vastly larger and more complex score values in the DV
> of the actual data.
> 
> p <- d %>%
> ggplot( aes(x=anomaly_score, fill=label)) +
> geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
> scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +
> theme_ipsum() +
> labs(fill="")
> 
> p
> 
> # Produces a normal multiclass histogram.
> 
> 
> 
> # Now produce a series of x and y-axis log-transformed histograms,
> producing one histogram for each distinct label class in the dataset:
> 
> 
> # Group A, log transformed
> 
> ggplot(group_a, aes(x = anomaly_score)) +
>      geom_histogram(aes(y = ..count..), binwidth = 0.05,
>      colour = "darkgoldenrod1", fill = "darkgoldenrod2") +
>      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
> +
>      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
> Counts") +
>      ggtitle("Transformed Anomaly Scores - Group A Only")
> 
> 
> # Group A transformed histogram is produced here.
> 
> 
> 
> # Group B, log transformed
> 
>  ggplot(group_b, aes(x = anomaly_score)) +
>      geom_histogram(aes(y = ..count..), binwidth = 0.05,
>      colour = "green", fill = "darkgreen") +
>      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
> +
>      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
> Counts") +
>      ggtitle("Transformed Anomaly Scores - Group B Only")
> 
> # Group B transformed histogram is produced here.
> 
> 
> 
> # Group C, log transformed
> 
>  ggplot(group_c, aes(x = anomaly_score)) +
>      geom_histogram(aes(y = ..count..), binwidth = 0.05,
>      colour = "red", fill = "darkred") +
>      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
> +
>      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
> Counts") +
>      ggtitle("Transformed Anomaly Scores - Group C Only")
> 
> # Group C transformed histogram is produced here.
> 
> 
> # End.
> 
> 
> 
> Thanks in advance, everyone!
> 
> 
> - Tom
> 
> 
> Thomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, 
> MS
> On Target Technologies, Inc.
> Virginia, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@tth|@@-gond@n @end|ng |rom gmx@de  Wed Aug  4 14:08:05 2021
From: m@tth|@@-gond@n @end|ng |rom gmx@de (matthias-gondan)
Date: Wed, 04 Aug 2021 14:08:05 +0200
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <mailman.363724.1.1628071201.45489.r-help@r-project.org>
Message-ID: <1MGz1V-1mODz13MnL-00E3Ov@mail.gmx.net>

Response to 1You need the log version e.g. in maximum likelihood, otherwise the product of the densities and probabilities can become very small.
-------- Urspr?ngliche Nachricht --------Von: r-help-request at r-project.org Datum: 04.08.21  12:01  (GMT+01:00) An: r-help at r-project.org Betreff: R-help Digest, Vol 222, Issue 4 Send R-help mailing list submissions to	r-help at r-project.orgTo subscribe or unsubscribe via the World Wide Web, visit	https://stat.ethz.ch/mailman/listinfo/r-helpor, via email, send a message with subject or body 'help' to	r-help-request at r-project.orgYou can reach the person managing the list at	r-help-owner at r-project.orgWhen replying, please edit your Subject line so it is more specificthan "Re: Contents of R-help digest..."Today's Topics:?? 1. What are the pros and cons of the log.p parameter in????? (p|q)norm and similar? (Michael Dewey)?? 2. Help with package EasyPubmed (bharat rawlley)?? 3. Re: Help with package EasyPubmed (bharat rawlley)?? 4. Re:? What are the pros and cons of the log.p parameter in????? (p|q)norm and similar? (Duncan Murdoch)?? 5. Re:? What are the pros and cons of the log.p parameter in????? (p|q)norm and similar? (Bill Dunlap)?? 6. Creating a log-transformed histogram of multiclass data????? (Tom Woolman)?? 7. Re: Creating a log-transformed histogram of multiclass data????? (Tom Woolman)----------------------------------------------------------------------Message: 1Date: Tue, 3 Aug 2021 17:20:12 +0100From: Michael Dewey <lists at dewey.myzen.co.uk>To: "r-help at r-project.org" <r-help at r-project.org>Subject: [R] What are the pros and cons of the log.p parameter in	(p|q)norm and similar?Message-ID: <e17bdaaa-7945-4f37-ee69-941eb8270f16 at dewey.myzen.co.uk>Content-Type: text/plain; charset="utf-8"; Format="flowed"Short versionApart from the ability to work with values of p too small to be of much practical use what are the advantages and disadvantages of setting this to TRUE?Longer versionI am contemplating upgrading various functions in one of my packages to use this and as far as I can see it would only have the advantage of allowing people to use very small p-values but before I go ahead have I missed anything? I am most concerned with negatives but if there is any other advantage I would mention that in the vignette. I am not concerned about speed or the extra effort in coding and expanding the documentation.-- Michaelhttp://www.dewey.myzen.co.uk/home.html------------------------------Message: 2Date: Tue, 3 Aug 2021 18:20:52 +0000 (UTC)From: bharat rawlley <bharat_m_all at yahoo.co.in>To: R-help Mailing List <r-help at r-project.org>Subject: [R] Help with package EasyPubmedMessage-ID: <1046636584.2205366.1628014852065 at mail.yahoo.com>Content-Type: text/plain; charset="utf-8"Hello,?When I try to run the following code using the package Easypubmed, I get a null result -?> batch_pubmed_download(query_7)NULL#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"However, the exact same search string yields 668 results on Pubmed.?I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?Any help would be?greatly appreciatedThank you!?	[[alternative HTML version deleted]]------------------------------Message: 3Date: Tue, 3 Aug 2021 18:26:40 +0000 (UTC)From: bharat rawlley <bharat_m_all at yahoo.co.in>To: R-help Mailing List <r-help at r-project.org>Subject: Re: [R] Help with package EasyPubmedMessage-ID: <712126143.2207911.1628015200446 at mail.yahoo.com>Content-Type: text/plain; charset="utf-8" ?Okay, the following search string resolved my issue? -?"Cardiology AND randomized controlled trial[Publication type] AND 2011[PDAT]"Thank you!??? On Tuesday, 3 August, 2021, 02:21:38 pm GMT-4, bharat rawlley via R-help <r-help at r-project.org> wrote:?   Hello,?When I try to run the following code using the package Easypubmed, I get a null result -?> batch_pubmed_download(query_7)NULL#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"However, the exact same search string yields 668 results on Pubmed.?I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?Any help would be?greatly appreciatedThank you!???? [[alternative HTML version deleted]]______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.? 	[[alternative HTML version deleted]]------------------------------Message: 4Date: Tue, 3 Aug 2021 14:53:28 -0400From: Duncan Murdoch <murdoch.duncan at gmail.com>To: Michael Dewey <lists at dewey.myzen.co.uk>, "r-help at r-project.org"	<r-help at r-project.org>Subject: Re: [R]? What are the pros and cons of the log.p parameter in	(p|q)norm and similar?Message-ID: <c15f610b-7a16-9d84-884c-54cc170bbad8 at gmail.com>Content-Type: text/plain; charset="utf-8"; Format="flowed"On 03/08/2021 12:20 p.m., Michael Dewey wrote:> Short version> > Apart from the ability to work with values of p too small to be of much> practical use what are the advantages and disadvantages of setting this> to TRUE?> > Longer version> > I am contemplating upgrading various functions in one of my packages to> use this and as far as I can see it would only have the advantage of> allowing people to use very small p-values but before I go ahead have I> missed anything? I am most concerned with negatives but if there is any> other advantage I would mention that in the vignette. I am not concerned> about speed or the extra effort in coding and expanding the documentation.> These are often needed in likelihood problems.? In just about any problem where the normal density shows up in the likelihood, you're better off working with the log likelihood and setting log = TRUE in dnorm, because sometimes you want to evaluate the likelihood very far from its mode.The same sort of thing happens with pnorm for similar reasons.? Some likelihoods involve normal integrals and will need it.I can't think of an example for qnorm off the top of my head, but I imagine there are some:? maybe involving simulation way out in the tails.The main negative about using logs is that they aren't always needed.Duncan Murdoch------------------------------Message: 5Date: Tue, 3 Aug 2021 13:24:08 -0700From: Bill Dunlap <williamwdunlap at gmail.com>To: Duncan Murdoch <murdoch.duncan at gmail.com>Cc: Michael Dewey <lists at dewey.myzen.co.uk>, "r-help at r-project.org"	<r-help at r-project.org>Subject: Re: [R]? What are the pros and cons of the log.p parameter in	(p|q)norm and similar?Message-ID:	<CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A at mail.gmail.com>Content-Type: text/plain; charset="utf-8"In maximum likelihood problems, even when the individual density values arefairly far from zero, their product may underflow to zero.? Optimizers haveproblems when there is a large flat area.?? > q <- runif(n=1000, -0.1, +0.1)?? > prod(dnorm(q))?? [1] 0?? > sum(dnorm(q, log=TRUE))?? [1] -920.6556A more minor advantage for some probability-related functions is speed.E.g., dnorm(log=TRUE,...) does not need to evaluate exp().?? > q <- runif(1e6, -10, 10)?? > system.time(for(i in 1:100)dnorm(q, log=FALSE))????? user? system elapsed????? 9.13??? 0.11??? 9.23?? > system.time(for(i in 1:100)dnorm(q, log=TRUE))????? user? system elapsed????? 4.60??? 0.19??? 4.78 -BillOn Tue, Aug 3, 2021 at 11:53 AM Duncan Murdoch <murdoch.duncan at gmail.com>wrote:> On 03/08/2021 12:20 p.m., Michael Dewey wrote:> > Short version> >> > Apart from the ability to work with values of p too small to be of much> > practical use what are the advantages and disadvantages of setting this> > to TRUE?> >> > Longer version> >> > I am contemplating upgrading various functions in one of my packages to> > use this and as far as I can see it would only have the advantage of> > allowing people to use very small p-values but before I go ahead have I> > missed anything? I am most concerned with negatives but if there is any> > other advantage I would mention that in the vignette. I am not concerned> > about speed or the extra effort in coding and expanding the> documentation.> >>> These are often needed in likelihood problems.? In just about any> problem where the normal density shows up in the likelihood, you're> better off working with the log likelihood and setting log = TRUE in> dnorm, because sometimes you want to evaluate the likelihood very far> from its mode.>> The same sort of thing happens with pnorm for similar reasons.? Some> likelihoods involve normal integrals and will need it.>> I can't think of an example for qnorm off the top of my head, but I> imagine there are some:? maybe involving simulation way out in the tails.>> The main negative about using logs is that they aren't always needed.>> Duncan Murdoch>> ______________________________________________> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide> http://www.R-project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.>	[[alternative HTML version deleted]]------------------------------Message: 6Date: Tue, 03 Aug 2021 18:56:08 -0400From: Tom Woolman <twoolman at ontargettek.com>To: r-help at r-project.orgSubject: [R] Creating a log-transformed histogram of multiclass dataMessage-ID: <2bc87c25f161bac1d8e5101e20bf2237 at ontargettek.com>Content-Type: text/plain; charset="us-ascii"; Format="flowed"# Resending this message since the original email was held in queue by the listserv software because of a "suspicious" subject line, and/or because of attached .png histogram chart attachments. I'm guessing that the listserv software doesn't like multiple image file attachments.Hi everyone. I'm working on a research model now that is calculating anomaly scores (RMSE values) for three distinct groups within a large dataset. The anomaly scores are a continuous data type and are quite small, ranging from approximately 1e-04 to 1-e07 across a population of approximately 1 million observations.I have all of the summary and descriptive statistics for each of the anomaly score distributions across each group label in the dataset, and I am able to create some useful histograms showing how each of the three groups is uniquely distributed across the range of scores. However, because of the large variance within the frequency of score values and the high density peaks within much of the anomaly scores, I need to use a log transformation within the histogram to show both the log frequency count of each binned observation range (y-axis) and a log transformation of the binned score values (x-axis) to be able to appropriately illustrate the distributions within the data and make it more readily understandable.Fortunately, ggplot2 is really useful for creating some really attractive dual-axis log transformed histograms.However, I cannot figure out a way to create the log transformed histograms to show each of my three groups by color within the same histogram. I would want it to look like this, BUT use a log transformation for each axis. This plot below shows the 3 groups in one histogram but uses the default normal values.For log transformed axis values, the best I can do so far is produce three separate histograms, one for each group.Below is sample R code to illustrate my problem with a randomly-generated example dataset and the ggplot2 approaches that I have taken so far:# Sample R code below:library(ggplot2)library(dplyr)library(hrbrthemes)# I created some simple random sample data to produce an example dataset.# This produces an example dataframe called d, which contains a class label IV of either A, B or C for each observation. The target variable is the anomaly_score continuous value for each observation.# There are 300 rows of dummy data in this dataframe.DV_score_generator = round(runif(300,0.001,0.999), 3)d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE, prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)# First, I use ggplot to create the normal distribution histogram that shows all 3 groups on the same plot, by color.# Please note that with this small set of randomized sample data it doesn't appear to be necessary to use an x and y-axis log transformation to show the distribution patterns, but it does becomes an issue with my vastly larger and more complex score values in the DV of the actual data.p <- d %>%ggplot( aes(x=anomaly_score, fill=label)) +geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +theme_ipsum() +labs(fill="")p# Produces a normal multiclass histogram.# Now produce a series of x and y-axis log-transformed histograms, producing one histogram for each distinct label class in the dataset:# Group A, log transformedggplot(group_a, aes(x = anomaly_score)) +????? geom_histogram(aes(y = ..count..), binwidth = 0.05,????? colour = "darkgoldenrod1", fill = "darkgoldenrod2") +????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") +????? scale_y_continuous(trans="log2", name="Log-transformed Frequency Counts") +????? ggtitle("Transformed Anomaly Scores - Group A Only")# Group A transformed histogram is produced here.# Group B, log transformed? ggplot(group_b, aes(x = anomaly_score)) +????? geom_histogram(aes(y = ..count..), binwidth = 0.05,????? colour = "green", fill = "darkgreen") +????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") +????? scale_y_continuous(trans="log2", name="Log-transformed Frequency Counts") +????? ggtitle("Transformed Anomaly Scores - Group B Only")# Group B transformed histogram is produced here.# Group C, log transformed? ggplot(group_c, aes(x = anomaly_score)) +????? geom_histogram(aes(y = ..count..), binwidth = 0.05,????? colour = "red", fill = "darkred") +????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") +????? scale_y_continuous(trans="log2", name="Log-transformed Frequency Counts") +????? ggtitle("Transformed Anomaly Scores - Group C Only")# Group C transformed histogram is produced here.# End.Thanks in advance, everyone!- TomThomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, MSOn Target Technologies, Inc.Virginia, USA------------------------------Message: 7Date: Tue, 03 Aug 2021 19:04:29 -0400From: Tom Woolman <twoolman at ontargettek.com>To: r-help at r-project.orgSubject: Re: [R] Creating a log-transformed histogram of multiclass	dataMessage-ID: <ba170db0581b2b7f5c79448355685e92 at ontargettek.com>Content-Type: text/plain; charset="us-ascii"; Format="flowed"Apologies, I left out 3 critical lines of code after the randomized sample dataframe is created:group_a <- d[ which(d$label =='A'), ]group_b <- d[ which(d$label =='B'), ]group_c <- d[ which(d$label =='C'), ]On 2021-08-03 18:56, Tom Woolman wrote:> # Resending this message since the original email was held in queue by> the listserv software because of a "suspicious" subject line, and/or> because of attached .png histogram chart attachments. I'm guessing> that the listserv software doesn't like multiple image file> attachments.> > > Hi everyone. I'm working on a research model now that is calculating> anomaly scores (RMSE values) for three distinct groups within a large> dataset. The anomaly scores are a continuous data type and are quite> small, ranging from approximately 1e-04 to 1-e07 across a population> of approximately 1 million observations.> > I have all of the summary and descriptive statistics for each of the> anomaly score distributions across each group label in the dataset,> and I am able to create some useful histograms showing how each of the> three groups is uniquely distributed across the range of scores.> However, because of the large variance within the frequency of score> values and the high density peaks within much of the anomaly scores, I> need to use a log transformation within the histogram to show both the> log frequency count of each binned observation range (y-axis) and a> log transformation of the binned score values (x-axis) to be able to> appropriately illustrate the distributions within the data and make it> more readily understandable.> > Fortunately, ggplot2 is really useful for creating some really> attractive dual-axis log transformed histograms.> > However, I cannot figure out a way to create the log transformed> histograms to show each of my three groups by color within the same> histogram. I would want it to look like this, BUT use a log> transformation for each axis. This plot below shows the 3 groups in> one histogram but uses the default normal values.> > For log transformed axis values, the best I can do so far is produce> three separate histograms, one for each group.> > > > Below is sample R code to illustrate my problem with a> randomly-generated example dataset and the ggplot2 approaches that I> have taken so far:> > # Sample R code below:> > library(ggplot2)> library(dplyr)> library(hrbrthemes)> > # I created some simple random sample data to produce an example > dataset.> # This produces an example dataframe called d, which contains a class> label IV of either A, B or C for each observation. The target variable> is the anomaly_score continuous value for each observation.> # There are 300 rows of dummy data in this dataframe.> > DV_score_generator = round(runif(300,0.001,0.999), 3)> d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE,> prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)> > # First, I use ggplot to create the normal distribution histogram that> shows all 3 groups on the same plot, by color.> # Please note that with this small set of randomized sample data it> doesn't appear to be necessary to use an x and y-axis log> transformation to show the distribution patterns, but it does becomes> an issue with my vastly larger and more complex score values in the DV> of the actual data.> > p <- d %>%> ggplot( aes(x=anomaly_score, fill=label)) +> geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +> scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +> theme_ipsum() +> labs(fill="")> > p> > # Produces a normal multiclass histogram.> > > > # Now produce a series of x and y-axis log-transformed histograms,> producing one histogram for each distinct label class in the dataset:> > > # Group A, log transformed> > ggplot(group_a, aes(x = anomaly_score)) +>????? geom_histogram(aes(y = ..count..), binwidth = 0.05,>????? colour = "darkgoldenrod1", fill = "darkgoldenrod2") +>????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") > +>????? scale_y_continuous(trans="log2", name="Log-transformed Frequency > Counts") +>????? ggtitle("Transformed Anomaly Scores - Group A Only")> > > # Group A transformed histogram is produced here.> > > > # Group B, log transformed> >? ggplot(group_b, aes(x = anomaly_score)) +>????? geom_histogram(aes(y = ..count..), binwidth = 0.05,>????? colour = "green", fill = "darkgreen") +>????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") > +>????? scale_y_continuous(trans="log2", name="Log-transformed Frequency > Counts") +>????? ggtitle("Transformed Anomaly Scores - Group B Only")> > # Group B transformed histogram is produced here.> > > > # Group C, log transformed> >? ggplot(group_c, aes(x = anomaly_score)) +>????? geom_histogram(aes(y = ..count..), binwidth = 0.05,>????? colour = "red", fill = "darkred") +>????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") > +>????? scale_y_continuous(trans="log2", name="Log-transformed Frequency > Counts") +>????? ggtitle("Transformed Anomaly Scores - Group C Only")> > # Group C transformed histogram is produced here.> > > # End.> > > > Thanks in advance, everyone!> > > - Tom> > > Thomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, > MS> On Target Technologies, Inc.> Virginia, USA> > ______________________________________________> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide > http://www.R-project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.------------------------------Subject: Digest Footer_______________________________________________R-help at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.------------------------------End of R-help Digest, Vol 222, Issue 4**************************************
	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Aug  4 15:51:52 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 4 Aug 2021 15:51:52 +0200
Subject: [R] How to ignore outliers in a boxplot
Message-ID: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>

Hi

I have values like:

var= c(0, 0, 0,0, 0, 14, 0, 14, 0, 2, 3)

I want to show these values in a boxplot

boxplot (var)

However, the boxplot shows only the zero values and the value till 14 are
shown as outliers.. I want to show all my values as boxplot, can I do that?

If I use outline=F, it excludes all the outliers.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Aug  4 16:01:46 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 4 Aug 2021 15:01:46 +0100
Subject: [R] How to ignore outliers in a boxplot
In-Reply-To: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>
References: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>
Message-ID: <aac00ab8-d192-af2b-a86a-54be812828df@sapo.pt>

Hello,

I'm not sure whether you are looking for argument range:


boxplot(var, range = 0)


14 is now part of the whiskers, see ?boxplot.

Hope this helps,

Rui Barradas

?s 14:51 de 04/08/21, Neha gupta escreveu:
> Hi
> 
> I have values like:
> 
> var= c(0, 0, 0,0, 0, 14, 0, 14, 0, 2, 3)
> 
> I want to show these values in a boxplot
> 
> boxplot (var)
> 
> However, the boxplot shows only the zero values and the value till 14 are
> shown as outliers.. I want to show all my values as boxplot, can I do that?
> 
> If I use outline=F, it excludes all the outliers.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Aug  4 16:04:05 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 4 Aug 2021 16:04:05 +0200
Subject: [R] How to ignore outliers in a boxplot
In-Reply-To: <aac00ab8-d192-af2b-a86a-54be812828df@sapo.pt>
References: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>
 <aac00ab8-d192-af2b-a86a-54be812828df@sapo.pt>
Message-ID: <CA+nrPntYsyFCye-_xw1d=6k72UDTOXnrp9WupezyssTsWjwHQg@mail.gmail.com>

Thanks a lot Sir

Yes, that's what I was looking for.

Warm regards

On Wed, Aug 4, 2021 at 4:01 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I'm not sure whether you are looking for argument range:
>
>
> boxplot(var, range = 0)
>
>
> 14 is now part of the whiskers, see ?boxplot.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 14:51 de 04/08/21, Neha gupta escreveu:
> > Hi
> >
> > I have values like:
> >
> > var= c(0, 0, 0,0, 0, 14, 0, 14, 0, 2, 3)
> >
> > I want to show these values in a boxplot
> >
> > boxplot (var)
> >
> > However, the boxplot shows only the zero values and the value till 14 are
> > shown as outliers.. I want to show all my values as boxplot, can I do
> that?
> >
> > If I use outline=F, it excludes all the outliers.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Aug  5 06:57:11 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 4 Aug 2021 21:57:11 -0700
Subject: [R] Help with package EasyPubmed
In-Reply-To: <1046636584.2205366.1628014852065@mail.yahoo.com>
References: <1046636584.2205366.1628014852065.ref@mail.yahoo.com>
 <1046636584.2205366.1628014852065@mail.yahoo.com>
Message-ID: <1D3CCD60-0C84-4B36-AF52-FB491F6C30EC@comcast.net>



> On Aug 3, 2021, at 11:20 AM, bharat rawlley via R-help <r-help at r-project.org> wrote:
> 
> Hello, 
> When I try to run the following code using the package Easypubmed, I get a null result - 
>> batch_pubmed_download(query_7)
> NULL
> #query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"
> However, the exact same search string yields 668 results on Pubmed. 

Did you try with: 
'Cardiology AND "randomized controlled trial"[Filter] AND 2011[PDAT]'

DAVID.

> 
> 
> I am unable to figure out why this is happening. If I use the search string "Cardiology AND 2011[PDAT]" then it works just fine. 
> Any help would be greatly appreciated
> Thank you! 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug  5 11:53:17 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 5 Aug 2021 19:53:17 +1000
Subject: [R] Long Format data
In-Reply-To: <CAFfFd+uViqwkFfELZzzQomzCWyDqQ2HmoB+Qshs2vv_ShOzzig@mail.gmail.com>
References: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
 <CAFfFd+uViqwkFfELZzzQomzCWyDqQ2HmoB+Qshs2vv_ShOzzig@mail.gmail.com>
Message-ID: <CA+8X3fWtCM7TOt9B_0n7d0py5CbqqjUEE+pBexkHQu8Q1wp2Ag@mail.gmail.com>

Hi Admire,
I think rep_n_stack in the prettyR package may do what you want:

# download and install the prettyR package
install.packages("prettyR")
# load the prettyR package
library(prettyR)
# read in your data
ATCdf<-read.csv("BOP_All_Countries.csv",stringsAsFactors=TRUE)
# convert the values you want to long format
ATClong<-rep_n_stack(ATCdf,to.stack=3:17,stack.names=c("year","value"))
# as your column names in Excel will be coerced to character values by
prepending "X",
# coerce them back to numeric
ATClong$year<-as.numeric(substr(ATClong$year,2,5))
# check the first row
ATClong[1,]

As the "Variables" column is messy, you may want to substitute the
numeric value in the long output and print a table of the numeric and
character values of the factor:

unique(ATClong$Variables)
ATClong$Variables<-as.numeric(ATClong$Variables)

Jim

On Tue, Aug 3, 2021 at 9:53 PM Admire Tarisirayi Chirume
<atchirume at gmail.com> wrote:
>
>
>
> Hello Jim, i hope you are well. I think my msg was rejected beacuse of the size of my files. I was kindly help me to structure data in the folder attached herewith in file BOP_All_Countries.csv. I am doing panel data analysis. I need it to be structured as it is on the file R_help.csv.
>
> Please kindly see the r-script below (r_help.R) that i ran which did not yield what i wanted.
>
> Thank you in advance for your help.
>
>
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug  5 15:16:22 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 5 Aug 2021 15:16:22 +0200
Subject: [R] Sanity check in loading large dataframe
Message-ID: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>

Hello,
I am using a large spreadsheet (over 600 variables).
I tried `str` to check the dimensions of the spreadsheet and I got
```
> (str(df))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
....
$ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
NULL
```
I understand that `[list output truncated]` means that there are more
variables than those allowed by str to be displayed as rows. Thus I
increased the row's output with:
```

> (str(df, list.len=1000))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
...
NULL
```

Does `NULL` mean that some of the variables are not closed? (perhaps a
missing comma somewhere)
Is there a way to check the sanity of the data and avoid that some
separator is not in the right place?
Thank you



-- 
Best regards,
Luigi


From @tch|rume @end|ng |rom gm@||@com  Thu Aug  5 15:23:54 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Thu, 5 Aug 2021 15:23:54 +0200
Subject: [R] Long Format data
In-Reply-To: <CA+8X3fWtCM7TOt9B_0n7d0py5CbqqjUEE+pBexkHQu8Q1wp2Ag@mail.gmail.com>
References: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
 <CAFfFd+uViqwkFfELZzzQomzCWyDqQ2HmoB+Qshs2vv_ShOzzig@mail.gmail.com>
 <CA+8X3fWtCM7TOt9B_0n7d0py5CbqqjUEE+pBexkHQu8Q1wp2Ag@mail.gmail.com>
Message-ID: <CAFfFd+sv6yLgJ_87Cc7d661KZkEa8mOtOAZpAMx2afu+6urjOg@mail.gmail.com>

Thank you very much, the code worked the trick. Thank you, i appreciate.

Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504


On Thu, Aug 5, 2021 at 11:53 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Admire,
> I think rep_n_stack in the prettyR package may do what you want:
>
> # download and install the prettyR package
> install.packages("prettyR")
> # load the prettyR package
> library(prettyR)
> # read in your data
> ATCdf<-read.csv("BOP_All_Countries.csv",stringsAsFactors=TRUE)
> # convert the values you want to long format
> ATClong<-rep_n_stack(ATCdf,to.stack=3:17,stack.names=c("year","value"))
> # as your column names in Excel will be coerced to character values by
> prepending "X",
> # coerce them back to numeric
> ATClong$year<-as.numeric(substr(ATClong$year,2,5))
> # check the first row
> ATClong[1,]
>
> As the "Variables" column is messy, you may want to substitute the
> numeric value in the long output and print a table of the numeric and
> character values of the factor:
>
> unique(ATClong$Variables)
> ATClong$Variables<-as.numeric(ATClong$Variables)
>
> Jim
>
> On Tue, Aug 3, 2021 at 9:53 PM Admire Tarisirayi Chirume
> <atchirume at gmail.com> wrote:
> >
> >
> >
> > Hello Jim, i hope you are well. I think my msg was rejected beacuse of
> the size of my files. I was kindly help me to structure data in the folder
> attached herewith in file BOP_All_Countries.csv. I am doing panel data
> analysis. I need it to be structured as it is on the file R_help.csv.
> >
> > Please kindly see the r-script below (r_help.R) that i ran which did not
> yield what i wanted.
> >
> > Thank you in advance for your help.
> >
> >
> > Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> > Skype: admirechirume
> > Call: +263773369884
> > whatsapp: +818099861504
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Aug  5 15:40:51 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Aug 2021 09:40:51 -0400
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
Message-ID: <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>

On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
 > Hello,
 > I am using a large spreadsheet (over 600 variables).
 > I tried `str` to check the dimensions of the spreadsheet and I got
 > ```
 >> (str(df))
 > 'data.frame': 302 obs. of  626 variables:
 >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
 > ....
 > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
 >    [list output truncated]
 > NULL
 > ```
 > I understand that `[list output truncated]` means that there are more
 > variables than those allowed by str to be displayed as rows. Thus I
 > increased the row's output with:
 > ```
 >
 >> (str(df, list.len=1000))
 > 'data.frame': 302 obs. of  626 variables:
 >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
 > ...
 > NULL
 > ```
 >
 > Does `NULL` mean that some of the variables are not closed? (perhaps a
 > missing comma somewhere)
 > Is there a way to check the sanity of the data and avoid that some
 > separator is not in the right place?
 > Thank you

The NULL is the value returned by str().  Normally it is not printed, 
but when you wrap str in parens as (str(df, list.len=1000)), that forces 
the value to print.

str() is unusual in R functions in that it prints to the console as it 
runs and returns nothing.  Many other functions construct a value which 
is only displayed if you print it, but something like

x <- str(df, list.len=1000)

will print the same as if there was no assignment, and then assign NULL 
to x.

Duncan Murdoch


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Aug  5 18:01:52 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 5 Aug 2021 12:01:52 -0400
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
Message-ID: <025301d78a13$3501c880$9f055980$@verizon.net>

Luigi,

Duncan answered part of your question. My feedback is to consider looking at
your data using other tools besides str(). 

There are ways in base R to get lists of row or column names or count them
or ask what types they are and so forth.

Printing an entire large object is hard but printing many subsets can give
you a handle on it.

You may also want to use packages in the tidyverse such as dplyr and work
with tibbles as a mild variation on a data.frame.

I am not sure what you are hoping to do with str() besides getting the
number of rows and columns but consider:

	dim(df)
	nrow(df)
	ncol(df)

To get names: 
	names(df)
	colnames(df)
	rownames(df)

To get many kinds of info about columns in your data.frame, various
functional methods like this can be used:
	sapply(df, typeof)

The above will tell you for each column if it is an integer or double or
other things.
	
To do more interesting things there are packages. The psych package, for
example, lets you get some metrics about each column:
	psych::describe(df)

And you can use various methods of subsetting to limit what you are looking
at and only show or print a manageable amount.

You seem to be asking about sanity checking in your subject line and that
depends on what you want to check. Clearly that can include making sure
various columns of data are valid in being of the expected data type or not
having any NA values or even removing outliers and so on. Tools are there
for much of that including the few I mention. Your data may seem huge but I
have worked on much larger ones. One suggestion is to consider trimming some
of that data before working on it IF some is not needed. Both base R and the
tidyverse have lots to offer to do such things.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
Sent: Thursday, August 5, 2021 9:16 AM
To: r-help <r-help at r-project.org>
Subject: [R] Sanity check in loading large dataframe

Hello,
I am using a large spreadsheet (over 600 variables).
I tried `str` to check the dimensions of the spreadsheet and I got ```
> (str(df))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
....
$ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
NULL
```
I understand that `[list output truncated]` means that there are more
variables than those allowed by str to be displayed as rows. Thus I
increased the row's output with:
```

> (str(df, list.len=1000))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
...
NULL
```

Does `NULL` mean that some of the variables are not closed? (perhaps a
missing comma somewhere) Is there a way to check the sanity of the data and
avoid that some separator is not in the right place?
Thank you



--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 07:34:05 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 07:34:05 +0200
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
Message-ID: <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>

Ok, so nothing to worry about. Yet, are there other checks I can implement?
Thank you

On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com> wrote:

> On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
>  > Hello,
>  > I am using a large spreadsheet (over 600 variables).
>  > I tried `str` to check the dimensions of the spreadsheet and I got
>  > ```
>  >> (str(df))
>  > 'data.frame': 302 obs. of  626 variables:
>  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
>  > ....
>  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
>  >    [list output truncated]
>  > NULL
>  > ```
>  > I understand that `[list output truncated]` means that there are more
>  > variables than those allowed by str to be displayed as rows. Thus I
>  > increased the row's output with:
>  > ```
>  >
>  >> (str(df, list.len=1000))
>  > 'data.frame': 302 obs. of  626 variables:
>  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
>  > ...
>  > NULL
>  > ```
>  >
>  > Does `NULL` mean that some of the variables are not closed? (perhaps a
>  > missing comma somewhere)
>  > Is there a way to check the sanity of the data and avoid that some
>  > separator is not in the right place?
>  > Thank you
>
> The NULL is the value returned by str().  Normally it is not printed,
> but when you wrap str in parens as (str(df, list.len=1000)), that forces
> the value to print.
>
> str() is unusual in R functions in that it prints to the console as it
> runs and returns nothing.  Many other functions construct a value which
> is only displayed if you print it, but something like
>
> x <- str(df, list.len=1000)
>
> will print the same as if there was no assignment, and then assign NULL
> to x.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Aug  6 09:56:34 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 6 Aug 2021 07:56:34 +0000
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
Message-ID: <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>

Hi 

You already got answer from Avi. I often use dim(data) to inspect how many
rows/columns I have.
After that I check if some columns contain all or many NA values.

colSums(is.na(data))
keep <- which(colSums(is.na(data))<nnn)
cleaned.data <- data[, keep]

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Friday, August 6, 2021 7:34 AM
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Sanity check in loading large dataframe
> 
> Ok, so nothing to worry about. Yet, are there other checks I can
implement?
> Thank you
> 
> On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com>
> wrote:
> 
> > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> >  > Hello,
> >  > I am using a large spreadsheet (over 600 variables).
> >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ....
> >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> >  >    [list output truncated]
> >  > NULL
> >  > ```
> >  > I understand that `[list output truncated]` means that there are
> > more  > variables than those allowed by str to be displayed as rows.
> > Thus I  > increased the row's output with:
> >  > ```
> >  >
> >  >> (str(df, list.len=1000))
> >  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ...
> >  > NULL
> >  > ```
> >  >
> >  > Does `NULL` mean that some of the variables are not closed?
> > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > sanity of the data and avoid that some  > separator is not in the
> > right place?
> >  > Thank you
> >
> > The NULL is the value returned by str().  Normally it is not printed,
> > but when you wrap str in parens as (str(df, list.len=1000)), that
> > forces the value to print.
> >
> > str() is unusual in R functions in that it prints to the console as it
> > runs and returns nothing.  Many other functions construct a value
> > which is only displayed if you print it, but something like
> >
> > x <- str(df, list.len=1000)
> >
> > will print the same as if there was no assignment, and then assign
> > NULL to x.
> >
> > Duncan Murdoch
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 10:15:35 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 10:15:35 +0200
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2Tmzi+qF3mcRhLn7PJXtM63PoODCicCmSxB1WHQDSqRtQ@mail.gmail.com>

OK, thank you.

On Fri, Aug 6, 2021 at 9:56 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> You already got answer from Avi. I often use dim(data) to inspect how many
> rows/columns I have.
> After that I check if some columns contain all or many NA values.
>
> colSums(is.na(data))
> keep <- which(colSums(is.na(data))<nnn)
> cleaned.data <- data[, keep]
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Friday, August 6, 2021 7:34 AM
> > To: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Sanity check in loading large dataframe
> >
> > Ok, so nothing to worry about. Yet, are there other checks I can
> implement?
> > Thank you
> >
> > On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com>
> > wrote:
> >
> > > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> > >  > Hello,
> > >  > I am using a large spreadsheet (over 600 variables).
> > >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ....
> > >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> > >  >    [list output truncated]
> > >  > NULL
> > >  > ```
> > >  > I understand that `[list output truncated]` means that there are
> > > more  > variables than those allowed by str to be displayed as rows.
> > > Thus I  > increased the row's output with:
> > >  > ```
> > >  >
> > >  >> (str(df, list.len=1000))
> > >  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ...
> > >  > NULL
> > >  > ```
> > >  >
> > >  > Does `NULL` mean that some of the variables are not closed?
> > > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > > sanity of the data and avoid that some  > separator is not in the
> > > right place?
> > >  > Thank you
> > >
> > > The NULL is the value returned by str().  Normally it is not printed,
> > > but when you wrap str in parens as (str(df, list.len=1000)), that
> > > forces the value to print.
> > >
> > > str() is unusual in R functions in that it prints to the console as it
> > > runs and returns nothing.  Many other functions construct a value
> > > which is only displayed if you print it, but something like
> > >
> > > x <- str(df, list.len=1000)
> > >
> > > will print the same as if there was no assignment, and then assign
> > > NULL to x.
> > >
> > > Duncan Murdoch
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug  6 13:28:46 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 6 Aug 2021 04:28:46 -0700
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>

... but remove the which() and use logical indexing ...  ;-)

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 6, 2021 at 12:57 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You already got answer from Avi. I often use dim(data) to inspect how many
> rows/columns I have.
> After that I check if some columns contain all or many NA values.
>
> colSums(is.na(data))
> keep <- which(colSums(is.na(data))<nnn)
> cleaned.data <- data[, keep]
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Friday, August 6, 2021 7:34 AM
> > To: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Sanity check in loading large dataframe
> >
> > Ok, so nothing to worry about. Yet, are there other checks I can
> implement?
> > Thank you
> >
> > On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com>
> > wrote:
> >
> > > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> > >  > Hello,
> > >  > I am using a large spreadsheet (over 600 variables).
> > >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ....
> > >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> > >  >    [list output truncated]
> > >  > NULL
> > >  > ```
> > >  > I understand that `[list output truncated]` means that there are
> > > more  > variables than those allowed by str to be displayed as rows.
> > > Thus I  > increased the row's output with:
> > >  > ```
> > >  >
> > >  >> (str(df, list.len=1000))
> > >  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ...
> > >  > NULL
> > >  > ```
> > >  >
> > >  > Does `NULL` mean that some of the variables are not closed?
> > > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > > sanity of the data and avoid that some  > separator is not in the
> > > right place?
> > >  > Thank you
> > >
> > > The NULL is the value returned by str().  Normally it is not printed,
> > > but when you wrap str in parens as (str(df, list.len=1000)), that
> > > forces the value to print.
> > >
> > > str() is unusual in R functions in that it prints to the console as it
> > > runs and returns nothing.  Many other functions construct a value
> > > which is only displayed if you print it, but something like
> > >
> > > x <- str(df, list.len=1000)
> > >
> > > will print the same as if there was no assignment, and then assign
> > > NULL to x.
> > >
> > > Duncan Murdoch
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 16:13:18 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 16:13:18 +0200
Subject: [R] split element vector
Message-ID: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>

Hello,
I have a vector that contains some elements with concatenated values, such as:
```
> vect
[1] "name_1"
[2] "name_2"
[3] "name_3\nsurname_3"
[4] "some other text\netc"
```
How can I create a new vector where each component is an element, such as:
```
> vect
[1] "name_1"
[2] "name_2"
[3] "name_3"
[4] "surname_3"
[5] "some other text"
[6] "etc"
```
I can split the elements on '\n' but how do I transfer these directly
on a new vector?
Thanks


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Aug  6 16:17:45 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 6 Aug 2021 07:17:45 -0700
Subject: [R] split element vector
In-Reply-To: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>
References: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>
Message-ID: <CAHqSRuQeH403gj7pTkPLF5Y4sEnXmTuqAJhUqbcznbzo4xjR_w@mail.gmail.com>

unlist(strsplit(vect, "\n"))

On Fri, Aug 6, 2021 at 7:13 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have a vector that contains some elements with concatenated values, such
> as:
> ```
> > vect
> [1] "name_1"
> [2] "name_2"
> [3] "name_3\nsurname_3"
> [4] "some other text\netc"
> ```
> How can I create a new vector where each component is an element, such as:
> ```
> > vect
> [1] "name_1"
> [2] "name_2"
> [3] "name_3"
> [4] "surname_3"
> [5] "some other text"
> [6] "etc"
> ```
> I can split the elements on '\n' but how do I transfer these directly
> on a new vector?
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 16:49:15 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 16:49:15 +0200
Subject: [R] split element vector
In-Reply-To: <CAHqSRuQeH403gj7pTkPLF5Y4sEnXmTuqAJhUqbcznbzo4xjR_w@mail.gmail.com>
References: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>
 <CAHqSRuQeH403gj7pTkPLF5Y4sEnXmTuqAJhUqbcznbzo4xjR_w@mail.gmail.com>
Message-ID: <CAMk+s2RXcft_ayPgU6Fd_rtYzCrkx0pqF+a0Ujwt9ojS-RqdUg@mail.gmail.com>

Perfect!
thank you

On Fri, Aug 6, 2021 at 4:17 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> unlist(strsplit(vect, "\n"))
>
> On Fri, Aug 6, 2021 at 7:13 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I have a vector that contains some elements with concatenated values, such as:
>> ```
>> > vect
>> [1] "name_1"
>> [2] "name_2"
>> [3] "name_3\nsurname_3"
>> [4] "some other text\netc"
>> ```
>> How can I create a new vector where each component is an element, such as:
>> ```
>> > vect
>> [1] "name_1"
>> [2] "name_2"
>> [3] "name_3"
>> [4] "surname_3"
>> [5] "some other text"
>> [6] "etc"
>> ```
>> I can split the elements on '\n' but how do I transfer these directly
>> on a new vector?
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Aug  6 18:02:42 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 6 Aug 2021 17:02:42 +0100
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A@mail.gmail.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>
 <CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A@mail.gmail.com>
Message-ID: <e2f33304-bae1-8b23-5376-fe26856a2046@dewey.myzen.co.uk>

Sent off-list

Thanks Bill and Duncan. I only asked for advice but I got an education too.

Michael

On 03/08/2021 21:24, Bill Dunlap wrote:
> In maximum likelihood problems, even when the individual density values 
> are fairly far from zero, their product may underflow to zero.  
> Optimizers have problems when there is a?large flat area.
>  ? ?> q <- runif(n=1000, -0.1, +0.1)
>  ? ?> prod(dnorm(q))
>  ? ?[1] 0
>  ? ?> sum(dnorm(q, log=TRUE))
>  ? ?[1] -920.6556
> 
> A more minor advantage for some probability-related functions is speed.  
> E.g., dnorm(log=TRUE,...) does not need to evaluate?exp().
>  ? ?> q <- runif(1e6, -10, 10)
>  ? ?> system.time(for(i in 1:100)dnorm(q, log=FALSE))
>  ? ? ? user ?system elapsed
>  ? ? ? 9.13 ? ?0.11 ? ?9.23
>  ? ?> system.time(for(i in 1:100)dnorm(q, log=TRUE))
>  ? ? ? user ?system elapsed
>  ? ? ? 4.60 ? ?0.19 ? ?4.78
> 
>  ?-Bill
> 
> On Tue, Aug 3, 2021 at 11:53 AM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 03/08/2021 12:20 p.m., Michael Dewey wrote:
>      > Short version
>      >
>      > Apart from the ability to work with values of p too small to be
>     of much
>      > practical use what are the advantages and disadvantages of
>     setting this
>      > to TRUE?
>      >
>      > Longer version
>      >
>      > I am contemplating upgrading various functions in one of my
>     packages to
>      > use this and as far as I can see it would only have the advantage of
>      > allowing people to use very small p-values but before I go ahead
>     have I
>      > missed anything? I am most concerned with negatives but if there
>     is any
>      > other advantage I would mention that in the vignette. I am not
>     concerned
>      > about speed or the extra effort in coding and expanding the
>     documentation.
>      >
> 
>     These are often needed in likelihood problems.? In just about any
>     problem where the normal density shows up in the likelihood, you're
>     better off working with the log likelihood and setting log = TRUE in
>     dnorm, because sometimes you want to evaluate the likelihood very far
>     from its mode.
> 
>     The same sort of thing happens with pnorm for similar reasons.? Some
>     likelihoods involve normal integrals and will need it.
> 
>     I can't think of an example for qnorm off the top of my head, but I
>     imagine there are some:? maybe involving simulation way out in the
>     tails.
> 
>     The main negative about using logs is that they aren't always needed.
> 
>     Duncan Murdoch
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 	Virus-free. www.avg.com 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 
> 
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From hu@p|ng@w@n @end|ng |rom gm@||@com  Sat Aug  7 09:57:17 2021
From: hu@p|ng@w@n @end|ng |rom gm@||@com (hp wan)
Date: Sat, 7 Aug 2021 15:57:17 +0800
Subject: [R] SOS package: findFn does not work
Message-ID: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>

Dear All,

Recently, I found that the SOS package (very helpful package) does not
work.  When I used the "findFn" function to search something, it always
said "found 0 matches" (see below). My desktop system is Win 10 and R
version is R-4.1.0. Any suggestion was greatly appreciated.

HP


> z <- findFn("spline", maxPages = 2)
found 0 matches
Warning message:
In findFn("spline", maxPages = 2) :
  HIT not found in HTML;  processing one page only.

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sat Aug  7 12:39:29 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sat, 7 Aug 2021 05:39:29 -0500
Subject: [R] SOS package: findFn does not work
In-Reply-To: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
References: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
Message-ID: <6043d8f0-8ca8-1ce8-b830-8398dc16bb9c@effectivedefense.org>

Thanks for the question.  Two things:


** 1.  TRY THE DEVELOPMENT VERSION OBTAINABLE AS FOLLOWS:


install.packages('devtools') # if it's not installed


library(devtools)


install_github("sbgraves237/sos")


library(sos)


  z <- findFn("spline", maxPages = 2)


# This should work.


** 2.  PLEASE PROVIDE:


sessionInfo()


	  "findFn('spline')" just worked for me using both the CRAN and 
development versions of sos.  (2.1-0 from CRAN under Windows 10; 2.1- 
from GitHub under macOS 11.4; both with R 4.1.0).


	  I need to push the GitHub version to CRAN.  However, it would help me 
if I understood your configuration and if the GitHub version fixes the 
problem for you.


	  Thanks for the report.  I apologize for the inconvenience.


	  Spencer Graves


On 8/7/21 2:57 AM, hp wan wrote:
> Dear All,
> 
> Recently, I found that the SOS package (very helpful package) does not
> work.  When I used the "findFn" function to search something, it always
> said "found 0 matches" (see below). My desktop system is Win 10 and R
> version is R-4.1.0. Any suggestion was greatly appreciated.
> 
> HP
> 
> 
>> z <- findFn("spline", maxPages = 2)
> found 0 matches
> Warning message:
> In findFn("spline", maxPages = 2) :
>    HIT not found in HTML;  processing one page only.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  7 12:42:23 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 7 Aug 2021 11:42:23 +0100
Subject: [R] SOS package: findFn does not work
In-Reply-To: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
References: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
Message-ID: <29cef7dd-0b0d-3189-2131-432b91279d0b@sapo.pt>

Hello,

R 4.1.0 on Ubuntu 20.04.
I cannot reproduce this:


sos::findFn("spline", maxPages = 2)
#found 3867 matches;  retrieving 2 pages, 40 matches.
#2
#Downloaded 40 links in 27 packages.


Possible solutions are to close and restart R and to check your internet 
connection.
Is the package updated?

packageVersion("sos")
#[1] ?2.1.0?


Hope this helps,

Rui Barradas

?s 08:57 de 07/08/21, hp wan escreveu:
> Dear All,
> 
> Recently, I found that the SOS package (very helpful package) does not
> work.  When I used the "findFn" function to search something, it always
> said "found 0 matches" (see below). My desktop system is Win 10 and R
> version is R-4.1.0. Any suggestion was greatly appreciated.
> 
> HP
> 
> 
>> z <- findFn("spline", maxPages = 2)
> found 0 matches
> Warning message:
> In findFn("spline", maxPages = 2) :
>    HIT not found in HTML;  processing one page only.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From er|cjberger @end|ng |rom gm@||@com  Sat Aug  7 14:35:42 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 7 Aug 2021 15:35:42 +0300
Subject: [R] SOS package: findFn does not work
In-Reply-To: <29cef7dd-0b0d-3189-2131-432b91279d0b@sapo.pt>
References: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
 <29cef7dd-0b0d-3189-2131-432b91279d0b@sapo.pt>
Message-ID: <CAGgJW760CJAvbUtQDPkOXHvkqHfmMMg-faKw_xOcwn=72pVpwg@mail.gmail.com>

Hi,
I was able to reproduce this problem on R 4.0.3 on Ubuntu 20.04.
I removed the CRAN sos package and installed the github version per
Spencer's advice.
After that it worked fine.

Eric


On Sat, Aug 7, 2021 at 1:50 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> R 4.1.0 on Ubuntu 20.04.
> I cannot reproduce this:
>
>
> sos::findFn("spline", maxPages = 2)
> #found 3867 matches;  retrieving 2 pages, 40 matches.
> #2
> #Downloaded 40 links in 27 packages.
>
>
> Possible solutions are to close and restart R and to check your internet
> connection.
> Is the package updated?
>
> packageVersion("sos")
> #[1] ?2.1.0?
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 08:57 de 07/08/21, hp wan escreveu:
> > Dear All,
> >
> > Recently, I found that the SOS package (very helpful package) does not
> > work.  When I used the "findFn" function to search something, it always
> > said "found 0 matches" (see below). My desktop system is Win 10 and R
> > version is R-4.1.0. Any suggestion was greatly appreciated.
> >
> > HP
> >
> >
> >> z <- findFn("spline", maxPages = 2)
> > found 0 matches
> > Warning message:
> > In findFn("spline", maxPages = 2) :
> >    HIT not found in HTML;  processing one page only.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @gent@ @end|ng |rom medd@t@|nc@com  Sun Aug  8 03:21:31 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Sat, 7 Aug 2021 21:21:31 -0400
Subject: [R] Markov modeling using msm
Message-ID: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>

I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...

The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?

If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?

Appreciate any pointers.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Aug  8 04:33:31 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Aug 2021 19:33:31 -0700
Subject: [R] Markov modeling using msm
In-Reply-To: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
References: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
Message-ID: <CAGxFJbSYCNz3B9-FZJunam_JFVGKwGqoQ4WDLv0j2EQr-VQqqA@mail.gmail.com>

Please read the posting guide linked below, which says, in part:

"Questions about statistics: The R mailing lists are primarily
intended for questions and discussion about the R software. However,
questions about statistical methodology are sometimes posted. If the
question is well-asked and of interest to someone on the list, it may
elicit an informative up-to-date answer. "

So do not be surprised if you do not get a response here.
stats.stackexchange.com may be a better venue for your query, too.

The posting guide also says:
"For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
If the question relates to a contributed package , e.g., one
downloaded from CRAN, try contacting the package maintainer first. You
can also use find("functionname") and
packageDescription("packagename") to find this information. Only send
such questions to R-help or R-devel if you get no reply or need
further assistance. This applies to both requests for help and to bug
reports."

So perhaps contacting the msm maintainer might be another possibility.
See ?maintainer for how to find their contact info.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 7, 2021 at 6:21 PM H <agents at meddatainc.com> wrote:
>
> I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...
>
> The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?
>
> If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?
>
> Appreciate any pointers.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  8 04:45:07 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 8 Aug 2021 14:45:07 +1200
Subject: [R] No "doc" directory in my installation  of R.
Message-ID: <20210808144507.61a8290e@rolf-Latitude-E7470>


Should/shouldn't there be one?

My R seems to be installed in /usr/lib/R.  If do an "ls" of this
directory, I get:

> bin/  COPYING@	etc/  lib/  library/  modules/
> site-library/  SVN-REVISION

Definitely no "doc".

The (only) reason that I am concerned about this, is that I have decided
to experiment a bit with Rstudio, and it apparently wants a "doc"
directory.  When I try to start Rstudio I get a pop-up window with the
error message

> R doc dir (/usr/local/lib64/R/doc) not found.

Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
The latter is where my installation put R; the former seems to be where
Rstudio wants it to.  So I created the symbolic link.

The discrepancy between locations is another puzzle/worry.

My installation comes from a pre-built binary ("sudo apt install
r-base").  I apparently have the latest version.  I remark that I am
running Ubuntu 20.04 with a Mate 1.20.4 desktop.

How can I get a "doc" directory into my R directory and make Rstudio
happy?

cheers,

Rolf Turner

P.S. I have also tried to ask about this on the  Rstudio community
forum, but it seems to me to more of an R question than an Rstudio one.

R. T.

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug  8 05:26:13 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 7 Aug 2021 20:26:13 -0700 (PDT)
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210808144507.61a8290e@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
Message-ID: <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>

R documentation on my Ubuntu 20.20 is in /usr/share/R/doc.

I see no doc directories in the locations you mention using

   locate /doc/

Maybe you should be asking on R-sig-debian, perhaps with less noise about 
RStudio?

On Sun, 8 Aug 2021, Rolf Turner wrote:

>
> Should/shouldn't there be one?
>
> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> directory, I get:
>
>> bin/  COPYING@	etc/  lib/  library/  modules/
>> site-library/  SVN-REVISION
>
> Definitely no "doc".
>
> The (only) reason that I am concerned about this, is that I have decided
> to experiment a bit with Rstudio, and it apparently wants a "doc"
> directory.  When I try to start Rstudio I get a pop-up window with the
> error message
>
>> R doc dir (/usr/local/lib64/R/doc) not found.
>
> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> The latter is where my installation put R; the former seems to be where
> Rstudio wants it to.  So I created the symbolic link.
>
> The discrepancy between locations is another puzzle/worry.
>
> My installation comes from a pre-built binary ("sudo apt install
> r-base").  I apparently have the latest version.  I remark that I am
> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>
> How can I get a "doc" directory into my R directory and make Rstudio
> happy?
>
> cheers,
>
> Rolf Turner
>
> P.S. I have also tried to ask about this on the  Rstudio community
> forum, but it seems to me to more of an R question than an Rstudio one.
>
> R. T.
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From drj|m|emon @end|ng |rom gm@||@com  Sun Aug  8 06:29:30 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 8 Aug 2021 14:29:30 +1000
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210808144507.61a8290e@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
Message-ID: <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>

Hi Rolf,
What about:

mkdir /usr/lib/R/doc

Jim

On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Should/shouldn't there be one?
>
> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> directory, I get:
>
> > bin/  COPYING@        etc/  lib/  library/  modules/
> > site-library/  SVN-REVISION
>
> Definitely no "doc".
>
> The (only) reason that I am concerned about this, is that I have decided
> to experiment a bit with Rstudio, and it apparently wants a "doc"
> directory.  When I try to start Rstudio I get a pop-up window with the
> error message
>
> > R doc dir (/usr/local/lib64/R/doc) not found.
>
> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> The latter is where my installation put R; the former seems to be where
> Rstudio wants it to.  So I created the symbolic link.
>
> The discrepancy between locations is another puzzle/worry.
>
> My installation comes from a pre-built binary ("sudo apt install
> r-base").  I apparently have the latest version.  I remark that I am
> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>
> How can I get a "doc" directory into my R directory and make Rstudio
> happy?
>
> cheers,
>
> Rolf Turner
>
> P.S. I have also tried to ask about this on the  Rstudio community
> forum, but it seems to me to more of an R question than an Rstudio one.
>
> R. T.
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  8 09:43:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Aug 2021 08:43:17 +0100
Subject: [R] Markov modeling using msm
In-Reply-To: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
References: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
Message-ID: <da291c0c-3657-264c-66cb-46f16c275595@sapo.pt>

Hello,

There are CRAN packages, for instance, packages DTMCPack and 
markovchain, that require transition probabilities as input. See this 
R-bloggers post [1].


[1] https://www.r-bloggers.com/2016/01/getting-started-with-markov-chains/


Hope this helps,

Rui Barradas

?s 02:21 de 08/08/21, H escreveu:
> I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...
> 
> The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?
> 
> If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?
> 
> Appreciate any pointers.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkr|de@u @end|ng |rom gm@||@com  Sun Aug  8 14:51:16 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sun, 8 Aug 2021 08:51:16 -0400
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
Message-ID: <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>

R version 4.1.0 (2021-05-18)
RStudio 1.4.1714
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.2 LTS

I do not see a doc folder at R level but a lot of newer packages,
probably tidyverse derived seem to have a doc sub-folder containing
documentation files

For example corrplot has a doc subfolder containing
corrplot-intro.html
corrplot-intro.R
corrplot-intro.Rmd
index.html

Jim Lemon's suggestion seems worth trying but I really think this is
some RStudio weirdity. I have been using RStudio for 3-4 years and a
several complete installations on new machines and tave never seen
anything like "R doc dir (/usr/local/lib64/R/doc) not found".

RStudio keeps getting tweaked.



On Sun, 8 Aug 2021 at 00:30, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Rolf,
> What about:
>
> mkdir /usr/lib/R/doc
>
> Jim
>
> On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > Should/shouldn't there be one?
> >
> > My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> > directory, I get:
> >
> > > bin/  COPYING@        etc/  lib/  library/  modules/
> > > site-library/  SVN-REVISION
> >
> > Definitely no "doc".
> >
> > The (only) reason that I am concerned about this, is that I have decided
> > to experiment a bit with Rstudio, and it apparently wants a "doc"
> > directory.  When I try to start Rstudio I get a pop-up window with the
> > error message
> >
> > > R doc dir (/usr/local/lib64/R/doc) not found.
> >
> > Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> > The latter is where my installation put R; the former seems to be where
> > Rstudio wants it to.  So I created the symbolic link.
> >
> > The discrepancy between locations is another puzzle/worry.
> >
> > My installation comes from a pre-built binary ("sudo apt install
> > r-base").  I apparently have the latest version.  I remark that I am
> > running Ubuntu 20.04 with a Mate 1.20.4 desktop.
> >
> > How can I get a "doc" directory into my R directory and make Rstudio
> > happy?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > P.S. I have also tried to ask about this on the  Rstudio community
> > forum, but it seems to me to more of an R question than an Rstudio one.
> >
> > R. T.
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  8 15:15:23 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 8 Aug 2021 09:15:23 -0400
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
 <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>
Message-ID: <1467d67e-2aa9-bb8d-d3e1-42843cb55aa8@gmail.com>

Jeff pointed out where the doc directory is installed in Ubuntu: 
/usr/share/R/doc.  So this is definitely an RStudio issue:  perhaps it 
got "tweaked", or perhaps Rolf installed a version meant for some other 
distribution.  In either case, off-topic in R-help, I think.

Duncan Murdoch

On 08/08/2021 8:51 a.m., John Kane wrote:
> R version 4.1.0 (2021-05-18)
> RStudio 1.4.1714
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.2 LTS
> 
> I do not see a doc folder at R level but a lot of newer packages,
> probably tidyverse derived seem to have a doc sub-folder containing
> documentation files
> 
> For example corrplot has a doc subfolder containing
> corrplot-intro.html
> corrplot-intro.R
> corrplot-intro.Rmd
> index.html
> 
> Jim Lemon's suggestion seems worth trying but I really think this is
> some RStudio weirdity. I have been using RStudio for 3-4 years and a
> several complete installations on new machines and tave never seen
> anything like "R doc dir (/usr/local/lib64/R/doc) not found".
> 
> RStudio keeps getting tweaked.
> 
> 
> 
> On Sun, 8 Aug 2021 at 00:30, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Rolf,
>> What about:
>>
>> mkdir /usr/lib/R/doc
>>
>> Jim
>>
>> On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>
>>>
>>> Should/shouldn't there be one?
>>>
>>> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
>>> directory, I get:
>>>
>>>> bin/  COPYING@        etc/  lib/  library/  modules/
>>>> site-library/  SVN-REVISION
>>>
>>> Definitely no "doc".
>>>
>>> The (only) reason that I am concerned about this, is that I have decided
>>> to experiment a bit with Rstudio, and it apparently wants a "doc"
>>> directory.  When I try to start Rstudio I get a pop-up window with the
>>> error message
>>>
>>>> R doc dir (/usr/local/lib64/R/doc) not found.
>>>
>>> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
>>> The latter is where my installation put R; the former seems to be where
>>> Rstudio wants it to.  So I created the symbolic link.
>>>
>>> The discrepancy between locations is another puzzle/worry.
>>>
>>> My installation comes from a pre-built binary ("sudo apt install
>>> r-base").  I apparently have the latest version.  I remark that I am
>>> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>>>
>>> How can I get a "doc" directory into my R directory and make Rstudio
>>> happy?
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> P.S. I have also tried to ask about this on the  Rstudio community
>>> forum, but it seems to me to more of an R question than an Rstudio one.
>>>
>>> R. T.
>>>
>>> --
>>> Honorary Research Fellow
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  8 16:03:32 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Aug 2021 15:03:32 +0100
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <1467d67e-2aa9-bb8d-d3e1-42843cb55aa8@gmail.com>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
 <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>
 <1467d67e-2aa9-bb8d-d3e1-42843cb55aa8@gmail.com>
Message-ID: <59dc9698-697d-90d4-e64b-1f9e612ce488@sapo.pt>

Hello,

R 4.1.0 on Ubuntu 20.04.
My ls command on /usr/lib/R on my home computer gives what Rolf posted, 
so I agree with every body that this is not an R issue and would insist 
with RStudio and ask for their help again. They are generally helpful, btw.

I follow installation instructions to the letter and have never had any 
problems like this one. If the installation of R seems OK, have you 
tried to uninstall and reinstall RStudio?


rui at rui:~$ ls /usr/lib/R
bin  COPYING  etc  lib  library  modules  site-library  SVN-REVISION
rui at rui:~$ ls /usr/share/R
debian  doc  include  share


Hope this helps,

Rui Barradas


?s 14:15 de 08/08/21, Duncan Murdoch escreveu:
> Jeff pointed out where the doc directory is installed in Ubuntu: 
> /usr/share/R/doc.? So this is definitely an RStudio issue:? perhaps it 
> got "tweaked", or perhaps Rolf installed a version meant for some other 
> distribution.? In either case, off-topic in R-help, I think.
> 
> Duncan Murdoch
> 
> On 08/08/2021 8:51 a.m., John Kane wrote:
>> R version 4.1.0 (2021-05-18)
>> RStudio 1.4.1714
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 20.04.2 LTS
>>
>> I do not see a doc folder at R level but a lot of newer packages,
>> probably tidyverse derived seem to have a doc sub-folder containing
>> documentation files
>>
>> For example corrplot has a doc subfolder containing
>> corrplot-intro.html
>> corrplot-intro.R
>> corrplot-intro.Rmd
>> index.html
>>
>> Jim Lemon's suggestion seems worth trying but I really think this is
>> some RStudio weirdity. I have been using RStudio for 3-4 years and a
>> several complete installations on new machines and tave never seen
>> anything like "R doc dir (/usr/local/lib64/R/doc) not found".
>>
>> RStudio keeps getting tweaked.
>>
>>
>>
>> On Sun, 8 Aug 2021 at 00:30, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Rolf,
>>> What about:
>>>
>>> mkdir /usr/lib/R/doc
>>>
>>> Jim
>>>
>>> On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> 
>>> wrote:
>>>>
>>>>
>>>> Should/shouldn't there be one?
>>>>
>>>> My R seems to be installed in /usr/lib/R.? If do an "ls" of this
>>>> directory, I get:
>>>>
>>>>> bin/? COPYING@??????? etc/? lib/? library/? modules/
>>>>> site-library/? SVN-REVISION
>>>>
>>>> Definitely no "doc".
>>>>
>>>> The (only) reason that I am concerned about this, is that I have 
>>>> decided
>>>> to experiment a bit with Rstudio, and it apparently wants a "doc"
>>>> directory.? When I try to start Rstudio I get a pop-up window with the
>>>> error message
>>>>
>>>>> R doc dir (/usr/local/lib64/R/doc) not found.
>>>>
>>>> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
>>>> The latter is where my installation put R; the former seems to be where
>>>> Rstudio wants it to.? So I created the symbolic link.
>>>>
>>>> The discrepancy between locations is another puzzle/worry.
>>>>
>>>> My installation comes from a pre-built binary ("sudo apt install
>>>> r-base").? I apparently have the latest version.? I remark that I am
>>>> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>>>>
>>>> How can I get a "doc" directory into my R directory and make Rstudio
>>>> happy?
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> P.S. I have also tried to ask about this on the? Rstudio community
>>>> forum, but it seems to me to more of an R question than an Rstudio one.
>>>>
>>>> R. T.
>>>>
>>>> -- 
>>>> Honorary Research Fellow
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Sun Aug  8 16:52:20 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Sun, 8 Aug 2021 10:52:20 -0400
Subject: [R] Markov modeling using msm
In-Reply-To: <da291c0c-3657-264c-66cb-46f16c275595@sapo.pt>
References: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
 <da291c0c-3657-264c-66cb-46f16c275595@sapo.pt>
Message-ID: <5736aa5f-fbae-4c42-be93-3d6d6c36926b@meddatainc.com>

On 08/08/2021 03:43 AM, Rui Barradas wrote:
> Hello,
>
> There are CRAN packages, for instance, packages DTMCPack and markovchain, that require transition probabilities as input. See this R-bloggers post [1].
>
>
> [1] https://www.r-bloggers.com/2016/01/getting-started-with-markov-chains/
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 02:21 de 08/08/21, H escreveu:
>> I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...
>>
>> The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?
>>
>> If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?
>>
>> Appreciate any pointers.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
Thank you, will check those out!


From @|@y@hz@k@r|@ @end|ng |rom un|m@p@edu@my  Sat Aug  7 09:53:43 2021
From: @|@y@hz@k@r|@ @end|ng |rom un|m@p@edu@my (SITI AISYAH ZAKARIA)
Date: Sat, 7 Aug 2021 15:53:43 +0800
Subject: [R] HOW TO SOLVE THIS PROBLEM (RVALS)
Message-ID: <CALcx2Bmkkd1KmB9ASXOaaHQpipehFPqq-j6vSsDHG11+XHCbKQ@mail.gmail.com>

Hi,

Can anyone help me how to solve this problem?

 #calculation of confidence intervals
1. > nc <- 10000
2. > M1 <- matrix(rfrechet(nc*nobs),nrow=nobs,ncol=nc)
3. > M <- t(apply(M1,2,sort))
4. > E <- envelope(mat=M) #compute 95% confidance bands
*Error in envelope.matrix(mat = M) : rvals must be supplied*

My problem is after I run my coding in line 4 the error is highlighted red
is come out. I don't know how to solve it. Please help me.

Thank you

-- 





"..Millions of trees are used to make papers, only to be thrown away 
after a couple of minutes reading from them. Our planet is at stake. Please 
be considerate. THINK TWICE BEFORE PRINTING THIS.."

DISCLAIMER:?This email \ and any files transmitte...{{dropped:24}}


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  8 17:41:22 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Aug 2021 16:41:22 +0100
Subject: [R] HOW TO SOLVE THIS PROBLEM (RVALS)
In-Reply-To: <CALcx2Bmkkd1KmB9ASXOaaHQpipehFPqq-j6vSsDHG11+XHCbKQ@mail.gmail.com>
References: <CALcx2Bmkkd1KmB9ASXOaaHQpipehFPqq-j6vSsDHG11+XHCbKQ@mail.gmail.com>
Message-ID: <518f8de5-7548-9bbd-8bb3-86f213391bc0@sapo.pt>

Hello,

nobs is missing in your example.

Assuming that envelope is the function in package base boot, I cannot 
reproduce the error.


set.seed(2021)
nc <- 10000
nobs <- 100
M1 <- matrix(evd::rfrechet(nc*nobs),nrow=nobs,ncol=nc)
M <- t(apply(M1,2,sort))
E <- boot::envelope(mat=M) #compute 95% confidance bands

str(E)
#List of 7
# $ point  : num [1:2, 1:100] 0.302 0.12 0.341 0.167 0.373 ...
# $ overall: num [1:2, 1:100] 0.3698 0.0832 0.4163 0.1287 0.4499 ...
# $ k.pt   : num [1:2] 250 9751
# $ err.pt : num [1:2] 0.05 0.562
# $ k.ov   : num [1:2] 11 9990
# $ err.ov : num [1:2] 0.0022 0.0496
# $ err.nom: num [1:2] 0.05 0.05


Hope this helps,

Rui Barradas


?s 08:53 de 07/08/21, SITI AISYAH ZAKARIA escreveu:
> Hi,
> 
> Can anyone help me how to solve this problem?
> 
>   #calculation of confidence intervals
> 1. > nc <- 10000
> 2. > M1 <- matrix(rfrechet(nc*nobs),nrow=nobs,ncol=nc)
> 3. > M <- t(apply(M1,2,sort))
> 4. > E <- envelope(mat=M) #compute 95% confidance bands
> *Error in envelope.matrix(mat = M) : rvals must be supplied*
> 
> My problem is after I run my coding in line 4 the error is highlighted red
> is come out. I don't know how to solve it. Please help me.
> 
> Thank you
>


From jwd @end|ng |rom @urewe@t@net  Sun Aug  8 21:43:44 2021
From: jwd @end|ng |rom @urewe@t@net (John Dougherty)
Date: Sun, 8 Aug 2021 12:43:44 -0700
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
Message-ID: <20210808124344.06013fe7.jwd@surewest.net>

On Sat, 7 Aug 2021 20:26:13 -0700 (PDT)
Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

Documentation on most Linux systems, regardless of release, is commonly
located under the /usr/share directory.  For R that is
/usr/share/doc/R.  There is also a "man" entry for R.  The rstudio help
list might be able to help more than this list.  

> R documentation on my Ubuntu 20.20 is in /usr/share/R/doc.
> 
> I see no doc directories in the locations you mention using
> 
>    locate /doc/
> 
> Maybe you should be asking on R-sig-debian, perhaps with less noise
> about RStudio?
> 
> On Sun, 8 Aug 2021, Rolf Turner wrote:
> 
> >
> > Should/shouldn't there be one?
> >
> > My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> > directory, I get:
> >  
> >> bin/  COPYING@	etc/  lib/  library/  modules/
> >> site-library/  SVN-REVISION  
> >
> > Definitely no "doc".
> >
> > The (only) reason that I am concerned about this, is that I have
> > decided to experiment a bit with Rstudio, and it apparently wants a
> > "doc" directory.  When I try to start Rstudio I get a pop-up window
> > with the error message
> >  
> >> R doc dir (/usr/local/lib64/R/doc) not found.  
> >
> > Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> > The latter is where my installation put R; the former seems to be
> > where Rstudio wants it to.  So I created the symbolic link.
> >
> > The discrepancy between locations is another puzzle/worry.
> >
> > My installation comes from a pre-built binary ("sudo apt install
> > r-base").  I apparently have the latest version.  I remark that I am
> > running Ubuntu 20.04 with a Mate 1.20.4 desktop.
> >
> > How can I get a "doc" directory into my R directory and make Rstudio
> > happy?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > P.S. I have also tried to ask about this on the  Rstudio community
> > forum, but it seems to me to more of an R question than an Rstudio
> > one.
> >
> > R. T.
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code. 
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go
> Live... DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
> ##.#.  Live Go... Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  8 22:19:54 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 8 Aug 2021 16:19:54 -0400
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210808144507.61a8290e@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
Message-ID: <340f22a2-45b3-e2b8-78c4-e99c1f8736cd@gmail.com>


If you start R just using the regular command line version (not 
RStudio), does

   Sys.getenv("R_DOC_DIR")

point to /usr/share/R/doc ?  The standard R startup script should do 
that, but if it doesn't maybe you've got an override?

Or maybe you have R_DOC_DIR defined yourself?

Duncan Murdoch


On 07/08/2021 10:45 p.m., Rolf Turner wrote:
> 
> Should/shouldn't there be one?
> 
> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> directory, I get:
> 
>> bin/  COPYING@	etc/  lib/  library/  modules/
>> site-library/  SVN-REVISION
> 
> Definitely no "doc".
> 
> The (only) reason that I am concerned about this, is that I have decided
> to experiment a bit with Rstudio, and it apparently wants a "doc"
> directory.  When I try to start Rstudio I get a pop-up window with the
> error message
> 
>> R doc dir (/usr/local/lib64/R/doc) not found.
> 
> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> The latter is where my installation put R; the former seems to be where
> Rstudio wants it to.  So I created the symbolic link.
> 
> The discrepancy between locations is another puzzle/worry.
> 
> My installation comes from a pre-built binary ("sudo apt install
> r-base").  I apparently have the latest version.  I remark that I am
> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
> 
> How can I get a "doc" directory into my R directory and make Rstudio
> happy?
> 
> cheers,
> 
> Rolf Turner
> 
> P.S. I have also tried to ask about this on the  Rstudio community
> forum, but it seems to me to more of an R question than an Rstudio one.
> 
> R. T.
> 
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Aug  8 23:24:35 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 8 Aug 2021 22:24:35 +0100
Subject: [R] Calculation of Age heaping
Message-ID: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>

Dear R-expert,

I hope that you are doing well.

I am interested to calculate the age heaping for each digit (0,1,...,9)
based on my data set. However, when I run the R code, I got the following
errors. Please help me in this regard.

##########################################
library(remotes)
install_github("timriffe/DemoTools")

###
Downloading GitHub repo timriffe/DemoTools at HEAD
These packages have more recent versions available.
It is recommended to update all of them.
Which would you like to update?

 1: All
 2: CRAN packages only
 3: None

Enter one or more numbers, or an empty line to skip updates: 1

*After installing some packages, I got the following error message*

package ?backports? successfully unpacked and MD5 sums checked
Error: Failed to install 'DemoTools' from GitHub:
  (converted from warning) cannot remove prior installation of package
?backports?

I am attaching the R-code and data file along with this email.

Please help me in this regard.

Thanks in advance.
-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-code.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210808/353b258e/attachment.txt>

From @v|gro@@ @end|ng |rom ver|zon@net  Sun Aug  8 23:48:12 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 8 Aug 2021 17:48:12 -0400
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
References: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
Message-ID: <117001d78c9f$164183c0$42c48b40$@verizon.net>

It is not too clear to me what you want to do and why that package is the way to do it. Is the package a required part of your assignment? If so, maybe someone else can help you find how to properly install it on your machine, assuming you have permissions to replace the other package it seems to require. You may need to create your own environment. If you are open to other ways, see below.

Are you trying to do something as simple as counting how many people in your data are in various buckets such as each age truncated or rounded to an integer from 0 to 99? If so, you might miss some of my cousins alive at 100 or that died at 103 and 105 recently ?

Or do you want ages in groups of 10 or so meaning the first of two digits is 0 through 9?

Many such things can be done quite easily without the package if you wish.

As far as I can tell, your code reads in a data.frame from your local file with any number of columns that you do not specify. If it is one, the solution becomes much easier. You then for some reason feel the need to convert it to a matrix. You then do whatever your Whipple does several ways.

Here is an outline of ways you can do this yourself.

First, combine all your data into one or more vectors. You already have that in your data.frame but if all columns are numeric, you can of course do something with a matrix.

Then make sure you remove anything objectionable, such as negative numbers or numbers too large or NA or whatever your logic requires.

If you have a variable ready with N entries to hold the buckets, such as length(0:100) or for even buckets of 5, perhaps length(0:99)/5 you initialize that to all zeroes.

Now take your data, and perhaps transform it into a copy where every age is truncated to an integer or divided by 5 first or whatever you need so it contains a pure integer like 6 or 12. What I mean is if your buckets are 5 wide, and you want 5:9 to map into one bucket, your transform might be as.integer(original/5.0) or one of many variants like that.

You can now simply use one of many methods in R to loop through your values that result and assuming you have a zeroed vector called counter and the current value being looked at is N, you simply increment counter[N] or of N-1 or whatever your logic requires.

Alternately R has many built-in methods (or in other packages) like cut() that might do something similar without as much work.

And just for the heck of it, I tried your download instructions. Unlike your three choices, I was offered 13 choices and as I had no clue what YOU were supposed to download, I aborted.

 1: All                               
2: CRAN packages only                
3: None                              
4: colorspace (2.0-1 -> 2.0-2) [CRAN]
5: isoband    (0.2.4 -> 0.2.5) [CRAN]
6: utf8       (1.2.1 -> 1.2.2) [CRAN]
7: cli        (3.0.0 -> 3.0.1) [CRAN]
8: ggplot2    (3.3.3 -> 3.3.5) [CRAN]
9: pillar     (1.6.1 -> 1.6.2) [CRAN]
10: tibble     (3.1.2 -> 3.1.3) [CRAN]
11: dplyr      (1.0.6 -> 1.0.7) [CRAN]
12: Rcpp       (1.0.6 -> 1.0.7) [CRAN]
13: curl       (4.3.1 -> 4.3.2) [CRAN]
14: cpp11      (0.2.7 -> 0.3.1) [CRAN]

In your case, if you selected All, what exactly did you expect?


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Md. Moyazzem Hossain
Sent: Sunday, August 8, 2021 5:25 PM
To: r-help at r-project.org
Subject: [R] Calculation of Age heaping

Dear R-expert,

I hope that you are doing well.

I am interested to calculate the age heaping for each digit (0,1,...,9) based on my data set. However, when I run the R code, I got the following errors. Please help me in this regard.

##########################################
library(remotes)
install_github("timriffe/DemoTools")

###
Downloading GitHub repo timriffe/DemoTools at HEAD These packages have more recent versions available.
It is recommended to update all of them.
Which would you like to update?

 1: All
 2: CRAN packages only
 3: None

Enter one or more numbers, or an empty line to skip updates: 1

*After installing some packages, I got the following error message*

package ?backports? successfully unpacked and MD5 sums checked
Error: Failed to install 'DemoTools' from GitHub:
  (converted from warning) cannot remove prior installation of package ?backports?

I am attaching the R-code and data file along with this email.

Please help me in this regard.

Thanks in advance.
--
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Aug  9 03:39:33 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 8 Aug 2021 18:39:33 -0700
Subject: [R] 
 Issue regarding specifying pdBlocked matrix for random effects
 vcov in nlme package
In-Reply-To: <DS7PR10MB4895D5BE058460D73A4C6907ADEF9@DS7PR10MB4895.namprd10.prod.outlook.com>
References: <DS7PR10MB4895D5BE058460D73A4C6907ADEF9@DS7PR10MB4895.namprd10.prod.outlook.com>
Message-ID: <fa4f197d-5c6e-0d40-1594-d86d5ec487b6@comcast.net>

Dear Dr. David;

Re; List rejection

I'm unable to explain why this posting was refused. It does have 4 image 
files attached. That is more than I typically see on Rhelp. I'm only a 
volunteer moderator, and not one of the owners of the list. I speculate 
that if you were to repost to rhelp (and NOT to R-Core where this 
message does not belong) and you were to substitute copied text from 
your console for all except the first image, it might go through (at 
least to the moderation queue where it could be reviewed by human eyes 
and wetware. (I suspect the number of images and links caused an 
automatic spam rejection.)

I also wonder if your modified re-submission should instead be directed 
to the R-SIG-mixed-models list since that appears to be the question 
topic. Some of the experts there are not regular contributor of viewers 
of Rhelp which is focused on the maechanics of the R language itself.

-- 

David Winsemius

Volunteer moderator.

On 8/2/21 1:43 PM, Benjamin Davis wrote:
>
> Hello,
>
> ??????????????? I have come across an issue regarding specifying the 
> vcov of the random effects while using the /medrc/ package, which I 
> believe is very likely to originate from the /nlme/ package. I have 
> posted the question to StackOverflow if it is easier to read there:
>
> https://stackoverflow.com/questions/68626894/specifying-the-variance-covariance-matrix-for-random-effects-for-medrc-or-nlme 
> <https://urldefense.com/v3/__https://stackoverflow.com/questions/68626894/specifying-the-variance-covariance-matrix-for-random-effects-for-medrc-or-nlme__;!!HGYKHdhaPg!Ghq6dEJafKNBdT7h64jc9_H5JJWEnEQ891_QRsUZClnGXCeYntzRiXDmmq2XMTQ$>.
>
> I am using a 3-parameter log-logistic non-linear function
>
> and am including a species indicator variable based on whether my data 
> originates from humans (H) or rats (R). I am looking to specify a 
> blocked variance-covariance matrix for the random effects where 
> covariances are estimated for the off-diagonals of function parameters 
> within the same species, but not between species.
>
> I have attempted to estimate this vcov using the ?medrm? function from 
> the /medrc/ package. While the notation is slightly different from the 
> ?nlme? function, the estimation is performed in the same manner. I 
> have attempted to specify the random effect vcov using the 
> ?'pdBlocked' function.
>
> M3b <- medrm(inhibition ~ concentration, curveid=b + d + e ~ species,? 
> data=OP,
>
> ?????????????????????????????random= 
> list(subject=pdBlocked(list(b~species, d~species, e~species))),
>
> ?????????????????????fct=LL.3(), control=c(drmc(method="CG"), 
> nlmeControl(msMaxIter = 150)))
>
> However, this results in almost the opposite of what I intended, 
> providing covariances within parameter type but across species (which 
> is non-sensical given that no subject can be both a human and a rat).
>
> Do you have any recommendations on how to fix this, ideally using one 
> of the existing pd-matrix functions?
>
> Thanks in advance for your reply.
>
> *Benjamin Davis, Ph.D.*
> Senior Scientist
> *Exponent*
> Direct +1-202-772-4942
> Email davisb at exponent.com <mailto:davisb at exponent.com>
>
> *Benjamin Davis, Ph.D.*
> Senior Scientist
> *Exponent*
> Direct +1-202-772-4942
> Email davisb at exponent.com <mailto:davisb at exponent.com>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug  9 08:30:11 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 9 Aug 2021 06:30:11 +0000
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>
Message-ID: <9192f7107d4148b18cf19d882cf002cc@SRVEXCHCM1302.precheza.cz>

Hi Bert

Yes, in this case which is not necessary. But in case NAs are involved 
sometimes logical indexing is not a best choice as NA propagates to the 
result, which may be not wanted.

x <- 1:10
x[c(2,5)] <- NA
y<- letters[1:10]
y[x<5]
[1] "a" NA  "c" "d" NA
y[which(x<5)]
[1] "a" "c" "d"
dat <- data.frame(x,y)
dat[x<5,]
      x    y
1     1    a
NA   NA <NA>
3     3    c
4     4    d
NA.1 NA <NA>

> dat[which(x<5),]
  x y
1 1 a
3 3 c
4 4 d

Both results are OK, but one has to consider this NA value propagation.

Cheers
Petr

From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Friday, August 6, 2021 1:29 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
Subject: Re: [R] Sanity check in loading large dataframe

... but remove the which() and use logical indexing ...  ;-)


Bert Gunter

"The trouble with having an open mind is that people keep coming along and 
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 6, 2021 at 12:57 AM PIKAL Petr <mailto:petr.pikal at precheza.cz> 
wrote:
Hi

You already got answer from Avi. I often use dim(data) to inspect how many
rows/columns I have.
After that I check if some columns contain all or many NA values.

colSums(http://is.na(data))
keep <- which(colSums(http://is.na(data))<nnn)
cleaned.data <- data[, keep]

Cheers
Petr


> -----Original Message-----
> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Luigi 
> Marongiu
> Sent: Friday, August 6, 2021 7:34 AM
> To: Duncan Murdoch <mailto:murdoch.duncan at gmail.com>
> Cc: r-help <mailto:r-help at r-project.org>
> Subject: Re: [R] Sanity check in loading large dataframe
>
> Ok, so nothing to worry about. Yet, are there other checks I can
implement?
> Thank you
>
> On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <mailto:murdoch.duncan at gmail.com>
> wrote:
>
> > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> >  > Hello,
> >  > I am using a large spreadsheet (over 600 variables).
> >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ....
> >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> >  >    [list output truncated]
> >  > NULL
> >  > ```
> >  > I understand that `[list output truncated]` means that there are
> > more  > variables than those allowed by str to be displayed as rows.
> > Thus I  > increased the row's output with:
> >  > ```
> >  >
> >  >> (str(df, list.len=1000))
> >  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ...
> >  > NULL
> >  > ```
> >  >
> >  > Does `NULL` mean that some of the variables are not closed?
> > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > sanity of the data and avoid that some  > separator is not in the
> > right place?
> >  > Thank you
> >
> > The NULL is the value returned by str().  Normally it is not printed,
> > but when you wrap str in parens as (str(df, list.len=1000)), that
> > forces the value to print.
> >
> > str() is unusual in R functions in that it prints to the console as it
> > runs and returns nothing.  Many other functions construct a value
> > which is only displayed if you print it, but something like
> >
> > x <- str(df, list.len=1000)
> >
> > will print the same as if there was no assignment, and then assign
> > NULL to x.
> >
> > Duncan Murdoch
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 10:26:03 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 10:26:03 +0200
Subject: [R] substitute column data frame based on name stored in variable
 in r
Message-ID: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>

Hello,
I would like to recursively select the columns of a dataframe by
strong the names of the dataframe in a vector and extracting one
element of the vector at a time. This I can do with, for instance:
```
vect = names(df)
sub_df[vect[1]]
```

The problem is that I would like also to change the values of the
selected column using some logic as in `df$column[df$column == value]
<- new.value`, but I am confused on the syntax for the vectorized
version. Specifically, this does not work:
```
sub_df[vect[1] == 0] = "No"
```
What would be the correct approach?
Thank you


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 10:42:32 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 10:42:32 +0200
Subject: [R] Apply gsub to dataframe to modify row values
Message-ID: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>

Hello,
I have a dataframe where I would like to change the string of certain
rows, essentially I am looking to remove some useless text from the
variables.
I tried with:
```
> df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> df
  VAR           VAL value is blue Value is red empty
1   1 value is blue          blue         blue  blue
2   2  Value is red           red          red   red
3   3         empty         empty        empty empty
```
which is of course wrong because I was expecting
```
  VAR           VAL
1   1             blue
2   2             red
3   3            empty
```
What is the correct syntax in these cases?
Thank you


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 10:53:29 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 18:53:29 +1000
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
Message-ID: <CA+8X3fVd4Gxg7668KMhB-nCrvxdHVmP8cqxgrUx2sn9G33qFZQ@mail.gmail.com>

Hi Luigi,
It looks to me as though you will have to copy the data frame or store
the output in a new data frame.

Jim

On Mon, Aug 9, 2021 at 6:26 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I would like to recursively select the columns of a dataframe by
> strong the names of the dataframe in a vector and extracting one
> element of the vector at a time. This I can do with, for instance:
> ```
> vect = names(df)
> sub_df[vect[1]]
> ```
>
> The problem is that I would like also to change the values of the
> selected column using some logic as in `df$column[df$column == value]
> <- new.value`, but I am confused on the syntax for the vectorized
> version. Specifically, this does not work:
> ```
> sub_df[vect[1] == 0] = "No"
> ```
> What would be the correct approach?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 10:57:22 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 10:57:22 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CA+8X3fVd4Gxg7668KMhB-nCrvxdHVmP8cqxgrUx2sn9G33qFZQ@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <CA+8X3fVd4Gxg7668KMhB-nCrvxdHVmP8cqxgrUx2sn9G33qFZQ@mail.gmail.com>
Message-ID: <CAMk+s2Rn7sMhvtanE3RiOPC8f-zwA19we4iNhn4MJ5NZ2D55VA@mail.gmail.com>

Thank you very much, but that would make even more work due to the
duplication...

On Mon, Aug 9, 2021 at 10:53 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> It looks to me as though you will have to copy the data frame or store
> the output in a new data frame.
>
> Jim
>
> On Mon, Aug 9, 2021 at 6:26 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I would like to recursively select the columns of a dataframe by
> > strong the names of the dataframe in a vector and extracting one
> > element of the vector at a time. This I can do with, for instance:
> > ```
> > vect = names(df)
> > sub_df[vect[1]]
> > ```
> >
> > The problem is that I would like also to change the values of the
> > selected column using some logic as in `df$column[df$column == value]
> > <- new.value`, but I am confused on the syntax for the vectorized
> > version. Specifically, this does not work:
> > ```
> > sub_df[vect[1] == 0] = "No"
> > ```
> > What would be the correct approach?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 11:01:41 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 19:01:41 +1000
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
Message-ID: <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>

Hi Luigi,
Ah, now I see:

 df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
df
 VAR   VAL
1   1  blue
2   2   red
3   3 empty

Jim

On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have a dataframe where I would like to change the string of certain
> rows, essentially I am looking to remove some useless text from the
> variables.
> I tried with:
> ```
> > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > df
>   VAR           VAL value is blue Value is red empty
> 1   1 value is blue          blue         blue  blue
> 2   2  Value is red           red          red   red
> 3   3         empty         empty        empty empty
> ```
> which is of course wrong because I was expecting
> ```
>   VAR           VAL
> 1   1             blue
> 2   2             red
> 3   3            empty
> ```
> What is the correct syntax in these cases?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug  9 11:24:51 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 9 Aug 2021 11:24:51 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
Message-ID: <20210809112451.78a21095@trisector>

On Mon, 9 Aug 2021 10:26:03 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> vect = names(df)
> sub_df[vect[1]]

> df$column[df$column == value] <- new.value

Let's see, an equivalent expression without the $ syntax is
`df[['column']][df[['column']] == value] <- new.value`. Slightly
shorter, matrix-like syntax would give us
`df[df[['column']] == value, 'column'] <- new.value`.

Now replace 'column' with vect[i] and you're done. The `[[`-indexing is
used here to get the column contents instead of a single-column
data.frame that `[`-indexing returns for lists.

Also note that df[[names(df)[i]]] should be the same as df[[i]] for
most data.frames.

-- 
Best regards,
Ivan


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  9 12:27:52 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 9 Aug 2021 11:27:52 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <117001d78c9f$164183c0$42c48b40$@verizon.net>
References: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
 <117001d78c9f$164183c0$42c48b40$@verizon.net>
Message-ID: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>

Dear Avi Gross,

Thank you very much for your email. Actually, I have a little knowledge of
R programming.

I have a dataset of ages ranging from 10 to 90. Now, I want to find out the
Whipple?s index for age heaping among individuals for each digit like
0,1,...,9.

I have searched in google I got the following functions. That's why I use
the package and the following code.

*check_heaping_whipple(Value, Age, ageMin = 25, ageMax = 65, digit = c(0,
5)) *     [link:
https://rdrr.io/github/timriffe/DemoTools/man/check_heaping_whipple.html]

Thanks in advance.

Md



On Sun, Aug 8, 2021 at 10:48 PM Avi Gross via R-help <r-help at r-project.org>
wrote:

> It is not too clear to me what you want to do and why that package is the
> way to do it. Is the package a required part of your assignment? If so,
> maybe someone else can help you find how to properly install it on your
> machine, assuming you have permissions to replace the other package it
> seems to require. You may need to create your own environment. If you are
> open to other ways, see below.
>
> Are you trying to do something as simple as counting how many people in
> your data are in various buckets such as each age truncated or rounded to
> an integer from 0 to 99? If so, you might miss some of my cousins alive at
> 100 or that died at 103 and 105 recently ?
>
> Or do you want ages in groups of 10 or so meaning the first of two digits
> is 0 through 9?
>
> Many such things can be done quite easily without the package if you wish.
>
> As far as I can tell, your code reads in a data.frame from your local file
> with any number of columns that you do not specify. If it is one, the
> solution becomes much easier. You then for some reason feel the need to
> convert it to a matrix. You then do whatever your Whipple does several ways.
>
> Here is an outline of ways you can do this yourself.
>
> First, combine all your data into one or more vectors. You already have
> that in your data.frame but if all columns are numeric, you can of course
> do something with a matrix.
>
> Then make sure you remove anything objectionable, such as negative numbers
> or numbers too large or NA or whatever your logic requires.
>
> If you have a variable ready with N entries to hold the buckets, such as
> length(0:100) or for even buckets of 5, perhaps length(0:99)/5 you
> initialize that to all zeroes.
>
> Now take your data, and perhaps transform it into a copy where every age
> is truncated to an integer or divided by 5 first or whatever you need so it
> contains a pure integer like 6 or 12. What I mean is if your buckets are 5
> wide, and you want 5:9 to map into one bucket, your transform might be
> as.integer(original/5.0) or one of many variants like that.
>
> You can now simply use one of many methods in R to loop through your
> values that result and assuming you have a zeroed vector called counter and
> the current value being looked at is N, you simply increment counter[N] or
> of N-1 or whatever your logic requires.
>
> Alternately R has many built-in methods (or in other packages) like cut()
> that might do something similar without as much work.
>
> And just for the heck of it, I tried your download instructions. Unlike
> your three choices, I was offered 13 choices and as I had no clue what YOU
> were supposed to download, I aborted.
>
>  1: All
> 2: CRAN packages only
> 3: None
> 4: colorspace (2.0-1 -> 2.0-2) [CRAN]
> 5: isoband    (0.2.4 -> 0.2.5) [CRAN]
> 6: utf8       (1.2.1 -> 1.2.2) [CRAN]
> 7: cli        (3.0.0 -> 3.0.1) [CRAN]
> 8: ggplot2    (3.3.3 -> 3.3.5) [CRAN]
> 9: pillar     (1.6.1 -> 1.6.2) [CRAN]
> 10: tibble     (3.1.2 -> 3.1.3) [CRAN]
> 11: dplyr      (1.0.6 -> 1.0.7) [CRAN]
> 12: Rcpp       (1.0.6 -> 1.0.7) [CRAN]
> 13: curl       (4.3.1 -> 4.3.2) [CRAN]
> 14: cpp11      (0.2.7 -> 0.3.1) [CRAN]
>
> In your case, if you selected All, what exactly did you expect?
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Md. Moyazzem
> Hossain
> Sent: Sunday, August 8, 2021 5:25 PM
> To: r-help at r-project.org
> Subject: [R] Calculation of Age heaping
>
> Dear R-expert,
>
> I hope that you are doing well.
>
> I am interested to calculate the age heaping for each digit (0,1,...,9)
> based on my data set. However, when I run the R code, I got the following
> errors. Please help me in this regard.
>
> ##########################################
> library(remotes)
> install_github("timriffe/DemoTools")
>
> ###
> Downloading GitHub repo timriffe/DemoTools at HEAD These packages have more
> recent versions available.
> It is recommended to update all of them.
> Which would you like to update?
>
>  1: All
>  2: CRAN packages only
>  3: None
>
> Enter one or more numbers, or an empty line to skip updates: 1
>
> *After installing some packages, I got the following error message*
>
> package ?backports? successfully unpacked and MD5 sums checked
> Error: Failed to install 'DemoTools' from GitHub:
>   (converted from warning) cannot remove prior installation of package
> ?backports?
>
> I am attaching the R-code and data file along with this email.
>
> Please help me in this regard.
>
> Thanks in advance.
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *Google Scholar
> <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 12:40:17 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 12:40:17 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
Message-ID: <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>

Thank you, that is much appreciated. But on the real data, the
substitution works only on few instances. Is there a way to introduce
regex into this?
Cheers
Luigi

On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> Ah, now I see:
>
>  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> df
>  VAR   VAL
> 1   1  blue
> 2   2   red
> 3   3 empty
>
> Jim
>
> On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have a dataframe where I would like to change the string of certain
> > rows, essentially I am looking to remove some useless text from the
> > variables.
> > I tried with:
> > ```
> > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > df
> >   VAR           VAL value is blue Value is red empty
> > 1   1 value is blue          blue         blue  blue
> > 2   2  Value is red           red          red   red
> > 3   3         empty         empty        empty empty
> > ```
> > which is of course wrong because I was expecting
> > ```
> >   VAR           VAL
> > 1   1             blue
> > 2   2             red
> > 3   3            empty
> > ```
> > What is the correct syntax in these cases?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 12:50:00 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 12:50:00 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
Message-ID: <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>

Sorry, silly question, gsub works already with regex. But still, if I
add `[[:blank:]]` still I don't get rid of all instances. And I am
keeping obtaining extra columns
```
> df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
  VAR           VAL value is blue Value is red empty
1   1 value is blue             b            b     b
2   2  Value is red            rd           rd    rd
3   3         empty          mpty         mpty  mpty
```

On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you, that is much appreciated. But on the real data, the
> substitution works only on few instances. Is there a way to introduce
> regex into this?
> Cheers
> Luigi
>
> On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > Ah, now I see:
> >
> >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > df
> >  VAR   VAL
> > 1   1  blue
> > 2   2   red
> > 3   3 empty
> >
> > Jim
> >
> > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I have a dataframe where I would like to change the string of certain
> > > rows, essentially I am looking to remove some useless text from the
> > > variables.
> > > I tried with:
> > > ```
> > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > > df
> > >   VAR           VAL value is blue Value is red empty
> > > 1   1 value is blue          blue         blue  blue
> > > 2   2  Value is red           red          red   red
> > > 3   3         empty         empty        empty empty
> > > ```
> > > which is of course wrong because I was expecting
> > > ```
> > >   VAR           VAL
> > > 1   1             blue
> > > 2   2             red
> > > 3   3            empty
> > > ```
> > > What is the correct syntax in these cases?
> > > Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m|n@h@|| @end|ng |rom um|ch@edu  Mon Aug  9 13:04:51 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Mon, 09 Aug 2021 14:04:51 +0300
Subject: [R] Calculation of Age heaping
In-Reply-To: Your message of "Mon, 09 Aug 2021 11:27:52 +0100."
 <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
Message-ID: <513810.1628507091@apollo2.minshall.org>

Md,

if this is what you are looking for:
----
https://en.wikipedia.org/wiki/Whipple%27s_index
----

then, the article says the algorithm is
----
The index score is obtained by summing the number of persons in the age
range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
that sum by the total population between ages 23 and 62 years inclusive,
and multiplying the result by 5. Restated as a percentage, index scores
range between 100 (no preference for ages ending in 0 and 5) and 500
(all people reporting ages ending in 0 and 5).
----

that seems fairly straight forward.  if you are trying to learn R,
and/or learn programming, i might suggest you *not* use a package, and
rather work on coding up the calculation yourself.  that would probably
be a good, but not too hard, exercise, of some interest.  enjoy!

cheers, Greg


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 13:16:02 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 13:16:02 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <20210809112451.78a21095@trisector>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
Message-ID: <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>

Thank you but I think I got it wrong:
```
> df = data.frame(VAR = letters[1:5], VAL = c(1, 2, NA, 2, NA)); df
  VAR VAL
1   a   1
2   b   2
3   c  NA
4   d   2
5   e  NA
> vect = letters[1:5]
> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"; df
  VAR VAL vect[2]
1   a   1    <NA>
2   b   2    <NA>
3   c  NA    <NA>
4   d   2    <NA>
5   e  NA    <NA>
```

On Mon, Aug 9, 2021 at 11:25 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Mon, 9 Aug 2021 10:26:03 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > vect = names(df)
> > sub_df[vect[1]]
>
> > df$column[df$column == value] <- new.value
>
> Let's see, an equivalent expression without the $ syntax is
> `df[['column']][df[['column']] == value] <- new.value`. Slightly
> shorter, matrix-like syntax would give us
> `df[df[['column']] == value, 'column'] <- new.value`.
>
> Now replace 'column' with vect[i] and you're done. The `[[`-indexing is
> used here to get the column contents instead of a single-column
> data.frame that `[`-indexing returns for lists.
>
> Also note that df[[names(df)[i]]] should be the same as df[[i]] for
> most data.frames.
>
> --
> Best regards,
> Ivan



-- 
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug  9 13:31:34 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 9 Aug 2021 13:31:34 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
Message-ID: <20210809133134.784edd06@trisector>

On Mon, 9 Aug 2021 13:16:02 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> df = data.frame(VAR = ..., VAL = ...)
> vect = letters[1:5]

What is the relation between vect and the column names of the data
frame? Is it your intention to choose rows or columns using `vect`?

> df[df[['vect[2]']] == 2, 'vect[2]']

'...' creates a string literal. If you want to evaluate an R
expression, don't wrap it in quotes.

I had assumed you wanted to put column names in the vector `vect`, but
now I'm just confused: `vect` is the same as df$VAR, not colnames(df).
What do you want to achieve?

Again, you can access the second column with much less typing by
addressing it directly: df[[2]]

Does it help if you consult [**] or some other tutorial on subsetting
in R?

-- 
Best regards,
Ivan

[**] 
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Lists


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 13:32:50 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 21:32:50 +1000
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
Message-ID: <CA+8X3fWBgRGEXM-QqkSAumb2e6FgBES_EdBUaX3gvtMTY5_QfQ@mail.gmail.com>

Hi Luigi,
You want to get rid of certain strings in the "VAL" column. You are
assigning to:

df[df$VAL]
Error in `[.data.frame`(df, df$VAL) : undefined columns selected

when I think you should be assigning to:

df$VAL

What do you want to remove other than "[V|v]alue is" ?

JIim

On Mon, Aug 9, 2021 at 8:50 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Sorry, silly question, gsub works already with regex. But still, if I
> add `[[:blank:]]` still I don't get rid of all instances. And I am
> keeping obtaining extra columns
> ```
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
>   VAR           VAL value is blue Value is red empty
> 1   1 value is blue             b            b     b
> 2   2  Value is red            rd           rd    rd
> 3   3         empty          mpty         mpty  mpty
> ```
>
> On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Thank you, that is much appreciated. But on the real data, the
> > substitution works only on few instances. Is there a way to introduce
> > regex into this?
> > Cheers
> > Luigi
> >
> > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > Ah, now I see:
> > >
> > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > > df
> > >  VAR   VAL
> > > 1   1  blue
> > > 2   2   red
> > > 3   3 empty
> > >
> > > Jim
> > >
> > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have a dataframe where I would like to change the string of certain
> > > > rows, essentially I am looking to remove some useless text from the
> > > > variables.
> > > > I tried with:
> > > > ```
> > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > > > df
> > > >   VAR           VAL value is blue Value is red empty
> > > > 1   1 value is blue          blue         blue  blue
> > > > 2   2  Value is red           red          red   red
> > > > 3   3         empty         empty        empty empty
> > > > ```
> > > > which is of course wrong because I was expecting
> > > > ```
> > > >   VAR           VAL
> > > > 1   1             blue
> > > > 2   2             red
> > > > 3   3            empty
> > > > ```
> > > > What is the correct syntax in these cases?
> > > > Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  9 13:36:30 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 9 Aug 2021 12:36:30 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <513810.1628507091@apollo2.minshall.org>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
Message-ID: <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>

Dear Greg,

Thank you very much for your suggestion. I will try it and follow your
advice.

Actually, I want to find out the index for each digit like 0, 1, ..., 9.

Thanks in advance. Take care.

Md



On Mon, Aug 9, 2021 at 12:05 PM Greg Minshall <minshall at umich.edu> wrote:

> Md,
>
> if this is what you are looking for:
> ----
> https://en.wikipedia.org/wiki/Whipple%27s_index
> ----
>
> then, the article says the algorithm is
> ----
> The index score is obtained by summing the number of persons in the age
> range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> that sum by the total population between ages 23 and 62 years inclusive,
> and multiplying the result by 5. Restated as a percentage, index scores
> range between 100 (no preference for ages ending in 0 and 5) and 500
> (all people reporting ages ending in 0 and 5).
> ----
>
> that seems fairly straight forward.  if you are trying to learn R,
> and/or learn programming, i might suggest you *not* use a package, and
> rather work on coding up the calculation yourself.  that would probably
> be a good, but not too hard, exercise, of some interest.  enjoy!
>
> cheers, Greg
>
>

-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Aug  9 13:40:01 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 9 Aug 2021 23:40:01 +1200
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
References: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
 <117001d78c9f$164183c0$42c48b40$@verizon.net>
 <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
Message-ID: <CABcYAdLvfO0KGcG8ozF7xVVbG27k__hADy04zpE_8jFXE+QMVw@mail.gmail.com>

According to Wikipedia, this is the definition of Whipple's index:

"The index score is obtained by summing the number of persons in the
age range 23 and 62 inclusive, who report ages ending in 0 and 5,
dividing that sum by the total population between ages 23 and 62 years
inclusive, and multiplying the result by 5. Restated as a percentage,
index scores range between 100 (no preference for ages ending in 0 and
5) and 500 (all people reporting ages ending in 0 and 5)."

Let ages be a vector of integers representing ages.
whipple <- function (ages) {
    mids <- ages[ages >= 23 & ages <= 62] * 2
    5 * mean( mids %% 10 == 0)
}

If you want any other digit(s), you could try
whipple <- function (ages, digits = c(0,5)) {
    mids <- ages[ages >= 23 & ages <= 62] %% 10
    (10/leng(digits)) * mean(mids %in% digits)
}

So it is not clear to me why you want any package to do this.
The Whipple index does not come with any statistical measure of strength,
although https://en.wikipedia.org/wiki/Whipple%27s_index
mentions a UN table of values to compare with.

That Wikipedia page also warns about limits to applicability.
I note that with the exception of using an upper inclusive bound of
62 (as in the Wikipedia page) this definition of the Whipple index
agrees perfectly with that in A'Hearn et al's papers (which use 72)
but NOT with DemoTools.  So you need to be very clear to yourself
and others where your definition of the Whipple index comes from,
what it is, and whether the code you use computes what you think
it does.  (UNTESTED CODE ABOVE!)

On Mon, 9 Aug 2021 at 22:28, Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Dear Avi Gross,
>
> Thank you very much for your email. Actually, I have a little knowledge of
> R programming.
>
> I have a dataset of ages ranging from 10 to 90. Now, I want to find out the
> Whipple?s index for age heaping among individuals for each digit like
> 0,1,...,9.
>
> I have searched in google I got the following functions. That's why I use
> the package and the following code.
>
> *check_heaping_whipple(Value, Age, ageMin = 25, ageMax = 65, digit = c(0,
> 5)) *     [link:
> https://rdrr.io/github/timriffe/DemoTools/man/check_heaping_whipple.html]
>
> Thanks in advance.
>
> Md
>
>
>
> On Sun, Aug 8, 2021 at 10:48 PM Avi Gross via R-help <r-help at r-project.org>
> wrote:
>
> > It is not too clear to me what you want to do and why that package is the
> > way to do it. Is the package a required part of your assignment? If so,
> > maybe someone else can help you find how to properly install it on your
> > machine, assuming you have permissions to replace the other package it
> > seems to require. You may need to create your own environment. If you are
> > open to other ways, see below.
> >
> > Are you trying to do something as simple as counting how many people in
> > your data are in various buckets such as each age truncated or rounded to
> > an integer from 0 to 99? If so, you might miss some of my cousins alive at
> > 100 or that died at 103 and 105 recently ?
> >
> > Or do you want ages in groups of 10 or so meaning the first of two digits
> > is 0 through 9?
> >
> > Many such things can be done quite easily without the package if you wish.
> >
> > As far as I can tell, your code reads in a data.frame from your local file
> > with any number of columns that you do not specify. If it is one, the
> > solution becomes much easier. You then for some reason feel the need to
> > convert it to a matrix. You then do whatever your Whipple does several ways.
> >
> > Here is an outline of ways you can do this yourself.
> >
> > First, combine all your data into one or more vectors. You already have
> > that in your data.frame but if all columns are numeric, you can of course
> > do something with a matrix.
> >
> > Then make sure you remove anything objectionable, such as negative numbers
> > or numbers too large or NA or whatever your logic requires.
> >
> > If you have a variable ready with N entries to hold the buckets, such as
> > length(0:100) or for even buckets of 5, perhaps length(0:99)/5 you
> > initialize that to all zeroes.
> >
> > Now take your data, and perhaps transform it into a copy where every age
> > is truncated to an integer or divided by 5 first or whatever you need so it
> > contains a pure integer like 6 or 12. What I mean is if your buckets are 5
> > wide, and you want 5:9 to map into one bucket, your transform might be
> > as.integer(original/5.0) or one of many variants like that.
> >
> > You can now simply use one of many methods in R to loop through your
> > values that result and assuming you have a zeroed vector called counter and
> > the current value being looked at is N, you simply increment counter[N] or
> > of N-1 or whatever your logic requires.
> >
> > Alternately R has many built-in methods (or in other packages) like cut()
> > that might do something similar without as much work.
> >
> > And just for the heck of it, I tried your download instructions. Unlike
> > your three choices, I was offered 13 choices and as I had no clue what YOU
> > were supposed to download, I aborted.
> >
> >  1: All
> > 2: CRAN packages only
> > 3: None
> > 4: colorspace (2.0-1 -> 2.0-2) [CRAN]
> > 5: isoband    (0.2.4 -> 0.2.5) [CRAN]
> > 6: utf8       (1.2.1 -> 1.2.2) [CRAN]
> > 7: cli        (3.0.0 -> 3.0.1) [CRAN]
> > 8: ggplot2    (3.3.3 -> 3.3.5) [CRAN]
> > 9: pillar     (1.6.1 -> 1.6.2) [CRAN]
> > 10: tibble     (3.1.2 -> 3.1.3) [CRAN]
> > 11: dplyr      (1.0.6 -> 1.0.7) [CRAN]
> > 12: Rcpp       (1.0.6 -> 1.0.7) [CRAN]
> > 13: curl       (4.3.1 -> 4.3.2) [CRAN]
> > 14: cpp11      (0.2.7 -> 0.3.1) [CRAN]
> >
> > In your case, if you selected All, what exactly did you expect?
> >
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Md. Moyazzem
> > Hossain
> > Sent: Sunday, August 8, 2021 5:25 PM
> > To: r-help at r-project.org
> > Subject: [R] Calculation of Age heaping
> >
> > Dear R-expert,
> >
> > I hope that you are doing well.
> >
> > I am interested to calculate the age heaping for each digit (0,1,...,9)
> > based on my data set. However, when I run the R code, I got the following
> > errors. Please help me in this regard.
> >
> > ##########################################
> > library(remotes)
> > install_github("timriffe/DemoTools")
> >
> > ###
> > Downloading GitHub repo timriffe/DemoTools at HEAD These packages have more
> > recent versions available.
> > It is recommended to update all of them.
> > Which would you like to update?
> >
> >  1: All
> >  2: CRAN packages only
> >  3: None
> >
> > Enter one or more numbers, or an empty line to skip updates: 1
> >
> > *After installing some packages, I got the following error message*
> >
> > package ?backports? successfully unpacked and MD5 sums checked
> > Error: Failed to install 'DemoTools' from GitHub:
> >   (converted from warning) cannot remove prior installation of package
> > ?backports?
> >
> > I am attaching the R-code and data file along with this email.
> >
> > Please help me in this regard.
> >
> > Thanks in advance.
> > --
> > Best Regards,
> > Md. Moyazzem Hossain
> > Associate Professor
> > Department of Statistics
> > Jahangirnagar University
> > Savar, Dhaka-1342
> > Bangladesh
> > Website: http://www.juniv.edu/teachers/hossainmm
> > Research: *Google Scholar
> > <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> > *ResearchGate
> > <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> > <https://orcid.org/0000-0003-3593-6936>*
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *Google Scholar
> <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 14:17:17 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 22:17:17 +1000
Subject: [R] Calculation of Age heaping
In-Reply-To: <513810.1628507091@apollo2.minshall.org>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
Message-ID: <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>

And if you really don't like programming:

whipple_index<-function(x,td=c(0,5)) {
 wi<-rep(NA,11)
 names(wi)<-c(paste0("wi",0:9),"O/all")
 for(i in 0:9) {
  ttd<-which((x %% 10) %in% i)
  wi[i+1]<-length(ttd) * 100/length(x)
 }
 ttd<-which((x %% 10) %in% td)
 wi[11]<-length(ttd) * 100/(length(x)/length(td))
 return(wi)
}

I haven't tested this extensively, but it may be helpful. You can
specify the final digits for the overall test. Select your ages before
passing them to whipple_index.

Jim

On Mon, Aug 9, 2021 at 9:05 PM Greg Minshall <minshall at umich.edu> wrote:
>
> Md,
>
> if this is what you are looking for:
> ----
> https://en.wikipedia.org/wiki/Whipple%27s_index
> ----
>
> then, the article says the algorithm is
> ----
> The index score is obtained by summing the number of persons in the age
> range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> that sum by the total population between ages 23 and 62 years inclusive,
> and multiplying the result by 5. Restated as a percentage, index scores
> range between 100 (no preference for ages ending in 0 and 5) and 500
> (all people reporting ages ending in 0 and 5).
> ----
>
> that seems fairly straight forward.  if you are trying to learn R,
> and/or learn programming, i might suggest you *not* use a package, and
> rather work on coding up the calculation yourself.  that would probably
> be a good, but not too hard, exercise, of some interest.  enjoy!
>
> cheers, Greg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  9 14:50:39 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 9 Aug 2021 13:50:39 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>
Message-ID: <CAO29qn6Nyis5Xric7ng6qMaZBgXs9ctxS97b6R6+HFmNWK7anA@mail.gmail.com>

Dear Jim,

Thank you very much for your kind help.

Take care.

Md

On Mon, Aug 9, 2021 at 1:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> And if you really don't like programming:
>
> whipple_index<-function(x,td=c(0,5)) {
>  wi<-rep(NA,11)
>  names(wi)<-c(paste0("wi",0:9),"O/all")
>  for(i in 0:9) {
>   ttd<-which((x %% 10) %in% i)
>   wi[i+1]<-length(ttd) * 100/length(x)
>  }
>  ttd<-which((x %% 10) %in% td)
>  wi[11]<-length(ttd) * 100/(length(x)/length(td))
>  return(wi)
> }
>
> I haven't tested this extensively, but it may be helpful. You can
> specify the final digits for the overall test. Select your ages before
> passing them to whipple_index.
>
> Jim
>
> On Mon, Aug 9, 2021 at 9:05 PM Greg Minshall <minshall at umich.edu> wrote:
> >
> > Md,
> >
> > if this is what you are looking for:
> > ----
> > https://en.wikipedia.org/wiki/Whipple%27s_index
> > ----
> >
> > then, the article says the algorithm is
> > ----
> > The index score is obtained by summing the number of persons in the age
> > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> > that sum by the total population between ages 23 and 62 years inclusive,
> > and multiplying the result by 5. Restated as a percentage, index scores
> > range between 100 (no preference for ages ending in 0 and 5) and 500
> > (all people reporting ages ending in 0 and 5).
> > ----
> >
> > that seems fairly straight forward.  if you are trying to learn R,
> > and/or learn programming, i might suggest you *not* use a package, and
> > rather work on coding up the calculation yourself.  that would probably
> > be a good, but not too hard, exercise, of some interest.  enjoy!
> >
> > cheers, Greg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 15:24:17 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 15:24:17 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CA+8X3fWBgRGEXM-QqkSAumb2e6FgBES_EdBUaX3gvtMTY5_QfQ@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
 <CA+8X3fWBgRGEXM-QqkSAumb2e6FgBES_EdBUaX3gvtMTY5_QfQ@mail.gmail.com>
Message-ID: <CAMk+s2TMVrMTJGy2NwvNUt0EF+WWjR8NUJRxz2FC+Do1oRc6KQ@mail.gmail.com>

I wanted to remove possible white spaces before or after the string.
Actually, it worked, I used `gsub("[:blank:]*val[:blank:]*", "",
df$VAL, ignore.case=TRUE)`. I don't know why in the example there were
extra columns -- they did not came out in the real case.
Thank you, I think the case is closed.
Cheers
Luigi

On Mon, Aug 9, 2021 at 1:33 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> You want to get rid of certain strings in the "VAL" column. You are
> assigning to:
>
> df[df$VAL]
> Error in `[.data.frame`(df, df$VAL) : undefined columns selected
>
> when I think you should be assigning to:
>
> df$VAL
>
> What do you want to remove other than "[V|v]alue is" ?
>
> JIim
>
> On Mon, Aug 9, 2021 at 8:50 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Sorry, silly question, gsub works already with regex. But still, if I
> > add `[[:blank:]]` still I don't get rid of all instances. And I am
> > keeping obtaining extra columns
> > ```
> > > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> > > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
> >   VAR           VAL value is blue Value is red empty
> > 1   1 value is blue             b            b     b
> > 2   2  Value is red            rd           rd    rd
> > 3   3         empty          mpty         mpty  mpty
> > ```
> >
> > On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you, that is much appreciated. But on the real data, the
> > > substitution works only on few instances. Is there a way to introduce
> > > regex into this?
> > > Cheers
> > > Luigi
> > >
> > > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > > Hi Luigi,
> > > > Ah, now I see:
> > > >
> > > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > > > df
> > > >  VAR   VAL
> > > > 1   1  blue
> > > > 2   2   red
> > > > 3   3 empty
> > > >
> > > > Jim
> > > >
> > > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Hello,
> > > > > I have a dataframe where I would like to change the string of certain
> > > > > rows, essentially I am looking to remove some useless text from the
> > > > > variables.
> > > > > I tried with:
> > > > > ```
> > > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > > > > df
> > > > >   VAR           VAL value is blue Value is red empty
> > > > > 1   1 value is blue          blue         blue  blue
> > > > > 2   2  Value is red           red          red   red
> > > > > 3   3         empty         empty        empty empty
> > > > > ```
> > > > > which is of course wrong because I was expecting
> > > > > ```
> > > > >   VAR           VAL
> > > > > 1   1             blue
> > > > > 2   2             red
> > > > > 3   3            empty
> > > > > ```
> > > > > What is the correct syntax in these cases?
> > > > > Thank you
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> >
> >
> >
> > --
> > Best regards,
> > Luigi



-- 
Best regards,
Luigi


From @kw@|mmo @end|ng |rom gm@||@com  Mon Aug  9 15:26:20 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 9 Aug 2021 09:26:20 -0400
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
Message-ID: <CAPcHnpQiXdgRUjUPafhub4s6jd3otQAATvboMpZZffbD4k_XZg@mail.gmail.com>

Hello,


There are two convenient ways to access a column in a data.frame using `$`
and `[[`. Using `df` from your first email, we would do something like

df <- data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red",
"empty"))
df$VAL
df[["VAL"]]

The two convenient ways to update / / replace a column with something new
are also very similar, something like

df$VAL <- ...
df[["VAL"]] <- ...

As for the regex part, I would suggest using `sub` instead of `gsub` since
you're looking to remove only the first instance of "value is". Also, I
would recommend using "^" to mark the beginning of your string, something
like

df$VAL <- sub("^Value is ", "", df$VAL, ignore.case = TRUE)

I might be misunderstanding, but it sounds like you also want to remove all
leading whitespace. If so, you could do something like

df$VAL <- sub("^[[:blank:]]*Value is ", "", df$VAL, ignore.case = TRUE)

where "*" signifies that there will be zero or more blank characters at the
beginning of the string. You can try `?regex` to read more about this.

I hope this helps!

On Mon, Aug 9, 2021 at 6:50 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Sorry, silly question, gsub works already with regex. But still, if I
> add `[[:blank:]]` still I don't get rid of all instances. And I am
> keeping obtaining extra columns
> ```
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
>   VAR           VAL value is blue Value is red empty
> 1   1 value is blue             b            b     b
> 2   2  Value is red            rd           rd    rd
> 3   3         empty          mpty         mpty  mpty
> ```
>
> On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >
> > Thank you, that is much appreciated. But on the real data, the
> > substitution works only on few instances. Is there a way to introduce
> > regex into this?
> > Cheers
> > Luigi
> >
> > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > Ah, now I see:
> > >
> > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > > df
> > >  VAR   VAL
> > > 1   1  blue
> > > 2   2   red
> > > 3   3 empty
> > >
> > > Jim
> > >
> > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <
> marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have a dataframe where I would like to change the string of certain
> > > > rows, essentially I am looking to remove some useless text from the
> > > > variables.
> > > > I tried with:
> > > > ```
> > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is
> red", "empty"))
> > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE,
> perl = FALSE)
> > > > > df
> > > >   VAR           VAL value is blue Value is red empty
> > > > 1   1 value is blue          blue         blue  blue
> > > > 2   2  Value is red           red          red   red
> > > > 3   3         empty         empty        empty empty
> > > > ```
> > > > which is of course wrong because I was expecting
> > > > ```
> > > >   VAR           VAL
> > > > 1   1             blue
> > > > 2   2             red
> > > > 3   3            empty
> > > > ```
> > > > What is the correct syntax in these cases?
> > > > Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 15:33:53 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 15:33:53 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <20210809133134.784edd06@trisector>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
Message-ID: <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>

You are right, vect will contain the names of the columns of the real
dataframe buyt the actual simulation of the real case is more like
this:
```
> df = data.frame(A = 1:5, B = c(1, 2, NA, 2, NA), C = c("value is blue", "Value is red", "empty", "  value is blue", " Value is green"), D = 9:13, E = c("light", "light", "heavy", "heavy", "heavy")); df
  A  B               C  D     E
1 1  1   value is blue  9 light
2 2  2    Value is red 10 light
3 3 NA           empty 11 heavy
4 4  2   value is blue 12 heavy
5 5 NA  Value is green 13 heavy
> vect = LETTERS[1:5]
> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"; df
  A  B               C  D     E vect[2]
1 1  1   value is blue  9 light    <NA>
2 2  2    Value is red 10 light    <NA>
3 3 NA           empty 11 heavy    <NA>
4 4  2   value is blue 12 heavy    <NA>
5 5 NA  Value is green 13 heavy    <NA>
> df[df[[vect[2]]] == 2, vect[2]] <- "No"; df
Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value = "No") :
  missing values are not allowed in subscripted assignments of data frames
```
but still, I get an extra column instead of working on column B
directly. and I can't dispense the quotation marks...

On Mon, Aug 9, 2021 at 1:31 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Mon, 9 Aug 2021 13:16:02 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > df = data.frame(VAR = ..., VAL = ...)
> > vect = letters[1:5]
>
> What is the relation between vect and the column names of the data
> frame? Is it your intention to choose rows or columns using `vect`?
>
> > df[df[['vect[2]']] == 2, 'vect[2]']
>
> '...' creates a string literal. If you want to evaluate an R
> expression, don't wrap it in quotes.
>
> I had assumed you wanted to put column names in the vector `vect`, but
> now I'm just confused: `vect` is the same as df$VAR, not colnames(df).
> What do you want to achieve?
>
> Again, you can access the second column with much less typing by
> addressing it directly: df[[2]]
>
> Does it help if you consult [**] or some other tutorial on subsetting
> in R?
>
> --
> Best regards,
> Ivan
>
> [**]
> https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors
> https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Lists



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 15:35:12 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 15:35:12 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAPcHnpQiXdgRUjUPafhub4s6jd3otQAATvboMpZZffbD4k_XZg@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
 <CAPcHnpQiXdgRUjUPafhub4s6jd3otQAATvboMpZZffbD4k_XZg@mail.gmail.com>
Message-ID: <CAMk+s2RN57puWp4+w4UYcmQb_TGzC0yYYXQG-DzFs67Gon=_Sw@mail.gmail.com>

Thank you, it works!

On Mon, Aug 9, 2021 at 3:26 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> Hello,
>
>
> There are two convenient ways to access a column in a data.frame using `$` and `[[`. Using `df` from your first email, we would do something like
>
> df <- data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> df$VAL
> df[["VAL"]]
>
> The two convenient ways to update / / replace a column with something new are also very similar, something like
>
> df$VAL <- ...
> df[["VAL"]] <- ...
>
> As for the regex part, I would suggest using `sub` instead of `gsub` since you're looking to remove only the first instance of "value is". Also, I would recommend using "^" to mark the beginning of your string, something like
>
> df$VAL <- sub("^Value is ", "", df$VAL, ignore.case = TRUE)
>
> I might be misunderstanding, but it sounds like you also want to remove all leading whitespace. If so, you could do something like
>
> df$VAL <- sub("^[[:blank:]]*Value is ", "", df$VAL, ignore.case = TRUE)
>
> where "*" signifies that there will be zero or more blank characters at the beginning of the string. You can try `?regex` to read more about this.
>
> I hope this helps!
>
> On Mon, Aug 9, 2021 at 6:50 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Sorry, silly question, gsub works already with regex. But still, if I
>> add `[[:blank:]]` still I don't get rid of all instances. And I am
>> keeping obtaining extra columns
>> ```
>> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
>> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
>>   VAR           VAL value is blue Value is red empty
>> 1   1 value is blue             b            b     b
>> 2   2  Value is red            rd           rd    rd
>> 3   3         empty          mpty         mpty  mpty
>> ```
>>
>> On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >
>> > Thank you, that is much appreciated. But on the real data, the
>> > substitution works only on few instances. Is there a way to introduce
>> > regex into this?
>> > Cheers
>> > Luigi
>> >
>> > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>> > >
>> > > Hi Luigi,
>> > > Ah, now I see:
>> > >
>> > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
>> > > df
>> > >  VAR   VAL
>> > > 1   1  blue
>> > > 2   2   red
>> > > 3   3 empty
>> > >
>> > > Jim
>> > >
>> > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> > > >
>> > > > Hello,
>> > > > I have a dataframe where I would like to change the string of certain
>> > > > rows, essentially I am looking to remove some useless text from the
>> > > > variables.
>> > > > I tried with:
>> > > > ```
>> > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
>> > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
>> > > > > df
>> > > >   VAR           VAL value is blue Value is red empty
>> > > > 1   1 value is blue          blue         blue  blue
>> > > > 2   2  Value is red           red          red   red
>> > > > 3   3         empty         empty        empty empty
>> > > > ```
>> > > > which is of course wrong because I was expecting
>> > > > ```
>> > > >   VAR           VAL
>> > > > 1   1             blue
>> > > > 2   2             red
>> > > > 3   3            empty
>> > > > ```
>> > > > What is the correct syntax in these cases?
>> > > > Thank you
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > Best regards,
>> > Luigi
>>
>>
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Mon Aug  9 15:41:04 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Mon, 9 Aug 2021 09:41:04 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
Message-ID: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>

Dear All: good morning



*Re:* Sample Size Determination to Compare Three Independent Proportions



*Situation:*



Three Binary variables (Yes, No)

Three independent populations with fixed sizes (*say:* N1 = 1500, N2 = 900,
N3 = 1350).

Power = 0.80

How to choose the sample sizes to compare the three proportions of ?Yes?
among the three variables.



If you know a reference to this topic, it will be very helpful too.



with many thanks in advance

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug  9 16:19:40 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Aug 2021 07:19:40 -0700
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <9192f7107d4148b18cf19d882cf002cc@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>
 <9192f7107d4148b18cf19d882cf002cc@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbR-6uz7VxgnmMpCVanKpWHPsbr+Cke3kWaQ6n5waxq=Vg@mail.gmail.com>

FWIW:

Yes, thanks for noting that.
My own preference is to always propagate NA's and manually decide how
to deal with them, but others may disagree.

Best,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Sun, Aug 8, 2021 at 11:30 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi Bert
>
> Yes, in this case which is not necessary. But in case NAs are involved
> sometimes logical indexing is not a best choice as NA propagates to the
> result, which may be not wanted.
>
> x <- 1:10
> x[c(2,5)] <- NA
> y<- letters[1:10]
> y[x<5]
> [1] "a" NA  "c" "d" NA
> y[which(x<5)]
> [1] "a" "c" "d"
> dat <- data.frame(x,y)
> dat[x<5,]
>       x    y
> 1     1    a
> NA   NA <NA>
> 3     3    c
> 4     4    d
> NA.1 NA <NA>
>
> > dat[which(x<5),]
>   x y
> 1 1 a
> 3 3 c
> 4 4 d
>
> Both results are OK, but one has to consider this NA value propagation.
>
> Cheers
> Petr
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Friday, August 6, 2021 1:29 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
> Subject: Re: [R] Sanity check in loading large dataframe
>
> ... but remove the which() and use logical indexing ...  ;-)
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Aug 6, 2021 at 12:57 AM PIKAL Petr <mailto:petr.pikal at precheza.cz>
> wrote:
> Hi
>
> You already got answer from Avi. I often use dim(data) to inspect how many
> rows/columns I have.
> After that I check if some columns contain all or many NA values.
>
> colSums(http://is.na(data))
> keep <- which(colSums(http://is.na(data))<nnn)
> cleaned.data <- data[, keep]
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Luigi
> > Marongiu
> > Sent: Friday, August 6, 2021 7:34 AM
> > To: Duncan Murdoch <mailto:murdoch.duncan at gmail.com>
> > Cc: r-help <mailto:r-help at r-project.org>
> > Subject: Re: [R] Sanity check in loading large dataframe
> >
> > Ok, so nothing to worry about. Yet, are there other checks I can
> implement?
> > Thank you
> >
> > On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <mailto:murdoch.duncan at gmail.com>
> > wrote:
> >
> > > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> > >  > Hello,
> > >  > I am using a large spreadsheet (over 600 variables).
> > >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ....
> > >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> > >  >    [list output truncated]
> > >  > NULL
> > >  > ```
> > >  > I understand that `[list output truncated]` means that there are
> > > more  > variables than those allowed by str to be displayed as rows.
> > > Thus I  > increased the row's output with:
> > >  > ```
> > >  >
> > >  >> (str(df, list.len=1000))
> > >  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ...
> > >  > NULL
> > >  > ```
> > >  >
> > >  > Does `NULL` mean that some of the variables are not closed?
> > > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > > sanity of the data and avoid that some  > separator is not in the
> > > right place?
> > >  > Thank you
> > >
> > > The NULL is the value returned by str().  Normally it is not printed,
> > > but when you wrap str in parens as (str(df, list.len=1000)), that
> > > forces the value to print.
> > >
> > > str() is unusual in R functions in that it prints to the console as it
> > > runs and returns nothing.  Many other functions construct a value
> > > which is only displayed if you print it, but something like
> > >
> > > x <- str(df, list.len=1000)
> > >
> > > will print the same as if there was no assignment, and then assign
> > > NULL to x.
> > >
> > > Duncan Murdoch
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rc_@chw@rtz @end|ng |rom me@com  Mon Aug  9 16:53:29 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 9 Aug 2021 10:53:29 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
Message-ID: <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>

Hi,

You are going to need to provide more information than what you have 
below and I may be mis-interpreting what you have provided.

Presuming you are designing a prospective, three-group, randomized 
allocation study, there is typically an a priori specification of the 
ratios of the sample sizes for each group such as 1:1:1, indicating that 
the desired sample size in each group is the same.

You would also need to specify the expected proportions of "Yes" values 
in each group.

Further, you need to specify how you are going to compare the 
proportions in each group. Are you going to perform an initial omnibus 
test of all three groups (e.g. 3 x 2 chi-square), possibly followed by 
all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 2 
versus 3), or are you just going to compare 2 versus 1, and 3 versus 1, 
where 1 is a control group?

Depending upon your testing plan, you may also need to account for p 
value adjustments for multiple comparisons, in which case, you also need 
to specify what adjustment method you plan to use, to know what the 
target alpha level will be.

On the other hand, if you already have the data collected, thus have 
fixed sample sizes available per your wording below, simply go ahead and 
perform your planned analyses, as the notion of "power" is largely an a 
priori consideration, which reflects the probability of finding a 
"statistically significant" result at a given alpha level, given that 
your a priori assumptions are valid.

Regards,

Marc Schwartz


AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
> Dear All: good morning
>
> *Re:* Sample Size Determination to Compare Three Independent Proportions
>
> *Situation:*
>
> Three Binary variables (Yes, No)
>
> Three independent populations with fixed sizes (*say:* N1 = 1500, N2 = 900,
> N3 = 1350).
>
> Power = 0.80
>
> How to choose the sample sizes to compare the three proportions of ?Yes?
> among the three variables.
>
> If you know a reference to this topic, it will be very helpful too.
>
> with many thanks in advance
>
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug  9 17:18:43 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 9 Aug 2021 17:18:43 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
Message-ID: <20210809171843.73629fbb@trisector>

Thanks for providing a reproducible example!

On Mon, 9 Aug 2021 15:33:53 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"

Please don't quote R expressions that you want to evaluate. 'vect[2]'
is just a string, like 'hello world' or 'I want to create a new column
named "vect[2]" instead of accessing the second one'.

> Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
> = "No") : missing values are not allowed in subscripted assignments
> of data frames

Since df[[2]] containts NAs, comparisons with it also contain NAs. While
it's possible to subset data.frames with NAs (the rows corresponding to
the NAs are returned filled with NAs of corresponding types),
assignment to undefined rows is not allowed. A simple way to remove the
NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
to use which(). Compare:

df[df[[vect[2]]] == 2,]
df[which(df[[vect[2]]] == 2),]

-- 
Best regards,
Ivan


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 21:22:40 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 21:22:40 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <20210809171843.73629fbb@trisector>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
 <20210809171843.73629fbb@trisector>
Message-ID: <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>

Thank you! it worked fine! The only pitfall is that `NA` became
`<NA>`. This is essentially the same thing anyway...

On Mon, Aug 9, 2021 at 5:18 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> Thanks for providing a reproducible example!
>
> On Mon, 9 Aug 2021 15:33:53 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"
>
> Please don't quote R expressions that you want to evaluate. 'vect[2]'
> is just a string, like 'hello world' or 'I want to create a new column
> named "vect[2]" instead of accessing the second one'.
>
> > Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
> > = "No") : missing values are not allowed in subscripted assignments
> > of data frames
>
> Since df[[2]] containts NAs, comparisons with it also contain NAs. While
> it's possible to subset data.frames with NAs (the rows corresponding to
> the NAs are returned filled with NAs of corresponding types),
> assignment to undefined rows is not allowed. A simple way to remove the
> NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
> to use which(). Compare:
>
> df[df[[vect[2]]] == 2,]
> df[which(df[[vect[2]]] == 2),]
>
> --
> Best regards,
> Ivan



-- 
Best regards,
Luigi


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Aug 10 00:12:26 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 9 Aug 2021 15:12:26 -0700
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
 <20210809171843.73629fbb@trisector>
 <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>
Message-ID: <36fe8019-bd11-3d34-81dc-5a0d4d7d3081@comcast.net>


On 8/9/21 12:22 PM, Luigi Marongiu wrote:
> Thank you! it worked fine! The only pitfall is that `NA` became
> `<NA>`. This is essentially the same thing anyway...


It's not "essentially the same thing". It IS the same thing. The print 
function displays those '<>' characters flanking NA's when the class is 
factor. Type this at your console:


factor(NA)


-- 

David

>
> On Mon, Aug 9, 2021 at 5:18 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>> Thanks for providing a reproducible example!
>>
>> On Mon, 9 Aug 2021 15:33:53 +0200
>> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>>> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"
>> Please don't quote R expressions that you want to evaluate. 'vect[2]'
>> is just a string, like 'hello world' or 'I want to create a new column
>> named "vect[2]" instead of accessing the second one'.
>>
>>> Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
>>> = "No") : missing values are not allowed in subscripted assignments
>>> of data frames
>> Since df[[2]] containts NAs, comparisons with it also contain NAs. While
>> it's possible to subset data.frames with NAs (the rows corresponding to
>> the NAs are returned filled with NAs of corresponding types),
>> assignment to undefined rows is not allowed. A simple way to remove the
>> NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
>> to use which(). Compare:
>>
>> df[df[[vect[2]]] == 2,]
>> df[which(df[[vect[2]]] == 2),]
>>
>> --
>> Best regards,
>> Ivan
>
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Aug 10 00:39:20 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 10 Aug 2021 10:39:20 +1200
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
Message-ID: <20210810103920.7fdbd930@rolf-Latitude-E7470>


I thought that I should let everyone know that I have, in some sense at
least, resolved my problem with 'no "doc" directory' and Rstudio.  I
got a useful reply off-list from Duncan Murdoch (thanks Duncan) to the
effect that Rstudio requires its own purpose-specific binaries.

I was always under the impression that Rstudio would invoke whatever
instance of R that the user had installed, but this seems not to
be the case.  Duncan pointed me to instructions for installing  R in
such a way as to satisfy Rstudio.  I had not found such instructions
previously.

After considerable travail (I had "curl" problems with which I will not
bore you) I managed to effect this installation, which put R into
/opt/R/4.1.0 and lo and behold /opt/R/4.1.0/lib/R does indeed contain a
"doc" directory (unlike, e.g. /usr/lib/R which is my non-Rstudio
instance of R lives.)

Having done that and having made the appropriate symbolic links,
I was able to click on the Rstudio icon under Applications ->
Programming and get Rstudio running.

So far I can find no way to get Rstudio to do what I had hoped to be
able to do --- something that cannot effectively be done in raw R.
But that's another story.

I raised this same issue on the "Rstudio Community" web site, and the
contrast between what I got from that and what I got from R-help was
striking.  What I got from the former was deafening silence.  I got
seven responses on the R-help mailing list, plus Duncan's off-list
response.

Does this say something about the efficacy of mailing lists as
contrasted with web site fora?  Or is it just a difference between the
R community and the Rstudio community?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From edd @end|ng |rom deb|@n@org  Tue Aug 10 00:58:21 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 9 Aug 2021 17:58:21 -0500
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210810103920.7fdbd930@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
 <20210810103920.7fdbd930@rolf-Latitude-E7470>
Message-ID: <24849.45837.453388.549593@rob.eddelbuettel.com>


Rolf,

Sorry for only briefly chiming in, and late, but I don't usually follow
r-help that much these days.

I am writing this from an Ubuntu machine running R as well as RStudio from
pre-made binary .deb packages. R comes via apt from CRAN (using Michael's
binaries), RStudio from them via helper scripts in a package of mine:

  edd at rob:~$ dpkg -l | grep "r-base-core\|rstudio\|rstudio-server" | cut -c-79
  ii  r-base-core                                4.1.0-1.2104.0                  
  ii  rstudio                                    2021-07.0.270                   
  ii  rstudio-server                             2021-07.0.270                   
  edd at rob:~$

Contrary to what you wrote, RStudio *will* use whichever binary it finds
first in the path, just like any other Unix tool.  So when I do

   $ rstudio

I get R 4.1.0 from the binary above, but if I opt into my locally compiled
R-devel via a standard PATH prefix then

   $ PATH=/usr/local/lib/R-devel/bin/:$PATH rstudio

RStudio happily runs with R-devel.

Next, "doc/". This has been in /usr/share/R for probably well over a decade
on these Debian system; almost all other packages on Linux distros also split
between binary ("architecture-specific") directories (such as lib/) and
binary-independent ones (such as share/).

And by the way, in R you can do call R.home() with an argument to see:

   > R.home("doc")
   [1] "/usr/share/R/doc"
   > R.home("library")
   [1] "/usr/lib/R/library"
   > 

Of course, you are free to use whichever R installation and configuration
*you* mind most suitable. It is after all your machine.  But quite a few of
us are happy with these official binaries.

Lastly, and I we may have mentioned this to you before, a dedicated mailing
lists for 'R on Debian + Ubuntu' exists (in r-sig-debian at the usual ETH
server) and you might have gotten useful answers sooner.

Anyway, you are set now, so enjoy R!

Cheers, Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug 10 06:21:48 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Aug 2021 14:21:48 +1000
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn6Nyis5Xric7ng6qMaZBgXs9ctxS97b6R6+HFmNWK7anA@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>
 <CAO29qn6Nyis5Xric7ng6qMaZBgXs9ctxS97b6R6+HFmNWK7anA@mail.gmail.com>
Message-ID: <CA+8X3fVN4wWkTcg=nnX7GkXTuzGd3yVsf89=38Ru3o4swaPO4A@mail.gmail.com>

Here is my hasty attempt last night checked in the light of morning.
It seems to return the correct extreme values and contains an example.

Jim

On Mon, Aug 9, 2021 at 10:50 PM Md. Moyazzem Hossain
<hossainmm at juniv.edu> wrote:
>
> Dear Jim,
>
> Thank you very much for your kind help.
>
> Take care.
>
> Md
>
> On Mon, Aug 9, 2021 at 1:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> And if you really don't like programming:
>>
>> whipple_index<-function(x,td=c(0,5)) {
>>  wi<-rep(NA,11)
>>  names(wi)<-c(paste0("wi",0:9),"O/all")
>>  for(i in 0:9) {
>>   ttd<-which((x %% 10) %in% i)
>>   wi[i+1]<-length(ttd) * 100/length(x)
>>  }
>>  ttd<-which((x %% 10) %in% td)
>>  wi[11]<-length(ttd) * 100/(length(x)/length(td))
>>  return(wi)
>> }
>>
>> I haven't tested this extensively, but it may be helpful. You can
>> specify the final digits for the overall test. Select your ages before
>> passing them to whipple_index.
>>
>> Jim
>>
>> On Mon, Aug 9, 2021 at 9:05 PM Greg Minshall <minshall at umich.edu> wrote:
>> >
>> > Md,
>> >
>> > if this is what you are looking for:
>> > ----
>> > https://en.wikipedia.org/wiki/Whipple%27s_index
>> > ----
>> >
>> > then, the article says the algorithm is
>> > ----
>> > The index score is obtained by summing the number of persons in the age
>> > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
>> > that sum by the total population between ages 23 and 62 years inclusive,
>> > and multiplying the result by 5. Restated as a percentage, index scores
>> > range between 100 (no preference for ages ending in 0 and 5) and 500
>> > (all people reporting ages ending in 0 and 5).
>> > ----
>> >
>> > that seems fairly straight forward.  if you are trying to learn R,
>> > and/or learn programming, i might suggest you *not* use a package, and
>> > rather work on coding up the calculation yourself.  that would probably
>> > be a good, but not too hard, exercise, of some interest.  enjoy!
>> >
>> > cheers, Greg
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: Google Scholar; ResearchGate; ORCID iD

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Aug 10 07:55:41 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 10 Aug 2021 07:55:41 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <36fe8019-bd11-3d34-81dc-5a0d4d7d3081@comcast.net>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
 <20210809171843.73629fbb@trisector>
 <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>
 <36fe8019-bd11-3d34-81dc-5a0d4d7d3081@comcast.net>
Message-ID: <CAMk+s2RrUBj0JBa-BFtk_UeZwoVB3xSVWUO_m8g_ddExhgrC4w@mail.gmail.com>

Got it, thank you!

On Tue, 10 Aug 2021, 00:12 David Winsemius, <dwinsemius at comcast.net> wrote:

>
> On 8/9/21 12:22 PM, Luigi Marongiu wrote:
> > Thank you! it worked fine! The only pitfall is that `NA` became
> > `<NA>`. This is essentially the same thing anyway...
>
>
> It's not "essentially the same thing". It IS the same thing. The print
> function displays those '<>' characters flanking NA's when the class is
> factor. Type this at your console:
>
>
> factor(NA)
>
>
> --
>
> David
>
> >
> > On Mon, Aug 9, 2021 at 5:18 PM Ivan Krylov <krylov.r00t at gmail.com>
> wrote:
> >> Thanks for providing a reproducible example!
> >>
> >> On Mon, 9 Aug 2021 15:33:53 +0200
> >> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>
> >>> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"
> >> Please don't quote R expressions that you want to evaluate. 'vect[2]'
> >> is just a string, like 'hello world' or 'I want to create a new column
> >> named "vect[2]" instead of accessing the second one'.
> >>
> >>> Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
> >>> = "No") : missing values are not allowed in subscripted assignments
> >>> of data frames
> >> Since df[[2]] containts NAs, comparisons with it also contain NAs. While
> >> it's possible to subset data.frames with NAs (the rows corresponding to
> >> the NAs are returned filled with NAs of corresponding types),
> >> assignment to undefined rows is not allowed. A simple way to remove the
> >> NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
> >> to use which(). Compare:
> >>
> >> df[df[[vect[2]]] == 2,]
> >> df[which(df[[vect[2]]] == 2),]
> >>
> >> --
> >> Best regards,
> >> Ivan
> >
> >
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Tue Aug 10 09:33:02 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 10 Aug 2021 19:33:02 +1200
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>
Message-ID: <CABcYAdJZmgLfTa=sgOwF6CPoGB0K0zQWBizihpPyt_uQmGbPSQ@mail.gmail.com>

If you want to look at each digit, you should take a step back and
think about what the
Whipple index is actually doing.  Basically, the model underlying the
Whipple index is
that Pr(age = xy) = Pr(age = x*)Pr(age = *y) if there is no age
heaping.  Or rather,
since the age is restricted to 23..62 (a whole number of decades), it is that
Pr(age - 23 = xy) = Pr(age - 23  = x*)Pr(age - 23 = *y) for 0 <= x <=
3, 0 <= y <= 9
and the "nothing to see here" case is Pr(age = *y) = 1/10.

I wasted way too much time trying to find a free age data set where
age *wasn't* already
grouped into 5 year bands.

So what's wrong with a chi-square test?
I would certainly want to check whether the high and low digits of age
- 23 were in fact independent.

On Mon, 9 Aug 2021 at 23:48, Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Dear Greg,
>
> Thank you very much for your suggestion. I will try it and follow your
> advice.
>
> Actually, I want to find out the index for each digit like 0, 1, ..., 9.
>
> Thanks in advance. Take care.
>
> Md
>
>
>
> On Mon, Aug 9, 2021 at 12:05 PM Greg Minshall <minshall at umich.edu> wrote:
>
> > Md,
> >
> > if this is what you are looking for:
> > ----
> > https://en.wikipedia.org/wiki/Whipple%27s_index
> > ----
> >
> > then, the article says the algorithm is
> > ----
> > The index score is obtained by summing the number of persons in the age
> > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> > that sum by the total population between ages 23 and 62 years inclusive,
> > and multiplying the result by 5. Restated as a percentage, index scores
> > range between 100 (no preference for ages ending in 0 and 5) and 500
> > (all people reporting ages ending in 0 and 5).
> > ----
> >
> > that seems fairly straight forward.  if you are trying to learn R,
> > and/or learn programming, i might suggest you *not* use a package, and
> > rather work on coding up the calculation yourself.  that would probably
> > be a good, but not too hard, exercise, of some interest.  enjoy!
> >
> > cheers, Greg
> >
> >
>
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *Google Scholar
> <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Tue Aug 10 10:18:08 2021
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Tue, 10 Aug 2021 10:18:08 +0200
Subject: [R] [Rd] R 4.1.1 is released
Message-ID: <8A0CEFBD-74CF-4928-A587-1C58811F799B@gmail.com>

The build system rolled up R-4.1.1.tar.gz (codename "Kick Things") this morning.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.1.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = da5e7c699a83608d0f1e39c458d9fc56
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 6094024214a482c0d01d2ab2adca4b3f
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = fbc4810ff26ebcec514ebaa1c1909ad7
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = a767f7809324c73c49eaff47d14bce81
MD5 (NEWS.3) = e55ed2c8a547b827b46e08eb7137ba23
MD5 (R-latest.tar.gz) = c278cfeb85b1564540ab214e45fe68d9
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = a79b9b338cab09bd665f6b62ac6f455b
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 34443dff7fcea700c8ec4740e5804374
MD5 (R-4/R-4.1.1.tar.gz) = c278cfeb85b1564540ab214e45fe68d9

9704a7d96c350a48417ef215888a29f1993ee5dec1b73cb95755e8625b860200  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
2894e7a88634a08c05bfafb8a694a26b635e4042160aab46fa6a0f4eb68ea91e  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
e8bdaf546cf65fdc5bf2a81fa5334572886ff2f1317ec6cdc9e61d6de3532dd4  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ba74618bc3f4c0e336dca13d472402a1863d12ba6f7f91a1782bc469ee986f6d  NEWS.2
1910a2405300b9bc7c76beeb0753a5249cf799afe175ce28f8d782fab723e012  NEWS.3
515e03265752257d0b7036f380f82e42b46ed8473f54f25c7b67ed25bbbdd364  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
8b7d3856100220f4555d4d57140829f2e81c27eccec5b441f5dce616e9ec9061  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
02686ea05e64304a755bf776cdeeadafd2c5017a13f9203f1db9278287c81aa6  VERSION-INFO.dcf
515e03265752257d0b7036f380f82e42b46ed8473f54f25c7b67ed25bbbdd364  R-4/R-4.1.1.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.1.1:

  NEW FEATURES:

    * require(pkg, quietly = TRUE) is quieter and in particular does
      not warn if the package is not found.

  DEPRECATED AND DEFUNCT:

    * Use of ftp:// URIs should be regarded as deprecated, with
      on-going support confined to method = "libcurl" and not routinely
      tested.  (Nowadays no major browser supports them.)

    * The non-default method = "internal" is deprecated for http:// and
      ftp:// URIs for both download.file and url.

    * On Windows, method = "wininet" is deprecated for http://,
      https:// and ftp:// URIs for both download.file and url.  (A
      warning is only given for ftp://.)

      For ftp:// URIs the default method is now "libcurl" if available
      (which it is on CRAN builds).

      method = "wininet" remains the default for http:// and https://
      URIs but if libcurl is available, using method = "libcurl" is
      preferred.

  INSTALLATION:

    * make check now works also without a LaTeX installation.  (Thanks
      to Sebastian Meyer's PR#18103.)

  BUG FIXES:

    * make check-devel works again in an R build configured with
      --without-recommended-packages.

    * qnbinom(p, size, mu) for large size/mu is correct now in a range
      of cases (PR#18095); similarly for the (size, prob)
      parametrization of the negative binomial.  Also qpois() and
      qbinom() are better and or faster for extreme cases.  The
      underlying C code has been modularized and is common to all four
      cases of discrete distributions.

    * gap.axis is now part of the axis() arguments which are passed
      from bxp(), and hence boxplot().  (Thanks to Martin Smith's
      report and suggestions in PR#18109.)

    * .First and .Last can again be set from the site profile.

    * seq.int(from, to, *) and seq.default(..) now work better in large
      range cases where from-to is infinite where the two boundaries
      are finite.

    * all.equal(x,y) now returns TRUE correctly also when several
      entries of abs(x) and abs(y) are close to .Machine$double.xmax,
      the largest finite numeric.

    * model.frame() now clears the object bit when removing the class
      attribute of a value via na.action (PR#18100).

    * charClass() now works with multi-character strings on Windows
      (PR#18104, fixed by Bill Dunlap).

    * encodeString() on Solaris now works again in Latin-1 encoding on
      characters represented differently in UTF-8.  Support for
      surrogate pairs on Solaris has been improved.

    * file.show() on Windows now works with non-ASCII path names
      representable in the current native encoding (PR#18132).

    * Embedded R on Windows can now find R home directory via the
      registry even when installed only for the current user
      (PR#18135).

    * pretty(x) with finite x now returns finite values also in the
      case where the extreme x values are close in size to the maximal
      representable number .Machine$double.xmax.

      Also, it's been tweaked for very small ranges and when a boundary
      is close (or equal) to zero; e.g., pretty(c(0,1e-317)) no longer
      has negative numbers, currently still warning about a very small
      range, and pretty(2^-(1024 - 2^-1/(c(24,10)))) is more accurate.

    * The error message for not finding vignette files when weaving has
      correct file sizes now. (Thanks to Sebastian Meyer's PR#18154.)

    * dnbinom(20, <large>, 1) now correctly gives 0, and similar cases
      are more accurate with underflow precaution.  (Reported by
      Francisco Vera Alcivar in PR#18072.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ho@@@|nmm @end|ng |rom jun|v@edu  Tue Aug 10 10:33:48 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Tue, 10 Aug 2021 09:33:48 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <CABcYAdJZmgLfTa=sgOwF6CPoGB0K0zQWBizihpPyt_uQmGbPSQ@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>
 <CABcYAdJZmgLfTa=sgOwF6CPoGB0K0zQWBizihpPyt_uQmGbPSQ@mail.gmail.com>
Message-ID: <CAO29qn7n=ncyk61tVBttqUM0RZcjLE61jp30gP7b-gbd0C45sA@mail.gmail.com>

Dear Richard O'Keefe,

Thank you very much.

Take care.

Md

On Tue, Aug 10, 2021 at 8:33 AM Richard O'Keefe <raoknz at gmail.com> wrote:

> If you want to look at each digit, you should take a step back and
> think about what the
> Whipple index is actually doing.  Basically, the model underlying the
> Whipple index is
> that Pr(age = xy) = Pr(age = x*)Pr(age = *y) if there is no age
> heaping.  Or rather,
> since the age is restricted to 23..62 (a whole number of decades), it is
> that
> Pr(age - 23 = xy) = Pr(age - 23  = x*)Pr(age - 23 = *y) for 0 <= x <=
> 3, 0 <= y <= 9
> and the "nothing to see here" case is Pr(age = *y) = 1/10.
>
> I wasted way too much time trying to find a free age data set where
> age *wasn't* already
> grouped into 5 year bands.
>
> So what's wrong with a chi-square test?
> I would certainly want to check whether the high and low digits of age
> - 23 were in fact independent.
>
> On Mon, 9 Aug 2021 at 23:48, Md. Moyazzem Hossain <hossainmm at juniv.edu>
> wrote:
> >
> > Dear Greg,
> >
> > Thank you very much for your suggestion. I will try it and follow your
> > advice.
> >
> > Actually, I want to find out the index for each digit like 0, 1, ..., 9.
> >
> > Thanks in advance. Take care.
> >
> > Md
> >
> >
> >
> > On Mon, Aug 9, 2021 at 12:05 PM Greg Minshall <minshall at umich.edu>
> wrote:
> >
> > > Md,
> > >
> > > if this is what you are looking for:
> > > ----
> > > https://en.wikipedia.org/wiki/Whipple%27s_index
> > > ----
> > >
> > > then, the article says the algorithm is
> > > ----
> > > The index score is obtained by summing the number of persons in the age
> > > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> > > that sum by the total population between ages 23 and 62 years
> inclusive,
> > > and multiplying the result by 5. Restated as a percentage, index scores
> > > range between 100 (no preference for ages ending in 0 and 5) and 500
> > > (all people reporting ages ending in 0 and 5).
> > > ----
> > >
> > > that seems fairly straight forward.  if you are trying to learn R,
> > > and/or learn programming, i might suggest you *not* use a package, and
> > > rather work on coding up the calculation yourself.  that would probably
> > > be a good, but not too hard, exercise, of some interest.  enjoy!
> > >
> > > cheers, Greg
> > >
> > >
> >
> > --
> > Best Regards,
> > Md. Moyazzem Hossain
> > Associate Professor
> > Department of Statistics
> > Jahangirnagar University
> > Savar, Dhaka-1342
> > Bangladesh
> > Website: http://www.juniv.edu/teachers/hossainmm
> > Research: *Google Scholar
> > <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> > *ResearchGate
> > <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> > <https://orcid.org/0000-0003-3593-6936>*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Aug 10 12:34:06 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 10 Aug 2021 06:34:06 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
 <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
Message-ID: <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>

Hi Marc:

First, thank you very much for your help in this matter.


Will perform an initial omnibus test of all three groups (e.g. 3 x 2
chi-square), possibly followed by
all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3,
2 versus 3),

We can assume *either* the desired sample size in each group is the same
*or* proportional to the population size.

 We can set p=0.25 and set p1=p2=p3=p so that the H0 is true.

We can assume that the expected proportion of "Yes" values in each group is
0.25

For the alternative hypotheses, for example,  we can set  p1 = .25, p2=.25,
p3=.35


Again thank you very much in advance.

abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Mon, Aug 9, 2021 at 10:53 AM Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> You are going to need to provide more information than what you have
> below and I may be mis-interpreting what you have provided.
>
> Presuming you are designing a prospective, three-group, randomized
> allocation study, there is typically an a priori specification of the
> ratios of the sample sizes for each group such as 1:1:1, indicating that
> the desired sample size in each group is the same.
>
> You would also need to specify the expected proportions of "Yes" values
> in each group.
>
> Further, you need to specify how you are going to compare the
> proportions in each group. Are you going to perform an initial omnibus
> test of all three groups (e.g. 3 x 2 chi-square), possibly followed by
> all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 2
> versus 3), or are you just going to compare 2 versus 1, and 3 versus 1,
> where 1 is a control group?
>
> Depending upon your testing plan, you may also need to account for p
> value adjustments for multiple comparisons, in which case, you also need
> to specify what adjustment method you plan to use, to know what the
> target alpha level will be.
>
> On the other hand, if you already have the data collected, thus have
> fixed sample sizes available per your wording below, simply go ahead and
> perform your planned analyses, as the notion of "power" is largely an a
> priori consideration, which reflects the probability of finding a
> "statistically significant" result at a given alpha level, given that
> your a priori assumptions are valid.
>
> Regards,
>
> Marc Schwartz
>
>
> AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
> > Dear All: good morning
> >
> > *Re:* Sample Size Determination to Compare Three Independent Proportions
> >
> > *Situation:*
> >
> > Three Binary variables (Yes, No)
> >
> > Three independent populations with fixed sizes (*say:* N1 = 1500, N2 =
> 900,
> > N3 = 1350).
> >
> > Power = 0.80
> >
> > How to choose the sample sizes to compare the three proportions of ?Yes?
> > among the three variables.
> >
> > If you know a reference to this topic, it will be very helpful too.
> >
> > with many thanks in advance
> >
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
>
>

	[[alternative HTML version deleted]]


From jrm||k@ @end|ng |rom y@hoo@com  Tue Aug 10 12:58:18 2021
From: jrm||k@ @end|ng |rom y@hoo@com (James Milks)
Date: Tue, 10 Aug 2021 06:58:18 -0400
Subject: [R] Replacing certain rows with values from a different column
References: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D.ref@yahoo.com>
Message-ID: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D@yahoo.com>

I have two columns in a larger data set that list countries in one column and, in some cases, individual provinces within a country or oversea territories in another. I have country population in a second data set that I?m planning to use to calculate per capita rates in the first data set. My issue: I need to match my two data sets. Here are some examples:

First data set:

Province <- c("Australian Capital Territory", "New South Wales", "Northern Territory", "Queensland", "South Australia", "Tasmania", "Victoria", "Western Australia", "", "", "", "Faroe Islands", "Greenland")

Country <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", "Denmark", "Denmark")

firstdf <- data.frame(Province, Country)

Second data set:

Country <- c("Australia", "Austria", "Azerbaijan", "Denmark", "Faroe Islands", "Greenland")

seconddf <- data.frame(Country)

In this example, I need to aggregate sum Australia while keeping Faroe Islands and Greenland separate from Denmark. What I?d like to do is create a column that looks like this:

firstdf$nation <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", ?Faroe Islands", ?Greenland?)

Is there a way to do this or am I stuck doing this by hand?

Thanks for any help on this vexing issue.

Jim Milks
	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Tue Aug 10 13:07:27 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Tue, 10 Aug 2021 13:07:27 +0200
Subject: [R] Replacing certain rows with values from a different column
In-Reply-To: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D@yahoo.com>
References: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D.ref@yahoo.com>
 <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D@yahoo.com>
Message-ID: <52d39762-4517-a6f9-393f-0f6d8732e57e@math.uni-giessen.de>

Hi, James,

if I understand you correctly, maybe,

with(firstdf,
   ifelse(Province %in% seconddf$Country,
          Province,
          Country)
)

does what you want?

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 10.08.2021 um 12:58 schrieb James Milks via R-help:
> I have two columns in a larger data set that list countries in one column and, in some cases, individual provinces within a country or oversea territories in another. I have country population in a second data set that I?m planning to use to calculate per capita rates in the first data set. My issue: I need to match my two data sets. Here are some examples:
> 
> First data set:
> 
> Province <- c("Australian Capital Territory", "New South Wales", "Northern Territory", "Queensland", "South Australia", "Tasmania", "Victoria", "Western Australia", "", "", "", "Faroe Islands", "Greenland")
> 
> Country <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", "Denmark", "Denmark")
> 
> firstdf <- data.frame(Province, Country)
> 
> Second data set:
> 
> Country <- c("Australia", "Austria", "Azerbaijan", "Denmark", "Faroe Islands", "Greenland")
> 
> seconddf <- data.frame(Country)
> 
> In this example, I need to aggregate sum Australia while keeping Faroe Islands and Greenland separate from Denmark. What I?d like to do is create a column that looks like this:
> 
> firstdf$nation <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", ?Faroe Islands", ?Greenland?)
> 
> Is there a way to do this or am I stuck doing this by hand?
> 
> Thanks for any help on this vexing issue.
> 
> Jim Milks
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Aug 10 15:28:52 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 10 Aug 2021 09:28:52 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
 <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
 <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>
Message-ID: <27668c28-708f-3674-3e58-f3228c0eccaa@me.com>

Hi,

A search would suggest that there may not be an R function/package that 
provides power/sample size calculations for the specific scenarios that 
you are describing. There may be something that I am missing, and there 
is also other dedicated software such as PASS 
(https://www.ncss.com/software/pass/) which is not free, but provides a 
large library of possibly relevant functions and support.

That being said, you can run Monte Carlo simulations in R to achieve the 
results you want, while providing yourself with options relative to 
study design, intended tests, and adjustments for multiple comparisons 
as apropos. Many prefer this approach, since it gives you specific 
control over this process.

Taking the simple case, where you are going to run a 3 x 2 chi-square as 
your primary endpoint, and want to power for that, here is a possible 
function, with the same sample size in each group:

ThreeGroups <- function(n, p1, p2, p3, R = 10000, power = 0.8) {

   MCSim <- function(n, p1, p2, p3) {
     ## Create a binary distribution for each group
     G1 <- rbinom(n, 1, p1)
     G2 <- rbinom(n, 1, p2)
     G3 <- rbinom(n, 1, p3)

     ## Create a 3 x 2 matrix containing the 3 group counts
     MAT <- cbind(table(G1), table(G2), table(G3))

     ## Perform a chi-square and just return the p value
     chisq.test(MAT)$p.value
   }

   ## Replicate the above R times, and get
   ## a distribution of p values
   MC <- replicate(R, MCSim(n, p1, p2, p3))

   ## Get the p value at the desired "power" quantile
   quantile(MC, power)
}

Essentially, the above internal MCSim() function generates 3 random 
samples of size 'n' from the binomial distribution, at the 3 proportions 
desired. For each run, it will perform a chi-square test of the 3 x 2 
matrix of counts, returning the p value for each run. The main function 
will then return the p value at the quantile (power) within the 
generated distribution of p values.

You can look at the help pages for the various functions that I use 
above, to get a sense for how they work.

You increase the sample size ('n') until you get a p value returned <= 
0.05, if that is your desired alpha level.

You also want 'R', the number of replications within each run, to be 
large enough so that the returned p value quantile is relatively stable. 
Values for 'R', once you get "close to" the desired p value should be on 
the order of 1,000,000 or higher. Stay with lower values for 'R' until 
you get in the ballpark of your target, since larger values take much 
longer to run.

Thus, using your example proportions of 0.25, 0.25, and 0.35:

## 250 per group, 750 total - Not enough
 > ThreeGroups(250, 0.25, 0.25, 0.35, R = 10000)
        80%
0.08884723

## 350 per group, 1050 total - Too high
 > ThreeGroups(350, 0.25, 0.25, 0.35, R = 10000)
       80%
0.0270829

## 300 per group, 900 total - Close!
 > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
        80%
0.04818842


So, keep tweaking the sample size until you get a returned p value at 
your target alpha level, with a large enough 'R', so that you get 
consistent sample sizes for multiple runs.

If I run 300 per group again, with 10,000 replicates:

 > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
        80%
0.05033933

the returned p value is slightly higher. So, again, increase R to 
improve the stability of the returned p value and run it multiple times 
to be comfortable that the p value change is less than an acceptable 
threshold.

Now, the tricky part is to decide if the 3 x 2 is your primary endpoint, 
and want to power only for that, or, if you also want to power for the 
other two-group comparisons, possibly having to account for p value 
adjustments for the multiple comparisons, resulting in the need to power 
for a lower alpha level for those tests. In that scenario, you would end 
up taking the largest sample size that you identify across the various 
hypotheses, recognizing that while you are powering for one hypothesis, 
you may be overpowering for others.

That is something that you need to decide, and perhaps consider 
consulting with other local statistical expertise, as may be apropos, in 
the prospective study design, possibly influenced by other 
relevant/similar research in your domain.

You can easily modify the above function for the two-group scenario as 
well, and I will leave that to you.

Regards,

Marc


AbouEl-Makarim Aboueissa wrote on 8/10/21 6:34 AM:
> Hi?Marc:
> 
> First, thank you very much for your help in this matter.
> 
> 
> Will perform an initial omnibus?test of all three groups (e.g. 3 x 2 
> chi-square), possibly followed by
> all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 
> 2?versus 3),
> 
> We can assume _either_ the desired sample size in each group is the same 
> _or_ proportional to the population size.
> 
>  ?We can set p=0.25 and set p1=p2=p3=p so that the H0 is true.
> 
> We can assume that the expected proportion of "Yes" values in each group 
> is 0.25
> 
> For the alternative hypotheses, for example,? we can set? p1 = .25, 
> p2=.25, p3=.35
> 
> 
> Again thank you very much in?advance.
> 
> abou
> 
> ______________________
> 
> *AbouEl-Makarim Aboueissa, PhD
> *
> *
> *
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
> *Department of Mathematics and Statistics
> *
> *University of Southern Maine*
> 
> 
> 
> On Mon, Aug 9, 2021 at 10:53 AM Marc Schwartz <marc_schwartz at me.com 
> <mailto:marc_schwartz at me.com>> wrote:
> 
>     Hi,
> 
>     You are going to need to provide more information than what you have
>     below and I may be mis-interpreting what you have provided.
> 
>     Presuming you are designing a prospective, three-group, randomized
>     allocation study, there is typically an a priori specification of the
>     ratios of the sample sizes for each group such as 1:1:1, indicating
>     that
>     the desired sample size in each group is the same.
> 
>     You would also need to specify the expected proportions of "Yes" values
>     in each group.
> 
>     Further, you need to specify how you are going to compare the
>     proportions in each group. Are you going to perform an initial omnibus
>     test of all three groups (e.g. 3 x 2 chi-square), possibly followed by
>     all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 2
>     versus 3), or are you just going to compare 2 versus 1, and 3 versus 1,
>     where 1 is a control group?
> 
>     Depending upon your testing plan, you may also need to account for p
>     value adjustments for multiple comparisons, in which case, you also
>     need
>     to specify what adjustment method you plan to use, to know what the
>     target alpha level will be.
> 
>     On the other hand, if you already have the data collected, thus have
>     fixed sample sizes available per your wording below, simply go ahead
>     and
>     perform your planned analyses, as the notion of "power" is largely an a
>     priori consideration, which reflects the probability of finding a
>     "statistically significant" result at a given alpha level, given that
>     your a priori assumptions are valid.
> 
>     Regards,
> 
>     Marc Schwartz
> 
> 
>     AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
>      > Dear All: good morning
>      >
>      > *Re:* Sample Size Determination to Compare Three Independent
>     Proportions
>      >
>      > *Situation:*
>      >
>      > Three Binary variables (Yes, No)
>      >
>      > Three independent populations with fixed sizes (*say:* N1 = 1500,
>     N2 = 900,
>      > N3 = 1350).
>      >
>      > Power = 0.80
>      >
>      > How to choose the sample sizes to compare the three proportions
>     of ?Yes?
>      > among the three variables.
>      >
>      > If you know a reference to this topic, it will be very helpful too.
>      >
>      > with many thanks in advance
>      >
>      > abou
>      > ______________________
>      >
>      >
>      > *AbouEl-Makarim Aboueissa, PhD*
>      >
>      > *Professor, Statistics and Data Science*
>      > *Graduate Coordinator*
>      >
>      > *Department of Mathematics and Statistics*
>      > *University of Southern Maine*
>      >
>


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Wed Aug 11 07:30:57 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Tue, 10 Aug 2021 22:30:57 -0700
Subject: [R] assigning suitability index value
Message-ID: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>

Hi R Users,
I have two tables, one is temperature data (temp) and another table is a
suitability index. I wanted to assign the suitability index value in the
temperature data (temp) based on Table 2 (or graph, which is a suitability
curve), but I could not figure it out.
Are there any suggestions for me how I can assign the suitability index
value in table1 (temp) based on the suitability graph? I have a very big
data set but showing only a few data to illustrate the problem.

temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,

1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,

1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,

1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,

415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,

415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,

415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,

15.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,

15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,

16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859

)), class = "data.frame", row.names = c(NA, -19L))


print(temp)


table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,

0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA,

-6L))

print(table2)


ggplot(data=table2, aes(x=temp, y=Index)) +

  geom_path()+

  geom_point()



# now I would like to assign the index value of table 2 into table 1
(temp), and I was looking for the following table as an output. The index
value in the output I put manually.


Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
 1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,

1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,

1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,

415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,

415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,

415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,

0.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,

15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,

16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859

), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,

0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class = "data.frame", row.names
= c(NA,

-19L))


print(Output)


Thank you very much for your help.

MW

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug 11 08:16:08 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 10 Aug 2021 23:16:08 -0700
Subject: [R] assigning suitability index value
In-Reply-To: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>
References: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>
Message-ID: <79717F5E-7972-418A-9727-FF9874CE91EE@dcn.davis.ca.us>

Piecewise linear interpolation is implemented in the ?approx function. It does not agree exactly with your Output, I don't know if there is something else you are accounting for it if your Output is in error.

temp$index <- approx( table2$temp, table2$Index, temp$temp )$y

BTW your code was usable but messed up... please set your email program to send plain text email so your formatting does not mess with your code.


On August 10, 2021 10:30:57 PM PDT, Marna Wagley <marna.wagley at gmail.com> wrote:
>Hi R Users,
>I have two tables, one is temperature data (temp) and another table is a
>suitability index. I wanted to assign the suitability index value in the
>temperature data (temp) based on Table 2 (or graph, which is a suitability
>curve), but I could not figure it out.
>Are there any suggestions for me how I can assign the suitability index
>value in table1 (temp) based on the suitability graph? I have a very big
>data set but showing only a few data to illustrate the problem.
>
>temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
>
>1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
>
>1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
>
>1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
>
>415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
>
>415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
>
>415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
>
>15.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
>
>15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
>
>16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
>
>)), class = "data.frame", row.names = c(NA, -19L))
>
>
>print(temp)
>
>
>table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,
>
>0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA,
>
>-6L))
>
>print(table2)
>
>
>ggplot(data=table2, aes(x=temp, y=Index)) +
>
>  geom_path()+
>
>  geom_point()
>
>
>
># now I would like to assign the index value of table 2 into table 1
>(temp), and I was looking for the following table as an output. The index
>value in the output I put manually.
>
>
>Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
> 1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
>
>1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
>
>1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
>
>415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
>
>415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
>
>415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
>
>0.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
>
>15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
>
>16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
>
>), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,
>
>0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class = "data.frame", row.names
>= c(NA,
>
>-19L))
>
>
>print(Output)
>
>
>Thank you very much for your help.
>
>MW
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Wed Aug 11 08:30:51 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Tue, 10 Aug 2021 23:30:51 -0700
Subject: [R] assigning suitability index value
In-Reply-To: <79717F5E-7972-418A-9727-FF9874CE91EE@dcn.davis.ca.us>
References: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>
 <79717F5E-7972-418A-9727-FF9874CE91EE@dcn.davis.ca.us>
Message-ID: <CAMwU6B13V5ZH1xW7GKKe4VxDgzDOcEfnvXrC3J17EE9fCME6kA@mail.gmail.com>

Thank you Jeff. I think the code you wrote works. The value I put in the
output was just guessing by looking at the graph.
Thank you once again Jeff.

temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27, 415096.27,
415096.27, 415096.27, 415093.27, 415093.27, 415093.27, 415093.27, 415093.27,
415093.27, 415093.27, 415090.27, 415090.27, 415090.27, 415090.27, 415090.27,
415090.27, 415090.27), temp = c(1.959473, 15.092773, 15.128174, 14.368896,
9.892578, 15.720215, 15.767822, 15.26001, 14.642334, 14.6521, 13.916016,
10.3479, 16.052246, 16.094971, 15.167236, 15.455322, 15.472412, 24.741211,
14.755859)), class = "data.frame", row.names = c(NA, -19L))


print(temp)


table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,
 0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA, -6L))

print(table2)


ggplot(data=table2, aes(x=temp, y=Index)) +geom_path()+geom_point()



Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27, 415096.27,
415096.27, 415096.27, 415093.27, 415093.27, 415093.27, 415093.27, 415093.27,
415093.27, 415093.27, 415090.27, 415090.27, 415090.27, 415090.27, 415090.27,
415090.27, 415090.27), temp = c(1.959473, 0.092773, 15.128174, 14.368896,
9.892578, 15.720215, 15.767822, 15.26001, 14.642334, 14.6521, 13.916016,
10.3479, 16.052246, 16.094971, 15.167236, 15.455322, 15.472412, 24.741211,
14.755859), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,
0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class="data.frame", row.names =
c(NA, -19L))


print(Output)

On Tue, Aug 10, 2021 at 11:16 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Piecewise linear interpolation is implemented in the ?approx function. It
> does not agree exactly with your Output, I don't know if there is something
> else you are accounting for it if your Output is in error.
>
> temp$index <- approx( table2$temp, table2$Index, temp$temp )$y
>
> BTW your code was usable but messed up... please set your email program to
> send plain text email so your formatting does not mess with your code.
>
>
> On August 10, 2021 10:30:57 PM PDT, Marna Wagley <marna.wagley at gmail.com>
> wrote:
> >Hi R Users,
> >I have two tables, one is temperature data (temp) and another table is a
> >suitability index. I wanted to assign the suitability index value in the
> >temperature data (temp) based on Table 2 (or graph, which is a suitability
> >curve), but I could not figure it out.
> >Are there any suggestions for me how I can assign the suitability index
> >value in table1 (temp) based on the suitability graph? I have a very big
> >data set but showing only a few data to illustrate the problem.
> >
> >temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
> >
> >1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
> >
> >1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
> >
> >1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
> >
> >415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
> >
> >415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
> >
> >415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
> >
> >15.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
> >
> >15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
> >
> >16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
> >
> >)), class = "data.frame", row.names = c(NA, -19L))
> >
> >
> >print(temp)
> >
> >
> >table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,
> >
> >0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA,
> >
> >-6L))
> >
> >print(table2)
> >
> >
> >ggplot(data=table2, aes(x=temp, y=Index)) +
> >
> >  geom_path()+
> >
> >  geom_point()
> >
> >
> >
> ># now I would like to assign the index value of table 2 into table 1
> >(temp), and I was looking for the following table as an output. The index
> >value in the output I put manually.
> >
> >
> >Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96,
> 1468482.96,
> > 1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
> >
> >1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
> >
> >1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
> >
> >415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
> >
> >415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
> >
> >415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
> >
> >0.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
> >
> >15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
> >
> >16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
> >
> >), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,
> >
> >0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class = "data.frame",
> row.names
> >= c(NA,
> >
> >-19L))
> >
> >
> >print(Output)
> >
> >
> >Thank you very much for your help.
> >
> >MW
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From t|m@t@y|or @end|ng |rom h|ddene|eph@nt@@co@uk  Wed Aug 11 10:45:48 2021
From: t|m@t@y|or @end|ng |rom h|ddene|eph@nt@@co@uk (Tim Taylor)
Date: Wed, 11 Aug 2021 08:45:48 +0000
Subject: [R] Formula compared to call within model call
Message-ID: <LO2P265MB2605932206CC0D6418B8D1E5DDF89@LO2P265MB2605.GBRP265.PROD.OUTLOOK.COM>

Manipulating formulas within different models I notice the following:

m1 <- lm(formula = hp ~ cyl, data = mtcars)
m2 <- update(m1, formula. = hp ~ cyl)
all.equal(m1, m2)
#> [1] TRUE
identical(m1, m2)
#> [1] FALSE
waldo::compare(m1, m2)
#> `old$call[[2]]` is a call
#> `new$call[[2]]` is an S3 object of class <formula>, a call

I'm aware formulas are a form of call but what I'm unsure of is whether there is meaningful difference between the two versions of the models? Any clarification, even just on the relation between formulas and calls would be useful.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Wed Aug 11 11:21:01 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Wed, 11 Aug 2021 05:21:01 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <27668c28-708f-3674-3e58-f3228c0eccaa@me.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
 <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
 <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>
 <27668c28-708f-3674-3e58-f3228c0eccaa@me.com>
Message-ID: <CAE9stmecM6b0Sn1otqbWWMxDhKHZjO9ALBUYO8LrMHdVbCWOFA@mail.gmail.com>

Hi Marc:


Thank you for your help in this matter.


With thanks
Abou


On Tue, Aug 10, 2021, 9:28 AM Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> A search would suggest that there may not be an R function/package that
> provides power/sample size calculations for the specific scenarios that
> you are describing. There may be something that I am missing, and there
> is also other dedicated software such as PASS
> (https://www.ncss.com/software/pass/) which is not free, but provides a
> large library of possibly relevant functions and support.
>
> That being said, you can run Monte Carlo simulations in R to achieve the
> results you want, while providing yourself with options relative to
> study design, intended tests, and adjustments for multiple comparisons
> as apropos. Many prefer this approach, since it gives you specific
> control over this process.
>
> Taking the simple case, where you are going to run a 3 x 2 chi-square as
> your primary endpoint, and want to power for that, here is a possible
> function, with the same sample size in each group:
>
> ThreeGroups <- function(n, p1, p2, p3, R = 10000, power = 0.8) {
>
>    MCSim <- function(n, p1, p2, p3) {
>      ## Create a binary distribution for each group
>      G1 <- rbinom(n, 1, p1)
>      G2 <- rbinom(n, 1, p2)
>      G3 <- rbinom(n, 1, p3)
>
>      ## Create a 3 x 2 matrix containing the 3 group counts
>      MAT <- cbind(table(G1), table(G2), table(G3))
>
>      ## Perform a chi-square and just return the p value
>      chisq.test(MAT)$p.value
>    }
>
>    ## Replicate the above R times, and get
>    ## a distribution of p values
>    MC <- replicate(R, MCSim(n, p1, p2, p3))
>
>    ## Get the p value at the desired "power" quantile
>    quantile(MC, power)
> }
>
> Essentially, the above internal MCSim() function generates 3 random
> samples of size 'n' from the binomial distribution, at the 3 proportions
> desired. For each run, it will perform a chi-square test of the 3 x 2
> matrix of counts, returning the p value for each run. The main function
> will then return the p value at the quantile (power) within the
> generated distribution of p values.
>
> You can look at the help pages for the various functions that I use
> above, to get a sense for how they work.
>
> You increase the sample size ('n') until you get a p value returned <=
> 0.05, if that is your desired alpha level.
>
> You also want 'R', the number of replications within each run, to be
> large enough so that the returned p value quantile is relatively stable.
> Values for 'R', once you get "close to" the desired p value should be on
> the order of 1,000,000 or higher. Stay with lower values for 'R' until
> you get in the ballpark of your target, since larger values take much
> longer to run.
>
> Thus, using your example proportions of 0.25, 0.25, and 0.35:
>
> ## 250 per group, 750 total - Not enough
>  > ThreeGroups(250, 0.25, 0.25, 0.35, R = 10000)
>         80%
> 0.08884723
>
> ## 350 per group, 1050 total - Too high
>  > ThreeGroups(350, 0.25, 0.25, 0.35, R = 10000)
>        80%
> 0.0270829
>
> ## 300 per group, 900 total - Close!
>  > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
>         80%
> 0.04818842
>
>
> So, keep tweaking the sample size until you get a returned p value at
> your target alpha level, with a large enough 'R', so that you get
> consistent sample sizes for multiple runs.
>
> If I run 300 per group again, with 10,000 replicates:
>
>  > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
>         80%
> 0.05033933
>
> the returned p value is slightly higher. So, again, increase R to
> improve the stability of the returned p value and run it multiple times
> to be comfortable that the p value change is less than an acceptable
> threshold.
>
> Now, the tricky part is to decide if the 3 x 2 is your primary endpoint,
> and want to power only for that, or, if you also want to power for the
> other two-group comparisons, possibly having to account for p value
> adjustments for the multiple comparisons, resulting in the need to power
> for a lower alpha level for those tests. In that scenario, you would end
> up taking the largest sample size that you identify across the various
> hypotheses, recognizing that while you are powering for one hypothesis,
> you may be overpowering for others.
>
> That is something that you need to decide, and perhaps consider
> consulting with other local statistical expertise, as may be apropos, in
> the prospective study design, possibly influenced by other
> relevant/similar research in your domain.
>
> You can easily modify the above function for the two-group scenario as
> well, and I will leave that to you.
>
> Regards,
>
> Marc
>
>
> AbouEl-Makarim Aboueissa wrote on 8/10/21 6:34 AM:
> > Hi Marc:
> >
> > First, thank you very much for your help in this matter.
> >
> >
> > Will perform an initial omnibus test of all three groups (e.g. 3 x 2
> > chi-square), possibly followed by
> > all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3,
> > 2 versus 3),
> >
> > We can assume _either_ the desired sample size in each group is the same
> > _or_ proportional to the population size.
> >
> >   We can set p=0.25 and set p1=p2=p3=p so that the H0 is true.
> >
> > We can assume that the expected proportion of "Yes" values in each group
> > is 0.25
> >
> > For the alternative hypotheses, for example,  we can set  p1 = .25,
> > p2=.25, p3=.35
> >
> >
> > Again thank you very much in advance.
> >
> > abou
> >
> > ______________________
> >
> > *AbouEl-Makarim Aboueissa, PhD
> > *
> > *
> > *
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> > *Department of Mathematics and Statistics
> > *
> > *University of Southern Maine*
> >
> >
> >
> > On Mon, Aug 9, 2021 at 10:53 AM Marc Schwartz <marc_schwartz at me.com
> > <mailto:marc_schwartz at me.com>> wrote:
> >
> >     Hi,
> >
> >     You are going to need to provide more information than what you have
> >     below and I may be mis-interpreting what you have provided.
> >
> >     Presuming you are designing a prospective, three-group, randomized
> >     allocation study, there is typically an a priori specification of the
> >     ratios of the sample sizes for each group such as 1:1:1, indicating
> >     that
> >     the desired sample size in each group is the same.
> >
> >     You would also need to specify the expected proportions of "Yes"
> values
> >     in each group.
> >
> >     Further, you need to specify how you are going to compare the
> >     proportions in each group. Are you going to perform an initial
> omnibus
> >     test of all three groups (e.g. 3 x 2 chi-square), possibly followed
> by
> >     all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus
> 3, 2
> >     versus 3), or are you just going to compare 2 versus 1, and 3 versus
> 1,
> >     where 1 is a control group?
> >
> >     Depending upon your testing plan, you may also need to account for p
> >     value adjustments for multiple comparisons, in which case, you also
> >     need
> >     to specify what adjustment method you plan to use, to know what the
> >     target alpha level will be.
> >
> >     On the other hand, if you already have the data collected, thus have
> >     fixed sample sizes available per your wording below, simply go ahead
> >     and
> >     perform your planned analyses, as the notion of "power" is largely
> an a
> >     priori consideration, which reflects the probability of finding a
> >     "statistically significant" result at a given alpha level, given that
> >     your a priori assumptions are valid.
> >
> >     Regards,
> >
> >     Marc Schwartz
> >
> >
> >     AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
> >      > Dear All: good morning
> >      >
> >      > *Re:* Sample Size Determination to Compare Three Independent
> >     Proportions
> >      >
> >      > *Situation:*
> >      >
> >      > Three Binary variables (Yes, No)
> >      >
> >      > Three independent populations with fixed sizes (*say:* N1 = 1500,
> >     N2 = 900,
> >      > N3 = 1350).
> >      >
> >      > Power = 0.80
> >      >
> >      > How to choose the sample sizes to compare the three proportions
> >     of ?Yes?
> >      > among the three variables.
> >      >
> >      > If you know a reference to this topic, it will be very helpful
> too.
> >      >
> >      > with many thanks in advance
> >      >
> >      > abou
> >      > ______________________
> >      >
> >      >
> >      > *AbouEl-Makarim Aboueissa, PhD*
> >      >
> >      > *Professor, Statistics and Data Science*
> >      > *Graduate Coordinator*
> >      >
> >      > *Department of Mathematics and Statistics*
> >      > *University of Southern Maine*
> >      >
> >
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Aug 11 11:51:25 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 11 Aug 2021 11:51:25 +0200
Subject: [R] Formula compared to call within model call
In-Reply-To: <LO2P265MB2605932206CC0D6418B8D1E5DDF89@LO2P265MB2605.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB2605932206CC0D6418B8D1E5DDF89@LO2P265MB2605.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <24851.40349.481350.63082@stat.math.ethz.ch>

>>>>> Tim Taylor 
>>>>>     on Wed, 11 Aug 2021 08:45:48 +0000 writes:

    > Manipulating formulas within different models I notice the following:

    > m1 <- lm(formula = hp ~ cyl, data = mtcars)
    > m2 <- update(m1, formula. = hp ~ cyl)
    > all.equal(m1, m2)
    > #> [1] TRUE
    > identical(m1, m2)
    > #> [1] FALSE
    > waldo::compare(m1, m2)
    > #> `old$call[[2]]` is a call
    > #> `new$call[[2]]` is an S3 object of class <formula>, a call

    > I'm aware formulas are a form of call but what I'm unsure
    > of is whether there is meaningful difference between the
    > two versions of the models? 

A good question.
In principle, the promise of an update()  method should be to
produce the *same* result as calling the original model-creation
(or more generally object-creation) function call.

So, already with identical(), you've shown that this is not
quite the case for simple lm(),
and indeed that is a bit undesirable.

To answer your question re "meaningful" difference,
given what I say above is:
No, there shouldn't be any relevant difference, and if there is,
that may considered a bug in the respective update() method,
here update.lm.

More about this in the following  R code snippet :

## MM: indeed,
identical(m1$call, m2$call) #> [1] FALSE
noCall <- function(x) x[setdiff(names(x), "call")]
identical(noCall(m1), noCall(m2))# TRUE!
## look closer:
c1 <- m1$call
c2 <- m2$call
str(as.list(c1))
## List of 3
##  $        : symbol lm
##  $ formula: language hp ~ cyl
##  $ data   : symbol mtcars

str(as.list(c2))
## List of 3
##  $        : symbol lm
##  $ formula:Class 'formula'  language hp ~ cyl
##   .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
##  $ data   : symbol mtcars

identical(c1[-2], c2[-2]) # TRUE ==> so, indeed the difference is *only* in the formula ( = [2]) component
f1 <- c1$formula
f2 <- c2$formula
all.equal(f1,f2) # TRUE
identical(f1,f2) # FALSE
## Note that this is typically *not* visible if the user uses the accessor functions:
identical(formula(m1), formula(m2)) # TRUE !
## and indeed, the formula() method for 'lm'  does set the environment:
stats:::formula.lm


--
Martin Maechler
ETH Zurich   and  R Core


From d|cook@rj @end|ng |rom gm@||@com  Wed Aug 11 09:29:32 2021
From: d|cook@rj @end|ng |rom gm@||@com (Dianne Cook)
Date: Wed, 11 Aug 2021 17:29:32 +1000
Subject: [R] Volume 13/1, June 2021 now available
Message-ID: <35571119-0C8A-43B1-A7BB-AB9E2630542B@gmail.com>

Dear R Community,

The first issue of the R Journal for 2021 is now available at https://journal.r-project.org/. 

There is also a dev version of rending articles in html at https://journal.r-project.org/dev/. Particularly look at articles by Earo Wang for embedded interactive graphics, and by Mike Kane for html rendering. Feedback and suggestions are welcome.

Happy reading, and coding!

Regards,
Di

%>%>%>%>%
Professor Dianne Cook
Editor-in-Chief, R Journal
dicook.rj at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From e@hoo@hm@nd96 @end|ng |rom gm@||@com  Wed Aug 11 09:34:37 2021
From: e@hoo@hm@nd96 @end|ng |rom gm@||@com (Elham Hooshmand)
Date: Wed, 11 Aug 2021 12:04:37 +0430
Subject: [R] collided row names in heatmap.2
Message-ID: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>

Hi,

I am trying to draw a heatmap for my 45 topvar gene by the use of
heatmap.2, and when I set a srtRow=45 in my code(below):

heatmap.2( assay(rld)[ topVarGenes, ], srtRow=45, scale="row",trace="none",
dendrogram="column",col = colorRampPalette( rev(brewer.pal(9, "RdBu"))
)(255))

row names collided with each other in a messy way.

would you please help me to solve this problem? (also I'm a newbie beginner
using R Studio) Thank you so much
(also I attached the output image)

From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 11 19:19:20 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 11 Aug 2021 10:19:20 -0700
Subject: [R] collided row names in heatmap.2
In-Reply-To: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
References: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
Message-ID: <CAGxFJbR2kkP+DYribHWgwHBd6ygCUmKNwneB3T6n5_tekD97NA@mail.gmail.com>

1. This is R-help. RStudio is a separate IDE from a private for-profit
company. You should go to their website for help with that:
https://www.rstudio.com/support/

2. I may be wrong, of course, but I believe your information is too
vague for folks to provide useful help: "row names collided with each
other in a messy way,' does not tell us much. What error message did
you get? Please provide a small, reproducible example (perhaps
via head(yourdatset, ...) see e.g. ?head and ?dput and
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
. You may also wish to download and use the "reprex" package for this
purpose, instead. **See also the posting guide linked below.**

All of us were newbies at one time; take the time to learn these tools
and follow the advice for posting to R-help, and I believe that you
will have much greater success in getting useful help here as you
climb the learning curve.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 11, 2021 at 9:07 AM Elham Hooshmand <e.hooshmand96 at gmail.com> wrote:
>
> Hi,
>
> I am trying to draw a heatmap for my 45 topvar gene by the use of
> heatmap.2, and when I set a srtRow=45 in my code(below):
>
> heatmap.2( assay(rld)[ topVarGenes, ], srtRow=45, scale="row",trace="none",
> dendrogram="column",col = colorRampPalette( rev(brewer.pal(9, "RdBu"))
> )(255))
>
> row names collided with each other in a messy way.
>
> would you please help me to solve this problem? (also I'm a newbie beginner
> using R Studio) Thank you so much
> (also I attached the output image)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 11 23:47:27 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Aug 2021 07:47:27 +1000
Subject: [R] collided row names in heatmap.2
In-Reply-To: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
References: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
Message-ID: <CA+8X3fUEe9726xbE0hCO0-TJXxPo8BH7UYZgt1zo7PMqNoc1DQ@mail.gmail.com>

Hi Elham,
Your image didn't get through, maybe PNG will work. Label crowding is
a common problem, whether horizontal or vertical. One solution is to
set a maximum length on label text (see truncString in the prettyR
package). Others are to stagger labels (staxlab in plotrix) or shift
them apart when crowded (spread.labels in plotrix). These functions
may not work with heatmap.2 (gplots). It will be easier to suggest
something if you can get your image through.

Jim

On Thu, Aug 12, 2021 at 2:07 AM Elham Hooshmand <e.hooshmand96 at gmail.com> wrote:
>
> Hi,
>
> I am trying to draw a heatmap for my 45 topvar gene by the use of
> heatmap.2, and when I set a srtRow=45 in my code(below):
>
> heatmap.2( assay(rld)[ topVarGenes, ], srtRow=45, scale="row",trace="none",
> dendrogram="column",col = colorRampPalette( rev(brewer.pal(9, "RdBu"))
> )(255))
>
> row names collided with each other in a messy way.
>
> would you please help me to solve this problem? (also I'm a newbie beginner
> using R Studio) Thank you so much
> (also I attached the output image)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug 12 14:37:32 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 12 Aug 2021 14:37:32 +0200
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
Message-ID: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>

Helo
I have a dataframe whose names are similar and I would like to change
the rows containing given values simultaneously.
I can select the columns using library(dplyr) but I can't modify the data:
```
library(dplyr)
> df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
+                 var2 = c(LETTERS[1:7]),
+                 var3 = c(letters[1:3], letters[1:4]),
+                 var4 = (1:7)^2,
+                 var5 = c("light", "light", "heavy", "heavy", "heavy",
+                          "light", "heavy"),
+                 stringsAsFactors = FALSE); df
  var1 var2 var3 var4  var5
1    a    A    a    1 light
2    b    B    b    4 light
3    c    C    c    9 heavy
4    a    D    a   16 heavy
5    b    E    b   25 heavy
6    c    F    c   36 light
7    d    G    d   49 heavy
> select(df, matches("var[123]"))
  var1 var2 var3
1    a    A    a
2    b    B    b
3    c    C    c
4    a    D    a
5    b    E    b
6    c    F    c
7    d    G    d
> df[[select(df, matches("var[123]")) == "a"]] <- "z"
Error in `[[<-`(`*tmp*`, i, value = value) :
  recursive indexing failed at level 2
> df[[select(df, contains("var1")) == "a"]] <- "z"
Error in `[[<-`(`*tmp*`, i, value = value) :
  recursive indexing failed at level 2
```
If I sue which, I get a wrong substitution :
```
> df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
   var1 var2 var3 var4  var5
1     z    z    z    z     z
2     b    B    b    4 light
3     c    C    c    9 heavy
4     z    z    z    z     z
5     b    E    b   25 heavy
6     c    F    c   36 light
7     d    G    d   49 heavy
8  <NA> <NA> <NA> <NA>  <NA>
9  <NA> <NA> <NA> <NA>  <NA>
10 <NA> <NA> <NA> <NA>  <NA>
11 <NA> <NA> <NA> <NA>  <NA>
12 <NA> <NA> <NA> <NA>  <NA>
13 <NA> <NA> <NA> <NA>  <NA>
14 <NA> <NA> <NA> <NA>  <NA>
15    z    z    z    z     z
16 <NA> <NA> <NA> <NA>  <NA>
17 <NA> <NA> <NA> <NA>  <NA>
18    z    z    z    z     z
```

what is the correct syntax?
Thank you

-- 
Best regards,
Luigi


From er|cjberger @end|ng |rom gm@||@com  Thu Aug 12 16:46:54 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 12 Aug 2021 17:46:54 +0300
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
Message-ID: <CAGgJW74wFo-Q1MBAGDYreApHQ7Kpc1RQVkJw9opHz_B7cKrGRg@mail.gmail.com>

Hi Luigi,
I would take a slightly different approach. Maybe this is helpful.

idV <- grep("var[123]",colnames(df))
df[,idV][df[,idV]=="a"] <- "z"

df
  var1 var2 var3 var4  var5
1    z    A    z    1 light
2    b    B    b    4 light
3    c    C    c    9 heavy
4    z    D    z   16 heavy
5    b    E    b   25 heavy
6    c    F    c   36 light
7    d    G    d   49 heavy

HTH,
Eric


On Thu, Aug 12, 2021 at 3:38 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Helo
> I have a dataframe whose names are similar and I would like to change
> the rows containing given values simultaneously.
> I can select the columns using library(dplyr) but I can't modify the data:
> ```
> library(dplyr)
> > df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> +                 var2 = c(LETTERS[1:7]),
> +                 var3 = c(letters[1:3], letters[1:4]),
> +                 var4 = (1:7)^2,
> +                 var5 = c("light", "light", "heavy", "heavy", "heavy",
> +                          "light", "heavy"),
> +                 stringsAsFactors = FALSE); df
>   var1 var2 var3 var4  var5
> 1    a    A    a    1 light
> 2    b    B    b    4 light
> 3    c    C    c    9 heavy
> 4    a    D    a   16 heavy
> 5    b    E    b   25 heavy
> 6    c    F    c   36 light
> 7    d    G    d   49 heavy
> > select(df, matches("var[123]"))
>   var1 var2 var3
> 1    a    A    a
> 2    b    B    b
> 3    c    C    c
> 4    a    D    a
> 5    b    E    b
> 6    c    F    c
> 7    d    G    d
> > df[[select(df, matches("var[123]")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> > df[[select(df, contains("var1")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> ```
> If I sue which, I get a wrong substitution :
> ```
> > df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
>    var1 var2 var3 var4  var5
> 1     z    z    z    z     z
> 2     b    B    b    4 light
> 3     c    C    c    9 heavy
> 4     z    z    z    z     z
> 5     b    E    b   25 heavy
> 6     c    F    c   36 light
> 7     d    G    d   49 heavy
> 8  <NA> <NA> <NA> <NA>  <NA>
> 9  <NA> <NA> <NA> <NA>  <NA>
> 10 <NA> <NA> <NA> <NA>  <NA>
> 11 <NA> <NA> <NA> <NA>  <NA>
> 12 <NA> <NA> <NA> <NA>  <NA>
> 13 <NA> <NA> <NA> <NA>  <NA>
> 14 <NA> <NA> <NA> <NA>  <NA>
> 15    z    z    z    z     z
> 16 <NA> <NA> <NA> <NA>  <NA>
> 17 <NA> <NA> <NA> <NA>  <NA>
> 18    z    z    z    z     z
> ```
>
> what is the correct syntax?
> Thank you
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From k|mmo@e|o @end|ng |rom utu@||  Thu Aug 12 15:17:25 2021
From: k|mmo@e|o @end|ng |rom utu@|| (Kimmo Elo)
Date: Thu, 12 Aug 2021 13:17:25 +0000
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
Message-ID: <44dc842b3afe5faccc0f2074a717fb811cca66af.camel@utu.fi>

Hi,

something like this (a customised version based on this: 
https://stackoverflow.com/questions/25768305/r-replace-multiple-values-in-multiple-columns-of-dataframes-with-na
):

--- snip ---

col_idx<-grep("^var[123]", names(df))
m1<-as.matrix(df[,col_idx])
m1[m1=="a"]<-"z"
df[col_idx]<-m1
df

--- snip ---

HTH,

Kimmo

to, 2021-08-12 kello 14:37 +0200, Luigi Marongiu kirjoitti:
> Helo
> I have a dataframe whose names are similar and I would like to change
> the rows containing given values simultaneously.
> I can select the columns using library(dplyr) but I can't modify the
> data:
> ```
> library(dplyr)
> > df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> +                 var2 = c(LETTERS[1:7]),
> +                 var3 = c(letters[1:3], letters[1:4]),
> +                 var4 = (1:7)^2,
> +                 var5 = c("light", "light", "heavy", "heavy",
> "heavy",
> +                          "light", "heavy"),
> +                 stringsAsFactors = FALSE); df
>   var1 var2 var3 var4  var5
> 1    a    A    a    1 light
> 2    b    B    b    4 light
> 3    c    C    c    9 heavy
> 4    a    D    a   16 heavy
> 5    b    E    b   25 heavy
> 6    c    F    c   36 light
> 7    d    G    d   49 heavy
> > select(df, matches("var[123]"))
>   var1 var2 var3
> 1    a    A    a
> 2    b    B    b
> 3    c    C    c
> 4    a    D    a
> 5    b    E    b
> 6    c    F    c
> 7    d    G    d
> > df[[select(df, matches("var[123]")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> > df[[select(df, contains("var1")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> ```
> If I sue which, I get a wrong substitution :
> ```
> > df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
>    var1 var2 var3 var4  var5
> 1     z    z    z    z     z
> 2     b    B    b    4 light
> 3     c    C    c    9 heavy
> 4     z    z    z    z     z
> 5     b    E    b   25 heavy
> 6     c    F    c   36 light
> 7     d    G    d   49 heavy
> 8  <NA> <NA> <NA> <NA>  <NA>
> 9  <NA> <NA> <NA> <NA>  <NA>
> 10 <NA> <NA> <NA> <NA>  <NA>
> 11 <NA> <NA> <NA> <NA>  <NA>
> 12 <NA> <NA> <NA> <NA>  <NA>
> 13 <NA> <NA> <NA> <NA>  <NA>
> 14 <NA> <NA> <NA> <NA>  <NA>
> 15    z    z    z    z     z
> 16 <NA> <NA> <NA> <NA>  <NA>
> 17 <NA> <NA> <NA> <NA>  <NA>
> 18    z    z    z    z     z
> ```
> 
> what is the correct syntax?
> Thank you
> 

From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Aug 12 17:38:42 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 12 Aug 2021 15:38:42 +0000 (UTC)
Subject: [R] ggplot: add percentage for each element in legend and remove
 tick mark
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
Message-ID: <774219336.1144213.1628782722523@mail.yahoo.com>

Hello List,
I use the following code to generate a donut plot.
# Compute percentages
eth$fraction = eth$individuals / sum(eth$individuals)
# Compute the cumulative percentages (top of each rectangle)
eth$ymax = cumsum(eth$fraction)
# Compute the bottom of each rectangle
eth$ymin = c(0, head(eth$ymax, n=-1))
# Make the plot using percentage
ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
? geom_rect() +
? coord_polar(theta="y")? +
? xlim(c(2, 4)?
? )?

I want to improve the plot for two thing:?
1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
2. remove all number (tick mark ?) around the plot
Please help
Thank you,
Kai

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 12 18:59:10 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 12 Aug 2021 17:59:10 +0100
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
Message-ID: <44f605e2-ef51-d25a-24d8-fe5c23e656b7@sapo.pt>

Hello,

And another way, with which(., arr.ind = TRUE).
In two steps, to make it clearer.


i <- which(df[grep("var[123]", names(df))] == "a", arr.ind = TRUE)
df[i] <- "z"

df
#  var1 var2 var3 var4  var5
#1    z    A    z    1 light
#2    b    B    b    4 light
#3    c    C    c    9 heavy
#4    z    D    z   16 heavy
#5    b    E    b   25 heavy
#6    c    F    c   36 light
#7    d    G    d   49 heavy


Hope this helps,

Rui Barradas


?s 13:37 de 12/08/21, Luigi Marongiu escreveu:
> Helo
> I have a dataframe whose names are similar and I would like to change
> the rows containing given values simultaneously.
> I can select the columns using library(dplyr) but I can't modify the data:
> ```
> library(dplyr)
>> df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> +                 var2 = c(LETTERS[1:7]),
> +                 var3 = c(letters[1:3], letters[1:4]),
> +                 var4 = (1:7)^2,
> +                 var5 = c("light", "light", "heavy", "heavy", "heavy",
> +                          "light", "heavy"),
> +                 stringsAsFactors = FALSE); df
>    var1 var2 var3 var4  var5
> 1    a    A    a    1 light
> 2    b    B    b    4 light
> 3    c    C    c    9 heavy
> 4    a    D    a   16 heavy
> 5    b    E    b   25 heavy
> 6    c    F    c   36 light
> 7    d    G    d   49 heavy
>> select(df, matches("var[123]"))
>    var1 var2 var3
> 1    a    A    a
> 2    b    B    b
> 3    c    C    c
> 4    a    D    a
> 5    b    E    b
> 6    c    F    c
> 7    d    G    d
>> df[[select(df, matches("var[123]")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>    recursive indexing failed at level 2
>> df[[select(df, contains("var1")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>    recursive indexing failed at level 2
> ```
> If I sue which, I get a wrong substitution :
> ```
>> df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
>     var1 var2 var3 var4  var5
> 1     z    z    z    z     z
> 2     b    B    b    4 light
> 3     c    C    c    9 heavy
> 4     z    z    z    z     z
> 5     b    E    b   25 heavy
> 6     c    F    c   36 light
> 7     d    G    d   49 heavy
> 8  <NA> <NA> <NA> <NA>  <NA>
> 9  <NA> <NA> <NA> <NA>  <NA>
> 10 <NA> <NA> <NA> <NA>  <NA>
> 11 <NA> <NA> <NA> <NA>  <NA>
> 12 <NA> <NA> <NA> <NA>  <NA>
> 13 <NA> <NA> <NA> <NA>  <NA>
> 14 <NA> <NA> <NA> <NA>  <NA>
> 15    z    z    z    z     z
> 16 <NA> <NA> <NA> <NA>  <NA>
> 17 <NA> <NA> <NA> <NA>  <NA>
> 18    z    z    z    z     z
> ```
> 
> what is the correct syntax?
> Thank you
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug 13 15:09:01 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 13 Aug 2021 15:09:01 +0200
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <44f605e2-ef51-d25a-24d8-fe5c23e656b7@sapo.pt>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
 <44f605e2-ef51-d25a-24d8-fe5c23e656b7@sapo.pt>
Message-ID: <CAMk+s2TRfiC76AZ2yhOp-73_v9Wr42851qNBrphGZe_5mtW6OQ@mail.gmail.com>

Thank you! both hacks worked as needed!

On Thu, Aug 12, 2021 at 6:59 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> And another way, with which(., arr.ind = TRUE).
> In two steps, to make it clearer.
>
>
> i <- which(df[grep("var[123]", names(df))] == "a", arr.ind = TRUE)
> df[i] <- "z"
>
> df
> #  var1 var2 var3 var4  var5
> #1    z    A    z    1 light
> #2    b    B    b    4 light
> #3    c    C    c    9 heavy
> #4    z    D    z   16 heavy
> #5    b    E    b   25 heavy
> #6    c    F    c   36 light
> #7    d    G    d   49 heavy
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 13:37 de 12/08/21, Luigi Marongiu escreveu:
> > Helo
> > I have a dataframe whose names are similar and I would like to change
> > the rows containing given values simultaneously.
> > I can select the columns using library(dplyr) but I can't modify the data:
> > ```
> > library(dplyr)
> >> df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> > +                 var2 = c(LETTERS[1:7]),
> > +                 var3 = c(letters[1:3], letters[1:4]),
> > +                 var4 = (1:7)^2,
> > +                 var5 = c("light", "light", "heavy", "heavy", "heavy",
> > +                          "light", "heavy"),
> > +                 stringsAsFactors = FALSE); df
> >    var1 var2 var3 var4  var5
> > 1    a    A    a    1 light
> > 2    b    B    b    4 light
> > 3    c    C    c    9 heavy
> > 4    a    D    a   16 heavy
> > 5    b    E    b   25 heavy
> > 6    c    F    c   36 light
> > 7    d    G    d   49 heavy
> >> select(df, matches("var[123]"))
> >    var1 var2 var3
> > 1    a    A    a
> > 2    b    B    b
> > 3    c    C    c
> > 4    a    D    a
> > 5    b    E    b
> > 6    c    F    c
> > 7    d    G    d
> >> df[[select(df, matches("var[123]")) == "a"]] <- "z"
> > Error in `[[<-`(`*tmp*`, i, value = value) :
> >    recursive indexing failed at level 2
> >> df[[select(df, contains("var1")) == "a"]] <- "z"
> > Error in `[[<-`(`*tmp*`, i, value = value) :
> >    recursive indexing failed at level 2
> > ```
> > If I sue which, I get a wrong substitution :
> > ```
> >> df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
> >     var1 var2 var3 var4  var5
> > 1     z    z    z    z     z
> > 2     b    B    b    4 light
> > 3     c    C    c    9 heavy
> > 4     z    z    z    z     z
> > 5     b    E    b   25 heavy
> > 6     c    F    c   36 light
> > 7     d    G    d   49 heavy
> > 8  <NA> <NA> <NA> <NA>  <NA>
> > 9  <NA> <NA> <NA> <NA>  <NA>
> > 10 <NA> <NA> <NA> <NA>  <NA>
> > 11 <NA> <NA> <NA> <NA>  <NA>
> > 12 <NA> <NA> <NA> <NA>  <NA>
> > 13 <NA> <NA> <NA> <NA>  <NA>
> > 14 <NA> <NA> <NA> <NA>  <NA>
> > 15    z    z    z    z     z
> > 16 <NA> <NA> <NA> <NA>  <NA>
> > 17 <NA> <NA> <NA> <NA>  <NA>
> > 18    z    z    z    z     z
> > ```
> >
> > what is the correct syntax?
> > Thank you
> >



-- 
Best regards,
Luigi


From jrkr|de@u @end|ng |rom gm@||@com  Fri Aug 13 15:21:17 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 13 Aug 2021 09:21:17 -0400
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <774219336.1144213.1628782722523@mail.yahoo.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
Message-ID: <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>

Would you supply some sample data please? A handy way to supply sample
data is to use the dput() function. See ?dput.  If you have a very
large data set then something like head(dput(myfile), 100) will likely
supply enough data for us to work with.

On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> I use the following code to generate a donut plot.
> # Compute percentages
> eth$fraction = eth$individuals / sum(eth$individuals)
> # Compute the cumulative percentages (top of each rectangle)
> eth$ymax = cumsum(eth$fraction)
> # Compute the bottom of each rectangle
> eth$ymin = c(0, head(eth$ymax, n=-1))
> # Make the plot using percentage
> ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
>   geom_rect() +
>   coord_polar(theta="y")  +
>   xlim(c(2, 4)
>   )
>
> I want to improve the plot for two thing:
> 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> 2. remove all number (tick mark ?) around the plot
> Please help
> Thank you,
> Kai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From y@ngk@|9999 @end|ng |rom y@hoo@com  Fri Aug 13 23:48:15 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 13 Aug 2021 21:48:15 +0000 (UTC)
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
Message-ID: <227125051.247175.1628891295722@mail.yahoo.com>

 Hello John,
I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
Thanks,
Kai

| 
ethnicity | 
individuals |
| Caucasian | 36062 |
| Ashkenazi Jewish | 4309 |
| Multiple | 3193 |
| Hispanic | 2113 |
| Asian. not specified | 1538 |
| Chinese | 1031 |
| African | 643 |
| Unknown | 510 |
| Filipino | 222 |
| Japanese | 129 |
| Native American | 116 |
| Indian | 111 |
| Pacific Islander | 23 |



    On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:  
 
 Would you supply some sample data please? A handy way to supply sample
data is to use the dput() function. See ?dput.? If you have a very
large data set then something like head(dput(myfile), 100) will likely
supply enough data for us to work with.

On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> I use the following code to generate a donut plot.
> # Compute percentages
> eth$fraction = eth$individuals / sum(eth$individuals)
> # Compute the cumulative percentages (top of each rectangle)
> eth$ymax = cumsum(eth$fraction)
> # Compute the bottom of each rectangle
> eth$ymin = c(0, head(eth$ymax, n=-1))
> # Make the plot using percentage
> ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
>? geom_rect() +
>? coord_polar(theta="y")? +
>? xlim(c(2, 4)
>? )
>
> I want to improve the plot for two thing:
> 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> 2. remove all number (tick mark ?) around the plot
> Please help
> Thank you,
> Kai
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada
  
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug 14 00:02:13 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 13 Aug 2021 15:02:13 -0700
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <227125051.247175.1628891295722@mail.yahoo.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
 <227125051.247175.1628891295722@mail.yahoo.com>
Message-ID: <CAGxFJbR-uWkjeNkNjGUyGEJ5AOMTEAGWSEZ_n9DQHGMYSgv6=Q@mail.gmail.com>

It's dput()  *not* dupt() .  ?dput tells you how to use it (as usual).

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 13, 2021 at 2:48 PM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
>  Hello John,
> I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
> Thanks,
> Kai
>
> |
> ethnicity |
> individuals |
> | Caucasian | 36062 |
> | Ashkenazi Jewish | 4309 |
> | Multiple | 3193 |
> | Hispanic | 2113 |
> | Asian. not specified | 1538 |
> | Chinese | 1031 |
> | African | 643 |
> | Unknown | 510 |
> | Filipino | 222 |
> | Japanese | 129 |
> | Native American | 116 |
> | Indian | 111 |
> | Pacific Islander | 23 |
>
>
>
>     On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:
>
>  Would you supply some sample data please? A handy way to supply sample
> data is to use the dput() function. See ?dput.  If you have a very
> large data set then something like head(dput(myfile), 100) will likely
> supply enough data for us to work with.
>
> On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
> >
> > Hello List,
> > I use the following code to generate a donut plot.
> > # Compute percentages
> > eth$fraction = eth$individuals / sum(eth$individuals)
> > # Compute the cumulative percentages (top of each rectangle)
> > eth$ymax = cumsum(eth$fraction)
> > # Compute the bottom of each rectangle
> > eth$ymin = c(0, head(eth$ymax, n=-1))
> > # Make the plot using percentage
> > ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
> >  geom_rect() +
> >  coord_polar(theta="y")  +
> >  xlim(c(2, 4)
> >  )
> >
> > I want to improve the plot for two thing:
> > 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> > 2. remove all number (tick mark ?) around the plot
> > Please help
> > Thank you,
> > Kai
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Sat Aug 14 01:35:06 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 13 Aug 2021 23:35:06 +0000 (UTC)
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <CAGxFJbR-uWkjeNkNjGUyGEJ5AOMTEAGWSEZ_n9DQHGMYSgv6=Q@mail.gmail.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
 <227125051.247175.1628891295722@mail.yahoo.com>
 <CAGxFJbR-uWkjeNkNjGUyGEJ5AOMTEAGWSEZ_n9DQHGMYSgv6=Q@mail.gmail.com>
Message-ID: <2107813080.268761.1628897706580@mail.yahoo.com>

 Got it.Thank you.
    On Friday, August 13, 2021, 03:03:26 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 It's dput()? *not* dupt() .? ?dput tells you how to use it (as usual).

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 13, 2021 at 2:48 PM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
>? Hello John,
> I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
> Thanks,
> Kai
>
> |
> ethnicity |
> individuals |
> | Caucasian | 36062 |
> | Ashkenazi Jewish | 4309 |
> | Multiple | 3193 |
> | Hispanic | 2113 |
> | Asian. not specified | 1538 |
> | Chinese | 1031 |
> | African | 643 |
> | Unknown | 510 |
> | Filipino | 222 |
> | Japanese | 129 |
> | Native American | 116 |
> | Indian | 111 |
> | Pacific Islander | 23 |
>
>
>
>? ? On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:
>
>? Would you supply some sample data please? A handy way to supply sample
> data is to use the dput() function. See ?dput.? If you have a very
> large data set then something like head(dput(myfile), 100) will likely
> supply enough data for us to work with.
>
> On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
> >
> > Hello List,
> > I use the following code to generate a donut plot.
> > # Compute percentages
> > eth$fraction = eth$individuals / sum(eth$individuals)
> > # Compute the cumulative percentages (top of each rectangle)
> > eth$ymax = cumsum(eth$fraction)
> > # Compute the bottom of each rectangle
> > eth$ymin = c(0, head(eth$ymax, n=-1))
> > # Make the plot using percentage
> > ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
> >? geom_rect() +
> >? coord_polar(theta="y")? +
> >? xlim(c(2, 4)
> >? )
> >
> > I want to improve the plot for two thing:
> > 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> > 2. remove all number (tick mark ?) around the plot
> > Please help
> > Thank you,
> > Kai
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Aug 14 03:29:15 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 13 Aug 2021 21:29:15 -0400
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <227125051.247175.1628891295722@mail.yahoo.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
 <227125051.247175.1628891295722@mail.yahoo.com>
Message-ID: <02ed01d790ab$cb4a4ad0$61dee070$@verizon.net>

Kai,

It is easier to want to help someone if they generally know what they are doing and are stuck on something. Less so when they do not know enough to explain to us what they want, show what they did, and so on.

I modified the data you showed and hopefully it can be recreated this way:

library(tidyverse)

df <- tribble(
  ~ethnicity, ~individuals,
  "Caucasian", 36062,
  "Ashkenazi Jewish", 4309,
  "Multiple", 3193,
  "Hispanic", 2113,
  "Asian. not specified", 1538,
  "Chinese", 1031,
  "African", 643,
  "Unknown", 510,
  "Filipino", 222,
  "Japanese", 129,
  "Native American", 116,
  "Indian", 111,
  "Pacific Islander", 23)

If it was not clear, assuming you already had your data in some variable with a name, like my df, you could do this:

> dput(df)
structure(list(
  ethnicity = c(
    "Caucasian",
    "Ashkenazi Jewish",
    "Multiple",
    "Hispanic",
    "Asian. not specified",
    "Chinese",
    "African",
    "Unknown",
    "Filipino",
    "Japanese",
    "Native American",
    "Indian",
    "Pacific Islander"
  ),
  individuals = c(36062, 4309, 3193, 2113,
                  1538, 1031, 643, 510, 222, 129, 116, 111, 23)
), row.names = c(NA,
                 -13L), class = c("tbl_df", "tbl", "data.frame"))   

The above structure can be used to recreate the data somewhat portably including a cut and paste like this:

Restoring <- the.above.put.here

The question you ask may better be answered by CHANGING what is in df before calling ggplot.

Be that as it may, with lotf of work on your badly formatted code as shown in plain text, I have this:

> eth
# A tibble: 13 x 5
ethnicity            individuals fraction  ymax  ymin
<chr>                      <dbl>    <dbl> <dbl> <dbl>
  1 Caucasian                  36062  0.721   0.721 0    
2 Ashkenazi Jewish            4309  0.0862  0.807 0.721
3 Multiple                    3193  0.0639  0.871 0.807
4 Hispanic                    2113  0.0423  0.914 0.871
5 Asian. not specified        1538  0.0308  0.944 0.914
6 Chinese                     1031  0.0206  0.965 0.944
7 African                      643  0.0129  0.978 0.965
8 Unknown                      510  0.0102  0.988 0.978
9 Filipino                     222  0.00444 0.992 0.988
10 Japanese                     129  0.00258 0.995 0.992
11 Native American              116  0.00232 0.997 0.995
12 Indian                       111  0.00222 1.00  0.997
13 Pacific Islander              23  0.00046 1     1.00

I used your ggplot code, reformatted so people can read and run it as:

ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
  geom_rect() +
  coord_polar(theta="y")  +
  xlim(c(2, 4))

It shows  donut plot I am not sure I can easily share here. You want to change the legend by adding more. Sure, tons of ways to do that BUT not sure what you actually want. 

ONE WAY to do what you want is to make a new column like this:

> eth$label <- paste(eth$ethnicity, " ", eth$fraction*100, "%", sep="")
> eth
# A tibble: 13 x 6
ethnicity            individuals fraction  ymax  ymin label                      
<chr>                      <dbl>    <dbl> <dbl> <dbl> <chr>                      
  1 Caucasian                  36062  0.721   0.721 0     Caucasian 72.124%          
2 Ashkenazi Jewish            4309  0.0862  0.807 0.721 Ashkenazi Jewish 8.618%    
3 Multiple                    3193  0.0639  0.871 0.807 Multiple 6.386%            
4 Hispanic                    2113  0.0423  0.914 0.871 Hispanic 4.226%            
5 Asian. not specified        1538  0.0308  0.944 0.914 Asian. not specified 3.076%
6 Chinese                     1031  0.0206  0.965 0.944 Chinese 2.062%             
7 African                      643  0.0129  0.978 0.965 African 1.286%             
8 Unknown                      510  0.0102  0.988 0.978 Unknown 1.02%              
9 Filipino                     222  0.00444 0.992 0.988 Filipino 0.444%            
10 Japanese                     129  0.00258 0.995 0.992 Japanese 0.258%            
11 Native American              116  0.00232 0.997 0.995 Native American 0.232%     
12 Indian                       111  0.00222 1.00  0.997 Indian 0.222%              
13 Pacific Islander              23  0.00046 1     1.00  Pacific Islander 0.046%

Now once you make the labels look like the exact way you want, you need to ask ggplot to substitute your labels, and make sure they line up right. It may be tricky and may require making factors properly. You may also want to round the percentages to all be the same. You can also use scale_fill_discrete to change other things like replace "ethnicity" with another phrase and so on.

Here is the additional part of ggplot that makes the change:

ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
  geom_rect() +
  coord_polar(theta="y")  +
  xlim(c(2, 4)) +
  scale_fill_discrete( labels = eth$label)

Removing the tick mark text can be done by setting the right elements of a theme as in the following:

ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
  geom_rect() +
  coord_polar(theta="y")  +
  xlim(c(2, 4)) +
  scale_fill_discrete( labels = eth$label) +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank())

Only one of the two above is actually needed, and you can experiment.

I can send you personally an attachment showing the output as this is a text only setup.




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-help
Sent: Friday, August 13, 2021 5:48 PM
To: John Kane <jrkrideau at gmail.com>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] ggplot: add percentage for each element in legend and remove tick mark

 Hello John,
I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
Thanks,
Kai

| 
ethnicity |
individuals |
| Caucasian | 36062 |
| Ashkenazi Jewish | 4309 |
| Multiple | 3193 |
| Hispanic | 2113 |
| Asian. not specified | 1538 |
| Chinese | 1031 |
| African | 643 |
| Unknown | 510 |
| Filipino | 222 |
| Japanese | 129 |
| Native American | 116 |
| Indian | 111 |
| Pacific Islander | 23 |



    On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:  
 
 Would you supply some sample data please? A handy way to supply sample data is to use the dput() function. See ?dput.  If you have a very large data set then something like head(dput(myfile), 100) will likely supply enough data for us to work with.

On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> I use the following code to generate a donut plot.
> # Compute percentages
> eth$fraction = eth$individuals / sum(eth$individuals)  # Compute the 
>cumulative percentages (top of each rectangle)  eth$ymax = 
>cumsum(eth$fraction)  # Compute the bottom of each rectangle  eth$ymin 
>= c(0, head(eth$ymax, n=-1))  # Make the plot using percentage  
>ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) 
>+
>  geom_rect() +
>  coord_polar(theta="y")  +
>  xlim(c(2, 4)
>  )
>
> I want to improve the plot for two thing:
> 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> 2. remove all number (tick mark ?) around the plot Please help Thank 
> you, Kai
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
John Kane
Kingston ON Canada
  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From he||yj @end|ng |rom uc@d@edu  Sun Aug 15 03:37:40 2021
From: he||yj @end|ng |rom uc@d@edu (John Helly)
Date: Sat, 14 Aug 2021 15:37:40 -1000
Subject: [R] R.app spontaneously switching windows during editing
Message-ID: <e634662b-086f-9394-4b1d-f65924be7535@ucsd.edu>

Aloha.

Apparently since I switched to Big Sur, R has begun spontaneously 
switching the active window from console to editor back and forth for no 
obvious reason.? This disrupts editing and has almost destroyed whole 
editing files due to the deletion of highlighted lines (a different 
behavior that has always been dangerous but is exacerbated by the 
window-switching).

I've looked at the default settings in the Preferences and can't see or 
change anything that seems to affect this behavior. I've tried turning 
off everything that might be doing it (e.g., matching delimiters) and I 
can't find anything or anyone else that complains about this. Am I the 
only one?

Any suggestions for debugging this would be welcome.? sessionInfo below.

J. Helly.

-- John Helly, University of California, San Diego / San Diego 
Supercomputer Center / Scripps Institution of Oceanography / 760 840 
8660 mobile / http://www.sdsc.edu/~hellyj ORCID ID: 
orcid.org/0000-0002-3779-0603



 > sessionInfo()
R version 4.1.0 (2021-05-18)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Big Sur 11.4

Matrix products: default
BLAS: 
/Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib
LAPACK: 
/Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

other attached packages:
 ?[1] Hmisc_4.5-0????? Formula_1.2-4??? survival_3.2-11 lattice_0.20-44? 
runner_0.4.0???? GGally_2.1.2 rpart.plot_3.0.9
 ?[8] rpart_4.1-15???? stargazer_5.2.2? texreg_1.37.5 factoextra_1.0.7 
forcats_0.5.1??? stringr_1.4.0??? dplyr_1.0.6
[15] purrr_0.3.4????? readr_1.4.0????? tidyr_1.1.3 tibble_3.1.2???? 
tidyverse_1.3.1? tables_0.9.6???? reshape2_1.4.4
[22] plyr_1.8.6?????? ggplot2_3.3.5

loaded via a namespace (and not attached):
 ?[1] fs_1.5.0??????????? lubridate_1.7.10??? RColorBrewer_1.1-2 
httr_1.4.2????????? tools_4.1.0???????? backports_1.2.1
 ?[7] utf8_1.2.1????????? R6_2.5.0??????????? DBI_1.1.1 
colorspace_2.0-1??? nnet_7.3-16???????? withr_2.4.2
[13] tidyselect_1.1.1??? gridExtra_2.3?????? curl_4.3.1 
compiler_4.1.0????? cli_2.5.0?????????? rvest_1.0.0
[19] htmlTable_2.2.1???? xml2_1.3.2????????? labeling_0.4.2 
scales_1.1.1??????? checkmate_2.0.0???? digest_0.6.27
[25] foreign_0.8-81????? rio_0.5.27????????? base64enc_0.1-3 
jpeg_0.1-8.1??????? pkgconfig_2.0.3???? htmltools_0.5.1.1
[31] dbplyr_2.1.1??????? htmlwidgets_1.5.3?? rlang_0.4.11 
readxl_1.3.1??????? rstudioapi_0.13???? generics_0.1.0
[37] farver_2.1.0??????? jsonlite_1.7.2????? zip_2.2.0 
car_3.0-11????????? magrittr_2.0.1????? Matrix_1.3-3
[43] Rcpp_1.0.6????????? munsell_0.5.0?????? fansi_0.5.0 
abind_1.4-5???????? lifecycle_1.0.0???? stringi_1.6.2
[49] carData_3.0-4?????? grid_4.1.0????????? parallel_4.1.0 
ggrepel_0.9.1?????? crayon_1.4.1??????? haven_2.4.1
[55] splines_4.1.0?????? hms_1.1.0?????????? knitr_1.33 
ps_1.6.0??????????? pillar_1.6.1??????? ggpubr_0.4.0
[61] ggsignif_0.6.2????? reprex_2.0.0??????? glue_1.4.2 
latticeExtra_0.6-29 data.table_1.14.0?? modelr_0.1.8
[67] png_0.1-7?????????? vctrs_0.3.8???????? cellranger_1.1.0 
gtable_0.3.0??????? reshape_0.8.8?????? assertthat_0.2.1
[73] openxlsx_4.2.4????? xfun_0.23?????????? broom_0.7.6 
rstatix_0.7.0?????? cluster_2.1.2?????? ellipsis_0.3.2
 >

-- John Helly, University of California, San Diego / San Diego 
Supercomputer Center / Scripps Institution of Oceanography / 760 840 
8660 mobile / http://www.sdsc.edu/~hellyj ORCID ID: 
orcid.org/0000-0002-3779-0603


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Aug 15 03:56:17 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 14 Aug 2021 18:56:17 -0700
Subject: [R] R.app spontaneously switching windows during editing
In-Reply-To: <e634662b-086f-9394-4b1d-f65924be7535@ucsd.edu>
References: <e634662b-086f-9394-4b1d-f65924be7535@ucsd.edu>
Message-ID: <CAGxFJbSTxzmjQqMbSsPVR4oEmphk75aWg_MMACwZjgtKDvJCwQ@mail.gmail.com>

Sorry, I can't help; but you should post this on the r-sig-mac list
instead of here I think.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Aug 14, 2021 at 6:38 PM John Helly via R-help
<r-help at r-project.org> wrote:
>
> Aloha.
>
> Apparently since I switched to Big Sur, R has begun spontaneously
> switching the active window from console to editor back and forth for no
> obvious reason.  This disrupts editing and has almost destroyed whole
> editing files due to the deletion of highlighted lines (a different
> behavior that has always been dangerous but is exacerbated by the
> window-switching).
>
> I've looked at the default settings in the Preferences and can't see or
> change anything that seems to affect this behavior. I've tried turning
> off everything that might be doing it (e.g., matching delimiters) and I
> can't find anything or anyone else that complains about this. Am I the
> only one?
>
> Any suggestions for debugging this would be welcome.  sessionInfo below.
>
> J. Helly.
>
> -- John Helly, University of California, San Diego / San Diego
> Supercomputer Center / Scripps Institution of Oceanography / 760 840
> 8660 mobile / http://www.sdsc.edu/~hellyj ORCID ID:
> orcid.org/0000-0002-3779-0603
>
>
>
>  > sessionInfo()
> R version 4.1.0 (2021-05-18)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Big Sur 11.4
>
> Matrix products: default
> BLAS:
> /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
>   [1] Hmisc_4.5-0      Formula_1.2-4    survival_3.2-11 lattice_0.20-44
> runner_0.4.0     GGally_2.1.2 rpart.plot_3.0.9
>   [8] rpart_4.1-15     stargazer_5.2.2  texreg_1.37.5 factoextra_1.0.7
> forcats_0.5.1    stringr_1.4.0    dplyr_1.0.6
> [15] purrr_0.3.4      readr_1.4.0      tidyr_1.1.3 tibble_3.1.2
> tidyverse_1.3.1  tables_0.9.6     reshape2_1.4.4
> [22] plyr_1.8.6       ggplot2_3.3.5
>
> loaded via a namespace (and not attached):
>   [1] fs_1.5.0            lubridate_1.7.10    RColorBrewer_1.1-2
> httr_1.4.2          tools_4.1.0         backports_1.2.1
>   [7] utf8_1.2.1          R6_2.5.0            DBI_1.1.1
> colorspace_2.0-1    nnet_7.3-16         withr_2.4.2
> [13] tidyselect_1.1.1    gridExtra_2.3       curl_4.3.1
> compiler_4.1.0      cli_2.5.0           rvest_1.0.0
> [19] htmlTable_2.2.1     xml2_1.3.2          labeling_0.4.2
> scales_1.1.1        checkmate_2.0.0     digest_0.6.27
> [25] foreign_0.8-81      rio_0.5.27          base64enc_0.1-3
> jpeg_0.1-8.1        pkgconfig_2.0.3     htmltools_0.5.1.1
> [31] dbplyr_2.1.1        htmlwidgets_1.5.3   rlang_0.4.11
> readxl_1.3.1        rstudioapi_0.13     generics_0.1.0
> [37] farver_2.1.0        jsonlite_1.7.2      zip_2.2.0
> car_3.0-11          magrittr_2.0.1      Matrix_1.3-3
> [43] Rcpp_1.0.6          munsell_0.5.0       fansi_0.5.0
> abind_1.4-5         lifecycle_1.0.0     stringi_1.6.2
> [49] carData_3.0-4       grid_4.1.0          parallel_4.1.0
> ggrepel_0.9.1       crayon_1.4.1        haven_2.4.1
> [55] splines_4.1.0       hms_1.1.0           knitr_1.33
> ps_1.6.0            pillar_1.6.1        ggpubr_0.4.0
> [61] ggsignif_0.6.2      reprex_2.0.0        glue_1.4.2
> latticeExtra_0.6-29 data.table_1.14.0   modelr_0.1.8
> [67] png_0.1-7           vctrs_0.3.8         cellranger_1.1.0
> gtable_0.3.0        reshape_0.8.8       assertthat_0.2.1
> [73] openxlsx_4.2.4      xfun_0.23           broom_0.7.6
> rstatix_0.7.0       cluster_2.1.2       ellipsis_0.3.2
>  >
>
> -- John Helly, University of California, San Diego / San Diego
> Supercomputer Center / Scripps Institution of Oceanography / 760 840
> 8660 mobile / http://www.sdsc.edu/~hellyj ORCID ID:
> orcid.org/0000-0002-3779-0603
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgchoy @end|ng |rom @nu@@c@kr  Sun Aug 15 06:41:25 2021
From: bgchoy @end|ng |rom @nu@@c@kr (=?UTF-8?B?7LWc67OR6raM?=)
Date: Sun, 15 Aug 2021 13:41:25 +0900
Subject: [R] about L-BFGS-B
Message-ID: <CAL2vBT1+YqOC8cOHPu=EdyTXvCbhz2mtYiiAHw5B+5CtUhZmMw@mail.gmail.com>

Hello Dear,

I am Choy from Seoul.
I have a question about R

Is it possible to answer the error that occurred while executing R?
I am currently doing zero inflated regression because the data follows a
poisson distribution.


However, for glm.c <http://glm.cm>mp (rndclass ~ CR4), the results are
normally displayed, but when an independent variable is added, the
following error message is displayed:

#Error in optim(par.init, loglik, method = optim.method, control =
optim.control,  :
  L-BFGS-B needs finite values of 'fn'


I can't solve it, but I'd appreciate it if you could help.

For reference, the estimated regression equation is attached below.

# A CMP example with offset terms
 cmp.m3 = glm.cmp(rndclass ~ CR4 + offset(CR4), data=dta)  -(1)
 print(cmp.m3)

 # A ZICMP example with offset terms.

 zicmp.m4 = glm.cmp(rndclass ~ CR4+offset(CR4),
                    formula.nu = ~ offset(CR4),
                      formula.p = ~ CR4+offset(CR4), data=dta)  -(2)

# dependent variable:

 summary(dta$rndc)
    0     1     2     3
12398  1290 11341   109

Thank you

Best
Choy

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Sun Aug 15 14:26:42 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sun, 15 Aug 2021 08:26:42 -0400
Subject: [R] about L-BFGS-B
In-Reply-To: <CAL2vBT1+YqOC8cOHPu=EdyTXvCbhz2mtYiiAHw5B+5CtUhZmMw@mail.gmail.com>
References: <CAL2vBT1+YqOC8cOHPu=EdyTXvCbhz2mtYiiAHw5B+5CtUhZmMw@mail.gmail.com>
Message-ID: <0d6b47f5-739c-d159-9ccd-1009b5a96098@gmail.com>

You have the answer in the error message: the objective function has
been calculated as +/-Inf somehow. You are going to have to figure
out where the function is computed and why it is not finite.

JN

On 2021-08-15 12:41 a.m., ??? wrote:
> Hello Dear,
> 
> I am Choy from Seoul.
> I have a question about R
> 
> Is it possible to answer the error that occurred while executing R?
> I am currently doing zero inflated regression because the data follows a
> poisson distribution.
> 
> 
> However, for glm.c <http://glm.cm>mp (rndclass ~ CR4), the results are
> normally displayed, but when an independent variable is added, the
> following error message is displayed:
> 
> #Error in optim(par.init, loglik, method = optim.method, control =
> optim.control,  :
>   L-BFGS-B needs finite values of 'fn'
> 
> 
> I can't solve it, but I'd appreciate it if you could help.
> 
> For reference, the estimated regression equation is attached below.
> 
> # A CMP example with offset terms
>  cmp.m3 = glm.cmp(rndclass ~ CR4 + offset(CR4), data=dta)  -(1)
>  print(cmp.m3)
> 
>  # A ZICMP example with offset terms.
> 
>  zicmp.m4 = glm.cmp(rndclass ~ CR4+offset(CR4),
>                     formula.nu = ~ offset(CR4),
>                       formula.p = ~ CR4+offset(CR4), data=dta)  -(2)
> 
> # dependent variable:
> 
>  summary(dta$rndc)
>     0     1     2     3
> 12398  1290 11341   109
> 
> Thank you
> 
> Best
> Choy
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sun Aug 15 14:49:42 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sun, 15 Aug 2021 07:49:42 -0500
Subject: [R] about L-BFGS-B
In-Reply-To: <0d6b47f5-739c-d159-9ccd-1009b5a96098@gmail.com>
References: <CAL2vBT1+YqOC8cOHPu=EdyTXvCbhz2mtYiiAHw5B+5CtUhZmMw@mail.gmail.com>
 <0d6b47f5-739c-d159-9ccd-1009b5a96098@gmail.com>
Message-ID: <749c40ed-c9d6-63d9-5326-3119ca67cb35@effectivedefense.org>

Hello ??? <bgchoy at snu.ac.kr>:


	  Are you familiar with the "debug" function?  "debug(glm.cmp)" 
followed by the problem command will put you into the environment of 
"glm.cmp", and you can walk through that function line by line looking 
at each variable.


	  If you need more help, "PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html and provide commented, 
minimal, self-contained, reproducible code."


	  Also, am I correct that this glm.cmp function is in the COMPoissonReg 
package?  If yes, have you tried contacting the maintainer of that 
package (Andrew Raim <andrew.raim at gmail.com>?)?  If you can't solve 
your problem using "debug(glm.cmp)" AND you have NOT yet asked the 
package maintainer with "commented, minimal, self-contained, 
reproducible code."  They might like to have that example to make the 
code easier to use, e.g., by giving a more informative error message.


	  Hope this helps,
	  Spencer Graves


On 8/15/21 7:26 AM, J C Nash wrote:
> You have the answer in the error message: the objective function has
> been calculated as +/-Inf somehow. You are going to have to figure
> out where the function is computed and why it is not finite.
> 
> JN
> 
> On 2021-08-15 12:41 a.m., ??? wrote:
>> Hello Dear,
>>
>> I am Choy from Seoul.
>> I have a question about R
>>
>> Is it possible to answer the error that occurred while executing R?
>> I am currently doing zero inflated regression because the data follows a
>> poisson distribution.
>>
>>
>> However, for glm.c <http://glm.cm>mp (rndclass ~ CR4), the results are
>> normally displayed, but when an independent variable is added, the
>> following error message is displayed:
>>
>> #Error in optim(par.init, loglik, method = optim.method, control =
>> optim.control,  :
>>    L-BFGS-B needs finite values of 'fn'
>>
>>
>> I can't solve it, but I'd appreciate it if you could help.
>>
>> For reference, the estimated regression equation is attached below.
>>
>> # A CMP example with offset terms
>>   cmp.m3 = glm.cmp(rndclass ~ CR4 + offset(CR4), data=dta)  -(1)
>>   print(cmp.m3)
>>
>>   # A ZICMP example with offset terms.
>>
>>   zicmp.m4 = glm.cmp(rndclass ~ CR4+offset(CR4),
>>                      formula.nu = ~ offset(CR4),
>>                        formula.p = ~ CR4+offset(CR4), data=dta)  -(2)
>>
>> # dependent variable:
>>
>>   summary(dta$rndc)
>>      0     1     2     3
>> 12398  1290 11341   109
>>
>> Thank you
>>
>> Best
>> Choy
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @kw@|mmo @end|ng |rom gm@||@com  Sun Aug 15 21:47:25 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Sun, 15 Aug 2021 15:47:25 -0400
Subject: [R] Returning .Call / / .External results invisibly
Message-ID: <CAPcHnpSgHi9ZPH_rTku0FMnbXaSqcbevrQBSxorrwcs7BpzpvA@mail.gmail.com>

Hello,


I have a C function in which I want to return a result visibly or invisibly
(depends on the arguments provided). My current implementation was to
return a list like 'withVisible' does, where element "value" is the value
the function returns, and element "visible" is TRUE or FALSE depending on
whether the result is returned visibly or not. Something like:

{
    value <- .External(C_fun, ...)
    if (value$visible)
        value$value
    else invisible(value$value)
}

Is there a way to do this in C instead? Thank you!

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Aug 16 23:54:48 2021
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 16 Aug 2021 16:54:48 -0500
Subject: [R] Including percentage values inside columns of a histogram
Message-ID: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>

Hello everyone,

I am currently working with R version 4.1.0 and I am trying to include
(inside the columns of the histogram), the percentage distribution and I
want to generate three histograms, one for each fiscal year (in the Date
column, there are three fiscal year AF 2017, AF 2020 and AF 2021). However,
I can?t seem to accomplish this.

Here is my data:

structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
"factor"),
    Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
    15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
    15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
    15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
    15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
    16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
    15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
    15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
    15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
"data.frame")

I would like to modify the following script:

> with(datasetregs, Hist(Amount, groups=Date, scale="frequency",
+   breaks="Sturges", col="darkgray"))

#The only thing missing here are the percentages corresponding to each bin
(I would like to see the percentages inside each column, or on top outside
if possible)

Any help will be greatly appreciated.

Best regards,

Paul.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 17 00:07:43 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Aug 2021 23:07:43 +0100
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
Message-ID: <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>

Hello,

The function Hist comes from what package?

Are you sure you don't want a bar plot?


agg <- aggregate(Amount ~ Date, datasetregs, sum)
bp <- barplot(Amount ~ Date, agg)
with(agg, text(bp, Amount/2, labels = Amount))


Hope this helps,

Rui Barradas

?s 22:54 de 16/08/21, Paul Bernal escreveu:
> Hello everyone,
> 
> I am currently working with R version 4.1.0 and I am trying to include
> (inside the columns of the histogram), the percentage distribution and I
> want to generate three histograms, one for each fiscal year (in the Date
> column, there are three fiscal year AF 2017, AF 2020 and AF 2021). However,
> I can?t seem to accomplish this.
> 
> Here is my data:
> 
> structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> "factor"),
>      Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
>      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
>      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
>      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
>      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
>      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
>      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
>      15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
> "data.frame")
> 
> I would like to modify the following script:
> 
>> with(datasetregs, Hist(Amount, groups=Date, scale="frequency",
> +   breaks="Sturges", col="darkgray"))
> 
> #The only thing missing here are the percentages corresponding to each bin
> (I would like to see the percentages inside each column, or on top outside
> if possible)
> 
> Any help will be greatly appreciated.
> 
> Best regards,
> 
> Paul.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 17 00:33:33 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Aug 2021 23:33:33 +0100
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
Message-ID: <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>

Hello,

You forgot to cc the list.

Here are two ways, both of them apply hist() and text() to Amount split 
by Date. The return value of hist is saved because it's a list with 
members the histogram's bars midpoints and the counts. Those are used to 
know where to put the text labels.
A vector lbls is created to get rid of counts of zero.

The main difference between the two ways is the histogram's titles.


old_par <- par(mfrow = c(1, 3))
h_list <- with(datasetregs, tapply(Amount, Date, function(x){
   h <- hist(x)
   lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
   text(h$mids, h$counts/2, labels = lbls)
}))
par(old_par)



old_par <- par(mfrow = c(1, 3))
sp <- split(datasetregs, datasetregs$Date)
h_list <- lapply(seq_along(sp), function(i){
   hist_title <- paste("Histogram of", names(sp)[i])
   h <- hist(sp[[i]]$Amount, main = hist_title)
   lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
   text(h$mids, h$counts/2, labels = lbls)
})
par(old_par)


Hope this helps,

Rui Barradas

?s 23:16 de 16/08/21, Paul Bernal escreveu:
> Dear Rui,
> 
> The hist() function comes from the graphics package, from what I could 
> see. The thing is that I want to divide the Amount column into several 
> bins and then generate three different histograms, one for each AF 
> period (AF refers to fiscal years). As you can see, the data contains 
> three fiscal years (2017, 2020 and 2021). I want to see the percentage 
> of cases that fall into different amount categories, from 15,000 and 
> below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> 
> Thanks for your kind help.
> 
> Paul
> 
> El lun, 16 ago 2021 a las 17:07, Rui Barradas (<ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>>) escribi?:
> 
>     Hello,
> 
>     The function Hist comes from what package?
> 
>     Are you sure you don't want a bar plot?
> 
> 
>     agg <- aggregate(Amount ~ Date, datasetregs, sum)
>     bp <- barplot(Amount ~ Date, agg)
>     with(agg, text(bp, Amount/2, labels = Amount))
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 22:54 de 16/08/21, Paul Bernal escreveu:
>      > Hello everyone,
>      >
>      > I am currently working with R version 4.1.0 and I am trying to
>     include
>      > (inside the columns of the histogram), the percentage
>     distribution and I
>      > want to generate three histograms, one for each fiscal year (in
>     the Date
>      > column, there are three fiscal year AF 2017, AF 2020 and AF
>     2021). However,
>      > I can?t seem to accomplish this.
>      >
>      > Here is my data:
>      >
>      > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
>      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>      > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>      > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
>      > "factor"),
>      >? ? ? Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
>      >? ? ? 15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
>      >? ? ? 15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
>      >? ? ? 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>      >? ? ? 15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
>      >? ? ? 16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
>      >? ? ? 15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
>      >? ? ? 15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
>      >? ? ? 15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
>      > "data.frame")
>      >
>      > I would like to modify the following script:
>      >
>      >> with(datasetregs, Hist(Amount, groups=Date, scale="frequency",
>      > +? ?breaks="Sturges", col="darkgray"))
>      >
>      > #The only thing missing here are the percentages corresponding to
>     each bin
>      > (I would like to see the percentages inside each column, or on
>     top outside
>      > if possible)
>      >
>      > Any help will be greatly appreciated.
>      >
>      > Best regards,
>      >
>      > Paul.
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Aug 17 00:43:33 2021
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 16 Aug 2021 17:43:33 -0500
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
Message-ID: <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>

This is way better, now, how could I put the frequency labels in the
columns as a percentage, instead of presenting them as counts?

Thank you so much.

Paul

El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
escribi?:

> Hello,
>
> You forgot to cc the list.
>
> Here are two ways, both of them apply hist() and text() to Amount split
> by Date. The return value of hist is saved because it's a list with
> members the histogram's bars midpoints and the counts. Those are used to
> know where to put the text labels.
> A vector lbls is created to get rid of counts of zero.
>
> The main difference between the two ways is the histogram's titles.
>
>
> old_par <- par(mfrow = c(1, 3))
> h_list <- with(datasetregs, tapply(Amount, Date, function(x){
>    h <- hist(x)
>    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>    text(h$mids, h$counts/2, labels = lbls)
> }))
> par(old_par)
>
>
>
> old_par <- par(mfrow = c(1, 3))
> sp <- split(datasetregs, datasetregs$Date)
> h_list <- lapply(seq_along(sp), function(i){
>    hist_title <- paste("Histogram of", names(sp)[i])
>    h <- hist(sp[[i]]$Amount, main = hist_title)
>    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>    text(h$mids, h$counts/2, labels = lbls)
> })
> par(old_par)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 23:16 de 16/08/21, Paul Bernal escreveu:
> > Dear Rui,
> >
> > The hist() function comes from the graphics package, from what I could
> > see. The thing is that I want to divide the Amount column into several
> > bins and then generate three different histograms, one for each AF
> > period (AF refers to fiscal years). As you can see, the data contains
> > three fiscal years (2017, 2020 and 2021). I want to see the percentage
> > of cases that fall into different amount categories, from 15,000 and
> > below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> >
> > Thanks for your kind help.
> >
> > Paul
> >
> > El lun, 16 ago 2021 a las 17:07, Rui Barradas (<ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> >
> >     Hello,
> >
> >     The function Hist comes from what package?
> >
> >     Are you sure you don't want a bar plot?
> >
> >
> >     agg <- aggregate(Amount ~ Date, datasetregs, sum)
> >     bp <- barplot(Amount ~ Date, agg)
> >     with(agg, text(bp, Amount/2, labels = Amount))
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 22:54 de 16/08/21, Paul Bernal escreveu:
> >      > Hello everyone,
> >      >
> >      > I am currently working with R version 4.1.0 and I am trying to
> >     include
> >      > (inside the columns of the histogram), the percentage
> >     distribution and I
> >      > want to generate three histograms, one for each fiscal year (in
> >     the Date
> >      > column, there are three fiscal year AF 2017, AF 2020 and AF
> >     2021). However,
> >      > I can?t seem to accomplish this.
> >      >
> >      > Here is my data:
> >      >
> >      > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >      > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >      > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >      > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> >      > "factor"),
> >      >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
> >      >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
> 15000,
> >      >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
> 15000,
> >      >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> 15000,
> >      >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
> 15000,
> >      >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
> 15000,
> >      >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
> 15000,
> >      >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
> 15000,
> >      >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class
> =
> >      > "data.frame")
> >      >
> >      > I would like to modify the following script:
> >      >
> >      >> with(datasetregs, Hist(Amount, groups=Date, scale="frequency",
> >      > +   breaks="Sturges", col="darkgray"))
> >      >
> >      > #The only thing missing here are the percentages corresponding to
> >     each bin
> >      > (I would like to see the percentages inside each column, or on
> >     top outside
> >      > if possible)
> >      >
> >      > Any help will be greatly appreciated.
> >      >
> >      > Best regards,
> >      >
> >      > Paul.
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >     <https://stat.ethz.ch/mailman/listinfo/r-help>
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     <http://www.R-project.org/posting-guide.html>
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug 17 00:57:06 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 17 Aug 2021 08:57:06 +1000
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
Message-ID: <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>

Hi Paul,
I just worked out your first request:

datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
"factor"),
    Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
    15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
    15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
    15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
    15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
    16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
    15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
    15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
    15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
"data.frame")
histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
 breaks="Sturges", col="darkgray"))
library(plotrix)
histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
barlabels(histval$mids,histval$counts,histpcts)

I think that's what you asked for:

Jim

On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> This is way better, now, how could I put the frequency labels in the
> columns as a percentage, instead of presenting them as counts?
>
> Thank you so much.
>
> Paul
>
> El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
> escribi?:
>
> > Hello,
> >
> > You forgot to cc the list.
> >
> > Here are two ways, both of them apply hist() and text() to Amount split
> > by Date. The return value of hist is saved because it's a list with
> > members the histogram's bars midpoints and the counts. Those are used to
> > know where to put the text labels.
> > A vector lbls is created to get rid of counts of zero.
> >
> > The main difference between the two ways is the histogram's titles.
> >
> >
> > old_par <- par(mfrow = c(1, 3))
> > h_list <- with(datasetregs, tapply(Amount, Date, function(x){
> >    h <- hist(x)
> >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> >    text(h$mids, h$counts/2, labels = lbls)
> > }))
> > par(old_par)
> >
> >
> >
> > old_par <- par(mfrow = c(1, 3))
> > sp <- split(datasetregs, datasetregs$Date)
> > h_list <- lapply(seq_along(sp), function(i){
> >    hist_title <- paste("Histogram of", names(sp)[i])
> >    h <- hist(sp[[i]]$Amount, main = hist_title)
> >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> >    text(h$mids, h$counts/2, labels = lbls)
> > })
> > par(old_par)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 23:16 de 16/08/21, Paul Bernal escreveu:
> > > Dear Rui,
> > >
> > > The hist() function comes from the graphics package, from what I could
> > > see. The thing is that I want to divide the Amount column into several
> > > bins and then generate three different histograms, one for each AF
> > > period (AF refers to fiscal years). As you can see, the data contains
> > > three fiscal years (2017, 2020 and 2021). I want to see the percentage
> > > of cases that fall into different amount categories, from 15,000 and
> > > below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> > >
> > > Thanks for your kind help.
> > >
> > > Paul
> > >
> > > El lun, 16 ago 2021 a las 17:07, Rui Barradas (<ruipbarradas at sapo.pt
> > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> > >
> > >     Hello,
> > >
> > >     The function Hist comes from what package?
> > >
> > >     Are you sure you don't want a bar plot?
> > >
> > >
> > >     agg <- aggregate(Amount ~ Date, datasetregs, sum)
> > >     bp <- barplot(Amount ~ Date, agg)
> > >     with(agg, text(bp, Amount/2, labels = Amount))
> > >
> > >
> > >     Hope this helps,
> > >
> > >     Rui Barradas
> > >
> > >     ?s 22:54 de 16/08/21, Paul Bernal escreveu:
> > >      > Hello everyone,
> > >      >
> > >      > I am currently working with R version 4.1.0 and I am trying to
> > >     include
> > >      > (inside the columns of the histogram), the percentage
> > >     distribution and I
> > >      > want to generate three histograms, one for each fiscal year (in
> > >     the Date
> > >      > column, there are three fiscal year AF 2017, AF 2020 and AF
> > >     2021). However,
> > >      > I can?t seem to accomplish this.
> > >      >
> > >      > Here is my data:
> > >      >
> > >      > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > >      > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > >      > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > >      > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> > >      > "factor"),
> > >      >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
> > >      >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
> > 15000,
> > >      >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
> > 15000,
> > >      >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> > 15000,
> > >      >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
> > 15000,
> > >      >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
> > 15000,
> > >      >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
> > 15000,
> > >      >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
> > 15000,
> > >      >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class
> > =
> > >      > "data.frame")
> > >      >
> > >      > I would like to modify the following script:
> > >      >
> > >      >> with(datasetregs, Hist(Amount, groups=Date, scale="frequency",
> > >      > +   breaks="Sturges", col="darkgray"))
> > >      >
> > >      > #The only thing missing here are the percentages corresponding to
> > >     each bin
> > >      > (I would like to see the percentages inside each column, or on
> > >     top outside
> > >      > if possible)
> > >      >
> > >      > Any help will be greatly appreciated.
> > >      >
> > >      > Best regards,
> > >      >
> > >      > Paul.
> > >      >
> > >      >       [[alternative HTML version deleted]]
> > >      >
> > >      > ______________________________________________
> > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > >     <https://stat.ethz.ch/mailman/listinfo/r-help>
> > >      > PLEASE do read the posting guide
> > >     http://www.R-project.org/posting-guide.html
> > >     <http://www.R-project.org/posting-guide.html>
> > >      > and provide commented, minimal, self-contained, reproducible code.
> > >      >
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Aug 17 01:14:13 2021
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 16 Aug 2021 18:14:13 -0500
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
Message-ID: <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>

Dear Jim,

Thank you so much for your kind reply. Yes, this is what I am looking for,
however, can?t see clearly how the bars correspond to the bins in the
x-axis. Maybe there is a way to align the amounts so that they match the
columns, sorry if I sound picky, but just want to learn if there is a way
to accomplish this.

Best regards,

Paul

El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
escribi?:

> Hi Paul,
> I just worked out your first request:
>
> datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> "factor"),
>     Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
>     15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
>     15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
>     15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>     15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
>     16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
>     15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
>     15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
>     15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
> "data.frame")
> histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
>  breaks="Sturges", col="darkgray"))
> library(plotrix)
> histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
> barlabels(histval$mids,histval$counts,histpcts)
>
> I think that's what you asked for:
>
> Jim
>
> On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >
> > This is way better, now, how could I put the frequency labels in the
> > columns as a percentage, instead of presenting them as counts?
> >
> > Thank you so much.
> >
> > Paul
> >
> > El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
> > escribi?:
> >
> > > Hello,
> > >
> > > You forgot to cc the list.
> > >
> > > Here are two ways, both of them apply hist() and text() to Amount split
> > > by Date. The return value of hist is saved because it's a list with
> > > members the histogram's bars midpoints and the counts. Those are used
> to
> > > know where to put the text labels.
> > > A vector lbls is created to get rid of counts of zero.
> > >
> > > The main difference between the two ways is the histogram's titles.
> > >
> > >
> > > old_par <- par(mfrow = c(1, 3))
> > > h_list <- with(datasetregs, tapply(Amount, Date, function(x){
> > >    h <- hist(x)
> > >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> > >    text(h$mids, h$counts/2, labels = lbls)
> > > }))
> > > par(old_par)
> > >
> > >
> > >
> > > old_par <- par(mfrow = c(1, 3))
> > > sp <- split(datasetregs, datasetregs$Date)
> > > h_list <- lapply(seq_along(sp), function(i){
> > >    hist_title <- paste("Histogram of", names(sp)[i])
> > >    h <- hist(sp[[i]]$Amount, main = hist_title)
> > >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> > >    text(h$mids, h$counts/2, labels = lbls)
> > > })
> > > par(old_par)
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 23:16 de 16/08/21, Paul Bernal escreveu:
> > > > Dear Rui,
> > > >
> > > > The hist() function comes from the graphics package, from what I
> could
> > > > see. The thing is that I want to divide the Amount column into
> several
> > > > bins and then generate three different histograms, one for each AF
> > > > period (AF refers to fiscal years). As you can see, the data contains
> > > > three fiscal years (2017, 2020 and 2021). I want to see the
> percentage
> > > > of cases that fall into different amount categories, from 15,000 and
> > > > below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> > > >
> > > > Thanks for your kind help.
> > > >
> > > > Paul
> > > >
> > > > El lun, 16 ago 2021 a las 17:07, Rui Barradas (<ruipbarradas at sapo.pt
> > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> > > >
> > > >     Hello,
> > > >
> > > >     The function Hist comes from what package?
> > > >
> > > >     Are you sure you don't want a bar plot?
> > > >
> > > >
> > > >     agg <- aggregate(Amount ~ Date, datasetregs, sum)
> > > >     bp <- barplot(Amount ~ Date, agg)
> > > >     with(agg, text(bp, Amount/2, labels = Amount))
> > > >
> > > >
> > > >     Hope this helps,
> > > >
> > > >     Rui Barradas
> > > >
> > > >     ?s 22:54 de 16/08/21, Paul Bernal escreveu:
> > > >      > Hello everyone,
> > > >      >
> > > >      > I am currently working with R version 4.1.0 and I am trying to
> > > >     include
> > > >      > (inside the columns of the histogram), the percentage
> > > >     distribution and I
> > > >      > want to generate three histograms, one for each fiscal year
> (in
> > > >     the Date
> > > >      > column, there are three fiscal year AF 2017, AF 2020 and AF
> > > >     2021). However,
> > > >      > I can?t seem to accomplish this.
> > > >      >
> > > >      > Here is my data:
> > > >      >
> > > >      > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> > > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L,
> > > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L,
> > > >      > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L,
> > > >      > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L,
> > > >      > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
> class =
> > > >      > "factor"),
> > > >      >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
> 40200,
> > > >      >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
> > > 15000,
> > > >      >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
> > > 15000,
> > > >      >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> > > 15000,
> > > >      >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
> > > 15000,
> > > >      >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
> > > 15000,
> > > >      >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
> > > 15000,
> > > >      >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
> > > 15000,
> > > >      >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
> class
> > > =
> > > >      > "data.frame")
> > > >      >
> > > >      > I would like to modify the following script:
> > > >      >
> > > >      >> with(datasetregs, Hist(Amount, groups=Date,
> scale="frequency",
> > > >      > +   breaks="Sturges", col="darkgray"))
> > > >      >
> > > >      > #The only thing missing here are the percentages
> corresponding to
> > > >     each bin
> > > >      > (I would like to see the percentages inside each column, or on
> > > >     top outside
> > > >      > if possible)
> > > >      >
> > > >      > Any help will be greatly appreciated.
> > > >      >
> > > >      > Best regards,
> > > >      >
> > > >      > Paul.
> > > >      >
> > > >      >       [[alternative HTML version deleted]]
> > > >      >
> > > >      > ______________________________________________
> > > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> list
> > > >     -- To UNSUBSCRIBE and more, see
> > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >     <https://stat.ethz.ch/mailman/listinfo/r-help>
> > > >      > PLEASE do read the posting guide
> > > >     http://www.R-project.org/posting-guide.html
> > > >     <http://www.R-project.org/posting-guide.html>
> > > >      > and provide commented, minimal, self-contained, reproducible
> code.
> > > >      >
> > > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 17 02:49:16 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Aug 2021 17:49:16 -0700
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
 <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
Message-ID: <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>

I may well misunderstand, but proffered solutions seem more complicated
than necessary.
Note that the return of hist() can be saved as a list of class "histogram"
and then plotted with  plot.histogram(), which already has a "labels"
argument that seems to be what you want. A simple example is"

dat <- runif(50, 0, 10)
myhist <- hist(dat, freq = TRUE, breaks ="Sturges")

plot(myhist, col = "darkgray",
     labels = as.character(round(myhist$density*100,1) ),
     ylim = c(0, 1.1*max(myhist$counts)))
## note that this is plot.histogram because myhist has class "histogram"

Note that I expanded the y axis a bit to be sure to include the labels. You
can, of course, plot your separate years as Rui has indicated or via e.g.
?layout.

Apologies if I have misunderstood. Just ignore this in that case.
Otherwise, I leave it to you to fill in details.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 16, 2021 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear Jim,
>
> Thank you so much for your kind reply. Yes, this is what I am looking for,
> however, can?t see clearly how the bars correspond to the bins in the
> x-axis. Maybe there is a way to align the amounts so that they match the
> columns, sorry if I sound picky, but just want to learn if there is a way
> to accomplish this.
>
> Best regards,
>
> Paul
>
> El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
> escribi?:
>
> > Hi Paul,
> > I just worked out your first request:
> >
> > datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> > 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> > "factor"),
> >     Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
> >     15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
> >     15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
> >     15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> >     15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
> >     16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
> >     15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
> >     15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
> >     15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
> > "data.frame")
> > histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
> >  breaks="Sturges", col="darkgray"))
> > library(plotrix)
> > histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
> > barlabels(histval$mids,histval$counts,histpcts)
> >
> > I think that's what you asked for:
> >
> > Jim
> >
> > On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
> > wrote:
> > >
> > > This is way better, now, how could I put the frequency labels in the
> > > columns as a percentage, instead of presenting them as counts?
> > >
> > > Thank you so much.
> > >
> > > Paul
> > >
> > > El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
> > > escribi?:
> > >
> > > > Hello,
> > > >
> > > > You forgot to cc the list.
> > > >
> > > > Here are two ways, both of them apply hist() and text() to Amount
> split
> > > > by Date. The return value of hist is saved because it's a list with
> > > > members the histogram's bars midpoints and the counts. Those are used
> > to
> > > > know where to put the text labels.
> > > > A vector lbls is created to get rid of counts of zero.
> > > >
> > > > The main difference between the two ways is the histogram's titles.
> > > >
> > > >
> > > > old_par <- par(mfrow = c(1, 3))
> > > > h_list <- with(datasetregs, tapply(Amount, Date, function(x){
> > > >    h <- hist(x)
> > > >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> > > >    text(h$mids, h$counts/2, labels = lbls)
> > > > }))
> > > > par(old_par)
> > > >
> > > >
> > > >
> > > > old_par <- par(mfrow = c(1, 3))
> > > > sp <- split(datasetregs, datasetregs$Date)
> > > > h_list <- lapply(seq_along(sp), function(i){
> > > >    hist_title <- paste("Histogram of", names(sp)[i])
> > > >    h <- hist(sp[[i]]$Amount, main = hist_title)
> > > >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> > > >    text(h$mids, h$counts/2, labels = lbls)
> > > > })
> > > > par(old_par)
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > > Rui Barradas
> > > >
> > > > ?s 23:16 de 16/08/21, Paul Bernal escreveu:
> > > > > Dear Rui,
> > > > >
> > > > > The hist() function comes from the graphics package, from what I
> > could
> > > > > see. The thing is that I want to divide the Amount column into
> > several
> > > > > bins and then generate three different histograms, one for each AF
> > > > > period (AF refers to fiscal years). As you can see, the data
> contains
> > > > > three fiscal years (2017, 2020 and 2021). I want to see the
> > percentage
> > > > > of cases that fall into different amount categories, from 15,000
> and
> > > > > below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> > > > >
> > > > > Thanks for your kind help.
> > > > >
> > > > > Paul
> > > > >
> > > > > El lun, 16 ago 2021 a las 17:07, Rui Barradas (<
> ruipbarradas at sapo.pt
> > > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
> > > > >
> > > > >     Hello,
> > > > >
> > > > >     The function Hist comes from what package?
> > > > >
> > > > >     Are you sure you don't want a bar plot?
> > > > >
> > > > >
> > > > >     agg <- aggregate(Amount ~ Date, datasetregs, sum)
> > > > >     bp <- barplot(Amount ~ Date, agg)
> > > > >     with(agg, text(bp, Amount/2, labels = Amount))
> > > > >
> > > > >
> > > > >     Hope this helps,
> > > > >
> > > > >     Rui Barradas
> > > > >
> > > > >     ?s 22:54 de 16/08/21, Paul Bernal escreveu:
> > > > >      > Hello everyone,
> > > > >      >
> > > > >      > I am currently working with R version 4.1.0 and I am trying
> to
> > > > >     include
> > > > >      > (inside the columns of the histogram), the percentage
> > > > >     distribution and I
> > > > >      > want to generate three histograms, one for each fiscal year
> > (in
> > > > >     the Date
> > > > >      > column, there are three fiscal year AF 2017, AF 2020 and AF
> > > > >     2021). However,
> > > > >      > I can?t seem to accomplish this.
> > > > >      >
> > > > >      > Here is my data:
> > > > >      >
> > > > >      > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> 2L,
> > > > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L,
> > > > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L,
> > > > >      > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L,
> > > > >      > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L,
> > > > >      > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
> > class =
> > > > >      > "factor"),
> > > > >      >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
> > 40200,
> > > > >      >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
> > > > 15000,
> > > > >      >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
> > > > 15000,
> > > > >      >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> > > > 15000,
> > > > >      >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
> > > > 15000,
> > > > >      >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
> > > > 15000,
> > > > >      >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
> > > > 15000,
> > > > >      >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
> > > > 15000,
> > > > >      >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
> > class
> > > > =
> > > > >      > "data.frame")
> > > > >      >
> > > > >      > I would like to modify the following script:
> > > > >      >
> > > > >      >> with(datasetregs, Hist(Amount, groups=Date,
> > scale="frequency",
> > > > >      > +   breaks="Sturges", col="darkgray"))
> > > > >      >
> > > > >      > #The only thing missing here are the percentages
> > corresponding to
> > > > >     each bin
> > > > >      > (I would like to see the percentages inside each column, or
> on
> > > > >     top outside
> > > > >      > if possible)
> > > > >      >
> > > > >      > Any help will be greatly appreciated.
> > > > >      >
> > > > >      > Best regards,
> > > > >      >
> > > > >      > Paul.
> > > > >      >
> > > > >      >       [[alternative HTML version deleted]]
> > > > >      >
> > > > >      > ______________________________________________
> > > > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> > list
> > > > >     -- To UNSUBSCRIBE and more, see
> > > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >     <https://stat.ethz.ch/mailman/listinfo/r-help>
> > > > >      > PLEASE do read the posting guide
> > > > >     http://www.R-project.org/posting-guide.html
> > > > >     <http://www.R-project.org/posting-guide.html>
> > > > >      > and provide commented, minimal, self-contained, reproducible
> > code.
> > > > >      >
> > > > >
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e||z@_botto @end|ng |rom out|ook@com  Tue Aug 17 03:03:52 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 17 Aug 2021 01:03:52 +0000
Subject: [R] Sectors covered by the Nearest Neighbors
Message-ID: <AS8P194MB0999FDED6B2895F5A9BD57C99AFE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

deaR useRs,

I have a very basic question. I am for putting up a real long text. But I tried searching for some clues in the previous help posts but unfortunately, I could get any. I have the following data called "el".

> dput(el)

structure(c(1.00451374640952, 1.88100123102175, 0.201887566680345,
0.339762002462043, 0.211735740664752, 1.29011079195732, 1.72343044727123,
2.07304062371769, 0.58596635207222, 0.994665572425113, 0.398851046368486,
1.29503487894953, 1.01025376658795, 1.00853759936143, 1.015781421492,
1.01308743805501, 1.00815844613696, 0.994069910533143, 0.993411381248545,
0.987205241627033, 0.98411214953271, 0.987005687298367, 1.01957295373665,
0.978804004390195, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), .Dim = c(12L,
3L))

you see, there are 3 columns. The first 2 columns contain actual data whereas the third column contains the "gate numbers" for which the data is presented in the first 2 columns. I then executed distance matrix by using the data in the first 2 columns by using the following command

> d53<-dist(el[,1])

> d15<-d53/mean(d53)

> d54<-dist(el[,2])

> dr1<-d54/mean(d54)

> t<-as.matrix((d15)^2+(dr1)^2)

> w<-sqrt(t)

I then sorted the nearest neighbors of "gate 6" in the order of their distance from the data of "gate 6"

> u<-matrix(sort(as.matrix(w)[6,],index.return=TRUE)$ix,ncol=1)

Finally, I plotted the entire data by giving different colors to "gate 6" (red) and its 5 nearest neighbors (green)

> plot(el[,1],el[,2])

> textxy(el[,1],el[,2],el[,3])

> points(el[,1][6],el[,2][6],col="red",pch=16)

> points(el[,1][u[2]],el[,2][u[2]],col="green",pch=16)

> points(el[,1][u[3]],el[,2][u[3]],col="green",pch=16)

> points(el[,1][u[4]],el[,2][u[4]],col="green",pch=16)

> points(el[,1][u[5]],el[,2][u[5]],col="green",pch=16)

> points(el[,1][u[6]],el[,2][u[6]],col="green",pch=16)

Afterwards I bisected the space around gate 6 into 6 sectors each covering 60 degrees.

> X1<-(el[,1])[6]

> Y1<-(el[,2])[6]

> X2<-1.5*X1

> Y2<-Y1

> base<-sqrt((X1-X2)^2+(Y1-Y2)^2)

> Hyp =base/cos(60*pi/180)

> Pre= Hyp*sin(60*pi/180)

> Y3<-Pre+Y2

> X3<-X2

> segments((X3), (Y3), (X1-base), (Y1-Pre),type="l",col="red")

> segments((X1-base), (Y3), (X3), (Y1-Pre),type="l",col="red")

> segments((X2), (Y2), (X1-base), (Y1),type="l",col="red")


As you can see from the plot that the nearest neighbours of gate 6 have covered 4 (of those 6) sectors. For example, the gates 7 and 8 are covering the sector (301 to 360 degrees), the sectors (0 to 60 degrees and 61 to 120 degrees) are vacant so they are not counted, the sector (121 to 180 degrees) is covered by gate 1, gate 10 covers the sector from 181 to 240 degrees, and gate 12 covers the sector from 241 to 300 degrees.  Currently, I have to manually write down the number of sectors the nearest neighbours of each gate are covering. Is there a command that can help me executing ONLY the TOTAL number of covered sectors around each gate directly (4 in the current case)?

The gate 6 here is just given as an example. I have almost 3000 gates for which I have to find the number of covered sectors by the nearest neighbours.

I hope there is a way around it. I thank-you all in advance.


Regards,

Eliza

Trinity College Dublin

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Aug 17 03:04:20 2021
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 16 Aug 2021 20:04:20 -0500
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
 <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
 <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
Message-ID: <CAMOcQfP7w2FSPCjXkRp4eE+BAm+QKmotMC-H_opdNpwidZnaCw@mail.gmail.com>

Thank you very much Mr. Gunter, I will give it a try.

Cheers,

Paul

El lun., 16 de agosto de 2021 7:49 p. m., Bert Gunter <
bgunter.4567 at gmail.com> escribi?:

> I may well misunderstand, but proffered solutions seem more complicated
> than necessary.
> Note that the return of hist() can be saved as a list of class "histogram"
> and then plotted with  plot.histogram(), which already has a "labels"
> argument that seems to be what you want. A simple example is"
>
> dat <- runif(50, 0, 10)
> myhist <- hist(dat, freq = TRUE, breaks ="Sturges")
>
> plot(myhist, col = "darkgray",
>      labels = as.character(round(myhist$density*100,1) ),
>      ylim = c(0, 1.1*max(myhist$counts)))
> ## note that this is plot.histogram because myhist has class "histogram"
>
> Note that I expanded the y axis a bit to be sure to include the labels.
> You can, of course, plot your separate years as Rui has indicated or via
> e.g. ?layout.
>
> Apologies if I have misunderstood. Just ignore this in that case.
> Otherwise, I leave it to you to fill in details.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 16, 2021 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear Jim,
>>
>> Thank you so much for your kind reply. Yes, this is what I am looking for,
>> however, can?t see clearly how the bars correspond to the bins in the
>> x-axis. Maybe there is a way to align the amounts so that they match the
>> columns, sorry if I sound picky, but just want to learn if there is a way
>> to accomplish this.
>>
>> Best regards,
>>
>> Paul
>>
>> El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
>> escribi?:
>>
>> > Hi Paul,
>> > I just worked out your first request:
>> >
>> > datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>> > 2L,
>> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
>> > "factor"),
>> >     Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
>> >     15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
>> >     15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
>> >     15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>> >     15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
>> >     16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
>> >     15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
>> >     15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
>> >     15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
>> > "data.frame")
>> > histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
>> >  breaks="Sturges", col="darkgray"))
>> > library(plotrix)
>> > histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
>> > barlabels(histval$mids,histval$counts,histpcts)
>> >
>> > I think that's what you asked for:
>> >
>> > Jim
>> >
>> > On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
>> > wrote:
>> > >
>> > > This is way better, now, how could I put the frequency labels in the
>> > > columns as a percentage, instead of presenting them as counts?
>> > >
>> > > Thank you so much.
>> > >
>> > > Paul
>> > >
>> > > El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt
>> >)
>> > > escribi?:
>> > >
>> > > > Hello,
>> > > >
>> > > > You forgot to cc the list.
>> > > >
>> > > > Here are two ways, both of them apply hist() and text() to Amount
>> split
>> > > > by Date. The return value of hist is saved because it's a list with
>> > > > members the histogram's bars midpoints and the counts. Those are
>> used
>> > to
>> > > > know where to put the text labels.
>> > > > A vector lbls is created to get rid of counts of zero.
>> > > >
>> > > > The main difference between the two ways is the histogram's titles.
>> > > >
>> > > >
>> > > > old_par <- par(mfrow = c(1, 3))
>> > > > h_list <- with(datasetregs, tapply(Amount, Date, function(x){
>> > > >    h <- hist(x)
>> > > >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>> > > >    text(h$mids, h$counts/2, labels = lbls)
>> > > > }))
>> > > > par(old_par)
>> > > >
>> > > >
>> > > >
>> > > > old_par <- par(mfrow = c(1, 3))
>> > > > sp <- split(datasetregs, datasetregs$Date)
>> > > > h_list <- lapply(seq_along(sp), function(i){
>> > > >    hist_title <- paste("Histogram of", names(sp)[i])
>> > > >    h <- hist(sp[[i]]$Amount, main = hist_title)
>> > > >    lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>> > > >    text(h$mids, h$counts/2, labels = lbls)
>> > > > })
>> > > > par(old_par)
>> > > >
>> > > >
>> > > > Hope this helps,
>> > > >
>> > > > Rui Barradas
>> > > >
>> > > > ?s 23:16 de 16/08/21, Paul Bernal escreveu:
>> > > > > Dear Rui,
>> > > > >
>> > > > > The hist() function comes from the graphics package, from what I
>> > could
>> > > > > see. The thing is that I want to divide the Amount column into
>> > several
>> > > > > bins and then generate three different histograms, one for each AF
>> > > > > period (AF refers to fiscal years). As you can see, the data
>> contains
>> > > > > three fiscal years (2017, 2020 and 2021). I want to see the
>> > percentage
>> > > > > of cases that fall into different amount categories, from 15,000
>> and
>> > > > > below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
>> > > > >
>> > > > > Thanks for your kind help.
>> > > > >
>> > > > > Paul
>> > > > >
>> > > > > El lun, 16 ago 2021 a las 17:07, Rui Barradas (<
>> ruipbarradas at sapo.pt
>> > > > > <mailto:ruipbarradas at sapo.pt>>) escribi?:
>> > > > >
>> > > > >     Hello,
>> > > > >
>> > > > >     The function Hist comes from what package?
>> > > > >
>> > > > >     Are you sure you don't want a bar plot?
>> > > > >
>> > > > >
>> > > > >     agg <- aggregate(Amount ~ Date, datasetregs, sum)
>> > > > >     bp <- barplot(Amount ~ Date, agg)
>> > > > >     with(agg, text(bp, Amount/2, labels = Amount))
>> > > > >
>> > > > >
>> > > > >     Hope this helps,
>> > > > >
>> > > > >     Rui Barradas
>> > > > >
>> > > > >     ?s 22:54 de 16/08/21, Paul Bernal escreveu:
>> > > > >      > Hello everyone,
>> > > > >      >
>> > > > >      > I am currently working with R version 4.1.0 and I am
>> trying to
>> > > > >     include
>> > > > >      > (inside the columns of the histogram), the percentage
>> > > > >     distribution and I
>> > > > >      > want to generate three histograms, one for each fiscal year
>> > (in
>> > > > >     the Date
>> > > > >      > column, there are three fiscal year AF 2017, AF 2020 and AF
>> > > > >     2021). However,
>> > > > >      > I can?t seem to accomplish this.
>> > > > >      >
>> > > > >      > Here is my data:
>> > > > >      >
>> > > > >      > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>> 2L,
>> > > > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> > 2L,
>> > > > >      > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> > 2L,
>> > > > >      > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> > 3L,
>> > > > >      > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> > 3L,
>> > > > >      > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
>> > class =
>> > > > >      > "factor"),
>> > > > >      >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
>> > 40200,
>> > > > >      >      15000, 35000, 35100, 20300, 40100, 15000, 67100,
>> 17100,
>> > > > 15000,
>> > > > >      >      15000, 50100, 35100, 15000, 15000, 15000, 15000,
>> 15000,
>> > > > 15000,
>> > > > >      >      15000, 15000, 15000, 15000, 15000, 15000, 15000,
>> 15000,
>> > > > 15000,
>> > > > >      >      15000, 15000, 20100, 15000, 15000, 15000, 15000,
>> 15000,
>> > > > 15000,
>> > > > >      >      16600, 15000, 15000, 15700, 15000, 15000, 15000,
>> 15000,
>> > > > 15000,
>> > > > >      >      15000, 15000, 15000, 15000, 20200, 21400, 25100,
>> 15000,
>> > > > 15000,
>> > > > >      >      15000, 15000, 15000, 15000, 25600, 15000, 15000,
>> 15000,
>> > > > 15000,
>> > > > >      >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
>> > class
>> > > > =
>> > > > >      > "data.frame")
>> > > > >      >
>> > > > >      > I would like to modify the following script:
>> > > > >      >
>> > > > >      >> with(datasetregs, Hist(Amount, groups=Date,
>> > scale="frequency",
>> > > > >      > +   breaks="Sturges", col="darkgray"))
>> > > > >      >
>> > > > >      > #The only thing missing here are the percentages
>> > corresponding to
>> > > > >     each bin
>> > > > >      > (I would like to see the percentages inside each column,
>> or on
>> > > > >     top outside
>> > > > >      > if possible)
>> > > > >      >
>> > > > >      > Any help will be greatly appreciated.
>> > > > >      >
>> > > > >      > Best regards,
>> > > > >      >
>> > > > >      > Paul.
>> > > > >      >
>> > > > >      >       [[alternative HTML version deleted]]
>> > > > >      >
>> > > > >      > ______________________________________________
>> > > > >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>> > list
>> > > > >     -- To UNSUBSCRIBE and more, see
>> > > > >      > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > >     <https://stat.ethz.ch/mailman/listinfo/r-help>
>> > > > >      > PLEASE do read the posting guide
>> > > > >     http://www.R-project.org/posting-guide.html
>> > > > >     <http://www.R-project.org/posting-guide.html>
>> > > > >      > and provide commented, minimal, self-contained,
>> reproducible
>> > code.
>> > > > >      >
>> > > > >
>> > > >
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Tue Aug 17 12:25:23 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Tue, 17 Aug 2021 12:25:23 +0200
Subject: [R] Rolling 7 day incidence
Message-ID: <sfg2qo$env$1@ciao.gmane.io>

Hi,

I am loading the coronavirus dataset everyday which looks something like:


	 as_tibble(coronavirus) %>%
		 filter(country=="Namibia" & type=="confirmed") %>%
		 arrange(desc(date)) %>%
		 print(n=10)

	 # A tibble: 573 ? 7
		 date       province country   lat  long type      cases
		 <date>     <chr>    <chr>   <dbl> <dbl> <chr>     <dbl>
	  1 2021-08-16 ""       Namibia -23.0  18.5 confirmed    76
	  2 2021-08-15 ""       Namibia -23.0  18.5 confirmed   242
	  3 2021-08-14 ""       Namibia -23.0  18.5 confirmed   130
	  4 2021-08-13 ""       Namibia -23.0  18.5 confirmed   280
	  5 2021-08-12 ""       Namibia -23.0  18.5 confirmed   214
	  6 2021-08-11 ""       Namibia -23.0  18.5 confirmed    96
	  7 2021-08-10 ""       Namibia -23.0  18.5 confirmed   304
	  8 2021-08-09 ""       Namibia -23.0  18.5 confirmed   160
	  9 2021-08-08 ""       Namibia -23.0  18.5 confirmed   229
	 10 2021-08-07 ""       Namibia -23.0  18.5 confirmed   319
	 # ? with 563 more rows

How do I do a rolling 7 day incidence (ie sum the cases over 7 days) but
rolling, ie from the last day to 7 (or 6?)  days before the end of the
dataset, so I get pairs of date/7-Day-Incidence?

I know it's probably re-inventing the plot as it were but I can't find
R code to do that.

I want to plot it per 100000 but that I can do.

greetings, el


-- 
To email me replace 'nospam' with 'el'


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Aug 17 12:46:19 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 17 Aug 2021 10:46:19 +0000
Subject: [R] Rolling 7 day incidence
In-Reply-To: <sfg2qo$env$1@ciao.gmane.io>
References: <sfg2qo$env$1@ciao.gmane.io>
Message-ID: <5c953a87cabe466bbca7516d26788434@SRVEXCHCM1302.precheza.cz>

Hi.

There are several ways how to do it. You could find them easily using Google. e.g.

https://stackoverflow.com/questions/19200841/consecutive-rolling-sums-in-a-vector-in-r

where you find several options.

Cheers
Petr



> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Eberhard
> Lisse
> Sent: Tuesday, August 17, 2021 12:25 PM
> To: r-help at r-project.org
> Subject: [R] Rolling 7 day incidence
> 
> Hi,
> 
> I am loading the coronavirus dataset everyday which looks something like:
> 
> 
> 	 as_tibble(coronavirus) %>%
> 		 filter(country=="Namibia" & type=="confirmed") %>%
> 		 arrange(desc(date)) %>%
> 		 print(n=10)
> 
> 	 # A tibble: 573 ? 7
> 		 date       province country   lat  long type      cases
> 		 <date>     <chr>    <chr>   <dbl> <dbl> <chr>     <dbl>
> 	  1 2021-08-16 ""       Namibia -23.0  18.5 confirmed    76
> 	  2 2021-08-15 ""       Namibia -23.0  18.5 confirmed   242
> 	  3 2021-08-14 ""       Namibia -23.0  18.5 confirmed   130
> 	  4 2021-08-13 ""       Namibia -23.0  18.5 confirmed   280
> 	  5 2021-08-12 ""       Namibia -23.0  18.5 confirmed   214
> 	  6 2021-08-11 ""       Namibia -23.0  18.5 confirmed    96
> 	  7 2021-08-10 ""       Namibia -23.0  18.5 confirmed   304
> 	  8 2021-08-09 ""       Namibia -23.0  18.5 confirmed   160
> 	  9 2021-08-08 ""       Namibia -23.0  18.5 confirmed   229
> 	 10 2021-08-07 ""       Namibia -23.0  18.5 confirmed   319
> 	 # ? with 563 more rows
> 
> How do I do a rolling 7 day incidence (ie sum the cases over 7 days) but
> rolling, ie from the last day to 7 (or 6?)  days before the end of the dataset, so
> I get pairs of date/7-Day-Incidence?
> 
> I know it's probably re-inventing the plot as it were but I can't find R code to
> do that.
> 
> I want to plot it per 100000 but that I can do.
> 
> greetings, el
> 
> 
> --
> To email me replace 'nospam' with 'el'
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 17 13:09:49 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 17 Aug 2021 12:09:49 +0100
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
 <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
 <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
Message-ID: <d8b7b7f5-4076-a5e7-42fc-d7d2be85d755@sapo.pt>

Hello,

I had forgotten about plot.histogram, it does make everything simpler.
To have percentages on the bars, in the code below I use package scales.

Note that it seems to me that you do not want densities, to have 
percentages,  the proportions of counts are given by any of

h$counts/sum(h$counts)
h$density*diff(h$breaks)



# One histogram for all dates
h <- hist(datasetregs$Amount, plot = FALSE)
plot(h, labels = scales::percent(h$counts/sum(h$counts)),
      ylim = c(0, 1.1*max(h$counts)))



# Histograms by date
sp <- split(datasetregs, datasetregs$Date)
old_par <- par(mfrow = c(1, 3))
h_list <- lapply(seq_along(sp), function(i){
   hist_title <- paste("Histogram of", names(sp)[i])
   h <- hist(sp[[i]]$Amount, plot = FALSE)
   plot(h, main = hist_title, xlab = "Amount",
        labels = scales::percent(h$counts/sum(h$counts)),
        ylim = c(0, 1.1*max(h$counts)))
})
par(old_par)


Hope this helps,

Rui Barradas

?s 01:49 de 17/08/21, Bert Gunter escreveu:
> I may well misunderstand, but proffered solutions seem more complicated
> than necessary.
> Note that the return of hist() can be saved as a list of class "histogram"
> and then plotted with  plot.histogram(), which already has a "labels"
> argument that seems to be what you want. A simple example is"
> 
> dat <- runif(50, 0, 10)
> myhist <- hist(dat, freq = TRUE, breaks ="Sturges")
> 
> plot(myhist, col = "darkgray",
>       labels = as.character(round(myhist$density*100,1) ),
>       ylim = c(0, 1.1*max(myhist$counts)))
> ## note that this is plot.histogram because myhist has class "histogram"
> 
> Note that I expanded the y axis a bit to be sure to include the labels. You
> can, of course, plot your separate years as Rui has indicated or via e.g.
> ?layout.
> 
> Apologies if I have misunderstood. Just ignore this in that case.
> Otherwise, I leave it to you to fill in details.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Aug 16, 2021 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
>> Dear Jim,
>>
>> Thank you so much for your kind reply. Yes, this is what I am looking for,
>> however, can?t see clearly how the bars correspond to the bins in the
>> x-axis. Maybe there is a way to align the amounts so that they match the
>> columns, sorry if I sound picky, but just want to learn if there is a way
>> to accomplish this.
>>
>> Best regards,
>>
>> Paul
>>
>> El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
>> escribi?:
>>
>>> Hi Paul,
>>> I just worked out your first request:
>>>
>>> datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>>> 2L,
>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>> 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
>>> "factor"),
>>>      Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
>>>      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
>>>      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
>>>      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>>>      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
>>>      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
>>>      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
>>>      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
>>>      15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
>>> "data.frame")
>>> histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
>>>   breaks="Sturges", col="darkgray"))
>>> library(plotrix)
>>> histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
>>> barlabels(histval$mids,histval$counts,histpcts)
>>>
>>> I think that's what you asked for:
>>>
>>> Jim
>>>
>>> On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>>
>>>> This is way better, now, how could I put the frequency labels in the
>>>> columns as a percentage, instead of presenting them as counts?
>>>>
>>>> Thank you so much.
>>>>
>>>> Paul
>>>>
>>>> El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
>>>> escribi?:
>>>>
>>>>> Hello,
>>>>>
>>>>> You forgot to cc the list.
>>>>>
>>>>> Here are two ways, both of them apply hist() and text() to Amount
>> split
>>>>> by Date. The return value of hist is saved because it's a list with
>>>>> members the histogram's bars midpoints and the counts. Those are used
>>> to
>>>>> know where to put the text labels.
>>>>> A vector lbls is created to get rid of counts of zero.
>>>>>
>>>>> The main difference between the two ways is the histogram's titles.
>>>>>
>>>>>
>>>>> old_par <- par(mfrow = c(1, 3))
>>>>> h_list <- with(datasetregs, tapply(Amount, Date, function(x){
>>>>>     h <- hist(x)
>>>>>     lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>>>>>     text(h$mids, h$counts/2, labels = lbls)
>>>>> }))
>>>>> par(old_par)
>>>>>
>>>>>
>>>>>
>>>>> old_par <- par(mfrow = c(1, 3))
>>>>> sp <- split(datasetregs, datasetregs$Date)
>>>>> h_list <- lapply(seq_along(sp), function(i){
>>>>>     hist_title <- paste("Histogram of", names(sp)[i])
>>>>>     h <- hist(sp[[i]]$Amount, main = hist_title)
>>>>>     lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>>>>>     text(h$mids, h$counts/2, labels = lbls)
>>>>> })
>>>>> par(old_par)
>>>>>
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>> ?s 23:16 de 16/08/21, Paul Bernal escreveu:
>>>>>> Dear Rui,
>>>>>>
>>>>>> The hist() function comes from the graphics package, from what I
>>> could
>>>>>> see. The thing is that I want to divide the Amount column into
>>> several
>>>>>> bins and then generate three different histograms, one for each AF
>>>>>> period (AF refers to fiscal years). As you can see, the data
>> contains
>>>>>> three fiscal years (2017, 2020 and 2021). I want to see the
>>> percentage
>>>>>> of cases that fall into different amount categories, from 15,000
>> and
>>>>>> below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
>>>>>>
>>>>>> Thanks for your kind help.
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>> El lun, 16 ago 2021 a las 17:07, Rui Barradas (<
>> ruipbarradas at sapo.pt
>>>>>> <mailto:ruipbarradas at sapo.pt>>) escribi?:
>>>>>>
>>>>>>      Hello,
>>>>>>
>>>>>>      The function Hist comes from what package?
>>>>>>
>>>>>>      Are you sure you don't want a bar plot?
>>>>>>
>>>>>>
>>>>>>      agg <- aggregate(Amount ~ Date, datasetregs, sum)
>>>>>>      bp <- barplot(Amount ~ Date, agg)
>>>>>>      with(agg, text(bp, Amount/2, labels = Amount))
>>>>>>
>>>>>>
>>>>>>      Hope this helps,
>>>>>>
>>>>>>      Rui Barradas
>>>>>>
>>>>>>      ?s 22:54 de 16/08/21, Paul Bernal escreveu:
>>>>>>       > Hello everyone,
>>>>>>       >
>>>>>>       > I am currently working with R version 4.1.0 and I am trying
>> to
>>>>>>      include
>>>>>>       > (inside the columns of the histogram), the percentage
>>>>>>      distribution and I
>>>>>>       > want to generate three histograms, one for each fiscal year
>>> (in
>>>>>>      the Date
>>>>>>       > column, there are three fiscal year AF 2017, AF 2020 and AF
>>>>>>      2021). However,
>>>>>>       > I can?t seem to accomplish this.
>>>>>>       >
>>>>>>       > Here is my data:
>>>>>>       >
>>>>>>       > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>> 2L,
>>>>>>       > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>> 2L,
>>>>>>       > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>> 2L,
>>>>>>       > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>> 3L,
>>>>>>       > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>> 3L,
>>>>>>       > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
>>> class =
>>>>>>       > "factor"),
>>>>>>       >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
>>> 40200,
>>>>>>       >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
>>>>> 15000,
>>>>>>       >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
>>>>> 15000,
>>>>>>       >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>>>>> 15000,
>>>>>>       >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
>>>>> 15000,
>>>>>>       >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
>>>>> 15000,
>>>>>>       >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
>>>>> 15000,
>>>>>>       >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
>>>>> 15000,
>>>>>>       >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
>>> class
>>>>> =
>>>>>>       > "data.frame")
>>>>>>       >
>>>>>>       > I would like to modify the following script:
>>>>>>       >
>>>>>>       >> with(datasetregs, Hist(Amount, groups=Date,
>>> scale="frequency",
>>>>>>       > +   breaks="Sturges", col="darkgray"))
>>>>>>       >
>>>>>>       > #The only thing missing here are the percentages
>>> corresponding to
>>>>>>      each bin
>>>>>>       > (I would like to see the percentages inside each column, or
>> on
>>>>>>      top outside
>>>>>>       > if possible)
>>>>>>       >
>>>>>>       > Any help will be greatly appreciated.
>>>>>>       >
>>>>>>       > Best regards,
>>>>>>       >
>>>>>>       > Paul.
>>>>>>       >
>>>>>>       >       [[alternative HTML version deleted]]
>>>>>>       >
>>>>>>       > ______________________________________________
>>>>>>       > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>> list
>>>>>>      -- To UNSUBSCRIBE and more, see
>>>>>>       > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>      <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>       > PLEASE do read the posting guide
>>>>>>      http://www.R-project.org/posting-guide.html
>>>>>>      <http://www.R-project.org/posting-guide.html>
>>>>>>       > and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>       >
>>>>>>
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From no@p@m @end|ng |rom ||@@e@NA  Tue Aug 17 14:30:18 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Tue, 17 Aug 2021 14:30:18 +0200
Subject: [R] Rolling 7 day incidence
In-Reply-To: <5c953a87cabe466bbca7516d26788434@SRVEXCHCM1302.precheza.cz>
References: <sfg2qo$env$1@ciao.gmane.io>
 <5c953a87cabe466bbca7516d26788434@SRVEXCHCM1302.precheza.cz>
Message-ID: <sfga4v$tpp$1@ciao.gmane.io>

Petr,

thank you very much, this pointed me in the right direction (to refine
my Google search :-)-O):

	 library(tidyverse)
	 library(coronavirus)
	 library(zoo)

	 as_tibble(coronavirus) %>%
		 filter(country=='Namibia' & type=="confirmed") %>%
		 mutate(rollsum = rollapplyr(cases, 7, sum, partial=TRUE)) %>%
		 arrange(desc(date)) %>%
		 mutate(R7=rollsum / 25.4 )  %>%
		 select(date,R7)

gives me something like

	 # A tibble: 573 ? 2
		 date          R7
		 <date>     <dbl>
	  1 2021-08-16  52.8
	  2 2021-08-15  56.1
	  3 2021-08-14  55.6
	  4 2021-08-13  63.1
	  5 2021-08-12  62.8
	  6 2021-08-11  63.7
	  7 2021-08-10  67.3
	  8 2021-08-09  69.3
	  9 2021-08-08  69.2
	 10 2021-08-07  74.5
	 # ? with 563 more rows

which seems to be correct :-)-O so I can now play with ggplot2 over the
weekend :-)-O

greetings, el

On 17/08/2021 12:46, PIKAL Petr wrote:
> Hi.
> 
> There are several ways how to do it.  You could find them easily using
> Google.  e.g.
> 
> https://stackoverflow.com/questions/19200841/consecutive-rolling-sums-in-a-vector-in-r
> 
> where you find several options.
> 
> Cheers
> Petr
[...]


-- 
To email me replace 'nospam' with 'el'


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Aug 17 15:09:50 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 17 Aug 2021 13:09:50 +0000
Subject: [R] Rolling 7 day incidence
In-Reply-To: <sfga4v$tpp$1@ciao.gmane.io>
References: <sfg2qo$env$1@ciao.gmane.io>
 <5c953a87cabe466bbca7516d26788434@SRVEXCHCM1302.precheza.cz>
 <sfga4v$tpp$1@ciao.gmane.io>
Message-ID: <ec15f4487c4b490382d5d465e87545ef@SRVEXCHCM1302.precheza.cz>

Hi

You're wellcome. You probably know 

https://www.repidemicsconsortium.org/projects/

as a collection of tools for epidemy evaluation.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Eberhard
> Lisse
> Sent: Tuesday, August 17, 2021 2:30 PM
> To: r-help at r-project.org
> Subject: Re: [R] Rolling 7 day incidence
> 
> Petr,
> 
> thank you very much, this pointed me in the right direction (to refine my
> Google search :-)-O):
> 
> 	 library(tidyverse)
> 	 library(coronavirus)
> 	 library(zoo)
> 
> 	 as_tibble(coronavirus) %>%
> 		 filter(country=='Namibia' & type=="confirmed") %>%
> 		 mutate(rollsum = rollapplyr(cases, 7, sum, partial=TRUE))
> %>%
> 		 arrange(desc(date)) %>%
> 		 mutate(R7=rollsum / 25.4 )  %>%
> 		 select(date,R7)
> 
> gives me something like
> 
> 	 # A tibble: 573 ? 2
> 		 date          R7
> 		 <date>     <dbl>
> 	  1 2021-08-16  52.8
> 	  2 2021-08-15  56.1
> 	  3 2021-08-14  55.6
> 	  4 2021-08-13  63.1
> 	  5 2021-08-12  62.8
> 	  6 2021-08-11  63.7
> 	  7 2021-08-10  67.3
> 	  8 2021-08-09  69.3
> 	  9 2021-08-08  69.2
> 	 10 2021-08-07  74.5
> 	 # ? with 563 more rows
> 
> which seems to be correct :-)-O so I can now play with ggplot2 over the
> weekend :-)-O
> 
> greetings, el
> 
> On 17/08/2021 12:46, PIKAL Petr wrote:
> > Hi.
> >
> > There are several ways how to do it.  You could find them easily using
> > Google.  e.g.
> >
> > https://stackoverflow.com/questions/19200841/consecutive-rolling-sums-
> > in-a-vector-in-r
> >
> > where you find several options.
> >
> > Cheers
> > Petr
> [...]
> 
> 
> --
> To email me replace 'nospam' with 'el'
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From g@be||@@ @end|ng |rom uq@net@@u  Tue Aug 17 11:50:54 2021
From: g@be||@@ @end|ng |rom uq@net@@u (George Bellas)
Date: Tue, 17 Aug 2021 09:50:54 +0000
Subject: [R] Cars2
Message-ID: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>

Hi R Core team,

I was looking at this link for data sets,

https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html

and wanted to use cars2. I found cars2 earlier this week, but now when I look at the list, it's not there!

Can you tell me what happened to cars2? I have tried calling it on my version of R4.0.5 (backdated so Shiny works), but I can't find it anymore.

Thanks,
George


	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Aug 17 19:32:05 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 17 Aug 2021 19:32:05 +0200
Subject: [R] Cars2
In-Reply-To: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>
References: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>
Message-ID: <20210817193205.60a65b0e@trisector>

On Tue, 17 Aug 2021 09:50:54 +0000
George Bellas <g.bellas at uq.net.au> wrote:

> I found cars2 earlier this week, but now when I look at the list,
> it's not there!

That sounds like a dataset provided by a contributed package. Does
https://search.r-project.org/ help find it again?

-- 
Best regards,
Ivan

> 	[[alternative HTML version deleted]]

P.S. When you compose hybrid HTML + plain text e-mail, the HTML version
gets stripped by the mailing list software and everyone gets the plain
text version, which may look wildly different from the HTML original.
Please stick to plain text e-mail to avoid nasty surprises.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 17 20:28:06 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Aug 2021 11:28:06 -0700
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <d8b7b7f5-4076-a5e7-42fc-d7d2be85d755@sapo.pt>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
 <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
 <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
 <d8b7b7f5-4076-a5e7-42fc-d7d2be85d755@sapo.pt>
Message-ID: <CAGxFJbTkSOCCnZfFioib0nEPVm1GVgNLP-Ark3=hLT+H5jCFRg@mail.gmail.com>

Inline below.



On Tue, Aug 17, 2021 at 4:09 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I had forgotten about plot.histogram, it does make everything simpler.
> To have percentages on the bars, in the code below I use package scales.
>
> Note that it seems to me that you do not want densities, to have
> percentages,  the proportions of counts are given by any of

Under the default of equal width bins -- which is what Sturges gives
if I read the docs correctly -- since the densities sum to 1, they are
already the proportion of counts in each histogram bin, no?

-- Bert


>
> h$counts/sum(h$counts)
> h$density*diff(h$breaks)
>
>
>
> # One histogram for all dates
> h <- hist(datasetregs$Amount, plot = FALSE)
> plot(h, labels = scales::percent(h$counts/sum(h$counts)),
>       ylim = c(0, 1.1*max(h$counts)))
>
>
>
> # Histograms by date
> sp <- split(datasetregs, datasetregs$Date)
> old_par <- par(mfrow = c(1, 3))
> h_list <- lapply(seq_along(sp), function(i){
>    hist_title <- paste("Histogram of", names(sp)[i])
>    h <- hist(sp[[i]]$Amount, plot = FALSE)
>    plot(h, main = hist_title, xlab = "Amount",
>         labels = scales::percent(h$counts/sum(h$counts)),
>         ylim = c(0, 1.1*max(h$counts)))
> })
> par(old_par)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 01:49 de 17/08/21, Bert Gunter escreveu:
> > I may well misunderstand, but proffered solutions seem more complicated
> > than necessary.
> > Note that the return of hist() can be saved as a list of class "histogram"
> > and then plotted with  plot.histogram(), which already has a "labels"
> > argument that seems to be what you want. A simple example is"
> >
> > dat <- runif(50, 0, 10)
> > myhist <- hist(dat, freq = TRUE, breaks ="Sturges")
> >
> > plot(myhist, col = "darkgray",
> >       labels = as.character(round(myhist$density*100,1) ),
> >       ylim = c(0, 1.1*max(myhist$counts)))
> > ## note that this is plot.histogram because myhist has class "histogram"
> >
> > Note that I expanded the y axis a bit to be sure to include the labels. You
> > can, of course, plot your separate years as Rui has indicated or via e.g.
> > ?layout.
> >
> > Apologies if I have misunderstood. Just ignore this in that case.
> > Otherwise, I leave it to you to fill in details.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Aug 16, 2021 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> >> Dear Jim,
> >>
> >> Thank you so much for your kind reply. Yes, this is what I am looking for,
> >> however, can?t see clearly how the bars correspond to the bins in the
> >> x-axis. Maybe there is a way to align the amounts so that they match the
> >> columns, sorry if I sound picky, but just want to learn if there is a way
> >> to accomplish this.
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >> El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
> >> escribi?:
> >>
> >>> Hi Paul,
> >>> I just worked out your first request:
> >>>
> >>> datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> >>> 2L,
> >>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>> 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> >>> "factor"),
> >>>      Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
> >>>      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
> >>>      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
> >>>      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
> >>>      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
> >>>      15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
> >>> "data.frame")
> >>> histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
> >>>   breaks="Sturges", col="darkgray"))
> >>> library(plotrix)
> >>> histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
> >>> barlabels(histval$mids,histval$counts,histpcts)
> >>>
> >>> I think that's what you asked for:
> >>>
> >>> Jim
> >>>
> >>> On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
> >>> wrote:
> >>>>
> >>>> This is way better, now, how could I put the frequency labels in the
> >>>> columns as a percentage, instead of presenting them as counts?
> >>>>
> >>>> Thank you so much.
> >>>>
> >>>> Paul
> >>>>
> >>>> El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
> >>>> escribi?:
> >>>>
> >>>>> Hello,
> >>>>>
> >>>>> You forgot to cc the list.
> >>>>>
> >>>>> Here are two ways, both of them apply hist() and text() to Amount
> >> split
> >>>>> by Date. The return value of hist is saved because it's a list with
> >>>>> members the histogram's bars midpoints and the counts. Those are used
> >>> to
> >>>>> know where to put the text labels.
> >>>>> A vector lbls is created to get rid of counts of zero.
> >>>>>
> >>>>> The main difference between the two ways is the histogram's titles.
> >>>>>
> >>>>>
> >>>>> old_par <- par(mfrow = c(1, 3))
> >>>>> h_list <- with(datasetregs, tapply(Amount, Date, function(x){
> >>>>>     h <- hist(x)
> >>>>>     lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> >>>>>     text(h$mids, h$counts/2, labels = lbls)
> >>>>> }))
> >>>>> par(old_par)
> >>>>>
> >>>>>
> >>>>>
> >>>>> old_par <- par(mfrow = c(1, 3))
> >>>>> sp <- split(datasetregs, datasetregs$Date)
> >>>>> h_list <- lapply(seq_along(sp), function(i){
> >>>>>     hist_title <- paste("Histogram of", names(sp)[i])
> >>>>>     h <- hist(sp[[i]]$Amount, main = hist_title)
> >>>>>     lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> >>>>>     text(h$mids, h$counts/2, labels = lbls)
> >>>>> })
> >>>>> par(old_par)
> >>>>>
> >>>>>
> >>>>> Hope this helps,
> >>>>>
> >>>>> Rui Barradas
> >>>>>
> >>>>> ?s 23:16 de 16/08/21, Paul Bernal escreveu:
> >>>>>> Dear Rui,
> >>>>>>
> >>>>>> The hist() function comes from the graphics package, from what I
> >>> could
> >>>>>> see. The thing is that I want to divide the Amount column into
> >>> several
> >>>>>> bins and then generate three different histograms, one for each AF
> >>>>>> period (AF refers to fiscal years). As you can see, the data
> >> contains
> >>>>>> three fiscal years (2017, 2020 and 2021). I want to see the
> >>> percentage
> >>>>>> of cases that fall into different amount categories, from 15,000
> >> and
> >>>>>> below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> >>>>>>
> >>>>>> Thanks for your kind help.
> >>>>>>
> >>>>>> Paul
> >>>>>>
> >>>>>> El lun, 16 ago 2021 a las 17:07, Rui Barradas (<
> >> ruipbarradas at sapo.pt
> >>>>>> <mailto:ruipbarradas at sapo.pt>>) escribi?:
> >>>>>>
> >>>>>>      Hello,
> >>>>>>
> >>>>>>      The function Hist comes from what package?
> >>>>>>
> >>>>>>      Are you sure you don't want a bar plot?
> >>>>>>
> >>>>>>
> >>>>>>      agg <- aggregate(Amount ~ Date, datasetregs, sum)
> >>>>>>      bp <- barplot(Amount ~ Date, agg)
> >>>>>>      with(agg, text(bp, Amount/2, labels = Amount))
> >>>>>>
> >>>>>>
> >>>>>>      Hope this helps,
> >>>>>>
> >>>>>>      Rui Barradas
> >>>>>>
> >>>>>>      ?s 22:54 de 16/08/21, Paul Bernal escreveu:
> >>>>>>       > Hello everyone,
> >>>>>>       >
> >>>>>>       > I am currently working with R version 4.1.0 and I am trying
> >> to
> >>>>>>      include
> >>>>>>       > (inside the columns of the histogram), the percentage
> >>>>>>      distribution and I
> >>>>>>       > want to generate three histograms, one for each fiscal year
> >>> (in
> >>>>>>      the Date
> >>>>>>       > column, there are three fiscal year AF 2017, AF 2020 and AF
> >>>>>>      2021). However,
> >>>>>>       > I can?t seem to accomplish this.
> >>>>>>       >
> >>>>>>       > Here is my data:
> >>>>>>       >
> >>>>>>       > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> >> 2L,
> >>>>>>       > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>> 2L,
> >>>>>>       > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>> 2L,
> >>>>>>       > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>> 3L,
> >>>>>>       > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>> 3L,
> >>>>>>       > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
> >>> class =
> >>>>>>       > "factor"),
> >>>>>>       >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
> >>> 40200,
> >>>>>>       >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
> >>>>> 15000,
> >>>>>>       >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
> >>>>> 15000,
> >>>>>>       >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>>> 15000,
> >>>>>>       >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
> >>>>> 15000,
> >>>>>>       >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
> >>>>> 15000,
> >>>>>>       >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
> >>>>> 15000,
> >>>>>>       >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
> >>>>> 15000,
> >>>>>>       >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
> >>> class
> >>>>> =
> >>>>>>       > "data.frame")
> >>>>>>       >
> >>>>>>       > I would like to modify the following script:
> >>>>>>       >
> >>>>>>       >> with(datasetregs, Hist(Amount, groups=Date,
> >>> scale="frequency",
> >>>>>>       > +   breaks="Sturges", col="darkgray"))
> >>>>>>       >
> >>>>>>       > #The only thing missing here are the percentages
> >>> corresponding to
> >>>>>>      each bin
> >>>>>>       > (I would like to see the percentages inside each column, or
> >> on
> >>>>>>      top outside
> >>>>>>       > if possible)
> >>>>>>       >
> >>>>>>       > Any help will be greatly appreciated.
> >>>>>>       >
> >>>>>>       > Best regards,
> >>>>>>       >
> >>>>>>       > Paul.
> >>>>>>       >
> >>>>>>       >       [[alternative HTML version deleted]]
> >>>>>>       >
> >>>>>>       > ______________________________________________
> >>>>>>       > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> >>> list
> >>>>>>      -- To UNSUBSCRIBE and more, see
> >>>>>>       > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>      <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>>>>       > PLEASE do read the posting guide
> >>>>>>      http://www.R-project.org/posting-guide.html
> >>>>>>      <http://www.R-project.org/posting-guide.html>
> >>>>>>       > and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>       >
> >>>>>>
> >>>>>
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 17 20:51:53 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 17 Aug 2021 19:51:53 +0100
Subject: [R] Cars2
In-Reply-To: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>
References: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>
Message-ID: <3386880d-748d-8dff-8b74-2a4f41fdc33d@sapo.pt>

Hello,

That seems to be a subset of dataset cars.
Are you sure that it wasn't created before by code?


Hope this helps,

Rui Barradas

?s 10:50 de 17/08/21, George Bellas escreveu:
> Hi R Core team,
> 
> I was looking at this link for data sets,
> 
> https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html
> 
> and wanted to use cars2. I found cars2 earlier this week, but now when I look at the list, it's not there!
> 
> Can you tell me what happened to cars2? I have tried calling it on my version of R4.0.5 (backdated so Shiny works), but I can't find it anymore.
> 
> Thanks,
> George
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 17 21:03:47 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 17 Aug 2021 20:03:47 +0100
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <CAGxFJbTkSOCCnZfFioib0nEPVm1GVgNLP-Ark3=hLT+H5jCFRg@mail.gmail.com>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
 <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
 <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
 <d8b7b7f5-4076-a5e7-42fc-d7d2be85d755@sapo.pt>
 <CAGxFJbTkSOCCnZfFioib0nEPVm1GVgNLP-Ark3=hLT+H5jCFRg@mail.gmail.com>
Message-ID: <18d74dff-2511-93c8-02d8-d46da5a4bc0b@sapo.pt>

Hello,



?s 19:28 de 17/08/21, Bert Gunter escreveu:
> Inline below.
> 
> 
> 
> On Tue, Aug 17, 2021 at 4:09 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> I had forgotten about plot.histogram, it does make everything simpler.
>> To have percentages on the bars, in the code below I use package scales.
>>
>> Note that it seems to me that you do not want densities, to have
>> percentages,  the proportions of counts are given by any of
> 
> Under the default of equal width bins -- which is what Sturges gives

Right.

> if I read the docs correctly -- since the densities sum to 1, 

The "densities" do not sum to 1. From ?hist, section Value:

density	
values f^(x[i]), as estimated density values. If all(diff(breaks) == 1), 
they are the relative frequencies counts/n and in general satisfy
sum[i; f^(x[i]) (b[i+1]-b[i])] = 1, where b[i] = breaks[i].


If all(diff(breaks) == 1) is FALSE, the density list member must be 
multiplied by diff(.$breaks)


h <- hist(datasetregs$Amount, plot = FALSE)
sum(h$density)
#[1] 1e-04
diff(h$breaks)
#[1] 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000
sum(h$density*diff(h$breaks))
#[1] 1


Hope this helps,

Rui Barradas

they are
> already the proportion of counts in each histogram bin, no?
> 
> -- Bert
> 
> 
>>
>> h$counts/sum(h$counts)
>> h$density*diff(h$breaks)
>>
>>
>>
>> # One histogram for all dates
>> h <- hist(datasetregs$Amount, plot = FALSE)
>> plot(h, labels = scales::percent(h$counts/sum(h$counts)),
>>        ylim = c(0, 1.1*max(h$counts)))
>>
>>
>>
>> # Histograms by date
>> sp <- split(datasetregs, datasetregs$Date)
>> old_par <- par(mfrow = c(1, 3))
>> h_list <- lapply(seq_along(sp), function(i){
>>     hist_title <- paste("Histogram of", names(sp)[i])
>>     h <- hist(sp[[i]]$Amount, plot = FALSE)
>>     plot(h, main = hist_title, xlab = "Amount",
>>          labels = scales::percent(h$counts/sum(h$counts)),
>>          ylim = c(0, 1.1*max(h$counts)))
>> })
>> par(old_par)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 01:49 de 17/08/21, Bert Gunter escreveu:
>>> I may well misunderstand, but proffered solutions seem more complicated
>>> than necessary.
>>> Note that the return of hist() can be saved as a list of class "histogram"
>>> and then plotted with  plot.histogram(), which already has a "labels"
>>> argument that seems to be what you want. A simple example is"
>>>
>>> dat <- runif(50, 0, 10)
>>> myhist <- hist(dat, freq = TRUE, breaks ="Sturges")
>>>
>>> plot(myhist, col = "darkgray",
>>>        labels = as.character(round(myhist$density*100,1) ),
>>>        ylim = c(0, 1.1*max(myhist$counts)))
>>> ## note that this is plot.histogram because myhist has class "histogram"
>>>
>>> Note that I expanded the y axis a bit to be sure to include the labels. You
>>> can, of course, plot your separate years as Rui has indicated or via e.g.
>>> ?layout.
>>>
>>> Apologies if I have misunderstood. Just ignore this in that case.
>>> Otherwise, I leave it to you to fill in details.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Aug 16, 2021 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>>>
>>>> Dear Jim,
>>>>
>>>> Thank you so much for your kind reply. Yes, this is what I am looking for,
>>>> however, can?t see clearly how the bars correspond to the bins in the
>>>> x-axis. Maybe there is a way to align the amounts so that they match the
>>>> columns, sorry if I sound picky, but just want to learn if there is a way
>>>> to accomplish this.
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>> El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
>>>> escribi?:
>>>>
>>>>> Hi Paul,
>>>>> I just worked out your first request:
>>>>>
>>>>> datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>>>>> 2L,
>>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>>>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>>>> 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
>>>>> "factor"),
>>>>>       Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
>>>>>       15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
>>>>>       15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
>>>>>       15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>>>>>       15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
>>>>>       16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
>>>>>       15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
>>>>>       15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
>>>>>       15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
>>>>> "data.frame")
>>>>> histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
>>>>>    breaks="Sturges", col="darkgray"))
>>>>> library(plotrix)
>>>>> histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
>>>>> barlabels(histval$mids,histval$counts,histpcts)
>>>>>
>>>>> I think that's what you asked for:
>>>>>
>>>>> Jim
>>>>>
>>>>> On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> This is way better, now, how could I put the frequency labels in the
>>>>>> columns as a percentage, instead of presenting them as counts?
>>>>>>
>>>>>> Thank you so much.
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>> El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
>>>>>> escribi?:
>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>> You forgot to cc the list.
>>>>>>>
>>>>>>> Here are two ways, both of them apply hist() and text() to Amount
>>>> split
>>>>>>> by Date. The return value of hist is saved because it's a list with
>>>>>>> members the histogram's bars midpoints and the counts. Those are used
>>>>> to
>>>>>>> know where to put the text labels.
>>>>>>> A vector lbls is created to get rid of counts of zero.
>>>>>>>
>>>>>>> The main difference between the two ways is the histogram's titles.
>>>>>>>
>>>>>>>
>>>>>>> old_par <- par(mfrow = c(1, 3))
>>>>>>> h_list <- with(datasetregs, tapply(Amount, Date, function(x){
>>>>>>>      h <- hist(x)
>>>>>>>      lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>>>>>>>      text(h$mids, h$counts/2, labels = lbls)
>>>>>>> }))
>>>>>>> par(old_par)
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> old_par <- par(mfrow = c(1, 3))
>>>>>>> sp <- split(datasetregs, datasetregs$Date)
>>>>>>> h_list <- lapply(seq_along(sp), function(i){
>>>>>>>      hist_title <- paste("Histogram of", names(sp)[i])
>>>>>>>      h <- hist(sp[[i]]$Amount, main = hist_title)
>>>>>>>      lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
>>>>>>>      text(h$mids, h$counts/2, labels = lbls)
>>>>>>> })
>>>>>>> par(old_par)
>>>>>>>
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> ?s 23:16 de 16/08/21, Paul Bernal escreveu:
>>>>>>>> Dear Rui,
>>>>>>>>
>>>>>>>> The hist() function comes from the graphics package, from what I
>>>>> could
>>>>>>>> see. The thing is that I want to divide the Amount column into
>>>>> several
>>>>>>>> bins and then generate three different histograms, one for each AF
>>>>>>>> period (AF refers to fiscal years). As you can see, the data
>>>> contains
>>>>>>>> three fiscal years (2017, 2020 and 2021). I want to see the
>>>>> percentage
>>>>>>>> of cases that fall into different amount categories, from 15,000
>>>> and
>>>>>>>> below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
>>>>>>>>
>>>>>>>> Thanks for your kind help.
>>>>>>>>
>>>>>>>> Paul
>>>>>>>>
>>>>>>>> El lun, 16 ago 2021 a las 17:07, Rui Barradas (<
>>>> ruipbarradas at sapo.pt
>>>>>>>> <mailto:ruipbarradas at sapo.pt>>) escribi?:
>>>>>>>>
>>>>>>>>       Hello,
>>>>>>>>
>>>>>>>>       The function Hist comes from what package?
>>>>>>>>
>>>>>>>>       Are you sure you don't want a bar plot?
>>>>>>>>
>>>>>>>>
>>>>>>>>       agg <- aggregate(Amount ~ Date, datasetregs, sum)
>>>>>>>>       bp <- barplot(Amount ~ Date, agg)
>>>>>>>>       with(agg, text(bp, Amount/2, labels = Amount))
>>>>>>>>
>>>>>>>>
>>>>>>>>       Hope this helps,
>>>>>>>>
>>>>>>>>       Rui Barradas
>>>>>>>>
>>>>>>>>       ?s 22:54 de 16/08/21, Paul Bernal escreveu:
>>>>>>>>        > Hello everyone,
>>>>>>>>        >
>>>>>>>>        > I am currently working with R version 4.1.0 and I am trying
>>>> to
>>>>>>>>       include
>>>>>>>>        > (inside the columns of the histogram), the percentage
>>>>>>>>       distribution and I
>>>>>>>>        > want to generate three histograms, one for each fiscal year
>>>>> (in
>>>>>>>>       the Date
>>>>>>>>        > column, there are three fiscal year AF 2017, AF 2020 and AF
>>>>>>>>       2021). However,
>>>>>>>>        > I can?t seem to accomplish this.
>>>>>>>>        >
>>>>>>>>        > Here is my data:
>>>>>>>>        >
>>>>>>>>        > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
>>>> 2L,
>>>>>>>>        > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>> 2L,
>>>>>>>>        > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>> 2L,
>>>>>>>>        > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>>>> 3L,
>>>>>>>>        > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>>>> 3L,
>>>>>>>>        > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
>>>>> class =
>>>>>>>>        > "factor"),
>>>>>>>>        >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
>>>>> 40200,
>>>>>>>>        >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
>>>>>>> 15000,
>>>>>>>>        >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
>>>>>>> 15000,
>>>>>>>>        >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
>>>>>>> 15000,
>>>>>>>>        >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
>>>>>>> 15000,
>>>>>>>>        >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
>>>>>>> 15000,
>>>>>>>>        >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
>>>>>>> 15000,
>>>>>>>>        >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
>>>>>>> 15000,
>>>>>>>>        >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
>>>>> class
>>>>>>> =
>>>>>>>>        > "data.frame")
>>>>>>>>        >
>>>>>>>>        > I would like to modify the following script:
>>>>>>>>        >
>>>>>>>>        >> with(datasetregs, Hist(Amount, groups=Date,
>>>>> scale="frequency",
>>>>>>>>        > +   breaks="Sturges", col="darkgray"))
>>>>>>>>        >
>>>>>>>>        > #The only thing missing here are the percentages
>>>>> corresponding to
>>>>>>>>       each bin
>>>>>>>>        > (I would like to see the percentages inside each column, or
>>>> on
>>>>>>>>       top outside
>>>>>>>>        > if possible)
>>>>>>>>        >
>>>>>>>>        > Any help will be greatly appreciated.
>>>>>>>>        >
>>>>>>>>        > Best regards,
>>>>>>>>        >
>>>>>>>>        > Paul.
>>>>>>>>        >
>>>>>>>>        >       [[alternative HTML version deleted]]
>>>>>>>>        >
>>>>>>>>        > ______________________________________________
>>>>>>>>        > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>>> list
>>>>>>>>       -- To UNSUBSCRIBE and more, see
>>>>>>>>        > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>        > PLEASE do read the posting guide
>>>>>>>>       http://www.R-project.org/posting-guide.html
>>>>>>>>       <http://www.R-project.org/posting-guide.html>
>>>>>>>>        > and provide commented, minimal, self-contained, reproducible
>>>>> code.
>>>>>>>>        >
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>>           [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From m@dsmh m@iii@g oii gm@ii@com  Mon Aug 16 18:55:50 2021
From: m@dsmh m@iii@g oii gm@ii@com (m@dsmh m@iii@g oii gm@ii@com)
Date: Mon, 16 Aug 2021 18:55:50 +0200
Subject: [R] Package for "design graphs"
Message-ID: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>

Hi,

in our course littrature a "design graph" of two factors R and S with
associated maps s : I -> S and f : I -> S where I is some finite index
set, is a graph with factor labeles as vertices and lines f(i) to s(i)
for all observations i in I. Is there a package on CRAN that can draw
graphs like this automatically?

I haven't been able to find anyting by searching.

Regards, Mads


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 17 22:58:10 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Aug 2021 13:58:10 -0700
Subject: [R] Including percentage values inside columns of a histogram
In-Reply-To: <18d74dff-2511-93c8-02d8-d46da5a4bc0b@sapo.pt>
References: <CAMOcQfOR6piNJ8tvXa1E2NjzBM=AXL=BveAJSFJ3ipMhVHkutg@mail.gmail.com>
 <e0c2c85e-14dc-bfed-2676-67f1401cf475@sapo.pt>
 <CAMOcQfMyJhuB2hKPp7=rJJ94itx8OAiFGdS8GdOcBfOD7wri=A@mail.gmail.com>
 <98d59c5e-0247-e753-26c5-2646d9b3174b@sapo.pt>
 <CAMOcQfNM1ne00OgCniXt4YhtLtsVPS20AR02qcv99DS8vKxDag@mail.gmail.com>
 <CA+8X3fX251=oChJSNZUjxSAduiJkUcHZ+HiST-PiQfvKTNZuXw@mail.gmail.com>
 <CAMOcQfN=6a4iDrJNkeV3X1Gp=RAm7GpqACLw0UW1vDHSUw2g6w@mail.gmail.com>
 <CAGxFJbSpW6_wNFYd9ExN0dVaQtKCOPRT43JNUrDXzFYuaY_XjA@mail.gmail.com>
 <d8b7b7f5-4076-a5e7-42fc-d7d2be85d755@sapo.pt>
 <CAGxFJbTkSOCCnZfFioib0nEPVm1GVgNLP-Ark3=hLT+H5jCFRg@mail.gmail.com>
 <18d74dff-2511-93c8-02d8-d46da5a4bc0b@sapo.pt>
Message-ID: <CAGxFJbSmoXiRrda8ZNdndL2c-GH=V+=SUBVF6=DDCiFHJP0iTA@mail.gmail.com>

Ah yes. Duhhh...  Thanks Rui.

So h$density *diff(h$breaks) *100 will give the percentages. No need
for arithmetic beyond that.

Bert

On Tue, Aug 17, 2021 at 12:03 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
>
>
> ?s 19:28 de 17/08/21, Bert Gunter escreveu:
> > Inline below.
> >
> >
> >
> > On Tue, Aug 17, 2021 at 4:09 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >>
> >> Hello,
> >>
> >> I had forgotten about plot.histogram, it does make everything simpler.
> >> To have percentages on the bars, in the code below I use package scales.
> >>
> >> Note that it seems to me that you do not want densities, to have
> >> percentages,  the proportions of counts are given by any of
> >
> > Under the default of equal width bins -- which is what Sturges gives
>
> Right.
>
> > if I read the docs correctly -- since the densities sum to 1,
>
> The "densities" do not sum to 1. From ?hist, section Value:
>
> density
> values f^(x[i]), as estimated density values. If all(diff(breaks) == 1),
> they are the relative frequencies counts/n and in general satisfy
> sum[i; f^(x[i]) (b[i+1]-b[i])] = 1, where b[i] = breaks[i].
>
>
> If all(diff(breaks) == 1) is FALSE, the density list member must be
> multiplied by diff(.$breaks)
>
>
> h <- hist(datasetregs$Amount, plot = FALSE)
> sum(h$density)
> #[1] 1e-04
> diff(h$breaks)
> #[1] 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000
> sum(h$density*diff(h$breaks))
> #[1] 1
>
>
> Hope this helps,
>
> Rui Barradas
>
> they are
> > already the proportion of counts in each histogram bin, no?
> >
> > -- Bert
> >
> >
> >>
> >> h$counts/sum(h$counts)
> >> h$density*diff(h$breaks)
> >>
> >>
> >>
> >> # One histogram for all dates
> >> h <- hist(datasetregs$Amount, plot = FALSE)
> >> plot(h, labels = scales::percent(h$counts/sum(h$counts)),
> >>        ylim = c(0, 1.1*max(h$counts)))
> >>
> >>
> >>
> >> # Histograms by date
> >> sp <- split(datasetregs, datasetregs$Date)
> >> old_par <- par(mfrow = c(1, 3))
> >> h_list <- lapply(seq_along(sp), function(i){
> >>     hist_title <- paste("Histogram of", names(sp)[i])
> >>     h <- hist(sp[[i]]$Amount, plot = FALSE)
> >>     plot(h, main = hist_title, xlab = "Amount",
> >>          labels = scales::percent(h$counts/sum(h$counts)),
> >>          ylim = c(0, 1.1*max(h$counts)))
> >> })
> >> par(old_par)
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >> ?s 01:49 de 17/08/21, Bert Gunter escreveu:
> >>> I may well misunderstand, but proffered solutions seem more complicated
> >>> than necessary.
> >>> Note that the return of hist() can be saved as a list of class "histogram"
> >>> and then plotted with  plot.histogram(), which already has a "labels"
> >>> argument that seems to be what you want. A simple example is"
> >>>
> >>> dat <- runif(50, 0, 10)
> >>> myhist <- hist(dat, freq = TRUE, breaks ="Sturges")
> >>>
> >>> plot(myhist, col = "darkgray",
> >>>        labels = as.character(round(myhist$density*100,1) ),
> >>>        ylim = c(0, 1.1*max(myhist$counts)))
> >>> ## note that this is plot.histogram because myhist has class "histogram"
> >>>
> >>> Note that I expanded the y axis a bit to be sure to include the labels. You
> >>> can, of course, plot your separate years as Rui has indicated or via e.g.
> >>> ?layout.
> >>>
> >>> Apologies if I have misunderstood. Just ignore this in that case.
> >>> Otherwise, I leave it to you to fill in details.
> >>>
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along and
> >>> sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Mon, Aug 16, 2021 at 4:14 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
> >>>
> >>>> Dear Jim,
> >>>>
> >>>> Thank you so much for your kind reply. Yes, this is what I am looking for,
> >>>> however, can?t see clearly how the bars correspond to the bins in the
> >>>> x-axis. Maybe there is a way to align the amounts so that they match the
> >>>> columns, sorry if I sound picky, but just want to learn if there is a way
> >>>> to accomplish this.
> >>>>
> >>>> Best regards,
> >>>>
> >>>> Paul
> >>>>
> >>>> El lun, 16 ago 2021 a las 17:57, Jim Lemon (<drjimlemon at gmail.com>)
> >>>> escribi?:
> >>>>
> >>>>> Hi Paul,
> >>>>> I just worked out your first request:
> >>>>>
> >>>>> datasetregs<-<-structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> >>>>> 2L,
> >>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>>>> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>>>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>>>> 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"), class =
> >>>>> "factor"),
> >>>>>       Amount = c(40100, 101100, 35000, 40100, 15000, 45100, 40200,
> >>>>>       15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100, 15000,
> >>>>>       15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>>>       15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>>>       15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>>>       16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000, 15000,
> >>>>>       15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000, 15000,
> >>>>>       15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000, 15000,
> >>>>>       15000, 15000, 15000, 15000)), row.names = c(NA, -74L), class =
> >>>>> "data.frame")
> >>>>> histval<-with(datasetregs, hist(Amount, groups=Date, scale="frequency",
> >>>>>    breaks="Sturges", col="darkgray"))
> >>>>> library(plotrix)
> >>>>> histpcts<-paste0(round(100*histval$counts/sum(histval$counts),1),"%")
> >>>>> barlabels(histval$mids,histval$counts,histpcts)
> >>>>>
> >>>>> I think that's what you asked for:
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>> On Tue, Aug 17, 2021 at 8:44 AM Paul Bernal <paulbernal07 at gmail.com>
> >>>>> wrote:
> >>>>>>
> >>>>>> This is way better, now, how could I put the frequency labels in the
> >>>>>> columns as a percentage, instead of presenting them as counts?
> >>>>>>
> >>>>>> Thank you so much.
> >>>>>>
> >>>>>> Paul
> >>>>>>
> >>>>>> El lun, 16 ago 2021 a las 17:33, Rui Barradas (<ruipbarradas at sapo.pt>)
> >>>>>> escribi?:
> >>>>>>
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> You forgot to cc the list.
> >>>>>>>
> >>>>>>> Here are two ways, both of them apply hist() and text() to Amount
> >>>> split
> >>>>>>> by Date. The return value of hist is saved because it's a list with
> >>>>>>> members the histogram's bars midpoints and the counts. Those are used
> >>>>> to
> >>>>>>> know where to put the text labels.
> >>>>>>> A vector lbls is created to get rid of counts of zero.
> >>>>>>>
> >>>>>>> The main difference between the two ways is the histogram's titles.
> >>>>>>>
> >>>>>>>
> >>>>>>> old_par <- par(mfrow = c(1, 3))
> >>>>>>> h_list <- with(datasetregs, tapply(Amount, Date, function(x){
> >>>>>>>      h <- hist(x)
> >>>>>>>      lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> >>>>>>>      text(h$mids, h$counts/2, labels = lbls)
> >>>>>>> }))
> >>>>>>> par(old_par)
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> old_par <- par(mfrow = c(1, 3))
> >>>>>>> sp <- split(datasetregs, datasetregs$Date)
> >>>>>>> h_list <- lapply(seq_along(sp), function(i){
> >>>>>>>      hist_title <- paste("Histogram of", names(sp)[i])
> >>>>>>>      h <- hist(sp[[i]]$Amount, main = hist_title)
> >>>>>>>      lbls <- ifelse(h$counts == 0, NA_integer_, h$counts)
> >>>>>>>      text(h$mids, h$counts/2, labels = lbls)
> >>>>>>> })
> >>>>>>> par(old_par)
> >>>>>>>
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>> ?s 23:16 de 16/08/21, Paul Bernal escreveu:
> >>>>>>>> Dear Rui,
> >>>>>>>>
> >>>>>>>> The hist() function comes from the graphics package, from what I
> >>>>> could
> >>>>>>>> see. The thing is that I want to divide the Amount column into
> >>>>> several
> >>>>>>>> bins and then generate three different histograms, one for each AF
> >>>>>>>> period (AF refers to fiscal years). As you can see, the data
> >>>> contains
> >>>>>>>> three fiscal years (2017, 2020 and 2021). I want to see the
> >>>>> percentage
> >>>>>>>> of cases that fall into different amount categories, from 15,000
> >>>> and
> >>>>>>>> below, 16,000 to 17,000, from 18,000 to 19,000, and so on.
> >>>>>>>>
> >>>>>>>> Thanks for your kind help.
> >>>>>>>>
> >>>>>>>> Paul
> >>>>>>>>
> >>>>>>>> El lun, 16 ago 2021 a las 17:07, Rui Barradas (<
> >>>> ruipbarradas at sapo.pt
> >>>>>>>> <mailto:ruipbarradas at sapo.pt>>) escribi?:
> >>>>>>>>
> >>>>>>>>       Hello,
> >>>>>>>>
> >>>>>>>>       The function Hist comes from what package?
> >>>>>>>>
> >>>>>>>>       Are you sure you don't want a bar plot?
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>       agg <- aggregate(Amount ~ Date, datasetregs, sum)
> >>>>>>>>       bp <- barplot(Amount ~ Date, agg)
> >>>>>>>>       with(agg, text(bp, Amount/2, labels = Amount))
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>       Hope this helps,
> >>>>>>>>
> >>>>>>>>       Rui Barradas
> >>>>>>>>
> >>>>>>>>       ?s 22:54 de 16/08/21, Paul Bernal escreveu:
> >>>>>>>>        > Hello everyone,
> >>>>>>>>        >
> >>>>>>>>        > I am currently working with R version 4.1.0 and I am trying
> >>>> to
> >>>>>>>>       include
> >>>>>>>>        > (inside the columns of the histogram), the percentage
> >>>>>>>>       distribution and I
> >>>>>>>>        > want to generate three histograms, one for each fiscal year
> >>>>> (in
> >>>>>>>>       the Date
> >>>>>>>>        > column, there are three fiscal year AF 2017, AF 2020 and AF
> >>>>>>>>       2021). However,
> >>>>>>>>        > I can?t seem to accomplish this.
> >>>>>>>>        >
> >>>>>>>>        > Here is my data:
> >>>>>>>>        >
> >>>>>>>>        > structure(list(Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> >>>> 2L,
> >>>>>>>>        > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>>>> 2L,
> >>>>>>>>        > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>>>> 2L,
> >>>>>>>>        > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>>>> 3L,
> >>>>>>>>        > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>>>> 3L,
> >>>>>>>>        > 3L, 3L, 3L), .Label = c("AF 2017", "AF 2020", "AF 2021"),
> >>>>> class =
> >>>>>>>>        > "factor"),
> >>>>>>>>        >      Amount = c(40100, 101100, 35000, 40100, 15000, 45100,
> >>>>> 40200,
> >>>>>>>>        >      15000, 35000, 35100, 20300, 40100, 15000, 67100, 17100,
> >>>>>>> 15000,
> >>>>>>>>        >      15000, 50100, 35100, 15000, 15000, 15000, 15000, 15000,
> >>>>>>> 15000,
> >>>>>>>>        >      15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,
> >>>>>>> 15000,
> >>>>>>>>        >      15000, 15000, 20100, 15000, 15000, 15000, 15000, 15000,
> >>>>>>> 15000,
> >>>>>>>>        >      16600, 15000, 15000, 15700, 15000, 15000, 15000, 15000,
> >>>>>>> 15000,
> >>>>>>>>        >      15000, 15000, 15000, 15000, 20200, 21400, 25100, 15000,
> >>>>>>> 15000,
> >>>>>>>>        >      15000, 15000, 15000, 15000, 25600, 15000, 15000, 15000,
> >>>>>>> 15000,
> >>>>>>>>        >      15000, 15000, 15000, 15000)), row.names = c(NA, -74L),
> >>>>> class
> >>>>>>> =
> >>>>>>>>        > "data.frame")
> >>>>>>>>        >
> >>>>>>>>        > I would like to modify the following script:
> >>>>>>>>        >
> >>>>>>>>        >> with(datasetregs, Hist(Amount, groups=Date,
> >>>>> scale="frequency",
> >>>>>>>>        > +   breaks="Sturges", col="darkgray"))
> >>>>>>>>        >
> >>>>>>>>        > #The only thing missing here are the percentages
> >>>>> corresponding to
> >>>>>>>>       each bin
> >>>>>>>>        > (I would like to see the percentages inside each column, or
> >>>> on
> >>>>>>>>       top outside
> >>>>>>>>        > if possible)
> >>>>>>>>        >
> >>>>>>>>        > Any help will be greatly appreciated.
> >>>>>>>>        >
> >>>>>>>>        > Best regards,
> >>>>>>>>        >
> >>>>>>>>        > Paul.
> >>>>>>>>        >
> >>>>>>>>        >       [[alternative HTML version deleted]]
> >>>>>>>>        >
> >>>>>>>>        > ______________________________________________
> >>>>>>>>        > R-help at r-project.org <mailto:R-help at r-project.org> mailing
> >>>>> list
> >>>>>>>>       -- To UNSUBSCRIBE and more, see
> >>>>>>>>        > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>>>>>>        > PLEASE do read the posting guide
> >>>>>>>>       http://www.R-project.org/posting-guide.html
> >>>>>>>>       <http://www.R-project.org/posting-guide.html>
> >>>>>>>>        > and provide commented, minimal, self-contained, reproducible
> >>>>> code.
> >>>>>>>>        >
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>>           [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>           [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 17 23:03:15 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Aug 2021 14:03:15 -0700
Subject: [R] Package for "design graphs"
In-Reply-To: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
Message-ID: <CAGxFJbSvVVJVzKoXW94wgtVrcRSrwhMZqe5LsB0o7Rh++irPdA@mail.gmail.com>

Have you looked at the gR Task View on CRAN:
https://cran.r-project.org/web/views/gR.html

(I have no idea whether it's relevant to your query, though).

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 17, 2021 at 1:02 PM <madsmh at gmail.com> wrote:
>
> Hi,
>
> in our course littrature a "design graph" of two factors R and S with
> associated maps s : I -> S and f : I -> S where I is some finite index
> set, is a graph with factor labeles as vertices and lines f(i) to s(i)
> for all observations i in I. Is there a package on CRAN that can draw
> graphs like this automatically?
>
> I haven't been able to find anyting by searching.
>
> Regards, Mads
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug 18 00:17:16 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Aug 2021 15:17:16 -0700
Subject: [R] Package for "design graphs"
In-Reply-To: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
Message-ID: <95591ECA-673F-4F43-BA80-CBC310124AE7@dcn.davis.ca.us>

Perhaps igraph or DiagrammeR?

On August 16, 2021 9:55:50 AM PDT, madsmh at gmail.com wrote:
>Hi,
>
>in our course littrature a "design graph" of two factors R and S with
>associated maps s : I -> S and f : I -> S where I is some finite index
>set, is a graph with factor labeles as vertices and lines f(i) to s(i)
>for all observations i in I. Is there a package on CRAN that can draw
>graphs like this automatically?
>
>I haven't been able to find anyting by searching.
>
>Regards, Mads
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From rmh @end|ng |rom temp|e@edu  Wed Aug 18 00:42:02 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 17 Aug 2021 22:42:02 +0000
Subject: [R] [External]  Package for "design graphs"
In-Reply-To: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
Message-ID: <BL1PR11MB52392661D86D09E20D87A07DD2FE9@BL1PR11MB5239.namprd11.prod.outlook.com>

can you post an example of the graph?

________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of madsmh at gmail.com <madsmh at gmail.com>
Sent: Tuesday, August 17, 2021 16:02
To: r-help at r-project.org
Subject: [External] [R] Package for "design graphs"

Hi,

in our course littrature a "design graph" of two factors R and S with
associated maps s : I -> S and f : I -> S where I is some finite index
set, is a graph with factor labeles as vertices and lines f(i) to s(i)
for all observations i in I. Is there a package on CRAN that can draw
graphs like this automatically?

I haven't been able to find anyting by searching.

Regards, Mads

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7C00a59081bd66463e433d08d961b9e105%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648273248735184%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=dNwMcJa6okIxlK97dprkVkCk4g5mn6hYsBr1Hez7m%2F8%3D&amp;reserved=0
PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7C00a59081bd66463e433d08d961b9e105%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648273248745142%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=YZlqRVki%2FaQMdaGQgddyLLmAH3bCsnhPTuhlnrSb1PE%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ips m@iii@g oii posteo@de  Wed Aug 18 11:38:52 2021
From: ips m@iii@g oii posteo@de (ips m@iii@g oii posteo@de)
Date: Wed, 18 Aug 2021 09:38:52 +0000
Subject: [R] Fwd: R Windows 64 bit Version above 4.01 crash on Windows 10 on
 startup
Message-ID: <cb8350cb7a9f8fa227d02141036ea4ba@posteo.de>

Hi,

I did not know where to turn to, but I found a bug in all versions of 
rgui.exe from 4.0.2 to 4.1.1patched. On a brandnew Windows 10 Pro 64bit 
Version: 21H1 the 64 bit gui crashes at startup. No console is 
displayed. 32 bit works fine. Eventmanager applications log shows 
consistently follwing entry:

Name der fehlerhaften Anwendung: Rgui.exe, Version: 4.11.15200.0, 
Zeitstempel: 0x611470e7
Name des fehlerhaften Moduls: msvcrt.dll, Version: 7.0.19041.546, 
Zeitstempel: 0x564f9f39
Ausnahmecode: 0xc0000409
Fehleroffset: 0x0000000000030a70
ID des fehlerhaften Prozesses: 0x171c
Startzeit der fehlerhaften Anwendung: 0x01d78f719895911a
Pfad der fehlerhaften Anwendung: C:\Program 
Files\R\R-4.1.1patched\bin\x64\Rgui.exe
Pfad des fehlerhaften Moduls: C:\Windows\System32\msvcrt.dll

4.0.1 works fine. Tinkering with the msvcrt.dll did not help!

It is a physical machine, a Dell XPS Laptop, no virtual machine.
I tried at least 5 different versions 4.1.0, 4.0.3 etc. they all show 
the same behavior.

Maybe you find this information usefull enough to relay it to whomever 
could fix this.


Best regards
Frank


From m@dsmh m@iii@g oii gm@ii@com  Wed Aug 18 16:29:18 2021
From: m@dsmh m@iii@g oii gm@ii@com (m@dsmh m@iii@g oii gm@ii@com)
Date: Wed, 18 Aug 2021 16:29:18 +0200
Subject: [R] [External]  Package for "design graphs"
In-Reply-To: <BL1PR11MB52392661D86D09E20D87A07DD2FE9@BL1PR11MB5239.namprd11.prod.outlook.com>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
 <BL1PR11MB52392661D86D09E20D87A07DD2FE9@BL1PR11MB5239.namprd11.prod.outlook.com>
Message-ID: <1616bbc41b16c627c43bab5cb875bb5c7c17b61b.camel@gmail.com>

I have attached a photo from our book 

E. Hansen "Introduktion til matematisk statistik"

the numbers represent the labels of one factor while the letters
represent the labels of anothr factor.

.. Mads


On Tue, 2021-08-17 at 22:42 +0000, Richard M. Heiberger wrote:
> can you post an example of the graph?
> 
> From: R-help <r-help-bounces at r-project.org> on behalf of 
> madsmh at gmail.com <madsmh at gmail.com>
> Sent: Tuesday, August 17, 2021 16:02
> To: r-help at r-project.org
> Subject: [External] [R] Package for "design graphs"
>  
> Hi,
> 
> in our course littrature a "design graph" of two factors R and S with
> associated maps s : I -> S and f : I -> S where I is some finite
> index
> set, is a graph with factor labeles as vertices and lines f(i) to
> s(i)
> for all observations i in I. Is there a package on CRAN that can draw
> graphs like this automatically?
> 
> I haven't been able to find anyting by searching.
> 
> Regards, Mads
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7C00a59081bd66463e433d08d961b9e105%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648273248735184%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=dNwMcJa6okIxlK97dprkVkCk4g5mn6hYsBr1Hez7m%2F8%3D&amp;reserved=0
> PLEASE do read the posting guide 
> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7C00a59081bd66463e433d08d961b9e105%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648273248745142%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=YZlqRVki%2FaQMdaGQgddyLLmAH3bCsnhPTuhlnrSb1PE%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.

From rmh @end|ng |rom temp|e@edu  Thu Aug 19 02:22:35 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 19 Aug 2021 00:22:35 +0000
Subject: [R] [External]  Package for "design graphs"
In-Reply-To: <1616bbc41b16c627c43bab5cb875bb5c7c17b61b.camel@gmail.com>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
 <BL1PR11MB52392661D86D09E20D87A07DD2FE9@BL1PR11MB5239.namprd11.prod.outlook.com>
 <1616bbc41b16c627c43bab5cb875bb5c7c17b61b.camel@gmail.com>
Message-ID: <187B4550-DEB4-4A18-8B40-694EF77ED6FF@temple.edu>

Thank you for the example.

Here is a simple function in base graphics that does what you ask for.

You can turn off the default borders and ticks and tick labels and xlab and ylab,
and add your own x tick labels, and then it will look exactly like the example you sent.

Rich


expt1 <- data.frame(from=c(1,1,2,2,3,3,4,4),
                    to=c("A","B","A","B","C","D","C","D"))

expt2 <-  data.frame(from=c(1,1,2,2,3,3,4,4),
                     to=c("A","B","B","C","C","D","D","A"))


DesignGraph <- function(x, pch.from=19, pch.to=19) {
  from <- unique(x$from)
  to <- unique(x$to)


  n.from <- length(from)
  n.to <- length(to)
  Nrows<- max(1:n.from, 1:n.to)

  plot(1 ~ 1, type="n", xlim=c(1-.5, 2+.5), ylim=c(Nrows, 1))

  points(x=rep(1, n.from), y=1:n.from, pch=pch.from)
  text(x=1-.3, y=1:n.from, labels=from)

  points(x=rep(2, n.to), y=1:n.to, pch=pch.to)
  text(x=2+.3, y=1:n.to, labels=to)

  index.from <- which
  index.to <- which

  segments(1, match(x$from, from), 2, match(x$to, to))
}

DesignGraph(expt1)

DesignGraph(expt2)






> On Aug 18, 2021, at 10:29, madsmh at gmail.com wrote:
> 
> I have attached a photo from our book 
> 
> E. Hansen "Introduktion til matematisk statistik"
> 
> the numbers represent the labels of one factor while the letters
> represent the labels of anothr factor.
> 
> .. Mads
> 
> 
> On Tue, 2021-08-17 at 22:42 +0000, Richard M. Heiberger wrote:
>> can you post an example of the graph?
>> 
>> From: R-help <r-help-bounces at r-project.org> on behalf of 
>> madsmh at gmail.com <madsmh at gmail.com>
>> Sent: Tuesday, August 17, 2021 16:02
>> To: r-help at r-project.org
>> Subject: [External] [R] Package for "design graphs"
>> 
>> Hi,
>> 
>> in our course littrature a "design graph" of two factors R and S with
>> associated maps s : I -> S and f : I -> S where I is some finite
>> index
>> set, is a graph with factor labeles as vertices and lines f(i) to
>> s(i)
>> for all observations i in I. Is there a package on CRAN that can draw
>> graphs like this automatically?
>> 
>> I haven't been able to find anyting by searching.
>> 
>> Regards, Mads
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7Cf18619e1691a4333682a08d962549a74%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648937938659341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=0LTywXuQ5Y%2FymuUTKOQeeozEx4MpAnF9QavJBcd4FNE%3D&amp;reserved=0
>> PLEASE do read the posting guide 
>> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7Cf18619e1691a4333682a08d962549a74%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648937938659341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=GT1zdL3%2BOAuVkXGGRMysbsfucmiIz6Dqozr6xyNbm8s%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
> <IMG_0665.JPG>


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Aug 19 03:45:54 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 18 Aug 2021 18:45:54 -0700
Subject: [R] [External] Package for "design graphs"
In-Reply-To: <1616bbc41b16c627c43bab5cb875bb5c7c17b61b.camel@gmail.com>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
 <BL1PR11MB52392661D86D09E20D87A07DD2FE9@BL1PR11MB5239.namprd11.prod.outlook.com>
 <1616bbc41b16c627c43bab5cb875bb5c7c17b61b.camel@gmail.com>
Message-ID: <cef030e2-bc3a-c6bb-b541-a56e65a1ae4f@comcast.net>

The only person who got the image was Richard. The rest of us got the 
posting from the list server which stripped you image. If it had been a 
pdf or png I think it might have survived the digital journey rather 
than being blown to bits.

On 8/18/21 7:29 AM, madsmh at gmail.com wrote:
> I have attached a photo from our book
>
> E. Hansen "Introduktion til matematisk statistik"
>
> the numbers represent the labels of one factor while the letters
> represent the labels of anothr factor.
>
> .. Mads
>
>
> On Tue, 2021-08-17 at 22:42 +0000, Richard M. Heiberger wrote:
>> can you post an example of the graph?
>>
>> From: R-help <r-help-bounces at r-project.org> on behalf of
>> madsmh at gmail.com <madsmh at gmail.com>
>> Sent: Tuesday, August 17, 2021 16:02
>> To: r-help at r-project.org
>> Subject: [External] [R] Package for "design graphs"
>>   
>> Hi,
>>
>> in our course littrature a "design graph" of two factors R and S with
>> associated maps s : I -> S and f : I -> S where I is some finite
>> index
>> set, is a graph with factor labeles as vertices and lines f(i) to
>> s(i)
>> for all observations i in I. Is there a package on CRAN that can draw
>> graphs like this automatically?
>>
>> I haven't been able to find anyting by searching.
>>
>> Regards, Mads
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7C00a59081bd66463e433d08d961b9e105%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648273248735184%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=dNwMcJa6okIxlK97dprkVkCk4g5mn6hYsBr1Hez7m%2F8%3D&amp;reserved=0
>> PLEASE do read the posting guide
>> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7C00a59081bd66463e433d08d961b9e105%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648273248745142%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=YZlqRVki%2FaQMdaGQgddyLLmAH3bCsnhPTuhlnrSb1PE%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Thu Aug 19 05:57:47 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 19 Aug 2021 03:57:47 +0000 (UTC)
Subject: [R] Problem in Notrend_test()
References: <944576176.46852.1629345467704.ref@mail.yahoo.com>
Message-ID: <944576176.46852.1629345467704@mail.yahoo.com>

Hello,?I have the following vector in R,?
print(column_Data)[1] 42 33 34 28
But I get the following error on using notrend_test on this data as follows -?

notrend_test(column_Data)Error in notrend_test(column_Data) : set a proper window.

I am unable to find any information on Stackoverflow etc.?
Any help would be appreciated?
Thank you

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 19 07:47:16 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Aug 2021 15:47:16 +1000
Subject: [R] Problem in Notrend_test()
In-Reply-To: <944576176.46852.1629345467704@mail.yahoo.com>
References: <944576176.46852.1629345467704.ref@mail.yahoo.com>
 <944576176.46852.1629345467704@mail.yahoo.com>
Message-ID: <CA+8X3fWKCfDskBUARJEw8dfNmMWRcNz7o-ufkkXkcvzUQ7N9DQ@mail.gmail.com>

Hi bharat,
notrend_test (funtimes) wants a vector (univariate time series) as the
first argument. My crystal ball suggests that column_Data is too
short, but try this:

notrend_test(column_Data,test="WAVK")

Be aware that this is a guess.

Jim

On Thu, Aug 19, 2021 at 1:58 PM bharat rawlley via R-help
<r-help at r-project.org> wrote:
>
> Hello, I have the following vector in R,
> print(column_Data)[1] 42 33 34 28
> But I get the following error on using notrend_test on this data as follows -
>
> notrend_test(column_Data)Error in notrend_test(column_Data) : set a proper window.
>
> I am unable to find any information on Stackoverflow etc.
> Any help would be appreciated
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 19 08:21:18 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 19 Aug 2021 07:21:18 +0100
Subject: [R] [External] Package for "design graphs"
In-Reply-To: <187B4550-DEB4-4A18-8B40-694EF77ED6FF@temple.edu>
References: <599a5f1680c425b59da33cb08e82f623aa27de2f.camel@gmail.com>
 <BL1PR11MB52392661D86D09E20D87A07DD2FE9@BL1PR11MB5239.namprd11.prod.outlook.com>
 <1616bbc41b16c627c43bab5cb875bb5c7c17b61b.camel@gmail.com>
 <187B4550-DEB4-4A18-8B40-694EF77ED6FF@temple.edu>
Message-ID: <3580bdd2-24bf-bead-c93b-34ffc0ca005d@sapo.pt>

Hello,

Here is a igraph function to plot the graph as bipartite graph (which it 
is).
The reordering of the input dataframe columns, the order() call and 
vertex label distance value are a hack, and the plot could use the dots 
argument to allow the user to choose other custom graphics elements.
I post it mostly to show a graph theoretical solution is also possible.



library(igraph)

ig_DesignGraph <- function(x, vertex.size = 10, vertex.color = "black", 
edge.color = "gray"){
   g <- graph_from_data_frame(x[2:1], directed = FALSE)
   V(g)$type <- V(g)$name %in% x[[2]]
   V(g)$color <- V(g)$type
   V(g)$color <- gsub("FALSE", vertex.color, V(g)$color)
   V(g)$color <- gsub("TRUE", vertex.color, V(g)$color)
   L0 <- layout_as_bipartite(g)[, 2:1]
   i <- order(L0[, 1], L0[, 2])
   plot(
     g,
     edge.color = edge.color,
     vertex.size = vertex.size,
     vertex.label.dist = -3,
     vertex.label.degree = pi*V(g)$type,
     layout = -L0[i, ]
   )
}

ig_DesignGraph(expt1)
ig_DesignGraph(expt2)


Hope this helps,

Rui Barradas


?s 01:22 de 19/08/21, Richard M. Heiberger escreveu:
> Thank you for the example.
> 
> Here is a simple function in base graphics that does what you ask for.
> 
> You can turn off the default borders and ticks and tick labels and xlab and ylab,
> and add your own x tick labels, and then it will look exactly like the example you sent.
> 
> Rich
> 
> 
> expt1 <- data.frame(from=c(1,1,2,2,3,3,4,4),
>                      to=c("A","B","A","B","C","D","C","D"))
> 
> expt2 <-  data.frame(from=c(1,1,2,2,3,3,4,4),
>                       to=c("A","B","B","C","C","D","D","A"))
> 
> 
> DesignGraph <- function(x, pch.from=19, pch.to=19) {
>    from <- unique(x$from)
>    to <- unique(x$to)
> 
> 
>    n.from <- length(from)
>    n.to <- length(to)
>    Nrows<- max(1:n.from, 1:n.to)
> 
>    plot(1 ~ 1, type="n", xlim=c(1-.5, 2+.5), ylim=c(Nrows, 1))
> 
>    points(x=rep(1, n.from), y=1:n.from, pch=pch.from)
>    text(x=1-.3, y=1:n.from, labels=from)
> 
>    points(x=rep(2, n.to), y=1:n.to, pch=pch.to)
>    text(x=2+.3, y=1:n.to, labels=to)
> 
>    index.from <- which
>    index.to <- which
> 
>    segments(1, match(x$from, from), 2, match(x$to, to))
> }
> 
> DesignGraph(expt1)
> 
> DesignGraph(expt2)
> 
> 
> 
> 
> 
> 
>> On Aug 18, 2021, at 10:29, madsmh at gmail.com wrote:
>>
>> I have attached a photo from our book
>>
>> E. Hansen "Introduktion til matematisk statistik"
>>
>> the numbers represent the labels of one factor while the letters
>> represent the labels of anothr factor.
>>
>> .. Mads
>>
>>
>> On Tue, 2021-08-17 at 22:42 +0000, Richard M. Heiberger wrote:
>>> can you post an example of the graph?
>>>
>>> From: R-help <r-help-bounces at r-project.org> on behalf of
>>> madsmh at gmail.com <madsmh at gmail.com>
>>> Sent: Tuesday, August 17, 2021 16:02
>>> To: r-help at r-project.org
>>> Subject: [External] [R] Package for "design graphs"
>>>
>>> Hi,
>>>
>>> in our course littrature a "design graph" of two factors R and S with
>>> associated maps s : I -> S and f : I -> S where I is some finite
>>> index
>>> set, is a graph with factor labeles as vertices and lines f(i) to
>>> s(i)
>>> for all observations i in I. Is there a package on CRAN that can draw
>>> graphs like this automatically?
>>>
>>> I haven't been able to find anyting by searching.
>>>
>>> Regards, Mads
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7Cf18619e1691a4333682a08d962549a74%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648937938659341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=0LTywXuQ5Y%2FymuUTKOQeeozEx4MpAnF9QavJBcd4FNE%3D&amp;reserved=0
>>> PLEASE do read the posting guide
>>> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7Cf18619e1691a4333682a08d962549a74%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637648937938659341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=GT1zdL3%2BOAuVkXGGRMysbsfucmiIz6Dqozr6xyNbm8s%3D&amp;reserved=0
>>> and provide commented, minimal, self-contained, reproducible code.
>> <IMG_0665.JPG>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Aug 19 09:32:43 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 19 Aug 2021 09:32:43 +0200
Subject: [R] Cars2
In-Reply-To: <SYBPR01MB3516A8671CE341060098C79BC9C09@SYBPR01MB3516.ausprd01.prod.outlook.com>
References: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>
 <20210817193205.60a65b0e@trisector>
 <SYBPR01MB3516A8671CE341060098C79BC9C09@SYBPR01MB3516.ausprd01.prod.outlook.com>
Message-ID: <20210819093243.6721da2a@parabola>

On Thu, 19 Aug 2021 00:12:51 +0000
George Bellas <g.bellas at uq.net.au> wrote:

> I'm still looking for it, it had car prices and car models in it. I
> couldn't find it through the r search link.

Could it be the third search result for a query of 'cars2'?

https://search.r-project.org/?P=cars2&SORT=&HITSPERPAGE=10&DB=r-manuals&DB=r-help&DB=cran-views&DB=cran-info&DB=cran-help&DB=cran-news&DB=cran-readme&DB=cran-vignettes&DEFAULTOP=and&FMT=query&xDB=cran-help&xFILTERS=.%7E%7E

->

https://search.r-project.org/CRAN/refmans/fBasics/html/data-examples.html

>> cars2 contains the price, country, reliability, mileage, type,
>> weight, engine displacement and net horsepower of various car
>> models.

-- 
Best regards,
Ivan


From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Thu Aug 19 09:46:13 2021
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Thu, 19 Aug 2021 09:46:13 +0200
Subject: [R] Getting different results with set.seed()
Message-ID: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>

Dear All,

I was using set.seed to reproduce the same results for the discrete event
simulation model. I have 12 unknown parameters for optimization (just a
little background). I got a good fit of parameter combinations. However,
when I use those parameters combinations again in the model. I am getting
different results.

Is there any problem with the set.seed. I assume the set.seed should
produce the same results.

I used set.seed(1234).

Best regards,
Shah

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug 19 09:56:34 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 19 Aug 2021 07:56:34 +0000
Subject: [R] Getting different results with set.seed()
In-Reply-To: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
Message-ID: <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>

Hi

Please provide at least your code preferably with some data to reproduce
this behaviour. I wonder if anybody could help you without such information.

My wild guess is that you used 

set.seed(1234)

some code

the code used again

in which case you have to expect different results.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Shah Alam
> Sent: Thursday, August 19, 2021 9:46 AM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] Getting different results with set.seed()
> 
> Dear All,
> 
> I was using set.seed to reproduce the same results for the discrete event
> simulation model. I have 12 unknown parameters for optimization (just a
> little background). I got a good fit of parameter combinations. However,
> when I use those parameters combinations again in the model. I am getting
> different results.
> 
> Is there any problem with the set.seed. I assume the set.seed should
> produce the same results.
> 
> I used set.seed(1234).
> 
> Best regards,
> Shah
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Thu Aug 19 10:10:28 2021
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Thu, 19 Aug 2021 10:10:28 +0200
Subject: [R] Getting different results with set.seed()
In-Reply-To: <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>

Dear Petr,

It is more than 2000 lines of code with a lot of functions and data inputs.
I am not sure whether it would be useful to upload it. However, you are
absolutely right. I used

Step 1. Self-coded functions (these functions generate random numbers as
well)

Step 2: set.seed (123)

Step 3: Call those functions.

Step 4: model results.

I close the R session and run the code from step 1. I get different results
for the same set of values for parameters.

Best regards,
Shah




On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Please provide at least your code preferably with some data to reproduce
> this behaviour. I wonder if anybody could help you without such
> information.
>
> My wild guess is that you used
>
> set.seed(1234)
>
> some code
>
> the code used again
>
> in which case you have to expect different results.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Shah Alam
> > Sent: Thursday, August 19, 2021 9:46 AM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Getting different results with set.seed()
> >
> > Dear All,
> >
> > I was using set.seed to reproduce the same results for the discrete event
> > simulation model. I have 12 unknown parameters for optimization (just a
> > little background). I got a good fit of parameter combinations. However,
> > when I use those parameters combinations again in the model. I am getting
> > different results.
> >
> > Is there any problem with the set.seed. I assume the set.seed should
> > produce the same results.
> >
> > I used set.seed(1234).
> >
> > Best regards,
> > Shah
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug 19 10:26:41 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 19 Aug 2021 01:26:41 -0700
Subject: [R] Getting different results with set.seed()
In-Reply-To: <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
 <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
Message-ID: <B5CB525F-E9C4-4AEF-A1CA-0C9DB50D6FA8@dcn.davis.ca.us>

When you provide an actual minimal reproducible example we will be able to help you. 2000 lines is excessive to demonstrate the problem.

Based on your description, I think you are doing some computations before you set seed, and your results depend partly on the values computed prior to the set.seed.

On August 19, 2021 1:10:28 AM PDT, Shah Alam <dr.alamsolangi at gmail.com> wrote:
>Dear Petr,
>
>It is more than 2000 lines of code with a lot of functions and data inputs.
>I am not sure whether it would be useful to upload it. However, you are
>absolutely right. I used
>
>Step 1. Self-coded functions (these functions generate random numbers as
>well)
>
>Step 2: set.seed (123)
>
>Step 3: Call those functions.
>
>Step 4: model results.
>
>I close the R session and run the code from step 1. I get different results
>for the same set of values for parameters.
>
>Best regards,
>Shah
>
>
>
>
>On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> Please provide at least your code preferably with some data to reproduce
>> this behaviour. I wonder if anybody could help you without such
>> information.
>>
>> My wild guess is that you used
>>
>> set.seed(1234)
>>
>> some code
>>
>> the code used again
>>
>> in which case you have to expect different results.
>>
>> Cheers
>> Petr
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Shah Alam
>> > Sent: Thursday, August 19, 2021 9:46 AM
>> > To: r-help mailing list <r-help at r-project.org>
>> > Subject: [R] Getting different results with set.seed()
>> >
>> > Dear All,
>> >
>> > I was using set.seed to reproduce the same results for the discrete event
>> > simulation model. I have 12 unknown parameters for optimization (just a
>> > little background). I got a good fit of parameter combinations. However,
>> > when I use those parameters combinations again in the model. I am getting
>> > different results.
>> >
>> > Is there any problem with the set.seed. I assume the set.seed should
>> > produce the same results.
>> >
>> > I used set.seed(1234).
>> >
>> > Best regards,
>> > Shah
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t  Thu Aug 19 10:36:06 2021
From: er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t (Erich Subscriptions)
Date: Thu, 19 Aug 2021 10:36:06 +0200
Subject: [R] Problem in Notrend_test()
In-Reply-To: <944576176.46852.1629345467704@mail.yahoo.com>
References: <944576176.46852.1629345467704.ref@mail.yahoo.com>
 <944576176.46852.1629345467704@mail.yahoo.com>
Message-ID: <192635E9-C666-448E-852F-95EEB640D036@neuwirth.priv.at>

You did not give any information which package contains the function notrend_test.


> On 19.08.2021, at 05:57, bharat rawlley via R-help <r-help at r-project.org> wrote:
> 
> Hello, I have the following vector in R, 
> print(column_Data)[1] 42 33 34 28
> But I get the following error on using notrend_test on this data as follows - 
> 
> notrend_test(column_Data)Error in notrend_test(column_Data) : set a proper window.
> 
> I am unable to find any information on Stackoverflow etc. 
> Any help would be appreciated 
> Thank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug 19 11:25:41 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 19 Aug 2021 09:25:41 +0000
Subject: [R] Getting different results with set.seed()
In-Reply-To: <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
 <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
Message-ID: <ba0057ce5c244d8ba297b30913d97d48@SRVEXCHCM1302.precheza.cz>

Hi

Did you try different order?

Step 2: set.seed (123)

Step 1. Self-coded functions (these functions generate random numbers as well)

Step 3: Call those functions.

Step 4: model results.

Cheers
Petr.

And BTW, do not use HTML formating, it could cause problems in text only list.


From: Shah Alam <dr.alamsolangi at gmail.com>
Sent: Thursday, August 19, 2021 10:10 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Getting different results with set.seed()

Dear Petr,

It is more than 2000 lines of code with a lot of functions and data inputs. I 
am not sure whether it would be useful to upload it. However, you are 
absolutely right. I used

Step 1. Self-coded functions (these functions generate random numbers as well)

Step 2: set.seed (123)

Step 3: Call those functions.

Step 4: model results.

I close the R session and run the code from step 1. I get different results 
for the same set of values for parameters.

Best regards,
Shah




On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <mailto:petr.pikal at precheza.cz> 
wrote:
Hi

Please provide at least your code preferably with some data to reproduce
this behaviour. I wonder if anybody could help you without such information.

My wild guess is that you used

set.seed(1234)

some code

the code used again

in which case you have to expect different results.

Cheers
Petr

> -----Original Message-----
> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Shah Alam
> Sent: Thursday, August 19, 2021 9:46 AM
> To: r-help mailing list <mailto:r-help at r-project.org>
> Subject: [R] Getting different results with set.seed()
>
> Dear All,
>
> I was using set.seed to reproduce the same results for the discrete event
> simulation model. I have 12 unknown parameters for optimization (just a
> little background). I got a good fit of parameter combinations. However,
> when I use those parameters combinations again in the model. I am getting
> different results.
>
> Is there any problem with the set.seed. I assume the set.seed should
> produce the same results.
>
> I used set.seed(1234).
>
> Best regards,
> Shah
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From rhe|p @end|ng |rom eoo@@dd@@n|  Thu Aug 19 11:56:59 2021
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Thu, 19 Aug 2021 11:56:59 +0200
Subject: [R] Getting different results with set.seed()
In-Reply-To: <ba0057ce5c244d8ba297b30913d97d48@SRVEXCHCM1302.precheza.cz>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
 <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
 <ba0057ce5c244d8ba297b30913d97d48@SRVEXCHCM1302.precheza.cz>
Message-ID: <dcbb1131-9598-86c1-93cd-dafdc3366e73@eoos.dds.nl>



What you could also try is check if the self coded functions use the 
random generator when defining them:

starting_seed <- .Random.seed

Step 1. Self-coded functions (these functions generate random numbers as 
well)

# check if functions have modified the seed:
all.equal(starting_seed, .Random.seed)

Step 2: set.seed (123)



What has also happened to me is that some of the functions I called had 
their own random number generator independent of that of R. For example 
using one in C/C++.

Do your functions do stuff in parallel? For example using the parallel 
or snow package? In that case you also have to set the seed in the 
parallel workers.

Best,
Jan









On 19-08-2021 11:25, PIKAL Petr wrote:
> Hi
> 
> Did you try different order?
> 
> Step 2: set.seed (123)
> 
> Step 1. Self-coded functions (these functions generate random numbers as well)
> 
> Step 3: Call those functions.
> 
> Step 4: model results.
> 
> Cheers
> Petr.
> 
> And BTW, do not use HTML formating, it could cause problems in text only list.
> 
> 
> From: Shah Alam <dr.alamsolangi at gmail.com>
> Sent: Thursday, August 19, 2021 10:10 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Getting different results with set.seed()
> 
> Dear Petr,
> 
> It is more than 2000 lines of code with a lot of functions and data inputs. I
> am not sure whether it would be useful to upload it. However, you are
> absolutely right. I used
> 
> Step 1. Self-coded functions (these functions generate random numbers as well)
> 
> Step 2: set.seed (123)
> 
> Step 3: Call those functions.
> 
> Step 4: model results.
> 
> I close the R session and run the code from step 1. I get different results
> for the same set of values for parameters.
> 
> Best regards,
> Shah
> 
> 
> 
> 
> On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <mailto:petr.pikal at precheza.cz>
> wrote:
> Hi
> 
> Please provide at least your code preferably with some data to reproduce
> this behaviour. I wonder if anybody could help you without such information.
> 
> My wild guess is that you used
> 
> set.seed(1234)
> 
> some code
> 
> the code used again
> 
> in which case you have to expect different results.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Shah Alam
>> Sent: Thursday, August 19, 2021 9:46 AM
>> To: r-help mailing list <mailto:r-help at r-project.org>
>> Subject: [R] Getting different results with set.seed()
>>
>> Dear All,
>>
>> I was using set.seed to reproduce the same results for the discrete event
>> simulation model. I have 12 unknown parameters for optimization (just a
>> little background). I got a good fit of parameter combinations. However,
>> when I use those parameters combinations again in the model. I am getting
>> different results.
>>
>> Is there any problem with the set.seed. I assume the set.seed should
>> produce the same results.
>>
>> I used set.seed(1234).
>>
>> Best regards,
>> Shah
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Thu Aug 19 13:29:28 2021
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Thu, 19 Aug 2021 13:29:28 +0200
Subject: [R] Getting different results with set.seed()
In-Reply-To: <dcbb1131-9598-86c1-93cd-dafdc3366e73@eoos.dds.nl>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
 <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
 <ba0057ce5c244d8ba297b30913d97d48@SRVEXCHCM1302.precheza.cz>
 <dcbb1131-9598-86c1-93cd-dafdc3366e73@eoos.dds.nl>
Message-ID: <CA+bivFjeDCbcC8Hw67heVKo68KkXVSGDaMyRJR8PBfDt7HdgaQ@mail.gmail.com>

Dear All,

Thanks a lot for your valuable suggestions. I am going to implement one by
one.

Jan:

Yes, I am using the "doParallel" package for parallelization. I will let
you know the results after implementing all the given suggestions.

Best regards,
Shah



On Thu, 19 Aug 2021 at 11:57, Jan van der Laan <rhelp at eoos.dds.nl> wrote:

>
>
> What you could also try is check if the self coded functions use the
> random generator when defining them:
>
> starting_seed <- .Random.seed
>
> Step 1. Self-coded functions (these functions generate random numbers as
> well)
>
> # check if functions have modified the seed:
> all.equal(starting_seed, .Random.seed)
>
> Step 2: set.seed (123)
>
>
>
> What has also happened to me is that some of the functions I called had
> their own random number generator independent of that of R. For example
> using one in C/C++.
>
> Do your functions do stuff in parallel? For example using the parallel
> or snow package? In that case you also have to set the seed in the
> parallel workers.
>
> Best,
> Jan
>
>
>
>
>
>
>
>
>
> On 19-08-2021 11:25, PIKAL Petr wrote:
> > Hi
> >
> > Did you try different order?
> >
> > Step 2: set.seed (123)
> >
> > Step 1. Self-coded functions (these functions generate random numbers as
> well)
> >
> > Step 3: Call those functions.
> >
> > Step 4: model results.
> >
> > Cheers
> > Petr.
> >
> > And BTW, do not use HTML formating, it could cause problems in text only
> list.
> >
> >
> > From: Shah Alam <dr.alamsolangi at gmail.com>
> > Sent: Thursday, August 19, 2021 10:10 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] Getting different results with set.seed()
> >
> > Dear Petr,
> >
> > It is more than 2000 lines of code with a lot of functions and data
> inputs. I
> > am not sure whether it would be useful to upload it. However, you are
> > absolutely right. I used
> >
> > Step 1. Self-coded functions (these functions generate random numbers as
> well)
> >
> > Step 2: set.seed (123)
> >
> > Step 3: Call those functions.
> >
> > Step 4: model results.
> >
> > I close the R session and run the code from step 1. I get different
> results
> > for the same set of values for parameters.
> >
> > Best regards,
> > Shah
> >
> >
> >
> >
> > On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <mailto:petr.pikal at precheza.cz>
> > wrote:
> > Hi
> >
> > Please provide at least your code preferably with some data to reproduce
> > this behaviour. I wonder if anybody could help you without such
> information.
> >
> > My wild guess is that you used
> >
> > set.seed(1234)
> >
> > some code
> >
> > the code used again
> >
> > in which case you have to expect different results.
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Shah
> Alam
> >> Sent: Thursday, August 19, 2021 9:46 AM
> >> To: r-help mailing list <mailto:r-help at r-project.org>
> >> Subject: [R] Getting different results with set.seed()
> >>
> >> Dear All,
> >>
> >> I was using set.seed to reproduce the same results for the discrete
> event
> >> simulation model. I have 12 unknown parameters for optimization (just a
> >> little background). I got a good fit of parameter combinations. However,
> >> when I use those parameters combinations again in the model. I am
> getting
> >> different results.
> >>
> >> Is there any problem with the set.seed. I assume the set.seed should
> >> produce the same results.
> >>
> >> I used set.seed(1234).
> >>
> >> Best regards,
> >> Shah
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Aug 19 13:33:00 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 19 Aug 2021 14:33:00 +0300
Subject: [R] Getting different results with set.seed()
In-Reply-To: <CA+bivFjeDCbcC8Hw67heVKo68KkXVSGDaMyRJR8PBfDt7HdgaQ@mail.gmail.com>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
 <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
 <ba0057ce5c244d8ba297b30913d97d48@SRVEXCHCM1302.precheza.cz>
 <dcbb1131-9598-86c1-93cd-dafdc3366e73@eoos.dds.nl>
 <CA+bivFjeDCbcC8Hw67heVKo68KkXVSGDaMyRJR8PBfDt7HdgaQ@mail.gmail.com>
Message-ID: <CAGgJW77hMcOhhaioYkjJ6F4Y2p7ASSdZ8xZVq5kW74d+4w042Q@mail.gmail.com>

In that case, another interesting test would be to check whether the
problem exists when you don't use doParallel().


On Thu, Aug 19, 2021 at 2:28 PM Shah Alam <dr.alamsolangi at gmail.com> wrote:
>
> Dear All,
>
> Thanks a lot for your valuable suggestions. I am going to implement one by
> one.
>
> Jan:
>
> Yes, I am using the "doParallel" package for parallelization. I will let
> you know the results after implementing all the given suggestions.
>
> Best regards,
> Shah
>
>
>
> On Thu, 19 Aug 2021 at 11:57, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>
> >
> >
> > What you could also try is check if the self coded functions use the
> > random generator when defining them:
> >
> > starting_seed <- .Random.seed
> >
> > Step 1. Self-coded functions (these functions generate random numbers as
> > well)
> >
> > # check if functions have modified the seed:
> > all.equal(starting_seed, .Random.seed)
> >
> > Step 2: set.seed (123)
> >
> >
> >
> > What has also happened to me is that some of the functions I called had
> > their own random number generator independent of that of R. For example
> > using one in C/C++.
> >
> > Do your functions do stuff in parallel? For example using the parallel
> > or snow package? In that case you also have to set the seed in the
> > parallel workers.
> >
> > Best,
> > Jan
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > On 19-08-2021 11:25, PIKAL Petr wrote:
> > > Hi
> > >
> > > Did you try different order?
> > >
> > > Step 2: set.seed (123)
> > >
> > > Step 1. Self-coded functions (these functions generate random numbers as
> > well)
> > >
> > > Step 3: Call those functions.
> > >
> > > Step 4: model results.
> > >
> > > Cheers
> > > Petr.
> > >
> > > And BTW, do not use HTML formating, it could cause problems in text only
> > list.
> > >
> > >
> > > From: Shah Alam <dr.alamsolangi at gmail.com>
> > > Sent: Thursday, August 19, 2021 10:10 AM
> > > To: PIKAL Petr <petr.pikal at precheza.cz>
> > > Cc: r-help mailing list <r-help at r-project.org>
> > > Subject: Re: [R] Getting different results with set.seed()
> > >
> > > Dear Petr,
> > >
> > > It is more than 2000 lines of code with a lot of functions and data
> > inputs. I
> > > am not sure whether it would be useful to upload it. However, you are
> > > absolutely right. I used
> > >
> > > Step 1. Self-coded functions (these functions generate random numbers as
> > well)
> > >
> > > Step 2: set.seed (123)
> > >
> > > Step 3: Call those functions.
> > >
> > > Step 4: model results.
> > >
> > > I close the R session and run the code from step 1. I get different
> > results
> > > for the same set of values for parameters.
> > >
> > > Best regards,
> > > Shah
> > >
> > >
> > >
> > >
> > > On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <mailto:petr.pikal at precheza.cz>
> > > wrote:
> > > Hi
> > >
> > > Please provide at least your code preferably with some data to reproduce
> > > this behaviour. I wonder if anybody could help you without such
> > information.
> > >
> > > My wild guess is that you used
> > >
> > > set.seed(1234)
> > >
> > > some code
> > >
> > > the code used again
> > >
> > > in which case you have to expect different results.
> > >
> > > Cheers
> > > Petr
> > >
> > >> -----Original Message-----
> > >> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Shah
> > Alam
> > >> Sent: Thursday, August 19, 2021 9:46 AM
> > >> To: r-help mailing list <mailto:r-help at r-project.org>
> > >> Subject: [R] Getting different results with set.seed()
> > >>
> > >> Dear All,
> > >>
> > >> I was using set.seed to reproduce the same results for the discrete
> > event
> > >> simulation model. I have 12 unknown parameters for optimization (just a
> > >> little background). I got a good fit of parameter combinations. However,
> > >> when I use those parameters combinations again in the model. I am
> > getting
> > >> different results.
> > >>
> > >> Is there any problem with the set.seed. I assume the set.seed should
> > >> produce the same results.
> > >>
> > >> I used set.seed(1234).
> > >>
> > >> Best regards,
> > >> Shah
> > >>
> > >>        [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >> guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From no@p@m @end|ng |rom ||@@e@NA  Thu Aug 19 14:03:23 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 19 Aug 2021 14:03:23 +0200
Subject: [R] Rolling 7 day incidence
In-Reply-To: <ec15f4487c4b490382d5d465e87545ef@SRVEXCHCM1302.precheza.cz>
References: <sfg2qo$env$1@ciao.gmane.io>
 <5c953a87cabe466bbca7516d26788434@SRVEXCHCM1302.precheza.cz>
 <sfga4v$tpp$1@ciao.gmane.io>
 <ec15f4487c4b490382d5d465e87545ef@SRVEXCHCM1302.precheza.cz>
Message-ID: <sflhac$13rq$1@ciao.gmane.io>

Thanks,

I'll delve into this deepr, eventually :-)-O

el

On 17/08/2021 15:09, PIKAL Petr wrote:
> Hi
> 
> You're wellcome. You probably know
> 
> https://www.repidemicsconsortium.org/projects/
> 
> as a collection of tools for epidemy evaluation.
> 
> Cheers
> Petr
[...]
-- 
To email me replace 'nospam' with 'el'


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Aug 19 15:24:49 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 19 Aug 2021 15:24:49 +0200
Subject: [R] Getting different results with set.seed()
In-Reply-To: <CAGgJW77hMcOhhaioYkjJ6F4Y2p7ASSdZ8xZVq5kW74d+4w042Q@mail.gmail.com>
References: <CA+bivFhy6u4yV_ZqNbAtUXjrW88pacgPO0+cJqkvzkFz1+Jj=g@mail.gmail.com>
 <87d3dfcdcb9b414ba0800e6e06747845@SRVEXCHCM1302.precheza.cz>
 <CA+bivFghZbZbOF6rGLfFMz=DZJSBT=95XUktiNpeM0xNd5-dNQ@mail.gmail.com>
 <ba0057ce5c244d8ba297b30913d97d48@SRVEXCHCM1302.precheza.cz>
 <dcbb1131-9598-86c1-93cd-dafdc3366e73@eoos.dds.nl>
 <CA+bivFjeDCbcC8Hw67heVKo68KkXVSGDaMyRJR8PBfDt7HdgaQ@mail.gmail.com>
 <CAGgJW77hMcOhhaioYkjJ6F4Y2p7ASSdZ8xZVq5kW74d+4w042Q@mail.gmail.com>
Message-ID: <CAFDcVCS5o=864jdmA8U6WpCMkh8zACy18=1__8c+8A+zWhDkcg@mail.gmail.com>

You need to use %dorng% from the doRNG package instead of %dopar% when
parallelizing with foreach::foreach() to get reproducible random
numbers.  See also
https://www.jottr.org/2020/09/22/push-for-statical-sound-rng/.

/Henrik

On Thu, Aug 19, 2021 at 1:38 PM Eric Berger <ericjberger at gmail.com> wrote:
>
> In that case, another interesting test would be to check whether the
> problem exists when you don't use doParallel().
>
>
> On Thu, Aug 19, 2021 at 2:28 PM Shah Alam <dr.alamsolangi at gmail.com> wrote:
> >
> > Dear All,
> >
> > Thanks a lot for your valuable suggestions. I am going to implement one by
> > one.
> >
> > Jan:
> >
> > Yes, I am using the "doParallel" package for parallelization. I will let
> > you know the results after implementing all the given suggestions.
> >
> > Best regards,
> > Shah
> >
> >
> >
> > On Thu, 19 Aug 2021 at 11:57, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
> >
> > >
> > >
> > > What you could also try is check if the self coded functions use the
> > > random generator when defining them:
> > >
> > > starting_seed <- .Random.seed
> > >
> > > Step 1. Self-coded functions (these functions generate random numbers as
> > > well)
> > >
> > > # check if functions have modified the seed:
> > > all.equal(starting_seed, .Random.seed)
> > >
> > > Step 2: set.seed (123)
> > >
> > >
> > >
> > > What has also happened to me is that some of the functions I called had
> > > their own random number generator independent of that of R. For example
> > > using one in C/C++.
> > >
> > > Do your functions do stuff in parallel? For example using the parallel
> > > or snow package? In that case you also have to set the seed in the
> > > parallel workers.
> > >
> > > Best,
> > > Jan
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > On 19-08-2021 11:25, PIKAL Petr wrote:
> > > > Hi
> > > >
> > > > Did you try different order?
> > > >
> > > > Step 2: set.seed (123)
> > > >
> > > > Step 1. Self-coded functions (these functions generate random numbers as
> > > well)
> > > >
> > > > Step 3: Call those functions.
> > > >
> > > > Step 4: model results.
> > > >
> > > > Cheers
> > > > Petr.
> > > >
> > > > And BTW, do not use HTML formating, it could cause problems in text only
> > > list.
> > > >
> > > >
> > > > From: Shah Alam <dr.alamsolangi at gmail.com>
> > > > Sent: Thursday, August 19, 2021 10:10 AM
> > > > To: PIKAL Petr <petr.pikal at precheza.cz>
> > > > Cc: r-help mailing list <r-help at r-project.org>
> > > > Subject: Re: [R] Getting different results with set.seed()
> > > >
> > > > Dear Petr,
> > > >
> > > > It is more than 2000 lines of code with a lot of functions and data
> > > inputs. I
> > > > am not sure whether it would be useful to upload it. However, you are
> > > > absolutely right. I used
> > > >
> > > > Step 1. Self-coded functions (these functions generate random numbers as
> > > well)
> > > >
> > > > Step 2: set.seed (123)
> > > >
> > > > Step 3: Call those functions.
> > > >
> > > > Step 4: model results.
> > > >
> > > > I close the R session and run the code from step 1. I get different
> > > results
> > > > for the same set of values for parameters.
> > > >
> > > > Best regards,
> > > > Shah
> > > >
> > > >
> > > >
> > > >
> > > > On Thu, 19 Aug 2021 at 09:56, PIKAL Petr <mailto:petr.pikal at precheza.cz>
> > > > wrote:
> > > > Hi
> > > >
> > > > Please provide at least your code preferably with some data to reproduce
> > > > this behaviour. I wonder if anybody could help you without such
> > > information.
> > > >
> > > > My wild guess is that you used
> > > >
> > > > set.seed(1234)
> > > >
> > > > some code
> > > >
> > > > the code used again
> > > >
> > > > in which case you have to expect different results.
> > > >
> > > > Cheers
> > > > Petr
> > > >
> > > >> -----Original Message-----
> > > >> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Shah
> > > Alam
> > > >> Sent: Thursday, August 19, 2021 9:46 AM
> > > >> To: r-help mailing list <mailto:r-help at r-project.org>
> > > >> Subject: [R] Getting different results with set.seed()
> > > >>
> > > >> Dear All,
> > > >>
> > > >> I was using set.seed to reproduce the same results for the discrete
> > > event
> > > >> simulation model. I have 12 unknown parameters for optimization (just a
> > > >> little background). I got a good fit of parameter combinations. However,
> > > >> when I use those parameters combinations again in the model. I am
> > > getting
> > > >> different results.
> > > >>
> > > >> Is there any problem with the set.seed. I assume the set.seed should
> > > >> produce the same results.
> > > >>
> > > >> I used set.seed(1234).
> > > >>
> > > >> Best regards,
> > > >> Shah
> > > >>
> > > >>        [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide http://www.R-project.org/posting-
> > > >> guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > >>
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From n|ckmwr@y @end|ng |rom gm@||@com  Thu Aug 19 15:35:43 2021
From: n|ckmwr@y @end|ng |rom gm@||@com (Nick Wray)
Date: Thu, 19 Aug 2021 14:35:43 +0100
Subject: [R] airGR package
Message-ID: <CABxY9BN=ZsicJRRku4S_UxYDt9OWR_De==ELZu_vL0Ww+CXFfQ@mail.gmail.com>

Hi  I'm trying to get to grips with the airGR hydrological package - I've
done various searches with various questions and there seems to be a
limited amount of accessible info out there, with every site quoting the
same example run using the GR4J model.  Has anyone out there used this
package and do they have any further examples or just explanatory info
which they would be willing to share?

Thanks, Nick Wray

	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Thu Aug 19 15:50:21 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 19 Aug 2021 13:50:21 +0000 (UTC)
Subject: [R] Problem in Notrend_test()
In-Reply-To: <192635E9-C666-448E-852F-95EEB640D036@neuwirth.priv.at>
References: <944576176.46852.1629345467704.ref@mail.yahoo.com>
 <944576176.46852.1629345467704@mail.yahoo.com>
 <192635E9-C666-448E-852F-95EEB640D036@neuwirth.priv.at>
Message-ID: <652620490.239960.1629381021045@mail.yahoo.com>

Thank you for the reply and suggestions, I will look into them
The function is in the package funtimes.?

Sent from Yahoo Mail on Android 
 
  On Thu, 19 Aug 2021 at 4:36 AM, Erich Subscriptions<erich.subs at neuwirth.priv.at> wrote:   You did not give any information which package contains the function notrend_test.


> On 19.08.2021, at 05:57, bharat rawlley via R-help <r-help at r-project.org> wrote:
> 
> Hello, I have the following vector in R, 
> print(column_Data)[1] 42 33 34 28
> But I get the following error on using notrend_test on this data as follows - 
> 
> notrend_test(column_Data)Error in notrend_test(column_Data) : set a proper window.
> 
> I am unable to find any information on Stackoverflow etc. 
> Any help would be appreciated 
> Thank you
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

  

	[[alternative HTML version deleted]]


From g@be||@@ @end|ng |rom uq@net@@u  Thu Aug 19 09:51:26 2021
From: g@be||@@ @end|ng |rom uq@net@@u (George Bellas)
Date: Thu, 19 Aug 2021 07:51:26 +0000
Subject: [R] Cars2
In-Reply-To: <20210819093243.6721da2a@parabola>
References: <SYBPR01MB35165C015AAA1D7DADA01DC8C9FE9@SYBPR01MB3516.ausprd01.prod.outlook.com>
 <20210817193205.60a65b0e@trisector>
 <SYBPR01MB3516A8671CE341060098C79BC9C09@SYBPR01MB3516.ausprd01.prod.outlook.com>
 <20210819093243.6721da2a@parabola>
Message-ID: <SYBPR01MB351614EE20BCFBDAEAAA0CBAC9C09@SYBPR01MB3516.ausprd01.prod.outlook.com>

Thanks Ivan, I was a fool.

That?s the one I am looking for.

Best,
George


________________________________
From: Ivan Krylov <krylov.r00t at gmail.com>
Sent: Thursday, August 19, 2021 5:32:43 PM
To: George Bellas <g.bellas at uq.net.au>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Cars2

On Thu, 19 Aug 2021 00:12:51 +0000
George Bellas <g.bellas at uq.net.au> wrote:

> I'm still looking for it, it had car prices and car models in it. I
> couldn't find it through the r search link.

Could it be the third search result for a query of 'cars2'?

https://search.r-project.org/?P=cars2&SORT=&HITSPERPAGE=10&DB=r-manuals&DB=r-help&DB=cran-views&DB=cran-info&DB=cran-help&DB=cran-news&DB=cran-readme&DB=cran-vignettes&DEFAULTOP=and&FMT=query&xDB=cran-help&xFILTERS=.%7E%7E

->

https://search.r-project.org/CRAN/refmans/fBasics/html/data-examples.html

>> cars2 contains the price, country, reliability, mileage, type,
>> weight, engine displacement and net horsepower of various car
>> models.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Thu Aug 19 18:52:57 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 19 Aug 2021 16:52:57 +0000 (UTC)
Subject: [R] Help needed in double bar plot made using ggplot2
References: <1697104439.274263.1629391977827.ref@mail.yahoo.com>
Message-ID: <1697104439.274263.1629391977827@mail.yahoo.com>

Hello
I have tried to create the following graph using ggplot2 using the following code -?
ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? scale_y_continuous(expand = c(0,0))+? theme_classic()+? geom_text(aes(label = percentage), size = 5, position = position_dodge(width = 0.5), vjust=0)


I wanted to ask?
1) In the last plot why is the label on top not showing up even when I save the image as a pdf??
2) Is there anyway to make the labels appear in the middle of the bar? It is aligned to the left right now
3) Is there any way to change the colour of the labels on the top of the bars??
Thank you!?













-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1629391809673blob.jpg
Type: image/png
Size: 35018 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210819/8fa15ba9/attachment.png>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 19 20:07:35 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 19 Aug 2021 19:07:35 +0100
Subject: [R] Help needed in double bar plot made using ggplot2
In-Reply-To: <1697104439.274263.1629391977827@mail.yahoo.com>
References: <1697104439.274263.1629391977827.ref@mail.yahoo.com>
 <1697104439.274263.1629391977827@mail.yahoo.com>
Message-ID: <bc8ac039-899b-f040-2d57-70b82c229d5c@sapo.pt>

Hello,

First, sample data.

set.seed(2021)
year <- rep(2016:2019, 2)
percentage <- runif(length(year), 0.25, 0.70)
gender <- rep(c("M", "F"), each = 4)
graph_text <- data.frame(year, percentage, gender)


1) You have expand = c(0,0). Like this there is no space above the 
greatest bar. In order to make room, change to limits = c(0, ymax + 10 
percent).

2) Make the width of the bars larger, position_dodge(width = 0.9)

3) Assign a aesthetic color in geom_text, if you want the bars and text 
colors to be the same, assign a value outside aes() if you want only one 
color for the text. See at the end.

4) Not asked but I use scales::percent to make the percentages 
automatic. Change back to your code if not needed.



ymax <- max(graph_text$percentage)

ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = 
graph_text)+
   geom_bar(position = 'dodge', stat='identity')+
   geom_text(
     aes(label = scales::percent(percentage, accuracy = 0.1), color = 
gender),
     position = position_dodge(width = 0.9),
     size = 5,
     vjust = 0
   )+
   scale_y_continuous(
     limits = c(0, 1.1*ymax),
     labels = scales::percent
   )+
   theme_classic()


The following geom_text will change the text labels color to red.


   geom_text(
     aes(label = scales::percent(percentage, accuracy = 0.1)),
     position = position_dodge(width = 0.9),
     #
     color = "red",
     #
     size = 5,
     vjust = 0
   )



Hope this helps,

Rui Barradas

?s 17:52 de 19/08/21, bharat rawlley via R-help escreveu:
> Hello
> I have tried to create the following graph using ggplot2 using the following code -
> ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? scale_y_continuous(expand = c(0,0))+? theme_classic()+? geom_text(aes(label = percentage), size = 5, position = position_dodge(width = 0.5), vjust=0)
> 
> 
> I wanted to ask
> 1) In the last plot why is the label on top not showing up even when I save the image as a pdf?
> 2) Is there anyway to make the labels appear in the middle of the bar? It is aligned to the left right now
> 3) Is there any way to change the colour of the labels on the top of the bars?
> Thank you!
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Thu Aug 19 22:35:32 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 19 Aug 2021 20:35:32 +0000 (UTC)
Subject: [R] Help needed in double bar plot made using ggplot2
In-Reply-To: <bc8ac039-899b-f040-2d57-70b82c229d5c@sapo.pt>
References: <1697104439.274263.1629391977827.ref@mail.yahoo.com>
 <1697104439.274263.1629391977827@mail.yahoo.com>
 <bc8ac039-899b-f040-2d57-70b82c229d5c@sapo.pt>
Message-ID: <190940195.286206.1629405332904@mail.yahoo.com>

 Thank you very much for the elaborate response, Dr. Barradas! It was extremely helpful!?
This resolves all my queries except one; I am unable to assign aesthetic colors in a way that the bar and text colors remain the same. I am not sure how to exactly assign color outside of aes. I used the following code which made everything red (and I want only text on top of the red bars to be red, rest to be blue according to their bar colors)
ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? geom_text(aes(label = percentage), size = 5, position = position_dodge(width = 0.9), vjust=0, color = "Red") +?? scale_y_continuous(limits=c(0, 1.1*ymax))
Thank you very much for your time and help, Dr. Barradas!?

    On Thursday, 19 August, 2021, 02:07:44 pm GMT-4, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,

First, sample data.

set.seed(2021)
year <- rep(2016:2019, 2)
percentage <- runif(length(year), 0.25, 0.70)
gender <- rep(c("M", "F"), each = 4)
graph_text <- data.frame(year, percentage, gender)


1) You have expand = c(0,0). Like this there is no space above the 
greatest bar. In order to make room, change to limits = c(0, ymax + 10 
percent).

2) Make the width of the bars larger, position_dodge(width = 0.9)

3) Assign a aesthetic color in geom_text, if you want the bars and text 
colors to be the same, assign a value outside aes() if you want only one 
color for the text. See at the end.

4) Not asked but I use scales::percent to make the percentages 
automatic. Change back to your code if not needed.



ymax <- max(graph_text$percentage)

ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = 
graph_text)+
? geom_bar(position = 'dodge', stat='identity')+
? geom_text(
? ? aes(label = scales::percent(percentage, accuracy = 0.1), color = 
gender),
? ? position = position_dodge(width = 0.9),
? ? size = 5,
? ? vjust = 0
? )+
? scale_y_continuous(
? ? limits = c(0, 1.1*ymax),
? ? labels = scales::percent
? )+
? theme_classic()


The following geom_text will change the text labels color to red.


? geom_text(
? ? aes(label = scales::percent(percentage, accuracy = 0.1)),
? ? position = position_dodge(width = 0.9),
? ? #
? ? color = "red",
? ? #
? ? size = 5,
? ? vjust = 0
? )



Hope this helps,

Rui Barradas

?s 17:52 de 19/08/21, bharat rawlley via R-help escreveu:
> Hello
> I have tried to create the following graph using ggplot2 using the following code -
> ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? scale_y_continuous(expand = c(0,0))+? theme_classic()+? geom_text(aes(label = percentage), size = 5, position = position_dodge(width = 0.5), vjust=0)
> 
> 
> I wanted to ask
> 1) In the last plot why is the label on top not showing up even when I save the image as a pdf?
> 2) Is there anyway to make the labels appear in the middle of the bar? It is aligned to the left right now
> 3) Is there any way to change the colour of the labels on the top of the bars?
> Thank you!
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
  
	[[alternative HTML version deleted]]


From @||v@no @end|ng |rom ue|@br  Thu Aug 19 22:39:52 2021
From: @||v@no @end|ng |rom ue|@br (Silvano Cesar da Costa)
Date: Thu, 19 Aug 2021 17:39:52 -0300
Subject: [R] Selecting elements
Message-ID: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>

Hi,

I need to select 15 elements, always considering the highest values
(descending order) but obeying the following configuration:

3A - 4B - 0C - 3D or
2A - 5B - 0C - 3D or
3A - 3B - 2C - 2D

If I have, for example, 5 A elements as the highest values, I can only
choose 3 (first and third choice) or 2 (second choice) elements.

how to make this selection?


library(dplyr)

Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)

data = data.frame(Var.1, Var.2)
(data = data[order(data$Var.2, decreasing=TRUE), ])

Elements = data %>%
  arrange(desc(Var.2))

Thanks,

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 19 22:47:36 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 19 Aug 2021 21:47:36 +0100
Subject: [R] Help needed in double bar plot made using ggplot2
In-Reply-To: <190940195.286206.1629405332904@mail.yahoo.com>
References: <1697104439.274263.1629391977827.ref@mail.yahoo.com>
 <1697104439.274263.1629391977827@mail.yahoo.com>
 <bc8ac039-899b-f040-2d57-70b82c229d5c@sapo.pt>
 <190940195.286206.1629405332904@mail.yahoo.com>
Message-ID: <d3da5fd6-2b61-b5d1-9297-7282440f22d2@sapo.pt>

Hello,

Glad it helped.

As for making everything red, that only happens with the 2nd geom_text I 
posted. And this is because color = "red" is not in aes().

In the 1st geom_text, I have aes( etc , color = gender)
and this makes the color depend on gender.

To make the text and bars colors the same, put color = gender in the 
initial call to ggplot. Like this, all geom_ (layers) will inherit that 
aesthetic.

And you don't need group = gender, fill or color already group the data.


ggplot(aes(x=year, y=percentage, fill=gender, color=gender), data = 
graph_text)+
   rest_of_code


Hope this helps,

Rui Barradas

?s 21:35 de 19/08/21, bharat rawlley escreveu:
> Thank you very much for the elaborate response, Dr. Barradas! It was 
> extremely helpful!
> 
> This resolves all my queries except one; I am unable to assign aesthetic 
> colors in a way that the bar and text colors remain the same. I am not 
> sure how to exactly assign color outside of aes. I used the following 
> code which made everything red (and I want only text on top of the red 
> bars to be red, rest to be blue according to their bar colors)
> 
> ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = 
> graph_text)+
>  ? geom_bar(position = 'dodge', stat='identity')+
>  ? theme_classic()+
>  ? geom_text(aes(label = percentage), size = 5, position = 
> position_dodge(width = 0.9), vjust=0, color = "Red") +
>  ? scale_y_continuous(limits=c(0, 1.1*ymax))
> 
> Thank you very much for your time and help, Dr. Barradas!
> 
> 
> On Thursday, 19 August, 2021, 02:07:44 pm GMT-4, Rui Barradas 
> <ruipbarradas at sapo.pt> wrote:
> 
> 
> Hello,
> 
> First, sample data.
> 
> set.seed(2021)
> year <- rep(2016:2019, 2)
> percentage <- runif(length(year), 0.25, 0.70)
> gender <- rep(c("M", "F"), each = 4)
> graph_text <- data.frame(year, percentage, gender)
> 
> 
> 1) You have expand = c(0,0). Like this there is no space above the
> greatest bar. In order to make room, change to limits = c(0, ymax + 10
> percent).
> 
> 2) Make the width of the bars larger, position_dodge(width = 0.9)
> 
> 3) Assign a aesthetic color in geom_text, if you want the bars and text
> colors to be the same, assign a value outside aes() if you want only one
> color for the text. See at the end.
> 
> 4) Not asked but I use scales::percent to make the percentages
> automatic. Change back to your code if not needed.
> 
> 
> 
> ymax <- max(graph_text$percentage)
> 
> ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data =
> graph_text)+
>  ? geom_bar(position = 'dodge', stat='identity')+
>  ? geom_text(
>  ? ? aes(label = scales::percent(percentage, accuracy = 0.1), color =
> gender),
>  ? ? position = position_dodge(width = 0.9),
>  ? ? size = 5,
>  ? ? vjust = 0
>  ? )+
>  ? scale_y_continuous(
>  ? ? limits = c(0, 1.1*ymax),
>  ? ? labels = scales::percent
>  ? )+
>  ? theme_classic()
> 
> 
> The following geom_text will change the text labels color to red.
> 
> 
>  ? geom_text(
>  ? ? aes(label = scales::percent(percentage, accuracy = 0.1)),
>  ? ? position = position_dodge(width = 0.9),
>  ? ? #
>  ? ? color = "red",
>  ? ? #
>  ? ? size = 5,
>  ? ? vjust = 0
>  ? )
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 17:52 de 19/08/21, bharat rawlley via R-help escreveu:
>  > Hello
>  > I have tried to create the following graph using ggplot2 using the 
> following code -
>  > ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = 
> graph_text)+? geom_bar(position = 'dodge', stat='identity')+  
> scale_y_continuous(expand = c(0,0))+? theme_classic()+  
> geom_text(aes(label = percentage), size = 5, position = 
> position_dodge(width = 0.5), vjust=0)
>  >
>  >
>  > I wanted to ask
>  > 1) In the last plot why is the label on top not showing up even when 
> I save the image as a pdf?
>  > 2) Is there anyway to make the labels appear in the middle of the 
> bar? It is aligned to the left right now
>  > 3) Is there any way to change the colour of the labels on the top of 
> the bars?
>  > Thank you!
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  >
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>  > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
>  > and provide commented, minimal, self-contained, reproducible code.
>  >


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Fri Aug 20 00:02:08 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 19 Aug 2021 22:02:08 +0000 (UTC)
Subject: [R] Help needed in double bar plot made using ggplot2
In-Reply-To: <d3da5fd6-2b61-b5d1-9297-7282440f22d2@sapo.pt>
References: <1697104439.274263.1629391977827.ref@mail.yahoo.com>
 <1697104439.274263.1629391977827@mail.yahoo.com>
 <bc8ac039-899b-f040-2d57-70b82c229d5c@sapo.pt>
 <190940195.286206.1629405332904@mail.yahoo.com>
 <d3da5fd6-2b61-b5d1-9297-7282440f22d2@sapo.pt>
Message-ID: <118093652.275634.1629410528921@mail.yahoo.com>

 Thank you, Dr. Burradas!?
That resolved my query
Have a great rest of your day
    On Thursday, 19 August, 2021, 04:47:42 pm GMT-4, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,

Glad it helped.

As for making everything red, that only happens with the 2nd geom_text I 
posted. And this is because color = "red" is not in aes().

In the 1st geom_text, I have aes( etc , color = gender)
and this makes the color depend on gender.

To make the text and bars colors the same, put color = gender in the 
initial call to ggplot. Like this, all geom_ (layers) will inherit that 
aesthetic.

And you don't need group = gender, fill or color already group the data.


ggplot(aes(x=year, y=percentage, fill=gender, color=gender), data = 
graph_text)+
? rest_of_code


Hope this helps,

Rui Barradas

?s 21:35 de 19/08/21, bharat rawlley escreveu:
> Thank you very much for the elaborate response, Dr. Barradas! It was 
> extremely helpful!
> 
> This resolves all my queries except one; I am unable to assign aesthetic 
> colors in a way that the bar and text colors remain the same. I am not 
> sure how to exactly assign color outside of aes. I used the following 
> code which made everything red (and I want only text on top of the red 
> bars to be red, rest to be blue according to their bar colors)
> 
> ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = 
> graph_text)+
>? ? geom_bar(position = 'dodge', stat='identity')+
>? ? theme_classic()+
>? ? geom_text(aes(label = percentage), size = 5, position = 
> position_dodge(width = 0.9), vjust=0, color = "Red") +
>? ? scale_y_continuous(limits=c(0, 1.1*ymax))
> 
> Thank you very much for your time and help, Dr. Barradas!
> 
> 
> On Thursday, 19 August, 2021, 02:07:44 pm GMT-4, Rui Barradas 
> <ruipbarradas at sapo.pt> wrote:
> 
> 
> Hello,
> 
> First, sample data.
> 
> set.seed(2021)
> year <- rep(2016:2019, 2)
> percentage <- runif(length(year), 0.25, 0.70)
> gender <- rep(c("M", "F"), each = 4)
> graph_text <- data.frame(year, percentage, gender)
> 
> 
> 1) You have expand = c(0,0). Like this there is no space above the
> greatest bar. In order to make room, change to limits = c(0, ymax + 10
> percent).
> 
> 2) Make the width of the bars larger, position_dodge(width = 0.9)
> 
> 3) Assign a aesthetic color in geom_text, if you want the bars and text
> colors to be the same, assign a value outside aes() if you want only one
> color for the text. See at the end.
> 
> 4) Not asked but I use scales::percent to make the percentages
> automatic. Change back to your code if not needed.
> 
> 
> 
> ymax <- max(graph_text$percentage)
> 
> ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data =
> graph_text)+
>? ? geom_bar(position = 'dodge', stat='identity')+
>? ? geom_text(
>? ? ? aes(label = scales::percent(percentage, accuracy = 0.1), color =
> gender),
>? ? ? position = position_dodge(width = 0.9),
>? ? ? size = 5,
>? ? ? vjust = 0
>? ? )+
>? ? scale_y_continuous(
>? ? ? limits = c(0, 1.1*ymax),
>? ? ? labels = scales::percent
>? ? )+
>? ? theme_classic()
> 
> 
> The following geom_text will change the text labels color to red.
> 
> 
>? ? geom_text(
>? ? ? aes(label = scales::percent(percentage, accuracy = 0.1)),
>? ? ? position = position_dodge(width = 0.9),
>? ? ? #
>? ? ? color = "red",
>? ? ? #
>? ? ? size = 5,
>? ? ? vjust = 0
>? ? )
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 17:52 de 19/08/21, bharat rawlley via R-help escreveu:
>? > Hello
>? > I have tried to create the following graph using ggplot2 using the 
> following code -
>? > ggplot(aes(x=year, y=percentage, group=gender, fill=gender), data = 
> graph_text)+? geom_bar(position = 'dodge', stat='identity')+? 
> scale_y_continuous(expand = c(0,0))+? theme_classic()+? 
> geom_text(aes(label = percentage), size = 5, position = 
> position_dodge(width = 0.5), vjust=0)
>? >
>? >
>? > I wanted to ask
>? > 1) In the last plot why is the label on top not showing up even when 
> I save the image as a pdf?
>? > 2) Is there anyway to make the labels appear in the middle of the 
> bar? It is aligned to the left right now
>? > 3) Is there any way to change the colour of the labels on the top of 
> the bars?
>? > Thank you!
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? >
>? > ______________________________________________
>? > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
>? > https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>? > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
>? > and provide commented, minimal, self-contained, reproducible code.
>? >
  
	[[alternative HTML version deleted]]


From donm@c @end|ng |rom m@t@t@t@com  Fri Aug 20 02:55:00 2021
From: donm@c @end|ng |rom m@t@t@t@com (Donald Macnaughton)
Date: Fri, 20 Aug 2021 00:55:00 +0000
Subject: [R] Characters Failing in SVG Output
Message-ID: <0100017b610dd0b2-31439963-5db6-47f2-9fd5-f3478240cebe-000000@email.amazonses.com>

Hello list,

The following program illustrates my problem:

# The program illustrates an apparent error generating SVG files.
# Note how the figure renders properly in the R graphics window, but
# fails if you open it in in an SVG-capable viewer, such as Chrome, 
# Firefox, or Edge.

# It appears that something in the svg() device is failing to
# handle characters in higher parts of the Unicode range.

# This program runs under Windows and the system must have the Cambria
# Math font, which comes builtin with Windows.
# (The font and range below are used by the Microsoft Word equation 
# editor, so it's desirable to use the same font and range in some 
# graphics to duplicate the algebraic characters used in math
equations
# in Word documents.)

# Don Macnaughton August 2021.

# Specify where to save the generated svg file.
SVGfile = "C:/Temp/TestSVG.svg"

# Make the Cambria Math font available to R.
windowsFonts("Cambria Math"=windowsFont("Cambria Math"))

# Use a loop to draw the graph twice, once in the SVG file and once 
# in the graphics window.
for (i in 1:2){

graphics.off()

# If this is the first  pass, specify the file for the SVG graph.
if (i == 1) {svg(SVGfile)}

xvals = c(0,100)
yvals = c(0,100)

# Draw an invisible graph to establish the ranges
# using using the two points in xvals and yvals defined above.
plot(xvals, yvals, type="n", xlab=" ", ylab=" ", axes=FALSE)


llab <- '\U01d44e' # the letter a in the math italic range

text(x=1,y=60,labels=llab,family="Cambria Math",adj=0,cex=3)
text(x=7,y=63,
   labels="<- The desired lowercase math italic a in the Cambria Math
font",
   adj=0)


llab <- '\U000061' # the letter a in the standard range.

text(x=1,y=40,labels=llab,family="Cambria Math",adj=0,cex=3,font=3)
text(x=7,y=40,
   labels="<- The lowercase italic a in the standard range in the
Cambria Math font",
   adj=0)

if (i == 1) {dev.off()}

# End of the loop to draw the graph twice:
}

# End of program.

Here's my sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):
[1] compiler_4.1.1 tools_4.1.1   

Thank you for your help,

Don Macnaughton


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Aug 20 08:27:59 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 20 Aug 2021 06:27:59 +0000
Subject: [R] Selecting elements
In-Reply-To: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
Message-ID: <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>

Hallo

I am confused, maybe others know what do you want but could you be more specific?

Let say you have such data
set.seed(123)
Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)
data = data.frame(Var.1, Var.2)

What should be the desired outcome?

You can sort
data <- data[order(data$Var.2, decreasing=TRUE), ]
and split the data
> split(data$Var.2, data$Var.1)
$A
 [1] 38 35 32 31 30 22 11  8  2  1

$B
 [1] 39 28 25 23 16 15  7  6  5  4

$C
 [1] 40 36 29 26 21 19 18 14 10  9

$D
 [1] 37 34 33 27 24 20 17 13 12  3

T inspect highest values. But here I am lost. As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?

Or I do not understand at all what you really want to achieve.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Silvano Cesar da
> Costa
> Sent: Thursday, August 19, 2021 10:40 PM
> To: r-help at r-project.org
> Subject: [R] Selecting elements
> 
> Hi,
> 
> I need to select 15 elements, always considering the highest values
> (descending order) but obeying the following configuration:
> 
> 3A - 4B - 0C - 3D or
> 2A - 5B - 0C - 3D or
> 3A - 3B - 2C - 2D
> 
> If I have, for example, 5 A elements as the highest values, I can only choose
> (first and third choice) or 2 (second choice) elements.
> 
> how to make this selection?
> 
> 
> library(dplyr)
> 
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> 
> data = data.frame(Var.1, Var.2)
> (data = data[order(data$Var.2, decreasing=TRUE), ])
> 
> Elements = data %>%
>   arrange(desc(Var.2))
> 
> Thanks,
> 
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
> 
> Fone: (43) 3371-4346
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ke@ m@iii@g oii ii@uxdeveioper@xyz  Fri Aug 20 00:18:20 2021
From: ke@ m@iii@g oii ii@uxdeveioper@xyz (ke@ m@iii@g oii ii@uxdeveioper@xyz)
Date: Thu, 19 Aug 2021 22:18:20 +0000
Subject: [R] Help needed in double bar plot made using ggplot2
In-Reply-To: <118093652.275634.1629410528921@mail.yahoo.com>
References: <118093652.275634.1629410528921@mail.yahoo.com>
 <1697104439.274263.1629391977827.ref@mail.yahoo.com>
 <1697104439.274263.1629391977827@mail.yahoo.com>
 <bc8ac039-899b-f040-2d57-70b82c229d5c@sapo.pt>
 <190940195.286206.1629405332904@mail.yahoo.com>
 <d3da5fd6-2b61-b5d1-9297-7282440f22d2@sapo.pt>
Message-ID: <23ff9128a45f2280a392256e767d6a5d@linuxdeveloper.xyz>

Thanks Dr. Burradas too. i also had the same question.

regards


August 20, 2021 6:02 AM, "bharat rawlley via R-help" <r-help at r-project.org> wrote:

> Thank you, Dr. Burradas! 
> That resolved my query
> Have a great rest of your day
> On Thursday, 19 August, 2021, 04:47:42 pm GMT-4, Rui Barradas <ruipbarradas at sapo.pt> wrote: 
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 20 09:38:12 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 20 Aug 2021 00:38:12 -0700
Subject: [R] Selecting elements
In-Reply-To: <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
Message-ID: <372C42E9-DCC4-41D3-B576-DBFB6B4CE2B2@dcn.davis.ca.us>

Agreed. Need the rest of a complete example.

On August 19, 2021 11:27:59 PM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hallo
>
>I am confused, maybe others know what do you want but could you be more specific?
>
>Let say you have such data
>set.seed(123)
>Var.1 = rep(LETTERS[1:4], 10)
>Var.2 = sample(1:40, replace=FALSE)
>data = data.frame(Var.1, Var.2)
>
>What should be the desired outcome?
>
>You can sort
>data <- data[order(data$Var.2, decreasing=TRUE), ]
>and split the data
>> split(data$Var.2, data$Var.1)
>$A
> [1] 38 35 32 31 30 22 11  8  2  1
>
>$B
> [1] 39 28 25 23 16 15  7  6  5  4
>
>$C
> [1] 40 36 29 26 21 19 18 14 10  9
>
>$D
> [1] 37 34 33 27 24 20 17 13 12  3
>
>T inspect highest values. But here I am lost. As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>
>Or I do not understand at all what you really want to achieve.
>
>Cheers
>Petr
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Silvano Cesar da
>> Costa
>> Sent: Thursday, August 19, 2021 10:40 PM
>> To: r-help at r-project.org
>> Subject: [R] Selecting elements
>> 
>> Hi,
>> 
>> I need to select 15 elements, always considering the highest values
>> (descending order) but obeying the following configuration:
>> 
>> 3A - 4B - 0C - 3D or
>> 2A - 5B - 0C - 3D or
>> 3A - 3B - 2C - 2D
>> 
>> If I have, for example, 5 A elements as the highest values, I can only choose
>> (first and third choice) or 2 (second choice) elements.
>> 
>> how to make this selection?
>> 
>> 
>> library(dplyr)
>> 
>> Var.1 = rep(LETTERS[1:4], 10)
>> Var.2 = sample(1:40, replace=FALSE)
>> 
>> data = data.frame(Var.1, Var.2)
>> (data = data[order(data$Var.2, decreasing=TRUE), ])
>> 
>> Elements = data %>%
>>   arrange(desc(Var.2))
>> 
>> Thanks,
>> 
>> Prof. Dr. Silvano Cesar da Costa
>> Universidade Estadual de Londrina
>> Centro de Ci?ncias Exatas
>> Departamento de Estat?stica
>> 
>> Fone: (43) 3371-4346
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From k|mmo@e|o @end|ng |rom utu@||  Fri Aug 20 10:59:34 2021
From: k|mmo@e|o @end|ng |rom utu@|| (Kimmo Elo)
Date: Fri, 20 Aug 2021 08:59:34 +0000
Subject: [R] Find "undirected" duplicates in a tibble
Message-ID: <47d240b33b929af0e3aed792bec69d929756c684.camel@utu.fi>

Hi!

I am working with a large network data consisting of source-target
pairs stored in a tibble. Now I need to transform the directed dataset
to an undirected network data. This means, I need to keep only one
instance for pairs with the same "nodes". In other words, if my data
has one row with A (source) and B (target) and one with B (source) and
A (target), only the pair A-B should be kept.

Here an example how I have solved this problem so far:

--- snip ---

# Create some data
x<-tibble(Source=rep(1:3,4), Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
x	# print original data

# Remove "undirected" duplicates
x<-x %>% mutate(pair=mapply(function(x,y)
paste0(sort(c(x,y)),collapse="-"), Source, Target)) %>% distinct(pair,
.keep_all = T) %>% mutate(Source=sapply(pair, function(x)
unlist(strsplit(x, split="-"))[1]), Target=sapply(pair, function(x)
unlist(strsplit(x, split="-"))[2])) %>% select(-pair)

x	# print cleaned data

--- snip ---

The good thing with my own solution is that it allows the creation of
weighted pairs as well. One just needs to replace 'distinct(pair,
.keep_all=T)' with 'count(pair)'.

I have done a lot of searching but not found any function providing
this functionality. Does someone know an alternative, maybe a more
effective function/solution?

Best,

Kimmo Elo


-- 
Dr. Kimmo Elo
Senior researcher in European Studies
=====================================================
University of Turku
Centre for Parliamentary Studies
Finland
E-mail: kimmo.elo at utu.fi
=====================================================

From m|n@h@|| @end|ng |rom um|ch@edu  Fri Aug 20 13:12:23 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Fri, 20 Aug 2021 14:12:23 +0300
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: Your message of "Fri, 20 Aug 2021 08:59:34 +0000."
 <47d240b33b929af0e3aed792bec69d929756c684.camel@utu.fi>
Message-ID: <732064.1629457943@apollo2.minshall.org>

Kimmo,

i'll be curious to see other, maybe more elegant, answers.  in the
meantime, this seems to work.

----
  x = data.frame(Source=rep(1:3,4), Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
  y <- apply(x, 1, function(y) return (c(n=min(y), x=max(y))))
  res <- data.frame()
  for (n in unique(y["n",])) {
    unique(y["x",y["n",]==n])
    res <- rbind(res, data.frame(A=c(n), B=unique(y["x",y["n",]==n])))
  }
  res
----

thanks for the question!

cheers, Greg


From er|cjberger @end|ng |rom gm@||@com  Fri Aug 20 15:38:19 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 20 Aug 2021 16:38:19 +0300
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <732064.1629457943@apollo2.minshall.org>
References: <47d240b33b929af0e3aed792bec69d929756c684.camel@utu.fi>
 <732064.1629457943@apollo2.minshall.org>
Message-ID: <CAGgJW77TZAE7c4SkNBpmW_GDPJ2FAAd9BRxaMHqkRQqbNeG6zQ@mail.gmail.com>

x %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
  unique() %>% rename(Source=a, Target=b)



On Fri, Aug 20, 2021 at 2:12 PM Greg Minshall <minshall at umich.edu> wrote:

> Kimmo,
>
> i'll be curious to see other, maybe more elegant, answers.  in the
> meantime, this seems to work.
>
> ----
>   x = data.frame(Source=rep(1:3,4),
> Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
>   y <- apply(x, 1, function(y) return (c(n=min(y), x=max(y))))
>   res <- data.frame()
>   for (n in unique(y["n",])) {
>     unique(y["x",y["n",]==n])
>     res <- rbind(res, data.frame(A=c(n), B=unique(y["x",y["n",]==n])))
>   }
>   res
> ----
>
> thanks for the question!
>
> cheers, Greg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|n@h@|| @end|ng |rom um|ch@edu  Fri Aug 20 16:13:06 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Fri, 20 Aug 2021 17:13:06 +0300
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: Your message of "Fri, 20 Aug 2021 16:38:19 +0300."
 <CAGgJW77TZAE7c4SkNBpmW_GDPJ2FAAd9BRxaMHqkRQqbNeG6zQ@mail.gmail.com>
Message-ID: <770351.1629468786@apollo2.minshall.org>

Eric,

> x %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
>   unique() %>% rename(Source=a, Target=b)

ah, very nice.  i have trouble remembering, e.g., unique().

fwiw, (hopefully) here's a baser version.
----
  x = data.frame(Source=rep(1:3,4), Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))

  y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
  unique(t(y))
----

cheers, Greg


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug 20 17:43:46 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 20 Aug 2021 16:43:46 +0100
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <770351.1629468786@apollo2.minshall.org>
References: <770351.1629468786@apollo2.minshall.org>
Message-ID: <8e726835-5f3e-6f9c-95cc-73b55a433cd0@sapo.pt>

Hello,

This seems elegant to me but it's also the slowest, courtesy sort.

apply(x, 1, sort) |> t() |> unique()


(My tests show that for small inputs Greg's base apply is fastest, with 
nrow(x) > 700, Eric's dplyr is fastest)


Hope this helps,

Rui Barradas

?s 15:13 de 20/08/21, Greg Minshall escreveu:
> Eric,
> 
>> x %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
>>    unique() %>% rename(Source=a, Target=b)
> 
> ah, very nice.  i have trouble remembering, e.g., unique().
> 
> fwiw, (hopefully) here's a baser version.
> ----
>    x = data.frame(Source=rep(1:3,4), Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
> 
>    y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
>    unique(t(y))
> ----
> 
> cheers, Greg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From er|cjberger @end|ng |rom gm@||@com  Fri Aug 20 17:54:07 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 20 Aug 2021 18:54:07 +0300
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <8e726835-5f3e-6f9c-95cc-73b55a433cd0@sapo.pt>
References: <770351.1629468786@apollo2.minshall.org>
 <8e726835-5f3e-6f9c-95cc-73b55a433cd0@sapo.pt>
Message-ID: <CAGgJW75ma==YN5BLwfX8axwpOf8TG_gsPU=8AJOp_sMF+9uJ_Q@mail.gmail.com>

Nice Rui.
Here's a version in base R with no apply().

unique(data.frame(V1=pmin(x$Source,x$Target), V2=pmax(x$Source,x$Target)))

On Fri, Aug 20, 2021 at 6:43 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> This seems elegant to me but it's also the slowest, courtesy sort.
>
> apply(x, 1, sort) |> t() |> unique()
>
>
> (My tests show that for small inputs Greg's base apply is fastest, with
> nrow(x) > 700, Eric's dplyr is fastest)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 15:13 de 20/08/21, Greg Minshall escreveu:
> > Eric,
> >
> >> x %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
> >>    unique() %>% rename(Source=a, Target=b)
> >
> > ah, very nice.  i have trouble remembering, e.g., unique().
> >
> > fwiw, (hopefully) here's a baser version.
> > ----
> >    x = data.frame(Source=rep(1:3,4),
> Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
> >
> >    y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
> >    unique(t(y))
> > ----
> >
> > cheers, Greg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Fri Aug 20 18:18:42 2021
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Fri, 20 Aug 2021 12:18:42 -0400
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <47d240b33b929af0e3aed792bec69d929756c684.camel@utu.fi>
References: <47d240b33b929af0e3aed792bec69d929756c684.camel@utu.fi>
Message-ID: <CAP01uR=c8ninOB8w7JD66kC1gnwB6LMD2G8Y2ZqcxiNnreQepw@mail.gmail.com>

Since you are dealing with graphs you could consider using
the igraph package.  This is more involved than needed for
what you are
asking but it might be useful for other follow on calculations.
We first define a 2 column matrix of edges, then convert it to
an igraph and simplify it to remove duplicate edges giving g.
At the end we get an edgelist back.

  library(igraph)
  m <- matrix(c(1, 2, 6, 6, 4, 9, 1, 5, 2, 1, 8, 7, 5, 10, 6, 10), 8, 2)
  g <- m |>
    graph_from_edgelist(directed = FALSE) |>
    simplify()

  plot(g)

  g |>
    get.edgelist() |>
    as.data.frame()



On Fri, Aug 20, 2021 at 5:00 AM Kimmo Elo <kimmo.elo at utu.fi> wrote:
>
> Hi!
>
> I am working with a large network data consisting of source-target
> pairs stored in a tibble. Now I need to transform the directed dataset
> to an undirected network data. This means, I need to keep only one
> instance for pairs with the same "nodes". In other words, if my data
> has one row with A (source) and B (target) and one with B (source) and
> A (target), only the pair A-B should be kept.
>
> Here an example how I have solved this problem so far:
>
> --- snip ---
>
> # Create some data
> x<-tibble(Source=rep(1:3,4), Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
> x       # print original data
>
> # Remove "undirected" duplicates
> x<-x %>% mutate(pair=mapply(function(x,y)
> paste0(sort(c(x,y)),collapse="-"), Source, Target)) %>% distinct(pair,
> .keep_all = T) %>% mutate(Source=sapply(pair, function(x)
> unlist(strsplit(x, split="-"))[1]), Target=sapply(pair, function(x)
> unlist(strsplit(x, split="-"))[2])) %>% select(-pair)
>
> x       # print cleaned data
>
> --- snip ---
>
> The good thing with my own solution is that it allows the creation of
> weighted pairs as well. One just needs to replace 'distinct(pair,
> .keep_all=T)' with 'count(pair)'.
>
> I have done a lot of searching but not found any function providing
> this functionality. Does someone know an alternative, maybe a more
> effective function/solution?
>
> Best,
>
> Kimmo Elo
>
>
> --
> Dr. Kimmo Elo
> Senior researcher in European Studies
> =====================================================
> University of Turku
> Centre for Parliamentary Studies
> Finland
> E-mail: kimmo.elo at utu.fi
> =====================================================
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 20 19:17:18 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Aug 2021 10:17:18 -0700
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <770351.1629468786@apollo2.minshall.org>
References: <CAGgJW77TZAE7c4SkNBpmW_GDPJ2FAAd9BRxaMHqkRQqbNeG6zQ@mail.gmail.com>
 <770351.1629468786@apollo2.minshall.org>
Message-ID: <CAGxFJbSiWWZ7AJRyW9jWDEAp=sf45qLmsOkYRXQ6uY79W1wjnA@mail.gmail.com>

Note that:

1. Your solution returns a matrix, not a data frame (or Tibble)
2. Assuming that the order of the entries in the pairs does not matter
(which your solution also assumes and seems reasonable given the OP's
specification), I think that you'll find the following, which returns
the data.frame, is considerably more efficient:

x[!duplicated(cbind(do.call(pmin,x), do.call(pmax,x))),]

For example:

> x <- expand.grid(Source = 1:1000, Target = 1:1000)

>  system.time({
 y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
 unique(t(y))})
   user  system elapsed
  5.075   0.034   5.109

> system.time({
 x[!duplicated(cbind(do.call(pmin, x), do.call(pmax, x))), ]
 })
   user  system elapsed
  1.340   0.013   1.353

Still more efficient and still returning a data frame is:

w <- x[,2] > x[,1]
x[w,] <- x[w, 2:1]
unique(x)

> system.time({
 w <- x[, 2] > x[,1]
 x[w, ] <- x[w, 2:1]
 unique(x)})
   user  system elapsed
  0.693   0.011   0.703


The efficiency gains are due to vectorization and the use of more
efficient primitives. None of this may matter of course, but it seemed
worth mentioning.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 20, 2021 at 7:13 AM Greg Minshall <minshall at umich.edu> wrote:
>
> Eric,
>
> > x %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
> >   unique() %>% rename(Source=a, Target=b)
>
> ah, very nice.  i have trouble remembering, e.g., unique().
>
> fwiw, (hopefully) here's a baser version.
> ----
>   x = data.frame(Source=rep(1:3,4), Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
>
>   y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
>   unique(t(y))
> ----
>
> cheers, Greg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @||v@no @end|ng |rom ue|@br  Fri Aug 20 21:27:50 2021
From: @||v@no @end|ng |rom ue|@br (Silvano Cesar da Costa)
Date: Fri, 20 Aug 2021 16:27:50 -0300
Subject: [R] Selecting elements
In-Reply-To: <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>

Hi, thanks you for the answer.
Sorry English is not my native language.

But you got it right.
> As C is first and fourth biggest value, you follow third option and
select 3 highest A, 3B 2C and 2D?

I must select the 10 (not 15) highest values, but which follow a certain
order:
3A - 3B - 2C - 2D     or
2A - 5B - 0C - 3D     or
3A - 3B - 2C - 2D

I'll put the example in Excel for a better understanding (with 20 elements
only).
I must select 10 elements (the highest values of variable Var.2), which fit
one of the 3 options above.

Number Position Var.1 Var.2
1 27 C 40
2 30 B 39 Selected:
3 5 A 38 Number Position Var.1 Var.2
4 16 D 37 1 27 C 40
5 23 C 36 2 30 B 39   3A - 3B - 2C - 2D
6 13 A 35 3 5 A 38
7 20 D 34 4 16 D 37 3A - 3B - 1C - 3D
8 12 D 33 5 23 C 36
9 9 A 32 6 13 A 35 2A - 5B - 0C - 3D
10 1 A 31 7 20 D 34
11 21 A 30 10 9 A 32
12 35 C 29 13 14 B 28
13 14 B 28 17 6 B 25
14 8 D 27
15 7 C 26
16 6 B 25
17 40 D 24
18 26 B 23
19 29 A 22
20 31 C 21



Second option (other data set):

Number Position Var.1 Var.2
1 36 D 20
2 11 B 19 Selected:
3 39 A 18 Number Position Var.1 Var.2
4 24 D 17 1 36 D 20
5 34 B 16 2 11 B 19   3A - 3B - 2C - 2D
6 2 B 15 3 39 A 18
7 3 A 14 4 24 D 17   3A - 3B - 1C - 3D
8 32 D 13 5 34 B 16
9 28 D 12 6 2 B 15 2A - 5B - 0C - 3D
10 25 A 11 7 3 A 14
11 19 B 10 8 32 D 13
12 15 B 9 9 25 A 11
13 17 A 8 10 18 C 7
14 18 C 7
15 38 B 6
16 10 B 5
17 22 B 4
18 4 D 3
19 33 A 2
20 37 A 1


How to make the selection of these 10 elements that fit one of the 3
options using R?

Thanks,

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <petr.pikal at precheza.cz>
escreveu:

> Hallo
>
> I am confused, maybe others know what do you want but could you be more
> specific?
>
> Let say you have such data
> set.seed(123)
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> data = data.frame(Var.1, Var.2)
>
> What should be the desired outcome?
>
> You can sort
> data <- data[order(data$Var.2, decreasing=TRUE), ]
> and split the data
> > split(data$Var.2, data$Var.1)
> $A
>  [1] 38 35 32 31 30 22 11  8  2  1
>
> $B
>  [1] 39 28 25 23 16 15  7  6  5  4
>
> $C
>  [1] 40 36 29 26 21 19 18 14 10  9
>
> $D
>  [1] 37 34 33 27 24 20 17 13 12  3
>
> T inspect highest values. But here I am lost. As C is first and fourth
> biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>
> Or I do not understand at all what you really want to achieve.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Silvano Cesar
> da
> > Costa
> > Sent: Thursday, August 19, 2021 10:40 PM
> > To: r-help at r-project.org
> > Subject: [R] Selecting elements
> >
> > Hi,
> >
> > I need to select 15 elements, always considering the highest values
> > (descending order) but obeying the following configuration:
> >
> > 3A - 4B - 0C - 3D or
> > 2A - 5B - 0C - 3D or
> > 3A - 3B - 2C - 2D
> >
> > If I have, for example, 5 A elements as the highest values, I can only
> choose
> > (first and third choice) or 2 (second choice) elements.
> >
> > how to make this selection?
> >
> >
> > library(dplyr)
> >
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> >
> > data = data.frame(Var.1, Var.2)
> > (data = data[order(data$Var.2, decreasing=TRUE), ])
> >
> > Elements = data %>%
> >   arrange(desc(Var.2))
> >
> > Thanks,
> >
> > Prof. Dr. Silvano Cesar da Costa
> > Universidade Estadual de Londrina
> > Centro de Ci?ncias Exatas
> > Departamento de Estat?stica
> >
> > Fone: (43) 3371-4346
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|n@h@|| @end|ng |rom um|ch@edu  Fri Aug 20 21:39:08 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Fri, 20 Aug 2021 22:39:08 +0300
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: Your message of "Fri, 20 Aug 2021 10:17:18 -0700."
 <CAGxFJbSiWWZ7AJRyW9jWDEAp=sf45qLmsOkYRXQ6uY79W1wjnA@mail.gmail.com>
Message-ID: <838195.1629488348@apollo2.minshall.org>

Bert,

> The efficiency gains are due to vectorization and the use of more
> efficient primitives. None of this may matter of course, but it seemed
> worth mentioning.

thanks very much!  the varieties of code, and disparities of
performance, are truly wonderful.

Rui's point that what works better for small n is not necessarily what
will work better for large n is important to keep in [my] mind.

as a "so-far" summary, here are some timings.  the relevant code is below.
----
my apply
   user  system elapsed 
  8.397   0.124   8.531 
Bert's !duplicated
   user  system elapsed 
  2.367   0.000   2.370 
Bert's x[,2]>x[,1]
   user  system elapsed 
  1.052   0.000   1.054 
my a.d.f(unique(cbind(do.call)))
   user  system elapsed 
  3.909   0.000   3.914 
Eric Berger's unique(...pmin...pmax)
   user  system elapsed 
  0.848   0.000   0.850 
Eric Berger's transmuting tibble...
   user  system elapsed 
  0.986   0.000   0.988 
Kimmo Elo's [OP] mutating paste
   user  system elapsed 
 52.079   0.000  52.136 
Rui Barradas' sort-based
   user  system elapsed 
 42.327   0.080  42.450 
----

cheers, Greg

----
n <- 1000
x <- expand.grid(Source = 1:n, Target = 1:n)

cat("my apply\n")
system.time({
 y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
 unique(t(y))})
#   user  system elapsed
#  5.075   0.034   5.109

cat("Bert's !duplicated\n")
system.time({
 x[!duplicated(cbind(do.call(pmin, x), do.call(pmax, x))), ]
 })
#   user  system elapsed
#  1.340   0.013   1.353

# Still more efficient and still returning a data frame is:
cat("Bert's x[,2]>x[,1]\n")
system.time({
 w <- x[, 2] > x[,1]
 x[w, ] <- x[w, 2:1]
 unique(x)})
#   user  system elapsed
#  0.693   0.011   0.703

cat("my a.d.f(unique(cbind(do.call)))\n")
system.time({
  as.data.frame(unique(cbind(A=do.call(pmin,x), B=do.call(pmax,x))))
})

cat("Eric Berger's unique(...pmin...pmax)\n")
system.time({
  unique(data.frame(V1=pmin(x$Source,x$Target), V2=pmax(x$Source,x$Target)))
})

cat("Eric Berger's transmuting tibble...\n")
require(dplyr)
xt<-tibble(x)
system.time({
  xt %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
    unique() %>% rename(Source=a, Target=b)
})

cat("Kimmo Elo's [OP] mutating paste\n")
system.time({
  xt %>%
    mutate(pair=mapply(function(x,y)
      paste0(sort(c(x,y)),collapse="-"), Source, Target)) %>%
    distinct(pair,
             .keep_all = T) %>%
    mutate(Source=sapply(pair, function(x)
      unlist(strsplit(x, split="-"))[1]), Target=sapply(pair, function(x)
        unlist(strsplit(x, split="-"))[2])) %>%
    select(-pair)
})

cat("Rui Barradas' sort-based\n")
system.time({
  apply(x, 1, sort) |> t() |> unique()
})


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug 21 00:42:35 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Aug 2021 15:42:35 -0700
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <838195.1629488348@apollo2.minshall.org>
References: <CAGxFJbSiWWZ7AJRyW9jWDEAp=sf45qLmsOkYRXQ6uY79W1wjnA@mail.gmail.com>
 <838195.1629488348@apollo2.minshall.org>
Message-ID: <CAGxFJbQ9Gv7m_f83go01O4Xi5ZjP94MGeMdDYdK5suwJe5FNqg@mail.gmail.com>

Thanks, Greg.

Turns out that there's an even faster alternative. Note that the OP
asked whether one could include in the result the counts of each
unordered pair, which I assume could be either 2 or 1. This can be
done easily using table(), and it's quite a bit faster for my 1
million pair example. Herewith the details, which I'll define as
functions for convenience.

## my earlier attempt using unique():
 g <- function(x) {
   w <- x[,2] > x[, 1]
   x[w,] <- x[w, 2:1]
   unique(x)
}

## present version using table():
f <- function(x){
   w <- x[,2] > x[,1]
   x[w, ] <- x[w, 2:1]
   x$counts <- as.vector(table(x)) ## drop the dim
   x[x$counts>0, ]
}

>  y <- expand.grid(source =1:4, target = 1:3)
> g(y)
   source target
1       1      1
2       2      1
3       3      1
4       4      1
6       2      2
7       3      2
8       4      2
11      3      3
12      4      3
> f(y)
   source target counts
1       1      1      1
2       2      1      2
3       3      1      2
4       4      1      1
6       2      2      1
7       3      2      2
8       4      2      1
11      3      3      1
12      4      3      1

## Timing:
> y <- expand.grid(sample.int(1000), sample.int(1000))
##
> system.time(g(y))
   user  system elapsed
  0.896   0.027   0.924
##
> system.time(f(y))
   user  system elapsed
  0.142   0.009   0.151

And, yes, I was surprised by this, too.

Again, it may not matter, but it is interesting.
Your mileage may vary, of course.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 20, 2021 at 12:39 PM Greg Minshall <minshall at umich.edu> wrote:
>
> Bert,
>
> > The efficiency gains are due to vectorization and the use of more
> > efficient primitives. None of this may matter of course, but it seemed
> > worth mentioning.
>
> thanks very much!  the varieties of code, and disparities of
> performance, are truly wonderful.
>
> Rui's point that what works better for small n is not necessarily what
> will work better for large n is important to keep in [my] mind.
>
> as a "so-far" summary, here are some timings.  the relevant code is below.
> ----
> my apply
>    user  system elapsed
>   8.397   0.124   8.531
> Bert's !duplicated
>    user  system elapsed
>   2.367   0.000   2.370
> Bert's x[,2]>x[,1]
>    user  system elapsed
>   1.052   0.000   1.054
> my a.d.f(unique(cbind(do.call)))
>    user  system elapsed
>   3.909   0.000   3.914
> Eric Berger's unique(...pmin...pmax)
>    user  system elapsed
>   0.848   0.000   0.850
> Eric Berger's transmuting tibble...
>    user  system elapsed
>   0.986   0.000   0.988
> Kimmo Elo's [OP] mutating paste
>    user  system elapsed
>  52.079   0.000  52.136
> Rui Barradas' sort-based
>    user  system elapsed
>  42.327   0.080  42.450
> ----
>
> cheers, Greg
>
> ----
> n <- 1000
> x <- expand.grid(Source = 1:n, Target = 1:n)
>
> cat("my apply\n")
> system.time({
>  y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
>  unique(t(y))})
> #   user  system elapsed
> #  5.075   0.034   5.109
>
> cat("Bert's !duplicated\n")
> system.time({
>  x[!duplicated(cbind(do.call(pmin, x), do.call(pmax, x))), ]
>  })
> #   user  system elapsed
> #  1.340   0.013   1.353
>
> # Still more efficient and still returning a data frame is:
> cat("Bert's x[,2]>x[,1]\n")
> system.time({
>  w <- x[, 2] > x[,1]
>  x[w, ] <- x[w, 2:1]
>  unique(x)})
> #   user  system elapsed
> #  0.693   0.011   0.703
>
> cat("my a.d.f(unique(cbind(do.call)))\n")
> system.time({
>   as.data.frame(unique(cbind(A=do.call(pmin,x), B=do.call(pmax,x))))
> })
>
> cat("Eric Berger's unique(...pmin...pmax)\n")
> system.time({
>   unique(data.frame(V1=pmin(x$Source,x$Target), V2=pmax(x$Source,x$Target)))
> })
>
> cat("Eric Berger's transmuting tibble...\n")
> require(dplyr)
> xt<-tibble(x)
> system.time({
>   xt %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
>     unique() %>% rename(Source=a, Target=b)
> })
>
> cat("Kimmo Elo's [OP] mutating paste\n")
> system.time({
>   xt %>%
>     mutate(pair=mapply(function(x,y)
>       paste0(sort(c(x,y)),collapse="-"), Source, Target)) %>%
>     distinct(pair,
>              .keep_all = T) %>%
>     mutate(Source=sapply(pair, function(x)
>       unlist(strsplit(x, split="-"))[1]), Target=sapply(pair, function(x)
>         unlist(strsplit(x, split="-"))[2])) %>%
>     select(-pair)
> })
>
> cat("Rui Barradas' sort-based\n")
> system.time({
>   apply(x, 1, sort) |> t() |> unique()
> })


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 21 01:14:00 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 20 Aug 2021 16:14:00 -0700
Subject: [R] Selecting elements
In-Reply-To: <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
Message-ID: <36035388-D6DF-4DA4-95CB-474F25FA7424@dcn.davis.ca.us>

Well, I don't think language is as much of a problem as your failure to compose your messages using plain text format. Your examples are all mushed together since the mailing list removes formatting. See what we see below for example.

On August 20, 2021 12:27:50 PM PDT, Silvano Cesar da Costa <silvano at uel.br> wrote:
>Hi, thanks you for the answer.
>Sorry English is not my native language.
>
>But you got it right.
>> As C is first and fourth biggest value, you follow third option and
>select 3 highest A, 3B 2C and 2D?
>
>I must select the 10 (not 15) highest values, but which follow a certain
>order:
>3A - 3B - 2C - 2D     or
>2A - 5B - 0C - 3D     or
>3A - 3B - 2C - 2D
>
>I'll put the example in Excel for a better understanding (with 20 elements
>only).
>I must select 10 elements (the highest values of variable Var.2), which fit
>one of the 3 options above.
>
>Number Position Var.1 Var.2
>1 27 C 40
>2 30 B 39 Selected:
>3 5 A 38 Number Position Var.1 Var.2
>4 16 D 37 1 27 C 40
>5 23 C 36 2 30 B 39   3A - 3B - 2C - 2D
>6 13 A 35 3 5 A 38
>7 20 D 34 4 16 D 37 3A - 3B - 1C - 3D
>8 12 D 33 5 23 C 36
>9 9 A 32 6 13 A 35 2A - 5B - 0C - 3D
>10 1 A 31 7 20 D 34
>11 21 A 30 10 9 A 32
>12 35 C 29 13 14 B 28
>13 14 B 28 17 6 B 25
>14 8 D 27
>15 7 C 26
>16 6 B 25
>17 40 D 24
>18 26 B 23
>19 29 A 22
>20 31 C 21
>
>
>
>Second option (other data set):
>
>Number Position Var.1 Var.2
>1 36 D 20
>2 11 B 19 Selected:
>3 39 A 18 Number Position Var.1 Var.2
>4 24 D 17 1 36 D 20
>5 34 B 16 2 11 B 19   3A - 3B - 2C - 2D
>6 2 B 15 3 39 A 18
>7 3 A 14 4 24 D 17   3A - 3B - 1C - 3D
>8 32 D 13 5 34 B 16
>9 28 D 12 6 2 B 15 2A - 5B - 0C - 3D
>10 25 A 11 7 3 A 14
>11 19 B 10 8 32 D 13
>12 15 B 9 9 25 A 11
>13 17 A 8 10 18 C 7
>14 18 C 7
>15 38 B 6
>16 10 B 5
>17 22 B 4
>18 4 D 3
>19 33 A 2
>20 37 A 1
>
>
>How to make the selection of these 10 elements that fit one of the 3
>options using R?
>
>Thanks,
>
>Prof. Dr. Silvano Cesar da Costa
>Universidade Estadual de Londrina
>Centro de Ci?ncias Exatas
>Departamento de Estat?stica
>
>Fone: (43) 3371-4346
>
>
>Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <petr.pikal at precheza.cz>
>escreveu:
>
>> Hallo
>>
>> I am confused, maybe others know what do you want but could you be more
>> specific?
>>
>> Let say you have such data
>> set.seed(123)
>> Var.1 = rep(LETTERS[1:4], 10)
>> Var.2 = sample(1:40, replace=FALSE)
>> data = data.frame(Var.1, Var.2)
>>
>> What should be the desired outcome?
>>
>> You can sort
>> data <- data[order(data$Var.2, decreasing=TRUE), ]
>> and split the data
>> > split(data$Var.2, data$Var.1)
>> $A
>>  [1] 38 35 32 31 30 22 11  8  2  1
>>
>> $B
>>  [1] 39 28 25 23 16 15  7  6  5  4
>>
>> $C
>>  [1] 40 36 29 26 21 19 18 14 10  9
>>
>> $D
>>  [1] 37 34 33 27 24 20 17 13 12  3
>>
>> T inspect highest values. But here I am lost. As C is first and fourth
>> biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>>
>> Or I do not understand at all what you really want to achieve.
>>
>> Cheers
>> Petr
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Silvano Cesar
>> da
>> > Costa
>> > Sent: Thursday, August 19, 2021 10:40 PM
>> > To: r-help at r-project.org
>> > Subject: [R] Selecting elements
>> >
>> > Hi,
>> >
>> > I need to select 15 elements, always considering the highest values
>> > (descending order) but obeying the following configuration:
>> >
>> > 3A - 4B - 0C - 3D or
>> > 2A - 5B - 0C - 3D or
>> > 3A - 3B - 2C - 2D
>> >
>> > If I have, for example, 5 A elements as the highest values, I can only
>> choose
>> > (first and third choice) or 2 (second choice) elements.
>> >
>> > how to make this selection?
>> >
>> >
>> > library(dplyr)
>> >
>> > Var.1 = rep(LETTERS[1:4], 10)
>> > Var.2 = sample(1:40, replace=FALSE)
>> >
>> > data = data.frame(Var.1, Var.2)
>> > (data = data[order(data$Var.2, decreasing=TRUE), ])
>> >
>> > Elements = data %>%
>> >   arrange(desc(Var.2))
>> >
>> > Thanks,
>> >
>> > Prof. Dr. Silvano Cesar da Costa
>> > Universidade Estadual de Londrina
>> > Centro de Ci?ncias Exatas
>> > Departamento de Estat?stica
>> >
>> > Fone: (43) 3371-4346
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m|n@h@|| @end|ng |rom um|ch@edu  Sat Aug 21 12:06:53 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Sat, 21 Aug 2021 13:06:53 +0300
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: Your message of "Fri, 20 Aug 2021 15:42:35 -0700."
 <CAGxFJbQ9Gv7m_f83go01O4Xi5ZjP94MGeMdDYdK5suwJe5FNqg@mail.gmail.com>
Message-ID: <1011104.1629540413@apollo2.minshall.org>

Bert,

> Turns out that there's an even faster alternative.

hah, but i'm *not* surprised.  thanks for sharing the (current)
low-price leader!

and, thanks, again, to Kimmo for posting such a productive question!

cheers, Greg

----
my apply
   user  system elapsed 
  8.465   0.103   8.578 
Bert's !duplicated
   user  system elapsed 
  2.397   0.000   2.399 
Bert's x[,2]>x[,1]
   user  system elapsed 
  1.068   0.000   1.069 
Bert's table()-based   user  system elapsed 
  0.235   0.000   0.235 
my a.d.f(unique(cbind(do.call)))
   user  system elapsed 
  4.470   0.000   4.475 
Eric Berger's unique(...pmin...pmax)
   user  system elapsed 
  0.820   0.017   0.837 
Eric Berger's transmuting tibble...
   user  system elapsed 
  0.936   0.000   0.938 
Kimmo Elo's [OP] mutating paste
   user  system elapsed 
 50.769   0.000  50.821 
Rui Barradas' sort-based
   user  system elapsed 
 42.001   0.053  42.112 
----

----
n <- 1000
x <- expand.grid(Source = 1:n, Target = 1:n)

cat("my apply\n")
system.time({
 y <- apply(x, 1, function(y) return (c(A=min(y), B=max(y))))
 unique(t(y))})
#   user  system elapsed
#  5.075   0.034   5.109

cat("Bert's !duplicated\n")
system.time({
 x[!duplicated(cbind(do.call(pmin, x), do.call(pmax, x))), ]
 })
#   user  system elapsed
#  1.340   0.013   1.353

# Still more efficient and still returning a data frame is:
cat("Bert's x[,2]>x[,1]\n")
system.time({
 w <- x[, 2] > x[,1]
 x[w, ] <- x[w, 2:1]
 unique(x)})
#   user  system elapsed
#  0.693   0.011   0.703

cat("Bert's table()-based")
f <- function(x){
   w <- x[,2] > x[,1]
   x[w, ] <- x[w, 2:1]
   x$counts <- as.vector(table(x)) ## drop the dim
   x[x$counts>0, ]
}
system.time({
  f(x)
})

cat("my a.d.f(unique(cbind(do.call)))\n")
system.time({
  as.data.frame(unique(cbind(A=do.call(pmin,x), B=do.call(pmax,x))))
})

cat("Eric Berger's unique(...pmin...pmax)\n")
system.time({
  unique(data.frame(V1=pmin(x$Source,x$Target), V2=pmax(x$Source,x$Target)))
})

cat("Eric Berger's transmuting tibble...\n")
require(dplyr)
xt<-tibble(x)
system.time({
  xt %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
    unique() %>% rename(Source=a, Target=b)
})

cat("Kimmo Elo's [OP] mutating paste\n")
system.time({
  xt %>%
    mutate(pair=mapply(function(x,y)
      paste0(sort(c(x,y)),collapse="-"), Source, Target)) %>%
    distinct(pair,
             .keep_all = T) %>%
    mutate(Source=sapply(pair, function(x)
      unlist(strsplit(x, split="-"))[1]), Target=sapply(pair, function(x)
        unlist(strsplit(x, split="-"))[2])) %>%
    select(-pair)
})

cat("Rui Barradas' sort-based\n")
system.time({
  apply(x, 1, sort) |> t() |> unique()
})


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Sat Aug 21 23:46:59 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Sat, 21 Aug 2021 21:46:59 +0000 (UTC)
Subject: [R] Help needed with ggplot2
References: <1522896138.708155.1629582419338.ref@mail.yahoo.com>
Message-ID: <1522896138.708155.1629582419338@mail.yahoo.com>


Hello, on using the following code for the following data, the graph I get has an x axis where years are mentioned as 2012.5, 2017.5 etc.?

I have the following questions -?
Q1 How can I make the years on x axis as 2011, 2012, 2013, 2014 and so on..?
Q2 Is there any way to create a small gap between the red and blue bars for aesthetic purposes
Q3 Is there anyway to make the text on top of the bars bolder or thicker??
Thank you

code -?
ymax <- max(graph_text$percentage)ggplot(aes(x=year, y=percentage, color = gender, fill=gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? geom_text(aes(label = percentage), size = 4, position = position_dodge(width = 1.1), vjust=-0.2) +?? scale_y_continuous(limits=c(0, 1.4*ymax))


| 57.14 | 2020 | ?male |
| 29.76 | 2020? | female |
| 69.32 | 2019? | male |
| 28.41 | 2019 | ?female |
| 57.89 | 2018 | ?male |
| 34.21 | 2018? | female |
| 58.59 | 2017 | ?male |
| 33.33 | 2017? | female |
| 48.42 | 2016? | male |
| 42.11 | 2016 | ?female |
| 59.77 | 2015 | ?male |
| 29.89 | 2015 | ?female |
| 72.13 | 2014 | ?male |
| 18.03 | 2014 | ?female |
| 53.33 | 2013 | ?male |
| 33.33 | 2013 | ?female |
| 55.1 | 2012 | ?male |
| 40.82 | 2012? | female |
| 46.55 | 2011? | male |
| 37.93 | 2011? | female |






-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1629581970448blob.jpg
Type: image/png
Size: 42813 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210821/b2079a33/attachment.png>

From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug 21 23:56:54 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 21 Aug 2021 14:56:54 -0700
Subject: [R] Help needed with ggplot2
In-Reply-To: <1522896138.708155.1629582419338@mail.yahoo.com>
References: <1522896138.708155.1629582419338.ref@mail.yahoo.com>
 <1522896138.708155.1629582419338@mail.yahoo.com>
Message-ID: <CAGxFJbTOGs=pn289n4o66hc0pSjDO0fbQw0B2NgALVSdj0N+Xw@mail.gmail.com>

See ?dput for how to provide a reproducible example (a reprex). Or see here:
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

It will improve your chance of getting a helpful and quick response.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Aug 21, 2021 at 2:47 PM bharat rawlley via R-help
<r-help at r-project.org> wrote:
>
>
> Hello, on using the following code for the following data, the graph I get has an x axis where years are mentioned as 2012.5, 2017.5 etc.
>
> I have the following questions -
> Q1 How can I make the years on x axis as 2011, 2012, 2013, 2014 and so on..
> Q2 Is there any way to create a small gap between the red and blue bars for aesthetic purposes
> Q3 Is there anyway to make the text on top of the bars bolder or thicker?
> Thank you
>
> code -
> ymax <- max(graph_text$percentage)ggplot(aes(x=year, y=percentage, color = gender, fill=gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  geom_text(aes(label = percentage), size = 4, position = position_dodge(width = 1.1), vjust=-0.2) +   scale_y_continuous(limits=c(0, 1.4*ymax))
>
>
> | 57.14 | 2020 |  male |
> | 29.76 | 2020  | female |
> | 69.32 | 2019  | male |
> | 28.41 | 2019 |  female |
> | 57.89 | 2018 |  male |
> | 34.21 | 2018  | female |
> | 58.59 | 2017 |  male |
> | 33.33 | 2017  | female |
> | 48.42 | 2016  | male |
> | 42.11 | 2016 |  female |
> | 59.77 | 2015 |  male |
> | 29.89 | 2015 |  female |
> | 72.13 | 2014 |  male |
> | 18.03 | 2014 |  female |
> | 53.33 | 2013 |  male |
> | 33.33 | 2013 |  female |
> | 55.1 | 2012 |  male |
> | 40.82 | 2012  | female |
> | 46.55 | 2011  | male |
> | 37.93 | 2011  | female |
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Sun Aug 22 00:23:32 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Sat, 21 Aug 2021 22:23:32 +0000 (UTC)
Subject: [R] Help needed with ggplot2
In-Reply-To: <CAGxFJbTOGs=pn289n4o66hc0pSjDO0fbQw0B2NgALVSdj0N+Xw@mail.gmail.com>
References: <1522896138.708155.1629582419338.ref@mail.yahoo.com>
 <1522896138.708155.1629582419338@mail.yahoo.com>
 <CAGxFJbTOGs=pn289n4o66hc0pSjDO0fbQw0B2NgALVSdj0N+Xw@mail.gmail.com>
Message-ID: <1380350883.720390.1629584612603@mail.yahoo.com>

 Thank you, I have tried to do a better job here -?



Data -?
email <- structure(list(percentage = c(57.14, 29.76, 69.32, 28.41, 57.89,?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?34.21, 58.59, 33.33, 48.42, 42.11, 59.77, 29.89, 72.13, 18.03,?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?53.33, 33.33, 55.1, 40.82, 46.55, 37.93), year = c(2020L, 2020L,?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2019L, 2019L, 2018L, 2018L, 2017L, 2017L, 2016L, 2016L, 2015L,?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2015L, 2014L, 2014L, 2013L, 2013L, 2012L, 2012L, 2011L, 2011L? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?), gender = c("male", "female", "male", "female", "male", "female",?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"male", "female", "male", "female", "male", "female", "male",?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?"female", "male", "female", "male", "female", "male", "female"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)), class = "data.frame", row.names = c(NA, -20L))



Code -?
ymax <- max(graph_text$percentage)ggplot(aes(x=year, y=percentage, color = gender, fill=gender, data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? geom_text(aes(label = percentage), size = 4, position = position_dodge(width = 1.1), vjust=-0.2) +?? scale_y_continuous(limits=c(0, 1.4*ymax))



Session info -?
R version 4.1.0 (2021-05-18)Platform: x86_64-w64-mingw32/x64 (64-bit)Running under: Windows 10 x64 (build 19042)
Matrix products: default
locale:[1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252? ? LC_MONETARY=English_India.1252[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252? ??
attached base packages:[1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base? ? ?
loaded via a namespace (and not attached):?[1] fansi_0.5.0? ? ? assertthat_0.2.1 dplyr_1.0.6? ? ? crayon_1.4.1? ? ?utf8_1.2.1? ? ???[6] grid_4.1.0? ? ? ?R6_2.5.0? ? ? ? ?DBI_1.1.1? ? ? ? lifecycle_1.0.0? gtable_0.3.0? ??[11] magrittr_2.0.1? ?scales_1.1.1? ? ?ggplot2_3.3.3? ? pillar_1.6.1? ? ?rlang_0.4.11? ??[16] generics_0.1.0? ?vctrs_0.3.8? ? ? ellipsis_0.3.2? ?tools_4.1.0? ? ? glue_1.4.2? ? ??[21] purrr_0.3.4? ? ? munsell_0.5.0? ? compiler_4.1.0? ?pkgconfig_2.0.3? colorspace_2.0-1[26] tidyselect_1.1.1 tibble_3.1.2? ??


I have the following questions -?
Q1 How can I make the years appear on x axis as 2011, 2012, 2013, 2014 and so on (earlier they were showing up as 2012.5 etc. which has disappeared now for reason I do not know)
Q2 Is there any way to create a small gap between the red and blue bars for aesthetic purposes
Q3 Is there anyway to make the text on top of the bars bolder or thicker??
Thank you




    On Saturday, 21 August, 2021, 05:57:09 pm GMT-4, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 See ?dput for how to provide a reproducible example (a reprex). Or see here:
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

It will improve your chance of getting a helpful and quick response.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Aug 21, 2021 at 2:47 PM bharat rawlley via R-help
<r-help at r-project.org> wrote:
>
>
> Hello, on using the following code for the following data, the graph I get has an x axis where years are mentioned as 2012.5, 2017.5 etc.
>
> I have the following questions -
> Q1 How can I make the years on x axis as 2011, 2012, 2013, 2014 and so on..
> Q2 Is there any way to create a small gap between the red and blue bars for aesthetic purposes
> Q3 Is there anyway to make the text on top of the bars bolder or thicker?
> Thank you
>
> code -
> ymax <- max(graph_text$percentage)ggplot(aes(x=year, y=percentage, color = gender, fill=gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? geom_text(aes(label = percentage), size = 4, position = position_dodge(width = 1.1), vjust=-0.2) +? scale_y_continuous(limits=c(0, 1.4*ymax))
>
>
> | 57.14 | 2020 |? male |
> | 29.76 | 2020? | female |
> | 69.32 | 2019? | male |
> | 28.41 | 2019 |? female |
> | 57.89 | 2018 |? male |
> | 34.21 | 2018? | female |
> | 58.59 | 2017 |? male |
> | 33.33 | 2017? | female |
> | 48.42 | 2016? | male |
> | 42.11 | 2016 |? female |
> | 59.77 | 2015 |? male |
> | 29.89 | 2015 |? female |
> | 72.13 | 2014 |? male |
> | 18.03 | 2014 |? female |
> | 53.33 | 2013 |? male |
> | 33.33 | 2013 |? female |
> | 55.1 | 2012 |? male |
> | 40.82 | 2012? | female |
> | 46.55 | 2011? | male |
> | 37.93 | 2011? | female |
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1629584566984blob.jpg
Type: image/png
Size: 39551 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210821/93aa7a3e/attachment.png>

From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sun Aug 22 00:55:08 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Sun, 22 Aug 2021 03:55:08 +0500
Subject: [R] differential gene expression
Message-ID: <CAG0CrLgCXh9mMJ4Tv_oCz9tGrtJthaLRkq3dKOXrKQhJwXMMyQ@mail.gmail.com>

I have this data:
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE162562&fbclid=IwAR0iZQhttG8HzGhFIIMWbFgNszQrVDgiyVChYzQ_ypCx_d-1pn_tm7STjGs

and I want to compare:
healthy vs Mild healthy vs Highly exposed seronegative (ishgl) Healthy vs
Asymptomatic covid19 patient healthy vs Highly exposed seronegative (non
ishgl)  from this data.

I started like :

gset <- getGEO("GSE162562", GSEMatrix =TRUE, getGPL=FALSE)

gset

sampleinfo = pData(gset[[1]])[, 1:3]
print(sampleinfo)

but i need help to proceed futher

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 22 01:21:02 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 21 Aug 2021 19:21:02 -0400
Subject: [R] differential gene expression
In-Reply-To: <CAG0CrLgCXh9mMJ4Tv_oCz9tGrtJthaLRkq3dKOXrKQhJwXMMyQ@mail.gmail.com>
References: <CAG0CrLgCXh9mMJ4Tv_oCz9tGrtJthaLRkq3dKOXrKQhJwXMMyQ@mail.gmail.com>
Message-ID: <edb23604-3f4d-4ff7-99b1-445ba1710442@gmail.com>

On 21/08/2021 6:55 p.m., Anas Jamshed wrote:
> I have this data:
> https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE162562&fbclid=IwAR0iZQhttG8HzGhFIIMWbFgNszQrVDgiyVChYzQ_ypCx_d-1pn_tm7STjGs
> 
> and I want to compare:
> healthy vs Mild healthy vs Highly exposed seronegative (ishgl) Healthy vs
> Asymptomatic covid19 patient healthy vs Highly exposed seronegative (non
> ishgl)  from this data.
> 
> I started like :
> 
> gset <- getGEO("GSE162562", GSEMatrix =TRUE, getGPL=FALSE)
> 
> gset
> 
> sampleinfo = pData(gset[[1]])[, 1:3]
> print(sampleinfo)
> 
> but i need help to proceed futher

I think you're asking in the wrong place.  You need statistical help, 
not R help.  Once you know what you want to do, ask here about how to do 
it; in the meantime, look for statistical help.  Some people suggest 
stats.stackexchange.com for that; I haven't read it enough to know if it 
is useful or not.  In many cases, talking to a local expert is the best 
solution.

Duncan Murdoch


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Aug 22 01:38:33 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 21 Aug 2021 19:38:33 -0400
Subject: [R] Help needed with ggplot2
In-Reply-To: <1380350883.720390.1629584612603@mail.yahoo.com>
References: <1522896138.708155.1629582419338.ref@mail.yahoo.com>
 <1522896138.708155.1629582419338@mail.yahoo.com>
 <CAGxFJbTOGs=pn289n4o66hc0pSjDO0fbQw0B2NgALVSdj0N+Xw@mail.gmail.com>
 <1380350883.720390.1629584612603@mail.yahoo.com>
Message-ID: <020a01d796e5$a8100ba0$f83022e0$@verizon.net>

The code supplied is not proper for several reasons including not being on multiple lines properly and use of variables not defined.

"percentage" is a field in data.frame "email" not in "graph_text" and of course you need to load libraries properly to use the functions.

I rewrote and fixed a few errors to look like this:

library(tidyverse)

graph_text <- structure(list(percentage = c(57.14, 29.76, 69.32, 28.41, 57.89, 34.21, 58.59, 33.33, 48.42, 42.11, 59.77, 29.89, 72.13, 18.03, 53.33, 33.33, 55.1, 40.82, 46.55, 37.93),
                             year = c(2020L, 2020L, 2019L, 2019L, 2018L, 2018L, 2017L, 2017L, 2016L, 2016L, 2015L, 2015L, 2014L, 2014L, 2013L, 2013L, 2012L, 2012L, 2011L, 2011L), 
                             gender = c("male", "female", "male", "female", "male", "female", "male", "female", "male", "female", "male", "female", "male", "female", "male", "female", "male", "female", "male", "female")), 
                        class = "data.frame", 
                        row.names = c(NA, -20L))

ymax <- max(graph_text$percentage)

ggplot(data = graph_text, 
       aes(x=year, 
           y=percentage, 
           color = gender, 
           fill=gender)) +  
  geom_bar(position = 'dodge', 
           stat='identity') +  
  theme_classic() +  
  geom_text(aes(label = percentage), 
            size = 4, 
            position = position_dodge(width = 1.1), 
            vjust=-0.2) +   
  scale_y_continuous(limits=c(0, 1.4*ymax))


And interestingly, it showed the years as 2010.0, 2012.5 and every 2.5 years thereafter, like the first version you showed. 

What you are asking for is straightforward enough if you do some simple queries on how to set the x axis up. You want integers shown as it they were years that presumably start with some year near the minimum and continue toward the maximum.  Do you want every year or just every N years?

One low-tech solution is to change year from an integer to a factor of integers or characters like this:

graph_text$year <- as.factor(graph_text$year)

The labels now look reasonable.

I won't solve your other issues but there are documented ways. Bold text is an example that can be changed in many places. In this case, note the addition to the following part from above:

fontface="bold

as in:

  geom_text(aes(label = percentage), 
            size = 4, 
            position = position_dodge(width = 1.1), 
            vjust=-0.2,
            fontface="bold") +








-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of bharat rawlley via R-help
Sent: Saturday, August 21, 2021 6:24 PM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] Help needed with ggplot2

 Thank you, I have tried to do a better job here - 



Data - 
email <- structure(list(percentage = c(57.14, 29.76, 69.32, 28.41, 57.89,                                        34.21, 58.59, 33.33, 48.42, 42.11, 59.77, 29.89, 72.13, 18.03,                                        53.33, 33.33, 55.1, 40.82, 46.55, 37.93), year = c(2020L, 2020L,                                                                                           2019L, 2019L, 2018L, 2018L, 2017L, 2017L, 2016L, 2016L, 2015L,                                                                                           2015L, 2014L, 2014L, 2013L, 2013L, 2012L, 2012L, 2011L, 2011L                                       ), gender = c("male", "female", "male", "female", "male", "female",                                                      "male", "female", "male", "female", "male", "female", "male",                                                      "female", "male", "female", "male", "female", "male", "female"                                       )), class = "data.frame", row.names = c(NA, -20L))



Code - 
ymax <- max(graph_text$percentage)ggplot(aes(x=year, y=percentage, color = gender, fill=gender, data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  geom_text(aes(label = percentage), size = 4, position = position_dodge(width = 1.1), vjust=-0.2) +   scale_y_continuous(limits=c(0, 1.4*ymax))



Session info - 
R version 4.1.0 (2021-05-18)Platform: x86_64-w64-mingw32/x64 (64-bit)Running under: Windows 10 x64 (build 19042)
Matrix products: default
locale:[1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252    LC_MONETARY=English_India.1252[4] LC_NUMERIC=C                   LC_TIME=English_India.1252    
attached base packages:[1] stats     graphics  grDevices utils     datasets  methods   base     
loaded via a namespace (and not attached): [1] fansi_0.5.0      assertthat_0.2.1 dplyr_1.0.6      crayon_1.4.1     utf8_1.2.1       [6] grid_4.1.0       R6_2.5.0         DBI_1.1.1        lifecycle_1.0.0  gtable_0.3.0    [11] magrittr_2.0.1   scales_1.1.1     ggplot2_3.3.3    pillar_1.6.1     rlang_0.4.11    [16] generics_0.1.0   vctrs_0.3.8      ellipsis_0.3.2   tools_4.1.0      glue_1.4.2      [21] purrr_0.3.4      munsell_0.5.0    compiler_4.1.0   pkgconfig_2.0.3  colorspace_2.0-1[26] tidyselect_1.1.1 tibble_3.1.2    


I have the following questions - 
Q1 How can I make the years appear on x axis as 2011, 2012, 2013, 2014 and so on (earlier they were showing up as 2012.5 etc. which has disappeared now for reason I do not know)
Q2 Is there any way to create a small gap between the red and blue bars for aesthetic purposes
Q3 Is there anyway to make the text on top of the bars bolder or thicker? 
Thank you




    On Saturday, 21 August, 2021, 05:57:09 pm GMT-4, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 See ?dput for how to provide a reproducible example (a reprex). Or see here:
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

It will improve your chance of getting a helpful and quick response.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Aug 21, 2021 at 2:47 PM bharat rawlley via R-help
<r-help at r-project.org> wrote:
>
>
> Hello, on using the following code for the following data, the graph I get has an x axis where years are mentioned as 2012.5, 2017.5 etc.
>
> I have the following questions -
> Q1 How can I make the years on x axis as 2011, 2012, 2013, 2014 and so on..
> Q2 Is there any way to create a small gap between the red and blue bars for aesthetic purposes
> Q3 Is there anyway to make the text on top of the bars bolder or thicker?
> Thank you
>
> code -
> ymax <- max(graph_text$percentage)ggplot(aes(x=year, y=percentage, color = gender, fill=gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  geom_text(aes(label = percentage), size = 4, position = position_dodge(width = 1.1), vjust=-0.2) +  scale_y_continuous(limits=c(0, 1.4*ymax))
>
>
> | 57.14 | 2020 |  male |
> | 29.76 | 2020  | female |
> | 69.32 | 2019  | male |
> | 28.41 | 2019 |  female |
> | 57.89 | 2018 |  male |
> | 34.21 | 2018  | female |
> | 58.59 | 2017 |  male |
> | 33.33 | 2017  | female |
> | 48.42 | 2016  | male |
> | 42.11 | 2016 |  female |
> | 59.77 | 2015 |  male |
> | 29.89 | 2015 |  female |
> | 72.13 | 2014 |  male |
> | 18.03 | 2014 |  female |
> | 53.33 | 2013 |  male |
> | 33.33 | 2013 |  female |
> | 55.1 | 2012 |  male |
> | 40.82 | 2012  | female |
> | 46.55 | 2011  | male |
> | 37.93 | 2011  | female |
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sun Aug 22 20:13:34 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Sun, 22 Aug 2021 23:13:34 +0500
Subject: [R] Differential Gene Expression in R
Message-ID: <CAG0CrLjLWnLyejPv_v+Y3623docazdux-vkd9ON-Xr7Jn9Cisg@mail.gmail.com>

 I have downloaded data from:
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE162562&fbclid=IwAR0iZQhttG8HzGhFIIMWbFgNszQrVDgiyVChYzQ_ypCx_d-1pn_tm7STjGs

and now I want to compare:
healthy vs Mild healthy vs Highly exposed seronegative (ishgl) Healthy vs
Asymptomatic covid19 patient healthy vs Highly exposed seronegative (non
ishgl)  from this data.

I started  like  :

library(edgeR)
library(limma)
library(GEOquery)
library(Biobase)

Sys.setenv("VROOM_CONNECTION_SIZE" = 131072 * 2)

setwd("D:\\")

untar("GSE162562_RAW.tar")

filelist = list.files(pattern = ".*.txt.gz")



But after getting text files I don't know how to proceed further. I want to
find degs from these files  *Plz help me *

	[[alternative HTML version deleted]]


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Sun Aug 22 21:09:18 2021
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Sun, 22 Aug 2021 15:09:18 -0400
Subject: [R] Differential Gene Expression in R
In-Reply-To: <CAG0CrLjLWnLyejPv_v+Y3623docazdux-vkd9ON-Xr7Jn9Cisg@mail.gmail.com>
References: <CAG0CrLjLWnLyejPv_v+Y3623docazdux-vkd9ON-Xr7Jn9Cisg@mail.gmail.com>
Message-ID: <b5c79e63-4ad0-8746-ce94-1c8ea49cf871@molbio.mgh.harvard.edu>

 ? You can look into the edgeR vignette. To get the vignette type 
'vignette("edgeR")' in the R command line. Also, just type 'vignette()' 
and R will list all the vignette's for your loaded packages.? Vignettes 
often have a model analysis that you can follow along and try to adjust 
to your specific data. There is also Biostars,? 
https://www.biostars.org/ . However, I doubt you will find anyone on an 
online forum that will walk you through the whole analysis. Although, 
there is probably only 10 plus or minus 4 commands for the whole analysis.

 ??? Alternatively, if you click on the URL you provided below, and at 
the bottom of that page click on 'SRA Run Selector', scroll down a 
little on the page you get to and select the runs you want to analyze by 
checking the appropriate boxes, then click on the grey box on the right 
that has the word 'Galaxy' in it, and it will load your selected runs 
into an instance of Galaxy in which it is a little easier to analyze 
data than on the R command line.

 ?? In the leftmost column of the galaxy page, scroll down to Genomics 
Analysis and then click RNA-seq and scroll down a little and you will 
see that edgeR is available. You will still have to learn a little about 
edgeR analysis, so reading the vignette will be very helpful.

 ?? Also, for the comparisons you want to do, statistical help is 
recommended.

Matthew

On 8/22/21 2:13 PM, Anas Jamshed wrote:
>          External Email - Use Caution
>
>   I have downloaded data from:
> https://secure-web.cisco.com/11QZcUaPohN9T-S3dXC_GmXle9LtWOwH3EZzb3DhLTvve9_5ltt1RpGGssjgmLGBrEaZGEhesLze6XzCJazVRBgu4xc8kHortjlXtfoXyWlsSXouXicfjhSkh_t-WWivcXHpnTvUtVtq9wEKnxWPCPFNu9hprFt91ho02_8XiRAYDkVLcT76BhLbTleUjEezCPbuh9ieLGA6MVW9oiqYERXpYc2dL-KmvVBER3bd-7KiXJJngxji9kbJDDmm-Irysc8aUWDHZZpWkIB8yT_HFAg/https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fgeo%2Fquery%2Facc.cgi%3Facc%3DGSE162562%26fbclid%3DIwAR0iZQhttG8HzGhFIIMWbFgNszQrVDgiyVChYzQ_ypCx_d-1pn_tm7STjGs
>
> and now I want to compare:
> healthy vs Mild healthy vs Highly exposed seronegative (ishgl) Healthy vs
> Asymptomatic covid19 patient healthy vs Highly exposed seronegative (non
> ishgl)  from this data.
>
> I started  like  :
>
> library(edgeR)
> library(limma)
> library(GEOquery)
> library(Biobase)
>
> Sys.setenv("VROOM_CONNECTION_SIZE" = 131072 * 2)
>
> setwd("D:\\")
>
> untar("GSE162562_RAW.tar")
>
> filelist = list.files(pattern = ".*.txt.gz")
>
>
>
> But after getting text files I don't know how to proceed further. I want to
> find degs from these files  *Plz help me *
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1tH9oPhtwGwMZPdSa6iYRfgPKcDjB0RbwLvAsZlByhBsnZOnWMGyfAJedegd7zgzjhBGoJR4l667r5yELyZUobz_rb-7cCszSEx-M4al0kObEUewwS1-66OaSN7ZHYe8OS9Oz6xG6KzS1XBqB5GDyXiA8FMoIEfaq49EamqyjBtwwgsNKpMdy2IyCTZ2dSL_cdkkD5dacTj5gg4PLprBua7uc32IM4bJmSXSAMxd31lqPP9m3V83kjORuTO61SZzQOeTSf8g8HwY6bDJLlOATxA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> PLEASE do read the posting guide http://secure-web.cisco.com/1qNZPXyZ9T-DwVY58dRhW-s2KI0g8PKqYBjd8eU1WX1DwW8TqASTq2NkdBNjUHF6T9QiEWRKhGinSfo78D3RrHq9hc9HVXYF7t9KAzK-sUNE0Y0IB62wcBJrH8Gd0LS7aus-36dSfndVD9CShsOMfwyMj5KIVQI8sppBOu5xbWhJEYfH3MgGhC_TVJIkQ126GdEuG4wK7xnnBh90fF4tdTJbHmaIWBn4yxPbhSdrYqs7GCgf_Gp4kee0aSyzxk_0WBkd2fPtnz5Ecbqkb1P8C6g/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sun Aug 22 21:19:57 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Mon, 23 Aug 2021 00:19:57 +0500
Subject: [R] Differential Gene Expression in R
In-Reply-To: <b5c79e63-4ad0-8746-ce94-1c8ea49cf871@molbio.mgh.harvard.edu>
References: <CAG0CrLjLWnLyejPv_v+Y3623docazdux-vkd9ON-Xr7Jn9Cisg@mail.gmail.com>
 <b5c79e63-4ad0-8746-ce94-1c8ea49cf871@molbio.mgh.harvard.edu>
Message-ID: <CAG0CrLgWr35FmqmzESioUAL+ig_TghCbZnpTCZcqX1aAXq=Q2A@mail.gmail.com>

EdgeR in Galaxy requires factor, group, and contrast so what should I do?

On Mon, Aug 23, 2021 at 12:09 AM Matthew McCormack <
mccormack at molbio.mgh.harvard.edu> wrote:

>    You can look into the edgeR vignette. To get the vignette type
> 'vignette("edgeR")' in the R command line. Also, just type 'vignette()'
> and R will list all the vignette's for your loaded packages.  Vignettes
> often have a model analysis that you can follow along and try to adjust
> to your specific data. There is also Biostars,
> https://www.biostars.org/ . However, I doubt you will find anyone on an
> online forum that will walk you through the whole analysis. Although,
> there is probably only 10 plus or minus 4 commands for the whole analysis.
>
>      Alternatively, if you click on the URL you provided below, and at
> the bottom of that page click on 'SRA Run Selector', scroll down a
> little on the page you get to and select the runs you want to analyze by
> checking the appropriate boxes, then click on the grey box on the right
> that has the word 'Galaxy' in it, and it will load your selected runs
> into an instance of Galaxy in which it is a little easier to analyze
> data than on the R command line.
>
>     In the leftmost column of the galaxy page, scroll down to Genomics
> Analysis and then click RNA-seq and scroll down a little and you will
> see that edgeR is available. You will still have to learn a little about
> edgeR analysis, so reading the vignette will be very helpful.
>
>     Also, for the comparisons you want to do, statistical help is
> recommended.
>
> Matthew
>
> On 8/22/21 2:13 PM, Anas Jamshed wrote:
> >          External Email - Use Caution
> >
> >   I have downloaded data from:
> >
> https://secure-web.cisco.com/11QZcUaPohN9T-S3dXC_GmXle9LtWOwH3EZzb3DhLTvve9_5ltt1RpGGssjgmLGBrEaZGEhesLze6XzCJazVRBgu4xc8kHortjlXtfoXyWlsSXouXicfjhSkh_t-WWivcXHpnTvUtVtq9wEKnxWPCPFNu9hprFt91ho02_8XiRAYDkVLcT76BhLbTleUjEezCPbuh9ieLGA6MVW9oiqYERXpYc2dL-KmvVBER3bd-7KiXJJngxji9kbJDDmm-Irysc8aUWDHZZpWkIB8yT_HFAg/https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fgeo%2Fquery%2Facc.cgi%3Facc%3DGSE162562%26fbclid%3DIwAR0iZQhttG8HzGhFIIMWbFgNszQrVDgiyVChYzQ_ypCx_d-1pn_tm7STjGs
> >
> > and now I want to compare:
> > healthy vs Mild healthy vs Highly exposed seronegative (ishgl) Healthy vs
> > Asymptomatic covid19 patient healthy vs Highly exposed seronegative (non
> > ishgl)  from this data.
> >
> > I started  like  :
> >
> > library(edgeR)
> > library(limma)
> > library(GEOquery)
> > library(Biobase)
> >
> > Sys.setenv("VROOM_CONNECTION_SIZE" = 131072 * 2)
> >
> > setwd("D:\\")
> >
> > untar("GSE162562_RAW.tar")
> >
> > filelist = list.files(pattern = ".*.txt.gz")
> >
> >
> >
> > But after getting text files I don't know how to proceed further. I want
> to
> > find degs from these files  *Plz help me *
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://secure-web.cisco.com/1tH9oPhtwGwMZPdSa6iYRfgPKcDjB0RbwLvAsZlByhBsnZOnWMGyfAJedegd7zgzjhBGoJR4l667r5yELyZUobz_rb-7cCszSEx-M4al0kObEUewwS1-66OaSN7ZHYe8OS9Oz6xG6KzS1XBqB5GDyXiA8FMoIEfaq49EamqyjBtwwgsNKpMdy2IyCTZ2dSL_cdkkD5dacTj5gg4PLprBua7uc32IM4bJmSXSAMxd31lqPP9m3V83kjORuTO61SZzQOeTSf8g8HwY6bDJLlOATxA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> > PLEASE do read the posting guide
> http://secure-web.cisco.com/1qNZPXyZ9T-DwVY58dRhW-s2KI0g8PKqYBjd8eU1WX1DwW8TqASTq2NkdBNjUHF6T9QiEWRKhGinSfo78D3RrHq9hc9HVXYF7t9KAzK-sUNE0Y0IB62wcBJrH8Gd0LS7aus-36dSfndVD9CShsOMfwyMj5KIVQI8sppBOu5xbWhJEYfH3MgGhC_TVJIkQ126GdEuG4wK7xnnBh90fF4tdTJbHmaIWBn4yxPbhSdrYqs7GCgf_Gp4kee0aSyzxk_0WBkd2fPtnz5Ecbqkb1P8C6g/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From k|mmo@e|o @end|ng |rom utu@||  Mon Aug 23 08:18:07 2021
From: k|mmo@e|o @end|ng |rom utu@|| (Kimmo Elo)
Date: Mon, 23 Aug 2021 06:18:07 +0000
Subject: [R] Find "undirected" duplicates in a tibble
In-Reply-To: <CAGgJW77TZAE7c4SkNBpmW_GDPJ2FAAd9BRxaMHqkRQqbNeG6zQ@mail.gmail.com>
References: <47d240b33b929af0e3aed792bec69d929756c684.camel@utu.fi>
 <732064.1629457943@apollo2.minshall.org>
 <CAGgJW77TZAE7c4SkNBpmW_GDPJ2FAAd9BRxaMHqkRQqbNeG6zQ@mail.gmail.com>
Message-ID: <05acaec669fa54a9f355bb83cf44d97304932abf.camel@utu.fi>

Hi!

Thank you very much for the fascinating solutions. Nice to learn
different approaches. All solutions seem to work with text data as
well.

@Gabor (who suggested the 'igraph' package): yes, I am familiar with
'igraph' and the solution suggested by you works fine, too. Since I
need this kind of "simplification" of my datasets in many analysis
outside network analysis, I just wanted to figure out alternatives :-)

Best,

Kimmo



pe, 2021-08-20 kello 16:38 +0300, Eric Berger kirjoitti:
> x %>% transmute( a=pmin(Source,Target), b=pmax(Source,Target)) %>%
>   unique() %>% rename(Source=a, Target=b)
> 
> 
> 
> On Fri, Aug 20, 2021 at 2:12 PM Greg Minshall <minshall at umich.edu>
> wrote:
> 
> > Kimmo,
> > 
> > i'll be curious to see other, maybe more elegant, answers.  in the
> > meantime, this seems to work.
> > 
> > ----
> >   x = data.frame(Source=rep(1:3,4),
> > Target=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3)))
> >   y <- apply(x, 1, function(y) return (c(n=min(y), x=max(y))))
> >   res <- data.frame()
> >   for (n in unique(y["n",])) {
> >     unique(y["x",y["n",]==n])
> >     res <- rbind(res, data.frame(A=c(n),
> > B=unique(y["x",y["n",]==n])))
> >   }
> >   res
> > ----
> > 
> > thanks for the question!
> > 
> > cheers, Greg
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 

From no@p@m @end|ng |rom ||@@e@NA  Mon Aug 23 08:37:54 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Mon, 23 Aug 2021 08:37:54 +0200
Subject: [R] Dynamic Creation and Use of Object Names
Message-ID: <sfvfo6$4hm$1@ciao.gmane.io>

Hi,

I have a function PICTURE() and do something like

	COUNTRY = 'Namibia'
	NAKURVE = PICTURE(COUNTRY)
	NAKURVE
	ggsave(paste0(tolower(COUNTRY),".png"), width = 16, height = 9)

	COUNTRY = ('Germany')
	DEKURVE = PICTURE(COUNTRY)
	DEKURVE
	ggsave(paste0(tolower(COUNTRY),".png"), width = 16, height = 9)

	COUNTRY = ('Netherlands')
	NLKURVE = PICTURE(COUNTRY)
	NLKURVE
	ggsave(paste0(tolower(COUNTRY),".png"), width = 16, height = 9)

[...]

	COUNTRYGRID=grid.arrange(NAKURVE, DEKURVE, NLKURVE,
				 ncol=3)
	COUNTRYGRID
	ggsave(paste0("R7.incidence.", Sys.Date(), ".png"), COUNTRYGRID)

I am not able to figure out (and/or find on Google) how to do this in a
loop (of sorts), ie create the variables dynamically and add them to to
the grid (dynamically, ie adding more countries)

Any ideas?

greetings, el
-- 
To email me replace 'nospam' with 'el'


From db@ndur @end|ng |rom @ymp@t|co@c@  Fri Aug 20 18:49:24 2021
From: db@ndur @end|ng |rom @ymp@t|co@c@ (DB)
Date: Fri, 20 Aug 2021 12:49:24 -0400 (EDT)
Subject: [R] [R-pkgs] New Release: package replacer_v.1.0.0
Message-ID: <710094407.167898.1629478164878.JavaMail.open-xchange@torgui05>

"replacer v.1.0.0"

new package submission

"replacer" is a value replacement utility currently based on the powerful
package "data.table", available on CRAN.

This utility is purposed for outside-database update of datasets. It is
accessible to beginners to `R` and facilitates complex dataset updates with
minimal prompt time by employing User-friendly functions that automatically
follow a decision tree rooted in User's input. 

The package source can be downloaded from
https://CRAN.R-project.org/package=replacer
<https://CRAN.R-project.org/package=replacer>

or, by typing:

install.packages('replacer')

at the R prompt. Once installed, the User can run a short example by copying the
next 3 lines below:

require(replacer)

dir = system.file('extdata', package = 'replacer')

replaceVals(dir, save = FALSE)

Familiarity with basic R commands is necessary. Familiarity with `data.table` is
not, yet strongly recommended!

Users are encouraged to start by reading the vignette found at the link above.

Thank you,

Dragos Bandur, author
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug 23 10:05:30 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 23 Aug 2021 08:05:30 +0000
Subject: [R] Selecting elements
In-Reply-To: <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
Message-ID: <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>

Hi

Only I got your HTML formated mail, rest of the world got complete mess. Do not use HTML formating.

As I got it right I wonder why in your second example you did not follow
3A - 3B - 2C - 2D

as D were positioned 1st and 4th.

I hope that you could use something like

sss <- split(data$Var.2, data$Var.1)
lapply(sss, cumsum)
$A
 [1]  38  73 105 136 166 188 199 207 209 210

$B
 [1]  39  67  92 115 131 146 153 159 164 168

$C
 [1]  40  76 105 131 152 171 189 203 213 222

$D
 [1]  37  71 104 131 155 175 192 205 217 220

Now you need to evaluate this result according to your sets. Here the highest value (76) is in C so the set with 2C is the one you should choose and select you value according to this set.

With
> set.seed(666)
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> data = data.frame(Var.1, Var.2)
> data <- data[order(data$Var.2, decreasing=TRUE), ]
> sss <- split(data$Var.2, data$Var.1)
> lapply(sss, cumsum)
$A
 [1]  36  70 102 133 163 182 200 207 212 213

$B
 [1]  35  57  78  95 108 120 131 140 148 150

$C
 [1]  40  73 102 130 156 180 196 211 221 225

$D
 [1]  39  77 114 141 166 189 209 223 229 232

Highest value is in D so either 3A - 3B - 2C - 2D  or 3A - 3B - 2C - 2D should be appropriate. And here I am again lost as both sets are same. Maybe you need to reconsider your statements.

Cheers
Petr

From: Silvano Cesar da Costa <silvano at uel.br> 
Sent: Friday, August 20, 2021 9:28 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Re: [R] Selecting elements

Hi, thanks you for the answer. 
Sorry English is not my native language.

But you got it right. 
> As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?

I must select the 10 (not 15) highest values, but which follow a certain order:
3A - 3B - 2C - 2D     or 
2A - 5B - 0C - 3D     or
3A - 3B - 2C - 2D
I'll put the example in Excel for a better understanding (with 20 elements only). 
I must select 10 elements (the highest values of variable Var.2), which fit one of the 3 options above. 

Number
Position
Var.1
Var.2








1
27
C
40








2
30
B
39

Selected: 





3
5
A
38

Number
Position
Var.1
Var.2



4
16
D
37

1
27
C
40



5
23
C
36

2
30
B
39
 
3A - 3B - 2C - 2D
6
13
A
35

3
5
A
38



7
20
D
34

4
16
D
37

3A - 3B - 1C - 3D
8
12
D
33

5
23
C
36



9
9
A
32

6
13
A
35

2A - 5B - 0C - 3D
10
1
A
31

7
20
D
34



11
21
A
30

10
9
A
32



12
35
C
29

13
14
B
28



13
14
B
28

17
6
B
25



14
8
D
27








15
7
C
26








16
6
B
25





 
 
 
17
40
D
24





 
 
 
18
26
B
23





 
 
 
19
29
A
22





 
 
 
20
31
C
21





 
 
 



Second option (other data set):

Number
Position
Var.1
Var.2








1
36
D
20








2
11
B
19

Selected: 





3
39
A
18

Number
Position
Var.1
Var.2



4
24
D
17

1
36
D
20



5
34
B
16

2
11
B
19
 
3A - 3B - 2C - 2D
6
2
B
15

3
39
A
18



7
3
A
14

4
24
D
17
 
3A - 3B - 1C - 3D
8
32
D
13

5
34
B
16



9
28
D
12

6
2
B
15

2A - 5B - 0C - 3D
10
25
A
11

7
3
A
14



11
19
B
10

8
32
D
13



12
15
B
9

9
25
A
11



13
17
A
8

10
18
C
7



14
18
C
7








15
38
B
6








16
10
B
5








17
22
B
4








18
4
D
3








19
33
A
2








20
37
A
1










How to make the selection of these 10 elements that fit one of the 3 options using R?

Thanks,

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <mailto:petr.pikal at precheza.cz> escreveu:
Hallo

I am confused, maybe others know what do you want but could you be more specific?

Let say you have such data
set.seed(123)
Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)
data = data.frame(Var.1, Var.2)

What should be the desired outcome?

You can sort
data <- data[order(data$Var.2, decreasing=TRUE), ]
and split the data
> split(data$Var.2, data$Var.1)
$A
 [1] 38 35 32 31 30 22 11  8  2  1

$B
 [1] 39 28 25 23 16 15  7  6  5  4

$C
 [1] 40 36 29 26 21 19 18 14 10  9

$D
 [1] 37 34 33 27 24 20 17 13 12  3

T inspect highest values. But here I am lost. As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?

Or I do not understand at all what you really want to achieve.

Cheers
Petr

> -----Original Message-----
> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Silvano Cesar da
> Costa
> Sent: Thursday, August 19, 2021 10:40 PM
> To: mailto:r-help at r-project.org
> Subject: [R] Selecting elements
> 
> Hi,
> 
> I need to select 15 elements, always considering the highest values
> (descending order) but obeying the following configuration:
> 
> 3A - 4B - 0C - 3D or
> 2A - 5B - 0C - 3D or
> 3A - 3B - 2C - 2D
> 
> If I have, for example, 5 A elements as the highest values, I can only choose
> (first and third choice) or 2 (second choice) elements.
> 
> how to make this selection?
> 
> 
> library(dplyr)
> 
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> 
> data = data.frame(Var.1, Var.2)
> (data = data[order(data$Var.2, decreasing=TRUE), ])
> 
> Elements = data %>%
>   arrange(desc(Var.2))
> 
> Thanks,
> 
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
> 
> Fone: (43) 3371-4346
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug 23 10:20:39 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 23 Aug 2021 10:20:39 +0200
Subject: [R] Dynamic Creation and Use of Object Names
In-Reply-To: <sfvfo6$4hm$1@ciao.gmane.io>
References: <sfvfo6$4hm$1@ciao.gmane.io>
Message-ID: <20210823102039.3acfa6df@trisector>

On Mon, 23 Aug 2021 08:37:54 +0200
Dr Eberhard Lisse <nospam at lisse.NA> wrote:

> create the variables dynamically and add them to to
> the grid (dynamically, ie adding more countries)

In my opinion, creating variables in the global environment
programmatically may lead to code that is hard to understand and debug
[*]. A key-value data structure (a named list or a separate
environment) would avoid the potential problems from variable name
collision. How about the following:

1. Put the countries in a vector: c('Namibia', 'Germany', ...)

2. Use lapply() to get a list of objects returned from your PICTURE
   function

3. To save the pictures into individual files, loop over the list. You
   can use setNames on the step 1 or 2 to make it a named list and keep
   the country names together with their pictures:
   
   for (n in names(pictures)) {
     dev.new()
     print(pictures[[n]])
     ggsave(paste0(n, '.png'), ...)
     dev.off()
   }

   (You can also use the png() device and plot straight to the file,
   avoiding the need to draw the plot in the window for a fraction of a
   second and for ggsave().)

4. Use the grobs= argument of grid.arrange() to pass the list of
   objects to arrange instead of passing individual objects via ...

-- 
Best regards,
Ivan

[*] For example, there's this FAQ for a different language:
https://perldoc.perl.org/perlfaq7#How-can-I-use-a-variable-as-a-variable-name?


From no@p@m @end|ng |rom ||@@e@NA  Mon Aug 23 13:51:09 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Mon, 23 Aug 2021 13:51:09 +0200
Subject: [R] Dynamic Creation and Use of Object Names
In-Reply-To: <20210823102039.3acfa6df@trisector>
References: <sfvfo6$4hm$1@ciao.gmane.io> <20210823102039.3acfa6df@trisector>
Message-ID: <bf0f25c4-0c86-ae61-cc2f-dc318123ee6b@lisse.NA>

Thank you,

more to study :-)-O

el

On 23/08/2021 10:20, Ivan Krylov wrote:
> On Mon, 23 Aug 2021 08:37:54 +0200
> Dr Eberhard Lisse <nospam at lisse.NA> wrote:
> 
>> create the variables dynamically and add them to to
>> the grid (dynamically, ie adding more countries)
> 
> In my opinion, creating variables in the global environment
> programmatically may lead to code that is hard to understand and debug
> [*]. A key-value data structure (a named list or a separate
> environment) would avoid the potential problems from variable name
> collision. How about the following:
> 
> 1. Put the countries in a vector: c('Namibia', 'Germany', ...)
> 
> 2. Use lapply() to get a list of objects returned from your PICTURE
>     function
> 
> 3. To save the pictures into individual files, loop over the list. You
>     can use setNames on the step 1 or 2 to make it a named list and keep
>     the country names together with their pictures:
>     
>     for (n in names(pictures)) {
>       dev.new()
>       print(pictures[[n]])
>       ggsave(paste0(n, '.png'), ...)
>       dev.off()
>     }
> 
>     (You can also use the png() device and plot straight to the file,
>     avoiding the need to draw the plot in the window for a fraction of a
>     second and for ggsave().)
> 
> 4. Use the grobs= argument of grid.arrange() to pass the list of
>     objects to arrange instead of passing individual objects via ...
> 


-- 
To email me replace 'nospam' with 'el'


From no@p@m @end|ng |rom ||@@e@NA  Mon Aug 23 13:51:09 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Mon, 23 Aug 2021 13:51:09 +0200
Subject: [R] Dynamic Creation and Use of Object Names
In-Reply-To: <20210823102039.3acfa6df@trisector>
References: <sfvfo6$4hm$1@ciao.gmane.io> <20210823102039.3acfa6df@trisector>
Message-ID: <bf0f25c4-0c86-ae61-cc2f-dc318123ee6b@lisse.NA>

Thank you,

more to study :-)-O

el

On 23/08/2021 10:20, Ivan Krylov wrote:
> On Mon, 23 Aug 2021 08:37:54 +0200
> Dr Eberhard Lisse <nospam at lisse.NA> wrote:
> 
>> create the variables dynamically and add them to to
>> the grid (dynamically, ie adding more countries)
> 
> In my opinion, creating variables in the global environment
> programmatically may lead to code that is hard to understand and debug
> [*]. A key-value data structure (a named list or a separate
> environment) would avoid the potential problems from variable name
> collision. How about the following:
> 
> 1. Put the countries in a vector: c('Namibia', 'Germany', ...)
> 
> 2. Use lapply() to get a list of objects returned from your PICTURE
>     function
> 
> 3. To save the pictures into individual files, loop over the list. You
>     can use setNames on the step 1 or 2 to make it a named list and keep
>     the country names together with their pictures:
>     
>     for (n in names(pictures)) {
>       dev.new()
>       print(pictures[[n]])
>       ggsave(paste0(n, '.png'), ...)
>       dev.off()
>     }
> 
>     (You can also use the png() device and plot straight to the file,
>     avoiding the need to draw the plot in the window for a fraction of a
>     second and for ggsave().)
> 
> 4. Use the grobs= argument of grid.arrange() to pass the list of
>     objects to arrange instead of passing individual objects via ...
> 


-- 
To email me replace 'nospam' with 'el'


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 23 18:06:50 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Aug 2021 09:06:50 -0700
Subject: [R] Dynamic Creation and Use of Object Names
In-Reply-To: <bf0f25c4-0c86-ae61-cc2f-dc318123ee6b@lisse.NA>
References: <sfvfo6$4hm$1@ciao.gmane.io> <20210823102039.3acfa6df@trisector>
 <bf0f25c4-0c86-ae61-cc2f-dc318123ee6b@lisse.NA>
Message-ID: <CAGxFJbTSbbRxaMGbqn-zRDgsUFpHbmU1HV+55VaySpLub5S3zQ@mail.gmail.com>

... and to add to Ivan's suggestions, **depending on what you are
trying to show with your grid of graphs,**  you may wish to consider
using ggplot's "facet" capabilities to assure that any quantitative
variables that you are encoding in the maps (e.g. by color, density
shading, etc.) are depicted on the same scale with appropriate
legends.  (Of course, ignore if this is not the case).  If so, you
will need a different data structure for your data, I believe.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Aug 23, 2021 at 4:51 AM Dr Eberhard Lisse <nospam at lisse.na> wrote:
>
> Thank you,
>
> more to study :-)-O
>
> el
>
> On 23/08/2021 10:20, Ivan Krylov wrote:
> > On Mon, 23 Aug 2021 08:37:54 +0200
> > Dr Eberhard Lisse <nospam at lisse.NA> wrote:
> >
> >> create the variables dynamically and add them to to
> >> the grid (dynamically, ie adding more countries)
> >
> > In my opinion, creating variables in the global environment
> > programmatically may lead to code that is hard to understand and debug
> > [*]. A key-value data structure (a named list or a separate
> > environment) would avoid the potential problems from variable name
> > collision. How about the following:
> >
> > 1. Put the countries in a vector: c('Namibia', 'Germany', ...)
> >
> > 2. Use lapply() to get a list of objects returned from your PICTURE
> >     function
> >
> > 3. To save the pictures into individual files, loop over the list. You
> >     can use setNames on the step 1 or 2 to make it a named list and keep
> >     the country names together with their pictures:
> >
> >     for (n in names(pictures)) {
> >       dev.new()
> >       print(pictures[[n]])
> >       ggsave(paste0(n, '.png'), ...)
> >       dev.off()
> >     }
> >
> >     (You can also use the png() device and plot straight to the file,
> >     avoiding the need to draw the plot in the window for a fraction of a
> >     second and for ggsave().)
> >
> > 4. Use the grobs= argument of grid.arrange() to pass the list of
> >     objects to arrange instead of passing individual objects via ...
> >
>
>
> --
> To email me replace 'nospam' with 'el'
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Mon Aug 23 18:52:29 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Mon, 23 Aug 2021 21:52:29 +0500
Subject: [R] Need help to unzip files in Windows
Message-ID: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>

I have the file GSE162562_RAW. First I untar them
by untar("GSE162562_RAW.tar")
then I am running like:
 system("gunzip ~/Desktop/GSE162562_RAW/*.gz")


This is running fine in Linux but not in windows. What changes I
should make to run this command in windows as well

	[[alternative HTML version deleted]]


From @||v@no @end|ng |rom ue|@br  Mon Aug 23 19:54:13 2021
From: @||v@no @end|ng |rom ue|@br (Silvano Cesar da Costa)
Date: Mon, 23 Aug 2021 14:54:13 -0300
Subject: [R] Selecting elements
In-Reply-To: <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
 <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMaZ2WBKonNK47bCL3W3p-RmmhKw_Lw7oqHyHCzqTTBWdX=fSA@mail.gmail.com>

Hi,

I apologize for the confusion. I will try to be clearer in my explanation.
I believe that with the R script it becomes clearer.

I have 4 variables with 10 repetitions and each one receives a value,
randomly.
I order the dataset from largest to smallest value. I have to select 10
elements in
descending order of values, according to one of three schemes:

# 3A - 3B - 2C - 2D
# 2A - 5B - 0C - 3D
# 3A - 4B - 2C - 1D

If the first 3 elements (out of the 10 to be selected) are of the letter D,
automatically
the adopted scheme will be the second. So, I have to (following) choose 2A,
5B and 0C.
How to make the selection automatically?

I created two selection examples, with different schemes:


set.seed(123)

Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)

data = data.frame(Var.1, Var.2)

(Order = data[order(data$Var.2, decreasing=TRUE), ])

# I must select the 10 highest values (),
# but which follow a certain scheme:
#
#  3A - 3B - 2C - 2D     or
#  2A - 5B - 0C - 3D     or
#  3A - 4B - 2C - 1D
#
# In this case, I started with the highest value that refers to the letter
C.
# Next comes only 1 of the letters B, A and D. All are selected once.
# The fifth observation is the letter C, completing 2 C values. In this
case,
# following the 3 adopted schemes, note that the second scheme has 0C,
# so this scheme is out.
# Therefore, it can be the first scheme (3A - 3B - 2C - 2D) or the
# third scheme (3A - 4B - 2C - 1D).
# The next letter to be completed is the D (fourth and seventh elements),
# among the 10 elements being selected. Therefore, the scheme adopted is
the
# first one (3A - 3B - 2C - 2D).
# Therefore, it is necessary to select 2 values with the letter B and 1
value
# with the letter A.
#
# Manual Selection -
# The end result is:
(Selected.data = Order[c(1,2,3,4,5,6,7,9,13,16), ])

# Scheme: 3A - 3B - 2C - 2D
sort(Selected.data$Var.1)


#------------------
# Second example: -
#------------------
set.seed(4)

Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)

data = data.frame(Var.1, Var.2)
(Order = data[order(data$Var.2, decreasing=TRUE), ])

# The end result is:
(Selected.data.2 = Order[c(1,2,3,4,5,6,7,8,9,11), ])

# Scheme: 3A - 4B - 2C - 1D
sort(Selected.data.2$Var.1)

How to make the selection of the 10 elements automatically?

Thank you very much.

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


Em seg., 23 de ago. de 2021 ?s 05:05, PIKAL Petr <petr.pikal at precheza.cz>
escreveu:

> Hi
>
> Only I got your HTML formated mail, rest of the world got complete mess.
> Do not use HTML formating.
>
> As I got it right I wonder why in your second example you did not follow
> 3A - 3B - 2C - 2D
>
> as D were positioned 1st and 4th.
>
> I hope that you could use something like
>
> sss <- split(data$Var.2, data$Var.1)
> lapply(sss, cumsum)
> $A
>  [1]  38  73 105 136 166 188 199 207 209 210
>
> $B
>  [1]  39  67  92 115 131 146 153 159 164 168
>
> $C
>  [1]  40  76 105 131 152 171 189 203 213 222
>
> $D
>  [1]  37  71 104 131 155 175 192 205 217 220
>
> Now you need to evaluate this result according to your sets. Here the
> highest value (76) is in C so the set with 2C is the one you should choose
> and select you value according to this set.
>
> With
> > set.seed(666)
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> > data = data.frame(Var.1, Var.2)
> > data <- data[order(data$Var.2, decreasing=TRUE), ]
> > sss <- split(data$Var.2, data$Var.1)
> > lapply(sss, cumsum)
> $A
>  [1]  36  70 102 133 163 182 200 207 212 213
>
> $B
>  [1]  35  57  78  95 108 120 131 140 148 150
>
> $C
>  [1]  40  73 102 130 156 180 196 211 221 225
>
> $D
>  [1]  39  77 114 141 166 189 209 223 229 232
>
> Highest value is in D so either 3A - 3B - 2C - 2D  or 3A - 3B - 2C - 2D
> should be appropriate. And here I am again lost as both sets are same.
> Maybe you need to reconsider your statements.
>
> Cheers
> Petr
>
> From: Silvano Cesar da Costa <silvano at uel.br>
> Sent: Friday, August 20, 2021 9:28 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Re: [R] Selecting elements
>
> Hi, thanks you for the answer.
> Sorry English is not my native language.
>
> But you got it right.
> > As C is first and fourth biggest value, you follow third option and
> select 3 highest A, 3B 2C and 2D?
>
> I must select the 10 (not 15) highest values, but which follow a certain
> order:
> 3A - 3B - 2C - 2D     or
> 2A - 5B - 0C - 3D     or
> 3A - 3B - 2C - 2D
> I'll put the example in Excel for a better understanding (with 20 elements
> only).
> I must select 10 elements (the highest values of variable Var.2), which
> fit one of the 3 options above.
>
> Number
> Position
> Var.1
> Var.2
>
>
>
>
>
>
>
>
> 1
> 27
> C
> 40
>
>
>
>
>
>
>
>
> 2
> 30
> B
> 39
>
> Selected:
>
>
>
>
>
> 3
> 5
> A
> 38
>
> Number
> Position
> Var.1
> Var.2
>
>
>
> 4
> 16
> D
> 37
>
> 1
> 27
> C
> 40
>
>
>
> 5
> 23
> C
> 36
>
> 2
> 30
> B
> 39
>
> 3A - 3B - 2C - 2D
> 6
> 13
> A
> 35
>
> 3
> 5
> A
> 38
>
>
>
> 7
> 20
> D
> 34
>
> 4
> 16
> D
> 37
>
> 3A - 3B - 1C - 3D
> 8
> 12
> D
> 33
>
> 5
> 23
> C
> 36
>
>
>
> 9
> 9
> A
> 32
>
> 6
> 13
> A
> 35
>
> 2A - 5B - 0C - 3D
> 10
> 1
> A
> 31
>
> 7
> 20
> D
> 34
>
>
>
> 11
> 21
> A
> 30
>
> 10
> 9
> A
> 32
>
>
>
> 12
> 35
> C
> 29
>
> 13
> 14
> B
> 28
>
>
>
> 13
> 14
> B
> 28
>
> 17
> 6
> B
> 25
>
>
>
> 14
> 8
> D
> 27
>
>
>
>
>
>
>
>
> 15
> 7
> C
> 26
>
>
>
>
>
>
>
>
> 16
> 6
> B
> 25
>
>
>
>
>
>
>
>
> 17
> 40
> D
> 24
>
>
>
>
>
>
>
>
> 18
> 26
> B
> 23
>
>
>
>
>
>
>
>
> 19
> 29
> A
> 22
>
>
>
>
>
>
>
>
> 20
> 31
> C
> 21
>
>
>
>
>
>
>
>
>
>
>
> Second option (other data set):
>
> Number
> Position
> Var.1
> Var.2
>
>
>
>
>
>
>
>
> 1
> 36
> D
> 20
>
>
>
>
>
>
>
>
> 2
> 11
> B
> 19
>
> Selected:
>
>
>
>
>
> 3
> 39
> A
> 18
>
> Number
> Position
> Var.1
> Var.2
>
>
>
> 4
> 24
> D
> 17
>
> 1
> 36
> D
> 20
>
>
>
> 5
> 34
> B
> 16
>
> 2
> 11
> B
> 19
>
> 3A - 3B - 2C - 2D
> 6
> 2
> B
> 15
>
> 3
> 39
> A
> 18
>
>
>
> 7
> 3
> A
> 14
>
> 4
> 24
> D
> 17
>
> 3A - 3B - 1C - 3D
> 8
> 32
> D
> 13
>
> 5
> 34
> B
> 16
>
>
>
> 9
> 28
> D
> 12
>
> 6
> 2
> B
> 15
>
> 2A - 5B - 0C - 3D
> 10
> 25
> A
> 11
>
> 7
> 3
> A
> 14
>
>
>
> 11
> 19
> B
> 10
>
> 8
> 32
> D
> 13
>
>
>
> 12
> 15
> B
> 9
>
> 9
> 25
> A
> 11
>
>
>
> 13
> 17
> A
> 8
>
> 10
> 18
> C
> 7
>
>
>
> 14
> 18
> C
> 7
>
>
>
>
>
>
>
>
> 15
> 38
> B
> 6
>
>
>
>
>
>
>
>
> 16
> 10
> B
> 5
>
>
>
>
>
>
>
>
> 17
> 22
> B
> 4
>
>
>
>
>
>
>
>
> 18
> 4
> D
> 3
>
>
>
>
>
>
>
>
> 19
> 33
> A
> 2
>
>
>
>
>
>
>
>
> 20
> 37
> A
> 1
>
>
>
>
>
>
>
>
>
>
> How to make the selection of these 10 elements that fit one of the 3
> options using R?
>
> Thanks,
>
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
>
> Fone: (43) 3371-4346
>
>
> Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <mailto:
> petr.pikal at precheza.cz> escreveu:
> Hallo
>
> I am confused, maybe others know what do you want but could you be more
> specific?
>
> Let say you have such data
> set.seed(123)
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> data = data.frame(Var.1, Var.2)
>
> What should be the desired outcome?
>
> You can sort
> data <- data[order(data$Var.2, decreasing=TRUE), ]
> and split the data
> > split(data$Var.2, data$Var.1)
> $A
>  [1] 38 35 32 31 30 22 11  8  2  1
>
> $B
>  [1] 39 28 25 23 16 15  7  6  5  4
>
> $C
>  [1] 40 36 29 26 21 19 18 14 10  9
>
> $D
>  [1] 37 34 33 27 24 20 17 13 12  3
>
> T inspect highest values. But here I am lost. As C is first and fourth
> biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>
> Or I do not understand at all what you really want to achieve.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Silvano
> Cesar da
> > Costa
> > Sent: Thursday, August 19, 2021 10:40 PM
> > To: mailto:r-help at r-project.org
> > Subject: [R] Selecting elements
> >
> > Hi,
> >
> > I need to select 15 elements, always considering the highest values
> > (descending order) but obeying the following configuration:
> >
> > 3A - 4B - 0C - 3D or
> > 2A - 5B - 0C - 3D or
> > 3A - 3B - 2C - 2D
> >
> > If I have, for example, 5 A elements as the highest values, I can only
> choose
> > (first and third choice) or 2 (second choice) elements.
> >
> > how to make this selection?
> >
> >
> > library(dplyr)
> >
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> >
> > data = data.frame(Var.1, Var.2)
> > (data = data[order(data$Var.2, decreasing=TRUE), ])
> >
> > Elements = data %>%
> >   arrange(desc(Var.2))
> >
> > Thanks,
> >
> > Prof. Dr. Silvano Cesar da Costa
> > Universidade Estadual de Londrina
> > Centro de Ci?ncias Exatas
> > Departamento de Estat?stica
> >
> > Fone: (43) 3371-4346
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Mon Aug 23 20:41:50 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 23 Aug 2021 14:41:50 -0400
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
Message-ID: <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>

Hello,


I don't think you need to use a system command directly, I think
'utils::untar' is all you need. I tried the same thing myself, something
like:


URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
FILE <- file.path(tempdir(), basename(URL))


utils::download.file(URL, FILE)
utils::untar(FILE, exdir = dirname(FILE))


and it makes a folder "Image-ExifTool-12.30". It seems to work perfectly
fine in Windows 10 x64 build 19042. Can you send the specific file (or
provide a URL to the specific file) that isn't working for you?

On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> I have the file GSE162562_RAW. First I untar them
> by untar("GSE162562_RAW.tar")
> then I am running like:
>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>
>
> This is running fine in Linux but not in windows. What changes I
> should make to run this command in windows as well
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Mon Aug 23 21:20:45 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Tue, 24 Aug 2021 00:20:45 +0500
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
 <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
Message-ID: <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>

I am trying this URL: "
https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
"

but it is not giving me any file

On Mon, Aug 23, 2021 at 11:42 PM Andrew Simmons <akwsimmo at gmail.com> wrote:

> Hello,
>
>
> I don't think you need to use a system command directly, I think
> 'utils::untar' is all you need. I tried the same thing myself, something
> like:
>
>
> URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
> FILE <- file.path(tempdir(), basename(URL))
>
>
> utils::download.file(URL, FILE)
> utils::untar(FILE, exdir = dirname(FILE))
>
>
> and it makes a folder "Image-ExifTool-12.30". It seems to work perfectly
> fine in Windows 10 x64 build 19042. Can you send the specific file (or
> provide a URL to the specific file) that isn't working for you?
>
> On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <anasjamshed1994 at gmail.com>
> wrote:
>
>> I have the file GSE162562_RAW. First I untar them
>> by untar("GSE162562_RAW.tar")
>> then I am running like:
>>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>>
>>
>> This is running fine in Linux but not in windows. What changes I
>> should make to run this command in windows as well
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Mon Aug 23 23:03:33 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 23 Aug 2021 17:03:33 -0400
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
 <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
 <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>
Message-ID: <CAPcHnpSU1kc-TmB42dq4wyfZf_wQv2oyx+Kx4qkgzar3gz1jaw@mail.gmail.com>

Hello,


I tried downloading that file using 'utils::download.file' (which worked),
but then continued to complain about "damaged archive" when trying to use
'utils::untar'. However, it seemed to work when I downloaded the archive
manually. Finally, the solution I found is that you have to specify the
mode in which you're downloading the file. Something like:


URL <- "
https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
"
FILE <- file.path(tempdir(), basename(URL))


utils::download.file(URL, FILE, mode = "wb")
utils::untar(FILE, exdir = dirname(FILE))


worked perfectly for me. It seems to also work still on Ubuntu, but you can
let us know if you find it doesn't. I hope this helps!



On Mon, Aug 23, 2021 at 3:20 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> I am trying this URL: "
> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
> "
>
> but it is not giving me any file
>
> On Mon, Aug 23, 2021 at 11:42 PM Andrew Simmons <akwsimmo at gmail.com>
> wrote:
>
>> Hello,
>>
>>
>> I don't think you need to use a system command directly, I think
>> 'utils::untar' is all you need. I tried the same thing myself, something
>> like:
>>
>>
>> URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
>> FILE <- file.path(tempdir(), basename(URL))
>>
>>
>> utils::download.file(URL, FILE)
>> utils::untar(FILE, exdir = dirname(FILE))
>>
>>
>> and it makes a folder "Image-ExifTool-12.30". It seems to work perfectly
>> fine in Windows 10 x64 build 19042. Can you send the specific file (or
>> provide a URL to the specific file) that isn't working for you?
>>
>> On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <anasjamshed1994 at gmail.com>
>> wrote:
>>
>>> I have the file GSE162562_RAW. First I untar them
>>> by untar("GSE162562_RAW.tar")
>>> then I am running like:
>>>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>>>
>>>
>>> This is running fine in Linux but not in windows. What changes I
>>> should make to run this command in windows as well
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Aug 24 00:15:12 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 24 Aug 2021 10:15:12 +1200
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
Message-ID: <CAB8pepy1hHg8KuTn3pHS0FNLQMbAn8cwFPw7VfouNGEPOFBEtQ@mail.gmail.com>

There are some differences in R, between Windows and Linux.
You could try the 'shell' command instead.

#On Windows
?shell

On Tue, Aug 24, 2021 at 4:53 AM Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>
> I have the file GSE162562_RAW. First I untar them
> by untar("GSE162562_RAW.tar")
> then I am running like:
>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>
>
> This is running fine in Linux but not in windows. What changes I
> should make to run this command in windows as well
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Tue Aug 24 01:22:17 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 23 Aug 2021 23:22:17 +0000 (UTC)
Subject: [R] data manipulation question
References: <1560501578.578.1629760937806.ref@mail.yahoo.com>
Message-ID: <1560501578.578.1629760937806@mail.yahoo.com>

Hello List,
I wrote the script below to assign value to a new field?DisclosureStatus.
my goal is if?gl_resultsdisclosed=1 then?DisclosureStatus=DISCLOSED
else if?gl_resultsdisclosed=0 then?DisclosureStatus=?ATTEMPTED
else if?gl_resultsdisclosed is missing and?gl_discloseattempt1 is not missing then?DisclosureStatus=?ATTEMPTED
else missing


germlinepatients$DisclosureStatus <-?
? ? ? ? ? ? ? ifelse(germlinepatients$gl_resultsdisclosed==1, "DISCLOSED",
? ? ? ? ? ? ? ? ifelse(germlinepatients$ gl_resultsdisclosed==0, "ATTEMPTED",?
? ? ? ? ? ? ? ? ? ?ifelse(is.na(germlinepatients$gl_resultsdisclosed) & germlinepatients$gl_discloseattempt1!='', "ATTEMPTED",
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?NA)))

the first 3 row give me right result, but the 3rd row does not. After checking the data, there are 23 cases are?gl_resultsdisclosed is missing and?gl_discloseattempt1 is not missing.? the code doesn't has any error message.
Please help?
thank you

	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Tue Aug 24 01:41:40 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Tue, 24 Aug 2021 01:41:40 +0200
Subject: [R] Dynamic Creation and Use of Object Names
In-Reply-To: <CAGxFJbTSbbRxaMGbqn-zRDgsUFpHbmU1HV+55VaySpLub5S3zQ@mail.gmail.com>
References: <sfvfo6$4hm$1@ciao.gmane.io> <20210823102039.3acfa6df@trisector>
 <bf0f25c4-0c86-ae61-cc2f-dc318123ee6b@lisse.NA>
 <CAGxFJbTSbbRxaMGbqn-zRDgsUFpHbmU1HV+55VaySpLub5S3zQ@mail.gmail.com>
Message-ID: <sg1bnk$12bf$1@ciao.gmane.io>

Thanks,

long weekend coming up :-)-O

el

On 2021-08-23 18:06 , Bert Gunter wrote:
> ...  and to add to Ivan's suggestions, **depending on what you are
> trying to show with your grid of graphs,** you may wish to consider
> using ggplot's "facet" capabilities to assure that any quantitative
> variables that you are encoding in the maps (e.g. by color, density
> shading, etc.)  are depicted on the same scale with appropriate
> legends.  (Of course, ignore if this is not the case).  If so, you
> will need a different data structure for your data, I believe.
> 
> Bert Gunter
[...]


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Tue Aug 24 02:16:44 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Tue, 24 Aug 2021 05:16:44 +0500
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAPcHnpSU1kc-TmB42dq4wyfZf_wQv2oyx+Kx4qkgzar3gz1jaw@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
 <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
 <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>
 <CAPcHnpSU1kc-TmB42dq4wyfZf_wQv2oyx+Kx4qkgzar3gz1jaw@mail.gmail.com>
Message-ID: <CAG0CrLj6g4Np_6+GqYWJqs5iJiEPzEqcdTari7=W38u54sZ9ag@mail.gmail.com>

sir after that I want to run:
#get the list of sample names
GSMnames <- t(list.files("~/Desktop/GSE162562_RAW", full.names = F))

#remove .txt from file/sample names
GSMnames <- gsub(pattern = ".txt", replacement = "", GSMnames)

#make a vector of the list of files to aggregate
files <- list.files("~/Desktop/GSE162562_RAW", full.names = TRUE)


but it is not running as after running utils::untar(FILE, exdir =
dirname(FILE)) it creates another 108 archieves

On Tue, Aug 24, 2021 at 2:03 AM Andrew Simmons <akwsimmo at gmail.com> wrote:

> Hello,
>
>
> I tried downloading that file using 'utils::download.file' (which worked),
> but then continued to complain about "damaged archive" when trying to use
> 'utils::untar'. However, it seemed to work when I downloaded the archive
> manually. Finally, the solution I found is that you have to specify the
> mode in which you're downloading the file. Something like:
>
>
> URL <- "
> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
> "
> FILE <- file.path(tempdir(), basename(URL))
>
>
> utils::download.file(URL, FILE, mode = "wb")
> utils::untar(FILE, exdir = dirname(FILE))
>
>
> worked perfectly for me. It seems to also work still on Ubuntu, but you
> can let us know if you find it doesn't. I hope this helps!
>
>
>
> On Mon, Aug 23, 2021 at 3:20 PM Anas Jamshed <anasjamshed1994 at gmail.com>
> wrote:
>
>> I am trying this URL: "
>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>> "
>>
>> but it is not giving me any file
>>
>> On Mon, Aug 23, 2021 at 11:42 PM Andrew Simmons <akwsimmo at gmail.com>
>> wrote:
>>
>>> Hello,
>>>
>>>
>>> I don't think you need to use a system command directly, I think
>>> 'utils::untar' is all you need. I tried the same thing myself, something
>>> like:
>>>
>>>
>>> URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
>>> FILE <- file.path(tempdir(), basename(URL))
>>>
>>>
>>> utils::download.file(URL, FILE)
>>> utils::untar(FILE, exdir = dirname(FILE))
>>>
>>>
>>> and it makes a folder "Image-ExifTool-12.30". It seems to work perfectly
>>> fine in Windows 10 x64 build 19042. Can you send the specific file (or
>>> provide a URL to the specific file) that isn't working for you?
>>>
>>> On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <anasjamshed1994 at gmail.com>
>>> wrote:
>>>
>>>> I have the file GSE162562_RAW. First I untar them
>>>> by untar("GSE162562_RAW.tar")
>>>> then I am running like:
>>>>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>>>>
>>>>
>>>> This is running fine in Linux but not in windows. What changes I
>>>> should make to run this command in windows as well
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug 24 02:19:34 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 24 Aug 2021 10:19:34 +1000
Subject: [R] data manipulation question
In-Reply-To: <1560501578.578.1629760937806@mail.yahoo.com>
References: <1560501578.578.1629760937806.ref@mail.yahoo.com>
 <1560501578.578.1629760937806@mail.yahoo.com>
Message-ID: <CA+8X3fUO9GVOzq+DfF-CnPeUo06Fw2T7N36AQR=4i1B83EuVDg@mail.gmail.com>

Hi Kai,
How about setting:

germlinepatients$DisclosureStatus <- NA

then having your three conditional statements as indices:

germlinepatients$DisclosureStatus[germlinepatients$gl_resultsdisclosed
== 1] <-"DISCLOSED"
germlinepatients$DisclosureStatus[germlinepatients$
gl_resultsdisclosed == 0] <- "ATTEMPTED"
 germlinepatients$DisclosureStatus[is.na(germlinepatients$gl_resultsdisclosed) &
 germlinepatients$gl_discloseattempt1 != "ATTEMPTED"] <-"ATTEMPTED"

I know it's not elegant and you could join the last two statements
with OR (|) but it may work.

Jim

On Tue, Aug 24, 2021 at 9:22 AM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
> Hello List,
> I wrote the script below to assign value to a new field DisclosureStatus.
> my goal is if gl_resultsdisclosed=1 then DisclosureStatus=DISCLOSED
> else if gl_resultsdisclosed=0 then DisclosureStatus= ATTEMPTED
> else if gl_resultsdisclosed is missing and gl_discloseattempt1 is not missing then DisclosureStatus= ATTEMPTED
> else missing
>
>
> germlinepatients$DisclosureStatus <-
>               ifelse(germlinepatients$gl_resultsdisclosed==1, "DISCLOSED",
>                 ifelse(germlinepatients$ gl_resultsdisclosed==0, "ATTEMPTED",
>                    ifelse(is.na(germlinepatients$gl_resultsdisclosed) & germlinepatients$gl_discloseattempt1!='', "ATTEMPTED",
>                                                            NA)))
>
> the first 3 row give me right result, but the 3rd row does not. After checking the data, there are 23 cases are gl_resultsdisclosed is missing and gl_discloseattempt1 is not missing.  the code doesn't has any error message.
> Please help
> thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @kw@|mmo @end|ng |rom gm@||@com  Tue Aug 24 04:43:09 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 23 Aug 2021 22:43:09 -0400
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAG0CrLj6g4Np_6+GqYWJqs5iJiEPzEqcdTari7=W38u54sZ9ag@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
 <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
 <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>
 <CAPcHnpSU1kc-TmB42dq4wyfZf_wQv2oyx+Kx4qkgzar3gz1jaw@mail.gmail.com>
 <CAG0CrLj6g4Np_6+GqYWJqs5iJiEPzEqcdTari7=W38u54sZ9ag@mail.gmail.com>
Message-ID: <CAPcHnpROQApeRS_56qMcALT-x6E8LyFi-wNmw6Y5L2txYPB7uw@mail.gmail.com>

Hello,


I see what you're saying that the .tar archive contains many more
compressed files, but that's not necessarily a problem. R can read directly
from a compressed file without having to decompress it beforehand. I
modified my code to look a little more like yours:


# need to do 'path.expand' or 'untar' will fail
# this is where we put the downloaded files
exdir <- path.expand("~/GSE162562_RAW")
dir.create(exdir, showWarnings = FALSE)


URL <- "
https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
"
FILE <- file.path(tempdir(), basename(URL))


utils::download.file(URL, FILE, mode = "wb")
utils::untar(FILE, exdir = exdir)
unlink(FILE, recursive = TRUE, force = TRUE)


# 'files' is the full path to the downloaded files
# attribute 'names' is the basename with '.txt.gz' removed from the end
files <- list.files(exdir, full.names = TRUE)
names(files) <- sub("\\.txt\\.gz$", "", basename(files))


# R can open compressed files without decompressing beforehand
print(utils::read.table(files[[1]], sep = "\t"))
print(utils::read.delim(files[[2]], header = FALSE))


Does this work better than before for you?

On Mon, Aug 23, 2021 at 8:16 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> sir after that I want to run:
> #get the list of sample names
> GSMnames <- t(list.files("~/Desktop/GSE162562_RAW", full.names = F))
>
> #remove .txt from file/sample names
> GSMnames <- gsub(pattern = ".txt", replacement = "", GSMnames)
>
> #make a vector of the list of files to aggregate
> files <- list.files("~/Desktop/GSE162562_RAW", full.names = TRUE)
>
>
> but it is not running as after running utils::untar(FILE, exdir =
> dirname(FILE)) it creates another 108 archieves
>
> On Tue, Aug 24, 2021 at 2:03 AM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
>> Hello,
>>
>>
>> I tried downloading that file using 'utils::download.file' (which
>> worked), but then continued to complain about "damaged archive" when trying
>> to use 'utils::untar'. However, it seemed to work when I downloaded the
>> archive manually. Finally, the solution I found is that you have to specify
>> the mode in which you're downloading the file. Something like:
>>
>>
>> URL <- "
>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>> "
>> FILE <- file.path(tempdir(), basename(URL))
>>
>>
>> utils::download.file(URL, FILE, mode = "wb")
>> utils::untar(FILE, exdir = dirname(FILE))
>>
>>
>> worked perfectly for me. It seems to also work still on Ubuntu, but you
>> can let us know if you find it doesn't. I hope this helps!
>>
>>
>>
>> On Mon, Aug 23, 2021 at 3:20 PM Anas Jamshed <anasjamshed1994 at gmail.com>
>> wrote:
>>
>>> I am trying this URL: "
>>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>>> "
>>>
>>> but it is not giving me any file
>>>
>>> On Mon, Aug 23, 2021 at 11:42 PM Andrew Simmons <akwsimmo at gmail.com>
>>> wrote:
>>>
>>>> Hello,
>>>>
>>>>
>>>> I don't think you need to use a system command directly, I think
>>>> 'utils::untar' is all you need. I tried the same thing myself, something
>>>> like:
>>>>
>>>>
>>>> URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
>>>> FILE <- file.path(tempdir(), basename(URL))
>>>>
>>>>
>>>> utils::download.file(URL, FILE)
>>>> utils::untar(FILE, exdir = dirname(FILE))
>>>>
>>>>
>>>> and it makes a folder "Image-ExifTool-12.30". It seems to work
>>>> perfectly fine in Windows 10 x64 build 19042. Can you send the specific
>>>> file (or provide a URL to the specific file) that isn't working for you?
>>>>
>>>> On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <
>>>> anasjamshed1994 at gmail.com> wrote:
>>>>
>>>>> I have the file GSE162562_RAW. First I untar them
>>>>> by untar("GSE162562_RAW.tar")
>>>>> then I am running like:
>>>>>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>>>>>
>>>>>
>>>>> This is running fine in Linux but not in windows. What changes I
>>>>> should make to run this command in windows as well
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>

	[[alternative HTML version deleted]]


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Tue Aug 24 04:48:38 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Tue, 24 Aug 2021 07:48:38 +0500
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAPcHnpROQApeRS_56qMcALT-x6E8LyFi-wNmw6Y5L2txYPB7uw@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
 <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
 <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>
 <CAPcHnpSU1kc-TmB42dq4wyfZf_wQv2oyx+Kx4qkgzar3gz1jaw@mail.gmail.com>
 <CAG0CrLj6g4Np_6+GqYWJqs5iJiEPzEqcdTari7=W38u54sZ9ag@mail.gmail.com>
 <CAPcHnpROQApeRS_56qMcALT-x6E8LyFi-wNmw6Y5L2txYPB7uw@mail.gmail.com>
Message-ID: <CAG0CrLjT7mRgg-4GyxJcqFU96=QUX0i20UbCKP-=QANkHwvgKw@mail.gmail.com>

but the point is that where should I start from now

On Tue, Aug 24, 2021 at 7:43 AM Andrew Simmons <akwsimmo at gmail.com> wrote:

> Hello,
>
>
> I see what you're saying that the .tar archive contains many more
> compressed files, but that's not necessarily a problem. R can read directly
> from a compressed file without having to decompress it beforehand. I
> modified my code to look a little more like yours:
>
>
> # need to do 'path.expand' or 'untar' will fail
> # this is where we put the downloaded files
> exdir <- path.expand("~/GSE162562_RAW")
> dir.create(exdir, showWarnings = FALSE)
>
>
> URL <- "
> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
> "
> FILE <- file.path(tempdir(), basename(URL))
>
>
> utils::download.file(URL, FILE, mode = "wb")
> utils::untar(FILE, exdir = exdir)
> unlink(FILE, recursive = TRUE, force = TRUE)
>
>
> # 'files' is the full path to the downloaded files
> # attribute 'names' is the basename with '.txt.gz' removed from the end
> files <- list.files(exdir, full.names = TRUE)
> names(files) <- sub("\\.txt\\.gz$", "", basename(files))
>
>
> # R can open compressed files without decompressing beforehand
> print(utils::read.table(files[[1]], sep = "\t"))
> print(utils::read.delim(files[[2]], header = FALSE))
>
>
> Does this work better than before for you?
>
> On Mon, Aug 23, 2021 at 8:16 PM Anas Jamshed <anasjamshed1994 at gmail.com>
> wrote:
>
>> sir after that I want to run:
>> #get the list of sample names
>> GSMnames <- t(list.files("~/Desktop/GSE162562_RAW", full.names = F))
>>
>> #remove .txt from file/sample names
>> GSMnames <- gsub(pattern = ".txt", replacement = "", GSMnames)
>>
>> #make a vector of the list of files to aggregate
>> files <- list.files("~/Desktop/GSE162562_RAW", full.names = TRUE)
>>
>>
>> but it is not running as after running utils::untar(FILE, exdir =
>> dirname(FILE)) it creates another 108 archieves
>>
>> On Tue, Aug 24, 2021 at 2:03 AM Andrew Simmons <akwsimmo at gmail.com>
>> wrote:
>>
>>> Hello,
>>>
>>>
>>> I tried downloading that file using 'utils::download.file' (which
>>> worked), but then continued to complain about "damaged archive" when trying
>>> to use 'utils::untar'. However, it seemed to work when I downloaded the
>>> archive manually. Finally, the solution I found is that you have to specify
>>> the mode in which you're downloading the file. Something like:
>>>
>>>
>>> URL <- "
>>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>>> "
>>> FILE <- file.path(tempdir(), basename(URL))
>>>
>>>
>>> utils::download.file(URL, FILE, mode = "wb")
>>> utils::untar(FILE, exdir = dirname(FILE))
>>>
>>>
>>> worked perfectly for me. It seems to also work still on Ubuntu, but you
>>> can let us know if you find it doesn't. I hope this helps!
>>>
>>>
>>>
>>> On Mon, Aug 23, 2021 at 3:20 PM Anas Jamshed <anasjamshed1994 at gmail.com>
>>> wrote:
>>>
>>>> I am trying this URL: "
>>>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>>>> "
>>>>
>>>> but it is not giving me any file
>>>>
>>>> On Mon, Aug 23, 2021 at 11:42 PM Andrew Simmons <akwsimmo at gmail.com>
>>>> wrote:
>>>>
>>>>> Hello,
>>>>>
>>>>>
>>>>> I don't think you need to use a system command directly, I think
>>>>> 'utils::untar' is all you need. I tried the same thing myself, something
>>>>> like:
>>>>>
>>>>>
>>>>> URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
>>>>> FILE <- file.path(tempdir(), basename(URL))
>>>>>
>>>>>
>>>>> utils::download.file(URL, FILE)
>>>>> utils::untar(FILE, exdir = dirname(FILE))
>>>>>
>>>>>
>>>>> and it makes a folder "Image-ExifTool-12.30". It seems to work
>>>>> perfectly fine in Windows 10 x64 build 19042. Can you send the specific
>>>>> file (or provide a URL to the specific file) that isn't working for you?
>>>>>
>>>>> On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <
>>>>> anasjamshed1994 at gmail.com> wrote:
>>>>>
>>>>>> I have the file GSE162562_RAW. First I untar them
>>>>>> by untar("GSE162562_RAW.tar")
>>>>>> then I am running like:
>>>>>>  system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>>>>>>
>>>>>>
>>>>>> This is running fine in Linux but not in windows. What changes I
>>>>>> should make to run this command in windows as well
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Aug 24 11:10:54 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 24 Aug 2021 09:10:54 +0000
Subject: [R] Selecting elements
In-Reply-To: <CAMaZ2WBKonNK47bCL3W3p-RmmhKw_Lw7oqHyHCzqTTBWdX=fSA@mail.gmail.com>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
 <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WBKonNK47bCL3W3p-RmmhKw_Lw7oqHyHCzqTTBWdX=fSA@mail.gmail.com>
Message-ID: <0db77aa4a7a74611ad833311cc9ef880@SRVEXCHCM1302.precheza.cz>

Hi.

Now it is understandable.  However the solution is not clear for me. 

table(Order$Var.1[1:10])
A B C D 
4 1 2 3 

should give you a hint which scheme could be acceptable, but how to do it programmatically I do not know.

maybe to start with lower value in the table call and gradually increse it to check which scheme starts to be the chosen one

> table(data.o$Var.1[1]) # scheme 2 is out
C 
1
...
> table(data.o$Var.1[1:5]) #scheme 3
A B C D 
1 1 2 1 

> table(data.o$Var.1[1:6]) #scheme 3

A B C D 
2 1 2 1 

> table(data.o$Var.1[1:7]) # scheme1
A B C D 
2 1 2 2 

> table(data.o$Var.1[1:8]) # no such scheme, so scheme 1 is chosen one
A B C D 
2 1 2 3 

#Now you need to select values based on scheme 1.
# 3A - 3B - 2C - 2D

sss <- split(Order, Order$Var.1)
selection <- c(3,3,2,2)
result <- vector("list", 4)

#I would use loop

for(i in 1:4) {
result[[i]] <- sss[[i]][1:selection[i],]
}

Maybe someone come with other ingenious solution.

Cheers
Petr

From: Silvano Cesar da Costa <silvano at uel.br> 
Sent: Monday, August 23, 2021 7:54 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Re: [R] Selecting elements

Hi,

I apologize for the confusion. I will try to be clearer in my explanation. I believe that with the R script it becomes clearer.

I have 4 variables with 10 repetitions and each one receives a value, randomly. 
I order the dataset from largest to smallest value. I have to select 10 elements in 
descending order of values, according to one of three schemes:

# 3A - 3B - 2C - 2D
# 2A - 5B - 0C - 3D
# 3A - 4B - 2C - 1D

If the first 3 elements (out of the 10 to be selected) are of the letter D, automatically 
the adopted scheme will be the second. So, I have to (following) choose 2A, 5B and 0C.
How to make the selection automatically?

I created two selection examples, with different schemes:



set.seed(123)

Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)

data = data.frame(Var.1, Var.2)

(Order = data[order(data$Var.2, decreasing=TRUE), ])

# I must select the 10 highest values (), 
# but which follow a certain scheme:
#
#  3A - 3B - 2C - 2D     or 
#  2A - 5B - 0C - 3D     or
#  3A - 4B - 2C - 1D
#
# In this case, I started with the highest value that refers to the letter C. 
# Next comes only 1 of the letters B, A and D. All are selected once. 
# The fifth observation is the letter C, completing 2 C values. In this case, 
# following the 3 adopted schemes, note that the second scheme has 0C, 
# so this scheme is out.
# Therefore, it can be the first scheme (3A - 3B - 2C - 2D) or the 
# third scheme (3A - 4B - 2C - 1D).
# The next letter to be completed is the D (fourth and seventh elements), 
# among the 10 elements being selected. Therefore, the scheme adopted is the 
# first one (3A - 3B - 2C - 2D).
# Therefore, it is necessary to select 2 values with the letter B and 1 value 
# with the letter A.
#
# Manual Selection -
# The end result is:
(Selected.data = Order[c(1,2,3,4,5,6,7,9,13,16), ])

# Scheme: 3A - 3B - 2C - 2D
sort(Selected.data$Var.1)


#------------------
# Second example: -
#------------------
set.seed(4)

Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)

data = data.frame(Var.1, Var.2)
(Order = data[order(data$Var.2, decreasing=TRUE), ])

# The end result is:
(Selected.data.2 = Order[c(1,2,3,4,5,6,7,8,9,11), ])

# Scheme: 3A - 4B - 2C - 1D
sort(Selected.data.2$Var.1)

How to make the selection of the 10 elements automatically?

Thank you very much.

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


Em seg., 23 de ago. de 2021 ?s 05:05, PIKAL Petr <mailto:petr.pikal at precheza.cz> escreveu:
Hi

Only I got your HTML formated mail, rest of the world got complete mess. Do not use HTML formating.

As I got it right I wonder why in your second example you did not follow
3A - 3B - 2C - 2D

as D were positioned 1st and 4th.

I hope that you could use something like

sss <- split(data$Var.2, data$Var.1)
lapply(sss, cumsum)
$A
 [1]  38  73 105 136 166 188 199 207 209 210

$B
 [1]  39  67  92 115 131 146 153 159 164 168

$C
 [1]  40  76 105 131 152 171 189 203 213 222

$D
 [1]  37  71 104 131 155 175 192 205 217 220

Now you need to evaluate this result according to your sets. Here the highest value (76) is in C so the set with 2C is the one you should choose and select you value according to this set.

With
> set.seed(666)
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> data = data.frame(Var.1, Var.2)
> data <- data[order(data$Var.2, decreasing=TRUE), ]
> sss <- split(data$Var.2, data$Var.1)
> lapply(sss, cumsum)
$A
 [1]  36  70 102 133 163 182 200 207 212 213

$B
 [1]  35  57  78  95 108 120 131 140 148 150

$C
 [1]  40  73 102 130 156 180 196 211 221 225

$D
 [1]  39  77 114 141 166 189 209 223 229 232

Highest value is in D so either 3A - 3B - 2C - 2D  or 3A - 3B - 2C - 2D should be appropriate. And here I am again lost as both sets are same. Maybe you need to reconsider your statements.

Cheers
Petr

From: Silvano Cesar da Costa <mailto:silvano at uel.br> 
Sent: Friday, August 20, 2021 9:28 PM
To: PIKAL Petr <mailto:petr.pikal at precheza.cz>
Cc: mailto:r-help at r-project.org
Subject: Re: [R] Selecting elements

Hi, thanks you for the answer. 
Sorry English is not my native language.

But you got it right. 
> As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?

I must select the 10 (not 15) highest values, but which follow a certain order:
3A - 3B - 2C - 2D     or 
2A - 5B - 0C - 3D     or
3A - 3B - 2C - 2D
I'll put the example in Excel for a better understanding (with 20 elements only). 
I must select 10 elements (the highest values of variable Var.2), which fit one of the 3 options above. 

Number
Position
Var.1
Var.2








1
27
C
40








2
30
B
39

Selected: 





3
5
A
38

Number
Position
Var.1
Var.2



4
16
D
37

1
27
C
40



5
23
C
36

2
30
B
39

3A - 3B - 2C - 2D
6
13
A
35

3
5
A
38



7
20
D
34

4
16
D
37

3A - 3B - 1C - 3D
8
12
D
33

5
23
C
36



9
9
A
32

6
13
A
35

2A - 5B - 0C - 3D
10
1
A
31

7
20
D
34



11
21
A
30

10
9
A
32



12
35
C
29

13
14
B
28



13
14
B
28

17
6
B
25



14
8
D
27








15
7
C
26








16
6
B
25








17
40
D
24








18
26
B
23








19
29
A
22








20
31
C
21











Second option (other data set):

Number
Position
Var.1
Var.2








1
36
D
20








2
11
B
19

Selected: 





3
39
A
18

Number
Position
Var.1
Var.2



4
24
D
17

1
36
D
20



5
34
B
16

2
11
B
19

3A - 3B - 2C - 2D
6
2
B
15

3
39
A
18



7
3
A
14

4
24
D
17

3A - 3B - 1C - 3D
8
32
D
13

5
34
B
16



9
28
D
12

6
2
B
15

2A - 5B - 0C - 3D
10
25
A
11

7
3
A
14



11
19
B
10

8
32
D
13



12
15
B
9

9
25
A
11



13
17
A
8

10
18
C
7



14
18
C
7








15
38
B
6








16
10
B
5








17
22
B
4








18
4
D
3








19
33
A
2








20
37
A
1










How to make the selection of these 10 elements that fit one of the 3 options using R?

Thanks,

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <mailto:mailto:petr.pikal at precheza.cz> escreveu:
Hallo

I am confused, maybe others know what do you want but could you be more specific?

Let say you have such data
set.seed(123)
Var.1 = rep(LETTERS[1:4], 10)
Var.2 = sample(1:40, replace=FALSE)
data = data.frame(Var.1, Var.2)

What should be the desired outcome?

You can sort
data <- data[order(data$Var.2, decreasing=TRUE), ]
and split the data
> split(data$Var.2, data$Var.1)
$A
 [1] 38 35 32 31 30 22 11  8  2  1

$B
 [1] 39 28 25 23 16 15  7  6  5  4

$C
 [1] 40 36 29 26 21 19 18 14 10  9

$D
 [1] 37 34 33 27 24 20 17 13 12  3

T inspect highest values. But here I am lost. As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?

Or I do not understand at all what you really want to achieve.

Cheers
Petr

> -----Original Message-----
> From: R-help <mailto:mailto:r-help-bounces at r-project.org> On Behalf Of Silvano Cesar da
> Costa
> Sent: Thursday, August 19, 2021 10:40 PM
> To: mailto:mailto:r-help at r-project.org
> Subject: [R] Selecting elements
> 
> Hi,
> 
> I need to select 15 elements, always considering the highest values
> (descending order) but obeying the following configuration:
> 
> 3A - 4B - 0C - 3D or
> 2A - 5B - 0C - 3D or
> 3A - 3B - 2C - 2D
> 
> If I have, for example, 5 A elements as the highest values, I can only choose
> (first and third choice) or 2 (second choice) elements.
> 
> how to make this selection?
> 
> 
> library(dplyr)
> 
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> 
> data = data.frame(Var.1, Var.2)
> (data = data[order(data$Var.2, decreasing=TRUE), ])
> 
> Elements = data %>%
>   arrange(desc(Var.2))
> 
> Thanks,
> 
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
> 
> Fone: (43) 3371-4346
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> mailto:mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From d@v|d@w@nepoe| @end|ng |rom hotm@||@com  Tue Aug 24 16:44:55 2021
From: d@v|d@w@nepoe| @end|ng |rom hotm@||@com (David Swanepoel)
Date: Tue, 24 Aug 2021 14:44:55 +0000
Subject: [R] Query regarding stats/p.adjust package (base) - specifically
 'Hochberg' function
Message-ID: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>

Dear R Core Dev Team, I hope all is well your side!
My apologies if this is not the correct point of contact to use to address this. If not, kindly advise or forward my request to the relevant team/persons.

I have a query regarding the 'Hochberg' method of the stats/p.adjust R package and hope you can assist me please. I have attached the data I used in Excel, which are lists of p-values for two different tests (Hardy Weinberg Equilibrium and Linkage Disequilibrium) for four population groups.

The basis of my concern is a discrepancy specifically between the Hochberg correction applied by four different R packages and the results of the Hochberg correction by the online tool, MultipleTesting.com<http://www.multipletesting.com/>.

Using the below R packages/functions, I ran multiple test correction (MTC) adjustments for the p-values listed in my dataset. All R packages below agreed with each other regarding the 'significance' of the p-values for the Hochberg adjustment.


  *   stats/p.adjust (method: Hochberg)
  *   mutoss/hochberg
  *   multtest/mt.rawp2adjp (procedure: Hochberg)
  *   elitism/mtp (method: Hochberg)

In checking the same values on the MultipleTesting.com, more p-values were flagged as significant for both the HWE and LD results across all four populations. I show these differences in the Excel sheet attached.
Essentially, using the R packages, only the first HWE p-value of Pop2 is significant at an alpha of 0.05. Using the MT.com tool, however, multiple p-values are shown to be significant across both tests with the Hochberg correction (the highlighted cells in the Excel sheet).


I asked the authors of MT.com about this, and they gave the following response:

"we have checked the issue, and we believe the computation by our page is correct (I cannot give opinion about the other packages).
When we look on the original Hochberg paper, and we only use the very first (smallest) p value, then m"=1, thus, according to the equation in the Hochberg 1988 paper, in this case practically there is no further correction necessary.
In other words, in case the *smallest* p value is smaller than alpha, then the *smallest* p value will remain significant irrespective of the other p values when we make the Hochberg correction."

I have attached the Hochberg paper here but, unfortunately, I don't understand enough of the stats to verify this. I have applied their logic on the same Excel sheet under the section "MT.com explanation", which shows why they consider the highlighted values significant.

I have also attached the 2 R files that I used to do the MTC runs and they can be run as is. They are just quite long as they contain many of the other MTC methods in the different packages too.

Kindly provide your thoughts as to whether you agree with this interpretation of the Hochberg paper or not? I would like to see concordance between the MT.com tool and the different R packages above (or understand why they are different), so that I can be more confident in the explanations of my own results as a stats layman.

I hope this makes sense. Please let me know if I need to clarify anything.


Many thanks and kind regards,
David

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Hochberg - 1988 - A Sharper Bonferroni Procedure for Multiple Tests of Significance.pdf
Type: application/pdf
Size: 325078 bytes
Desc: Hochberg - 1988 - A Sharper Bonferroni Procedure for Multiple Tests of Significance.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210824/19a37779/attachment.pdf>

From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 24 19:50:50 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 24 Aug 2021 10:50:50 -0700
Subject: [R] 
 Query regarding stats/p.adjust package (base) - specifically
 'Hochberg' function
In-Reply-To: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
References: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
Message-ID: <CAGxFJbRMbWKztE73KCWHVomwUKpeR3hjwOiwqFOwx-vgZnpJPA@mail.gmail.com>

1. No Excel attachments made it through. Binary attachments are
generally stripped by the list server for security reasons.

2. As you may have already learned, this is the wrong forum for
statistics or package specific questions. Read *and follow* the
posting guide linked below to post on r-help appropriately. In
particular, for questions about specific non-standard packages,
contact package maintainers (found through e.g. ?maintainers)

3. Statistics issues generally don't belong here. Try
stats.stackexchange.com instead perhaps.

4. We are not *R Core development,*  and you probably should not be
contacting them either.  See here for general guidelines for R lists:
https://www.r-project.org/mail.html


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 24, 2021 at 10:39 AM David Swanepoel
<davidswanepoel at hotmail.com> wrote:
>
> Dear R Core Dev Team, I hope all is well your side!
> My apologies if this is not the correct point of contact to use to address this. If not, kindly advise or forward my request to the relevant team/persons.
>
> I have a query regarding the 'Hochberg' method of the stats/p.adjust R package and hope you can assist me please. I have attached the data I used in Excel, which are lists of p-values for two different tests (Hardy Weinberg Equilibrium and Linkage Disequilibrium) for four population groups.
>
> The basis of my concern is a discrepancy specifically between the Hochberg correction applied by four different R packages and the results of the Hochberg correction by the online tool, MultipleTesting.com<http://www.multipletesting.com/>.
>
> Using the below R packages/functions, I ran multiple test correction (MTC) adjustments for the p-values listed in my dataset. All R packages below agreed with each other regarding the 'significance' of the p-values for the Hochberg adjustment.
>
>
>   *   stats/p.adjust (method: Hochberg)
>   *   mutoss/hochberg
>   *   multtest/mt.rawp2adjp (procedure: Hochberg)
>   *   elitism/mtp (method: Hochberg)
>
> In checking the same values on the MultipleTesting.com, more p-values were flagged as significant for both the HWE and LD results across all four populations. I show these differences in the Excel sheet attached.
> Essentially, using the R packages, only the first HWE p-value of Pop2 is significant at an alpha of 0.05. Using the MT.com tool, however, multiple p-values are shown to be significant across both tests with the Hochberg correction (the highlighted cells in the Excel sheet).
>
>
> I asked the authors of MT.com about this, and they gave the following response:
>
> "we have checked the issue, and we believe the computation by our page is correct (I cannot give opinion about the other packages).
> When we look on the original Hochberg paper, and we only use the very first (smallest) p value, then m"=1, thus, according to the equation in the Hochberg 1988 paper, in this case practically there is no further correction necessary.
> In other words, in case the *smallest* p value is smaller than alpha, then the *smallest* p value will remain significant irrespective of the other p values when we make the Hochberg correction."
>
> I have attached the Hochberg paper here but, unfortunately, I don't understand enough of the stats to verify this. I have applied their logic on the same Excel sheet under the section "MT.com explanation", which shows why they consider the highlighted values significant.
>
> I have also attached the 2 R files that I used to do the MTC runs and they can be run as is. They are just quite long as they contain many of the other MTC methods in the different packages too.
>
> Kindly provide your thoughts as to whether you agree with this interpretation of the Hochberg paper or not? I would like to see concordance between the MT.com tool and the different R packages above (or understand why they are different), so that I can be more confident in the explanations of my own results as a stats layman.
>
> I hope this makes sense. Please let me know if I need to clarify anything.
>
>
> Many thanks and kind regards,
> David
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Aug 24 23:11:16 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 24 Aug 2021 23:11:16 +0200
Subject: [R] 
 Query regarding stats/p.adjust package (base) - specifically
 'Hochberg' function
In-Reply-To: <CAGxFJbRMbWKztE73KCWHVomwUKpeR3hjwOiwqFOwx-vgZnpJPA@mail.gmail.com>
References: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
 <CAGxFJbRMbWKztE73KCWHVomwUKpeR3hjwOiwqFOwx-vgZnpJPA@mail.gmail.com>
Message-ID: <24869.24692.79708.756742@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Tue, 24 Aug 2021 10:50:50 -0700 writes:

    > 1. No Excel attachments made it through. Binary
    > attachments are generally stripped by the list server for
    > security reasons.

    > 2. As you may have already learned, this is the wrong
    > forum for statistics or package specific questions. Read
    > *and follow* the posting guide linked below to post on
    > r-help appropriately. In particular, for questions about
    > specific non-standard packages, contact package
    > maintainers (found through e.g. ?maintainers)

    > 3. Statistics issues generally don't belong here. Try
    > stats.stackexchange.com instead perhaps.

    > 4. We are not *R Core development,* and you probably
    > should not be contacting them either.  See here for
    > general guidelines for R lists:
    > https://www.r-project.org/mail.html


    > Bert Gunter

    > "The trouble with having an open mind is that people keep
    > coming along and sticking things into it."  -- Opus (aka
    > Berkeley Breathed in his "Bloom County" comic strip )

Well, this was a bit harsh of an answer, Bert.

p.adjust() is a standard R  function  (package 'stats') -- as
David Swanepoel did even mention.

I think he's okay asking here if the algorithms used in such a
standard R functions are  "ok"  and how/why they seemlingly
differ from other implementations ...

Martin

    > On Tue, Aug 24, 2021 at 10:39 AM David Swanepoel
    > <davidswanepoel at hotmail.com> wrote:
    >> 
    >> Dear R Core Dev Team, I hope all is well your side!  My
    >> apologies if this is not the correct point of contact to
    >> use to address this. If not, kindly advise or forward my
    >> request to the relevant team/persons.
    >> 
    >> I have a query regarding the 'Hochberg' method of the
    >> stats/p.adjust R package and hope you can assist me
    >> please. I have attached the data I used in Excel, which
    >> are lists of p-values for two different tests (Hardy
    >> Weinberg Equilibrium and Linkage Disequilibrium) for four
    >> population groups.
    >> 
    >> The basis of my concern is a discrepancy specifically
    >> between the Hochberg correction applied by four different
    >> R packages and the results of the Hochberg correction by
    >> the online tool,
    >> MultipleTesting.com<http://www.multipletesting.com/>.
    >> 
    >> Using the below R packages/functions, I ran multiple test
    >> correction (MTC) adjustments for the p-values listed in
    >> my dataset. All R packages below agreed with each other
    >> regarding the 'significance' of the p-values for the
    >> Hochberg adjustment.
    >> 
    >> 
    >> * stats/p.adjust (method: Hochberg) * mutoss/hochberg *
    >> multtest/mt.rawp2adjp (procedure: Hochberg) * elitism/mtp
    >> (method: Hochberg)
    >> 
    >> In checking the same values on the MultipleTesting.com,
    >> more p-values were flagged as significant for both the
    >> HWE and LD results across all four populations. I show
    >> these differences in the Excel sheet attached.
    >> Essentially, using the R packages, only the first HWE
    >> p-value of Pop2 is significant at an alpha of 0.05. Using
    >> the MT.com tool, however, multiple p-values are shown to
    >> be significant across both tests with the Hochberg
    >> correction (the highlighted cells in the Excel sheet).
    >> 
    >> 
    >> I asked the authors of MT.com about this, and they gave
    >> the following response:
    >> 
    >> "we have checked the issue, and we believe the
    >> computation by our page is correct (I cannot give opinion
    >> about the other packages).  When we look on the original
    >> Hochberg paper, and we only use the very first (smallest)
    >> p value, then m"=1, thus, according to the equation in
    >> the Hochberg 1988 paper, in this case practically there
    >> is no further correction necessary.  In other words, in
    >> case the *smallest* p value is smaller than alpha, then
    >> the *smallest* p value will remain significant
    >> irrespective of the other p values when we make the
    >> Hochberg correction."
    >> 
    >> I have attached the Hochberg paper here but,
    >> unfortunately, I don't understand enough of the stats to
    >> verify this. I have applied their logic on the same Excel
    >> sheet under the section "MT.com explanation", which shows
    >> why they consider the highlighted values significant.
    >> 
    >> I have also attached the 2 R files that I used to do the
    >> MTC runs and they can be run as is. They are just quite
    >> long as they contain many of the other MTC methods in the
    >> different packages too.
    >> 
    >> Kindly provide your thoughts as to whether you agree with
    >> this interpretation of the Hochberg paper or not? I would
    >> like to see concordance between the MT.com tool and the
    >> different R packages above (or understand why they are
    >> different), so that I can be more confident in the
    >> explanations of my own results as a stats layman.
    >> 
    >> I hope this makes sense. Please let me know if I need to
    >> clarify anything.
    >> 
    >> 
    >> Many thanks and kind regards, David
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From x|@oyuzengp@y @end|ng |rom gm@||@com  Tue Aug 24 15:41:47 2021
From: x|@oyuzengp@y @end|ng |rom gm@||@com (Xiaoyu Zeng)
Date: Tue, 24 Aug 2021 21:41:47 +0800
Subject: [R] unable to install source packages with Rtools installed
Message-ID: <CABAL1U4pKqKegsZPmCY-4jaHqdAO1XV27a1z8kdfGz1si1jKbA@mail.gmail.com>

Hi all.

I installed the latest R and Rtools, and I followed the guidelines to test
the installation of Rtools (rtools40v2-x86_64.exe for windows10). I
verified that *make* can be found, but I still could not install an R
package from the source.

Any ideas?

*More detailed info:*
https://github.com/r-windows/rtools-packages/issues/222

Best regards,
Xiaoyu

Xiaoyu Zeng

Graduate student, Social and Affective NeuroPharmacology (SANP) Lab

State Key Laboratory of Cognitive Neuroscience and Learning

Beijing Normal University

http://brain.bnu.edu.cn/home/yinama/

	[[alternative HTML version deleted]]


From p@tze|t @end|ng |rom g@h@rv@rd@edu  Tue Aug 24 20:24:43 2021
From: p@tze|t @end|ng |rom g@h@rv@rd@edu (Patzelt, Edward)
Date: Tue, 24 Aug 2021 13:24:43 -0500
Subject: [R] Specifying non-linear mixed effects models in R (non-linear DV)
Message-ID: <CAB9UfhR8-Yq_0Ha2=vUvv_hMFTc4=Nr1CWmsN4mrDneA1EdrYw@mail.gmail.com>

Hi R-Help,

Data is below. I used a Kruskal Wallis to compare across 4 study groups for
my DV (beta - this is highly non-normal). Now I want to add a covariate
(cpz).

1) What package do I use and how do I specify the model? (I tried T.aov
from fANCOVA but received a lot of simpleLoess errors)

2) Can I specify "subject" as a random effect like in lme?

structure(list(subject = c("C5B1001", "C5B1002", "C5B1003", "C5B1004",
"C5B1005", "C5B1007", "C5B1008", "C5B1009", "C5B1010", "C5B1011",
"C5B1012", "C5B1013", "C5B1014", "C5B1015", "C5B1016", "C5B1017",
"C5B1018", "C5B1019", "C5B1020", "C5B1021", "C5B1022", "C5B1023",
"C5B1024", "C5B1025", "C5B1026", "C5B1027", "C5B1029", "C5B1030",
"C5B1031", "C5B1032", "C5B1033", "C5B1034", "C5B1035", "C5B1036",
"C5B1037", "C5B1038", "C5B1039", "C5B1040", "C5B1041", "C5B1042",
"C5B1043", "C5B1044", "C5B1045", "C5B1046", "C5B1047", "C5B1048",
"C5B1049", "C5D2002", "C5D2003", "C5D2005", "C5D2006", "C5D2007",
"C5D2009", "C5D2010", "C5D2011", "C5D2012", "C5D2013", "C5D2014",
"C5D2017", "C5D2021", "C5D2022", "C5D2023", "C5D2024", "C5D2025",
"C5D2026", "C5D2027", "C5D2028", "C5D2029", "C5D2030", "C5D2031",
"C5D2032", "C5D2035", "C5D2036", "C5D2037", "C5D2039", "C5D2040",
"C5D2042", "C5D2043", "C5D2044", "C5D2045", "C5D2046", "C5D2047",
"C5D2048", "C5D2049", "C5D2051", "C5D2052", "C5D2053", "C5D2054",
"C5D2055", "C5M3001", "C5M3003", "C5M3004", "C5M3005", "C5M3006",
"C5M3007", "C5M3008", "C5M3009", "C5M3010", "C5M3011", "C5M3013",
"C5M3014", "C5M3015", "C5M3016", "C5M3017", "C5M3019", "C5M3020",
"C5M3021", "C5M3022", "C5M3023", "C5M3024", "C5M3029", "C5M3030",
"C5M3031", "C5M3032", "C5M3033", "C5M3034", "C5M3035", "C5M3036",
"C5M3038", "C5M3039", "C5M3042", "C5M3043", "C5M3044", "C5M3046",
"C5M3047", "C5M3048", "C5M3049", "C5M3050", "C5M3051", "C5M3054",
"C5M3055", "C5M3056", "C5M3057", "C5M3058", "C5R4001", "C5R4004",
"C5R4005", "C5R4008", "C5R4009", "C5R4010", "C5R4011", "C5R4012",
"C5R4013", "C5R4014", "C5R4015", "C5R4016", "C5R4017", "C5R4019",
"C5R4020", "C5R4021", "C5R4022", "C5R4024", "C5R4025", "C5R4026",
"C5R4027", "C5R4028", "C5R4031", "C5R4032", "C5R4034", "C5R4037",
"C5R4038", "C5R4040", "C5R4041", "C5R4043", "C5R4048", "C5R4050",
"C5R4053", "C5R4056", "C5W5001", "C5W5002", "C5W5003", "C5W5004",
"C5W5005", "C5W5006", "C5W5007", "C5W5008", "C5W5012", "C5W5013",
"C5W5014", "C5W5015", "C5W5016", "C5W5017", "C5W5018", "C5W5019",
"C5W5020", "C5W5021", "C5W5022", "C5W5023", "C5W5024", "C5W5025",
"C5W5028", "C5W5029", "C5W5030", "C5W5031", "C5W5033", "C5W5035",
"C5W5037", "C5W5038", "C5W5039", "C5W5042", "C5W5043", "C5W5044",
"C5W5045", "C5W5046", "C5W5047", "C5W5048", "C5W5049", "C5W5050",
"C5W5051", "C5W5053", "C5W5054", "C5W5055", "C5W5057", "C5W5058",
"C5W5060"), beta = c(5, 5, 5, 4.84951578282477, 5, 1.75435411010482,
2.59653537897755, 4.58343041388045, 1.19813289503568, 5, 4.41030503473763,
3.48886522319213, 5, 3.69347465973804, 5, 3.61341511433856, 5,
5, 5, 5, 2.82540030433712, 5, 2.01269174411245, 5, 5, 5, 5,
3.66605514409922,
5, 5, 1.20492768779028, 5, 5, 5, 5, 4.71051510737403, 0.973607667104191,
2.13320899798223, 3.55527726960037, 5, 3.13840519694586, 5,
4.33164972914231,
3.2716034981509, 5, 3.59865983897491, 5, 5, 2.98982117172486,
3.15884653708899, 5, 1.21006283114433, 1.88594293315325, 2.37248899411035,
2.40289344741545, 0.262839947401338, 2.89061041570249, 2.98573373614306,
2.82385009686039, 1.78295361666595, 4.27268021897288, 5, 5, 5,
2.52131830224533, 5, 2.32463450150955, 5, 5, 2.18297518836912,
5, 2.53256388646574, 5, 5, 5, 1.11901989122708, 1.56266936421015,
5, 2.1480772866684, 1.03201411339444, 3.22476904165877, 5,
2.23963439946338,
5, 3.85477002456212, 5, 5, 3.15602152904957, 4.81306354520538,
1.20566795082516, 5, 5, 5, 5, 3.04288106123443, 5, 4.06490230904187,
3.06547070051755, 5, 2.5258266208828, 3.52552152448218, 0.0968896467078101,
5, 5, 5, 5, 5, 5, 5, 4.99152057373263, 5, 5, 5, 1.1311501363613,
1.28951722667904, 0.001, 5, 4.58718394461838, 1.22231984982818,
5, 5, 3.35873683772968, 5, 3.87156907439221, 4.8859664986002,
5, 5, 0.976932521703834, 5, 4.50479324287729, 4.65093425894735,
4.22173593981599, 3.15590632469025, 4.86144574792365, 3.39926845337078,
1.24825519695535, 5, 3.27167737085564, 2.2107731064995, 0.187339326704238,
5, 5, 2.78773672362584, 0.977242332964066, 1.05162966383033,
4.24031503174416, 1.9558880208883, 4.01331863994726, 5, 5,
4.50553723427244,
4.03830955873134, 0.0731678404955063, 0.326005643499137, 1.48169477386196,
5, 5, 2.1217771592687, 1.55381162571676, 5, 0.388739153131157,
5, 5, 1.22549904356884, 4.30605773910623, 5, 5, 3.90617032103214,
0.884096418271427, 1.7166358084411, 4.26908188373059, 1.97226101693004,
5, 0.831616239014777, 0.001, 4.15065454327444, 5, 5, 2.6582186770924,
4.69752970800906, 4.50106281557844, 4.21353152726281, 5, 0.620184007188853,
5, 3.86897558241413, 3.63483407688021, 3.18900423687508, 1.24002620770954,
5, 5, 5, 5, 5, 1.20112016323594, 1.99534703415304, 5, 2.13269987318149,
3.76529884137316, 2.88523566628984, 1.93828880175044, 5, 1.04561250178734,
3.74875347444577, 5, 5, 2.48460418075441, 5, 4.55602711347155,
3.97926864514993, 3.59636722716411, 5, 2.95039073432615, 4.82668935707021,
3.70517802450053), group = structure(c(1L, 1L, 1L, 1L, 2L, 3L,
3L, 2L, 3L, 2L, 3L, 4L, 4L, 4L, 2L, 2L, 1L, 3L, 3L, 1L, 3L, 1L,
3L, 2L, 3L, 3L, 3L, 2L, 4L, 2L, 3L, 4L, 1L, 2L, 1L, 1L, 2L, 1L,
2L, 4L, 2L, 1L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 3L, 2L, 4L, 4L, 4L,
2L, 2L, 2L, 2L, 2L, 4L, 4L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 4L, 3L,
1L, 4L, 2L, 4L, 3L, 4L, 3L, 4L, 3L, 4L, 3L, 2L, 4L, 1L, 3L, 1L,
2L, 2L, 3L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 3L, 3L, 3L, 4L, 3L, 2L,
3L, 2L, 3L, 2L, 3L, 1L, 1L, 1L, 4L, 1L, 4L, 4L, 3L, 3L, 3L, 2L,
4L, 2L, 4L, 3L, 4L, 2L, 2L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 2L,
3L, 1L, 4L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 4L,
2L, 2L, 3L, 2L, 1L, 1L, 3L, 2L, 2L, 1L, 3L, 4L, 1L, 1L, 4L, 1L,
3L, 3L, 3L, 3L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 3L, 4L, 4L, 2L, 3L,
2L, 2L, 3L, 4L, 3L, 1L, 1L, 1L, 1L, 3L, 1L, 2L, 3L, 2L, 3L, 2L,
2L, 4L, 2L, 4L, 4L, 1L, 1L, 1L, 3L, 1L, 1L, 4L, 4L, 1L, 1L, 4L,
4L), .Label = c("1", "2", "3", "4"), class = "factor"), cpz = c(0,
0, 0, 0, 200, 220, 262.5, 1200, 519.6, 450, 400, 0, 780, 0, 960,
750, 0, 450, 262.5, 0, 910, 0, 236.156156156156, 400, 1120, 300,
599.8, 820, 300, 89.5, 266.6, 200, 0, 262.5, 0, 0, 640, 0, 302.4,
600, 600, 0, 750, 200, 149.925037481259, 0, 100, 0, 0, 788.666666666667,
500, 560, 0, 300, 350, 0, 700, 600, 100, 0, 200, 0, 0, 0, 240,
0, 0, 520, 0, 0, 0, 286.666666666667, 160, 0, 320, 360, 720,
16, 0, 200, 680, 200, 50, 0, 900, 0, 150, 300, 400, 0, 0, 4714.2,
0, 0, 0, 100, 300, 0, 480, 600, 300, 0, 450, 450, 1000, 300,
899.850074962519, 0, 0, 0, 300, 0, 0, 0, 600, 0, 120, 1574.76,
400, 1200, 0, 1240, 10, 0, 450, 300, 0, 450, 0, 0, 0, 0, 0, 600,
300, 0, 600, 346.666666666667, 320, 1050, 0, 0, 450, 6000, 300,
400, 0, 1050, 300, 200, 300, 1050.24, 450, 450, 0, 0, 225, 400,
500, 0, 6000, 750, 0, 0, 300, 0, 2140, 300, 320, 400, 800,
766.666666666667,
0, 2960, 1200, 200, 640, 640, 198, 600, 600, 0, 600, 666.666666666667,
80, 150, 200, 0, 0, 0, 0, 299.850074962519, 0, 0, 200, 400, 600,
800, 0, 0, 1342.66666666667, 0, 0, 0, 0, 0, 640, 0, 0, 120, 280,
0, 0, 0, 200)), class = "data.frame", row.names = c(NA, -215L
))



-- 
Edward Patzelt, PhD

	[[alternative HTML version deleted]]


From d@v|d@w@nepoe| @end|ng |rom hotm@||@com  Tue Aug 24 21:57:14 2021
From: d@v|d@w@nepoe| @end|ng |rom hotm@||@com (David Swanepoel)
Date: Tue, 24 Aug 2021 19:57:14 +0000
Subject: [R] 
 Query regarding stats/p.adjust package (base) - specifically
 'Hochberg' function
In-Reply-To: <CAGxFJbRMbWKztE73KCWHVomwUKpeR3hjwOiwqFOwx-vgZnpJPA@mail.gmail.com>
References: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
 <CAGxFJbRMbWKztE73KCWHVomwUKpeR3hjwOiwqFOwx-vgZnpJPA@mail.gmail.com>
Message-ID: <AM6PR03MB36400584FF24A5C1F93DAD16C9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>

Dear Bert,

Thanks for your prompt response. I used R-help as it was listed as the contact point in the Description file of the stats package.

I'll attempt to find more information from stats.stackexchange.com as suggested and also see if I can figure out the sci.stat.consult and sci.stat.math Usenet groups that is mentioned in the guidance document too. Much appreciated.

Kind regards,
David

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: 24 August 2021 19:51
To: David Swanepoel <davidswanepoel at hotmail.com>
Cc: r-help at r-project.org; luke-tierney at uiowa.edu; Kurt.Hornik at wu.ac.at; t.kalibera at kent.ac.uk
Subject: Re: [R] Query regarding stats/p.adjust package (base) - specifically 'Hochberg' function

1. No Excel attachments made it through. Binary attachments are generally stripped by the list server for security reasons.

2. As you may have already learned, this is the wrong forum for statistics or package specific questions. Read *and follow* the posting guide linked below to post on r-help appropriately. In particular, for questions about specific non-standard packages, contact package maintainers (found through e.g. ?maintainers)

3. Statistics issues generally don't belong here. Try stats.stackexchange.com instead perhaps.

4. We are not *R Core development,*  and you probably should not be contacting them either.  See here for general guidelines for R lists:
https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.r-project.org%2Fmail.html&amp;data=04%7C01%7C%7Cba1cd94903054f3328d608d96727bcb1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637654242624008665%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=UgFMJoteTmcrGsYlA6w6mgMx8EhDsU9ndbBn5LeOFJ0%3D&amp;reserved=0


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 24, 2021 at 10:39 AM David Swanepoel <davidswanepoel at hotmail.com> wrote:
>
> Dear R Core Dev Team, I hope all is well your side!
> My apologies if this is not the correct point of contact to use to address this. If not, kindly advise or forward my request to the relevant team/persons.
>
> I have a query regarding the 'Hochberg' method of the stats/p.adjust R package and hope you can assist me please. I have attached the data I used in Excel, which are lists of p-values for two different tests (Hardy Weinberg Equilibrium and Linkage Disequilibrium) for four population groups.
>
> The basis of my concern is a discrepancy specifically between the Hochberg correction applied by four different R packages and the results of the Hochberg correction by the online tool, MultipleTesting.com<https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.multipletesting.com%2F&amp;data=04%7C01%7C%7Cba1cd94903054f3328d608d96727bcb1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637654242624018660%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=I6IKtam382hI1ONk%2BJIFiTyCzwThHhdet6fDoNZPOv8%3D&amp;reserved=0>.
>
> Using the below R packages/functions, I ran multiple test correction (MTC) adjustments for the p-values listed in my dataset. All R packages below agreed with each other regarding the 'significance' of the p-values for the Hochberg adjustment.
>
>
>   *   stats/p.adjust (method: Hochberg)
>   *   mutoss/hochberg
>   *   multtest/mt.rawp2adjp (procedure: Hochberg)
>   *   elitism/mtp (method: Hochberg)
>
> In checking the same values on the MultipleTesting.com, more p-values were flagged as significant for both the HWE and LD results across all four populations. I show these differences in the Excel sheet attached.
> Essentially, using the R packages, only the first HWE p-value of Pop2 is significant at an alpha of 0.05. Using the MT.com tool, however, multiple p-values are shown to be significant across both tests with the Hochberg correction (the highlighted cells in the Excel sheet).
>
>
> I asked the authors of MT.com about this, and they gave the following response:
>
> "we have checked the issue, and we believe the computation by our page is correct (I cannot give opinion about the other packages).
> When we look on the original Hochberg paper, and we only use the very first (smallest) p value, then m"=1, thus, according to the equation in the Hochberg 1988 paper, in this case practically there is no further correction necessary.
> In other words, in case the *smallest* p value is smaller than alpha, then the *smallest* p value will remain significant irrespective of the other p values when we make the Hochberg correction."
>
> I have attached the Hochberg paper here but, unfortunately, I don't understand enough of the stats to verify this. I have applied their logic on the same Excel sheet under the section "MT.com explanation", which shows why they consider the highlighted values significant.
>
> I have also attached the 2 R files that I used to do the MTC runs and they can be run as is. They are just quite long as they contain many of the other MTC methods in the different packages too.
>
> Kindly provide your thoughts as to whether you agree with this interpretation of the Hochberg paper or not? I would like to see concordance between the MT.com tool and the different R packages above (or understand why they are different), so that I can be more confident in the explanations of my own results as a stats layman.
>
> I hope this makes sense. Please let me know if I need to clarify anything.
>
>
> Many thanks and kind regards,
> David
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsta
> t.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7Cba1cd949
> 03054f3328d608d96727bcb1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C
> 637654242624018660%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjo
> iV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=PwZTKChLa2Mch
> cejeoBGOwyNBlJZvyjYUkz%2Bkpfi7Lk%3D&amp;reserved=0
> PLEASE do read the posting guide 
> https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.
> r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7Cba1cd94903054
> f3328d608d96727bcb1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C63765
> 4242624018660%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2lu
> MzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=YvD%2FzEuYQWy2PsG5
> EtV6K64l3RzToRDeUmIlgq5zgRM%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Aug 24 23:46:51 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 25 Aug 2021 09:46:51 +1200
Subject: [R] 
 Query regarding stats/p.adjust package (base) - specifically
 'Hochberg' function
In-Reply-To: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
References: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
Message-ID: <20210825094651.062e2b67@rolf-Latitude-E7470>


On Tue, 24 Aug 2021 14:44:55 +0000
David Swanepoel <davidswanepoel at hotmail.com> wrote:

> Dear R Core Dev Team, I hope all is well your side!
> My apologies if this is not the correct point of contact to use to
> address this. If not, kindly advise or forward my request to the
> relevant team/persons.
> 
> I have a query regarding the 'Hochberg' method of the stats/p.adjust
> R package and hope you can assist me please. I have attached the data
> I used in Excel,

<SNIP>

In addition to the good advice given to you earlier by Bert Gunter, you
should consider the following advice:

Don't use Excel!!!

This is a corollary of a more general theorem:   Don't use Micro$oft!!!

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 25 00:11:42 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 24 Aug 2021 15:11:42 -0700
Subject: [R] 
 Specifying non-linear mixed effects models in R (non-linear DV)
In-Reply-To: <CAB9UfhR8-Yq_0Ha2=vUvv_hMFTc4=Nr1CWmsN4mrDneA1EdrYw@mail.gmail.com>
References: <CAB9UfhR8-Yq_0Ha2=vUvv_hMFTc4=Nr1CWmsN4mrDneA1EdrYw@mail.gmail.com>
Message-ID: <CAGxFJbR+uCVm2=7+bVKdosmjkFfzt-nS-GhHBBQ1EVYj_CXgaA@mail.gmail.com>

Per the posting guide, statistics issues are generally off topic on this list:
"Questions about statistics: The R mailing lists are primarily
intended for questions and discussion about the R software. However,
questions about statistical methodology are sometimes posted. If the
question is well-asked and of interest to someone on the list, it may
elicit an informative up-to-date answer. See also the Usenet groups
sci.stat.consult (applied statistics and consulting) and sci.stat.math
(mathematical stat and probability)."

stats.stackexchange.com is also a possible venue for statistics questions.

Questions on mixed effects models -- including how to set them up
using nlme or lmer (in the lme4 package) -- are almost always better
posted on r-sig-mixed-models .

That said, the best advice may be to to find expert local help, as an
answer to your query may depend on questions of design,
interpretation, and use that are best explored in direct dialogue.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 24, 2021 at 2:23 PM Patzelt, Edward <patzelt at g.harvard.edu> wrote:
>
> Hi R-Help,
>
> Data is below. I used a Kruskal Wallis to compare across 4 study groups for
> my DV (beta - this is highly non-normal). Now I want to add a covariate
> (cpz).
>
> 1) What package do I use and how do I specify the model? (I tried T.aov
> from fANCOVA but received a lot of simpleLoess errors)
>
> 2) Can I specify "subject" as a random effect like in lme?
>
> structure(list(subject = c("C5B1001", "C5B1002", "C5B1003", "C5B1004",
> "C5B1005", "C5B1007", "C5B1008", "C5B1009", "C5B1010", "C5B1011",
> "C5B1012", "C5B1013", "C5B1014", "C5B1015", "C5B1016", "C5B1017",
> "C5B1018", "C5B1019", "C5B1020", "C5B1021", "C5B1022", "C5B1023",
> "C5B1024", "C5B1025", "C5B1026", "C5B1027", "C5B1029", "C5B1030",
> "C5B1031", "C5B1032", "C5B1033", "C5B1034", "C5B1035", "C5B1036",
> "C5B1037", "C5B1038", "C5B1039", "C5B1040", "C5B1041", "C5B1042",
> "C5B1043", "C5B1044", "C5B1045", "C5B1046", "C5B1047", "C5B1048",
> "C5B1049", "C5D2002", "C5D2003", "C5D2005", "C5D2006", "C5D2007",
> "C5D2009", "C5D2010", "C5D2011", "C5D2012", "C5D2013", "C5D2014",
> "C5D2017", "C5D2021", "C5D2022", "C5D2023", "C5D2024", "C5D2025",
> "C5D2026", "C5D2027", "C5D2028", "C5D2029", "C5D2030", "C5D2031",
> "C5D2032", "C5D2035", "C5D2036", "C5D2037", "C5D2039", "C5D2040",
> "C5D2042", "C5D2043", "C5D2044", "C5D2045", "C5D2046", "C5D2047",
> "C5D2048", "C5D2049", "C5D2051", "C5D2052", "C5D2053", "C5D2054",
> "C5D2055", "C5M3001", "C5M3003", "C5M3004", "C5M3005", "C5M3006",
> "C5M3007", "C5M3008", "C5M3009", "C5M3010", "C5M3011", "C5M3013",
> "C5M3014", "C5M3015", "C5M3016", "C5M3017", "C5M3019", "C5M3020",
> "C5M3021", "C5M3022", "C5M3023", "C5M3024", "C5M3029", "C5M3030",
> "C5M3031", "C5M3032", "C5M3033", "C5M3034", "C5M3035", "C5M3036",
> "C5M3038", "C5M3039", "C5M3042", "C5M3043", "C5M3044", "C5M3046",
> "C5M3047", "C5M3048", "C5M3049", "C5M3050", "C5M3051", "C5M3054",
> "C5M3055", "C5M3056", "C5M3057", "C5M3058", "C5R4001", "C5R4004",
> "C5R4005", "C5R4008", "C5R4009", "C5R4010", "C5R4011", "C5R4012",
> "C5R4013", "C5R4014", "C5R4015", "C5R4016", "C5R4017", "C5R4019",
> "C5R4020", "C5R4021", "C5R4022", "C5R4024", "C5R4025", "C5R4026",
> "C5R4027", "C5R4028", "C5R4031", "C5R4032", "C5R4034", "C5R4037",
> "C5R4038", "C5R4040", "C5R4041", "C5R4043", "C5R4048", "C5R4050",
> "C5R4053", "C5R4056", "C5W5001", "C5W5002", "C5W5003", "C5W5004",
> "C5W5005", "C5W5006", "C5W5007", "C5W5008", "C5W5012", "C5W5013",
> "C5W5014", "C5W5015", "C5W5016", "C5W5017", "C5W5018", "C5W5019",
> "C5W5020", "C5W5021", "C5W5022", "C5W5023", "C5W5024", "C5W5025",
> "C5W5028", "C5W5029", "C5W5030", "C5W5031", "C5W5033", "C5W5035",
> "C5W5037", "C5W5038", "C5W5039", "C5W5042", "C5W5043", "C5W5044",
> "C5W5045", "C5W5046", "C5W5047", "C5W5048", "C5W5049", "C5W5050",
> "C5W5051", "C5W5053", "C5W5054", "C5W5055", "C5W5057", "C5W5058",
> "C5W5060"), beta = c(5, 5, 5, 4.84951578282477, 5, 1.75435411010482,
> 2.59653537897755, 4.58343041388045, 1.19813289503568, 5, 4.41030503473763,
> 3.48886522319213, 5, 3.69347465973804, 5, 3.61341511433856, 5,
> 5, 5, 5, 2.82540030433712, 5, 2.01269174411245, 5, 5, 5, 5,
> 3.66605514409922,
> 5, 5, 1.20492768779028, 5, 5, 5, 5, 4.71051510737403, 0.973607667104191,
> 2.13320899798223, 3.55527726960037, 5, 3.13840519694586, 5,
> 4.33164972914231,
> 3.2716034981509, 5, 3.59865983897491, 5, 5, 2.98982117172486,
> 3.15884653708899, 5, 1.21006283114433, 1.88594293315325, 2.37248899411035,
> 2.40289344741545, 0.262839947401338, 2.89061041570249, 2.98573373614306,
> 2.82385009686039, 1.78295361666595, 4.27268021897288, 5, 5, 5,
> 2.52131830224533, 5, 2.32463450150955, 5, 5, 2.18297518836912,
> 5, 2.53256388646574, 5, 5, 5, 1.11901989122708, 1.56266936421015,
> 5, 2.1480772866684, 1.03201411339444, 3.22476904165877, 5,
> 2.23963439946338,
> 5, 3.85477002456212, 5, 5, 3.15602152904957, 4.81306354520538,
> 1.20566795082516, 5, 5, 5, 5, 3.04288106123443, 5, 4.06490230904187,
> 3.06547070051755, 5, 2.5258266208828, 3.52552152448218, 0.0968896467078101,
> 5, 5, 5, 5, 5, 5, 5, 4.99152057373263, 5, 5, 5, 1.1311501363613,
> 1.28951722667904, 0.001, 5, 4.58718394461838, 1.22231984982818,
> 5, 5, 3.35873683772968, 5, 3.87156907439221, 4.8859664986002,
> 5, 5, 0.976932521703834, 5, 4.50479324287729, 4.65093425894735,
> 4.22173593981599, 3.15590632469025, 4.86144574792365, 3.39926845337078,
> 1.24825519695535, 5, 3.27167737085564, 2.2107731064995, 0.187339326704238,
> 5, 5, 2.78773672362584, 0.977242332964066, 1.05162966383033,
> 4.24031503174416, 1.9558880208883, 4.01331863994726, 5, 5,
> 4.50553723427244,
> 4.03830955873134, 0.0731678404955063, 0.326005643499137, 1.48169477386196,
> 5, 5, 2.1217771592687, 1.55381162571676, 5, 0.388739153131157,
> 5, 5, 1.22549904356884, 4.30605773910623, 5, 5, 3.90617032103214,
> 0.884096418271427, 1.7166358084411, 4.26908188373059, 1.97226101693004,
> 5, 0.831616239014777, 0.001, 4.15065454327444, 5, 5, 2.6582186770924,
> 4.69752970800906, 4.50106281557844, 4.21353152726281, 5, 0.620184007188853,
> 5, 3.86897558241413, 3.63483407688021, 3.18900423687508, 1.24002620770954,
> 5, 5, 5, 5, 5, 1.20112016323594, 1.99534703415304, 5, 2.13269987318149,
> 3.76529884137316, 2.88523566628984, 1.93828880175044, 5, 1.04561250178734,
> 3.74875347444577, 5, 5, 2.48460418075441, 5, 4.55602711347155,
> 3.97926864514993, 3.59636722716411, 5, 2.95039073432615, 4.82668935707021,
> 3.70517802450053), group = structure(c(1L, 1L, 1L, 1L, 2L, 3L,
> 3L, 2L, 3L, 2L, 3L, 4L, 4L, 4L, 2L, 2L, 1L, 3L, 3L, 1L, 3L, 1L,
> 3L, 2L, 3L, 3L, 3L, 2L, 4L, 2L, 3L, 4L, 1L, 2L, 1L, 1L, 2L, 1L,
> 2L, 4L, 2L, 1L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 3L, 2L, 4L, 4L, 4L,
> 2L, 2L, 2L, 2L, 2L, 4L, 4L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 4L, 3L,
> 1L, 4L, 2L, 4L, 3L, 4L, 3L, 4L, 3L, 4L, 3L, 2L, 4L, 1L, 3L, 1L,
> 2L, 2L, 3L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 3L, 3L, 3L, 4L, 3L, 2L,
> 3L, 2L, 3L, 2L, 3L, 1L, 1L, 1L, 4L, 1L, 4L, 4L, 3L, 3L, 3L, 2L,
> 4L, 2L, 4L, 3L, 4L, 2L, 2L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 2L,
> 3L, 1L, 4L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 4L,
> 2L, 2L, 3L, 2L, 1L, 1L, 3L, 2L, 2L, 1L, 3L, 4L, 1L, 1L, 4L, 1L,
> 3L, 3L, 3L, 3L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 3L, 4L, 4L, 2L, 3L,
> 2L, 2L, 3L, 4L, 3L, 1L, 1L, 1L, 1L, 3L, 1L, 2L, 3L, 2L, 3L, 2L,
> 2L, 4L, 2L, 4L, 4L, 1L, 1L, 1L, 3L, 1L, 1L, 4L, 4L, 1L, 1L, 4L,
> 4L), .Label = c("1", "2", "3", "4"), class = "factor"), cpz = c(0,
> 0, 0, 0, 200, 220, 262.5, 1200, 519.6, 450, 400, 0, 780, 0, 960,
> 750, 0, 450, 262.5, 0, 910, 0, 236.156156156156, 400, 1120, 300,
> 599.8, 820, 300, 89.5, 266.6, 200, 0, 262.5, 0, 0, 640, 0, 302.4,
> 600, 600, 0, 750, 200, 149.925037481259, 0, 100, 0, 0, 788.666666666667,
> 500, 560, 0, 300, 350, 0, 700, 600, 100, 0, 200, 0, 0, 0, 240,
> 0, 0, 520, 0, 0, 0, 286.666666666667, 160, 0, 320, 360, 720,
> 16, 0, 200, 680, 200, 50, 0, 900, 0, 150, 300, 400, 0, 0, 4714.2,
> 0, 0, 0, 100, 300, 0, 480, 600, 300, 0, 450, 450, 1000, 300,
> 899.850074962519, 0, 0, 0, 300, 0, 0, 0, 600, 0, 120, 1574.76,
> 400, 1200, 0, 1240, 10, 0, 450, 300, 0, 450, 0, 0, 0, 0, 0, 600,
> 300, 0, 600, 346.666666666667, 320, 1050, 0, 0, 450, 6000, 300,
> 400, 0, 1050, 300, 200, 300, 1050.24, 450, 450, 0, 0, 225, 400,
> 500, 0, 6000, 750, 0, 0, 300, 0, 2140, 300, 320, 400, 800,
> 766.666666666667,
> 0, 2960, 1200, 200, 640, 640, 198, 600, 600, 0, 600, 666.666666666667,
> 80, 150, 200, 0, 0, 0, 0, 299.850074962519, 0, 0, 200, 400, 600,
> 800, 0, 0, 1342.66666666667, 0, 0, 0, 0, 0, 640, 0, 0, 120, 280,
> 0, 0, 0, 200)), class = "data.frame", row.names = c(NA, -215L
> ))
>
>
>
> --
> Edward Patzelt, PhD
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 25 00:16:36 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 24 Aug 2021 15:16:36 -0700
Subject: [R] unable to install source packages with Rtools installed
In-Reply-To: <CABAL1U4pKqKegsZPmCY-4jaHqdAO1XV27a1z8kdfGz1si1jKbA@mail.gmail.com>
References: <CABAL1U4pKqKegsZPmCY-4jaHqdAO1XV27a1z8kdfGz1si1jKbA@mail.gmail.com>
Message-ID: <CAGxFJbQur-acDZbJJkUn7hZJw78bTejwtovCEKiXrOxLgANUhg@mail.gmail.com>

1. Why not installed a pre-built binary for Windows? (No need to reply
... Just saying.)

2. You should post the results of sessionInfo() to better enable
others to help you.
Also post any error or diagnostic messages you received.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 24, 2021 at 2:23 PM Xiaoyu Zeng <xiaoyuzengpsy at gmail.com> wrote:
>
> Hi all.
>
> I installed the latest R and Rtools, and I followed the guidelines to test
> the installation of Rtools (rtools40v2-x86_64.exe for windows10). I
> verified that *make* can be found, but I still could not install an R
> package from the source.
>
> Any ideas?
>
> *More detailed info:*
> https://github.com/r-windows/rtools-packages/issues/222
>
> Best regards,
> Xiaoyu
>
> Xiaoyu Zeng
>
> Graduate student, Social and Affective NeuroPharmacology (SANP) Lab
>
> State Key Laboratory of Cognitive Neuroscience and Learning
>
> Beijing Normal University
>
> http://brain.bnu.edu.cn/home/yinama/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Wed Aug 25 00:21:08 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 24 Aug 2021 22:21:08 +0000 (UTC)
Subject: [R] Help needed with getting a decent image of ggplot2 graph
References: <324038213.311154.1629843668905.ref@mail.yahoo.com>
Message-ID: <324038213.311154.1629843668905@mail.yahoo.com>

Hello, I made the following graph in R with the following code.
ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? scale_y_continuous(limits=c(0, 1.4*ymax))+? labs(x= 'Year', y = 'Percentage', title = 'Men and Women')



However, on using the following code -?tiff("test.tiff", units = "px", width = 440, height = 250, res = 300)ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? scale_y_continuous(limits=c(0, 1.4*ymax))+? labs(x= 'Year', y = 'Percentage', title = 'Men and Women')dev.off()


I get the following image -?



I need to keep the DPI = 300 and Width = 440 fixed. I can only manipulate height. Any help would be appreciated
Thank you
?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1629843563534blob.jpg
Type: image/png
Size: 34899 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210824/a35847e1/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1629843619873blob.jpg
Type: image/png
Size: 18367 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210824/a35847e1/attachment-0001.png>

From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Wed Aug 25 00:42:28 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 24 Aug 2021 22:42:28 +0000 (UTC)
Subject: [R] Help needed with getting a decent image of ggplot2 graph
In-Reply-To: <CA+8X3fUThuMQa+YEtUnaA+pkY1sQrxrPEV_TX_S_W0s_GyEx_w@mail.gmail.com>
References: <324038213.311154.1629843668905.ref@mail.yahoo.com>
 <324038213.311154.1629843668905@mail.yahoo.com>
 <CA+8X3fUThuMQa+YEtUnaA+pkY1sQrxrPEV_TX_S_W0s_GyEx_w@mail.gmail.com>
Message-ID: <621897339.317567.1629844948273@mail.yahoo.com>

 I am able to change but the place where I have to submit a similar graph has kept a fixed upper limit of 440 pixels for the width and an upper limit of 300 for the dpi.
    On Tuesday, 24 August, 2021, 06:36:16 pm GMT-4, Jim Lemon <drjimlemon at gmail.com> wrote:  
 
 Hi bharat,
I think there is a conflict between your image size and resolution.
You need a lot larger height and width in pixels to get 300 dpi
resolution for the whole plot.

 tiff("test.tiff", units = "px", width = 2200, height = 1250, res = 300)

would probably do it for you. How come you can't change the width and
height in pixels?

Jim

On Wed, Aug 25, 2021 at 8:22 AM bharat rawlley via R-help
<r-help at r-project.org> wrote:
>
> Hello, I made the following graph in R with the following code.
> ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? scale_y_continuous(limits=c(0, 1.4*ymax))+? labs(x= 'Year', y = 'Percentage', title = 'Men and Women')
>
>
>
> However, on using the following code - tiff("test.tiff", units = "px", width = 440, height = 250, res = 300)ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? scale_y_continuous(limits=c(0, 1.4*ymax))+? labs(x= 'Year', y = 'Percentage', title = 'Men and Women')dev.off()
>
>
> I get the following image -
>
>
>
> I need to keep the DPI = 300 and Width = 440 fixed. I can only manipulate height. Any help would be appreciated
> Thank you
>? ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 25 00:36:03 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Aug 2021 08:36:03 +1000
Subject: [R] Help needed with getting a decent image of ggplot2 graph
In-Reply-To: <324038213.311154.1629843668905@mail.yahoo.com>
References: <324038213.311154.1629843668905.ref@mail.yahoo.com>
 <324038213.311154.1629843668905@mail.yahoo.com>
Message-ID: <CA+8X3fUThuMQa+YEtUnaA+pkY1sQrxrPEV_TX_S_W0s_GyEx_w@mail.gmail.com>

Hi bharat,
I think there is a conflict between your image size and resolution.
You need a lot larger height and width in pixels to get 300 dpi
resolution for the whole plot.

 tiff("test.tiff", units = "px", width = 2200, height = 1250, res = 300)

would probably do it for you. How come you can't change the width and
height in pixels?

Jim

On Wed, Aug 25, 2021 at 8:22 AM bharat rawlley via R-help
<r-help at r-project.org> wrote:
>
> Hello, I made the following graph in R with the following code.
> ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  scale_y_continuous(limits=c(0, 1.4*ymax))+  labs(x= 'Year', y = 'Percentage', title = 'Men and Women')
>
>
>
> However, on using the following code - tiff("test.tiff", units = "px", width = 440, height = 250, res = 300)ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  scale_y_continuous(limits=c(0, 1.4*ymax))+  labs(x= 'Year', y = 'Percentage', title = 'Men and Women')dev.off()
>
>
> I get the following image -
>
>
>
> I need to keep the DPI = 300 and Width = 440 fixed. I can only manipulate height. Any help would be appreciated
> Thank you
>  ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 25 00:50:45 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Aug 2021 08:50:45 +1000
Subject: [R] 
 Query regarding stats/p.adjust package (base) - specifically
 'Hochberg' function
In-Reply-To: <20210825094651.062e2b67@rolf-Latitude-E7470>
References: <AM6PR03MB364053F485BB95E86264E0FAC9C59@AM6PR03MB3640.eurprd03.prod.outlook.com>
 <20210825094651.062e2b67@rolf-Latitude-E7470>
Message-ID: <CA+8X3fV6aLj=sPs64hTHkPdNa87NwBv+vvmMdr7Nv26sP_EvjQ@mail.gmail.com>

This is beginning to sound like a stats taliban fatwa. I don't care if
you're using an abacus, you want to get the correct result. My guess
is that the different instantiations of the Hochberg adjustment are
using different algorithms to calculate the result. The Hochberg
adjustment is known to be sensitive to the distributions of the test
statistics. People who are more expert than I in this area have
different ideas about how to handle this problem. This probably
contributes to the hopefully small differences in the eventual
corrected p-values.

Jim

On Wed, Aug 25, 2021 at 8:02 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On Tue, 24 Aug 2021 14:44:55 +0000
> David Swanepoel <davidswanepoel at hotmail.com> wrote:
>
> > Dear R Core Dev Team, I hope all is well your side!
> > My apologies if this is not the correct point of contact to use to
> > address this. If not, kindly advise or forward my request to the
> > relevant team/persons.
> >
> > I have a query regarding the 'Hochberg' method of the stats/p.adjust
> > R package and hope you can assist me please. I have attached the data
> > I used in Excel,
>
> <SNIP>
>
> In addition to the good advice given to you earlier by Bert Gunter, you
> should consider the following advice:
>
> Don't use Excel!!!
>
> This is a corollary of a more general theorem:   Don't use Micro$oft!!!
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 25 00:54:11 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Aug 2021 08:54:11 +1000
Subject: [R] Help needed with getting a decent image of ggplot2 graph
In-Reply-To: <621897339.317567.1629844948273@mail.yahoo.com>
References: <324038213.311154.1629843668905.ref@mail.yahoo.com>
 <324038213.311154.1629843668905@mail.yahoo.com>
 <CA+8X3fUThuMQa+YEtUnaA+pkY1sQrxrPEV_TX_S_W0s_GyEx_w@mail.gmail.com>
 <621897339.317567.1629844948273@mail.yahoo.com>
Message-ID: <CA+8X3fVLqG2owEN2zS1MBgHr41Nkocp5X7v8RNVXp2_hQA2Asw@mail.gmail.com>

Ah, an _upper_ limit. Why not let tiff() work out the resolution
(res=NA - the default) and see if that passes muster.

Jim

On Wed, Aug 25, 2021 at 8:42 AM bharat rawlley <bharat_m_all at yahoo.co.in> wrote:
>
> I am able to change but the place where I have to submit a similar graph has kept a fixed upper limit of 440 pixels for the width and an upper limit of 300 for the dpi.
>
> On Tuesday, 24 August, 2021, 06:36:16 pm GMT-4, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
> Hi bharat,
> I think there is a conflict between your image size and resolution.
> You need a lot larger height and width in pixels to get 300 dpi
> resolution for the whole plot.
>
> tiff("test.tiff", units = "px", width = 2200, height = 1250, res = 300)
>
> would probably do it for you. How come you can't change the width and
> height in pixels?
>
> Jim
>
> On Wed, Aug 25, 2021 at 8:22 AM bharat rawlley via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello, I made the following graph in R with the following code.
> > ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  scale_y_continuous(limits=c(0, 1.4*ymax))+  labs(x= 'Year', y = 'Percentage', title = 'Men and Women')
> >
> >
> >
> > However, on using the following code - tiff("test.tiff", units = "px", width = 440, height = 250, res = 300)ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  scale_y_continuous(limits=c(0, 1.4*ymax))+  labs(x= 'Year', y = 'Percentage', title = 'Men and Women')dev.off()
> >
> >
> > I get the following image -
> >
> >
> >
> > I need to keep the DPI = 300 and Width = 440 fixed. I can only manipulate height. Any help would be appreciated
> > Thank you
>
> >  ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Wed Aug 25 02:00:27 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Wed, 25 Aug 2021 00:00:27 +0000 (UTC)
Subject: [R] Help needed with getting a decent image of ggplot2 graph
In-Reply-To: <CA+8X3fVLqG2owEN2zS1MBgHr41Nkocp5X7v8RNVXp2_hQA2Asw@mail.gmail.com>
References: <324038213.311154.1629843668905.ref@mail.yahoo.com>
 <324038213.311154.1629843668905@mail.yahoo.com>
 <CA+8X3fUThuMQa+YEtUnaA+pkY1sQrxrPEV_TX_S_W0s_GyEx_w@mail.gmail.com>
 <621897339.317567.1629844948273@mail.yahoo.com>
 <CA+8X3fVLqG2owEN2zS1MBgHr41Nkocp5X7v8RNVXp2_hQA2Asw@mail.gmail.com>
Message-ID: <1559591659.319235.1629849627465@mail.yahoo.com>

I tried doing that.?
So the real title of my graph is much longer than men and women and isn't not being incorporated in that width.?
I think I'll have to settle for a smaller title?

Sent from Yahoo Mail on Android 
 
  On Tue, 24 Aug 2021 at 6:54 PM, Jim Lemon<drjimlemon at gmail.com> wrote:   Ah, an _upper_ limit. Why not let tiff() work out the resolution
(res=NA - the default) and see if that passes muster.

Jim

On Wed, Aug 25, 2021 at 8:42 AM bharat rawlley <bharat_m_all at yahoo.co.in> wrote:
>
> I am able to change but the place where I have to submit a similar graph has kept a fixed upper limit of 440 pixels for the width and an upper limit of 300 for the dpi.
>
> On Tuesday, 24 August, 2021, 06:36:16 pm GMT-4, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
> Hi bharat,
> I think there is a conflict between your image size and resolution.
> You need a lot larger height and width in pixels to get 300 dpi
> resolution for the whole plot.
>
> tiff("test.tiff", units = "px", width = 2200, height = 1250, res = 300)
>
> would probably do it for you. How come you can't change the width and
> height in pixels?
>
> Jim
>
> On Wed, Aug 25, 2021 at 8:22 AM bharat rawlley via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello, I made the following graph in R with the following code.
> > ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? scale_y_continuous(limits=c(0, 1.4*ymax))+? labs(x= 'Year', y = 'Percentage', title = 'Men and Women')
> >
> >
> >
> > However, on using the following code - tiff("test.tiff", units = "px", width = 440, height = 250, res = 300)ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+? geom_bar(position = 'dodge', stat='identity')+? theme_classic()+? scale_y_continuous(limits=c(0, 1.4*ymax))+? labs(x= 'Year', y = 'Percentage', title = 'Men and Women')dev.off()
> >
> >
> > I get the following image -
> >
> >
> >
> > I need to keep the DPI = 300 and Width = 440 fixed. I can only manipulate height. Any help would be appreciated
> > Thank you
>
> >? ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
  

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 25 07:56:08 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Aug 2021 15:56:08 +1000
Subject: [R] unable to install source packages with Rtools installed
In-Reply-To: <CABAL1U4=1xo7gkZ=nAArMH07ykTfDmmsDeqCroc3c+4icfjdyQ@mail.gmail.com>
References: <CABAL1U4pKqKegsZPmCY-4jaHqdAO1XV27a1z8kdfGz1si1jKbA@mail.gmail.com>
 <CA+8X3fXAGr++9dwJ5tTf9Nwhy7=6pYnGvaNrMpQtaqEnDqA7sA@mail.gmail.com>
 <CABAL1U4=1xo7gkZ=nAArMH07ykTfDmmsDeqCroc3c+4icfjdyQ@mail.gmail.com>
Message-ID: <CA+8X3fVFQStx=-B2hOhR24A8Dbew6KRSs1n1nyrd5_Wf2uq2_A@mail.gmail.com>

Hi Xiaoyu,
"non-zero exit status" is just a fancy way of saying something went
wrong. An old computing convention is for a function to return zero
(FALSE) for success or some positive integer that tells you what the
error was. In general, when you have a sequence of interdependent
functions or programs, if one goes wrong, all subsequent ones usually
do, too.

Jim

On Wed, Aug 25, 2021 at 11:16 AM Xiaoyu Zeng <xiaoyuzengpsy at gmail.com> wrote:
>
> Thanks for replying, Jim and Bert.
>
> I installed proxy and reinstalled jsonlite, but it failed again. I even tried setting ''dependencies = TRUE", and it turned out with the same error "had non-zero exit status". Session info and error information were enclosed.
>
> I need to ensure Rtool work and I can install package from source as I need to install a package from Github. But I had no clue about the error "had non-zero exit status". Any ideas?
>
> Best regards,
> Xiaoyu
>
> Error info:
> install.packages("jsonlite", type = "source",dependencies = TRUE)
> ????????e1071?, ?wk?, ?tinytex?, ?R.cache?, ?classInt?, ?DBI?, ?s2?, ?units?, ?rmarkdown?, ?R.rsp?, ?sf?
>
> trying URL 'https://cran.rstudio.com/src/contrib/e1071_1.7-8.tar.gz'
> Content type 'application/x-gzip' length 581347 bytes (567 KB)
> downloaded 567 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/wk_0.5.0.tar.gz'
> Content type 'application/x-gzip' length 138686 bytes (135 KB)
> downloaded 135 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/tinytex_0.33.tar.gz'
> Content type 'application/x-gzip' length 30085 bytes (29 KB)
> downloaded 29 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/R.cache_0.15.0.tar.gz'
> Content type 'application/x-gzip' length 34692 bytes (33 KB)
> downloaded 33 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/classInt_0.4-3.tar.gz'
> Content type 'application/x-gzip' length 403884 bytes (394 KB)
> downloaded 394 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/DBI_1.1.1.tar.gz'
> Content type 'application/x-gzip' length 743802 bytes (726 KB)
> downloaded 726 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/s2_1.0.6.tar.gz'
> Content type 'application/x-gzip' length 1605788 bytes (1.5 MB)
> downloaded 1.5 MB
>
> trying URL 'https://cran.rstudio.com/src/contrib/units_0.7-2.tar.gz'
> Content type 'application/x-gzip' length 855840 bytes (835 KB)
> downloaded 835 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/rmarkdown_2.10.tar.gz'
> Content type 'application/x-gzip' length 3248794 bytes (3.1 MB)
> downloaded 3.1 MB
>
> trying URL 'https://cran.rstudio.com/src/contrib/R.rsp_0.44.0.tar.gz'
> Content type 'application/x-gzip' length 823684 bytes (804 KB)
> downloaded 804 KB
>
> trying URL 'https://cran.rstudio.com/src/contrib/sf_1.0-2.tar.gz'
> Content type 'application/x-gzip' length 3645982 bytes (3.5 MB)
> downloaded 3.5 MB
>
> trying URL 'https://cran.rstudio.com/src/contrib/jsonlite_1.7.2.tar.gz'
> Content type 'application/x-gzip' length 421716 bytes (411 KB)
> downloaded 411 KB
>
> Warning in install.packages :
>   installation of package ?e1071? had non-zero exit status
> Warning in install.packages :
>   installation of package ?wk? had non-zero exit status
> Warning in install.packages :
>   installation of package ?tinytex? had non-zero exit status
> Warning in install.packages :
>   installation of package ?R.cache? had non-zero exit status
> Warning in install.packages :
>   installation of package ?DBI? had non-zero exit status
> Warning in install.packages :
>   installation of package ?units? had non-zero exit status
> Warning in install.packages :
>   installation of package ?jsonlite? had non-zero exit status
> Warning in install.packages :
>   installation of package ?classInt? had non-zero exit status
> Warning in install.packages :
>   installation of package ?s2? had non-zero exit status
> Warning in install.packages :
>   installation of package ?rmarkdown? had non-zero exit status
> Warning in install.packages :
>   installation of package ?R.rsp? had non-zero exit status
> Warning in install.packages :
>   installation of package ?sf? had non-zero exit status
>
> The downloaded source packages are in
> ?C:\Users\xiaoy\AppData\Local\Temp\RtmpoPSf4N\downloaded_packages?
>
> Session info:
> > sessionInfo()
> R version 4.1.1 (2021-08-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Chinese (Simplified)_China.936  LC_CTYPE=Chinese (Simplified)_China.936
> [3] LC_MONETARY=Chinese (Simplified)_China.936 LC_NUMERIC=C
> [5] LC_TIME=Chinese (Simplified)_China.936
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.1.1 tools_4.1.1
>
>
> Xiaoyu Zeng
>
> Graduate student, Social and Affective NeuroPharmacology (SANP) Lab
>
> State Key Laboratory of Cognitive Neuroscience and Learning
>
> Beijing Normal University
>
> http://brain.bnu.edu.cn/home/yinama/
>
>
>
> Jim Lemon <drjimlemon at gmail.com> ?2021?8?25??? ??7:09???
>>
>> Hi Xiaoyu,
>> From your github posting, it seems that the "proxy" package failed for
>> some reason. As the following packages probably depend upon "proxy",
>> installation for them will usually fail, too. Maybe "proxy" or some of
>> the other packages aren't source but require compiling? Have you tried
>> install.packages()? I see that "proxy" is available on CRAN.
>>
>> Jim
>>
>> On Wed, Aug 25, 2021 at 7:24 AM Xiaoyu Zeng <xiaoyuzengpsy at gmail.com> wrote:
>> >
>> > Hi all.
>> >
>> > I installed the latest R and Rtools, and I followed the guidelines to test
>> > the installation of Rtools (rtools40v2-x86_64.exe for windows10). I
>> > verified that *make* can be found, but I still could not install an R
>> > package from the source.
>> >
>> > Any ideas?
>> >
>> > *More detailed info:*
>> > https://github.com/r-windows/rtools-packages/issues/222
>> >
>> > Best regards,
>> > Xiaoyu
>> >
>> > Xiaoyu Zeng
>> >
>> > Graduate student, Social and Affective NeuroPharmacology (SANP) Lab
>> >
>> > State Key Laboratory of Cognitive Neuroscience and Learning
>> >
>> > Beijing Normal University
>> >
>> > http://brain.bnu.edu.cn/home/yinama/
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 25 08:12:35 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Aug 2021 16:12:35 +1000
Subject: [R] Selecting elements
In-Reply-To: <0db77aa4a7a74611ad833311cc9ef880@SRVEXCHCM1302.precheza.cz>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
 <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WBKonNK47bCL3W3p-RmmhKw_Lw7oqHyHCzqTTBWdX=fSA@mail.gmail.com>
 <0db77aa4a7a74611ad833311cc9ef880@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fW4BN1xsh87jd62rDBB40X9x7e2MerMnp22Q8X6FPco9w@mail.gmail.com>

Hi Silvano,
I was completely stumped by your problem until I looked through Petr's
response and guessed that you wanted the largest sum of 'Var.1"
constrained by the specified numbers in your three schemes. I think
this is what you want, but I haven't checked it exhaustively.

set.seed(123)
Var.1 <- rep(LETTERS[1:4], 10)
Var.2 <- sample(1:40, replace=FALSE)
data <- data.frame(Var.1, Var.2)
(Order <- data[order(data$Var.2, decreasing=TRUE), ])
allowed<-matrix(c(3,3,2,2,2,5,0,3,3,4,2,1),nrow=3,byrow=TRUE)
colnames(allowed)<-LETTERS[1:4]
select_largest<-function(x,allowed,n=10) {
 totals<-rep(0,nrow(allowed))
 indices<-matrix(0,ncol=n,nrow=nrow(allowed))
 for(i in 1:nrow(allowed)) {
  ii<-1
  for(j in 1:ncol(allowed)) {
   if(allowed[i,j]) {
    indx<-which(x[,1] == colnames(allowed)[j])
    totals[i]<-totals[i]+sum(x[indx[1:allowed[i,j]],2])
    indices[i,ii:(ii+allowed[i,j]-1)]<-indx[1:allowed[i,j]]
    ii<-ii+allowed[i,j]
   }
  }
 }
 largest<-which.max(totals)
 return(list(scheme=largest,total=totals[largest],
  indices=sort(indices[largest,])))
}
select_largest(Order,allowed)

Jim

On Tue, Aug 24, 2021 at 7:11 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi.
>
> Now it is understandable.  However the solution is not clear for me.
>
> table(Order$Var.1[1:10])
> A B C D
> 4 1 2 3
>
> should give you a hint which scheme could be acceptable, but how to do it programmatically I do not know.
>
> maybe to start with lower value in the table call and gradually increse it to check which scheme starts to be the chosen one
>
> > table(data.o$Var.1[1]) # scheme 2 is out
> C
> 1
> ...
> > table(data.o$Var.1[1:5]) #scheme 3
> A B C D
> 1 1 2 1
>
> > table(data.o$Var.1[1:6]) #scheme 3
>
> A B C D
> 2 1 2 1
>
> > table(data.o$Var.1[1:7]) # scheme1
> A B C D
> 2 1 2 2
>
> > table(data.o$Var.1[1:8]) # no such scheme, so scheme 1 is chosen one
> A B C D
> 2 1 2 3
>
> #Now you need to select values based on scheme 1.
> # 3A - 3B - 2C - 2D
>
> sss <- split(Order, Order$Var.1)
> selection <- c(3,3,2,2)
> result <- vector("list", 4)
>
> #I would use loop
>
> for(i in 1:4) {
> result[[i]] <- sss[[i]][1:selection[i],]
> }
>
> Maybe someone come with other ingenious solution.
>
> Cheers
> Petr
>
> From: Silvano Cesar da Costa <silvano at uel.br>
> Sent: Monday, August 23, 2021 7:54 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Re: [R] Selecting elements
>
> Hi,
>
> I apologize for the confusion. I will try to be clearer in my explanation. I believe that with the R script it becomes clearer.
>
> I have 4 variables with 10 repetitions and each one receives a value, randomly.
> I order the dataset from largest to smallest value. I have to select 10 elements in
> descending order of values, according to one of three schemes:
>
> # 3A - 3B - 2C - 2D
> # 2A - 5B - 0C - 3D
> # 3A - 4B - 2C - 1D
>
> If the first 3 elements (out of the 10 to be selected) are of the letter D, automatically
> the adopted scheme will be the second. So, I have to (following) choose 2A, 5B and 0C.
> How to make the selection automatically?
>
> I created two selection examples, with different schemes:
>
>
>
> set.seed(123)
>
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
>
> data = data.frame(Var.1, Var.2)
>
> (Order = data[order(data$Var.2, decreasing=TRUE), ])
>
> # I must select the 10 highest values (),
> # but which follow a certain scheme:
> #
> #  3A - 3B - 2C - 2D     or
> #  2A - 5B - 0C - 3D     or
> #  3A - 4B - 2C - 1D
> #
> # In this case, I started with the highest value that refers to the letter C.
> # Next comes only 1 of the letters B, A and D. All are selected once.
> # The fifth observation is the letter C, completing 2 C values. In this case,
> # following the 3 adopted schemes, note that the second scheme has 0C,
> # so this scheme is out.
> # Therefore, it can be the first scheme (3A - 3B - 2C - 2D) or the
> # third scheme (3A - 4B - 2C - 1D).
> # The next letter to be completed is the D (fourth and seventh elements),
> # among the 10 elements being selected. Therefore, the scheme adopted is the
> # first one (3A - 3B - 2C - 2D).
> # Therefore, it is necessary to select 2 values with the letter B and 1 value
> # with the letter A.
> #
> # Manual Selection -
> # The end result is:
> (Selected.data = Order[c(1,2,3,4,5,6,7,9,13,16), ])
>
> # Scheme: 3A - 3B - 2C - 2D
> sort(Selected.data$Var.1)
>
>
> #------------------
> # Second example: -
> #------------------
> set.seed(4)
>
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
>
> data = data.frame(Var.1, Var.2)
> (Order = data[order(data$Var.2, decreasing=TRUE), ])
>
> # The end result is:
> (Selected.data.2 = Order[c(1,2,3,4,5,6,7,8,9,11), ])
>
> # Scheme: 3A - 4B - 2C - 1D
> sort(Selected.data.2$Var.1)
>
> How to make the selection of the 10 elements automatically?
>
> Thank you very much.
>
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
>
> Fone: (43) 3371-4346
>
>
> Em seg., 23 de ago. de 2021 ?s 05:05, PIKAL Petr <mailto:petr.pikal at precheza.cz> escreveu:
> Hi
>
> Only I got your HTML formated mail, rest of the world got complete mess. Do not use HTML formating.
>
> As I got it right I wonder why in your second example you did not follow
> 3A - 3B - 2C - 2D
>
> as D were positioned 1st and 4th.
>
> I hope that you could use something like
>
> sss <- split(data$Var.2, data$Var.1)
> lapply(sss, cumsum)
> $A
>  [1]  38  73 105 136 166 188 199 207 209 210
>
> $B
>  [1]  39  67  92 115 131 146 153 159 164 168
>
> $C
>  [1]  40  76 105 131 152 171 189 203 213 222
>
> $D
>  [1]  37  71 104 131 155 175 192 205 217 220
>
> Now you need to evaluate this result according to your sets. Here the highest value (76) is in C so the set with 2C is the one you should choose and select you value according to this set.
>
> With
> > set.seed(666)
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> > data = data.frame(Var.1, Var.2)
> > data <- data[order(data$Var.2, decreasing=TRUE), ]
> > sss <- split(data$Var.2, data$Var.1)
> > lapply(sss, cumsum)
> $A
>  [1]  36  70 102 133 163 182 200 207 212 213
>
> $B
>  [1]  35  57  78  95 108 120 131 140 148 150
>
> $C
>  [1]  40  73 102 130 156 180 196 211 221 225
>
> $D
>  [1]  39  77 114 141 166 189 209 223 229 232
>
> Highest value is in D so either 3A - 3B - 2C - 2D  or 3A - 3B - 2C - 2D should be appropriate. And here I am again lost as both sets are same. Maybe you need to reconsider your statements.
>
> Cheers
> Petr
>
> From: Silvano Cesar da Costa <mailto:silvano at uel.br>
> Sent: Friday, August 20, 2021 9:28 PM
> To: PIKAL Petr <mailto:petr.pikal at precheza.cz>
> Cc: mailto:r-help at r-project.org
> Subject: Re: [R] Selecting elements
>
> Hi, thanks you for the answer.
> Sorry English is not my native language.
>
> But you got it right.
> > As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>
> I must select the 10 (not 15) highest values, but which follow a certain order:
> 3A - 3B - 2C - 2D     or
> 2A - 5B - 0C - 3D     or
> 3A - 3B - 2C - 2D
> I'll put the example in Excel for a better understanding (with 20 elements only).
> I must select 10 elements (the highest values of variable Var.2), which fit one of the 3 options above.
>
> Number
> Position
> Var.1
> Var.2
>
>
>
>
>
>
>
>
> 1
> 27
> C
> 40
>
>
>
>
>
>
>
>
> 2
> 30
> B
> 39
>
> Selected:
>
>
>
>
>
> 3
> 5
> A
> 38
>
> Number
> Position
> Var.1
> Var.2
>
>
>
> 4
> 16
> D
> 37
>
> 1
> 27
> C
> 40
>
>
>
> 5
> 23
> C
> 36
>
> 2
> 30
> B
> 39
>
> 3A - 3B - 2C - 2D
> 6
> 13
> A
> 35
>
> 3
> 5
> A
> 38
>
>
>
> 7
> 20
> D
> 34
>
> 4
> 16
> D
> 37
>
> 3A - 3B - 1C - 3D
> 8
> 12
> D
> 33
>
> 5
> 23
> C
> 36
>
>
>
> 9
> 9
> A
> 32
>
> 6
> 13
> A
> 35
>
> 2A - 5B - 0C - 3D
> 10
> 1
> A
> 31
>
> 7
> 20
> D
> 34
>
>
>
> 11
> 21
> A
> 30
>
> 10
> 9
> A
> 32
>
>
>
> 12
> 35
> C
> 29
>
> 13
> 14
> B
> 28
>
>
>
> 13
> 14
> B
> 28
>
> 17
> 6
> B
> 25
>
>
>
> 14
> 8
> D
> 27
>
>
>
>
>
>
>
>
> 15
> 7
> C
> 26
>
>
>
>
>
>
>
>
> 16
> 6
> B
> 25
>
>
>
>
>
>
>
>
> 17
> 40
> D
> 24
>
>
>
>
>
>
>
>
> 18
> 26
> B
> 23
>
>
>
>
>
>
>
>
> 19
> 29
> A
> 22
>
>
>
>
>
>
>
>
> 20
> 31
> C
> 21
>
>
>
>
>
>
>
>
>
>
>
> Second option (other data set):
>
> Number
> Position
> Var.1
> Var.2
>
>
>
>
>
>
>
>
> 1
> 36
> D
> 20
>
>
>
>
>
>
>
>
> 2
> 11
> B
> 19
>
> Selected:
>
>
>
>
>
> 3
> 39
> A
> 18
>
> Number
> Position
> Var.1
> Var.2
>
>
>
> 4
> 24
> D
> 17
>
> 1
> 36
> D
> 20
>
>
>
> 5
> 34
> B
> 16
>
> 2
> 11
> B
> 19
>
> 3A - 3B - 2C - 2D
> 6
> 2
> B
> 15
>
> 3
> 39
> A
> 18
>
>
>
> 7
> 3
> A
> 14
>
> 4
> 24
> D
> 17
>
> 3A - 3B - 1C - 3D
> 8
> 32
> D
> 13
>
> 5
> 34
> B
> 16
>
>
>
> 9
> 28
> D
> 12
>
> 6
> 2
> B
> 15
>
> 2A - 5B - 0C - 3D
> 10
> 25
> A
> 11
>
> 7
> 3
> A
> 14
>
>
>
> 11
> 19
> B
> 10
>
> 8
> 32
> D
> 13
>
>
>
> 12
> 15
> B
> 9
>
> 9
> 25
> A
> 11
>
>
>
> 13
> 17
> A
> 8
>
> 10
> 18
> C
> 7
>
>
>
> 14
> 18
> C
> 7
>
>
>
>
>
>
>
>
> 15
> 38
> B
> 6
>
>
>
>
>
>
>
>
> 16
> 10
> B
> 5
>
>
>
>
>
>
>
>
> 17
> 22
> B
> 4
>
>
>
>
>
>
>
>
> 18
> 4
> D
> 3
>
>
>
>
>
>
>
>
> 19
> 33
> A
> 2
>
>
>
>
>
>
>
>
> 20
> 37
> A
> 1
>
>
>
>
>
>
>
>
>
>
> How to make the selection of these 10 elements that fit one of the 3 options using R?
>
> Thanks,
>
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
>
> Fone: (43) 3371-4346
>
>
> Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <mailto:mailto:petr.pikal at precheza.cz> escreveu:
> Hallo
>
> I am confused, maybe others know what do you want but could you be more specific?
>
> Let say you have such data
> set.seed(123)
> Var.1 = rep(LETTERS[1:4], 10)
> Var.2 = sample(1:40, replace=FALSE)
> data = data.frame(Var.1, Var.2)
>
> What should be the desired outcome?
>
> You can sort
> data <- data[order(data$Var.2, decreasing=TRUE), ]
> and split the data
> > split(data$Var.2, data$Var.1)
> $A
>  [1] 38 35 32 31 30 22 11  8  2  1
>
> $B
>  [1] 39 28 25 23 16 15  7  6  5  4
>
> $C
>  [1] 40 36 29 26 21 19 18 14 10  9
>
> $D
>  [1] 37 34 33 27 24 20 17 13 12  3
>
> T inspect highest values. But here I am lost. As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>
> Or I do not understand at all what you really want to achieve.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <mailto:mailto:r-help-bounces at r-project.org> On Behalf Of Silvano Cesar da
> > Costa
> > Sent: Thursday, August 19, 2021 10:40 PM
> > To: mailto:mailto:r-help at r-project.org
> > Subject: [R] Selecting elements
> >
> > Hi,
> >
> > I need to select 15 elements, always considering the highest values
> > (descending order) but obeying the following configuration:
> >
> > 3A - 4B - 0C - 3D or
> > 2A - 5B - 0C - 3D or
> > 3A - 3B - 2C - 2D
> >
> > If I have, for example, 5 A elements as the highest values, I can only choose
> > (first and third choice) or 2 (second choice) elements.
> >
> > how to make this selection?
> >
> >
> > library(dplyr)
> >
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> >
> > data = data.frame(Var.1, Var.2)
> > (data = data[order(data$Var.2, decreasing=TRUE), ])
> >
> > Elements = data %>%
> >   arrange(desc(Var.2))
> >
> > Thanks,
> >
> > Prof. Dr. Silvano Cesar da Costa
> > Universidade Estadual de Londrina
> > Centro de Ci?ncias Exatas
> > Departamento de Estat?stica
> >
> > Fone: (43) 3371-4346
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 25 08:20:59 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Aug 2021 16:20:59 +1000
Subject: [R] Help needed with getting a decent image of ggplot2 graph
In-Reply-To: <1559591659.319235.1629849627465@mail.yahoo.com>
References: <324038213.311154.1629843668905.ref@mail.yahoo.com>
 <324038213.311154.1629843668905@mail.yahoo.com>
 <CA+8X3fUThuMQa+YEtUnaA+pkY1sQrxrPEV_TX_S_W0s_GyEx_w@mail.gmail.com>
 <621897339.317567.1629844948273@mail.yahoo.com>
 <CA+8X3fVLqG2owEN2zS1MBgHr41Nkocp5X7v8RNVXp2_hQA2Asw@mail.gmail.com>
 <1559591659.319235.1629849627465@mail.yahoo.com>
Message-ID: <CA+8X3fUS6aAyhu-spFtwzDNT+xDADPCrO7Zj-i2sojxZ=ZmQBA@mail.gmail.com>

If they can't work out how to resize an image, a 300 dpi resolution
leaves you with an image a bit over 37 mm wide. Doesn't add up for me.

Jim

On Wed, Aug 25, 2021 at 10:00 AM bharat rawlley
<bharat_m_all at yahoo.co.in> wrote:
>
> I tried doing that.
>
> So the real title of my graph is much longer than men and women and isn't not being incorporated in that width.
>
> I think I'll have to settle for a smaller title
>
> Sent from Yahoo Mail on Android
>
> On Tue, 24 Aug 2021 at 6:54 PM, Jim Lemon
> <drjimlemon at gmail.com> wrote:
> Ah, an _upper_ limit. Why not let tiff() work out the resolution
> (res=NA - the default) and see if that passes muster.
>
> Jim
>
> On Wed, Aug 25, 2021 at 8:42 AM bharat rawlley <bharat_m_all at yahoo.co.in> wrote:
> >
> > I am able to change but the place where I have to submit a similar graph has kept a fixed upper limit of 440 pixels for the width and an upper limit of 300 for the dpi.
> >
> > On Tuesday, 24 August, 2021, 06:36:16 pm GMT-4, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >
> > Hi bharat,
> > I think there is a conflict between your image size and resolution.
> > You need a lot larger height and width in pixels to get 300 dpi
> > resolution for the whole plot.
> >
> > tiff("test.tiff", units = "px", width = 2200, height = 1250, res = 300)
> >
> > would probably do it for you. How come you can't change the width and
> > height in pixels?
> >
> > Jim
> >
> > On Wed, Aug 25, 2021 at 8:22 AM bharat rawlley via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello, I made the following graph in R with the following code.
> > > ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  scale_y_continuous(limits=c(0, 1.4*ymax))+  labs(x= 'Year', y = 'Percentage', title = 'Men and Women')
> > >
> > >
> > >
> > > However, on using the following code - tiff("test.tiff", units = "px", width = 440, height = 250, res = 300)ggplot(aes(x=factor(year), y=percentage, color = Gender, fill=Gender), data = graph_text)+  geom_bar(position = 'dodge', stat='identity')+  theme_classic()+  scale_y_continuous(limits=c(0, 1.4*ymax))+  labs(x= 'Year', y = 'Percentage', title = 'Men and Women')dev.off()
> > >
> > >
> > > I get the following image -
> > >
> > >
> > >
> > > I need to keep the DPI = 300 and Width = 440 fixed. I can only manipulate height. Any help would be appreciated
> > > Thank you
> >
> > >  ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Aug 25 10:03:26 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 25 Aug 2021 09:03:26 +0100
Subject: [R] Need help to unzip files in Windows
In-Reply-To: <CAG0CrLj6g4Np_6+GqYWJqs5iJiEPzEqcdTari7=W38u54sZ9ag@mail.gmail.com>
References: <CAG0CrLig=A9QHg64_T-=gagVdEnq=YJ1gT-LAUBbimHF722YQA@mail.gmail.com>
 <CAPcHnpQb79ai6yCXKK5ExqmWenydKFFXPR71f5280k9ZQX-2ww@mail.gmail.com>
 <CAG0CrLgyzAo63yHdU_LKHi=M9nWm5CAN+b+_Q0=sRG5OexeoQg@mail.gmail.com>
 <CAPcHnpSU1kc-TmB42dq4wyfZf_wQv2oyx+Kx4qkgzar3gz1jaw@mail.gmail.com>
 <CAG0CrLj6g4Np_6+GqYWJqs5iJiEPzEqcdTari7=W38u54sZ9ag@mail.gmail.com>
Message-ID: <a4813211-3cc5-f6cf-76fc-25a05c55f66a@sapo.pt>

Hello,

Are you looking for what follows Andrew's code below to download and 
untar the files?



read_one_gz_file <- function(x, path){
   fl <- file.path(path, x)
   tryCatch({
     read.table(zz <- gzfile(fl))
   },
   warning = function(w) w,
   error = function(e) e
   )
}

URL <- 
"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar"
FILE <- file.path(tempdir(), basename(URL))
utils::download.file(URL, FILE, mode = "wb")
utils::untar(FILE, exdir = dirname(FILE))

fls <- list.files(path = dirname(FILE), pattern = "\\.gz$")
length(fls)
#[1] 108

data_list <- lapply(fls, read_one_gz_file, path = dirname(FILE))
length(data_list)
#[1] 108

head(data_list[[1]])
#        V1  V2
#1     A1BG   4
#2 A1BG-AS1  52
#3     A1CF  12
#4      A2M 645
#5  A2M-AS1 113
#6    A2ML1  21



I don't understand what you mean by to aggregate the files but if you 
want them all in one df, maybe this will do it.



sapply(data_list, ncol) # All files have 2 columns

# create a column with the original dataset name
data_list <- lapply(seq_along(data_list), function(i){
   dftmp <- data_list[[i]]
   dftmp$dataset <- sub("\\.txt\\.gz$", "", fls[i])
   dftmp
})

# put all data sets in one data.frame
df1 <- do.call(rbind, data_list)

dim(df1)  # Over 2.8 million rows, 3 columns
head(df1) # see the first 6 rows
#        V1  V2                 dataset
#1     A1BG   4 GSM4954457_A_1_Asymptom
#2 A1BG-AS1  52 GSM4954457_A_1_Asymptom
#3     A1CF  12 GSM4954457_A_1_Asymptom
#4      A2M 645 GSM4954457_A_1_Asymptom
#5  A2M-AS1 113 GSM4954457_A_1_Asymptom
#6    A2ML1  21 GSM4954457_A_1_Asymptom




Hope this helps,

Rui Barradas


?s 01:16 de 24/08/21, Anas Jamshed escreveu:
> sir after that I want to run:
> #get the list of sample names
> GSMnames <- t(list.files("~/Desktop/GSE162562_RAW", full.names = F))
> 
> #remove .txt from file/sample names
> GSMnames <- gsub(pattern = ".txt", replacement = "", GSMnames)
> 
> #make a vector of the list of files to aggregate
> files <- list.files("~/Desktop/GSE162562_RAW", full.names = TRUE)
> 
> 
> but it is not running as after running utils::untar(FILE, exdir =
> dirname(FILE)) it creates another 108 archieves
> 
> On Tue, Aug 24, 2021 at 2:03 AM Andrew Simmons <akwsimmo at gmail.com> wrote:
> 
>> Hello,
>>
>>
>> I tried downloading that file using 'utils::download.file' (which worked),
>> but then continued to complain about "damaged archive" when trying to use
>> 'utils::untar'. However, it seemed to work when I downloaded the archive
>> manually. Finally, the solution I found is that you have to specify the
>> mode in which you're downloading the file. Something like:
>>
>>
>> URL <- "
>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>> "
>> FILE <- file.path(tempdir(), basename(URL))
>>
>>
>> utils::download.file(URL, FILE, mode = "wb")
>> utils::untar(FILE, exdir = dirname(FILE))
>>
>>
>> worked perfectly for me. It seems to also work still on Ubuntu, but you
>> can let us know if you find it doesn't. I hope this helps!
>>
>>
>>
>> On Mon, Aug 23, 2021 at 3:20 PM Anas Jamshed <anasjamshed1994 at gmail.com>
>> wrote:
>>
>>> I am trying this URL: "
>>> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
>>> "
>>>
>>> but it is not giving me any file
>>>
>>> On Mon, Aug 23, 2021 at 11:42 PM Andrew Simmons <akwsimmo at gmail.com>
>>> wrote:
>>>
>>>> Hello,
>>>>
>>>>
>>>> I don't think you need to use a system command directly, I think
>>>> 'utils::untar' is all you need. I tried the same thing myself, something
>>>> like:
>>>>
>>>>
>>>> URL <- "https://exiftool.org/Image-ExifTool-12.30.tar.gz"
>>>> FILE <- file.path(tempdir(), basename(URL))
>>>>
>>>>
>>>> utils::download.file(URL, FILE)
>>>> utils::untar(FILE, exdir = dirname(FILE))
>>>>
>>>>
>>>> and it makes a folder "Image-ExifTool-12.30". It seems to work perfectly
>>>> fine in Windows 10 x64 build 19042. Can you send the specific file (or
>>>> provide a URL to the specific file) that isn't working for you?
>>>>
>>>> On Mon, Aug 23, 2021 at 12:53 PM Anas Jamshed <anasjamshed1994 at gmail.com>
>>>> wrote:
>>>>
>>>>> I have the file GSE162562_RAW. First I untar them
>>>>> by untar("GSE162562_RAW.tar")
>>>>> then I am running like:
>>>>>   system("gunzip ~/Desktop/GSE162562_RAW/*.gz")
>>>>>
>>>>>
>>>>> This is running fine in Linux but not in windows. What changes I
>>>>> should make to run this command in windows as well
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @||v@no @end|ng |rom ue|@br  Wed Aug 25 16:50:52 2021
From: @||v@no @end|ng |rom ue|@br (Silvano Cesar da Costa)
Date: Wed, 25 Aug 2021 11:50:52 -0300
Subject: [R] Selecting elements
In-Reply-To: <CA+8X3fW4BN1xsh87jd62rDBB40X9x7e2MerMnp22Q8X6FPco9w@mail.gmail.com>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
 <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WBKonNK47bCL3W3p-RmmhKw_Lw7oqHyHCzqTTBWdX=fSA@mail.gmail.com>
 <0db77aa4a7a74611ad833311cc9ef880@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fW4BN1xsh87jd62rDBB40X9x7e2MerMnp22Q8X6FPco9w@mail.gmail.com>
Message-ID: <CAMaZ2WA3do=z4n6ysQC==+B+NRu3j_NEfdmudRn2uqO7CxvL+A@mail.gmail.com>

Wow,

That's exactly what I want. But, if possible, that a list was created with
the selected elements (variable and value).
Is it possible to add in the output file?
Thank you very much.

Prof. Dr. Silvano Cesar da Costa
Universidade Estadual de Londrina
Centro de Ci?ncias Exatas
Departamento de Estat?stica

Fone: (43) 3371-4346


Em qua., 25 de ago. de 2021 ?s 03:12, Jim Lemon <drjimlemon at gmail.com>
escreveu:

> Hi Silvano,
> I was completely stumped by your problem until I looked through Petr's
> response and guessed that you wanted the largest sum of 'Var.1"
> constrained by the specified numbers in your three schemes. I think
> this is what you want, but I haven't checked it exhaustively.
>
> set.seed(123)
> Var.1 <- rep(LETTERS[1:4], 10)
> Var.2 <- sample(1:40, replace=FALSE)
> data <- data.frame(Var.1, Var.2)
> (Order <- data[order(data$Var.2, decreasing=TRUE), ])
> allowed<-matrix(c(3,3,2,2,2,5,0,3,3,4,2,1),nrow=3,byrow=TRUE)
> colnames(allowed)<-LETTERS[1:4]
> select_largest<-function(x,allowed,n=10) {
>  totals<-rep(0,nrow(allowed))
>  indices<-matrix(0,ncol=n,nrow=nrow(allowed))
>  for(i in 1:nrow(allowed)) {
>   ii<-1
>   for(j in 1:ncol(allowed)) {
>    if(allowed[i,j]) {
>     indx<-which(x[,1] == colnames(allowed)[j])
>     totals[i]<-totals[i]+sum(x[indx[1:allowed[i,j]],2])
>     indices[i,ii:(ii+allowed[i,j]-1)]<-indx[1:allowed[i,j]]
>     ii<-ii+allowed[i,j]
>    }
>   }
>  }
>  largest<-which.max(totals)
>  return(list(scheme=largest,total=totals[largest],
>   indices=sort(indices[largest,])))
> }
> select_largest(Order,allowed)
>
> Jim
>
> On Tue, Aug 24, 2021 at 7:11 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Hi.
> >
> > Now it is understandable.  However the solution is not clear for me.
> >
> > table(Order$Var.1[1:10])
> > A B C D
> > 4 1 2 3
> >
> > should give you a hint which scheme could be acceptable, but how to do
> it programmatically I do not know.
> >
> > maybe to start with lower value in the table call and gradually increse
> it to check which scheme starts to be the chosen one
> >
> > > table(data.o$Var.1[1]) # scheme 2 is out
> > C
> > 1
> > ...
> > > table(data.o$Var.1[1:5]) #scheme 3
> > A B C D
> > 1 1 2 1
> >
> > > table(data.o$Var.1[1:6]) #scheme 3
> >
> > A B C D
> > 2 1 2 1
> >
> > > table(data.o$Var.1[1:7]) # scheme1
> > A B C D
> > 2 1 2 2
> >
> > > table(data.o$Var.1[1:8]) # no such scheme, so scheme 1 is chosen one
> > A B C D
> > 2 1 2 3
> >
> > #Now you need to select values based on scheme 1.
> > # 3A - 3B - 2C - 2D
> >
> > sss <- split(Order, Order$Var.1)
> > selection <- c(3,3,2,2)
> > result <- vector("list", 4)
> >
> > #I would use loop
> >
> > for(i in 1:4) {
> > result[[i]] <- sss[[i]][1:selection[i],]
> > }
> >
> > Maybe someone come with other ingenious solution.
> >
> > Cheers
> > Petr
> >
> > From: Silvano Cesar da Costa <silvano at uel.br>
> > Sent: Monday, August 23, 2021 7:54 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Selecting elements
> >
> > Hi,
> >
> > I apologize for the confusion. I will try to be clearer in my
> explanation. I believe that with the R script it becomes clearer.
> >
> > I have 4 variables with 10 repetitions and each one receives a value,
> randomly.
> > I order the dataset from largest to smallest value. I have to select 10
> elements in
> > descending order of values, according to one of three schemes:
> >
> > # 3A - 3B - 2C - 2D
> > # 2A - 5B - 0C - 3D
> > # 3A - 4B - 2C - 1D
> >
> > If the first 3 elements (out of the 10 to be selected) are of the letter
> D, automatically
> > the adopted scheme will be the second. So, I have to (following) choose
> 2A, 5B and 0C.
> > How to make the selection automatically?
> >
> > I created two selection examples, with different schemes:
> >
> >
> >
> > set.seed(123)
> >
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> >
> > data = data.frame(Var.1, Var.2)
> >
> > (Order = data[order(data$Var.2, decreasing=TRUE), ])
> >
> > # I must select the 10 highest values (),
> > # but which follow a certain scheme:
> > #
> > #  3A - 3B - 2C - 2D     or
> > #  2A - 5B - 0C - 3D     or
> > #  3A - 4B - 2C - 1D
> > #
> > # In this case, I started with the highest value that refers to the
> letter C.
> > # Next comes only 1 of the letters B, A and D. All are selected once.
> > # The fifth observation is the letter C, completing 2 C values. In this
> case,
> > # following the 3 adopted schemes, note that the second scheme has 0C,
> > # so this scheme is out.
> > # Therefore, it can be the first scheme (3A - 3B - 2C - 2D) or the
> > # third scheme (3A - 4B - 2C - 1D).
> > # The next letter to be completed is the D (fourth and seventh elements),
> > # among the 10 elements being selected. Therefore, the scheme adopted is
> the
> > # first one (3A - 3B - 2C - 2D).
> > # Therefore, it is necessary to select 2 values with the letter B and 1
> value
> > # with the letter A.
> > #
> > # Manual Selection -
> > # The end result is:
> > (Selected.data = Order[c(1,2,3,4,5,6,7,9,13,16), ])
> >
> > # Scheme: 3A - 3B - 2C - 2D
> > sort(Selected.data$Var.1)
> >
> >
> > #------------------
> > # Second example: -
> > #------------------
> > set.seed(4)
> >
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> >
> > data = data.frame(Var.1, Var.2)
> > (Order = data[order(data$Var.2, decreasing=TRUE), ])
> >
> > # The end result is:
> > (Selected.data.2 = Order[c(1,2,3,4,5,6,7,8,9,11), ])
> >
> > # Scheme: 3A - 4B - 2C - 1D
> > sort(Selected.data.2$Var.1)
> >
> > How to make the selection of the 10 elements automatically?
> >
> > Thank you very much.
> >
> > Prof. Dr. Silvano Cesar da Costa
> > Universidade Estadual de Londrina
> > Centro de Ci?ncias Exatas
> > Departamento de Estat?stica
> >
> > Fone: (43) 3371-4346
> >
> >
> > Em seg., 23 de ago. de 2021 ?s 05:05, PIKAL Petr <mailto:
> petr.pikal at precheza.cz> escreveu:
> > Hi
> >
> > Only I got your HTML formated mail, rest of the world got complete mess.
> Do not use HTML formating.
> >
> > As I got it right I wonder why in your second example you did not follow
> > 3A - 3B - 2C - 2D
> >
> > as D were positioned 1st and 4th.
> >
> > I hope that you could use something like
> >
> > sss <- split(data$Var.2, data$Var.1)
> > lapply(sss, cumsum)
> > $A
> >  [1]  38  73 105 136 166 188 199 207 209 210
> >
> > $B
> >  [1]  39  67  92 115 131 146 153 159 164 168
> >
> > $C
> >  [1]  40  76 105 131 152 171 189 203 213 222
> >
> > $D
> >  [1]  37  71 104 131 155 175 192 205 217 220
> >
> > Now you need to evaluate this result according to your sets. Here the
> highest value (76) is in C so the set with 2C is the one you should choose
> and select you value according to this set.
> >
> > With
> > > set.seed(666)
> > > Var.1 = rep(LETTERS[1:4], 10)
> > > Var.2 = sample(1:40, replace=FALSE)
> > > data = data.frame(Var.1, Var.2)
> > > data <- data[order(data$Var.2, decreasing=TRUE), ]
> > > sss <- split(data$Var.2, data$Var.1)
> > > lapply(sss, cumsum)
> > $A
> >  [1]  36  70 102 133 163 182 200 207 212 213
> >
> > $B
> >  [1]  35  57  78  95 108 120 131 140 148 150
> >
> > $C
> >  [1]  40  73 102 130 156 180 196 211 221 225
> >
> > $D
> >  [1]  39  77 114 141 166 189 209 223 229 232
> >
> > Highest value is in D so either 3A - 3B - 2C - 2D  or 3A - 3B - 2C - 2D
> should be appropriate. And here I am again lost as both sets are same.
> Maybe you need to reconsider your statements.
> >
> > Cheers
> > Petr
> >
> > From: Silvano Cesar da Costa <mailto:silvano at uel.br>
> > Sent: Friday, August 20, 2021 9:28 PM
> > To: PIKAL Petr <mailto:petr.pikal at precheza.cz>
> > Cc: mailto:r-help at r-project.org
> > Subject: Re: [R] Selecting elements
> >
> > Hi, thanks you for the answer.
> > Sorry English is not my native language.
> >
> > But you got it right.
> > > As C is first and fourth biggest value, you follow third option and
> select 3 highest A, 3B 2C and 2D?
> >
> > I must select the 10 (not 15) highest values, but which follow a certain
> order:
> > 3A - 3B - 2C - 2D     or
> > 2A - 5B - 0C - 3D     or
> > 3A - 3B - 2C - 2D
> > I'll put the example in Excel for a better understanding (with 20
> elements only).
> > I must select 10 elements (the highest values of variable Var.2), which
> fit one of the 3 options above.
> >
> > Number
> > Position
> > Var.1
> > Var.2
> >
> >
> >
> >
> >
> >
> >
> >
> > 1
> > 27
> > C
> > 40
> >
> >
> >
> >
> >
> >
> >
> >
> > 2
> > 30
> > B
> > 39
> >
> > Selected:
> >
> >
> >
> >
> >
> > 3
> > 5
> > A
> > 38
> >
> > Number
> > Position
> > Var.1
> > Var.2
> >
> >
> >
> > 4
> > 16
> > D
> > 37
> >
> > 1
> > 27
> > C
> > 40
> >
> >
> >
> > 5
> > 23
> > C
> > 36
> >
> > 2
> > 30
> > B
> > 39
> >
> > 3A - 3B - 2C - 2D
> > 6
> > 13
> > A
> > 35
> >
> > 3
> > 5
> > A
> > 38
> >
> >
> >
> > 7
> > 20
> > D
> > 34
> >
> > 4
> > 16
> > D
> > 37
> >
> > 3A - 3B - 1C - 3D
> > 8
> > 12
> > D
> > 33
> >
> > 5
> > 23
> > C
> > 36
> >
> >
> >
> > 9
> > 9
> > A
> > 32
> >
> > 6
> > 13
> > A
> > 35
> >
> > 2A - 5B - 0C - 3D
> > 10
> > 1
> > A
> > 31
> >
> > 7
> > 20
> > D
> > 34
> >
> >
> >
> > 11
> > 21
> > A
> > 30
> >
> > 10
> > 9
> > A
> > 32
> >
> >
> >
> > 12
> > 35
> > C
> > 29
> >
> > 13
> > 14
> > B
> > 28
> >
> >
> >
> > 13
> > 14
> > B
> > 28
> >
> > 17
> > 6
> > B
> > 25
> >
> >
> >
> > 14
> > 8
> > D
> > 27
> >
> >
> >
> >
> >
> >
> >
> >
> > 15
> > 7
> > C
> > 26
> >
> >
> >
> >
> >
> >
> >
> >
> > 16
> > 6
> > B
> > 25
> >
> >
> >
> >
> >
> >
> >
> >
> > 17
> > 40
> > D
> > 24
> >
> >
> >
> >
> >
> >
> >
> >
> > 18
> > 26
> > B
> > 23
> >
> >
> >
> >
> >
> >
> >
> >
> > 19
> > 29
> > A
> > 22
> >
> >
> >
> >
> >
> >
> >
> >
> > 20
> > 31
> > C
> > 21
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > Second option (other data set):
> >
> > Number
> > Position
> > Var.1
> > Var.2
> >
> >
> >
> >
> >
> >
> >
> >
> > 1
> > 36
> > D
> > 20
> >
> >
> >
> >
> >
> >
> >
> >
> > 2
> > 11
> > B
> > 19
> >
> > Selected:
> >
> >
> >
> >
> >
> > 3
> > 39
> > A
> > 18
> >
> > Number
> > Position
> > Var.1
> > Var.2
> >
> >
> >
> > 4
> > 24
> > D
> > 17
> >
> > 1
> > 36
> > D
> > 20
> >
> >
> >
> > 5
> > 34
> > B
> > 16
> >
> > 2
> > 11
> > B
> > 19
> >
> > 3A - 3B - 2C - 2D
> > 6
> > 2
> > B
> > 15
> >
> > 3
> > 39
> > A
> > 18
> >
> >
> >
> > 7
> > 3
> > A
> > 14
> >
> > 4
> > 24
> > D
> > 17
> >
> > 3A - 3B - 1C - 3D
> > 8
> > 32
> > D
> > 13
> >
> > 5
> > 34
> > B
> > 16
> >
> >
> >
> > 9
> > 28
> > D
> > 12
> >
> > 6
> > 2
> > B
> > 15
> >
> > 2A - 5B - 0C - 3D
> > 10
> > 25
> > A
> > 11
> >
> > 7
> > 3
> > A
> > 14
> >
> >
> >
> > 11
> > 19
> > B
> > 10
> >
> > 8
> > 32
> > D
> > 13
> >
> >
> >
> > 12
> > 15
> > B
> > 9
> >
> > 9
> > 25
> > A
> > 11
> >
> >
> >
> > 13
> > 17
> > A
> > 8
> >
> > 10
> > 18
> > C
> > 7
> >
> >
> >
> > 14
> > 18
> > C
> > 7
> >
> >
> >
> >
> >
> >
> >
> >
> > 15
> > 38
> > B
> > 6
> >
> >
> >
> >
> >
> >
> >
> >
> > 16
> > 10
> > B
> > 5
> >
> >
> >
> >
> >
> >
> >
> >
> > 17
> > 22
> > B
> > 4
> >
> >
> >
> >
> >
> >
> >
> >
> > 18
> > 4
> > D
> > 3
> >
> >
> >
> >
> >
> >
> >
> >
> > 19
> > 33
> > A
> > 2
> >
> >
> >
> >
> >
> >
> >
> >
> > 20
> > 37
> > A
> > 1
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > How to make the selection of these 10 elements that fit one of the 3
> options using R?
> >
> > Thanks,
> >
> > Prof. Dr. Silvano Cesar da Costa
> > Universidade Estadual de Londrina
> > Centro de Ci?ncias Exatas
> > Departamento de Estat?stica
> >
> > Fone: (43) 3371-4346
> >
> >
> > Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <mailto:mailto:
> petr.pikal at precheza.cz> escreveu:
> > Hallo
> >
> > I am confused, maybe others know what do you want but could you be more
> specific?
> >
> > Let say you have such data
> > set.seed(123)
> > Var.1 = rep(LETTERS[1:4], 10)
> > Var.2 = sample(1:40, replace=FALSE)
> > data = data.frame(Var.1, Var.2)
> >
> > What should be the desired outcome?
> >
> > You can sort
> > data <- data[order(data$Var.2, decreasing=TRUE), ]
> > and split the data
> > > split(data$Var.2, data$Var.1)
> > $A
> >  [1] 38 35 32 31 30 22 11  8  2  1
> >
> > $B
> >  [1] 39 28 25 23 16 15  7  6  5  4
> >
> > $C
> >  [1] 40 36 29 26 21 19 18 14 10  9
> >
> > $D
> >  [1] 37 34 33 27 24 20 17 13 12  3
> >
> > T inspect highest values. But here I am lost. As C is first and fourth
> biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
> >
> > Or I do not understand at all what you really want to achieve.
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help <mailto:mailto:r-help-bounces at r-project.org> On Behalf
> Of Silvano Cesar da
> > > Costa
> > > Sent: Thursday, August 19, 2021 10:40 PM
> > > To: mailto:mailto:r-help at r-project.org
> > > Subject: [R] Selecting elements
> > >
> > > Hi,
> > >
> > > I need to select 15 elements, always considering the highest values
> > > (descending order) but obeying the following configuration:
> > >
> > > 3A - 4B - 0C - 3D or
> > > 2A - 5B - 0C - 3D or
> > > 3A - 3B - 2C - 2D
> > >
> > > If I have, for example, 5 A elements as the highest values, I can only
> choose
> > > (first and third choice) or 2 (second choice) elements.
> > >
> > > how to make this selection?
> > >
> > >
> > > library(dplyr)
> > >
> > > Var.1 = rep(LETTERS[1:4], 10)
> > > Var.2 = sample(1:40, replace=FALSE)
> > >
> > > data = data.frame(Var.1, Var.2)
> > > (data = data[order(data$Var.2, decreasing=TRUE), ])
> > >
> > > Elements = data %>%
> > >   arrange(desc(Var.2))
> > >
> > > Thanks,
> > >
> > > Prof. Dr. Silvano Cesar da Costa
> > > Universidade Estadual de Londrina
> > > Centro de Ci?ncias Exatas
> > > Departamento de Estat?stica
> > >
> > > Fone: (43) 3371-4346
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > mailto:mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 26 01:38:43 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 26 Aug 2021 09:38:43 +1000
Subject: [R] Selecting elements
In-Reply-To: <CAMaZ2WA3do=z4n6ysQC==+B+NRu3j_NEfdmudRn2uqO7CxvL+A@mail.gmail.com>
References: <CAMaZ2WApiOFxNj9qY4Gt7=COx=UoWdshyV-FebfpTc+fQ2aruA@mail.gmail.com>
 <807fbea8c3f04d378c583102cad605f5@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WA3MirRdQHaXOEaaHXhB3n6icjjd-B5Yboc35B_keUbaQ@mail.gmail.com>
 <21ee040536754b0b8da279e4c2a6ebc2@SRVEXCHCM1302.precheza.cz>
 <CAMaZ2WBKonNK47bCL3W3p-RmmhKw_Lw7oqHyHCzqTTBWdX=fSA@mail.gmail.com>
 <0db77aa4a7a74611ad833311cc9ef880@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fW4BN1xsh87jd62rDBB40X9x7e2MerMnp22Q8X6FPco9w@mail.gmail.com>
 <CAMaZ2WA3do=z4n6ysQC==+B+NRu3j_NEfdmudRn2uqO7CxvL+A@mail.gmail.com>
Message-ID: <CA+8X3fXEDPf3AiHyGzR62g_J1+oUXZb8vEV6_FLyMGvC0TsOZQ@mail.gmail.com>

Hi Silvano,
Just add the selected elements to the return value:

set.seed(123)
Var.1 <- rep(LETTERS[1:4], 10)
Var.2 <- sample(1:40, replace=FALSE)
data <- data.frame(Var.1, Var.2)
(Order <- data[order(data$Var.2, decreasing=TRUE), ])
allowed<-matrix(c(3,3,2,2,2,5,0,3,3,4,2,1),nrow=3,byrow=TRUE)
colnames(allowed)<-LETTERS[1:4]
select_largest<-function(x,allowed,n=10) {
 totals<-rep(0,nrow(allowed))
 indices<-matrix(0,ncol=n,nrow=nrow(allowed))
 for(i in 1:nrow(allowed)) {
  ii<-1
  for(j in 1:ncol(allowed)) {
   if(allowed[i,j]) {
    indx<-which(x[,1] == colnames(allowed)[j])
    totals[i]<-totals[i]+sum(x[indx[1:allowed[i,j]],2])
    indices[i,ii:(ii+allowed[i,j]-1)]<-indx[1:allowed[i,j]]
    ii<-ii+allowed[i,j]
   }
  }
 }
 largest<-which.max(totals)
 # sort the indices here
 indices<-sort(indices[largest,])
 return(list(scheme=largest,total=totals[largest],
  indices=indices,elements=x[indices,]))
}
select_largest(Order,allowed)

Jim

On Thu, Aug 26, 2021 at 12:46 AM Silvano Cesar da Costa <silvano at uel.br> wrote:
>
> Wow,
>
> That's exactly what I want. But, if possible, that a list was created with the selected elements (variable and value).
> Is it possible to add in the output file?
> Thank you very much.
>
> Prof. Dr. Silvano Cesar da Costa
> Universidade Estadual de Londrina
> Centro de Ci?ncias Exatas
> Departamento de Estat?stica
>
> Fone: (43) 3371-4346
>
>
> Em qua., 25 de ago. de 2021 ?s 03:12, Jim Lemon <drjimlemon at gmail.com> escreveu:
>>
>> Hi Silvano,
>> I was completely stumped by your problem until I looked through Petr's
>> response and guessed that you wanted the largest sum of 'Var.1"
>> constrained by the specified numbers in your three schemes. I think
>> this is what you want, but I haven't checked it exhaustively.
>>
>> set.seed(123)
>> Var.1 <- rep(LETTERS[1:4], 10)
>> Var.2 <- sample(1:40, replace=FALSE)
>> data <- data.frame(Var.1, Var.2)
>> (Order <- data[order(data$Var.2, decreasing=TRUE), ])
>> allowed<-matrix(c(3,3,2,2,2,5,0,3,3,4,2,1),nrow=3,byrow=TRUE)
>> colnames(allowed)<-LETTERS[1:4]
>> select_largest<-function(x,allowed,n=10) {
>>  totals<-rep(0,nrow(allowed))
>>  indices<-matrix(0,ncol=n,nrow=nrow(allowed))
>>  for(i in 1:nrow(allowed)) {
>>   ii<-1
>>   for(j in 1:ncol(allowed)) {
>>    if(allowed[i,j]) {
>>     indx<-which(x[,1] == colnames(allowed)[j])
>>     totals[i]<-totals[i]+sum(x[indx[1:allowed[i,j]],2])
>>     indices[i,ii:(ii+allowed[i,j]-1)]<-indx[1:allowed[i,j]]
>>     ii<-ii+allowed[i,j]
>>    }
>>   }
>>  }
>>  largest<-which.max(totals)
>>  return(list(scheme=largest,total=totals[largest],
>>   indices=sort(indices[largest,])))
>> }
>> select_largest(Order,allowed)
>>
>> Jim
>>
>> On Tue, Aug 24, 2021 at 7:11 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> >
>> > Hi.
>> >
>> > Now it is understandable.  However the solution is not clear for me.
>> >
>> > table(Order$Var.1[1:10])
>> > A B C D
>> > 4 1 2 3
>> >
>> > should give you a hint which scheme could be acceptable, but how to do it programmatically I do not know.
>> >
>> > maybe to start with lower value in the table call and gradually increse it to check which scheme starts to be the chosen one
>> >
>> > > table(data.o$Var.1[1]) # scheme 2 is out
>> > C
>> > 1
>> > ...
>> > > table(data.o$Var.1[1:5]) #scheme 3
>> > A B C D
>> > 1 1 2 1
>> >
>> > > table(data.o$Var.1[1:6]) #scheme 3
>> >
>> > A B C D
>> > 2 1 2 1
>> >
>> > > table(data.o$Var.1[1:7]) # scheme1
>> > A B C D
>> > 2 1 2 2
>> >
>> > > table(data.o$Var.1[1:8]) # no such scheme, so scheme 1 is chosen one
>> > A B C D
>> > 2 1 2 3
>> >
>> > #Now you need to select values based on scheme 1.
>> > # 3A - 3B - 2C - 2D
>> >
>> > sss <- split(Order, Order$Var.1)
>> > selection <- c(3,3,2,2)
>> > result <- vector("list", 4)
>> >
>> > #I would use loop
>> >
>> > for(i in 1:4) {
>> > result[[i]] <- sss[[i]][1:selection[i],]
>> > }
>> >
>> > Maybe someone come with other ingenious solution.
>> >
>> > Cheers
>> > Petr
>> >
>> > From: Silvano Cesar da Costa <silvano at uel.br>
>> > Sent: Monday, August 23, 2021 7:54 PM
>> > To: PIKAL Petr <petr.pikal at precheza.cz>
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] Selecting elements
>> >
>> > Hi,
>> >
>> > I apologize for the confusion. I will try to be clearer in my explanation. I believe that with the R script it becomes clearer.
>> >
>> > I have 4 variables with 10 repetitions and each one receives a value, randomly.
>> > I order the dataset from largest to smallest value. I have to select 10 elements in
>> > descending order of values, according to one of three schemes:
>> >
>> > # 3A - 3B - 2C - 2D
>> > # 2A - 5B - 0C - 3D
>> > # 3A - 4B - 2C - 1D
>> >
>> > If the first 3 elements (out of the 10 to be selected) are of the letter D, automatically
>> > the adopted scheme will be the second. So, I have to (following) choose 2A, 5B and 0C.
>> > How to make the selection automatically?
>> >
>> > I created two selection examples, with different schemes:
>> >
>> >
>> >
>> > set.seed(123)
>> >
>> > Var.1 = rep(LETTERS[1:4], 10)
>> > Var.2 = sample(1:40, replace=FALSE)
>> >
>> > data = data.frame(Var.1, Var.2)
>> >
>> > (Order = data[order(data$Var.2, decreasing=TRUE), ])
>> >
>> > # I must select the 10 highest values (),
>> > # but which follow a certain scheme:
>> > #
>> > #  3A - 3B - 2C - 2D     or
>> > #  2A - 5B - 0C - 3D     or
>> > #  3A - 4B - 2C - 1D
>> > #
>> > # In this case, I started with the highest value that refers to the letter C.
>> > # Next comes only 1 of the letters B, A and D. All are selected once.
>> > # The fifth observation is the letter C, completing 2 C values. In this case,
>> > # following the 3 adopted schemes, note that the second scheme has 0C,
>> > # so this scheme is out.
>> > # Therefore, it can be the first scheme (3A - 3B - 2C - 2D) or the
>> > # third scheme (3A - 4B - 2C - 1D).
>> > # The next letter to be completed is the D (fourth and seventh elements),
>> > # among the 10 elements being selected. Therefore, the scheme adopted is the
>> > # first one (3A - 3B - 2C - 2D).
>> > # Therefore, it is necessary to select 2 values with the letter B and 1 value
>> > # with the letter A.
>> > #
>> > # Manual Selection -
>> > # The end result is:
>> > (Selected.data = Order[c(1,2,3,4,5,6,7,9,13,16), ])
>> >
>> > # Scheme: 3A - 3B - 2C - 2D
>> > sort(Selected.data$Var.1)
>> >
>> >
>> > #------------------
>> > # Second example: -
>> > #------------------
>> > set.seed(4)
>> >
>> > Var.1 = rep(LETTERS[1:4], 10)
>> > Var.2 = sample(1:40, replace=FALSE)
>> >
>> > data = data.frame(Var.1, Var.2)
>> > (Order = data[order(data$Var.2, decreasing=TRUE), ])
>> >
>> > # The end result is:
>> > (Selected.data.2 = Order[c(1,2,3,4,5,6,7,8,9,11), ])
>> >
>> > # Scheme: 3A - 4B - 2C - 1D
>> > sort(Selected.data.2$Var.1)
>> >
>> > How to make the selection of the 10 elements automatically?
>> >
>> > Thank you very much.
>> >
>> > Prof. Dr. Silvano Cesar da Costa
>> > Universidade Estadual de Londrina
>> > Centro de Ci?ncias Exatas
>> > Departamento de Estat?stica
>> >
>> > Fone: (43) 3371-4346
>> >
>> >
>> > Em seg., 23 de ago. de 2021 ?s 05:05, PIKAL Petr <mailto:petr.pikal at precheza.cz> escreveu:
>> > Hi
>> >
>> > Only I got your HTML formated mail, rest of the world got complete mess. Do not use HTML formating.
>> >
>> > As I got it right I wonder why in your second example you did not follow
>> > 3A - 3B - 2C - 2D
>> >
>> > as D were positioned 1st and 4th.
>> >
>> > I hope that you could use something like
>> >
>> > sss <- split(data$Var.2, data$Var.1)
>> > lapply(sss, cumsum)
>> > $A
>> >  [1]  38  73 105 136 166 188 199 207 209 210
>> >
>> > $B
>> >  [1]  39  67  92 115 131 146 153 159 164 168
>> >
>> > $C
>> >  [1]  40  76 105 131 152 171 189 203 213 222
>> >
>> > $D
>> >  [1]  37  71 104 131 155 175 192 205 217 220
>> >
>> > Now you need to evaluate this result according to your sets. Here the highest value (76) is in C so the set with 2C is the one you should choose and select you value according to this set.
>> >
>> > With
>> > > set.seed(666)
>> > > Var.1 = rep(LETTERS[1:4], 10)
>> > > Var.2 = sample(1:40, replace=FALSE)
>> > > data = data.frame(Var.1, Var.2)
>> > > data <- data[order(data$Var.2, decreasing=TRUE), ]
>> > > sss <- split(data$Var.2, data$Var.1)
>> > > lapply(sss, cumsum)
>> > $A
>> >  [1]  36  70 102 133 163 182 200 207 212 213
>> >
>> > $B
>> >  [1]  35  57  78  95 108 120 131 140 148 150
>> >
>> > $C
>> >  [1]  40  73 102 130 156 180 196 211 221 225
>> >
>> > $D
>> >  [1]  39  77 114 141 166 189 209 223 229 232
>> >
>> > Highest value is in D so either 3A - 3B - 2C - 2D  or 3A - 3B - 2C - 2D should be appropriate. And here I am again lost as both sets are same. Maybe you need to reconsider your statements.
>> >
>> > Cheers
>> > Petr
>> >
>> > From: Silvano Cesar da Costa <mailto:silvano at uel.br>
>> > Sent: Friday, August 20, 2021 9:28 PM
>> > To: PIKAL Petr <mailto:petr.pikal at precheza.cz>
>> > Cc: mailto:r-help at r-project.org
>> > Subject: Re: [R] Selecting elements
>> >
>> > Hi, thanks you for the answer.
>> > Sorry English is not my native language.
>> >
>> > But you got it right.
>> > > As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>> >
>> > I must select the 10 (not 15) highest values, but which follow a certain order:
>> > 3A - 3B - 2C - 2D     or
>> > 2A - 5B - 0C - 3D     or
>> > 3A - 3B - 2C - 2D
>> > I'll put the example in Excel for a better understanding (with 20 elements only).
>> > I must select 10 elements (the highest values of variable Var.2), which fit one of the 3 options above.
>> >
>> > Number
>> > Position
>> > Var.1
>> > Var.2
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 1
>> > 27
>> > C
>> > 40
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 2
>> > 30
>> > B
>> > 39
>> >
>> > Selected:
>> >
>> >
>> >
>> >
>> >
>> > 3
>> > 5
>> > A
>> > 38
>> >
>> > Number
>> > Position
>> > Var.1
>> > Var.2
>> >
>> >
>> >
>> > 4
>> > 16
>> > D
>> > 37
>> >
>> > 1
>> > 27
>> > C
>> > 40
>> >
>> >
>> >
>> > 5
>> > 23
>> > C
>> > 36
>> >
>> > 2
>> > 30
>> > B
>> > 39
>> >
>> > 3A - 3B - 2C - 2D
>> > 6
>> > 13
>> > A
>> > 35
>> >
>> > 3
>> > 5
>> > A
>> > 38
>> >
>> >
>> >
>> > 7
>> > 20
>> > D
>> > 34
>> >
>> > 4
>> > 16
>> > D
>> > 37
>> >
>> > 3A - 3B - 1C - 3D
>> > 8
>> > 12
>> > D
>> > 33
>> >
>> > 5
>> > 23
>> > C
>> > 36
>> >
>> >
>> >
>> > 9
>> > 9
>> > A
>> > 32
>> >
>> > 6
>> > 13
>> > A
>> > 35
>> >
>> > 2A - 5B - 0C - 3D
>> > 10
>> > 1
>> > A
>> > 31
>> >
>> > 7
>> > 20
>> > D
>> > 34
>> >
>> >
>> >
>> > 11
>> > 21
>> > A
>> > 30
>> >
>> > 10
>> > 9
>> > A
>> > 32
>> >
>> >
>> >
>> > 12
>> > 35
>> > C
>> > 29
>> >
>> > 13
>> > 14
>> > B
>> > 28
>> >
>> >
>> >
>> > 13
>> > 14
>> > B
>> > 28
>> >
>> > 17
>> > 6
>> > B
>> > 25
>> >
>> >
>> >
>> > 14
>> > 8
>> > D
>> > 27
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 15
>> > 7
>> > C
>> > 26
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 16
>> > 6
>> > B
>> > 25
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 17
>> > 40
>> > D
>> > 24
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 18
>> > 26
>> > B
>> > 23
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 19
>> > 29
>> > A
>> > 22
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 20
>> > 31
>> > C
>> > 21
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > Second option (other data set):
>> >
>> > Number
>> > Position
>> > Var.1
>> > Var.2
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 1
>> > 36
>> > D
>> > 20
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 2
>> > 11
>> > B
>> > 19
>> >
>> > Selected:
>> >
>> >
>> >
>> >
>> >
>> > 3
>> > 39
>> > A
>> > 18
>> >
>> > Number
>> > Position
>> > Var.1
>> > Var.2
>> >
>> >
>> >
>> > 4
>> > 24
>> > D
>> > 17
>> >
>> > 1
>> > 36
>> > D
>> > 20
>> >
>> >
>> >
>> > 5
>> > 34
>> > B
>> > 16
>> >
>> > 2
>> > 11
>> > B
>> > 19
>> >
>> > 3A - 3B - 2C - 2D
>> > 6
>> > 2
>> > B
>> > 15
>> >
>> > 3
>> > 39
>> > A
>> > 18
>> >
>> >
>> >
>> > 7
>> > 3
>> > A
>> > 14
>> >
>> > 4
>> > 24
>> > D
>> > 17
>> >
>> > 3A - 3B - 1C - 3D
>> > 8
>> > 32
>> > D
>> > 13
>> >
>> > 5
>> > 34
>> > B
>> > 16
>> >
>> >
>> >
>> > 9
>> > 28
>> > D
>> > 12
>> >
>> > 6
>> > 2
>> > B
>> > 15
>> >
>> > 2A - 5B - 0C - 3D
>> > 10
>> > 25
>> > A
>> > 11
>> >
>> > 7
>> > 3
>> > A
>> > 14
>> >
>> >
>> >
>> > 11
>> > 19
>> > B
>> > 10
>> >
>> > 8
>> > 32
>> > D
>> > 13
>> >
>> >
>> >
>> > 12
>> > 15
>> > B
>> > 9
>> >
>> > 9
>> > 25
>> > A
>> > 11
>> >
>> >
>> >
>> > 13
>> > 17
>> > A
>> > 8
>> >
>> > 10
>> > 18
>> > C
>> > 7
>> >
>> >
>> >
>> > 14
>> > 18
>> > C
>> > 7
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 15
>> > 38
>> > B
>> > 6
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 16
>> > 10
>> > B
>> > 5
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 17
>> > 22
>> > B
>> > 4
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 18
>> > 4
>> > D
>> > 3
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 19
>> > 33
>> > A
>> > 2
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 20
>> > 37
>> > A
>> > 1
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > How to make the selection of these 10 elements that fit one of the 3 options using R?
>> >
>> > Thanks,
>> >
>> > Prof. Dr. Silvano Cesar da Costa
>> > Universidade Estadual de Londrina
>> > Centro de Ci?ncias Exatas
>> > Departamento de Estat?stica
>> >
>> > Fone: (43) 3371-4346
>> >
>> >
>> > Em sex., 20 de ago. de 2021 ?s 03:28, PIKAL Petr <mailto:mailto:petr.pikal at precheza.cz> escreveu:
>> > Hallo
>> >
>> > I am confused, maybe others know what do you want but could you be more specific?
>> >
>> > Let say you have such data
>> > set.seed(123)
>> > Var.1 = rep(LETTERS[1:4], 10)
>> > Var.2 = sample(1:40, replace=FALSE)
>> > data = data.frame(Var.1, Var.2)
>> >
>> > What should be the desired outcome?
>> >
>> > You can sort
>> > data <- data[order(data$Var.2, decreasing=TRUE), ]
>> > and split the data
>> > > split(data$Var.2, data$Var.1)
>> > $A
>> >  [1] 38 35 32 31 30 22 11  8  2  1
>> >
>> > $B
>> >  [1] 39 28 25 23 16 15  7  6  5  4
>> >
>> > $C
>> >  [1] 40 36 29 26 21 19 18 14 10  9
>> >
>> > $D
>> >  [1] 37 34 33 27 24 20 17 13 12  3
>> >
>> > T inspect highest values. But here I am lost. As C is first and fourth biggest value, you follow third option and select 3 highest A, 3B 2C and 2D?
>> >
>> > Or I do not understand at all what you really want to achieve.
>> >
>> > Cheers
>> > Petr
>> >
>> > > -----Original Message-----
>> > > From: R-help <mailto:mailto:r-help-bounces at r-project.org> On Behalf Of Silvano Cesar da
>> > > Costa
>> > > Sent: Thursday, August 19, 2021 10:40 PM
>> > > To: mailto:mailto:r-help at r-project.org
>> > > Subject: [R] Selecting elements
>> > >
>> > > Hi,
>> > >
>> > > I need to select 15 elements, always considering the highest values
>> > > (descending order) but obeying the following configuration:
>> > >
>> > > 3A - 4B - 0C - 3D or
>> > > 2A - 5B - 0C - 3D or
>> > > 3A - 3B - 2C - 2D
>> > >
>> > > If I have, for example, 5 A elements as the highest values, I can only choose
>> > > (first and third choice) or 2 (second choice) elements.
>> > >
>> > > how to make this selection?
>> > >
>> > >
>> > > library(dplyr)
>> > >
>> > > Var.1 = rep(LETTERS[1:4], 10)
>> > > Var.2 = sample(1:40, replace=FALSE)
>> > >
>> > > data = data.frame(Var.1, Var.2)
>> > > (data = data[order(data$Var.2, decreasing=TRUE), ])
>> > >
>> > > Elements = data %>%
>> > >   arrange(desc(Var.2))
>> > >
>> > > Thanks,
>> > >
>> > > Prof. Dr. Silvano Cesar da Costa
>> > > Universidade Estadual de Londrina
>> > > Centro de Ci?ncias Exatas
>> > > Departamento de Estat?stica
>> > >
>> > > Fone: (43) 3371-4346
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > mailto:mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > > guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From n|ckmwr@y @end|ng |rom gm@||@com  Thu Aug 26 15:23:16 2021
From: n|ckmwr@y @end|ng |rom gm@||@com (Nick Wray)
Date: Thu, 26 Aug 2021 14:23:16 +0100
Subject: [R] Augmented Dickie-Fuller test
Message-ID: <CABxY9BPhLpNwBThX107zT=9q48rxCfSUutH5+5H+d6A10mZ35w@mail.gmail.com>

Hello: I've downloaded this dataset, and when I plot it it is clearly
non-stationary


df <- read.csv('
https://raw.githubusercontent.com/ourcodingclub/CC-time-series/master/monthly_milk.csv
')

plot(df,type="l")

But when I apply the Augmented Dickie-Fuller Test I get a p value of 0.01,
implying that there is evidence to reject the null that the series is
non-stationary. I am puzzled as to why this is happening. Is this because
the confidence level is basically too high or is something else going on?

adf.test(df[,2])

Augmented Dickey-Fuller Test

data: df[, 2] Dickey-Fuller = -9.9714, Lag order = 5, p-value = 0.01
alternative hypothesis: stationary

Thanks Nick Wray

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Aug 26 17:53:10 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 26 Aug 2021 15:53:10 +0000 (UTC)
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
Message-ID: <1630275966.648706.1629993190721@mail.yahoo.com>

Hello List,
I got an error message when I submit the code below
ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +? geom_rect() +? coord_polar(theta="y")? +? xlim(c(2, 4)?? )?

Error: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx


I checked the syntax. But I can? not find any error on my code. Can you help me to find where is the problem?

Thanks

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Aug 26 17:55:31 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 26 Aug 2021 17:55:31 +0200
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1630275966.648706.1629993190721@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
Message-ID: <CAJuCY5zyipDm-iOLCJ05Hptq5uPfB8XxWtGGvcmw5KgpVmejrQ@mail.gmail.com>

eth is not a dataframe but of the class rxlsx. You'll need to convert eth
into a dataframe.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 26 aug. 2021 om 17:53 schreef Kai Yang via R-help <
r-help at r-project.org>:

> Hello List,
> I got an error message when I submit the code below
> ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
> geom_rect() +  coord_polar(theta="y")  +  xlim(c(2, 4)   )
>
> Error: `data` must be a data frame, or other object coercible by
> `fortify()`, not an S3 object with class rxlsx
>
>
> I checked the syntax. But I can  not find any error on my code. Can you
> help me to find where is the problem?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Thu Aug 26 17:56:16 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 26 Aug 2021 11:56:16 -0400
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1630275966.648706.1629993190721@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
Message-ID: <CAPcHnpTP6DbSF4_-vL6B39VnwP8zKS010ZvK+GtofY_p2LjYYw@mail.gmail.com>

The class of 'eth' must be incorrect. You could try 'as.data.frame' or
possibly 'as.list' to convert 'eth' to an acceptable form.

On Thu, Aug 26, 2021, 11:53 Kai Yang via R-help <r-help at r-project.org>
wrote:

> Hello List,
> I got an error message when I submit the code below
> ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
> geom_rect() +  coord_polar(theta="y")  +  xlim(c(2, 4)   )
>
> Error: `data` must be a data frame, or other object coercible by
> `fortify()`, not an S3 object with class rxlsx
>
>
> I checked the syntax. But I can  not find any error on my code. Can you
> help me to find where is the problem?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |r@|nj @end|ng |rom gm@||@com  Thu Aug 26 18:01:53 2021
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Thu, 26 Aug 2021 17:01:53 +0100
Subject: [R] Augmented Dickie-Fuller test
In-Reply-To: <CABxY9BPhLpNwBThX107zT=9q48rxCfSUutH5+5H+d6A10mZ35w@mail.gmail.com>
References: <CABxY9BPhLpNwBThX107zT=9q48rxCfSUutH5+5H+d6A10mZ35w@mail.gmail.com>
Message-ID: <CAHrK516wjLMpzDtJG8Rp=5ac-H5=W4JyhegrCXnyB32+mO2bDg@mail.gmail.com>

Your series shows a strong seasonal pattern that looks fairly constant.   I
would think that the adf style test is not appropriate.  What are you
trying to achieve?


John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
https://jcfrain.wordpress.com/
https://jcfraincv19.wordpress.com/

mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Thu, 26 Aug 2021 at 14:24, Nick Wray <nickmwray at gmail.com> wrote:

> Hello: I've downloaded this dataset, and when I plot it it is clearly
> non-stationary
>
>
> df <- read.csv('
>
> https://raw.githubusercontent.com/ourcodingclub/CC-time-series/master/monthly_milk.csv
> ')
>
> plot(df,type="l")
>
> But when I apply the Augmented Dickie-Fuller Test I get a p value of 0.01,
> implying that there is evidence to reject the null that the series is
> non-stationary. I am puzzled as to why this is happening. Is this because
> the confidence level is basically too high or is something else going on?
>
> adf.test(df[,2])
>
> Augmented Dickey-Fuller Test
>
> data: df[, 2] Dickey-Fuller = -9.9714, Lag order = 5, p-value = 0.01
> alternative hypothesis: stationary
>
> Thanks Nick Wray
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Aug 26 18:10:53 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 26 Aug 2021 12:10:53 -0400
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1630275966.648706.1629993190721@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
Message-ID: <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>

Kai,

The answer is fairly probable to find  if you examine your variable "eth" as that is the only time you are being asked to provide the argument as in "ggplot(data=eth, ..) ...)

As the message states, it expects that argument to be a data frame or something it can change into a data.frame. What you gave it probably is an object meant to represent an EXCEL file or something. You may need to extract a data.frame (or tibble or ...) from it before passing that to ggplot.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-help
Sent: Thursday, August 26, 2021 11:53 AM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

Hello List,
I got an error message when I submit the code below ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +  geom_rect() +  coord_polar(theta="y")  +  xlim(c(2, 4)   ) 

Error: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx


I checked the syntax. But I can  not find any error on my code. Can you help me to find where is the problem?

Thanks

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From |eo@|unde|| @end|ng |rom @und@ku@dk  Thu Aug 26 09:46:02 2021
From: |eo@|unde|| @end|ng |rom @und@ku@dk (Leonidas Lundell)
Date: Thu, 26 Aug 2021 07:46:02 +0000
Subject: [R] Potential bug/unexpected behaviour in model matrix
In-Reply-To: <BBE9883E-0580-46C9-A6C5-381DFA083BF4@ku.dk>
References: <BBE9883E-0580-46C9-A6C5-381DFA083BF4@ku.dk>
Message-ID: <023094CE-40C0-4810-A796-196BE79BF580@ku.dk>

Dear R-project,
 
Apologies if I am sending this to the wrong list, and thank you for your enormous contribution.

I discovered a subtle interaction between the data.table package and model.matrix function that influences the output to the point that you will get completely erroneous results:

df  <- data.frame(basespaceID = 8:1, group = paste0(rep(c("a", "b"), 4), "_", sort(rep(c("1", "2"), 4))))
designDF <- model.matrix(~0 + group, data = df)

dt <- data.table::as.data.table(df)
designDT <- model.matrix(~0 + group, data = dt)

all(designDF == designDT)
#TRUE

data.table::setkey(dt, "basespaceID")
designDTkeyed <- model.matrix(~0 + group, data = dt)

all(designDF == designDTkeyed)
#FALSE

# It seems that a keyed data.table reorders the rows of the design matrix by alphabetical order:
  
 designDFreordered <- model.matrix(~0 + group, data = df[8:1,])
all(designDFreordered == designDTkeyed)
#TRUE

And my sessionInfo if that?s of any help:

sessionInfo()

R version 4.1.0 (2021-05-18)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Big Sur 11.5.2

Matrix products: default
LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] data.table_1.14.0

loaded via a namespace (and not attached):
[1] umap_0.2.7.0????? Rcpp_1.0.7??????? knitr_1.33????? ??magrittr_2.0.1?? 
?[5] maps_3.3.0??????? lattice_0.20-44?? rlang_0.4.11????? stringr_1.4.0??? 
?[9] tools_4.1.0?????? grid_4.1.0??????? xfun_0.25???????? png_0.1-7??????? 
[13] audio_0.1-7?????? RSpectra_0.16-0?? htmltools_0.5.1.1 shapefiles_0.7?? 
[17] askpass_1.1?????? openssl_1.4.4???? yaml_2.2.1??????? digest_0.6.27??? 
[21] zip_2.2.0???????? Matrix_1.3-4????? beepr_1.3???????? evaluate_0.14??? 
[25] rmarkdown_2.10??? openxlsx_4.2.4??? sp_1.4-5????????? stringi_1.7.3??? 
[29] compiler_4.1.0??? fossil_0.4.0????? jsonlite_1.7.2??? reticulate_1.20? 
[33] foreign_0.8-81?? 

Best regards

Leonidas Lundell
Postdoc
Barres & Zierath group
?
University of Copenhagen
Novo Nordisk Foundation
Center for Basic Metabolic Research
?
mailto:leo.lundell at sund.ku.dk
?
?




-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 22059 bytes
Desc: image001.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210826/c3ec9058/attachment.png>

From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Aug 26 20:37:23 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 26 Aug 2021 18:37:23 +0000 (UTC)
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
Message-ID: <1522879933.604983.1630003043143@mail.yahoo.com>

 Hi All,
1. the eth is a data frame (not sure that based on error message?) that I load it from excel file. Here is the code:?eth <- read_xlsx("c:/temp/eth.xlsx")
2. I try to use the code to convert eth into eth2, but I got error message:
> eth2 <- data.frame(eth)
Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) :?
? cannot coerce class ?"rxlsx"? to a data.frame

So, it seems the data.frame can not do this data convert? Do you know which statement/function can do this?


thank you for your help.

    On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:  
 
 Kai,

The answer is fairly probable to find? if you examine your variable "eth" as that is the only time you are being asked to provide the argument as in "ggplot(data=eth, ..) ...)

As the message states, it expects that argument to be a data frame or something it can change into a data.frame. What you gave it probably is an object meant to represent an EXCEL file or something. You may need to extract a data.frame (or tibble or ...) from it before passing that to ggplot.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-help
Sent: Thursday, August 26, 2021 11:53 AM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

Hello List,
I got an error message when I submit the code below ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +? geom_rect() +? coord_polar(theta="y")? +? xlim(c(2, 4)? ) 

Error: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx


I checked the syntax. But I can? not find any error on my code. Can you help me to find where is the problem?

Thanks

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Aug 26 21:03:12 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 26 Aug 2021 19:03:12 +0000 (UTC)
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1522879933.604983.1630003043143@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
 <1522879933.604983.1630003043143@mail.yahoo.com>
Message-ID: <1790298022.702404.1630004592959@mail.yahoo.com>

 Hi all,
I found something, but I don't know why it happen.
when I submitted the following code, the Eth is data frame. I can see 14 obs. of 2 variables
library(readxl)
library(ggplot2)
eth <- read_xlsx("c:/temp/eth.xlsx")


but when I add more package (see below,) the Eth is "List of 1"
library(readxl)
library(ggplot2)
library(dplyr)
library(magrittr)
library(knitr)
library(xtable)
library(flextable)
library(officer)
eth <- read_xlsx("c:/temp/eth.xlsx")

But I need those package in future. Is there a way to fix the problem?
Thanks,
Kai    On Thursday, August 26, 2021, 11:37:53 AM PDT, Kai Yang via R-help <r-help at r-project.org> wrote:  
 
  Hi All,
1. the eth is a data frame (not sure that based on error message?) that I load it from excel file. Here is the code:?eth <- read_xlsx("c:/temp/eth.xlsx")
2. I try to use the code to convert eth into eth2, but I got error message:
> eth2 <- data.frame(eth)
Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) :?
? cannot coerce class ?"rxlsx"? to a data.frame

So, it seems the data.frame can not do this data convert? Do you know which statement/function can do this?


thank you for your help.

? ? On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:? 
 
 Kai,

The answer is fairly probable to find? if you examine your variable "eth" as that is the only time you are being asked to provide the argument as in "ggplot(data=eth, ..) ...)

As the message states, it expects that argument to be a data frame or something it can change into a data.frame. What you gave it probably is an object meant to represent an EXCEL file or something. You may need to extract a data.frame (or tibble or ...) from it before passing that to ggplot.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-help
Sent: Thursday, August 26, 2021 11:53 AM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

Hello List,
I got an error message when I submit the code below ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +? geom_rect() +? coord_polar(theta="y")? +? xlim(c(2, 4)? ) 

Error: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx


I checked the syntax. But I can? not find any error on my code. Can you help me to find where is the problem?

Thanks

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From |r@|nj @end|ng |rom gm@||@com  Thu Aug 26 21:16:50 2021
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Thu, 26 Aug 2021 20:16:50 +0100
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1790298022.702404.1630004592959@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
 <1522879933.604983.1630003043143@mail.yahoo.com>
 <1790298022.702404.1630004592959@mail.yahoo.com>
Message-ID: <CAHrK5169etMvudq3vX5iK_ad_M=6mDhGRyiQXA5gZX4ZsVbYHA@mail.gmail.com>

officer redefines the read_xlsx command.  You should have got a message to
that effect when you loaded the officer package.  You can use the version
from the readxl package with

readxl::read_xlsx()  command.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
https://jcfrain.wordpress.com/
https://jcfraincv19.wordpress.com/

mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Thu, 26 Aug 2021 at 20:04, Kai Yang via R-help <r-help at r-project.org>
wrote:

>  Hi all,
> I found something, but I don't know why it happen.
> when I submitted the following code, the Eth is data frame. I can see 14
> obs. of 2 variables
> library(readxl)
> library(ggplot2)
> eth <- read_xlsx("c:/temp/eth.xlsx")
>
>
> but when I add more package (see below,) the Eth is "List of 1"
> library(readxl)
> library(ggplot2)
> library(dplyr)
> library(magrittr)
> library(knitr)
> library(xtable)
> library(flextable)
> library(officer)
> eth <- read_xlsx("c:/temp/eth.xlsx")
>
> But I need those package in future. Is there a way to fix the problem?
> Thanks,
> Kai    On Thursday, August 26, 2021, 11:37:53 AM PDT, Kai Yang via R-help <
> r-help at r-project.org> wrote:
>
>   Hi All,
> 1. the eth is a data frame (not sure that based on error message?) that I
> load it from excel file. Here is the code: eth <-
> read_xlsx("c:/temp/eth.xlsx")
> 2. I try to use the code to convert eth into eth2, but I got error message:
> > eth2 <- data.frame(eth)
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors =
> stringsAsFactors) :
>   cannot coerce class ?"rxlsx"? to a data.frame
>
> So, it seems the data.frame can not do this data convert? Do you know
> which statement/function can do this?
>
>
> thank you for your help.
>
>     On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <
> r-help at r-project.org> wrote:
>
>  Kai,
>
> The answer is fairly probable to find  if you examine your variable "eth"
> as that is the only time you are being asked to provide the argument as in
> "ggplot(data=eth, ..) ...)
>
> As the message states, it expects that argument to be a data frame or
> something it can change into a data.frame. What you gave it probably is an
> object meant to represent an EXCEL file or something. You may need to
> extract a data.frame (or tibble or ...) from it before passing that to
> ggplot.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via
> R-help
> Sent: Thursday, August 26, 2021 11:53 AM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] ggplot error of "`data` must be a data frame, or other object
> coercible by `fortify()`, not an S3 object with class rxlsx"
>
> Hello List,
> I got an error message when I submit the code below ggplot(eth,
> aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +  geom_rect()
> +  coord_polar(theta="y")  +  xlim(c(2, 4)  )
>
> Error: `data` must be a data frame, or other object coercible by
> `fortify()`, not an S3 object with class rxlsx
>
>
> I checked the syntax. But I can  not find any error on my code. Can you
> help me to find where is the problem?
>
> Thanks
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Aug 26 21:17:23 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 26 Aug 2021 12:17:23 -0700
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1790298022.702404.1630004592959@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
 <1522879933.604983.1630003043143@mail.yahoo.com>
 <1790298022.702404.1630004592959@mail.yahoo.com>
Message-ID: <CAHqSRuQ5P6-CjkStpNKz6C5dgbN2i-SCO5CPUP_=FGQ3MQJXew@mail.gmail.com>

The packages "officer" and "readxl" both contain functions named
"read_xlsx".  It looks like you want the one from readxl so refer to it as
readxl::read_xlsx instead of just read_xlsx.

-Bill

On Thu, Aug 26, 2021 at 12:03 PM Kai Yang via R-help <r-help at r-project.org>
wrote:

>  Hi all,
> I found something, but I don't know why it happen.
> when I submitted the following code, the Eth is data frame. I can see 14
> obs. of 2 variables
> library(readxl)
> library(ggplot2)
> eth <- read_xlsx("c:/temp/eth.xlsx")
>
>
> but when I add more package (see below,) the Eth is "List of 1"
> library(readxl)
> library(ggplot2)
> library(dplyr)
> library(magrittr)
> library(knitr)
> library(xtable)
> library(flextable)
> library(officer)
> eth <- read_xlsx("c:/temp/eth.xlsx")
>
> But I need those package in future. Is there a way to fix the problem?
> Thanks,
> Kai    On Thursday, August 26, 2021, 11:37:53 AM PDT, Kai Yang via R-help <
> r-help at r-project.org> wrote:
>
>   Hi All,
> 1. the eth is a data frame (not sure that based on error message?) that I
> load it from excel file. Here is the code: eth <-
> read_xlsx("c:/temp/eth.xlsx")
> 2. I try to use the code to convert eth into eth2, but I got error message:
> > eth2 <- data.frame(eth)
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors =
> stringsAsFactors) :
>   cannot coerce class ?"rxlsx"? to a data.frame
>
> So, it seems the data.frame can not do this data convert? Do you know
> which statement/function can do this?
>
>
> thank you for your help.
>
>     On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <
> r-help at r-project.org> wrote:
>
>  Kai,
>
> The answer is fairly probable to find  if you examine your variable "eth"
> as that is the only time you are being asked to provide the argument as in
> "ggplot(data=eth, ..) ...)
>
> As the message states, it expects that argument to be a data frame or
> something it can change into a data.frame. What you gave it probably is an
> object meant to represent an EXCEL file or something. You may need to
> extract a data.frame (or tibble or ...) from it before passing that to
> ggplot.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via
> R-help
> Sent: Thursday, August 26, 2021 11:53 AM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] ggplot error of "`data` must be a data frame, or other object
> coercible by `fortify()`, not an S3 object with class rxlsx"
>
> Hello List,
> I got an error message when I submit the code below ggplot(eth,
> aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +  geom_rect()
> +  coord_polar(theta="y")  +  xlim(c(2, 4)  )
>
> Error: `data` must be a data frame, or other object coercible by
> `fortify()`, not an S3 object with class rxlsx
>
>
> I checked the syntax. But I can  not find any error on my code. Can you
> help me to find where is the problem?
>
> Thanks
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Thu Aug 26 21:17:42 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 26 Aug 2021 15:17:42 -0400
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <1790298022.702404.1630004592959@mail.yahoo.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
 <1522879933.604983.1630003043143@mail.yahoo.com>
 <1790298022.702404.1630004592959@mail.yahoo.com>
Message-ID: <CAPcHnpT8mGaqnMgDo+f7OUhbAhU_X0Qu-3+ENNcWtrv4y4666A@mail.gmail.com>

Hello,


Package 'officer' has a function 'read_xlsx', so when you attach those
packages in that order, it returns 'read_xlsx' from package 'officer'
instead of 'readxl'. To avoid the confusion, instead of

eth <- read_xlsx("c:/temp/eth.xlsx")

try

eth <- readxl::read_xlsx("c:/temp/eth.xlsx")

which will always refer to the correct function. I can't seem to reproduce
the original error you have, I tried something like:

openxlsx::write.xlsx(data.frame(x = 1:26, y = stats::rnorm(26)), FILE <-
tempfile())
eth <- readxl::read_xlsx(FILE)
eth2 <- as.data.frame(eth)
ggplot2::ggplot(eth2, ggplot2::aes(x = x, y = y))


unlink(FILE)

which just worked as expected.

On Thu, Aug 26, 2021 at 3:03 PM Kai Yang via R-help <r-help at r-project.org>
wrote:

>  Hi all,
> I found something, but I don't know why it happen.
> when I submitted the following code, the Eth is data frame. I can see 14
> obs. of 2 variables
> library(readxl)
> library(ggplot2)
> eth <- read_xlsx("c:/temp/eth.xlsx")
>
>
> but when I add more package (see below,) the Eth is "List of 1"
> library(readxl)
> library(ggplot2)
> library(dplyr)
> library(magrittr)
> library(knitr)
> library(xtable)
> library(flextable)
> library(officer)
> eth <- read_xlsx("c:/temp/eth.xlsx")
>
> But I need those package in future. Is there a way to fix the problem?
> Thanks,
> Kai    On Thursday, August 26, 2021, 11:37:53 AM PDT, Kai Yang via R-help <
> r-help at r-project.org> wrote:
>
>   Hi All,
> 1. the eth is a data frame (not sure that based on error message?) that I
> load it from excel file. Here is the code: eth <-
> read_xlsx("c:/temp/eth.xlsx")
> 2. I try to use the code to convert eth into eth2, but I got error message:
> > eth2 <- data.frame(eth)
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors =
> stringsAsFactors) :
>   cannot coerce class ?"rxlsx"? to a data.frame
>
> So, it seems the data.frame can not do this data convert? Do you know
> which statement/function can do this?
>
>
> thank you for your help.
>
>     On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <
> r-help at r-project.org> wrote:
>
>  Kai,
>
> The answer is fairly probable to find  if you examine your variable "eth"
> as that is the only time you are being asked to provide the argument as in
> "ggplot(data=eth, ..) ...)
>
> As the message states, it expects that argument to be a data frame or
> something it can change into a data.frame. What you gave it probably is an
> object meant to represent an EXCEL file or something. You may need to
> extract a data.frame (or tibble or ...) from it before passing that to
> ggplot.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via
> R-help
> Sent: Thursday, August 26, 2021 11:53 AM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] ggplot error of "`data` must be a data frame, or other object
> coercible by `fortify()`, not an S3 object with class rxlsx"
>
> Hello List,
> I got an error message when I submit the code below ggplot(eth,
> aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +  geom_rect()
> +  coord_polar(theta="y")  +  xlim(c(2, 4)  )
>
> Error: `data` must be a data frame, or other object coercible by
> `fortify()`, not an S3 object with class rxlsx
>
>
> I checked the syntax. But I can  not find any error on my code. Can you
> help me to find where is the problem?
>
> Thanks
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Thu Aug 26 21:26:42 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 26 Aug 2021 15:26:42 -0400
Subject: [R] Potential bug/unexpected behaviour in model matrix
In-Reply-To: <023094CE-40C0-4810-A796-196BE79BF580@ku.dk>
References: <BBE9883E-0580-46C9-A6C5-381DFA083BF4@ku.dk>
 <023094CE-40C0-4810-A796-196BE79BF580@ku.dk>
Message-ID: <CAPcHnpS48ni9cUbycr1tY8FQsXh957vEcMha3mAfY5A9Q=+Ong@mail.gmail.com>

Hello,


I'm not so sure this is a bug, it appears to be behaving as intended from
the documentation. I would suggest using argument 'physical' from 'setkey'
to avoid reordering the rows. Something like:


x <- data.table::data.table(V1 = 9:0)
y <- data.table::copy(x)


data.table::setkey(x, V1, physical = TRUE)
data.table::setkey(y, V1, physical = FALSE)


print(x)
print(y)


attr(x, "index")
attr(y, "index")


'x' does not have an attribute index because the rows were reordered. 'y'
does have an index because its rows weren't reordered. I hope this helps!



On Thu, Aug 26, 2021 at 1:02 PM Leonidas Lundell <leo.lundell at sund.ku.dk>
wrote:

> Dear R-project,
>
> Apologies if I am sending this to the wrong list, and thank you for your
> enormous contribution.
>
> I discovered a subtle interaction between the data.table package and
> model.matrix function that influences the output to the point that you will
> get completely erroneous results:
>
> df  <- data.frame(basespaceID = 8:1, group = paste0(rep(c("a", "b"), 4),
> "_", sort(rep(c("1", "2"), 4))))
> designDF <- model.matrix(~0 + group, data = df)
>
> dt <- data.table::as.data.table(df)
> designDT <- model.matrix(~0 + group, data = dt)
>
> all(designDF == designDT)
> #TRUE
>
> data.table::setkey(dt, "basespaceID")
> designDTkeyed <- model.matrix(~0 + group, data = dt)
>
> all(designDF == designDTkeyed)
> #FALSE
>
> # It seems that a keyed data.table reorders the rows of the design matrix
> by alphabetical order:
>
>  designDFreordered <- model.matrix(~0 + group, data = df[8:1,])
> all(designDFreordered == designDTkeyed)
> #TRUE
>
> And my sessionInfo if that?s of any help:
>
> sessionInfo()
>
> R version 4.1.0 (2021-05-18)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Big Sur 11.5.2
>
> Matrix products: default
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] data.table_1.14.0
>
> loaded via a namespace (and not attached):
> [1] umap_0.2.7.0      Rcpp_1.0.7        knitr_1.33        magrittr_2.0.1
>  [5] maps_3.3.0        lattice_0.20-44   rlang_0.4.11
> stringr_1.4.0
>  [9] tools_4.1.0       grid_4.1.0        xfun_0.25
> png_0.1-7
> [13] audio_0.1-7       RSpectra_0.16-0   htmltools_0.5.1.1
> shapefiles_0.7
> [17] askpass_1.1       openssl_1.4.4     yaml_2.2.1
> digest_0.6.27
> [21] zip_2.2.0         Matrix_1.3-4      beepr_1.3
> evaluate_0.14
> [25] rmarkdown_2.10    openxlsx_4.2.4    sp_1.4-5
> stringi_1.7.3
> [29] compiler_4.1.0    fossil_0.4.0      jsonlite_1.7.2
> reticulate_1.20
> [33] foreign_0.8-81
>
> Best regards
>
> Leonidas Lundell
> Postdoc
> Barres & Zierath group
>
> University of Copenhagen
> Novo Nordisk Foundation
> Center for Basic Metabolic Research
>
> mailto:leo.lundell at sund.ku.dk
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Thu Aug 26 22:17:38 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Thu, 26 Aug 2021 20:17:38 +0000 (UTC)
Subject: [R] Help with clinical trials.gov AACT database
References: <820637952.937014.1630009058438.ref@mail.yahoo.com>
Message-ID: <820637952.937014.1630009058438@mail.yahoo.com>


?Hello, I am trying to use R to access the clinicaltrials.gov AACT database to create a list of facility_investigators for a specific topic.

The following code is an example of how to get a list of all clinical trials on the topic TP53
library(dplyr)
library(RPostgreSQL)

aact = src_postgres(dbname = 'aact',
                    host = "aact-db.ctti-clinicaltrials.org",
                    user = 'aact',
                    password = 'aact')
study_tbl = tbl(src=aact, 'studies')
x  = study_tbl %>% filter(official_title %like% '%TP53%') %>% collect()

Similarly, if I want a list of principal investigators,
library(dplyr)
library(RPostgreSQL)
aact = src_postgres(dbname = 'aact',
                    host = "aact-db.ctti-clinicaltrials.org",
                    user = 'aact',
                    password = 'aact')
study_tbl = tbl(src=aact, 'facility_investigators')

I am unable to make a list on only TP53 facility_investigators. Something like TP53 & facility_investigators. Any help would be appreciated

This is a link where some explanation is provided, but my problem is not resolved -?http://www.cancerdatasci.org/post/2017/03/approaches-to-accessing-clinicaltrials.gov-data/

Sent from Yahoo Mail on Android
	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Aug 27 01:07:19 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 26 Aug 2021 19:07:19 -0400
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <CAHrK5169etMvudq3vX5iK_ad_M=6mDhGRyiQXA5gZX4ZsVbYHA@mail.gmail.com>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
 <1522879933.604983.1630003043143@mail.yahoo.com>
 <1790298022.702404.1630004592959@mail.yahoo.com>
 <CAHrK5169etMvudq3vX5iK_ad_M=6mDhGRyiQXA5gZX4ZsVbYHA@mail.gmail.com>
Message-ID: <03eb01d79acf$1f24eb60$5d6ec220$@verizon.net>

This illustrates many things but in particular, why there is a difference between saying you tried:

 

    class(eth)

 

And saying the function you (think you) called is documented to return a data.frame.

 

Just typing something asking for the class would rapidly have shown it was not a data.frame and also what it was. True, having multiple packages in some order overlay each other is a bit subtle for some and I am glad quite a few people here noticed it. 

 

It may indeed make sense to more fully specify package::function notation in anything you let others use as they may indeed load more packages ?

 

From: John C Frain <frainj at gmail.com> 
Sent: Thursday, August 26, 2021 3:17 PM
To: Kai Yang <yangkai9999 at yahoo.com>
Cc: r-help at r-project.org; Avi Gross <avigross at verizon.net>
Subject: Re: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

 

officer redefines the read_xlsx command.  You should have got a message to that effect when you loaded the officer package.  You can use the version from the readxl package with

 

readxl::read_xlsx()  command.




John C Frain

3 Aranleigh Park

Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html <http://www.tcd.ie/Economics/staff/frainj/home.html> 

https://jcfrain.wordpress.com/

https://jcfraincv19.wordpress.com/


mailto:frainj at tcd.ie <mailto:frainj at tcd.ie> 
mailto:frainj at gmail.com <mailto:frainj at gmail.com> 

 

 

On Thu, 26 Aug 2021 at 20:04, Kai Yang via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

 Hi all,
I found something, but I don't know why it happen.
when I submitted the following code, the Eth is data frame. I can see 14 obs. of 2 variables
library(readxl)
library(ggplot2)
eth <- read_xlsx("c:/temp/eth.xlsx")


but when I add more package (see below,) the Eth is "List of 1"
library(readxl)
library(ggplot2)
library(dplyr)
library(magrittr)
library(knitr)
library(xtable)
library(flextable)
library(officer)
eth <- read_xlsx("c:/temp/eth.xlsx")

But I need those package in future. Is there a way to fix the problem?
Thanks,
Kai    On Thursday, August 26, 2021, 11:37:53 AM PDT, Kai Yang via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:  

  Hi All,
1. the eth is a data frame (not sure that based on error message?) that I load it from excel file. Here is the code: eth <- read_xlsx("c:/temp/eth.xlsx")
2. I try to use the code to convert eth into eth2, but I got error message:
> eth2 <- data.frame(eth)
Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : 
  cannot coerce class ?"rxlsx"? to a data.frame

So, it seems the data.frame can not do this data convert? Do you know which statement/function can do this?


thank you for your help.

    On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:  

 Kai,

The answer is fairly probable to find  if you examine your variable "eth" as that is the only time you are being asked to provide the argument as in "ggplot(data=eth, ..) ...)

As the message states, it expects that argument to be a data frame or something it can change into a data.frame. What you gave it probably is an object meant to represent an EXCEL file or something. You may need to extract a data.frame (or tibble or ...) from it before passing that to ggplot.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Kai Yang via R-help
Sent: Thursday, August 26, 2021 11:53 AM
To: R-help Mailing List <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

Hello List,
I got an error message when I submit the code below ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +  geom_rect() +  coord_polar(theta="y")  +  xlim(c(2, 4)  ) 

Error: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx


I checked the syntax. But I can  not find any error on my code. Can you help me to find where is the problem?

Thanks

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Fri Aug 27 01:42:27 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 26 Aug 2021 23:42:27 +0000 (UTC)
Subject: [R] ggplot error of "`data` must be a data frame,
 or other object coercible by `fortify()`, not an S3 object with class rxlsx"
In-Reply-To: <03eb01d79acf$1f24eb60$5d6ec220$@verizon.net>
References: <1630275966.648706.1629993190721.ref@mail.yahoo.com>
 <1630275966.648706.1629993190721@mail.yahoo.com>
 <00ef01d79a94$f23cff00$d6b6fd00$@verizon.net>
 <1522879933.604983.1630003043143@mail.yahoo.com>
 <1790298022.702404.1630004592959@mail.yahoo.com>
 <CAHrK5169etMvudq3vX5iK_ad_M=6mDhGRyiQXA5gZX4ZsVbYHA@mail.gmail.com>
 <03eb01d79acf$1f24eb60$5d6ec220$@verizon.net>
Message-ID: <1934712831.761026.1630021347600@mail.yahoo.com>

 Thank you all of your help. The error message gone.
    On Thursday, August 26, 2021, 04:07:59 PM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:  
 
 This illustrates many things but in particular, why there is a difference between saying you tried:

 

? ? class(eth)

 

And saying the function you (think you) called is documented to return a data.frame.

 

Just typing something asking for the class would rapidly have shown it was not a data.frame and also what it was. True, having multiple packages in some order overlay each other is a bit subtle for some and I am glad quite a few people here noticed it. 

 

It may indeed make sense to more fully specify package::function notation in anything you let others use as they may indeed load more packages ?

 

From: John C Frain <frainj at gmail.com> 
Sent: Thursday, August 26, 2021 3:17 PM
To: Kai Yang <yangkai9999 at yahoo.com>
Cc: r-help at r-project.org; Avi Gross <avigross at verizon.net>
Subject: Re: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

 

officer redefines the read_xlsx command.? You should have got a message to that effect when you loaded the officer package.? You can use the version from the readxl package with

 

readxl::read_xlsx()? command.




John C Frain

3 Aranleigh Park

Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html <http://www.tcd.ie/Economics/staff/frainj/home.html> 

https://jcfrain.wordpress.com/

https://jcfraincv19.wordpress.com/


mailto:frainj at tcd.ie <mailto:frainj at tcd.ie> 
mailto:frainj at gmail.com <mailto:frainj at gmail.com> 

 

 

On Thu, 26 Aug 2021 at 20:04, Kai Yang via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

 Hi all,
I found something, but I don't know why it happen.
when I submitted the following code, the Eth is data frame. I can see 14 obs. of 2 variables
library(readxl)
library(ggplot2)
eth <- read_xlsx("c:/temp/eth.xlsx")


but when I add more package (see below,) the Eth is "List of 1"
library(readxl)
library(ggplot2)
library(dplyr)
library(magrittr)
library(knitr)
library(xtable)
library(flextable)
library(officer)
eth <- read_xlsx("c:/temp/eth.xlsx")

But I need those package in future. Is there a way to fix the problem?
Thanks,
Kai? ? On Thursday, August 26, 2021, 11:37:53 AM PDT, Kai Yang via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:? 

? Hi All,
1. the eth is a data frame (not sure that based on error message?) that I load it from excel file. Here is the code: eth <- read_xlsx("c:/temp/eth.xlsx")
2. I try to use the code to convert eth into eth2, but I got error message:
> eth2 <- data.frame(eth)
Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : 
? cannot coerce class ?"rxlsx"? to a data.frame

So, it seems the data.frame can not do this data convert? Do you know which statement/function can do this?


thank you for your help.

? ? On Thursday, August 26, 2021, 09:33:51 AM PDT, Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:? 

 Kai,

The answer is fairly probable to find? if you examine your variable "eth" as that is the only time you are being asked to provide the argument as in "ggplot(data=eth, ..) ...)

As the message states, it expects that argument to be a data frame or something it can change into a data.frame. What you gave it probably is an object meant to represent an EXCEL file or something. You may need to extract a data.frame (or tibble or ...) from it before passing that to ggplot.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Kai Yang via R-help
Sent: Thursday, August 26, 2021 11:53 AM
To: R-help Mailing List <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: [R] ggplot error of "`data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx"

Hello List,
I got an error message when I submit the code below ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +? geom_rect() +? coord_polar(theta="y")? +? xlim(c(2, 4)? ) 

Error: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class rxlsx


I checked the syntax. But I can? not find any error on my code. Can you help me to find where is the problem?

Thanks

? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>? mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>? mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
? 
? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>? mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>? mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Fri Aug 27 02:08:06 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Fri, 27 Aug 2021 00:08:06 +0000 (UTC)
Subject: [R] Help with clinical trials.gov AACT database
In-Reply-To: <820637952.937014.1630009058438@mail.yahoo.com>
References: <820637952.937014.1630009058438.ref@mail.yahoo.com>
 <820637952.937014.1630009058438@mail.yahoo.com>
Message-ID: <1676597745.947961.1630022886660@mail.yahoo.com>

 I am completely stuck here, any help would be greatly appreciated!
    On Thursday, 26 August, 2021, 04:18:31 pm GMT-4, bharat rawlley via R-help <r-help at r-project.org> wrote:  
 
 
?Hello, I am trying to use R to access the clinicaltrials.gov AACT database to create a list of facility_investigators for a specific topic.

The following code is an example of how to get a list of all clinical trials on the topic TP53
library(dplyr)
library(RPostgreSQL)

aact = src_postgres(dbname = 'aact',
? ? ? ? ? ? ? ? ? ? host = "aact-db.ctti-clinicaltrials.org",
? ? ? ? ? ? ? ? ? ? user = 'aact',
? ? ? ? ? ? ? ? ? ? password = 'aact')
study_tbl = tbl(src=aact, 'studies')
x? = study_tbl %>% filter(official_title %like% '%TP53%') %>% collect()

Similarly, if I want a list of principal investigators,
library(dplyr)
library(RPostgreSQL)
aact = src_postgres(dbname = 'aact',
? ? ? ? ? ? ? ? ? ? host = "aact-db.ctti-clinicaltrials.org",
? ? ? ? ? ? ? ? ? ? user = 'aact',
? ? ? ? ? ? ? ? ? ? password = 'aact')
study_tbl = tbl(src=aact, 'facility_investigators')

I am unable to make a list on only TP53 facility_investigators. Something like TP53 & facility_investigators. Any help would be appreciated

This is a link where some explanation is provided, but my problem is not resolved -?http://www.cancerdatasci.org/post/2017/03/approaches-to-accessing-clinicaltrials.gov-data/

Sent from Yahoo Mail on Android
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Aug 27 08:17:37 2021
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 27 Aug 2021 06:17:37 +0000
Subject: [R] showing the complexity of r code.....
Message-ID: <SLXP216MB0288D22B101ACBB772356A2CC8C89@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am a stock trader and a data science freelancer.  I am weighing the advantages of taking a R course in coursera to show my proficiency in R in some freelancing sites. But I have already done extensive research on Stock trading and data science, using R. How do I show that I am proficient in R, given my workspace? For example, can I show the total size of my workspace and the size of the functions I have created? Any other ideas?

Yours sincerely,
AKSHAY M KULKARNI



	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Aug 27 09:06:53 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 27 Aug 2021 10:06:53 +0300
Subject: [R] showing the complexity of r code.....
In-Reply-To: <SLXP216MB0288D22B101ACBB772356A2CC8C89@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
References: <SLXP216MB0288D22B101ACBB772356A2CC8C89@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
Message-ID: <0645A76D-6651-410D-ABDD-8E1B010393B1@gmail.com>

One approach would be to put some (non-confidential) projects on a site such as GitHub so that people can examine your work.

Sent from my iPhone

> On 27 Aug 2021, at 9:18, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> ?dear members,
>                            I am a stock trader and a data science freelancer.  I am weighing the advantages of taking a R course in coursera to show my proficiency in R in some freelancing sites. But I have already done extensive research on Stock trading and data science, using R. How do I show that I am proficient in R, given my workspace? For example, can I show the total size of my workspace and the size of the functions I have created? Any other ideas?
> 
> Yours sincerely,
> AKSHAY M KULKARNI
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zwj|08 @end|ng |rom gm@||@com  Fri Aug 27 13:11:06 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Fri, 27 Aug 2021 19:11:06 +0800
Subject: [R] showing the complexity of r code.....
In-Reply-To: <SLXP216MB0288D22B101ACBB772356A2CC8C89@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
References: <SLXP216MB0288D22B101ACBB772356A2CC8C89@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGiFhPPj1G5Y28CdG_ogLysAJCNZSOdxU90dtbgQfv7PqD9wfQ@mail.gmail.com>

Hi,

It all depends on the R skill level of your audience. If they are also
programmers, show them your Github page and a list of the packages you
made would be great. If they do not have any R experience, do some
work on R shiny, tell them you can do all kinds of magic things with
the data, and visualize the result.

Cheers,
Jiefei

On Fri, Aug 27, 2021 at 2:18 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear members,
>                             I am a stock trader and a data science freelancer.  I am weighing the advantages of taking a R course in coursera to show my proficiency in R in some freelancing sites. But I have already done extensive research on Stock trading and data science, using R. How do I show that I am proficient in R, given my workspace? For example, can I show the total size of my workspace and the size of the functions I have created? Any other ideas?
>
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @dr|@n @end|ng |rom tr@p|ett|@org  Fri Aug 27 16:39:40 2021
From: @dr|@n @end|ng |rom tr@p|ett|@org (Adrian Trapletti)
Date: Fri, 27 Aug 2021 16:39:40 +0200
Subject: [R] Augmented Dickie-Fuller test (Nick Wray)
Message-ID: <CAFmikf2d1kwHfuQP4cnByfwfN5GwuoNm2Vniy1bGMNQ681iEpg@mail.gmail.com>

Hi Nick,

If you are using adf.test() from tseries, then the reason is the
linear trend incorporated into the regression. From the help: "The
general regression equation which incorporates a constant and a linear
trend is used and the t-statistic for a first order autoregressive
coefficient equals one is computed."

Regress the data on a constant and a linear trend and check the residuals.

Cheers,
Adrian

Adrian Trapletti

Steinstrasse 9b, 8610 Uster, Switzerland
P +41 44 994 56 30  |  M +41 79 103 71 31
adrian at trapletti.org  |  www.trapletti.org


On Fri, Aug 27, 2021 at 12:00 PM <r-help-request at r-project.org> wrote:
>
> Send R-help mailing list submissions to
>         r-help at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-help
> or, via email, send a message with subject or body 'help' to
>         r-help-request at r-project.org
>
> You can reach the person managing the list at
>         r-help-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-help digest..."
>
>
> Today's Topics:
>
>    1. Augmented Dickie-Fuller test (Nick Wray)
>    2. ggplot error of "`data` must be a data frame, or other object
>       coercible by `fortify()`, not an S3 object with class rxlsx"
>       (Kai Yang)
>    3. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Thierry Onkelinx)
>    4. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Andrew Simmons)
>    5. Re: Augmented Dickie-Fuller test (John C Frain)
>    6. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Avi Gross)
>    7. Potential bug/unexpected behaviour in model matrix
>       (Leonidas Lundell)
>    8. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Kai Yang)
>    9. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Kai Yang)
>   10. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (John C Frain)
>   11. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Bill Dunlap)
>   12. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Andrew Simmons)
>   13. Re: Potential bug/unexpected behaviour in model matrix
>       (Andrew Simmons)
>   14. Help with clinical trials.gov AACT database (bharat rawlley)
>   15. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Avi Gross)
>   16. Re: ggplot error of "`data` must be a data frame, or other
>       object coercible by `fortify()`, not an S3 object with class
>       rxlsx" (Kai Yang)
>   17. Re: Help with clinical trials.gov AACT database (bharat rawlley)
>   18. showing the complexity of r code..... (akshay kulkarni)
>   19. Re: showing the complexity of r code..... (Eric Berger)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 26 Aug 2021 14:23:16 +0100
> From: Nick Wray <nickmwray at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Augmented Dickie-Fuller test
> Message-ID:
>         <CABxY9BPhLpNwBThX107zT=9q48rxCfSUutH5+5H+d6A10mZ35w at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hello: I've downloaded this dataset, and when I plot it it is clearly
> non-stationary
>
>
> df <- read.csv('
> https://raw.githubusercontent.com/ourcodingclub/CC-time-series/master/monthly_milk.csv
> ')
>
> plot(df,type="l")
>
> But when I apply the Augmented Dickie-Fuller Test I get a p value of 0.01,
> implying that there is evidence to reject the null that the series is
> non-stationary. I am puzzled as to why this is happening. Is this because
> the confidence level is basically too high or is something else going on?
>
> adf.test(df[,2])
>
> Augmented Dickey-Fuller Test
>
> data: df[, 2] Dickey-Fuller = -9.9714, Lag order = 5, p-value = 0.01
> alternative hypothesis: stationary
>
> Thanks Nick Wray
>


From tg@77m @end|ng |rom y@hoo@com  Fri Aug 27 19:30:38 2021
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Fri, 27 Aug 2021 10:30:38 -0700
Subject: [R] uniroot
References: <001101d79b69$412eb390$c38c1ab0$.ref@yahoo.com>
Message-ID: <001101d79b69$412eb390$c38c1ab0$@yahoo.com>

Colleagues,

I've been using uniroot to identify a root of an equation. 
As a check, I always verify that calculated root. 
This is where I need some help.

Consider the following script

fun <- function(x) {x^x -23}

# Clearly the root lies somewhere between 2.75 and 3.00

uniroot(fun, lower = 2.75, upper = 3.00,  tol = 0.001)

# output
$root
[1] 2.923125

$f.root
[1] 0.0001136763

# Let's verify this root.

2.923125^2.923125 - 23

0.0001222225

This result is different than what was calculated with uniroot
0.0001222225		# verified check using x = 2.923125
0.0001136763		# using $f.root

Does this imply that the root output of  2.923125 may need more significant
digits displayed?

I suspect that whatever root is calculated, that root may well be dependent
on what interval one defines where the root may occur
and what tolerance one has input.
I am not sure that is the case, nevertheless, it's worth asking the
question.

Some guidance would be appreciated.

Thanks!

Thomas Subia


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 27 19:42:18 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Aug 2021 10:42:18 -0700
Subject: [R] uniroot
In-Reply-To: <001101d79b69$412eb390$c38c1ab0$@yahoo.com>
References: <001101d79b69$412eb390$c38c1ab0$.ref@yahoo.com>
 <001101d79b69$412eb390$c38c1ab0$@yahoo.com>
Message-ID: <720CDE6B-D0F8-4399-B90A-58DA91723ACB@dcn.davis.ca.us>

Yes. This kind of issue is covered in any decent undergraduate course in numerical methods... it is not specific to R. It is also related to FAQ 7.31.
 https://en.m.wikipedia.org/wiki/Root-finding_algorithms

https://en.m.wikipedia.org/wiki/Floating-point_arithmetic#Representable_numbers,_conversion_and_rounding

On August 27, 2021 10:30:38 AM PDT, Thomas Subia via R-help <r-help at r-project.org> wrote:
>Colleagues,
>
>I've been using uniroot to identify a root of an equation. 
>As a check, I always verify that calculated root. 
>This is where I need some help.
>
>Consider the following script
>
>fun <- function(x) {x^x -23}
>
># Clearly the root lies somewhere between 2.75 and 3.00
>
>uniroot(fun, lower = 2.75, upper = 3.00,  tol = 0.001)
>
># output
>$root
>[1] 2.923125
>
>$f.root
>[1] 0.0001136763
>
># Let's verify this root.
>
>2.923125^2.923125 - 23
>
>0.0001222225
>
>This result is different than what was calculated with uniroot
>0.0001222225		# verified check using x = 2.923125
>0.0001136763		# using $f.root
>
>Does this imply that the root output of  2.923125 may need more significant
>digits displayed?
>
>I suspect that whatever root is calculated, that root may well be dependent
>on what interval one defines where the root may occur
>and what tolerance one has input.
>I am not sure that is the case, nevertheless, it's worth asking the
>question.
>
>Some guidance would be appreciated.
>
>Thanks!
>
>Thomas Subia
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug 27 20:52:24 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 27 Aug 2021 19:52:24 +0100
Subject: [R] uniroot
In-Reply-To: <720CDE6B-D0F8-4399-B90A-58DA91723ACB@dcn.davis.ca.us>
References: <001101d79b69$412eb390$c38c1ab0$.ref@yahoo.com>
 <001101d79b69$412eb390$c38c1ab0$@yahoo.com>
 <720CDE6B-D0F8-4399-B90A-58DA91723ACB@dcn.davis.ca.us>
Message-ID: <6d1488e8-57c2-f78f-fcb2-327c303925a8@sapo.pt>

Hello,

Yes, it's FAQ 7.31 but it's not uniroot's fault.
The proper way of checking the result would be to call the function fun, 
not to take the digits output by the print method and compute the 
function's expression with them.



rui at rui:~$ R -q -f rhelp.R
fun <- function(x) {x^x -23}

# Clearly the root lies somewhere between 2.75 and 3.00
x0 <- uniroot(fun, lower = 2.75, upper = 3.00,  tol = 0.001)

# uniroot result
x0$f.root
#[1] 0.0001136763

# check the root, right
fun(x0$root)
#[1] 0.0001136763

# OP result, wrong
2.923125^2.923125 - 23
#[1] 0.0001222225


sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.1.1


Also, why change the default tol to a lesser one?


Hope this helps,

Rui Barradas


?s 18:42 de 27/08/21, Jeff Newmiller escreveu:
> Yes. This kind of issue is covered in any decent undergraduate course in numerical methods... it is not specific to R. It is also related to FAQ 7.31.
>   https://en.m.wikipedia.org/wiki/Root-finding_algorithms
> 
> https://en.m.wikipedia.org/wiki/Floating-point_arithmetic#Representable_numbers,_conversion_and_rounding
> 
> On August 27, 2021 10:30:38 AM PDT, Thomas Subia via R-help <r-help at r-project.org> wrote:
>> Colleagues,
>>
>> I've been using uniroot to identify a root of an equation.
>> As a check, I always verify that calculated root.
>> This is where I need some help.
>>
>> Consider the following script
>>
>> fun <- function(x) {x^x -23}
>>
>> # Clearly the root lies somewhere between 2.75 and 3.00
>>
>> uniroot(fun, lower = 2.75, upper = 3.00,  tol = 0.001)
>>
>> # output
>> $root
>> [1] 2.923125
>>
>> $f.root
>> [1] 0.0001136763
>>
>> # Let's verify this root.
>>
>> 2.923125^2.923125 - 23
>>
>> 0.0001222225
>>
>> This result is different than what was calculated with uniroot
>> 0.0001222225		# verified check using x = 2.923125
>> 0.0001136763		# using $f.root
>>
>> Does this imply that the root output of  2.923125 may need more significant
>> digits displayed?
>>
>> I suspect that whatever root is calculated, that root may well be dependent
>> on what interval one defines where the root may occur
>> and what tolerance one has input.
>> I am not sure that is the case, nevertheless, it's worth asking the
>> question.
>>
>> Some guidance would be appreciated.
>>
>> Thanks!
>>
>> Thomas Subia
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 28 03:19:01 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Aug 2021 13:19:01 +1200
Subject: [R] A glitch (???) in tools::texi2pf.
Message-ID: <20210828131901.2394f863@rolf-Latitude-E7470>


I have found that tools::texi2pf() ignores changes to the *.bib file
unless the *.bbl file is removed prior to re-running tools::texi2pdf().
I have constructed a minimal reproducible example which is contained
in the attached file "mreprex.txt".

This *.txt file should be split into two files, mreprex.tex and
mreprex.bib.  (I wasn't sure whether *.tex and *.bib files would make
it through to the list.)

After doing the splitting, start R, execute

tools::texi2pf("mreprex.tex")

and view the resulting mreprex.pdf file.  Then edit mreprex.bib
and change (e.g.) the version number from "0.0-21" to "0.0-22".

Re-run tools::texi2pf("mreprex.tex") and view mreprex.pdf.  You will
see that it hasn't changed; the version number cited is still given as
0.0-21.  Now remove mreprex.bbl, re-run tools::texi2pf("mreprex.tex")
and view mreprex.pdf.  You will see that the version number is given as
0.0-22 as it should be.

Should this be considered a bug?  If so, what is the appropriate way of
drawing this to the attention of those who have the power to fix it?

Thanks.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mreprex.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210828/5cde37f8/attachment.txt>

From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Sat Aug 28 09:47:03 2021
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Sat, 28 Aug 2021 09:47:03 +0200 (CEST)
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <20210828131901.2394f863@rolf-Latitude-E7470>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
Message-ID: <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>

On Sat, 28 Aug 2021, Rolf Turner wrote:

> I have found that tools::texi2pf() ignores changes to the *.bib file
> unless the *.bbl file is removed prior to re-running tools::texi2pdf().

This is how texi2pdf (or actually texi2dvi) from texinfo behaves. This is 
likely what tools::texi2pdf calles in your setup anyway. In short, 
texi2dvi considers the .bbl as input files to the .tex and does not remove 
them if they are available prior to calling texi2dvi.

Alternatives:

(1) You can always re-run everything. Then simply start with a clean 
directory and always use tools::texi2pdf(..., clean = TRUE). This cleans 
up all the files it has produced (except the .pdf). But it will preserve 
files left in the directory from previous runs.

(2) You can detect upstream changes, e.g., based on timestamps etc. Then 
the traditional approach would be to use a Makefile.

Best,
Z

> I have constructed a minimal reproducible example which is contained
> in the attached file "mreprex.txt".
>
> This *.txt file should be split into two files, mreprex.tex and
> mreprex.bib.  (I wasn't sure whether *.tex and *.bib files would make
> it through to the list.)
>
> After doing the splitting, start R, execute
>
> tools::texi2pf("mreprex.tex")
>
> and view the resulting mreprex.pdf file.  Then edit mreprex.bib
> and change (e.g.) the version number from "0.0-21" to "0.0-22".
>
> Re-run tools::texi2pf("mreprex.tex") and view mreprex.pdf.  You will
> see that it hasn't changed; the version number cited is still given as
> 0.0-21.  Now remove mreprex.bbl, re-run tools::texi2pf("mreprex.tex")
> and view mreprex.pdf.  You will see that the version number is given as
> 0.0-22 as it should be.
>
> Should this be considered a bug?  If so, what is the appropriate way of
> drawing this to the attention of those who have the power to fix it?
>
> Thanks.
>
> cheers,
>
> Rolf Turner
>
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 28 11:38:55 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Aug 2021 21:38:55 +1200
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
Message-ID: <20210828213855.07e32063@rolf-Latitude-E7470>


On Sat, 28 Aug 2021 09:47:03 +0200
Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:

> On Sat, 28 Aug 2021, Rolf Turner wrote:
> 
> > I have found that tools::texi2pf() ignores changes to the *.bib file
> > unless the *.bbl file is removed prior to re-running
> > tools::texi2pdf().
> 
> This is how texi2pdf (or actually texi2dvi) from texinfo behaves.
> This is likely what tools::texi2pdf calles in your setup anyway. In
> short, texi2dvi considers the .bbl as input files to the .tex and
> does not remove them if they are available prior to calling texi2dvi.
> 
> Alternatives:
> 
> (1) You can always re-run everything. Then simply start with a clean 
> directory and always use tools::texi2pdf(..., clean = TRUE). This
> cleans up all the files it has produced (except the .pdf). But it
> will preserve files left in the directory from previous runs.
> 
> (2) You can detect upstream changes, e.g., based on timestamps etc.
> Then the traditional approach would be to use a Makefile.
> 
> Best,
> Z

Thanks.  I guess you're saying that it's a feature, not a bug. :-)

Well it's a feature that I intensely dislike, but that cuts no ice I'm
sure, and I'll just have to cope with it. I can easily build a local
function that will remove *.bbl before invoking tools::texi2pdf(),
and use that, rather than calling tools::texi2pdf() directly.

However I *really* believe that this is a bad feature, and is a Trap
For Young Players.  Hardly anyone knows what a *.bbl is or is for.
Users would expect that changing the *.bib file would change the
reference list in the output.  (I.e. that texi2pdf() would re-run
bibtex "under the bonnet", as the user would do if processing from the
OS command line rather than applying texi2pdf() from R.)

I wonder how many papers in the R Journal have errors in their
reference lists due to the fact that authors corrected the *.bib file,
reprocessed using texi2pdf() and did not notice that the error they
corrected had *not* been corrected in the *.pdf output?

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From er|cjberger @end|ng |rom gm@||@com  Sat Aug 28 11:49:04 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 28 Aug 2021 12:49:04 +0300
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <20210828213855.07e32063@rolf-Latitude-E7470>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
 <20210828213855.07e32063@rolf-Latitude-E7470>
Message-ID: <CAGgJW77Xi=Dn6uh17KtDst6ji17L15oy4rfCAfaRhow5RCHw2g@mail.gmail.com>

As Achim wrote in point (2), Makefile is your friend.


On Sat, Aug 28, 2021 at 12:39 PM Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> On Sat, 28 Aug 2021 09:47:03 +0200
> Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
>
> > On Sat, 28 Aug 2021, Rolf Turner wrote:
> >
> > > I have found that tools::texi2pf() ignores changes to the *.bib file
> > > unless the *.bbl file is removed prior to re-running
> > > tools::texi2pdf().
> >
> > This is how texi2pdf (or actually texi2dvi) from texinfo behaves.
> > This is likely what tools::texi2pdf calles in your setup anyway. In
> > short, texi2dvi considers the .bbl as input files to the .tex and
> > does not remove them if they are available prior to calling texi2dvi.
> >
> > Alternatives:
> >
> > (1) You can always re-run everything. Then simply start with a clean
> > directory and always use tools::texi2pdf(..., clean = TRUE). This
> > cleans up all the files it has produced (except the .pdf). But it
> > will preserve files left in the directory from previous runs.
> >
> > (2) You can detect upstream changes, e.g., based on timestamps etc.
> > Then the traditional approach would be to use a Makefile.
> >
> > Best,
> > Z
>
> Thanks.  I guess you're saying that it's a feature, not a bug. :-)
>
> Well it's a feature that I intensely dislike, but that cuts no ice I'm
> sure, and I'll just have to cope with it. I can easily build a local
> function that will remove *.bbl before invoking tools::texi2pdf(),
> and use that, rather than calling tools::texi2pdf() directly.
>
> However I *really* believe that this is a bad feature, and is a Trap
> For Young Players.  Hardly anyone knows what a *.bbl is or is for.
> Users would expect that changing the *.bib file would change the
> reference list in the output.  (I.e. that texi2pdf() would re-run
> bibtex "under the bonnet", as the user would do if processing from the
> OS command line rather than applying texi2pdf() from R.)
>
> I wonder how many papers in the R Journal have errors in their
> reference lists due to the fact that authors corrected the *.bib file,
> reprocessed using texi2pdf() and did not notice that the error they
> corrected had *not* been corrected in the *.pdf output?
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 28 12:18:10 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Aug 2021 22:18:10 +1200
Subject: [R] Configure error: checking if libcurl supports https... no
Message-ID: <20210828221810.7306dfde@rolf-Latitude-E7470>


I'm getting results from a package which differ from results that I got
a few weeks ago, and the only thing that I can think of that's changed
is the version of R (from 4.1.0 to 4.4.1).

So I wanted to install 4.1.0 and play around with that, to see if that
is indeed the explanation.  (If that is so, a whole new set of
questions would be raised, but let's leave that for the moment.)  I
downloaded the tarball and set about installing 4.1.0 from source.  But
the configure step threw an error, as given in the subject line of
this message.  The error went on:

> configure: error: libcurl >= 7.28.0 library and headers are required
> with support for https

A bit of web searching turned up the advice to re-install curl
using

    sudo apt-get install curl

but when I did that I was informed that:

> curl is already the newest version (7.68.0-1ubuntu2.6).

Has anyone got any *useful* advice?  If so, please present it
in very simple terms if you can.  (I am a Bear of Very Little Brain,
and long words bother me.)  A step-by-step recipe would be appreciated.

I'm running Ubuntu 20.04, with a Mate 1.24.0 desktop.

Grateful for any pearls of wisdom.

cheers,

Rolf Turner

P.S. The config.log file seems to be full of stuff relating to errors
from "openssl.c" but this is *way* beyond my pay grade.

R. T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Sat Aug 28 14:38:49 2021
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Sat, 28 Aug 2021 14:38:49 +0200 (CEST)
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <20210828213855.07e32063@rolf-Latitude-E7470>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
 <20210828213855.07e32063@rolf-Latitude-E7470>
Message-ID: <fa594ee9-824d-8cb2-b39-c421be318a1c@uibk.ac.at>

On Sat, 28 Aug 2021, Rolf Turner wrote:

>
> On Sat, 28 Aug 2021 09:47:03 +0200
> Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
>
>> On Sat, 28 Aug 2021, Rolf Turner wrote:
>>
>>> I have found that tools::texi2pf() ignores changes to the *.bib file
>>> unless the *.bbl file is removed prior to re-running
>>> tools::texi2pdf().
>>
>> This is how texi2pdf (or actually texi2dvi) from texinfo behaves.
>> This is likely what tools::texi2pdf calles in your setup anyway. In
>> short, texi2dvi considers the .bbl as input files to the .tex and
>> does not remove them if they are available prior to calling texi2dvi.
>>
>> Alternatives:
>>
>> (1) You can always re-run everything. Then simply start with a clean
>> directory and always use tools::texi2pdf(..., clean = TRUE). This
>> cleans up all the files it has produced (except the .pdf). But it
>> will preserve files left in the directory from previous runs.
>>
>> (2) You can detect upstream changes, e.g., based on timestamps etc.
>> Then the traditional approach would be to use a Makefile.
>>
>> Best,
>> Z
>
> Thanks.  I guess you're saying that it's a feature, not a bug. :-)

Also. But the main point is that it's a feature of texi2dvi from texinfo 
which is called by tools::texi2dvi(). Hence, if you want to raise this 
somewhere it would have to be with the texinfo maintainers.

> Well it's a feature that I intensely dislike, but that cuts no ice I'm
> sure, and I'll just have to cope with it. I can easily build a local
> function that will remove *.bbl before invoking tools::texi2pdf(),
> and use that, rather than calling tools::texi2pdf() directly.
>
> However I *really* believe that this is a bad feature, and is a Trap For 
> Young Players.  Hardly anyone knows what a *.bbl is or is for. Users 
> would expect that changing the *.bib file would change the reference 
> list in the output.  (I.e. that texi2pdf() would re-run bibtex "under 
> the bonnet", as the user would do if processing from the OS command line 
> rather than applying texi2pdf() from R.)

The problem is that currently texi2dvi has no concept of judging whether 
the .bib or .bbl were modified last.

> I wonder how many papers in the R Journal have errors in their
> reference lists due to the fact that authors corrected the *.bib file,
> reprocessed using texi2pdf() and did not notice that the error they
> corrected had *not* been corrected in the *.pdf output?

I don't know what the R Journal editors are doing but for JSS I'm cleaning 
such files up (repeatedly actually) before compiling the final PDFs.

Best,
Z


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 28 15:14:35 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 29 Aug 2021 01:14:35 +1200
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <CAGgJW77Xi=Dn6uh17KtDst6ji17L15oy4rfCAfaRhow5RCHw2g@mail.gmail.com>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
 <20210828213855.07e32063@rolf-Latitude-E7470>
 <CAGgJW77Xi=Dn6uh17KtDst6ji17L15oy4rfCAfaRhow5RCHw2g@mail.gmail.com>
Message-ID: <20210829011435.32419924@rolf-Latitude-E7470>


On Sat, 28 Aug 2021 12:49:04 +0300
Eric Berger <ericjberger at gmail.com> wrote:

> As Achim wrote in point (2), Makefile is your friend.

Well, all I can say is that Makefile is *not* my friend; I have never
made its acquaintance and wouldn't know where to begin looking.

Would it be possible for you to provide a template/prototype Makefile
and give me some idea what to *do* with it?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Aug 28 15:24:23 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 28 Aug 2021 09:24:23 -0400
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <20210829011435.32419924@rolf-Latitude-E7470>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
 <20210828213855.07e32063@rolf-Latitude-E7470>
 <CAGgJW77Xi=Dn6uh17KtDst6ji17L15oy4rfCAfaRhow5RCHw2g@mail.gmail.com>
 <20210829011435.32419924@rolf-Latitude-E7470>
Message-ID: <c8feaf61-2a0f-e581-d0fa-9a2f41bf97c5@gmail.com>

I can understand Rolf's concern. Make is a tool that is very helpful,
but also not trivial to learn how to make work. If a good Makefile
has been set up, then things are easy, but I've generally found my
skills limited to fairly simple Makefiles.

I would suggest that what is needed is a bit of modest collaboration
to set up a Makefile for dealing with this issue that has enough comments
so it is clear what Make will be doing. I suspect that in this case the
need is to remove the offending .bbl file and then run the tex*** operations.
Possibly the result is small enough to post in this thread. Anyone?

Cheers, JN



On 2021-08-28 9:14 a.m., Rolf Turner wrote:
> 
> On Sat, 28 Aug 2021 12:49:04 +0300
> Eric Berger <ericjberger at gmail.com> wrote:
> 
>> As Achim wrote in point (2), Makefile is your friend.
> 
> Well, all I can say is that Makefile is *not* my friend; I have never
> made its acquaintance and wouldn't know where to begin looking.
> 
> Would it be possible for you to provide a template/prototype Makefile
> and give me some idea what to *do* with it?
> 
> cheers,
> 
> Rolf Turner
>


From e||z@_botto @end|ng |rom out|ook@com  Sat Aug 28 17:57:09 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Sat, 28 Aug 2021 15:57:09 +0000
Subject: [R] Finding if numbers fall within a range
Message-ID: <AS8P194MB09991D0DA6E6FB9AACFEA4629AC99@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Dear useRs,

Is there a way in R to see if the numbers in a matrix-row fall within the given range or not? For example, I have the following data;

> dput(EB)

structure(c(1, 57, 59, 271, 279, 59, 179, 279, 278, 359, 52,
118, 178, 239, 334), .Dim = c(3L, 5L))

The ranges for which these numbers are to be reserved are;

0-60, 61-120, 121-180, 181-240, 241-300, 301-360

In row 1, the number "1", "57", and "59" fall 2ith the range 0-60. Whereas "271" and "279" falls within the range 241-300. So in total 2 ranges are covered and coding should execute 2 for row one.

In row 2, the number "59" falls in the range 0-60, "179" falls in the range 121-180, "279" and "278" fall within the range 241-300, and 359 falls in the range 301-360. In total 4 ranges are covered for row 2.

In the like-wise pattern, 5 ranges are covered in row 3.

So, what I want is a matrix that looks in the following

> dput(EBI)

structure(c(2, 4, 5), .Dim = c(3L, 1L))

Is there an easy way of doing it?

I thank you all very much in advance

EB

	[[alternative HTML version deleted]]


From Den|@@Cou@|ne@u @end|ng |rom uott@w@@c@  Thu Aug 26 12:56:52 2021
From: Den|@@Cou@|ne@u @end|ng |rom uott@w@@c@ (Denis Cousineau)
Date: Thu, 26 Aug 2021 10:56:52 +0000
Subject: [R] [R-pkgs] summary plots with adjusted error bar: A Shiny
 interface
Message-ID: <YQXPR0101MB082351072BA906CD5E0E69C69CC79@YQXPR0101MB0823.CANPRD01.PROD.OUTLOOK.COM>


Dear all,

This short email to inform you that a new version  of *superb* (SUmmary Plots with adjusted ERror Bars) is now available on CRAN (version 0.9.7.5; codename "two-tail 95% confident").

This package lets you generate plots with correct error bars without heavy programming. I know that this does not concern you, users of this mailing list, but you certainly know people around you for which plotting error bars and adjusting these to the experimental design is a challenge. Please share this announcement.

The package now comes with a shiny interface, launched from within R with the command superbShiny().

It is also available online for those who don't have R, from https://dcousin3.shinyapps.io/superbshiny/

Finally, a brief tutorial on YouTube can be found at https://www.youtube.com/watch?v=rw_6ll5nVus

Plotting error bars has never been so easy!

You can read more from this recently published article to *Advances in Methods and Practices in Psychological Science* (doi: https://doi.org/10.1177/25152459211035109).

All the best,
Denis, Marc-Andr? and Brad!

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dj@ndr|j@ @end|ng |rom gm@||@com  Thu Aug 26 13:50:30 2021
From: dj@ndr|j@ @end|ng |rom gm@||@com (Andrija Djurovic)
Date: Thu, 26 Aug 2021 13:50:30 +0200
Subject: [R] [R-pkgs] monobinShiny: Shiny User Interface for 'monobin'
 Package
Message-ID: <CABcwgRRpdX-Mv+Vm4dpYUcvRNX0qvO4Fr0keJkbG4nMTgWuCPg@mail.gmail.com>

Dear R users,

I am happy to announce that my new package monobinShiny is now available on
CRAN.
This is an add-on package to the 'monobin' package that simplifies its use.
As reminder, the goal of 'monobin' is to perform monotonic binning of
numeric risk factor in credit rating models (PD, LGD, EAD) development. All
functions handle both binary and continuous target variable. Missing values
and other possible special values are treated separately from so-called
complete cases.

'monobinShiny' provides shiny-based user interface to 'monobin' package and
it can be especially handy for less experienced R users as well as for
those who intend to perform quick scanning of numeric risk factors when
building credit rating models. The additional functions implemented in
'monobinShiny' that do no exist in 'monobin' package are: descriptive
statistics, special case and outliers imputation. The function descriptive
statistics is exported and can be used in R sessions independently from the
user interface, while the special case and the outlier imputation functions
are written to be used with shiny UI.

Here is, also, the link to github page:
https://github.com/andrija-djurovic/monobinShiny

Hope that some of you will find the package useful.

Best regards,
Andrija Djurovic

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @kw@|mmo @end|ng |rom gm@||@com  Sat Aug 28 18:20:12 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Sat, 28 Aug 2021 12:20:12 -0400
Subject: [R] Finding if numbers fall within a range
In-Reply-To: <AS8P194MB09991D0DA6E6FB9AACFEA4629AC99@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB09991D0DA6E6FB9AACFEA4629AC99@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CAPcHnpSpJg6ix2Mei9tygGyF4juAM5otOZepYfZEX2N5++R7rw@mail.gmail.com>

Hello,


I think I've found a solution, but it's not producing the same answer as
what you're expecting. I think you might've mixed up row and column a few
times, but you should be able to alter the following to your needs. Also,
see ?.bincode:


EB <- matrix(data = c(
      1, 271, 179, 359, 178,
     57, 279, 279,  52, 239,
     59,  59, 278, 118, 334
), nrow = 3, ncol = 5, byrow = TRUE)


# ranges <- list(
#     c(  0,  60),
#     c( 61, 120),
#     c(121, 180),
#     c(181, 240),
#     c(241, 300),
#     c(301, 360)
# )
breaks <- seq.int(0, 360, 60)


codes <- .bincode(EB, breaks, include.lowest = TRUE)
dim(codes) <- dim(EB)


num.ranges <- apply(codes, 1, function(xx) length(unique(xx)))


I hope this helps!

On Sat, Aug 28, 2021 at 11:57 AM Eliza Botto <eliza_botto at outlook.com>
wrote:

> Dear useRs,
>
> Is there a way in R to see if the numbers in a matrix-row fall within the
> given range or not? For example, I have the following data;
>
> > dput(EB)
>
> structure(c(1, 57, 59, 271, 279, 59, 179, 279, 278, 359, 52,
> 118, 178, 239, 334), .Dim = c(3L, 5L))
>
> The ranges for which these numbers are to be reserved are;
>
> 0-60, 61-120, 121-180, 181-240, 241-300, 301-360
>
> In row 1, the number "1", "57", and "59" fall 2ith the range 0-60. Whereas
> "271" and "279" falls within the range 241-300. So in total 2 ranges are
> covered and coding should execute 2 for row one.
>
> In row 2, the number "59" falls in the range 0-60, "179" falls in the
> range 121-180, "279" and "278" fall within the range 241-300, and 359 falls
> in the range 301-360. In total 4 ranges are covered for row 2.
>
> In the like-wise pattern, 5 ranges are covered in row 3.
>
> So, what I want is a matrix that looks in the following
>
> > dput(EBI)
>
> structure(c(2, 4, 5), .Dim = c(3L, 1L))
>
> Is there an easy way of doing it?
>
> I thank you all very much in advance
>
> EB
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 28 18:32:01 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 28 Aug 2021 09:32:01 -0700
Subject: [R] Finding if numbers fall within a range
In-Reply-To: <AS8P194MB09991D0DA6E6FB9AACFEA4629AC99@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB09991D0DA6E6FB9AACFEA4629AC99@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <3B4C3B34-FCC3-4E0B-9C67-1D488A426827@dcn.davis.ca.us>

You messed up the dput somehow... but I think this works:

m <- t(structure(c(1, 57, 59, 271, 279, 59, 179, 279, 278, 359, 52,
118, 178, 239, 334), .Dim = c(5L, 3L)))
brk <- c( 0, 60, 120, 180, 240, 300 )
mc <- matrix( findInterval( m, brk ), ncol = ncol(m) )

m
mc

DBI <- apply( mc, 1, function(v) length( unique( v ) ) )


On August 28, 2021 8:57:09 AM PDT, Eliza Botto <eliza_botto at outlook.com> wrote:
>Dear useRs,
>
>Is there a way in R to see if the numbers in a matrix-row fall within the given range or not? For example, I have the following data;
>
>> dput(EB)
>
>structure(c(1, 57, 59, 271, 279, 59, 179, 279, 278, 359, 52,
>118, 178, 239, 334), .Dim = c(3L, 5L))
>
>The ranges for which these numbers are to be reserved are;
>
>0-60, 61-120, 121-180, 181-240, 241-300, 301-360
>
>In row 1, the number "1", "57", and "59" fall 2ith the range 0-60. Whereas "271" and "279" falls within the range 241-300. So in total 2 ranges are covered and coding should execute 2 for row one.
>
>In row 2, the number "59" falls in the range 0-60, "179" falls in the range 121-180, "279" and "278" fall within the range 241-300, and 359 falls in the range 301-360. In total 4 ranges are covered for row 2.
>
>In the like-wise pattern, 5 ranges are covered in row 3.
>
>So, what I want is a matrix that looks in the following
>
>> dput(EBI)
>
>structure(c(2, 4, 5), .Dim = c(3L, 1L))
>
>Is there an easy way of doing it?
>
>I thank you all very much in advance
>
>EB
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From phii m@iii@g oii phiiipsmith@c@  Sun Aug 29 03:45:11 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Sat, 28 Aug 2021 21:45:11 -0400
Subject: [R] ggplot geom_line problem
Message-ID: <9109f671242b6f8fd17376e3d83dea1f@philipsmith.ca>

I am preparing a time series plot using the ggplot function. It includes 
an area plot outlined at its edges with a line plot. For some reason the 
line plot, drawn with geom_line(), has some broken portions where the 
line does not appear, although the filled geom_area() part of the plot 
is shown. The problem is related to the last line of code because when I 
remove it, the problem disappears.
Why is this happening and what can I do about it? Thank you. Philip

library(tidyverse)
df <- dget("df.txt")
mnGr <- 345.666605809
mnGDP <- 859.752763485
ggplot(df)+
   geom_area(aes(x=Date,y=GDP*(mnGr/mnGDP)-Gr),
     fill="red",alpha=0.3)+
   geom_line(aes(x=Date,y=GDP*(mnGr/mnGDP)-Gr),
     colour="black",size=1)+
   scale_y_continuous(position="right",limits=c(-30,30))

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: df.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210828/29dadc4e/attachment.txt>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 29 03:54:57 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 28 Aug 2021 18:54:57 -0700
Subject: [R] ggplot geom_line problem
In-Reply-To: <9109f671242b6f8fd17376e3d83dea1f@philipsmith.ca>
References: <9109f671242b6f8fd17376e3d83dea1f@philipsmith.ca>
Message-ID: <56481797-4138-4AFE-B9E7-9E62786BC83A@dcn.davis.ca.us>

Maybe you will find that coord_cartesian( ylim=c(-30,30) ) works better since it doesn't filter out data before rendering.

On August 28, 2021 6:45:11 PM PDT, phil at philipsmith.ca wrote:
>I am preparing a time series plot using the ggplot function. It includes 
>an area plot outlined at its edges with a line plot. For some reason the 
>line plot, drawn with geom_line(), has some broken portions where the 
>line does not appear, although the filled geom_area() part of the plot 
>is shown. The problem is related to the last line of code because when I 
>remove it, the problem disappears.
>Why is this happening and what can I do about it? Thank you. Philip
>
>library(tidyverse)
>df <- dget("df.txt")
>mnGr <- 345.666605809
>mnGDP <- 859.752763485
>ggplot(df)+
>   geom_area(aes(x=Date,y=GDP*(mnGr/mnGDP)-Gr),
>     fill="red",alpha=0.3)+
>   geom_line(aes(x=Date,y=GDP*(mnGr/mnGDP)-Gr),
>     colour="black",size=1)+
>   scale_y_continuous(position="right",limits=c(-30,30))

-- 
Sent from my phone. Please excuse my brevity.


From r@oknz @end|ng |rom gm@||@com  Sun Aug 29 10:37:42 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 29 Aug 2021 20:37:42 +1200
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <c8feaf61-2a0f-e581-d0fa-9a2f41bf97c5@gmail.com>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
 <20210828213855.07e32063@rolf-Latitude-E7470>
 <CAGgJW77Xi=Dn6uh17KtDst6ji17L15oy4rfCAfaRhow5RCHw2g@mail.gmail.com>
 <20210829011435.32419924@rolf-Latitude-E7470>
 <c8feaf61-2a0f-e581-d0fa-9a2f41bf97c5@gmail.com>
Message-ID: <CABcYAd+jitHWuWu=mZaBWB7oTYKizwuJuTrkXt1pMSPYW-W8bw@mail.gmail.com>

It is a general "feature" of TeX that documents with tables of
contents, indices,
bibliographies, and so on, have to be "iterated to convergence".  A couple of
PhD theses came out of Stanford; the problem is in that which page one thing
goes on depends on where other things went, which depends on where the
first thing went... TeX users got accustomed to this, which meant that they
also tolerated similar things in outboard tools like bibtex.  You
could of course
run bibtex explicitly to recreate the .bbl file.

Frankly, the suggestion of patching texi2pdf to delete the .bbl file(s) seems
like the simplest way forward.

On Sun, 29 Aug 2021 at 01:25, J C Nash <profjcnash at gmail.com> wrote:
>
> I can understand Rolf's concern. Make is a tool that is very helpful,
> but also not trivial to learn how to make work. If a good Makefile
> has been set up, then things are easy, but I've generally found my
> skills limited to fairly simple Makefiles.
>
> I would suggest that what is needed is a bit of modest collaboration
> to set up a Makefile for dealing with this issue that has enough comments
> so it is clear what Make will be doing. I suspect that in this case the
> need is to remove the offending .bbl file and then run the tex*** operations.
> Possibly the result is small enough to post in this thread. Anyone?
>
> Cheers, JN
>
>
>
> On 2021-08-28 9:14 a.m., Rolf Turner wrote:
> >
> > On Sat, 28 Aug 2021 12:49:04 +0300
> > Eric Berger <ericjberger at gmail.com> wrote:
> >
> >> As Achim wrote in point (2), Makefile is your friend.
> >
> > Well, all I can say is that Makefile is *not* my friend; I have never
> > made its acquaintance and wouldn't know where to begin looking.
> >
> > Would it be possible for you to provide a template/prototype Makefile
> > and give me some idea what to *do* with it?
> >
> > cheers,
> >
> > Rolf Turner
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Aug 29 13:22:23 2021
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 29 Aug 2021 11:22:23 +0000
Subject: [R] coercion to an object...
Message-ID: <SLXP216MB028830010F6B589E2F7618A5C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>

Dear members,
                             I think the following question is rudimentary, but I couldn't find an answer in the Internet.

Suppose there is an object A, and ls() lists it as "A". How do you convert this character object to the object A. i.e I want a function f such that class(f("A")) = class(A) (of course, class("A") = "character") . f should just coerce the character to the object represented by it.

Thank you,
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Sun Aug 29 13:27:25 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sun, 29 Aug 2021 13:27:25 +0200
Subject: [R] coercion to an object...
In-Reply-To: <SLXP216MB028830010F6B589E2F7618A5C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
 (akshay kulkarni's message of "Sun, 29 Aug 2021 11:22:23 +0000")
References: <SLXP216MB028830010F6B589E2F7618A5C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
Message-ID: <87lf4kcwyq.fsf@enricoschumann.net>

On Sun, 29 Aug 2021, akshay kulkarni writes:

> Dear members,
>                              I think the following question is rudimentary, but I couldn't find an answer in the Internet.
>
> Suppose there is an object A, and ls() lists it as "A". How do you convert this character object to the object A. i.e I want a function f such that class(f("A")) = class(A) (of course, class("A") = "character") . f should just coerce the character to the object represented by it.


Perhaps ?get is what you're looking for:

  A <- 42
  get("A")
  ## [1] 42


> Thank you,
> Yours sincerely,
> AKSHAY M KULKARNI
>

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Aug 29 13:52:27 2021
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 29 Aug 2021 11:52:27 +0000
Subject: [R] coercion to an object...
In-Reply-To: <87lf4kcwyq.fsf@enricoschumann.net>
References: <SLXP216MB028830010F6B589E2F7618A5C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
 <87lf4kcwyq.fsf@enricoschumann.net>
Message-ID: <SLXP216MB0288B291D274EFF4F89C1CB6C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>

dear Enrico,
                       it works. Thanks a lot. I spent over an hour looking for this function in the web, but was bootless. Do you have any way to get functions where you are given what it has to do? The most common case is that you are given a list of functions, but they number to over 100000. Any idea to find them without resorting to help from another R expert?

yours sincerely
AKSHAY M KULKARNI

________________________________
From: Enrico Schumann <es at enricoschumann.net>
Sent: Sunday, August 29, 2021 4:57 PM
To: akshay kulkarni <akshay_e4 at hotmail.com>
Cc: R help Mailing list <r-help at r-project.org>; r-help-request at r-project.org <r-help-request at r-project.org>
Subject: Re: [R] coercion to an object...

On Sun, 29 Aug 2021, akshay kulkarni writes:

> Dear members,
>                              I think the following question is rudimentary, but I couldn't find an answer in the Internet.
>
> Suppose there is an object A, and ls() lists it as "A". How do you convert this character object to the object A. i.e I want a function f such that class(f("A")) = class(A) (of course, class("A") = "character") . f should just coerce the character to the object represented by it.


Perhaps ?get is what you're looking for:

  A <- 42
  get("A")
  ## [1] 42


> Thank you,
> Yours sincerely,
> AKSHAY M KULKARNI
>

--
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>  Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Sun Aug 29 14:06:10 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Sun, 29 Aug 2021 08:06:10 -0400
Subject: [R] ggplot geom_line problem
In-Reply-To: <56481797-4138-4AFE-B9E7-9E62786BC83A@dcn.davis.ca.us>
References: <9109f671242b6f8fd17376e3d83dea1f@philipsmith.ca>
 <56481797-4138-4AFE-B9E7-9E62786BC83A@dcn.davis.ca.us>
Message-ID: <5656e298e1086549132f3df4440cbe19@philipsmith.ca>

Thank you Jeff. This solves my problem.

On 2021-08-28 21:54, Jeff Newmiller wrote:
> Maybe you will find that coord_cartesian( ylim=c(-30,30) ) works
> better since it doesn't filter out data before rendering.
> 
> On August 28, 2021 6:45:11 PM PDT, phil at philipsmith.ca wrote:
>> I am preparing a time series plot using the ggplot function. It 
>> includes
>> an area plot outlined at its edges with a line plot. For some reason 
>> the
>> line plot, drawn with geom_line(), has some broken portions where the
>> line does not appear, although the filled geom_area() part of the plot
>> is shown. The problem is related to the last line of code because when 
>> I
>> remove it, the problem disappears.
>> Why is this happening and what can I do about it? Thank you. Philip
>> 
>> library(tidyverse)
>> df <- dget("df.txt")
>> mnGr <- 345.666605809
>> mnGDP <- 859.752763485
>> ggplot(df)+
>>   geom_area(aes(x=Date,y=GDP*(mnGr/mnGDP)-Gr),
>>     fill="red",alpha=0.3)+
>>   geom_line(aes(x=Date,y=GDP*(mnGr/mnGDP)-Gr),
>>     colour="black",size=1)+
>>   scale_y_continuous(position="right",limits=c(-30,30))


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 29 14:19:20 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 29 Aug 2021 08:19:20 -0400
Subject: [R] coercion to an object...
In-Reply-To: <SLXP216MB0288B291D274EFF4F89C1CB6C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
References: <SLXP216MB028830010F6B589E2F7618A5C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
 <87lf4kcwyq.fsf@enricoschumann.net>
 <SLXP216MB0288B291D274EFF4F89C1CB6C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
Message-ID: <f732e1bc-dd7d-a350-7822-71b4d43fe4ae@gmail.com>

On 29/08/2021 7:52 a.m., akshay kulkarni wrote:
> dear Enrico,
>                         it works. Thanks a lot. I spent over an hour looking for this function in the web, but was bootless. Do you have any way to get functions where you are given what it has to do? The most common case is that you are given a list of functions, but they number to over 100000. Any idea to find them without resorting to help from another R expert?

The sos package does a pretty good job, but your query needs to be 
fairly narrow or the result list will be really long.  I don't think it 
would have found get() in the top hits given the words in your original 
question.  Some questions need intelligence to interpret, not just 
pattern matching.

Other than asking on this list, there's stackoverflow.com to get humans 
involved in the search.

Duncan Murdoch


> 
> yours sincerely
> AKSHAY M KULKARNI
> 
> ________________________________
> From: Enrico Schumann <es at enricoschumann.net>
> Sent: Sunday, August 29, 2021 4:57 PM
> To: akshay kulkarni <akshay_e4 at hotmail.com>
> Cc: R help Mailing list <r-help at r-project.org>; r-help-request at r-project.org <r-help-request at r-project.org>
> Subject: Re: [R] coercion to an object...
> 
> On Sun, 29 Aug 2021, akshay kulkarni writes:
> 
>> Dear members,
>>                               I think the following question is rudimentary, but I couldn't find an answer in the Internet.
>>
>> Suppose there is an object A, and ls() lists it as "A". How do you convert this character object to the object A. i.e I want a function f such that class(f("A")) = class(A) (of course, class("A") = "character") . f should just coerce the character to the object represented by it.
> 
> 
> Perhaps ?get is what you're looking for:
> 
>    A <- 42
>    get("A")
>    ## [1] 42
> 
> 
>> Thank you,
>> Yours sincerely,
>> AKSHAY M KULKARNI
>>
> 
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
> 
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>  Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Aug 29 14:24:07 2021
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 29 Aug 2021 12:24:07 +0000
Subject: [R] coercion to an object...
In-Reply-To: <f732e1bc-dd7d-a350-7822-71b4d43fe4ae@gmail.com>
References: <SLXP216MB028830010F6B589E2F7618A5C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
 <87lf4kcwyq.fsf@enricoschumann.net>
 <SLXP216MB0288B291D274EFF4F89C1CB6C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>
 <f732e1bc-dd7d-a350-7822-71b4d43fe4ae@gmail.com>
Message-ID: <SLXP216MB02883A284F4671C0ACC001E9C8CA9@SLXP216MB0288.KORP216.PROD.OUTLOOK.COM>

dear Duncun,
                           Thanks a lot...

________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Sunday, August 29, 2021 5:49 PM
To: akshay kulkarni <akshay_e4 at hotmail.com>; Enrico Schumann <es at enricoschumann.net>
Cc: R help Mailing list <r-help at r-project.org>; r-help-request at r-project.org <r-help-request at r-project.org>
Subject: Re: [R] coercion to an object...

On 29/08/2021 7:52 a.m., akshay kulkarni wrote:
> dear Enrico,
>                         it works. Thanks a lot. I spent over an hour looking for this function in the web, but was bootless. Do you have any way to get functions where you are given what it has to do? The most common case is that you are given a list of functions, but they number to over 100000. Any idea to find them without resorting to help from another R expert?

The sos package does a pretty good job, but your query needs to be
fairly narrow or the result list will be really long.  I don't think it
would have found get() in the top hits given the words in your original
question.  Some questions need intelligence to interpret, not just
pattern matching.

Other than asking on this list, there's stackoverflow.com to get humans
involved in the search.

Duncan Murdoch


>
> yours sincerely
> AKSHAY M KULKARNI
>
> ________________________________
> From: Enrico Schumann <es at enricoschumann.net>
> Sent: Sunday, August 29, 2021 4:57 PM
> To: akshay kulkarni <akshay_e4 at hotmail.com>
> Cc: R help Mailing list <r-help at r-project.org>; r-help-request at r-project.org <r-help-request at r-project.org>
> Subject: Re: [R] coercion to an object...
>
> On Sun, 29 Aug 2021, akshay kulkarni writes:
>
>> Dear members,
>>                               I think the following question is rudimentary, but I couldn't find an answer in the Internet.
>>
>> Suppose there is an object A, and ls() lists it as "A". How do you convert this character object to the object A. i.e I want a function f such that class(f("A")) = class(A) (of course, class("A") = "character") . f should just coerce the character to the object represented by it.
>
>
> Perhaps ?get is what you're looking for:
>
>    A <- 42
>    get("A")
>    ## [1] 42
>
>
>> Thank you,
>> Yours sincerely,
>> AKSHAY M KULKARNI
>>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>  Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From e||z@_botto @end|ng |rom out|ook@com  Sun Aug 29 15:22:12 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Sun, 29 Aug 2021 13:22:12 +0000
Subject: [R] Finding if numbers fall within a range
In-Reply-To: <3B4C3B34-FCC3-4E0B-9C67-1D488A426827@dcn.davis.ca.us>
References: <AS8P194MB09991D0DA6E6FB9AACFEA4629AC99@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <3B4C3B34-FCC3-4E0B-9C67-1D488A426827@dcn.davis.ca.us>
Message-ID: <AS8P194MB09993CE992B18EB56569DB6A9ACA9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Thanks Jeff,
It worked!!
________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Saturday 28 August 2021 16:32
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto <eliza_botto at outlook.com>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Finding if numbers fall within a range

You messed up the dput somehow... but I think this works:

m <- t(structure(c(1, 57, 59, 271, 279, 59, 179, 279, 278, 359, 52,
118, 178, 239, 334), .Dim = c(5L, 3L)))
brk <- c( 0, 60, 120, 180, 240, 300 )
mc <- matrix( findInterval( m, brk ), ncol = ncol(m) )

m
mc

DBI <- apply( mc, 1, function(v) length( unique( v ) ) )


On August 28, 2021 8:57:09 AM PDT, Eliza Botto <eliza_botto at outlook.com> wrote:
>Dear useRs,
>
>Is there a way in R to see if the numbers in a matrix-row fall within the given range or not? For example, I have the following data;
>
>> dput(EB)
>
>structure(c(1, 57, 59, 271, 279, 59, 179, 279, 278, 359, 52,
>118, 178, 239, 334), .Dim = c(3L, 5L))
>
>The ranges for which these numbers are to be reserved are;
>
>0-60, 61-120, 121-180, 181-240, 241-300, 301-360
>
>In row 1, the number "1", "57", and "59" fall 2ith the range 0-60. Whereas "271" and "279" falls within the range 241-300. So in total 2 ranges are covered and coding should execute 2 for row one.
>
>In row 2, the number "59" falls in the range 0-60, "179" falls in the range 121-180, "279" and "278" fall within the range 241-300, and 359 falls in the range 301-360. In total 4 ranges are covered for row 2.
>
>In the like-wise pattern, 5 ranges are covered in row 3.
>
>So, what I want is a matrix that looks in the following
>
>> dput(EBI)
>
>structure(c(2, 4, 5), .Dim = c(3L, 1L))
>
>Is there an easy way of doing it?
>
>I thank you all very much in advance
>
>EB
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 17:08:58 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 08:08:58 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
Message-ID: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>

I have a year's hydraulic data (discharge, stage height, velocity, etc.)
from a USGS monitoring gauge recording values every 5 minutes. The data
files contain 90K-93K lines and plotting all these data would produce a
solid block of color.

What I want are the daily means and standard deviation from these data.

As an occasional R user (depending on project needs) I've no idea what
packages could be applied to these data frames. There likely are multiple
paths to extracting these daily values so summary statistics can be
calculated and plotted. I'd appreciate suggestions on where to start to
learn how I can do this.

TIA,

Rich


From er|cjberger @end|ng |rom gm@||@com  Sun Aug 29 17:57:32 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 29 Aug 2021 18:57:32 +0300
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
Message-ID: <CAGgJW74m5sh1gNt-rqrF04Xq6PbS44oSWCSw+FYOvXUuZ3YuDw@mail.gmail.com>

Hi Rich,
Your request is a bit open-ended but here's a suggestion that might help
get you an answer.
Provide dummy data (e.g. 5-10 lines), say like the contents of a csv file,
and calculate by hand what you'd like to see in the plot. (And describe
what the plot would look like.)
It sounds like what you want could be done in a few lines of R code which
would work both on the dummy
data and the real data.

HTH,
Eric


On Sun, Aug 29, 2021 at 6:09 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> I have a year's hydraulic data (discharge, stage height, velocity, etc.)
> from a USGS monitoring gauge recording values every 5 minutes. The data
> files contain 90K-93K lines and plotting all these data would produce a
> solid block of color.
>
> What I want are the daily means and standard deviation from these data.
>
> As an occasional R user (depending on project needs) I've no idea what
> packages could be applied to these data frames. There likely are multiple
> paths to extracting these daily values so summary statistics can be
> calculated and plotted. I'd appreciate suggestions on where to start to
> learn how I can do this.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 29 18:23:31 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 29 Aug 2021 09:23:31 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
Message-ID: <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>

The general idea is to create a "grouping" column with repeated values for each day, and then to use aggregate to compute your combined results. The dplyr package's group_by/summarise functions can also do this, and there are also proponents of the data.table package which is high performance but tends to depend on altering data in-place unlike most other R data handling functions.

Also pay attention to missing data... if you have any then you will need to consider whether you want the strictness of na.rm=FALSE or permissiveness of na.rm=TRUE for your aggregation functions.

On August 29, 2021 8:08:58 AM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>I have a year's hydraulic data (discharge, stage height, velocity, etc.)
>from a USGS monitoring gauge recording values every 5 minutes. The data
>files contain 90K-93K lines and plotting all these data would produce a
>solid block of color.
>
>What I want are the daily means and standard deviation from these data.
>
>As an occasional R user (depending on project needs) I've no idea what
>packages could be applied to these data frames. There likely are multiple
>paths to extracting these daily values so summary statistics can be
>calculated and plotted. I'd appreciate suggestions on where to start to
>learn how I can do this.
>
>TIA,
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 18:49:06 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 09:49:06 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAGgJW74m5sh1gNt-rqrF04Xq6PbS44oSWCSw+FYOvXUuZ3YuDw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CAGgJW74m5sh1gNt-rqrF04Xq6PbS44oSWCSw+FYOvXUuZ3YuDw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2108290946180.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Eric Berger wrote:

> Provide dummy data (e.g. 5-10 lines), say like the contents of a csv file,
> and calculate by hand what you'd like to see in the plot. (And describe
> what the plot would look like.)

Eric,

Mea culpa! I extracted a set of sample data and forgot to include it in the
message. Here it is:

date,time,cfs
2020-08-26,09:30,136000
2020-08-26,09:35,126000
2020-08-26,09:40,130000
2020-08-26,09:45,128000
2020-08-26,09:50,126000
2020-08-26,09:55,125000
2020-08-26,10:00,121000
2020-08-26,10:05,117000
2020-08-26,10:10,120000
...
2020-08-26,23:10,108000
2020-08-26,23:15,96200
2020-08-26,23:20,86700
2020-08-26,23:25,103000
2020-08-26,23:30,103000
2020-08-26,23:35,99500
2020-08-26,23:40,85200
2020-08-26,23:45,103000
2020-08-26,23:50,95800
2020-08-26,23:55,88200

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 18:52:45 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 09:52:45 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2108290950170.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Jeff Newmiller wrote:

> The general idea is to create a "grouping" column with repeated values for
> each day, and then to use aggregate to compute your combined results. The
> dplyr package's group_by/summarise functions can also do this, and there
> are also proponents of the data.table package which is high performance
> but tends to depend on altering data in-place unlike most other R data
> handling functions.
>
> Also pay attention to missing data... if you have any then you will need
> to consider whether you want the strictness of na.rm=FALSE or
> permissiveness of na.rm=TRUE for your aggregation functions.

Jeff,

Thank you. Yes, there are missing data as sometimes the equipment fails, or
there's some other reason why some samples are missing.

Grouping on each day is just what I need. I'll re-learn dplyr and take a
look at data.table.

Regards,

Rich


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 29 18:56:13 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 29 Aug 2021 09:56:13 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
Message-ID: <CE066626-6824-4F79-A169-147021B389AD@dcn.davis.ca.us>

You may find something useful on handling timestamp data here: https://jdnewmil.github.io/

On August 29, 2021 9:23:31 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>The general idea is to create a "grouping" column with repeated values for each day, and then to use aggregate to compute your combined results. The dplyr package's group_by/summarise functions can also do this, and there are also proponents of the data.table package which is high performance but tends to depend on altering data in-place unlike most other R data handling functions.
>
>Also pay attention to missing data... if you have any then you will need to consider whether you want the strictness of na.rm=FALSE or permissiveness of na.rm=TRUE for your aggregation functions.
>
>On August 29, 2021 8:08:58 AM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>>I have a year's hydraulic data (discharge, stage height, velocity, etc.)
>>from a USGS monitoring gauge recording values every 5 minutes. The data
>>files contain 90K-93K lines and plotting all these data would produce a
>>solid block of color.
>>
>>What I want are the daily means and standard deviation from these data.
>>
>>As an occasional R user (depending on project needs) I've no idea what
>>packages could be applied to these data frames. There likely are multiple
>>paths to extracting these daily values so summary statistics can be
>>calculated and plotted. I'd appreciate suggestions on where to start to
>>learn how I can do this.
>>
>>TIA,
>>
>>Rich
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug 29 19:01:02 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 29 Aug 2021 18:01:02 +0100
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108290946180.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CAGgJW74m5sh1gNt-rqrF04Xq6PbS44oSWCSw+FYOvXUuZ3YuDw@mail.gmail.com>
 <alpine.LNX.2.20.2108290946180.32406@salmo.appl-ecosys.com>
Message-ID: <a76fbb4e-055e-050e-bd0f-b08b24d7574e@sapo.pt>

Hello,

You have date and hour in two separate columns, so to compute daily 
stats part of the work is already done. (Were they in the same column 
you would have to extract the date only.)

# convert to class "Date"
df1$date <- as.Date(df1$date)


# function to compute the stats required
# it's important to note that all the stats
# are returned in a vector, see below
fun <- function(x, na.rm = FALSE){
   c(mean_cfs = mean(x, na.rm = na.rm),
     sd_cfs = sd(x, na.rm = na.rm))
}

# now this will put a *matrix* under cfs
# each row has the  statistics computed
# by the function
agg <- aggregate(cfs ~ date, df1, fun)
str(agg)
#'data.frame':	1 obs. of  2 variables:
# $ date: Date, format: "2020-08-26"
# $ cfs : num [1, 1:2] 110400 16143
#  ..- attr(*, "dimnames")=List of 2
#  .. ..$ : NULL
#  .. ..$ : chr [1:2] "mean_cfs" "sd_cfs"


# so now put everything in separate columns
agg <- cbind(agg[-ncol(agg)], agg[[ncol(agg)]])
str(agg)
#'data.frame':	1 obs. of  3 variables:
# $ date    : Date, format: "2020-08-26"
# $ mean_cfs: num 110400
# $ sd_cfs  : num 16143


Hope this helps,

Rui Barradas

?s 17:49 de 29/08/21, Rich Shepard escreveu:
> On Sun, 29 Aug 2021, Eric Berger wrote:
> 
>> Provide dummy data (e.g. 5-10 lines), say like the contents of a csv 
>> file,
>> and calculate by hand what you'd like to see in the plot. (And describe
>> what the plot would look like.)
> 
> Eric,
> 
> Mea culpa! I extracted a set of sample data and forgot to include it in the
> message. Here it is:
> 
> date,time,cfs
> 2020-08-26,09:30,136000
> 2020-08-26,09:35,126000
> 2020-08-26,09:40,130000
> 2020-08-26,09:45,128000
> 2020-08-26,09:50,126000
> 2020-08-26,09:55,125000
> 2020-08-26,10:00,121000
> 2020-08-26,10:05,117000
> 2020-08-26,10:10,120000
> ...
> 2020-08-26,23:10,108000
> 2020-08-26,23:15,96200
> 2020-08-26,23:20,86700
> 2020-08-26,23:25,103000
> 2020-08-26,23:30,103000
> 2020-08-26,23:35,99500
> 2020-08-26,23:40,85200
> 2020-08-26,23:45,103000
> 2020-08-26,23:50,95800
> 2020-08-26,23:55,88200
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 19:03:16 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 10:03:16 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CE066626-6824-4F79-A169-147021B389AD@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <CE066626-6824-4F79-A169-147021B389AD@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2108291002310.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Jeff Newmiller wrote:

> You may find something useful on handling timestamp data here:
> https://jdnewmil.github.io/

Jeff,

I'll certainly read those articles.

Many thanks,

Rich


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug 29 19:04:54 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 29 Aug 2021 18:04:54 +0100
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108290950170.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <alpine.LNX.2.20.2108290950170.32406@salmo.appl-ecosys.com>
Message-ID: <13d266fe-9b35-ab21-e798-0037db517f67@sapo.pt>

Hello,

I forgot in my previous answer, sorry for the duplicated mails.

The function in my previous mail has a na.rm argument, defaulting to 
FALSE, pass na.rm = TRUE to remove the NA's.


agg <- aggregate(cfs ~ date, df1, fun, na.rm = TRUE)



Or simply change the default. I prefer to set na.rm = FALSE because 
that's what R's functions do. And I will only be used to one default, 
with base R functions or my own code.


Hope this helps,

Rui Barradas

?s 17:52 de 29/08/21, Rich Shepard escreveu:
> On Sun, 29 Aug 2021, Jeff Newmiller wrote:
> 
>> The general idea is to create a "grouping" column with repeated values 
>> for
>> each day, and then to use aggregate to compute your combined results. The
>> dplyr package's group_by/summarise functions can also do this, and there
>> are also proponents of the data.table package which is high performance
>> but tends to depend on altering data in-place unlike most other R data
>> handling functions.
>>
>> Also pay attention to missing data... if you have any then you will need
>> to consider whether you want the strictness of na.rm=FALSE or
>> permissiveness of na.rm=TRUE for your aggregation functions.
> 
> Jeff,
> 
> Thank you. Yes, there are missing data as sometimes the equipment fails, or
> there's some other reason why some samples are missing.
> 
> Grouping on each day is just what I need. I'll re-learn dplyr and take a
> look at data.table.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 19:05:38 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 10:05:38 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <a76fbb4e-055e-050e-bd0f-b08b24d7574e@sapo.pt>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CAGgJW74m5sh1gNt-rqrF04Xq6PbS44oSWCSw+FYOvXUuZ3YuDw@mail.gmail.com>
 <alpine.LNX.2.20.2108290946180.32406@salmo.appl-ecosys.com>
 <a76fbb4e-055e-050e-bd0f-b08b24d7574e@sapo.pt>
Message-ID: <alpine.LNX.2.20.2108291004090.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Rui Barradas wrote:

> Hope this helps,

Rui,

Greatly! I'll study it carefully so I fully understand the process.

Many thanks.

Stay well,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 19:07:24 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 10:07:24 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <13d266fe-9b35-ab21-e798-0037db517f67@sapo.pt>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <alpine.LNX.2.20.2108290950170.32406@salmo.appl-ecosys.com>
 <13d266fe-9b35-ab21-e798-0037db517f67@sapo.pt>
Message-ID: <alpine.LNX.2.20.2108291006220.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Rui Barradas wrote:

> I forgot in my previous answer, sorry for the duplicated mails.
> The function in my previous mail has a na.rm argument, defaulting to FALSE, 
> pass na.rm = TRUE to remove the NA's.
>
> agg <- aggregate(cfs ~ date, df1, fun, na.rm = TRUE)
>
> Or simply change the default. I prefer to set na.rm = FALSE because that's 
> what R's functions do. And I will only be used to one default, with base R 
> functions or my own code.

> Hope this helps,

Rui,

Again, yes it does.

Regards,

Rich


From @kw@|mmo @end|ng |rom gm@||@com  Sun Aug 29 19:13:03 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Sun, 29 Aug 2021 13:13:03 -0400
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
Message-ID: <CAPcHnpTxhVCJuDGLkFUqUj+W9kYbAOUgGaNW97=zwpdNjgGEyw@mail.gmail.com>

Hello,


I would suggest something like:


date <- seq(as.Date("2020-01-01"), as.Date("2020-12-31"), 1)
time <- sprintf("%02d:%02d", rep(0:23, each = 12), seq.int(0, 55, 5))
x <- data.frame(
    date = rep(date, each = length(time)),
    time = time
)
x$cfs <- stats::rnorm(nrow(x))


cols2aggregate <- "cfs"  # add more as necessary


S <- split(x[cols2aggregate], x$date)


means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
TRUE)))

On Sun, Aug 29, 2021 at 11:09 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> I have a year's hydraulic data (discharge, stage height, velocity, etc.)
> from a USGS monitoring gauge recording values every 5 minutes. The data
> files contain 90K-93K lines and plotting all these data would produce a
> solid block of color.
>
> What I want are the daily means and standard deviation from these data.
>
> As an occasional R user (depending on project needs) I've no idea what
> packages could be applied to these data frames. There likely are multiple
> paths to extracting these daily values so summary statistics can be
> calculated and plotted. I'd appreciate suggestions on where to start to
> learn how I can do this.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 19:29:18 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 10:29:18 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAPcHnpTxhVCJuDGLkFUqUj+W9kYbAOUgGaNW97=zwpdNjgGEyw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CAPcHnpTxhVCJuDGLkFUqUj+W9kYbAOUgGaNW97=zwpdNjgGEyw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2108291028540.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Andrew Simmons wrote:

> I would suggest something like:

Thanks, Andrew.

Stay well,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 21:26:42 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 12:26:42 -0700 (PDT)
Subject: [R] Upgraded to 4.1.1 assignment operator keys not working
Message-ID: <alpine.LNX.2.20.2108291216530.32406@salmo.appl-ecosys.com>

Just upgraded to R-4.1.1-x86_64-1_SBo on Slackware-14.2/x86_64. While it's
been a while since I last ran R trying 'Alt + -' to enter the assignment
monitor is not working. Assuming the problem is with me I'm not finding what
I'm doing incorrectly in all the docs I searched and I'm suitably
embarrassed that I need to ask for help. But, ... help.

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 29 21:37:44 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 29 Aug 2021 12:37:44 -0700 (PDT)
Subject: [R] Upgraded to 4.1.1 assignment operator keys not working
 [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.2108291216530.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108291216530.32406@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.2108291235470.32406@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Rich Shepard wrote:

> But, ... help.

Sigh. It helps to start ESS in emacs first.

Rich


From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Sun Aug 29 23:23:15 2021
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Sun, 29 Aug 2021 23:23:15 +0200 (CEST)
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <20210829011435.32419924@rolf-Latitude-E7470>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <6d6567c-13c7-1f4f-aa6f-2a4b1d41df93@uibk.ac.at>
 <20210828213855.07e32063@rolf-Latitude-E7470>
 <CAGgJW77Xi=Dn6uh17KtDst6ji17L15oy4rfCAfaRhow5RCHw2g@mail.gmail.com>
 <20210829011435.32419924@rolf-Latitude-E7470>
Message-ID: <78204174-741f-1378-e82c-1d8aece7e2e@uibk.ac.at>

On Sat, 28 Aug 2021, Rolf Turner wrote:

>
> On Sat, 28 Aug 2021 12:49:04 +0300
> Eric Berger <ericjberger at gmail.com> wrote:
>
>> As Achim wrote in point (2), Makefile is your friend.
>
> Well, all I can say is that Makefile is *not* my friend; I have never
> made its acquaintance and wouldn't know where to begin looking.
>
> Would it be possible for you to provide a template/prototype Makefile
> and give me some idea what to *do* with it?

In a Makefile you can declare "rules" for producing certain "target" files 
from "prerequisite" files. The rules are only applied if any of the 
prerequisite files have changed since the target was last produced.

In your case the .bib is a prerequisite for the target .bbl which in turn 
is a prerequisite (along with the .tex) for the .pdf.

A nice introduction to GNU Make for data analysis workflows is this JSS 
paper by Peter Baker (http://petebaker.id.au/):

https://doi.org/10.18637/jss.v094.c01

Best wishes,
Z


From r@oknz @end|ng |rom gm@||@com  Mon Aug 30 04:09:01 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 30 Aug 2021 14:09:01 +1200
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
Message-ID: <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>

Why would you need a package for this?
> samples.per.day <- 12*24

That's 12 5-minute intervals per hour and 24 hours per day.
Generate some fake data.

> x <- rnorm(samples.per.day * 365)
> length(x)
[1] 105120

Reshape the fake data into a matrix where each row represents one
24-hour period.

> m <- matrix(x, ncol=samples.per.day, byrow=TRUE)

Now we can summarise the rows any way we want.
The basic tool here is ?apply.
?rowMeans is said to be faster than using apply to calculate means,
so we'll use that.  There is no *rowSds so we have to use apply
for the standard deviation.  I use ?head because I don't want to
post tens of thousands of meaningless numbers.

> head(rowMeans(m))
[1] -0.03510177  0.11817337  0.06725203 -0.03578195 -0.02448077 -0.03033692
> head(apply(m, MARGIN=1, FUN=sd))
[1] 1.0017718 0.9922920 1.0100550 0.9956810 1.0077477 0.9833144

Now whether this is a *sensible* way to summarise your flow data is a question
that a hydrologist would be better placed to answer.  I would have started with
> plot(density(x))
which I just did with some real river data (only a month of it, sigh).
Very long tail.
Even
> plot(density(log(r)))
shows a very long tail.  Time to plot the data against time.  Oh my!
All of the long tail came from a single event.
There's a period of low flow, then there's a big rainstorm and the
flow goes WAY up, then over about two days the flow subsides to a new
somewhat higher level.

None of this is reflected in means or standard deviations.
This is *time series* data, and time series data of a fairly special kind.

One thing that might be helpful with your data would simply be
> image(log(m))
For my one month sample, the spike showed up very clearly that way.
Because right now, your first task is to get an idea of what the data
look like, and means-and-standard-deviations won't really do that.

Oh heck, here's another reason to go with image(log(m)).
With image(m) I just see the one big spike.
With image(log(m)), I can see that little spikes often start in the
afternoon of one day and continue into the morning of the next.
>From daily means, it looks like two unusual, but not very
unusual, days.  From the image, it's clearly ONE rainfall event
that just happens to straddle a day boundary.

This is all very basic stuff, which is really the point.  You want to use
elementary tools to look at the data before you reach for fancy ones.


On Mon, 30 Aug 2021 at 03:09, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> I have a year's hydraulic data (discharge, stage height, velocity, etc.)
> from a USGS monitoring gauge recording values every 5 minutes. The data
> files contain 90K-93K lines and plotting all these data would produce a
> solid block of color.
>
> What I want are the daily means and standard deviation from these data.
>
> As an occasional R user (depending on project needs) I've no idea what
> packages could be applied to these data frames. There likely are multiple
> paths to extracting these daily values so summary statistics can be
> calculated and plotted. I'd appreciate suggestions on where to start to
> learn how I can do this.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 30 04:47:20 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 29 Aug 2021 19:47:20 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
Message-ID: <6661B073-6581-42CA-8439-6B5551FC4A5B@dcn.davis.ca.us>

IMO assuming periodicity is a bad practice for this. Missing timestamps happen too, and there is no reason to build a broken analysis process.

On August 29, 2021 7:09:01 PM PDT, Richard O'Keefe <raoknz at gmail.com> wrote:
>Why would you need a package for this?
>> samples.per.day <- 12*24
>
>That's 12 5-minute intervals per hour and 24 hours per day.
>Generate some fake data.
>
>> x <- rnorm(samples.per.day * 365)
>> length(x)
>[1] 105120
>
>Reshape the fake data into a matrix where each row represents one
>24-hour period.
>
>> m <- matrix(x, ncol=samples.per.day, byrow=TRUE)
>
>Now we can summarise the rows any way we want.
>The basic tool here is ?apply.
>?rowMeans is said to be faster than using apply to calculate means,
>so we'll use that.  There is no *rowSds so we have to use apply
>for the standard deviation.  I use ?head because I don't want to
>post tens of thousands of meaningless numbers.
>
>> head(rowMeans(m))
>[1] -0.03510177  0.11817337  0.06725203 -0.03578195 -0.02448077 -0.03033692
>> head(apply(m, MARGIN=1, FUN=sd))
>[1] 1.0017718 0.9922920 1.0100550 0.9956810 1.0077477 0.9833144
>
>Now whether this is a *sensible* way to summarise your flow data is a question
>that a hydrologist would be better placed to answer.  I would have started with
>> plot(density(x))
>which I just did with some real river data (only a month of it, sigh).
>Very long tail.
>Even
>> plot(density(log(r)))
>shows a very long tail.  Time to plot the data against time.  Oh my!
>All of the long tail came from a single event.
>There's a period of low flow, then there's a big rainstorm and the
>flow goes WAY up, then over about two days the flow subsides to a new
>somewhat higher level.
>
>None of this is reflected in means or standard deviations.
>This is *time series* data, and time series data of a fairly special kind.
>
>One thing that might be helpful with your data would simply be
>> image(log(m))
>For my one month sample, the spike showed up very clearly that way.
>Because right now, your first task is to get an idea of what the data
>look like, and means-and-standard-deviations won't really do that.
>
>Oh heck, here's another reason to go with image(log(m)).
>With image(m) I just see the one big spike.
>With image(log(m)), I can see that little spikes often start in the
>afternoon of one day and continue into the morning of the next.
>From daily means, it looks like two unusual, but not very
>unusual, days.  From the image, it's clearly ONE rainfall event
>that just happens to straddle a day boundary.
>
>This is all very basic stuff, which is really the point.  You want to use
>elementary tools to look at the data before you reach for fancy ones.
>
>
>On Mon, 30 Aug 2021 at 03:09, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>>
>> I have a year's hydraulic data (discharge, stage height, velocity, etc.)
>> from a USGS monitoring gauge recording values every 5 minutes. The data
>> files contain 90K-93K lines and plotting all these data would produce a
>> solid block of color.
>>
>> What I want are the daily means and standard deviation from these data.
>>
>> As an occasional R user (depending on project needs) I've no idea what
>> packages could be applied to these data frames. There likely are multiple
>> paths to extracting these daily values so summary statistics can be
>> calculated and plotted. I'd appreciate suggestions on where to start to
>> learn how I can do this.
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @d@m@wy@ok|n@k| @end|ng |rom e@em@||  Sun Aug 29 19:22:51 2021
From: @d@m@wy@ok|n@k| @end|ng |rom e@em@|| (=?UTF-8?Q?Adam_Wysoki=c5=84ski?=)
Date: Sun, 29 Aug 2021 19:22:51 +0200
Subject: [R] Configure error: checking if libcurl supports https... no
In-Reply-To: <20210828221810.7306dfde@rolf-Latitude-E7470>
References: <20210828221810.7306dfde@rolf-Latitude-E7470>
Message-ID: <ff12886e-1c4a-07fa-542d-48dcf5391128@e.email>

Hi,
What you need is the libcurl library, not the program curl (which you 
have installed):

     sudo apt-get install libcurl4

and probably (if not installed automatically by apt):

     sudo apt-get install libcurl4-openssl-dev

Now it should work.

PS. you may always check which package provides a particular file by using:

     apt-file find libcurl

-- 
Regards,
Adam Wysoki?ski

On 8/28/21 12:18, Rolf Turner wrote:
> 
> I'm getting results from a package which differ from results that I got
> a few weeks ago, and the only thing that I can think of that's changed
> is the version of R (from 4.1.0 to 4.4.1).
> 
> So I wanted to install 4.1.0 and play around with that, to see if that
> is indeed the explanation.  (If that is so, a whole new set of
> questions would be raised, but let's leave that for the moment.)  I
> downloaded the tarball and set about installing 4.1.0 from source.  But
> the configure step threw an error, as given in the subject line of
> this message.  The error went on:
> 
>> configure: error: libcurl >= 7.28.0 library and headers are required
>> with support for https
> 
> A bit of web searching turned up the advice to re-install curl
> using
> 
>      sudo apt-get install curl
> 
> but when I did that I was informed that:
> 
>> curl is already the newest version (7.68.0-1ubuntu2.6).
> 
> Has anyone got any *useful* advice?  If so, please present it
> in very simple terms if you can.  (I am a Bear of Very Little Brain,
> and long words bother me.)  A step-by-step recipe would be appreciated.
> 
> I'm running Ubuntu 20.04, with a Mate 1.24.0 desktop.
> 
> Grateful for any pearls of wisdom.
> 
> cheers,
> 
> Rolf Turner
> 
> P.S. The config.log file seems to be full of stuff relating to errors
> from "openssl.c" but this is *way* beyond my pay grade.
> 
> R. T.
>


From @|@y@hz@k@r|@ @end|ng |rom un|m@p@edu@my  Mon Aug 30 10:21:44 2021
From: @|@y@hz@k@r|@ @end|ng |rom un|m@p@edu@my (SITI AISYAH ZAKARIA)
Date: Mon, 30 Aug 2021 16:21:44 +0800
Subject: [R] How to solve this?
Message-ID: <CALcx2BnOYqA9f+Rzdtnm=3X_o1vkQYuNUC4N++gGdgf-gJEeKA@mail.gmail.com>

Dear all,

Can anyone help me? I'm using this coding to get the spatial gev model and
plotting the quantile plot to justify the model is fit but the plot look
like not fit.. How can I solve this? It is I need to change in the any
value at the coding.For example I want to change form.shape <-shape ~1 to
form.shape <- shape ~average shape but is not available for average coding.

below is my coding

#----------------------------------------------------------------------------------------------
# fitspatgev
#----------------------------------------------------------------------------------------------
# response surface model
Ozone<-data.matrix(Ozone_S)
Ozone
LotLatAlt<-data.matrix(OzoneLotLatAlt_S)
LotLatAlt
form.loc <- loc ~ Lon + Lat + Alt
form.scale <- scale ~ 1
form.shape <- shape ~ 1
dim(Ozone_S)
dim(OzoneLotLatAlt_S)
fit1 <- fitspatgev(Ozone, scale(LotLatAlt,scale=FALSE), form.loc,
form.scale, form.shape);fit1
TIC(fit1)
fit1$param
#data(rain
#symbolplot(rain, coord, plot.border = swiss)
#check the fit of the model: compute QQplots for each station
par(mfrow=c(1,3))
par(mar=c(3,2.5,1.5,0.5),mgp=c(1.5,0.5,0),font.main=1,cex=0.66,cex.main=1)
#calculation of confidance intervals
nc <- 10000
M1 <- matrix(rfrechet(nc*nobs),nrow=nobs,ncol=nc)
M <- t(apply(M1,2,sort))
E <- boot::envelope(mat=M) #compute 95% confidance bands
for (k in c(1:3,4,5,6)){ #choose some stations
  park <- predict(fit1)[k,]
  fk <- gev2frech(Ozone[,k],loc=park[4],scale=park[5],shape=park[6])
  qqplot(y=fk,x=qfrechet((1:nobs)/(nobs+1)),log='xy',main=k,ylab='Sample
Quantiles',xlab='Theoretical Quantiles',cex=0.7);
  abline(0,1)
  lines(y=E$overall[1,],x=qfrechet((1:nobs)/(nobs +1)),lty='dotted')
  lines(y=E$overall[2,],x=qfrechet((1:nobs)/(nobs +1)),lty='dotted')
}

the quantile plot is in attachment file.
please, can anyone help me?

thank you

-- 





"..Millions of trees are used to make papers, only to be thrown away 
after a couple of minutes reading from them. Our planet is at stake. Please 
be considerate. THINK TWICE BEFORE PRINTING THIS.."

DISCLAIMER:?This email 
and any files transmitted with it are confidential and intended solely for 
the use of the individual orentity to whom they are addressed. If you have 
received this email in error please notify the UniMAP's Email 
Administrator. Please note that any views or opinions presented in this 
email are solely those of the author and do not necessarily represent those 
of the university. Finally, the recipient should check this email and any 
attachments for the presence of viruses.The university accepts no liability 
for any damage caused by any virus transmitted by this email.

Universiti 
Malaysia Perlis (UniMAP) | Digital Management & Development Centre (DMDC), 
Universiti Malaysia Perlis (UniMAP), Pauh Putra Campus, 02600 Arau, Perlis, 
MALAYSIA |?www.unimap.edu.my <http://www.unimap.edu.my/>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 6bdf71f9-f33f-4c53-bf12-1e21e9c55b26.png
Type: image/png
Size: 6679 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210830/033f6705/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 45d43732-cc62-4c43-8659-97ca2d7134c5.png
Type: image/png
Size: 6573 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210830/033f6705/attachment-0001.png>

From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Mon Aug 30 11:28:27 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Mon, 30 Aug 2021 05:28:27 -0400
Subject: [R] R codes/functions for test procedures
Message-ID: <CAE9stmdMQzVcYfb57EOnd88imvpRBenu4aYzoCMEfUL4dCwOag@mail.gmail.com>

Dear All:





I am wondering if someone have an R codes (R functions) to run the test
procedures described in the paper titled ?ESTIMATION AND COMPARISON OF
LOGNORMAL PARAMETERS IN THE PRESENCE OF CENSORED DATA? by STAVROS POULOUKAS
2004, Journal of Statistical Computation & Simulation, Vol. 74, No. 3,
March 2004, pp. 157?169.





with many thanks

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Aug 30 11:49:46 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 30 Aug 2021 12:49:46 +0300
Subject: [R] R codes/functions for test procedures
In-Reply-To: <CAE9stmdMQzVcYfb57EOnd88imvpRBenu4aYzoCMEfUL4dCwOag@mail.gmail.com>
References: <CAE9stmdMQzVcYfb57EOnd88imvpRBenu4aYzoCMEfUL4dCwOag@mail.gmail.com>
Message-ID: <CAGgJW74NSCZEk9ua1MppfefJi6ni437XM934LdXcbOfA_ueJyA@mail.gmail.com>

You might also try asking the author directly if he knows of any
implementations of his procedures.
I searched online and found his website at:
https://www.unic.ac.cy/pouloukas-stavros/
You can also find his email there.


On Mon, Aug 30, 2021 at 12:29 PM AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All:
>
>
>
>
>
> I am wondering if someone have an R codes (R functions) to run the test
> procedures described in the paper titled ?ESTIMATION AND COMPARISON OF
> LOGNORMAL PARAMETERS IN THE PRESENCE OF CENSORED DATA? by STAVROS POULOUKAS
> 2004, Journal of Statistical Computation & Simulation, Vol. 74, No. 3,
> March 2004, pp. 157?169.
>
>
>
>
>
> with many thanks
>
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Aug 30 12:34:19 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 30 Aug 2021 22:34:19 +1200
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <6661B073-6581-42CA-8439-6B5551FC4A5B@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <6661B073-6581-42CA-8439-6B5551FC4A5B@dcn.davis.ca.us>
Message-ID: <CABcYAdJkAPFG0hZ-nN9_vxH+QTfVSy8rREizMk7FYF2JAZxxdQ@mail.gmail.com>

It is not clear to me who Jeff Newmiller's comment about periodicity
is addressed to.
The original poster, for asking for daily summaries?
A summary of what I wrote:
- daily means and standard deviations are a very poor choice for river flow data
- if you insist on doing that anyway, no fancy packages are required, just
  reshape the data into a matrix where rows correspond to days using matrix()
  and summarise it using rowMeans() and apply(... FUN=sd).
- but it is quite revealing to just plot the data using image(), which makes no
  assumptions about periodicity or anything else, just a way of wrapping 1D
  data to fill a 2D space and still have interpretable axes
- the river data I examined showed fairly boring time series interrupted by
  substantial shocks (caused by rainfall in catchment areas).

New stuff...
The river data I looked at came from Environment Canterbury.
River flows there are driven by (a) snow-melt from the Southern Alps.
which *is* roughly periodic with a period of one year and (b) rainfall
events which charge the upstream catchment areas, leading to a
rapid ramp up following by a slower exponential-looking decay.
The (a) elemen happens to be invisible in the Environment Canterbury
data, as they only release the latest month of flow data, The ratio
between low flows and high flows ranged from 2 to 10 in the data I
could get.

The (b) component is NOT periodic and is NOT aligned with days
and is NOT predictable and is extremely important.

Where you begin is not with R or a search for packages but with
the question "what is actually going on in the real world?  What
are the influences on river flow, are they natural (and which) or
human (and which)?"  It's going to matter a lot how much
irrigation water is drawn from a river, and that may be roughly
predictable.  If water is occasionally diverted into another river
for flood control, that's going to make a difference.  If there is a
dam, that's going to make a difference.  Rainfall and snowmelt
are going to be seasonal (in a hand-wavy sense) but differently so.

And there is an equally important question:  "Why am I doing this?
What do I want to see in the data that doesn't already leap to the
eye?  What is anyone going to DO differently if they see that?"
Are you interested in whether minimum flows are adequate for
irrigation or whether flood control systems are adequate for high
flows?

Thinking about the people who might read my report, if I were
tasked with analysing river data, I would want to analyse the
data and present the results in such a way that most of them
would say "Why did I need this guy?  It's so obvious!  I could
have done that!  (If I had ever thought of it.)"  But that is because
I am thinking of farmers and politicians who have other maddened
grizzly bears to stun (thanks, Terry Pratchett).  If writing for an
audience of hydrologists and statisticians, you would make
different choices.

Here's a little bit of insight from the physics.
Why is it that the spikes in the flows rise rapidly and fall slowly?
Because the fall is limited by the rate at which the river system
can carry water away, but the rate at which a storm can deliver
water to the river system is not.  Did I know this before looking
at the ECan data?  Well, I had *seen* rivers rising rapidly and
falling slowly, but I had never *observed*; I had never thought
about it.   But now that I have, it's *obvious*: you cannot
understand the river without understanding the weather that
the river is subject to.  Anyone who genuinely understands
hydrology is looking at me sadly and saying "Just now you
figured this out?  At your mother's knee you didn't learn this?"
But it has such repercussions.  It means you need data on
rainfall in the catchment areas.  (Which ECan, to their credit,
also provide.)  In an important sense, there is no right way to
analyse river flow data *on its own*.

On Mon, 30 Aug 2021 at 14:47, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> IMO assuming periodicity is a bad practice for this. Missing timestamps happen too, and there is no reason to build a broken analysis process.
>
> On August 29, 2021 7:09:01 PM PDT, Richard O'Keefe <raoknz at gmail.com> wrote:
> >Why would you need a package for this?
> >> samples.per.day <- 12*24
> >
> >That's 12 5-minute intervals per hour and 24 hours per day.
> >Generate some fake data.
> >
> >> x <- rnorm(samples.per.day * 365)
> >> length(x)
> >[1] 105120
> >
> >Reshape the fake data into a matrix where each row represents one
> >24-hour period.
> >
> >> m <- matrix(x, ncol=samples.per.day, byrow=TRUE)
> >
> >Now we can summarise the rows any way we want.
> >The basic tool here is ?apply.
> >?rowMeans is said to be faster than using apply to calculate means,
> >so we'll use that.  There is no *rowSds so we have to use apply
> >for the standard deviation.  I use ?head because I don't want to
> >post tens of thousands of meaningless numbers.
> >
> >> head(rowMeans(m))
> >[1] -0.03510177  0.11817337  0.06725203 -0.03578195 -0.02448077 -0.03033692
> >> head(apply(m, MARGIN=1, FUN=sd))
> >[1] 1.0017718 0.9922920 1.0100550 0.9956810 1.0077477 0.9833144
> >
> >Now whether this is a *sensible* way to summarise your flow data is a question
> >that a hydrologist would be better placed to answer.  I would have started with
> >> plot(density(x))
> >which I just did with some real river data (only a month of it, sigh).
> >Very long tail.
> >Even
> >> plot(density(log(r)))
> >shows a very long tail.  Time to plot the data against time.  Oh my!
> >All of the long tail came from a single event.
> >There's a period of low flow, then there's a big rainstorm and the
> >flow goes WAY up, then over about two days the flow subsides to a new
> >somewhat higher level.
> >
> >None of this is reflected in means or standard deviations.
> >This is *time series* data, and time series data of a fairly special kind.
> >
> >One thing that might be helpful with your data would simply be
> >> image(log(m))
> >For my one month sample, the spike showed up very clearly that way.
> >Because right now, your first task is to get an idea of what the data
> >look like, and means-and-standard-deviations won't really do that.
> >
> >Oh heck, here's another reason to go with image(log(m)).
> >With image(m) I just see the one big spike.
> >With image(log(m)), I can see that little spikes often start in the
> >afternoon of one day and continue into the morning of the next.
> >From daily means, it looks like two unusual, but not very
> >unusual, days.  From the image, it's clearly ONE rainfall event
> >that just happens to straddle a day boundary.
> >
> >This is all very basic stuff, which is really the point.  You want to use
> >elementary tools to look at the data before you reach for fancy ones.
> >
> >
> >On Mon, 30 Aug 2021 at 03:09, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> >>
> >> I have a year's hydraulic data (discharge, stage height, velocity, etc.)
> >> from a USGS monitoring gauge recording values every 5 minutes. The data
> >> files contain 90K-93K lines and plotting all these data would produce a
> >> solid block of color.
> >>
> >> What I want are the daily means and standard deviation from these data.
> >>
> >> As an occasional R user (depending on project needs) I've no idea what
> >> packages could be applied to these data frames. There likely are multiple
> >> paths to extracting these daily values so summary statistics can be
> >> calculated and plotted. I'd appreciate suggestions on where to start to
> >> learn how I can do this.
> >>
> >> TIA,
> >>
> >> Rich
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Aug 30 14:42:29 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 30 Aug 2021 05:42:29 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>

On Mon, 30 Aug 2021, Richard O'Keefe wrote:

> Why would you need a package for this?
>> samples.per.day <- 12*24
>
> That's 12 5-minute intervals per hour and 24 hours per day.
> Generate some fake data.

Richard,

The problem is that there are days with fewer than 12 recorded values for
various reasons.

When testing algorithms I use small subsets of actual data rather than fake
data.

Thanks for your detailed procedure.

Regards,

Rich


From no@p@m @end|ng |rom ||@@e@NA  Mon Aug 30 15:10:48 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Mon, 30 Aug 2021 15:10:48 +0200
Subject: [R] Upgraded to 4.1.1 assignment operator keys not working
 [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.2108291235470.32406@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108291216530.32406@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2108291235470.32406@salmo.appl-ecosys.com>
Message-ID: <sgilco$3dn$1@ciao.gmane.io>

Or using RStudio :-)-O

el

On 29/08/2021 21:37, Rich Shepard wrote:
> On Sun, 29 Aug 2021, Rich Shepard wrote:
> 
>> But, ... help.
> 
> Sigh. It helps to start ESS in emacs first.
> 
> Rich
> 


-- 
To email me replace 'nospam' with 'el'


From d@v|d@@teven@ @end|ng |rom u@u@edu  Mon Aug 30 18:04:06 2021
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David K Stevens)
Date: Mon, 30 Aug 2021 10:04:06 -0600
Subject: [R] [EXT]  R codes/functions for test procedures
In-Reply-To: <CAE9stmdMQzVcYfb57EOnd88imvpRBenu4aYzoCMEfUL4dCwOag@mail.gmail.com>
References: <CAE9stmdMQzVcYfb57EOnd88imvpRBenu4aYzoCMEfUL4dCwOag@mail.gmail.com>
Message-ID: <3761089f-f344-aaec-a476-7d61e4b94b54@usu.edu>

Dr. Abou - check into the R package NADA, written by Dennis Helsel and 
colleagues of the USGS and Practical Stats. It may include what you want.

Best regards,

David

On 8/30/2021 3:28 AM, AbouEl-Makarim Aboueissa wrote:
> Dear All:
>
>
>
>
>
> I am wondering if someone have an R codes (R functions) to run the test
> procedures described in the paper titled ?ESTIMATION AND COMPARISON OF
> LOGNORMAL PARAMETERS IN THE PRESENCE OF CENSORED DATA? by STAVROS POULOUKAS
> 2004, Journal of Statistical Computation & Simulation, Vol. 74, No. 3,
> March 2004, pp. 157?169.
>
>
>
>
>
> with many thanks
>
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> CAUTION: This email originated from outside of USU. If this appears to be a USU employee, beware of impersonators. Do not click links, reply, download images, or open attachments unless you verify the sender?s identity and know the content is safe.
>
-- 
David K Stevens, PhD,PE
Professor
Civil and Environmental Engineering
Utah State University
Logan, UT 84322-8200
david.stevens at usu.edu
014357973229


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Mon Aug 30 18:15:25 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Mon, 30 Aug 2021 21:15:25 +0500
Subject: [R] Gene Set Enrichment Analysis and plots
Message-ID: <CAG0CrLjPetUO00qmDk5ytv8aKHXdnapFpRX7_+mpR+n6BGYWcA@mail.gmail.com>

I have done this analysis:

#You can select Working Directory according to your choice
setwd("D:")

#Check Working Directory
getwd()

#Creation of object(folder) exdir
exdir <- path.expand("~/GSE162562_RAW")
dir.create(exdir, showWarnings = FALSE)

URL <- "
https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
"
FILE <- file.path(tempdir(), basename(URL))

#Downlaod the Raw Data from GEO
utils::download.file(URL, FILE, mode = "wb")

#unzip the files and storing them in GSE162562_RAW folder which we created
already
utils::untar(FILE, exdir = exdir)

#Check your GSE162562_RAW folder after this , it must contains 108 samples
in compressed format

unlink(FILE, recursive = TRUE, force = TRUE)

#listing of samples
listed_files <- list.files(exdir, pattern=".gz", full.names=TRUE)


#/ load files into R:
loaded <- lapply(listed_files, function(x) read.delim(x, header=FALSE,
row.names = "V1"))

#/ bind everything into a single count matrix and assign colnames:
raw_counts <- do.call(cbind, loaded)
colnames(raw_counts) <- gsub(".txt.*", "", basename(listed_files))



#/ there is some nonsense in these files, probably due to the tool that was
used (HTSeq?),
#/ such as rows with names "__no_feature", lets remove that:
raw_counts <- raw_counts[!grepl("^__", rownames(raw_counts)),]

# / View raw_counts after filtering
raw_counts
#There are total 26364 genes after filtering

#Store Raw counts in CSV File
#I am sacing them in my Desktop.You can save according to your choice
write.csv(raw_counts,"C:\\Users\\USER\\Desktop\\countsdata.csv")

#load library
library(DESeq2)

#/ make a DESeq2 object. We can parse the group membership (Mild etc) from
the colnames,
#/ which are based on the original filenames:

dds <- DESeqDataSetFromMatrix(
  countData=raw_counts,

colData=data.frame(group=factor(unlist(lapply(strsplit(colnames(raw_counts),
split="_"), function(x) x[4])))),
  design=~group)


#View Deseq2 object
dds

#/ some Quality Control via PCA using the in-built PCA function from DESeq2:
vsd <- vst(dds, blind=TRUE)
#/ plot the PCA:
plotPCA(vsd, "group")


#/ extract the data:
pcadata <- plotPCA(vsd, "group", returnData=TRUE)

#view pca data
pcadata

#/ there is a very obvious batch effect, that we can correct, simply
everything that is greater or less than zero in the first principal
component, very obvious just by looking at the plot:
dds$batch <- factor(ifelse(pcadata$PC1 > 0, "batch1", "batch2"))

#/ lets use limma::removeBatchEffect to see whether it can be removed:
library(limma)
vsd2 <- vsd
assay(vsd2) <- removeBatchEffect(assay(vsd), batch=dds$batch)


#/ plot PCA again, looks much better. this means we modify our design to
include batch and group,
plotPCA(vsd2, "group")

#include batch and group both in design
design(dds) <- ~batch + group

#Running the differential expression pipeline
dds <- DESeq(dds)

#Building the results table
res <- results(dds)
res

#Saving Results in CSV file

write.csv(res , "dds.csv")

mcols(res, use.names = TRUE)

#We can also summarize the results with the following line of code, which
reports some additional information:
summary(res)

#Total 1236 DEGs have been found when we se p_value less than 0.1

table(res$padj < 0.01)

res.05 <- results(dds, alpha = 0.05)

summary(res.05)

table(res.05$padj < 0.05)

sum(res$pvalue < 0.05, na.rm=TRUE)

sum(!is.na(res$pvalue<0.05))

sum(res$padj < 0.1, na.rm=TRUE)

sum(res$padj < 0.05, na.rm=TRUE)

resSig <- subset(res, padj < 0.1)

head(resSig[ order(resSig$log2FoldChange),])

head(resSig[ order(resSig$log2FoldChange, decreasing = TRUE), ])

#Save DEGS at padj < 0.1
write.csv(resSig,"DEGs at 0.1.csv")

resSig0.05 <- subset(res, padj < 0.05)

#Save DEGS at padj < 0.01
write.csv(resSig0.05,"DEGs at 0.05.csv")


Now I want to do gene set enrichment analysis by using topgo library and
also want to make a heatmap and Venn diagram. Please help me

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Aug 30 20:28:55 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 30 Aug 2021 11:28:55 -0700 (PDT)
Subject: [R] bookdown: build using pdflatex from source directory
Message-ID: <alpine.LNX.2.20.2108301119050.15422@salmo.appl-ecosys.com>

I have a dead tree copy of 'R for Data Science' and want a PDF that's more
efficiently accessed when I'm working with R.

Installed here are all the files in r4ds-master/. Reading the online copy of
'bookdown: Authoring Books and Technical Documents with R Markdown' I'm not
seeing how to build the pdf copy from the source located in ~/R/r4ds-master/
and I'm running R in a different virtual terminal.

Would the command (issued in R):
bookdown::render_book("R/r4ds-master/rmarkdown.Rmd")
compile the entire book?

Rich


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug 30 22:45:43 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 30 Aug 2021 21:45:43 +0100
Subject: [R] bookdown: build using pdflatex from source directory
In-Reply-To: <alpine.LNX.2.20.2108301119050.15422@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108301119050.15422@salmo.appl-ecosys.com>
Message-ID: <cf7a37f4-7caa-6f3c-f863-b1bc47fab314@sapo.pt>

Hello,

Assuming the file index.Rmd is in R/r4ds-master, try

bookdown::render_book("R/r4ds-master/index.Rmd", output_format = 
"bookdown::pdf_book")


Hope this helps,

Rui Barradas

?s 19:28 de 30/08/21, Rich Shepard escreveu:
> I have a dead tree copy of 'R for Data Science' and want a PDF that's more
> efficiently accessed when I'm working with R.
> 
> Installed here are all the files in r4ds-master/. Reading the online 
> copy of
> 'bookdown: Authoring Books and Technical Documents with R Markdown' I'm not
> seeing how to build the pdf copy from the source located in 
> ~/R/r4ds-master/
> and I'm running R in a different virtual terminal.
> 
> Would the command (issued in R):
> bookdown::render_book("R/r4ds-master/rmarkdown.Rmd")
> compile the entire book?
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 30 23:01:07 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 30 Aug 2021 14:01:07 -0700
Subject: [R] Gene Set Enrichment Analysis and plots
In-Reply-To: <CAG0CrLjPetUO00qmDk5ytv8aKHXdnapFpRX7_+mpR+n6BGYWcA@mail.gmail.com>
References: <CAG0CrLjPetUO00qmDk5ytv8aKHXdnapFpRX7_+mpR+n6BGYWcA@mail.gmail.com>
Message-ID: <CAGxFJbS-JNvYWH4=P+CBKqy6VKmM_MmATWho5DfJ37t8k_TdTg@mail.gmail.com>

Please read the posting guide linked below for how to post questions
that are likely to receive useful responses. "Help me do a gene
enrichment analysis" does not conform to the pg. We usually expect
posters to offer their best attempts, preferably in a reproducible
example ("a reprex" -- see here for discussion:
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
), to provide help.

Also note that per the pg:
"For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
If the question relates to a contributed package , e.g., one
downloaded from CRAN, try contacting the package maintainer first. You
can also use find("functionname") and
packageDescription("packagename") to find this information. Only send
such questions to R-help or R-devel if you get no reply or need
further assistance. This applies to both requests for help and to bug
reports."

Finally, note that "topgo" is a Bioconductor **package** (not
"library"), and you should almost certainly post questions about its
use on their support site not here:
https://www.bioconductor.org/help/

(Do read their pg before posting, of course)

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Aug 30, 2021 at 9:22 AM Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>
> I have done this analysis:
>
> #You can select Working Directory according to your choice
> setwd("D:")
>
> #Check Working Directory
> getwd()
>
> #Creation of object(folder) exdir
> exdir <- path.expand("~/GSE162562_RAW")
> dir.create(exdir, showWarnings = FALSE)
>
> URL <- "
> https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162562/suppl/GSE162562_RAW.tar
> "
> FILE <- file.path(tempdir(), basename(URL))
>
> #Downlaod the Raw Data from GEO
> utils::download.file(URL, FILE, mode = "wb")
>
> #unzip the files and storing them in GSE162562_RAW folder which we created
> already
> utils::untar(FILE, exdir = exdir)
>
> #Check your GSE162562_RAW folder after this , it must contains 108 samples
> in compressed format
>
> unlink(FILE, recursive = TRUE, force = TRUE)
>
> #listing of samples
> listed_files <- list.files(exdir, pattern=".gz", full.names=TRUE)
>
>
> #/ load files into R:
> loaded <- lapply(listed_files, function(x) read.delim(x, header=FALSE,
> row.names = "V1"))
>
> #/ bind everything into a single count matrix and assign colnames:
> raw_counts <- do.call(cbind, loaded)
> colnames(raw_counts) <- gsub(".txt.*", "", basename(listed_files))
>
>
>
> #/ there is some nonsense in these files, probably due to the tool that was
> used (HTSeq?),
> #/ such as rows with names "__no_feature", lets remove that:
> raw_counts <- raw_counts[!grepl("^__", rownames(raw_counts)),]
>
> # / View raw_counts after filtering
> raw_counts
> #There are total 26364 genes after filtering
>
> #Store Raw counts in CSV File
> #I am sacing them in my Desktop.You can save according to your choice
> write.csv(raw_counts,"C:\\Users\\USER\\Desktop\\countsdata.csv")
>
> #load library
> library(DESeq2)
>
> #/ make a DESeq2 object. We can parse the group membership (Mild etc) from
> the colnames,
> #/ which are based on the original filenames:
>
> dds <- DESeqDataSetFromMatrix(
>   countData=raw_counts,
>
> colData=data.frame(group=factor(unlist(lapply(strsplit(colnames(raw_counts),
> split="_"), function(x) x[4])))),
>   design=~group)
>
>
> #View Deseq2 object
> dds
>
> #/ some Quality Control via PCA using the in-built PCA function from DESeq2:
> vsd <- vst(dds, blind=TRUE)
> #/ plot the PCA:
> plotPCA(vsd, "group")
>
>
> #/ extract the data:
> pcadata <- plotPCA(vsd, "group", returnData=TRUE)
>
> #view pca data
> pcadata
>
> #/ there is a very obvious batch effect, that we can correct, simply
> everything that is greater or less than zero in the first principal
> component, very obvious just by looking at the plot:
> dds$batch <- factor(ifelse(pcadata$PC1 > 0, "batch1", "batch2"))
>
> #/ lets use limma::removeBatchEffect to see whether it can be removed:
> library(limma)
> vsd2 <- vsd
> assay(vsd2) <- removeBatchEffect(assay(vsd), batch=dds$batch)
>
>
> #/ plot PCA again, looks much better. this means we modify our design to
> include batch and group,
> plotPCA(vsd2, "group")
>
> #include batch and group both in design
> design(dds) <- ~batch + group
>
> #Running the differential expression pipeline
> dds <- DESeq(dds)
>
> #Building the results table
> res <- results(dds)
> res
>
> #Saving Results in CSV file
>
> write.csv(res , "dds.csv")
>
> mcols(res, use.names = TRUE)
>
> #We can also summarize the results with the following line of code, which
> reports some additional information:
> summary(res)
>
> #Total 1236 DEGs have been found when we se p_value less than 0.1
>
> table(res$padj < 0.01)
>
> res.05 <- results(dds, alpha = 0.05)
>
> summary(res.05)
>
> table(res.05$padj < 0.05)
>
> sum(res$pvalue < 0.05, na.rm=TRUE)
>
> sum(!is.na(res$pvalue<0.05))
>
> sum(res$padj < 0.1, na.rm=TRUE)
>
> sum(res$padj < 0.05, na.rm=TRUE)
>
> resSig <- subset(res, padj < 0.1)
>
> head(resSig[ order(resSig$log2FoldChange),])
>
> head(resSig[ order(resSig$log2FoldChange, decreasing = TRUE), ])
>
> #Save DEGS at padj < 0.1
> write.csv(resSig,"DEGs at 0.1.csv")
>
> resSig0.05 <- subset(res, padj < 0.05)
>
> #Save DEGS at padj < 0.01
> write.csv(resSig0.05,"DEGs at 0.05.csv")
>
>
> Now I want to do gene set enrichment analysis by using topgo library and
> also want to make a heatmap and Venn diagram. Please help me
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Aug 30 23:16:17 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 30 Aug 2021 14:16:17 -0700 (PDT)
Subject: [R] bookdown: build using pdflatex from source directory
In-Reply-To: <cf7a37f4-7caa-6f3c-f863-b1bc47fab314@sapo.pt>
References: <alpine.LNX.2.20.2108301119050.15422@salmo.appl-ecosys.com>
 <cf7a37f4-7caa-6f3c-f863-b1bc47fab314@sapo.pt>
Message-ID: <alpine.LNX.2.20.2108301410150.15422@salmo.appl-ecosys.com>

On Mon, 30 Aug 2021, Rui Barradas wrote:

> Assuming the file index.Rmd is in R/r4ds-master, try
> bookdown::render_book("R/r4ds-master/index.Rmd", output_format = 
> "bookdown::pdf_book")

Rui,

The build needs to run it from the r4ds-master/ directory. I wondered if
index.rmd was the entry, but didn't try it because the index is at the end
of the book.

The build shows 100% completion, but:
label: unnamed-chunk-67 (with options) 
List of 1
  $ indent: chr "    "

   |......................................................................| 100%
    inline R code fragments

output file: strings.knit.md

Error: Functions that produce HTML output found in document targeting latex output.
Please change the output type of this document to HTML. Alternatively, you can allow
HTML output in non-HTML formats by adding this option to the YAML front-matter of
your rmarkdown file:

   always_allow_html: true

Note however that the HTML output will not be visible in non-HTML formats.

Execution halted
Error in Rscript_render(f, render_args, render_meta, add1, add2) :
   Failed to compile strings.Rmd

And I have no idea how to fix this.

I can try downloading it from github again and see if that makes a
difference.

Many thanks,

Rich


From r@oknz @end|ng |rom gm@||@com  Tue Aug 31 01:18:47 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 31 Aug 2021 11:18:47 +1200
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
Message-ID: <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>

I made up fake data in order to avoid showing untested code.
It's not part of the process I was recommending.
I expect data recorded every N minutes to use NA when something
is missing, not to simply not be recorded.  Well and good, all that
means is that reshaping the data is not a trivial call to matrix().
It does not mean that any additional package is needed or appropriate
and it does not affect the rest of the process.

You will want the POSIXct class, see ?DateTimeClasses.
Do you know whether the time stamps are in universal time or in
local time?

Above all, it doesn't affect the point that you probably should not
be doing any of this.

On Tue, 31 Aug 2021 at 00:42, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Mon, 30 Aug 2021, Richard O'Keefe wrote:
>
> > Why would you need a package for this?
> >> samples.per.day <- 12*24
> >
> > That's 12 5-minute intervals per hour and 24 hours per day.
> > Generate some fake data.
>
> Richard,
>
> The problem is that there are days with fewer than 12 recorded values for
> various reasons.
>
> When testing algorithms I use small subsets of actual data rather than fake
> data.
>
> Thanks for your detailed procedure.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Aug 31 01:34:18 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 30 Aug 2021 16:34:18 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>

On Tue, 31 Aug 2021, Richard O'Keefe wrote:

> I made up fake data in order to avoid showing untested code. It's not part
> of the process I was recommending. I expect data recorded every N minutes
> to use NA when something is missing, not to simply not be recorded. Well
> and good, all that means is that reshaping the data is not a trivial call
> to matrix(). It does not mean that any additional package is needed or
> appropriate and it does not affect the rest of the process.

Richard,

The instruments in the gauge pipe don't know to write NA when they're not
measuring. :-) The outage period varies greatly by location, constituent
measured, and other unknown factors.

> You will want the POSIXct class, see ?DateTimeClasses. Do you know whether
> the time stamps are in universal time or in local time?

The data values are not timestamps. There's one column for date a second
colume for time and a third column for time zone (P in the case of the west
coast.

> Above all, it doesn't affect the point that you probably should not
> be doing any of this.

? (Doesn't require an explanation.)

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Aug 31 01:47:09 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 30 Aug 2021 19:47:09 -0400
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
Message-ID: <043b01d79df9$5906e2c0$0b14a840$@verizon.net>

Am I seeing an odd aspect to this discussion.

There are many ways to solve problems and some may be favored by some more
than others.

All require some examination of the data so it can be massaged into shape
for the processes that follow.

If you insist on using the matrix method to arrange that each row or column
has the data you want, then, yes, you need to guarantee all your data is
present and in the right order. If some may be missing, you may want to
write a program that generates all possible dates in order and interpolates
them back (or into a copy more likely) so all the missing items are
represented and show up as an NA or whatever you want. You may also want to
check all dates are in order with no duplicates and anything else that makes
sense and then you are free to ask the vector to be seen as a matrix with N
columns or rows.

For many, the solution is much cleaner to use constructs that may be more
resistant to imperfections or allow them to be treated better. I would
probably use tidyverse functionality these days but can easily understand
people preferring base R or other packages. I have done similar analyses of
real data gathered from streams of various chemicals and levels taken at
various times and depths including times no measures happened and times
there were more than one measure. It is thus much more robust to use methods
like group_by and then apply other such verbs already being done grouped and
especially when the next steps involved making plots with ggplot. It was
rather trivial for example, to replace multiple measures by the average of
the measures. And many of my plots are faceted by variables which is not
trivial to do in base R.

I suggest not falling in love with the first way you think of and try to
bend everything to fit. Yes, some methods may be quite a bit more efficient
but rarely do I run into problems even with quite large collections of data
like a quarter million rows with dozens of columns, including odd columns
like the output of some analysis.

And note the current set of data may be extended with more over time or you
may get other data collected that would not necessarily work well with a
hard-coded method but might easily adjust to a new method. 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, August 30, 2021 7:34 PM
To: R Project Help <r-help at r-project.org>
Subject: Re: [R] Calculate daily means from 5-minute interval data

On Tue, 31 Aug 2021, Richard O'Keefe wrote:

> I made up fake data in order to avoid showing untested code. It's not 
> part of the process I was recommending. I expect data recorded every N 
> minutes to use NA when something is missing, not to simply not be 
> recorded. Well and good, all that means is that reshaping the data is 
> not a trivial call to matrix(). It does not mean that any additional 
> package is needed or appropriate and it does not affect the rest of the
process.

Richard,

The instruments in the gauge pipe don't know to write NA when they're not
measuring. :-) The outage period varies greatly by location, constituent
measured, and other unknown factors.

> You will want the POSIXct class, see ?DateTimeClasses. Do you know 
> whether the time stamps are in universal time or in local time?

The data values are not timestamps. There's one column for date a second
colume for time and a third column for time zone (P in the case of the west
coast.

> Above all, it doesn't affect the point that you probably should not be 
> doing any of this.

? (Doesn't require an explanation.)

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 31 01:53:43 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 30 Aug 2021 16:53:43 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQuhWY5LwJaMp-BmEQm0pvdkGb7vP4RuVYEFW=k7yxybQ@mail.gmail.com>

I do not wish to express any opinion on what should be done or how. But...

1. I assume that when data are missing, they are missing -- i.e.
simply not present in the data. So there will be possibly several/many
in succession missing rows of data corresponding to those times,
right? (Apologies for being a bit dumb about this, but I always need
to check that what I think is blindingly obvious really is).

2. Do note that when one takes daily averages/sd's/whatever summaries
of data that, because of missingness, may be calculated from possibly
quite different numbers of data points -- are whole days sometimes
missing?? -- then all the summaries (e.g. means) are not created
equal: summaries created from more data are more "trustworthy" and
should receive "appropriately" greater weight than those created from
fewer. Makes sense, right?

So I suspect that this may not be as straightforward as you think --
you may wish to find a local statistician with some experience in
these sorts of things to help you deal with them. Up to you, of
course.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 30, 2021 at 4:34 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 31 Aug 2021, Richard O'Keefe wrote:
>
> > I made up fake data in order to avoid showing untested code. It's not part
> > of the process I was recommending. I expect data recorded every N minutes
> > to use NA when something is missing, not to simply not be recorded. Well
> > and good, all that means is that reshaping the data is not a trivial call
> > to matrix(). It does not mean that any additional package is needed or
> > appropriate and it does not affect the rest of the process.
>
> Richard,
>
> The instruments in the gauge pipe don't know to write NA when they're not
> measuring. :-) The outage period varies greatly by location, constituent
> measured, and other unknown factors.
>
> > You will want the POSIXct class, see ?DateTimeClasses. Do you know whether
> > the time stamps are in universal time or in local time?
>
> The data values are not timestamps. There's one column for date a second
> colume for time and a third column for time zone (P in the case of the west
> coast.
>
> > Above all, it doesn't affect the point that you probably should not
> > be doing any of this.
>
> ? (Doesn't require an explanation.)
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e|@g|n@m@t|@|@v @end|ng |rom @|umn|@hu-ber||n@de  Tue Aug 31 00:25:02 2021
From: e|@g|n@m@t|@|@v @end|ng |rom @|umn|@hu-ber||n@de (Mstislav Elagin)
Date: Tue, 31 Aug 2021 00:25:02 +0200
Subject: [R] R-lang.epub is invalid according to epubcheck
Message-ID: <354288dd676eeb1b1c46ca95cd57a968.squirrel@webmail.alumni.hu-berlin.de>

Hello R folks,

when validating the epub version of "The R language definition" from

https://cran.r-project.org/doc/manuals/r-release/R-lang.epub

with epubcheck (https://github.com/w3c/epubcheck), the latter reports 490
errors. According to the Makefile in R sources, epubs are being produced
using calibre. Using another converter
(https://github.com/jlhg/texinfo2epub ) that transforms via Docbook XSL
leads to a clean epub (according to the epubcheck). In the past I
encountered quite a few invalid epubs that confuse my e-ink reader and
were made by calibre. Might it be worth switching the epub converter?

Best regards
/me


From r@oknz @end|ng |rom gm@||@com  Tue Aug 31 07:11:18 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 31 Aug 2021 17:11:18 +1200
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
Message-ID: <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>

By the time you get the data from the USGS, you are already far past the point
where what the instruments can write is important.
(Obviously an instrument can be sufficiently broken that it cannot
write anything.)
The data for Rogue River that I just downloaded include this comment:

# Data for the following 1 site(s) are contained in this file
#    USGS 04118500 ROGUE RIVER NEAR ROCKFORD, MI
# -----------------------------------------------------------------------------------
#
# Data provided for site 04118500
#            TS   parameter     Description
#         71932       00060     Discharge, cubic feet per second
#
# Data-value qualification codes included in this output:
#     A  Approved for publication -- Processing and review completed.
#     P  Provisional data subject to revision.
#     e  Value has been estimated.
#
agency_cd site_no datetime tz_cd 71932_00060 71932_00060_cd
5s 15s 20d 6s 14n 10s

(I do not know what the last line signifies.)
It is, I think, sufficiently clear that the instrument does not know what
the qualification code is!

After using read.delim to read the file

I note that the timestamps are in a single column, formatted like
"2020-08-30 00:15", matching the pattern "%Y-%m-%d %H:%M".

After reading the data into R and using
r$datetime <- as.POSIXct(r$datetime, format="%Y-%m-%d %H:%M",
                           tz=r$tz_cd)
I get
  agency           site            datetime                     tz
 USGS:33550   Min.   :4118500   Min.   :2020-08-30 00:00:00   EST:33550
              1st Qu.:4118500   1st Qu.:2020-11-25 13:33:45
              Median :4118500   Median :2021-03-08 03:52:30
              Mean   :4118500   Mean   :2021-03-01 07:05:54
              3rd Qu.:4118500   3rd Qu.:2021-06-03 12:41:15
              Max.   :4118500   Max.   :2021-08-30 22:00:00
      flow        qual
 Min.   : 96.5   A  :18052
 1st Qu.:156.0   A:e:  757
 Median :193.0   P  :14741
 Mean   :212.5
 3rd Qu.:237.0
 Max.   :767.0

So for this data set, spanning one year, all the times are in the same time
zone, observations are 15 minutes apart, not 5, and there are no missing
data.  This was obviously the wrong data set.
Oh well, picking an epoch such as
> epoch <- min(r$datetime)
and then calculating
as.numeric(difftime(timestamp, epoch, units="min")))
will give you a minute count from which determining day number
and bucket within day is trivial arithmetic.

I have attached a plot of the Rogue River flows which should make it
very clear what I mean by saying that means and standard deviations
are not a good way to characterise this kind of data.

The flow is dominated by a series of "bursts" with a fast onset to a peak
and a slow decay, coming in a range of sizes from quite small to rather
large, separated by gaps of 4 to 45 days.

I'd be looking at
 - how do I *detect* these bursts? (detecting a peak isn't too hard,
   but the peak is not the onset)
 - how do I *characterise* these bursts?
   (and is the onset rate related to the peak size?)
 - what's left after taking the bursts out?
 - can I relate these bursts to something going on upstream?

My usual recommendation is to start with things available in R out of the
box in order to reduce learning time.

On Tue, 31 Aug 2021 at 11:34, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 31 Aug 2021, Richard O'Keefe wrote:
>
> > I made up fake data in order to avoid showing untested code. It's not part
> > of the process I was recommending. I expect data recorded every N minutes
> > to use NA when something is missing, not to simply not be recorded. Well
> > and good, all that means is that reshaping the data is not a trivial call
> > to matrix(). It does not mean that any additional package is needed or
> > appropriate and it does not affect the rest of the process.
>
> Richard,
>
> The instruments in the gauge pipe don't know to write NA when they're not
> measuring. :-) The outage period varies greatly by location, constituent
> measured, and other unknown factors.
>
> > You will want the POSIXct class, see ?DateTimeClasses. Do you know whether
> > the time stamps are in universal time or in local time?
>
> The data values are not timestamps. There's one column for date a second
> colume for time and a third column for time zone (P in the case of the west
> coast.
>
> > Above all, it doesn't affect the point that you probably should not
> > be doing any of this.
>
> ? (Doesn't require an explanation.)
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rogue River.pdf
Type: application/pdf
Size: 86051 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210831/30014163/attachment.pdf>

From m|n@h@|| @end|ng |rom um|ch@edu  Tue Aug 31 12:48:25 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Tue, 31 Aug 2021 13:48:25 +0300
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: Your message of "Sat, 28 Aug 2021 13:19:01 +1200."
 <20210828131901.2394f863@rolf-Latitude-E7470>
Message-ID: <643116.1630406905@apollo2.minshall.org>

by the way, and "fwiw", the emacs org mode community seems to like using
latexmk for moving latex files towards .pdf'ishness:
----
https://mg.readthedocs.io/latexmk.html

cheers, Greg


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Aug 31 14:36:43 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 31 Aug 2021 05:36:43 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
 <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>

On Tue, 31 Aug 2021, Richard O'Keefe wrote:

> By the time you get the data from the USGS, you are already far past the point
> where what the instruments can write is important.

Richard,

The data are important because they show what's happened in that period of
record. Don't physicians take a medical history from patients even though
those data are far past the point they occurred?

> agency_cd site_no datetime tz_cd 71932_00060 71932_00060_cd
> 5s 15s 20d 6s 14n 10s
>
> (I do not know what the last line signifies.)

The numbers represent the space for each fixed-width field.

> After using read.delim to read the file
>
> I note that the timestamps are in a single column, formatted like
> "2020-08-30 00:15", matching the pattern "%Y-%m-%d %H:%M".
>
> After reading the data into R and using
> r$datetime <- as.POSIXct(r$datetime, format="%Y-%m-%d %H:%M",
>                           tz=r$tz_cd)

And I use emacs to replace the space between columns with commas so the date
and the time are separate.

> So for this data set, spanning one year, all the times are in the same time
> zone, observations are 15 minutes apart, not 5, and there are no missing
> data.  This was obviously the wrong data set.

As I provided when I first asked for suggestions:
sampdate,samptime,cfs
2020-08-26,09:30,136000
2020-08-26,09:35,126000
2020-08-26,09:40,130000
2020-08-26,09:45,128000
2020-08-26,09:50,126000
2020-08-26,09:55,125000

The recorded values are 5 minutes apart.

That data set is immaterial for my project but perfect when one needs data
from that gauge station on the Rogue River.

> The flow is dominated by a series of "bursts" with a fast onset to a peak
> and a slow decay, coming in a range of sizes from quite small to rather
> large, separated by gaps of 4 to 45 days.

And when discharge is controlled by flows through a hydroelectric dam there
is a lot of variability. The pattern is important to fish as well as
regulators.

> I'd be looking at
> - how do I *detect* these bursts? (detecting a peak isn't too hard,
>   but the peak is not the onset)
> - how do I *characterise* these bursts?
>   (and is the onset rate related to the peak size?)
> - what's left after taking the bursts out?
> - can I relate these bursts to something going on upstream?

Well, those questions could be appropriate depending on what questions you
need the data to answer.

Environmental data are quite different from experimental, economic,
financial, and public data (e.g., unemployment, housing costs).

There are always multiple ways to address an analytical need. Thank you for
your contributions.

Stay well,

Rich


From er|cjberger @end|ng |rom gm@||@com  Tue Aug 31 15:26:08 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 31 Aug 2021 16:26:08 +0300
Subject: [R] A glitch (???) in tools::texi2pf.
In-Reply-To: <643116.1630406905@apollo2.minshall.org>
References: <20210828131901.2394f863@rolf-Latitude-E7470>
 <643116.1630406905@apollo2.minshall.org>
Message-ID: <CAGgJW76xHyaJQNC_hhFub+FPS6zNSb42Tnc1rHSFOPGq9v2QFg@mail.gmail.com>

Thanks Greg!

On Tue, Aug 31, 2021 at 1:49 PM Greg Minshall <minshall at umich.edu> wrote:

> by the way, and "fwiw", the emacs org mode community seems to like using
> latexmk for moving latex files towards .pdf'ishness:
> ----
> https://mg.readthedocs.io/latexmk.html
>
> cheers, Greg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chr|@0web@ter @end|ng |rom gm@||@com  Tue Aug 31 16:08:34 2021
From: chr|@0web@ter @end|ng |rom gm@||@com (Chris Webster)
Date: Tue, 31 Aug 2021 10:08:34 -0400
Subject: [R] [R-pkgs] Announcing R package 'fedmatch'
Message-ID: <CAJqRp3b3Hv+xxP77MRxqBaNrqkxpHPRt0=FGyi8z7GJkd9GWFg@mail.gmail.com>

Hello all,
We have just released the R package 'fedmatch' to CRAN. Following is a
brief description and some links for more information:
With an ever-expanding set of financial data providers, each covering many
of the same firms and entities, matching data sets that do not share common
identifiers has never been more important. *fedmatch* is a set of tools for
performing record linkage between two data sets. It allows for a variety of
different matching techniques, letting the user build a matching algorithm
for their specific application. Although *fedmatch* was designed with
economic data in mind (i.e. loans or companies), it is very flexible, so it
can be used for any matching problem. With *fedmatch*, a researcher or
analyst can quickly go from having 0 matches between two datasets to having
many. With more time and care, they can use more advanced techniques to
pull out even more matches.
Website <https://seunglee98.github.io/fedmatch/>
CRAN <https://cran.r-project.org/package=fedmatch>
Thanks,
Chris Webster

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From e||z@_botto @end|ng |rom out|ook@com  Tue Aug 31 22:26:01 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Tue, 31 Aug 2021 20:26:01 +0000
Subject: [R] Converting characters back to Date and Time
Message-ID: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

DeaR useR,

I read an excel column in R having Date and time (written in the same cell) as follow,

06/18/18 10:00

06/18/18 11:00

06/18/18 12:00

In R environment, they are read as

43269.42

43269.46

43269.50

Is there a way to covert these characters back to the original format?

Thank-you very much in advance.


Eliza Botto

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Aug 31 23:11:05 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 31 Aug 2021 14:11:05 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>

On Sun, 29 Aug 2021, Jeff Newmiller wrote:

> The general idea is to create a "grouping" column with repeated values for
> each day, and then to use aggregate to compute your combined results. The
> dplyr package's group_by/summarise functions can also do this, and there
> are also proponents of the data.table package which is high performance
> but tends to depend on altering data in-place unlike most other R data
> handling functions.

Jeff,

I've read a number of docs discussing dplyr's summerize and group_by
functions (including that section of Hadley's 'R for Data Science' book, yet
I'm missing something; I think that I need to separate the single sampdate
column into colums for year, month, and day and group_by year/month
summarizing within those groups.

The data are of this format:
sampdate,samptime,cfs
2020-08-26,09:30,136000
2020-08-26,09:35,126000
2020-08-26,09:40,130000
2020-08-26,09:45,128000
2020-08-26,09:50,126000
2020-08-26,09:55,125000
2020-08-26,10:00,121000
2020-08-26,10:05,117000
2020-08-26,10:10,120000

My curent script is:

-------8<--------------
library('tidyverse')

discharge <- read.table('../data/discharge.dat', header = TRUE, sep = ',', stringsAsFactors = TRUE)
discharge$sampdate <- as.Date(discharge$sampdate)
discharge$cfs <- as.numeric(discharge$cfs, length = 6)

# use dplyr.summarize grouped by date

# need to separate sampdate into %Y-%M-%D in order to group_by the month?
by_month <- discharge %>%
   group_by(sampdate ...
summarize(by_month, exp_value = mean(cfs, na.rm = TRUE), sd(cfs))
---------------->8--------

and the results are:

> str(discharge)
'data.frame':	93254 obs. of  3 variables:
  $ sampdate: Date, format: "2020-08-26" "2020-08-26" ...
  $ samptime: Factor w/ 728 levels "00:00","00:05",..: 115 116 117 118 123 128 133 138 143 148 ...
  $ cfs     : num  176 156 165 161 156 154 144 137 142 142 ...
> ls()
[1] "by_month"  "discharge"
> by_month
# A tibble: 93,254 ? 3
# Groups:   sampdate [322]
    sampdate   samptime   cfs
    <date>     <fct>    <dbl>
  1 2020-08-26 09:30      176
  2 2020-08-26 09:35      156
  3 2020-08-26 09:40      165
  4 2020-08-26 09:45      161
  5 2020-08-26 09:50      156
  6 2020-08-26 09:55      154
  7 2020-08-26 10:00      144
  8 2020-08-26 10:05      137
  9 2020-08-26 10:10      142
10 2020-08-26 10:15      142
# ? with 93,244 more rows

I don't know why the discharge values are truncated to 3 digits when they're
6 digits in the input data.

Suggested readings appreciated,

Rich


From @kw@|mmo @end|ng |rom gm@||@com  Tue Aug 31 23:23:08 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 31 Aug 2021 17:23:08 -0400
Subject: [R] Converting characters back to Date and Time
In-Reply-To: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CAPcHnpRRCs1LjU6=YB=VamtKw1MPEvFXypvpEPFva3v6i4_Bjw@mail.gmail.com>

Hello,


I'm assuming you're reading from an "*.xlsx" file. I'm not sure which
package you're using for this scenario, but my preference is 'openxlsx'. If
this is the package you're using, you could set argument 'detectDates' to
'TRUE', and then it should read them correctly.


FILE <- tempfile(fileext = ".xlsx")


openxlsx::write.xlsx(
    data.frame(V1 = as.Date("2000-01-01")),
    FILE
)


openxlsx::read.xlsx(FILE)
openxlsx::read.xlsx(FILE, detectDates = TRUE)


unlink(FILE)


The first one should read the dates as numbers (days since 1900-01-01 or
1904-01-01, depending upon setup), while the second should parse them to
class "Date". I hope this helps!

On Tue, Aug 31, 2021 at 4:26 PM Eliza Botto <eliza_botto at outlook.com> wrote:

> DeaR useR,
>
> I read an excel column in R having Date and time (written in the same
> cell) as follow,
>
> 06/18/18 10:00
>
> 06/18/18 11:00
>
> 06/18/18 12:00
>
> In R environment, they are read as
>
> 43269.42
>
> 43269.46
>
> 43269.50
>
> Is there a way to covert these characters back to the original format?
>
> Thank-you very much in advance.
>
>
> Eliza Botto
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Tue Aug 31 23:39:35 2021
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Tue, 31 Aug 2021 14:39:35 -0700
Subject: [R] How to solve this?
In-Reply-To: <CALcx2BnOYqA9f+Rzdtnm=3X_o1vkQYuNUC4N++gGdgf-gJEeKA@mail.gmail.com>
References: <CALcx2BnOYqA9f+Rzdtnm=3X_o1vkQYuNUC4N++gGdgf-gJEeKA@mail.gmail.com>
Message-ID: <CAA99HCwjVvsGpXsaQiWZpf3RqsYwMDDHUj9kaOmT1Ta4R20GpQ@mail.gmail.com>

Hello,

You may have more luck posting your question to the R-SIG-Geo mailing-list:

https://stat.ethz.ch/mailman/listinfo/R-SIG-Geo/

Be sure to use an appropriate "Subject" line, for example, the
particular package/function that seems problematic.

HTH, Bill.

W. Michels, Ph.D.



On Mon, Aug 30, 2021 at 1:36 AM SITI AISYAH ZAKARIA
<aisyahzakaria at unimap.edu.my> wrote:
>
> Dear all,
>
> Can anyone help me? I'm using this coding to get the spatial gev model and
> plotting the quantile plot to justify the model is fit but the plot look
> like not fit.. How can I solve this? It is I need to change in the any
> value at the coding.For example I want to change form.shape <-shape ~1 to
> form.shape <- shape ~average shape but is not available for average coding.
>
> below is my coding
>
> #----------------------------------------------------------------------------------------------
> # fitspatgev
> #----------------------------------------------------------------------------------------------
> # response surface model
> Ozone<-data.matrix(Ozone_S)
> Ozone
> LotLatAlt<-data.matrix(OzoneLotLatAlt_S)
> LotLatAlt
> form.loc <- loc ~ Lon + Lat + Alt
> form.scale <- scale ~ 1
> form.shape <- shape ~ 1
> dim(Ozone_S)
> dim(OzoneLotLatAlt_S)
> fit1 <- fitspatgev(Ozone, scale(LotLatAlt,scale=FALSE), form.loc,
> form.scale, form.shape);fit1
> TIC(fit1)
> fit1$param
> #data(rain
> #symbolplot(rain, coord, plot.border = swiss)
> #check the fit of the model: compute QQplots for each station
> par(mfrow=c(1,3))
> par(mar=c(3,2.5,1.5,0.5),mgp=c(1.5,0.5,0),font.main=1,cex=0.66,cex.main=1)
> #calculation of confidance intervals
> nc <- 10000
> M1 <- matrix(rfrechet(nc*nobs),nrow=nobs,ncol=nc)
> M <- t(apply(M1,2,sort))
> E <- boot::envelope(mat=M) #compute 95% confidance bands
> for (k in c(1:3,4,5,6)){ #choose some stations
>   park <- predict(fit1)[k,]
>   fk <- gev2frech(Ozone[,k],loc=park[4],scale=park[5],shape=park[6])
>   qqplot(y=fk,x=qfrechet((1:nobs)/(nobs+1)),log='xy',main=k,ylab='Sample
> Quantiles',xlab='Theoretical Quantiles',cex=0.7);
>   abline(0,1)
>   lines(y=E$overall[1,],x=qfrechet((1:nobs)/(nobs +1)),lty='dotted')
>   lines(y=E$overall[2,],x=qfrechet((1:nobs)/(nobs +1)),lty='dotted')
> }
>
> the quantile plot is in attachment file.
> please, can anyone help me?
>
> thank you
>
> --
>
>
>
>
>
> "..Millions of trees are used to make papers, only to be thrown away
> after a couple of minutes reading from them. Our planet is at stake. Please
> be considerate. THINK TWICE BEFORE PRINTING THIS.."
>
> DISCLAIMER: This email
> and any files transmitted with it are confidential and intended solely for
> the use of the individual orentity to whom they are addressed. If you have
> received this email in error please notify the UniMAP's Email
> Administrator. Please note that any views or opinions presented in this
> email are solely those of the author and do not necessarily represent those
> of the university. Finally, the recipient should check this email and any
> attachments for the presence of viruses.The university accepts no liability
> for any damage caused by any virus transmitted by this email.
>
> Universiti
> Malaysia Perlis (UniMAP) | Digital Management & Development Centre (DMDC),
> Universiti Malaysia Perlis (UniMAP), Pauh Putra Campus, 02600 Arau, Perlis,
> MALAYSIA | www.unimap.edu.my <http://www.unimap.edu.my/>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |v@n @end|ng |rom @vetunkov@ru  Tue Aug 31 22:25:35 2021
From: |v@n @end|ng |rom @vetunkov@ru (Ivan Svetunkov)
Date: Tue, 31 Aug 2021 21:25:35 +0100
Subject: [R] forecast method in stats package
Message-ID: <CAEpiX9mYEgLEUBYSqBpp1xL=x0=ezSzt6Yqd7V62nfo4izMftw@mail.gmail.com>

Hi all,

I'm not sure where to post the suggestions for stats R package, so I've
decided to use the contact email from the package description.

There are several R packages that use "forecast()" method for purposes of
prediction (it is a bit different than "predict()"). The generic was
initially defined in "forecast" package, but now exists also in
"fabletools" and "greybox" (the two I know of, there might be others). And
as mentioned above, several packages implement the method for their
purposes (e.g. tsutils, nnfor, robets, fable, fasster, smooth etc), and
there are potential conflicts, when "forecast", "fabletools" and "greybox"
are used in the same script. So, given the popularity of the method,
wouldn't it make sense to implement the generic in "stats" package? The
default method could just call "predict.default()" with parameters provided
by the user. This would simplify the life of several package maintainers
and resolve the conflicts between packages. If needed, I could provide the
description of the method. Let me know what you think.

Kind regards,
Ivan Svetunkov.

	[[alternative HTML version deleted]]


