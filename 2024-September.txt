From @vi@e@gross m@iii@g oii gm@ii@com  Sun Sep  1 00:17:27 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 31 Aug 2024 18:17:27 -0400
Subject: [R] aggregating data with quality control
In-Reply-To: <27c3b1964d64474aac11678760647e61@regione.marche.it>
References: <27c3b1964d64474aac11678760647e61@regione.marche.it>
Message-ID: <017a01dafbf3$902a31c0$b07e9540$@gmail.com>

Stefano,

I see you already have an answer that works for you.

Sometimes you want to step back and see if some modification makes a problem easier to solve.

I often simply switch to using tools in the tidyverse such as dplyr for parts of the job albeit much of the same can be done using functions built-in to R.

In your case, there are many possible solutions besides taking the max in some way as in a factor column.

You seem to expect exactly 48 measurements. Currently you encode them as one of two character strings but if this is really a binary choice, you could have used a 0/1 or TRUE/FALSE column instead, or make one. This lets you do things like take the sum and compare it to 48 to see if all are true, or to zero to check if all are false. You could take the product to check if at least one is false or use a negation for another perspective. If the number of rows may not be 48, you can compare to a calculation of the actual number of rows in that subset.

If your data was placed into wide format, say based on your hs field being unique for each test site, there are similar ideas by taking a subset of the columns and applying things  by using functions like rowSum.

Again, some things I commonly use in dplyr such as group_by() and how it impacts other operations including reports, makes this a little different but most things can be done with careful use of base R, except areas where dplyr supports more and more abstract ways to specify what you want and that your example does not need.

Just FYI, you did not share what your function my.mean() is. 

I won't share the code unless interested but it looks like part of what you are doing is to bundle by a truncated version of date/time to just a day.  I am not sure your method is optimal. You make a list of three different things containing parts of a date. That can work but as dates are already looking like 2024-01-02 which sorts and compares well alphabetically, I wonder if instead you group by that.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Stefano Sofia
Sent: Saturday, August 31, 2024 7:15 AM
To: r-help at R-project.org
Subject: [R] aggregating data with quality control

Dear R-list users,

I deal with semi-hourly data from automatic meteorological stations.

They have to pass a manual validation; suppose that status = "C" stands for correct and status = "D" for discarded.

Here a simple example with "Snow height" (HS):


mydf <- data.frame(data_POSIX=seq(as.POSIXct("2024-01-01 00:00:00", format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT-1"), as.POSIXct("2024-01-02 23:30:00", format = "%Y-%m-%d %H:%M:%S", tz="Etc/GMT-1"), by="30 min"))

mydf$hs <- round(runif(96, 0, 100))

mydf$status <- c(rep("C", 50), "S", rep("C", 45))


Evaluating the daily mean indipendently from the status is very easy:

aggregate(mydf$hs, by=list(format(mydf$data_POSIX, "%Y"), format(mydf$data_POSIX, "%m"), format(mydf$data_POSIX, "%d")), my.mean)


Things become more complicated when I need to export also the status: this should be "C" when all 48 data have status equal to "C", and status "D" when at least one value has status ="D".


I have no clue on how to do that in an efficient way.

Could some of you give me some clues on how to do that?


Thank you for your usual support

Stefano Sofia


         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Tue Sep  3 01:26:17 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Tue, 3 Sep 2024 04:56:17 +0530
Subject: [R] Adding parameters for Benchmark normal distribution in
 shapiro.test
Message-ID: <CA+dpOJnCG=jhE=T4fdsq8F6X8JiLQmm81jX=kTGcMokywCC13w@mail.gmail.com>

Hi,

In ?shapiro.test, there seems to be no option to pass mean and sd
information of the Normal distribution which I want to compare my
sample data to.

For example in the code below, I want to test my sample to N(0, 10).

shapiro.test(rnorm(100, mean = 5, sd = 3))

Is there any way to pass the information of the benchmark normal distribution?


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep  3 01:53:50 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 02 Sep 2024 16:53:50 -0700
Subject: [R] Adding parameters for Benchmark normal distribution in
 shapiro.test
In-Reply-To: <CA+dpOJnCG=jhE=T4fdsq8F6X8JiLQmm81jX=kTGcMokywCC13w@mail.gmail.com>
References: <CA+dpOJnCG=jhE=T4fdsq8F6X8JiLQmm81jX=kTGcMokywCC13w@mail.gmail.com>
Message-ID: <637456A8-A64B-44DB-AADE-E660B413238B@dcn.davis.ca.us>

Wouldn't that be because the sample is not being compared to a specific distribution but rather to many possible distributions by MC? [1]

If you think that need not be the case, perhaps you can write your own test... but then it will probably be answering a different question?

[1] https://en.m.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test

On September 2, 2024 4:26:17 PM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>In ?shapiro.test, there seems to be no option to pass mean and sd
>information of the Normal distribution which I want to compare my
>sample data to.
>
>For example in the code below, I want to test my sample to N(0, 10).
>
>shapiro.test(rnorm(100, mean = 5, sd = 3))
>
>Is there any way to pass the information of the benchmark normal distribution?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bbo|ker @end|ng |rom gm@||@com  Tue Sep  3 02:22:08 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 2 Sep 2024 20:22:08 -0400
Subject: [R] Adding parameters for Benchmark normal distribution in
 shapiro.test
In-Reply-To: <CA+dpOJnCG=jhE=T4fdsq8F6X8JiLQmm81jX=kTGcMokywCC13w@mail.gmail.com>
References: <CA+dpOJnCG=jhE=T4fdsq8F6X8JiLQmm81jX=kTGcMokywCC13w@mail.gmail.com>
Message-ID: <d557d541-24cf-45dc-9bbb-d7b9d050f5f1@gmail.com>

   From Shapiro and Wilk's paper:

 > The objective is to derive a test for the hypothesis that this is a 
sample from a normal distribution with unknown mean mu and unknown 
variance sigma^2

  That is, the estimates of the mean and SD are folded into the 
derivation of the test statistic.

   If you want to test against a specified alternative you could try 
e.g. a Kolmogorov-Smirnov test

set.seed(101)
x <- rnorm(100, mean = 5, sd = 3)

ks.test(x, "pnorm", 0, 10)




On 2024-09-02 7:26 p.m., Christofer Bogaso wrote:
> Hi,
> 
> In ?shapiro.test, there seems to be no option to pass mean and sd
> information of the Normal distribution which I want to compare my
> sample data to.
> 
> For example in the code below, I want to test my sample to N(0, 10).
> 
> shapiro.test(rnorm(100, mean = 5, sd = 3))
> 
> Is there any way to pass the information of the benchmark normal distribution?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From p@ych@o||u @end|ng |rom gm@||@com  Tue Sep  3 18:30:54 2024
From: p@ych@o||u @end|ng |rom gm@||@com (Chao Liu)
Date: Tue, 3 Sep 2024 12:30:54 -0400
Subject: [R] Goodreader: Scrape and Analyze 'Goodreads' Book Data
Message-ID: <CACCU-vM3B95EnoYz=-wKf5r+iWm-O8iCW6h-cBo-q+kjvuRk1Q@mail.gmail.com>

Dear R Users,

I am pleased to announce that Goodreader 0.1.1 is now available on CRAN.

Goodreader offers a toolkit for scraping and analyzing book data from
Goodreads. Users can search for books, scrape detailed information and
reviews, perform sentiment analysis on reviews, and conduct topic modeling.

Here?s a quick overview of how to use Goodreader:
# Search for books
AI_df <- search_goodreads(search_term = "artificial intelligence",
search_in = "title", num_books = 10, sort_by = "ratings")

# Retrieve Book IDs and save them to a text file
get_book_ids(input_data = AI_df, file_name = "AI_books.txt")

# Get book-related information
scrape_books(book_ids_path = "AI_books.txt")

# Scrape book reviews
scrape_reviews(book_ids_path = "AI_books.txt", num_reviews = 10)

For more details, please visit: https://liu-chao.site/Goodreader/

Best regards,

Chao Liu

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Wed Sep  4 01:15:11 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Wed, 4 Sep 2024 04:45:11 +0530
Subject: [R] How R calculates SE of prediction for Logistic regression?
Message-ID: <CA+dpOJ=Opxvsc+GM06ge=Rpqecr6KTMr7x-WytL3W3uzndkbeQ@mail.gmail.com>

Hi,

I have below logistic regression

Dat =
read.csv('https://raw.githubusercontent.com/sam16tyagi/Machine-Learning-techniques-in-python/master/logistic%20regression%20dataset-Social_Network_Ads.csv')
head(Dat)
Model = glm(Purchased ~ Gender, data = Dat, family = binomial())

How I can get Standard deviation of forecasts as

head(predict(Model, type="response", se.fit = T)$se.fit)

My question: given that in Logistic regression, logit link is used,
how R calculate SE for the predicted probability from the VCV matrix
of estimated coefficients?

Does R uses some approximation like delta rule?


From |@go@g|ne @end|ng |rom @jd@e@  Wed Sep  4 07:23:48 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?iso-8859-1?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Wed, 4 Sep 2024 05:23:48 +0000
Subject: [R] fixed set.seed + kmeans output disagree on distinct platforms
Message-ID: <VI0PR02MB104934BC51026686BB56EEE3594922@VI0PR02MB10493.eurprd02.prod.outlook.com>

Hi all,

I build a dataset processing in the same way the same data in Windows than in Linux.

The output of Windows processing is: https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads
The output of Linux processing is: https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads

exdata=as.matrix(read.csv("https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads", header=FALSE))
exdata2=as.matrix(read.csv("https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads", header=FALSE))

They are not identical (`identical(exdata,exdata2)` is FALSE), but they are essentially equal (`all.equal(exdata,exdata2)` is TRUE). If I run

set.seed(20232260)
exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)

I get

exkmns$centers
          V1         V2          V3          V4          V5           V6
1 -0.4910731 -0.2662055  0.57928758  0.14267293 -0.03013791  0.106472717
2  0.5301237  0.2815620 -0.23898532  1.00979412 -0.26123328  0.068099931
3  0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
4 -0.2616257  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.028248679
5 -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
6  0.6455994 -0.1396674  0.05988547 -0.15557399  0.62766365  0.031051986
7  0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130

both in Windows  (1) and in Linux (2, 3) up to rows order. If I run in Linux in my computer (2)

set.seed(20232260)
exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)

then, I get

exkmns2$centers
           V1         V2          V3          V4          V5          V6
1  0.64559941 -0.1396674  0.05988547 -0.15557399  0.62766365  0.03105199
2 -0.26162573  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.02824868
3  0.53012369  0.2815620 -0.23898532  1.00979412 -0.26123328  0.06809993
4  0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
5 -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
6 -0.49107314 -0.2662055  0.57928758  0.14267293 -0.03013791  0.10647272
7  0.22552984 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.10753886

therefore, all rows essentially equal except for rows 5 and 7 of first dataset (5 and 4 of second dataset).  With a bit more detail:

  *
Row 0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855 belongs to exdata (and exdata2) and is center of both outputs
  *
Row 0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130 belongs to the dataset and it is only center of exdata output
  *
Row -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259 does not belong to the dataset and it is only center of exdata output
  *
Row -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379 belongs to the dataset and it is only center for exdata2 on Linux in my computer
  *
Row 0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180 does not belong to the dataset and it is only center for exdata2 on Linux in my computer
  *
All other 4 rows (1,2,4 and 6 of first output) do not belong to the dataset and are common centers.

Even, further, if I run

set.seed(20232260)
exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)

in  posit.cloud (3), I get the same result than above. However, if I run (both in posit.cloud or in Windows)

set.seed(20232260)
exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)

then I get


exkmns2$centers
          V1         V2          V3         V4          V5          V6
1  0.6426035 -0.1449498  0.05843435 -0.1527968  0.62943077  0.02984948
2 -0.4092382 -0.3740695  0.69597037  0.1956896 -0.05026200 -0.01453132
3  0.1072127  0.5538876 -0.33117098 -0.4320920 -0.18646403 -0.08127313
4  0.2255298 -0.5165964 -0.02498471 -0.2043827 -0.41224195 -0.10753886
5  0.5301237  0.2815620 -0.23898532  1.0097941 -0.26123328  0.06809993
6 -0.5223387 -0.1484517 -0.38982567 -0.0341488  0.06446446  0.03622056
7 -0.2701703  0.5263218  0.52942311 -0.1112202 -0.03460591  0.03577287

So only its rows 4 and 5 are common centers to both of previous outputs and row 3 is common width exdata centers.

Does all this have any sense?

Thanks!

Iago

(1)
R version 4.4.1 (2024-06-14 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 10 x64 (build 19045)

Matrix products: default

(2)
R version 4.4.1 (2024-06-14)
Platform: x86_64-pc-linux-gnu
Running under: Debian GNU/Linux 12 (bookworm)

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.21.so;  LAPACK version 3.11.0

(3)
R version 4.4.1 (2024-06-14)
Platform: x86_64-pc-linux-gnu
Running under: Ubuntu 20.04.6 LTS

 Matrix products: default
BLAS/LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.8.so;  LAPACK version 3.9.0




	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep  4 08:32:25 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 3 Sep 2024 23:32:25 -0700
Subject: [R] 
 fixed set.seed + kmeans output disagree on distinct platforms
In-Reply-To: <VI0PR02MB104934BC51026686BB56EEE3594922@VI0PR02MB10493.eurprd02.prod.outlook.com>
References: <VI0PR02MB104934BC51026686BB56EEE3594922@VI0PR02MB10493.eurprd02.prod.outlook.com>
Message-ID: <CAGxFJbR2AHToKZM+L0ZXnQSY+acZbBsMgYUPi9wM1GuXmBszSQ@mail.gmail.com>

I have no clue, but I did note that you are using different versions of
BLAS/LAPACK on the different platforms. Could that be (part) of the issue?

Cheers,
Bert

On Tue, Sep 3, 2024 at 10:24?PM Iago Gin? V?zquez <iago.gine at sjd.es> wrote:

> Hi all,
>
> I build a dataset processing in the same way the same data in Windows than
> in Linux.
>
> The output of Windows processing is:
> https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads
> The output of Linux processing is:
> https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads
>
> exdata=as.matrix(read.csv("
> https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads",
> header=FALSE))
> exdata2=as.matrix(read.csv("
> https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads",
> header=FALSE))
>
> They are not identical (`identical(exdata,exdata2)` is FALSE), but they
> are essentially equal (`all.equal(exdata,exdata2)` is TRUE). If I run
>
> set.seed(20232260)
> exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)
>
> I get
>
> exkmns$centers
>           V1         V2          V3          V4          V5           V6
> 1 -0.4910731 -0.2662055  0.57928758  0.14267293 -0.03013791  0.106472717
> 2  0.5301237  0.2815620 -0.23898532  1.00979412 -0.26123328  0.068099931
> 3  0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
> 4 -0.2616257  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.028248679
> 5 -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
> 6  0.6455994 -0.1396674  0.05988547 -0.15557399  0.62766365  0.031051986
> 7  0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130
>
> both in Windows  (1) and in Linux (2, 3) up to rows order. If I run in
> Linux in my computer (2)
>
> set.seed(20232260)
> exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)
>
> then, I get
>
> exkmns2$centers
>            V1         V2          V3          V4          V5          V6
> 1  0.64559941 -0.1396674  0.05988547 -0.15557399  0.62766365  0.03105199
> 2 -0.26162573  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.02824868
> 3  0.53012369  0.2815620 -0.23898532  1.00979412 -0.26123328  0.06809993
> 4  0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
> 5 -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
> 6 -0.49107314 -0.2662055  0.57928758  0.14267293 -0.03013791  0.10647272
> 7  0.22552984 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.10753886
>
> therefore, all rows essentially equal except for rows 5 and 7 of first
> dataset (5 and 4 of second dataset).  With a bit more detail:
>
>   *
> Row 0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
> belongs to exdata (and exdata2) and is center of both outputs
>   *
> Row 0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130
> belongs to the dataset and it is only center of exdata output
>   *
> Row -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
> does not belong to the dataset and it is only center of exdata output
>   *
> Row -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
> belongs to the dataset and it is only center for exdata2 on Linux in my
> computer
>   *
> Row 0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
> does not belong to the dataset and it is only center for exdata2 on Linux
> in my computer
>   *
> All other 4 rows (1,2,4 and 6 of first output) do not belong to the
> dataset and are common centers.
>
> Even, further, if I run
>
> set.seed(20232260)
> exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)
>
> in  posit.cloud (3), I get the same result than above. However, if I run
> (both in posit.cloud or in Windows)
>
> set.seed(20232260)
> exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)
>
> then I get
>
>
> exkmns2$centers
>           V1         V2          V3         V4          V5          V6
> 1  0.6426035 -0.1449498  0.05843435 -0.1527968  0.62943077  0.02984948
> 2 -0.4092382 -0.3740695  0.69597037  0.1956896 -0.05026200 -0.01453132
> 3  0.1072127  0.5538876 -0.33117098 -0.4320920 -0.18646403 -0.08127313
> 4  0.2255298 -0.5165964 -0.02498471 -0.2043827 -0.41224195 -0.10753886
> 5  0.5301237  0.2815620 -0.23898532  1.0097941 -0.26123328  0.06809993
> 6 -0.5223387 -0.1484517 -0.38982567 -0.0341488  0.06446446  0.03622056
> 7 -0.2701703  0.5263218  0.52942311 -0.1112202 -0.03460591  0.03577287
>
> So only its rows 4 and 5 are common centers to both of previous outputs
> and row 3 is common width exdata centers.
>
> Does all this have any sense?
>
> Thanks!
>
> Iago
>
> (1)
> R version 4.4.1 (2024-06-14 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 10 x64 (build 19045)
>
> Matrix products: default
>
> (2)
> R version 4.4.1 (2024-06-14)
> Platform: x86_64-pc-linux-gnu
> Running under: Debian GNU/Linux 12 (bookworm)
>
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.21.so;
> LAPACK version 3.11.0
>
> (3)
> R version 4.4.1 (2024-06-14)
> Platform: x86_64-pc-linux-gnu
> Running under: Ubuntu 20.04.6 LTS
>
>  Matrix products: default
> BLAS/LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/
> libopenblasp-r0.3.8.so;  LAPACK version 3.9.0
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep  4 10:41:34 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 4 Sep 2024 10:41:34 +0200
Subject: [R] 
 fixed set.seed + kmeans output disagree on distinct platforms
In-Reply-To: <CAGxFJbR2AHToKZM+L0ZXnQSY+acZbBsMgYUPi9wM1GuXmBszSQ@mail.gmail.com>
References: <VI0PR02MB104934BC51026686BB56EEE3594922@VI0PR02MB10493.eurprd02.prod.outlook.com>
 <CAGxFJbR2AHToKZM+L0ZXnQSY+acZbBsMgYUPi9wM1GuXmBszSQ@mail.gmail.com>
Message-ID: <26328.7486.699492.779127@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Tue, 3 Sep 2024 23:32:25 -0700 writes:

    > I have no clue, but I did note that you are using different versions of
    > BLAS/LAPACK on the different platforms. Could that be (part) of the issue?

Good catch!  My gut feeling would say "yes!" that is almost surely part of
the issue.

    > Cheers,
    > Bert

Additionally, careful reading of the help page (*before* any post ..)
would have shown

   Note:

	The clusters are numbered in the returned object, but they are a
	_set_ and no ordering is implied.  (Their apparent ordering may
	differ by platform.)


Martin



    > On Tue, Sep 3, 2024 at 10:24?PM Iago Gin? V?zquez <iago.gine at sjd.es> wrote:

    >> Hi all,
    >> 
    >> I build a dataset processing in the same way the same data in Windows than
    >> in Linux.
    >> 
    >> The output of Windows processing is:
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads
    >> The output of Linux processing is:
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads
    >> 
    >> exdata=as.matrix(read.csv("
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads",
    >> header=FALSE))
    >> exdata2=as.matrix(read.csv("
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads",
    >> header=FALSE))
    >> 
    >> They are not identical (`identical(exdata,exdata2)` is FALSE), but they
    >> are essentially equal (`all.equal(exdata,exdata2)` is TRUE). If I run
    >> 
    >> set.seed(20232260)
    >> exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)
    >> 
    >> I get
    >> 
    >> exkmns$centers
    >> V1         V2          V3          V4          V5           V6
    >> 1 -0.4910731 -0.2662055  0.57928758  0.14267293 -0.03013791  0.106472717
    >> 2  0.5301237  0.2815620 -0.23898532  1.00979412 -0.26123328  0.068099931
    >> 3  0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
    >> 4 -0.2616257  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.028248679
    >> 5 -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
    >> 6  0.6455994 -0.1396674  0.05988547 -0.15557399  0.62766365  0.031051986
    >> 7  0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130
    >> 
    >> both in Windows  (1) and in Linux (2, 3) up to rows order. If I run in
    >> Linux in my computer (2)
    >> 
    >> set.seed(20232260)
    >> exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)
    >> 
    >> then, I get
    >> 
    >> exkmns2$centers
    >> V1         V2          V3          V4          V5          V6
    >> 1  0.64559941 -0.1396674  0.05988547 -0.15557399  0.62766365  0.03105199
    >> 2 -0.26162573  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.02824868
    >> 3  0.53012369  0.2815620 -0.23898532  1.00979412 -0.26123328  0.06809993
    >> 4  0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
    >> 5 -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
    >> 6 -0.49107314 -0.2662055  0.57928758  0.14267293 -0.03013791  0.10647272
    >> 7  0.22552984 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.10753886
    >> 
    >> therefore, all rows essentially equal except for rows 5 and 7 of first
    >> dataset (5 and 4 of second dataset).  With a bit more detail:
    >> 
    >> *
    >> Row 0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
    >> belongs to exdata (and exdata2) and is center of both outputs
    >> *
    >> Row 0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130
    >> belongs to the dataset and it is only center of exdata output
    >> *
    >> Row -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
    >> does not belong to the dataset and it is only center of exdata output
    >> *
    >> Row -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
    >> belongs to the dataset and it is only center for exdata2 on Linux in my
    >> computer
    >> *
    >> Row 0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
    >> does not belong to the dataset and it is only center for exdata2 on Linux
    >> in my computer
    >> *
    >> All other 4 rows (1,2,4 and 6 of first output) do not belong to the
    >> dataset and are common centers.
    >> 
    >> Even, further, if I run
    >> 
    >> set.seed(20232260)
    >> exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)
    >> 
    >> in  posit.cloud (3), I get the same result than above. However, if I run
    >> (both in posit.cloud or in Windows)
    >> 
    >> set.seed(20232260)
    >> exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)
    >> 
    >> then I get
    >> 
    >> 
    >> exkmns2$centers
    >> V1         V2          V3         V4          V5          V6
    >> 1  0.6426035 -0.1449498  0.05843435 -0.1527968  0.62943077  0.02984948
    >> 2 -0.4092382 -0.3740695  0.69597037  0.1956896 -0.05026200 -0.01453132
    >> 3  0.1072127  0.5538876 -0.33117098 -0.4320920 -0.18646403 -0.08127313
    >> 4  0.2255298 -0.5165964 -0.02498471 -0.2043827 -0.41224195 -0.10753886
    >> 5  0.5301237  0.2815620 -0.23898532  1.0097941 -0.26123328  0.06809993
    >> 6 -0.5223387 -0.1484517 -0.38982567 -0.0341488  0.06446446  0.03622056
    >> 7 -0.2701703  0.5263218  0.52942311 -0.1112202 -0.03460591  0.03577287
    >> 
    >> So only its rows 4 and 5 are common centers to both of previous outputs
    >> and row 3 is common width exdata centers.
    >> 
    >> Does all this have any sense?
    >> 
    >> Thanks!
    >> 
    >> Iago
    >> 
    >> (1)
    >> R version 4.4.1 (2024-06-14 ucrt)
    >> Platform: x86_64-w64-mingw32/x64
    >> Running under: Windows 10 x64 (build 19045)
    >> 
    >> Matrix products: default
    >> 
    >> (2)
    >> R version 4.4.1 (2024-06-14)
    >> Platform: x86_64-pc-linux-gnu
    >> Running under: Debian GNU/Linux 12 (bookworm)
    >> 
    >> Matrix products: default
    >> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
    >> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.21.so;
    >> LAPACK version 3.11.0
    >> 
    >> (3)
    >> R version 4.4.1 (2024-06-14)
    >> Platform: x86_64-pc-linux-gnu
    >> Running under: Ubuntu 20.04.6 LTS
    >> 
    >> Matrix products: default
    >> BLAS/LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/
    >> libopenblasp-r0.3.8.so;  LAPACK version 3.9.0
    >>


From |@go@g|ne @end|ng |rom @jd@e@  Wed Sep  4 11:18:55 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?utf-8?B?SWFnbyBHaW7DqSBWw6F6cXVleg==?=)
Date: Wed, 4 Sep 2024 09:18:55 +0000
Subject: [R] 
 fixed set.seed + kmeans output disagree on distinct platforms
In-Reply-To: <26328.7486.699492.779127@stat.math.ethz.ch>
References: <VI0PR02MB104934BC51026686BB56EEE3594922@VI0PR02MB10493.eurprd02.prod.outlook.com>
 <CAGxFJbR2AHToKZM+L0ZXnQSY+acZbBsMgYUPi9wM1GuXmBszSQ@mail.gmail.com>
 <26328.7486.699492.779127@stat.math.ethz.ch>
Message-ID: <VI0PR02MB10493B13612F7B58FC7A3872A949C2@VI0PR02MB10493.eurprd02.prod.outlook.com>

Thanks both Bert and Martin,

However  exkmns2$centers is common in posit.cloud  - LAPACK version 3.9.0- and in Windows -LAPACK 3.12.0-, while  distinct with my Linux settings -LAPACK version 3.11.0- (I don't know the BLAS version used by R in windows). It is a bit strange...

Iago

________________________________
De: Martin Maechler <maechler at stat.math.ethz.ch>
Enviat el: dimecres, 4 de setembre de 2024 10:41
Per a: Bert Gunter <bgunter.4567 at gmail.com>
A/c: Iago Gin? V?zquez <iago.gine at sjd.es>; r-help at r-project.org <r-help at r-project.org>
Tema: Re: [R] fixed set.seed + kmeans output disagree on distinct platforms

>>>>> Bert Gunter
>>>>>     on Tue, 3 Sep 2024 23:32:25 -0700 writes:

    > I have no clue, but I did note that you are using different versions of
    > BLAS/LAPACK on the different platforms. Could that be (part) of the issue?

Good catch!  My gut feeling would say "yes!" that is almost surely part of
the issue.

    > Cheers,
    > Bert

Additionally, careful reading of the help page (*before* any post ..)
would have shown

   Note:

        The clusters are numbered in the returned object, but they are a
        _set_ and no ordering is implied.  (Their apparent ordering may
        differ by platform.)


Martin



    > On Tue, Sep 3, 2024 at 10:24?PM Iago Gin? V?zquez <iago.gine at sjd.es> wrote:

    >> Hi all,
    >>
    >> I build a dataset processing in the same way the same data in Windows than
    >> in Linux.
    >>
    >> The output of Windows processing is:
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads
    >> The output of Linux processing is:
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads
    >>
    >> exdata=as.matrix(read.csv("
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata.csv?ref_type=heads",
    >> header=FALSE))
    >> exdata2=as.matrix(read.csv("
    >> https://gitlab.com/iagogv/repdata/-/raw/main/exdata2.csv?ref_type=heads",
    >> header=FALSE))
    >>
    >> They are not identical (`identical(exdata,exdata2)` is FALSE), but they
    >> are essentially equal (`all.equal(exdata,exdata2)` is TRUE). If I run
    >>
    >> set.seed(20232260)
    >> exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)
    >>
    >> I get
    >>
    >> exkmns$centers
    >> V1         V2          V3          V4          V5           V6
    >> 1 -0.4910731 -0.2662055  0.57928758  0.14267293 -0.03013791  0.106472717
    >> 2  0.5301237  0.2815620 -0.23898532  1.00979412 -0.26123328  0.068099931
    >> 3  0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
    >> 4 -0.2616257  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.028248679
    >> 5 -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
    >> 6  0.6455994 -0.1396674  0.05988547 -0.15557399  0.62766365  0.031051986
    >> 7  0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130
    >>
    >> both in Windows  (1) and in Linux (2, 3) up to rows order. If I run in
    >> Linux in my computer (2)
    >>
    >> set.seed(20232260)
    >> exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)
    >>
    >> then, I get
    >>
    >> exkmns2$centers
    >> V1         V2          V3          V4          V5          V6
    >> 1  0.64559941 -0.1396674  0.05988547 -0.15557399  0.62766365  0.03105199
    >> 2 -0.26162573  0.5680582  0.55387437 -0.09562789 -0.01706577 -0.02824868
    >> 3  0.53012369  0.2815620 -0.23898532  1.00979412 -0.26123328  0.06809993
    >> 4  0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
    >> 5 -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
    >> 6 -0.49107314 -0.2662055  0.57928758  0.14267293 -0.03013791  0.10647272
    >> 7  0.22552984 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.10753886
    >>
    >> therefore, all rows essentially equal except for rows 5 and 7 of first
    >> dataset (5 and 4 of second dataset).  With a bit more detail:
    >>
    >> *
    >> Row 0.2255298 -0.5165964 -0.02498471 -0.20438275 -0.41224195 -0.107538855
    >> belongs to exdata (and exdata2) and is center of both outputs
    >> *
    >> Row 0.1072127  0.5538876 -0.33117098 -0.43209203 -0.18646403 -0.081273130
    >> belongs to the dataset and it is only center of exdata output
    >> *
    >> Row -0.4820078 -0.1667370 -0.46533618 -0.05271446  0.05477352  0.005236259
    >> does not belong to the dataset and it is only center of exdata output
    >> *
    >> Row -0.58527394 -0.1790337 -0.46778956  0.03573883  0.15473589 -0.07980379
    >> belongs to the dataset and it is only center for exdata2 on Linux in my
    >> computer
    >> *
    >> Row 0.03409765  0.3492520 -0.36910409 -0.40721418 -0.21482793  0.03073180
    >> does not belong to the dataset and it is only center for exdata2 on Linux
    >> in my computer
    >> *
    >> All other 4 rows (1,2,4 and 6 of first output) do not belong to the
    >> dataset and are common centers.
    >>
    >> Even, further, if I run
    >>
    >> set.seed(20232260)
    >> exkmns <- kmeans(exdata, centers = 7, iter.max = 2000, nstart = 750)
    >>
    >> in  posit.cloud (3), I get the same result than above. However, if I run
    >> (both in posit.cloud or in Windows)
    >>
    >> set.seed(20232260)
    >> exkmns2 <- kmeans(exdata2, centers = 7, iter.max = 2000, nstart = 750)
    >>
    >> then I get
    >>
    >>
    >> exkmns2$centers
    >> V1         V2          V3         V4          V5          V6
    >> 1  0.6426035 -0.1449498  0.05843435 -0.1527968  0.62943077  0.02984948
    >> 2 -0.4092382 -0.3740695  0.69597037  0.1956896 -0.05026200 -0.01453132
    >> 3  0.1072127  0.5538876 -0.33117098 -0.4320920 -0.18646403 -0.08127313
    >> 4  0.2255298 -0.5165964 -0.02498471 -0.2043827 -0.41224195 -0.10753886
    >> 5  0.5301237  0.2815620 -0.23898532  1.0097941 -0.26123328  0.06809993
    >> 6 -0.5223387 -0.1484517 -0.38982567 -0.0341488  0.06446446  0.03622056
    >> 7 -0.2701703  0.5263218  0.52942311 -0.1112202 -0.03460591  0.03577287
    >>
    >> So only its rows 4 and 5 are common centers to both of previous outputs
    >> and row 3 is common width exdata centers.
    >>
    >> Does all this have any sense?
    >>
    >> Thanks!
    >>
    >> Iago
    >>
    >> (1)
    >> R version 4.4.1 (2024-06-14 ucrt)
    >> Platform: x86_64-w64-mingw32/x64
    >> Running under: Windows 10 x64 (build 19045)
    >>
    >> Matrix products: default
    >>
    >> (2)
    >> R version 4.4.1 (2024-06-14)
    >> Platform: x86_64-pc-linux-gnu
    >> Running under: Debian GNU/Linux 12 (bookworm)
    >>
    >> Matrix products: default
    >> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
    >> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.21.so;
    >> LAPACK version 3.11.0
    >>
    >> (3)
    >> R version 4.4.1 (2024-06-14)
    >> Platform: x86_64-pc-linux-gnu
    >> Running under: Ubuntu 20.04.6 LTS
    >>
    >> Matrix products: default
    >> BLAS/LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/
    >> libopenblasp-r0.3.8.so;  LAPACK version 3.9.0
    >>

	[[alternative HTML version deleted]]


From @nupty@g| @end|ng |rom gm@||@com  Wed Sep  4 15:16:18 2024
From: @nupty@g| @end|ng |rom gm@||@com (Anupam Tyagi)
Date: Wed, 4 Sep 2024 18:46:18 +0530
Subject: [R] dotchart and dotplot(lattice) plot with two/three conditioning
 variables
Message-ID: <CAFL9eu=RLJ2-cdDSkjp_uokTnAahGxaX2YE6w51zE7kkm6YM_Q@mail.gmail.com>

Hello, I am trying to make a Cleaveland Dotplot with two, if possible
three, variables on the vertical axis. I was able to do it in Stata
with two variables, Year and Population (see graph at the link:
https://drive.google.com/file/d/1SiIfmmqk6IFa_OI5i26Ux1ZxkN2oek-o/view?usp=sharing
). I hope the link to the graph works. I have never tried this before.

I want to make a similar (possibly better) graph in R. I tried several
ways to make it in R with dotchart() and dotplot(lattice). I have been
only partially successful thus far. I would like Year, Population and
popGroup on the vertical axis. If popGroup occupies too much space,
then I would like a gap between the groups of Cities and Villages, so
they can be seen as distinct "Populations". My code and a made-up data
are below (in actual data I have 18 categories in "Population",
instead of only six in the made-up data). How can I make this type of
graph?

# Only for 2004-05. How to plot 2011-12 on the same plot?
dotchart(test$"X0_50"[test$"Year"=="2004-05"], labels=test$Population,
xlab = "Income Share ",
         main = "Income shares of percentiles of population", xlim = c(12, 50))
points(test$"X50_90"[test$"Year"=="2004-05"], 1:6, pch = 2)
points(test$"X90_100"[test$"Year"=="2004-05"], 1:6, pch = 16)
legend(x = "topleft",
       legend = c("0-50%", "50-90%", "90-100%"),
       pch = c(1,2, 16)
)

# reorder so Year 2004-05 is plotted before Year 2011-12. This is not
plotting correctly for
# second and third variables. Gap between different Cities and
Villages is quite a bit.
test2 <- test[order(test$seqCode, test$Year, decreasing = T),]

dotchart(test2$"X0_50", labels=test2$Year, xlab = "Income Share ",
         main = "Income shares of percentiles of population", groups =
as.factor(test2$Population), xlim = c(12, 50))
points(test2$"X50_90", 1:12, pch = 2)
points(test2$"X90_100", 1: 12, pch = 16)


# use lattice library
library(lattice)
dotplot(reorder(Population, -seqCode) ~ test$"X0_50" + test$"X50_90" +
test$"X90_100", data = test, auto.key = TRUE)

testLong <- reshape(test, idvar = c("Population", "Year"), varying = list(5:7),
                           v.names = "ptile", direction = "long")

dotplot(reorder(Population, -seqCode) ~ ptile | Year, data = testLong,
groups = time, auto.key = T)

Dataframe is below using dput(). Dataframe is named "test" in my code.

structure(list(seqCode = c(1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L,
4L, 5L, 6L), popGroup = c("City", "City", "City", "Village",
"Village", "Village", "City", "City", "City", "Village", "Village",
"Village"), Population = c("Dallas", "Boston", "Chicago", "Kip",
"Von", "Dan", "Dallas", "Boston", "Chicago", "Kip", "Von", "Dan"
), Year = c("2004-05", "2004-05", "2004-05", "2004-05", "2004-05",
"2004-05", "2011-12", "2011-12", "2011-12", "2011-12", "2011-12",
"2011-12"), X0_50 = c(15.47, 21.29, 18.04, 15.62, 18.89, 24.37,
17.43, 17.99, 18.04, 14.95, 16.33, 28.98), X50_90 = c(44.12,
43.25, 45.72, 46.15, 43.84, 46.24, 44.39, 44.08, 43.62, 42.89,
44.57, 47.14), X90_100 = c(40.42, 35.47, 36.24, 38.24, 37.27,
29.39, 38.18, 37.93, 38.34, 42.16, 39.11, 23.88)), class =
"data.frame", row.names = c(NA,
-12L))

--
Anupam.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Wed Sep  4 16:31:40 2024
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Wed, 4 Sep 2024 20:01:40 +0530
Subject: [R] 
 dotchart and dotplot(lattice) plot with two/three conditioning
 variables
In-Reply-To: <CAFL9eu=RLJ2-cdDSkjp_uokTnAahGxaX2YE6w51zE7kkm6YM_Q@mail.gmail.com>
References: <CAFL9eu=RLJ2-cdDSkjp_uokTnAahGxaX2YE6w51zE7kkm6YM_Q@mail.gmail.com>
Message-ID: <CADfFDC7PWFrncupE57PNmg_pTibOM7XyrgFBC5iNB44z=UGr1g@mail.gmail.com>

For lattice::dotplot(), you are close; this is more like the layout you
want:

dotplot(Year ~ ptile | reorder(Population, ptile, mean), testLong,
        groups = c("0-50", "50-90", "90-100")[time],
        layout = c(1, NA),
        par.settings = simpleTheme(pch = 16), auto.key = TRUE)

dotchart() works better with tables, but unfortunately it doesn't seem to
handle more than two dimensions, so you can only get one group at a time:

xtabs(ptile ~ Year + Population, testLong, subset = time == 1) |>
dotchart(pch = 16)

This seems like something that should not be too difficult to improve.

Best,
-Deepayan


On Wed, 4 Sept 2024 at 18:46, Anupam Tyagi <anuptyagi at gmail.com> wrote:

> Hello, I am trying to make a Cleaveland Dotplot with two, if possible
> three, variables on the vertical axis. I was able to do it in Stata
> with two variables, Year and Population (see graph at the link:
>
> https://drive.google.com/file/d/1SiIfmmqk6IFa_OI5i26Ux1ZxkN2oek-o/view?usp=sharing
> ). I hope the link to the graph works. I have never tried this before.
>
> I want to make a similar (possibly better) graph in R. I tried several
> ways to make it in R with dotchart() and dotplot(lattice). I have been
> only partially successful thus far. I would like Year, Population and
> popGroup on the vertical axis. If popGroup occupies too much space,
> then I would like a gap between the groups of Cities and Villages, so
> they can be seen as distinct "Populations". My code and a made-up data
> are below (in actual data I have 18 categories in "Population",
> instead of only six in the made-up data). How can I make this type of
> graph?
>
> # Only for 2004-05. How to plot 2011-12 on the same plot?
> dotchart(test$"X0_50"[test$"Year"=="2004-05"], labels=test$Population,
> xlab = "Income Share ",
>          main = "Income shares of percentiles of population", xlim = c(12,
> 50))
> points(test$"X50_90"[test$"Year"=="2004-05"], 1:6, pch = 2)
> points(test$"X90_100"[test$"Year"=="2004-05"], 1:6, pch = 16)
> legend(x = "topleft",
>        legend = c("0-50%", "50-90%", "90-100%"),
>        pch = c(1,2, 16)
> )
>
> # reorder so Year 2004-05 is plotted before Year 2011-12. This is not
> plotting correctly for
> # second and third variables. Gap between different Cities and
> Villages is quite a bit.
> test2 <- test[order(test$seqCode, test$Year, decreasing = T),]
>
> dotchart(test2$"X0_50", labels=test2$Year, xlab = "Income Share ",
>          main = "Income shares of percentiles of population", groups =
> as.factor(test2$Population), xlim = c(12, 50))
> points(test2$"X50_90", 1:12, pch = 2)
> points(test2$"X90_100", 1: 12, pch = 16)
>
>
> # use lattice library
> library(lattice)
> dotplot(reorder(Population, -seqCode) ~ test$"X0_50" + test$"X50_90" +
> test$"X90_100", data = test, auto.key = TRUE)
>
> testLong <- reshape(test, idvar = c("Population", "Year"), varying =
> list(5:7),
>                            v.names = "ptile", direction = "long")
>
> dotplot(reorder(Population, -seqCode) ~ ptile | Year, data = testLong,
> groups = time, auto.key = T)
>
> Dataframe is below using dput(). Dataframe is named "test" in my code.
>
> structure(list(seqCode = c(1L, 2L, 3L, 4L, 5L, 6L, 1L, 2L, 3L,
> 4L, 5L, 6L), popGroup = c("City", "City", "City", "Village",
> "Village", "Village", "City", "City", "City", "Village", "Village",
> "Village"), Population = c("Dallas", "Boston", "Chicago", "Kip",
> "Von", "Dan", "Dallas", "Boston", "Chicago", "Kip", "Von", "Dan"
> ), Year = c("2004-05", "2004-05", "2004-05", "2004-05", "2004-05",
> "2004-05", "2011-12", "2011-12", "2011-12", "2011-12", "2011-12",
> "2011-12"), X0_50 = c(15.47, 21.29, 18.04, 15.62, 18.89, 24.37,
> 17.43, 17.99, 18.04, 14.95, 16.33, 28.98), X50_90 = c(44.12,
> 43.25, 45.72, 46.15, 43.84, 46.24, 44.39, 44.08, 43.62, 42.89,
> 44.57, 47.14), X90_100 = c(40.42, 35.47, 36.24, 38.24, 37.27,
> 29.39, 38.18, 37.93, 38.34, 42.16, 39.11, 23.88)), class =
> "data.frame", row.names = c(NA,
> -12L))
>
> --
> Anupam.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@n|e|obo9976 @end|ng |rom gm@||@com  Wed Sep  4 20:54:15 2024
From: d@n|e|obo9976 @end|ng |rom gm@||@com (Daniel Lobo)
Date: Thu, 5 Sep 2024 00:24:15 +0530
Subject: [R] Calculation of VCV matrix of estimated coefficient
In-Reply-To: <CADZb7hocD=zCsmWTw3DaG7P_qgnSww5aRFsPpeL5fkAj48Tzug@mail.gmail.com>
References: <CADZb7hocD=zCsmWTw3DaG7P_qgnSww5aRFsPpeL5fkAj48Tzug@mail.gmail.com>
Message-ID: <CADZb7hpfAc-RPyQHAoYcz8rYEt--37BrDSWmBHuv5SnWhcAEKQ@mail.gmail.com>

Hi,

I am trying to replicate the R's result for VCV matrix of estimated
coefficients from linear model as below

data(mtcars)
model <- lm(mpg~disp+hp, data=mtcars)
model_summ <-summary(model)
MSE = mean(model_summ$residuals^2)
vcov(model)

Now I want to calculate the same thing manually,

library(dplyr)
X = as.matrix(mtcars[, c('disp', 'hp')] %>% mutate(Intercept = 1));
solve(t(X) %*% X) * MSE

Unfortunately they do not match.

Could you please help where I made mistake, if any.

Thanks


From bbo|ker @end|ng |rom gm@||@com  Wed Sep  4 22:14:09 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 4 Sep 2024 16:14:09 -0400
Subject: [R] Calculation of VCV matrix of estimated coefficient
In-Reply-To: <CADZb7hpfAc-RPyQHAoYcz8rYEt--37BrDSWmBHuv5SnWhcAEKQ@mail.gmail.com>
References: <CADZb7hocD=zCsmWTw3DaG7P_qgnSww5aRFsPpeL5fkAj48Tzug@mail.gmail.com>
 <CADZb7hpfAc-RPyQHAoYcz8rYEt--37BrDSWmBHuv5SnWhcAEKQ@mail.gmail.com>
Message-ID: <CABghstTTqF25PnS0tRs+Pxibx+Q-X5PEwMd3vckN2Rw_bWDkwQ@mail.gmail.com>

The number you need for MSE is

sum(residuals(model)^2)/df.residual(model)

On Wed, Sep 4, 2024 at 3:34?PM Daniel Lobo <danielobo9976 at gmail.com> wrote:
>
> Hi,
>
> I am trying to replicate the R's result for VCV matrix of estimated
> coefficients from linear model as below
>
> data(mtcars)
> model <- lm(mpg~disp+hp, data=mtcars)
> model_summ <-summary(model)
> MSE = mean(model_summ$residuals^2)
> vcov(model)
>
> Now I want to calculate the same thing manually,
>
> library(dplyr)
> X = as.matrix(mtcars[, c('disp', 'hp')] %>% mutate(Intercept = 1));
> solve(t(X) %*% X) * MSE
>
> Unfortunately they do not match.
>
> Could you please help where I made mistake, if any.
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@ych@o||u @end|ng |rom gm@||@com  Tue Sep  3 18:30:54 2024
From: p@ych@o||u @end|ng |rom gm@||@com (Chao Liu)
Date: Tue, 3 Sep 2024 12:30:54 -0400
Subject: [R] [R-pkgs] Goodreader: Scrape and Analyze 'Goodreads' Book Data
Message-ID: <CACCU-vM3B95EnoYz=-wKf5r+iWm-O8iCW6h-cBo-q+kjvuRk1Q@mail.gmail.com>

Dear R Users,

I am pleased to announce that Goodreader 0.1.1 is now available on CRAN.

Goodreader offers a toolkit for scraping and analyzing book data from
Goodreads. Users can search for books, scrape detailed information and
reviews, perform sentiment analysis on reviews, and conduct topic modeling.

Here?s a quick overview of how to use Goodreader:
# Search for books
AI_df <- search_goodreads(search_term = "artificial intelligence",
search_in = "title", num_books = 10, sort_by = "ratings")

# Retrieve Book IDs and save them to a text file
get_book_ids(input_data = AI_df, file_name = "AI_books.txt")

# Get book-related information
scrape_books(book_ids_path = "AI_books.txt")

# Scrape book reviews
scrape_reviews(book_ids_path = "AI_books.txt", num_reviews = 10)

For more details, please visit: https://liu-chao.site/Goodreader/

Best regards,

Chao Liu

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From gdr@|@m@ @end|ng |rom x@4@||@n|  Thu Sep  5 13:05:35 2024
From: gdr@|@m@ @end|ng |rom x@4@||@n| (Gerrit Draisma)
Date: Thu, 5 Sep 2024 13:05:35 +0200
Subject: [R] lattice log scale labels.
Message-ID: <b01b6e2d-9c73-420f-8170-0cb4c900f312@xs4all.nl>

Dear R-helpers,

In the plot below I would like to have labels at positions 2^(3*(0:10)),
and keep the labels in the exponential format.
I tried using yscale.components.default.

*This* gives the right format of the labels:
--------
 > yscale.components.default(lim= c(0,30),log=2)
....
$num.limit
[1]  0 30
...
[1]  0  5 10 15 20 25 30
...
$left$labels$labels
[1] "2^0"  "2^5"  "2^10" "2^15" "2^20" "2^25" "2^30"
--------

and *this* gives the right locations
--------
 > yscale.components.default(lim= c(0,30),log=2,at=2^(3*(0:10)))
$num.limit
[1]  0 30
...
  [1]  0  3  6  9 12 15 18 21 24 27 30
...
$left$labels$labels
  [1] "1"          "8"          "64"         "512"        "4096"
  [6] "32768"      "262144"     "2097152"    "16777216"   "134217728"
[11] "1073741824"
--------

How can I get the format in the first example at the locations of the 
second?

Thanks,
Gerrit

-------------
x <- read.csv(text="
n,c,t,u
4,1,2,1
8,28,8,1
12,495,42,3
16,8008,256,7
20,125970,1680,31
24,1961256,11640,138
28,30421755,83776,808
32,471435600,620576,4956
36,7307872110,4700880,33719")
library(lattice)
yscale.components.log2 <- function(...){
     ans <- yscale.components.default(...)
     ans$left$labels$labels <-
         parse(text = ans$left$labels$labels)
     ans
}


# pdf("tangle_mathFig06.pdf")
xyplot(c+t+u~n,data=x,type="b", xlab="Size", ylab="Number of tangles",
    scales=list(x=list(at=4*(1:9)),y=list(log=2)),
    yscale.components=yscale.components.log2,
    auto.key=list(columns=3,text=c("(choose m n)","tangles","unique 
tangles"),
    points=FALSE,lines=TRUE))
# dev.off()


From ggrothend|eck @end|ng |rom gm@||@com  Thu Sep  5 16:36:54 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 5 Sep 2024 10:36:54 -0400
Subject: [R] Calculation of VCV matrix of estimated coefficient
In-Reply-To: <CADZb7hpfAc-RPyQHAoYcz8rYEt--37BrDSWmBHuv5SnWhcAEKQ@mail.gmail.com>
References: <CADZb7hocD=zCsmWTw3DaG7P_qgnSww5aRFsPpeL5fkAj48Tzug@mail.gmail.com>
 <CADZb7hpfAc-RPyQHAoYcz8rYEt--37BrDSWmBHuv5SnWhcAEKQ@mail.gmail.com>
Message-ID: <CAP01uRnywJTLerMkPEm4MsNRF4GLUVcKXyBjOpHAw8ED8HYjKw@mail.gmail.com>

sigma(model)^2 will give the correct MSE.  Also note that your model
matrix has intercept at
the end whereas vcov will have it at the beginning so you will need to
permute the rows
and columns to get them to be the same/

On Wed, Sep 4, 2024 at 3:34?PM Daniel Lobo <danielobo9976 at gmail.com> wrote:
>
> Hi,
>
> I am trying to replicate the R's result for VCV matrix of estimated
> coefficients from linear model as below
>
> data(mtcars)
> model <- lm(mpg~disp+hp, data=mtcars)
> model_summ <-summary(model)
> MSE = mean(model_summ$residuals^2)
> vcov(model)
>
> Now I want to calculate the same thing manually,
>
> library(dplyr)
> X = as.matrix(mtcars[, c('disp', 'hp')] %>% mutate(Intercept = 1));
> solve(t(X) %*% X) * MSE
>
> Unfortunately they do not match.
>
> Could you please help where I made mistake, if any.
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  5 16:54:00 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Sep 2024 07:54:00 -0700
Subject: [R] lattice log scale labels.
In-Reply-To: <b01b6e2d-9c73-420f-8170-0cb4c900f312@xs4all.nl>
References: <b01b6e2d-9c73-420f-8170-0cb4c900f312@xs4all.nl>
Message-ID: <CAGxFJbT+yMfCOLNdWPsADYZYBK_P-S4ga5SRBFD_--FFehi1-w@mail.gmail.com>

Do the "at" and "labels" components of the "scales" list argument to xyplot
not do what you want?

Cheers,
Bert

On Thu, Sep 5, 2024 at 4:05?AM Gerrit Draisma <gdraisma at xs4all.nl> wrote:

> Dear R-helpers,
>
> In the plot below I would like to have labels at positions 2^(3*(0:10)),
> and keep the labels in the exponential format.
> I tried using yscale.components.default.
>
> *This* gives the right format of the labels:
> --------
>  > yscale.components.default(lim= c(0,30),log=2)
> ....
> $num.limit
> [1]  0 30
> ...
> [1]  0  5 10 15 20 25 30
> ...
> $left$labels$labels
> [1] "2^0"  "2^5"  "2^10" "2^15" "2^20" "2^25" "2^30"
> --------
>
> and *this* gives the right locations
> --------
>  > yscale.components.default(lim= c(0,30),log=2,at=2^(3*(0:10)))
> $num.limit
> [1]  0 30
> ...
>   [1]  0  3  6  9 12 15 18 21 24 27 30
> ...
> $left$labels$labels
>   [1] "1"          "8"          "64"         "512"        "4096"
>   [6] "32768"      "262144"     "2097152"    "16777216"   "134217728"
> [11] "1073741824"
> --------
>
> How can I get the format in the first example at the locations of the
> second?
>
> Thanks,
> Gerrit
>
> -------------
> x <- read.csv(text="
> n,c,t,u
> 4,1,2,1
> 8,28,8,1
> 12,495,42,3
> 16,8008,256,7
> 20,125970,1680,31
> 24,1961256,11640,138
> 28,30421755,83776,808
> 32,471435600,620576,4956
> 36,7307872110,4700880,33719")
> library(lattice)
> yscale.components.log2 <- function(...){
>      ans <- yscale.components.default(...)
>      ans$left$labels$labels <-
>          parse(text = ans$left$labels$labels)
>      ans
> }
>
>
> # pdf("tangle_mathFig06.pdf")
> xyplot(c+t+u~n,data=x,type="b", xlab="Size", ylab="Number of tangles",
>     scales=list(x=list(at=4*(1:9)),y=list(log=2)),
>     yscale.components=yscale.components.log2,
>     auto.key=list(columns=3,text=c("(choose m n)","tangles","unique
> tangles"),
>     points=FALSE,lines=TRUE))
> # dev.off()
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gdr@|@m@ @end|ng |rom x@4@||@n|  Thu Sep  5 19:01:24 2024
From: gdr@|@m@ @end|ng |rom x@4@||@n| (Gerrit Draisma)
Date: Thu, 5 Sep 2024 19:01:24 +0200
Subject: [R] lattice log scale labels.
In-Reply-To: <CAGxFJbT+yMfCOLNdWPsADYZYBK_P-S4ga5SRBFD_--FFehi1-w@mail.gmail.com>
References: <b01b6e2d-9c73-420f-8170-0cb4c900f312@xs4all.nl>
 <CAGxFJbT+yMfCOLNdWPsADYZYBK_P-S4ga5SRBFD_--FFehi1-w@mail.gmail.com>
Message-ID: <34aa1fe5-0160-4c34-8844-0145dc681b08@xs4all.nl>

Thanks Greg and Bert for solving my problem.
This gives what I want:
----------------

myticks <- 2^(3*(0:11))
mylabels <- parse(text=paste0("2^",log2(myticks)))

xyplot(c+t+u~n,data=x,type="b", xlab="Size", ylab="Number of tangles",
   scales=list(x=list(at=4*(1:9)),y=list(log=2,at=myticks,labels=mylabels),
    auto.key=list(columns=3,text=c("(choose m n)","tangles","unique
       tangles"), points=FALSE,lines=TRUE)))
----------------
Solved!
Gerrit

Op 05-09-2024 om 16:54 schreef Bert Gunter:
> Do the "at" and "labels" components of the "scales" list argument to 
> xyplot not do what you want?
> 
> Cheers,
> Bert
> 
> On Thu, Sep 5, 2024 at 4:05?AM Gerrit Draisma <gdraisma at xs4all.nl 
> <mailto:gdraisma at xs4all.nl>> wrote:
> 
>     Dear R-helpers,
> 
>     In the plot below I would like to have labels at positions 2^(3*(0:10)),
>     and keep the labels in the exponential format.
>     I tried using yscale.components.default.
> 
>     *This* gives the right format of the labels:
>     --------
>      ?> yscale.components.default(lim= c(0,30),log=2)
>     ....
>     $num.limit
>     [1]? 0 30
>     ...
>     [1]? 0? 5 10 15 20 25 30
>     ...
>     $left$labels$labels
>     [1] "2^0"? "2^5"? "2^10" "2^15" "2^20" "2^25" "2^30"
>     --------
> 
>     and *this* gives the right locations
>     --------
>      ?> yscale.components.default(lim= c(0,30),log=2,at=2^(3*(0:10)))
>     $num.limit
>     [1]? 0 30
>     ...
>      ? [1]? 0? 3? 6? 9 12 15 18 21 24 27 30
>     ...
>     $left$labels$labels
>      ? [1] "1"? ? ? ? ? "8"? ? ? ? ? "64"? ? ? ? ?"512"? ? ? ? "4096"
>      ? [6] "32768"? ? ? "262144"? ? ?"2097152"? ? "16777216"? ?"134217728"
>     [11] "1073741824"
>     --------
> 
>     How can I get the format in the first example at the locations of the
>     second?
> 
>     Thanks,
>     Gerrit
> 
>     -------------
>     x <- read.csv(text="
>     n,c,t,u
>     4,1,2,1
>     8,28,8,1
>     12,495,42,3
>     16,8008,256,7
>     20,125970,1680,31
>     24,1961256,11640,138
>     28,30421755,83776,808
>     32,471435600,620576,4956
>     36,7307872110,4700880,33719")
>     library(lattice)
>     yscale.components.log2 <- function(...){
>      ? ? ?ans <- yscale.components.default(...)
>      ? ? ?ans$left$labels$labels <-
>      ? ? ? ? ?parse(text = ans$left$labels$labels)
>      ? ? ?ans
>     }
> 
> 
>     # pdf("tangle_mathFig06.pdf")
>     xyplot(c+t+u~n,data=x,type="b", xlab="Size", ylab="Number of tangles",
>      ? ? scales=list(x=list(at=4*(1:9)),y=list(log=2)),
>      ? ? yscale.components=yscale.components.log2,
>      ? ? auto.key=list(columns=3,text=c("(choose m n)","tangles","unique
>     tangles"),
>      ? ? points=FALSE,lines=TRUE))
>     # dev.off()
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/
>     mailman/listinfo/r-help>
>     PLEASE do read the posting guide https://www.R-project.org/posting-
>     guide.html <https://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Thu Sep  5 22:23:25 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Thu, 5 Sep 2024 20:23:25 +0000
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
Message-ID: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear R Users,

Is this desired behaviour?
I presume it's a bug.

atan(1i)
# 0+Infi

tan(atan(1i))
# 0+1i

atan(1i) / 5
# NaN+Infi

There were some changes in handling of complex numbers. But it looks like a bug.

Sincerely,

Leonard


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  5 23:38:15 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Sep 2024 14:38:15 -0700
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbT-FU3ehHir6xUf=FSyyuSW_MArTeFCdbRwV=CU8HgieA@mail.gmail.com>

What version of R are you using and on what platform?

I get:
> atan(1i)
[1] 0.7853982+Infi
> atan(1i)/5
[1] NaN+Infi

on:
R version 4.4.1 (2024-06-14)
Platform: aarch64-apple-darwin20
Running under: macOS Sonoma 14.6.1

-- Bert

On Thu, Sep 5, 2024 at 1:23?PM Leo Mada via R-help <r-help at r-project.org>
wrote:

> Dear R Users,
>
> Is this desired behaviour?
> I presume it's a bug.
>
> atan(1i)
> # 0+Infi
>
> tan(atan(1i))
> # 0+1i
>
> atan(1i) / 5
> # NaN+Infi
>
> There were some changes in handling of complex numbers. But it looks like
> a bug.
>
> Sincerely,
>
> Leonard
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  5 23:40:53 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Sep 2024 17:40:53 -0400
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>

On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> Dear R Users,
> 
> Is this desired behaviour?
> I presume it's a bug.
> 
> atan(1i)
> # 0+Infi
> 
> tan(atan(1i))
> # 0+1i
> 
> atan(1i) / 5
> # NaN+Infi

There's no need to involve atan() and tan() in this:

 > (0+Inf*1i)/5
[1] NaN+Infi

Why do you think this is a bug?

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep  6 00:12:06 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Sep 2024 15:12:06 -0700
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
Message-ID: <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>

Perhaps

> Inf*1i
[1] NaN+Infi

clarifies why it is *not* a bug.
(Boy, did that jog some long dusty math memories :-)  )

-- Bert

On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> > Dear R Users,
> >
> > Is this desired behaviour?
> > I presume it's a bug.
> >
> > atan(1i)
> > # 0+Infi
> >
> > tan(atan(1i))
> > # 0+1i
> >
> > atan(1i) / 5
> > # NaN+Infi
>
> There's no need to involve atan() and tan() in this:
>
>  > (0+Inf*1i)/5
> [1] NaN+Infi
>
> Why do you think this is a bug?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Fri Sep  6 00:20:20 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Thu, 5 Sep 2024 22:20:20 +0000
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
Message-ID: <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear Bert,

These behave like real divisions/multiplications:
complex(re=Inf, im = Inf) * 5
# Inf+Infi
complex(re=-Inf, im = Inf) * 5
# -Inf+Infi

The real division / multiplication should be faster and also is well behaved. I was expecting R to do the real division/multiplication on a complex number. Which R actually does for these very particular cases; but not when only Im(x) is Inf.

Sincerely,

Leonard

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Friday, September 6, 2024 1:12 AM
To: Duncan Murdoch <murdoch.duncan at gmail.com>
Cc: Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?

Perhaps

> Inf*1i
[1] NaN+Infi

clarifies why it is *not* a bug.
(Boy, did that jog some long dusty math memories :-)  )

-- Bert

On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>> wrote:
On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> Dear R Users,
>
> Is this desired behaviour?
> I presume it's a bug.
>
> atan(1i)
> # 0+Infi
>
> tan(atan(1i))
> # 0+1i
>
> atan(1i) / 5
> # NaN+Infi

There's no need to involve atan() and tan() in this:

 > (0+Inf*1i)/5
[1] NaN+Infi

Why do you think this is a bug?

Duncan Murdoch

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep  6 00:38:33 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Sep 2024 15:38:33 -0700
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>

> complex(real = 0, imaginary = Inf)
[1] 0+Infi

> Inf*1i
[1] NaN+Infi

>> complex(real = 0, imaginary = Inf)/5
[1] NaN+Infi

See the Note in ?complex for the explanation, I think.  Duncan can correct
if I'm wrong.

-- Bert

On Thu, Sep 5, 2024 at 3:20?PM Leo Mada <leo.mada at syonic.eu> wrote:

> Dear Bert,
>
> These behave like real divisions/multiplications:
> complex(re=Inf, im = Inf) * 5
> # Inf+Infi
> complex(re=-Inf, im = Inf) * 5
> # -Inf+Infi
>
> The real division / multiplication should be faster and also is well
> behaved. I was expecting R to do the real division/multiplication on a
> complex number. Which R actually does for these very particular cases; but
> not when only Im(x) is Inf.
>
> Sincerely,
>
> Leonard
>
> ------------------------------
> *From:* Bert Gunter <bgunter.4567 at gmail.com>
> *Sent:* Friday, September 6, 2024 1:12 AM
> *To:* Duncan Murdoch <murdoch.duncan at gmail.com>
> *Cc:* Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org <
> r-help at r-project.org>
> *Subject:* Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?
>
> Perhaps
>
> > Inf*1i
> [1] NaN+Infi
>
> clarifies why it is *not* a bug.
> (Boy, did that jog some long dusty math memories :-)  )
>
> -- Bert
>
> On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> > Dear R Users,
> >
> > Is this desired behaviour?
> > I presume it's a bug.
> >
> > atan(1i)
> > # 0+Infi
> >
> > tan(atan(1i))
> > # 0+1i
> >
> > atan(1i) / 5
> > # NaN+Infi
>
> There's no need to involve atan() and tan() in this:
>
>  > (0+Inf*1i)/5
> [1] NaN+Infi
>
> Why do you think this is a bug?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep  6 01:06:57 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 05 Sep 2024 16:06:57 -0700
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
Message-ID: <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>

atan(1i) -> 0 + Inf i
complex(1/5) -> 0.2 + 0i
atan(1i) -> (0 + Inf i) * (0.2 + 0i)
-> 0*0.2 + 0*0i + Inf i * 0.2 + Inf i * 0i
infinity times zero is undefined
-> 0 + 0i + Inf i + NaN * i^2
-> 0 + 0i + Inf i - NaN
-> NaN + Inf i

I am not sure how complex arithmetic could arrive at another answer.

I advise against messing with infinities... use atan2() if you don't actually need complex arithmetic.

On September 5, 2024 3:38:33 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> complex(real = 0, imaginary = Inf)
>[1] 0+Infi
>
>> Inf*1i
>[1] NaN+Infi
>
>>> complex(real = 0, imaginary = Inf)/5
>[1] NaN+Infi
>
>See the Note in ?complex for the explanation, I think.  Duncan can correct
>if I'm wrong.
>
>-- Bert
>
>On Thu, Sep 5, 2024 at 3:20?PM Leo Mada <leo.mada at syonic.eu> wrote:
>
>> Dear Bert,
>>
>> These behave like real divisions/multiplications:
>> complex(re=Inf, im = Inf) * 5
>> # Inf+Infi
>> complex(re=-Inf, im = Inf) * 5
>> # -Inf+Infi
>>
>> The real division / multiplication should be faster and also is well
>> behaved. I was expecting R to do the real division/multiplication on a
>> complex number. Which R actually does for these very particular cases; but
>> not when only Im(x) is Inf.
>>
>> Sincerely,
>>
>> Leonard
>>
>> ------------------------------
>> *From:* Bert Gunter <bgunter.4567 at gmail.com>
>> *Sent:* Friday, September 6, 2024 1:12 AM
>> *To:* Duncan Murdoch <murdoch.duncan at gmail.com>
>> *Cc:* Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org <
>> r-help at r-project.org>
>> *Subject:* Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?
>>
>> Perhaps
>>
>> > Inf*1i
>> [1] NaN+Infi
>>
>> clarifies why it is *not* a bug.
>> (Boy, did that jog some long dusty math memories :-)  )
>>
>> -- Bert
>>
>> On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
>> > Dear R Users,
>> >
>> > Is this desired behaviour?
>> > I presume it's a bug.
>> >
>> > atan(1i)
>> > # 0+Infi
>> >
>> > tan(atan(1i))
>> > # 0+1i
>> >
>> > atan(1i) / 5
>> > # NaN+Infi
>>
>> There's no need to involve atan() and tan() in this:
>>
>>  > (0+Inf*1i)/5
>> [1] NaN+Infi
>>
>> Why do you think this is a bug?
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep  6 01:40:35 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Sep 2024 19:40:35 -0400
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <DBAP192MB0956C07B3C3DE087A227C12C849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <DBAP192MB0956C07B3C3DE087A227C12C849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <73d502d2-d6f3-4dde-bcbf-e520666b9036@gmail.com>

On 2024-09-05 6:12 p.m., Leo Mada wrote:
> Dear Duncan,
> 
> Here is also the missing information:
> R version 4.4.1 (2024-06-14 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 10 x64 (build 19045)
> 
> Regarding the results:
> atan(1i)
> #?0+Infi
> Re(atan(1i))
> # 0
> Im(atan(1i))
> #? Inf
> 
> 0 + Inf i is a valid complex number:
> tan(atan(1i))
> # 0+1i
> 
> Inf / 5
> # Inf
> 
> Note: atan(1i) / 5 should have generated 0 + Inf * 1i; even the explicit 
> complex number fails:
> complex(re=0, im = Inf) / 5
> # NaN+Infi
> complex(re=Inf, im = Inf) / 5
> # Inf+Infi
> 
> I presume that R tries to do the complex division, although the real 
> division is well defined.

I imagine that what happens is that when one operand is complex, both 
are coerced to complex and the operation is carried out.  I had assumed 
this was documented in ?complex, but I don't see it there.  Maybe it 
should be.

If you want z/5 to be carried out using the correct mathematical 
approach, you'll probably have to define it yourself.  For example,

   CxByReal <- function(num, denom) {
     if (is.complex(denom)) stop("this is for a real denominator!")
     complex(real = Re(num)/denom, imaginary = Im(num)/denom)
   }

   CxByReal(complex(real=0, imaginary=Inf), 5)
   # [1] 0+Infi

Duncan Murdoch

> 
> Sincerely,
> 
> Leonard
> 
> ------------------------------------------------------------------------
> *From:* Duncan Murdoch <murdoch.duncan at gmail.com>
> *Sent:* Friday, September 6, 2024 12:40 AM
> *To:* Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org 
> <r-help at r-project.org>
> *Subject:* Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?
> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
>> Dear R Users,
>> 
>> Is this desired behaviour?
>> I presume it's a bug.
>> 
>> atan(1i)
>> # 0+Infi
>> 
>> tan(atan(1i))
>> # 0+1i
>> 
>> atan(1i) / 5
>> # NaN+Infi
> 
> There's no need to involve atan() and tan() in this:
> 
>  ?> (0+Inf*1i)/5
> [1] NaN+Infi
> 
> Why do you think this is a bug?
> 
> Duncan Murdoch
>


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep  6 01:55:09 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Sep 2024 16:55:09 -0700
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
 <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
Message-ID: <CAGxFJbQX65wpeF8mXa7P1+A9+vJ77hpmMR5v3wssidp+JFC4gw@mail.gmail.com>

> x <- complex(imag = Inf)
> x
[1] 0+Infi
> x*1
[1] NaN+Infi
> x+0
[1] 0+Infi

R does the addition and subtraction "coordinatewise"; the C library handles
everything else. This results in 2 different ways the point at infinity is
printed.

(Correction requested if this is wrong)

Bert

On Thu, Sep 5, 2024 at 4:07?PM Jeff Newmiller via R-help <
r-help at r-project.org> wrote:

> atan(1i) -> 0 + Inf i
> complex(1/5) -> 0.2 + 0i
> atan(1i) -> (0 + Inf i) * (0.2 + 0i)
> -> 0*0.2 + 0*0i + Inf i * 0.2 + Inf i * 0i
> infinity times zero is undefined
> -> 0 + 0i + Inf i + NaN * i^2
> -> 0 + 0i + Inf i - NaN
> -> NaN + Inf i
>
> I am not sure how complex arithmetic could arrive at another answer.
>
> I advise against messing with infinities... use atan2() if you don't
> actually need complex arithmetic.
>
> On September 5, 2024 3:38:33 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >> complex(real = 0, imaginary = Inf)
> >[1] 0+Infi
> >
> >> Inf*1i
> >[1] NaN+Infi
> >
> >>> complex(real = 0, imaginary = Inf)/5
> >[1] NaN+Infi
> >
> >See the Note in ?complex for the explanation, I think.  Duncan can correct
> >if I'm wrong.
> >
> >-- Bert
> >
> >On Thu, Sep 5, 2024 at 3:20?PM Leo Mada <leo.mada at syonic.eu> wrote:
> >
> >> Dear Bert,
> >>
> >> These behave like real divisions/multiplications:
> >> complex(re=Inf, im = Inf) * 5
> >> # Inf+Infi
> >> complex(re=-Inf, im = Inf) * 5
> >> # -Inf+Infi
> >>
> >> The real division / multiplication should be faster and also is well
> >> behaved. I was expecting R to do the real division/multiplication on a
> >> complex number. Which R actually does for these very particular cases;
> but
> >> not when only Im(x) is Inf.
> >>
> >> Sincerely,
> >>
> >> Leonard
> >>
> >> ------------------------------
> >> *From:* Bert Gunter <bgunter.4567 at gmail.com>
> >> *Sent:* Friday, September 6, 2024 1:12 AM
> >> *To:* Duncan Murdoch <murdoch.duncan at gmail.com>
> >> *Cc:* Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org <
> >> r-help at r-project.org>
> >> *Subject:* Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?
> >>
> >> Perhaps
> >>
> >> > Inf*1i
> >> [1] NaN+Infi
> >>
> >> clarifies why it is *not* a bug.
> >> (Boy, did that jog some long dusty math memories :-)  )
> >>
> >> -- Bert
> >>
> >> On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com
> >
> >> wrote:
> >>
> >> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> >> > Dear R Users,
> >> >
> >> > Is this desired behaviour?
> >> > I presume it's a bug.
> >> >
> >> > atan(1i)
> >> > # 0+Infi
> >> >
> >> > tan(atan(1i))
> >> > # 0+1i
> >> >
> >> > atan(1i) / 5
> >> > # NaN+Infi
> >>
> >> There's no need to involve atan() and tan() in this:
> >>
> >>  > (0+Inf*1i)/5
> >> [1] NaN+Infi
> >>
> >> Why do you think this is a bug?
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Fri Sep  6 04:50:24 2024
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Thu, 5 Sep 2024 22:50:24 -0400
Subject: [R] effects() extractor for a quantile reqression object: error
 message
Message-ID: <ff1b1a84-d571-7e4c-d7d6-195cd240442e@binghamton.edu>

I'm using quantreg package version 5.98 of 24 May 2024, in R 4.4.1 on
Linux Mint.

The online documentation for quantreg says, in part, under the
description of the rq.object, "The coefficients, residuals, and effects
may be extracted by the generic functions of the same name, rather than
by the $ operator."

I create an rq object for the 0.9 quantile, called qm.9

effects(qm.9)

yields, the error message, " effects(qm.9)
Error in UseMethod("effects") :
  no applicable method for 'effects' applied to an object of class "rq"

I'm confused. Appreciate any suggestions. Thanks.

--Chris Ryan


From r@oknz @end|ng |rom gm@||@com  Fri Sep  6 06:44:01 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 6 Sep 2024 16:44:01 +1200
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
Message-ID: <CABcYAd+QTEB0ryJFT34N_sQDEaP=ycXQdfhFQzuO1KP56P8bdA@mail.gmail.com>

I expect that atan(1i) = (0 + infinity i) and that atan(1i)/5 = (0 +
infinity i)/5 = (0 + infinity i).
Here's what I get in C:
(0,1) = (0, 1)
atan((0,1)) = (0, inf)
atan((0,1))/5 = (0, inf)

Note the difference between I*infinity = (0,1)*infinity =
(0*infinity,1*infinity) = (NaN,infinity)
and (0,infinity)/5 = (0/5,infinity/5) = (0,infinity).
The former involves multiplying 0 by infinity, which yields NaN.
The latter does not.

> complex(1,0,Inf)*2
[1] NaN+Infi
There is no good reason for this. 0*2 is 0, not NaN.

In IEEE arithmetic, multiplying or dividing a complex number by a real number is
NOT the same as multiplying or dividing by the complex version of that
real number.
(0,Inf) * 2 = (0*2, Inf*2) = (0, Inf).
(0,Inf) * (2,0) = (0*2 - Inf*0, 0*0 + Inf*2) = (NaN, Inf).

There really truly is a bug here, and it is treating R*Z, Z*R, and Z/R
as if they were
the same as W*Z, Z*W, and Z/W where W = complex(1,R,0).

On Fri, 6 Sept 2024 at 10:12, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Perhaps
>
> > Inf*1i
> [1] NaN+Infi
>
> clarifies why it is *not* a bug.
> (Boy, did that jog some long dusty math memories :-)  )
>
> -- Bert
>
> On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> > > Dear R Users,
> > >
> > > Is this desired behaviour?
> > > I presume it's a bug.
> > >
> > > atan(1i)
> > > # 0+Infi
> > >
> > > tan(atan(1i))
> > > # 0+1i
> > >
> > > atan(1i) / 5
> > > # NaN+Infi
> >
> > There's no need to involve atan() and tan() in this:
> >
> >  > (0+Inf*1i)/5
> > [1] NaN+Infi
> >
> > Why do you think this is a bug?
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Fri Sep  6 07:24:07 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 6 Sep 2024 17:24:07 +1200
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
 <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
Message-ID: <CABcYAdLZaO+9HTTAQg0PTGjgDzdSc42LV+fJv8nNMy_WOrb4+A@mail.gmail.com>

The thing is that real*complex, complex*real, and complex/real are not
"complex arithmetic"
in the requisite sense.  The complex numbers are a vector space over
the reals, and
complex*real and real*complex are vector*scalar and scalar*vector.
For example, in the Ada programming language, we have
function "*" (Left, Right : Complex) return Complex;
function "*" (Left : Complex;   Right : Real'Base) return Complex;
function "*" (Left : Real'Base; Right : Complex)   return Complex;
showing that Z*R and Z*W involve *different* functions.

It's worth noting that complex*real and real*complex just require two
real multiplications,
no other arithmetic operations, while complex*complex requires four
real multiplications,
an addition, and a subtraction.  So implementing complex*real by
conventing the real
to complex is inefficient (as well as getting the finer points of IEEE
arithmetic wrong).
As for comple division, getting that *right* in floating-point is
fiendishly difficult (there are
lots of algorithms out there and the majority of them have serious
flaws) and woefully costly.
It's not unfair to characterise implementing complex/real by
conversion to complex and
doing complex/complex as a beginner's bungle.

There are good reasons why "double", "_Imaginary double", and "_Complex double"
are distinct types in standard C (as they are in Ada), and the
definition of multiplication
in G.5.1 para 2 is *direct* (not via complex*complex).

Now R has its own way of doing things, and if the judgement of the R
maintainers is
that keeping the "convert to a common type and then operate" model is
more important
than getting good answers, well, it's THEIR language, not mine.  But
let's not pretend
that the answers are *right* in any other sense.

On Fri, 6 Sept 2024 at 11:07, Jeff Newmiller via R-help
<r-help at r-project.org> wrote:
>
> atan(1i) -> 0 + Inf i
> complex(1/5) -> 0.2 + 0i
> atan(1i) -> (0 + Inf i) * (0.2 + 0i)
> -> 0*0.2 + 0*0i + Inf i * 0.2 + Inf i * 0i
> infinity times zero is undefined
> -> 0 + 0i + Inf i + NaN * i^2
> -> 0 + 0i + Inf i - NaN
> -> NaN + Inf i
>
> I am not sure how complex arithmetic could arrive at another answer.
>
> I advise against messing with infinities... use atan2() if you don't actually need complex arithmetic.
>
> On September 5, 2024 3:38:33 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >> complex(real = 0, imaginary = Inf)
> >[1] 0+Infi
> >
> >> Inf*1i
> >[1] NaN+Infi
> >
> >>> complex(real = 0, imaginary = Inf)/5
> >[1] NaN+Infi
> >
> >See the Note in ?complex for the explanation, I think.  Duncan can correct
> >if I'm wrong.
> >
> >-- Bert
> >
> >On Thu, Sep 5, 2024 at 3:20?PM Leo Mada <leo.mada at syonic.eu> wrote:
> >
> >> Dear Bert,
> >>
> >> These behave like real divisions/multiplications:
> >> complex(re=Inf, im = Inf) * 5
> >> # Inf+Infi
> >> complex(re=-Inf, im = Inf) * 5
> >> # -Inf+Infi
> >>
> >> The real division / multiplication should be faster and also is well
> >> behaved. I was expecting R to do the real division/multiplication on a
> >> complex number. Which R actually does for these very particular cases; but
> >> not when only Im(x) is Inf.
> >>
> >> Sincerely,
> >>
> >> Leonard
> >>
> >> ------------------------------
> >> *From:* Bert Gunter <bgunter.4567 at gmail.com>
> >> *Sent:* Friday, September 6, 2024 1:12 AM
> >> *To:* Duncan Murdoch <murdoch.duncan at gmail.com>
> >> *Cc:* Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org <
> >> r-help at r-project.org>
> >> *Subject:* Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?
> >>
> >> Perhaps
> >>
> >> > Inf*1i
> >> [1] NaN+Infi
> >>
> >> clarifies why it is *not* a bug.
> >> (Boy, did that jog some long dusty math memories :-)  )
> >>
> >> -- Bert
> >>
> >> On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com>
> >> wrote:
> >>
> >> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> >> > Dear R Users,
> >> >
> >> > Is this desired behaviour?
> >> > I presume it's a bug.
> >> >
> >> > atan(1i)
> >> > # 0+Infi
> >> >
> >> > tan(atan(1i))
> >> > # 0+1i
> >> >
> >> > atan(1i) / 5
> >> > # NaN+Infi
> >>
> >> There's no need to involve atan() and tan() in this:
> >>
> >>  > (0+Inf*1i)/5
> >> [1] NaN+Infi
> >>
> >> Why do you think this is a bug?
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Fri Sep  6 00:12:43 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Thu, 5 Sep 2024 22:12:43 +0000
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
Message-ID: <DBAP192MB0956C07B3C3DE087A227C12C849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear Duncan,

Here is also the missing information:
R version 4.4.1 (2024-06-14 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 10 x64 (build 19045)

Regarding the results:
atan(1i)
# 0+Infi
Re(atan(1i))
# 0
Im(atan(1i))
#  Inf

0 + Inf i is a valid complex number:
tan(atan(1i))
# 0+1i

Inf / 5
# Inf

Note: atan(1i) / 5 should have generated 0 + Inf * 1i; even the explicit complex number fails:
complex(re=0, im = Inf) / 5
# NaN+Infi
complex(re=Inf, im = Inf) / 5
# Inf+Infi

I presume that R tries to do the complex division, although the real division is well defined.

Sincerely,

Leonard

________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Friday, September 6, 2024 12:40 AM
To: Leo Mada <leo.mada at syonic.eu>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] BUG: atan(1i) / 5 = NaN+Infi ?

On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
> Dear R Users,
>
> Is this desired behaviour?
> I presume it's a bug.
>
> atan(1i)
> # 0+Infi
>
> tan(atan(1i))
> # 0+1i
>
> atan(1i) / 5
> # NaN+Infi

There's no need to involve atan() and tan() in this:

 > (0+Inf*1i)/5
[1] NaN+Infi

Why do you think this is a bug?

Duncan Murdoch


-------------- next part --------------
A non-text attachment was scrubbed...
Name: =?iso-8859-7?Q?5-(2019)-CEBP=E2-LIP_induces_cancer-type_metabolic_reprogr?= =?iso-8859-7?Q?amming_by_regulating_the_let-7LIN28B_circuit_in_mice.pdf?=
Type: application/pdf
Size: 2136921 bytes
Desc: =?iso-8859-7?Q?5-(2019)-CEBP=E2-LIP_induces_cancer-type_metabolic_reprogr?= =?iso-8859-7?Q?amming_by_regulating_the_let-7LIN28B_circuit_in_mice.pdf?=
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20240905/85b49427/attachment-0001.pdf>

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep  6 10:04:11 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 6 Sep 2024 10:04:11 +0200
Subject: [R] effects() extractor for a quantile reqression object: error
 message
In-Reply-To: <ff1b1a84-d571-7e4c-d7d6-195cd240442e@binghamton.edu>
References: <ff1b1a84-d571-7e4c-d7d6-195cd240442e@binghamton.edu>
Message-ID: <26330.46971.450132.890513@stat.math.ethz.ch>

>>>>> Christopher W Ryan via R-help 
>>>>>     on Thu, 5 Sep 2024 22:50:24 -0400 writes:

    > I'm using quantreg package version 5.98 of 24 May 2024, in R 4.4.1 on
    > Linux Mint.

    > The online documentation for quantreg says, in part, under the
    > description of the rq.object, "The coefficients, residuals, and effects
    > may be extracted by the generic functions of the same name, rather than
    > by the $ operator."

    > I create an rq object for the 0.9 quantile, called qm.9

    > effects(qm.9)

    > yields, the error message, " effects(qm.9)
    > Error in UseMethod("effects") :
    > no applicable method for 'effects' applied to an object of class "rq"

    > I'm confused. Appreciate any suggestions. Thanks.

    > --Chris Ryan

Unfortunately, the documentation is wrong, here.

You can always use

     methods(class = class(qm.9))

to get list of generic function names for there is a method for
your object (of class "rq") in this case...
and indeed, "effects" is not among them.

Possibly this was a thinko (on the 'rq.object' help page) and
it was "predict" that was meant there,
as indeed there is a predict method (actually there are even 3
different predict() methods in package 'quantreg', and they are
well documented on the  ?predict.qr  help page.

{OTOH my guess is that there originally *was* an effects method
 and it has been dropped in the mean time}


Martin Maechler

ETH Zurich  and  R Core team


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep  6 10:37:36 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 6 Sep 2024 10:37:36 +0200
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CABcYAdLZaO+9HTTAQg0PTGjgDzdSc42LV+fJv8nNMy_WOrb4+A@mail.gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
 <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
 <CABcYAdLZaO+9HTTAQg0PTGjgDzdSc42LV+fJv8nNMy_WOrb4+A@mail.gmail.com>
Message-ID: <26330.48976.240526.972936@stat.math.ethz.ch>

>>>>> Richard O'Keefe 
>>>>>     on Fri, 6 Sep 2024 17:24:07 +1200 writes:

    > The thing is that real*complex, complex*real, and complex/real are not
    > "complex arithmetic" in the requisite sense.

    > The complex numbers are a vector space over  the reals,

Yes, but they _also_ are field (and as others have argued mathematically only
have one infinity point),
and I think here we are fighting with which definition should
take precedence here.
The English Wikipedia page is even more extensive and precise,
 https://en.wikipedia.org/wiki/Complex_number   (line breaking by me):

 " The complex numbers form a rich structure that is simultaneously
  - an algebraically closed field, 
  - a commutative algebra over the reals,   and 
  - a Euclidean vector space of dimension two."

our problem "of course" is that we additionally add  +/- Inf for
the reals and for storage etc treating them as a 2D vector space
over the reals is "obvious".

    > and complex*real and real*complex are vector*scalar and scalar*vector.
    > For example, in the Ada programming language, we have
    > function "*" (Left, Right : Complex) return Complex;
    > function "*" (Left : Complex;   Right : Real'Base) return Complex;
    > function "*" (Left : Real'Base; Right : Complex)   return Complex;
    > showing that Z*R and Z*W involve *different* functions.

    > It's worth noting that complex*real and real*complex just require two
    > real multiplications,
    > no other arithmetic operations, while complex*complex requires four
    > real multiplications,
    > an addition, and a subtraction.  So implementing complex*real by
    > conventing the real
    > to complex is inefficient (as well as getting the finer points of IEEE
    > arithmetic wrong).

I see your point.

    > As for complex division, getting that *right* in floating-point is
    > fiendishly difficult (there are
    > lots of algorithms out there and the majority of them have serious flaws)
    > and woefully costly.

    > It's not unfair to characterise implementing complex/real
    > by conversion to complex and doing complex/complex as a
    > beginner's bungle.

ouch!  ... but still I tend to acknowledge your point, incl the "not unfair" ..

    > There are good reasons why "double", "_Imaginary double", and "_Complex double"
    > are distinct types in standard C (as they are in Ada), 

interesting.  OTOH, I think standard C did not have strict
standards about complex number storage etc in the mid 1990s
when R was created.

    > and the definition of multiplication
    > in G.5.1 para 2 is *direct* (not via complex*complex).

I see (did not know about) -- where can we find  'G.5.1 para 2'

    > Now R has its own way of doing things, and if the judgement of the R
    > maintainers is
    > that keeping the "convert to a common type and then operate" model is
    > more important
    > than getting good answers, well, it's THEIR language, not mine.

Well, it should also be the R community's language,
where we, the R core team, do most of the "base" work and also
emphasize guaranteeing long term stability.

Personally, I think that
   "convert to a common type and then operate"
is a good rule and principle in many, even most places and cases,
but I hate it if humans should not be allowed to break good
rules for even better reasons  (but should rather behave like algorithms  ..).

This may well be a very good example of re-considering.
As mentioned above, e.g., I was not aware of the C language standard
being so specific here and different than what we've been doing
in R.


    > But let's not pretend
    > that the answers are *right* in any other sense.

I think that's too strong -- Jeff's computation (just here below)
is showing one well defined sense of "right" I'd say.
(Still I know and agree the    Inf * 0 |--> NaN
 rule *is* sometimes undesirable)

    > On Fri, 6 Sept 2024 at 11:07, Jeff Newmiller via R-help
    > <r-help at r-project.org> wrote:
    >> 
    >> atan(1i) -> 0 + Inf i
    >> complex(1/5) -> 0.2 + 0i
    >> atan(1i) -> (0 + Inf i) * (0.2 + 0i)
    -> 0*0.2 + 0*0i + Inf i * 0.2 + Inf i * 0i
    >> infinity times zero is undefined
    -> 0 + 0i + Inf i + NaN * i^2
    -> 0 + 0i + Inf i - NaN
    -> NaN + Inf i
    >> 
    >> I am not sure how complex arithmetic could arrive at another answer.
    >> 
    >> I advise against messing with infinities... use atan2() if you don't actually need complex arithmetic.
    >> 
    >> On September 5, 2024 3:38:33 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >> >> complex(real = 0, imaginary = Inf)
    >> >[1] 0+Infi
    >> >
    >> >> Inf*1i
    >> >[1] NaN+Infi
    >> >
    >> >>> complex(real = 0, imaginary = Inf)/5
    >> >[1] NaN+Infi
    >> >
    >> >See the Note in ?complex for the explanation, I think.  Duncan can correct
    >> >if I'm wrong.
    >> >
    >> >-- Bert

 [...................]

Martin

--
Martin Maechler
ETH Zurich  and   R Core team


From rkoenker @end|ng |rom ||||no|@@edu  Fri Sep  6 10:37:54 2024
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Fri, 6 Sep 2024 08:37:54 +0000
Subject: [R] Fwd: effects() extractor for a quantile reqression object:
 error message
References: <FB2308EE-B26C-49D4-A468-1802A4DD4655@illinois.edu>
Message-ID: <ECCF1BD8-B3E8-4981-A0A0-BD522337159D@illinois.edu>

Apologies,  forgot to copy R-help on this response.

Begin forwarded message:


From: Roger Koenker <rkoenker at illinois.edu>
Subject: Re: [R] effects() extractor for a quantile reqression object: error message
Date: September 6, 2024 at 8:38:47?AM GMT+1
To: "Christopher W. Ryan" <cryan at binghamton.edu>

Chris,

This was intended to emulate the effects component of lm() fitting, but was never implemented.  Frankly, I don?t quite see on first glance how this works for lm() ? it seems to be (mostly) about situations where X is not full rank (see lm.fit) and I also never bothered to implement rq for X that were not full rank.

Roger


On Sep 6, 2024, at 3:50?AM, Christopher W. Ryan via R-help <r-help at r-project.org> wrote:

I'm using quantreg package version 5.98 of 24 May 2024, in R 4.4.1 on
Linux Mint.

The online documentation for quantreg says, in part, under the
description of the rq.object, "The coefficients, residuals, and effects
may be extracted by the generic functions of the same name, rather than
by the $ operator."

I create an rq object for the 0.9 quantile, called qm.9

effects(qm.9)

yields, the error message, " effects(qm.9)
Error in UseMethod("effects") :
no applicable method for 'effects' applied to an object of class "rq"

I'm confused. Appreciate any suggestions. Thanks.

--Chris Ryan

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!DZ3fjg!8EOq_-vshoZYLg-FZREULmFkpvaXrZ6aw5ABLzjX4aq3XNvoDxGipcY73SPgiBQasfWdncPj7J2odYZKU3BD$
PLEASE do read the posting guide https://urldefense.com/v3/__https://www.R-project.org/posting-guide.html__;!!DZ3fjg!8EOq_-vshoZYLg-FZREULmFkpvaXrZ6aw5ABLzjX4aq3XNvoDxGipcY73SPgiBQasfWdncPj7J2odY7Gv6_Z$
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Sep  6 10:46:36 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 6 Sep 2024 10:46:36 +0200
Subject: [R] Calculation of VCV matrix of estimated coefficient
In-Reply-To: <CAP01uRnywJTLerMkPEm4MsNRF4GLUVcKXyBjOpHAw8ED8HYjKw@mail.gmail.com>
References: <CADZb7hocD=zCsmWTw3DaG7P_qgnSww5aRFsPpeL5fkAj48Tzug@mail.gmail.com>
 <CADZb7hpfAc-RPyQHAoYcz8rYEt--37BrDSWmBHuv5SnWhcAEKQ@mail.gmail.com>
 <CAP01uRnywJTLerMkPEm4MsNRF4GLUVcKXyBjOpHAw8ED8HYjKw@mail.gmail.com>
Message-ID: <D0E4E2BC-27B2-4476-8E14-A03866771C51@gmail.com>



> On 5 Sep 2024, at 16:36 , Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
> sigma(model)^2 will give the correct MSE.  Also note that your model
> matrix has intercept at
> the end whereas vcov will have it at the beginning so you will need to
> permute the rows
> and columns to get them to be the same/


Also, 

X <- cbind(1, as.matrix(mtcars[, c('disp', 'hp')]))

or even

X <- model.matrix(~ disp + hp, mtcars)

-pd


> 
> On Wed, Sep 4, 2024 at 3:34?PM Daniel Lobo <danielobo9976 at gmail.com> wrote:
>> 
>> Hi,
>> 
>> I am trying to replicate the R's result for VCV matrix of estimated
>> coefficients from linear model as below
>> 
>> data(mtcars)
>> model <- lm(mpg~disp+hp, data=mtcars)
>> model_summ <-summary(model)
>> MSE = mean(model_summ$residuals^2)
>> vcov(model)
>> 
>> Now I want to calculate the same thing manually,
>> 
>> library(dplyr)
>> X = as.matrix(mtcars[, c('disp', 'hp')] %>% mutate(Intercept = 1));
>> solve(t(X) %*% X) * MSE
>> 
>> Unfortunately they do not match.
>> 
>> Could you please help where I made mistake, if any.
>> 
>> Thanks
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep  6 11:54:23 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 6 Sep 2024 05:54:23 -0400
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CABcYAd+QTEB0ryJFT34N_sQDEaP=ycXQdfhFQzuO1KP56P8bdA@mail.gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <CABcYAd+QTEB0ryJFT34N_sQDEaP=ycXQdfhFQzuO1KP56P8bdA@mail.gmail.com>
Message-ID: <8975c0de-df0a-4f39-b298-662f7debbac3@gmail.com>

On 2024-09-06 12:44 a.m., Richard O'Keefe wrote:
> I expect that atan(1i) = (0 + infinity i) and that atan(1i)/5 = (0 +
> infinity i)/5 = (0 + infinity i).
> Here's what I get in C:
> (0,1) = (0, 1)
> atan((0,1)) = (0, inf)
> atan((0,1))/5 = (0, inf)
> 
> Note the difference between I*infinity = (0,1)*infinity =
> (0*infinity,1*infinity) = (NaN,infinity)
> and (0,infinity)/5 = (0/5,infinity/5) = (0,infinity).
> The former involves multiplying 0 by infinity, which yields NaN.
> The latter does not.
> 
>> complex(1,0,Inf)*2
> [1] NaN+Infi
> There is no good reason for this. 0*2 is 0, not NaN.
> 
> In IEEE arithmetic, multiplying or dividing a complex number by a real number is
> NOT the same as multiplying or dividing by the complex version of that
> real number.
> (0,Inf) * 2 = (0*2, Inf*2) = (0, Inf).
> (0,Inf) * (2,0) = (0*2 - Inf*0, 0*0 + Inf*2) = (NaN, Inf).
> 
> There really truly is a bug here, and it is treating R*Z, Z*R, and Z/R
> as if they were
> the same as W*Z, Z*W, and Z/W where W = complex(1,R,0).

I would only disagree with the statement above by distinguishing between 
a "bug" (where R is not behaving as documented) and a "design flaw" 
(where it is behaving as documented, but the behaviour is undesirable).

I think this is a design flaw rather than a bug.

The distinction is important:  if it is a design flaw, then a change is 
harder, because users who rely on the behaviour deserve more help in 
adapting than those who rely on a bug.  Bugs should be fixed.  Design 
flaws need thinking about, and sometimes shouldn't be fixed.

On the other hand, I was unable to find documentation saying that the 
current behaviour is intended, so I could be wrong.

Duncan Murdoch

> 
> On Fri, 6 Sept 2024 at 10:12, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Perhaps
>>
>>> Inf*1i
>> [1] NaN+Infi
>>
>> clarifies why it is *not* a bug.
>> (Boy, did that jog some long dusty math memories :-)  )
>>
>> -- Bert
>>
>> On Thu, Sep 5, 2024 at 2:48?PM Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>> On 2024-09-05 4:23 p.m., Leo Mada via R-help wrote:
>>>> Dear R Users,
>>>>
>>>> Is this desired behaviour?
>>>> I presume it's a bug.
>>>>
>>>> atan(1i)
>>>> # 0+Infi
>>>>
>>>> tan(atan(1i))
>>>> # 0+1i
>>>>
>>>> atan(1i) / 5
>>>> # NaN+Infi
>>>
>>> There's no need to involve atan() and tan() in this:
>>>
>>>   > (0+Inf*1i)/5
>>> [1] NaN+Infi
>>>
>>> Why do you think this is a bug?
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep  6 13:10:13 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 6 Sep 2024 13:10:13 +0200
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <8975c0de-df0a-4f39-b298-662f7debbac3@gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <CABcYAd+QTEB0ryJFT34N_sQDEaP=ycXQdfhFQzuO1KP56P8bdA@mail.gmail.com>
 <8975c0de-df0a-4f39-b298-662f7debbac3@gmail.com>
Message-ID: <26330.58133.15925.293052@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Fri, 6 Sep 2024 05:54:23 -0400 writes:

    > On 2024-09-06 12:44 a.m., Richard O'Keefe wrote:
    >> I expect that atan(1i) = (0 + infinity i) and that atan(1i)/5 = (0 +
    >> infinity i)/5 = (0 + infinity i).
    >> Here's what I get in C:
    >> (0,1) = (0, 1)
    >> atan((0,1)) = (0, inf)
    >> atan((0,1))/5 = (0, inf)
    >> 
    >> Note the difference between I*infinity = (0,1)*infinity =
    >> (0*infinity,1*infinity) = (NaN,infinity)
    >> and (0,infinity)/5 = (0/5,infinity/5) = (0,infinity).
    >> The former involves multiplying 0 by infinity, which yields NaN.
    >> The latter does not.
    >> 
    >>> complex(1,0,Inf)*2
    >> [1] NaN+Infi
    >> There is no good reason for this. 0*2 is 0, not NaN.
    >> 
    >> In IEEE arithmetic, multiplying or dividing a complex number by a real number is
    >> NOT the same as multiplying or dividing by the complex version of that
    >> real number.
    >> (0,Inf) *  2    = (0*2, Inf*2)               = (0, Inf).
    >> (0,Inf) * (2,0) = (0*2 - Inf*0, 0*0 + Inf*2) = (NaN, Inf).
    >> 
    >> There really truly is a bug here, and it is treating R*Z, Z*R, and Z/R
    >> as if they were
    >> the same as W*Z, Z*W, and Z/W where W = complex(1,R,0).

    > I would only disagree with the statement above by distinguishing between 
    > a "bug" (where R is not behaving as documented) and a "design flaw" 
    > (where it is behaving as documented, but the behaviour is undesirable).

    > I think this is a design flaw rather than a bug.

    > The distinction is important:  if it is a design flaw, then a change is 
    > harder, because users who rely on the behaviour deserve more help in 
    > adapting than those who rely on a bug.  Bugs should be fixed.  Design 
    > flaws need thinking about, and sometimes shouldn't be fixed.

    > On the other hand, I was unable to find documentation saying that the 
    > current behaviour is intended, so I could be wrong.

    > Duncan Murdoch

I agree 100% (with Duncan).

I've now also carefully read  ?Arithmetic  and  ?complex
and could not find docu explicitly documenting the current
behavior, in the context of complex arithmetic not even
mentioning the "overall principle" used very often in R to

	1. coerce to common type
	2. then compute with that "pure type"

In ?complex, we have the (last sentence of the first) 'Note:'

 --->  For ?+? and ?-?, R's own handling works strictly ?coordinate wise?.

now, implicitly that implies that {+, -} are the only
ops/functions where coordinate-wise arithmetic is used/applied
and hence could it be _stretched_ to say that for
 * and /  coordinate wise does not always apply,
in our case not even when it would make sense, i.e., when one of
the two operands is real (in the '/' case, it must be the 2nd operand)
and hence 2d-vector space arithmetic  <scalar  *  vector>
should be applied naturally.

It is still true that this must be considered a design flaw
rather than a bug, even if only because the above  "overall
principle"  is predominant and tought very often when teaching R.

In this case, I do think we should look into the consequences of
indeed distinguishing
  <double> * <complex> 
  <complex> * <double>  and
  <complex> / <double>
from their respective current {1. coerce to complex, 2. use complex arith}
arithmetic.

Hence, thanks a lot for bringing this up, to Leo Mada and
notably to Richard O'Keefe  for providing context, notably wrt
to C standards  {which I'd want to follow mostly, but not
always ... but I'm not opening that now}...

Martin


From g@@@powe|| @end|ng |rom protonm@||@com  Fri Sep  6 16:12:53 2024
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg Powell)
Date: Fri, 06 Sep 2024 14:12:53 +0000
Subject: [R] Fwd: effects() extractor for a quantile reqression object:
 error message
In-Reply-To: <ECCF1BD8-B3E8-4981-A0A0-BD522337159D@illinois.edu>
References: <FB2308EE-B26C-49D4-A468-1802A4DD4655@illinois.edu>
 <ECCF1BD8-B3E8-4981-A0A0-BD522337159D@illinois.edu>
Message-ID: <NNXrX1YsEp2Vz-Id6jV0Kd7bhuqKWJlJUHZRq6bIEJG9b3ofXbkshxH1X8C_NUUstSNxzXTMgctpafBEtZuqpdhjxfwUB2v96QYxeNegNUY=@protonmail.com>

Need to kill some time, so thought I'd Opine.

Given the intent, as I understood it... to extract components from a quantile regression (rq) object similar to how one might extract effects from an lm object.
 
Since it seems effects() is not implemented for rq, here are some alternative approaches to achieve similar functionality or extract useful information from the quantile regression model:

1. Extracting Coefficients. Use the coef() function to extract the coefficients of the quantile regression model. This is similar to extracting the effects in a linear model.

> coef(qm.9)

This will return the estimated coefficients for the 0.9 quantile.

2. Extracting Fitted Values. To get the fitted values from the quantile regression model, use: 

> fitted(qm.9)

This gives the fitted values for the quantile regression model, similar to what you'd see in an lm() model.

3. Extracting ResidualsResiduals from the quantile regression can be extracted using the resid() function: 

> resid(qm.9)

This gives the residuals for the 0.9 quantile regression model, which can be a useful diagnostic for checking model fit.

4. Manually Calculating "Effects".    While effects() is not available, you can manually calculate effects by examining the design matrix and the coefficients. If the term "effects" refers to the influence of different covariates in the model, these can be assessed by looking at the coefficients themselves and their impact on the fitted values.

5. Using the summary() Function.        The summary() function for rq objects provides detailed information about the quantile regression fit, including coefficient estimates, standard errors, and statistical significance:

> summary(qm.9)

This can give a more comprehensive understanding of how covariates are contributing to the model. 

6. Working with Design Matrices.            If you need the design matrix for further custom calculations, you can extract it using: 

> model.matrix(qm.9)                 

 This returns the matrix of predictor variables, which you can then use to manually compute the "effects" of changes in the predictors.

7. Explore Partial Effects with predict(). The predict() function can help you assess how changes in predictor values affect the outcome. For instance, to predict values at specific points in the design space, you can use: 

> predict(qm.9, newdata = data.frame(your_new_data))

8. Bootstrapping to Examine Variability. If you want to assess variability in the effects of predictors, you could use bootstrapping. The boot.rq() function in the quantreg package allows you to bootstrap the quantile regression coefficients, giving insight into the variability of the estimated "effects."

Example:

> boot_results <- boot.rq(y ~ X, tau = 0.9, data = your_data, R = 1000)

> summary(boot_results)

9.Interaction or Additive Effects (If Applicable). If you're trying to capture interaction or additive effects, you might need to specify interaction terms directly in your formula and then inspect the coefficients for these terms. Quantile regression will estimate these coefficients in the same manner as linear regression but specific to the quantile of interest.

In conclusion, while effects() is not available for quantile regression, the combination of coef(), fitted(), resid(), model.matrix(), and summary() provides the main components of a quantile regression model that should provide similar insights to what effects() provides for linear models.

Forgive any typos please... I'm on a mobile device.

Kind regards,
Gregg Powell


Sent from Proton Mail Android


-------- Original Message --------
On 06/09/2024 01:37, Koenker, Roger W <rkoenker at illinois.edu> wrote:

>  Apologies,  forgot to copy R-help on this response.
>  
>  Begin forwarded message:
>  
>  
>  From: Roger Koenker <rkoenker at illinois.edu>
>  Subject: Re: [R] effects() extractor for a quantile reqression object: error message
>  Date: September 6, 2024 at 8:38:47?AM GMT+1
>  To: "Christopher W. Ryan" <cryan at binghamton.edu>
>  
>  Chris,
>  
>  This was intended to emulate the effects component of lm() fitting, but was never implemented.  Frankly, I don?t quite see on first glance how this works for lm() ? it seems to be (mostly) about situations where X is not full rank (see lm.fit) and I also never bothered to implement rq for X that were not full rank.
>  
>  Roger
>  
>  
>  On Sep 6, 2024, at 3:50?AM, Christopher W. Ryan via R-help <r-help at r-project.org> wrote:
>  
>  I'm using quantreg package version 5.98 of 24 May 2024, in R 4.4.1 on
>  Linux Mint.
>  
>  The online documentation for quantreg says, in part, under the
>  description of the rq.object, "The coefficients, residuals, and effects
>  may be extracted by the generic functions of the same name, rather than
>  by the $ operator."
>  
>  I create an rq object for the 0.9 quantile, called qm.9
>  
>  effects(qm.9)
>  
>  yields, the error message, " effects(qm.9)
>  Error in UseMethod("effects") :
>  no applicable method for 'effects' applied to an object of class "rq"
>  
>  I'm confused. Appreciate any suggestions. Thanks.
>  
>  --Chris Ryan
>  
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!DZ3fjg!8EOq_-vshoZYLg-FZREULmFkpvaXrZ6aw5ABLzjX4aq3XNvoDxGipcY73SPgiBQasfWdncPj7J2odYZKU3BD$
>  PLEASE do read the posting guide https://urldefense.com/v3/__https://www.R-project.org/posting-guide.html__;!!DZ3fjg!8EOq_-vshoZYLg-FZREULmFkpvaXrZ6aw5ABLzjX4aq3XNvoDxGipcY73SPgiBQasfWdncPj7J2odY7Gv6_Z$
>  and provide commented, minimal, self-contained, reproducible code.
>  
>  
>  
>  	[[alternative HTML version deleted]]
>  
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>  and provide commented, minimal, self-contained, reproducible code.
>  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20240906/881ff7fd/attachment.sig>

From r@oknz @end|ng |rom gm@||@com  Fri Sep  6 16:40:29 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 7 Sep 2024 02:40:29 +1200
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <26330.48976.240526.972936@stat.math.ethz.ch>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
 <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
 <CABcYAdLZaO+9HTTAQg0PTGjgDzdSc42LV+fJv8nNMy_WOrb4+A@mail.gmail.com>
 <26330.48976.240526.972936@stat.math.ethz.ch>
Message-ID: <CABcYAd+LZrfVMU9AjU6jQfd_O8pCbbYotNSthpWSJKdLAG4oDA@mail.gmail.com>

G.5.1 para 2 can be found in the C17 standard -- I actually have the
final draft not the published standard.  It's in earlier standards, I
just didn't check earlier standards.  Complex arithmetic was not in
the first C standard (C89) but was in C99.

The complex numbers do indeed form a field, and Z*W invokes an
operation in that field when Z and W are both complex numbers.  Z*R
and R*Z, where R is real-but-not-complex, is not that field operation;
it's the scalar multiplication from the vector spec view.

One way to characterise the C and Ada view is that real numbers x can
be viewed as (x,ZERO!!!) and imaginary numbers y*i can be viewed as
(ZERO!!!, y) where ZERO!!! is a real serious HARD zero, not an IEEE
+epsilon or -epsilon,  In fact this is important for getting "sign of
zero" right.
x + (u,v) = (x+u, v) *NOT* (x+u, v+0) and this does matter in IEEE arithmetic.

R is of course based on S, and S was not only designed before C got
complex numbers, but before there was an IEEE standard with things
like NaN, Inf, and signed zeros  But there *is* an IEEE standard now,
and even IBM mainframes offer IEEE-compliant arithmetic, so worrying
about the sign of zero etc is not something we can really overlook
these days.

You are of course correct that the one-point compactification of the
complex numbers involves adjoining just one infinity and that whacking
IEEE infinities into complex numbers does not give you anything
mathematically interesting (unless you count grief and vexation as
"interesting" (:-)).  Since R distinguishes between 0+Infi and
NaN+Infi, it's not clear that the one-point compactification has any
relevance to what R does.  And it's not just an unexpected NaN; with
all numbers finite you can get zeros with the wrong sign.  (S having
been designed before the sign of zero was something you needed to be
aware of.)

For what it's worth, the ISO "Language Independent Arithmetic"
standard, part 3, defines separate real, imaginary, and complex types,
and defines x*(z,w) to be (x*z, x*w) directly, just like C and Ada.
So it is quite clear that R does not currently conform to LIA-3.
LIA-3 (ISO/IEC 10967-3:2006) is the nearest we have to a definition of
what "right" answers are for floating-point complex arithmetic, and
what R does cannot be called "right" by that definition.  But of
course R doesn't claim conformance to any part of the LIA standard.

Whether the R community *want* R and C to give the same answers is not
for me to say.  I can only say that *I* found it reassuring that C
gave the expected answers when R did not, or, to put it another way,
disconcerting that R did not agree with C (or LIA-3).


What really annoys me is that I wrote an entire technical report on
(some of the) problems with complex arithmetic, and this whole "just
treat x as (x, +0.0)" thing completely failed to occur to me as
something anyone might do.

On Fri, 6 Sept 2024 at 20:37, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Richard O'Keefe
> >>>>>     on Fri, 6 Sep 2024 17:24:07 +1200 writes:
>
>     > The thing is that real*complex, complex*real, and complex/real are not
>     > "complex arithmetic" in the requisite sense.
>
>     > The complex numbers are a vector space over  the reals,
>
> Yes, but they _also_ are field (and as others have argued mathematically only
> have one infinity point),
> and I think here we are fighting with which definition should
> take precedence here.
> The English Wikipedia page is even more extensive and precise,
>  https://en.wikipedia.org/wiki/Complex_number   (line breaking by me):
>
>  " The complex numbers form a rich structure that is simultaneously
>   - an algebraically closed field,
>   - a commutative algebra over the reals,   and
>   - a Euclidean vector space of dimension two."
>
> our problem "of course" is that we additionally add  +/- Inf for
> the reals and for storage etc treating them as a 2D vector space
> over the reals is "obvious".
>
>     > and complex*real and real*complex are vector*scalar and scalar*vector.
>     > For example, in the Ada programming language, we have
>     > function "*" (Left, Right : Complex) return Complex;
>     > function "*" (Left : Complex;   Right : Real'Base) return Complex;
>     > function "*" (Left : Real'Base; Right : Complex)   return Complex;
>     > showing that Z*R and Z*W involve *different* functions.
>
>     > It's worth noting that complex*real and real*complex just require two
>     > real multiplications,
>     > no other arithmetic operations, while complex*complex requires four
>     > real multiplications,
>     > an addition, and a subtraction.  So implementing complex*real by
>     > conventing the real
>     > to complex is inefficient (as well as getting the finer points of IEEE
>     > arithmetic wrong).
>
> I see your point.
>
>     > As for complex division, getting that *right* in floating-point is
>     > fiendishly difficult (there are
>     > lots of algorithms out there and the majority of them have serious flaws)
>     > and woefully costly.
>
>     > It's not unfair to characterise implementing complex/real
>     > by conversion to complex and doing complex/complex as a
>     > beginner's bungle.
>
> ouch!  ... but still I tend to acknowledge your point, incl the "not unfair" ..
>
>     > There are good reasons why "double", "_Imaginary double", and "_Complex double"
>     > are distinct types in standard C (as they are in Ada),
>
> interesting.  OTOH, I think standard C did not have strict
> standards about complex number storage etc in the mid 1990s
> when R was created.
>
>     > and the definition of multiplication
>     > in G.5.1 para 2 is *direct* (not via complex*complex).
>
> I see (did not know about) -- where can we find  'G.5.1 para 2'
>
>     > Now R has its own way of doing things, and if the judgement of the R
>     > maintainers is
>     > that keeping the "convert to a common type and then operate" model is
>     > more important
>     > than getting good answers, well, it's THEIR language, not mine.
>
> Well, it should also be the R community's language,
> where we, the R core team, do most of the "base" work and also
> emphasize guaranteeing long term stability.
>
> Personally, I think that
>    "convert to a common type and then operate"
> is a good rule and principle in many, even most places and cases,
> but I hate it if humans should not be allowed to break good
> rules for even better reasons  (but should rather behave like algorithms  ..).
>
> This may well be a very good example of re-considering.
> As mentioned above, e.g., I was not aware of the C language standard
> being so specific here and different than what we've been doing
> in R.
>
>
>     > But let's not pretend
>     > that the answers are *right* in any other sense.
>
> I think that's too strong -- Jeff's computation (just here below)
> is showing one well defined sense of "right" I'd say.
> (Still I know and agree the    Inf * 0 |--> NaN
>  rule *is* sometimes undesirable)
>
>     > On Fri, 6 Sept 2024 at 11:07, Jeff Newmiller via R-help
>     > <r-help at r-project.org> wrote:
>     >>
>     >> atan(1i) -> 0 + Inf i
>     >> complex(1/5) -> 0.2 + 0i
>     >> atan(1i) -> (0 + Inf i) * (0.2 + 0i)
>     -> 0*0.2 + 0*0i + Inf i * 0.2 + Inf i * 0i
>     >> infinity times zero is undefined
>     -> 0 + 0i + Inf i + NaN * i^2
>     -> 0 + 0i + Inf i - NaN
>     -> NaN + Inf i
>     >>
>     >> I am not sure how complex arithmetic could arrive at another answer.
>     >>
>     >> I advise against messing with infinities... use atan2() if you don't actually need complex arithmetic.
>     >>
>     >> On September 5, 2024 3:38:33 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>     >> >> complex(real = 0, imaginary = Inf)
>     >> >[1] 0+Infi
>     >> >
>     >> >> Inf*1i
>     >> >[1] NaN+Infi
>     >> >
>     >> >>> complex(real = 0, imaginary = Inf)/5
>     >> >[1] NaN+Infi
>     >> >
>     >> >See the Note in ?complex for the explanation, I think.  Duncan can correct
>     >> >if I'm wrong.
>     >> >
>     >> >-- Bert
>
>  [...................]
>
> Martin
>
> --
> Martin Maechler
> ETH Zurich  and   R Core team


From JH@rm@e @end|ng |rom roku@com  Fri Sep  6 18:57:35 2024
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Fri, 6 Sep 2024 16:57:35 +0000
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <mailman.371911.7678.1725607380.1268.r-help@r-project.org>
References: <mailman.371911.7678.1725607380.1268.r-help@r-project.org>
Message-ID: <BL0PR01MB4434094155C2FD480814D4A0DC9E2@BL0PR01MB4434.prod.exchangelabs.com>

It seems to me that the documentation of R's complex class & R's atan function do not tell us what to expect, so (as others have suggested), some additional notes are needed. I think that mathematically atan(1i) should be NA_complex_, but R seems not to use any mathematically standard compactification of the complex plane (and I'm not sure that IEEE does either).

Incidentally, the signature of the complex constructor is confusing. complex(1L) returns zero, but complex(1L, argument=theta) is an element of the unit circle. The defaults suggest ambiguous results in case only length.out is specified, and you have to read a parenthesis in the details to figure out what will happen. Even then, the behaviour in my example is not spelled out (although it is suggested by negative inference). Moreover, the real & imaginary parts are ignored if either modulus or argument is provided, and I don't see that this is explained at all.

R's numeric (& IEEE's floating-point types) seem to approximate a multi-point compactification of the real line. +Inf & -Inf fill out the approximation to the extended real line, and NaN, NA_real_ & maybe some others handle some cases in which the answer does not live in the extended real line. (I'm not digging into bit patterns here. I suspect that there are several versions of NaN, but I hope that they all behave the same way.) The documentation suggests that a complex scalar in R is just a pair of numeric scalars, so we are not dealing with the Riemann sphere or any other usually-studied extension of the complex plane. Since R distinguishes various complex infinities (and seems to allow any combination of numeric values in real & imaginary parts), the usual mathematical answer for atan(1i) may no longer be relevant.

The tangent function has an essential singularity at complex infinity (the compactification point in the Riemann sphere, which I consider the natural extension for the study of meromorphic functions, for example making the tangent function well defined on the whole plane), so the usual extension of the plane does not give us an answer for atan(1i). However, another possible extension is the Cartesian square of the extended real line, and in that extension continuity suggests that tan(x + Inf*1i) = 1i and tan(x - Inf*1i) = -1i (for x real & finite). That is the result from R's tan function, and it explains why atan(1i) in R is not NA or NaN. The specific choice of pi/4 + Inf*1i puzzled me at first, but I think it's related to the branch-cut rules given in the documentation. The real part of atan((1+.Machine$double.eps)*1i) is pi/2, and the real part of atan((1-.Machine$double.eps)*1i) is zero, and someone apparently decided to average those for atan(1i).

TL;DR: The documentation needs more details, and I don't really like the extended complex plane that R implemented, but within that framework the answers for atan(1i) & atan(-1i) make sense.

Regards,
Jorgen Harmse.





	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Sep  7 17:01:12 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 7 Sep 2024 17:01:12 +0200
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CABcYAd+LZrfVMU9AjU6jQfd_O8pCbbYotNSthpWSJKdLAG4oDA@mail.gmail.com>
References: <DBAP192MB0956E56C96996102FA20D5E8849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <f3a0740d-386a-44e4-8415-7259c1e8827f@gmail.com>
 <CAGxFJbQGcyzHa=Km+z_+iy=m9RaUCrsPOfXmHKWMPcXh9bbeHA@mail.gmail.com>
 <DBAP192MB09561B0A36D4EE0719704DFF849D2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbRmhS0Uuzwa75A=9bwj1+fv50Q1T78V-kbezKwcEFoDvQ@mail.gmail.com>
 <B013294E-6859-41ED-B0E4-D6E1E6512B3E@dcn.davis.ca.us>
 <CABcYAdLZaO+9HTTAQg0PTGjgDzdSc42LV+fJv8nNMy_WOrb4+A@mail.gmail.com>
 <26330.48976.240526.972936@stat.math.ethz.ch>
 <CABcYAd+LZrfVMU9AjU6jQfd_O8pCbbYotNSthpWSJKdLAG4oDA@mail.gmail.com>
Message-ID: <26332.27320.79283.293497@stat.math.ethz.ch>

>>>>> Richard O'Keefe 
>>>>>     on Sat, 7 Sep 2024 02:40:29 +1200 writes:

    > G.5.1 para 2 can be found in the C17 standard -- I
    > actually have the final draft not the published standard.

Ok.  Thank you.

A direct hopefully stable link to that final draft's  Appendix G
seems to be    
  https://www.open-std.org/JTC1/SC22/WG14/www/docs/n2310.pdf#chapter.14

which is good to have available.

    > It's in earlier standards, I just didn't check earlier
    > standards.  Complex arithmetic was not in the first C
    > standard (C89) but was in C99.

indeed, currently we only require C11 for R.

A longer term solution that we (the R core team) will probably
look into is to start making use of current C standards for
complex arithmetic.

As mentioned, all this was not yet available when R started and
already came with complex numbers as base type  ....
It may (or may not, I'm not the expert) be a bit challenging
trying to remain back compatible (e.g. with save complex number
R objects)  and still use C standard complex headers ...

But mid to long term I guess that would be the way to go.

Martin

    > The complex numbers do indeed form a field, and Z*W
    > invokes an operation in that field when Z and W are both
    > complex numbers.  Z*R and R*Z, where R is
    > real-but-not-complex, is not that field operation; it's
    > the scalar multiplication from the vector spec view.

    > One way to characterise the C and Ada view is that real
    > numbers x can be viewed as (x,ZERO!!!) and imaginary
    > numbers y*i can be viewed as (ZERO!!!, y) where ZERO!!! is
    > a real serious HARD zero, not an IEEE +epsilon or
    > -epsilon, In fact this is important for getting "sign of
    > zero" right.  x + (u,v) = (x+u, v) *NOT* (x+u, v+0) and
    > this does matter in IEEE arithmetic.

    > R is of course based on S, and S was not only designed
    > before C got complex numbers, but before there was an IEEE
    > standard with things like NaN, Inf, and signed zeros But
    > there *is* an IEEE standard now, and even IBM mainframes
    > offer IEEE-compliant arithmetic, so worrying about the
    > sign of zero etc is not something we can really overlook
    > these days.

    > You are of course correct that the one-point
    > compactification of the complex numbers involves adjoining
    > just one infinity and that whacking IEEE infinities into
    > complex numbers does not give you anything mathematically
    > interesting (unless you count grief and vexation as
    > "interesting" (:-)).  Since R distinguishes between 0+Infi
    > and NaN+Infi, it's not clear that the one-point
    > compactification has any relevance to what R does.  And
    > it's not just an unexpected NaN; with all numbers finite
    > you can get zeros with the wrong sign.  (S having been
    > designed before the sign of zero was something you needed
    > to be aware of.)

    > For what it's worth, the ISO "Language Independent
    > Arithmetic" standard, part 3, defines separate real,
    > imaginary, and complex types, and defines x*(z,w) to be
    > (x*z, x*w) directly, just like C and Ada.  So it is quite
    > clear that R does not currently conform to LIA-3.  LIA-3
    > (ISO/IEC 10967-3:2006) is the nearest we have to a
    > definition of what "right" answers are for floating-point
    > complex arithmetic, and what R does cannot be called
    > "right" by that definition.  But of course R doesn't claim
    > conformance to any part of the LIA standard.

    > Whether the R community *want* R and C to give the same
    > answers is not for me to say.  I can only say that *I*
    > found it reassuring that C gave the expected answers when
    > R did not, or, to put it another way, disconcerting that R
    > did not agree with C (or LIA-3).


Thank you.
Indeed, I'd  like the idea to consider  LIA  standards as much
as (sensibly) possible.

Martin


    > What really annoys me is that I wrote an entire technical
    > report on (some of the) problems with complex arithmetic,
    > and this whole "just treat x as (x, +0.0)" thing
    > completely failed to occur to me as something anyone might
    > do.

    > On Fri, 6 Sept 2024 at 20:37, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> >>>>> Richard O'Keefe >>>>> on Fri, 6 Sep 2024 17:24:07
    >> +1200 writes:
    >> 
    >> > The thing is that real*complex, complex*real, and
    >> complex/real are not > "complex arithmetic" in the
    >> requisite sense.
    >> 
    >> > The complex numbers are a vector space over the reals,
    >> 
    >> Yes, but they _also_ are field (and as others have argued
    >> mathematically only have one infinity point), and I think
    >> here we are fighting with which definition should take
    >> precedence here.  The English Wikipedia page is even more
    >> extensive and precise,
    >> https://en.wikipedia.org/wiki/Complex_number (line
    >> breaking by me):
    >> 
    >> " The complex numbers form a rich structure that is
    >> simultaneously - an algebraically closed field, - a
    >> commutative algebra over the reals, and - a Euclidean
    >> vector space of dimension two."
    >> 
    >> our problem "of course" is that we additionally add +/-
    >> Inf for the reals and for storage etc treating them as a
    >> 2D vector space over the reals is "obvious".
    >> 
    >> > and complex*real and real*complex are vector*scalar and
    >> scalar*vector.  > For example, in the Ada programming
    >> language, we have > function "*" (Left, Right : Complex)
    >> return Complex; > function "*" (Left : Complex; Right :
    >> Real'Base) return Complex; > function "*" (Left :
    >> Real'Base; Right : Complex) return Complex; > showing
    >> that Z*R and Z*W involve *different* functions.
    >> 
    >> > It's worth noting that complex*real and real*complex
    >> just require two > real multiplications, > no other
    >> arithmetic operations, while complex*complex requires
    >> four > real multiplications, > an addition, and a
    >> subtraction.  So implementing complex*real by >
    >> conventing the real > to complex is inefficient (as well
    >> as getting the finer points of IEEE > arithmetic wrong).
    >> 
    >> I see your point.
    >> 
    >> > As for complex division, getting that *right* in
    >> floating-point is > fiendishly difficult (there are >
    >> lots of algorithms out there and the majority of them
    >> have serious flaws) > and woefully costly.
    >> 
    >> > It's not unfair to characterise implementing
    >> complex/real > by conversion to complex and doing
    >> complex/complex as a > beginner's bungle.
    >> 
    >> ouch!  ... but still I tend to acknowledge your point,
    >> incl the "not unfair" ..
    >> 
    >> > There are good reasons why "double", "_Imaginary
    >> double", and "_Complex double" > are distinct types in
    >> standard C (as they are in Ada),
    >> 
    >> interesting.  OTOH, I think standard C did not have
    >> strict standards about complex number storage etc in the
    >> mid 1990s when R was created.
    >> 
    >> > and the definition of multiplication > in G.5.1 para 2
    >> is *direct* (not via complex*complex).
    >> 
    >> I see (did not know about) -- where can we find 'G.5.1
    >> para 2'
    >> 
    >> > Now R has its own way of doing things, and if the
    >> judgement of the R > maintainers is > that keeping the
    >> "convert to a common type and then operate" model is >
    >> more important > than getting good answers, well, it's
    >> THEIR language, not mine.
    >> 
    >> Well, it should also be the R community's language, where
    >> we, the R core team, do most of the "base" work and also
    >> emphasize guaranteeing long term stability.
    >> 
    >> Personally, I think that "convert to a common type and
    >> then operate" is a good rule and principle in many, even
    >> most places and cases, but I hate it if humans should not
    >> be allowed to break good rules for even better reasons
    >> (but should rather behave like algorithms ..).
    >> 
    >> This may well be a very good example of re-considering.
    >> As mentioned above, e.g., I was not aware of the C
    >> language standard being so specific here and different
    >> than what we've been doing in R.
    >> 
    >> 
    >> > But let's not pretend > that the answers are *right* in
    >> any other sense.
    >> 
    >> I think that's too strong -- Jeff's computation (just
    >> here below) is showing one well defined sense of "right"
    >> I'd say.  (Still I know and agree the Inf * 0 |--> NaN
    >> rule *is* sometimes undesirable)
    >> 
    >> > On Fri, 6 Sept 2024 at 11:07, Jeff Newmiller via R-help
    >> > <r-help at r-project.org> wrote:
    >> >>
    >> >> atan(1i) -> 0 + Inf i >> complex(1/5) -> 0.2 + 0i >>
    >> atan(1i) -> (0 + Inf i) * (0.2 + 0i)
    -> 0*0.2 + 0*0i + Inf i * 0.2 + Inf i * 0i
    >> >> infinity times zero is undefined
    -> 0 + 0i + Inf i + NaN * i^2 0 + 0i + Inf i - NaN NaN + Inf
    -> i
    >> >>
    >> >> I am not sure how complex arithmetic could arrive at
    >> another answer.
    >> >>
    >> >> I advise against messing with infinities... use
    >> atan2() if you don't actually need complex arithmetic.
    >> >>
    >> >> On September 5, 2024 3:38:33 PM PDT, Bert Gunter
    >> <bgunter.4567 at gmail.com> wrote: >> >> complex(real = 0,
    >> imaginary = Inf) >> >[1] 0+Infi
    >> >> >
    >> >> >> Inf*1i >> >[1] NaN+Infi
    >> >> >
    >> >> >>> complex(real = 0, imaginary = Inf)/5 >> >[1]
    >> NaN+Infi
    >> >> >
    >> >> >See the Note in ?complex for the explanation, I
    >> think.  Duncan can correct >> >if I'm wrong.
    >> >> >
    >> >> >-- Bert
    >> 
    >> [...................]
    >> 
    >> Martin
    >> 
    >> --
    >> Martin Maechler ETH Zurich and R Core team


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Sep  7 21:56:36 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 8 Sep 2024 01:26:36 +0530
Subject: [R] Reading a txt file from internet
Message-ID: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>

Hi,

I am trying to the data from
https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
without any success. Below is the error I am getting:

> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')

Error in make.names(col.names, unique = TRUE) :

  invalid multibyte string at '<ff><fe>t'

In addition: Warning messages:

1: In read.table(file = file, header = header, sep = sep, quote = quote,  :

  line 1 appears to contain embedded nulls

2: In read.table(file = file, header = header, sep = sep, quote = quote,  :

  line 2 appears to contain embedded nulls

3: In read.table(file = file, header = header, sep = sep, quote = quote,  :

  line 3 appears to contain embedded nulls

4: In read.table(file = file, header = header, sep = sep, quote = quote,  :

  line 4 appears to contain embedded nulls

5: In read.table(file = file, header = header, sep = sep, quote = quote,  :

  line 5 appears to contain embedded nulls

Is there any way to read this data directly onto R?

Thanks for your time


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  7 22:20:21 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Sep 2024 13:20:21 -0700
Subject: [R] Reading a txt file from internet
In-Reply-To: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
Message-ID: <CAGxFJbTohZ-mR-ezm-v2Byr=WkAuppLd5CdVKNR5UzKA2m3U7w@mail.gmail.com>

Well, this is frankly an unsatisfactory answer, as it does not try to deal
properly with the issues that you experienced, which I also did. However,
it's simple and works. As this is a small text file,
simply copy it in your browser to the clipboard, and then use:
thefile <- read.table(text =
"<paste text here>", header = TRUE)
either in an editor or directly at the prompt in the console.

In fact here's the whole thing that you can just copy and paste from this
email:

thefile <-read.table(text =
"time vendor metal
1 322 44.2
2 317 44.3
3 319 44.4
4 323 43.4
5 327 42.8
6 328 44.3
7 325 44.4
8 326 44.8
9 330 44.4
10 334 43.1
11 337 42.6
12 341 42.4
13 322 42.2
14 318 41.8
15 320 40.1
16 326 42
17 332 42.4
18 334 43.1
19 335 42.4
20 336 43.1
21 335 43.2
22 338 42.8
23 342 43
24 348 42.8
25 330 42.5
26 326 42.6
27 329 42.3
28 337 42.9
29 345 43.6
30 350 44.7
31 351 44.5
32 354 45
33 355 44.8
34 357 44.9
35 362 45.2
36 368 45.2
37 348 45
38 345 45.5
39 349 46.2
40 355 46.8
41 362 47.5
42 367 48.3
43 366 48.3
44 370 49.1
45 371 48.9
46 375 49.4
47 380 50
48 385 50
49 361 49.6
50 354 49.9
51 357 49.6
52 367 50.7
53 376 50.7
54 381 50.9
55 381 50.5
56 383 51.2
57 384 50.7
58 387 50.3
59 392 49.2
60 396 48.1", header = TRUE)

Cheers,
Bert

On Sat, Sep 7, 2024 at 12:57?PM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I am trying to the data from
>
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> without any success. Below is the error I am getting:
>
> > read.delim('
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> ')
>
> Error in make.names(col.names, unique = TRUE) :
>
>   invalid multibyte string at '<ff><fe>t'
>
> In addition: Warning messages:
>
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 1 appears to contain embedded nulls
>
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 2 appears to contain embedded nulls
>
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 3 appears to contain embedded nulls
>
> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 4 appears to contain embedded nulls
>
> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 5 appears to contain embedded nulls
>
> Is there any way to read this data directly onto R?
>
> Thanks for your time
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |kw@|mmo @end|ng |rom gm@||@com  Sat Sep  7 22:20:59 2024
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Sat, 7 Sep 2024 16:20:59 -0400
Subject: [R] Reading a txt file from internet
In-Reply-To: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
Message-ID: <CADNULg_WHHBBGFS7YO0E3e9NEYQFaLrYmRjKq5S436c5hLk_4Q@mail.gmail.com>

That looks like a UTF-16LE byte order mark. Simply open the connection
with the proper encoding:

read.delim(
    'https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
    fileEncoding = "UTF-16LE"
)

On Sat, Sep 7, 2024 at 3:57?PM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> I am trying to the data from
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> without any success. Below is the error I am getting:
>
> > read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>
> Error in make.names(col.names, unique = TRUE) :
>
>   invalid multibyte string at '<ff><fe>t'
>
> In addition: Warning messages:
>
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 1 appears to contain embedded nulls
>
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 2 appears to contain embedded nulls
>
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 3 appears to contain embedded nulls
>
> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 4 appears to contain embedded nulls
>
> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 5 appears to contain embedded nulls
>
> Is there any way to read this data directly onto R?
>
> Thanks for your time
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Sat Sep  7 22:22:23 2024
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sat, 07 Sep 2024 22:22:23 +0200
Subject: [R] Reading a txt file from internet
In-Reply-To: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 (Christofer Bogaso's message of "Sun, 8 Sep 2024 01:26:36 +0530")
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
Message-ID: <8734mb1af4.fsf@enricoschumann.net>

On Sun, 08 Sep 2024, Christofer Bogaso writes:

> Hi,
>
> I am trying to the data from
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> without any success. Below is the error I am getting:
>
>> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>
> Error in make.names(col.names, unique = TRUE) :
>
>   invalid multibyte string at '<ff><fe>t'
>
> In addition: Warning messages:
>
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 1 appears to contain embedded nulls
>
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 2 appears to contain embedded nulls
>
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 3 appears to contain embedded nulls
>
> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 4 appears to contain embedded nulls
>
> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>   line 5 appears to contain embedded nulls
>
> Is there any way to read this data directly onto R?
>
> Thanks for your time
>

The <ff><fe> looks like a byte-order mark
(https://en.wikipedia.org/wiki/Byte_order_mark).
Try this:

    fn <- file('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
               encoding = "UTF-16LE")
    read.delim(fn)

-- 
Enrico Schumann
Lucerne, Switzerland
https://enricoschumann.net


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  7 22:40:34 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Sep 2024 13:40:34 -0700
Subject: [R] Reading a txt file from internet
In-Reply-To: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
Message-ID: <9983BE81-B175-42CC-8479-66004BA83A64@dcn.davis.ca.us>

Add the

   fileEncoding = "UTF-16"

argument to the read call.

For a human explanation of why this is going on I recommend [1]. For a more R-related take, try [2].

For reference, I downloaded your file and used the "file" command line program typically available on Linux (and possibly MacOSX) which will tell you about what encoding is used in a particular file.

[1] https://www.youtube.com/watch?v=4mRxIgu9R70
[2] https://kevinushey.github.io/blog/2018/02/21/string-encoding-and-r/

On September 7, 2024 12:56:36 PM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>I am trying to the data from
>https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
>without any success. Below is the error I am getting:
>
>> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>
>Error in make.names(col.names, unique = TRUE) :
>
>  invalid multibyte string at '<ff><fe>t'
>
>In addition: Warning messages:
>
>1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>  line 1 appears to contain embedded nulls
>
>2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>  line 2 appears to contain embedded nulls
>
>3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>  line 3 appears to contain embedded nulls
>
>4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>  line 4 appears to contain embedded nulls
>
>5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>
>  line 5 appears to contain embedded nulls
>
>Is there any way to read this data directly onto R?
>
>Thanks for your time
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  7 22:44:47 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Sep 2024 13:44:47 -0700
Subject: [R] Reading a txt file from internet
In-Reply-To: <CADNULg_WHHBBGFS7YO0E3e9NEYQFaLrYmRjKq5S436c5hLk_4Q@mail.gmail.com>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 <CADNULg_WHHBBGFS7YO0E3e9NEYQFaLrYmRjKq5S436c5hLk_4Q@mail.gmail.com>
Message-ID: <CAGxFJbSswXfFq7dYbQ=N+Hs1+_-zH5juOMii=OkS0dtTVBv_fQ@mail.gmail.com>

Ha, the proper answer!
Thanks for this, Iris. I followed up by consulting the Wikipedia "byte
order mark" entry and learned something I knew nothing about.

FWIW, if I had simply searched on <ff><fe>t it would have immediately led
me to BOMs.

Best,
Bert

On Sat, Sep 7, 2024 at 1:30?PM Iris Simmons <ikwsimmo at gmail.com> wrote:

> That looks like a UTF-16LE byte order mark. Simply open the connection
> with the proper encoding:
>
> read.delim(
>     '
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> ',
>     fileEncoding = "UTF-16LE"
> )
>
> On Sat, Sep 7, 2024 at 3:57?PM Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
> >
> > Hi,
> >
> > I am trying to the data from
> >
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> > without any success. Below is the error I am getting:
> >
> > > read.delim('
> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
> ')
> >
> > Error in make.names(col.names, unique = TRUE) :
> >
> >   invalid multibyte string at '<ff><fe>t'
> >
> > In addition: Warning messages:
> >
> > 1: In read.table(file = file, header = header, sep = sep, quote =
> quote,  :
> >
> >   line 1 appears to contain embedded nulls
> >
> > 2: In read.table(file = file, header = header, sep = sep, quote =
> quote,  :
> >
> >   line 2 appears to contain embedded nulls
> >
> > 3: In read.table(file = file, header = header, sep = sep, quote =
> quote,  :
> >
> >   line 3 appears to contain embedded nulls
> >
> > 4: In read.table(file = file, header = header, sep = sep, quote =
> quote,  :
> >
> >   line 4 appears to contain embedded nulls
> >
> > 5: In read.table(file = file, header = header, sep = sep, quote =
> quote,  :
> >
> >   line 5 appears to contain embedded nulls
> >
> > Is there any way to read this data directly onto R?
> >
> > Thanks for your time
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  7 22:52:31 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Sep 2024 13:52:31 -0700
Subject: [R] Reading a txt file from internet
In-Reply-To: <8734mb1af4.fsf@enricoschumann.net>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 <8734mb1af4.fsf@enricoschumann.net>
Message-ID: <66E77559-A57E-4273-B8E6-E9B433ECDE43@dcn.davis.ca.us>

When you specify LE in the encoding type, you are logically telling the decoder that you know the two-byte pairs are in little-endian order... which could override whatever the byte-order-mark was indicating. If the BOM indicated big-endian then the file decoding would break. If there is a BOM, don't override it unless you have to (e.g. for a wrong BOM)... leave off the LE unless you really need it.

On September 7, 2024 1:22:23 PM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>On Sun, 08 Sep 2024, Christofer Bogaso writes:
>
>> Hi,
>>
>> I am trying to the data from
>> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
>> without any success. Below is the error I am getting:
>>
>>> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>>
>> Error in make.names(col.names, unique = TRUE) :
>>
>>   invalid multibyte string at '<ff><fe>t'
>>
>> In addition: Warning messages:
>>
>> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>
>>   line 1 appears to contain embedded nulls
>>
>> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>
>>   line 2 appears to contain embedded nulls
>>
>> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>
>>   line 3 appears to contain embedded nulls
>>
>> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>
>>   line 4 appears to contain embedded nulls
>>
>> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>
>>   line 5 appears to contain embedded nulls
>>
>> Is there any way to read this data directly onto R?
>>
>> Thanks for your time
>>
>
>The <ff><fe> looks like a byte-order mark
>(https://en.wikipedia.org/wiki/Byte_order_mark).
>Try this:
>
>    fn <- file('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
>               encoding = "UTF-16LE")
>    read.delim(fn)
>

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep  7 23:43:24 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 7 Sep 2024 17:43:24 -0400
Subject: [R] Reading a txt file from internet
In-Reply-To: <66E77559-A57E-4273-B8E6-E9B433ECDE43@dcn.davis.ca.us>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 <8734mb1af4.fsf@enricoschumann.net>
 <66E77559-A57E-4273-B8E6-E9B433ECDE43@dcn.davis.ca.us>
Message-ID: <54c12472-4017-4e09-ab1a-2df1c6b12ecb@gmail.com>

On 2024-09-07 4:52 p.m., Jeff Newmiller via R-help wrote:
> When you specify LE in the encoding type, you are logically telling the decoder that you know the two-byte pairs are in little-endian order... which could override whatever the byte-order-mark was indicating. If the BOM indicated big-endian then the file decoding would break. If there is a BOM, don't override it unless you have to (e.g. for a wrong BOM)... leave off the LE unless you really need it.

That sounds like good advice, but it doesn't work:

  > read.delim(
  +     'https://online.stat.psu.edu/onlinecourses/sites/stat501/files 
/ch15/employee.txt',
  +     fileEncoding = "UTF-16"
  + )
  [1] time 
 
 
 
 
 
 
 
 
 
 
 
 
 

  [2] 
vendor.?????........??........?.??........?.??.?..?.....?..?..?...?.?..?..?...?.??....?...?.??.

and so on.
> 
> On September 7, 2024 1:22:23 PM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>> On Sun, 08 Sep 2024, Christofer Bogaso writes:
>>
>>> Hi,
>>>
>>> I am trying to the data from
>>> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
>>> without any success. Below is the error I am getting:
>>>
>>>> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>>>
>>> Error in make.names(col.names, unique = TRUE) :
>>>
>>>    invalid multibyte string at '<ff><fe>t'
>>>
>>> In addition: Warning messages:
>>>
>>> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>
>>>    line 1 appears to contain embedded nulls
>>>
>>> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>
>>>    line 2 appears to contain embedded nulls
>>>
>>> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>
>>>    line 3 appears to contain embedded nulls
>>>
>>> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>
>>>    line 4 appears to contain embedded nulls
>>>
>>> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>
>>>    line 5 appears to contain embedded nulls
>>>
>>> Is there any way to read this data directly onto R?
>>>
>>> Thanks for your time
>>>
>>
>> The <ff><fe> looks like a byte-order mark
>> (https://en.wikipedia.org/wiki/Byte_order_mark).
>> Try this:
>>
>>     fn <- file('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
>>                encoding = "UTF-16LE")
>>     read.delim(fn)
>>
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  8 01:37:50 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Sep 2024 16:37:50 -0700
Subject: [R] Reading a txt file from internet
In-Reply-To: <54c12472-4017-4e09-ab1a-2df1c6b12ecb@gmail.com>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 <8734mb1af4.fsf@enricoschumann.net>
 <66E77559-A57E-4273-B8E6-E9B433ECDE43@dcn.davis.ca.us>
 <54c12472-4017-4e09-ab1a-2df1c6b12ecb@gmail.com>
Message-ID: <663B47CF-365D-4C12-8B9E-4BDDF4F10E05@dcn.davis.ca.us>

I tried it on R 4.4.1 on Linux Mint 21.3 just before I posted it, and I just tried it on R 3.4.2 on Ubuntu 16.04 and R 4.3.2 on Windows 11 just now and it works on all of them.

I don't have a big-endian machine to test on, but the Unicode spec says to honor the BOM and if there isn't one to assume that it is big-endian data. But in this case there is a BOM so your machine has a buggy decoder?

On September 7, 2024 2:43:24 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 2024-09-07 4:52 p.m., Jeff Newmiller via R-help wrote:
>> When you specify LE in the encoding type, you are logically telling the decoder that you know the two-byte pairs are in little-endian order... which could override whatever the byte-order-mark was indicating. If the BOM indicated big-endian then the file decoding would break. If there is a BOM, don't override it unless you have to (e.g. for a wrong BOM)... leave off the LE unless you really need it.
>
>That sounds like good advice, but it doesn't work:
>
> > read.delim(
> +     'https://online.stat.psu.edu/onlinecourses/sites/stat501/files /ch15/employee.txt',
> +     fileEncoding = "UTF-16"
> + )
> [1] time 
>
>
>
>
>
>
>
>
>
>
>
>
>
> [2] vendor.?????........??........?.??........?.??.?..?.....?..?..?...?.?..?..?...?.??....?...?.??.
>
>and so on.
>> 
>> On September 7, 2024 1:22:23 PM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>>> On Sun, 08 Sep 2024, Christofer Bogaso writes:
>>> 
>>>> Hi,
>>>> 
>>>> I am trying to the data from
>>>> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
>>>> without any success. Below is the error I am getting:
>>>> 
>>>>> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>>>> 
>>>> Error in make.names(col.names, unique = TRUE) :
>>>> 
>>>>    invalid multibyte string at '<ff><fe>t'
>>>> 
>>>> In addition: Warning messages:
>>>> 
>>>> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>> 
>>>>    line 1 appears to contain embedded nulls
>>>> 
>>>> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>> 
>>>>    line 2 appears to contain embedded nulls
>>>> 
>>>> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>> 
>>>>    line 3 appears to contain embedded nulls
>>>> 
>>>> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>> 
>>>>    line 4 appears to contain embedded nulls
>>>> 
>>>> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>> 
>>>>    line 5 appears to contain embedded nulls
>>>> 
>>>> Is there any way to read this data directly onto R?
>>>> 
>>>> Thanks for your time
>>>> 
>>> 
>>> The <ff><fe> looks like a byte-order mark
>>> (https://en.wikipedia.org/wiki/Byte_order_mark).
>>> Try this:
>>> 
>>>     fn <- file('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
>>>                encoding = "UTF-16LE")
>>>     read.delim(fn)
>>> 
>> 
>

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Sep  8 11:05:41 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 8 Sep 2024 05:05:41 -0400
Subject: [R] Reading a txt file from internet
In-Reply-To: <663B47CF-365D-4C12-8B9E-4BDDF4F10E05@dcn.davis.ca.us>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 <8734mb1af4.fsf@enricoschumann.net>
 <66E77559-A57E-4273-B8E6-E9B433ECDE43@dcn.davis.ca.us>
 <54c12472-4017-4e09-ab1a-2df1c6b12ecb@gmail.com>
 <663B47CF-365D-4C12-8B9E-4BDDF4F10E05@dcn.davis.ca.us>
Message-ID: <0a263f2d-51c5-4900-b4ab-ec11d3edd821@gmail.com>

On 2024-09-07 7:37 p.m., Jeff Newmiller wrote:
> I tried it on R 4.4.1 on Linux Mint 21.3 just before I posted it, and I just tried it on R 3.4.2 on Ubuntu 16.04 and R 4.3.2 on Windows 11 just now and it works on all of them.
> 
> I don't have a big-endian machine to test on, but the Unicode spec says to honor the BOM and if there isn't one to assume that it is big-endian data. But in this case there is a BOM so your machine has a buggy decoder?

Sounds like it!  I did it on a Mac running R 4.4.1.

Duncan Murdoch

> 
> On September 7, 2024 2:43:24 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 2024-09-07 4:52 p.m., Jeff Newmiller via R-help wrote:
>>> When you specify LE in the encoding type, you are logically telling the decoder that you know the two-byte pairs are in little-endian order... which could override whatever the byte-order-mark was indicating. If the BOM indicated big-endian then the file decoding would break. If there is a BOM, don't override it unless you have to (e.g. for a wrong BOM)... leave off the LE unless you really need it.
>>
>> That sounds like good advice, but it doesn't work:
>>
>>> read.delim(
>> +     'https://online.stat.psu.edu/onlinecourses/sites/stat501/files /ch15/employee.txt',
>> +     fileEncoding = "UTF-16"
>> + )
>> [1] time
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> [2] vendor.?????........??........?.??........?.??.?..?.....?..?..?...?.?..?..?...?.??....?...?.??.
>>
>> and so on.
>>>
>>> On September 7, 2024 1:22:23 PM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>>>> On Sun, 08 Sep 2024, Christofer Bogaso writes:
>>>>
>>>>> Hi,
>>>>>
>>>>> I am trying to the data from
>>>>> https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt
>>>>> without any success. Below is the error I am getting:
>>>>>
>>>>>> read.delim('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt')
>>>>>
>>>>> Error in make.names(col.names, unique = TRUE) :
>>>>>
>>>>>     invalid multibyte string at '<ff><fe>t'
>>>>>
>>>>> In addition: Warning messages:
>>>>>
>>>>> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 1 appears to contain embedded nulls
>>>>>
>>>>> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 2 appears to contain embedded nulls
>>>>>
>>>>> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 3 appears to contain embedded nulls
>>>>>
>>>>> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 4 appears to contain embedded nulls
>>>>>
>>>>> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 5 appears to contain embedded nulls
>>>>>
>>>>> Is there any way to read this data directly onto R?
>>>>>
>>>>> Thanks for your time
>>>>>
>>>>
>>>> The <ff><fe> looks like a byte-order mark
>>>> (https://en.wikipedia.org/wiki/Byte_order_mark).
>>>> Try this:
>>>>
>>>>      fn <- file('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
>>>>                 encoding = "UTF-16LE")
>>>>      read.delim(fn)
>>>>
>>>
>>
>


From tebert @end|ng |rom u||@edu  Sun Sep  8 13:47:57 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sun, 8 Sep 2024 11:47:57 +0000
Subject: [R] Reading a txt file from internet
In-Reply-To: <0a263f2d-51c5-4900-b4ab-ec11d3edd821@gmail.com>
References: <CA+dpOJmXu6=+Ho9dosHyJW4fDhEE91S2c9_q59K66D74FhVFMw@mail.gmail.com>
 <8734mb1af4.fsf@enricoschumann.net>
 <66E77559-A57E-4273-B8E6-E9B433ECDE43@dcn.davis.ca.us>
 <54c12472-4017-4e09-ab1a-2df1c6b12ecb@gmail.com>
 <663B47CF-365D-4C12-8B9E-4BDDF4F10E05@dcn.davis.ca.us>
 <0a263f2d-51c5-4900-b4ab-ec11d3edd821@gmail.com>
Message-ID: <CH3PR22MB4514B61558CD31FD492EABBECF982@CH3PR22MB4514.namprd22.prod.outlook.com>

Say that you have several files from different places or times and you wanted to run your program on all of them without reprogramming. You could start with the readr package and use guess_encoding.
j <- 1
for (i in file_paths){
  file_encoding[j] <- as.character(readr::guess_encoding(i)$encoding)
  j=j+1
}

With the encoding of each file, you can combine file_paths and file_encoding and then break this into multiple data frames based on encoding. Read all the data, reformat for consistency, and then combine them.

More simply, you could just guess_encoding() on one file just to see what it might be like. It gives you a name like UTF-16LE that you can then use in the encoding statement as others have already shown.


Tim



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Duncan Murdoch
Sent: Sunday, September 8, 2024 5:06 AM
To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org; Enrico Schumann <es at enricoschumann.net>; Christofer Bogaso <bogaso.christofer at gmail.com>
Subject: Re: [R] Reading a txt file from internet

[External Email]

On 2024-09-07 7:37 p.m., Jeff Newmiller wrote:
> I tried it on R 4.4.1 on Linux Mint 21.3 just before I posted it, and I just tried it on R 3.4.2 on Ubuntu 16.04 and R 4.3.2 on Windows 11 just now and it works on all of them.
>
> I don't have a big-endian machine to test on, but the Unicode spec says to honor the BOM and if there isn't one to assume that it is big-endian data. But in this case there is a BOM so your machine has a buggy decoder?

Sounds like it!  I did it on a Mac running R 4.4.1.

Duncan Murdoch

>
> On September 7, 2024 2:43:24 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 2024-09-07 4:52 p.m., Jeff Newmiller via R-help wrote:
>>> When you specify LE in the encoding type, you are logically telling the decoder that you know the two-byte pairs are in little-endian order... which could override whatever the byte-order-mark was indicating. If the BOM indicated big-endian then the file decoding would break. If there is a BOM, don't override it unless you have to (e.g. for a wrong BOM)... leave off the LE unless you really need it.
>>
>> That sounds like good advice, but it doesn't work:
>>
>>> read.delim(
>> +     'https://online.stat.psu.edu/onlinecourses/sites/stat501/files /ch15/employee.txt',
>> +     fileEncoding = "UTF-16"
>> + )
>> [1] time
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> [2] vendor.?????........??........?.??........?.??.?..?.....?..?..?...?.?..?..?...?.??....?...?.??.
>>
>> and so on.
>>>
>>> On September 7, 2024 1:22:23 PM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>>>> On Sun, 08 Sep 2024, Christofer Bogaso writes:
>>>>
>>>>> Hi,
>>>>>
>>>>> I am trying to the data from
>>>>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2F
>>>>> online.stat.psu.edu%2Fonlinecourses%2Fsites%2Fstat501%2Ffiles%2Fch
>>>>> 15%2Femployee.txt&data=05%7C02%7Ctebert%40ufl.edu%7C07d806c97fa945
>>>>> f64baf08dccfe57631%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C63
>>>>> 8613831690785878%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQI
>>>>> joiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=icg%2
>>>>> BW984cnNyT1XEjXU8HA%2B%2Bm0euoDQjblE4gsdFl4c%3D&reserved=0
>>>>> without any success. Below is the error I am getting:
>>>>>
>>>>>> read.delim('http://h/
>>>>>> ttps%3A%2F%2Fonline.stat.psu.edu%2Fonlinecourses%2Fsites%2Fstat50
>>>>>> 1%2Ffiles%2Fch15%2Femployee.txt&data=05%7C02%7Ctebert%40ufl.edu%7
>>>>>> C07d806c97fa945f64baf08dccfe57631%7C0d4da0f84a314d76ace60a62331e1
>>>>>> b84%7C0%7C0%7C638613831690788947%7CUnknown%7CTWFpbGZsb3d8eyJWIjoi
>>>>>> MC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C
>>>>>> %7C%7C&sdata=CKXMTrJdSo%2F%2FADPixS7XKkliVcETjbxLq0X2BSseCe4%3D&r
>>>>>> eserved=0')
>>>>>
>>>>> Error in make.names(col.names, unique = TRUE) :
>>>>>
>>>>>     invalid multibyte string at '<ff><fe>t'
>>>>>
>>>>> In addition: Warning messages:
>>>>>
>>>>> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 1 appears to contain embedded nulls
>>>>>
>>>>> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 2 appears to contain embedded nulls
>>>>>
>>>>> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 3 appears to contain embedded nulls
>>>>>
>>>>> 4: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 4 appears to contain embedded nulls
>>>>>
>>>>> 5: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>>>>>
>>>>>     line 5 appears to contain embedded nulls
>>>>>
>>>>> Is there any way to read this data directly onto R?
>>>>>
>>>>> Thanks for your time
>>>>>
>>>>
>>>> The <ff><fe> looks like a byte-order mark
>>>> (https://en.wikipedia.org/wiki/Byte_order_mark).
>>>> Try this:
>>>>
>>>>      fn <- file('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/ch15/employee.txt',
>>>>                 encoding = "UTF-16LE")
>>>>      read.delim(fn)
>>>>
>>>
>>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From @@e||ck @end|ng |rom gm@||@com  Wed Sep 11 15:44:05 2024
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Wed, 11 Sep 2024 09:44:05 -0400
Subject: [R] Stop or limit to console printing large list and so on
Message-ID: <CADKEMqiO42e5tfy6qC3VzUzabX31u5duS86Er0F5kXsJOrgoBQ@mail.gmail.com>

Hello All:

Background/setup:
Editor Emacs using "isend" to send code to shell in another window. This is
on Linux. I can share more of the setup if others would find it useful, but
I suspect this is an option I am unaware of.

Problem:
I am having a problem with accidentally typing an object name at the
console that is a very large list and then having to wait for it to be
printed until I can resume my work.

Is there a way that I have missed to stem this default behavior?
Kindest regards,

Stephen Sefick

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Wed Sep 11 17:47:47 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 11 Sep 2024 18:47:47 +0300
Subject: [R] Stop or limit to console printing large list and so on
In-Reply-To: <CADKEMqiO42e5tfy6qC3VzUzabX31u5duS86Er0F5kXsJOrgoBQ@mail.gmail.com>
References: <CADKEMqiO42e5tfy6qC3VzUzabX31u5duS86Er0F5kXsJOrgoBQ@mail.gmail.com>
Message-ID: <20240911184747.4210bf09@arachnoid>

? Wed, 11 Sep 2024 09:44:05 -0400
stephen sefick <ssefick at gmail.com> ?????:

> I am having a problem with accidentally typing an object name at the
> console that is a very large list and then having to wait for it to be
> printed until I can resume my work.

Does it help to interrupt the process?

https://www.gnu.org/software/emacs/manual/html_mono/emacs.html#index-C_002dc-C_002dc-_0028Shell-mode_0029
https://ess.r-project.org/Manual/ess.html#index-interrupting-R-commands

I'm afraid that the behaviour of the print() method is very
class-dependent and limiting options(max.print=...) may not help in
your case.

-- 
Best regards,
Ivan


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Sep 11 17:55:53 2024
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 11 Sep 2024 17:55:53 +0200
Subject: [R] non-conformable arrays
Message-ID: <CAJuCY5ypgAc2CBC+=OwpJDKDNFsOBbFNAi_NxFViLCp2o4C-nw@mail.gmail.com>

Dear all,

I'm puzzled by this error. When running tcrossprod() within the function it
returns the error message. The code also outputs the object a and b.
Running the tcrossprod() outside of the function works as expected.

        cat("a <-")
        dput(a)
        cat("b <-")
        dput(b)
        cat("tcrossprod(a, b)")
        tcrossprod(a, b)

a <-structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 1), dim = c(10L, 2L), dimnames = list(c("9", "13", "21",
"29", "30", "37", "52", "53", "56", "70"),
c("tmp2028c70ae152b4c63bb7ab902158b408366217581",
"tmp2028c70ae152b4c63bb7ab902158b408366217582")), assign = c(1L,
1L), contrasts = list(tmp2028c70ae152b4c63bb7ab902158b40836621758 =
"contr.treatment"))
b <-structure(c(-0.916362039446752, -0.849801808879291, -0.744535398206787,
0.875896407785924, 0.822587420283086, 0.894210774042389), dim = 3:2)
tcrossprod(a, b)

For those how like a fully reproducible example:
the offending line in the code:
https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/R/impute_glmermod.R#L65
a (failing) unit test for the code:
https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/tests/testthat/test_ccc_hurdle_impute.R#L10

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

	[[alternative HTML version deleted]]


From @@e||ck @end|ng |rom gm@||@com  Wed Sep 11 18:21:53 2024
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Wed, 11 Sep 2024 12:21:53 -0400
Subject: [R] Stop or limit to console printing large list and so on
In-Reply-To: <20240911184747.4210bf09@arachnoid>
References: <CADKEMqiO42e5tfy6qC3VzUzabX31u5duS86Er0F5kXsJOrgoBQ@mail.gmail.com>
 <20240911184747.4210bf09@arachnoid>
Message-ID: <CADKEMqjz_+=JqQQwohmNH=G7rM=opV5+UeKSeVrKntjxr6Qemw@mail.gmail.com>

No an interrupt does not help, unfortunately.

I'll just try be more careful.

Stephen Sefick

On Wed, Sep 11, 2024, 11:47 Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Wed, 11 Sep 2024 09:44:05 -0400
> stephen sefick <ssefick at gmail.com> ?????:
>
> > I am having a problem with accidentally typing an object name at the
> > console that is a very large list and then having to wait for it to be
> > printed until I can resume my work.
>
> Does it help to interrupt the process?
>
>
> https://www.gnu.org/software/emacs/manual/html_mono/emacs.html#index-C_002dc-C_002dc-_0028Shell-mode_0029
> https://ess.r-project.org/Manual/ess.html#index-interrupting-R-commands
>
> I'm afraid that the behaviour of the print() method is very
> class-dependent and limiting options(max.print=...) may not help in
> your case.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Sep 11 18:41:02 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 11 Sep 2024 18:41:02 +0200
Subject: [R] non-conformable arrays
In-Reply-To: <CAJuCY5ypgAc2CBC+=OwpJDKDNFsOBbFNAi_NxFViLCp2o4C-nw@mail.gmail.com>
References: <CAJuCY5ypgAc2CBC+=OwpJDKDNFsOBbFNAi_NxFViLCp2o4C-nw@mail.gmail.com>
Message-ID: <02692EEA-454B-4515-9FDB-81BF44C12AF7@gmail.com>

Hum... Two points: You are using |> a lot and tcrossprod() is a primitive, so ignores argnames. This makes me suspicious that things like 

... ) |>  tcrossprod(x = mm)

might not do what you think it does.

E.g., 

> a <- matrix(1,10,2)
> b <- matrix(1,3,2)
> tcrossprod(y=b, x=a)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    2    2    2    2    2    2    2    2    2     2
[2,]    2    2    2    2    2    2    2    2    2     2
[3,]    2    2    2    2    2    2    2    2    2     2
> tcrossprod(x=a, y=b)
      [,1] [,2] [,3]
 [1,]    2    2    2
 [2,]    2    2    2
 [3,]    2    2    2
 [4,]    2    2    2
 [5,]    2    2    2
 [6,]    2    2    2
 [7,]    2    2    2
 [8,]    2    2    2
 [9,]    2    2    2
[10,]    2    2    2

-pd

> On 11 Sep 2024, at 17:55 , Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear all,
> 
> I'm puzzled by this error. When running tcrossprod() within the function it
> returns the error message. The code also outputs the object a and b.
> Running the tcrossprod() outside of the function works as expected.
> 
>        cat("a <-")
>        dput(a)
>        cat("b <-")
>        dput(b)
>        cat("tcrossprod(a, b)")
>        tcrossprod(a, b)
> 
> a <-structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 1), dim = c(10L, 2L), dimnames = list(c("9", "13", "21",
> "29", "30", "37", "52", "53", "56", "70"),
> c("tmp2028c70ae152b4c63bb7ab902158b408366217581",
> "tmp2028c70ae152b4c63bb7ab902158b408366217582")), assign = c(1L,
> 1L), contrasts = list(tmp2028c70ae152b4c63bb7ab902158b40836621758 =
> "contr.treatment"))
> b <-structure(c(-0.916362039446752, -0.849801808879291, -0.744535398206787,
> 0.875896407785924, 0.822587420283086, 0.894210774042389), dim = 3:2)
> tcrossprod(a, b)
> 
> For those how like a fully reproducible example:
> the offending line in the code:
> https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/R/impute_glmermod.R#L65
> a (failing) unit test for the code:
> https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/tests/testthat/test_ccc_hurdle_impute.R#L10
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From |kry|ov @end|ng |rom d|@root@org  Wed Sep 11 22:27:55 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 11 Sep 2024 23:27:55 +0300
Subject: [R] non-conformable arrays
In-Reply-To: <CAJuCY5ypgAc2CBC+=OwpJDKDNFsOBbFNAi_NxFViLCp2o4C-nw@mail.gmail.com>
References: <CAJuCY5ypgAc2CBC+=OwpJDKDNFsOBbFNAi_NxFViLCp2o4C-nw@mail.gmail.com>
Message-ID: <20240911232755.16850b0b@Tarkus>

? Wed, 11 Sep 2024 17:55:53 +0200
Thierry Onkelinx <thierry.onkelinx at inbo.be> ?????:

> For those how like a fully reproducible example:
> the offending line in the code:
> https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/R/impute_glmermod.R#L65
> a (failing) unit test for the code:
> https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/tests/testthat/test_ccc_hurdle_impute.R#L10

Setting options(error = recover) and evaluating your test expression
directly using
eval(parse('testthat/test_ccc_hurdle_impute.R')[[1]][[3]]), I see:

Browse[1]> names(random)
[1] "Year"
Browse[1]> paste("~0 + ", 'Year') |>
+ as.formula() |>
+ model.matrix(data = data[missing_obs,]) |>
+ str()
 num [1:68, 1] 7 6 9 4 3 5 10 1 6 8 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:68] "37" "56" "59" "114" ...
  ..$ : chr "Year"
 - attr(*, "assign")= int 1
Browse[1]> t(random[['Year']]) |> str()
 num [1:19, 1:10] 0.175 0.181 0.102 0.119 0.158 ...

...and they are indeed non-conformable. Why is random$Year a matrix?

-- 
Best regards,
Ivan


From |ern@nd_@rce @end|ng |rom y@hoo@e@  Wed Sep 11 16:25:03 2024
From: |ern@nd_@rce @end|ng |rom y@hoo@e@ (Fer Arce)
Date: Wed, 11 Sep 2024 16:25:03 +0200
Subject: [R] Stop or limit to console printing large list and so on
In-Reply-To: <CADKEMqiO42e5tfy6qC3VzUzabX31u5duS86Er0F5kXsJOrgoBQ@mail.gmail.com>
References: <CADKEMqiO42e5tfy6qC3VzUzabX31u5duS86Er0F5kXsJOrgoBQ@mail.gmail.com>
Message-ID: <d68c991b-de30-4b9e-8ceb-d2e90c7c74aa@yahoo.es>

Hello Stephen.
I am not sure of the exact details of your problem, but following the 
second part of your e-mail, if you accidentally print a large object in 
the console and do not want to wait (i.e. you want to stop printing), 
just press C-c C-c and it will stop it (it will stop any process 
happening in the console, the same if you send a loong loop and want to 
abort...)
cheers
F.

On 9/11/24 15:44, stephen sefick wrote:
> Stephen Sefick


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Thu Sep 12 09:42:57 2024
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Thu, 12 Sep 2024 09:42:57 +0200
Subject: [R] "And" condition spanning over multiple columns in data frame
Message-ID: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>

Dear contributors,
I need to create a set of columns, based on conditions of a dataframe as
follows.
I have managed to do the trick for one column, but I do not seem to find
any good example where the condition is extended to all the dataframe.

I have these dataframe called c10Dt:



id cp1 cp2 cp3 cp4 cp5 cp6 cp7 cp8 cp9 cp10 cp11 cp12
1  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
2  4   8  18  15  10  12  11   9  18   8   16   15   NA
3  3   8   5   5   4  NA   5  NA   6  NA   10   10   10
4  3   5   5   4   4   3   2   1   3   2    1    1    2
5  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
6  2   5   5  10  10   9  10  10  10  NA   10    9   10
-- 

Columns are id, cp1, cp2.. and so on.

What I need to do is the following, made on just one column:

c10Dt <-  mutate(c10Dt, exit1= ifelse(is.na(cp1) & id!=1, 1, 0))

So, I create a new variable, called exit1, in which the program selects
cp1, checks if it is NA, and if it is NA but also the value of the column
"id" is not 1, then it gives back a 1, otherwise 0.
So, what I want is that it selects all the cases in which the id=2,3, or 4
is not NA in the corresponding values of the matrix.
I managed to do it manually column by column, but I feel there should be
something smarter here.

The problem is that I need to replicate this over all the columns from cp2,
to cp12, but keeping fixed the id column instead.

I have tried with

c10Dt %>%
  mutate(x=across(starts_with("cp"), ~ifelse(. == NA)) & id!=1,1,0 )

but the problem with across is that it will implement the condition only on
cp_ columns. How do I tell R to use the column id with all the other
columns?


Thanks for any help provided.


Francesca


----------------------------------

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Thu Sep 12 10:42:43 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 12 Sep 2024 11:42:43 +0300
Subject: [R] 
 "And" condition spanning over multiple columns in data frame
In-Reply-To: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>
References: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>
Message-ID: <20240912114243.62d9a757@arachnoid>

? Thu, 12 Sep 2024 09:42:57 +0200
Francesca <francesca.pancotto at gmail.com> ?????:

> c10Dt <-  mutate(c10Dt, exit1= ifelse(is.na(cp1) & id!=1, 1, 0))

> So, I create a new variable, called exit1, in which the program
> selects cp1, checks if it is NA, and if it is NA but also the value
> of the column "id" is not 1, then it gives back a 1, otherwise 0.
> So, what I want is that it selects all the cases in which the id=2,3,
> or 4 is not NA in the corresponding values of the matrix.

Since all your columns except the first one are the desired "cp*"
columns, you can obtain your "exit" columns in bulk:

(
 c10Dt$id != 1 & # will be recycled column-wise, as we need
 is.na(c10Dt[-1])
) |>
# ...and then convert back into a data.frame,
as.data.frame() |>
# rename the columns...
(\(x) setNames(x, sub('cp', 'exit', names(x))))() |>
# ...and finally attach to the original data.frame
cbind(c10Dt)

-- 
Best regards,
Ivan


From er|cjberger @end|ng |rom gm@||@com  Thu Sep 12 10:44:54 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 12 Sep 2024 11:44:54 +0300
Subject: [R] 
 "And" condition spanning over multiple columns in data frame
In-Reply-To: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>
References: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>
Message-ID: <CAGgJW77dvt=RPAw3GXabin5t0RTmo7MBrUB_pRQbi4LEA=W2Gw@mail.gmail.com>

Hi,
To rephrase what you are trying to do, you want a copy of all the cp
columns, in which all the NAs become 1s and any other value becomes a
zero. There is an exception for the first row, where the NAs should
become 0s.

a <- c10Dt
b <- matrix(as.numeric(is.na(a[,-1])), nrow=nrow(a))
b[1,] <- 0  # first row gets special treatment
colnames(b) <- paste0("exit",1:ncol(b))
d <- cbind(a,b)
d


On Thu, Sep 12, 2024 at 10:43?AM Francesca <francesca.pancotto at gmail.com> wrote:
>
> Dear contributors,
> I need to create a set of columns, based on conditions of a dataframe as
> follows.
> I have managed to do the trick for one column, but I do not seem to find
> any good example where the condition is extended to all the dataframe.
>
> I have these dataframe called c10Dt:
>
>
>
> id cp1 cp2 cp3 cp4 cp5 cp6 cp7 cp8 cp9 cp10 cp11 cp12
> 1  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
> 2  4   8  18  15  10  12  11   9  18   8   16   15   NA
> 3  3   8   5   5   4  NA   5  NA   6  NA   10   10   10
> 4  3   5   5   4   4   3   2   1   3   2    1    1    2
> 5  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
> 6  2   5   5  10  10   9  10  10  10  NA   10    9   10
> --
>
> Columns are id, cp1, cp2.. and so on.
>
> What I need to do is the following, made on just one column:
>
> c10Dt <-  mutate(c10Dt, exit1= ifelse(is.na(cp1) & id!=1, 1, 0))
>
> So, I create a new variable, called exit1, in which the program selects
> cp1, checks if it is NA, and if it is NA but also the value of the column
> "id" is not 1, then it gives back a 1, otherwise 0.
> So, what I want is that it selects all the cases in which the id=2,3, or 4
> is not NA in the corresponding values of the matrix.
> I managed to do it manually column by column, but I feel there should be
> something smarter here.
>
> The problem is that I need to replicate this over all the columns from cp2,
> to cp12, but keeping fixed the id column instead.
>
> I have tried with
>
> c10Dt %>%
>   mutate(x=across(starts_with("cp"), ~ifelse(. == NA)) & id!=1,1,0 )
>
> but the problem with across is that it will implement the condition only on
> cp_ columns. How do I tell R to use the column id with all the other
> columns?
>
>
> Thanks for any help provided.
>
>
> Francesca
>
>
> ----------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Sep 12 14:48:31 2024
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 12 Sep 2024 14:48:31 +0200
Subject: [R] non-conformable arrays
In-Reply-To: <02692EEA-454B-4515-9FDB-81BF44C12AF7@gmail.com>
References: <CAJuCY5ypgAc2CBC+=OwpJDKDNFsOBbFNAi_NxFViLCp2o4C-nw@mail.gmail.com>
 <02692EEA-454B-4515-9FDB-81BF44C12AF7@gmail.com>
Message-ID: <CAJuCY5yhTFMZCHeGw0n+Fuz_-BqZHgt=oywbJ+ePgb7_Xt6iDQ@mail.gmail.com>

Dear Peter,

That was indeed this issue. Thanks for the feedback.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 11 sep 2024 om 18:41 schreef peter dalgaard <pdalgd at gmail.com>:

> Hum... Two points: You are using |> a lot and tcrossprod() is a primitive,
> so ignores argnames. This makes me suspicious that things like
>
> ... ) |>  tcrossprod(x = mm)
>
> might not do what you think it does.
>
> E.g.,
>
> > a <- matrix(1,10,2)
> > b <- matrix(1,3,2)
> > tcrossprod(y=b, x=a)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    2    2    2    2    2    2    2    2    2     2
> [2,]    2    2    2    2    2    2    2    2    2     2
> [3,]    2    2    2    2    2    2    2    2    2     2
> > tcrossprod(x=a, y=b)
>       [,1] [,2] [,3]
>  [1,]    2    2    2
>  [2,]    2    2    2
>  [3,]    2    2    2
>  [4,]    2    2    2
>  [5,]    2    2    2
>  [6,]    2    2    2
>  [7,]    2    2    2
>  [8,]    2    2    2
>  [9,]    2    2    2
> [10,]    2    2    2
>
> -pd
>
> > On 11 Sep 2024, at 17:55 , Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> >
> > Dear all,
> >
> > I'm puzzled by this error. When running tcrossprod() within the function
> it
> > returns the error message. The code also outputs the object a and b.
> > Running the tcrossprod() outside of the function works as expected.
> >
> >        cat("a <-")
> >        dput(a)
> >        cat("b <-")
> >        dput(b)
> >        cat("tcrossprod(a, b)")
> >        tcrossprod(a, b)
> >
> > a <-structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 1), dim = c(10L, 2L), dimnames = list(c("9", "13", "21",
> > "29", "30", "37", "52", "53", "56", "70"),
> > c("tmp2028c70ae152b4c63bb7ab902158b408366217581",
> > "tmp2028c70ae152b4c63bb7ab902158b408366217582")), assign = c(1L,
> > 1L), contrasts = list(tmp2028c70ae152b4c63bb7ab902158b40836621758 =
> > "contr.treatment"))
> > b <-structure(c(-0.916362039446752, -0.849801808879291,
> -0.744535398206787,
> > 0.875896407785924, 0.822587420283086, 0.894210774042389), dim = 3:2)
> > tcrossprod(a, b)
> >
> > For those how like a fully reproducible example:
> > the offending line in the code:
> >
> https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/R/impute_glmermod.R#L65
> > a (failing) unit test for the code:
> >
> https://github.com/inbo/multimput/blob/e1cd0cdff7d2868e4101c411f7508301c7be7482/tests/testthat/test_ccc_hurdle_impute.R#L10
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> > *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> > digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> > dossiers volledig digitaal behandelen. Poststukken met de vermelding
> > ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de
> geadresseerde
> > bezorgd.*
> > www.inbo.be
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 12 16:36:32 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 12 Sep 2024 15:36:32 +0100
Subject: [R] 
 "And" condition spanning over multiple columns in data frame
In-Reply-To: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>
References: <CAKFaUKjpkLO_xoxN6rBfdRtvEDazjMFGbo8wRXyv-m6CRfyKKQ@mail.gmail.com>
Message-ID: <748281fa-6b29-42d4-a59a-d1f027aa5480@sapo.pt>

?s 08:42 de 12/09/2024, Francesca escreveu:
> Dear contributors,
> I need to create a set of columns, based on conditions of a dataframe as
> follows.
> I have managed to do the trick for one column, but I do not seem to find
> any good example where the condition is extended to all the dataframe.
> 
> I have these dataframe called c10Dt:
> 
> 
> 
> id cp1 cp2 cp3 cp4 cp5 cp6 cp7 cp8 cp9 cp10 cp11 cp12
> 1  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
> 2  4   8  18  15  10  12  11   9  18   8   16   15   NA
> 3  3   8   5   5   4  NA   5  NA   6  NA   10   10   10
> 4  3   5   5   4   4   3   2   1   3   2    1    1    2
> 5  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
> 6  2   5   5  10  10   9  10  10  10  NA   10    9   10
> -- Columns are id, cp1, cp2.. and so on. What I need to do is the 
> following, made on just one column: c10Dt <- mutate(c10Dt, exit1= 
> ifelse(is.na(cp1) & id!=1, 1, 0)) So, I create a new variable, called 
> exit1, in which the program selects cp1, checks if it is NA, and if it 
> is NA but also the value of the column "id" is not 1, then it gives back 
> a 1, otherwise 0. So, what I want is that it selects all the cases in 
> which the id=2,3, or 4 is not NA in the corresponding values of the 
> matrix. I managed to do it manually column by column, but I feel there 
> should be something smarter here. The problem is that I need to 
> replicate this over all the columns from cp2, to cp12, but keeping fixed 
> the id column instead. I have tried with c10Dt %>% 
> mutate(x=across(starts_with("cp"), ~ifelse(. == NA)) & id!=1,1,0 ) but 
> the problem with across is that it will implement the condition only on 
> cp_ columns. How do I tell R to use the column id with all the other 
> columns? Thanks for any help provided. Francesca 
> ----------------------------------

Hello,

Something like this?

1. If an ifelse instruction is meant to create a binary result, coerce 
the logical condition to integer instead. You can make it more clear by 
substituting as.integer for the plus sign below;
2. the .names argument is used to create new columns and keeping the 
original ones.



df1 <- read.table(text = "id cp1 cp2 cp3 cp4 cp5 cp6 cp7 cp8 cp9 cp10 
cp11 cp12
1  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
2  4   8  18  15  10  12  11   9  18   8   16   15   NA
3  3   8   5   5   4  NA   5  NA   6  NA   10   10   10
4  3   5   5   4   4   3   2   1   3   2    1    1    2
5  1  NA  NA  NA  NA  NA  NA  NA  NA  NA   NA   NA   NA
6  2   5   5  10  10   9  10  10  10  NA   10    9   10", header = TRUE)
df1

library(dplyr)

df1 %>%
   mutate(across(starts_with("cp"),  ~ +(is.na(.) & id != 1), .names = 
"{col}_new"))



Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From du@ho|| @end|ng |rom mcm@@ter@c@  Thu Sep 12 17:08:54 2024
From: du@ho|| @end|ng |rom mcm@@ter@c@ (Jonathan Dushoff)
Date: Thu, 12 Sep 2024 11:08:54 -0400
Subject: [R] Subject: Re:  BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <63654bcd06e94303a406e1e06fad5663@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
References: <63654bcd06e94303a406e1e06fad5663@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CALF-=E+DSN1bV2TZFeuqPr5ehJzFwT1KUO5-EqE76o9FK-B7MA@mail.gmail.com>

> In this case, I do think we should look into the consequences of
> indeed distinguishing
>   <double> * <complex>
>   <complex> * <double>  and
>   <complex> / <double>
> from their respective current {1. coerce to complex, 2. use complex arith}
> arithmetic.

I'm wondering whether ? if this indeed gets opened up ? it might also
make sense to calculate <double> x / <complex> y using real arithmetic
(as x*y / |y|?)

Jonathan


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep 12 17:21:02 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 12 Sep 2024 11:21:02 -0400
Subject: [R] Subject: Re: BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CALF-=E+DSN1bV2TZFeuqPr5ehJzFwT1KUO5-EqE76o9FK-B7MA@mail.gmail.com>
References: <63654bcd06e94303a406e1e06fad5663@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
 <CALF-=E+DSN1bV2TZFeuqPr5ehJzFwT1KUO5-EqE76o9FK-B7MA@mail.gmail.com>
Message-ID: <35d23b38-9943-4f16-a847-a1f659bbbbb1@gmail.com>

On 2024-09-12 11:08 a.m., Jonathan Dushoff wrote:
>> In this case, I do think we should look into the consequences of
>> indeed distinguishing
>>    <double> * <complex>
>>    <complex> * <double>  and
>>    <complex> / <double>
>> from their respective current {1. coerce to complex, 2. use complex arith}
>> arithmetic.
> 
> I'm wondering whether ? if this indeed gets opened up ? it might also
> make sense to calculate <double> x / <complex> y using real arithmetic
> (as x*y / |y|?)

That's not the correct formula, is it?  I think the result should be x * 
Conj(y) / Mod(y)^2 . So that would involve <double> * <complex> and 
<complex> / <double>, not just real arithmetic.

Duncan Murdoch


From cwr @end|ng |rom @gency@t@t|@t|c@|@com  Fri Sep 13 03:10:53 2024
From: cwr @end|ng |rom @gency@t@t|@t|c@|@com (Christopher W. Ryan)
Date: Thu, 12 Sep 2024 21:10:53 -0400
Subject: [R] how to specify point symbols in the key on a lattice dotplot
Message-ID: <20240912211053.17549527@rcw-lm203c>

I am making a dotplot with lattice, as follows:

dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
               as.table = TRUE,
                pch = 16:17,
                cex = 1.8,
                scales = list(cex = 1.4),
               auto.key = TRUE)

impact is a factor with two levels.

They key shows 2 open circles, one of each color of my two
plotting symbols, one for each group. I would like the
symbols in the key to match the plotting characters in the graph: 16
(filled circle) for one group and 17 (filled triangle) for the second
group.  How would I do that? I have not had any success with supplying
arguments to auto.key, simpleKey, or key. Guess I'm not understanding
the syntax.

Thanks.

--Chris Ryan

-- 
Agency Statistical Consulting, LLC
Helping those in public service get the most from their data.
www.agencystatistical.com

Public GnuPG email encryption key at
https://keys.openpgp.org
9E53101D261BEC070CFF1A0DC8BC50E715A672A0


From po|c1410 @end|ng |rom gm@||@com  Fri Sep 13 09:29:20 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Fri, 13 Sep 2024 08:29:20 +0100
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <20240912211053.17549527@rcw-lm203c>
References: <20240912211053.17549527@rcw-lm203c>
Message-ID: <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>

Add:

key = list(points=16:17)

Into the dotplot section possibly without the autokey

On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan, <cwr at agencystatistical.com>
wrote:

> I am making a dotplot with lattice, as follows:
>
> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>                as.table = TRUE,
>                 pch = 16:17,
>                 cex = 1.8,
>                 scales = list(cex = 1.4),
>                auto.key = TRUE)
>
> impact is a factor with two levels.
>
> They key shows 2 open circles, one of each color of my two
> plotting symbols, one for each group. I would like the
> symbols in the key to match the plotting characters in the graph: 16
> (filled circle) for one group and 17 (filled triangle) for the second
> group.  How would I do that? I have not had any success with supplying
> arguments to auto.key, simpleKey, or key. Guess I'm not understanding
> the syntax.
>
> Thanks.
>
> --Chris Ryan
>
> --
> Agency Statistical Consulting, LLC
> Helping those in public service get the most from their data.
> www.agencystatistical.com
>
> Public GnuPG email encryption key at
> https://keys.openpgp.org
> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Fri Sep 13 12:19:48 2024
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Fri, 13 Sep 2024 15:49:48 +0530
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <20240912211053.17549527@rcw-lm203c>
References: <20240912211053.17549527@rcw-lm203c>
Message-ID: <CADfFDC7ATHTVE=Rw2f=g7-XGOYp-SF6GLesGWjgiraBFszFvxg@mail.gmail.com>

On Fri, 13 Sept 2024 at 12:49, Christopher W. Ryan
<cwr at agencystatistical.com> wrote:
>
> I am making a dotplot with lattice, as follows:
>
> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>                as.table = TRUE,
>                 pch = 16:17,
>                 cex = 1.8,
>                 scales = list(cex = 1.4),
>                auto.key = TRUE)
>
> impact is a factor with two levels.
>
> They key shows 2 open circles, one of each color of my two
> plotting symbols, one for each group. I would like the
> symbols in the key to match the plotting characters in the graph: 16
> (filled circle) for one group and 17 (filled triangle) for the second
> group.  How would I do that? I have not had any success with supplying
> arguments to auto.key, simpleKey, or key. Guess I'm not understanding
> the syntax.

Specifying key = list(...) will work, but the shortcut is to add

par.settings = simpleTheme(pch = 16:17, cex = 1.8)

That way, you don't need to specify the parameters anywhere else.

-Deepayan

> Thanks.
>
> --Chris Ryan
>
> --
> Agency Statistical Consulting, LLC
> Helping those in public service get the most from their data.
> www.agencystatistical.com
>
> Public GnuPG email encryption key at
> https://keys.openpgp.org
> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From du@ho|| @end|ng |rom mcm@@ter@c@  Fri Sep 13 14:53:55 2024
From: du@ho|| @end|ng |rom mcm@@ter@c@ (Jonathan Dushoff)
Date: Fri, 13 Sep 2024 08:53:55 -0400
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <e9c8a99f8f4142ca9c46c1a28d37f50b@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
References: <e9c8a99f8f4142ca9c46c1a28d37f50b@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CALF-=E+Hux+ZEeRzKNTpsDHoWUuTm1LUV70GjbAH=qcXDwOF4Q@mail.gmail.com>

> Message: 4
> Date: Thu, 12 Sep 2024 11:21:02 -0400
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> That's not the correct formula, is it?  I think the result should be x *
> Conj(y) / Mod(y)^2 .

Correct, sorry. And thanks.

> So that would involve <double> * <complex> and
> <complex> / <double>, not just real arithmetic.

Not an expert, but I don't see it. Conj and Mod seem to be numerically
straightforward real-like operations. We do those, and then multiply
one complex number by one real quotient.


From cwr @end|ng |rom @gency@t@t|@t|c@|@com  Fri Sep 13 17:58:50 2024
From: cwr @end|ng |rom @gency@t@t|@t|c@|@com (Christopher W. Ryan)
Date: Fri, 13 Sep 2024 11:58:50 -0400
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
References: <20240912211053.17549527@rcw-lm203c>
 <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
Message-ID: <20240913115850.03bbed1d@rcw-lm203c>


dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
               pch = 16:17,
               cex = 1.8,
               scales = list(cex = 1.4),
               key = list(points = 16:17) )

produces a graph with no discernible key, but with an asterisk at the
top, above the plotting region.

Same result from 

dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
               pch = 16:17,
               cex = 1.8,
               scales = list(cex = 1.4),
               key = list(points = 16:17),
               auto.key = TRUE )




dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
               scales = list(cex = 1.4),
               par.settings = simpleTheme(pch = 16:17, cex = 1.8),
               auto.key = TRUE) 

produces the desired result.

Why does key = list(points = 16:17)  not work?  Below is a MWE:

================================

library(lattice)
library(dplyr)
dd <- structure(list(impact = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L), levels = c("impaction", "no impaction"), class = "factor"), 
    segment = structure(c(4L, 2L, 1L, 3L, 4L, 2L, 1L, 3L), levels =
c("left", "right", "rectosigmoid", "total"), class = c("ordered",
"factor" )), transit_time = c(70, 10, 20, 32, 42, 10, 12, 18)), class =
"data.frame", row.names = c(NA, -8L))

dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
               pch = 16:17,
               cex = 1.8,
               scales = list(cex = 1.4),
               key = list(points = 16:17) )

=================================


Thanks.

--Chris Ryan
-- 
Agency Statistical Consulting, LLC
Helping those in public service get the most from their data.
www.agencystatistical.com

Public GnuPG email encryption key at
https://keys.openpgp.org
9E53101D261BEC070CFF1A0DC8BC50E715A672A0


On Fri, 13 Sep 2024 08:29:20 +0100, CALUM POLWART wrote:

>Add:
>
>key = list(points=16:17)
>
>Into the dotplot section possibly without the autokey
>
>On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan,
><cwr at agencystatistical.com> wrote:
>
>> I am making a dotplot with lattice, as follows:
>>
>> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>>                as.table = TRUE,
>>                 pch = 16:17,
>>                 cex = 1.8,
>>                 scales = list(cex = 1.4),
>>                auto.key = TRUE)
>>
>> impact is a factor with two levels.
>>
>> They key shows 2 open circles, one of each color of my two
>> plotting symbols, one for each group. I would like the
>> symbols in the key to match the plotting characters in the graph: 16
>> (filled circle) for one group and 17 (filled triangle) for the second
>> group.  How would I do that? I have not had any success with
>> supplying arguments to auto.key, simpleKey, or key. Guess I'm not
>> understanding the syntax.
>>
>> Thanks.
>>
>> --Chris Ryan
>>
>> --
>> Agency Statistical Consulting, LLC
>> Helping those in public service get the most from their data.
>> www.agencystatistical.com
>>
>> Public GnuPG email encryption key at
>> https://keys.openpgp.org
>> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 13 19:10:16 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 13 Sep 2024 13:10:16 -0400
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <CALF-=E+Hux+ZEeRzKNTpsDHoWUuTm1LUV70GjbAH=qcXDwOF4Q@mail.gmail.com>
References: <e9c8a99f8f4142ca9c46c1a28d37f50b@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
 <CALF-=E+Hux+ZEeRzKNTpsDHoWUuTm1LUV70GjbAH=qcXDwOF4Q@mail.gmail.com>
Message-ID: <af830183-5d1c-4d8a-b32a-e4e7aaa5960c@gmail.com>

On 2024-09-13 8:53 a.m., Jonathan Dushoff wrote:
>> Message: 4
>> Date: Thu, 12 Sep 2024 11:21:02 -0400
>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>> That's not the correct formula, is it?  I think the result should be x *
>> Conj(y) / Mod(y)^2 .
> 
> Correct, sorry. And thanks.
> 
>> So that would involve <double> * <complex> and
>> <complex> / <double>, not just real arithmetic.
> 
> Not an expert, but I don't see it. Conj and Mod seem to be numerically
> straightforward real-like operations. We do those, and then multiply
> one complex number by one real quotient.
> 

Are you sure?  We aren't dealing with real numbers and complex numbers 
here, we're dealing with those sets extended with infinities and other 
weird things.

I think the formula I gave assumes no infinities.

So for example if y is some kind of infinite complex number, then 1/y 
should come out to zero, and if x is finite, the final result of x/y 
should be zero.

But if we evaluate x/y as (x / Mod(y)^2) * Conj(y), won't we get a NaN 
from zero times infinity?

I imagine someone has thought about all these edge cases.  Maybe they're 
discussed in one of the standards that Richard referenced.

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 13 19:45:08 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 13 Sep 2024 10:45:08 -0700
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <20240913115850.03bbed1d@rcw-lm203c>
References: <20240912211053.17549527@rcw-lm203c>
 <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
 <20240913115850.03bbed1d@rcw-lm203c>
Message-ID: <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>

"Why does key = list(points = 16:17)  not work? "

Because, from the "key" section of ?xyplot
" The contents of the key are determined by (possibly repeated)
components named "rectangles", "lines", "points" or "text". Each of
these must be **lists** with relevant graphical parameters (see later)
controlling their appearance."

Ergo, try:

dd |> dotplot( segment ~ transit_time, groups = impact,  data = .,
                pch = 16:17,
                cex = 1.8,
                scales = list(cex = 1.4),
                key = list(points = list(pch =16:17) ))

Cheers,
Bert


On Fri, Sep 13, 2024 at 9:53?AM Christopher W. Ryan
<cwr at agencystatistical.com> wrote:
>
>
> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>                pch = 16:17,
>                cex = 1.8,
>                scales = list(cex = 1.4),
>                key = list(points = 16:17) )
>
> produces a graph with no discernible key, but with an asterisk at the
> top, above the plotting region.
>
> Same result from
>
> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>                pch = 16:17,
>                cex = 1.8,
>                scales = list(cex = 1.4),
>                key = list(points = 16:17),
>                auto.key = TRUE )
>
>
>
>
> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>                scales = list(cex = 1.4),
>                par.settings = simpleTheme(pch = 16:17, cex = 1.8),
>                auto.key = TRUE)
>
> produces the desired result.
>
> Why does key = list(points = 16:17)  not work?  Below is a MWE:
>
> ================================
>
> library(lattice)
> library(dplyr)
> dd <- structure(list(impact = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L), levels = c("impaction", "no impaction"), class = "factor"),
>     segment = structure(c(4L, 2L, 1L, 3L, 4L, 2L, 1L, 3L), levels =
> c("left", "right", "rectosigmoid", "total"), class = c("ordered",
> "factor" )), transit_time = c(70, 10, 20, 32, 42, 10, 12, 18)), class =
> "data.frame", row.names = c(NA, -8L))
>
> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>                pch = 16:17,
>                cex = 1.8,
>                scales = list(cex = 1.4),
>                key = list(points = 16:17) )
>
> =================================
>
>
> Thanks.
>
> --Chris Ryan
> --
> Agency Statistical Consulting, LLC
> Helping those in public service get the most from their data.
> www.agencystatistical.com
>
> Public GnuPG email encryption key at
> https://keys.openpgp.org
> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>
>
> On Fri, 13 Sep 2024 08:29:20 +0100, CALUM POLWART wrote:
>
> >Add:
> >
> >key = list(points=16:17)
> >
> >Into the dotplot section possibly without the autokey
> >
> >On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan,
> ><cwr at agencystatistical.com> wrote:
> >
> >> I am making a dotplot with lattice, as follows:
> >>
> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >>                as.table = TRUE,
> >>                 pch = 16:17,
> >>                 cex = 1.8,
> >>                 scales = list(cex = 1.4),
> >>                auto.key = TRUE)
> >>
> >> impact is a factor with two levels.
> >>
> >> They key shows 2 open circles, one of each color of my two
> >> plotting symbols, one for each group. I would like the
> >> symbols in the key to match the plotting characters in the graph: 16
> >> (filled circle) for one group and 17 (filled triangle) for the second
> >> group.  How would I do that? I have not had any success with
> >> supplying arguments to auto.key, simpleKey, or key. Guess I'm not
> >> understanding the syntax.
> >>
> >> Thanks.
> >>
> >> --Chris Ryan
> >>
> >> --
> >> Agency Statistical Consulting, LLC
> >> Helping those in public service get the most from their data.
> >> www.agencystatistical.com
> >>
> >> Public GnuPG email encryption key at
> >> https://keys.openpgp.org
> >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 13 19:55:03 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 13 Sep 2024 10:55:03 -0700
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>
References: <20240912211053.17549527@rcw-lm203c>
 <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
 <20240913115850.03bbed1d@rcw-lm203c>
 <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>
Message-ID: <CAGxFJbQH8aiT95cprv-d-VJSCXrhc3FM000PO8uvp+b5ATzMHw@mail.gmail.com>

Oh, and for correct syntax with R's |> operator, "data = ." , should
be "data = _" ; although the former seemed to work.

-- Bert

On Fri, Sep 13, 2024 at 10:45?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> "Why does key = list(points = 16:17)  not work? "
>
> Because, from the "key" section of ?xyplot
> " The contents of the key are determined by (possibly repeated)
> components named "rectangles", "lines", "points" or "text". Each of
> these must be **lists** with relevant graphical parameters (see later)
> controlling their appearance."
>
> Ergo, try:
>
> dd |> dotplot( segment ~ transit_time, groups = impact,  data = .,
>                 pch = 16:17,
>                 cex = 1.8,
>                 scales = list(cex = 1.4),
>                 key = list(points = list(pch =16:17) ))
>
> Cheers,
> Bert
>
>
> On Fri, Sep 13, 2024 at 9:53?AM Christopher W. Ryan
> <cwr at agencystatistical.com> wrote:
> >
> >
> > dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >                pch = 16:17,
> >                cex = 1.8,
> >                scales = list(cex = 1.4),
> >                key = list(points = 16:17) )
> >
> > produces a graph with no discernible key, but with an asterisk at the
> > top, above the plotting region.
> >
> > Same result from
> >
> > dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >                pch = 16:17,
> >                cex = 1.8,
> >                scales = list(cex = 1.4),
> >                key = list(points = 16:17),
> >                auto.key = TRUE )
> >
> >
> >
> >
> > dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >                scales = list(cex = 1.4),
> >                par.settings = simpleTheme(pch = 16:17, cex = 1.8),
> >                auto.key = TRUE)
> >
> > produces the desired result.
> >
> > Why does key = list(points = 16:17)  not work?  Below is a MWE:
> >
> > ================================
> >
> > library(lattice)
> > library(dplyr)
> > dd <- structure(list(impact = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L,
> > 2L), levels = c("impaction", "no impaction"), class = "factor"),
> >     segment = structure(c(4L, 2L, 1L, 3L, 4L, 2L, 1L, 3L), levels =
> > c("left", "right", "rectosigmoid", "total"), class = c("ordered",
> > "factor" )), transit_time = c(70, 10, 20, 32, 42, 10, 12, 18)), class =
> > "data.frame", row.names = c(NA, -8L))
> >
> > dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >                pch = 16:17,
> >                cex = 1.8,
> >                scales = list(cex = 1.4),
> >                key = list(points = 16:17) )
> >
> > =================================
> >
> >
> > Thanks.
> >
> > --Chris Ryan
> > --
> > Agency Statistical Consulting, LLC
> > Helping those in public service get the most from their data.
> > www.agencystatistical.com
> >
> > Public GnuPG email encryption key at
> > https://keys.openpgp.org
> > 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
> >
> >
> > On Fri, 13 Sep 2024 08:29:20 +0100, CALUM POLWART wrote:
> >
> > >Add:
> > >
> > >key = list(points=16:17)
> > >
> > >Into the dotplot section possibly without the autokey
> > >
> > >On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan,
> > ><cwr at agencystatistical.com> wrote:
> > >
> > >> I am making a dotplot with lattice, as follows:
> > >>
> > >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> > >>                as.table = TRUE,
> > >>                 pch = 16:17,
> > >>                 cex = 1.8,
> > >>                 scales = list(cex = 1.4),
> > >>                auto.key = TRUE)
> > >>
> > >> impact is a factor with two levels.
> > >>
> > >> They key shows 2 open circles, one of each color of my two
> > >> plotting symbols, one for each group. I would like the
> > >> symbols in the key to match the plotting characters in the graph: 16
> > >> (filled circle) for one group and 17 (filled triangle) for the second
> > >> group.  How would I do that? I have not had any success with
> > >> supplying arguments to auto.key, simpleKey, or key. Guess I'm not
> > >> understanding the syntax.
> > >>
> > >> Thanks.
> > >>
> > >> --Chris Ryan
> > >>
> > >> --
> > >> Agency Statistical Consulting, LLC
> > >> Helping those in public service get the most from their data.
> > >> www.agencystatistical.com
> > >>
> > >> Public GnuPG email encryption key at
> > >> https://keys.openpgp.org
> > >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> https://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From cwr @end|ng |rom @gency@t@t|@t|c@|@com  Fri Sep 13 20:06:05 2024
From: cwr @end|ng |rom @gency@t@t|@t|c@|@com (Christopher W. Ryan)
Date: Fri, 13 Sep 2024 14:06:05 -0400
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>
References: <20240912211053.17549527@rcw-lm203c>
 <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
 <20240913115850.03bbed1d@rcw-lm203c>
 <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>
Message-ID: <20240913140605.51a11cb6@rcw-lm203c>

For me, Bert's suggestion produces a plot with two black symbols above
the plotting region, a circle and a triangle, both filled, and no text.

This, in which I specify several features of the symbols in the key,

dd %>%  dotplot( segment ~ transit_time, groups = impact,  data = .,
                pch = 16:17,
                col = 1:2,
                cex = 1.8,
                scales = list(cex = 1.4),
                key = list(text = list(c("impaction", "no impaction")),
points = list(pch =16:17, col = 1:2) ))

gets me what I want.

When using key = (), is it necessary to specify all features of the
plotting symbols and the text? I was under the impression that auto.key
and/or simpleKey (which I'd also tried) had certain defaults, but one or
more of those defaults could be changed by providing arguments, with all
unspecified features remaining at their respective defaults.  

Thanks.

--Chris Ryan




On Fri, 13 Sep 2024 10:45:08 -0700, Bert Gunter wrote:

>"Why does key = list(points = 16:17)  not work? "
>
>Because, from the "key" section of ?xyplot
>" The contents of the key are determined by (possibly repeated)
>components named "rectangles", "lines", "points" or "text". Each of
>these must be **lists** with relevant graphical parameters (see later)
>controlling their appearance."
>
>Ergo, try:
>
>dd |> dotplot( segment ~ transit_time, groups = impact,  data = .,
>                pch = 16:17,
>                cex = 1.8,
>                scales = list(cex = 1.4),
>                key = list(points = list(pch =16:17) ))
>
>Cheers,
>Bert
>
>
>On Fri, Sep 13, 2024 at 9:53?AM Christopher W. Ryan
><cwr at agencystatistical.com> wrote:
>>
>>
>> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>>                pch = 16:17,
>>                cex = 1.8,
>>                scales = list(cex = 1.4),
>>                key = list(points = 16:17) )
>>
>> produces a graph with no discernible key, but with an asterisk at the
>> top, above the plotting region.
>>
>> Same result from
>>
>> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>>                pch = 16:17,
>>                cex = 1.8,
>>                scales = list(cex = 1.4),
>>                key = list(points = 16:17),
>>                auto.key = TRUE )
>>
>>
>>
>>
>> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>>                scales = list(cex = 1.4),
>>                par.settings = simpleTheme(pch = 16:17, cex = 1.8),
>>                auto.key = TRUE)
>>
>> produces the desired result.
>>
>> Why does key = list(points = 16:17)  not work?  Below is a MWE:
>>
>> ================================
>>
>> library(lattice)
>> library(dplyr)
>> dd <- structure(list(impact = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L,
>> 2L), levels = c("impaction", "no impaction"), class = "factor"),
>>     segment = structure(c(4L, 2L, 1L, 3L, 4L, 2L, 1L, 3L), levels =
>> c("left", "right", "rectosigmoid", "total"), class = c("ordered",
>> "factor" )), transit_time = c(70, 10, 20, 32, 42, 10, 12, 18)),
>> class = "data.frame", row.names = c(NA, -8L))
>>
>> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
>>                pch = 16:17,
>>                cex = 1.8,
>>                scales = list(cex = 1.4),
>>                key = list(points = 16:17) )
>>
>> =================================
>>
>>
>> Thanks.
>>
>> --Chris Ryan
>> --
>> Agency Statistical Consulting, LLC
>> Helping those in public service get the most from their data.
>> www.agencystatistical.com
>>
>> Public GnuPG email encryption key at
>> https://keys.openpgp.org
>> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>>
>>
>> On Fri, 13 Sep 2024 08:29:20 +0100, CALUM POLWART wrote:
>>  
>> >Add:
>> >
>> >key = list(points=16:17)
>> >
>> >Into the dotplot section possibly without the autokey
>> >
>> >On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan,
>> ><cwr at agencystatistical.com> wrote:
>> >  
>> >> I am making a dotplot with lattice, as follows:
>> >>
>> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data =
>> >> ., as.table = TRUE,
>> >>                 pch = 16:17,
>> >>                 cex = 1.8,
>> >>                 scales = list(cex = 1.4),
>> >>                auto.key = TRUE)
>> >>
>> >> impact is a factor with two levels.
>> >>
>> >> They key shows 2 open circles, one of each color of my two
>> >> plotting symbols, one for each group. I would like the
>> >> symbols in the key to match the plotting characters in the graph:
>> >> 16 (filled circle) for one group and 17 (filled triangle) for the
>> >> second group.  How would I do that? I have not had any success
>> >> with supplying arguments to auto.key, simpleKey, or key. Guess
>> >> I'm not understanding the syntax.
>> >>
>> >> Thanks.
>> >>
>> >> --Chris Ryan
>> >>
>> >> --
>> >> Agency Statistical Consulting, LLC
>> >> Helping those in public service get the most from their data.
>> >> www.agencystatistical.com
>> >>
>> >> Public GnuPG email encryption key at
>> >> https://keys.openpgp.org
>> >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> https://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>  
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.  


From du@ho|| @end|ng |rom mcm@@ter@c@  Fri Sep 13 20:23:14 2024
From: du@ho|| @end|ng |rom mcm@@ter@c@ (Jonathan Dushoff)
Date: Fri, 13 Sep 2024 14:23:14 -0400
Subject: [R] BUG: atan(1i) / 5 = NaN+Infi ?
In-Reply-To: <5fdbeea24c5b4da78a0d5257a8f5089f@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
References: <e9c8a99f8f4142ca9c46c1a28d37f50b@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
 <CALF-=E+Hux+ZEeRzKNTpsDHoWUuTm1LUV70GjbAH=qcXDwOF4Q@mail.gmail.com>
 <5fdbeea24c5b4da78a0d5257a8f5089f@YTBPR01MB2797.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CALF-=ELetMWyVq-kA2b=ieyrQ=bD9wS4nqafbuh+ek++mzDkZg@mail.gmail.com>

On Fri, Sep 13, 2024 at 1:10?PM Duncan Murdoch wrote:

> [You don't often get email from murdoch.duncan at gmail.com. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]

> Caution: External email.


> On 2024-09-13 8:53 a.m., Jonathan Dushoff wrote:
> >> Message: 4
> >> Date: Thu, 12 Sep 2024 11:21:02 -0400
> >> From: Duncan Murdoch
> >> That's not the correct formula, is it? I think the result should be x *
> >> Conj(y) / Mod(y)^2 .

> > Correct, sorry. And thanks.

> >> So that would involve * and
> >> / , not just real arithmetic.

> > Not an expert, but I don't see it. Conj and Mod seem to be numerically
> > straightforward real-like operations. We do those, and then multiply
> > one complex number by one real quotient.

> Are you sure? We aren't dealing with real numbers and complex numbers
> here, we're dealing with those sets extended with infinities and other
> weird things.

Definitely not sure, just thought I would suggest it as a possibility.

> So for example if y is some kind of infinite complex number, then 1/y
> should come out to zero, and if x is finite, the final result of x/y
> should be zero.

> But if we evaluate x/y as (x / Mod(y)^2) * Conj(y), won't we get a NaN
> from zero times infinity?

Yes, and it's not trivial to work around, so probably not worth it.

Thanks,


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Sep 14 09:57:23 2024
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 14 Sep 2024 13:27:23 +0530
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <20240913140605.51a11cb6@rcw-lm203c>
References: <20240912211053.17549527@rcw-lm203c>
 <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
 <20240913115850.03bbed1d@rcw-lm203c>
 <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>
 <20240913140605.51a11cb6@rcw-lm203c>
Message-ID: <CADfFDC6nPvd09TOPEjqX-gaibXZoio4Wj1+yjK_-ymiN7egDNw@mail.gmail.com>

On Fri, 13 Sept 2024 at 23:36, Christopher W. Ryan
<cwr at agencystatistical.com> wrote:
>
> For me, Bert's suggestion produces a plot with two black symbols above
> the plotting region, a circle and a triangle, both filled, and no text.
>
> This, in which I specify several features of the symbols in the key,
>
> dd %>%  dotplot( segment ~ transit_time, groups = impact,  data = .,
>                 pch = 16:17,
>                 col = 1:2,
>                 cex = 1.8,
>                 scales = list(cex = 1.4),
>                 key = list(text = list(c("impaction", "no impaction")),
> points = list(pch =16:17, col = 1:2) ))
>
> gets me what I want.
>
> When using key = (), is it necessary to specify all features of the
> plotting symbols and the text? I was under the impression that auto.key
> and/or simpleKey (which I'd also tried) had certain defaults, but one or
> more of those defaults could be changed by providing arguments, with all
> unspecified features remaining at their respective defaults.

Here is a very brief review:

- To use key = list(...) you need to be very verbose, specifying
everything you need. It will not "guess" anything. E.g.,

dotplot(1 ~ 1, key = list(text = list(c("one", "two")), points =
list(pch = 16:17, col = 3:4), lines = list(lwd = 2:3, lty = 2:3)))

This used to be the only option in the original Trellis implementation
in S-PLUS.

- simpleKey() produces a key with parameters taken from the current
settings, but you still need to explicitly specify the text labels,
and which components you want. E.g.,

dotplot(1 ~ 1, key = simpleKey(text = c("one", "two"), points = TRUE,
lines = TRUE))

- The result will change if you change the current settings _before_
calling simpleKey(). E.g.,

trellis.par.set(simpleTheme(pch = 16:17))
dotplot(1 ~ 1, key = simpleKey(text = c("one", "two"), points = TRUE,
lines = TRUE))

- auto.key goes one step further and tries to guess the text (and
which components should be included) from the context and the levels
of the 'groups' argument. E.g.,

dotplot(1:10 ~ 1:10, groups = gl(2, 5), auto.key = TRUE)

It also delays the call to simpleKey() to the point when the plot is
actually drawn, in case the settings have changed before then. One way
to do so is to attach a list of settings (as supplied to
trellis.par.set()) as the par.settings argument. Hence,

dotplot(1:10 ~ 1:10, groups = gl(2, 5), auto.key = TRUE, par.settings
= simpleTheme(pch = 3:4))

Hope this helps.

Best,
-Deepayan


> Thanks.
>
> --Chris Ryan
>
>
>
>
> On Fri, 13 Sep 2024 10:45:08 -0700, Bert Gunter wrote:
>
> >"Why does key = list(points = 16:17)  not work? "
> >
> >Because, from the "key" section of ?xyplot
> >" The contents of the key are determined by (possibly repeated)
> >components named "rectangles", "lines", "points" or "text". Each of
> >these must be **lists** with relevant graphical parameters (see later)
> >controlling their appearance."
> >
> >Ergo, try:
> >
> >dd |> dotplot( segment ~ transit_time, groups = impact,  data = .,
> >                pch = 16:17,
> >                cex = 1.8,
> >                scales = list(cex = 1.4),
> >                key = list(points = list(pch =16:17) ))
> >
> >Cheers,
> >Bert
> >
> >
> >On Fri, Sep 13, 2024 at 9:53?AM Christopher W. Ryan
> ><cwr at agencystatistical.com> wrote:
> >>
> >>
> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >>                pch = 16:17,
> >>                cex = 1.8,
> >>                scales = list(cex = 1.4),
> >>                key = list(points = 16:17) )
> >>
> >> produces a graph with no discernible key, but with an asterisk at the
> >> top, above the plotting region.
> >>
> >> Same result from
> >>
> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >>                pch = 16:17,
> >>                cex = 1.8,
> >>                scales = list(cex = 1.4),
> >>                key = list(points = 16:17),
> >>                auto.key = TRUE )
> >>
> >>
> >>
> >>
> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >>                scales = list(cex = 1.4),
> >>                par.settings = simpleTheme(pch = 16:17, cex = 1.8),
> >>                auto.key = TRUE)
> >>
> >> produces the desired result.
> >>
> >> Why does key = list(points = 16:17)  not work?  Below is a MWE:
> >>
> >> ================================
> >>
> >> library(lattice)
> >> library(dplyr)
> >> dd <- structure(list(impact = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L,
> >> 2L), levels = c("impaction", "no impaction"), class = "factor"),
> >>     segment = structure(c(4L, 2L, 1L, 3L, 4L, 2L, 1L, 3L), levels =
> >> c("left", "right", "rectosigmoid", "total"), class = c("ordered",
> >> "factor" )), transit_time = c(70, 10, 20, 32, 42, 10, 12, 18)),
> >> class = "data.frame", row.names = c(NA, -8L))
> >>
> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data = .,
> >>                pch = 16:17,
> >>                cex = 1.8,
> >>                scales = list(cex = 1.4),
> >>                key = list(points = 16:17) )
> >>
> >> =================================
> >>
> >>
> >> Thanks.
> >>
> >> --Chris Ryan
> >> --
> >> Agency Statistical Consulting, LLC
> >> Helping those in public service get the most from their data.
> >> www.agencystatistical.com
> >>
> >> Public GnuPG email encryption key at
> >> https://keys.openpgp.org
> >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
> >>
> >>
> >> On Fri, 13 Sep 2024 08:29:20 +0100, CALUM POLWART wrote:
> >>
> >> >Add:
> >> >
> >> >key = list(points=16:17)
> >> >
> >> >Into the dotplot section possibly without the autokey
> >> >
> >> >On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan,
> >> ><cwr at agencystatistical.com> wrote:
> >> >
> >> >> I am making a dotplot with lattice, as follows:
> >> >>
> >> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data =
> >> >> ., as.table = TRUE,
> >> >>                 pch = 16:17,
> >> >>                 cex = 1.8,
> >> >>                 scales = list(cex = 1.4),
> >> >>                auto.key = TRUE)
> >> >>
> >> >> impact is a factor with two levels.
> >> >>
> >> >> They key shows 2 open circles, one of each color of my two
> >> >> plotting symbols, one for each group. I would like the
> >> >> symbols in the key to match the plotting characters in the graph:
> >> >> 16 (filled circle) for one group and 17 (filled triangle) for the
> >> >> second group.  How would I do that? I have not had any success
> >> >> with supplying arguments to auto.key, simpleKey, or key. Guess
> >> >> I'm not understanding the syntax.
> >> >>
> >> >> Thanks.
> >> >>
> >> >> --Chris Ryan
> >> >>
> >> >> --
> >> >> Agency Statistical Consulting, LLC
> >> >> Helping those in public service get the most from their data.
> >> >> www.agencystatistical.com
> >> >>
> >> >> Public GnuPG email encryption key at
> >> >> https://keys.openpgp.org
> >> >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> https://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html and provide commented,
> >> minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cwr @end|ng |rom @gency@t@t|@t|c@|@com  Sat Sep 14 22:32:34 2024
From: cwr @end|ng |rom @gency@t@t|@t|c@|@com (Christopher W. Ryan)
Date: Sat, 14 Sep 2024 16:32:34 -0400
Subject: [R] 
 how to specify point symbols in the key on a lattice dotplot
In-Reply-To: <CADfFDC6nPvd09TOPEjqX-gaibXZoio4Wj1+yjK_-ymiN7egDNw@mail.gmail.com>
References: <20240912211053.17549527@rcw-lm203c>
 <CA+etgP=xyPBFv=pkkaFBrwT6aeZ7tj-Sgb2+Q9K+NX+LArNwvw@mail.gmail.com>
 <20240913115850.03bbed1d@rcw-lm203c>
 <CAGxFJbRSkDWuTj9ujEfdg7pK4544LeMQWsA1kqUduakKVCmcwg@mail.gmail.com>
 <20240913140605.51a11cb6@rcw-lm203c>
 <CADfFDC6nPvd09TOPEjqX-gaibXZoio4Wj1+yjK_-ymiN7egDNw@mail.gmail.com>
Message-ID: <20240914163234.0c77cd65@rcw-lm203c>

Thanks Deepayan. This is an excellent review. I found it very helpful.

--Chris Ryan


-- 
Agency Statistical Consulting, LLC
Helping those in public service get the most from their data.
www.agencystatistical.com

Public GnuPG email encryption key at
https://keys.openpgp.org
9E53101D261BEC070CFF1A0DC8BC50E715A672A0


On Sat, 14 Sep 2024 13:27:23 +0530, Deepayan Sarkar wrote:

>On Fri, 13 Sept 2024 at 23:36, Christopher W. Ryan
><cwr at agencystatistical.com> wrote:
>>
>> For me, Bert's suggestion produces a plot with two black symbols
>> above the plotting region, a circle and a triangle, both filled, and
>> no text.
>>
>> This, in which I specify several features of the symbols in the key,
>>
>> dd %>%  dotplot( segment ~ transit_time, groups = impact,  data = .,
>>                 pch = 16:17,
>>                 col = 1:2,
>>                 cex = 1.8,
>>                 scales = list(cex = 1.4),
>>                 key = list(text = list(c("impaction", "no
>> impaction")), points = list(pch =16:17, col = 1:2) ))
>>
>> gets me what I want.
>>
>> When using key = (), is it necessary to specify all features of the
>> plotting symbols and the text? I was under the impression that
>> auto.key and/or simpleKey (which I'd also tried) had certain
>> defaults, but one or more of those defaults could be changed by
>> providing arguments, with all unspecified features remaining at
>> their respective defaults.  
>
>Here is a very brief review:
>
>- To use key = list(...) you need to be very verbose, specifying
>everything you need. It will not "guess" anything. E.g.,
>
>dotplot(1 ~ 1, key = list(text = list(c("one", "two")), points =
>list(pch = 16:17, col = 3:4), lines = list(lwd = 2:3, lty = 2:3)))
>
>This used to be the only option in the original Trellis implementation
>in S-PLUS.
>
>- simpleKey() produces a key with parameters taken from the current
>settings, but you still need to explicitly specify the text labels,
>and which components you want. E.g.,
>
>dotplot(1 ~ 1, key = simpleKey(text = c("one", "two"), points = TRUE,
>lines = TRUE))
>
>- The result will change if you change the current settings _before_
>calling simpleKey(). E.g.,
>
>trellis.par.set(simpleTheme(pch = 16:17))
>dotplot(1 ~ 1, key = simpleKey(text = c("one", "two"), points = TRUE,
>lines = TRUE))
>
>- auto.key goes one step further and tries to guess the text (and
>which components should be included) from the context and the levels
>of the 'groups' argument. E.g.,
>
>dotplot(1:10 ~ 1:10, groups = gl(2, 5), auto.key = TRUE)
>
>It also delays the call to simpleKey() to the point when the plot is
>actually drawn, in case the settings have changed before then. One way
>to do so is to attach a list of settings (as supplied to
>trellis.par.set()) as the par.settings argument. Hence,
>
>dotplot(1:10 ~ 1:10, groups = gl(2, 5), auto.key = TRUE, par.settings
>= simpleTheme(pch = 3:4))
>
>Hope this helps.
>
>Best,
>-Deepayan
>
>
>> Thanks.
>>
>> --Chris Ryan
>>
>>
>>
>>
>> On Fri, 13 Sep 2024 10:45:08 -0700, Bert Gunter wrote:
>>  
>> >"Why does key = list(points = 16:17)  not work? "
>> >
>> >Because, from the "key" section of ?xyplot
>> >" The contents of the key are determined by (possibly repeated)
>> >components named "rectangles", "lines", "points" or "text". Each of
>> >these must be **lists** with relevant graphical parameters (see
>> >later) controlling their appearance."
>> >
>> >Ergo, try:
>> >
>> >dd |> dotplot( segment ~ transit_time, groups = impact,  data = .,
>> >                pch = 16:17,
>> >                cex = 1.8,
>> >                scales = list(cex = 1.4),
>> >                key = list(points = list(pch =16:17) ))
>> >
>> >Cheers,
>> >Bert
>> >
>> >
>> >On Fri, Sep 13, 2024 at 9:53?AM Christopher W. Ryan
>> ><cwr at agencystatistical.com> wrote:  
>> >>
>> >>
>> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data =
>> >> ., pch = 16:17,
>> >>                cex = 1.8,
>> >>                scales = list(cex = 1.4),
>> >>                key = list(points = 16:17) )
>> >>
>> >> produces a graph with no discernible key, but with an asterisk at
>> >> the top, above the plotting region.
>> >>
>> >> Same result from
>> >>
>> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data =
>> >> ., pch = 16:17,
>> >>                cex = 1.8,
>> >>                scales = list(cex = 1.4),
>> >>                key = list(points = 16:17),
>> >>                auto.key = TRUE )
>> >>
>> >>
>> >>
>> >>
>> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data =
>> >> ., scales = list(cex = 1.4),
>> >>                par.settings = simpleTheme(pch = 16:17, cex = 1.8),
>> >>                auto.key = TRUE)
>> >>
>> >> produces the desired result.
>> >>
>> >> Why does key = list(points = 16:17)  not work?  Below is a MWE:
>> >>
>> >> ================================
>> >>
>> >> library(lattice)
>> >> library(dplyr)
>> >> dd <- structure(list(impact = structure(c(1L, 1L, 1L, 1L, 2L, 2L,
>> >> 2L, 2L), levels = c("impaction", "no impaction"), class =
>> >> "factor"), segment = structure(c(4L, 2L, 1L, 3L, 4L, 2L, 1L, 3L),
>> >> levels = c("left", "right", "rectosigmoid", "total"), class =
>> >> c("ordered", "factor" )), transit_time = c(70, 10, 20, 32, 42,
>> >> 10, 12, 18)), class = "data.frame", row.names = c(NA, -8L))
>> >>
>> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data =
>> >> ., pch = 16:17,
>> >>                cex = 1.8,
>> >>                scales = list(cex = 1.4),
>> >>                key = list(points = 16:17) )
>> >>
>> >> =================================
>> >>
>> >>
>> >> Thanks.
>> >>
>> >> --Chris Ryan
>> >> --
>> >> Agency Statistical Consulting, LLC
>> >> Helping those in public service get the most from their data.
>> >> www.agencystatistical.com
>> >>
>> >> Public GnuPG email encryption key at
>> >> https://keys.openpgp.org
>> >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>> >>
>> >>
>> >> On Fri, 13 Sep 2024 08:29:20 +0100, CALUM POLWART wrote:
>> >>  
>> >> >Add:
>> >> >
>> >> >key = list(points=16:17)
>> >> >
>> >> >Into the dotplot section possibly without the autokey
>> >> >
>> >> >On Fri, 13 Sep 2024, 08:19 Christopher W. Ryan,
>> >> ><cwr at agencystatistical.com> wrote:
>> >> >  
>> >> >> I am making a dotplot with lattice, as follows:
>> >> >>
>> >> >> dd %>% dotplot( segment ~ transit_time, groups = impact,  data
>> >> >> = ., as.table = TRUE,
>> >> >>                 pch = 16:17,
>> >> >>                 cex = 1.8,
>> >> >>                 scales = list(cex = 1.4),
>> >> >>                auto.key = TRUE)
>> >> >>
>> >> >> impact is a factor with two levels.
>> >> >>
>> >> >> They key shows 2 open circles, one of each color of my two
>> >> >> plotting symbols, one for each group. I would like the
>> >> >> symbols in the key to match the plotting characters in the
>> >> >> graph: 16 (filled circle) for one group and 17 (filled
>> >> >> triangle) for the second group.  How would I do that? I have
>> >> >> not had any success with supplying arguments to auto.key,
>> >> >> simpleKey, or key. Guess I'm not understanding the syntax.
>> >> >>
>> >> >> Thanks.
>> >> >>
>> >> >> --Chris Ryan
>> >> >>
>> >> >> --
>> >> >> Agency Statistical Consulting, LLC
>> >> >> Helping those in public service get the most from their data.
>> >> >> www.agencystatistical.com
>> >> >>
>> >> >> Public GnuPG email encryption key at
>> >> >> https://keys.openpgp.org
>> >> >> 9E53101D261BEC070CFF1A0DC8BC50E715A672A0
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >> see https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> https://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible
>> >> >> code. 
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> https://www.R-project.org/posting-guide.html and provide
>> >> commented, minimal, self-contained, reproducible code.  
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.  


From @@mue|@gr@nje@ud @end|ng |rom |n@erm@|r  Sat Sep 14 15:55:53 2024
From: @@mue|@gr@nje@ud @end|ng |rom |n@erm@|r (Samuel Granjeaud IR/Inserm)
Date: Sat, 14 Sep 2024 15:55:53 +0200
Subject: [R] Dirichlet kernel requires r to be defined,
 which is not in the help
Message-ID: <91076ee4-020d-4ece-b00d-6b7304aa9af8@inserm.fr>

Code to reproduce

 > kernel("dirichlet")
Error in kernel("dirichlet") : argument "r" is missing, with no default

The help says

r??? the kernel order for a Fejer kernel.

Thanks to update the help.

Best,
Samuel


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Mon Sep 16 09:28:14 2024
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Mon, 16 Sep 2024 09:28:14 +0200
Subject: [R] (no subject)
Message-ID: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>

Dear Contributors,
I hope someone has found a similar issue.

I have this data set,



cp1
cp2
role
groupid
1
10
13
4
5
2
5
10
3
1
3
7
7
4
6
4
10
4
2
7
5
5
8
3
2
6
8
7
4
4
7
8
8
4
7
8
10
15
3
3
9
15
10
2
2
10
5
5
2
4
11
20
20
2
5
12
9
11
3
6
13
10
13
4
3
14
12
6
4
2
15
7
4
4
1
16
10
0
3
7
17
20
15
3
8
18
10
7
3
4
19
8
13
3
5
20
10
9
2
6



I need to to average of groups, using the values of column groupid, and
create a twin dataset in which the mean of the group is replaced instead of
individual values.
So for example, groupid 3, I calculate the mean (12+18)/2 and then I
replace in the new dataframe, but in the same positions, instead of 12 and
18, the values of the corresponding mean.
I found this solution, where db10_means is the output dataset, db10 is my
initial data.

db10_means<-db10 %>%
  group_by(groupid) %>%
  mutate(across(starts_with("cp"), list(mean = mean)))

It works perfectly, except that for NA values, where it replaces to all
group members the NA, while in some cases, the group is made of some NA and
some values.
So, when I have a group of two values and one NA, I would like that for
those with a value, the mean is replaced, for those with NA, the NA is
replaced.
Here the mean function has not the na.rm=T option associated, but it
appears that this solution cannot be implemented in this case. I am not
even sure that this would be enough to solve my problem.
Thanks for any help provided.

-- 

Francesca


----------------------------------

	[[alternative HTML version deleted]]


From ro||turner @end|ng |rom po@teo@net  Mon Sep 16 11:05:09 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Mon, 16 Sep 2024 09:05:09 +0000
Subject: [R] Your data set manipulations
In-Reply-To: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
Message-ID: <20240916210509.2e14b965@elderly-dell>

On Mon, 16 Sep 2024 09:28:14 +0200
Francesca <francesca.pancotto at gmail.com> wrote:

> Dear Contributors,
> I hope someone has found a similar issue.

I hope *not*! ??

> I have this data set,

You may have, but we haven't.  The data you provided have an
incomprehensible (to me at least) structure.  Please use dput()
to include your data in the message.

> cp1
> cp2
> role
> groupid
> 1
> 10
> 13
> 4
> 5
> 2
> 5
> 10

<SNIP>

<SNIP>

> 10
> 9
> 2
> 6
> 
> 
> 
> I need to to average of groups, using the values of column groupid,
> and create a twin dataset in which the mean of the group is replaced
> instead of individual values.
> So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> replace in the new dataframe, but in the same positions, instead of
> 12 and 18, the values of the corresponding mean.
> I found this solution, where db10_means is the output dataset, db10
> is my initial data.
> 
> db10_means<-db10 %>%
>   group_by(groupid) %>%
>   mutate(across(starts_with("cp"), list(mean = mean)))

What does "%>%" mean?

> It works perfectly, except that for NA values,

I see no sign of there being any NAs in your data set.

> where it replaces to
> all group members the NA, while in some cases, the group is made of
> some NA and some values.
> So, when I have a group of two values and one NA, I would like that
> for those with a value, the mean is replaced, for those with NA, the
> NA is replaced.
> Here the mean function has not the na.rm=T option associated, but it
> appears that this solution cannot be implemented in this case. I am
> not even sure that this would be enough to solve my problem.
> Thanks for any help provided.

A more coherent message is required before I (at least) could possibly
give any help.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 16 11:35:18 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Sep 2024 10:35:18 +0100
Subject: [R] (no subject)
In-Reply-To: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
Message-ID: <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>

?s 08:28 de 16/09/2024, Francesca escreveu:
> Dear Contributors,
> I hope someone has found a similar issue.
> 
> I have this data set,
> 
> 
> 
> cp1
> cp2
> role
> groupid
> 1
> 10
> 13
> 4
> 5
> 2
> 5
> 10
> 3
> 1
> 3
> 7
> 7
> 4
> 6
> 4
> 10
> 4
> 2
> 7
> 5
> 5
> 8
> 3
> 2
> 6
> 8
> 7
> 4
> 4
> 7
> 8
> 8
> 4
> 7
> 8
> 10
> 15
> 3
> 3
> 9
> 15
> 10
> 2
> 2
> 10
> 5
> 5
> 2
> 4
> 11
> 20
> 20
> 2
> 5
> 12
> 9
> 11
> 3
> 6
> 13
> 10
> 13
> 4
> 3
> 14
> 12
> 6
> 4
> 2
> 15
> 7
> 4
> 4
> 1
> 16
> 10
> 0
> 3
> 7
> 17
> 20
> 15
> 3
> 8
> 18
> 10
> 7
> 3
> 4
> 19
> 8
> 13
> 3
> 5
> 20
> 10
> 9
> 2
> 6
> 
> 
> 
> I need to to average of groups, using the values of column groupid, and
> create a twin dataset in which the mean of the group is replaced instead of
> individual values.
> So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> replace in the new dataframe, but in the same positions, instead of 12 and
> 18, the values of the corresponding mean.
> I found this solution, where db10_means is the output dataset, db10 is my
> initial data.
> 
> db10_means<-db10 %>%
>    group_by(groupid) %>%
>    mutate(across(starts_with("cp"), list(mean = mean)))
> 
> It works perfectly, except that for NA values, where it replaces to all
> group members the NA, while in some cases, the group is made of some NA and
> some values.
> So, when I have a group of two values and one NA, I would like that for
> those with a value, the mean is replaced, for those with NA, the NA is
> replaced.
> Here the mean function has not the na.rm=T option associated, but it
> appears that this solution cannot be implemented in this case. I am not
> even sure that this would be enough to solve my problem.
> Thanks for any help provided.
> 
Hello,

Your data is a mess, please don't post html, this is plain text only 
list. Anyway, I managed to create a data frame by copying the data to a 
file named "rhelp.txt" and then running



db10 <- scan(file = "rhelp.txt", what = character())
header <- db10[1:4]
db10 <- db10[-(1:4)] |> as.numeric()
db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
   as.data.frame() |>
   setNames(header)

str(db10)
#> 'data.frame':    25 obs. of  4 variables:
#>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
#>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
#>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
#>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...


And here is the data in dput format.



db10 <-
   structure(list(
     cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
             2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
     cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
             4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
     role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
              11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
     groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
                 20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
     class = "data.frame", row.names = c(NA, -25L))



As for the problem, I am not sure if you want summarise instead of 
mutate but here is a summarise solution.



library(dplyr)

db10 %>%
   group_by(groupid) %>%
   summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))

# same result, summarise's new argument .by avoids the need to group_by
db10 %>%
   summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by = 
groupid)



Can you post the expected output too?

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Mon Sep 16 16:23:55 2024
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Mon, 16 Sep 2024 16:23:55 +0200
Subject: [R] (no subject)
In-Reply-To: <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
Message-ID: <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>

Sorry for posting a non understandable code. In my screen the dataset
looked correctly.


I recreated my dataset, folllowing your example:

test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
 2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
                        c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5, 19,
NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
                        c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4, 2,
2, 3, 2, 3, 3, 2, 2 ,4),
                        c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
8, 5, 1, 2, 4, 7, 6, 6)))
colnames(test)    <-c("cp1","cp2","role","groupid")

What I have done so far is the following, that works:
 test %>%
  group_by(groupid) %>%
  mutate(across(starts_with("cp"), list(mean = mean)))

But the problem is with NA: everytime the mean encounters a NA, it creates
NA for all group members.
I need the software to calculate the mean ignoring NA. So when the group is
made of three people, mean of the three.
If the group is two values and an NA, calculate the mean of two.

My code works , creates a mean at each position for three subjects,
replacing instead of the value of the single, the group mean.
But when NA appears, all the group gets NA.

Perhaps there is a different way to obtain the same result.



On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 08:28 de 16/09/2024, Francesca escreveu:
> > Dear Contributors,
> > I hope someone has found a similar issue.
> >
> > I have this data set,
> >
> >
> >
> > cp1
> > cp2
> > role
> > groupid
> > 1
> > 10
> > 13
> > 4
> > 5
> > 2
> > 5
> > 10
> > 3
> > 1
> > 3
> > 7
> > 7
> > 4
> > 6
> > 4
> > 10
> > 4
> > 2
> > 7
> > 5
> > 5
> > 8
> > 3
> > 2
> > 6
> > 8
> > 7
> > 4
> > 4
> > 7
> > 8
> > 8
> > 4
> > 7
> > 8
> > 10
> > 15
> > 3
> > 3
> > 9
> > 15
> > 10
> > 2
> > 2
> > 10
> > 5
> > 5
> > 2
> > 4
> > 11
> > 20
> > 20
> > 2
> > 5
> > 12
> > 9
> > 11
> > 3
> > 6
> > 13
> > 10
> > 13
> > 4
> > 3
> > 14
> > 12
> > 6
> > 4
> > 2
> > 15
> > 7
> > 4
> > 4
> > 1
> > 16
> > 10
> > 0
> > 3
> > 7
> > 17
> > 20
> > 15
> > 3
> > 8
> > 18
> > 10
> > 7
> > 3
> > 4
> > 19
> > 8
> > 13
> > 3
> > 5
> > 20
> > 10
> > 9
> > 2
> > 6
> >
> >
> >
> > I need to to average of groups, using the values of column groupid, and
> > create a twin dataset in which the mean of the group is replaced instead
> of
> > individual values.
> > So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> > replace in the new dataframe, but in the same positions, instead of 12
> and
> > 18, the values of the corresponding mean.
> > I found this solution, where db10_means is the output dataset, db10 is my
> > initial data.
> >
> > db10_means<-db10 %>%
> >    group_by(groupid) %>%
> >    mutate(across(starts_with("cp"), list(mean = mean)))
> >
> > It works perfectly, except that for NA values, where it replaces to all
> > group members the NA, while in some cases, the group is made of some NA
> and
> > some values.
> > So, when I have a group of two values and one NA, I would like that for
> > those with a value, the mean is replaced, for those with NA, the NA is
> > replaced.
> > Here the mean function has not the na.rm=T option associated, but it
> > appears that this solution cannot be implemented in this case. I am not
> > even sure that this would be enough to solve my problem.
> > Thanks for any help provided.
> >
> Hello,
>
> Your data is a mess, please don't post html, this is plain text only
> list. Anyway, I managed to create a data frame by copying the data to a
> file named "rhelp.txt" and then running
>
>
>
> db10 <- scan(file = "rhelp.txt", what = character())
> header <- db10[1:4]
> db10 <- db10[-(1:4)] |> as.numeric()
> db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
>    as.data.frame() |>
>    setNames(header)
>
> str(db10)
> #> 'data.frame':    25 obs. of  4 variables:
> #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
>
>
> And here is the data in dput format.
>
>
>
> db10 <-
>    structure(list(
>      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
>              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
>      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
>              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
>      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
>               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
>      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
>                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
>      class = "data.frame", row.names = c(NA, -25L))
>
>
>
> As for the problem, I am not sure if you want summarise instead of
> mutate but here is a summarise solution.
>
>
>
> library(dplyr)
>
> db10 %>%
>    group_by(groupid) %>%
>    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
>
> # same result, summarise's new argument .by avoids the need to group_by
> db10 %>%
>    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> groupid)
>
>
>
> Can you post the expected output too?
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>


-- 

Francesca


----------------------------------

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 16 16:29:27 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Sep 2024 07:29:27 -0700
Subject: [R] (no subject)
In-Reply-To: <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
Message-ID: <CAGxFJbSdUO-NjqdeHdx1xsShTfiXjB+jy4FbQGaxPuRQOiJrZQ@mail.gmail.com>

See the na.rm argument of ?mean

But what happens if all values are NA?

-- Bert


On Mon, Sep 16, 2024 at 7:24?AM Francesca <francesca.pancotto at gmail.com> wrote:
>
> Sorry for posting a non understandable code. In my screen the dataset
> looked correctly.
>
>
> I recreated my dataset, folllowing your example:
>
> test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
>  2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
>                         c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5, 19,
> NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
>                         c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4, 2,
> 2, 3, 2, 3, 3, 2, 2 ,4),
>                         c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
> 8, 5, 1, 2, 4, 7, 6, 6)))
> colnames(test)    <-c("cp1","cp2","role","groupid")
>
> What I have done so far is the following, that works:
>  test %>%
>   group_by(groupid) %>%
>   mutate(across(starts_with("cp"), list(mean = mean)))
>
> But the problem is with NA: everytime the mean encounters a NA, it creates
> NA for all group members.
> I need the software to calculate the mean ignoring NA. So when the group is
> made of three people, mean of the three.
> If the group is two values and an NA, calculate the mean of two.
>
> My code works , creates a mean at each position for three subjects,
> replacing instead of the value of the single, the group mean.
> But when NA appears, all the group gets NA.
>
> Perhaps there is a different way to obtain the same result.
>
>
>
> On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > ?s 08:28 de 16/09/2024, Francesca escreveu:
> > > Dear Contributors,
> > > I hope someone has found a similar issue.
> > >
> > > I have this data set,
> > >
> > >
> > >
> > > cp1
> > > cp2
> > > role
> > > groupid
> > > 1
> > > 10
> > > 13
> > > 4
> > > 5
> > > 2
> > > 5
> > > 10
> > > 3
> > > 1
> > > 3
> > > 7
> > > 7
> > > 4
> > > 6
> > > 4
> > > 10
> > > 4
> > > 2
> > > 7
> > > 5
> > > 5
> > > 8
> > > 3
> > > 2
> > > 6
> > > 8
> > > 7
> > > 4
> > > 4
> > > 7
> > > 8
> > > 8
> > > 4
> > > 7
> > > 8
> > > 10
> > > 15
> > > 3
> > > 3
> > > 9
> > > 15
> > > 10
> > > 2
> > > 2
> > > 10
> > > 5
> > > 5
> > > 2
> > > 4
> > > 11
> > > 20
> > > 20
> > > 2
> > > 5
> > > 12
> > > 9
> > > 11
> > > 3
> > > 6
> > > 13
> > > 10
> > > 13
> > > 4
> > > 3
> > > 14
> > > 12
> > > 6
> > > 4
> > > 2
> > > 15
> > > 7
> > > 4
> > > 4
> > > 1
> > > 16
> > > 10
> > > 0
> > > 3
> > > 7
> > > 17
> > > 20
> > > 15
> > > 3
> > > 8
> > > 18
> > > 10
> > > 7
> > > 3
> > > 4
> > > 19
> > > 8
> > > 13
> > > 3
> > > 5
> > > 20
> > > 10
> > > 9
> > > 2
> > > 6
> > >
> > >
> > >
> > > I need to to average of groups, using the values of column groupid, and
> > > create a twin dataset in which the mean of the group is replaced instead
> > of
> > > individual values.
> > > So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> > > replace in the new dataframe, but in the same positions, instead of 12
> > and
> > > 18, the values of the corresponding mean.
> > > I found this solution, where db10_means is the output dataset, db10 is my
> > > initial data.
> > >
> > > db10_means<-db10 %>%
> > >    group_by(groupid) %>%
> > >    mutate(across(starts_with("cp"), list(mean = mean)))
> > >
> > > It works perfectly, except that for NA values, where it replaces to all
> > > group members the NA, while in some cases, the group is made of some NA
> > and
> > > some values.
> > > So, when I have a group of two values and one NA, I would like that for
> > > those with a value, the mean is replaced, for those with NA, the NA is
> > > replaced.
> > > Here the mean function has not the na.rm=T option associated, but it
> > > appears that this solution cannot be implemented in this case. I am not
> > > even sure that this would be enough to solve my problem.
> > > Thanks for any help provided.
> > >
> > Hello,
> >
> > Your data is a mess, please don't post html, this is plain text only
> > list. Anyway, I managed to create a data frame by copying the data to a
> > file named "rhelp.txt" and then running
> >
> >
> >
> > db10 <- scan(file = "rhelp.txt", what = character())
> > header <- db10[1:4]
> > db10 <- db10[-(1:4)] |> as.numeric()
> > db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> >    as.data.frame() |>
> >    setNames(header)
> >
> > str(db10)
> > #> 'data.frame':    25 obs. of  4 variables:
> > #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> > #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> > #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> > #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> >
> >
> > And here is the data in dput format.
> >
> >
> >
> > db10 <-
> >    structure(list(
> >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> >      class = "data.frame", row.names = c(NA, -25L))
> >
> >
> >
> > As for the problem, I am not sure if you want summarise instead of
> > mutate but here is a summarise solution.
> >
> >
> >
> > library(dplyr)
> >
> > db10 %>%
> >    group_by(groupid) %>%
> >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> >
> > # same result, summarise's new argument .by avoids the need to group_by
> > db10 %>%
> >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> > groupid)
> >
> >
> >
> > Can you post the expected output too?
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > --
> > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> > presen?a de v?rus.
> > www.avg.com
> >
>
>
> --
>
> Francesca
>
>
> ----------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkr|de@u @end|ng |rom gm@||@com  Mon Sep 16 16:40:08 2024
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 16 Sep 2024 10:40:08 -0400
Subject: [R] (no subject)
In-Reply-To: <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
Message-ID: <CAKZQJMCnWexNcVOo=j_+0MN3ZaMgHZLRq8o7j-Qxcrr_VSLxDg@mail.gmail.com>

Hi,

Thanks for the revised dataset.  The R-list does not accept HTML s a safety
measure so it strips everything down to text which is what gives us the
very garbled text so you need to always send in text format.

The best way to supply sample   data is using the dput() function.  The
dput() function gives us an exact copy of your R data set. Here is a very
simple example of how to do it.

```
dat <- data.frame(xx = 1:10, yy = letters[1:10])

dput(dat)
```
This gives us
```
structure(list(xx = 1:10, yy = c("a", "b", "c", "d", "e", "f",
                                 "g", "h", "i", "j")), class =
"data.frame", row.names = c(NA,  -10L))
```
Paste it into your email and we  can then copy it into R





On Mon, 16 Sept 2024 at 10:24, Francesca <francesca.pancotto at gmail.com>
wrote:

> Sorry for posting a non understandable code. In my screen the dataset
> looked correctly.
>
>
> I recreated my dataset, folllowing your example:
>
> test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
>  2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
>                         c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5, 19,
> NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
>                         c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4, 2,
> 2, 3, 2, 3, 3, 2, 2 ,4),
>                         c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
> 8, 5, 1, 2, 4, 7, 6, 6)))
> colnames(test)    <-c("cp1","cp2","role","groupid")
>
> What I have done so far is the following, that works:
>  test %>%
>   group_by(groupid) %>%
>   mutate(across(starts_with("cp"), list(mean = mean)))
>
> But the problem is with NA: everytime the mean encounters a NA, it creates
> NA for all group members.
> I need the software to calculate the mean ignoring NA. So when the group is
> made of three people, mean of the three.
> If the group is two values and an NA, calculate the mean of two.
>
> My code works , creates a mean at each position for three subjects,
> replacing instead of the value of the single, the group mean.
> But when NA appears, all the group gets NA.
>
> Perhaps there is a different way to obtain the same result.
>
>
>
> On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > ?s 08:28 de 16/09/2024, Francesca escreveu:
> > > Dear Contributors,
> > > I hope someone has found a similar issue.
> > >
> > > I have this data set,
> > >
> > >
> > >
> > > cp1
> > > cp2
> > > role
> > > groupid
> > > 1
> > > 10
> > > 13
> > > 4
> > > 5
> > > 2
> > > 5
> > > 10
> > > 3
> > > 1
> > > 3
> > > 7
> > > 7
> > > 4
> > > 6
> > > 4
> > > 10
> > > 4
> > > 2
> > > 7
> > > 5
> > > 5
> > > 8
> > > 3
> > > 2
> > > 6
> > > 8
> > > 7
> > > 4
> > > 4
> > > 7
> > > 8
> > > 8
> > > 4
> > > 7
> > > 8
> > > 10
> > > 15
> > > 3
> > > 3
> > > 9
> > > 15
> > > 10
> > > 2
> > > 2
> > > 10
> > > 5
> > > 5
> > > 2
> > > 4
> > > 11
> > > 20
> > > 20
> > > 2
> > > 5
> > > 12
> > > 9
> > > 11
> > > 3
> > > 6
> > > 13
> > > 10
> > > 13
> > > 4
> > > 3
> > > 14
> > > 12
> > > 6
> > > 4
> > > 2
> > > 15
> > > 7
> > > 4
> > > 4
> > > 1
> > > 16
> > > 10
> > > 0
> > > 3
> > > 7
> > > 17
> > > 20
> > > 15
> > > 3
> > > 8
> > > 18
> > > 10
> > > 7
> > > 3
> > > 4
> > > 19
> > > 8
> > > 13
> > > 3
> > > 5
> > > 20
> > > 10
> > > 9
> > > 2
> > > 6
> > >
> > >
> > >
> > > I need to to average of groups, using the values of column groupid, and
> > > create a twin dataset in which the mean of the group is replaced
> instead
> > of
> > > individual values.
> > > So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> > > replace in the new dataframe, but in the same positions, instead of 12
> > and
> > > 18, the values of the corresponding mean.
> > > I found this solution, where db10_means is the output dataset, db10 is
> my
> > > initial data.
> > >
> > > db10_means<-db10 %>%
> > >    group_by(groupid) %>%
> > >    mutate(across(starts_with("cp"), list(mean = mean)))
> > >
> > > It works perfectly, except that for NA values, where it replaces to all
> > > group members the NA, while in some cases, the group is made of some NA
> > and
> > > some values.
> > > So, when I have a group of two values and one NA, I would like that for
> > > those with a value, the mean is replaced, for those with NA, the NA is
> > > replaced.
> > > Here the mean function has not the na.rm=T option associated, but it
> > > appears that this solution cannot be implemented in this case. I am not
> > > even sure that this would be enough to solve my problem.
> > > Thanks for any help provided.
> > >
> > Hello,
> >
> > Your data is a mess, please don't post html, this is plain text only
> > list. Anyway, I managed to create a data frame by copying the data to a
> > file named "rhelp.txt" and then running
> >
> >
> >
> > db10 <- scan(file = "rhelp.txt", what = character())
> > header <- db10[1:4]
> > db10 <- db10[-(1:4)] |> as.numeric()
> > db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> >    as.data.frame() |>
> >    setNames(header)
> >
> > str(db10)
> > #> 'data.frame':    25 obs. of  4 variables:
> > #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> > #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> > #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> > #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> >
> >
> > And here is the data in dput format.
> >
> >
> >
> > db10 <-
> >    structure(list(
> >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> >      class = "data.frame", row.names = c(NA, -25L))
> >
> >
> >
> > As for the problem, I am not sure if you want summarise instead of
> > mutate but here is a summarise solution.
> >
> >
> >
> > library(dplyr)
> >
> > db10 %>%
> >    group_by(groupid) %>%
> >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> >
> > # same result, summarise's new argument .by avoids the need to group_by
> > db10 %>%
> >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> > groupid)
> >
> >
> >
> > Can you post the expected output too?
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > --
> > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> > presen?a de v?rus.
> > www.avg.com
> >
>
>
> --
>
> Francesca
>
>
> ----------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Mon Sep 16 17:05:06 2024
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Mon, 16 Sep 2024 17:05:06 +0200
Subject: [R] (no subject)
In-Reply-To: <CAGxFJbSdUO-NjqdeHdx1xsShTfiXjB+jy4FbQGaxPuRQOiJrZQ@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
 <CAGxFJbSdUO-NjqdeHdx1xsShTfiXjB+jy4FbQGaxPuRQOiJrZQ@mail.gmail.com>
Message-ID: <CAKFaUKjygXNwqDphZ1hx+YLfcbK26=QJwF-s61mP=tTdxCFrtQ@mail.gmail.com>

All' Na Is Na.


Il lun 16 set 2024, 16:29 Bert Gunter <bgunter.4567 at gmail.com> ha scritto:

> See the na.rm argument of ?mean
>
> But what happens if all values are NA?
>
> -- Bert
>
>
> On Mon, Sep 16, 2024 at 7:24?AM Francesca <francesca.pancotto at gmail.com>
> wrote:
> >
> > Sorry for posting a non understandable code. In my screen the dataset
> > looked correctly.
> >
> >
> > I recreated my dataset, folllowing your example:
> >
> > test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
> >  2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
> >                         c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5,
> 19,
> > NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
> >                         c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4,
> 2,
> > 2, 3, 2, 3, 3, 2, 2 ,4),
> >                         c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
> > 8, 5, 1, 2, 4, 7, 6, 6)))
> > colnames(test)    <-c("cp1","cp2","role","groupid")
> >
> > What I have done so far is the following, that works:
> >  test %>%
> >   group_by(groupid) %>%
> >   mutate(across(starts_with("cp"), list(mean = mean)))
> >
> > But the problem is with NA: everytime the mean encounters a NA, it
> creates
> > NA for all group members.
> > I need the software to calculate the mean ignoring NA. So when the group
> is
> > made of three people, mean of the three.
> > If the group is two values and an NA, calculate the mean of two.
> >
> > My code works , creates a mean at each position for three subjects,
> > replacing instead of the value of the single, the group mean.
> > But when NA appears, all the group gets NA.
> >
> > Perhaps there is a different way to obtain the same result.
> >
> >
> >
> > On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> > > ?s 08:28 de 16/09/2024, Francesca escreveu:
> > > > Dear Contributors,
> > > > I hope someone has found a similar issue.
> > > >
> > > > I have this data set,
> > > >
> > > >
> > > >
> > > > cp1
> > > > cp2
> > > > role
> > > > groupid
> > > > 1
> > > > 10
> > > > 13
> > > > 4
> > > > 5
> > > > 2
> > > > 5
> > > > 10
> > > > 3
> > > > 1
> > > > 3
> > > > 7
> > > > 7
> > > > 4
> > > > 6
> > > > 4
> > > > 10
> > > > 4
> > > > 2
> > > > 7
> > > > 5
> > > > 5
> > > > 8
> > > > 3
> > > > 2
> > > > 6
> > > > 8
> > > > 7
> > > > 4
> > > > 4
> > > > 7
> > > > 8
> > > > 8
> > > > 4
> > > > 7
> > > > 8
> > > > 10
> > > > 15
> > > > 3
> > > > 3
> > > > 9
> > > > 15
> > > > 10
> > > > 2
> > > > 2
> > > > 10
> > > > 5
> > > > 5
> > > > 2
> > > > 4
> > > > 11
> > > > 20
> > > > 20
> > > > 2
> > > > 5
> > > > 12
> > > > 9
> > > > 11
> > > > 3
> > > > 6
> > > > 13
> > > > 10
> > > > 13
> > > > 4
> > > > 3
> > > > 14
> > > > 12
> > > > 6
> > > > 4
> > > > 2
> > > > 15
> > > > 7
> > > > 4
> > > > 4
> > > > 1
> > > > 16
> > > > 10
> > > > 0
> > > > 3
> > > > 7
> > > > 17
> > > > 20
> > > > 15
> > > > 3
> > > > 8
> > > > 18
> > > > 10
> > > > 7
> > > > 3
> > > > 4
> > > > 19
> > > > 8
> > > > 13
> > > > 3
> > > > 5
> > > > 20
> > > > 10
> > > > 9
> > > > 2
> > > > 6
> > > >
> > > >
> > > >
> > > > I need to to average of groups, using the values of column groupid,
> and
> > > > create a twin dataset in which the mean of the group is replaced
> instead
> > > of
> > > > individual values.
> > > > So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> > > > replace in the new dataframe, but in the same positions, instead of
> 12
> > > and
> > > > 18, the values of the corresponding mean.
> > > > I found this solution, where db10_means is the output dataset, db10
> is my
> > > > initial data.
> > > >
> > > > db10_means<-db10 %>%
> > > >    group_by(groupid) %>%
> > > >    mutate(across(starts_with("cp"), list(mean = mean)))
> > > >
> > > > It works perfectly, except that for NA values, where it replaces to
> all
> > > > group members the NA, while in some cases, the group is made of some
> NA
> > > and
> > > > some values.
> > > > So, when I have a group of two values and one NA, I would like that
> for
> > > > those with a value, the mean is replaced, for those with NA, the NA
> is
> > > > replaced.
> > > > Here the mean function has not the na.rm=T option associated, but it
> > > > appears that this solution cannot be implemented in this case. I am
> not
> > > > even sure that this would be enough to solve my problem.
> > > > Thanks for any help provided.
> > > >
> > > Hello,
> > >
> > > Your data is a mess, please don't post html, this is plain text only
> > > list. Anyway, I managed to create a data frame by copying the data to a
> > > file named "rhelp.txt" and then running
> > >
> > >
> > >
> > > db10 <- scan(file = "rhelp.txt", what = character())
> > > header <- db10[1:4]
> > > db10 <- db10[-(1:4)] |> as.numeric()
> > > db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> > >    as.data.frame() |>
> > >    setNames(header)
> > >
> > > str(db10)
> > > #> 'data.frame':    25 obs. of  4 variables:
> > > #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> > > #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> > > #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> > > #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> > >
> > >
> > > And here is the data in dput format.
> > >
> > >
> > >
> > > db10 <-
> > >    structure(list(
> > >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> > >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> > >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> > >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> > >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> > >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> > >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> > >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> > >      class = "data.frame", row.names = c(NA, -25L))
> > >
> > >
> > >
> > > As for the problem, I am not sure if you want summarise instead of
> > > mutate but here is a summarise solution.
> > >
> > >
> > >
> > > library(dplyr)
> > >
> > > db10 %>%
> > >    group_by(groupid) %>%
> > >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> > >
> > > # same result, summarise's new argument .by avoids the need to group_by
> > > db10 %>%
> > >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> > > groupid)
> > >
> > >
> > >
> > > Can you post the expected output too?
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > --
> > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> > > presen?a de v?rus.
> > > www.avg.com
> > >
> >
> >
> > --
> >
> > Francesca
> >
> >
> > ----------------------------------
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 16 20:02:27 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Sep 2024 11:02:27 -0700
Subject: [R] (no subject)
In-Reply-To: <CAKFaUKjygXNwqDphZ1hx+YLfcbK26=QJwF-s61mP=tTdxCFrtQ@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
 <CAGxFJbSdUO-NjqdeHdx1xsShTfiXjB+jy4FbQGaxPuRQOiJrZQ@mail.gmail.com>
 <CAKFaUKjygXNwqDphZ1hx+YLfcbK26=QJwF-s61mP=tTdxCFrtQ@mail.gmail.com>
Message-ID: <CAGxFJbS=AZEj5GgdC_o2Zt1Vn7b0=xLbrW25=bPjJA5g00VopQ@mail.gmail.com>

It's NA *not* Na. Details matter.

Ah, but note:
> mean(c(NA,NA), na.rm = TRUE)
[1] NaN

So if that might happen, you'll have to write your own mean function,
say mymean(), to do what you want. I leave that (simple) pleasure to
you.

-- Bert

On Mon, Sep 16, 2024 at 8:05?AM Francesca <francesca.pancotto at gmail.com> wrote:
>
> All' Na Is Na.
>
>
> Il lun 16 set 2024, 16:29 Bert Gunter <bgunter.4567 at gmail.com> ha scritto:
>>
>> See the na.rm argument of ?mean
>>
>> But what happens if all values are NA?
>>
>> -- Bert
>>
>>
>> On Mon, Sep 16, 2024 at 7:24?AM Francesca <francesca.pancotto at gmail.com> wrote:
>> >
>> > Sorry for posting a non understandable code. In my screen the dataset
>> > looked correctly.
>> >
>> >
>> > I recreated my dataset, folllowing your example:
>> >
>> > test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
>> >  2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
>> >                         c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5, 19,
>> > NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
>> >                         c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4, 2,
>> > 2, 3, 2, 3, 3, 2, 2 ,4),
>> >                         c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
>> > 8, 5, 1, 2, 4, 7, 6, 6)))
>> > colnames(test)    <-c("cp1","cp2","role","groupid")
>> >
>> > What I have done so far is the following, that works:
>> >  test %>%
>> >   group_by(groupid) %>%
>> >   mutate(across(starts_with("cp"), list(mean = mean)))
>> >
>> > But the problem is with NA: everytime the mean encounters a NA, it creates
>> > NA for all group members.
>> > I need the software to calculate the mean ignoring NA. So when the group is
>> > made of three people, mean of the three.
>> > If the group is two values and an NA, calculate the mean of two.
>> >
>> > My code works , creates a mean at each position for three subjects,
>> > replacing instead of the value of the single, the group mean.
>> > But when NA appears, all the group gets NA.
>> >
>> > Perhaps there is a different way to obtain the same result.
>> >
>> >
>> >
>> > On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> >
>> > > ?s 08:28 de 16/09/2024, Francesca escreveu:
>> > > > Dear Contributors,
>> > > > I hope someone has found a similar issue.
>> > > >
>> > > > I have this data set,
>> > > >
>> > > >
>> > > >
>> > > > cp1
>> > > > cp2
>> > > > role
>> > > > groupid
>> > > > 1
>> > > > 10
>> > > > 13
>> > > > 4
>> > > > 5
>> > > > 2
>> > > > 5
>> > > > 10
>> > > > 3
>> > > > 1
>> > > > 3
>> > > > 7
>> > > > 7
>> > > > 4
>> > > > 6
>> > > > 4
>> > > > 10
>> > > > 4
>> > > > 2
>> > > > 7
>> > > > 5
>> > > > 5
>> > > > 8
>> > > > 3
>> > > > 2
>> > > > 6
>> > > > 8
>> > > > 7
>> > > > 4
>> > > > 4
>> > > > 7
>> > > > 8
>> > > > 8
>> > > > 4
>> > > > 7
>> > > > 8
>> > > > 10
>> > > > 15
>> > > > 3
>> > > > 3
>> > > > 9
>> > > > 15
>> > > > 10
>> > > > 2
>> > > > 2
>> > > > 10
>> > > > 5
>> > > > 5
>> > > > 2
>> > > > 4
>> > > > 11
>> > > > 20
>> > > > 20
>> > > > 2
>> > > > 5
>> > > > 12
>> > > > 9
>> > > > 11
>> > > > 3
>> > > > 6
>> > > > 13
>> > > > 10
>> > > > 13
>> > > > 4
>> > > > 3
>> > > > 14
>> > > > 12
>> > > > 6
>> > > > 4
>> > > > 2
>> > > > 15
>> > > > 7
>> > > > 4
>> > > > 4
>> > > > 1
>> > > > 16
>> > > > 10
>> > > > 0
>> > > > 3
>> > > > 7
>> > > > 17
>> > > > 20
>> > > > 15
>> > > > 3
>> > > > 8
>> > > > 18
>> > > > 10
>> > > > 7
>> > > > 3
>> > > > 4
>> > > > 19
>> > > > 8
>> > > > 13
>> > > > 3
>> > > > 5
>> > > > 20
>> > > > 10
>> > > > 9
>> > > > 2
>> > > > 6
>> > > >
>> > > >
>> > > >
>> > > > I need to to average of groups, using the values of column groupid, and
>> > > > create a twin dataset in which the mean of the group is replaced instead
>> > > of
>> > > > individual values.
>> > > > So for example, groupid 3, I calculate the mean (12+18)/2 and then I
>> > > > replace in the new dataframe, but in the same positions, instead of 12
>> > > and
>> > > > 18, the values of the corresponding mean.
>> > > > I found this solution, where db10_means is the output dataset, db10 is my
>> > > > initial data.
>> > > >
>> > > > db10_means<-db10 %>%
>> > > >    group_by(groupid) %>%
>> > > >    mutate(across(starts_with("cp"), list(mean = mean)))
>> > > >
>> > > > It works perfectly, except that for NA values, where it replaces to all
>> > > > group members the NA, while in some cases, the group is made of some NA
>> > > and
>> > > > some values.
>> > > > So, when I have a group of two values and one NA, I would like that for
>> > > > those with a value, the mean is replaced, for those with NA, the NA is
>> > > > replaced.
>> > > > Here the mean function has not the na.rm=T option associated, but it
>> > > > appears that this solution cannot be implemented in this case. I am not
>> > > > even sure that this would be enough to solve my problem.
>> > > > Thanks for any help provided.
>> > > >
>> > > Hello,
>> > >
>> > > Your data is a mess, please don't post html, this is plain text only
>> > > list. Anyway, I managed to create a data frame by copying the data to a
>> > > file named "rhelp.txt" and then running
>> > >
>> > >
>> > >
>> > > db10 <- scan(file = "rhelp.txt", what = character())
>> > > header <- db10[1:4]
>> > > db10 <- db10[-(1:4)] |> as.numeric()
>> > > db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
>> > >    as.data.frame() |>
>> > >    setNames(header)
>> > >
>> > > str(db10)
>> > > #> 'data.frame':    25 obs. of  4 variables:
>> > > #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
>> > > #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
>> > > #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
>> > > #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
>> > >
>> > >
>> > > And here is the data in dput format.
>> > >
>> > >
>> > >
>> > > db10 <-
>> > >    structure(list(
>> > >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
>> > >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
>> > >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
>> > >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
>> > >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
>> > >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
>> > >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
>> > >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
>> > >      class = "data.frame", row.names = c(NA, -25L))
>> > >
>> > >
>> > >
>> > > As for the problem, I am not sure if you want summarise instead of
>> > > mutate but here is a summarise solution.
>> > >
>> > >
>> > >
>> > > library(dplyr)
>> > >
>> > > db10 %>%
>> > >    group_by(groupid) %>%
>> > >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
>> > >
>> > > # same result, summarise's new argument .by avoids the need to group_by
>> > > db10 %>%
>> > >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
>> > > groupid)
>> > >
>> > >
>> > >
>> > > Can you post the expected output too?
>> > >
>> > > Hope this helps,
>> > >
>> > > Rui Barradas
>> > >
>> > >
>> > > --
>> > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> > > presen?a de v?rus.
>> > > www.avg.com
>> > >
>> >
>> >
>> > --
>> >
>> > Francesca
>> >
>> >
>> > ----------------------------------
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 16 20:08:03 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Sep 2024 11:08:03 -0700
Subject: [R] (no subject)
In-Reply-To: <CAGxFJbS=AZEj5GgdC_o2Zt1Vn7b0=xLbrW25=bPjJA5g00VopQ@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
 <CAGxFJbSdUO-NjqdeHdx1xsShTfiXjB+jy4FbQGaxPuRQOiJrZQ@mail.gmail.com>
 <CAKFaUKjygXNwqDphZ1hx+YLfcbK26=QJwF-s61mP=tTdxCFrtQ@mail.gmail.com>
 <CAGxFJbS=AZEj5GgdC_o2Zt1Vn7b0=xLbrW25=bPjJA5g00VopQ@mail.gmail.com>
Message-ID: <CAGxFJbR-iQs4LOjBAiNG1bgQhC=b4E467WU0PsDiYCr7PdKhXA@mail.gmail.com>

Incidentally, if you intend to use these means for further analytical
purposes, you may produce irreproducible conclusions: after all, a
mean of 10 things is more *meaningful* than a mean of 2. However, that
is a discussion too far for this list. Consult your local statistical
resources if you need to go there and need help.

Cheers,
Bert

On Mon, Sep 16, 2024 at 11:02?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> It's NA *not* Na. Details matter.
>
> Ah, but note:
> > mean(c(NA,NA), na.rm = TRUE)
> [1] NaN
>
> So if that might happen, you'll have to write your own mean function,
> say mymean(), to do what you want. I leave that (simple) pleasure to
> you.
>
> -- Bert
>
> On Mon, Sep 16, 2024 at 8:05?AM Francesca <francesca.pancotto at gmail.com> wrote:
> >
> > All' Na Is Na.
> >
> >
> > Il lun 16 set 2024, 16:29 Bert Gunter <bgunter.4567 at gmail.com> ha scritto:
> >>
> >> See the na.rm argument of ?mean
> >>
> >> But what happens if all values are NA?
> >>
> >> -- Bert
> >>
> >>
> >> On Mon, Sep 16, 2024 at 7:24?AM Francesca <francesca.pancotto at gmail.com> wrote:
> >> >
> >> > Sorry for posting a non understandable code. In my screen the dataset
> >> > looked correctly.
> >> >
> >> >
> >> > I recreated my dataset, folllowing your example:
> >> >
> >> > test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
> >> >  2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
> >> >                         c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5, 19,
> >> > NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
> >> >                         c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4, 2,
> >> > 2, 3, 2, 3, 3, 2, 2 ,4),
> >> >                         c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
> >> > 8, 5, 1, 2, 4, 7, 6, 6)))
> >> > colnames(test)    <-c("cp1","cp2","role","groupid")
> >> >
> >> > What I have done so far is the following, that works:
> >> >  test %>%
> >> >   group_by(groupid) %>%
> >> >   mutate(across(starts_with("cp"), list(mean = mean)))
> >> >
> >> > But the problem is with NA: everytime the mean encounters a NA, it creates
> >> > NA for all group members.
> >> > I need the software to calculate the mean ignoring NA. So when the group is
> >> > made of three people, mean of the three.
> >> > If the group is two values and an NA, calculate the mean of two.
> >> >
> >> > My code works , creates a mean at each position for three subjects,
> >> > replacing instead of the value of the single, the group mean.
> >> > But when NA appears, all the group gets NA.
> >> >
> >> > Perhaps there is a different way to obtain the same result.
> >> >
> >> >
> >> >
> >> > On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >> >
> >> > > ?s 08:28 de 16/09/2024, Francesca escreveu:
> >> > > > Dear Contributors,
> >> > > > I hope someone has found a similar issue.
> >> > > >
> >> > > > I have this data set,
> >> > > >
> >> > > >
> >> > > >
> >> > > > cp1
> >> > > > cp2
> >> > > > role
> >> > > > groupid
> >> > > > 1
> >> > > > 10
> >> > > > 13
> >> > > > 4
> >> > > > 5
> >> > > > 2
> >> > > > 5
> >> > > > 10
> >> > > > 3
> >> > > > 1
> >> > > > 3
> >> > > > 7
> >> > > > 7
> >> > > > 4
> >> > > > 6
> >> > > > 4
> >> > > > 10
> >> > > > 4
> >> > > > 2
> >> > > > 7
> >> > > > 5
> >> > > > 5
> >> > > > 8
> >> > > > 3
> >> > > > 2
> >> > > > 6
> >> > > > 8
> >> > > > 7
> >> > > > 4
> >> > > > 4
> >> > > > 7
> >> > > > 8
> >> > > > 8
> >> > > > 4
> >> > > > 7
> >> > > > 8
> >> > > > 10
> >> > > > 15
> >> > > > 3
> >> > > > 3
> >> > > > 9
> >> > > > 15
> >> > > > 10
> >> > > > 2
> >> > > > 2
> >> > > > 10
> >> > > > 5
> >> > > > 5
> >> > > > 2
> >> > > > 4
> >> > > > 11
> >> > > > 20
> >> > > > 20
> >> > > > 2
> >> > > > 5
> >> > > > 12
> >> > > > 9
> >> > > > 11
> >> > > > 3
> >> > > > 6
> >> > > > 13
> >> > > > 10
> >> > > > 13
> >> > > > 4
> >> > > > 3
> >> > > > 14
> >> > > > 12
> >> > > > 6
> >> > > > 4
> >> > > > 2
> >> > > > 15
> >> > > > 7
> >> > > > 4
> >> > > > 4
> >> > > > 1
> >> > > > 16
> >> > > > 10
> >> > > > 0
> >> > > > 3
> >> > > > 7
> >> > > > 17
> >> > > > 20
> >> > > > 15
> >> > > > 3
> >> > > > 8
> >> > > > 18
> >> > > > 10
> >> > > > 7
> >> > > > 3
> >> > > > 4
> >> > > > 19
> >> > > > 8
> >> > > > 13
> >> > > > 3
> >> > > > 5
> >> > > > 20
> >> > > > 10
> >> > > > 9
> >> > > > 2
> >> > > > 6
> >> > > >
> >> > > >
> >> > > >
> >> > > > I need to to average of groups, using the values of column groupid, and
> >> > > > create a twin dataset in which the mean of the group is replaced instead
> >> > > of
> >> > > > individual values.
> >> > > > So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> >> > > > replace in the new dataframe, but in the same positions, instead of 12
> >> > > and
> >> > > > 18, the values of the corresponding mean.
> >> > > > I found this solution, where db10_means is the output dataset, db10 is my
> >> > > > initial data.
> >> > > >
> >> > > > db10_means<-db10 %>%
> >> > > >    group_by(groupid) %>%
> >> > > >    mutate(across(starts_with("cp"), list(mean = mean)))
> >> > > >
> >> > > > It works perfectly, except that for NA values, where it replaces to all
> >> > > > group members the NA, while in some cases, the group is made of some NA
> >> > > and
> >> > > > some values.
> >> > > > So, when I have a group of two values and one NA, I would like that for
> >> > > > those with a value, the mean is replaced, for those with NA, the NA is
> >> > > > replaced.
> >> > > > Here the mean function has not the na.rm=T option associated, but it
> >> > > > appears that this solution cannot be implemented in this case. I am not
> >> > > > even sure that this would be enough to solve my problem.
> >> > > > Thanks for any help provided.
> >> > > >
> >> > > Hello,
> >> > >
> >> > > Your data is a mess, please don't post html, this is plain text only
> >> > > list. Anyway, I managed to create a data frame by copying the data to a
> >> > > file named "rhelp.txt" and then running
> >> > >
> >> > >
> >> > >
> >> > > db10 <- scan(file = "rhelp.txt", what = character())
> >> > > header <- db10[1:4]
> >> > > db10 <- db10[-(1:4)] |> as.numeric()
> >> > > db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> >> > >    as.data.frame() |>
> >> > >    setNames(header)
> >> > >
> >> > > str(db10)
> >> > > #> 'data.frame':    25 obs. of  4 variables:
> >> > > #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> >> > > #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> >> > > #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> >> > > #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> >> > >
> >> > >
> >> > > And here is the data in dput format.
> >> > >
> >> > >
> >> > >
> >> > > db10 <-
> >> > >    structure(list(
> >> > >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> >> > >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> >> > >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> >> > >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> >> > >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> >> > >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> >> > >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> >> > >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> >> > >      class = "data.frame", row.names = c(NA, -25L))
> >> > >
> >> > >
> >> > >
> >> > > As for the problem, I am not sure if you want summarise instead of
> >> > > mutate but here is a summarise solution.
> >> > >
> >> > >
> >> > >
> >> > > library(dplyr)
> >> > >
> >> > > db10 %>%
> >> > >    group_by(groupid) %>%
> >> > >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> >> > >
> >> > > # same result, summarise's new argument .by avoids the need to group_by
> >> > > db10 %>%
> >> > >    summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> >> > > groupid)
> >> > >
> >> > >
> >> > >
> >> > > Can you post the expected output too?
> >> > >
> >> > > Hope this helps,
> >> > >
> >> > > Rui Barradas
> >> > >
> >> > >
> >> > > --
> >> > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> > > presen?a de v?rus.
> >> > > www.avg.com
> >> > >
> >> >
> >> >
> >> > --
> >> >
> >> > Francesca
> >> >
> >> >
> >> > ----------------------------------
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 16 20:47:28 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Sep 2024 19:47:28 +0100
Subject: [R] (no subject)
In-Reply-To: <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
Message-ID: <4c3f9360-51bc-42c2-8b00-c7970bfcbfa9@sapo.pt>

?s 15:23 de 16/09/2024, Francesca escreveu:
> Sorry for posting a non understandable code. In my screen the dataset
> looked correctly.
> 
> 
> I recreated my dataset, folllowing your example:
> 
> test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
>   2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
>                          c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5, 19,
> NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
>                          c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4, 2,
> 2, 3, 2, 3, 3, 2, 2 ,4),
>                          c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7, 5,
> 8, 5, 1, 2, 4, 7, 6, 6)))
> colnames(test)    <-c("cp1","cp2","role","groupid")
> 
> What I have done so far is the following, that works:
>   test %>%
>    group_by(groupid) %>%
>    mutate(across(starts_with("cp"), list(mean = mean)))
> 
> But the problem is with NA: everytime the mean encounters a NA, it creates
> NA for all group members.
> I need the software to calculate the mean ignoring NA. So when the group is
> made of three people, mean of the three.
> If the group is two values and an NA, calculate the mean of two.
> 
> My code works , creates a mean at each position for three subjects,
> replacing instead of the value of the single, the group mean.
> But when NA appears, all the group gets NA.
> 
> Perhaps there is a different way to obtain the same result.
> 
> 
> 
> On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> ?s 08:28 de 16/09/2024, Francesca escreveu:
>>> Dear Contributors,
>>> I hope someone has found a similar issue.
>>>
>>> I have this data set,
>>>
>>>
>>>
>>> cp1
>>> cp2
>>> role
>>> groupid
>>> 1
>>> 10
>>> 13
>>> 4
>>> 5
>>> 2
>>> 5
>>> 10
>>> 3
>>> 1
>>> 3
>>> 7
>>> 7
>>> 4
>>> 6
>>> 4
>>> 10
>>> 4
>>> 2
>>> 7
>>> 5
>>> 5
>>> 8
>>> 3
>>> 2
>>> 6
>>> 8
>>> 7
>>> 4
>>> 4
>>> 7
>>> 8
>>> 8
>>> 4
>>> 7
>>> 8
>>> 10
>>> 15
>>> 3
>>> 3
>>> 9
>>> 15
>>> 10
>>> 2
>>> 2
>>> 10
>>> 5
>>> 5
>>> 2
>>> 4
>>> 11
>>> 20
>>> 20
>>> 2
>>> 5
>>> 12
>>> 9
>>> 11
>>> 3
>>> 6
>>> 13
>>> 10
>>> 13
>>> 4
>>> 3
>>> 14
>>> 12
>>> 6
>>> 4
>>> 2
>>> 15
>>> 7
>>> 4
>>> 4
>>> 1
>>> 16
>>> 10
>>> 0
>>> 3
>>> 7
>>> 17
>>> 20
>>> 15
>>> 3
>>> 8
>>> 18
>>> 10
>>> 7
>>> 3
>>> 4
>>> 19
>>> 8
>>> 13
>>> 3
>>> 5
>>> 20
>>> 10
>>> 9
>>> 2
>>> 6
>>>
>>>
>>>
>>> I need to to average of groups, using the values of column groupid, and
>>> create a twin dataset in which the mean of the group is replaced instead
>> of
>>> individual values.
>>> So for example, groupid 3, I calculate the mean (12+18)/2 and then I
>>> replace in the new dataframe, but in the same positions, instead of 12
>> and
>>> 18, the values of the corresponding mean.
>>> I found this solution, where db10_means is the output dataset, db10 is my
>>> initial data.
>>>
>>> db10_means<-db10 %>%
>>>     group_by(groupid) %>%
>>>     mutate(across(starts_with("cp"), list(mean = mean)))
>>>
>>> It works perfectly, except that for NA values, where it replaces to all
>>> group members the NA, while in some cases, the group is made of some NA
>> and
>>> some values.
>>> So, when I have a group of two values and one NA, I would like that for
>>> those with a value, the mean is replaced, for those with NA, the NA is
>>> replaced.
>>> Here the mean function has not the na.rm=T option associated, but it
>>> appears that this solution cannot be implemented in this case. I am not
>>> even sure that this would be enough to solve my problem.
>>> Thanks for any help provided.
>>>
>> Hello,
>>
>> Your data is a mess, please don't post html, this is plain text only
>> list. Anyway, I managed to create a data frame by copying the data to a
>> file named "rhelp.txt" and then running
>>
>>
>>
>> db10 <- scan(file = "rhelp.txt", what = character())
>> header <- db10[1:4]
>> db10 <- db10[-(1:4)] |> as.numeric()
>> db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
>>     as.data.frame() |>
>>     setNames(header)
>>
>> str(db10)
>> #> 'data.frame':    25 obs. of  4 variables:
>> #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
>> #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
>> #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
>> #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
>>
>>
>> And here is the data in dput format.
>>
>>
>>
>> db10 <-
>>     structure(list(
>>       cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
>>               2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
>>       cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
>>               4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
>>       role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
>>                11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
>>       groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
>>                   20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
>>       class = "data.frame", row.names = c(NA, -25L))
>>
>>
>>
>> As for the problem, I am not sure if you want summarise instead of
>> mutate but here is a summarise solution.
>>
>>
>>
>> library(dplyr)
>>
>> db10 %>%
>>     group_by(groupid) %>%
>>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
>>
>> # same result, summarise's new argument .by avoids the need to group_by
>> db10 %>%
>>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
>> groupid)
>>
>>
>>
>> Can you post the expected output too?
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
> 
> 
Hello,

Something like this?


test <-
   structure(list(
     cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
             2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
     cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
             4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
     role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
              11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
     groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
                 20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
     class = "data.frame", row.names = c(NA, -25L))

library(dplyr)

test %>%
   group_by(groupid) %>%
   mutate(across(starts_with("cp"), list(mean = ~ mean(.x, na.rm = TRUE))))
#> # A tibble: 25 ? 6
#> # Groups:   groupid [11]
#>      cp1   cp2  role groupid cp1_mean cp2_mean
#>    <dbl> <dbl> <dbl>   <dbl>    <dbl>    <dbl>
#>  1     1    10    13       4     7        8
#>  2     5     2     5      10     5        2
#>  3     3     1     3       7     6.17     5.17
#>  4     7     4     6       4     7        8
#>  5    10     4     2       7     6.17     5.17
#>  6     5     5     8       3    10.7     13.3
#>  7     2     6     8       7     6.17     5.17
#>  8     4     4     7       8     5        4
#>  9     8     4     7       8     5        4
#> 10    10    15     3       3    10.7     13.3
#> # ? 15 more rows


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From Thom@@@Ro@e @end|ng |rom d@@d-@|umn|@de  Mon Sep 16 11:16:10 2024
From: Thom@@@Ro@e @end|ng |rom d@@d-@|umn|@de (Thomas.Rose)
Date: Mon, 16 Sep 2024 09:16:10 +0000
Subject: [R] Your data set manipulations
In-Reply-To: <20240916210509.2e14b965@elderly-dell>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <20240916210509.2e14b965@elderly-dell>
Message-ID: <AS4P192MB160005CCE08CFB31C764DA27C3602@AS4P192MB1600.EURP192.PROD.OUTLOOK.COM>

Dear Francesca,

As Rolf already pointed out, please provide more comprehensible information.

As shot into the blue, excluding the NAs when calculating the mean might help:


> mean(c(3, 5, NA))

[1] NA

> mean(c(3, 5, NA), na.rm = TRUE)
[1] 4

Cheers,
Thomas
________________________________
Von: R-help <r-help-bounces at r-project.org> im Auftrag von Rolf Turner <rolfturner at posteo.net>
Gesendet: Montag, 16. September 2024 11:05
An: Francesca <francesca.pancotto at gmail.com>
Cc: R help <r-help at r-project.org>
Betreff: Re: [R] Your data set manipulations

On Mon, 16 Sep 2024 09:28:14 +0200
Francesca <francesca.pancotto at gmail.com> wrote:

> Dear Contributors,
> I hope someone has found a similar issue.

I hope *not*! ??

> I have this data set,

You may have, but we haven't.  The data you provided have an
incomprehensible (to me at least) structure.  Please use dput()
to include your data in the message.

> cp1
> cp2
> role
> groupid
> 1
> 10
> 13
> 4
> 5
> 2
> 5
> 10

<SNIP>

<SNIP>

> 10
> 9
> 2
> 6
>
>
>
> I need to to average of groups, using the values of column groupid,
> and create a twin dataset in which the mean of the group is replaced
> instead of individual values.
> So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> replace in the new dataframe, but in the same positions, instead of
> 12 and 18, the values of the corresponding mean.
> I found this solution, where db10_means is the output dataset, db10
> is my initial data.
>
> db10_means<-db10 %>%
>   group_by(groupid) %>%
>   mutate(across(starts_with("cp"), list(mean = mean)))

What does "%>%" mean?

> It works perfectly, except that for NA values,

I see no sign of there being any NAs in your data set.

> where it replaces to
> all group members the NA, while in some cases, the group is made of
> some NA and some values.
> So, when I have a group of two values and one NA, I would like that
> for those with a value, the mean is replaced, for those with NA, the
> NA is replaced.
> Here the mean function has not the na.rm=T option associated, but it
> appears that this solution cannot be implemented in this case. I am
> not even sure that this would be enough to solve my problem.
> Thanks for any help provided.

A more coherent message is required before I (at least) could possibly
give any help.

cheers,

Rolf

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From po|c1410 @end|ng |rom gm@||@com  Tue Sep 17 01:39:44 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Tue, 17 Sep 2024 00:39:44 +0100
Subject: [R] (no subject)
In-Reply-To: <4c3f9360-51bc-42c2-8b00-c7970bfcbfa9@sapo.pt>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
 <4c3f9360-51bc-42c2-8b00-c7970bfcbfa9@sapo.pt>
Message-ID: <CA+etgP=gyTBkAHJ_1ch1=u3ZB__6dTDCmEZ1+L7_1g2kTzY_gQ@mail.gmail.com>

Rui's solution is good.

Bert's suggestion is also good!

For Berts suggestion you'd make the list bit

list(mean = mean_narm)

But prior to that define a function:

mean_narm<- function(x) {

m <- mean(x, na.rm = T)

if (!is.Nan (m)) {
m <- NA
}

return (m)
}

Would do what you suggested in your reply to Bert.

On Mon, 16 Sep 2024, 19:48 Rui Barradas, <ruipbarradas at sapo.pt> wrote:

> ?s 15:23 de 16/09/2024, Francesca escreveu:
> > Sorry for posting a non understandable code. In my screen the dataset
> > looked correctly.
> >
> >
> > I recreated my dataset, folllowing your example:
> >
> > test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
> >   2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
> >                          c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5,
> 19,
> > NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
> >                          c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4,
> 2,
> > 2, 3, 2, 3, 3, 2, 2 ,4),
> >                          c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7,
> 5,
> > 8, 5, 1, 2, 4, 7, 6, 6)))
> > colnames(test)    <-c("cp1","cp2","role","groupid")
> >
> > What I have done so far is the following, that works:
> >   test %>%
> >    group_by(groupid) %>%
> >    mutate(across(starts_with("cp"), list(mean = mean)))
> >
> > But the problem is with NA: everytime the mean encounters a NA, it
> creates
> > NA for all group members.
> > I need the software to calculate the mean ignoring NA. So when the group
> is
> > made of three people, mean of the three.
> > If the group is two values and an NA, calculate the mean of two.
> >
> > My code works , creates a mean at each position for three subjects,
> > replacing instead of the value of the single, the group mean.
> > But when NA appears, all the group gets NA.
> >
> > Perhaps there is a different way to obtain the same result.
> >
> >
> >
> > On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> ?s 08:28 de 16/09/2024, Francesca escreveu:
> >>> Dear Contributors,
> >>> I hope someone has found a similar issue.
> >>>
> >>> I have this data set,
> >>>
> >>>
> >>>
> >>> cp1
> >>> cp2
> >>> role
> >>> groupid
> >>> 1
> >>> 10
> >>> 13
> >>> 4
> >>> 5
> >>> 2
> >>> 5
> >>> 10
> >>> 3
> >>> 1
> >>> 3
> >>> 7
> >>> 7
> >>> 4
> >>> 6
> >>> 4
> >>> 10
> >>> 4
> >>> 2
> >>> 7
> >>> 5
> >>> 5
> >>> 8
> >>> 3
> >>> 2
> >>> 6
> >>> 8
> >>> 7
> >>> 4
> >>> 4
> >>> 7
> >>> 8
> >>> 8
> >>> 4
> >>> 7
> >>> 8
> >>> 10
> >>> 15
> >>> 3
> >>> 3
> >>> 9
> >>> 15
> >>> 10
> >>> 2
> >>> 2
> >>> 10
> >>> 5
> >>> 5
> >>> 2
> >>> 4
> >>> 11
> >>> 20
> >>> 20
> >>> 2
> >>> 5
> >>> 12
> >>> 9
> >>> 11
> >>> 3
> >>> 6
> >>> 13
> >>> 10
> >>> 13
> >>> 4
> >>> 3
> >>> 14
> >>> 12
> >>> 6
> >>> 4
> >>> 2
> >>> 15
> >>> 7
> >>> 4
> >>> 4
> >>> 1
> >>> 16
> >>> 10
> >>> 0
> >>> 3
> >>> 7
> >>> 17
> >>> 20
> >>> 15
> >>> 3
> >>> 8
> >>> 18
> >>> 10
> >>> 7
> >>> 3
> >>> 4
> >>> 19
> >>> 8
> >>> 13
> >>> 3
> >>> 5
> >>> 20
> >>> 10
> >>> 9
> >>> 2
> >>> 6
> >>>
> >>>
> >>>
> >>> I need to to average of groups, using the values of column groupid, and
> >>> create a twin dataset in which the mean of the group is replaced
> instead
> >> of
> >>> individual values.
> >>> So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> >>> replace in the new dataframe, but in the same positions, instead of 12
> >> and
> >>> 18, the values of the corresponding mean.
> >>> I found this solution, where db10_means is the output dataset, db10 is
> my
> >>> initial data.
> >>>
> >>> db10_means<-db10 %>%
> >>>     group_by(groupid) %>%
> >>>     mutate(across(starts_with("cp"), list(mean = mean)))
> >>>
> >>> It works perfectly, except that for NA values, where it replaces to all
> >>> group members the NA, while in some cases, the group is made of some NA
> >> and
> >>> some values.
> >>> So, when I have a group of two values and one NA, I would like that for
> >>> those with a value, the mean is replaced, for those with NA, the NA is
> >>> replaced.
> >>> Here the mean function has not the na.rm=T option associated, but it
> >>> appears that this solution cannot be implemented in this case. I am not
> >>> even sure that this would be enough to solve my problem.
> >>> Thanks for any help provided.
> >>>
> >> Hello,
> >>
> >> Your data is a mess, please don't post html, this is plain text only
> >> list. Anyway, I managed to create a data frame by copying the data to a
> >> file named "rhelp.txt" and then running
> >>
> >>
> >>
> >> db10 <- scan(file = "rhelp.txt", what = character())
> >> header <- db10[1:4]
> >> db10 <- db10[-(1:4)] |> as.numeric()
> >> db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> >>     as.data.frame() |>
> >>     setNames(header)
> >>
> >> str(db10)
> >> #> 'data.frame':    25 obs. of  4 variables:
> >> #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> >> #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> >> #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> >> #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> >>
> >>
> >> And here is the data in dput format.
> >>
> >>
> >>
> >> db10 <-
> >>     structure(list(
> >>       cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> >>               2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> >>       cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> >>               4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> >>       role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> >>                11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> >>       groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> >>                   20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> >>       class = "data.frame", row.names = c(NA, -25L))
> >>
> >>
> >>
> >> As for the problem, I am not sure if you want summarise instead of
> >> mutate but here is a summarise solution.
> >>
> >>
> >>
> >> library(dplyr)
> >>
> >> db10 %>%
> >>     group_by(groupid) %>%
> >>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> >>
> >> # same result, summarise's new argument .by avoids the need to group_by
> >> db10 %>%
> >>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> >> groupid)
> >>
> >>
> >>
> >> Can you post the expected output too?
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> --
> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> presen?a de v?rus.
> >> www.avg.com
> >>
> >
> >
> Hello,
>
> Something like this?
>
>
> test <-
>    structure(list(
>      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
>              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
>      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
>              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
>      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
>               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
>      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
>                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
>      class = "data.frame", row.names = c(NA, -25L))
>
> library(dplyr)
>
> test %>%
>    group_by(groupid) %>%
>    mutate(across(starts_with("cp"), list(mean = ~ mean(.x, na.rm = TRUE))))
> #> # A tibble: 25 ? 6
> #> # Groups:   groupid [11]
> #>      cp1   cp2  role groupid cp1_mean cp2_mean
> #>    <dbl> <dbl> <dbl>   <dbl>    <dbl>    <dbl>
> #>  1     1    10    13       4     7        8
> #>  2     5     2     5      10     5        2
> #>  3     3     1     3       7     6.17     5.17
> #>  4     7     4     6       4     7        8
> #>  5    10     4     2       7     6.17     5.17
> #>  6     5     5     8       3    10.7     13.3
> #>  7     2     6     8       7     6.17     5.17
> #>  8     4     4     7       8     5        4
> #>  9     8     4     7       8     5        4
> #> 10    10    15     3       3    10.7     13.3
> #> # ? 15 more rows
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 17 02:26:58 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Sep 2024 17:26:58 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+etgP=gyTBkAHJ_1ch1=u3ZB__6dTDCmEZ1+L7_1g2kTzY_gQ@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
 <4c3f9360-51bc-42c2-8b00-c7970bfcbfa9@sapo.pt>
 <CA+etgP=gyTBkAHJ_1ch1=u3ZB__6dTDCmEZ1+L7_1g2kTzY_gQ@mail.gmail.com>
Message-ID: <CAGxFJbSdih=A9N6U5jL18f--O33Zi8nqm-T1UjUoKu4Zq=jijQ@mail.gmail.com>

Hmmm... typos and thinkos ?

Maybe:
mean_narm<- function(x) {
   m <- mean(x, na.rm = T)
   if (is.nan (m)) NA else m
}

-- Bert

On Mon, Sep 16, 2024 at 4:40?PM CALUM POLWART <polc1410 at gmail.com> wrote:
>
> Rui's solution is good.
>
> Bert's suggestion is also good!
>
> For Berts suggestion you'd make the list bit
>
> list(mean = mean_narm)
>
> But prior to that define a function:
>
> mean_narm<- function(x) {
>
> m <- mean(x, na.rm = T)
>
> if (!is.Nan (m)) {
> m <- NA
> }
>
> return (m)
> }
>
> Would do what you suggested in your reply to Bert.
>
> On Mon, 16 Sep 2024, 19:48 Rui Barradas, <ruipbarradas at sapo.pt> wrote:
>
> > ?s 15:23 de 16/09/2024, Francesca escreveu:
> > > Sorry for posting a non understandable code. In my screen the dataset
> > > looked correctly.
> > >
> > >
> > > I recreated my dataset, folllowing your example:
> > >
> > > test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5, NA, 17,
> > >   2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
> > >                          c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 , 5,
> > 19,
> > > NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
> > >                          c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4, 4, 4,
> > 2,
> > > 2, 3, 2, 3, 3, 2, 2 ,4),
> > >                          c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4, 7,
> > 5,
> > > 8, 5, 1, 2, 4, 7, 6, 6)))
> > > colnames(test)    <-c("cp1","cp2","role","groupid")
> > >
> > > What I have done so far is the following, that works:
> > >   test %>%
> > >    group_by(groupid) %>%
> > >    mutate(across(starts_with("cp"), list(mean = mean)))
> > >
> > > But the problem is with NA: everytime the mean encounters a NA, it
> > creates
> > > NA for all group members.
> > > I need the software to calculate the mean ignoring NA. So when the group
> > is
> > > made of three people, mean of the three.
> > > If the group is two values and an NA, calculate the mean of two.
> > >
> > > My code works , creates a mean at each position for three subjects,
> > > replacing instead of the value of the single, the group mean.
> > > But when NA appears, all the group gets NA.
> > >
> > > Perhaps there is a different way to obtain the same result.
> > >
> > >
> > >
> > > On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt>
> > wrote:
> > >
> > >> ?s 08:28 de 16/09/2024, Francesca escreveu:
> > >>> Dear Contributors,
> > >>> I hope someone has found a similar issue.
> > >>>
> > >>> I have this data set,
> > >>>
> > >>>
> > >>>
> > >>> cp1
> > >>> cp2
> > >>> role
> > >>> groupid
> > >>> 1
> > >>> 10
> > >>> 13
> > >>> 4
> > >>> 5
> > >>> 2
> > >>> 5
> > >>> 10
> > >>> 3
> > >>> 1
> > >>> 3
> > >>> 7
> > >>> 7
> > >>> 4
> > >>> 6
> > >>> 4
> > >>> 10
> > >>> 4
> > >>> 2
> > >>> 7
> > >>> 5
> > >>> 5
> > >>> 8
> > >>> 3
> > >>> 2
> > >>> 6
> > >>> 8
> > >>> 7
> > >>> 4
> > >>> 4
> > >>> 7
> > >>> 8
> > >>> 8
> > >>> 4
> > >>> 7
> > >>> 8
> > >>> 10
> > >>> 15
> > >>> 3
> > >>> 3
> > >>> 9
> > >>> 15
> > >>> 10
> > >>> 2
> > >>> 2
> > >>> 10
> > >>> 5
> > >>> 5
> > >>> 2
> > >>> 4
> > >>> 11
> > >>> 20
> > >>> 20
> > >>> 2
> > >>> 5
> > >>> 12
> > >>> 9
> > >>> 11
> > >>> 3
> > >>> 6
> > >>> 13
> > >>> 10
> > >>> 13
> > >>> 4
> > >>> 3
> > >>> 14
> > >>> 12
> > >>> 6
> > >>> 4
> > >>> 2
> > >>> 15
> > >>> 7
> > >>> 4
> > >>> 4
> > >>> 1
> > >>> 16
> > >>> 10
> > >>> 0
> > >>> 3
> > >>> 7
> > >>> 17
> > >>> 20
> > >>> 15
> > >>> 3
> > >>> 8
> > >>> 18
> > >>> 10
> > >>> 7
> > >>> 3
> > >>> 4
> > >>> 19
> > >>> 8
> > >>> 13
> > >>> 3
> > >>> 5
> > >>> 20
> > >>> 10
> > >>> 9
> > >>> 2
> > >>> 6
> > >>>
> > >>>
> > >>>
> > >>> I need to to average of groups, using the values of column groupid, and
> > >>> create a twin dataset in which the mean of the group is replaced
> > instead
> > >> of
> > >>> individual values.
> > >>> So for example, groupid 3, I calculate the mean (12+18)/2 and then I
> > >>> replace in the new dataframe, but in the same positions, instead of 12
> > >> and
> > >>> 18, the values of the corresponding mean.
> > >>> I found this solution, where db10_means is the output dataset, db10 is
> > my
> > >>> initial data.
> > >>>
> > >>> db10_means<-db10 %>%
> > >>>     group_by(groupid) %>%
> > >>>     mutate(across(starts_with("cp"), list(mean = mean)))
> > >>>
> > >>> It works perfectly, except that for NA values, where it replaces to all
> > >>> group members the NA, while in some cases, the group is made of some NA
> > >> and
> > >>> some values.
> > >>> So, when I have a group of two values and one NA, I would like that for
> > >>> those with a value, the mean is replaced, for those with NA, the NA is
> > >>> replaced.
> > >>> Here the mean function has not the na.rm=T option associated, but it
> > >>> appears that this solution cannot be implemented in this case. I am not
> > >>> even sure that this would be enough to solve my problem.
> > >>> Thanks for any help provided.
> > >>>
> > >> Hello,
> > >>
> > >> Your data is a mess, please don't post html, this is plain text only
> > >> list. Anyway, I managed to create a data frame by copying the data to a
> > >> file named "rhelp.txt" and then running
> > >>
> > >>
> > >>
> > >> db10 <- scan(file = "rhelp.txt", what = character())
> > >> header <- db10[1:4]
> > >> db10 <- db10[-(1:4)] |> as.numeric()
> > >> db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> > >>     as.data.frame() |>
> > >>     setNames(header)
> > >>
> > >> str(db10)
> > >> #> 'data.frame':    25 obs. of  4 variables:
> > >> #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> > >> #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> > >> #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> > >> #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> > >>
> > >>
> > >> And here is the data in dput format.
> > >>
> > >>
> > >>
> > >> db10 <-
> > >>     structure(list(
> > >>       cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> > >>               2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> > >>       cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> > >>               4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> > >>       role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> > >>                11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> > >>       groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> > >>                   20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> > >>       class = "data.frame", row.names = c(NA, -25L))
> > >>
> > >>
> > >>
> > >> As for the problem, I am not sure if you want summarise instead of
> > >> mutate but here is a summarise solution.
> > >>
> > >>
> > >>
> > >> library(dplyr)
> > >>
> > >> db10 %>%
> > >>     group_by(groupid) %>%
> > >>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> > >>
> > >> # same result, summarise's new argument .by avoids the need to group_by
> > >> db10 %>%
> > >>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)), .by =
> > >> groupid)
> > >>
> > >>
> > >>
> > >> Can you post the expected output too?
> > >>
> > >> Hope this helps,
> > >>
> > >> Rui Barradas
> > >>
> > >>
> > >> --
> > >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> > >> presen?a de v?rus.
> > >> www.avg.com
> > >>
> > >
> > >
> > Hello,
> >
> > Something like this?
> >
> >
> > test <-
> >    structure(list(
> >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> >      class = "data.frame", row.names = c(NA, -25L))
> >
> > library(dplyr)
> >
> > test %>%
> >    group_by(groupid) %>%
> >    mutate(across(starts_with("cp"), list(mean = ~ mean(.x, na.rm = TRUE))))
> > #> # A tibble: 25 ? 6
> > #> # Groups:   groupid [11]
> > #>      cp1   cp2  role groupid cp1_mean cp2_mean
> > #>    <dbl> <dbl> <dbl>   <dbl>    <dbl>    <dbl>
> > #>  1     1    10    13       4     7        8
> > #>  2     5     2     5      10     5        2
> > #>  3     3     1     3       7     6.17     5.17
> > #>  4     7     4     6       4     7        8
> > #>  5    10     4     2       7     6.17     5.17
> > #>  6     5     5     8       3    10.7     13.3
> > #>  7     2     6     8       7     6.17     5.17
> > #>  8     4     4     7       8     5        4
> > #>  9     8     4     7       8     5        4
> > #> 10    10    15     3       3    10.7     13.3
> > #> # ? 15 more rows
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > --
> > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> > presen?a de v?rus.
> > www.avg.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Tue Sep 17 08:27:26 2024
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Tue, 17 Sep 2024 08:27:26 +0200
Subject: [R] (no subject)
In-Reply-To: <CAGxFJbSdih=A9N6U5jL18f--O33Zi8nqm-T1UjUoKu4Zq=jijQ@mail.gmail.com>
References: <CAKFaUKi4Mu4BrOJcfn9JRpEpt6NMk5388g3_WJnOiEreb0K5Jw@mail.gmail.com>
 <7115eab0-e3a9-4747-abcc-713ba8168a74@sapo.pt>
 <CAKFaUKjVL0yM97AW5DYfN71vEEhjrGp82kjsct_FOx=zU9phRg@mail.gmail.com>
 <4c3f9360-51bc-42c2-8b00-c7970bfcbfa9@sapo.pt>
 <CA+etgP=gyTBkAHJ_1ch1=u3ZB__6dTDCmEZ1+L7_1g2kTzY_gQ@mail.gmail.com>
 <CAGxFJbSdih=A9N6U5jL18f--O33Zi8nqm-T1UjUoKu4Zq=jijQ@mail.gmail.com>
Message-ID: <CAKFaUKgbe_ngxCVypQyPYPEMB45pqwmB7L58Z9keVcLkXXQaoA@mail.gmail.com>

Sorry, my typing was corrected by the computer.
When I have a NA, there should be a missing value.
So, if a group has 2 values and a NA, the two that have values, should be
replaced by the mean of the two,
the third should be NA.
The NA is the participant that dropped out.

On Tue, 17 Sept 2024 at 02:27, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Hmmm... typos and thinkos ?
>
> Maybe:
> mean_narm<- function(x) {
>    m <- mean(x, na.rm = T)
>    if (is.nan (m)) NA else m
> }
>
> -- Bert
>
> On Mon, Sep 16, 2024 at 4:40?PM CALUM POLWART <polc1410 at gmail.com> wrote:
> >
> > Rui's solution is good.
> >
> > Bert's suggestion is also good!
> >
> > For Berts suggestion you'd make the list bit
> >
> > list(mean = mean_narm)
> >
> > But prior to that define a function:
> >
> > mean_narm<- function(x) {
> >
> > m <- mean(x, na.rm = T)
> >
> > if (!is.Nan (m)) {
> > m <- NA
> > }
> >
> > return (m)
> > }
> >
> > Would do what you suggested in your reply to Bert.
> >
> > On Mon, 16 Sep 2024, 19:48 Rui Barradas, <ruipbarradas at sapo.pt> wrote:
> >
> > > ?s 15:23 de 16/09/2024, Francesca escreveu:
> > > > Sorry for posting a non understandable code. In my screen the dataset
> > > > looked correctly.
> > > >
> > > >
> > > > I recreated my dataset, folllowing your example:
> > > >
> > > > test<-data.frame(matrix(c( 8,  8,  5 , 5 ,NA ,NA , 1, 15, 20,  5,
> NA, 17,
> > > >   2 , 5 , 5,  2 , 5 ,NA,  5 ,10, 10,  5 ,12, NA),
> > > >                          c( 18,  5,  5,  5, NA,  9,  2,  2, 10,  7 ,
> 5,
> > > 19,
> > > > NA, 10, NA, 4, NA,  8, NA,  5, 10,  3, 17, NA),
> > > >                          c( 4, 3, 3, 2, 2, 4, 3, 3, 2, 4, 4 ,3, 4,
> 4, 4,
> > > 2,
> > > > 2, 3, 2, 3, 3, 2, 2 ,4),
> > > >                          c(3, 8, 1, 2, 4, 2, 7, 6, 3, 5, 1, 3, 8, 4,
> 7,
> > > 5,
> > > > 8, 5, 1, 2, 4, 7, 6, 6)))
> > > > colnames(test)    <-c("cp1","cp2","role","groupid")
> > > >
> > > > What I have done so far is the following, that works:
> > > >   test %>%
> > > >    group_by(groupid) %>%
> > > >    mutate(across(starts_with("cp"), list(mean = mean)))
> > > >
> > > > But the problem is with NA: everytime the mean encounters a NA, it
> > > creates
> > > > NA for all group members.
> > > > I need the software to calculate the mean ignoring NA. So when the
> group
> > > is
> > > > made of three people, mean of the three.
> > > > If the group is two values and an NA, calculate the mean of two.
> > > >
> > > > My code works , creates a mean at each position for three subjects,
> > > > replacing instead of the value of the single, the group mean.
> > > > But when NA appears, all the group gets NA.
> > > >
> > > > Perhaps there is a different way to obtain the same result.
> > > >
> > > >
> > > >
> > > > On Mon, 16 Sept 2024 at 11:35, Rui Barradas <ruipbarradas at sapo.pt>
> > > wrote:
> > > >
> > > >> ?s 08:28 de 16/09/2024, Francesca escreveu:
> > > >>> Dear Contributors,
> > > >>> I hope someone has found a similar issue.
> > > >>>
> > > >>> I have this data set,
> > > >>>
> > > >>>
> > > >>>
> > > >>> cp1
> > > >>> cp2
> > > >>> role
> > > >>> groupid
> > > >>> 1
> > > >>> 10
> > > >>> 13
> > > >>> 4
> > > >>> 5
> > > >>> 2
> > > >>> 5
> > > >>> 10
> > > >>> 3
> > > >>> 1
> > > >>> 3
> > > >>> 7
> > > >>> 7
> > > >>> 4
> > > >>> 6
> > > >>> 4
> > > >>> 10
> > > >>> 4
> > > >>> 2
> > > >>> 7
> > > >>> 5
> > > >>> 5
> > > >>> 8
> > > >>> 3
> > > >>> 2
> > > >>> 6
> > > >>> 8
> > > >>> 7
> > > >>> 4
> > > >>> 4
> > > >>> 7
> > > >>> 8
> > > >>> 8
> > > >>> 4
> > > >>> 7
> > > >>> 8
> > > >>> 10
> > > >>> 15
> > > >>> 3
> > > >>> 3
> > > >>> 9
> > > >>> 15
> > > >>> 10
> > > >>> 2
> > > >>> 2
> > > >>> 10
> > > >>> 5
> > > >>> 5
> > > >>> 2
> > > >>> 4
> > > >>> 11
> > > >>> 20
> > > >>> 20
> > > >>> 2
> > > >>> 5
> > > >>> 12
> > > >>> 9
> > > >>> 11
> > > >>> 3
> > > >>> 6
> > > >>> 13
> > > >>> 10
> > > >>> 13
> > > >>> 4
> > > >>> 3
> > > >>> 14
> > > >>> 12
> > > >>> 6
> > > >>> 4
> > > >>> 2
> > > >>> 15
> > > >>> 7
> > > >>> 4
> > > >>> 4
> > > >>> 1
> > > >>> 16
> > > >>> 10
> > > >>> 0
> > > >>> 3
> > > >>> 7
> > > >>> 17
> > > >>> 20
> > > >>> 15
> > > >>> 3
> > > >>> 8
> > > >>> 18
> > > >>> 10
> > > >>> 7
> > > >>> 3
> > > >>> 4
> > > >>> 19
> > > >>> 8
> > > >>> 13
> > > >>> 3
> > > >>> 5
> > > >>> 20
> > > >>> 10
> > > >>> 9
> > > >>> 2
> > > >>> 6
> > > >>>
> > > >>>
> > > >>>
> > > >>> I need to to average of groups, using the values of column
> groupid, and
> > > >>> create a twin dataset in which the mean of the group is replaced
> > > instead
> > > >> of
> > > >>> individual values.
> > > >>> So for example, groupid 3, I calculate the mean (12+18)/2 and then
> I
> > > >>> replace in the new dataframe, but in the same positions, instead
> of 12
> > > >> and
> > > >>> 18, the values of the corresponding mean.
> > > >>> I found this solution, where db10_means is the output dataset,
> db10 is
> > > my
> > > >>> initial data.
> > > >>>
> > > >>> db10_means<-db10 %>%
> > > >>>     group_by(groupid) %>%
> > > >>>     mutate(across(starts_with("cp"), list(mean = mean)))
> > > >>>
> > > >>> It works perfectly, except that for NA values, where it replaces
> to all
> > > >>> group members the NA, while in some cases, the group is made of
> some NA
> > > >> and
> > > >>> some values.
> > > >>> So, when I have a group of two values and one NA, I would like
> that for
> > > >>> those with a value, the mean is replaced, for those with NA, the
> NA is
> > > >>> replaced.
> > > >>> Here the mean function has not the na.rm=T option associated, but
> it
> > > >>> appears that this solution cannot be implemented in this case. I
> am not
> > > >>> even sure that this would be enough to solve my problem.
> > > >>> Thanks for any help provided.
> > > >>>
> > > >> Hello,
> > > >>
> > > >> Your data is a mess, please don't post html, this is plain text only
> > > >> list. Anyway, I managed to create a data frame by copying the data
> to a
> > > >> file named "rhelp.txt" and then running
> > > >>
> > > >>
> > > >>
> > > >> db10 <- scan(file = "rhelp.txt", what = character())
> > > >> header <- db10[1:4]
> > > >> db10 <- db10[-(1:4)] |> as.numeric()
> > > >> db10 <- matrix(db10, ncol = 4L, byrow = TRUE) |>
> > > >>     as.data.frame() |>
> > > >>     setNames(header)
> > > >>
> > > >> str(db10)
> > > >> #> 'data.frame':    25 obs. of  4 variables:
> > > >> #>  $ cp1    : num  1 5 3 7 10 5 2 4 8 10 ...
> > > >> #>  $ cp2    : num  10 2 1 4 4 5 6 4 4 15 ...
> > > >> #>  $ role   : num  13 5 3 6 2 8 8 7 7 3 ...
> > > >> #>  $ groupid: num  4 10 7 4 7 3 7 8 8 3 ...
> > > >>
> > > >>
> > > >> And here is the data in dput format.
> > > >>
> > > >>
> > > >>
> > > >> db10 <-
> > > >>     structure(list(
> > > >>       cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> > > >>               2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> > > >>       cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> > > >>               4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> > > >>       role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> > > >>                11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> > > >>       groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> > > >>                   20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> > > >>       class = "data.frame", row.names = c(NA, -25L))
> > > >>
> > > >>
> > > >>
> > > >> As for the problem, I am not sure if you want summarise instead of
> > > >> mutate but here is a summarise solution.
> > > >>
> > > >>
> > > >>
> > > >> library(dplyr)
> > > >>
> > > >> db10 %>%
> > > >>     group_by(groupid) %>%
> > > >>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)))
> > > >>
> > > >> # same result, summarise's new argument .by avoids the need to
> group_by
> > > >> db10 %>%
> > > >>     summarise(across(starts_with("cp"), ~ mean(.x, na.rm = TRUE)),
> .by =
> > > >> groupid)
> > > >>
> > > >>
> > > >>
> > > >> Can you post the expected output too?
> > > >>
> > > >> Hope this helps,
> > > >>
> > > >> Rui Barradas
> > > >>
> > > >>
> > > >> --
> > > >> Este e-mail foi analisado pelo software antiv?rus AVG para
> verificar a
> > > >> presen?a de v?rus.
> > > >> www.avg.com
> > > >>
> > > >
> > > >
> > > Hello,
> > >
> > > Something like this?
> > >
> > >
> > > test <-
> > >    structure(list(
> > >      cp1 = c(1, 5, 3, 7, 10, 5, 2, 4, 8, 10, 9, 2,
> > >              2, 20, 9, 13, 3, 4, 4, 10, 17, 8, 3, 13, 10),
> > >      cp2 = c(10, 2, 1, 4, 4, 5, 6, 4, 4, 15, 15, 10,
> > >              4, 2, 11, 10, 14, 2, 4, 0, 20, 18, 4, 3, 9),
> > >      role = c(13, 5, 3, 6, 2, 8, 8, 7, 7, 3, 10, 5,
> > >               11, 5, 3, 13, 12, 15, 1, 3, 15, 10, 19, 5, 2),
> > >      groupid = c(4, 10, 7, 4, 7, 3, 7, 8, 8, 3, 2, 5,
> > >                  20, 12, 6, 4, 6, 7, 16, 7, 3, 7, 8, 20, 6)),
> > >      class = "data.frame", row.names = c(NA, -25L))
> > >
> > > library(dplyr)
> > >
> > > test %>%
> > >    group_by(groupid) %>%
> > >    mutate(across(starts_with("cp"), list(mean = ~ mean(.x, na.rm =
> TRUE))))
> > > #> # A tibble: 25 ? 6
> > > #> # Groups:   groupid [11]
> > > #>      cp1   cp2  role groupid cp1_mean cp2_mean
> > > #>    <dbl> <dbl> <dbl>   <dbl>    <dbl>    <dbl>
> > > #>  1     1    10    13       4     7        8
> > > #>  2     5     2     5      10     5        2
> > > #>  3     3     1     3       7     6.17     5.17
> > > #>  4     7     4     6       4     7        8
> > > #>  5    10     4     2       7     6.17     5.17
> > > #>  6     5     5     8       3    10.7     13.3
> > > #>  7     2     6     8       7     6.17     5.17
> > > #>  8     4     4     7       8     5        4
> > > #>  9     8     4     7       8     5        4
> > > #> 10    10    15     3       3    10.7     13.3
> > > #> # ? 15 more rows
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > --
> > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> > > presen?a de v?rus.
> > > www.avg.com
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > https://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 

Francesca


----------------------------------

	[[alternative HTML version deleted]]


From n|ckmwr@y @end|ng |rom gm@||@com  Tue Sep 17 14:00:15 2024
From: n|ckmwr@y @end|ng |rom gm@||@com (Nick Wray)
Date: Tue, 17 Sep 2024 13:00:15 +0100
Subject: [R] Getting individual co-ordinate points in k medoids cluster
Message-ID: <CABxY9BP6TF+JbuRNwQfwUpmZOSSevW2kvj9vqzfQXFNDh_n0iw@mail.gmail.com>

Hello  I am using k medoids in R to generate sets of clusters for datasets
through time.  I can plot the individual clusters OK but what I cannot find
is a way of pulling out the co-ordinates of the individual points in the
cluster diagrams - none of the kmed$... info sets seems to be this.

Beneath is an example of a k medoid prog using the built in US arrests
dataset - this is not the data I am working with but it illustrates the
issue easily

library(factoextra)
library(cluster)
set.seed(170924)
df <- USArrests
df <- na.omit(df)
df <- scale(df)
kmed <- pam(df, k = 4)
fviz_cluster(kmed, data = df)

Thanks for any help or pointers
Nick Wray

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Sep 17 16:03:39 2024
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 17 Sep 2024 10:03:39 -0400
Subject: [R] Getting individual co-ordinate points in k medoids cluster
In-Reply-To: <CABxY9BP6TF+JbuRNwQfwUpmZOSSevW2kvj9vqzfQXFNDh_n0iw@mail.gmail.com>
References: <CABxY9BP6TF+JbuRNwQfwUpmZOSSevW2kvj9vqzfQXFNDh_n0iw@mail.gmail.com>
Message-ID: <CAM_vjukpvO5pyhD_39ioeLrOTF_N=0xOBjfwCvw9-E2EXw6NEA@mail.gmail.com>

Hi Nick,

If you're asking about the coordinates used in the plot produced by
fviz_cluster(), you're looking in the wrong place.

The 2D plot isn't anything intrinsic to the clustering. Instead, that
plot is of the first two principal components. From the help:

"Observations are represented by points in the plot, using principal
components if ncol(data) > 2."

The easiest way to get the coordinates is probably to use prcomp
yourself, as fviz_cluster does.
Specifically, it does:

pca <- stats::prcomp(data, scale = FALSE, center = FALSE)

That's also where the percentage values in the axis labels come from:
those are the variance explained by each of the first two PCA axes.

Sarah


On Tue, Sep 17, 2024 at 8:01?AM Nick Wray <nickmwray at gmail.com> wrote:
>
> Hello  I am using k medoids in R to generate sets of clusters for datasets
> through time.  I can plot the individual clusters OK but what I cannot find
> is a way of pulling out the co-ordinates of the individual points in the
> cluster diagrams - none of the kmed$... info sets seems to be this.
>
> Beneath is an example of a k medoid prog using the built in US arrests
> dataset - this is not the data I am working with but it illustrates the
> issue easily
>
> library(factoextra)
> library(cluster)
> set.seed(170924)
> df <- USArrests
> df <- na.omit(df)
> df <- scale(df)
> kmed <- pam(df, k = 4)
> fviz_cluster(kmed, data = df)
>
> Thanks for any help or pointers
> Nick Wray
>
>         [[alternative HTML version deleted]]
>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep 18 10:20:27 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 18 Sep 2024 10:20:27 +0200
Subject: [R] Dirichlet kernel requires r to be defined,
 which is not in the help
In-Reply-To: <91076ee4-020d-4ece-b00d-6b7304aa9af8@inserm.fr>
References: <91076ee4-020d-4ece-b00d-6b7304aa9af8@inserm.fr>
Message-ID: <26346.36171.80774.573109@stat.math.ethz.ch>

>>>>> Samuel Granjeaud IR/Inserm 
>>>>>     on Sat, 14 Sep 2024 15:55:53 +0200 writes:

    > Code to reproduce
    >> kernel("dirichlet")
    > Error in kernel("dirichlet") : argument "r" is missing, with no default

    > The help says

    > r??? the kernel order for a Fejer kernel.

    > Thanks to update the help.

You are right.  This is a documentation bug  which has *not*
been reported ever in the ca 25 years the function and its doc
exists ...

It should say

   r??? the kernel order for a Dirichlet or Fejer kernel.

--> I will fix the sources accordingly.
Should be in the next released version of R ..
thanks to you very much,  Samuel!

Martin


From @|een@@h@j|01 @end|ng |rom gm@||@com  Thu Sep 19 07:29:45 2024
From: @|een@@h@j|01 @end|ng |rom gm@||@com (Aleena Shaji)
Date: Thu, 19 Sep 2024 10:59:45 +0530
Subject: [R] Inquiry About R Packages for Specific Research Areas
Message-ID: <CABNGMAWO-Sc6xuS680AcaeLJeouj8cKVA3BYShkGy8axBT+eVQ@mail.gmail.com>

Dear R Support Team,

I hope this email finds you well.

I am writing to inquire about the specific R packages that would best suit
our academic research project, which involves analyses in various fields.
We are particularly interested in the following areas:

Epidemiology Analysis: We are aware that packages like epiR, survival, and
epitools exist for epidemiological analysis. Could you please confirm which
of these (or others) would be most suitable for our needs?
Dietary Intake/Analysis: We are considering packages like foodfreq and
Dietary for dietary intake analysis. Are these the best options, or do you
recommend other packages for this purpose?
Pedigree Analysis: We are exploring the kinship2 and pedigree packages for
pedigree data analysis. Is there a package you would suggest for more
comprehensive analysis?
Migration-Related Study: We are interested in migration-related studies and
have identified the migrant and spatstat packages. Would these be the most
appropriate, or are there others we should consider?
We would appreciate your guidance in selecting the best packages that align
with our research interests. Additionally, are there any resources or
documentation that you recommend for getting started with these packages?

Thank you for your support, and we look forward to your response.

Best regards,
Aleena

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 19 10:12:21 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 19 Sep 2024 09:12:21 +0100
Subject: [R] Inquiry About R Packages for Specific Research Areas
In-Reply-To: <CABNGMAWO-Sc6xuS680AcaeLJeouj8cKVA3BYShkGy8axBT+eVQ@mail.gmail.com>
References: <CABNGMAWO-Sc6xuS680AcaeLJeouj8cKVA3BYShkGy8axBT+eVQ@mail.gmail.com>
Message-ID: <f67f011c-db7e-45aa-8114-99d70eb884d5@sapo.pt>

Hello,

There is a CRAN Task View: Epidemiology that should be or have what you 
are looking for.

[1] 	https://CRAN.R-project.org/view=Epidemiology

Hope this helps,

Rui Barradas

?s 06:29 de 19/09/2024, Aleena Shaji escreveu:
> Dear R Support Team,
> 
> I hope this email finds you well.
> 
> I am writing to inquire about the specific R packages that would best suit
> our academic research project, which involves analyses in various fields.
> We are particularly interested in the following areas:
> 
> Epidemiology Analysis: We are aware that packages like epiR, survival, and
> epitools exist for epidemiological analysis. Could you please confirm which
> of these (or others) would be most suitable for our needs?
> Dietary Intake/Analysis: We are considering packages like foodfreq and
> Dietary for dietary intake analysis. Are these the best options, or do you
> recommend other packages for this purpose?
> Pedigree Analysis: We are exploring the kinship2 and pedigree packages for
> pedigree data analysis. Is there a package you would suggest for more
> comprehensive analysis?
> Migration-Related Study: We are interested in migration-related studies and
> have identified the migrant and spatstat packages. Would these be the most
> appropriate, or are there others we should consider?
> We would appreciate your guidance in selecting the best packages that align
> with our research interests. Additionally, are there any resources or
> documentation that you recommend for getting started with these packages?
> 
> Thank you for your support, and we look forward to your response.
> 
> Best regards,
> Aleena
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sat Sep 21 23:25:03 2024
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sat, 21 Sep 2024 17:25:03 -0400
Subject: [R] store list objects in data.table
Message-ID: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

I am trying to store regression objects in a data.table

df <- data.frame(x = rnorm(20))
df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))

mydt <- data.table(mypower = c(1, 2), myreg = list(lm(y ~ x, data = df),
lm(y ~ x + I(x^2), data = df)))

mydt
#?? mypower??? myreg
#???? <num>?? <list>
#1:?????? 1 <lm[12]>
#2:?????? 2 <lm[12]>

But mydt[1, 2] has only the coeffients of the first regression. mydt[2,
2] has residuals of the first regression.? These are the first two
components of "lm" object.

mydt[1, myreg[[1]]]
#(Intercept)?????????? x
#?? 0.107245??? 1.034110

Is there a way to put full "lm" object in each row?

Thanks,
Naresh


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep 22 00:33:53 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 21 Sep 2024 23:33:53 +0100
Subject: [R] store list objects in data.table
In-Reply-To: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <09e2455f-8a20-4a4e-bcba-4a71ab5a6c5b@sapo.pt>

?s 22:25 de 21/09/2024, Naresh Gurbuxani escreveu:
> I am trying to store regression objects in a data.table
> 
> df <- data.frame(x = rnorm(20))
> df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))
> 
> mydt <- data.table(mypower = c(1, 2), myreg = list(lm(y ~ x, data = df),
> lm(y ~ x + I(x^2), data = df)))
> 
> mydt
> #?? mypower??? myreg
> #???? <num>?? <list>
> #1:?????? 1 <lm[12]>
> #2:?????? 2 <lm[12]>
> 
> But mydt[1, 2] has only the coeffients of the first regression. mydt[2,
> 2] has residuals of the first regression.? These are the first two
> components of "lm" object.
> 
> mydt[1, myreg[[1]]]
> #(Intercept)?????????? x
> #?? 0.107245??? 1.034110
> 
> Is there a way to put full "lm" object in each row?
> 
> Thanks,
> Naresh
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Yes, there are ways of pulling the full lm objects from the list column. 
It's a matter of using the right indexing.

mydt[[2L]][1L] extracts a list whose element is a lm object.
mydt[[2L]][[1L]] extracts yhe lm object, this is the one you want.

See the two examples below.



library(data.table)

df <- data.frame(x = rnorm(20))
df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))

mydt <- data.table(
   mypower = c(1, 2),
   myreg = list(lm(y ~ x, data = df),
                lm(y ~ x + I(x^2), data = df)))

mydt[[2L]][1L] |> class()
#> [1] "list"

mydt[[2L]][[1L]] |> class()
#> [1] "lm"


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From po|c1410 @end|ng |rom gm@||@com  Sun Sep 22 00:56:27 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sat, 21 Sep 2024 23:56:27 +0100
Subject: [R] store list objects in data.table
In-Reply-To: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <CA+etgPk=jGe=aVjF75GzvVx7HYE1OWdG61BJGDFZ4E4R3WvC-Q@mail.gmail.com>

I think there is a typo in your reprex l(x^2) ??

mydt[1,2] contains a list. Which when unlisted contains a load of data.

I'm not sure what you are asking for? Are you trying to unlist that and
have it as a row? Sort of pivot.wider if you like or unnest in tidyverse
concepts?

I think the data.table verbs are rbindlist

But I haven't really understood what your end "product" looks like.

I think it's a two row table, with 20 intercepts and 20 gradients, repeated
a second time?

I'd have made that a 20 row table with x, y and then 4 columns for the two
versions?

On Sat, 21 Sep 2024, 22:25 Naresh Gurbuxani, <naresh_gurbuxani at hotmail.com>
wrote:

> I am trying to store regression objects in a data.table
>
> df <- data.frame(x = rnorm(20))
> df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))
>
> mydt <- data.table(mypower = c(1, 2), myreg = list(lm(y ~ x, data = df),
> lm(y ~ x + I(x^2), data = df)))
>
> mydt
> #   mypower    myreg
> #     <num>   <list>
> #1:       1 <lm[12]>
> #2:       2 <lm[12]>
>
> But mydt[1, 2] has only the coeffients of the first regression. mydt[2,
> 2] has residuals of the first regression.  These are the first two
> components of "lm" object.
>
> mydt[1, myreg[[1]]]
> #(Intercept)           x
> #   0.107245    1.034110
>
> Is there a way to put full "lm" object in each row?
>
> Thanks,
> Naresh
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep 22 08:00:57 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 21 Sep 2024 23:00:57 -0700
Subject: [R] store list objects in data.table
In-Reply-To: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQfrECatiMG7v+6kfX+3qwUHO1XPMtn+xzB6Z4WZX0JXg@mail.gmail.com>

Well, you may have good reasons to do things this way -- and you
certainly do not have to explain them here.

But you might wish to consider using R's poly() function and a basic
nested list structure to do something quite similar that seems much
simpler to me, anyway:

x <- rnorm(20)
df <- data.frame(x = x, y = x + .1*x^2 + rnorm(20, sd = .2))
result <-
   with(df,
          lapply(1:2, \(i)
                 list(
                     degree = i, reg =lm(y ~ poly(x, i, raw = TRUE))
                    )
          )
   )

As you can see, 'result' is a list, each component of which is a list
of two with names "degree" and "reg" giving the same info as each row
of your 'mydt'. You can use lapply() and friends to access these
results and fiddle with them as you like, such as: "extract the
coefficients from the second degree fits only", and so forth. Also
note that individual components of nested lists can be extracted by
giving a vector to [[ instead of repeated [['s. For example:
result[[2]][[2]]  ## the reg component of the degree 2 polynomial
## is the same as
result[[c(2,2)]] ## this is a bit easier for me to groc.

Again, feel free to ignore without replying if my gratuitous remarks
are unhelpful.

Cheers,
Bert


On Sat, Sep 21, 2024 at 2:25?PM Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
>
> I am trying to store regression objects in a data.table
>
> df <- data.frame(x = rnorm(20))
> df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))
>
> mydt <- data.table(mypower = c(1, 2), myreg = list(lm(y ~ x, data = df),
> lm(y ~ x + I(x^2), data = df)))
>
> mydt
> #   mypower    myreg
> #     <num>   <list>
> #1:       1 <lm[12]>
> #2:       2 <lm[12]>
>
> But mydt[1, 2] has only the coeffients of the first regression. mydt[2,
> 2] has residuals of the first regression.  These are the first two
> components of "lm" object.
>
> mydt[1, myreg[[1]]]
> #(Intercept)           x
> #   0.107245    1.034110
>
> Is there a way to put full "lm" object in each row?
>
> Thanks,
> Naresh
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sun Sep 22 13:44:16 2024
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sun, 22 Sep 2024 07:44:16 -0400
Subject: [R] store list objects in data.table
In-Reply-To: <CAGxFJbQfrECatiMG7v+6kfX+3qwUHO1XPMtn+xzB6Z4WZX0JXg@mail.gmail.com>
References: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
 <CAGxFJbQfrECatiMG7v+6kfX+3qwUHO1XPMtn+xzB6Z4WZX0JXg@mail.gmail.com>
Message-ID: <IA1P223MB049997F5E090D82443D98C70FA6E2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

Thanks everyone for their responses.

My data is organized in a data.table.? My goal is to perform analyses 
according to some groups.? The results of analysis are objects.? If 
these objects could be stored as elements of a data.table, this would 
help downstream summarizing of results.

Let me try another example.

carsdt <- setDT(copy(mtcars))

carsdt[, unique(cyl) |> length()]
#[1] 3

carsreg <- carsdt[, .(fit = lm(mpg ~ disp + hp + wt)), by = .(cyl)]

#I would like a data.table with three rows, one each for "lm" object 
corresponding to cyl value

carsreg[, .N]
#[1] 36

#Here each component of "lm" object is stored in a separate row.

carsreg[1]
#???? cyl???????????????????????????????????????????? fit
#?? <num> <lm>
#1:???? 6 30.27790680, 0.01610061,-0.01097072,-3.89618307

lm(mpg ~ disp + hp + wt, data = mtcars, subset = (cyl == 6)) |> coef()
#(Intercept)??????? disp????????? hp????????? wt
#30.27790680? 0.01610061 -0.01097072 -3.89618307

A less satisfactory solution is to extract desired components and store 
them in data.table.? But this requires multiple calls to lm().

carsreg2 <- carsdt[, .(coef = list(coef(lm(mpg ~ disp + hp + wt))), rsq 
= summary(lm(mpg ~ disp + hp + wt))$r.squared), by = .(cyl)]

Now if I want to also include F-statistic, it would require an 
additional call to lm() and adding a column to above data.table.? Is 
there a way to avoid this?

Naresh

On 9/22/24 2:00 AM, Bert Gunter wrote:
> Well, you may have good reasons to do things this way -- and you
> certainly do not have to explain them here.
>
> But you might wish to consider using R's poly() function and a basic
> nested list structure to do something quite similar that seems much
> simpler to me, anyway:
>
> x <- rnorm(20)
> df <- data.frame(x = x, y = x + .1*x^2 + rnorm(20, sd = .2))
> result <-
>     with(df,
>            lapply(1:2, \(i)
>                   list(
>                       degree = i, reg =lm(y ~ poly(x, i, raw = TRUE))
>                      )
>            )
>     )
>
> As you can see, 'result' is a list, each component of which is a list
> of two with names "degree" and "reg" giving the same info as each row
> of your 'mydt'. You can use lapply() and friends to access these
> results and fiddle with them as you like, such as: "extract the
> coefficients from the second degree fits only", and so forth. Also
> note that individual components of nested lists can be extracted by
> giving a vector to [[ instead of repeated [['s. For example:
> result[[2]][[2]]  ## the reg component of the degree 2 polynomial
> ## is the same as
> result[[c(2,2)]] ## this is a bit easier for me to groc.
>
> Again, feel free to ignore without replying if my gratuitous remarks
> are unhelpful.
>
> Cheers,
> Bert
>
>
> On Sat, Sep 21, 2024 at 2:25?PM Naresh Gurbuxani
> <naresh_gurbuxani at hotmail.com> wrote:
>> I am trying to store regression objects in a data.table
>>
>> df <- data.frame(x = rnorm(20))
>> df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))
>>
>> mydt <- data.table(mypower = c(1, 2), myreg = list(lm(y ~ x, data = df),
>> lm(y ~ x + I(x^2), data = df)))
>>
>> mydt
>> #   mypower    myreg
>> #     <num>   <list>
>> #1:       1 <lm[12]>
>> #2:       2 <lm[12]>
>>
>> But mydt[1, 2] has only the coeffients of the first regression. mydt[2,
>> 2] has residuals of the first regression.  These are the first two
>> components of "lm" object.
>>
>> mydt[1, myreg[[1]]]
>> #(Intercept)           x
>> #   0.107245    1.034110
>>
>> Is there a way to put full "lm" object in each row?
>>
>> Thanks,
>> Naresh
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From |kry|ov @end|ng |rom d|@root@org  Sun Sep 22 14:09:46 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 22 Sep 2024 15:09:46 +0300
Subject: [R] store list objects in data.table
In-Reply-To: <IA1P223MB049997F5E090D82443D98C70FA6E2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
 <CAGxFJbQfrECatiMG7v+6kfX+3qwUHO1XPMtn+xzB6Z4WZX0JXg@mail.gmail.com>
 <IA1P223MB049997F5E090D82443D98C70FA6E2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <20240922150946.20633a6f@trisector>

? Sun, 22 Sep 2024 07:44:16 -0400
Naresh Gurbuxani <naresh_gurbuxani at hotmail.com> ?????:

> carsreg <- carsdt[, .(fit = lm(mpg ~ disp + hp + wt)), by = .(cyl)]
> 
> #I would like a data.table with three rows, one each for "lm" object 
> corresponding to cyl value
> 
> carsreg[, .N]
> #[1] 36

Try wrapping the lm() expression in an extra list():

carsreg <- carsdt[, .(fit = list(lm(mpg ~ disp + hp + wt))), by = .(cyl)]
# [1] 3
carsreg
#      cyl      fit
#    <num>   <list>
# 1:     6 <lm[12]>
# 2:     4 <lm[12]>
# 3:     8 <lm[12]>

-- 
Best regards,
Ivan


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sun Sep 22 14:39:14 2024
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sun, 22 Sep 2024 08:39:14 -0400
Subject: [R] store list objects in data.table
In-Reply-To: <IA1P223MB049997F5E090D82443D98C70FA6E2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB0499F0305846AD419F820295FA6D2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
 <CAGxFJbQfrECatiMG7v+6kfX+3qwUHO1XPMtn+xzB6Z4WZX0JXg@mail.gmail.com>
 <IA1P223MB049997F5E090D82443D98C70FA6E2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <IA1P223MB04999CF74853C2FDA441E299FA6E2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

After rereading Rui Barrades's reply, I was able to get "lm" object from 
data.table

carsreg3 <- carsdt[, .(fit = list(lm(mpg ~ disp + hp + wt))), by = .(cyl)]
carsreg3[, .N]
#[1] 3
carsreg3[(cyl == 6), .(fit)][[1]][[1]] |> class()
#[1] "lm"
carsreg3[(cyl == 6), .(fit)][[1]][[1]] |> summary()
carsreg3[, .(rsq = summary(fit[[1]])$r.squared), by = .(cyl)]
#?? cyl?????? rsq
#1:?? 6 0.7217114
#2:?? 4 0.7080702
#3:?? 8 0.4970692

data.table is a fantastic tool.

Thanks again,

Naresh


On 9/22/24 07:44, Naresh Gurbuxani wrote:
> Thanks everyone for their responses.
>
> My data is organized in a data.table.? My goal is to perform analyses 
> according to some groups.? The results of analysis are objects.? If 
> these objects could be stored as elements of a data.table, this would 
> help downstream summarizing of results.
>
> Let me try another example.
>
> carsdt <- setDT(copy(mtcars))
>
> carsdt[, unique(cyl) |> length()]
> #[1] 3
>
> carsreg <- carsdt[, .(fit = lm(mpg ~ disp + hp + wt)), by = .(cyl)]
>
> #I would like a data.table with three rows, one each for "lm" object 
> corresponding to cyl value
>
> carsreg[, .N]
> #[1] 36
>
> #Here each component of "lm" object is stored in a separate row.
>
> carsreg[1]
> #???? cyl???????????????????????????????????????????? fit
> #?? <num> <lm>
> #1:???? 6 30.27790680, 0.01610061,-0.01097072,-3.89618307
>
> lm(mpg ~ disp + hp + wt, data = mtcars, subset = (cyl == 6)) |> coef()
> #(Intercept)??????? disp????????? hp????????? wt
> #30.27790680? 0.01610061 -0.01097072 -3.89618307
>
> A less satisfactory solution is to extract desired components and 
> store them in data.table.? But this requires multiple calls to lm().
>
> carsreg2 <- carsdt[, .(coef = list(coef(lm(mpg ~ disp + hp + wt))), 
> rsq = summary(lm(mpg ~ disp + hp + wt))$r.squared), by = .(cyl)]
>
> Now if I want to also include F-statistic, it would require an 
> additional call to lm() and adding a column to above data.table. Is 
> there a way to avoid this?
>
> Naresh
>
> On 9/22/24 2:00 AM, Bert Gunter wrote:
>> Well, you may have good reasons to do things this way -- and you
>> certainly do not have to explain them here.
>>
>> But you might wish to consider using R's poly() function and a basic
>> nested list structure to do something quite similar that seems much
>> simpler to me, anyway:
>>
>> x <- rnorm(20)
>> df <- data.frame(x = x, y = x + .1*x^2 + rnorm(20, sd = .2))
>> result <-
>> ??? with(df,
>> ?????????? lapply(1:2, \(i)
>> ????????????????? list(
>> ????????????????????? degree = i, reg =lm(y ~ poly(x, i, raw = TRUE))
>> ???????????????????? )
>> ?????????? )
>> ??? )
>>
>> As you can see, 'result' is a list, each component of which is a list
>> of two with names "degree" and "reg" giving the same info as each row
>> of your 'mydt'. You can use lapply() and friends to access these
>> results and fiddle with them as you like, such as: "extract the
>> coefficients from the second degree fits only", and so forth. Also
>> note that individual components of nested lists can be extracted by
>> giving a vector to [[ instead of repeated [['s. For example:
>> result[[2]][[2]]? ## the reg component of the degree 2 polynomial
>> ## is the same as
>> result[[c(2,2)]] ## this is a bit easier for me to groc.
>>
>> Again, feel free to ignore without replying if my gratuitous remarks
>> are unhelpful.
>>
>> Cheers,
>> Bert
>>
>>
>> On Sat, Sep 21, 2024 at 2:25?PM Naresh Gurbuxani
>> <naresh_gurbuxani at hotmail.com> wrote:
>>> I am trying to store regression objects in a data.table
>>>
>>> df <- data.frame(x = rnorm(20))
>>> df[, "y"] <- with(df, x + 0.1 * x^2 + 0.2 * rnorm(20))
>>>
>>> mydt <- data.table(mypower = c(1, 2), myreg = list(lm(y ~ x, data = 
>>> df),
>>> lm(y ~ x + I(x^2), data = df)))
>>>
>>> mydt
>>> #?? mypower??? myreg
>>> #???? <num>?? <list>
>>> #1:?????? 1 <lm[12]>
>>> #2:?????? 2 <lm[12]>
>>>
>>> But mydt[1, 2] has only the coeffients of the first regression. mydt[2,
>>> 2] has residuals of the first regression.? These are the first two
>>> components of "lm" object.
>>>
>>> mydt[1, myreg[[1]]]
>>> #(Intercept)?????????? x
>>> #?? 0.107245??? 1.034110
>>>
>>> Is there a way to put full "lm" object in each row?
>>>
>>> Thanks,
>>> Naresh
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||809 @end|ng |rom nc|@c@  Mon Sep 23 18:35:29 2024
From: ||809 @end|ng |rom nc|@c@ (Brian Lunergan)
Date: Mon, 23 Sep 2024 12:35:29 -0400
Subject: [R] Loading multiple packages with install.packages()...
Message-ID: <f1e4011edecd50a3f952348af819088ae960689e.camel@ncf.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hi folks:

Curious question. I've added Rcmdr to my setup (R 4.4.1). I would like
to add all of the plugins. Is there a way to get install.packages() to
gather up everything starting 'rcmdrplugin', or do I have to list each
package individually between the brackets?? ??

Regards...
- -- 
Brian Lunergan
Russell, Ontario
Canada

-----BEGIN PGP SIGNATURE-----

iQEzBAEBCgAdFiEETYnejayhh3NYXwphdgjwxcHhY5wFAmbxmNIACgkQdgjwxcHh
Y5wR9wf7BDbw9feBoJ/F6y3vHCNxuksaDJn263ur9HKFgJYwHLqjD6yRqzvhf9IG
N7G4LCmzjUk5NyjmKEGLCUCwGHYCxq6J0kKoWdwXczQzfxLDSBs2ePTcAhmaHmf4
60dZO7na9f6DXOqW2QQzb3A6P+dSUAHdhn1mP9RctjUq9pX1nrq+JUTAke/HsD/N
mV6FkQX0HMgZZR3KTkORePy2q+Ejui+Ct1iS0sCpSLsOJ9X4U20GlimdvD8JY00M
JWMPUgmu4nk9qebchqiegCydBMEemYT7FboS+B9fzGV7gHHojHYAppoQvPi5yjDy
XfR+4SqRzBlLNHxUbhepwEmUAfeIQw==
=JX0e
-----END PGP SIGNATURE-----


From tebert @end|ng |rom u||@edu  Mon Sep 23 18:40:11 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 23 Sep 2024 16:40:11 +0000
Subject: [R] Loading multiple packages with install.packages()...
In-Reply-To: <f1e4011edecd50a3f952348af819088ae960689e.camel@ncf.ca>
References: <f1e4011edecd50a3f952348af819088ae960689e.camel@ncf.ca>
Message-ID: <CH3PR22MB45142C399E9748C436ACD4D7CF6F2@CH3PR22MB4514.namprd22.prod.outlook.com>

If you can get a vector with all the package names (I do not know how to do this) then you could do something like this;
# Function to check and install missing packages
install_if_missing <- function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
  }
  library(pkg, character.only = TRUE)
}
# List of required packages.
packages <- c("emmeans", "multcomp", "sandwich", "multcompView", "ggplot2", "stringr", "dplyr", "openxlsx", "tidyr")
# Check and install each package
lapply(packages, install_if_missing)


Regards,
Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Brian Lunergan
Sent: Monday, September 23, 2024 12:35 PM
To: r-help at r-project.org
Subject: [R] Loading multiple packages with install.packages()...

[External Email]

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hi folks:

Curious question. I've added Rcmdr to my setup (R 4.4.1). I would like to add all of the plugins. Is there a way to get install.packages() to gather up everything starting 'rcmdrplugin', or do I have to list each package individually between the brackets?? ??

Regards...
- --
Brian Lunergan
Russell, Ontario
Canada

-----BEGIN PGP SIGNATURE-----

iQEzBAEBCgAdFiEETYnejayhh3NYXwphdgjwxcHhY5wFAmbxmNIACgkQdgjwxcHh
Y5wR9wf7BDbw9feBoJ/F6y3vHCNxuksaDJn263ur9HKFgJYwHLqjD6yRqzvhf9IG
N7G4LCmzjUk5NyjmKEGLCUCwGHYCxq6J0kKoWdwXczQzfxLDSBs2ePTcAhmaHmf4
60dZO7na9f6DXOqW2QQzb3A6P+dSUAHdhn1mP9RctjUq9pX1nrq+JUTAke/HsD/N
mV6FkQX0HMgZZR3KTkORePy2q+Ejui+Ct1iS0sCpSLsOJ9X4U20GlimdvD8JY00M
JWMPUgmu4nk9qebchqiegCydBMEemYT7FboS+B9fzGV7gHHojHYAppoQvPi5yjDy
XfR+4SqRzBlLNHxUbhepwEmUAfeIQw==
=JX0e
-----END PGP SIGNATURE-----

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 23 18:56:20 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 23 Sep 2024 09:56:20 -0700
Subject: [R] Loading multiple packages with install.packages()...
In-Reply-To: <CH3PR22MB45142C399E9748C436ACD4D7CF6F2@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <f1e4011edecd50a3f952348af819088ae960689e.camel@ncf.ca>
 <CH3PR22MB45142C399E9748C436ACD4D7CF6F2@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <CAGxFJbQbECX9h9NPQf0=uoSfjLjVvGxagdMq6qsjJnmhQqdoQA@mail.gmail.com>

"If you can get a vector with all the package names (I do not know how
to do this)..."

See ?available.packages

grep-ing the rownames of the available.packages() result appropriately
should give you a vector of the desired package names to install,
which can then be given to install.packages.

... Untested, so no guarantees.

Cheers,
Bert


On Mon, Sep 23, 2024 at 9:46?AM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> If you can get a vector with all the package names (I do not know how to do this) then you could do something like this;
> # Function to check and install missing packages
> install_if_missing <- function(pkg) {
>   if (!require(pkg, character.only = TRUE)) {
>     install.packages(pkg, dependencies = TRUE)
>   }
>   library(pkg, character.only = TRUE)
> }
> # List of required packages.
> packages <- c("emmeans", "multcomp", "sandwich", "multcompView", "ggplot2", "stringr", "dplyr", "openxlsx", "tidyr")
> # Check and install each package
> lapply(packages, install_if_missing)
>
>
> Regards,
> Tim
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Brian Lunergan
> Sent: Monday, September 23, 2024 12:35 PM
> To: r-help at r-project.org
> Subject: [R] Loading multiple packages with install.packages()...
>
> [External Email]
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> Hi folks:
>
> Curious question. I've added Rcmdr to my setup (R 4.4.1). I would like to add all of the plugins. Is there a way to get install.packages() to gather up everything starting 'rcmdrplugin', or do I have to list each package individually between the brackets?? ??
>
> Regards...
> - --
> Brian Lunergan
> Russell, Ontario
> Canada
>
> -----BEGIN PGP SIGNATURE-----
>
> iQEzBAEBCgAdFiEETYnejayhh3NYXwphdgjwxcHhY5wFAmbxmNIACgkQdgjwxcHh
> Y5wR9wf7BDbw9feBoJ/F6y3vHCNxuksaDJn263ur9HKFgJYwHLqjD6yRqzvhf9IG
> N7G4LCmzjUk5NyjmKEGLCUCwGHYCxq6J0kKoWdwXczQzfxLDSBs2ePTcAhmaHmf4
> 60dZO7na9f6DXOqW2QQzb3A6P+dSUAHdhn1mP9RctjUq9pX1nrq+JUTAke/HsD/N
> mV6FkQX0HMgZZR3KTkORePy2q+Ejui+Ct1iS0sCpSLsOJ9X4U20GlimdvD8JY00M
> JWMPUgmu4nk9qebchqiegCydBMEemYT7FboS+B9fzGV7gHHojHYAppoQvPi5yjDy
> XfR+4SqRzBlLNHxUbhepwEmUAfeIQw==
> =JX0e
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbo|ker @end|ng |rom gm@||@com  Mon Sep 23 18:57:52 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 23 Sep 2024 12:57:52 -0400
Subject: [R] Loading multiple packages with install.packages()...
In-Reply-To: <CH3PR22MB45142C399E9748C436ACD4D7CF6F2@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <f1e4011edecd50a3f952348af819088ae960689e.camel@ncf.ca>
 <CH3PR22MB45142C399E9748C436ACD4D7CF6F2@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <9881a7fa-89e2-4491-90e4-fbe5c97ea2d3@gmail.com>

   Continuing with this approach:

a1 <- available.packages()
packages <- grep("^rcmdrplugin", rownames(a1), ignore.case = TRUE, value 
= TRUE)
missing_pkgs <- setdiff(packages, rownames(installed.packages()))
install.packages(missing_pkgs, dependencies = TRUE)

   The pacman package also handles some of these "install only if not 
already installed" tasks.

On 2024-09-23 12:40 p.m., Ebert,Timothy Aaron wrote:
> If you can get a vector with all the package names (I do not know how to do this) then you could do something like this;
> # Function to check and install missing packages
> install_if_missing <- function(pkg) {
>    if (!require(pkg, character.only = TRUE)) {
>      install.packages(pkg, dependencies = TRUE)
>    }
>    library(pkg, character.only = TRUE)
> }
> # List of required packages.
> packages <- c("emmeans", "multcomp", "sandwich", "multcompView", "ggplot2", "stringr", "dplyr", "openxlsx", "tidyr")
> # Check and install each package
> lapply(packages, install_if_missing)
> 
> 
> Regards,
> Tim
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Brian Lunergan
> Sent: Monday, September 23, 2024 12:35 PM
> To: r-help at r-project.org
> Subject: [R] Loading multiple packages with install.packages()...
> 
> [External Email]
> 
> Hi folks:
> 
> Curious question. I've added Rcmdr to my setup (R 4.4.1). I would like to add all of the plugins. Is there a way to get install.packages() to gather up everything starting 'rcmdrplugin', or do I have to list each package individually between the brackets?? ??
> 
> Regards...
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
> E-mail is sent at my convenience; I don't expect replies outside of
working hours.


From j@b@y@t194 @end|ng |rom gm@||@com  Tue Sep 24 08:31:22 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Tue, 24 Sep 2024 10:01:22 +0330
Subject: [R] Problem with converting grib file to excel
Message-ID: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>

Dear R users;
I have downloaded a grib file format (Met.grib) and I want to export its
data to excel file. Also I want to do some mathematic on some columns. But
I got error. I would be more than happy if anyone can help me to do this. I
have provided the codes and the Met.grib file in this email.
Sincerely yours

# Load the necessary libraries
>  library(raster)      # For reading GRIB files
>  library(dplyr)       # For data manipulation
>  library(lubridate)   # For date manipulation
>  library(openxlsx)    # For writing Excel files

# Specify the file paths
>  grib_file_path <- "C:/Users/Omrab_Lab/Downloads/Met.grib"
>  excel_file_path <- "C:/Users/Omrab_Lab/Downloads/Met_updated.xlsx"

# Open the GRIB file
>  raster_data <- stack(grib_file_path)

# Check the names of the layers to identify which ones to extract
>  layer_names <- names(raster_data)
> print(layer_names)  # Prints


> # Extract layers based on layer names - adjust as necessary
> t2m <- raster_data[[grep("t2m", layer_names)]]
> d2m <- raster_data[[grep("d2m", layer_names)]]
> tcc <- raster_data[[grep("tcc", layer_names)]]
> valid_time <- raster_data[[grep("valid_time", layer_names)]]
> t2m
class      : RasterStack
nlayers    : 0

> # Check if the raster layers are loaded correctly
> if (is.null(t2m) || is.null(d2m) || is.null(tcc) || is.null(valid_time))
{
+     stop("One or more raster layers could not be loaded. Please check the
layer names.")
+ }

> # Convert raster values to vectors
> t2m_values <- values(t2m)
Error in dimnames(x) <- dn :
  length of 'dimnames' [2] not equal to array extent
> d2m_values <- values(d2m)
Error in dimnames(x) <- dn :
  length of 'dimnames' [2] not equal to array extent
> tcc_values <- values(tcc)
Error in dimnames(x) <- dn :
  length of 'dimnames' [2] not equal to array extent
> valid_time_values <- values(valid_time)
Error in dimnames(x) <- dn :
  length of 'dimnames' [2] not equal to array extent

# Check for NA values and dimensions
if (any(is.na(t2m_values)) || any(is.na(d2m_values)) || any(is.na(tcc_values))
|| any(is.na(valid_time_values))) {
  warning("One or more layers contain NA values. These will be removed.")
}

# Create the data frame, ensuring no NA values are included
df <- data.frame(
  t2m = t2m_values,
  d2m = d2m_values,
  tcc = tcc_values,
  valid_time = valid_time_values,
  stringsAsFactors = FALSE
)

# Remove rows with NA values
df <- na.omit(df)

# Convert temperatures from Kelvin to Celsius
df$t2m <- df$t2m - 273.15
df$d2m <- df$d2m - 273.15

# Calculate relative humidity
calculate_relative_humidity <- function(t2m, d2m) {
  es <- 6.112 * exp((17.67 * t2m) / (t2m + 243.5))
  e <- 6.112 * exp((17.67 * d2m) / (d2m + 243.5))
  rh <- (e / es) * 100
  return(rh)
}
df$RH <- calculate_relative_humidity(df$t2m, df$d2m)

# Convert valid_time from numeric to POSIXct assuming it's in seconds since
the epoch
df$valid_time <- as.POSIXct(df$valid_time, origin = "1970-01-01")

# Extract year, month, day, and hour from valid_time
df$Year <- year(df$valid_time)
df$Month <- month(df$valid_time)
df$Day <- day(df$valid_time)
df$Hour <- hour(df$valid_time)

# Select only the desired columns
df_selected <- df %>% select(Year, Month, Day, Hour, tcc, t2m, RH)

# Save the updated DataFrame to an Excel file
write.xlsx(df_selected, excel_file_path, row.names = FALSE)






-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From jen@@oeh|@ch|@ege| @end|ng |rom truec|u@ter@com  Mon Sep 23 22:45:10 2024
From: jen@@oeh|@ch|@ege| @end|ng |rom truec|u@ter@com (=?UTF-8?Q?Jens_Oehlschl=C3=A4gel?=)
Date: Mon, 23 Sep 2024 22:45:10 +0200
Subject: [R] [R-pkgs] bit, bit64, ff and greeNsort
Message-ID: <b11255da-dd8d-4731-8b3c-0e8a2bdab5e0@truecluster.com>

Dear package maintainers,

Dear users of packages `bit`, `bit64`, `ff`,

Everyone interested in sustainable sorting algorithms,

I submitted updated versions for the upcoming R 4.5.0. The are only 
minor changes (see the NEWS files) but there is one important change in 
bit64:

 ??? o setting options(integer64_semantics="new")
 ????? gives the better semantics suggested by Ofek Shilon.
 ????? Downstream package authors: please test and adjust to the new 
semantics,
 ????? we plan to make that the default.

After 25 years volunteer work for the R community, that was my last 
combined submission for packages `bit`, `bit64` and `ff`.

I learned S+ in 1996 and supported R's 1.0 release in 2000 with bug 
testing, a small code contribution to `pairs` and motivating the 
core-team to replace 'NA' with NA_character_.

In 2007 Daniel Adler and I published `ff`: the first R package allowing 
big out of memory data.frames was a nail in the coffin of SAS dominance 
and helped R into the big data era.

2009 and 2012 followed `bit`, `bit64` to enhance R's data types somewhat 
with `bit` vectors and signed `integer64`. Package `bit` supported 
efficient selection in `ff`. Package `bit64` was an emergency 
development in order to establish rather `integer64' than another 
`int64` package that had too expensive performance.

Since 2011 I work for an employer that does not use R, and maintenance 
of R packages is a little rewarded burden.

Since 2010 my priorities shifted to fighting global heating by 
developing more sustainable sorting algorithms that provide better 
trade-offs between memory investments, compute costs and adaptivity to 
easier input patterns. My R&D project was successfully completed 2024 
with theory and design of new symmetric sorting algorithms that can 
replace Quicksort, Mergesort and Timsort. Lots of info at greeNsort.org. 
I have an R package `greeNsort` on github with a research testbed that 
can measure RAM, CPU and RAPL energy for ?150 equally tuned sorting 
algorithms on multiple test patterns.

Since 24.2.2022 my priorities are on strengthening resilience of 
European civil society.

Hence I happily accept the generous offer of Michael Chirico to carry 
forward the maintenance of packages `bit` and `bit64`. Please support 
him in the difficult task of developing very close to the core as a 
normal package author.

I will continue bug-fixing `ff` as time permits, although a modern C++ 
rewrite would be preferable, which

1) supports long vectors

2) avoids copying between Mapped Memory and R's memory

3) simplifies the package, particularly removes the "virtual window" 
complexity

All the best


Jens Oehlschl?gel

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 24 22:26:12 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 24 Sep 2024 13:26:12 -0700
Subject: [R] Problem with converting grib file to excel
In-Reply-To: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>
References: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>
Message-ID: <CAGxFJbQ=kRFYFpsOD0VY84fz24enHnqjDVMWqsWpSFTDKkCSfA@mail.gmail.com>

You might try posting on r-sig-geo if you don't get a satisfactory
response here. I assume there's a lot of expertise there on handling
raster-type data.

Cheers,
Bert

On Mon, Sep 23, 2024 at 11:31?PM javad bayat <j.bayat194 at gmail.com> wrote:
>
> Dear R users;
> I have downloaded a grib file format (Met.grib) and I want to export its
> data to excel file. Also I want to do some mathematic on some columns. But
> I got error. I would be more than happy if anyone can help me to do this. I
> have provided the codes and the Met.grib file in this email.
> Sincerely yours
>
> # Load the necessary libraries
> >  library(raster)      # For reading GRIB files
> >  library(dplyr)       # For data manipulation
> >  library(lubridate)   # For date manipulation
> >  library(openxlsx)    # For writing Excel files
>
> # Specify the file paths
> >  grib_file_path <- "C:/Users/Omrab_Lab/Downloads/Met.grib"
> >  excel_file_path <- "C:/Users/Omrab_Lab/Downloads/Met_updated.xlsx"
>
> # Open the GRIB file
> >  raster_data <- stack(grib_file_path)
>
> # Check the names of the layers to identify which ones to extract
> >  layer_names <- names(raster_data)
> > print(layer_names)  # Prints
>
>
> > # Extract layers based on layer names - adjust as necessary
> > t2m <- raster_data[[grep("t2m", layer_names)]]
> > d2m <- raster_data[[grep("d2m", layer_names)]]
> > tcc <- raster_data[[grep("tcc", layer_names)]]
> > valid_time <- raster_data[[grep("valid_time", layer_names)]]
> > t2m
> class      : RasterStack
> nlayers    : 0
>
> > # Check if the raster layers are loaded correctly
> > if (is.null(t2m) || is.null(d2m) || is.null(tcc) || is.null(valid_time))
> {
> +     stop("One or more raster layers could not be loaded. Please check the
> layer names.")
> + }
>
> > # Convert raster values to vectors
> > t2m_values <- values(t2m)
> Error in dimnames(x) <- dn :
>   length of 'dimnames' [2] not equal to array extent
> > d2m_values <- values(d2m)
> Error in dimnames(x) <- dn :
>   length of 'dimnames' [2] not equal to array extent
> > tcc_values <- values(tcc)
> Error in dimnames(x) <- dn :
>   length of 'dimnames' [2] not equal to array extent
> > valid_time_values <- values(valid_time)
> Error in dimnames(x) <- dn :
>   length of 'dimnames' [2] not equal to array extent
>
> # Check for NA values and dimensions
> if (any(is.na(t2m_values)) || any(is.na(d2m_values)) || any(is.na(tcc_values))
> || any(is.na(valid_time_values))) {
>   warning("One or more layers contain NA values. These will be removed.")
> }
>
> # Create the data frame, ensuring no NA values are included
> df <- data.frame(
>   t2m = t2m_values,
>   d2m = d2m_values,
>   tcc = tcc_values,
>   valid_time = valid_time_values,
>   stringsAsFactors = FALSE
> )
>
> # Remove rows with NA values
> df <- na.omit(df)
>
> # Convert temperatures from Kelvin to Celsius
> df$t2m <- df$t2m - 273.15
> df$d2m <- df$d2m - 273.15
>
> # Calculate relative humidity
> calculate_relative_humidity <- function(t2m, d2m) {
>   es <- 6.112 * exp((17.67 * t2m) / (t2m + 243.5))
>   e <- 6.112 * exp((17.67 * d2m) / (d2m + 243.5))
>   rh <- (e / es) * 100
>   return(rh)
> }
> df$RH <- calculate_relative_humidity(df$t2m, df$d2m)
>
> # Convert valid_time from numeric to POSIXct assuming it's in seconds since
> the epoch
> df$valid_time <- as.POSIXct(df$valid_time, origin = "1970-01-01")
>
> # Extract year, month, day, and hour from valid_time
> df$Year <- year(df$valid_time)
> df$Month <- month(df$valid_time)
> df$Day <- day(df$valid_time)
> df$Hour <- hour(df$valid_time)
>
> # Select only the desired columns
> df_selected <- df %>% select(Year, Month, Day, Hour, tcc, t2m, RH)
>
> # Save the updated DataFrame to an Excel file
> write.xlsx(df_selected, excel_file_path, row.names = FALSE)
>
>
>
>
>
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bekzod@@khmur@tov @end|ng |rom gm@||@com  Tue Sep 24 07:04:46 2024
From: bekzod@@khmur@tov @end|ng |rom gm@||@com (Bekzod Akhmuratov)
Date: Tue, 24 Sep 2024 00:04:46 -0500
Subject: [R] Help needed! Pre-processing the dataset before splitting -
 model building - model tuning - performance evaluation
Message-ID: <CA+vithjq8CegZSSFG=HOjEGrnU_4_3k_+_D6_ZbiyBtDR1-4QA@mail.gmail.com>

Below is the link for a dataset on focus. I want to split the dataset into
training and test set, use training set to build the model and model tune,
use test set to evaluate performance. But before doing that I want to make
sure that original dataset doesn't have noise, collinearity to address, no
major outliers so that I have to transform the data using techniques like
Box-Cox and looking at VIF to eliminate highly correlated predictors.

https://www.kaggle.com/datasets/joaofilipemarques/google-advanced-data-analytics-waze-user-data

When I fit the original dataset into regression model with Minitab, I get
attached result for residuals. It doesn't look normal. Does it mean there
is high correlation or the dataset in have nonlinear response and
predictors? How should I approach this? What would be my strategy if I use
in Python, Minitab, and R. Explaining it in all softwares are appraciated
if possible.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Residual Plots for Response.png
Type: image/png
Size: 17679 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20240924/8046d3c5/attachment.png>

From |uc@@br|nkm@nn @end|ng |rom gmx@de  Tue Sep 24 16:10:13 2024
From: |uc@@br|nkm@nn @end|ng |rom gmx@de (Luca Brinkmann)
Date: Tue, 24 Sep 2024 16:10:13 +0200
Subject: [R] Question about Date Object and time zones
Message-ID: <2d16ff91-266a-4b64-8b1c-20929fb28cb6@gmx.de>

Hello,

I have a question regarding the date objects and timezones. My current
understanding is, that a Date object does only save the days from the
origin and no more information about timezones or other information
(please correct me if I am wrong).
But if I use
d = as.Date("2024-11-11")
or
d = as.Date("2024-11-11", tz="America/New_York")
the date object is displayed in my RStudio environment as "2024-11-11
UTC". If I try to read the timezone information from the date object in
the ways possible for POSIX, I will get NULL as return:

 > attr(d, "tzone")
NULL

Also unclassing the object does not reveal any information about the
timezone, unlike for POSIX objects
 > unclass(d)
[1] 20038

In contrast, getting the timezone information with base::format will
yield the timezone information
 > base::format(d, format="%Z")
[1] "UTC"

As for my current understanding, setting the tz Argument in as.Date will
only have an effect if the input is a date-time such as POSIX and else
it has no effect and it is not possible to set a timezone for an Date
object. But is this the case if there is some timezone information
present when using base::format or in the display in the RStudio
environment? Is there any way to add timezone information to an Date
object (other than UTC) and keeping it a Date object? And if not how is
the Date object internally structured, so that it will return "UTC" when
using base::format or in the RStudio environment? Is this due to some
default behavior of R?

Best regards,

Luca


My Session Info:
R version 4.3.2 (2023-10-31 ucrt)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=German_Germany.utf8 LC_CTYPE=German_Germany.utf8???
LC_MONETARY=German_Germany.utf8
[4] LC_NUMERIC=C??????????????????? LC_TIME=German_Germany.utf8

time zone: Europe/Berlin
tzcode source: internal


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 25 10:00:34 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 25 Sep 2024 09:00:34 +0100
Subject: [R] Help needed! Pre-processing the dataset before splitting -
 model building - model tuning - performance evaluation
In-Reply-To: <CA+vithjq8CegZSSFG=HOjEGrnU_4_3k_+_D6_ZbiyBtDR1-4QA@mail.gmail.com>
References: <CA+vithjq8CegZSSFG=HOjEGrnU_4_3k_+_D6_ZbiyBtDR1-4QA@mail.gmail.com>
Message-ID: <da7df12f-adaa-4060-833b-6c70b70da079@sapo.pt>

?s 06:04 de 24/09/2024, Bekzod Akhmuratov escreveu:
> Below is the link for a dataset on focus. I want to split the dataset into
> training and test set, use training set to build the model and model tune,
> use test set to evaluate performance. But before doing that I want to make
> sure that original dataset doesn't have noise, collinearity to address, no
> major outliers so that I have to transform the data using techniques like
> Box-Cox and looking at VIF to eliminate highly correlated predictors.
> 
> https://www.kaggle.com/datasets/joaofilipemarques/google-advanced-data-analytics-waze-user-data
> 
> When I fit the original dataset into regression model with Minitab, I get
> attached result for residuals. It doesn't look normal. Does it mean there
> is high correlation or the dataset in have nonlinear response and
> predictors? How should I approach this? What would be my strategy if I use
> in Python, Minitab, and R. Explaining it in all softwares are appraciated
> if possible.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

R-Help is a list of questions and answers about R code, not to suggest 
analysis strategies. Anyhow, I suggest that you read the Python notebook 
at the bottom of the Kaggle page, it addresses your main question and if 
you have doubts translating the Python code to R code, ask us more 
specific questions on those doubts.

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |kry|ov @end|ng |rom d|@root@org  Wed Sep 25 11:40:37 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 25 Sep 2024 12:40:37 +0300
Subject: [R] Question about Date Object and time zones
In-Reply-To: <2d16ff91-266a-4b64-8b1c-20929fb28cb6@gmx.de>
References: <2d16ff91-266a-4b64-8b1c-20929fb28cb6@gmx.de>
Message-ID: <670B2FCE-037F-42B2-96BC-FF8D579F8E8D@disroot.org>

24 ???????? 2024 ?. 17:10:13 GMT+03:00, Luca Brinkmann via R-help <r-help at r-project.org> ?????:
> My current
> understanding is, that a Date object does only save the days from the
> origin and no more information about timezones or other information
> (please correct me if I am wrong).

You are correct.


> the date object is displayed in my RStudio environment as "2024-11-11
> UTC".

This looks like a result of as.POSIXlt(<Date object>).

> In contrast, getting the timezone information with base::format will
> yield the timezone information
> > base::format(d, format="%Z")
> [1] "UTC"

That's an implementation detail: the format() method for Date objects conjures a temporary POSIXlt object and formats the result, and POSIXlt objects can contain time zone information.

> Is there any way to add timezone information to an Date
> object (other than UTC) and keeping it a Date object?

Not with a plain 'Date'. What should a date in a timezone mean? Start of day? End of day? The whole 24-hour interval (except when it lasts 23 or 25 hours due to DST)?

Perhaps you could store one (or two for an interval) POSIXt object(s) if you need timezone information for your dates.

-- 
Best regards,
Ivan


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Wed Sep 25 15:23:02 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Wed, 25 Sep 2024 18:53:02 +0530
Subject: [R] How to install this package
Message-ID: <CA+dpOJmV07zMxbeMon6yOGpbNRLeYVr4hMJYhKoGsVcG0S9DAg@mail.gmail.com>

Hi,

I would like to install an R library from
https://cran.r-project.org/src/contrib/Archive/termstrc/

I executed below code without success.

Any help would be appreciated.

> install.packages('/Users/termstrc_1.3.tar.gz', repos = NULL, type="source")

* installing *source* package ?termstrc? ...

** using staged installation

** libs

using C++ compiler: ?Apple clang version 16.0.0 (clang-1600.0.26.3)?

using SDK: ?MacOSX15.0.sdk?

clang++ -arch arm64 -std=gnu++17
-I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG
-I'/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/Rcpp/include'
-I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2
-c objfcts.cpp -o objfcts.o

clang++ -arch arm64 -std=gnu++17 -dynamiclib
-Wl,-headerpad_max_install_names -undefined dynamic_lookup
-L/Library/Frameworks/R.framework/Resources/lib -L/opt/R/arm64/lib -o
termstrc.so objfcts.o -F/Library/Frameworks/R.framework/.. -framework
R -Wl,-framework -Wl,CoreFoundation

installing to /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/00LOCK-termstrc/00new/termstrc/libs

** R

** data

** demo

** byte-compile and prepare package for lazy loading

Error in dyn.load(dynlib <- getDynlib(dir)) :

  unable to load shared object
'/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so':

  dlopen(/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so,
0x0006): Library not loaded: /opt/X11/lib/libGLU.1.dylib

  Referenced from: <C90BFE0D-3008-3759-8DC8-B7FD5F3D934B>
/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so

  Reason: tried: '/opt/X11/lib/libGLU.1.dylib' (no such file),
'/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libGLU.1.dylib' (no
such file), '/opt/X11/lib/libGLU.1.dylib' (no such file),
'/Library/Frameworks/R.framework/Resources/lib/libGLU.1.dylib' (no
such file), '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libGLU.1.dylib'
(no such file)

ERROR: lazy loading failed for package ?termstrc?

* removing ?/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/termstrc?

Warning message:

In install.packages("/Users/termstrc_1.3.tar.gz",  :

  installation of package ?/Users/termstrc_1.3.tar.gz? had non-zero exit status


From |kry|ov @end|ng |rom d|@root@org  Wed Sep 25 15:29:19 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 25 Sep 2024 16:29:19 +0300
Subject: [R] How to install this package
In-Reply-To: <CA+dpOJmV07zMxbeMon6yOGpbNRLeYVr4hMJYhKoGsVcG0S9DAg@mail.gmail.com>
References: <CA+dpOJmV07zMxbeMon6yOGpbNRLeYVr4hMJYhKoGsVcG0S9DAg@mail.gmail.com>
Message-ID: <20240925162919.66db1bc2@arachnoid>

? Wed, 25 Sep 2024 18:53:02 +0530
Christofer Bogaso <bogaso.christofer at gmail.com> ?????:

> Error in dyn.load(dynlib <- getDynlib(dir)) :
> 
>   unable to load shared object
> '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so':
> 
>   dlopen(/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/rgl/libs/rgl.so,
> 0x0006): Library not loaded: /opt/X11/lib/libGLU.1.dylib

You can force-install the 'termstrc' package by giving the
INSTALL_opts='--no-test-load' argument to install.packages(), but it
still won't work because 'termstrc' requires 'rgl' to load and your
'rgl' installation doesn't work.

Try following the instructions in the README of the 'rgl' package
regarding the OpenGL support. Perhaps it needs to be reinstalled after
some updates you have applied to your Mac?

-- 
Best regards,
Ivan


From k|mmo@e|o @end|ng |rom ue|@||  Wed Sep 25 09:43:15 2024
From: k|mmo@e|o @end|ng |rom ue|@|| (Kimmo Elo)
Date: Wed, 25 Sep 2024 07:43:15 +0000
Subject: [R] Question about Date Object and time zones
In-Reply-To: <2d16ff91-266a-4b64-8b1c-20929fb28cb6@gmx.de>
References: <2d16ff91-266a-4b64-8b1c-20929fb28cb6@gmx.de>
Message-ID: <80ec1008-4acb-4732-a866-0ca3abddfb61@uef.fi>

Hi,

I might have misunderstood your point, but why should a Date object 
store a timezone, since timezone is an attribute of time, not date?

Your tz-examples force R to present a timezone, resulting - this is my 
assumption - to default (=UTC) as there is no other information available.

Best,
Kimmo

Luca Brinkmann via R-help kirjoitti 24.9.2024 klo 17.10:
> Hello,
> 
> I have a question regarding the date objects and timezones. My current
> understanding is, that a Date object does only save the days from the
> origin and no more information about timezones or other information
> (please correct me if I am wrong).
> But if I use
> d = as.Date("2024-11-11")
> or
> d = as.Date("2024-11-11", tz="America/New_York")
> the date object is displayed in my RStudio environment as "2024-11-11
> UTC". If I try to read the timezone information from the date object in
> the ways possible for POSIX, I will get NULL as return:
> 
>  > attr(d, "tzone")
> NULL
> 
> Also unclassing the object does not reveal any information about the
> timezone, unlike for POSIX objects
>  > unclass(d)
> [1] 20038
> 
> In contrast, getting the timezone information with base::format will
> yield the timezone information
>  > base::format(d, format="%Z")
> [1] "UTC"
> 
> As for my current understanding, setting the tz Argument in as.Date will
> only have an effect if the input is a date-time such as POSIX and else
> it has no effect and it is not possible to set a timezone for an Date
> object. But is this the case if there is some timezone information
> present when using base::format or in the display in the RStudio
> environment? Is there any way to add timezone information to an Date
> object (other than UTC) and keeping it a Date object? And if not how is
> the Date object internally structured, so that it will return "UTC" when
> using base::format or in the RStudio environment? Is this due to some
> default behavior of R?
> 
> Best regards,
> 
> Luca
> 
> 
> My Session Info:
> R version 4.3.2 (2023-10-31 ucrt)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 11 x64 (build 22631)
> 
> Matrix products: default
> 
> 
> locale:
> [1] LC_COLLATE=German_Germany.utf8 LC_CTYPE=German_Germany.utf8
> LC_MONETARY=German_Germany.utf8
> [4] LC_NUMERIC=C??????????????????? LC_TIME=German_Germany.utf8
> 
> time zone: Europe/Berlin
> tzcode source: internal
> 

From unw|n @end|ng |rom m@th@un|-@ug@burg@de  Wed Sep 25 15:27:13 2024
From: unw|n @end|ng |rom m@th@un|-@ug@burg@de (Antony Unwin)
Date: Wed, 25 Sep 2024 15:27:13 +0200
Subject: [R] [R-pkgs] GmooG, ChessGmooG, FilmsGmooG, ComradesM
Message-ID: <DC8E6342-2A10-4A66-8D0C-007D663DC4F6@math.uni-augsburg.de>

Dear all,

GmooG, ChessGmooG, FilmsGmooG, ComradesM are dataset packages accompanying my book ?Getting (more out of) Graphics? (CRC Press 2024).  They are now available on CRAN.  R code producing the graphics in the book will be put online in a few weeks.

Regards

Antony

Professor Antony Unwin
Mathematics Institute,
University of Augsburg, 
86135 Augsburg, Germany




	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 25 20:09:44 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Sep 2024 11:09:44 -0700
Subject: [R] OFF TOPIC: "Scientific rigor proponents retract paper on
 benefits of scientific rigor"
Message-ID: <CAGxFJbSuWxSafwGC+m3bDiBqMzHrsckmns1OfZS1Go73H-BjAA@mail.gmail.com>

This is off topic and only tangentially related to statistics or R
(through "HARK"ing -- Hypothesizing After Results are Known). But
given the research interests of many on this list, I thought others
would enjoy it. My apologies if I have overstepped (please let me know
if so). Also, PLEASE DON'T RESPOND ON THIS LIST (privately is fine).
This is just FYI.

I don't know whether the (short) article is pay walled, but here's the
main message:

"A high-profile paper about ways to improve the rigor of research
papers has been retracted after critics attacked its own rigor. The
study, published on 9 November 2023 in Nature Human Behaviour,
purported to show the benefits of rigor-boosting measures including
so-called preregistration?announcing the goals, methods, and other
planned features of a study ahead of time?large sample sizes, and
methodological transparency. It reported that these measures boosted
the ?replicability? of 16 findings in social-behavioral science to
86%, far more than the 30% to 70% reported in some analyses.

?Editors no longer have confidence in the reliability of the findings
and conclusions reported in this article,? the journal said in a
retraction note published yesterday.

?The concerns relate to lack of transparency and misstatement of the
hypotheses and predictions the reported metastudy was designed to
test; lack of preregistration for measures and analyses supporting the
titular claim (against statements asserting preregistration in the
published article); selection of outcome measures and analyses with
knowledge of the data; and incomplete reporting of data and analyses,?
the note says."

Full article here:
https://www.science.org/content/article/we-are-embarrassed-scientific-rigor-proponents-retract-paper-benefits-scientific-rigor

Cheers to all,
Bert


From po|c1410 @end|ng |rom gm@||@com  Thu Sep 26 00:24:16 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Wed, 25 Sep 2024 23:24:16 +0100
Subject: [R] Problem with converting grib file to excel
In-Reply-To: <CAGxFJbQ=kRFYFpsOD0VY84fz24enHnqjDVMWqsWpSFTDKkCSfA@mail.gmail.com>
References: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>
 <CAGxFJbQ=kRFYFpsOD0VY84fz24enHnqjDVMWqsWpSFTDKkCSfA@mail.gmail.com>
Message-ID: <CA+etgPkH_F-f_ZOnQRLcucsug0U5cR7yB7VQvP7f4etC+ae-ew@mail.gmail.com>

Noticeable lack of silence in the group on this one.

I've not got time to test currently. But my experience of geo location
files - they often had more than 2 dimensional data. In other words you
might have a boundary of a region as an object with long and lat for maybe
100 data points making up the region. So 200 pieces of data. All held as a
list or something similar in a single "cell" as excel would refer to it.

My gut feeling is that's likely to make export to excel difficult without
data carpentry first?

On Tue, 24 Sep 2024, 21:26 Bert Gunter, <bgunter.4567 at gmail.com> wrote:

> You might try posting on r-sig-geo if you don't get a satisfactory
> response here. I assume there's a lot of expertise there on handling
> raster-type data.
>
> Cheers,
> Bert
>
> On Mon, Sep 23, 2024 at 11:31?PM javad bayat <j.bayat194 at gmail.com> wrote:
> >
> > Dear R users;
> > I have downloaded a grib file format (Met.grib) and I want to export its
> > data to excel file. Also I want to do some mathematic on some columns.
> But
> > I got error. I would be more than happy if anyone can help me to do
> this. I
> > have provided the codes and the Met.grib file in this email.
> > Sincerely yours
> >
> > # Load the necessary libraries
> > >  library(raster)      # For reading GRIB files
> > >  library(dplyr)       # For data manipulation
> > >  library(lubridate)   # For date manipulation
> > >  library(openxlsx)    # For writing Excel files
> >
> > # Specify the file paths
> > >  grib_file_path <- "C:/Users/Omrab_Lab/Downloads/Met.grib"
> > >  excel_file_path <- "C:/Users/Omrab_Lab/Downloads/Met_updated.xlsx"
> >
> > # Open the GRIB file
> > >  raster_data <- stack(grib_file_path)
> >
> > # Check the names of the layers to identify which ones to extract
> > >  layer_names <- names(raster_data)
> > > print(layer_names)  # Prints
> >
> >
> > > # Extract layers based on layer names - adjust as necessary
> > > t2m <- raster_data[[grep("t2m", layer_names)]]
> > > d2m <- raster_data[[grep("d2m", layer_names)]]
> > > tcc <- raster_data[[grep("tcc", layer_names)]]
> > > valid_time <- raster_data[[grep("valid_time", layer_names)]]
> > > t2m
> > class      : RasterStack
> > nlayers    : 0
> >
> > > # Check if the raster layers are loaded correctly
> > > if (is.null(t2m) || is.null(d2m) || is.null(tcc) ||
> is.null(valid_time))
> > {
> > +     stop("One or more raster layers could not be loaded. Please check
> the
> > layer names.")
> > + }
> >
> > > # Convert raster values to vectors
> > > t2m_values <- values(t2m)
> > Error in dimnames(x) <- dn :
> >   length of 'dimnames' [2] not equal to array extent
> > > d2m_values <- values(d2m)
> > Error in dimnames(x) <- dn :
> >   length of 'dimnames' [2] not equal to array extent
> > > tcc_values <- values(tcc)
> > Error in dimnames(x) <- dn :
> >   length of 'dimnames' [2] not equal to array extent
> > > valid_time_values <- values(valid_time)
> > Error in dimnames(x) <- dn :
> >   length of 'dimnames' [2] not equal to array extent
> >
> > # Check for NA values and dimensions
> > if (any(is.na(t2m_values)) || any(is.na(d2m_values)) || any(is.na
> (tcc_values))
> > || any(is.na(valid_time_values))) {
> >   warning("One or more layers contain NA values. These will be removed.")
> > }
> >
> > # Create the data frame, ensuring no NA values are included
> > df <- data.frame(
> >   t2m = t2m_values,
> >   d2m = d2m_values,
> >   tcc = tcc_values,
> >   valid_time = valid_time_values,
> >   stringsAsFactors = FALSE
> > )
> >
> > # Remove rows with NA values
> > df <- na.omit(df)
> >
> > # Convert temperatures from Kelvin to Celsius
> > df$t2m <- df$t2m - 273.15
> > df$d2m <- df$d2m - 273.15
> >
> > # Calculate relative humidity
> > calculate_relative_humidity <- function(t2m, d2m) {
> >   es <- 6.112 * exp((17.67 * t2m) / (t2m + 243.5))
> >   e <- 6.112 * exp((17.67 * d2m) / (d2m + 243.5))
> >   rh <- (e / es) * 100
> >   return(rh)
> > }
> > df$RH <- calculate_relative_humidity(df$t2m, df$d2m)
> >
> > # Convert valid_time from numeric to POSIXct assuming it's in seconds
> since
> > the epoch
> > df$valid_time <- as.POSIXct(df$valid_time, origin = "1970-01-01")
> >
> > # Extract year, month, day, and hour from valid_time
> > df$Year <- year(df$valid_time)
> > df$Month <- month(df$valid_time)
> > df$Day <- day(df$valid_time)
> > df$Hour <- hour(df$valid_time)
> >
> > # Select only the desired columns
> > df_selected <- df %>% select(Year, Month, Day, Hour, tcc, t2m, RH)
> >
> > # Save the updated DataFrame to an Excel file
> > write.xlsx(df_selected, excel_file_path, row.names = FALSE)
> >
> >
> >
> >
> >
> >
> > --
> > Best Regards
> > Javad Bayat
> > M.Sc. Environment Engineering
> > Alternative Mail: bayat194 at yahoo.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Thu Sep 26 01:02:50 2024
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 25 Sep 2024 16:02:50 -0700
Subject: [R] Problem with converting grib file to excel
In-Reply-To: <CA+etgPkH_F-f_ZOnQRLcucsug0U5cR7yB7VQvP7f4etC+ae-ew@mail.gmail.com>
References: <CANTxAmLoVGTLFum98dufmWtO6yHaBj35j6=AskUPuJALs0k6AA@mail.gmail.com>
 <CAGxFJbQ=kRFYFpsOD0VY84fz24enHnqjDVMWqsWpSFTDKkCSfA@mail.gmail.com>
 <CA+etgPkH_F-f_ZOnQRLcucsug0U5cR7yB7VQvP7f4etC+ae-ew@mail.gmail.com>
Message-ID: <6352A887-768E-473A-BAEF-423BE7080B43@noaa.gov>

At least for me the dataset file did not come through.  I will look at it if it can be made available.  It does look like the finial step of reading the data into raster failed,  so then did the rest of th commands.

-Roy


> On Sep 25, 2024, at 3:24 PM, CALUM POLWART <polc1410 at gmail.com> wrote:
> 
> Noticeable lack of silence in the group on this one.
> 
> I've not got time to test currently. But my experience of geo location
> files - they often had more than 2 dimensional data. In other words you
> might have a boundary of a region as an object with long and lat for maybe
> 100 data points making up the region. So 200 pieces of data. All held as a
> list or something similar in a single "cell" as excel would refer to it.
> 
> My gut feeling is that's likely to make export to excel difficult without
> data carpentry first?
> 
> On Tue, 24 Sep 2024, 21:26 Bert Gunter, <bgunter.4567 at gmail.com> wrote:
> 
>> You might try posting on r-sig-geo if you don't get a satisfactory
>> response here. I assume there's a lot of expertise there on handling
>> raster-type data.
>> 
>> Cheers,
>> Bert
>> 
>> On Mon, Sep 23, 2024 at 11:31?PM javad bayat <j.bayat194 at gmail.com> wrote:
>>> 
>>> Dear R users;
>>> I have downloaded a grib file format (Met.grib) and I want to export its
>>> data to excel file. Also I want to do some mathematic on some columns.
>> But
>>> I got error. I would be more than happy if anyone can help me to do
>> this. I
>>> have provided the codes and the Met.grib file in this email.
>>> Sincerely yours
>>> 
>>> # Load the necessary libraries
>>>> library(raster)      # For reading GRIB files
>>>> library(dplyr)       # For data manipulation
>>>> library(lubridate)   # For date manipulation
>>>> library(openxlsx)    # For writing Excel files
>>> 
>>> # Specify the file paths
>>>> grib_file_path <- "C:/Users/Omrab_Lab/Downloads/Met.grib"
>>>> excel_file_path <- "C:/Users/Omrab_Lab/Downloads/Met_updated.xlsx"
>>> 
>>> # Open the GRIB file
>>>> raster_data <- stack(grib_file_path)
>>> 
>>> # Check the names of the layers to identify which ones to extract
>>>> layer_names <- names(raster_data)
>>>> print(layer_names)  # Prints
>>> 
>>> 
>>>> # Extract layers based on layer names - adjust as necessary
>>>> t2m <- raster_data[[grep("t2m", layer_names)]]
>>>> d2m <- raster_data[[grep("d2m", layer_names)]]
>>>> tcc <- raster_data[[grep("tcc", layer_names)]]
>>>> valid_time <- raster_data[[grep("valid_time", layer_names)]]
>>>> t2m
>>> class      : RasterStack
>>> nlayers    : 0
>>> 
>>>> # Check if the raster layers are loaded correctly
>>>> if (is.null(t2m) || is.null(d2m) || is.null(tcc) ||
>> is.null(valid_time))
>>> {
>>> +     stop("One or more raster layers could not be loaded. Please check
>> the
>>> layer names.")
>>> + }
>>> 
>>>> # Convert raster values to vectors
>>>> t2m_values <- values(t2m)
>>> Error in dimnames(x) <- dn :
>>>  length of 'dimnames' [2] not equal to array extent
>>>> d2m_values <- values(d2m)
>>> Error in dimnames(x) <- dn :
>>>  length of 'dimnames' [2] not equal to array extent
>>>> tcc_values <- values(tcc)
>>> Error in dimnames(x) <- dn :
>>>  length of 'dimnames' [2] not equal to array extent
>>>> valid_time_values <- values(valid_time)
>>> Error in dimnames(x) <- dn :
>>>  length of 'dimnames' [2] not equal to array extent
>>> 
>>> # Check for NA values and dimensions
>>> if (any(is.na(t2m_values)) || any(is.na(d2m_values)) || any(is.na
>> (tcc_values))
>>> || any(is.na(valid_time_values))) {
>>>  warning("One or more layers contain NA values. These will be removed.")
>>> }
>>> 
>>> # Create the data frame, ensuring no NA values are included
>>> df <- data.frame(
>>>  t2m = t2m_values,
>>>  d2m = d2m_values,
>>>  tcc = tcc_values,
>>>  valid_time = valid_time_values,
>>>  stringsAsFactors = FALSE
>>> )
>>> 
>>> # Remove rows with NA values
>>> df <- na.omit(df)
>>> 
>>> # Convert temperatures from Kelvin to Celsius
>>> df$t2m <- df$t2m - 273.15
>>> df$d2m <- df$d2m - 273.15
>>> 
>>> # Calculate relative humidity
>>> calculate_relative_humidity <- function(t2m, d2m) {
>>>  es <- 6.112 * exp((17.67 * t2m) / (t2m + 243.5))
>>>  e <- 6.112 * exp((17.67 * d2m) / (d2m + 243.5))
>>>  rh <- (e / es) * 100
>>>  return(rh)
>>> }
>>> df$RH <- calculate_relative_humidity(df$t2m, df$d2m)
>>> 
>>> # Convert valid_time from numeric to POSIXct assuming it's in seconds
>> since
>>> the epoch
>>> df$valid_time <- as.POSIXct(df$valid_time, origin = "1970-01-01")
>>> 
>>> # Extract year, month, day, and hour from valid_time
>>> df$Year <- year(df$valid_time)
>>> df$Month <- month(df$valid_time)
>>> df$Day <- day(df$valid_time)
>>> df$Hour <- hour(df$valid_time)
>>> 
>>> # Select only the desired columns
>>> df_selected <- df %>% select(Year, Month, Day, Hour, tcc, t2m, RH)
>>> 
>>> # Save the updated DataFrame to an Excel file
>>> write.xlsx(df_selected, excel_file_path, row.names = FALSE)
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> --
>>> Best Regards
>>> Javad Bayat
>>> M.Sc. Environment Engineering
>>> Alternative Mail: bayat194 at yahoo.com
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From Scott@W@|ch|er @end|ng |rom pnn|@gov  Thu Sep 26 02:13:25 2024
From: Scott@W@|ch|er @end|ng |rom pnn|@gov (Waichler, Scott R)
Date: Thu, 26 Sep 2024 00:13:25 +0000
Subject: [R] plotting sf with lattice
In-Reply-To: <CO6PR09MB8216FB87234CB4AB50B415EAE8692@CO6PR09MB8216.namprd09.prod.outlook.com>
References: <CO6PR09MB8216FB87234CB4AB50B415EAE8692@CO6PR09MB8216.namprd09.prod.outlook.com>
Message-ID: <CO6PR09MB82165C67C4DBBF6B545FB1E1E86A2@CO6PR09MB8216.namprd09.prod.outlook.com>


Hi, I want to plot 2d cross sections from physical model output in a 3d domain, where the same cross section is represented at different times in the lattice panels.  The cross section is a set of sf polygons, where one attribute is being plotted, with a color ramp.  Can anyone point me to an example of using lattice to plot Simple Feature polygons?  I'm still learning sf and can't find any advice for using it with lattice.

Thank you,

Scott Waichler, PhD

Pacific Northwest National Lab

Washington, USA



	[[alternative HTML version deleted]]


